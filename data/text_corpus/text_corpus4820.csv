index,text
24100,the traditional formulation of three dimensional variational 3dvar data assimilation schemes for oceanographic applications neglects the temporal evolution of background errors within and across assimilation temporal windows such a simplification may be limiting for many climate e g reanalyses and operational e g medium range forecast applications this work explores possible extensions of the oceanvar data assimilation code aiming at overcoming these limitations general formulations are proposed and implemented in order to extend the 3dvar scheme of oceanvar into a simplified hybrid ensemble variational four dimensional variational 4dvar assimilation scheme where i background error covariances combine stationary and flow dependent components through an augmented control vector and ii a simplified tangent linear and adjoint model which assumes that only temperature and salinity are independent variables these extensions are shown to allow the background error covariances to follow the time varying structure typical of climate modes like enso and to shape the analysis increments in agreement with the underlying ocean circulation respectively the two extensions are cross compared in terms of computational time cost and accuracy and further combined together into a hybrid 4dvar scheme the hybrid formulation provides in general largely positive impact at short forecast ranges while 4dvar at long ones the hybrid 4dvar scheme improves the verification skill scores in most cases keywords 4dvar ocean reanalysis ocean forecasts tangent linear model 1 introduction owing to the requirements of long term climate prediction systems e g seasonal forecasts and activities that rely on operational ocean forecasting e g search and rescue route optimization oil spill etc oceanographic data assimilation schemes are a crucial component of environmental monitoring this is testified by the growing attention devoted to them by international programs during the last decade such as in europe the copernicus marine environment monitoring service cmems supported by the european union through the european commission directorate on enterprise and industry a number of data assimilation systems have therefore been developed during the last two decades for both operational and reanalysis applications e g martin et al 2015 masina et al 2017 new hybrid data assimilation algorithms that merge advantages of ensemble and variational schemes have been mostly developed to improve the accuracy of operational numerical weather prediction nwp as suggested for instance by the review article of bannister 2017 oceanographic data assimilation has some delay in following meteorological data assimilation advances several reasons concur to this nwp shows a much larger impact than ocean forecasts on diverse aspects of our daily life that can potentially affect the economy and the safety of human activities on a short time scale furthermore on a technical ground the much less dense observing network that has implications on the feasibility of the schemes e g preventing the reliability of ensemble derived error statistics panteleev et al 2015 while atmospheric data assimilation systems in operational centers mostly rely on four dimensional data assimilation recently upgraded to hybrid ensemble variational formulation e g at the european centre for medium range weather forecasts ecmwf bonavita et al 2012 at the metoffice clayton et al 2013 and at météo france raynaud et al 2011 the extension of three dimensional data assimilation systems to hybrid four dimensional is more limited and recent in time within the oceanic forecasting community potential advantages of 4dvar with respect to 3dvar reside in the 4dvar ability to implicitly evolve covariances within the assimilation time window through the tangent linear model approximation thus shaping the analysis increments consistently with the actual circulation lorenc 2003a the tangent linear assumption required in the 4dvar formulation limits its time window length although the weak constraint formulation where the tangent linear model is not assumed to be perfect may alleviate this weakness fisher et al 2011 4dvar has however very large costs not only in terms of computational demand due to the tangent linear and adjoint model integrations at every minimization iteration but also in terms of human resources needed for software coding and maintenance software engineering behind tangent linear and adjoint model is indeed non trivial and even when automatic differentiation tools are adopted manual intervention is still required elizondo et al 2002 such a limitation has fostered the development of adjoint free 4dvar formulations that in different ways exploit the information about model error temporal covariances implicitly contained in ensemble systems e g yaremchuk et al 2009 bishop et al 2017 yaremchuk et al 2017 only a few ocean data assimilation systems support 4dvar for instance the regional ocean modelling system roms moore et al 2011 allows for strong and weak constraint four dimensional data assimilation and it is used for regional applications both reanalyses and operational oceanography still for regional applications the u s naval research laboratory has developed a 4dvar system coupled with the navy coastal ocean model ngodock and carrier 2014 recently extended to allow weak constraint data assimilation ngodock et al 2016 for global applications the mit ogcm has been recently complemented with a 4dvar data assimilation capability fenty et al 2017 the nemovar variational code weaver et al 2003 developed by the nemovar consortium implements the possibility of running 4dvar when it is coupled to the nemotam package i e the tangent linear and adjoint version of the nemo ocean model vidard et al 2015 although all real world implementations for reanalysis or forecast applications still use a three dimensional formulation e g waters et al 2015 it is thus clear that the oceanographic community lacks detailed assessments of the potential benefits of four dimensional versus three dimensional data assimilation which is among the objectives of the present work furthermore comparisons between variational and ensemble methods have been outlined several times within global nwp applications lorenc 2003b kalnay et al 2007 fairbairn et al 2014 but never with ocean applications unlike variational data assimilation methods ensemble based filters include a flow dependent definition of error covariances implicit in the time evolving ensemble based cross covariances a step forward towards more accurate error characterization might reside in the use of hybrid static ensemble background error covariances in the variational scheme this relatively simple extension relaxes the assumption of stationarity of the background errors thus hybrid 4dvar schemes overcome the 3dvar limitation of stationarity of covariances either across through flow dependent covariance component or within through the implicit 4dvar propagation of covariances assimilation time windows hybrid covariance methods have been introduced by hamill and snyder 2000 who demonstrated how variational methods can benefit from incorporating information about the error of the day conversely ensemble methods may benefit from the variational solution scheme and from the incorporation of stationary covariances that can limit problems arising from limited size ensemble systems since then hybrid methods have become popular in nwp and are now implemented in many short and medium range operational forecast systems in europe e g bonavita et al 2012 clayton et al 2013 and at the u s national centers for environmental prediction ncep wang et al 2013 hybrid covariance formulation of data assimilation systems for ocean applications is emerging recently testified by only a few works at global penny et al 2015 and regional oddo et al 2016 scales although growing attention is being devoted to include ensemble based background error covariances in many ocean variational data assimilation schemes e g in nemovar weaver et al 2018 theoretical justification of the use of hybrid covariances has been recently highlighted the work of bishop and satterfield 2013 and bishop et al 2013 on hidden variances shows that features such as unknown sources of model error finite ensemble size and ensemble covariance localization may limit the optimality of the mere use of ensemble based covariances furthermore they provide a mathematical framework to combine stationary and ensemble based covariances in the context of impulsive synchronization perspective penny 2017 showed that hybrid data assimilation methods are able to recover the lost stability found when ensemble methods are implemented with limited ensemble size and cannot represent the unstable modes the work of ménétrier and auligné 2015 has also a similar aim the authors apply a linear filtering framework to sample covariances in order to simultaneously optimize hybridization weights and localization parameters however it should be noted that it is customary in real world applications to perform sensitivity tests to identify the optimal hybrid weight that maximizes certain skill scores in this work we summarize the latest developments in the oceanvar data assimilation code originally developed by fondazione cmcc centro euro mediterraneo sui cambiamenti climatici see dobricic and pinardi 2008 and used for both global and regional reanalysis and operational oceanography applications e g adani et al 2011 storto and masina 2016 in the context of cmems the developments include i the support of hybrid formulation for background error covariances either vertical only or both vertical and horizontal covariances and ii a new four dimensional variational formulation that required the development of a simplified tangent linear and adjoint model these approaches are compared to the original 3dvar formulation in terms of derivation computational costs and accuracy the article is structured as follows section 2 introduces the original oceanvar formulation and the experimental setup section 3 describes the new hybrid and 4dvar formulation and developments showing case studies to assess their potential benefits section 4 cross compares the new developments with respect to the original 3dvar in terms of both computational demand and accuracy while section 5 discusses the main achievements and future plans 2 original formulation of oceanvar the assimilation scheme presented here is called oceanvar it was originally developed for the mediterranean sea forecasting system dobricic and pinardi 2008 and later adapted to global ocean configurations storto et al 2011 mostly for reanalysis applications storto et al 2016 storto and masina 2016 oceanvar implements the tangent linear approximation to the observational term of the cost function the tangent linear assumption considers a taylor expansion for the model equivalents in observation space considering the ocean state x and the vector of observations y their difference is approximated with the following rule chain where x b is the ocean background state 1 h m x y h m x b h m δ x y hm δ x d where h is the observation function mapping the ocean state in model space into observation space and m is the non linear model function propagating forward in time the ocean state h and m are their respective tangent linear operators formally defined as h h x x m x b and m m x x m x b d y h m x b is the innovation vector and it may be calculated online during the model integration in the traditional 3dvar formulation of oceanvar with the first guess at appropriate time fgat the temporal evolution of the ocean state within the assimilation window is neglected for the analysis solution m i and 2 h m x y h δ x d while the definition of d remains unchanged keeping the use of the non linear model function the 3dvar cost function in its incremental formulation e g courtier 1997 where δ x x x b reads 3 j δ x 1 2 h δ x d t r 1 h δ x d 1 2 δ x t b 1 δ x b and r are the background and observation error covariance matrices respectively the latter being assumed to be diagonal i e observational errors are mutually uncorrelated the analysis is defined as x a x b δ x at the minimum of j the cost function formulation eq 3 can be derived from bayes theorem assuming gaussian errors for the background and observations lorenc 1986 and neglecting the evolution of the ocean state within the assimilation time window oceanvar optionally implements variational quality control varqc of observations in which case the cost function is modified to account for a non gaussian probability density function pdf for the observation errors storto 2016 however we keep eq 3 with the purely gaussian pdf for sake of simplicity varqc implying a different formulation of the observational term of the cost function i e the first term on the right hand side of eq 3 the control variable transformation is used in oceanvar to precondition the minimization problem the minimization is performed with respect to the control variable v such that δ x vv and v v δ x with v the generalized inverse of v and b vv t substituting the previous relationships in the cost function we obtain 4 j v 1 2 h v v d t r 1 h v v d 1 2 v t v the gradient of j is evaluated during the minimization for use with the limited memory quasi newton minimizer l bfgs byrd et al 1995 which is required for non quadratic cost functions for instance in the case of varqc dharssi et al 1992 the gradient is given by 5 j v v t h t r 1 h v v d v the minimization convergence is reached when the infinity norm of the gradient maximum of the absolute value of the gradient components falls behind a certain threshold multiplied by the infinity norm of the initial cost function gradient here the threshold used is 2 modeling background error covariances is equivalent to applying the operator v square root of b which is in turn decomposed in a sequence of operators assuming separability of horizontal and vertical scales in a general form 6 v v f v b v h v v v v is the square root vertical covariance operator that is modelled through multi variate empirical orthogonal functions eofs namely v v s λ 1 2 where columns of s contain multivariate eigenvectors and λ is a diagonal matrix with the corresponding eigenvalues a remapping function r i j such that for each model grid point i j vertical covariances are defined as v v i j s r i j λ r i j 1 2 is used to remap the grid where eofs are defined into the model grid this feature permits that eofs are defined on a different grid than the model e g at a resolution lower than the model grid note that eofs are forced to linearly decrease to zero between depths of 1600 m and 2000 m in order not to produce potentially spurious increments and drifts within the deep unobserved ocean horizontal correlations are modeled through the application of a recursive filter operator v h the filter may be chosen to be first or third order farina et al 2015 periodic and bathymetric boundary conditions may be achieved either with an artificial grid extension approach or with analytic boundary conditions mirouze and storto 2016 the recursive filter coefficients depend on the model grid spacing and the correlation length scales which can be spatially varying provided that they vary slowly in space storto et al 2014 and respect the stability criterion provided by mirouze and storto 2016 the operator v b controls the balances among the state variables and has different options in oceanvar depending on the applications and computational resources there exist options for strong constraint balances where both sea level the dynamic height of storto et al 2011 or the barotropic model of dobricic and pinardi 2008 and currents summing barotropic and baroclinic increments as in weaver et al 2005 depend only on temperature and salinity when these strong constraint balances are used the data assimilation state vector is formed only by temperature and salinity the other parameters being defined unambiguously by these balances alternatively the balances described above can also be used as weak constraint balances in this case as described by derber and bouttier 1999 and weaver et al 2005 the physical variable is the sum of balanced and unbalanced components when this option is used the unbalanced component variables are included in the multi variate vertical eofs which in turn are computed including the residuals of the balances for sea level and currents these options permit large flexibility in oceanvar in terms of ocean state vector and balance formulation which can be diversified depending on the area of study resolution and observing network assimilated 2 1 ocean model and experimental configuration we shortly introduce here the configuration used in the experiments presented in sections 3 and 4 the ocean model component is nemo v3 6 madec et al 1998 coupled with the lim2 sea ice model fichefet and morales maqueda 1997 with elasto visco plastic rheology bouillon et al 2009 implemented at the 2 resolution with meridional resolution refinement up to 0 5 in the tropics the resolution peaks to 50 km in the tropics decreases to 200 km at mid latitudes and increases again to about 100 km at high latitudes the vertical discretization consists of 31 vertical zeta levels and partial steps barnier et al 2006 the thickness of the vertical layers ranges from about 10 m at the sea surface to about 500 m at the ocean bottom the horizontal grid of nemo is tripolar madec and imbard 1996 the ocean model is forced by the ecmwf era interim atmospheric reanalysis dee et al 2011 at 0 75 of horizontal resolution using the bulk formulas of large and yeager 2004 turbulent parameters wind and temperature and humidity at 10 and 2 m above ground respectively from era interim are provided with 6 hourly frequency while radiative and freshwater fluxes are provided daily in order to apply the analytic diurnal modulation of bernie et al 2007 and resolve the diurnal cycle of the shortwave radiative flux the coupling frequency between the atmospheric forcing and the ocean model is 6 hourly which also corresponds to the coupling frequency between the ocean and the sea ice model this configuration although being at coarser resolution than most configurations used for reanalysis and operational oceanography represents a cheap benchmark configuration for testing data assimilation developments in the experiments presented in the following sections all the hydrographic profiles present in en4 good et al 2013 are assimilated which include argo floats ctds xbts moorings and measurements from sensors borne by marine mammals table 1 summarizes the number of observations by year observation type and latitudinal band highlighting the different distribution of the observing network in particular argo floats become the most numerous observing network since 2006 with a generally similar distribution among the three bands summing up the different network indicates that the largest number of profiles is located in the north extra tropics both the assimilation time window and the frequency of the analysis computation are set equal to 15 days we experienced small differences between 3dvar and 4dvar for assimilation windows shorter than one week due to the slowly evolving ocean circulation especially in relatively coarse resolution configurations the configuration of oceanvar used in this study includes only temperature and salinity in the control vector as we test our data assimilation extensions in the simple case where only temperature and salinity profiles are used the preferred sea level balance is the dynamic height as in the configuration used at cmcc for eddy permitting reanalyses storto et al 2016 analysis increments of currents are not produced nor applied 3 extensions to the 3dvar scheme 3 1 oceanvar with hybrid background error covariances 3 1 1 formulation the recourse to hybrid background error covariances that combine static and flow dependent e g ensemble derived has become popular during the last decade because it provides a relatively easy framework to introduce flow dependent error structures in variational schemes while keeping their robustness oceanvar has been accordingly extended in order to use hybrid covariances the implementation partly follows the approach originally proposed by buehner 2005 where the control vector is augmented by a part associated with the flow dependent covariances however while buehner 2005 uses a spatially localized representation of the ensemble derived sample covariances also the flow dependent component is here formulated as a covariance model similar to eq 6 in terms of the control vector transformation the formulation reads 7 δ x β c v c v c β e v e v e where v c and v e are the control vectors associated with the climatological static b c v c v c t and ensemble derived flow dependent covariances b e v e v e t respectively following wang et al 2007 and oddo et al 2016 such a formulation is equivalent to consider a hybrid background error covariance matrix of the form 8 b α b c 1 α b e where β c 2 α and β e 2 1 α oddo et al 2016 see in particular their appendix a demonstrated that when the vectors v c and v e are independent i e they span different uncertainty modes the cost function with hybrid covariances becomes 9 j v c v e 1 2 h β c v c v c β e v e v e d t r 1 h β c v c v c β e v e v e d 1 2 v c t v c 1 2 v e t v e and the gradient of the cost function with respect to the two control vectors is thus given by 10 j v c β c v c t h t r 1 h β c v c v c β e v e v e d v c and 11 j v e β e v e t h t r 1 h β c v c v c β e v e v e d v e in practice the two background error covariance sets may be built to sample different spatial scales in order to satisfy the assumption of independence where typically the ensemble derived statistics bear smaller scale features than the static ones which is however not straight forward to verify in real world experiments note also that both formulations of v e and v c rely on multivariate eofs to model vertical covariances the independence is therefore linked also to the orthogonality of the two sets of eofs in the case where flow dependent covariances come from an ensemble system localization procedures aiming at removing long range spurious covariances due to the fact that the ensemble system is of limited size and under samples the covariance matrix may be introduced following houtekamer and mitchell 2001 and wang et al 2007 but are not used here alternatively or complementary to localization strategies filtering of background error covariances may be introduced to eliminate spurious and noisy correlations see e g berre and desroziers 2010 for a review of strategies it is also important to note that the hybrid formalism presented above may also be used for multi scale data assimilation in a way similar to that proposed by mirouze et al 2016 the two sets of background error covariances may be conceived to represent different scales and the hybrid weight chosen accordingly rather than being associated with static and ensemble covariances thus the hybrid analysis of eq 9 is actually a powerful and general way to combine different error statistics in practice the way how v e is defined follows the same formulation as v c ensemble anomalies are not used directly in the assimilation scheme but are used to calculate ensemble derived eofs in the vertical covariance operator v v e and horizontal correlation length scales in the horizontal recursive filter operator v h e 3 1 2 further simplification we now introduce a simplification of the hybrid scheme presented above we consider as hybrid only the vertical covariances while leaving static horizontal correlations this simplification requiring orthogonality of the two eof sets formally reads 12 δ x v f v b v h β c v v c v c β e v v e v e thus v v c represents the static eofs invariant among successive years v v e represents the ensemble derived flow dependent eofs in the experimental results section we will assess this assumption compared to the full use of ensemble derived covariances i e also to modulate the horizontal covariances there is a twofold advantage in the previous simplification the horizontal recursive filter is the most expensive operator implemented in oceanvar and this simplification avoids its double application on the two control vectors thus resulting in a scheme approximately as cheap as the standard 3dvar except obviously for the underlying need of running an ensemble system in parallel for reanalysis applications this can be advantageous when the ensemble system is run offline which is the case where first the ensemble data assimilation experiments are performed to cover the reanalysed period and then flow dependent background error covariances are calculated and used in a follow on experiment with hybrid covariances conversely if the system is run online for instance in an operational context namely with simultaneous advancement of both the ensemble system and the analysis system with hybrid covariances this simplification will not provide significant benefits in terms of computational cost as the largest cost is given by the ensemble system itself in the latter case this simplification might become unimportant furthermore the estimation of flow dependent correlation length scales from an ensemble of very limited size is non trivial and often produces spurious results even when localization procedures are implemented thus this simplification avoids the need of calculating ensemble derived length scales however it is clear that neglecting the use of hybrid horizontal correlations misses an important flow dependent aspect affecting the horizontal propagation of the observations for instance in the case of eddy dominated regions temporally evolving oceanic fronts etc 3 1 3 optimal hybrid weight the hybrid covariance formulation of oceanvar requires the specification of the hybrid coefficient that determines the relative weight given to stationary and flow dependent covariance in the assimilation it is customary to determine the optimal weight based on sensitivity experiments namely choosing the weight that leads to the best forecast skill scores recently ménétrier and auligné 2015 proposed an estimation method of hybrid weights based on linear filtering of sample covariances which simultaneously optimizes the hybrid weight and localization parameters as a function of the asymptotic error covariance and the ensemble size if localization is not explicitly included as in our formulation of eq 9 such an optimization procedure might be difficult to apply a practical issue concerns the optimality of the perturbations applied to the ensemble system which may not necessarily represent the real world error sources bishop and satterfield 2013 a usual way to overcome this issue is to perform sensitivity tests to determine the optimal hybrid weight for a certain ensemble system ensemble size and ensemble generation note also that α could be a function of the spatial coordinates e g varying horizontally and or vertically although this option is not considered here because it includes additional degrees of freedom in the analysis system and requires reliable local estimates of α also in regions characterized by poor observational sampling e g high latitudes south hemisphere or deep ocean alternatively a simple diagnostics expression based on the posterior assimilation statistics of desroziers et al 2005 may be formulated by substituting the hybrid form for b 13 e h δ x d t hbh t h α b c 1 α b e h t where hδx d t are assimilation output diagnostics and the two background error covariance matrices are known eq 13 is applied using all available observation departure data namely it provides a globally averaged estimate b c and b e are the background error covariance sets used in the assimilation run from which misfits d and increments δx are evaluated this suggests that the formula can be applied iteratively to successively retune the hybrid weight as in the original formulation of desroziers et al 2005 although eq 13 can be analytically solved in α we are here interested in evaluating its behavior with time rather than finding its stationary value to this end eq 13 is later applied during each assimilation cycle to diagnose the optimal hybrid weight 3 1 4 ensemble variational data assimilation the hybrid covariance formulation requires the estimation of flow dependent background error covariances to complement stationary covariances there may exist several ways to estimate flow dependent covariances for instance using pre existing ensemble prediction systems eps as done by clayton et al 2013 a simple and effective way is the recourse to an ensemble variational data assimilation eda system which includes several realizations of the deterministic system through perturbation of relevant input data and has the advantage that ensemble and deterministic realizations share the same data assimilation system fisher 2003 for long term applications i e reanalyses the system can be thought as an offline ensemble system although this prevents the deterministic analysis with hybrid covariances to feed back the ensemble system itself whose impact might be non negligible keppenne 2014 the implementation of hybrid covariances in oceanvar presented earlier has been extensively tested within the same analysis system outlined in section 2 1 with such a configuration an eda system was run with perturbations of ocean observations and atmospheric forcing and introduction of stochastic physics in our experiments an ensemble system formed by 24 members is run for several years 1993 2013 each member incorporating only stationary covariances as in the original 3dvar formulation the ensemble is generated by i perturbing the atmospheric forcing ii perturbing the equation of state eos with the scheme of brankart 2013 iii perturbing the observations for the former perturbations are drawn from the error dataset consisting of the unbiased differences of wind vector at 10 m above mean sea level temperature and specific humidity at 2 m shortwave and longwave radiative fluxes and total precipitation between the ecmwf era interim dee et al 2011 and the ncep r2 kanamitsu et al 2002 reanalyses note that the ncep r2 atmospheric reanalysis data are used only to introduce perturbations in the atmospheric forcing the climatology of the differences era interim minus ncep r2 is subtracted to each error field to avoid biases in the perturbations perturbations for each day are then randomly selected from an error realization forcing difference occurring during the same month of the year taken from the error dataset for the period 1989 2014 then a first order auto regressive process ar 1 with a decorrelation time scale equal to 10 days is used to correlate in time the perturbations in a way similar to storto et al 2013 the eos perturbation implies that small variations in density may be linked to the uncertainty in the unresolved sub grid processes the stochastic equation of state is configured to consider an ar 1 process to correlate in time density perturbations with a 20 day decorrelation time scale note that decorrelation time scales were setup empirically based on sensitivity tests although the ratio of 2 between oceanic and atmospheric decorrelation scales follows the evaluation of storto et al 2018 finally the observation perturbation follows standard ensemble generation procedures burgers et al 1998 as observation errors are assumed uncorrelated the perturbation is drawn from the unbiased gaussian distribution with the nominal observation error variance fig 1 shows the temperature ensemble spread with time from the system described above for three different vertical levels at 300 1000 and 3000 m of depth and separately for north 30n 90n and south 90s 30s extra tropics and the tropics 30s 30n while the ensemble spread at 300 and 1000 m of depth for the northern extra tropics is fairly stable with time it exhibits an initial spin up phase with increasing spread up to around 2002 in the tropics and southern extra tropics followed by a decreasing phase associated with the increasing deployment of argo floats in these two regions therefore the poor observing network slows down the spin up of the ensemble system a qualitative similar result applies to the northern extra tropics deep ocean 3000 m conversely deep ocean spread in the tropics and south hemisphere keeps increasing during the entire whole period suggesting that it did not reach a stationary value even after the 21 year period due to the lack of constraining observations in the deep ocean and the slow penetration of upper ocean perturbations care should be taken therefore when using ensemble statistics for the deep ocean although the maximum depth of most observing networks is generally limited to 1000 2000 m at deepest besides the inter annual variability the upper ocean spread in all regions exhibits high frequency variability that justifies the adoption of ensemble derived covariances in hybrid data assimilation schemes in the experiments presented later we increase the sample size rather than localizing the covariances following the approach of raynaud et al 2008 who suggested to use a spatial moving average to increase the sample size and limit spurious covariances in particular for each grid point we use all the data from grid points distant less than 2 grid points this is similar to use 600 realizations 24 members multiplied by 25 grid points for each set of vertical covariances calculated for a single grid point for each 2 week flow dependent set of eofs correlations length scales are calculated through fitting the empirical correlation curve as a function of the distance to a gaussian curve this method provided more numerically stable results with respect to other strategies tested for instance by storto et al 2014 it is also worth mentioning that the eigen decomposition performed over the ensemble anomalies retains only the 20 leading eigenvectors corresponding on the average to about 90 of explained variance providing an implicit vertical localization as pointed out by clayton et al 2013 the ensemble system runs offline i e there is no feedback mechanism between deterministic and ensemble systems through the ensemble estimated background error covariances hybrid sensitivity tests were run for the period 1994 2013 we have in particular investigated the hybrid weight α the fraction of the weight given to climatological error covariances that leads to the best skill scores for five values of α 0 fully ensemble covariances 0 25 0 50 0 75 and 1 fully stationary covariances results of the experiments are reported in fig 2 in terms of an observational error metrics l as a function of the forecast range t in days and the α weight as 14 l α t 1 n t j o α t 1 n e α j o α t where jo is as the observational term of the 3dvar cost function but limited to the observations falling in the daily time slot of the forecast day t i e the sum of the square departure between observations and model equivalents weighted by the observation error variance n t is the number of verifying observations at day t and ne is the count of the experiments different values for α five here the metric l is an anomaly i e the mean of jo over the different α experiments for each forecast range is subtracted in order to provide a way for comparing model results across different forecast ranges provided that the forecast errors increase with forecast range is larger than the sensitivity of the skill score to the hybrid weight l accounts simultaneously for all observation types scaled by their nominal observation error the smaller the value of l is the larger the decrease of the weighted sum of squared observation departures is i e the more positive the impact of the hybrid α weight is fig 2 shows the metrics for the global ocean and the three latitudinal bands summarizing the results for the whole 1994 2013 period at global scale the best hybrid weight is found around 0 75 at all forecast ranges meaning that in this hybrid system better results maybe found by giving slightly more weight to stationary covariances probably due to the limited ensemble size the weak model parameterisation perturbation and the lack of feedback between the deterministic and the ensemble analysis all factors contributing to the non optimality of the ensemble system nevertheless the experiment with α 0 75 leads to smaller l and therefore improved skill scores compared to the experiment with fully stationary covariances demonstrating the ability of the hybrid system in outperforming the traditional variational formulation note that the impact of the hybrid weight appears clearer for longer forecast leads i e the verification metrics diverge with time among the five experiments while results for south extra tropics are qualitatively similar to the global north extra tropics exhibit better results for α 1 for the longest forecast ranges suggesting that dense observation network and or high mesoscale variability may prevent the hybrid system to have significant impact hamill and snyder 2000 on the contrary the verification scores in the tropics suggest that for some forecast ranges better skill scores are found for larger weight given to ensemble covariances α 0 25 likely due to the fact that the atmospheric forcing perturbations are able to reproduce accurately the uncertainty in the tropical upper ocean fig 3 applies eq 13 in order to find the hybrid weight α using global ocean innovation statistics from the α 1 experiment black line and the α 0 75 experiment red line and stationary and ensemble derived covariances as input results are in qualitative agreement with those found with the verification metrics l i e the optimal weight is found as time average around 0 72 an increase with time of the weight is visible in the figure which may be linked to the increased observation sampling and suggests the need of temporal inflation for hybrid covariance systems applied e g to reanalyses or multi decadal experiments indeed we interpret the increase of α with the fact that augmented observational sampling reduces the need and the effect of the hybridization see later in section 4 the discussion for the north vs south hemisphere skill scores note also that successive applications of the method of eq 13 i e red curve versus black curve on statistics coming from hybrid simulations as a fixed point algorithm does not provide significantly different results indicating a rapid convergence of the diagnostics the agreement between the empirical sensitivity tests and the optimal weight found with eq 13 indicates that a value of α between 0 70 and 0 75 may be used for our coarse resolution hybrid ensemble variational system in the following sections we freeze the hybrid system with the α weight equals to 0 72 fig 4 shows the signal to noise s n ratio of the ensemble derived background error covariances in particular examining background error standard deviations and horizontal correlation length scales the s n ratio is here defined as the ratio between the mean in fig s1 and the standard deviation fig s2 of the flow dependent errors either background error standard deviations or horizontal correlation length scales computed apart for each month temporal variability of the covariances is indeed expected to be the largest where the temporal mean of errors is the largest or the variability of errors is the smallest thus the s n ratio reveals areas characterized by anomalous variability of the flow dependent covariances and can spot areas where background error flow dependence is potentially important in winter time both horizontal correlations and standard deviations appear rather stable with time i e mean exceeding the standard deviation and large values for s n ratio for mesoscale active areas in the north hemisphere gulf stream and kuroshio extension regions the ratio is small elsewhere and in particular in the arctic ocean in the subtropical band of the pacific ocean and in the antarctic circumpolar current region indicating that over these regions the recourse to hybrid covariances may have large impact within coupled ocean sea ice data assimilation which is however not considered here conversely in summer time such metrics indicate small s n for north hemisphere mesoscale areas and the antarctic region although values are in general larger 3 1 5 experimental results a case study is investigated here in order to observe the potential benefit of the hybrid 3dvar formulation we study in particular the week starting on 5 october 2010 in the tropical region where verification skill scores calculated on in situ profiles indicate a rmse decrease of about 10 when hybrid covariances are used not shown with respect to the original 3dvar formulation we choose such a period because october 2010 is characterized by a la niña event where the anomalies linked to the enso occurrence may be large compared to the long term mean ocean state and thus lead to anomalous flow dependent background error covariances thus this test case exemplifies the potential advantages of using information from an ensemble analysis system the ensemble derived flow dependent background error standard deviation are shown in the top panel of fig 5 maximums of the background error standard deviations are found in correspondence of the thermocline in the comparison with the static covariances differences shown in the middle left panel the abnormally shallow thermocline depth typical of the la niña event is reflected in the standard deviation anomaly showing a positive anomaly at around 50 m of depth in the eastern tropical pacific ocean and a larger error in the atlantic and indian oceans the increased slope of the thermocline also leads to anomalously negative errors at around 100 m of depth in the tropical pacific ocean we also compare the background error standard deviations with the ensemble derived time averaged ones over the period 1994 2013 ensclim which show how the features mentioned above do not stem from the use of the ensemble anomalies themselves but are truly flow dependent except for the vertical dipole in the eastern indian ocean indeed the ensclim set of covariances are drawn from ensemble anomalies and not anomalies with respect the long term mean as in stat and may be considered a better way to model covariances as the ensemble system mimics the real world error propagation storto and randriamampianina 2010 this example suggests that flow dependence of background errors could also be introduced to some extent by simply parameterising the errors as a function e g of the tropical thermocline depth however in areas with more complicated dynamics or for modulating correlation length scales such an approach might be difficult to apply a similar comparison is performed for the vertical background error correlations between the level at 100 m of depth and the other model vertical levels fig 6 static covariances show a very broad behaviour in particular exhibiting large correlations between the sea surface and the ocean at 100 m in the eastern tropical pacific the adoption of time averaged ensemble derived covariances narrows the vertical covariances rather homogeneously however only the use of flow dependent covariances lead the vertical correlations to vanish between the sea surface and 100 m of depth in the eastern part of the tropical pacific and between 100 m and deeper levels in the western part of the basin in the other sectors of the tropical pacific vertical correlations remain similar between ensclim and ensfd the effect of the modified covariances is visible in the temperature weekly mean differences between the hybrid covariance experiment and the 3dvar fig 7 the modulation of vertical correlations in the western part of the tropical pacific ocean in association with smaller background error standard deviation leads to the warming of the 150 200 m layer significant changes also occur in the atlantic sector with cooling in correspondence of the thermocline and warming above and below likely associated with the background error standard deviations larger than the stationary ones leading to a closer fit to observational profiles thus the three dimensional structure of the background error covariances reflects the anomalous conditions associated with the enso occurrences finally we shortly compare the use of hybrid vertical covariances against the use of both hybrid horizontal and vertical covariances during the common validation period 2010 2013 this is shown in fig 8 in terms of verification skill scores against gridded satellite altimetry more verification results will be given in section 4 at global scale the improvement given by the use of both horizontal and vertical hybrid covariances with respect to only vertical covariances is small and equal to about 0 5 statistically non significant peaking in the tropics at 0 9 not shown statistically significant therefore the impact is slightly positive suggesting that fully hybrid covariances should be adopted unless they represents a computational constraint as discussed in section 3 1 2 it is also worth noting that the cost function of eq 9 led to a decreased number of iterations required by the minimizer to reach convergence and smaller values of the final cost function meaning that the augmented control vector is able to better fit the observational constraints implied by the innovations this aspect anticipates that the hybrid covariance formulation is able to reduce observation minus analysis departures 3 2 simplified 4dvar 3 2 1 formulation standard incremental strong constraint 4dvar formulation considers that the tangent linear version of the model operator m 0 t propagates forward in time the increment δx within the assimilation window from the initial time to time t note that for sake of simplicity we used the notation m in section 2 the assimilation time window is discretized in a finite number of temporal intervals k at each time 15 δ x t m 0 t vv with m 0 0 i implying that δ x 0 vv the control vector v is therefore nominally defined at the initial time of the 4dvar time window the strong constraint formulation assumes the model operator to be perfect thus the cost function is re defined as 16 j v 1 2 t 1 t k h t m 0 t v v d t t r t 1 h t m 0 t v v d t 1 2 v t v where d t are the innovations for the observations included in the tth time interval and r t the associated error covariance matrix the strong constraint formulation is equivalent to conceive a physically balances temporal operator v t m 0 t such that 17 δ x t v t v f v b v h v v v and evaluate the innovations using the background fields corresponding to δx at the closer temporal interval to the observations when multiple outer loops are implemented the background fields at the kth outer loop are redefined as 18 x k b x 0 b i 1 i k 1 δ x i 0 where x 0 b x b is the initial background field and δx i 0 is the analysis increment at the initial time and at the ith outer loop at the beginning of each outer loop the 4dvar increments from the previous outer loop and valid at the beginning of the 4dvar assimilation time window are added to the background valid at the initial time and the non linear trajectory is evaluated then the 4dvar increment valid at the end of the time window from the inner loop minimization of the latest outer loop is used to provide the initial conditions for the next forecast this sketch requires that 4dvar increments at both the beginning and end of each outer loop are saved the use of outer loops allows for a re linearization of observation and model operators around an improved model trajectory and provides a possible algorithm to implement non linear and linearized model operators at different resolution although in the remainder of this work the multi resolution approach is not used 3 2 2 simplified model operator the 4dvar formulation requires that the model operator m 0 t and its adjoint are applied at each iteration of the minimization this drives the computational cost of the assimilation very high especially for a large number of time intervals k i e long assimilation window an alternative formulation with respect to the classical one of eqs 16 and 17 is now proposed we change the definition of the covariance operator chain by swapping the sequence of the operators such that the state vector is defined as 19 δ x t v f v b m 0 t v h v v v v f v b v t v h v v v following the configuration discussed in section 2 v is the control vector that after multiplication with v v contains temperature and salinity fields thus if the ocean model space is only composed of temperature and salinity then the other ocean variables sea surface height and ocean currents are only calculated through the balance operator and possibly the filter v f v b the formulation of eq 19 approximately halves the computational cost with respect to the standard chain of operators in eq 17 as only the increments of temperature and salinity and not sea level or currents are propagated forward in time by m 0 t thus saving in time in particular by avoiding the computation of diffusive and advective processes for currents in the case that observations of sea level and currents are not assimilated i e not constrained by observations then the previous formulation is equivalent to the one in eq 17 the analysis increments of ocean velocities come merely from the balances implied by v b applied on the increments of temperature salinity and sea surface height when observations of sea level and currents are assimilated then the two formulations differ only temperature and salinity evolve with time within the 4dvar assimilation time window while the evolution of current and sea level is limited to the fraction of the balance components that depend on temperature and salinity this underlines a large confidence on the formulation of the balance operator v b however in regional applications when e g hf radars are the dominating observing network this simplification may be limiting coding efficient tangent linear and adjoint versions of an ocean model is known to be a demanding task at present the nemo ocean model provides a frozen version of the tangent linear and adjoint version called nemotam vidard et al 2015 our choice however is to further simplify the model physics by selecting only a number of relevant processes without using the nemotam package thus the tangent linear and adjoint models are formed by the tangent linear and adjoint versions of the routines representing the selected process this approach avoids a formal coupling between oceanvar and any external package such as nemotam our simplified model considers for temperature and salinity only advective and diffusive terms in the horizontal and vertical and air sea flux exchanges in form of salinity s and temperature t tendencies the linearized model reads 20 s t s u z a v s s z a h s s s a 21 t t t u z a v t t z a h t t t a where ah and av are horizontal and vertical diffusivities defined apart for temperature and salinity and s a and t a are the temperature and salinity terms that represent the air sea exchanges details of the formulation and schemes used within the tangent linear model of eqs 20 and 21 are provided in appendix a 3 2 3 experimental results in the 4dvar scheme implemented in oceanvar we used 1 day frequency for the non linear model trajectories around which the tangent linear model is linearized this implies that these trajectories are stored as daily means nominally valid at the middle of the day and linearly interpolated over time onto the tangent linear model timesteps such a strategy seems more appropriate than using daily snapshots in order to partly include the diurnal cycle in the trajectories further tests shall consider high frequency instantaneous fields to better resolve the diurnal variability the intervals k for the discretization of the observational term of the cost function in eq 16 corresponds to the tangent linear model timesteps in the assimilation time window a comparison of single observation experiments is provided in this section to offer a flavour of how the 4dvar formulation shapes the analysis increments with respect to the standard 3dvar fig 9 shows the evolution of a perturbation along the 4dvar time window where the perturbation is the analysis increments from a single temperature observation assimilation namely a near surface argo measurement in the tropical pacific ocean with a 0 5 c innovation such a perturbation at the beginning of the time window is also equal by construction to the 3dvar analysis increments the figure shows the perturbation at the end of the 15 day 4dvar assimilation time window i e the nominal analysis time for the following forecast step furthermore the top right panel shows the fully non linear forecast model propagation m x a m x b of the analysis increment perturbation along the 4dvar assimilation time window in order to observe a realistic non linear trajectory that includes the complete set of model physics and assess the performance of the simplified tangent linear model the increments at the beginning of the time window do not follow the underlying flow although they are not symmetrically distributed around the observation because of the non uniform correlation length scales adopted storto et al 2014 the mean flow follows a north eastward circulation approximately north of the observation location while south westward south of the observation at the end of the time window 4dvar increments are correctly stretched along the mean flow and take a twisted south west to north east shape in accordance with the circulation described above differences between 4dvar increments at the end minus increments at the beginning of the time window bottom right panel are therefore positive north east and south west of the observation location and negative elsewhere the comparison between 4dvar and the non linear model propagation suggest that even a simple tangent linear formulation is able to reproduce the dependence of the increments upon the underlying flow the shapes of the increments being similar two possible configurations of 4dvar are analysed now depending on the number of outer loops either one 4dvar 1ol or two 4dvar 2ol when two outer loops are used the maximum number of inner loops minimization in the first outer loop is fixed to 20 in order not to increase the computational demand by much the inner loop of the latest outer loop ends when the same convergence criterion as in 3dvar see section 2 is reached a first comparison between these two configurations is offered by fig 10 in the verification against altimetry data due to the non linear relationship between temperature salinity and sea surface height the assimilation of altimetry data may in principle be affected by the re linearization implicit in multiple outer loops results suggest that the adoption of the second outer loop helps slightly reducing biases and rmse and increasing anomaly correlation during the period 2010 2011 while results are generally mixed afterwards over the entire period 2010 2013 the anomaly correlation increases by more than 1 peaking in the southern extra tropics not shown at more than 6 and suggesting that the double outer loop may provide slight improvements more validation results will be presented in section 4 4 comparison of hybrid 3dvar 4dvar and 3d hybrid 4dvar in this section we cross compare the benefits of the new oceanvar formulations allowing for hybrid 3dvar 4dvar and hybrid 4dvar for the latter we consider only the experiment where the ensemble component of background error covariances comes from an ensemble of 3dvar based realizations as in the hybrid 3dvar while the analysis system itself is based on the 4dvar formulation presented in section 3 2 the cost function of such a scheme formally reads 22 j v c v e 1 2 t 1 t k h t m 0 t β c v c v c β e v e v e d t t r t 1 h t m 0 t β c v c v c β e v e v e d t 1 2 v c t v c 1 2 v e t v e table 2 summarizes the experiments performed all sharing the same initial conditions valid on the 1st january 2010 and covering the 4 year period 2010 2013 the hybrid 4dvar experiment where b e is estimated from an ensemble of 4dvar based members is not considered for sake of simplicity and because of its large computational demand fig 11 reports the computational demand of each experiment in averaged cpu minutes per assimilation and forecast cycle for the configuration outlined in section 2 1 to be comparable cpu time has been measured using the same computational configuration 1 computational node corresponding to 16 cores on the cmcc supercomputing center machine athena the cpu time is also scaled with respect to the standard 3dvar formulation ratio on top of the bars to provide a clear idea of the computational increase the v hybrid 3dvar experiment is 25 times more expensive than 3dvar owning to the 24 member ensemble system discussed earlier while hybrid 3dvar is 26 times expensive due to the fact that the horizontal operator dominating the total cpu time required by the 3dvar system is called twice using both climatological and ensemble correlation length scales in the hybrid covariance analysis clearly this difference is very small unless the system is run offline i e when the ensemble system and the hybrid covariance analysis are run separately the time spent by the hybrid schemes depends on the ensemble size used therefore these estimates are not general and refer only to our configuration although operational ensemble sizes are typically of the order of 20 50 members smaller ensemble size may be used anyway as it is currently done in many atmospheric reanalysis configurations where a trade off between robustness of ensemble derived covariances and computational demand is achieved e g poli et al 2013 if the ensemble system is run offline e g for retrospective experiments the computational cost increase becomes less critical for timeliness issues the 4dvar system is 16 or 22 times more expensive than 3dvar depending on how many outer loops are used 1 or 2 4dvar turns out to be less expensive than hybrid 3dvar for our configuration note also that unlike hybrid 3dvar the 4dvar computational rise is less affected by the specific configuration used although the model resolution and the choice of the assimilation time window may affect these estimates finally 3d hybrid 4dvar with two outer loops employs about 47 times the time spent by 3dvar being obviously the most expensive formulation tested it should be noted that in case of a hybrid 4dvar system that uses an ensemble of 4dvar members the computational cost should theoretically be equal to 550 times that of 3dvar for a 24 member ensemble 4dvar system although this configuration has not been tested in reality note that this sketch does not consider on purpose any possible gain in computational time depending on the code scalability and increase of cores as the goal here is to test the computational demand with the same computer resources operational implementations may also need to consider scalability issues with the different assimilation configurations the validation of the experiments performed is here summarized focusing on the comparison with in situ profiles note that even though this dataset is actually assimilated in the experiments skill scores are computed before the observations are ingested in the system from observation minus background departures i e the dataset is independent if one neglects the temporal correlation of observational errors fig 12 shows the 2010 2013 profiles of rmse for the six experiments computed separately for temperature and salinity and for the southern and northern extra tropics and the tropics the southern extra tropics are characterized by the fact that all new formulations significantly improve the upper ocean skill scores for both temperature and salinity temperature scores are equally benefited by 4dvar and hybrid formulations although 3d hybrid 4dvar 2ol appears to slightly deteriorate the scores with respect to 4dvar 2ol or hybrid 3dvar this might be due to the sub optimal choice of the hybrid weight in case of the 4dvar formulation indeed applying the diagnostics of eq 13 we found a slightly larger value for the optimal α 0 83 for the hybrid 4dvar case compared to the hybrid 3dvar suggesting that slightly smaller hybridization is optimal for the 4dvar scheme and requiring further tests the 3d hybrid 4dvar 2ol experiment is however the best for near surface salinity followed by the hybrid experiments namely the hybrid extension seems the most effective in the southern ocean this partly applies also to the skill scores in the tropics where 4dvar and 3d hybrid 4dvar 2ol outperforms the 3dvar salinity skill scores and hybrid schemes outperform 3dvar temperature skill scores note that near surface salinity skill scores are not improved in the hybrid covariance experiments in the tropics likely due to the dominant error of the atmospheric freshwater forcing that ensemble derived covariances are not able to mitigate on the contrary 4dvar based experiments where the dynamical adjustment in the assimilation time window appears to positively impact the skill scores in the northern extra tropics the sensitivity of the data assimilation scheme is the smallest probably due to more abundant observing network along with the presence of strong mesoscale activity gulf stream kuroshio extension that the coarse resolution configuration used here is not able to fully capture the hybrid schemes for temperature and both 4dvar 2ol and 3d hybrid 4dvar 2ol for salinity are however the best leading configurations in this region fig 13 attempts to summarize the benefits of the new formulations at global scale by showing the accuracy increase defined as the percentage rmse reduction with respect to 3dvar such a sketch is drawn separately for forecast ranges 1 to 3 days and 7 to 10 days where we assume that forecast ranges from 1 to 3 are typical of a reanalysis configuration corresponding to typical assimilation time windows in high resolution applications while forecast ranges from 7 to 10 days are interesting for medium range ocean forecasts this definition has clear limitations but here it serves the purposes to examine the benefits of the new formulations of oceanvar at different forecast ranges percentage differences are statistically significant when greater than 1 2 in absolute values the results generally do not allow to draw robust conclusions on the relative merits of the different data assimilation formulations because results for temperature and salinity differ in this aspect note that salinity skill scores are more sensitive at longer forecast ranges suggesting that the predictability of salinity is shorter than that of temperature at global scale nevertheless it appears that especially for temperature short forecast ranges are positively impacted by the hybrid extension of 3dvar in qualitative accordance with the fact that the ensemble component of covariances improves the error characterization leading to smaller observation innovations right after the analysis step using the hybrid vertical and horizontal covariances outperforms the use of only vertical hybrid covariances except for temperature at long time range whose sensitivity is however small and not easy to interpret conversely long forecast ranges are benefited by the 4dvar extension of oceanvar a common interpretation is that 4dvar yields analysis increments more balanced than 3dvar with respect to the model trajectories leading in turn to better forecast trajectories that can be observed for longer forecast ranges in all cases the adoption of two 4dvar outer loops outperforms the use of one outer loop only except for temperature skill scores at short forecast ranges whose performance is not straight forward to interpret 3d hybrid 4dvar 2ol provides the largest improvement and represents a significant improvement of the data assimilation system at an affordable increase in computational cost 5 summary and discussion in this work we investigate possible strategies to extend a three dimensional variational data assimilation system to a hybrid ensemble variational four dimensional formulation and document its potential impact in a realistic global ocean configuration the hybrid paradigm is implemented by means of augmenting the control vector by a part associated with the ensemble derived flow dependent covariances such a formalism also allows combining different covariance sets e g representing errors at different spatial scales and does not necessarily require an underlying ensemble system we have also proposed an empirical expression based on the diagnostic formulas of desroziers et al 2005 in order to define an optimal hybrid weight such a definition matches well with criteria based on verification skill scores we have also considered the possibility to allow only the vertical covariances to be hybrid thus avoiding to apply twice the horizontal correlation operator which is expensive this strategy can save computational time and prevent the system from the computation of ensemble derived correlation length scales which is non trivial for small ensemble sizes although it obviously neglects the flow dependent horizontal propagation of the observational information with such a hybrid system we have shown that flow dependent background error covariances are shaped based on the time varying regimes e g during enso events that modify the vertical structure of the errors in the tropics results suggest that the analysis system is significantly benefited by the hybrid covariances at an affordable additional cost roughly equal to the ensemble size for high resolution applications of the hybrid covariance scheme further gain in computational cost can be achieved by using flow dependent covariances from a coarser resolution system in a way similar to what is routinely done within many nwp assimilation systems where the inner loops of the variational minimization are performed over a reduced resolution grid the adoption of hybrid data assimilation schemes is also supported by the growing attention devoted to stochastic physics packages within ocean and sea ice modelling juricke and jung 2014 brankart et al 2015 bessières et al 2017 for predictability and multi scale interaction studies and data assimilation developments this will certainly foster the adoption of hybrid covariances in the future as ocean ensemble systems will be able to span a large number of multi scale uncertainties in a more realistic way contextually a simplified four dimensional data assimilation scheme has been implemented the novel approach consists in swapping the tangent linear model operator and the balance operator in the operator chain that defines the square root background error covariance matrix this allows to halve the computational time as ocean velocities are no longer independent variables in the tangent linear and adjoint model the drawback is that one should rely on the balance operator definition as a function of temperature and salinity for the implicit evolution of current and sea level within the assimilation time window regional data assimilation systems may benefit from ocean current measurements from hf radar or from float trajectories e g nilsson et al 2011 in such configurations the use of a full 4dvar scheme should be compared to our formulation even this simplified tangent linear modelling is proved able to shape the horizontal propagation of the observational information in large agreement with the non linear model trajectory and according to underlying ocean circulation the adoption of a two outer loop configuration is also found to yield better skill scores with respect to the use of one outer loop at a slight computational cost increase furthermore a tangent linear and adjoint model that includes advection diffusion and air sea exchanges have been developed and embedded in oceanvar this development stems from the idea to develop a model with very light software infrastructure for easy coupling with any data assimilation system future applications of such tangent linear model may also include sensitivity analyses singular vector computation and observation targeting and all applications relying on linear modelling see e g errico 1997 the cross comparison between hybrid 3dvar 4dvar and hybrid 4dvar in general suggests that all the new formulations explored are between 16 and 47 times more expensive than 3dvar with the same computational resources and are therefore affordable if one considers a greater number of cores used assuming a good enough scalability the hybrid formulation positively impacts the system accuracy especially at short forecast ranges with obvious implications for reanalysis applications on the contrary 4dvar is able to reduce the forecast errors especially at longer forecast ranges and thus provides promising results for operational applications using fully hybrid covariances and not only hybrid vertical covariances always improves the system accuracy the hybrid 4dvar experiment where ensemble derived flow dependent covariances are still estimated from an ensemble system based on 3dvar provides further improvements except in the short range temperature verification where hybrid 3dvar outperforms the other experiments oceanvar shows small sensitivities to the hybrid and 4dvar extensions in the north extra tropics with respect to the south probably due to the combined effect of rich observing network and coarse model resolution of the testbed configuration therefore results might change with increased resolution and or a different observational coverage future developments for oceanvar will include a weak constraint formulation for the simplified 4dvar system at present the oceanvar code already includes this option through augmenting the variational control vector with time discretized model error variables the so called model error forcing control variable see trémolet 2006 however the results not shown indicate a large sensitivity to the choice of model error covariances and temporal discretization of model errors and optimal strategies still need to be identified acknowledgments this work has received funding from the european commission through the copernicus marine environment monitoring service cmems acknowledgment is made for the use of ecmwf s computing and archive facilities in this research the en4 subsurface ocean temperature and salinity data were collected quality controlled and distributed by the u k met office hadley centre the altimeter products were produced by ssalto duacs and distributed by aviso with support from cnes we thank three anonymous reviewers for their valuable help in improving the quality of the manuscript appendix a simplified tangent linear model operator eqs 20 and 21 outline the simplified tangent linear operator included in the 4dvar version of oceanvar which considers the evolution of temperature and salinity within the assimilation time window from advective and diffusive processes and air sea flux exchanges the tangent linear timestep for the configuration presented in section 2 1 is the same as the non linear model and equals 5400 seconds the advection scheme is implemented through a 2nd order centered scheme and the time stepping is performed using a leapfrog scheme in conjunction with an asselin time filter asselin 1972 velocity fields are taken from the non linear model trajectories saved at daily frequency in the experiments presented in this article for numerical stability vertical velocities used in the vertical advection scheme are calculated from an upward integration of horizontal divergence from the daily mean velocity fields an iso level laplacian operator is used for horizontal diffusion with a h s a h t 4000 m 2 s 1 an implicit scheme is implemented for solving the vertical diffusion the vertical eddy diffusivity in the tangent linear model a v s a v t is assumed not to depend on temperature and salinity and is taken from the non linear model trajectories at daily frequency no specific convection parameterisation scheme is used in the tangent linear model air sea exchanges are formulated by linearizing the bulk formulas of large and yeager 2004 with additional simplification outlined below tangent linear freshwater fluxes f are equal to the tangent linear evaporation flux e the precipitation and river runoff not depending on the ocean state and sea ice melting processes being neglected 23 f e ρ a c e z q 2 t 0 e q 2 t 0 b t 0 b 2 u where ρa is the air density 1 22 kg m 3 ce is the evaporation transfer coefficient the coefficients z and q 2 are equal to 514403 6 dimensionless and 5107 4 k respectively t 0 is the tangent linear sea surface temperature t 0 b the background sea surface temperature from the non linear model trajectory the subscript 0 indicating the sea surface and u is the wind speed provided here from the era interim atmospheric reanalysis dee et al 2011 noting that shortwave radiation does not depend on the ocean state the air sea heat fluxes q in the tangent linear model are given by the sum of outgoing longwave radiative flux qlw and sensible qsn and latent qlt heat flux 24 q q l w q s n q l t 4 σ t 0 b 3 t 0 ρ a c a c h t 0 u l v e where σ is the stefan boltzmann constant 5 67 e 8 w m 2 k 4 ca is the specific heat of the air 1000 5 j kg 1 k 1 ch is the sensible heat transfer coefficient and lv is the latent heat of vaporization 2 5 e 6 j kg 1 a further simplification in the tangent linear air sea flux operator consists of assuming the transfer coefficients ce and ch are not dependent on the ocean state i e they are taken from the non linear model trajectory this prevents the tangent linear version to use the highly non linear iterative procedure to calculate non neutral transfer coefficients of large and yeager 2004 in the future weak dependence of the transfer coefficients on the sea surface temperature may be included using simplified empirical relationships for the coefficients as in kara et al 2000 temperature and salinity tendencies given by the air sea exchanges are respectively equal to 25 t a 1 ρ w c w d z q cw being the heat capacity of sea water 4000 j kg 1 k 1 ρw the sea water density 1026 kg m 3 and dz the thickness of the first vertical model level the salinity tendency is given by 26 s a 1 ρ w d z s 0 b e e b s 0 where s 0 s 0 b are the tangent linear sea surface salinity and its non linear background counterpart and eb is the background evaporation adjoint validation tests see e g vidard et al 2015 were implemented in oceanvar and all the adjoint routines passed the test successfully supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j ocemod 2018 06 005 appendix b supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
24100,the traditional formulation of three dimensional variational 3dvar data assimilation schemes for oceanographic applications neglects the temporal evolution of background errors within and across assimilation temporal windows such a simplification may be limiting for many climate e g reanalyses and operational e g medium range forecast applications this work explores possible extensions of the oceanvar data assimilation code aiming at overcoming these limitations general formulations are proposed and implemented in order to extend the 3dvar scheme of oceanvar into a simplified hybrid ensemble variational four dimensional variational 4dvar assimilation scheme where i background error covariances combine stationary and flow dependent components through an augmented control vector and ii a simplified tangent linear and adjoint model which assumes that only temperature and salinity are independent variables these extensions are shown to allow the background error covariances to follow the time varying structure typical of climate modes like enso and to shape the analysis increments in agreement with the underlying ocean circulation respectively the two extensions are cross compared in terms of computational time cost and accuracy and further combined together into a hybrid 4dvar scheme the hybrid formulation provides in general largely positive impact at short forecast ranges while 4dvar at long ones the hybrid 4dvar scheme improves the verification skill scores in most cases keywords 4dvar ocean reanalysis ocean forecasts tangent linear model 1 introduction owing to the requirements of long term climate prediction systems e g seasonal forecasts and activities that rely on operational ocean forecasting e g search and rescue route optimization oil spill etc oceanographic data assimilation schemes are a crucial component of environmental monitoring this is testified by the growing attention devoted to them by international programs during the last decade such as in europe the copernicus marine environment monitoring service cmems supported by the european union through the european commission directorate on enterprise and industry a number of data assimilation systems have therefore been developed during the last two decades for both operational and reanalysis applications e g martin et al 2015 masina et al 2017 new hybrid data assimilation algorithms that merge advantages of ensemble and variational schemes have been mostly developed to improve the accuracy of operational numerical weather prediction nwp as suggested for instance by the review article of bannister 2017 oceanographic data assimilation has some delay in following meteorological data assimilation advances several reasons concur to this nwp shows a much larger impact than ocean forecasts on diverse aspects of our daily life that can potentially affect the economy and the safety of human activities on a short time scale furthermore on a technical ground the much less dense observing network that has implications on the feasibility of the schemes e g preventing the reliability of ensemble derived error statistics panteleev et al 2015 while atmospheric data assimilation systems in operational centers mostly rely on four dimensional data assimilation recently upgraded to hybrid ensemble variational formulation e g at the european centre for medium range weather forecasts ecmwf bonavita et al 2012 at the metoffice clayton et al 2013 and at météo france raynaud et al 2011 the extension of three dimensional data assimilation systems to hybrid four dimensional is more limited and recent in time within the oceanic forecasting community potential advantages of 4dvar with respect to 3dvar reside in the 4dvar ability to implicitly evolve covariances within the assimilation time window through the tangent linear model approximation thus shaping the analysis increments consistently with the actual circulation lorenc 2003a the tangent linear assumption required in the 4dvar formulation limits its time window length although the weak constraint formulation where the tangent linear model is not assumed to be perfect may alleviate this weakness fisher et al 2011 4dvar has however very large costs not only in terms of computational demand due to the tangent linear and adjoint model integrations at every minimization iteration but also in terms of human resources needed for software coding and maintenance software engineering behind tangent linear and adjoint model is indeed non trivial and even when automatic differentiation tools are adopted manual intervention is still required elizondo et al 2002 such a limitation has fostered the development of adjoint free 4dvar formulations that in different ways exploit the information about model error temporal covariances implicitly contained in ensemble systems e g yaremchuk et al 2009 bishop et al 2017 yaremchuk et al 2017 only a few ocean data assimilation systems support 4dvar for instance the regional ocean modelling system roms moore et al 2011 allows for strong and weak constraint four dimensional data assimilation and it is used for regional applications both reanalyses and operational oceanography still for regional applications the u s naval research laboratory has developed a 4dvar system coupled with the navy coastal ocean model ngodock and carrier 2014 recently extended to allow weak constraint data assimilation ngodock et al 2016 for global applications the mit ogcm has been recently complemented with a 4dvar data assimilation capability fenty et al 2017 the nemovar variational code weaver et al 2003 developed by the nemovar consortium implements the possibility of running 4dvar when it is coupled to the nemotam package i e the tangent linear and adjoint version of the nemo ocean model vidard et al 2015 although all real world implementations for reanalysis or forecast applications still use a three dimensional formulation e g waters et al 2015 it is thus clear that the oceanographic community lacks detailed assessments of the potential benefits of four dimensional versus three dimensional data assimilation which is among the objectives of the present work furthermore comparisons between variational and ensemble methods have been outlined several times within global nwp applications lorenc 2003b kalnay et al 2007 fairbairn et al 2014 but never with ocean applications unlike variational data assimilation methods ensemble based filters include a flow dependent definition of error covariances implicit in the time evolving ensemble based cross covariances a step forward towards more accurate error characterization might reside in the use of hybrid static ensemble background error covariances in the variational scheme this relatively simple extension relaxes the assumption of stationarity of the background errors thus hybrid 4dvar schemes overcome the 3dvar limitation of stationarity of covariances either across through flow dependent covariance component or within through the implicit 4dvar propagation of covariances assimilation time windows hybrid covariance methods have been introduced by hamill and snyder 2000 who demonstrated how variational methods can benefit from incorporating information about the error of the day conversely ensemble methods may benefit from the variational solution scheme and from the incorporation of stationary covariances that can limit problems arising from limited size ensemble systems since then hybrid methods have become popular in nwp and are now implemented in many short and medium range operational forecast systems in europe e g bonavita et al 2012 clayton et al 2013 and at the u s national centers for environmental prediction ncep wang et al 2013 hybrid covariance formulation of data assimilation systems for ocean applications is emerging recently testified by only a few works at global penny et al 2015 and regional oddo et al 2016 scales although growing attention is being devoted to include ensemble based background error covariances in many ocean variational data assimilation schemes e g in nemovar weaver et al 2018 theoretical justification of the use of hybrid covariances has been recently highlighted the work of bishop and satterfield 2013 and bishop et al 2013 on hidden variances shows that features such as unknown sources of model error finite ensemble size and ensemble covariance localization may limit the optimality of the mere use of ensemble based covariances furthermore they provide a mathematical framework to combine stationary and ensemble based covariances in the context of impulsive synchronization perspective penny 2017 showed that hybrid data assimilation methods are able to recover the lost stability found when ensemble methods are implemented with limited ensemble size and cannot represent the unstable modes the work of ménétrier and auligné 2015 has also a similar aim the authors apply a linear filtering framework to sample covariances in order to simultaneously optimize hybridization weights and localization parameters however it should be noted that it is customary in real world applications to perform sensitivity tests to identify the optimal hybrid weight that maximizes certain skill scores in this work we summarize the latest developments in the oceanvar data assimilation code originally developed by fondazione cmcc centro euro mediterraneo sui cambiamenti climatici see dobricic and pinardi 2008 and used for both global and regional reanalysis and operational oceanography applications e g adani et al 2011 storto and masina 2016 in the context of cmems the developments include i the support of hybrid formulation for background error covariances either vertical only or both vertical and horizontal covariances and ii a new four dimensional variational formulation that required the development of a simplified tangent linear and adjoint model these approaches are compared to the original 3dvar formulation in terms of derivation computational costs and accuracy the article is structured as follows section 2 introduces the original oceanvar formulation and the experimental setup section 3 describes the new hybrid and 4dvar formulation and developments showing case studies to assess their potential benefits section 4 cross compares the new developments with respect to the original 3dvar in terms of both computational demand and accuracy while section 5 discusses the main achievements and future plans 2 original formulation of oceanvar the assimilation scheme presented here is called oceanvar it was originally developed for the mediterranean sea forecasting system dobricic and pinardi 2008 and later adapted to global ocean configurations storto et al 2011 mostly for reanalysis applications storto et al 2016 storto and masina 2016 oceanvar implements the tangent linear approximation to the observational term of the cost function the tangent linear assumption considers a taylor expansion for the model equivalents in observation space considering the ocean state x and the vector of observations y their difference is approximated with the following rule chain where x b is the ocean background state 1 h m x y h m x b h m δ x y hm δ x d where h is the observation function mapping the ocean state in model space into observation space and m is the non linear model function propagating forward in time the ocean state h and m are their respective tangent linear operators formally defined as h h x x m x b and m m x x m x b d y h m x b is the innovation vector and it may be calculated online during the model integration in the traditional 3dvar formulation of oceanvar with the first guess at appropriate time fgat the temporal evolution of the ocean state within the assimilation window is neglected for the analysis solution m i and 2 h m x y h δ x d while the definition of d remains unchanged keeping the use of the non linear model function the 3dvar cost function in its incremental formulation e g courtier 1997 where δ x x x b reads 3 j δ x 1 2 h δ x d t r 1 h δ x d 1 2 δ x t b 1 δ x b and r are the background and observation error covariance matrices respectively the latter being assumed to be diagonal i e observational errors are mutually uncorrelated the analysis is defined as x a x b δ x at the minimum of j the cost function formulation eq 3 can be derived from bayes theorem assuming gaussian errors for the background and observations lorenc 1986 and neglecting the evolution of the ocean state within the assimilation time window oceanvar optionally implements variational quality control varqc of observations in which case the cost function is modified to account for a non gaussian probability density function pdf for the observation errors storto 2016 however we keep eq 3 with the purely gaussian pdf for sake of simplicity varqc implying a different formulation of the observational term of the cost function i e the first term on the right hand side of eq 3 the control variable transformation is used in oceanvar to precondition the minimization problem the minimization is performed with respect to the control variable v such that δ x vv and v v δ x with v the generalized inverse of v and b vv t substituting the previous relationships in the cost function we obtain 4 j v 1 2 h v v d t r 1 h v v d 1 2 v t v the gradient of j is evaluated during the minimization for use with the limited memory quasi newton minimizer l bfgs byrd et al 1995 which is required for non quadratic cost functions for instance in the case of varqc dharssi et al 1992 the gradient is given by 5 j v v t h t r 1 h v v d v the minimization convergence is reached when the infinity norm of the gradient maximum of the absolute value of the gradient components falls behind a certain threshold multiplied by the infinity norm of the initial cost function gradient here the threshold used is 2 modeling background error covariances is equivalent to applying the operator v square root of b which is in turn decomposed in a sequence of operators assuming separability of horizontal and vertical scales in a general form 6 v v f v b v h v v v v is the square root vertical covariance operator that is modelled through multi variate empirical orthogonal functions eofs namely v v s λ 1 2 where columns of s contain multivariate eigenvectors and λ is a diagonal matrix with the corresponding eigenvalues a remapping function r i j such that for each model grid point i j vertical covariances are defined as v v i j s r i j λ r i j 1 2 is used to remap the grid where eofs are defined into the model grid this feature permits that eofs are defined on a different grid than the model e g at a resolution lower than the model grid note that eofs are forced to linearly decrease to zero between depths of 1600 m and 2000 m in order not to produce potentially spurious increments and drifts within the deep unobserved ocean horizontal correlations are modeled through the application of a recursive filter operator v h the filter may be chosen to be first or third order farina et al 2015 periodic and bathymetric boundary conditions may be achieved either with an artificial grid extension approach or with analytic boundary conditions mirouze and storto 2016 the recursive filter coefficients depend on the model grid spacing and the correlation length scales which can be spatially varying provided that they vary slowly in space storto et al 2014 and respect the stability criterion provided by mirouze and storto 2016 the operator v b controls the balances among the state variables and has different options in oceanvar depending on the applications and computational resources there exist options for strong constraint balances where both sea level the dynamic height of storto et al 2011 or the barotropic model of dobricic and pinardi 2008 and currents summing barotropic and baroclinic increments as in weaver et al 2005 depend only on temperature and salinity when these strong constraint balances are used the data assimilation state vector is formed only by temperature and salinity the other parameters being defined unambiguously by these balances alternatively the balances described above can also be used as weak constraint balances in this case as described by derber and bouttier 1999 and weaver et al 2005 the physical variable is the sum of balanced and unbalanced components when this option is used the unbalanced component variables are included in the multi variate vertical eofs which in turn are computed including the residuals of the balances for sea level and currents these options permit large flexibility in oceanvar in terms of ocean state vector and balance formulation which can be diversified depending on the area of study resolution and observing network assimilated 2 1 ocean model and experimental configuration we shortly introduce here the configuration used in the experiments presented in sections 3 and 4 the ocean model component is nemo v3 6 madec et al 1998 coupled with the lim2 sea ice model fichefet and morales maqueda 1997 with elasto visco plastic rheology bouillon et al 2009 implemented at the 2 resolution with meridional resolution refinement up to 0 5 in the tropics the resolution peaks to 50 km in the tropics decreases to 200 km at mid latitudes and increases again to about 100 km at high latitudes the vertical discretization consists of 31 vertical zeta levels and partial steps barnier et al 2006 the thickness of the vertical layers ranges from about 10 m at the sea surface to about 500 m at the ocean bottom the horizontal grid of nemo is tripolar madec and imbard 1996 the ocean model is forced by the ecmwf era interim atmospheric reanalysis dee et al 2011 at 0 75 of horizontal resolution using the bulk formulas of large and yeager 2004 turbulent parameters wind and temperature and humidity at 10 and 2 m above ground respectively from era interim are provided with 6 hourly frequency while radiative and freshwater fluxes are provided daily in order to apply the analytic diurnal modulation of bernie et al 2007 and resolve the diurnal cycle of the shortwave radiative flux the coupling frequency between the atmospheric forcing and the ocean model is 6 hourly which also corresponds to the coupling frequency between the ocean and the sea ice model this configuration although being at coarser resolution than most configurations used for reanalysis and operational oceanography represents a cheap benchmark configuration for testing data assimilation developments in the experiments presented in the following sections all the hydrographic profiles present in en4 good et al 2013 are assimilated which include argo floats ctds xbts moorings and measurements from sensors borne by marine mammals table 1 summarizes the number of observations by year observation type and latitudinal band highlighting the different distribution of the observing network in particular argo floats become the most numerous observing network since 2006 with a generally similar distribution among the three bands summing up the different network indicates that the largest number of profiles is located in the north extra tropics both the assimilation time window and the frequency of the analysis computation are set equal to 15 days we experienced small differences between 3dvar and 4dvar for assimilation windows shorter than one week due to the slowly evolving ocean circulation especially in relatively coarse resolution configurations the configuration of oceanvar used in this study includes only temperature and salinity in the control vector as we test our data assimilation extensions in the simple case where only temperature and salinity profiles are used the preferred sea level balance is the dynamic height as in the configuration used at cmcc for eddy permitting reanalyses storto et al 2016 analysis increments of currents are not produced nor applied 3 extensions to the 3dvar scheme 3 1 oceanvar with hybrid background error covariances 3 1 1 formulation the recourse to hybrid background error covariances that combine static and flow dependent e g ensemble derived has become popular during the last decade because it provides a relatively easy framework to introduce flow dependent error structures in variational schemes while keeping their robustness oceanvar has been accordingly extended in order to use hybrid covariances the implementation partly follows the approach originally proposed by buehner 2005 where the control vector is augmented by a part associated with the flow dependent covariances however while buehner 2005 uses a spatially localized representation of the ensemble derived sample covariances also the flow dependent component is here formulated as a covariance model similar to eq 6 in terms of the control vector transformation the formulation reads 7 δ x β c v c v c β e v e v e where v c and v e are the control vectors associated with the climatological static b c v c v c t and ensemble derived flow dependent covariances b e v e v e t respectively following wang et al 2007 and oddo et al 2016 such a formulation is equivalent to consider a hybrid background error covariance matrix of the form 8 b α b c 1 α b e where β c 2 α and β e 2 1 α oddo et al 2016 see in particular their appendix a demonstrated that when the vectors v c and v e are independent i e they span different uncertainty modes the cost function with hybrid covariances becomes 9 j v c v e 1 2 h β c v c v c β e v e v e d t r 1 h β c v c v c β e v e v e d 1 2 v c t v c 1 2 v e t v e and the gradient of the cost function with respect to the two control vectors is thus given by 10 j v c β c v c t h t r 1 h β c v c v c β e v e v e d v c and 11 j v e β e v e t h t r 1 h β c v c v c β e v e v e d v e in practice the two background error covariance sets may be built to sample different spatial scales in order to satisfy the assumption of independence where typically the ensemble derived statistics bear smaller scale features than the static ones which is however not straight forward to verify in real world experiments note also that both formulations of v e and v c rely on multivariate eofs to model vertical covariances the independence is therefore linked also to the orthogonality of the two sets of eofs in the case where flow dependent covariances come from an ensemble system localization procedures aiming at removing long range spurious covariances due to the fact that the ensemble system is of limited size and under samples the covariance matrix may be introduced following houtekamer and mitchell 2001 and wang et al 2007 but are not used here alternatively or complementary to localization strategies filtering of background error covariances may be introduced to eliminate spurious and noisy correlations see e g berre and desroziers 2010 for a review of strategies it is also important to note that the hybrid formalism presented above may also be used for multi scale data assimilation in a way similar to that proposed by mirouze et al 2016 the two sets of background error covariances may be conceived to represent different scales and the hybrid weight chosen accordingly rather than being associated with static and ensemble covariances thus the hybrid analysis of eq 9 is actually a powerful and general way to combine different error statistics in practice the way how v e is defined follows the same formulation as v c ensemble anomalies are not used directly in the assimilation scheme but are used to calculate ensemble derived eofs in the vertical covariance operator v v e and horizontal correlation length scales in the horizontal recursive filter operator v h e 3 1 2 further simplification we now introduce a simplification of the hybrid scheme presented above we consider as hybrid only the vertical covariances while leaving static horizontal correlations this simplification requiring orthogonality of the two eof sets formally reads 12 δ x v f v b v h β c v v c v c β e v v e v e thus v v c represents the static eofs invariant among successive years v v e represents the ensemble derived flow dependent eofs in the experimental results section we will assess this assumption compared to the full use of ensemble derived covariances i e also to modulate the horizontal covariances there is a twofold advantage in the previous simplification the horizontal recursive filter is the most expensive operator implemented in oceanvar and this simplification avoids its double application on the two control vectors thus resulting in a scheme approximately as cheap as the standard 3dvar except obviously for the underlying need of running an ensemble system in parallel for reanalysis applications this can be advantageous when the ensemble system is run offline which is the case where first the ensemble data assimilation experiments are performed to cover the reanalysed period and then flow dependent background error covariances are calculated and used in a follow on experiment with hybrid covariances conversely if the system is run online for instance in an operational context namely with simultaneous advancement of both the ensemble system and the analysis system with hybrid covariances this simplification will not provide significant benefits in terms of computational cost as the largest cost is given by the ensemble system itself in the latter case this simplification might become unimportant furthermore the estimation of flow dependent correlation length scales from an ensemble of very limited size is non trivial and often produces spurious results even when localization procedures are implemented thus this simplification avoids the need of calculating ensemble derived length scales however it is clear that neglecting the use of hybrid horizontal correlations misses an important flow dependent aspect affecting the horizontal propagation of the observations for instance in the case of eddy dominated regions temporally evolving oceanic fronts etc 3 1 3 optimal hybrid weight the hybrid covariance formulation of oceanvar requires the specification of the hybrid coefficient that determines the relative weight given to stationary and flow dependent covariance in the assimilation it is customary to determine the optimal weight based on sensitivity experiments namely choosing the weight that leads to the best forecast skill scores recently ménétrier and auligné 2015 proposed an estimation method of hybrid weights based on linear filtering of sample covariances which simultaneously optimizes the hybrid weight and localization parameters as a function of the asymptotic error covariance and the ensemble size if localization is not explicitly included as in our formulation of eq 9 such an optimization procedure might be difficult to apply a practical issue concerns the optimality of the perturbations applied to the ensemble system which may not necessarily represent the real world error sources bishop and satterfield 2013 a usual way to overcome this issue is to perform sensitivity tests to determine the optimal hybrid weight for a certain ensemble system ensemble size and ensemble generation note also that α could be a function of the spatial coordinates e g varying horizontally and or vertically although this option is not considered here because it includes additional degrees of freedom in the analysis system and requires reliable local estimates of α also in regions characterized by poor observational sampling e g high latitudes south hemisphere or deep ocean alternatively a simple diagnostics expression based on the posterior assimilation statistics of desroziers et al 2005 may be formulated by substituting the hybrid form for b 13 e h δ x d t hbh t h α b c 1 α b e h t where hδx d t are assimilation output diagnostics and the two background error covariance matrices are known eq 13 is applied using all available observation departure data namely it provides a globally averaged estimate b c and b e are the background error covariance sets used in the assimilation run from which misfits d and increments δx are evaluated this suggests that the formula can be applied iteratively to successively retune the hybrid weight as in the original formulation of desroziers et al 2005 although eq 13 can be analytically solved in α we are here interested in evaluating its behavior with time rather than finding its stationary value to this end eq 13 is later applied during each assimilation cycle to diagnose the optimal hybrid weight 3 1 4 ensemble variational data assimilation the hybrid covariance formulation requires the estimation of flow dependent background error covariances to complement stationary covariances there may exist several ways to estimate flow dependent covariances for instance using pre existing ensemble prediction systems eps as done by clayton et al 2013 a simple and effective way is the recourse to an ensemble variational data assimilation eda system which includes several realizations of the deterministic system through perturbation of relevant input data and has the advantage that ensemble and deterministic realizations share the same data assimilation system fisher 2003 for long term applications i e reanalyses the system can be thought as an offline ensemble system although this prevents the deterministic analysis with hybrid covariances to feed back the ensemble system itself whose impact might be non negligible keppenne 2014 the implementation of hybrid covariances in oceanvar presented earlier has been extensively tested within the same analysis system outlined in section 2 1 with such a configuration an eda system was run with perturbations of ocean observations and atmospheric forcing and introduction of stochastic physics in our experiments an ensemble system formed by 24 members is run for several years 1993 2013 each member incorporating only stationary covariances as in the original 3dvar formulation the ensemble is generated by i perturbing the atmospheric forcing ii perturbing the equation of state eos with the scheme of brankart 2013 iii perturbing the observations for the former perturbations are drawn from the error dataset consisting of the unbiased differences of wind vector at 10 m above mean sea level temperature and specific humidity at 2 m shortwave and longwave radiative fluxes and total precipitation between the ecmwf era interim dee et al 2011 and the ncep r2 kanamitsu et al 2002 reanalyses note that the ncep r2 atmospheric reanalysis data are used only to introduce perturbations in the atmospheric forcing the climatology of the differences era interim minus ncep r2 is subtracted to each error field to avoid biases in the perturbations perturbations for each day are then randomly selected from an error realization forcing difference occurring during the same month of the year taken from the error dataset for the period 1989 2014 then a first order auto regressive process ar 1 with a decorrelation time scale equal to 10 days is used to correlate in time the perturbations in a way similar to storto et al 2013 the eos perturbation implies that small variations in density may be linked to the uncertainty in the unresolved sub grid processes the stochastic equation of state is configured to consider an ar 1 process to correlate in time density perturbations with a 20 day decorrelation time scale note that decorrelation time scales were setup empirically based on sensitivity tests although the ratio of 2 between oceanic and atmospheric decorrelation scales follows the evaluation of storto et al 2018 finally the observation perturbation follows standard ensemble generation procedures burgers et al 1998 as observation errors are assumed uncorrelated the perturbation is drawn from the unbiased gaussian distribution with the nominal observation error variance fig 1 shows the temperature ensemble spread with time from the system described above for three different vertical levels at 300 1000 and 3000 m of depth and separately for north 30n 90n and south 90s 30s extra tropics and the tropics 30s 30n while the ensemble spread at 300 and 1000 m of depth for the northern extra tropics is fairly stable with time it exhibits an initial spin up phase with increasing spread up to around 2002 in the tropics and southern extra tropics followed by a decreasing phase associated with the increasing deployment of argo floats in these two regions therefore the poor observing network slows down the spin up of the ensemble system a qualitative similar result applies to the northern extra tropics deep ocean 3000 m conversely deep ocean spread in the tropics and south hemisphere keeps increasing during the entire whole period suggesting that it did not reach a stationary value even after the 21 year period due to the lack of constraining observations in the deep ocean and the slow penetration of upper ocean perturbations care should be taken therefore when using ensemble statistics for the deep ocean although the maximum depth of most observing networks is generally limited to 1000 2000 m at deepest besides the inter annual variability the upper ocean spread in all regions exhibits high frequency variability that justifies the adoption of ensemble derived covariances in hybrid data assimilation schemes in the experiments presented later we increase the sample size rather than localizing the covariances following the approach of raynaud et al 2008 who suggested to use a spatial moving average to increase the sample size and limit spurious covariances in particular for each grid point we use all the data from grid points distant less than 2 grid points this is similar to use 600 realizations 24 members multiplied by 25 grid points for each set of vertical covariances calculated for a single grid point for each 2 week flow dependent set of eofs correlations length scales are calculated through fitting the empirical correlation curve as a function of the distance to a gaussian curve this method provided more numerically stable results with respect to other strategies tested for instance by storto et al 2014 it is also worth mentioning that the eigen decomposition performed over the ensemble anomalies retains only the 20 leading eigenvectors corresponding on the average to about 90 of explained variance providing an implicit vertical localization as pointed out by clayton et al 2013 the ensemble system runs offline i e there is no feedback mechanism between deterministic and ensemble systems through the ensemble estimated background error covariances hybrid sensitivity tests were run for the period 1994 2013 we have in particular investigated the hybrid weight α the fraction of the weight given to climatological error covariances that leads to the best skill scores for five values of α 0 fully ensemble covariances 0 25 0 50 0 75 and 1 fully stationary covariances results of the experiments are reported in fig 2 in terms of an observational error metrics l as a function of the forecast range t in days and the α weight as 14 l α t 1 n t j o α t 1 n e α j o α t where jo is as the observational term of the 3dvar cost function but limited to the observations falling in the daily time slot of the forecast day t i e the sum of the square departure between observations and model equivalents weighted by the observation error variance n t is the number of verifying observations at day t and ne is the count of the experiments different values for α five here the metric l is an anomaly i e the mean of jo over the different α experiments for each forecast range is subtracted in order to provide a way for comparing model results across different forecast ranges provided that the forecast errors increase with forecast range is larger than the sensitivity of the skill score to the hybrid weight l accounts simultaneously for all observation types scaled by their nominal observation error the smaller the value of l is the larger the decrease of the weighted sum of squared observation departures is i e the more positive the impact of the hybrid α weight is fig 2 shows the metrics for the global ocean and the three latitudinal bands summarizing the results for the whole 1994 2013 period at global scale the best hybrid weight is found around 0 75 at all forecast ranges meaning that in this hybrid system better results maybe found by giving slightly more weight to stationary covariances probably due to the limited ensemble size the weak model parameterisation perturbation and the lack of feedback between the deterministic and the ensemble analysis all factors contributing to the non optimality of the ensemble system nevertheless the experiment with α 0 75 leads to smaller l and therefore improved skill scores compared to the experiment with fully stationary covariances demonstrating the ability of the hybrid system in outperforming the traditional variational formulation note that the impact of the hybrid weight appears clearer for longer forecast leads i e the verification metrics diverge with time among the five experiments while results for south extra tropics are qualitatively similar to the global north extra tropics exhibit better results for α 1 for the longest forecast ranges suggesting that dense observation network and or high mesoscale variability may prevent the hybrid system to have significant impact hamill and snyder 2000 on the contrary the verification scores in the tropics suggest that for some forecast ranges better skill scores are found for larger weight given to ensemble covariances α 0 25 likely due to the fact that the atmospheric forcing perturbations are able to reproduce accurately the uncertainty in the tropical upper ocean fig 3 applies eq 13 in order to find the hybrid weight α using global ocean innovation statistics from the α 1 experiment black line and the α 0 75 experiment red line and stationary and ensemble derived covariances as input results are in qualitative agreement with those found with the verification metrics l i e the optimal weight is found as time average around 0 72 an increase with time of the weight is visible in the figure which may be linked to the increased observation sampling and suggests the need of temporal inflation for hybrid covariance systems applied e g to reanalyses or multi decadal experiments indeed we interpret the increase of α with the fact that augmented observational sampling reduces the need and the effect of the hybridization see later in section 4 the discussion for the north vs south hemisphere skill scores note also that successive applications of the method of eq 13 i e red curve versus black curve on statistics coming from hybrid simulations as a fixed point algorithm does not provide significantly different results indicating a rapid convergence of the diagnostics the agreement between the empirical sensitivity tests and the optimal weight found with eq 13 indicates that a value of α between 0 70 and 0 75 may be used for our coarse resolution hybrid ensemble variational system in the following sections we freeze the hybrid system with the α weight equals to 0 72 fig 4 shows the signal to noise s n ratio of the ensemble derived background error covariances in particular examining background error standard deviations and horizontal correlation length scales the s n ratio is here defined as the ratio between the mean in fig s1 and the standard deviation fig s2 of the flow dependent errors either background error standard deviations or horizontal correlation length scales computed apart for each month temporal variability of the covariances is indeed expected to be the largest where the temporal mean of errors is the largest or the variability of errors is the smallest thus the s n ratio reveals areas characterized by anomalous variability of the flow dependent covariances and can spot areas where background error flow dependence is potentially important in winter time both horizontal correlations and standard deviations appear rather stable with time i e mean exceeding the standard deviation and large values for s n ratio for mesoscale active areas in the north hemisphere gulf stream and kuroshio extension regions the ratio is small elsewhere and in particular in the arctic ocean in the subtropical band of the pacific ocean and in the antarctic circumpolar current region indicating that over these regions the recourse to hybrid covariances may have large impact within coupled ocean sea ice data assimilation which is however not considered here conversely in summer time such metrics indicate small s n for north hemisphere mesoscale areas and the antarctic region although values are in general larger 3 1 5 experimental results a case study is investigated here in order to observe the potential benefit of the hybrid 3dvar formulation we study in particular the week starting on 5 october 2010 in the tropical region where verification skill scores calculated on in situ profiles indicate a rmse decrease of about 10 when hybrid covariances are used not shown with respect to the original 3dvar formulation we choose such a period because october 2010 is characterized by a la niña event where the anomalies linked to the enso occurrence may be large compared to the long term mean ocean state and thus lead to anomalous flow dependent background error covariances thus this test case exemplifies the potential advantages of using information from an ensemble analysis system the ensemble derived flow dependent background error standard deviation are shown in the top panel of fig 5 maximums of the background error standard deviations are found in correspondence of the thermocline in the comparison with the static covariances differences shown in the middle left panel the abnormally shallow thermocline depth typical of the la niña event is reflected in the standard deviation anomaly showing a positive anomaly at around 50 m of depth in the eastern tropical pacific ocean and a larger error in the atlantic and indian oceans the increased slope of the thermocline also leads to anomalously negative errors at around 100 m of depth in the tropical pacific ocean we also compare the background error standard deviations with the ensemble derived time averaged ones over the period 1994 2013 ensclim which show how the features mentioned above do not stem from the use of the ensemble anomalies themselves but are truly flow dependent except for the vertical dipole in the eastern indian ocean indeed the ensclim set of covariances are drawn from ensemble anomalies and not anomalies with respect the long term mean as in stat and may be considered a better way to model covariances as the ensemble system mimics the real world error propagation storto and randriamampianina 2010 this example suggests that flow dependence of background errors could also be introduced to some extent by simply parameterising the errors as a function e g of the tropical thermocline depth however in areas with more complicated dynamics or for modulating correlation length scales such an approach might be difficult to apply a similar comparison is performed for the vertical background error correlations between the level at 100 m of depth and the other model vertical levels fig 6 static covariances show a very broad behaviour in particular exhibiting large correlations between the sea surface and the ocean at 100 m in the eastern tropical pacific the adoption of time averaged ensemble derived covariances narrows the vertical covariances rather homogeneously however only the use of flow dependent covariances lead the vertical correlations to vanish between the sea surface and 100 m of depth in the eastern part of the tropical pacific and between 100 m and deeper levels in the western part of the basin in the other sectors of the tropical pacific vertical correlations remain similar between ensclim and ensfd the effect of the modified covariances is visible in the temperature weekly mean differences between the hybrid covariance experiment and the 3dvar fig 7 the modulation of vertical correlations in the western part of the tropical pacific ocean in association with smaller background error standard deviation leads to the warming of the 150 200 m layer significant changes also occur in the atlantic sector with cooling in correspondence of the thermocline and warming above and below likely associated with the background error standard deviations larger than the stationary ones leading to a closer fit to observational profiles thus the three dimensional structure of the background error covariances reflects the anomalous conditions associated with the enso occurrences finally we shortly compare the use of hybrid vertical covariances against the use of both hybrid horizontal and vertical covariances during the common validation period 2010 2013 this is shown in fig 8 in terms of verification skill scores against gridded satellite altimetry more verification results will be given in section 4 at global scale the improvement given by the use of both horizontal and vertical hybrid covariances with respect to only vertical covariances is small and equal to about 0 5 statistically non significant peaking in the tropics at 0 9 not shown statistically significant therefore the impact is slightly positive suggesting that fully hybrid covariances should be adopted unless they represents a computational constraint as discussed in section 3 1 2 it is also worth noting that the cost function of eq 9 led to a decreased number of iterations required by the minimizer to reach convergence and smaller values of the final cost function meaning that the augmented control vector is able to better fit the observational constraints implied by the innovations this aspect anticipates that the hybrid covariance formulation is able to reduce observation minus analysis departures 3 2 simplified 4dvar 3 2 1 formulation standard incremental strong constraint 4dvar formulation considers that the tangent linear version of the model operator m 0 t propagates forward in time the increment δx within the assimilation window from the initial time to time t note that for sake of simplicity we used the notation m in section 2 the assimilation time window is discretized in a finite number of temporal intervals k at each time 15 δ x t m 0 t vv with m 0 0 i implying that δ x 0 vv the control vector v is therefore nominally defined at the initial time of the 4dvar time window the strong constraint formulation assumes the model operator to be perfect thus the cost function is re defined as 16 j v 1 2 t 1 t k h t m 0 t v v d t t r t 1 h t m 0 t v v d t 1 2 v t v where d t are the innovations for the observations included in the tth time interval and r t the associated error covariance matrix the strong constraint formulation is equivalent to conceive a physically balances temporal operator v t m 0 t such that 17 δ x t v t v f v b v h v v v and evaluate the innovations using the background fields corresponding to δx at the closer temporal interval to the observations when multiple outer loops are implemented the background fields at the kth outer loop are redefined as 18 x k b x 0 b i 1 i k 1 δ x i 0 where x 0 b x b is the initial background field and δx i 0 is the analysis increment at the initial time and at the ith outer loop at the beginning of each outer loop the 4dvar increments from the previous outer loop and valid at the beginning of the 4dvar assimilation time window are added to the background valid at the initial time and the non linear trajectory is evaluated then the 4dvar increment valid at the end of the time window from the inner loop minimization of the latest outer loop is used to provide the initial conditions for the next forecast this sketch requires that 4dvar increments at both the beginning and end of each outer loop are saved the use of outer loops allows for a re linearization of observation and model operators around an improved model trajectory and provides a possible algorithm to implement non linear and linearized model operators at different resolution although in the remainder of this work the multi resolution approach is not used 3 2 2 simplified model operator the 4dvar formulation requires that the model operator m 0 t and its adjoint are applied at each iteration of the minimization this drives the computational cost of the assimilation very high especially for a large number of time intervals k i e long assimilation window an alternative formulation with respect to the classical one of eqs 16 and 17 is now proposed we change the definition of the covariance operator chain by swapping the sequence of the operators such that the state vector is defined as 19 δ x t v f v b m 0 t v h v v v v f v b v t v h v v v following the configuration discussed in section 2 v is the control vector that after multiplication with v v contains temperature and salinity fields thus if the ocean model space is only composed of temperature and salinity then the other ocean variables sea surface height and ocean currents are only calculated through the balance operator and possibly the filter v f v b the formulation of eq 19 approximately halves the computational cost with respect to the standard chain of operators in eq 17 as only the increments of temperature and salinity and not sea level or currents are propagated forward in time by m 0 t thus saving in time in particular by avoiding the computation of diffusive and advective processes for currents in the case that observations of sea level and currents are not assimilated i e not constrained by observations then the previous formulation is equivalent to the one in eq 17 the analysis increments of ocean velocities come merely from the balances implied by v b applied on the increments of temperature salinity and sea surface height when observations of sea level and currents are assimilated then the two formulations differ only temperature and salinity evolve with time within the 4dvar assimilation time window while the evolution of current and sea level is limited to the fraction of the balance components that depend on temperature and salinity this underlines a large confidence on the formulation of the balance operator v b however in regional applications when e g hf radars are the dominating observing network this simplification may be limiting coding efficient tangent linear and adjoint versions of an ocean model is known to be a demanding task at present the nemo ocean model provides a frozen version of the tangent linear and adjoint version called nemotam vidard et al 2015 our choice however is to further simplify the model physics by selecting only a number of relevant processes without using the nemotam package thus the tangent linear and adjoint models are formed by the tangent linear and adjoint versions of the routines representing the selected process this approach avoids a formal coupling between oceanvar and any external package such as nemotam our simplified model considers for temperature and salinity only advective and diffusive terms in the horizontal and vertical and air sea flux exchanges in form of salinity s and temperature t tendencies the linearized model reads 20 s t s u z a v s s z a h s s s a 21 t t t u z a v t t z a h t t t a where ah and av are horizontal and vertical diffusivities defined apart for temperature and salinity and s a and t a are the temperature and salinity terms that represent the air sea exchanges details of the formulation and schemes used within the tangent linear model of eqs 20 and 21 are provided in appendix a 3 2 3 experimental results in the 4dvar scheme implemented in oceanvar we used 1 day frequency for the non linear model trajectories around which the tangent linear model is linearized this implies that these trajectories are stored as daily means nominally valid at the middle of the day and linearly interpolated over time onto the tangent linear model timesteps such a strategy seems more appropriate than using daily snapshots in order to partly include the diurnal cycle in the trajectories further tests shall consider high frequency instantaneous fields to better resolve the diurnal variability the intervals k for the discretization of the observational term of the cost function in eq 16 corresponds to the tangent linear model timesteps in the assimilation time window a comparison of single observation experiments is provided in this section to offer a flavour of how the 4dvar formulation shapes the analysis increments with respect to the standard 3dvar fig 9 shows the evolution of a perturbation along the 4dvar time window where the perturbation is the analysis increments from a single temperature observation assimilation namely a near surface argo measurement in the tropical pacific ocean with a 0 5 c innovation such a perturbation at the beginning of the time window is also equal by construction to the 3dvar analysis increments the figure shows the perturbation at the end of the 15 day 4dvar assimilation time window i e the nominal analysis time for the following forecast step furthermore the top right panel shows the fully non linear forecast model propagation m x a m x b of the analysis increment perturbation along the 4dvar assimilation time window in order to observe a realistic non linear trajectory that includes the complete set of model physics and assess the performance of the simplified tangent linear model the increments at the beginning of the time window do not follow the underlying flow although they are not symmetrically distributed around the observation because of the non uniform correlation length scales adopted storto et al 2014 the mean flow follows a north eastward circulation approximately north of the observation location while south westward south of the observation at the end of the time window 4dvar increments are correctly stretched along the mean flow and take a twisted south west to north east shape in accordance with the circulation described above differences between 4dvar increments at the end minus increments at the beginning of the time window bottom right panel are therefore positive north east and south west of the observation location and negative elsewhere the comparison between 4dvar and the non linear model propagation suggest that even a simple tangent linear formulation is able to reproduce the dependence of the increments upon the underlying flow the shapes of the increments being similar two possible configurations of 4dvar are analysed now depending on the number of outer loops either one 4dvar 1ol or two 4dvar 2ol when two outer loops are used the maximum number of inner loops minimization in the first outer loop is fixed to 20 in order not to increase the computational demand by much the inner loop of the latest outer loop ends when the same convergence criterion as in 3dvar see section 2 is reached a first comparison between these two configurations is offered by fig 10 in the verification against altimetry data due to the non linear relationship between temperature salinity and sea surface height the assimilation of altimetry data may in principle be affected by the re linearization implicit in multiple outer loops results suggest that the adoption of the second outer loop helps slightly reducing biases and rmse and increasing anomaly correlation during the period 2010 2011 while results are generally mixed afterwards over the entire period 2010 2013 the anomaly correlation increases by more than 1 peaking in the southern extra tropics not shown at more than 6 and suggesting that the double outer loop may provide slight improvements more validation results will be presented in section 4 4 comparison of hybrid 3dvar 4dvar and 3d hybrid 4dvar in this section we cross compare the benefits of the new oceanvar formulations allowing for hybrid 3dvar 4dvar and hybrid 4dvar for the latter we consider only the experiment where the ensemble component of background error covariances comes from an ensemble of 3dvar based realizations as in the hybrid 3dvar while the analysis system itself is based on the 4dvar formulation presented in section 3 2 the cost function of such a scheme formally reads 22 j v c v e 1 2 t 1 t k h t m 0 t β c v c v c β e v e v e d t t r t 1 h t m 0 t β c v c v c β e v e v e d t 1 2 v c t v c 1 2 v e t v e table 2 summarizes the experiments performed all sharing the same initial conditions valid on the 1st january 2010 and covering the 4 year period 2010 2013 the hybrid 4dvar experiment where b e is estimated from an ensemble of 4dvar based members is not considered for sake of simplicity and because of its large computational demand fig 11 reports the computational demand of each experiment in averaged cpu minutes per assimilation and forecast cycle for the configuration outlined in section 2 1 to be comparable cpu time has been measured using the same computational configuration 1 computational node corresponding to 16 cores on the cmcc supercomputing center machine athena the cpu time is also scaled with respect to the standard 3dvar formulation ratio on top of the bars to provide a clear idea of the computational increase the v hybrid 3dvar experiment is 25 times more expensive than 3dvar owning to the 24 member ensemble system discussed earlier while hybrid 3dvar is 26 times expensive due to the fact that the horizontal operator dominating the total cpu time required by the 3dvar system is called twice using both climatological and ensemble correlation length scales in the hybrid covariance analysis clearly this difference is very small unless the system is run offline i e when the ensemble system and the hybrid covariance analysis are run separately the time spent by the hybrid schemes depends on the ensemble size used therefore these estimates are not general and refer only to our configuration although operational ensemble sizes are typically of the order of 20 50 members smaller ensemble size may be used anyway as it is currently done in many atmospheric reanalysis configurations where a trade off between robustness of ensemble derived covariances and computational demand is achieved e g poli et al 2013 if the ensemble system is run offline e g for retrospective experiments the computational cost increase becomes less critical for timeliness issues the 4dvar system is 16 or 22 times more expensive than 3dvar depending on how many outer loops are used 1 or 2 4dvar turns out to be less expensive than hybrid 3dvar for our configuration note also that unlike hybrid 3dvar the 4dvar computational rise is less affected by the specific configuration used although the model resolution and the choice of the assimilation time window may affect these estimates finally 3d hybrid 4dvar with two outer loops employs about 47 times the time spent by 3dvar being obviously the most expensive formulation tested it should be noted that in case of a hybrid 4dvar system that uses an ensemble of 4dvar members the computational cost should theoretically be equal to 550 times that of 3dvar for a 24 member ensemble 4dvar system although this configuration has not been tested in reality note that this sketch does not consider on purpose any possible gain in computational time depending on the code scalability and increase of cores as the goal here is to test the computational demand with the same computer resources operational implementations may also need to consider scalability issues with the different assimilation configurations the validation of the experiments performed is here summarized focusing on the comparison with in situ profiles note that even though this dataset is actually assimilated in the experiments skill scores are computed before the observations are ingested in the system from observation minus background departures i e the dataset is independent if one neglects the temporal correlation of observational errors fig 12 shows the 2010 2013 profiles of rmse for the six experiments computed separately for temperature and salinity and for the southern and northern extra tropics and the tropics the southern extra tropics are characterized by the fact that all new formulations significantly improve the upper ocean skill scores for both temperature and salinity temperature scores are equally benefited by 4dvar and hybrid formulations although 3d hybrid 4dvar 2ol appears to slightly deteriorate the scores with respect to 4dvar 2ol or hybrid 3dvar this might be due to the sub optimal choice of the hybrid weight in case of the 4dvar formulation indeed applying the diagnostics of eq 13 we found a slightly larger value for the optimal α 0 83 for the hybrid 4dvar case compared to the hybrid 3dvar suggesting that slightly smaller hybridization is optimal for the 4dvar scheme and requiring further tests the 3d hybrid 4dvar 2ol experiment is however the best for near surface salinity followed by the hybrid experiments namely the hybrid extension seems the most effective in the southern ocean this partly applies also to the skill scores in the tropics where 4dvar and 3d hybrid 4dvar 2ol outperforms the 3dvar salinity skill scores and hybrid schemes outperform 3dvar temperature skill scores note that near surface salinity skill scores are not improved in the hybrid covariance experiments in the tropics likely due to the dominant error of the atmospheric freshwater forcing that ensemble derived covariances are not able to mitigate on the contrary 4dvar based experiments where the dynamical adjustment in the assimilation time window appears to positively impact the skill scores in the northern extra tropics the sensitivity of the data assimilation scheme is the smallest probably due to more abundant observing network along with the presence of strong mesoscale activity gulf stream kuroshio extension that the coarse resolution configuration used here is not able to fully capture the hybrid schemes for temperature and both 4dvar 2ol and 3d hybrid 4dvar 2ol for salinity are however the best leading configurations in this region fig 13 attempts to summarize the benefits of the new formulations at global scale by showing the accuracy increase defined as the percentage rmse reduction with respect to 3dvar such a sketch is drawn separately for forecast ranges 1 to 3 days and 7 to 10 days where we assume that forecast ranges from 1 to 3 are typical of a reanalysis configuration corresponding to typical assimilation time windows in high resolution applications while forecast ranges from 7 to 10 days are interesting for medium range ocean forecasts this definition has clear limitations but here it serves the purposes to examine the benefits of the new formulations of oceanvar at different forecast ranges percentage differences are statistically significant when greater than 1 2 in absolute values the results generally do not allow to draw robust conclusions on the relative merits of the different data assimilation formulations because results for temperature and salinity differ in this aspect note that salinity skill scores are more sensitive at longer forecast ranges suggesting that the predictability of salinity is shorter than that of temperature at global scale nevertheless it appears that especially for temperature short forecast ranges are positively impacted by the hybrid extension of 3dvar in qualitative accordance with the fact that the ensemble component of covariances improves the error characterization leading to smaller observation innovations right after the analysis step using the hybrid vertical and horizontal covariances outperforms the use of only vertical hybrid covariances except for temperature at long time range whose sensitivity is however small and not easy to interpret conversely long forecast ranges are benefited by the 4dvar extension of oceanvar a common interpretation is that 4dvar yields analysis increments more balanced than 3dvar with respect to the model trajectories leading in turn to better forecast trajectories that can be observed for longer forecast ranges in all cases the adoption of two 4dvar outer loops outperforms the use of one outer loop only except for temperature skill scores at short forecast ranges whose performance is not straight forward to interpret 3d hybrid 4dvar 2ol provides the largest improvement and represents a significant improvement of the data assimilation system at an affordable increase in computational cost 5 summary and discussion in this work we investigate possible strategies to extend a three dimensional variational data assimilation system to a hybrid ensemble variational four dimensional formulation and document its potential impact in a realistic global ocean configuration the hybrid paradigm is implemented by means of augmenting the control vector by a part associated with the ensemble derived flow dependent covariances such a formalism also allows combining different covariance sets e g representing errors at different spatial scales and does not necessarily require an underlying ensemble system we have also proposed an empirical expression based on the diagnostic formulas of desroziers et al 2005 in order to define an optimal hybrid weight such a definition matches well with criteria based on verification skill scores we have also considered the possibility to allow only the vertical covariances to be hybrid thus avoiding to apply twice the horizontal correlation operator which is expensive this strategy can save computational time and prevent the system from the computation of ensemble derived correlation length scales which is non trivial for small ensemble sizes although it obviously neglects the flow dependent horizontal propagation of the observational information with such a hybrid system we have shown that flow dependent background error covariances are shaped based on the time varying regimes e g during enso events that modify the vertical structure of the errors in the tropics results suggest that the analysis system is significantly benefited by the hybrid covariances at an affordable additional cost roughly equal to the ensemble size for high resolution applications of the hybrid covariance scheme further gain in computational cost can be achieved by using flow dependent covariances from a coarser resolution system in a way similar to what is routinely done within many nwp assimilation systems where the inner loops of the variational minimization are performed over a reduced resolution grid the adoption of hybrid data assimilation schemes is also supported by the growing attention devoted to stochastic physics packages within ocean and sea ice modelling juricke and jung 2014 brankart et al 2015 bessières et al 2017 for predictability and multi scale interaction studies and data assimilation developments this will certainly foster the adoption of hybrid covariances in the future as ocean ensemble systems will be able to span a large number of multi scale uncertainties in a more realistic way contextually a simplified four dimensional data assimilation scheme has been implemented the novel approach consists in swapping the tangent linear model operator and the balance operator in the operator chain that defines the square root background error covariance matrix this allows to halve the computational time as ocean velocities are no longer independent variables in the tangent linear and adjoint model the drawback is that one should rely on the balance operator definition as a function of temperature and salinity for the implicit evolution of current and sea level within the assimilation time window regional data assimilation systems may benefit from ocean current measurements from hf radar or from float trajectories e g nilsson et al 2011 in such configurations the use of a full 4dvar scheme should be compared to our formulation even this simplified tangent linear modelling is proved able to shape the horizontal propagation of the observational information in large agreement with the non linear model trajectory and according to underlying ocean circulation the adoption of a two outer loop configuration is also found to yield better skill scores with respect to the use of one outer loop at a slight computational cost increase furthermore a tangent linear and adjoint model that includes advection diffusion and air sea exchanges have been developed and embedded in oceanvar this development stems from the idea to develop a model with very light software infrastructure for easy coupling with any data assimilation system future applications of such tangent linear model may also include sensitivity analyses singular vector computation and observation targeting and all applications relying on linear modelling see e g errico 1997 the cross comparison between hybrid 3dvar 4dvar and hybrid 4dvar in general suggests that all the new formulations explored are between 16 and 47 times more expensive than 3dvar with the same computational resources and are therefore affordable if one considers a greater number of cores used assuming a good enough scalability the hybrid formulation positively impacts the system accuracy especially at short forecast ranges with obvious implications for reanalysis applications on the contrary 4dvar is able to reduce the forecast errors especially at longer forecast ranges and thus provides promising results for operational applications using fully hybrid covariances and not only hybrid vertical covariances always improves the system accuracy the hybrid 4dvar experiment where ensemble derived flow dependent covariances are still estimated from an ensemble system based on 3dvar provides further improvements except in the short range temperature verification where hybrid 3dvar outperforms the other experiments oceanvar shows small sensitivities to the hybrid and 4dvar extensions in the north extra tropics with respect to the south probably due to the combined effect of rich observing network and coarse model resolution of the testbed configuration therefore results might change with increased resolution and or a different observational coverage future developments for oceanvar will include a weak constraint formulation for the simplified 4dvar system at present the oceanvar code already includes this option through augmenting the variational control vector with time discretized model error variables the so called model error forcing control variable see trémolet 2006 however the results not shown indicate a large sensitivity to the choice of model error covariances and temporal discretization of model errors and optimal strategies still need to be identified acknowledgments this work has received funding from the european commission through the copernicus marine environment monitoring service cmems acknowledgment is made for the use of ecmwf s computing and archive facilities in this research the en4 subsurface ocean temperature and salinity data were collected quality controlled and distributed by the u k met office hadley centre the altimeter products were produced by ssalto duacs and distributed by aviso with support from cnes we thank three anonymous reviewers for their valuable help in improving the quality of the manuscript appendix a simplified tangent linear model operator eqs 20 and 21 outline the simplified tangent linear operator included in the 4dvar version of oceanvar which considers the evolution of temperature and salinity within the assimilation time window from advective and diffusive processes and air sea flux exchanges the tangent linear timestep for the configuration presented in section 2 1 is the same as the non linear model and equals 5400 seconds the advection scheme is implemented through a 2nd order centered scheme and the time stepping is performed using a leapfrog scheme in conjunction with an asselin time filter asselin 1972 velocity fields are taken from the non linear model trajectories saved at daily frequency in the experiments presented in this article for numerical stability vertical velocities used in the vertical advection scheme are calculated from an upward integration of horizontal divergence from the daily mean velocity fields an iso level laplacian operator is used for horizontal diffusion with a h s a h t 4000 m 2 s 1 an implicit scheme is implemented for solving the vertical diffusion the vertical eddy diffusivity in the tangent linear model a v s a v t is assumed not to depend on temperature and salinity and is taken from the non linear model trajectories at daily frequency no specific convection parameterisation scheme is used in the tangent linear model air sea exchanges are formulated by linearizing the bulk formulas of large and yeager 2004 with additional simplification outlined below tangent linear freshwater fluxes f are equal to the tangent linear evaporation flux e the precipitation and river runoff not depending on the ocean state and sea ice melting processes being neglected 23 f e ρ a c e z q 2 t 0 e q 2 t 0 b t 0 b 2 u where ρa is the air density 1 22 kg m 3 ce is the evaporation transfer coefficient the coefficients z and q 2 are equal to 514403 6 dimensionless and 5107 4 k respectively t 0 is the tangent linear sea surface temperature t 0 b the background sea surface temperature from the non linear model trajectory the subscript 0 indicating the sea surface and u is the wind speed provided here from the era interim atmospheric reanalysis dee et al 2011 noting that shortwave radiation does not depend on the ocean state the air sea heat fluxes q in the tangent linear model are given by the sum of outgoing longwave radiative flux qlw and sensible qsn and latent qlt heat flux 24 q q l w q s n q l t 4 σ t 0 b 3 t 0 ρ a c a c h t 0 u l v e where σ is the stefan boltzmann constant 5 67 e 8 w m 2 k 4 ca is the specific heat of the air 1000 5 j kg 1 k 1 ch is the sensible heat transfer coefficient and lv is the latent heat of vaporization 2 5 e 6 j kg 1 a further simplification in the tangent linear air sea flux operator consists of assuming the transfer coefficients ce and ch are not dependent on the ocean state i e they are taken from the non linear model trajectory this prevents the tangent linear version to use the highly non linear iterative procedure to calculate non neutral transfer coefficients of large and yeager 2004 in the future weak dependence of the transfer coefficients on the sea surface temperature may be included using simplified empirical relationships for the coefficients as in kara et al 2000 temperature and salinity tendencies given by the air sea exchanges are respectively equal to 25 t a 1 ρ w c w d z q cw being the heat capacity of sea water 4000 j kg 1 k 1 ρw the sea water density 1026 kg m 3 and dz the thickness of the first vertical model level the salinity tendency is given by 26 s a 1 ρ w d z s 0 b e e b s 0 where s 0 s 0 b are the tangent linear sea surface salinity and its non linear background counterpart and eb is the background evaporation adjoint validation tests see e g vidard et al 2015 were implemented in oceanvar and all the adjoint routines passed the test successfully supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j ocemod 2018 06 005 appendix b supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
24101,the purpose of this study is to investigate possible local changes in the wave climate for the coastal waters off eastern canada particularly in the gulf of st lawrence gsl related to changes in marine winds storm and the sea ice climate due to climate change these analyses are based on application of a dynamical downscaling approach whereby a regional climate model is driven by climate change estimates from the canadian global climate model cgcm3 to provide relatively high resolution winds to drive a wave model the cgcm3 simulation follows the a1b climate change scenario of the special report on emission scenarios from the fourth assessment report ar4 of the intergovernmental panel on climate change ipcc ar4 2007 the analyses of the wave climate are based on simulations of the waves from a third generation wave model wavewatchiii and the downscaled winds obtained from the canadian regional atmospheric climate model crcm we show that the significant wave heights in the gulf of st lawrence hereafter gsl and neighboring coastal waters will slightly increase in the winter and decrease in the summer in response to changes in storms and sea ice in the future climate 2040 2069 compared to the present wave climate represented as 1970 1999 this time period is denoted as the historical wave climate in this study in summer the changes in significant wave heights hs are associated with estimated decreases in the frequency of the occurrence of the cyclones projected changes in return values for summer extremes in the wave climate are consistent with the associated changes in the maximum hs values in winter the projected increases in return values are mostly concentrated in the st lawrence estuary the northern and southwestern gsl consistent with changes in the maximum waves in these regions an important factor related to change in the winter wave climate is change in the sea ice keywords waves climate change storms sea ice extreme value analysis gulf of st lawrence 1 introduction waves are generated by wind very often in association with storms if sea ice is present it will tend to dampen the waves the gsl gulf of st lawrence is a semi enclosed sea adjoining the east coast region of canada it has special climate characteristics because it is partially covered by sea ice in winter and it can be affected by strong storms moving from west to east as well as nor easters moving along the eastern coast of north america from cape hatteras towards newfoundland and onwards to europe and extra tropical hurricanes moving from the southwest towards the northeast along the eastern coast of north america in the gsl the waves can impact society by their potential to damage coastal infrastructure as well as vulnerable near shore and offshore structures marine transport recreational activities and commercial fishing the possible impacts of climate change on waves including effects on sea ice wind and storms have been investigated by several recent studies wang and swail 2006 grabemann and weisse 2008 kharif et al 2008 wang et al 2012 guo et al 2015 ruest et al 2016 changes in storm activity in the north atlantic can affect the winds which are drivers for changes in the climate of the waves e g wang and swail 2006 wolf and woolf 2006 guo et al 2015 sea ice influences the wave climate mainly through dissipation of the wave energy as waves propagate into the ice and by directly modifying the open water fetch distance for wind wave generation and development tolman 2003 thomson et al 2016 shen et al 2018 global warming is expected to result in a reduction in sea ice in the gsl a decrease in extreme winds over large areas of the north atlantic and a poleward shift in storm tracks in the mid latitude north atlantic region as suggested by climate model simulations knippertz et al 2000 fischer bruns et al 2005 yin 2005 bengtsson et al 2006 lorenz and deweaver 2007 mclnnes et al 2011 guo et al 2015 long et al 2015 ruest et al 2016 however gallagher et al 2016 analysed two future climate scenarios rcp4 5 and rcp8 5 and found a mixed picture for the seasonal mean 10 m winds for the north atlantic region suggesting a decrease in future summer winds over eastern canadian coastal areas with negligible changes in estimates for future winter winds in these areas but there are additional factors like sea ice and therefore it is important to estimate the possible impacts to the wave climate of climate change and the role of these related factors several studies have investigated the mean and extreme wave climate in the northwest atlantic and the gsl swail et al 2006 ruest et al 2013 guo and sheng 2015 ruest et al 2016 based on wave simulations swail et al 2006 ocemod1312 xml 382 argument of genfrac has an extra estimated the annual mean and extremes of significant wave heights hs in the gsl for the period 1955 2004 they found that the maximum annual mean wave height the maximum 99 percentile wave heights and the highest percentage of days during a year with hs exceeding 3 m occur mostly in deep offshore waters whereas the hs values in near shore areas are relative low swail et al 2006 used the gumbel extremal distribution to estimate the 100 year return period for wave heights they showed that the 100 year wave height varies from under 6 m in some coastal regions to over 17 m in the deep offshore waters off eastern canada guo and sheng 2015 also estimated the 50 year return period for wave heights using the generalized pareto distribution gpd and demonstrated that the highest values are about 14 m in offshore areas beyond the continental shelf break but decrease in the coastal regions of the grand banks and scotian shelf compared to the results of guo and sheng 2015 the results for the 50 year return period for hs over the southwestern part of the gsl estimated by ruest et al 2013 are relative high possibly because the latter did not consider the winter sea ice in simulating the waves sea ice is projected to be notably reduced in the gsl by the end of the 21th century in response to changes in ice wave heights are expected to increase in this region in projections of the future climate ruest et al 2016 thus the impact of sea ice on the winter wave climate needs to be considered these studies focus on the annual mean and extreme wave statistics in the gsl the climate features related to seasonal mean and seasonal extreme waves in the gsl and discussion of the possible reasons behind these changes have received less investigation although ruest et al 2016 investigated the impact of sea ice cover on extreme waves they focused on a limited region of the northwestern gsl and the st lawrence estuary the impacts of climate change over other areas of this region including the southern gsl around prince edward island and the eastern gsl near newfoundland are still not explored in this study we investigate the impacts of future climate change on seasonal mean and seasonal extreme waves in the gsl winter january february march and summer july august september estimates are projected separately we also present a discussion of possible factors that may lead to these future climate changes this study takes account of the impact of winter sea ice in addition the pot method is used to estimate the 10 50 and 100 year significant wave heights the objective of this study is to investigate the impacts of climate change on the significant wave heights related winds storm and sea ice properties in the gulf of st lawrence and nearby coastal areas of the northwest north atlantic waves are driven by winds which are often generated by storms the impacts of climate change are experienced by storm activity and sea ice in the western north atlantic and thus are exhibited in the wave climate sections 2 and 3 describe the models the data and the relevant methods used in this study section 4 gives validations of the simulations of the storms and significant wave heights in terms of the reanalysis data in section 5 we discuss the impacts of climate change projections on storms sea ice and the significant wave heights analysis of extreme waves is given in section 6 discussion and conclusions are given in section 7 2 models and data 2 1 atmospheric winds in this study we use the canadian regional climate model crcm version 3 7 1 tanguay et al 1990 caya and laprise 1999 for simulations of the winds to drive the wave model the computational domain covers much of the eastern north american continent and the north atlantic crcm solves the fully elastic nonhydrostatic euler equations combining the semi lagrangian semi implicit mesoscale compressible community mcc model dynamical kernel with the atmospheric gcm physics parameterization package from the canadian centre for climate modelling and analysis thus crcm is an important downscaling technique to simulate regional climate for a limited area regional domain in the implementation used here there are 259 169 polar stereographic grid points and a relatively fine horizontal resolution of 45 km at 60 n vertically there are 29 gal chen levels gal chen and somerville 1975 from the ground to 29 km altitude at the top of the model s implementation initial and lateral boundary conditions are taken from outputs of the coupled global climate model cgcm3 t47 which has a horizontal resolution of about 3 75 so that there are two grid points per truncation wavelength around any great circle we use a spectral nudging technique in the crcm to weakly constrain the large scale fields towards the driving fields from cgcm3 t47 following riette and caya 2002 the time step is 15 min details about crcm are given by caya and laprise 1999 laprise et al 2003 caya and biner 2004 and for application in our model domain guo et al 2015 in this paper we simulate a 30 year period from 1970 to 1999 to represent the present climate this time period can be denoted as the historical wave climate initial and lateral boundary conditions for crcm are taken from cgcm3 outputs following the a1b scenario from ipcc 2007 this scenario assumes high economic growth and middle usage of the energy sources with co2 levels reaching 720 ppm by 2100 nakićenović et al 2000 we also simulate a 30 year period from 2040 to 2069 to represent the associated future climate change scenario also driven by cgcm3 outputs for the a1b scenario the sea ice and surface winds at 10 m reference height are interpolated in space to match the wavewatchiii hereafter ww3 wave model grid every 6 hours thus we use the winds to drive ww3 leading to estimates of the wave climate for present climate conditions and also for the future climate scenario 2 2 waves the wave climate for this study is computed by the ww3 wave model version 3 14 the version available at the time of the study which is a third generation spectral model with the st3 physics parameterizations as described by tolman et al 2002 and tolman 2009 and it includes the usual source terms such as energy input by wind wave dissipation non linear wave wave interactions and bottom dissipation parameterizations st3 was the most advanced parameterization package that was available at the time when this project was started later physics formulations like st4 or st6 were not yet available moreover liu et al 2017 have recently compared the performance of st3 st4 and st6 and suggest that within the uncertainty in the wind forcing fields all three formulations perform well in simulations of wave parameters generated by hurricane conditions the model domain is the north atlantic 20 n 65 n 85 w 10 w the wave model grid spacing is 0 5 0 5 and the spectral domain is divided into 29 frequency and 24 directional bins 15 discrete frequency bins range from 0 0418 to 0 6028 hz using an increment factor of 1 10 this domain is nested to a higher resolution domain focusing on the gsl 42 n 55 n 72 w 50 w with wave model grid spacing 0 125 0 125 wave simulations using ww3 are driven by crcm winds from 27 december to 31 march winter season and 27 june to 30 september summer season for each year during 1970 1999 and 2040 2069 allowing the first five days as spin up time for the wave model preliminary wave ice interaction processes were also considered specifically the ic0 source term package thus if the ice concentration is c at any grid point in the marginal ice zone then in the model simulation the spectral wave energy e at this grid point becomes 1 c 100 e default values for c of 25 and 75 were used to denote ice free conditions and conditions where sea ice is treated as land respectively the input fields for sea ice were obtained from the ice ocean simulations using nemo ocean model as described by long et al 2015 although preliminary experimental routines for representation of the boundary effects of ice on waves were implemented in ww3 as provided by tolman 2003 wave scattering due to ice floes was not yet available at the time of this study boundary conditions at the outermost boundary for the model system are assumed to behave like a solid wall nothing comes in and the boundary is like a sponge absorbing all waves crossing to the outside 2 3 sea ice sea ice is important in the study of wave climate and climate change because sea ice reduces the surface winds reducing the momentum exchange between the atmosphere and the ocean validation studies for sea ice were done by long et al 2015 comparing their model simulations with national snow and ice data center nsidc data peng et al 2013 and suggesting that the simulated sea ice cover and ice volume in the gsl are in good agreement with the observations long et al 2015 used the canadian opa canopa model as adapted by brickman and drozdowski 2012 based on the océan parallélisé version 9 model opa 9 0 madec et al 1998 and the louvain la neuve ice model version 2 lim2 fichefet and morales maqueda 1997 bouillon et al 2009 comparisons of sea ice cover from long et al 2015 to nsidc data are shown in fig 1 their simulated sea ice concentrations show seasonal variations whereby the sea ice forms over the shallow waters among the north and west gsl coasts with the maximum sea ice concentrations occurring in the st lawrence estuary and along the saguenay estuary in january eventually almost covering the entire gsl maximum concentrations are reached in february and then start to retreat back to the saguenay estuary in march fig 1 the simulated ice volume in the gsl increases from about 22 km3 in january to 60 km3 in march 2 4 reanalysis data for validation of present wave climate conditions we compared our results with those of the wave hindcast from the iowaga project integrated ocean waves for geophysical and other applications described by rascle and ardhuin 2013 for the northwest atlantic with 10 min spatial resolution this dataset was constructed using ww3 with st4 physics parameterizations which is the state of the art parameterization for generation and dissipation of wind waves ardhuin et al 2010 the dataset includes the period from 1990 to 2012 at the time of this study we use 6 hourly mean sea level pressure mslp fields from the european centre for medium range weather forecasts era interim reanalysis dataset dee et al 2011 as input to the methodology to detect and track cyclones described in section 3 1 era interim is one of the latest available global reanalysis datasets based on a four dimensional data assimilation system the data is available at a high spectral resolution t255 about 79 km for the time period from 1979 to the present strachan et al 2013 have demonstrated that the north atlantic cyclone track density can be reliably extracted from the era interim data 3 methods in this section we introduce three methods needed for investigation of the wave climate and the possible effects of climate change these methods are cyclone detection spatial correlation and extreme value analysis the importance of these methods is 1 detection and tracking of the extratropical cyclones 2 validation of the wave model estimates for wave climate results and 3 prediction of the extreme wave heights for differing intervals such as 10 50 and 100 year time periods 3 1 cyclone detection extratropical cyclones are detected and tracked using the university of melbourne automatic cyclone tracking scheme murray and simmonds 1991a 1991b simmonds and murray 1999 this cyclone tracking scheme is chosen due to its good performance compared to other automated tracking schemes e g raible et al 2008 neu et al al 2013 in this scheme the quasi lagrangian perspective of cyclone behavior was used rather than the eulerian perspective the automatic cyclone tracking scheme identifies possible cyclones based on the 6 hourly maps of the mslp fields by comparing the laplacian of the pressure to the values at 20 neighboring grid points after a possible candidate cyclone is identified the location of the associated pressure minimum is located by using ellipsoidal minimization techniques to determine the cyclones that are meteorologically significant the candidate cyclones are tested using a minimum concavity criterion which requires that the area averaged laplacian exceed 0 5 hpa olatitude 2 for closed depressions or 1 5 hpa olatitude 2 for open depressions over a radius of 2 latitude from the apparent cyclone center after a set of snapshots of potential cyclones is created satisfying the selection conditions described above an algorithm is used to track the individual cyclones in successive 6 hourly maps this approach makes an estimate of the new positon of the each cyclone calculates the probability of associations between the actual and predicted cyclone positions and then estimates the most probable combination for each single physical cyclone thus the storm track density is defined as the number of cyclone tracks passing through a given grid cell here 6 hourly mslp data from regional downscaled crcm model outputs are used to represent the present climate while mslp data from era interim reanalysis are used for validation since spatial resolution of the input data has a strong influence on the number and characteristics of detected cyclones jung et al 2006 both datasets are interpolated to the same polar stereographic grid before making an analysis of cyclones and their tracks we focus on cyclones that last at least 4 time steps on the 6 hourly maps i e 24 h the crcm model grid introduces geographical limits to our study thus cyclones are detected and tracked over the north atlantic 20 n 72 n 120 w 0 75 w 3 2 spatial correlation we adopt statistical metrics to quantitatively evaluate the spatial correlation of the climate variables estimated by models against the observations suppose that x y are simulated and observed data at m grid points in space respectively the spatial correlation c between x and y is defined as 1 c 1 m m 1 m x m x y m y s t d x s t d y where x and y are the mean of x and y over the m grid points and std is the spatial standard deviation the spatial standard deviation of x is defined as 2 s t d x 1 m m 1 m x m x 2 3 3 extreme value analysis in extreme value analysis two statistical approaches are commonly used to obtain the r year return period significant wave height menéndez et al 2009 teena et al 2012 ruest et al al 2013 these are the annual maxima am method and the peaks over threshold pot method 3 3 1 am method in the am method the maximum values in each year are extracted to construct the dataset that is used for the extreme value analysis the distribution of the maximum values can be represented approximately by a generalized extreme value distribution gev coles 2001 whose cumulative distribution function is 3 g z exp 1 ɛ z μ σ 1 ɛ f o r ɛ 0 exp exp z μ σ f o r ɛ 0 where μ σ ε are the location scale and shape parameters respectively the shape parameter can determine the type of distribution depending on the value of the shape parameter ε the gev distribution has three possible distribution families 1 gumbel distribution with ε 0 2 fréchet distribution with ε 0 and 3 weibull distribution with ε 0 in this paper the parameters are estimated by the maximum likelihood ml method and comparisons are made with the probability weighted moments pwm method in order to fit a candidate distribution function to a given sample the coefficient of determination r 2 and root mean square error rmse are used to identify the best fit distribution in this approach the return value zr for the r year significant wave height is the value exceeded once every r years on the average this is obtained by finding the inverse of the function of the cumulative distribution following goda 2010 4 z r g 1 1 1 r where r is the return period associated with the return value here r is defined as 5 r 1 1 g z and therefore the return value obtained by eqs 1 and 2 is expressed as follows 6 z r μ σ ɛ 1 log 1 1 r ɛ f o r ɛ 0 μ σ log log 1 1 r f o r ɛ 0 3 3 2 pot method alternately another method that can also be used for extreme wave analysis is the pot method which considers the peaks exceeding a pre set threshold in the pot method the distribution of the threshold excesses is assumed to follow a generalized pareto distribution gpd following coles 2001 in this approach z is the cluster maxima of the significant wave heights given a threshold u the cumulative distribution function of gpd can be expressed as 7 g z 1 1 ɛ z u σ 1 ɛ f o r ɛ 0 1 exp z u σ f o r ɛ 0 where σ represents the scale parameter and ε is the shape parameter like the gev method the shape parameter determines the type of the distribution when ε 0 the gpd reduces to an exponential distribution when ε 0 the gpd distribution becomes the pareto distribution finally when ε 0 the gpd distribution becomes the beta distribution the threshold selection methodology is necessary in the gpd method because the high threshold value reduces the bias but increases the uncertainties of the parameter estimation whereas the low threshold gives the opposite result a sensitivity analysis on threshold selection was performed by ruest et al 2013 in application of the pot method in the gulf of st lawrence gsl their results show that estimates of the return values are not sensitive to the choice of the threshold from 90 to 99 percentile therefore we choose 95 and 97 percentile for significant wave heights as the two threshold values after the threshold has been fixed the time length between consecutive exceedances of the threshold is set in order to get independent extreme events here we select a minimum of 48 h as the separation time following caries and sterl 2005 and teena et al 2012 besides the ml and pwm method the maximum product of spacings mps method is also used for parameter estimation when fitting the gpd therefore the return value zr of the r year significant wave height corresponding to the pot method is 8 z r u σ r n ξ u ɛ 1 ɛ f o r ɛ 0 u σ log r n ξ u f o r ɛ 0 an estimation of the return value zr is obtained by solving ξ u 1 ɛ z r u σ 1 ɛ 1 r n for ε 0and ξ u exp z u σ 1 r n for ε 0 where n is the number of observations per year and ξ u is the probability that an individual observation exceeds the threshold which can be estimated as 9 ξ u λ n here it is assumed that the number of exceedances is approximately poisson distributed with respect to the parameter λ 4 model validation as noted in section 2 1 to represent the present climate we simulate a 30 year period from 1970 to 1999 which can also be denoted as the historical wave climate in this paper however in this section the simulation is extended to a 43 year period from 1970 to 2012 in order to allow validation with iowaga reanalysis wave climate data which is only available from 1990 validation is carried out with respect to storms and significant wave heights to evaluate the performance of crcm and ww3 driven by crcm winds 4 1 storms in summer the cyclone track density derived from era interim data suggests that the high frequency region for cyclone development appears over the middle and high latitudes north to 45 n with a maximum density over the open water area directly southeast of greenland fig 2 a by comparison the crcm model can capture the overall spatial pattern of track density shown in the era interim reanalysis data although the former overestimates the cyclone frequencies south of the tip jet of greenland fig 2b the locations of maximum cyclone density are simulated well in the crcm simulations however crcm overestimates the cyclone activity in the gsl compared to the estimates from era interim data a similar comparison for the winter season is shown in fig 2c and d for the era interim data there are slightly more cyclones over the northeastern north atlantic and in the gsl than the results in summer fig 2a and c the maximum cyclone frequencies are mainly located in the open water areas on the east side of greenland overall the estimated cyclone track density for winter seasonal mean crcm simulations fig 2d are in agreement with era interim results in locations of maximums magnitudes and spatial patterns of track density for the gsl the overestimates from crcm simulations are found in winter similar results are found by the methodology of guo et al 2015 which is based on minimum mslp rather than mslp gradients used here 4 2 waves the simulated summer means for the mean 10 highest maximum and mean significant wave heights for the 1990 2012 period from ww3 driven by crcm winds are compared with the iowaga wave hindcast data in fig 3 in general results from ww3 as driven by crcm winds and wave data from the iowaga simulations show similar spatial patterns values for mean 10 highest maximum and mean wave heights are generally decreasing with a gradient from the deep water areas to the shallow water areas in the summer the simulated mean significant wave heights ww3 driven by crcm winds are around 0 5 1 3 m in the gsl while the simulated mean of 10 highest and maximum wave heights are around 2 3 6 m and 3 6 6 m respectively compared to iowaga ww3 driven by crcm winds produces higher values for the mean 10 highest waves as well as the maximum wave heights and reasonable comparisons for mean values based on the pattern correlation coefficient c and root mean square error rmse shown in each panel ww3 driven by crcm winds is able to capture the magnitude of the wave heights well especially the mean values as well as the spatial patterns correlation coefficients are in excess of 0 9 in winter our simulated ww3 results for mean 10 highest maximum and significant wave climate exhibit similar spatial patterns as those found in summer although the values are relatively higher as presented in fig 4 the simulated mean significant wave heights are around 1 3 5 m in the gsl and the wave heights for winter mean of the mean 10 highest and maximum are around 2 7 m and 3 10 m respectively ww3 driven by crcm winds overestimates the mean 10 highest the maximum and mean wave heights compared to the iowaga simulations but consistently captures the spatial patterns well with spatial correlations higher than 0 96 as illustrated from the rmse values in each panel the values of mean 10 highest and maximum wave heights estimated by ww3 have larger differences than those of mean wave heights when compared with results from iowaga simulations 5 climate change impacts 5 1 storms in this section we focus on summer and winter seasons the differences in cyclone track density between the future climate scenario considered in this study and the historical simulations for these two seasons are shown in fig 5 in summer for the future climate change scenario a significant increase in cyclone track density is projected to occur off the coasts of greenland and iceland with an apparent decrease in the labrador sea in the gsl and over the northeast atlantic and extending to western europe fig 5a the projected poleward shift in the summer cyclone track density and the estimated decrease in cyclones in the gsl are in agreement with the estimates based on the echam5 coupled climate model by bengtsson et al 2006 in winter the crcm simulations suggest that the cyclone track density decreases in the areas off greenland and iceland as well as in the gsl region with slight increases in track density off the coast of newfoundland fig 5b 5 2 sea ice ruest et al 2016 study the influence of sea ice on significant wave heights their results show that extreme values for hs in the gsl during 1981 2010 are reduced by about 12 through the effects of sea ice therefore extreme values for hs are expected to increase in the late 21th century due to the reduction in sea ice however the area of their interest was limited to the northwestern part of the gsl only considering the sea ice formation and melt processes during the winter shown in fig 1 we investigate possible future changes in sea ice concentration over the gsl for each month of the winter season for the a1b climate scenario during 2040 2069 relative to the present climate period 1970 1999 fig 6 in the a1b climate scenario the area covered by ice becomes smaller in each winter month compared to the present climate march is notable because the gsl is estimated to be virtually ice free in the future climate scenario a prominent feature in ice changes is that there is a slight decrease in ice over the shallow waters adjoining the coast in january and a significant decrease over nearly the entire gsl in both february and march the reduction in gsl sea ice is also suggested by the time series in fig 7 showing the changes in sea ice cover and ice volume from the present to the future climate scenario declining trends for sea ice cover area are apparent particularly after the late 2020s in each month the decrease in sea ice cover area is approximately 80 in the 2060s compared to the 1970s for each month the area covered with ice in january is smaller than the areas estimated for february and march for the entire time period the estimated mean ice volume shows similar steady decreases as with reductions in ice cover in the gsl the most remarkable decreases are estimated to occur after the late 2020s in all three months the seasonal maximum ice volume changes from around 100 km3 during the 1970s to about 25 km3 during the 2060s 5 3 waves for summer conditions the projected changes in mean hs maximum and mean of top 10 hs for 2040 2069 relative to the present climate 1970 1999 are shown in fig 8 overall the decrease of mean maximum and mean top 10 wave heights over areas of the gsl follow the projected poleward shift of the summer cyclone track density mentioned in the previous section therefore a decrease in cyclone activity in the gsl should be expected to contribute to decreases in the estimated mean hs maximum and mean top 10 hs in the summer seasons of the future climate scenario however there are a few small areas where waves are estimated to increase in the future climate relatively weak increases in maximum hs are estimated to occur for small areas of jacques cartier strait the st lawrence estuary and the southern gsl reflecting the related changes in the winds and cyclone tracks for winter conditions the changes in mean hs for each winter month are different we show the changes in mean hs for each month for the period 2040 2069 minus present climate conditions 1970 1999 in fig 9 this figure also shows the projected changes in maximum and mean of 10 highest hs it can be seen that in each month the changes in mean hs share similar spatial patterns as those of the mean of 10 highest hs and maximum hs in the gsl the projected changes in january are different from those of february and march in january there are slight increases in mean hs maximum and mean of top 10 hs over the st lawrence estuary the northeast gsl and waters leading to the belle isle strait and to a lesser extent the western gsl by comparison in february and march the significant increases in these variables are suggested to occur over the entire gsl for the wave climate in winter the two dominating factors are the impacts of climate change on cyclones and their tracks and on sea ice in winter the cyclone track density is projected to decrease in the gsl generally less cyclone activity implies decreased estimates for hs in the climate change scenario however this seems not to be the dominant process in our study on the contrary fig 1 suggests that the sea ice experiences changes in the formation and melt processes from january to march relative to the present climate these changes are progressive and significantly affect the associated wave climate at each phase of the seasonal cycle because wave ice interactions affect the attenuation of the wave climate section 2 2 and the spatial distribution of sea ice concentration in the gsl is different in each month moreover in the climate change scenario changes in sea ice are also different month by month fig 6 to address the role that sea ice plays in wave climate in winter we have presented the changes in the wave climate month by month compositely the seasonal mean hs of maximum and of mean 10 highest hs are projected to increase in the gsl therefore the influence of climate change on the cyclones and thus on the winter wave climate is mitigated by changes in sea ice here we consider the influence of ice on the gsl wave climate by comparing the change patterns for waves and sea ice comparing figs 6 and 9 it is apparently that the changes in mean hs mean 10 highest and maximum hs are consistent with changes in sea ice for each winter month in the gsl therefore reductions in sea ice are a determining factor that results in increased waves in the future climate scenario as shown in mean maximum and mean top 10 waves estimates in the gsl 6 extreme wave analysis in performing an extreme value analysis variations in the steps used in the methodology can lead to differing results considerations include the choice of the extreme value distributions gev family or gpd family the threshold selection for gpd 95 or 97 quantile and the choice of methods to estimate the parameter to fit a candidate distribution mps ml or pwm in this study we considered several combinations mentioned above and we adopted the r 2 coefficient of determination and root mean square error rmse to estimate differing distributions with respect to the model data see table 1 r 2 is a measure of how well a given distribution can fit the data the values of r 2 range from 0 to 1 where higher values indicate better fits in contrast rmse is used to measure the differences between values estimated by the differing distributions and the values of the original data lower values of rmse indicate better fits to the data we note that estimates of the return value have been shown to not be sensitive to the choice of the threshold from 90 to 99 percentile by ruest et al 2013 there can be large differences between statistical results obtained by using the gev model or the gpd model in the gsl in summer as illustrated in table 1 the values of r 2 resulting from gpd are all larger than 0 9 whereas r 2 resulting from gev are lower than 0 9 similar results are obtained for rmse values lower rmse values are obtained using gpd and higher values are estimated from gev these results indicate that the gpd distribution fits the summer gsl data better than the gev distribution in the gpd results the 95 percentile for hs is shown table 1 as a suitable threshold value for extreme wave analysis with a better performance for the fitted gpd compared to the gpd results with 97 percentile threshold therefore a gpd approach is applied to determine the 95 percentile as the threshold we choose the ml method to estimate the gpd parameters this methodology is treated as the best fit distribution to estimate the r year return period significant wave heights as shown by the results for summer the gev model is not the best candidate for fitting the distribution for the winter extreme hs when compared to the gpd model because the r 2 values resulting from gev are relatively low and the rmse values are relatively high comparing the statistical analysis obtained from the two thresholds and three methods to estimate the parameters in gpd we find that the 95 percentile threshold and the ml method are the best choice for fitting the distribution for the winter extreme hs the 10 50 and 100 year estimates for extreme values for hs are calculated by using the gpd model with 95 percentile threshold and the ml method for the 30 year time slice these estimates are achieved separately for the present climate represented as 1970 1999 also denoted as historical and for the future climate scenario 2040 2069 fig 10 displays the summer 10 50 and 100 year extreme values for hs in the gsl for 1970 1999 in the present climate the spatial patterns of the 10 50 and 100 year extreme values for hs are similar to each other the most severe extreme waves are located offshore in open ocean waters and decrease in moving to the coastal areas at the center of the gsl the summer 10 50 and 100 year extreme values for hs are around 7 9 m 7 10 m and 7 11 m respectively by comparison in the open ocean the most severe extreme waves are more than 10 m 12 m and 13 m respectively for each return level fig 10 also shows the difference between the future climate scenario and the present climate in the future the patterns of change in 10 50 and 100 year extreme values for hs are similar to each other however with slight exceptions the areas with increased return values of extremes in hs are enlarged from corresponding distributions of the 10 year hs to 100 year hs such as the st lawrence estuary jacques cartier strait and the southwestern part of the gsl in the regions mentioned above projected increases in the return values of extremes in hs fig 10 are consistent with the areas where there are projected increases in maximum hs fig 8 although the former are estimated to cover larger areas than the latter however as shown in fig 10 other regions are projected to decrease in terms of their return values the change amplitude of the decreases in extremes increases gradually in going from the coastal area to the open ocean the maximum amplitudes of the decreases in hs are about 1 5 m 2 m and 2 m for the 10 50 and 100 year extreme values respectively in winter the estimated return values of extreme values of hs are higher than those in summer as shown in fig 11 the distribution of extreme waves in winter is characterized by the gradient decreases in hs from the offshore open ocean waters to the coastal areas the large values of the 10 50 and 100 year extremes in hs in the gsl are approximately 11 m 13 m and 13 m respectively the return values over the st lawrence estuary and the southwestern gsl are around 0 5 m and over the northern gsl 5 7 m like the results in summer the spatial patterns of the corresponding results in winters for 10 50 and 100 year extremes in hs for the middle of the 21st century 2040 2069 are similar to each other however the projected increases in return values are mostly concentrated over the northern gsl with maximum amplitudes that are above 1 m for 10 year extremes in hs and above 2 m for 50 and 100 year extremes in hs these results are consistent with the areas where increases in maximum hs are projected to occur in the future climate scenario moreover decreases in return values are located in the central and rather large portions of the southern gsl with the maximal amplitudes above 0 5 m for the central gsl for 10 year extremes in hs and above 2 m over the gsl west coast area for 50 and 100 year extremes note that this is contrary to the projected maximum hs values for the same region to test the credibility of the return values estimated by gpd we use the gev distribution again fitted by the ml method to obtain the 10 50 and 100 year extreme values in hs for both present and future climates figures not shown in the present climate the return values estimated by the gev distribution have values that are similar to those obtained with the gpd method both in spatial patterns and in the amplitudes of the estimates however the gev estimates for hs in summer are slightly higher for the 50 and 100 year extremes over the waters approaching cabot strait compared to the corresponding estimates from gpd it is also found that gev estimates for hs are higher for the 50 year extreme values in winter over a small area of the central gsl overall the locations of projected increases and decreases in return values estimated by gev are consistent with the gpd results the variable amplitudes of projected return values estimated by gev are similar with those estimated by the gpd therefore the return values of extremes in hs estimated by gpd are credible thus the increases in return values of extremes in hs in gsl shown in figs 10 and 11 are cause for concern in terms of social economic activities like the maintenance of coastal and nearshore infrastructure and related issues 7 discussion and conclusions we have investigated the wave climate including the extreme waves over the gulf of st lawrence by using crcm simulations to provide relatively high resolution winds to drive a modern operational wave model wavewatchiii denoted ww3 by comparing ww3 results with the iowaga wave hindcast we first show that the constructed wave climate for the present period can capture the spatial patterns of mean hs mean 10 highest and the maximum hs well in both summer and winter moreover we show that crcm can reproduce the track density of extratropical cyclones well in the north atlantic in these two seasons moreover the sea ice concentrations over the gsl driven by nemo are simulated well in winter long et al 2015 this provides confidence in model projections of both wave climate changes over the gsl and possible impacts of climate change on the waves under a warmer climate scenario under the sres a1b scenario from ipcc 2007 the ww3 simulations driven by winds from crcm outputs suggest that projected changes in wave climate have seasonal differences in summer the mean hs mean 10 highest hs and the maximum hs are expected to decrease for nearly the entire gsl whereas the associated values for winter are projected to increase over almost the entire gsl these seasonal variations with respect to climate change can be related to particular climate change characteristics such as storms and sea ice properties in the gsl in summer projected decreases in mean hs mean 10 highest hs and the maximum hs are linked to decreases in cyclone track density in the gsl in winter the effects of changes in the cyclone climate on wave climate in gsl in the future change scenario are expected to be small because the cyclone track density is projected to slightly decrease in the gsl these effects are mitigated by competing climate factors namely sea ice the impacts of climate change causing reductions in ice are expected to be an important factor related to increases in the mean hs mean 10 highest and the maximum hs values in the gsl in winter expected reductions in ice allow more open water for waves to be generated and to grow whereas in former decades the gsl was frozen in winter thus changes in sea ice are consistent with increases in the wave climate in terms of the extreme wave analysis for the gsl we show that the gpd distribution provides a better fit for the extreme hs values than the gev distribution in both summer and winter comparing a statistical analysis based on different thresholds 95 and 97 percentile and three methods mps ml and pwm for parameter estimation the 95 percentile threshold and the ml method in gpd are treated as the best choice to fit the distribution of extreme hs values and to estimate the return values the spatial patterns of estimated 10 50 and 100 year extreme values for hs are similar to each other respectively and are characterized by the gradient decreases from the offshore open ocean waters to the coastal areas in summer the return values for hs over the western coastal area of the gsl are around 0 6 m for the 10 year return value for hs and around 0 7 for the 50 and 100 year extreme values return values for the northern gsl area are higher than those for the western coastal area with values between 5 7 m in the central gsl the largest values are relatively high estimated as 9 m 10 m and 11 m for return values in hs under the a1b scenario results obtained from ww3 simulations of waves suggest that the return values of hs will decrease over the eastern part of gsl and increase over small areas of the st lawrence estuary jacques cartier strait and southwestern part of gsl the projected changes in the return values of extremes in hs in these areas are consistent with the associated changes in the maximum hs values over most of the gsl although covering a relatively larger area for the increases in return values of hs in winter the return values over the st lawrence estuary and southwestern portion of the gsl are around 0 5 m and over the northern gsl around 5 9 m in the central gsl for 10 50 and 100 year extreme values in hs the largest values are up to 11 m 11 m and 13 m respectively in the future climate scenario the projected increases in return values are mostly concentrated in the st lawrence estuary the northern part and the southwestern gsl which is consistent with changes in the maximum hs in these regions in this paper a qualitative analysis using a single model simulation is performed to estimate possible future climate change the results are qualitative in that they are similar to what would be obtained using a larger ensemble of simulations however within a large ensemble of simulations uncertainty varies from one member of the ensemble to another and thus the entire ensemble needs to be calculated in order to accurately estimate the uncertainty for a particular given member of the ensemble presently for any given ipcc climate change scenario many climate projection studies are based on multi model ensembles a discussion of the application and development of multi model ensembles for studies of climate change and the variance of results across different members of the ensemble may be found in ipcc 2007 2013 and references therein on average the dominant source of uncertainty in the simulated climate response at middle and high latitudes is internal atmospheric variability which is estimated to account for at least half of the inter model spread in projected climate trends deser et al 2012 in the gulf of st lawrence the uncertainties are generally larger for surface wind speeds than for surface air temperatures sat for example the variance of sat changes is about 0 2 c which is about 10 of the sat increase however the variance for projected changes in surface wind speed is about 0 2 m s which has the same magnitude as the projected changes suggesting significant uncertainty in the projected changes in the surface wind speeds perrie et al 2015 the uncertainties associated with the inter model spread in the projections of the possible future wave height climate will need to be addressed in future studies acknowledgments we thank the panel on energy research and development perd the aquatic climate change adaptations service program accasp the marine environmental observation prediction and response network meopar and the northeast regional association of coastal ocean observing systems neracoos for supporting this work 
24101,the purpose of this study is to investigate possible local changes in the wave climate for the coastal waters off eastern canada particularly in the gulf of st lawrence gsl related to changes in marine winds storm and the sea ice climate due to climate change these analyses are based on application of a dynamical downscaling approach whereby a regional climate model is driven by climate change estimates from the canadian global climate model cgcm3 to provide relatively high resolution winds to drive a wave model the cgcm3 simulation follows the a1b climate change scenario of the special report on emission scenarios from the fourth assessment report ar4 of the intergovernmental panel on climate change ipcc ar4 2007 the analyses of the wave climate are based on simulations of the waves from a third generation wave model wavewatchiii and the downscaled winds obtained from the canadian regional atmospheric climate model crcm we show that the significant wave heights in the gulf of st lawrence hereafter gsl and neighboring coastal waters will slightly increase in the winter and decrease in the summer in response to changes in storms and sea ice in the future climate 2040 2069 compared to the present wave climate represented as 1970 1999 this time period is denoted as the historical wave climate in this study in summer the changes in significant wave heights hs are associated with estimated decreases in the frequency of the occurrence of the cyclones projected changes in return values for summer extremes in the wave climate are consistent with the associated changes in the maximum hs values in winter the projected increases in return values are mostly concentrated in the st lawrence estuary the northern and southwestern gsl consistent with changes in the maximum waves in these regions an important factor related to change in the winter wave climate is change in the sea ice keywords waves climate change storms sea ice extreme value analysis gulf of st lawrence 1 introduction waves are generated by wind very often in association with storms if sea ice is present it will tend to dampen the waves the gsl gulf of st lawrence is a semi enclosed sea adjoining the east coast region of canada it has special climate characteristics because it is partially covered by sea ice in winter and it can be affected by strong storms moving from west to east as well as nor easters moving along the eastern coast of north america from cape hatteras towards newfoundland and onwards to europe and extra tropical hurricanes moving from the southwest towards the northeast along the eastern coast of north america in the gsl the waves can impact society by their potential to damage coastal infrastructure as well as vulnerable near shore and offshore structures marine transport recreational activities and commercial fishing the possible impacts of climate change on waves including effects on sea ice wind and storms have been investigated by several recent studies wang and swail 2006 grabemann and weisse 2008 kharif et al 2008 wang et al 2012 guo et al 2015 ruest et al 2016 changes in storm activity in the north atlantic can affect the winds which are drivers for changes in the climate of the waves e g wang and swail 2006 wolf and woolf 2006 guo et al 2015 sea ice influences the wave climate mainly through dissipation of the wave energy as waves propagate into the ice and by directly modifying the open water fetch distance for wind wave generation and development tolman 2003 thomson et al 2016 shen et al 2018 global warming is expected to result in a reduction in sea ice in the gsl a decrease in extreme winds over large areas of the north atlantic and a poleward shift in storm tracks in the mid latitude north atlantic region as suggested by climate model simulations knippertz et al 2000 fischer bruns et al 2005 yin 2005 bengtsson et al 2006 lorenz and deweaver 2007 mclnnes et al 2011 guo et al 2015 long et al 2015 ruest et al 2016 however gallagher et al 2016 analysed two future climate scenarios rcp4 5 and rcp8 5 and found a mixed picture for the seasonal mean 10 m winds for the north atlantic region suggesting a decrease in future summer winds over eastern canadian coastal areas with negligible changes in estimates for future winter winds in these areas but there are additional factors like sea ice and therefore it is important to estimate the possible impacts to the wave climate of climate change and the role of these related factors several studies have investigated the mean and extreme wave climate in the northwest atlantic and the gsl swail et al 2006 ruest et al 2013 guo and sheng 2015 ruest et al 2016 based on wave simulations swail et al 2006 ocemod1312 xml 382 argument of genfrac has an extra estimated the annual mean and extremes of significant wave heights hs in the gsl for the period 1955 2004 they found that the maximum annual mean wave height the maximum 99 percentile wave heights and the highest percentage of days during a year with hs exceeding 3 m occur mostly in deep offshore waters whereas the hs values in near shore areas are relative low swail et al 2006 used the gumbel extremal distribution to estimate the 100 year return period for wave heights they showed that the 100 year wave height varies from under 6 m in some coastal regions to over 17 m in the deep offshore waters off eastern canada guo and sheng 2015 also estimated the 50 year return period for wave heights using the generalized pareto distribution gpd and demonstrated that the highest values are about 14 m in offshore areas beyond the continental shelf break but decrease in the coastal regions of the grand banks and scotian shelf compared to the results of guo and sheng 2015 the results for the 50 year return period for hs over the southwestern part of the gsl estimated by ruest et al 2013 are relative high possibly because the latter did not consider the winter sea ice in simulating the waves sea ice is projected to be notably reduced in the gsl by the end of the 21th century in response to changes in ice wave heights are expected to increase in this region in projections of the future climate ruest et al 2016 thus the impact of sea ice on the winter wave climate needs to be considered these studies focus on the annual mean and extreme wave statistics in the gsl the climate features related to seasonal mean and seasonal extreme waves in the gsl and discussion of the possible reasons behind these changes have received less investigation although ruest et al 2016 investigated the impact of sea ice cover on extreme waves they focused on a limited region of the northwestern gsl and the st lawrence estuary the impacts of climate change over other areas of this region including the southern gsl around prince edward island and the eastern gsl near newfoundland are still not explored in this study we investigate the impacts of future climate change on seasonal mean and seasonal extreme waves in the gsl winter january february march and summer july august september estimates are projected separately we also present a discussion of possible factors that may lead to these future climate changes this study takes account of the impact of winter sea ice in addition the pot method is used to estimate the 10 50 and 100 year significant wave heights the objective of this study is to investigate the impacts of climate change on the significant wave heights related winds storm and sea ice properties in the gulf of st lawrence and nearby coastal areas of the northwest north atlantic waves are driven by winds which are often generated by storms the impacts of climate change are experienced by storm activity and sea ice in the western north atlantic and thus are exhibited in the wave climate sections 2 and 3 describe the models the data and the relevant methods used in this study section 4 gives validations of the simulations of the storms and significant wave heights in terms of the reanalysis data in section 5 we discuss the impacts of climate change projections on storms sea ice and the significant wave heights analysis of extreme waves is given in section 6 discussion and conclusions are given in section 7 2 models and data 2 1 atmospheric winds in this study we use the canadian regional climate model crcm version 3 7 1 tanguay et al 1990 caya and laprise 1999 for simulations of the winds to drive the wave model the computational domain covers much of the eastern north american continent and the north atlantic crcm solves the fully elastic nonhydrostatic euler equations combining the semi lagrangian semi implicit mesoscale compressible community mcc model dynamical kernel with the atmospheric gcm physics parameterization package from the canadian centre for climate modelling and analysis thus crcm is an important downscaling technique to simulate regional climate for a limited area regional domain in the implementation used here there are 259 169 polar stereographic grid points and a relatively fine horizontal resolution of 45 km at 60 n vertically there are 29 gal chen levels gal chen and somerville 1975 from the ground to 29 km altitude at the top of the model s implementation initial and lateral boundary conditions are taken from outputs of the coupled global climate model cgcm3 t47 which has a horizontal resolution of about 3 75 so that there are two grid points per truncation wavelength around any great circle we use a spectral nudging technique in the crcm to weakly constrain the large scale fields towards the driving fields from cgcm3 t47 following riette and caya 2002 the time step is 15 min details about crcm are given by caya and laprise 1999 laprise et al 2003 caya and biner 2004 and for application in our model domain guo et al 2015 in this paper we simulate a 30 year period from 1970 to 1999 to represent the present climate this time period can be denoted as the historical wave climate initial and lateral boundary conditions for crcm are taken from cgcm3 outputs following the a1b scenario from ipcc 2007 this scenario assumes high economic growth and middle usage of the energy sources with co2 levels reaching 720 ppm by 2100 nakićenović et al 2000 we also simulate a 30 year period from 2040 to 2069 to represent the associated future climate change scenario also driven by cgcm3 outputs for the a1b scenario the sea ice and surface winds at 10 m reference height are interpolated in space to match the wavewatchiii hereafter ww3 wave model grid every 6 hours thus we use the winds to drive ww3 leading to estimates of the wave climate for present climate conditions and also for the future climate scenario 2 2 waves the wave climate for this study is computed by the ww3 wave model version 3 14 the version available at the time of the study which is a third generation spectral model with the st3 physics parameterizations as described by tolman et al 2002 and tolman 2009 and it includes the usual source terms such as energy input by wind wave dissipation non linear wave wave interactions and bottom dissipation parameterizations st3 was the most advanced parameterization package that was available at the time when this project was started later physics formulations like st4 or st6 were not yet available moreover liu et al 2017 have recently compared the performance of st3 st4 and st6 and suggest that within the uncertainty in the wind forcing fields all three formulations perform well in simulations of wave parameters generated by hurricane conditions the model domain is the north atlantic 20 n 65 n 85 w 10 w the wave model grid spacing is 0 5 0 5 and the spectral domain is divided into 29 frequency and 24 directional bins 15 discrete frequency bins range from 0 0418 to 0 6028 hz using an increment factor of 1 10 this domain is nested to a higher resolution domain focusing on the gsl 42 n 55 n 72 w 50 w with wave model grid spacing 0 125 0 125 wave simulations using ww3 are driven by crcm winds from 27 december to 31 march winter season and 27 june to 30 september summer season for each year during 1970 1999 and 2040 2069 allowing the first five days as spin up time for the wave model preliminary wave ice interaction processes were also considered specifically the ic0 source term package thus if the ice concentration is c at any grid point in the marginal ice zone then in the model simulation the spectral wave energy e at this grid point becomes 1 c 100 e default values for c of 25 and 75 were used to denote ice free conditions and conditions where sea ice is treated as land respectively the input fields for sea ice were obtained from the ice ocean simulations using nemo ocean model as described by long et al 2015 although preliminary experimental routines for representation of the boundary effects of ice on waves were implemented in ww3 as provided by tolman 2003 wave scattering due to ice floes was not yet available at the time of this study boundary conditions at the outermost boundary for the model system are assumed to behave like a solid wall nothing comes in and the boundary is like a sponge absorbing all waves crossing to the outside 2 3 sea ice sea ice is important in the study of wave climate and climate change because sea ice reduces the surface winds reducing the momentum exchange between the atmosphere and the ocean validation studies for sea ice were done by long et al 2015 comparing their model simulations with national snow and ice data center nsidc data peng et al 2013 and suggesting that the simulated sea ice cover and ice volume in the gsl are in good agreement with the observations long et al 2015 used the canadian opa canopa model as adapted by brickman and drozdowski 2012 based on the océan parallélisé version 9 model opa 9 0 madec et al 1998 and the louvain la neuve ice model version 2 lim2 fichefet and morales maqueda 1997 bouillon et al 2009 comparisons of sea ice cover from long et al 2015 to nsidc data are shown in fig 1 their simulated sea ice concentrations show seasonal variations whereby the sea ice forms over the shallow waters among the north and west gsl coasts with the maximum sea ice concentrations occurring in the st lawrence estuary and along the saguenay estuary in january eventually almost covering the entire gsl maximum concentrations are reached in february and then start to retreat back to the saguenay estuary in march fig 1 the simulated ice volume in the gsl increases from about 22 km3 in january to 60 km3 in march 2 4 reanalysis data for validation of present wave climate conditions we compared our results with those of the wave hindcast from the iowaga project integrated ocean waves for geophysical and other applications described by rascle and ardhuin 2013 for the northwest atlantic with 10 min spatial resolution this dataset was constructed using ww3 with st4 physics parameterizations which is the state of the art parameterization for generation and dissipation of wind waves ardhuin et al 2010 the dataset includes the period from 1990 to 2012 at the time of this study we use 6 hourly mean sea level pressure mslp fields from the european centre for medium range weather forecasts era interim reanalysis dataset dee et al 2011 as input to the methodology to detect and track cyclones described in section 3 1 era interim is one of the latest available global reanalysis datasets based on a four dimensional data assimilation system the data is available at a high spectral resolution t255 about 79 km for the time period from 1979 to the present strachan et al 2013 have demonstrated that the north atlantic cyclone track density can be reliably extracted from the era interim data 3 methods in this section we introduce three methods needed for investigation of the wave climate and the possible effects of climate change these methods are cyclone detection spatial correlation and extreme value analysis the importance of these methods is 1 detection and tracking of the extratropical cyclones 2 validation of the wave model estimates for wave climate results and 3 prediction of the extreme wave heights for differing intervals such as 10 50 and 100 year time periods 3 1 cyclone detection extratropical cyclones are detected and tracked using the university of melbourne automatic cyclone tracking scheme murray and simmonds 1991a 1991b simmonds and murray 1999 this cyclone tracking scheme is chosen due to its good performance compared to other automated tracking schemes e g raible et al 2008 neu et al al 2013 in this scheme the quasi lagrangian perspective of cyclone behavior was used rather than the eulerian perspective the automatic cyclone tracking scheme identifies possible cyclones based on the 6 hourly maps of the mslp fields by comparing the laplacian of the pressure to the values at 20 neighboring grid points after a possible candidate cyclone is identified the location of the associated pressure minimum is located by using ellipsoidal minimization techniques to determine the cyclones that are meteorologically significant the candidate cyclones are tested using a minimum concavity criterion which requires that the area averaged laplacian exceed 0 5 hpa olatitude 2 for closed depressions or 1 5 hpa olatitude 2 for open depressions over a radius of 2 latitude from the apparent cyclone center after a set of snapshots of potential cyclones is created satisfying the selection conditions described above an algorithm is used to track the individual cyclones in successive 6 hourly maps this approach makes an estimate of the new positon of the each cyclone calculates the probability of associations between the actual and predicted cyclone positions and then estimates the most probable combination for each single physical cyclone thus the storm track density is defined as the number of cyclone tracks passing through a given grid cell here 6 hourly mslp data from regional downscaled crcm model outputs are used to represent the present climate while mslp data from era interim reanalysis are used for validation since spatial resolution of the input data has a strong influence on the number and characteristics of detected cyclones jung et al 2006 both datasets are interpolated to the same polar stereographic grid before making an analysis of cyclones and their tracks we focus on cyclones that last at least 4 time steps on the 6 hourly maps i e 24 h the crcm model grid introduces geographical limits to our study thus cyclones are detected and tracked over the north atlantic 20 n 72 n 120 w 0 75 w 3 2 spatial correlation we adopt statistical metrics to quantitatively evaluate the spatial correlation of the climate variables estimated by models against the observations suppose that x y are simulated and observed data at m grid points in space respectively the spatial correlation c between x and y is defined as 1 c 1 m m 1 m x m x y m y s t d x s t d y where x and y are the mean of x and y over the m grid points and std is the spatial standard deviation the spatial standard deviation of x is defined as 2 s t d x 1 m m 1 m x m x 2 3 3 extreme value analysis in extreme value analysis two statistical approaches are commonly used to obtain the r year return period significant wave height menéndez et al 2009 teena et al 2012 ruest et al al 2013 these are the annual maxima am method and the peaks over threshold pot method 3 3 1 am method in the am method the maximum values in each year are extracted to construct the dataset that is used for the extreme value analysis the distribution of the maximum values can be represented approximately by a generalized extreme value distribution gev coles 2001 whose cumulative distribution function is 3 g z exp 1 ɛ z μ σ 1 ɛ f o r ɛ 0 exp exp z μ σ f o r ɛ 0 where μ σ ε are the location scale and shape parameters respectively the shape parameter can determine the type of distribution depending on the value of the shape parameter ε the gev distribution has three possible distribution families 1 gumbel distribution with ε 0 2 fréchet distribution with ε 0 and 3 weibull distribution with ε 0 in this paper the parameters are estimated by the maximum likelihood ml method and comparisons are made with the probability weighted moments pwm method in order to fit a candidate distribution function to a given sample the coefficient of determination r 2 and root mean square error rmse are used to identify the best fit distribution in this approach the return value zr for the r year significant wave height is the value exceeded once every r years on the average this is obtained by finding the inverse of the function of the cumulative distribution following goda 2010 4 z r g 1 1 1 r where r is the return period associated with the return value here r is defined as 5 r 1 1 g z and therefore the return value obtained by eqs 1 and 2 is expressed as follows 6 z r μ σ ɛ 1 log 1 1 r ɛ f o r ɛ 0 μ σ log log 1 1 r f o r ɛ 0 3 3 2 pot method alternately another method that can also be used for extreme wave analysis is the pot method which considers the peaks exceeding a pre set threshold in the pot method the distribution of the threshold excesses is assumed to follow a generalized pareto distribution gpd following coles 2001 in this approach z is the cluster maxima of the significant wave heights given a threshold u the cumulative distribution function of gpd can be expressed as 7 g z 1 1 ɛ z u σ 1 ɛ f o r ɛ 0 1 exp z u σ f o r ɛ 0 where σ represents the scale parameter and ε is the shape parameter like the gev method the shape parameter determines the type of the distribution when ε 0 the gpd reduces to an exponential distribution when ε 0 the gpd distribution becomes the pareto distribution finally when ε 0 the gpd distribution becomes the beta distribution the threshold selection methodology is necessary in the gpd method because the high threshold value reduces the bias but increases the uncertainties of the parameter estimation whereas the low threshold gives the opposite result a sensitivity analysis on threshold selection was performed by ruest et al 2013 in application of the pot method in the gulf of st lawrence gsl their results show that estimates of the return values are not sensitive to the choice of the threshold from 90 to 99 percentile therefore we choose 95 and 97 percentile for significant wave heights as the two threshold values after the threshold has been fixed the time length between consecutive exceedances of the threshold is set in order to get independent extreme events here we select a minimum of 48 h as the separation time following caries and sterl 2005 and teena et al 2012 besides the ml and pwm method the maximum product of spacings mps method is also used for parameter estimation when fitting the gpd therefore the return value zr of the r year significant wave height corresponding to the pot method is 8 z r u σ r n ξ u ɛ 1 ɛ f o r ɛ 0 u σ log r n ξ u f o r ɛ 0 an estimation of the return value zr is obtained by solving ξ u 1 ɛ z r u σ 1 ɛ 1 r n for ε 0and ξ u exp z u σ 1 r n for ε 0 where n is the number of observations per year and ξ u is the probability that an individual observation exceeds the threshold which can be estimated as 9 ξ u λ n here it is assumed that the number of exceedances is approximately poisson distributed with respect to the parameter λ 4 model validation as noted in section 2 1 to represent the present climate we simulate a 30 year period from 1970 to 1999 which can also be denoted as the historical wave climate in this paper however in this section the simulation is extended to a 43 year period from 1970 to 2012 in order to allow validation with iowaga reanalysis wave climate data which is only available from 1990 validation is carried out with respect to storms and significant wave heights to evaluate the performance of crcm and ww3 driven by crcm winds 4 1 storms in summer the cyclone track density derived from era interim data suggests that the high frequency region for cyclone development appears over the middle and high latitudes north to 45 n with a maximum density over the open water area directly southeast of greenland fig 2 a by comparison the crcm model can capture the overall spatial pattern of track density shown in the era interim reanalysis data although the former overestimates the cyclone frequencies south of the tip jet of greenland fig 2b the locations of maximum cyclone density are simulated well in the crcm simulations however crcm overestimates the cyclone activity in the gsl compared to the estimates from era interim data a similar comparison for the winter season is shown in fig 2c and d for the era interim data there are slightly more cyclones over the northeastern north atlantic and in the gsl than the results in summer fig 2a and c the maximum cyclone frequencies are mainly located in the open water areas on the east side of greenland overall the estimated cyclone track density for winter seasonal mean crcm simulations fig 2d are in agreement with era interim results in locations of maximums magnitudes and spatial patterns of track density for the gsl the overestimates from crcm simulations are found in winter similar results are found by the methodology of guo et al 2015 which is based on minimum mslp rather than mslp gradients used here 4 2 waves the simulated summer means for the mean 10 highest maximum and mean significant wave heights for the 1990 2012 period from ww3 driven by crcm winds are compared with the iowaga wave hindcast data in fig 3 in general results from ww3 as driven by crcm winds and wave data from the iowaga simulations show similar spatial patterns values for mean 10 highest maximum and mean wave heights are generally decreasing with a gradient from the deep water areas to the shallow water areas in the summer the simulated mean significant wave heights ww3 driven by crcm winds are around 0 5 1 3 m in the gsl while the simulated mean of 10 highest and maximum wave heights are around 2 3 6 m and 3 6 6 m respectively compared to iowaga ww3 driven by crcm winds produces higher values for the mean 10 highest waves as well as the maximum wave heights and reasonable comparisons for mean values based on the pattern correlation coefficient c and root mean square error rmse shown in each panel ww3 driven by crcm winds is able to capture the magnitude of the wave heights well especially the mean values as well as the spatial patterns correlation coefficients are in excess of 0 9 in winter our simulated ww3 results for mean 10 highest maximum and significant wave climate exhibit similar spatial patterns as those found in summer although the values are relatively higher as presented in fig 4 the simulated mean significant wave heights are around 1 3 5 m in the gsl and the wave heights for winter mean of the mean 10 highest and maximum are around 2 7 m and 3 10 m respectively ww3 driven by crcm winds overestimates the mean 10 highest the maximum and mean wave heights compared to the iowaga simulations but consistently captures the spatial patterns well with spatial correlations higher than 0 96 as illustrated from the rmse values in each panel the values of mean 10 highest and maximum wave heights estimated by ww3 have larger differences than those of mean wave heights when compared with results from iowaga simulations 5 climate change impacts 5 1 storms in this section we focus on summer and winter seasons the differences in cyclone track density between the future climate scenario considered in this study and the historical simulations for these two seasons are shown in fig 5 in summer for the future climate change scenario a significant increase in cyclone track density is projected to occur off the coasts of greenland and iceland with an apparent decrease in the labrador sea in the gsl and over the northeast atlantic and extending to western europe fig 5a the projected poleward shift in the summer cyclone track density and the estimated decrease in cyclones in the gsl are in agreement with the estimates based on the echam5 coupled climate model by bengtsson et al 2006 in winter the crcm simulations suggest that the cyclone track density decreases in the areas off greenland and iceland as well as in the gsl region with slight increases in track density off the coast of newfoundland fig 5b 5 2 sea ice ruest et al 2016 study the influence of sea ice on significant wave heights their results show that extreme values for hs in the gsl during 1981 2010 are reduced by about 12 through the effects of sea ice therefore extreme values for hs are expected to increase in the late 21th century due to the reduction in sea ice however the area of their interest was limited to the northwestern part of the gsl only considering the sea ice formation and melt processes during the winter shown in fig 1 we investigate possible future changes in sea ice concentration over the gsl for each month of the winter season for the a1b climate scenario during 2040 2069 relative to the present climate period 1970 1999 fig 6 in the a1b climate scenario the area covered by ice becomes smaller in each winter month compared to the present climate march is notable because the gsl is estimated to be virtually ice free in the future climate scenario a prominent feature in ice changes is that there is a slight decrease in ice over the shallow waters adjoining the coast in january and a significant decrease over nearly the entire gsl in both february and march the reduction in gsl sea ice is also suggested by the time series in fig 7 showing the changes in sea ice cover and ice volume from the present to the future climate scenario declining trends for sea ice cover area are apparent particularly after the late 2020s in each month the decrease in sea ice cover area is approximately 80 in the 2060s compared to the 1970s for each month the area covered with ice in january is smaller than the areas estimated for february and march for the entire time period the estimated mean ice volume shows similar steady decreases as with reductions in ice cover in the gsl the most remarkable decreases are estimated to occur after the late 2020s in all three months the seasonal maximum ice volume changes from around 100 km3 during the 1970s to about 25 km3 during the 2060s 5 3 waves for summer conditions the projected changes in mean hs maximum and mean of top 10 hs for 2040 2069 relative to the present climate 1970 1999 are shown in fig 8 overall the decrease of mean maximum and mean top 10 wave heights over areas of the gsl follow the projected poleward shift of the summer cyclone track density mentioned in the previous section therefore a decrease in cyclone activity in the gsl should be expected to contribute to decreases in the estimated mean hs maximum and mean top 10 hs in the summer seasons of the future climate scenario however there are a few small areas where waves are estimated to increase in the future climate relatively weak increases in maximum hs are estimated to occur for small areas of jacques cartier strait the st lawrence estuary and the southern gsl reflecting the related changes in the winds and cyclone tracks for winter conditions the changes in mean hs for each winter month are different we show the changes in mean hs for each month for the period 2040 2069 minus present climate conditions 1970 1999 in fig 9 this figure also shows the projected changes in maximum and mean of 10 highest hs it can be seen that in each month the changes in mean hs share similar spatial patterns as those of the mean of 10 highest hs and maximum hs in the gsl the projected changes in january are different from those of february and march in january there are slight increases in mean hs maximum and mean of top 10 hs over the st lawrence estuary the northeast gsl and waters leading to the belle isle strait and to a lesser extent the western gsl by comparison in february and march the significant increases in these variables are suggested to occur over the entire gsl for the wave climate in winter the two dominating factors are the impacts of climate change on cyclones and their tracks and on sea ice in winter the cyclone track density is projected to decrease in the gsl generally less cyclone activity implies decreased estimates for hs in the climate change scenario however this seems not to be the dominant process in our study on the contrary fig 1 suggests that the sea ice experiences changes in the formation and melt processes from january to march relative to the present climate these changes are progressive and significantly affect the associated wave climate at each phase of the seasonal cycle because wave ice interactions affect the attenuation of the wave climate section 2 2 and the spatial distribution of sea ice concentration in the gsl is different in each month moreover in the climate change scenario changes in sea ice are also different month by month fig 6 to address the role that sea ice plays in wave climate in winter we have presented the changes in the wave climate month by month compositely the seasonal mean hs of maximum and of mean 10 highest hs are projected to increase in the gsl therefore the influence of climate change on the cyclones and thus on the winter wave climate is mitigated by changes in sea ice here we consider the influence of ice on the gsl wave climate by comparing the change patterns for waves and sea ice comparing figs 6 and 9 it is apparently that the changes in mean hs mean 10 highest and maximum hs are consistent with changes in sea ice for each winter month in the gsl therefore reductions in sea ice are a determining factor that results in increased waves in the future climate scenario as shown in mean maximum and mean top 10 waves estimates in the gsl 6 extreme wave analysis in performing an extreme value analysis variations in the steps used in the methodology can lead to differing results considerations include the choice of the extreme value distributions gev family or gpd family the threshold selection for gpd 95 or 97 quantile and the choice of methods to estimate the parameter to fit a candidate distribution mps ml or pwm in this study we considered several combinations mentioned above and we adopted the r 2 coefficient of determination and root mean square error rmse to estimate differing distributions with respect to the model data see table 1 r 2 is a measure of how well a given distribution can fit the data the values of r 2 range from 0 to 1 where higher values indicate better fits in contrast rmse is used to measure the differences between values estimated by the differing distributions and the values of the original data lower values of rmse indicate better fits to the data we note that estimates of the return value have been shown to not be sensitive to the choice of the threshold from 90 to 99 percentile by ruest et al 2013 there can be large differences between statistical results obtained by using the gev model or the gpd model in the gsl in summer as illustrated in table 1 the values of r 2 resulting from gpd are all larger than 0 9 whereas r 2 resulting from gev are lower than 0 9 similar results are obtained for rmse values lower rmse values are obtained using gpd and higher values are estimated from gev these results indicate that the gpd distribution fits the summer gsl data better than the gev distribution in the gpd results the 95 percentile for hs is shown table 1 as a suitable threshold value for extreme wave analysis with a better performance for the fitted gpd compared to the gpd results with 97 percentile threshold therefore a gpd approach is applied to determine the 95 percentile as the threshold we choose the ml method to estimate the gpd parameters this methodology is treated as the best fit distribution to estimate the r year return period significant wave heights as shown by the results for summer the gev model is not the best candidate for fitting the distribution for the winter extreme hs when compared to the gpd model because the r 2 values resulting from gev are relatively low and the rmse values are relatively high comparing the statistical analysis obtained from the two thresholds and three methods to estimate the parameters in gpd we find that the 95 percentile threshold and the ml method are the best choice for fitting the distribution for the winter extreme hs the 10 50 and 100 year estimates for extreme values for hs are calculated by using the gpd model with 95 percentile threshold and the ml method for the 30 year time slice these estimates are achieved separately for the present climate represented as 1970 1999 also denoted as historical and for the future climate scenario 2040 2069 fig 10 displays the summer 10 50 and 100 year extreme values for hs in the gsl for 1970 1999 in the present climate the spatial patterns of the 10 50 and 100 year extreme values for hs are similar to each other the most severe extreme waves are located offshore in open ocean waters and decrease in moving to the coastal areas at the center of the gsl the summer 10 50 and 100 year extreme values for hs are around 7 9 m 7 10 m and 7 11 m respectively by comparison in the open ocean the most severe extreme waves are more than 10 m 12 m and 13 m respectively for each return level fig 10 also shows the difference between the future climate scenario and the present climate in the future the patterns of change in 10 50 and 100 year extreme values for hs are similar to each other however with slight exceptions the areas with increased return values of extremes in hs are enlarged from corresponding distributions of the 10 year hs to 100 year hs such as the st lawrence estuary jacques cartier strait and the southwestern part of the gsl in the regions mentioned above projected increases in the return values of extremes in hs fig 10 are consistent with the areas where there are projected increases in maximum hs fig 8 although the former are estimated to cover larger areas than the latter however as shown in fig 10 other regions are projected to decrease in terms of their return values the change amplitude of the decreases in extremes increases gradually in going from the coastal area to the open ocean the maximum amplitudes of the decreases in hs are about 1 5 m 2 m and 2 m for the 10 50 and 100 year extreme values respectively in winter the estimated return values of extreme values of hs are higher than those in summer as shown in fig 11 the distribution of extreme waves in winter is characterized by the gradient decreases in hs from the offshore open ocean waters to the coastal areas the large values of the 10 50 and 100 year extremes in hs in the gsl are approximately 11 m 13 m and 13 m respectively the return values over the st lawrence estuary and the southwestern gsl are around 0 5 m and over the northern gsl 5 7 m like the results in summer the spatial patterns of the corresponding results in winters for 10 50 and 100 year extremes in hs for the middle of the 21st century 2040 2069 are similar to each other however the projected increases in return values are mostly concentrated over the northern gsl with maximum amplitudes that are above 1 m for 10 year extremes in hs and above 2 m for 50 and 100 year extremes in hs these results are consistent with the areas where increases in maximum hs are projected to occur in the future climate scenario moreover decreases in return values are located in the central and rather large portions of the southern gsl with the maximal amplitudes above 0 5 m for the central gsl for 10 year extremes in hs and above 2 m over the gsl west coast area for 50 and 100 year extremes note that this is contrary to the projected maximum hs values for the same region to test the credibility of the return values estimated by gpd we use the gev distribution again fitted by the ml method to obtain the 10 50 and 100 year extreme values in hs for both present and future climates figures not shown in the present climate the return values estimated by the gev distribution have values that are similar to those obtained with the gpd method both in spatial patterns and in the amplitudes of the estimates however the gev estimates for hs in summer are slightly higher for the 50 and 100 year extremes over the waters approaching cabot strait compared to the corresponding estimates from gpd it is also found that gev estimates for hs are higher for the 50 year extreme values in winter over a small area of the central gsl overall the locations of projected increases and decreases in return values estimated by gev are consistent with the gpd results the variable amplitudes of projected return values estimated by gev are similar with those estimated by the gpd therefore the return values of extremes in hs estimated by gpd are credible thus the increases in return values of extremes in hs in gsl shown in figs 10 and 11 are cause for concern in terms of social economic activities like the maintenance of coastal and nearshore infrastructure and related issues 7 discussion and conclusions we have investigated the wave climate including the extreme waves over the gulf of st lawrence by using crcm simulations to provide relatively high resolution winds to drive a modern operational wave model wavewatchiii denoted ww3 by comparing ww3 results with the iowaga wave hindcast we first show that the constructed wave climate for the present period can capture the spatial patterns of mean hs mean 10 highest and the maximum hs well in both summer and winter moreover we show that crcm can reproduce the track density of extratropical cyclones well in the north atlantic in these two seasons moreover the sea ice concentrations over the gsl driven by nemo are simulated well in winter long et al 2015 this provides confidence in model projections of both wave climate changes over the gsl and possible impacts of climate change on the waves under a warmer climate scenario under the sres a1b scenario from ipcc 2007 the ww3 simulations driven by winds from crcm outputs suggest that projected changes in wave climate have seasonal differences in summer the mean hs mean 10 highest hs and the maximum hs are expected to decrease for nearly the entire gsl whereas the associated values for winter are projected to increase over almost the entire gsl these seasonal variations with respect to climate change can be related to particular climate change characteristics such as storms and sea ice properties in the gsl in summer projected decreases in mean hs mean 10 highest hs and the maximum hs are linked to decreases in cyclone track density in the gsl in winter the effects of changes in the cyclone climate on wave climate in gsl in the future change scenario are expected to be small because the cyclone track density is projected to slightly decrease in the gsl these effects are mitigated by competing climate factors namely sea ice the impacts of climate change causing reductions in ice are expected to be an important factor related to increases in the mean hs mean 10 highest and the maximum hs values in the gsl in winter expected reductions in ice allow more open water for waves to be generated and to grow whereas in former decades the gsl was frozen in winter thus changes in sea ice are consistent with increases in the wave climate in terms of the extreme wave analysis for the gsl we show that the gpd distribution provides a better fit for the extreme hs values than the gev distribution in both summer and winter comparing a statistical analysis based on different thresholds 95 and 97 percentile and three methods mps ml and pwm for parameter estimation the 95 percentile threshold and the ml method in gpd are treated as the best choice to fit the distribution of extreme hs values and to estimate the return values the spatial patterns of estimated 10 50 and 100 year extreme values for hs are similar to each other respectively and are characterized by the gradient decreases from the offshore open ocean waters to the coastal areas in summer the return values for hs over the western coastal area of the gsl are around 0 6 m for the 10 year return value for hs and around 0 7 for the 50 and 100 year extreme values return values for the northern gsl area are higher than those for the western coastal area with values between 5 7 m in the central gsl the largest values are relatively high estimated as 9 m 10 m and 11 m for return values in hs under the a1b scenario results obtained from ww3 simulations of waves suggest that the return values of hs will decrease over the eastern part of gsl and increase over small areas of the st lawrence estuary jacques cartier strait and southwestern part of gsl the projected changes in the return values of extremes in hs in these areas are consistent with the associated changes in the maximum hs values over most of the gsl although covering a relatively larger area for the increases in return values of hs in winter the return values over the st lawrence estuary and southwestern portion of the gsl are around 0 5 m and over the northern gsl around 5 9 m in the central gsl for 10 50 and 100 year extreme values in hs the largest values are up to 11 m 11 m and 13 m respectively in the future climate scenario the projected increases in return values are mostly concentrated in the st lawrence estuary the northern part and the southwestern gsl which is consistent with changes in the maximum hs in these regions in this paper a qualitative analysis using a single model simulation is performed to estimate possible future climate change the results are qualitative in that they are similar to what would be obtained using a larger ensemble of simulations however within a large ensemble of simulations uncertainty varies from one member of the ensemble to another and thus the entire ensemble needs to be calculated in order to accurately estimate the uncertainty for a particular given member of the ensemble presently for any given ipcc climate change scenario many climate projection studies are based on multi model ensembles a discussion of the application and development of multi model ensembles for studies of climate change and the variance of results across different members of the ensemble may be found in ipcc 2007 2013 and references therein on average the dominant source of uncertainty in the simulated climate response at middle and high latitudes is internal atmospheric variability which is estimated to account for at least half of the inter model spread in projected climate trends deser et al 2012 in the gulf of st lawrence the uncertainties are generally larger for surface wind speeds than for surface air temperatures sat for example the variance of sat changes is about 0 2 c which is about 10 of the sat increase however the variance for projected changes in surface wind speed is about 0 2 m s which has the same magnitude as the projected changes suggesting significant uncertainty in the projected changes in the surface wind speeds perrie et al 2015 the uncertainties associated with the inter model spread in the projections of the possible future wave height climate will need to be addressed in future studies acknowledgments we thank the panel on energy research and development perd the aquatic climate change adaptations service program accasp the marine environmental observation prediction and response network meopar and the northeast regional association of coastal ocean observing systems neracoos for supporting this work 
24102,the wave action equation is a widely used governing equation in wave forecasting models whilst it accounts for wave propagation its analytical derivation neglects various other effects such as the sea bottom reflection the present work derives an analytical source term for the bottom reflection of oblique incident waves to be used in numerical forecasting models this is done by means of a coupled oblique parabolic approximation of the mild slope equation which is then decoupled by introducing a perturbation solution the resulting first two orders produce the wave action equation itself for an on going wave in the first order and a wave action equation with a reflection source term in the second order for the reflected wave a method to implement this source term in two dimensional wave action forecasting models is discussed numerical simulations show this new source term to be in excellent agreement with the mild slope equation for different slopes wave periods and attack angles keywords wind waves wave action equation bottom reflection mild slope equation 1 introduction the wave action equation wae is one of the most commonly used governing equation in today s numerical sea and ocean wave forecasting models it is based on bretherton and garrett 1968 where it was developed as a transport equation of a conserved quantity describing the propagation of slowly varying wavetrains of small amplitude numerical models use the wae with the addition of source terms which represent the effects on water waves neglected by the wae these source terms are grouped in a semi arbitrary manner to account for different effects of ocean wave propagation such as dissipation wave breaking wind input non linear wave interactions and bottom interactions a commonly unresolved component of the bottom interactions source term is the wave reflection from the sea bottom as a wave shoals over a sloping sea bottom some of its energy is reflected from the seabed and creates a reflected wave in the opposite direction this mainly happens in shallow water where the bottom effects waves the most the bottom reflection is expected to be stronger near islands bays channels and ports with sloping sea floor and can increase wave amplitude as much as 20 in extreme cases and 5 10 for more common cases as seen in tatavarti et al 1988 mahony and pritchard 1980 elgar et al 1994 the approach used nowadays for calculating the wave reflection in wae based models was pioneered by miche 1951 where a semi empirical reflection term r was derived for monochromatic waves shoaling towards a sloped shore this reflection term was tested by elgar et al 1994 and later approximated more accurately by ardhuin and roland 2012 as 1 r 0 2 0 007 log 10 m i 4 5 0 15 m i m i 16 t a n 5 β 2 π 5 h 2 f 4 where r 0 2 is the energy reflection term for specific mi miche number β is the bottom slope h is the deep water wave height and f is the wave frequency this term was used to produce a reflection source term which is currently used by several wave forecasting models a different approach for calculating wave reflection was shown by mei et al 2005 this approach manipulates the mild slope equation mse a three dimensional laplace equation simplified by an integration over the depth with a predefined vertical profile and was originally developed in the works of biesel 1952 eckart 1952 svendsen 1967 berkhoff 1972 the mse was further simplified into the shallow water equation which assumes large wave lengths compared to the water depth using a wkb perturbation method mei et al 2005 chapter 4 5 derives the new term for the bottom reflection 2 r 1 d d x ln k h e 2 i k x d x d x where r 1 is the reflection term k is the wave number h is the water depth and x is the lateral coordinate this term was shown to be strongly influenced by the smoothness of the start and end points of the sloping bottom and was limited to a wave coming straight towards the beach in shallow water conditions mei s new term was not further studied or used another form of bottom reflection source term was derived in ardhuin and herbers 2002 magne et al 2005 where the bottom topography was described through a discrete fourier transform this source term accounts for bottom reflection due to class i bragg scattering and is currently used to describe sub grid bottom ripples it may have the potential to account for bottom reflection in larger scale though it will require a methodology of transforming a varying 2d bathymetry to a varying localized fourier representation the present work aims to derive a new analytical term for wave reflection caused by an incident wave with a general attack angle improving former models which are limited to direct incident waves such an analytical bottom reflection source term will be applicable to 2d spectral models and will result in a more accurate near shore environment wave prediction in large scale models the new analytical source term is derived through a parabolic approximation of the mild slope equation which defines a coupled oblique parabolic equations set ope as shown by radder 1979 liu and tsay 1983 toledo 2013 a perturbation method is applied to these ope in such a way that the shore ward incident wave and the sea ward reflected wave are decoupled finally a wave action form is derived for the new reflected wave equation and the source term to be used in numerical simulations is formulated the paper is structured as follows in section 2 the linear mild slope equation is introduced and transformed into a coupled linear ope in section 3 a perturbation method is applied to the ope in a way that decouples the incident shore ward wave and the reflected sea ward reflection in section 4 the reflected ope is transformed into a wae form and the reflection source term is constructed numerical simulations are presented in section 5 and the work is summarized and discussed in section 6 2 the coupled linear oblique parabolic equation model the linear 2d mild slope equation see berkhoff 1972 is given by 3 c c g ϕ k 2 c c g ϕ 0 where ϕ is the velocity potential on the undisturbed water surface z 0 is the horizontal gradient operator c is the phase velocity and cg is the group velocity k is the wave number which can be calculated using the dispersion relation 4 ω 2 g k tanh k h as a function of the angular frequency ω gravitational acceleration g and the water depth h x y using a scaling factor ccg 1 2 so that 5 ϕ c c g 1 2 ϕ the liouville transform is applied see e g radder 1979 dingemans 1997 toledo 2013 and the mild slope equation is written in the form of a linear helmholtz equation as follows 6 2 ϕ k c 2 ϕ 0 the effective wave number is defined by 7 k c 2 k 2 c c g 1 2 2 c c g 1 2 in order to apply a parabolic approximation to eq 6 a splitting method is used as in radder 1979 liu and tsay 1983 and toledo 2013 first the wave field is separated into two wave fields 8 ϕ ϕ ϕ where ϕ describes the wave propagating in the positive x direction and ϕ the negative x direction the linear coupled ope are derived similarly to toledo 2013 eq 3 13 without neglecting the reflected field 9 ϕ x 1 2 k 1 i k c 2 k 1 2 k 1 x i 2 y 2 ϕ 1 2 k 1 i k c 2 k 1 2 k 1 x i 2 y 2 ϕ where k 1 and k 2 are the x direction and y direction wave numbers respectively defined by 10 k 2 k 1 2 k 2 2 eq 9 describes a coupled linear ope model for waves where the lhs coincides with the linear part of toledo 2013 and the rhs acts as coupling term between the waves propagating in the positive x direction to the negative one and vice versa 3 a perturbation approximation for the coupled system up to this point the method of radder 1979 liu and tsay 1983 and toledo 2013 was followed closely here a perturbation method is used to decouple the incident and the reflected wave fields in order to simplify eq 9 a quasi 2d wave model is adopted this is done by defining the x axis in the direction of the gradient of the slope and y axis orthogonal to it assuming no change in the y direction the velocity potential can be described as 11 ϕ x y ϕ x e i k 2 y and the quasi 2d coupled model is derived as 12 ϕ x i k 1 1 2 k 1 k 1 x ϕ 1 2 k 1 k 1 x ϕ next a non dimensional model was derived using the non dimensional properties 13 ϕ ϕ h i g ω ϕ ϕ h r g ω 14 k 1 k 1 k 01 x x k 01 15 κ r h r h i where hi and hr are the incident and reflected wave heights respectively k 01 is the deep water wave number in the x direction and κ r is the reflection coefficient substituting eqs 13 15 into eq 12 results with 16 ϕ x i k 1 1 2 k 1 k 1 x ϕ κ r 1 2 k 1 k 1 x ϕ from a physical perspective the reflected wave is of a smaller order than the propagating wave causing it see e g liu and tsay 1983 thus it was neglected in other works see e g liu and mei 1976 radder 1979 toledo 2013 this is plausible in a mild slope bathymetry and without bragg resonance which is often the case this assumption corresponds to a small reflection coefficients κ r κ r 1 subsequently both expressions ϕ were expanded into 17 ϕ ϕ 0 κ r ϕ 1 18 ϕ κ r ϕ 1 assuming the incident wave is propagating only in the positive x direction this can be justified without loss of generality as the incident wave can be derived in any direction by changing the attack angle and the linear nature of the problem allows superposition comparing expressions of magnitudes o κ r 0 and o κ r 1 in eq 16 18 yields 19 ϕ 0 x i k 1 ϕ 0 1 2 k 1 k 1 x ϕ 0 0 20 ϕ 1 x i k 1 ϕ 1 1 2 k 1 k 1 x ϕ 1 1 2 k 1 k 1 x ϕ 0 which are the leading order and the first order approximations of the quasi 2d model in eq 16 it was assumed that ϕ 1 0 as the first order correction in eq 19 is identical to the zero order and thus no additional energy is entered using wave elevation instead of velocity potential will allow for an easier transformation into a wave action form the wave elevation above the undisturbed surface water level η is given by 21 ϕ x c c g 1 2 g i ω η x applying eqs 13 14 and 21 to eqs 19 and 20 results in 22 x c c g η i k 1 1 2 k 1 k 1 x c c g η 0 0 23 x c c g η 1 i k 1 1 2 k 1 k 1 x c c g η 1 1 2 k 1 k 1 x c c g η 0 eq 22 represents an oblique wave propagating in the x direction and is similar to the linear eq 3 15 in toledo 2013 eq 23 represents the first order correction to the negative x direction induced by the propagating incident wave in the positive x direction 4 derivation of the reflection source term for wave action equation models numerical forecasting models use the wae as a governing equation as it is invariant along a wave ray even in the presence of a mean current the wave action is defined as 24 a e ω 1 2 ρ g η 2 ω where e is the wave energy and ρ is the water density the wave elevation was defined as 25 η η e i ψ where exponential part accounts the oscillatory part of the wave elevation with phase function ψ and η is a complex wave elevation allowing for phase shift applying eqs 24 and 25 to eq 22 results in the zero order wave action solution see kirby 1984 26 x k 1 k c g a 0 where the eikonal equation of the zero order imaginary part gives the phase function 27 ψ x 0 x k 1 d x ω t in a similar manner the wave action form of eq 23 should yield the source term of the reflected wave in order to do so eqs 25 and 27 were applied to eq 23 giving 28 2 k 1 x c c g η 1 k 1 x c c g η 1 k 1 x c c g η 0 e 2 i k 1 d x dividing by k 1 eq 28 can be reduced to 29 x k 1 c c g η 1 2 k 1 c c g η 1 2 k 1 x c c g k 1 η 0 e 2 i k 1 d x and its integration yields 30 2 k 1 c c g η 1 2 x 0 x k 1 x c c g k 1 η 0 e 2 i k 1 d x d x taking the x derivative of the square of eq 30 gives 31 x k 1 c c g η 1 2 k 1 x c c g η 0 e 2 i k 1 d x k 1 x 0 x k 1 x c c g η 0 e 2 i k 1 d x 2 k 1 d x after this manipulation the rhs of eq 31 depends solely on the zero order elevation nevertheless it is difficult in its application to wae models as it is non local this can be resolved by applying a similar localization procedure as was done in stiassnie and drimer 2006 toledo and agnon 2012 and vrecica and toledo 2016 for localizing nonlinear triad interactions coefficients the integral in eq 31 can be written as 32 x 0 x k 1 x c c g η 0 2 k 1 e 2 i k 1 d x d x 0 ζ x ζ c c g η 0 2 ζ ζ e 2 i ζ d ζ where 33 ζ x x 0 x k 1 d x ζ x ζ x k 1 ζ x k 1 x solving eq 32 using the integration by parts method yields 34 0 ζ x ζ c c g η 0 2 ζ ζ e 2 i ζ d ζ i ζ c c g η 0 4 ζ ζ e 2 i ζ 0 ζ x i x ζ c c g η 0 2 ζ ζ e 2 i ζ 2 d ζ the second term on the rhs of eq 34 is assumed to be of a smaller order than the first term see toledo and agnon 2012 and can be neglected using this result in eq 31 gives 35 x k 1 c c g η 1 2 i k 1 x 2 k 1 2 c c g η 0 2 e 4 i k 1 d x noting that 36 k 1 c k 1 k ω the quasi 2d wae reflection was derived using the absolute values of both sides of the equation as wave action is relative to the amplitude of the wave elevation this is possible as η 2 η 2 and results with 37 x k 1 k c g a i k 1 x 2 k 1 2 c g a k e 4 i k 1 d x eq 37 is the main result of this paper its rhs is the analytical bottom reflection source term which is applicable to wae based forecasting models the new source term was developed using a quasi 2d model but can be applied to a general 2d numerical model this can be done by assuming that the local bathymetry is changing significantly only in single direction and the lateral bottom changes are negligible following this assumption the coordinate ξ is defined in the direction of the slope for each grid element this creates a local quasi 2d solution where the reflection source term is given by 38 s r e f i k ξ ξ 2 k ξ 2 c g a k e 4 i k ξ d ξ 5 numerical simulations numerical simulations of various wave reflection coefficients are presented in this section the mse was defined as eq 3 with the assumption of a quasi 2d wave propagation as defined by eq 11 the wae was defined as eq 26 and the new bottom reflection source term brs was calculated in the same way with the addition of eq 37 mei s analytical reflection coefficient mrc was simulated using eq 2 and the empirical correction to miche s number arr was defined as eq 1 the equations were solved in wolfram mathematica 10 software the mse and brs were solved using the ndsolve function with the bdf method the mrc was solved using the integrate function and the arr was solved directly the numerical simulations were performed over a sloping bottom with plateaus at both ends one in deep water kh 3 and one in shallow water k h 0 2 as seen in fig 1 a the slope lengths varied to accommodate these conditions the boundary conditions used were 1 a known incident wave at x 0 moving in the positive x direction 2 no reflection past the bottom slope the reflection was measured over the flat area in the deep sea the reflection coefficient is defined by eq 15 as the reflected wave amplitude normalized with the incident wave causing it the properties examined in the simulations are the wave period t the bottom slope β and the wave attack angle towards the x axis θ in fig 1a the mse curve shows the elevation of the partial standing wave created by the incident and reflected waves as a function of x l 0 where l 0 is the deep water wavelength the wae curve shows only the forward propagating wave which corresponds to the mean value of the undulating mse the brs added and subtracted from the wae fits an envelope around the mse curve which corresponds to the maximal and minimal elevations of the mse in the case of a linear monochromatic problem different initial phases of the deterministic mse do not change the reflected and transmitted wave amplitudes and their phase averaged ensemble is similar to a single phase realization hence the mse can be compared directly to the wae in fig 1b all the reflection coefficients are examined it can be seen that the brs corresponds well to the maximum value for the mse reflected wave the brs initially oscillates in shallow water and converges very quickly to a constant solution in intermediate and deep water mrc behaves in a similar fashion though it is interesting to note that it oscillates even in deep water conditions and only stops oscillating abruptly when the slope ends the final reflection at x 0 lies within this oscillation and is dependent on the wave phase and the bathymetry the oscillation in deep water is in fact an mrc error defined as the range between the top and bottom values of the oscillation the arr produces a similar maximum value but is limited by a minimal reflection value of 6 7 in order to examine its advantages the brs was compared to the mse reflection coefficient to the mrc and its error envelope and to the arr the effect of different slopes β were examined fig 2 a and a good agreement can be seen between the mse and the brs over different slopes for a wave with time period t 10 s e c shoaling straight towards the slope the mrc shows a similar trend but with an error marked in gray the arr has a minimal value of κ r m i n 0 067 causing its inaccuracy over small slopes and it trends to higher values over steeper slopes in fig 2b the effect of a changing wave period t on the reflection coefficients was examined a good agreement was once again found between the mse and the brs the mrc is initially much larger than the mse rises exponentially around t 5 s and converges towards it for longer wave periods while still showing an error area the high mrc values in the shorter wave length can be attributed to the shallow water theory that is based upon the arr is once again starting at κ r m i n 0 067 and rising rapidly for waves with higher periods than t 10 s fig 2c shows the reflection of oblique waves with an attack angle θ towards the slope it is very interesting to note that a significant increase in wave reflection for both the mse and the brs occurs around π 2 and 3π 2 where the incident wave is close to the y direction long shore this kind of reflection could have a major effect around islands and peninsulas where waves propagate almost parallel to elongated stretches of land looking at attack angles smaller than π 2 a slight increase in wave reflection can be seen with increasing angle for both the mse and the brs as expected both the mrc and the arr do not change with the attack angle in fig 3 a the effect of the wave period t in the infra gravity range propagating towards a slope of β 1 20 from depth of 1500 m to 10 m is shown the mse oscillates with higher amplitude as t increases in a manner reminding resonance the mrc oscillates in a similar manner and is very close to the mse but with an error of increasing size the longer the wave periods are the brs follows the general trend of the mse but in a linear way the arr is much larger starting from the gravity wave length and rising steeply reaching a none physical value of over 350 reflection as expected it is seen that for infra gravity waves the values of kh over the plateau in depth of 1500m are smaller for longer waves correlating to intermediate and shallow water conditions this causes the bottom slope smoothness to have an effect on the value of reflection as discussed in mei et al 2005 in most numerical models a single grid element usually consists of a uniform slope and no plateaus in fig 3b the same slope as in fig 3a is examined with no plateau at the start and end points in this case the assumption of zero reflection on the shallower part of the slope is inaccurate since there could be a reflection at the end point in a numerical model however such a reflection will be introduced as a wave from the adjacent grid element and not as a reflected energy making the assumption of a zero reflection plausible in this case the mse and brs are both rising linearly the mrc is still oscillating with the arr once again increasing too steeply 6 summary and discussion in this paper a bottom reflection source term was introduced to the wave action equation with the purpose of improving the accuracy of numerical wave forecasting models the reflection source term was based on the mild slope equation mse using a coupled oblique parabolic equation formulation and a perturbation method with the assumption of a small reflected wave amplitude the derived bottom reflection source term brs was compared to previously derived reflection terms and to the mse which was used as a benchmark results show the brs to be more accurate than the empiric reflection term arr currently in use in some models the new source term also shows good agreements with the mse for oblique incident waves a capability other reflection terms lack due to their 1d formulation in the infra gravity frequency range it was found that a shallow water equation based model mrc has a better agreement with the mse though with a large error margin it is worth to mention that both the mse and the mrc display a peculiar oscillatory behavior with increasing wave periods the reflection from a bathymetry with a uniform slope and no flat ends was also investigated as it is similar to that used in numerical forecasting models in this case the mse behaves in a similar manner to the brs and the mrc still displays oscillations probably due to inaccuracies resulting from its shallow water assumption the physical validity of the mse for these very long wave periods still needs to be confirmed as the bottom depth may change significantly within a single wave length the numerical simulations presented in this paper were performed on sharp edge bottom profiles where change from the sloping bottom to the plateau was sudden resulting in sharp angles smoother profiles produce even better agreement between the brs and mse but result in smaller reflected wave amplitudes as slopes are smaller over the same length in conclusion the new bottom reflection source term showed excellent agreements with the mse model while accounting for the full wave spectral regime varying slopes and general attack angles with reflected waves of amplitudes up to 20 of the incident wave the derived term is the first localized analytically developed bottom reflection source term its formulation is fitting for implementation in wave forecasting models in a simple and efficient manner acknowledgments this research was supported by the israel science foundation grant no 1940 14 and israel s ministry of science and technology grant no 3 12473 the insightful comments by ocean modeling reviewers are highly appreciated for their contribution to the brevity of the manuscript as well as for its rigorous formulation 
24102,the wave action equation is a widely used governing equation in wave forecasting models whilst it accounts for wave propagation its analytical derivation neglects various other effects such as the sea bottom reflection the present work derives an analytical source term for the bottom reflection of oblique incident waves to be used in numerical forecasting models this is done by means of a coupled oblique parabolic approximation of the mild slope equation which is then decoupled by introducing a perturbation solution the resulting first two orders produce the wave action equation itself for an on going wave in the first order and a wave action equation with a reflection source term in the second order for the reflected wave a method to implement this source term in two dimensional wave action forecasting models is discussed numerical simulations show this new source term to be in excellent agreement with the mild slope equation for different slopes wave periods and attack angles keywords wind waves wave action equation bottom reflection mild slope equation 1 introduction the wave action equation wae is one of the most commonly used governing equation in today s numerical sea and ocean wave forecasting models it is based on bretherton and garrett 1968 where it was developed as a transport equation of a conserved quantity describing the propagation of slowly varying wavetrains of small amplitude numerical models use the wae with the addition of source terms which represent the effects on water waves neglected by the wae these source terms are grouped in a semi arbitrary manner to account for different effects of ocean wave propagation such as dissipation wave breaking wind input non linear wave interactions and bottom interactions a commonly unresolved component of the bottom interactions source term is the wave reflection from the sea bottom as a wave shoals over a sloping sea bottom some of its energy is reflected from the seabed and creates a reflected wave in the opposite direction this mainly happens in shallow water where the bottom effects waves the most the bottom reflection is expected to be stronger near islands bays channels and ports with sloping sea floor and can increase wave amplitude as much as 20 in extreme cases and 5 10 for more common cases as seen in tatavarti et al 1988 mahony and pritchard 1980 elgar et al 1994 the approach used nowadays for calculating the wave reflection in wae based models was pioneered by miche 1951 where a semi empirical reflection term r was derived for monochromatic waves shoaling towards a sloped shore this reflection term was tested by elgar et al 1994 and later approximated more accurately by ardhuin and roland 2012 as 1 r 0 2 0 007 log 10 m i 4 5 0 15 m i m i 16 t a n 5 β 2 π 5 h 2 f 4 where r 0 2 is the energy reflection term for specific mi miche number β is the bottom slope h is the deep water wave height and f is the wave frequency this term was used to produce a reflection source term which is currently used by several wave forecasting models a different approach for calculating wave reflection was shown by mei et al 2005 this approach manipulates the mild slope equation mse a three dimensional laplace equation simplified by an integration over the depth with a predefined vertical profile and was originally developed in the works of biesel 1952 eckart 1952 svendsen 1967 berkhoff 1972 the mse was further simplified into the shallow water equation which assumes large wave lengths compared to the water depth using a wkb perturbation method mei et al 2005 chapter 4 5 derives the new term for the bottom reflection 2 r 1 d d x ln k h e 2 i k x d x d x where r 1 is the reflection term k is the wave number h is the water depth and x is the lateral coordinate this term was shown to be strongly influenced by the smoothness of the start and end points of the sloping bottom and was limited to a wave coming straight towards the beach in shallow water conditions mei s new term was not further studied or used another form of bottom reflection source term was derived in ardhuin and herbers 2002 magne et al 2005 where the bottom topography was described through a discrete fourier transform this source term accounts for bottom reflection due to class i bragg scattering and is currently used to describe sub grid bottom ripples it may have the potential to account for bottom reflection in larger scale though it will require a methodology of transforming a varying 2d bathymetry to a varying localized fourier representation the present work aims to derive a new analytical term for wave reflection caused by an incident wave with a general attack angle improving former models which are limited to direct incident waves such an analytical bottom reflection source term will be applicable to 2d spectral models and will result in a more accurate near shore environment wave prediction in large scale models the new analytical source term is derived through a parabolic approximation of the mild slope equation which defines a coupled oblique parabolic equations set ope as shown by radder 1979 liu and tsay 1983 toledo 2013 a perturbation method is applied to these ope in such a way that the shore ward incident wave and the sea ward reflected wave are decoupled finally a wave action form is derived for the new reflected wave equation and the source term to be used in numerical simulations is formulated the paper is structured as follows in section 2 the linear mild slope equation is introduced and transformed into a coupled linear ope in section 3 a perturbation method is applied to the ope in a way that decouples the incident shore ward wave and the reflected sea ward reflection in section 4 the reflected ope is transformed into a wae form and the reflection source term is constructed numerical simulations are presented in section 5 and the work is summarized and discussed in section 6 2 the coupled linear oblique parabolic equation model the linear 2d mild slope equation see berkhoff 1972 is given by 3 c c g ϕ k 2 c c g ϕ 0 where ϕ is the velocity potential on the undisturbed water surface z 0 is the horizontal gradient operator c is the phase velocity and cg is the group velocity k is the wave number which can be calculated using the dispersion relation 4 ω 2 g k tanh k h as a function of the angular frequency ω gravitational acceleration g and the water depth h x y using a scaling factor ccg 1 2 so that 5 ϕ c c g 1 2 ϕ the liouville transform is applied see e g radder 1979 dingemans 1997 toledo 2013 and the mild slope equation is written in the form of a linear helmholtz equation as follows 6 2 ϕ k c 2 ϕ 0 the effective wave number is defined by 7 k c 2 k 2 c c g 1 2 2 c c g 1 2 in order to apply a parabolic approximation to eq 6 a splitting method is used as in radder 1979 liu and tsay 1983 and toledo 2013 first the wave field is separated into two wave fields 8 ϕ ϕ ϕ where ϕ describes the wave propagating in the positive x direction and ϕ the negative x direction the linear coupled ope are derived similarly to toledo 2013 eq 3 13 without neglecting the reflected field 9 ϕ x 1 2 k 1 i k c 2 k 1 2 k 1 x i 2 y 2 ϕ 1 2 k 1 i k c 2 k 1 2 k 1 x i 2 y 2 ϕ where k 1 and k 2 are the x direction and y direction wave numbers respectively defined by 10 k 2 k 1 2 k 2 2 eq 9 describes a coupled linear ope model for waves where the lhs coincides with the linear part of toledo 2013 and the rhs acts as coupling term between the waves propagating in the positive x direction to the negative one and vice versa 3 a perturbation approximation for the coupled system up to this point the method of radder 1979 liu and tsay 1983 and toledo 2013 was followed closely here a perturbation method is used to decouple the incident and the reflected wave fields in order to simplify eq 9 a quasi 2d wave model is adopted this is done by defining the x axis in the direction of the gradient of the slope and y axis orthogonal to it assuming no change in the y direction the velocity potential can be described as 11 ϕ x y ϕ x e i k 2 y and the quasi 2d coupled model is derived as 12 ϕ x i k 1 1 2 k 1 k 1 x ϕ 1 2 k 1 k 1 x ϕ next a non dimensional model was derived using the non dimensional properties 13 ϕ ϕ h i g ω ϕ ϕ h r g ω 14 k 1 k 1 k 01 x x k 01 15 κ r h r h i where hi and hr are the incident and reflected wave heights respectively k 01 is the deep water wave number in the x direction and κ r is the reflection coefficient substituting eqs 13 15 into eq 12 results with 16 ϕ x i k 1 1 2 k 1 k 1 x ϕ κ r 1 2 k 1 k 1 x ϕ from a physical perspective the reflected wave is of a smaller order than the propagating wave causing it see e g liu and tsay 1983 thus it was neglected in other works see e g liu and mei 1976 radder 1979 toledo 2013 this is plausible in a mild slope bathymetry and without bragg resonance which is often the case this assumption corresponds to a small reflection coefficients κ r κ r 1 subsequently both expressions ϕ were expanded into 17 ϕ ϕ 0 κ r ϕ 1 18 ϕ κ r ϕ 1 assuming the incident wave is propagating only in the positive x direction this can be justified without loss of generality as the incident wave can be derived in any direction by changing the attack angle and the linear nature of the problem allows superposition comparing expressions of magnitudes o κ r 0 and o κ r 1 in eq 16 18 yields 19 ϕ 0 x i k 1 ϕ 0 1 2 k 1 k 1 x ϕ 0 0 20 ϕ 1 x i k 1 ϕ 1 1 2 k 1 k 1 x ϕ 1 1 2 k 1 k 1 x ϕ 0 which are the leading order and the first order approximations of the quasi 2d model in eq 16 it was assumed that ϕ 1 0 as the first order correction in eq 19 is identical to the zero order and thus no additional energy is entered using wave elevation instead of velocity potential will allow for an easier transformation into a wave action form the wave elevation above the undisturbed surface water level η is given by 21 ϕ x c c g 1 2 g i ω η x applying eqs 13 14 and 21 to eqs 19 and 20 results in 22 x c c g η i k 1 1 2 k 1 k 1 x c c g η 0 0 23 x c c g η 1 i k 1 1 2 k 1 k 1 x c c g η 1 1 2 k 1 k 1 x c c g η 0 eq 22 represents an oblique wave propagating in the x direction and is similar to the linear eq 3 15 in toledo 2013 eq 23 represents the first order correction to the negative x direction induced by the propagating incident wave in the positive x direction 4 derivation of the reflection source term for wave action equation models numerical forecasting models use the wae as a governing equation as it is invariant along a wave ray even in the presence of a mean current the wave action is defined as 24 a e ω 1 2 ρ g η 2 ω where e is the wave energy and ρ is the water density the wave elevation was defined as 25 η η e i ψ where exponential part accounts the oscillatory part of the wave elevation with phase function ψ and η is a complex wave elevation allowing for phase shift applying eqs 24 and 25 to eq 22 results in the zero order wave action solution see kirby 1984 26 x k 1 k c g a 0 where the eikonal equation of the zero order imaginary part gives the phase function 27 ψ x 0 x k 1 d x ω t in a similar manner the wave action form of eq 23 should yield the source term of the reflected wave in order to do so eqs 25 and 27 were applied to eq 23 giving 28 2 k 1 x c c g η 1 k 1 x c c g η 1 k 1 x c c g η 0 e 2 i k 1 d x dividing by k 1 eq 28 can be reduced to 29 x k 1 c c g η 1 2 k 1 c c g η 1 2 k 1 x c c g k 1 η 0 e 2 i k 1 d x and its integration yields 30 2 k 1 c c g η 1 2 x 0 x k 1 x c c g k 1 η 0 e 2 i k 1 d x d x taking the x derivative of the square of eq 30 gives 31 x k 1 c c g η 1 2 k 1 x c c g η 0 e 2 i k 1 d x k 1 x 0 x k 1 x c c g η 0 e 2 i k 1 d x 2 k 1 d x after this manipulation the rhs of eq 31 depends solely on the zero order elevation nevertheless it is difficult in its application to wae models as it is non local this can be resolved by applying a similar localization procedure as was done in stiassnie and drimer 2006 toledo and agnon 2012 and vrecica and toledo 2016 for localizing nonlinear triad interactions coefficients the integral in eq 31 can be written as 32 x 0 x k 1 x c c g η 0 2 k 1 e 2 i k 1 d x d x 0 ζ x ζ c c g η 0 2 ζ ζ e 2 i ζ d ζ where 33 ζ x x 0 x k 1 d x ζ x ζ x k 1 ζ x k 1 x solving eq 32 using the integration by parts method yields 34 0 ζ x ζ c c g η 0 2 ζ ζ e 2 i ζ d ζ i ζ c c g η 0 4 ζ ζ e 2 i ζ 0 ζ x i x ζ c c g η 0 2 ζ ζ e 2 i ζ 2 d ζ the second term on the rhs of eq 34 is assumed to be of a smaller order than the first term see toledo and agnon 2012 and can be neglected using this result in eq 31 gives 35 x k 1 c c g η 1 2 i k 1 x 2 k 1 2 c c g η 0 2 e 4 i k 1 d x noting that 36 k 1 c k 1 k ω the quasi 2d wae reflection was derived using the absolute values of both sides of the equation as wave action is relative to the amplitude of the wave elevation this is possible as η 2 η 2 and results with 37 x k 1 k c g a i k 1 x 2 k 1 2 c g a k e 4 i k 1 d x eq 37 is the main result of this paper its rhs is the analytical bottom reflection source term which is applicable to wae based forecasting models the new source term was developed using a quasi 2d model but can be applied to a general 2d numerical model this can be done by assuming that the local bathymetry is changing significantly only in single direction and the lateral bottom changes are negligible following this assumption the coordinate ξ is defined in the direction of the slope for each grid element this creates a local quasi 2d solution where the reflection source term is given by 38 s r e f i k ξ ξ 2 k ξ 2 c g a k e 4 i k ξ d ξ 5 numerical simulations numerical simulations of various wave reflection coefficients are presented in this section the mse was defined as eq 3 with the assumption of a quasi 2d wave propagation as defined by eq 11 the wae was defined as eq 26 and the new bottom reflection source term brs was calculated in the same way with the addition of eq 37 mei s analytical reflection coefficient mrc was simulated using eq 2 and the empirical correction to miche s number arr was defined as eq 1 the equations were solved in wolfram mathematica 10 software the mse and brs were solved using the ndsolve function with the bdf method the mrc was solved using the integrate function and the arr was solved directly the numerical simulations were performed over a sloping bottom with plateaus at both ends one in deep water kh 3 and one in shallow water k h 0 2 as seen in fig 1 a the slope lengths varied to accommodate these conditions the boundary conditions used were 1 a known incident wave at x 0 moving in the positive x direction 2 no reflection past the bottom slope the reflection was measured over the flat area in the deep sea the reflection coefficient is defined by eq 15 as the reflected wave amplitude normalized with the incident wave causing it the properties examined in the simulations are the wave period t the bottom slope β and the wave attack angle towards the x axis θ in fig 1a the mse curve shows the elevation of the partial standing wave created by the incident and reflected waves as a function of x l 0 where l 0 is the deep water wavelength the wae curve shows only the forward propagating wave which corresponds to the mean value of the undulating mse the brs added and subtracted from the wae fits an envelope around the mse curve which corresponds to the maximal and minimal elevations of the mse in the case of a linear monochromatic problem different initial phases of the deterministic mse do not change the reflected and transmitted wave amplitudes and their phase averaged ensemble is similar to a single phase realization hence the mse can be compared directly to the wae in fig 1b all the reflection coefficients are examined it can be seen that the brs corresponds well to the maximum value for the mse reflected wave the brs initially oscillates in shallow water and converges very quickly to a constant solution in intermediate and deep water mrc behaves in a similar fashion though it is interesting to note that it oscillates even in deep water conditions and only stops oscillating abruptly when the slope ends the final reflection at x 0 lies within this oscillation and is dependent on the wave phase and the bathymetry the oscillation in deep water is in fact an mrc error defined as the range between the top and bottom values of the oscillation the arr produces a similar maximum value but is limited by a minimal reflection value of 6 7 in order to examine its advantages the brs was compared to the mse reflection coefficient to the mrc and its error envelope and to the arr the effect of different slopes β were examined fig 2 a and a good agreement can be seen between the mse and the brs over different slopes for a wave with time period t 10 s e c shoaling straight towards the slope the mrc shows a similar trend but with an error marked in gray the arr has a minimal value of κ r m i n 0 067 causing its inaccuracy over small slopes and it trends to higher values over steeper slopes in fig 2b the effect of a changing wave period t on the reflection coefficients was examined a good agreement was once again found between the mse and the brs the mrc is initially much larger than the mse rises exponentially around t 5 s and converges towards it for longer wave periods while still showing an error area the high mrc values in the shorter wave length can be attributed to the shallow water theory that is based upon the arr is once again starting at κ r m i n 0 067 and rising rapidly for waves with higher periods than t 10 s fig 2c shows the reflection of oblique waves with an attack angle θ towards the slope it is very interesting to note that a significant increase in wave reflection for both the mse and the brs occurs around π 2 and 3π 2 where the incident wave is close to the y direction long shore this kind of reflection could have a major effect around islands and peninsulas where waves propagate almost parallel to elongated stretches of land looking at attack angles smaller than π 2 a slight increase in wave reflection can be seen with increasing angle for both the mse and the brs as expected both the mrc and the arr do not change with the attack angle in fig 3 a the effect of the wave period t in the infra gravity range propagating towards a slope of β 1 20 from depth of 1500 m to 10 m is shown the mse oscillates with higher amplitude as t increases in a manner reminding resonance the mrc oscillates in a similar manner and is very close to the mse but with an error of increasing size the longer the wave periods are the brs follows the general trend of the mse but in a linear way the arr is much larger starting from the gravity wave length and rising steeply reaching a none physical value of over 350 reflection as expected it is seen that for infra gravity waves the values of kh over the plateau in depth of 1500m are smaller for longer waves correlating to intermediate and shallow water conditions this causes the bottom slope smoothness to have an effect on the value of reflection as discussed in mei et al 2005 in most numerical models a single grid element usually consists of a uniform slope and no plateaus in fig 3b the same slope as in fig 3a is examined with no plateau at the start and end points in this case the assumption of zero reflection on the shallower part of the slope is inaccurate since there could be a reflection at the end point in a numerical model however such a reflection will be introduced as a wave from the adjacent grid element and not as a reflected energy making the assumption of a zero reflection plausible in this case the mse and brs are both rising linearly the mrc is still oscillating with the arr once again increasing too steeply 6 summary and discussion in this paper a bottom reflection source term was introduced to the wave action equation with the purpose of improving the accuracy of numerical wave forecasting models the reflection source term was based on the mild slope equation mse using a coupled oblique parabolic equation formulation and a perturbation method with the assumption of a small reflected wave amplitude the derived bottom reflection source term brs was compared to previously derived reflection terms and to the mse which was used as a benchmark results show the brs to be more accurate than the empiric reflection term arr currently in use in some models the new source term also shows good agreements with the mse for oblique incident waves a capability other reflection terms lack due to their 1d formulation in the infra gravity frequency range it was found that a shallow water equation based model mrc has a better agreement with the mse though with a large error margin it is worth to mention that both the mse and the mrc display a peculiar oscillatory behavior with increasing wave periods the reflection from a bathymetry with a uniform slope and no flat ends was also investigated as it is similar to that used in numerical forecasting models in this case the mse behaves in a similar manner to the brs and the mrc still displays oscillations probably due to inaccuracies resulting from its shallow water assumption the physical validity of the mse for these very long wave periods still needs to be confirmed as the bottom depth may change significantly within a single wave length the numerical simulations presented in this paper were performed on sharp edge bottom profiles where change from the sloping bottom to the plateau was sudden resulting in sharp angles smoother profiles produce even better agreement between the brs and mse but result in smaller reflected wave amplitudes as slopes are smaller over the same length in conclusion the new bottom reflection source term showed excellent agreements with the mse model while accounting for the full wave spectral regime varying slopes and general attack angles with reflected waves of amplitudes up to 20 of the incident wave the derived term is the first localized analytically developed bottom reflection source term its formulation is fitting for implementation in wave forecasting models in a simple and efficient manner acknowledgments this research was supported by the israel science foundation grant no 1940 14 and israel s ministry of science and technology grant no 3 12473 the insightful comments by ocean modeling reviewers are highly appreciated for their contribution to the brevity of the manuscript as well as for its rigorous formulation 
24103,an energetically consistent vertical mixing parameterization in ccsm4 søren b nielsen a markus jochum a carsten eden b roman nuterman a a climate and computational geophysics niels bohr institute university of copenhagen juliane maries vej 30 copenhagen 2100 denmark climate and computational geophysics niels bohr institute university of copenhagen juliane maries vej 30 copenhagen 2100 denmark b institut für meereskunde university of hamburg germany institut für meereskunde university of hamburg germany corresponding author an energetically consistent stratification dependent vertical mixing parameterization is implemented in the community climate system model 4 and forced with energy conversion from the barotropic tides to internal waves the structures of the resulting dissipation and diffusivity fields are compared to observations and the fidelity of the resulting temperature fields is assessed compared to existing biases in the control simulation differences in surface fields are small showing that the surface climate state is relatively robust to the choice of mixing parameterization the thermocline structure however depends greatly on the details of the vertical mixing parameterizations where the new energetically consistent parameterization results in low thermocline diffusivities and a sharper and shallower thermocline it is also investigated if the ocean state is more sensitive to a change in forcing if the energetically consistent scheme is used compared to a tidal mixing parameterization with fixed background diffusivity in particular we find that the atlantic meridional overturning circulation is more sensitive to changes in the southern ocean wind stress with the former however in line with previous results changes to southern ocean upwelling are still largely compensated by changes to the diabatic upwelling in the indo pacific basin keywords diapycnal mixing numerical mixing parameterizations internal wave breaking 1 introduction mechanical energy is needed to return the deep waters that are formed at high latitudes to the surface see e g sandström 1908 it has been hypothesized that this mechanical energy is provided by the breaking of internal waves to small scale turbulence munk 1966 munk and wunsch 1998 this hypothesis has been supported by numerical studies bryan 1987 marotzke 1997 yet despite its importance small scale turbulence in the ocean interior is still represented through diffusivity fixed in time and space more recently this so called background diffusivity will be amplified near the bottom to mimic tidally induced mixing e g bryan and lewis 1979 st laurent et al 2002 however for large parts of the ocean away from the boundary layers the vertical diffusivity is dominated by the background diffusivity the value of this background diffusivity is obtained by a combination of observations and model optimization using spatially varying maps of diffusivity to match global observations rather than a constant global value has been shown to improve climate models harrison and hallberg 2008 jochum 2009 however while using a constant diffusivity can yield pre industrial or present day simulations in good agreement with observations the reliability of these parameterizations is questionable for different climate states the model of osborn 1980 suggests that vertical diffusivity κ is a function of locally dissipated energy from the internal wave field ϵ and the brunt väisälä frequency n 1 κ ϵ n 2 because both variables are likely to change as climate changes we expect changes in diffusivities and therefore in ocean circulation heat and carbon storage and uptake furthermore present tidal mixing parameterizations have problems of representing observed dissipation rates due to assumptions regarding the propagation and dissipation of internal wave energy waterhouse et al 2014 mackinnon et al 2017 kunze 2017 the focus of this study is how climate is affected when using an energetically consistent mixing parameterization rather than using fixed background diffusivities studies suggest that the parameterization of interior mixing affects the simulations of pre industrial climate e g jayne 2009 melet et al 2013 in particular changes in the localization of dissipation of internal wave energy has consequences in regions of deep water formation as well as for thermocline structure melet et al 2013 2016 previous studies mainly focus on steady state properties of the ocean here we perform a simple experiment to assess to what degree the ocean response to changed forcing is affected by the choice of parameterization the topic of interest for this experiment is the strength of the atlantic meridional overturning circulation amoc the amoc is a measure of the volume transport from the southern hemisphere to the northern often referred to as the ocean conveyor belt with sinking waters in the north atlantic being replaced by sub tropical surface waters through the gulf stream this circulation gives rise to an atlantic heat transport from the southern to the northern hemisphere the driving mechanisms of the amoc have been investigated and discussed throughout the last decades see e g the review by kuhlbrodt et al 2007 in particular buoyancy fluxes diapycnal mixing rates and southern ocean wind stress have all been suggested to play important or even dominating roles these also impact the strength of the antarctic circumpolar current acc gent et al 2001 several numerical studies have implicated a direct dependency of overturning to the value of diapycnal diffusivity bryan 1987 marotzke 1997 yet many studies require mixing values larger than observed to sustain the observed rate of overturning toggweiler and samuels 1995 polzin et al 1997 ledwell et al 1998 in the mid 1990 s it was pointed out that southern ocean winds and the sill at the drake passage were potentially dominating global ocean upwelling sometimes referred to as the drake passage effect toggweiler and samuels 1995 even near the limit of no vertical diffusion the drake passage effect was discovered to sustain an observed overturning toggweiler and samuels 1998 in a more recent study munday et al 2013 found the overturning to be less sensitive to wind forcing as horizontal resolution increased due to the explicit generation of southern ocean eddies although a sensitivity remained additionally the overturning was found to be sensitive to the choice of diapycnal diffusivity regardless of model resolution all these results were obtained by forcing an ocean model with prescribed buoyancy forcing in contrast to these studies jochum and eden 2015 found that in a realistic coupled climate model the amoc is robust to changes in southern ocean wind stress changes to southern ocean winds and upwelling are compensated by diabatic upwelling in the indo pacific basin their study however used a fixed vertical diffusivity so that changed mixing rates due to changed ocean stratification are not present possibly leading to an overestimation of the indo pacific compensation here we will revisit this idea and check if their results still hold if a fixed energy rather than a fixed diffusivity parameterization is used the paper is structured as follows in section 2 current ideas about diapycnal mixing and its parameterizations are briefly reviewed and an energetically consistent parameterization idemix olbers and eden 2013 and its implementation in an ocean model are described in section 3 the results of model simulations with the standard mixing parameterization and with idemix are compared in two sets three coupled simulations including a sensitivity study and six forced simulations comparing the response of the ocean to changes in the wind stress under the two different mixing schemes in section 4 the results are summarized and discussed in context to modeling climate and future prospects 2 methods 2 1 vertical mixing in ocean models diapycnal from here on simply vertical mixing in the ocean in level coordinate ocean general circulation models is generally represented as a vertical diffusion of tracers this process represents the conversion of small scale turbulent kinetic energy into potential energy and is important in setting the global pycnocline structure munk 1966 it is often recognized that an average global value of 10 4 m2 s 1 is required to maintain the observed global stratification munk and wunsch 1998 the energy input needed to maintain the observed ocean stratification has been estimated to be approximately 2 terawatts tw partitioned between winds and tides munk and wunsch 1998 egbert and ray 2000 jayne and st laurent 2001 nycander 2005 wind energy enters the ocean through the work winds do on the surface ocean with a large fraction driving the time mean circulation eventually dissipating to mesoscale eddies and some through direct generation of near inertial waves niws see e g jochum et al 2013 of which only a fraction leaves the mixed layer energy from mesoscale eddies is lost through numerous processes including bottom and lateral friction and generation of lee waves over rough topography in a similar way as tidal energy loss nikurashin and ferrari 2010 estimates of dissipation and diffusivity from argo float fine structure measurements support the relationship between vertical mixing and dissipation of barotropic tides as well as geostrophic motions whalen et al 2012 pollmann et al 2017 with the recognition of the importance of tides and their signature bottom enhanced mixing parameterizations have been developed for tidally induced mixing near the bottom one such parameterization is the one by st laurent et al 2002 this parameterization calculates a bottom enhanced diffusivity based on the local energy flux from tides to internal waves taken from the model of tidal dissipation by jayne and st laurent 2001 by assuming that a fraction q of the energy that is locally converted from barotropic to internal tides is dissipated locally through a vertical distribution function which ensures bottom enhanced mixing whereas the remaining energy radiates away and contributes to background mixing for details see simmons et al 2004 jayne 2009 the mathematical expression becomes 2 κ κ b q γ e f t x y f z ρ n 2 where κb is the background diffusivity γ 0 2 is the mixing efficiency and q 1 3 is the fraction of the energy flux from barotropic tides to internal waves e f t that dissipates locally with the local dissipation being distributed vertically by an exponential decay function f z and ρ being the density one key uncertainty is the fixed vertical decay scale f z for the dissipation of internal wave energy this choice often does not match observations kunze 2017 and it has been shown that the choice of a vertical dissipation profile is important for setting the ocean state melet et al 2013 furthermore the globally constant value of locally dissipated energy in eq 2 q relies on sparse observations and there is little justification that one value is representative of the entire ocean waterhouse et al 2014 recent work has now provided a theoretical background to take a step in parameterizing small scale turbulence through directly computed values for dissipated energy as described below 2 2 idemix a recent paper proposes the model internal wave dissipation energy and mixing idemix olbers and eden 2013 to be implemented in a global ocean model although extensions to the model have been developed eden and olbers 2014 we will here use the first version as described in olbers and eden 2013 due to the simplicity and as the main focus is how the ocean and climate responds when the vertical mixing is defined from a constant energy flux compared to a fixed background diffusivity in space and time through a set of assumptions and simplifications idemix calculates the total internal wave energy e as well as the dissipation of internal wave energy ϵ iw e is calculated by solving a single differential equation obtained from the spectral radiation balance of a weakly interacting wave field 3 e t z c 0 τ v c 0 e z h v 0 τ h h v 0 e ϵ i w s where the second and third terms on the l h s are the vertical and horizontal transport of e respectively s represents the sum of local sources of internal wave energy idemix has been discussed in several papers already olbers and eden 2013 eden et al 2014 eden and olbers 2014 pollmann et al 2017 and will therefore only be summarized briefly here in order to arrive at eq 3 upward and downward propagating waves are first treated separately and the wave energy is integrated over all wave numbers in each vertical wave number half space equations for the sum of energy e and difference δe of the two half spaces are then simplified by assuming approximate symmetry in vertical wave number m and that nonlinear wave wave interactions work to eliminate δe through an exponential relaxation with decay scale τv the wave speed is also assumed to have the same value for the upward and downward propagating waves c 0 the value of c 0 can be found by assuming a garrett munk gm like internal wave energy spectrum the third term on the l h s of eq 3 represents the lateral propagation of energy with v 0 a horizontal average group velocity and τh a relaxation time for horizontal anisotropies similar to τv the model is closed on the r h s of eq 3 by setting 4 ϵ i w μ 0 f e m 2 n 2 e 2 which represents the energy flux at high vertical wavenumber a combination of calculations of mccomas and müller 1981 heyney et al 1986 with m the bandwidth in vertical wavenumber and μ 0 a constant mccomas and müller 1981 finally f e f arccosh n f the dissipation of energy is then related to a vertical diffusivity through the osborn 1980 model 5 κ δ 1 δ ϵ i w n 2 δ 1 δ μ 0 f e e 2 c 2 n 2 where the relation m n c is used with c 1 j π h 0 n z d z with j the modal bandwidth of the gm model 2 3 model and implementation eq 3 is implemented in the ocean component of the community climate system model 4 ccsm4 gent et al 2011 the parallel ocean program pop2 danabasoglu et al 2012 following the implementation of eden et al 2014 with the parameter values suggested by olbers and eden 2013 μ 0 4 3 δ 0 2 j 10 τ v 1 day and τ h 10 days first eq 3 is solved with a tri diagonal solver without the lateral propagation term which is then added explicitly to the solution afterwards diffusivities obtained through eq 5 are capped at a minimum of 10 7 m2 s 1 molecular level and a maximum of 10 2 m2 s 1 a total of 9 experiments are carried out using the coarse resolution version of ccsm4 shields et al 2012 the ocean component uses a horizontal nominal 3 resolution with 60 vertical layers of increasing thickness in the surface layers are 10 m thick ranging to several hundred meters in the deepest ocean first a coupled control simulation using the t31 3 configuration cont is run for 500 years using a latitudinal dependent background diffusivity 0 01 cm2 s 1 at equator 0 3 cm2 s 1 at 30 n s and 0 17 cm2 s 1 elsewhere jochum 2009 with bottom enhanced diffusivity calculated from eq 2 this is then compared to a similar 500 year long run where the background and tidal induced diffusivities are replaced by the idemix module referred to as ide forced with only the conversion of barotropic to baroclinic tides using the same forcing as cont jayne and st laurent 2001 st laurent et al 2002 jayne 2009 analysis is carried out for the years 450 499 one extra sensitivity simulation ieddy includes an additional energy source from mesoscale eddies as calculated from the simple dissipation form of eden and greatbatch 2008 where mesoscale eddy energy is converted to internal wave energy by 6 ϵ e d d y 0 1 l 2 σ 3 with l being the minimum of the first baroclinic rossby radius of deformation and the rhines scale and σ f u z n is the eady growth rate this parameterization of eddy forcing adds energy to the internal waves everywhere in the ocean in particular near eddying currents such as the acc western boundary currents and the tropics see e g fig 1d of eden et al 2009 eddy forcing of idemix can be implemented in different ways eden et al 2014 here we choose the simplest form of local injection in eq 3 this may not be the ideal implementation but the reasoning behind the simulation is to see what effect adding more energy to the parameterization has not how the choice of injection optimizes the simulations here we refer the reader to eden et al 2014 pollmann et al 2017 the background for the sensitivity experiment comes from the fact that idemix falls short of explaining observed dissipation rates without mesoscale eddy forcing pollmann et al 2017 however as cont is only forced with tidal forcing the main comparison experiment ide is also forced with tides only for an energetically consistent implementation the eddy forcing should be calculated from the used thickness diffusivity in our simulations calculated according to danabasoglu and marshall 2007 other ways to implement other energy would be from estimates of lee wave energy fluxes nikurashin and ferrari 2011 melet et al 2014 our implementation compares with the horizontal structure of such estimates the choice of eq 6 is based on the simplicity from the fact that it is already directly implemented in pop2 eden and greatbatch 2008 eden et al 2009 ieddy will be used only when discussing adding extra forcing to the idemix parameterization note that the simple additional energy source by eq 6 is most likely an overestimation of the effect of eddies as discussed in eden et al 2014 in order to revisit the indo pacific upwelling discussed by jochum and eden 2015 a set of three ocean ice simulations with corev2 normal year forcing large and yeager 2004 with a sea surface salinity restoring timescale of one month are performed for both parameterizations of mixing each set consists of a 500 year control simulation contf and idef each control simulation is accompanied by branched runs from year 300 one where winds over the southern ocean south of 35 s are shut off by multiplying the wind stress with a value p 0 contf00 and idef00 and one where the southern ocean winds are increased by 50 by setting p 1 5 contf15 and idef15 between 35 and 25 s p is reduced linearly to 1 the wind profiles are depicted in fig 1 each branch is run for 200 years the forced simulation are analyzed for years 490 499 the model setups are summarized in table 1 reducing the background diffusivity in simulations using idemix comes with the risk of making the model more prone to numerical noise but this has been found only to pose issues in marginal seas e g the baltic and caspian seas which only span few grid points and are not connected to the major basins in the coarse resolution pop2 for which reason the background diffusivities in these basins are set to the same value in idemix simulations as in the control simulations section 3 first considers the coupled simulations and response in climate and then deals with the two sets of forced simulations 3 results 3 1 coupled simulations we begin by assessing the differences between the two coupled simulations cont and ide beginning with the diffusivities followed by the differences in climatology global maps of the diffusivities in this case only background diffusivities and tidal mixing as calculated by eq 2 in cont and diffusivities as calculated by eqs 3 and 5 in ide are presented in fig 2 averaged over three depth intervals 0 2 1 km 1 2 km and 2 4 km the upper 200 m have been excluded because mixed and boundary layer diffusivities in ide contaminate the signal of the thermocline structure due to the low stratifications within these the pattern of bottom enhanced diffusivity due to topography is the same for the two simulations at all depths this is expected as both parameterizations have the same tidal energy induced at the same bottom cells the difference is in how the energy is distributed globally as only 1 3 of the energy is dissipated locally in cont and the rest is not considered but assumed to contribute to the background diffusivity whereas ide injects all the energy and distributes it through eq 3 cont is largely characterized by the latitudinal dependent background diffusivity jochum 2009 whereas ide is characterized strongly by the bottom topography and displays a more heterogeneous diffusivity pattern the diffusivities have been observed to be heterogeneous whalen et al 2012 pollmann et al 2017 although the pattern here does lack much of the observed structure likely due to only using tidal energy as forcing in all depth intervals ide has large regions of reduced diffusivities compared to cont in the upper layer the three major basins all have smaller diffusivities in ide than cont showing a tendency for very small thermocline diffusivities however regions of larger diffusivities are also present which is particularly connected to regions of weak stratification in the high latitudes and over rough topography between 1 2 km in the equatorial band the pacific and the south australia basin have lower diffusivities than the imposed background level in cont which is also valid for the 2 4 km interval these regions are associated with abyssal plains with very low tidal energy input to the internal waves the diffusivities close to rough topography on the other hand are generally the same magnitude or somewhere even larger in ide this suggests that more energy is dissipated locally or at least very close to injection in ide than the 1 3 used in cont and that the horizontal propagation of e is very weak compared to the vertical propagation term and the dissipation the left panel of fig 3 shows the distribution of grid points with a specific diffusivity it is evident that where cont has a very narrow peak around diffusivities just above 10 5 m2 s 1 ide has a more broad distribution of diffusivities but also has distinct peaks at the two cut off ends of the spectrum note that there is almost an order magnitude more points at the higher end of the spectrum in ide than cont due to the global dependency on stratification throughout the water column and not just near the bottom which increases the diffusivity greatly in the surface layers within the mixed layer the histogram also displays that a large number of grid points in ide have diffusivities smaller than in cont from fig 2 we can infer that these points are in particular located in the tropics and sub tropics over abyssal plains and are not only confined to the deep ocean but also the upper parts of the ocean below the mixed and boundary layers on the right panel of fig 3 globally averaged profiles of the diffusivities are plotted solid lines indicate diffusivities over rough topography defined here as bathymetry slopes larger than 0 01 and dashed lines indicate diffusivities over smooth topography only water columns with depths greater than 500 m are included this shows that cont has up to an order magnitude larger diffusivities than ide in the very deep ocean over smooth topography this is a result of the deep ocean points which have very little injection of tidal energy in the abyssal plains causing many points to be of small magnitude in ide see fig 2 in the deep ocean in contrast to the rather large background diffusivity in cont between 1 4 km depth the two models have very similar global profiles in the upper 200 m the stratification dependency in ide shows up in very large diffusivities the global power consumption to raise the potential energy due to vertical mixing is estimated as the global integral 7 p v κ ρ b z d v where b g δ ρ ρ 0 is buoyancy which yields a total of 0 26 tw for cont of which 0 12 tw is dissipated below 500 m and 0 30 tw for ide of which only 0 08 tw is dissipated below a depth of 500 m the vertical distribution of dissipated energy per unit volume divided by the density of water yielding the dissipation per unit mass is shown in fig 4 for cont black and ide red along with a global composite of fine structure estimates kunze 2017 magenta line the dashed red curve is calculated directly from eq 4 whereas solid curves are calculated by dividing the integrand of eq 7 with the mixing efficiency this estimate is derived as no direct estimate of dissipation is calculated in cont unstably stratified grid points are omitted as assumptions for fine structure as well as parameterizations are not valid under these conditions as can be seen using diffusivity and stratification to derive the dissipation in ide solid red underestimates the amount of dissipation calculated by eq 4 dashed red both parameterizations show too much dissipation in the deep regions of the ocean and in particular at mid depth but dissipation in cont is more in line with observations above 1 km where the dissipation rate in ide is too small and does not resemble fine structure estimates that both models have too much dissipation in the deep ocean suggests too much deep dissipation of tidal energy for ide discrepancies with observations might be related to either a poor representation of propagation of energy or missing energy sources in the upper ocean to investigate the latter the sensitivity study ieddy has been carried out where conversion of mesoscale eddy energy to internal wave energy is added in eq 3 the resulting dissipation profile from eq 4 is added in fig 4 as the dashed blue line it is seen that eddy energy forcing increases the interior dissipation rates in particular in the upper 2 km a different choice of implementation of mesoscale eddy dissipation may alter this distribution but this is beyond the scope of this study it should be noted that the fine structure estimates sample mostly the major ocean basins whereas the model estimates are global averages furthermore the uncertainty is large in the deep ocean where observations are sparse kunze 2017 the average amoc strength at 26 n is 14 3 sverdrups 1 sv 106 m3 s 1 for cont and 13 4 sv for ide thus the different dissipation in ide is accompanied by a weaker amoc this may be a reflection in changed mixing in waters associated with deep water formation melet et al 2016 although the amoc reduction is not necessarily a direct result of the mixing parameterization but could be due to feedbacks in buoyancy or wind forcing from the atmosphere however wintertime convection depths in the north atlantic are shallower in ide than cont suggesting the amoc reduction to be caused by reduced production of north atlantic deep water not shown changes in the surface fields are generally small fig 5 shows the sea surface temperature sst difference between ide and cont note that cont has several biases discussed in shields et al 2012 the most prominent ones being related to the western boundary currents and the upwelling regions such as the benguela system west of southern africa where the amplitude of the biases are larger in ide than cont the root mean squared error rmse for cont is 1 67 and somewhat larger for ide with a rmse of 1 90 reduced to 1 80 in ieddy not shown superimposed on the upper panel of fig 5 is the 15 sea ice concentration lines for cont black and ide red the two lines almost coincide with ide having a slightly more northward extent of sea ice in the southern ocean and a slightly more southward extent in the bering sea the north atlantic sea ice extent is comparable but sea ice concentrations are greater within parts of the ocean in ide most remarkably in the baffin bay not shown the sea ice extent is already too large in cont shields et al 2012 but is stable within the two parameterization schemes the lower panel of fig 5 shows the precipitation difference between ide and cont differences are confined to the tropics two major patterns are visible the first is an increase in precipitation in the double itcz seen over the pacific and atlantic these changes are rather small and related to the modest increase in sst in the upwelling regions the biggest change occurs over the indian ocean and the indonesian seas related to a difference in sst in the same region this precipitation pattern is related to the diffusivity in the banda sea region jochum and potemra 2008 in cont this region has enhanced background vertical diffusivity made to match observations of a large tidally induced mixing in the region which causes a reduction in the sst which heavily influences precipitation this mixing is not captured in ide which may either be due to a too low energy input from tides or in the way the energy propagates into the region in the idemix parameterization fig 6 shows the meridional distribution of temperature difference between the two simulations overlaid with contours 5 c intervals from cont dashed ide solid and world ocean atlas 2009 woa locarnini et al 2010 dotted a large difference in the simulations is in the thermocline ide has a sharper and shallower thermocline which causes temperatures to be cooler between 100 and 1000 m depth this is seen in particular in the waters between 5 and 15 c which are shallower in ide compared to both cont and observations causing the temperature stratification to be in less agreement with observations at mid depth however ide is closer to observations seen in the close agreement with the observed 5 c isotherm the rest of the global ocean has temperature differences with amplitude less than 0 5 c the large differences between cont and ide occur in the upper km which is also the region of the largest discrepancy in dissipated energy in fig 4 and in the region of small diffusivities in the pacific and atlantic causing a reduced diffusion of heat from the surface making the deep ocean largely colder and lifting the isotherms relatively to cont evidently the amount of energy used for mixing but also its distribution vertically and horizontally plays a major role in setting the thermocline structure in agreement with earlier studies such as bryan 1987 samelson 1998 melet et al 2016 3 2 forced experiments we now turn to the forced simulations with changed wind stress resulting diffusivities ssts and thermocline structure are similar as for the coupled simulations not shown and will not be discussed further as the focus of the forcing experiments is how the ocean responds to changes in forcing as can be seen in fig 1 the wind stress for p 1 5 peaks at almost 0 2 n m2 compared to 0 13 for p 1 0 this change in wind stress alters the wind stress curl over the southern ocean and forces increased ekman driven upwelling for p 0 the wind stress curl is zero and the corresponding ekman driven upwelling is zero the residual meridional overturning circulations rmoc from here on simply moc defined as the sum of the eulerian mean and the eddy induced overturning stream functions for the atlantic amoc and indo pacific pmoc calculated as the global moc subtracted the amoc minimum overturning north of 35s averaged over the last 10 model years are listed in table 2 the amoc strength at 26 n is plotted in fig 7 contf has an amoc strength of 15 7 sv after 300 years and 15 8 sv after 500 years compared to 13 5 sv at both times in idef suggesting that although not nearly equilibrated the model is stable enough for our purposes also the weaker amoc seen in the coupled runs is also reflected in the forced runs as with coupled runs shallow north atlantic boundary layer depths in ide suggest a reduced production of north atlantic deep water to be the cause of this as can be seen increasing decreasing winds results in an initial quick response where the amoc increases decreases over the first 30 years after this initial transient response a more gradual increase decrease follows the initial relative increase in amoc strength in contf15 is 9 after 30 years of perturbation and by the end in year 500 the amoc strength has increased by 18 for idef15 relative to idef the values are 12 and 24 respectively correspondingly for p 0 0 the values of contf00 relative to contf are a 16 and 26 decrease in amoc strength and for idef00 the decrease corresponds to 18 and 31 relative to idef it follows that the relative sensitivity towards changing wind stress is larger in simulations with the olbers and eden 2013 parameterization whereas the absolute values are comparable the pmoc for the six experiments is plotted in fig 8 along with the average depth of the σ θ 27 7 kg m 3 isopycnal the relative increase in strength of the upwelling pmoc in table 2 for idef00 is 194 and the relative reduction in idef15 is 17 for contf00 and contf15 these numbers are 106 and 27 respectively the absolute changes in pmoc in experiments with p 0 compares roughly to the strength of the amoc in the corresponding runs thus as in jochum and eden 2015 simulations without any wind stress over the southern ocean yield an enhanced upwelling in the indo pacific which at least in part compensates the missing upwelling in the southern ocean and sustains an amoc at least for several centuries following the beginning of the wind stress perturbation the 27 7 kg m 3 isopycnal shoals 200 300 m in the pacific and deepens in the southern ocean in both experiments with p 0 compared to simulations with p 1 flattening and shallowing the isopycnal for p 1 5 the isopycnal steepens over the southern ocean and deepens by up to 200 m at 40 s and about 100 m north of this latitude thus while the relative changes in stream function are different with the two parameterizations the impact of the winds on the pycnocline depth is very similar in the two cases thus despite diffusivities depending on the stratification the indo pacific overturning response in idef simulations is in absolute sense comparable to the response in contf simulations 4 summary and discussion three coupled ocean atmosphere and sea ice including a sensitivity run and six forced ocean sea ice simulations have been carried out to assess the impact of the vertical mixing parameterization idemix olbers and eden 2013 in the ocean component of ccsm4 the coupled simulations cont ide and the sensitivity study ieddy are run for 500 years and the forced contf and idef are run for 300 years at which time wind stress perturbations over the southern ocean are performed and simulations are run for 200 years more it has been shown that the way in which the dissipation of energy is localized globally impacts the ocean state and related climate in agreement with earlier studies such as samelson 1998 melet et al 2013 the most prominent differences occur in setting the thermocline depth reduced thermocline diffusivities cause less heat to be mixed downward causing a sharper and shallower thermocline consistent with other studies melet et al 2016 the relationship between thermocline structure and diffusivities implies that large differences in heat and carbon storage can occur over long timescales depending on the mixing parameterization something that is left for future studies to assess for the coupled simulations minor changes are observed in the ssts and precipitation fields the representation of precipitation and ssts in ide is worse than in cont however compared to the already existing biases in cont the differences between ide and cont are small also the overall climate state is very comparable in the two runs the sst differences in ide are adding to already existing biases which implies that with improved parameterizations of vertical mixing the biases might be reduced the benguela upwelling system is one area in the model with an already existing bias that gets worse in ide the nature of the bias has been studied and is thought to be a result of several processes xu et al 2014 harlaßet al 2015 in particular vertical mixing has been suggested to be one of the contributing mechanisms in generating temperature biases in pop2 xu et al 2014 our results support this hypothesis and suggest that either energy forcing or propagation is not adequately represented in the region it is also possible that a more realistic description of vertical mixing enhances the sst bias because a previous compensation with other model errors is relaxed the same holds for other model biases highlighting the need for more careful representation of vertical mixing in climate models while the errors in surface fields are larger in ide than cont in some areas idemix is developed from physical principles whereas the existing parameterization uses the background mixing to match diffusivities to observations which may not hold in studies of paleoclimate or future predictions it is furthermore interesting to note that while both simulations are missing energy sources from e g mesoscale eddies the contribution from these is easily implemented as forcing terms in idemix if one can calculate the energy transfer to the internal wave field whereas the existing model requires a new parameterization for each energy source that needs to be included using idemix the problem is reduced to the investigation of how and where energy enters the internal wave field eden et al 2014 the large amount of grid points with diffusivities below 10 6 m2 s 1 in ide seen in fig 2 and in the left panel of fig 3 may not be realistic but suggest that more energy forcing to the internal wave field is needed our sensitivity study ieddy is preliminary but indicates that adding energy sources in idemix might indeed bring the simulation closer to observed estimates of dissipation rates in the thermocline and thus improve climate simulations however this requires careful treatment of each individual source of internal wave energy for instance for coarse resolution ocean models tidal energy may be put in too deep in the water column which might in turn affect overturning strengths schmittner and egbert 2014 other improvements might be found by separate treatment of low mode internal waves eden and olbers 2014 finally the present results show that trapped waves and their dissipation in the banda sea is not well represented in the current parameterization of idemix it is not clear how such waves which are unresolved in climate models and their associated dissipation should be parameterized and implemented in idemix but as with the case of the banda sea these are of climatic importance and other areas might exist where similar wave dissipation is important in setting the mixing strength with regards to the forced simulations we find that the relative importance of the southern ocean wind stress on amoc strength is larger in idef than contf whereas absolute changes are similar it is therefore likely that the difference in relative importance of winds is a result of the changed background state and its associated weaker amoc observed in idef both parameterizations find a similar compensation in the indo pacific when the wind stress is shut off over the southern ocean in agreement with jochum and eden 2015 a key difference compared to their results is that without wind stress the amoc is declining toward a weak state whereas they found the amoc to be independent of the wind stress however the nature of forced ocean ice experiments do not allow for atmospheric feedbacks which might modify this result rahmstorf and england 1997 acknowledgments this study was supported by the danish council for independent research natural sciences 4002 00397 simulations were done with support from the high performance computing centre at the university of copenhagen the authors would also like to thank eric kunze for fine structure estimates of internal wave dissipation and nils brüggemann and dirk olbers for helpful comments 
24103,an energetically consistent vertical mixing parameterization in ccsm4 søren b nielsen a markus jochum a carsten eden b roman nuterman a a climate and computational geophysics niels bohr institute university of copenhagen juliane maries vej 30 copenhagen 2100 denmark climate and computational geophysics niels bohr institute university of copenhagen juliane maries vej 30 copenhagen 2100 denmark b institut für meereskunde university of hamburg germany institut für meereskunde university of hamburg germany corresponding author an energetically consistent stratification dependent vertical mixing parameterization is implemented in the community climate system model 4 and forced with energy conversion from the barotropic tides to internal waves the structures of the resulting dissipation and diffusivity fields are compared to observations and the fidelity of the resulting temperature fields is assessed compared to existing biases in the control simulation differences in surface fields are small showing that the surface climate state is relatively robust to the choice of mixing parameterization the thermocline structure however depends greatly on the details of the vertical mixing parameterizations where the new energetically consistent parameterization results in low thermocline diffusivities and a sharper and shallower thermocline it is also investigated if the ocean state is more sensitive to a change in forcing if the energetically consistent scheme is used compared to a tidal mixing parameterization with fixed background diffusivity in particular we find that the atlantic meridional overturning circulation is more sensitive to changes in the southern ocean wind stress with the former however in line with previous results changes to southern ocean upwelling are still largely compensated by changes to the diabatic upwelling in the indo pacific basin keywords diapycnal mixing numerical mixing parameterizations internal wave breaking 1 introduction mechanical energy is needed to return the deep waters that are formed at high latitudes to the surface see e g sandström 1908 it has been hypothesized that this mechanical energy is provided by the breaking of internal waves to small scale turbulence munk 1966 munk and wunsch 1998 this hypothesis has been supported by numerical studies bryan 1987 marotzke 1997 yet despite its importance small scale turbulence in the ocean interior is still represented through diffusivity fixed in time and space more recently this so called background diffusivity will be amplified near the bottom to mimic tidally induced mixing e g bryan and lewis 1979 st laurent et al 2002 however for large parts of the ocean away from the boundary layers the vertical diffusivity is dominated by the background diffusivity the value of this background diffusivity is obtained by a combination of observations and model optimization using spatially varying maps of diffusivity to match global observations rather than a constant global value has been shown to improve climate models harrison and hallberg 2008 jochum 2009 however while using a constant diffusivity can yield pre industrial or present day simulations in good agreement with observations the reliability of these parameterizations is questionable for different climate states the model of osborn 1980 suggests that vertical diffusivity κ is a function of locally dissipated energy from the internal wave field ϵ and the brunt väisälä frequency n 1 κ ϵ n 2 because both variables are likely to change as climate changes we expect changes in diffusivities and therefore in ocean circulation heat and carbon storage and uptake furthermore present tidal mixing parameterizations have problems of representing observed dissipation rates due to assumptions regarding the propagation and dissipation of internal wave energy waterhouse et al 2014 mackinnon et al 2017 kunze 2017 the focus of this study is how climate is affected when using an energetically consistent mixing parameterization rather than using fixed background diffusivities studies suggest that the parameterization of interior mixing affects the simulations of pre industrial climate e g jayne 2009 melet et al 2013 in particular changes in the localization of dissipation of internal wave energy has consequences in regions of deep water formation as well as for thermocline structure melet et al 2013 2016 previous studies mainly focus on steady state properties of the ocean here we perform a simple experiment to assess to what degree the ocean response to changed forcing is affected by the choice of parameterization the topic of interest for this experiment is the strength of the atlantic meridional overturning circulation amoc the amoc is a measure of the volume transport from the southern hemisphere to the northern often referred to as the ocean conveyor belt with sinking waters in the north atlantic being replaced by sub tropical surface waters through the gulf stream this circulation gives rise to an atlantic heat transport from the southern to the northern hemisphere the driving mechanisms of the amoc have been investigated and discussed throughout the last decades see e g the review by kuhlbrodt et al 2007 in particular buoyancy fluxes diapycnal mixing rates and southern ocean wind stress have all been suggested to play important or even dominating roles these also impact the strength of the antarctic circumpolar current acc gent et al 2001 several numerical studies have implicated a direct dependency of overturning to the value of diapycnal diffusivity bryan 1987 marotzke 1997 yet many studies require mixing values larger than observed to sustain the observed rate of overturning toggweiler and samuels 1995 polzin et al 1997 ledwell et al 1998 in the mid 1990 s it was pointed out that southern ocean winds and the sill at the drake passage were potentially dominating global ocean upwelling sometimes referred to as the drake passage effect toggweiler and samuels 1995 even near the limit of no vertical diffusion the drake passage effect was discovered to sustain an observed overturning toggweiler and samuels 1998 in a more recent study munday et al 2013 found the overturning to be less sensitive to wind forcing as horizontal resolution increased due to the explicit generation of southern ocean eddies although a sensitivity remained additionally the overturning was found to be sensitive to the choice of diapycnal diffusivity regardless of model resolution all these results were obtained by forcing an ocean model with prescribed buoyancy forcing in contrast to these studies jochum and eden 2015 found that in a realistic coupled climate model the amoc is robust to changes in southern ocean wind stress changes to southern ocean winds and upwelling are compensated by diabatic upwelling in the indo pacific basin their study however used a fixed vertical diffusivity so that changed mixing rates due to changed ocean stratification are not present possibly leading to an overestimation of the indo pacific compensation here we will revisit this idea and check if their results still hold if a fixed energy rather than a fixed diffusivity parameterization is used the paper is structured as follows in section 2 current ideas about diapycnal mixing and its parameterizations are briefly reviewed and an energetically consistent parameterization idemix olbers and eden 2013 and its implementation in an ocean model are described in section 3 the results of model simulations with the standard mixing parameterization and with idemix are compared in two sets three coupled simulations including a sensitivity study and six forced simulations comparing the response of the ocean to changes in the wind stress under the two different mixing schemes in section 4 the results are summarized and discussed in context to modeling climate and future prospects 2 methods 2 1 vertical mixing in ocean models diapycnal from here on simply vertical mixing in the ocean in level coordinate ocean general circulation models is generally represented as a vertical diffusion of tracers this process represents the conversion of small scale turbulent kinetic energy into potential energy and is important in setting the global pycnocline structure munk 1966 it is often recognized that an average global value of 10 4 m2 s 1 is required to maintain the observed global stratification munk and wunsch 1998 the energy input needed to maintain the observed ocean stratification has been estimated to be approximately 2 terawatts tw partitioned between winds and tides munk and wunsch 1998 egbert and ray 2000 jayne and st laurent 2001 nycander 2005 wind energy enters the ocean through the work winds do on the surface ocean with a large fraction driving the time mean circulation eventually dissipating to mesoscale eddies and some through direct generation of near inertial waves niws see e g jochum et al 2013 of which only a fraction leaves the mixed layer energy from mesoscale eddies is lost through numerous processes including bottom and lateral friction and generation of lee waves over rough topography in a similar way as tidal energy loss nikurashin and ferrari 2010 estimates of dissipation and diffusivity from argo float fine structure measurements support the relationship between vertical mixing and dissipation of barotropic tides as well as geostrophic motions whalen et al 2012 pollmann et al 2017 with the recognition of the importance of tides and their signature bottom enhanced mixing parameterizations have been developed for tidally induced mixing near the bottom one such parameterization is the one by st laurent et al 2002 this parameterization calculates a bottom enhanced diffusivity based on the local energy flux from tides to internal waves taken from the model of tidal dissipation by jayne and st laurent 2001 by assuming that a fraction q of the energy that is locally converted from barotropic to internal tides is dissipated locally through a vertical distribution function which ensures bottom enhanced mixing whereas the remaining energy radiates away and contributes to background mixing for details see simmons et al 2004 jayne 2009 the mathematical expression becomes 2 κ κ b q γ e f t x y f z ρ n 2 where κb is the background diffusivity γ 0 2 is the mixing efficiency and q 1 3 is the fraction of the energy flux from barotropic tides to internal waves e f t that dissipates locally with the local dissipation being distributed vertically by an exponential decay function f z and ρ being the density one key uncertainty is the fixed vertical decay scale f z for the dissipation of internal wave energy this choice often does not match observations kunze 2017 and it has been shown that the choice of a vertical dissipation profile is important for setting the ocean state melet et al 2013 furthermore the globally constant value of locally dissipated energy in eq 2 q relies on sparse observations and there is little justification that one value is representative of the entire ocean waterhouse et al 2014 recent work has now provided a theoretical background to take a step in parameterizing small scale turbulence through directly computed values for dissipated energy as described below 2 2 idemix a recent paper proposes the model internal wave dissipation energy and mixing idemix olbers and eden 2013 to be implemented in a global ocean model although extensions to the model have been developed eden and olbers 2014 we will here use the first version as described in olbers and eden 2013 due to the simplicity and as the main focus is how the ocean and climate responds when the vertical mixing is defined from a constant energy flux compared to a fixed background diffusivity in space and time through a set of assumptions and simplifications idemix calculates the total internal wave energy e as well as the dissipation of internal wave energy ϵ iw e is calculated by solving a single differential equation obtained from the spectral radiation balance of a weakly interacting wave field 3 e t z c 0 τ v c 0 e z h v 0 τ h h v 0 e ϵ i w s where the second and third terms on the l h s are the vertical and horizontal transport of e respectively s represents the sum of local sources of internal wave energy idemix has been discussed in several papers already olbers and eden 2013 eden et al 2014 eden and olbers 2014 pollmann et al 2017 and will therefore only be summarized briefly here in order to arrive at eq 3 upward and downward propagating waves are first treated separately and the wave energy is integrated over all wave numbers in each vertical wave number half space equations for the sum of energy e and difference δe of the two half spaces are then simplified by assuming approximate symmetry in vertical wave number m and that nonlinear wave wave interactions work to eliminate δe through an exponential relaxation with decay scale τv the wave speed is also assumed to have the same value for the upward and downward propagating waves c 0 the value of c 0 can be found by assuming a garrett munk gm like internal wave energy spectrum the third term on the l h s of eq 3 represents the lateral propagation of energy with v 0 a horizontal average group velocity and τh a relaxation time for horizontal anisotropies similar to τv the model is closed on the r h s of eq 3 by setting 4 ϵ i w μ 0 f e m 2 n 2 e 2 which represents the energy flux at high vertical wavenumber a combination of calculations of mccomas and müller 1981 heyney et al 1986 with m the bandwidth in vertical wavenumber and μ 0 a constant mccomas and müller 1981 finally f e f arccosh n f the dissipation of energy is then related to a vertical diffusivity through the osborn 1980 model 5 κ δ 1 δ ϵ i w n 2 δ 1 δ μ 0 f e e 2 c 2 n 2 where the relation m n c is used with c 1 j π h 0 n z d z with j the modal bandwidth of the gm model 2 3 model and implementation eq 3 is implemented in the ocean component of the community climate system model 4 ccsm4 gent et al 2011 the parallel ocean program pop2 danabasoglu et al 2012 following the implementation of eden et al 2014 with the parameter values suggested by olbers and eden 2013 μ 0 4 3 δ 0 2 j 10 τ v 1 day and τ h 10 days first eq 3 is solved with a tri diagonal solver without the lateral propagation term which is then added explicitly to the solution afterwards diffusivities obtained through eq 5 are capped at a minimum of 10 7 m2 s 1 molecular level and a maximum of 10 2 m2 s 1 a total of 9 experiments are carried out using the coarse resolution version of ccsm4 shields et al 2012 the ocean component uses a horizontal nominal 3 resolution with 60 vertical layers of increasing thickness in the surface layers are 10 m thick ranging to several hundred meters in the deepest ocean first a coupled control simulation using the t31 3 configuration cont is run for 500 years using a latitudinal dependent background diffusivity 0 01 cm2 s 1 at equator 0 3 cm2 s 1 at 30 n s and 0 17 cm2 s 1 elsewhere jochum 2009 with bottom enhanced diffusivity calculated from eq 2 this is then compared to a similar 500 year long run where the background and tidal induced diffusivities are replaced by the idemix module referred to as ide forced with only the conversion of barotropic to baroclinic tides using the same forcing as cont jayne and st laurent 2001 st laurent et al 2002 jayne 2009 analysis is carried out for the years 450 499 one extra sensitivity simulation ieddy includes an additional energy source from mesoscale eddies as calculated from the simple dissipation form of eden and greatbatch 2008 where mesoscale eddy energy is converted to internal wave energy by 6 ϵ e d d y 0 1 l 2 σ 3 with l being the minimum of the first baroclinic rossby radius of deformation and the rhines scale and σ f u z n is the eady growth rate this parameterization of eddy forcing adds energy to the internal waves everywhere in the ocean in particular near eddying currents such as the acc western boundary currents and the tropics see e g fig 1d of eden et al 2009 eddy forcing of idemix can be implemented in different ways eden et al 2014 here we choose the simplest form of local injection in eq 3 this may not be the ideal implementation but the reasoning behind the simulation is to see what effect adding more energy to the parameterization has not how the choice of injection optimizes the simulations here we refer the reader to eden et al 2014 pollmann et al 2017 the background for the sensitivity experiment comes from the fact that idemix falls short of explaining observed dissipation rates without mesoscale eddy forcing pollmann et al 2017 however as cont is only forced with tidal forcing the main comparison experiment ide is also forced with tides only for an energetically consistent implementation the eddy forcing should be calculated from the used thickness diffusivity in our simulations calculated according to danabasoglu and marshall 2007 other ways to implement other energy would be from estimates of lee wave energy fluxes nikurashin and ferrari 2011 melet et al 2014 our implementation compares with the horizontal structure of such estimates the choice of eq 6 is based on the simplicity from the fact that it is already directly implemented in pop2 eden and greatbatch 2008 eden et al 2009 ieddy will be used only when discussing adding extra forcing to the idemix parameterization note that the simple additional energy source by eq 6 is most likely an overestimation of the effect of eddies as discussed in eden et al 2014 in order to revisit the indo pacific upwelling discussed by jochum and eden 2015 a set of three ocean ice simulations with corev2 normal year forcing large and yeager 2004 with a sea surface salinity restoring timescale of one month are performed for both parameterizations of mixing each set consists of a 500 year control simulation contf and idef each control simulation is accompanied by branched runs from year 300 one where winds over the southern ocean south of 35 s are shut off by multiplying the wind stress with a value p 0 contf00 and idef00 and one where the southern ocean winds are increased by 50 by setting p 1 5 contf15 and idef15 between 35 and 25 s p is reduced linearly to 1 the wind profiles are depicted in fig 1 each branch is run for 200 years the forced simulation are analyzed for years 490 499 the model setups are summarized in table 1 reducing the background diffusivity in simulations using idemix comes with the risk of making the model more prone to numerical noise but this has been found only to pose issues in marginal seas e g the baltic and caspian seas which only span few grid points and are not connected to the major basins in the coarse resolution pop2 for which reason the background diffusivities in these basins are set to the same value in idemix simulations as in the control simulations section 3 first considers the coupled simulations and response in climate and then deals with the two sets of forced simulations 3 results 3 1 coupled simulations we begin by assessing the differences between the two coupled simulations cont and ide beginning with the diffusivities followed by the differences in climatology global maps of the diffusivities in this case only background diffusivities and tidal mixing as calculated by eq 2 in cont and diffusivities as calculated by eqs 3 and 5 in ide are presented in fig 2 averaged over three depth intervals 0 2 1 km 1 2 km and 2 4 km the upper 200 m have been excluded because mixed and boundary layer diffusivities in ide contaminate the signal of the thermocline structure due to the low stratifications within these the pattern of bottom enhanced diffusivity due to topography is the same for the two simulations at all depths this is expected as both parameterizations have the same tidal energy induced at the same bottom cells the difference is in how the energy is distributed globally as only 1 3 of the energy is dissipated locally in cont and the rest is not considered but assumed to contribute to the background diffusivity whereas ide injects all the energy and distributes it through eq 3 cont is largely characterized by the latitudinal dependent background diffusivity jochum 2009 whereas ide is characterized strongly by the bottom topography and displays a more heterogeneous diffusivity pattern the diffusivities have been observed to be heterogeneous whalen et al 2012 pollmann et al 2017 although the pattern here does lack much of the observed structure likely due to only using tidal energy as forcing in all depth intervals ide has large regions of reduced diffusivities compared to cont in the upper layer the three major basins all have smaller diffusivities in ide than cont showing a tendency for very small thermocline diffusivities however regions of larger diffusivities are also present which is particularly connected to regions of weak stratification in the high latitudes and over rough topography between 1 2 km in the equatorial band the pacific and the south australia basin have lower diffusivities than the imposed background level in cont which is also valid for the 2 4 km interval these regions are associated with abyssal plains with very low tidal energy input to the internal waves the diffusivities close to rough topography on the other hand are generally the same magnitude or somewhere even larger in ide this suggests that more energy is dissipated locally or at least very close to injection in ide than the 1 3 used in cont and that the horizontal propagation of e is very weak compared to the vertical propagation term and the dissipation the left panel of fig 3 shows the distribution of grid points with a specific diffusivity it is evident that where cont has a very narrow peak around diffusivities just above 10 5 m2 s 1 ide has a more broad distribution of diffusivities but also has distinct peaks at the two cut off ends of the spectrum note that there is almost an order magnitude more points at the higher end of the spectrum in ide than cont due to the global dependency on stratification throughout the water column and not just near the bottom which increases the diffusivity greatly in the surface layers within the mixed layer the histogram also displays that a large number of grid points in ide have diffusivities smaller than in cont from fig 2 we can infer that these points are in particular located in the tropics and sub tropics over abyssal plains and are not only confined to the deep ocean but also the upper parts of the ocean below the mixed and boundary layers on the right panel of fig 3 globally averaged profiles of the diffusivities are plotted solid lines indicate diffusivities over rough topography defined here as bathymetry slopes larger than 0 01 and dashed lines indicate diffusivities over smooth topography only water columns with depths greater than 500 m are included this shows that cont has up to an order magnitude larger diffusivities than ide in the very deep ocean over smooth topography this is a result of the deep ocean points which have very little injection of tidal energy in the abyssal plains causing many points to be of small magnitude in ide see fig 2 in the deep ocean in contrast to the rather large background diffusivity in cont between 1 4 km depth the two models have very similar global profiles in the upper 200 m the stratification dependency in ide shows up in very large diffusivities the global power consumption to raise the potential energy due to vertical mixing is estimated as the global integral 7 p v κ ρ b z d v where b g δ ρ ρ 0 is buoyancy which yields a total of 0 26 tw for cont of which 0 12 tw is dissipated below 500 m and 0 30 tw for ide of which only 0 08 tw is dissipated below a depth of 500 m the vertical distribution of dissipated energy per unit volume divided by the density of water yielding the dissipation per unit mass is shown in fig 4 for cont black and ide red along with a global composite of fine structure estimates kunze 2017 magenta line the dashed red curve is calculated directly from eq 4 whereas solid curves are calculated by dividing the integrand of eq 7 with the mixing efficiency this estimate is derived as no direct estimate of dissipation is calculated in cont unstably stratified grid points are omitted as assumptions for fine structure as well as parameterizations are not valid under these conditions as can be seen using diffusivity and stratification to derive the dissipation in ide solid red underestimates the amount of dissipation calculated by eq 4 dashed red both parameterizations show too much dissipation in the deep regions of the ocean and in particular at mid depth but dissipation in cont is more in line with observations above 1 km where the dissipation rate in ide is too small and does not resemble fine structure estimates that both models have too much dissipation in the deep ocean suggests too much deep dissipation of tidal energy for ide discrepancies with observations might be related to either a poor representation of propagation of energy or missing energy sources in the upper ocean to investigate the latter the sensitivity study ieddy has been carried out where conversion of mesoscale eddy energy to internal wave energy is added in eq 3 the resulting dissipation profile from eq 4 is added in fig 4 as the dashed blue line it is seen that eddy energy forcing increases the interior dissipation rates in particular in the upper 2 km a different choice of implementation of mesoscale eddy dissipation may alter this distribution but this is beyond the scope of this study it should be noted that the fine structure estimates sample mostly the major ocean basins whereas the model estimates are global averages furthermore the uncertainty is large in the deep ocean where observations are sparse kunze 2017 the average amoc strength at 26 n is 14 3 sverdrups 1 sv 106 m3 s 1 for cont and 13 4 sv for ide thus the different dissipation in ide is accompanied by a weaker amoc this may be a reflection in changed mixing in waters associated with deep water formation melet et al 2016 although the amoc reduction is not necessarily a direct result of the mixing parameterization but could be due to feedbacks in buoyancy or wind forcing from the atmosphere however wintertime convection depths in the north atlantic are shallower in ide than cont suggesting the amoc reduction to be caused by reduced production of north atlantic deep water not shown changes in the surface fields are generally small fig 5 shows the sea surface temperature sst difference between ide and cont note that cont has several biases discussed in shields et al 2012 the most prominent ones being related to the western boundary currents and the upwelling regions such as the benguela system west of southern africa where the amplitude of the biases are larger in ide than cont the root mean squared error rmse for cont is 1 67 and somewhat larger for ide with a rmse of 1 90 reduced to 1 80 in ieddy not shown superimposed on the upper panel of fig 5 is the 15 sea ice concentration lines for cont black and ide red the two lines almost coincide with ide having a slightly more northward extent of sea ice in the southern ocean and a slightly more southward extent in the bering sea the north atlantic sea ice extent is comparable but sea ice concentrations are greater within parts of the ocean in ide most remarkably in the baffin bay not shown the sea ice extent is already too large in cont shields et al 2012 but is stable within the two parameterization schemes the lower panel of fig 5 shows the precipitation difference between ide and cont differences are confined to the tropics two major patterns are visible the first is an increase in precipitation in the double itcz seen over the pacific and atlantic these changes are rather small and related to the modest increase in sst in the upwelling regions the biggest change occurs over the indian ocean and the indonesian seas related to a difference in sst in the same region this precipitation pattern is related to the diffusivity in the banda sea region jochum and potemra 2008 in cont this region has enhanced background vertical diffusivity made to match observations of a large tidally induced mixing in the region which causes a reduction in the sst which heavily influences precipitation this mixing is not captured in ide which may either be due to a too low energy input from tides or in the way the energy propagates into the region in the idemix parameterization fig 6 shows the meridional distribution of temperature difference between the two simulations overlaid with contours 5 c intervals from cont dashed ide solid and world ocean atlas 2009 woa locarnini et al 2010 dotted a large difference in the simulations is in the thermocline ide has a sharper and shallower thermocline which causes temperatures to be cooler between 100 and 1000 m depth this is seen in particular in the waters between 5 and 15 c which are shallower in ide compared to both cont and observations causing the temperature stratification to be in less agreement with observations at mid depth however ide is closer to observations seen in the close agreement with the observed 5 c isotherm the rest of the global ocean has temperature differences with amplitude less than 0 5 c the large differences between cont and ide occur in the upper km which is also the region of the largest discrepancy in dissipated energy in fig 4 and in the region of small diffusivities in the pacific and atlantic causing a reduced diffusion of heat from the surface making the deep ocean largely colder and lifting the isotherms relatively to cont evidently the amount of energy used for mixing but also its distribution vertically and horizontally plays a major role in setting the thermocline structure in agreement with earlier studies such as bryan 1987 samelson 1998 melet et al 2016 3 2 forced experiments we now turn to the forced simulations with changed wind stress resulting diffusivities ssts and thermocline structure are similar as for the coupled simulations not shown and will not be discussed further as the focus of the forcing experiments is how the ocean responds to changes in forcing as can be seen in fig 1 the wind stress for p 1 5 peaks at almost 0 2 n m2 compared to 0 13 for p 1 0 this change in wind stress alters the wind stress curl over the southern ocean and forces increased ekman driven upwelling for p 0 the wind stress curl is zero and the corresponding ekman driven upwelling is zero the residual meridional overturning circulations rmoc from here on simply moc defined as the sum of the eulerian mean and the eddy induced overturning stream functions for the atlantic amoc and indo pacific pmoc calculated as the global moc subtracted the amoc minimum overturning north of 35s averaged over the last 10 model years are listed in table 2 the amoc strength at 26 n is plotted in fig 7 contf has an amoc strength of 15 7 sv after 300 years and 15 8 sv after 500 years compared to 13 5 sv at both times in idef suggesting that although not nearly equilibrated the model is stable enough for our purposes also the weaker amoc seen in the coupled runs is also reflected in the forced runs as with coupled runs shallow north atlantic boundary layer depths in ide suggest a reduced production of north atlantic deep water to be the cause of this as can be seen increasing decreasing winds results in an initial quick response where the amoc increases decreases over the first 30 years after this initial transient response a more gradual increase decrease follows the initial relative increase in amoc strength in contf15 is 9 after 30 years of perturbation and by the end in year 500 the amoc strength has increased by 18 for idef15 relative to idef the values are 12 and 24 respectively correspondingly for p 0 0 the values of contf00 relative to contf are a 16 and 26 decrease in amoc strength and for idef00 the decrease corresponds to 18 and 31 relative to idef it follows that the relative sensitivity towards changing wind stress is larger in simulations with the olbers and eden 2013 parameterization whereas the absolute values are comparable the pmoc for the six experiments is plotted in fig 8 along with the average depth of the σ θ 27 7 kg m 3 isopycnal the relative increase in strength of the upwelling pmoc in table 2 for idef00 is 194 and the relative reduction in idef15 is 17 for contf00 and contf15 these numbers are 106 and 27 respectively the absolute changes in pmoc in experiments with p 0 compares roughly to the strength of the amoc in the corresponding runs thus as in jochum and eden 2015 simulations without any wind stress over the southern ocean yield an enhanced upwelling in the indo pacific which at least in part compensates the missing upwelling in the southern ocean and sustains an amoc at least for several centuries following the beginning of the wind stress perturbation the 27 7 kg m 3 isopycnal shoals 200 300 m in the pacific and deepens in the southern ocean in both experiments with p 0 compared to simulations with p 1 flattening and shallowing the isopycnal for p 1 5 the isopycnal steepens over the southern ocean and deepens by up to 200 m at 40 s and about 100 m north of this latitude thus while the relative changes in stream function are different with the two parameterizations the impact of the winds on the pycnocline depth is very similar in the two cases thus despite diffusivities depending on the stratification the indo pacific overturning response in idef simulations is in absolute sense comparable to the response in contf simulations 4 summary and discussion three coupled ocean atmosphere and sea ice including a sensitivity run and six forced ocean sea ice simulations have been carried out to assess the impact of the vertical mixing parameterization idemix olbers and eden 2013 in the ocean component of ccsm4 the coupled simulations cont ide and the sensitivity study ieddy are run for 500 years and the forced contf and idef are run for 300 years at which time wind stress perturbations over the southern ocean are performed and simulations are run for 200 years more it has been shown that the way in which the dissipation of energy is localized globally impacts the ocean state and related climate in agreement with earlier studies such as samelson 1998 melet et al 2013 the most prominent differences occur in setting the thermocline depth reduced thermocline diffusivities cause less heat to be mixed downward causing a sharper and shallower thermocline consistent with other studies melet et al 2016 the relationship between thermocline structure and diffusivities implies that large differences in heat and carbon storage can occur over long timescales depending on the mixing parameterization something that is left for future studies to assess for the coupled simulations minor changes are observed in the ssts and precipitation fields the representation of precipitation and ssts in ide is worse than in cont however compared to the already existing biases in cont the differences between ide and cont are small also the overall climate state is very comparable in the two runs the sst differences in ide are adding to already existing biases which implies that with improved parameterizations of vertical mixing the biases might be reduced the benguela upwelling system is one area in the model with an already existing bias that gets worse in ide the nature of the bias has been studied and is thought to be a result of several processes xu et al 2014 harlaßet al 2015 in particular vertical mixing has been suggested to be one of the contributing mechanisms in generating temperature biases in pop2 xu et al 2014 our results support this hypothesis and suggest that either energy forcing or propagation is not adequately represented in the region it is also possible that a more realistic description of vertical mixing enhances the sst bias because a previous compensation with other model errors is relaxed the same holds for other model biases highlighting the need for more careful representation of vertical mixing in climate models while the errors in surface fields are larger in ide than cont in some areas idemix is developed from physical principles whereas the existing parameterization uses the background mixing to match diffusivities to observations which may not hold in studies of paleoclimate or future predictions it is furthermore interesting to note that while both simulations are missing energy sources from e g mesoscale eddies the contribution from these is easily implemented as forcing terms in idemix if one can calculate the energy transfer to the internal wave field whereas the existing model requires a new parameterization for each energy source that needs to be included using idemix the problem is reduced to the investigation of how and where energy enters the internal wave field eden et al 2014 the large amount of grid points with diffusivities below 10 6 m2 s 1 in ide seen in fig 2 and in the left panel of fig 3 may not be realistic but suggest that more energy forcing to the internal wave field is needed our sensitivity study ieddy is preliminary but indicates that adding energy sources in idemix might indeed bring the simulation closer to observed estimates of dissipation rates in the thermocline and thus improve climate simulations however this requires careful treatment of each individual source of internal wave energy for instance for coarse resolution ocean models tidal energy may be put in too deep in the water column which might in turn affect overturning strengths schmittner and egbert 2014 other improvements might be found by separate treatment of low mode internal waves eden and olbers 2014 finally the present results show that trapped waves and their dissipation in the banda sea is not well represented in the current parameterization of idemix it is not clear how such waves which are unresolved in climate models and their associated dissipation should be parameterized and implemented in idemix but as with the case of the banda sea these are of climatic importance and other areas might exist where similar wave dissipation is important in setting the mixing strength with regards to the forced simulations we find that the relative importance of the southern ocean wind stress on amoc strength is larger in idef than contf whereas absolute changes are similar it is therefore likely that the difference in relative importance of winds is a result of the changed background state and its associated weaker amoc observed in idef both parameterizations find a similar compensation in the indo pacific when the wind stress is shut off over the southern ocean in agreement with jochum and eden 2015 a key difference compared to their results is that without wind stress the amoc is declining toward a weak state whereas they found the amoc to be independent of the wind stress however the nature of forced ocean ice experiments do not allow for atmospheric feedbacks which might modify this result rahmstorf and england 1997 acknowledgments this study was supported by the danish council for independent research natural sciences 4002 00397 simulations were done with support from the high performance computing centre at the university of copenhagen the authors would also like to thank eric kunze for fine structure estimates of internal wave dissipation and nils brüggemann and dirk olbers for helpful comments 
24104,wave hindcasts are tools to study climate and are regularly used in offshore and coastal engineering applications the growing number of wind datasets and reanalysis products create more opportunity for generating wave hindcasts each wind dataset or reanalysis product has different resolution model implementation and assimilation scheme and if the wave model implementation is not calibrated to the input wind field the resulting wave field can have large biases solely due to the wind in this work we calibrate the wind to wave growth parameter within the spectral wave model wavewatch iii for 10 reanalysis datasets and 2 datasets composed of merged satellite observations the calibration is performed globally by minimizing the differences between altimeter wave height observations and the model output for the year of 2001 we place special emphasis on ensuring the largest sea states are well captured and are not underestimated because of the important engineering applications of these data after the calibration we compare the datasets and find each product reproduces the average sea states similarly but high sea states have large discrepancies we demonstrate that the space time distribution of the extreme waves are very different even after calibration we summarize by providing recommendations of the most accurate wind datasets to generate wave hindcasts keywords wave hindcast wavewatch iii wave climate cowclip extreme waves reanalysis inter comparison 1 introduction understanding the wave climate is essential to understanding integrated ocean atmosphere wave interactions and mitigating damages caused by ocean surface waves the design of structures in offshore and coastal regions is still largely based on data generated from wave hindcasts this is due to the fact that they have high time and space resolution are of high fidelity and some are openly available e g rascle and ardhuin 2013 chawla et al 2013 perez et al 2017 in remote areas with limited in situ and remote sensing observations wave hindcasts are an attractive option to understand the wave climate variability stopa et al 2016b thomson et al 2016 there are uncertainties in the input wind fields and these impact the wave field for example the noted overestimation of the wind speeds in the southern ocean before 1994 creates distinct positive biases in the wave field chawla et al 2013 rascle and ardhuin 2013 stopa and cheung 2014 wave hindcasts are typically generated using reanalysis datasets because they are evenly spaced in time and have high resolution there have been many successful implementations of reanalysis driven wave hindcasts e g cox and swail 2001 caires and sterl 2005 chawla et al 2013 rascle and ardhuin 2013 perez et al 2017 there are a growing number of accurate wind products creating more opportunity for generating wave hindcasts reanalysis assimilates observations into models which sometimes consist of atmospheric oceanic land and ice models and generate evenly distributed global data the first notable release of a comprehensive reanalysis dataset started with the national center for environmental prediction ncep reanalysis 1 r1 kalnay et al 1996 the european center for medium range weather forecasts ecmwf 15 year and 40 year reanalyzes era15 era40 uppala et al 2005 and the japanese meteorological agency s jma 25 year reanalysis jra25 onogi et al 2007 followed suit with improvements these efforts established best practices to collect manage and archive observations that are the backbone of the reanalysis products kistler et al 2001 now most weather centers have released updated and improved reanalysis versions the ncep the climate forecast system cfsr 1979 present versions 1 and 2 saha et al 2010 2014 the ecmwf era interim erai 1979 present dee et al 2011 the jma 55 year jra55 1958 present kobayashi et al 2015 and the nasa modern era retrospective analysis for research and applications v2 merra gelaro et al 2017 many of these datasets start in 1979 with the modern satellite era or when global radiosonde observations were established in 1958 in addition there are reanalysis datasets that are constrained by atmospheric pressure observations to recreate the entire 20th century such as the cooperative institute for research in environmental sciences cires r20c compo et al 2011 and the ecmwf era20c stickler et al 2014 with the large amount of satellite wind observations from scatterometers and radiometers collected in the last 25 years there have been efforts to create merged and gridded products at regular time intervals atlas et al 2011 bentamy et al 2016 as improvements to models computing power increases and better quality satellite observations become available it is expected that there will be continued efforts to generate reanalysis products every 5 to 10 years therefore there are many options to generate wave hindcasts and there needs to be continual efforts to assess these products and their suitability to generate wave hindcasts e g caires et al 2004 stopa and cheung 2014 each wind dataset has different space time resolution and the reanalysis datasets have different physical parameterizations assimilation schemes and assimilate different observations all of these aspects change the characteristics of the surface wind field and when used to force a model will generate different wave fields to introduce this idea probability density functions pdf and quantile quantile qq plots are given in fig 1 for the near surface wind speed u10 and the significant wave height hs using several of the noted datasets it is clear the u10 pdfs are different especially for high wind speeds 25 ms 1 when using the same wave model implementation as in fig 1 d e f the generated wave field may not be consistent with wind forcing e g r20c has no occurrences of u10 35 ms 1 but has the largest sea states the details of these plots will be discussed throughout the manuscript our first goal is to demonstrate that some biases in the wave field can be corrected by calibrating the wave model parameterization to the input wind field since the wave field is a smoothed version of the atmosphere it is unclear how each of the differences in the forcing wind fields impact the wave field therefore after calibration we compare the output wave fields to understand their differences we place special emphasis on high sea states and provide recommendations of more accurate products to drive a wave hindcast the manuscript is organized as follows in section 2 we describe the datasets various reanalysis products and wave model implementation used to create 1 year wave hindcasts in section 3 we calibrate the wave model parameterization to the different wind datasets by comparing hs to satellite altimeters for 2001 in section 4 we compare the 12 different calibrated one year hindcasts to understand their behavior our recommendations and conclusions follow in section 5 2 datasets and model implementation in this section we describe the satellite and buoy observations input wind fields and model implementation 2 1 observations merged altimeter dataset and moored buoys the multi platform altimeter product abbreviated alt herein is quality controlled and calibrated between platforms and to moored buoys queffeulou and croize fillon 2015 in this work we chose the year of 2001 for the analysis since all datasets overlapped during this period in 2001 there are three altimeter platforms in orbit european remote sensing 2 ers2 1996 2011 topex poseidon tpx 1993 2005 and geosat follow on gfo 2000 2007 the multi mission dataset is calibrated between platforms and thus we expect it to be a fairly homogeneous dataset since the 1 hz altimeter measurements capture the instantaneous hs it is an unfair comparison with the time space averaged spectral wave model therefore we smooth the altimeter tracks for each platform within the wave model grid cell 0 5 by taking a running mean of 5 points since each platform has a spatial footprint of 7 10 km this dataset includes calibrated hs and u10 the national data buoy center ndbc provides quality controlled wave data from their network our model implementation is at the global scale 55 km so we chose buoys sufficiently far 30 km from the coastlines and located in deep water in total there are 32 buoys that met our criteria and they grouped by regions hawaii haw 51001 51002 51003 51004 north pacific nop 46001 46035 46066 northeast pacific nep 46002 46005 46006 46011 46012 46014 46022 46023 46025 46028 46042 2d 46047 46053 46054 46059 46063 gulf of mexico gom 42001 d 42002 2d 42003 2d 42039 2d 42040 2d northwest atlantic nwa 41001 41002 41010 44004 only a select number of buoys have frequency direction spectra 2d available for comparison to the wave model as noted above see fig 7 a for their locations which are limited to the northern hemisphere near the united states coastlines the frequency direction wave spectra are created using the maximum entropy method mem earle et al 1999 the highest frequency adequately resolved by the buoys is 0 4 hz the model spectra are interpolated in time and space to match the buoy observations 2 2 forcing fields wind and sea ice datasets in the following subsections we will briefly describe the model forcing datasets used in this study consisting of reanalysis and merged satellite products reanalysis assimilate various in situ and satellite observations using the same assimilation method and model settings some reanalysis assimilate data in 4 dimensions 4d var x y z t e g dee et al 2011 while others use 3 dimensions 3d var x y z for an initialization time step followed by a short forecast typically 6h e g saha et al 2010 most of the reanalysis datasets with the exception of cfsr have prescribed sea ice concentrations from external sources such as radiometers and sea surface temperatures e g dee et al 2011 hirahara et al 2014 we summarize pertinent information below and in table 1 the readers are referred to each of the references for detail on each product 2 2 1 ncep r1 the ncep r1 was the first long term reanalysis and has been used in a wide array of studies kalnay et al 1996 kistler et al 2001 this product starts in 1949 and continues to update the time series using the same model and assimilation scheme the atmospheric model is spectral and uses a spherical grid spacing the spatial resolution in atmospheric models is commonly specified by t followed by a number r1 has a resolution of t62 210 km which indicates spectral triangular truncation at wavenumber 62 with a linear grid r1 uses 3d var 2 2 2 ecmwf era40 era40 is based on its predecessor era15 developed at ecmwf and uses 3d var uppala et al 2005 this system has a truncated gaussian atmospheric model t159 n80 nominally 140 km these data were re gridded onto a regularly spaced longitude latitude grid using a spline interpolation this system includes a wave model which assimilates satellite altimeter observations but this does not affect our independent hindcasts 2 2 3 jma jra25 jma25 is the first long term atmospheric reanalysis produced by jma onogi et al 2007 it uses the jma assimilation system and observations from satellites from centers world wide including the national climatic data center nodc and ecmwf the atmospheric model resolution is t106 125 km and uses 3d var ice concentrations were included using the special sensor microwave imager ssmi and scanning multichannel microwave radiometer smmr 2 2 4 ncep cfsr the ncep cfsr is a global coupled system composed of atmosphere ocean land and ice models and begins with the modern satellite era 1979 2010 v1 saha et al 2010 the atmospheric resolution is 38 km t382 and uses 3d var initialized every 6 h version 2 starts in 2011 and has shown improvement in the product especially in the tropical regions with increased resolution 22 km t574 saha et al 2014 cfsr uses 3d var with assimilations being updated every 6 h cfsr is the only reanalysis product that has a dynamic sea ice model it uses the elastic viscous model of hunke and dukowicz 1997 2 2 5 ecmwf erai the ecmwf erai improved atmospheric model and assimilation system compared to its predecessor era40 dee et al 2011 erai established the 4d var assimilation scheme used in reanalysis the atmospheric model is 76 km t255 this system contains a coupled wave atmosphere component and the wave model assimilates altimeter observations 2 2 6 jma jra55 jra55 is the jma second official release of a reanalysis starting in 1958 when the use of global radiosondes were established kobayashi et al 2015 this product improves many of the aspects for jra25 by implementing 4d var with variational bias correction for satellite radiances including a new radiation scheme and introducing greenhouse gases that vary with time the atmospheric resolution is 62 km t319 a notable impact to wave modeling is the inclusion of an embedded parametric model to best capture the intensity of the tropical cyclones using information for the best track database it captures 95 of the events murakami 2014 2 2 7 nasa merra v2 the merra v2 called merra herein is a nasa reanalysis that uses the goddard earth observing system data assimilation system geos rienecker et al 2011 gelaro et al 2017 one of the original goals of the project v1 was to simulate the hydrological cycle correctly rienecker et al 2011 the latest release of the product improves many aspects including the model observing system data radiance assimilation and the boundary conditions for sea surface temperature and sea ice concentration based on reynolds et al 2002 the atmospheric resolution is 55 70 km and uses 3d var with assimilations being updated every 6h 2 2 8 cires r20c the noaa cooperative institute for research in environmental sciences cires climate diagnostics center led an effort to produce a reanalysis dataset spanning the entire 20th century assimilating only surface observations of air pressure and boundary conditions observed from monthly sea surface temperature and sea ice concentration compo et al 2006 2011 r20c has been extended to 1851 and has an advantage of not being subject to changes in the quality or quantity of data assimilated in the modern era this reanalysis applies a kalman filter for each 6 h analysis pressure field 3d var with an atmospheric model of 200 km t62 2 2 9 ecmwf era20c the ecmwf follows r20c practices and created a reanalysis for the 20th century stickler et al 2014 in addition to atmospheric pressure surface winds are assimilated into the reanalysis it includes a coupled land and ocean wave model the resolution is 125 km t159 and uses a 4d var assimilation scheme which is input approximately at 210 km 2 2 10 ncar cfdda the national center for atmospheric research ncar climate four dimensional data assimilation system cfdda established a method to downscale a mesoscale model hahmann et al 2010 ncar produced a 21 year 1985 2005 reanalysis based on the ncep reanalysis 2 r2 kanamitsu et al 2002 the mesoscale model mm5 is implemented at 40 km resolution using 4d var we chose to include this reanalysis to give insights on using downscaling through a mesoscale model also it uses a 4d var instead of the other ncep products which use 3d var 2 2 11 rss ccmp v2 remote sensing systems rss produced a cross calibrated multi platform ccmp gridded surface vector winds at regularly spaced time interval 6 h atlas et al 2011 data is combined from 7 radiometer missions 2 scatterometer missions quikscat ascat moored buoys and atmospheric models using a variational analysis method to produce global maps at 0 25 27 km the most recent release v2 uses updated satellite observations compared to its predecessor atlas et al 2011 we use sea ice concentrations from radiometers produced by institut francais pour la recherche et lexploitation de la mer ifremer making the forcing fields completely derived by satellite observations the ice coverage is produced by using a transfer equation that relates the polarization difference to ice concentration kaleschke et al 2001 the daily sea ice concentrations have an original spatial resolution of 12 5 km covering both poles this dataset was used in an arctic wave hindcast and captures the daily ice features well stopa et al 2016b 2 2 12 ifremer sct ifremer created a merged satellite product consisting of radiometers and scatterometers from 1992 to 2016 bentamy et al 2016 desbiolles et al 2017 this product includes wind vectors from ifremer ers 1 and ers 2 nasa quikscat and eumetsat ascat a ascat b and radiometers from rss ssm i ssmis and windsat the use of ancillary data sources such as radiometer data ssmi ssmis windsat and erai has enabled a blended product available at spatial resolution and every 6 h with spatial resolution of 0 25 27 km by using optimal interpolation and kriging methods note that data contained in either ccmp or sct has also been assimilated into the reanalysis datasets with the exclusion of r20c and era20c indeed ccmp and sct use the same datasets but the geophysical model functions which relate the measured mean radar cross section to u10 are different ccmp uses the rss gmf s which are expected to be more accurate for high wind speeds e g ricciardulli and wentz 2015 we use the sea ice concentration dataset produced by ifremer as input like ccmp 2 3 model implementation the wave datasets are generated using wavewatch iii version 5 16 abbreviated ww3 herein ww3 integrates the spectral wave action equation in space and time with discretized wave numbers and directions conservative wave processes like propagation represented by the local rate of change and spatial and spectral transport terms are balanced by the nonconservative sources and sinks we implement the same global model setup as rascle and ardhuin 2013 the model has a spatial grid of 0 5 in longitude and latitude covering 78 s 80 n and 0 e 360 e with spectra composed of 24 directions and 32 frequencies exponentially spaced from 0 037 to 0 7 hz at an increment of 10 obstructions such as islands smaller than the spatial resolution are accounted by apportioning the energy in the x and y directions chawla and tolman 2008 the nonlinear wavewave interactions are modeled using the discrete interaction approximation dia of hasselmann et al 1985 dissipation due to bottom friction uses the showex formulation to parameterize sandy bottoms here with a constant sand grain size of 0 2 mm ardhuin et al 2003 the ultimate quickest third order propagation scheme is implemented along with garden sprinkler reduction tolman 2002 all model simulations are forced with the listed wind fields and sea ice concentrations in table 1 we implement physical formulations that describe the wind input and dissipation of ardhuin et al 2010 this package of physical parameterizations performs well especially in terms of higher order moments of the wave spectrum and treatment of swell stopa et al 2016a one major advance when using this package is its treatment of swell which is described by a laminar to turbulent boundary within the atmosphere and was formulated and calibrated by tracking swells from synthetic aperture radar ardhuin et al 2009 stopa et al 2016c the wind input is adapted from the janssen 1991 formulation with an important reduction of input at high frequencies necessary to achieve a balance with the whitecapping term the original formulation from janssen 1991 is written in terms of the wave action n k θ for each wavenumber k and direction θ 1 s i n k θ β m a x ρ a ρ w 1 κ 2 e z z 4 u c z α 2 cos p i n θ θ u σ n k θ where ρ a w are the atmosphere and water densities κ is the von karman constant pin is a constant that controls the directional distribution of sin σ is the wave frequency zα is a wave age dependent tuning parameter u is the friction velocity and z is a parameterized sea surface roughness the term βmax is a non dimensional growth parameter that controls the wind to wave growth in this work we modify βmax to reduce the overall significant wave height bias it is expected that other variables such as the roughness length zα or even parameters in the dissipation source term could be modified to reduce the errors associated with different wind forcing 3 calibration and validation in the following each wind dataset is optimally calibrated and then each 1 year hindcast is compared to the altimeter and buoy observations to establish their performance our goal is to establish the optimal βmax that reduces the global sea state errors for the 0 5 model implementation there is a distinct seasonality in the hs ratios model altimeter as shown in chawla et al 2013 therefore we use a 1 year hindcast to avoid any over fitting that would occur if a particular month or season was used the year 2001 is used since all datasets overlap during this period there are 3 altimeter platforms in operation and it is the middle of the modern reanalysis period from 1979 to 2016 3 1 calibration as briefly discussed in the introduction in fig 1 there are notable differences of the wind products the u10 pdfs have similar shapes and the pdf maximum is within 6 to 8 ms 1 fig 1 a for upper wind speeds u10 25 ms 1 there are distinct differences and the maximum u10 ranges from 24 to 43 ms 1 the lower spatial resolution products era40 era20c r1 have less occurrences of high wind speeds which is expected since they cannot resolve the fine scale features the high resolution mesoscale model implemented by cfdda has lower wind speeds near the mean and upper wind speeds relative to the other products and altimeters fig 1 b r20c with its 210 km spatial resolution consistently has higher wind speeds in the range 20 u10 26 ms 1 compared to the altimeters in fig 1 b near the u10 average most datasets are shifted to the left of the altimeter the geophysical model function gmf relates the measured satellite normalized radar cross section nrcs of the altimeter to estimate u10 when waves are present this 1 parameter fit can result in an overestimation of u10 gourrion et al 2002 the u10 from alt deviates from all other products near the 5th through 30 percentile it is expected that this systematic over estimation of the derived u10 from altimeters at low wind speeds causes the shift in the pdf relative to the other datasets the cause of the overestimated u10 from altimeters under light wind speeds 4 ms 1 could be due to specular reflection of the nadir looking altimeter and or sea state impact to the radar cross section notice that when u10 8 ms 1 cfsr ccmp and sct more closely match the observations the same data is plotted in qq plots in fig 1 c it is clear most products have reduced wind speeds relative to the altimeters in the range 3 10 ms 1 and when u10 12 ms 1 the products begin to deviate from each other with the most drastic deviation when u10 20 ms 1 cfsr and ccmp perform well with their u10 within 0 5 ms 1 of the altimeter observations even at the 99th percentile the growth parameter βmax is arbitrarily set to 1 45 for all hindcasts in fig 1 d e f there are some consistent features between the u10 and hs pdfs the coarser spatial resolution products r1 era40 jra25 era20c erai also have lower hs in fig 1 d the shapes of the pdfs are similar and the mean is within 1 5 2 2 m cfdda has a higher occurrence of small wave heights while r20c has the lowest occurrence of small wave heights when hs 1 5 m when hs 5 6 m r20c systematically has the largest probability relative to all other hindcasts even though ccmp and sct both incorporate data from scatterometers they use different gmfs and these differences are clearly seen in the wave heights when comparing to the altimeters fig 1 e most datasets follow the features seen in the winds and the pdfs are shifted the left of the altimeters close to the average sea states 1 hs 2 2 m we have more confidence in the hs from altimeters so most of the forcing wind products might indeed have difficulties in estimating calm wind speeds which also contributes to the differences observed in the u10 pdfs fig 1 b the calm winds located in the tropics are expected to have larger uncertainties saha et al 2014 the qq plot fig 1 f shows a wide range of the wave heights from the hindcasts so simply using the same βmax for every input wind dataset results in a wide range of hs errors for the highest sea states hs 10 m the 99 9 percentile r1 era40 erai era20c underestimate hs and jra55 ccmp and r20c overestimate hs when βmax 1 45 using cfsr as an example βmax is varied and the corresponding hs pdfs and qq plots co located with alt are given in fig 2 it is clear that larger values of βmax result in taller wave heights our goal is to optimally determine the value for βmax where the hs pdfs output from the wave model and the altimeter observations best align the optimal βmax is determined for each dataset by searching the entire space of βmax which is typically within 1 0 2 1 with the exception of cfdda we require the 50 percentile p50 and p99 of the significant wave height are well matched between the hindcasts and the altimeters 0 1 m p 50 99 w w 3 h s p 50 99 a l t h s 0 1 m and require that p99 does not underestimate hs this second criteria is due to the important engineering applications of capturing the extreme wave heights in general we place more emphasis on capturing the largest sea states often at the expense of moderate seas in this example fig 2 the hindcast using βmax 1 385 best matches the p50 p99 and the upper wave heights hs 10 m in the qq plot fig 2 b βmax 1 385 closely fits the bisector line in fig 3 we objectively adjust βmax to determine the optimal value to reduce hs residuals of the p50 and p99 these plots show βmax x axis versus various percentile differences ww3 alt and the root means square error the coarser resolution products such as r1 era40 era20c have optimal performance when βmax is larger 1 7 on the other hand the higher resolution products such as cfsr ccmp and sct have lower values for βmax but in general this is not a rule since r20c with 210 km spatial resolution has an optimal performance when βmax is close to 1 10 an ideal behavior is when all percentiles intersect with negligible residual this means the pdfs are well matched for all sea states therefore era40 cfsr erai ccmp and sct all have good agreement with the altimeters for the majority of the sea states the only datasets which do not match our criteria of having hs residuals 10 cm are r20c and cfdda for r20c the median hs residual is underestimated by 12 cm and the p99 hs residual overestimated by 15 cm for cfdda we chose β m a x 2 55 because the rmse has a very subtle minimum we tested larger values of βmax up to 3 5 to get a better match of the extreme seas but the pdfs did not resemble the altimeter observations clearly this dataset is not suitable to drive a wave hindcast these plots can be used to understand how to calibrate the models for different applications for example to study the average sea states different criteria can be implemented it is important to reinforce the fact that these charts are valid for the spatial resolution of 0 5 and applicable for a global implementation models with different spatial resolution and coverage will need refinement and possible re calibration 3 2 validation the optimal βmax values are given in table 2 and are chosen from fig 3 here we summarize the overall performance of the 12 1 year hindcasts that use different wind forcing we compute standard error metrics the bias root mean square error rmse scatter index si and slope of the linear regression see stopa et al 2016a for equations there are clear differences in the performance of the older reanalysis datasets r1 era40 jr25 and cfdda compared to the recent reanalysis datasets cfsr erai jra55 and merra the older reanalysis r1 era40 jra25 cfdda have higher rmses and sis of 0 43 m and 15 compared to 0 41 m and 15 for more recent reanalysis cfsr erai jra55 and merra the 20th century reanalysis datasets r20c and era20c perform worse than the other reanalysis datasets both r20c and era20c have similar error metrics r20c underestimates the hs but has slightly better match of the linear regression slope both of the merged satellite observation datasets ccmp and sct perform well with rmse 35 cm and si 13 we generate similar error metrics for the extreme sea states hs 10 m the values are provided in parenthesis in table 2 the performance of all hindcasts degrade at the extremes all hindcasts have hs rmses that exceed 1 m and some have biases that underestimate hs by at least 1 5 m such as r1 cfdda r20c era20c the hindcasts that best capture the largest waves are cfsr merra ccmp and sct shown by the rmses 1 5 m and linear regression slopes between 0 88 and 1 14 erai is a precise forcing wind field si 10 but underestimates the largest heights as reported by others rascle and ardhuin 2013 stopa and cheung 2014 cfdda is out of the reasonable range and significantly underestimates the largest waves the pdfs and qq plots are given in fig 4 after calibration to complement fig 1 now the hs pdfs fig 4 a b closely resemble each other and the altimeter observations with the exception of cfdda at the extreme sea states the lower resolution products r1 era20c era40 still have reduced probability relative to the others and altimeter observations the qq plots are relatively close for all products and deviate less than 0 5 m up hs 8 4 m p99 5 notice we calibrated βmax at p99 and required all products do not underestimate hs at the largest quantile shown p99 9 the hs range is about 1 m between products often in engineering and oceanographic applications other variables besides hs such as the wave period and direction are important we use the buoys from the ndbc network to compare hs average wave periods tm02 2 t m 02 m 0 m 2 where m i 0 037 0 4 2 π f i e f d f is a frequency f moment of the wave spectrum e and the average wave direction θavr 3 θ a v r a r c tan 0 037 0 4 0 2 π sin θ e f θ 0 037 0 4 0 2 π cos θ e f θ we truncate the integration of the buoys at 0 4 hz since beyond this frequency the data is often noisy we use the same frequency range in the wave model output to ensure a fair comparison between the computed parameters the results summarized in table 3 the rmses and sis are given for both the hs and tm02 for θavr the rmse is reported as well as the normalized standard deviation nstd 4 n s t d s t d θ a v r h i n d c a s t s t d θ a v r b u o y 1 100 where std is the standard deviation and the nstd is given in a percentage note that we are using circular mathematics for the θavr error metrics we see the hs rmses are typically between 0 2 and 0 6 m and the sis are between 9 and 37 for tm02 the rmses are between 0 7 and 1 7 s and the sis are typically between 6 and 20 nearly all the hindcasts have θavr rmses of 30 for the northeast pacific and 50 in the gulf of mexico therefore the directional components of the wave model need improvement similar to the findings of stopa et al 2016a the θavr nstds of the hindcasts are typically 0 to 43 less than the buoy observations this means the directional components are relatively smooth compared to the observations this is particularly true for the northeast pacific in the northeast pacific and gulf of mexico the hindcasts are performing the worst with the largest hs and tm02 rmses in the gulf of mexico the θavr rmses are large and possibly small scale atmospheric features are not well captured by the products notice erai has some of the lowest sis for both hs and tm02 demonstrating it is a precise forcing wind field cfsr systematically has the lowest rmses and sis for tm02 some other credible forcing fields are modern reanalyzes cfsr jra55 merra and the satellite datasets ccmp and sct the spatial view of the hindcast performances relative to alt are given in figs 5 and 6 for the normalized rmse nrmse and the si respectively these error metrics show the hindcasts accuracy and precision respectively the wave hindcasts are interpolated in space and time to match the altimeters and the error metrics are computed in 2 bins for each 1 year hindcast for the nrmse fig 5 it is clear that r1 r20c era20c and cfdda have worse performance compared to the other products since the nrmse is often 15 it is interesting to note that the older reanalysis datasets such as era40 and jra25 perform reasonably well once they are properly calibrated however their performance is worse than their successors erai and jra55 respectively jra55 has larger errors in the tropics compared to the other recent hindcasts cfsr erai and merra era20c and r20c have similar spatial patterns and clearly have improved performance in the northern hemisphere nh compared to the southern hemisphere sh this is expected since the majority of the pressure observations were recorded in the nh cfsr erai jra55 merra ccmp and sct all perform well ccmp has the best performance with approximately 68 of the oceans having a nrmse 8 the second best performance is sct with 65 of the oceans having a nrmse 8 for hindcasts driven by reanalyses csfr and merra and have best performance and have nrsmes less than 8 for 62 and 58 of the oceans respectively the corresponding plots for the si are given in fig 6 r1 cfdda r20c and er20c have worse performance than the other hindcasts with si 15 r20c and era20c have lower precision higher sis in the sh the sis are less than 10 in the majority of the oceans for cfsr erai jra55 merra ccmp and sct ccmp sct cfsr and merra are the top 4 best forcing fields with sis less than 10 for 87 86 82 and 79 of the oceans respectively in general all wave hindcasts have larger nrmses and sis that are typically 2 5 higher near the equator compared to surrounding regions in addition near the ice edge in the southern ocean all hindcasts have larger errors and these features are more pronounced in the older reanalysis products like r1 era40 and jra25 therefore either ice edge location and or the atmospheric models are performing better in the more recent reanalysis datasets cfsr erai jra55 merra 4 comparison and extremes to assess the different hindcasts we compute the average and standard deviation of different statistics from the ensemble fig 7 in this analysis we remove cfdda since this hindcast was not in the reasonable range compared to the observations the median in fig 7 a b shows the sh has larger sea states than the nh more importantly the variability shown by the standard deviation of these 11 hindcasts is typically less than 30 cm globally in fact 68 88 and 97 of the ocean has standard deviation less than 10 15 and 20 cm respectively note that in pacific near the equator there is a region with standard deviations of 10 to 20 cm and the hs p50 is only 1 5 m so this region has a large relative variability approx 15 compared to the extra tropics 5 for hs p95 fig 7 c d the nh and sh now have similar magnitudes with maximum in the indian ocean sector of the southern ocean the magnitude of hs p95 is relatively smooth and the standard deviation is mostly less than 20 cm specifically 64 90 and 97 of the ocean has standard deviations less than 20 30 and 40 cm respectively the maximum hs in fig 7 e f does not have a smooth pattern and impact from individual storms can be identified the standard deviation shows particular events can have very large hs differences exceeding 2 5 m in the lower latitudes the standard deviations of the hindcasts are less than 50 cm with the exception of tropical cyclone regions that are most notable in the western pacific and atlantic most of the variability is in the extra tropics and it is common to have standard deviations greater than 1 m the maximum hs differences come from variations in the magnitude of the forcing wind fields or space time deviations of the storm locations in short all hindcasts reproduce the average sea state conditions and have hs within 10 cm of each other even the hs p95 is well matched between hindcasts the largest sea states have greater variability between the hindcasts and these differences are quantified by calculating the occurrence of hs 10 m based on hourly data the results are presented in fig 8 it is clear that the extra tropics have the strongest and most persistent storms tropical cyclones can indeed breach this threshold but their occurrence is low compared to extra tropical events r1 era40 and jra25 have similar patterns jra25 has slightly larger waves in both hemispheres cfdda is not applicable to capture these high sea states and most of the ocean has hs 10 m cfsr erai jra55 and merra have similar spatial patterns erai has the least energy at high sea states and it is known that erai underestimates these conditions stopa and cheung 2014 in the sh cfsr has reduced seas compared to jra55 and merra in the nh merra and cfsr have similar occurrence of hs 10 m but jra55 has less occurrences of elevated seas r20c and era20c have similar patterns however r20c has more occurrences of elevated seas in the sh especially in the indian ocean and perhaps this is too high with respect to the other hindcasts ccmp and sct have nearly the same pattern with slightly more wave activity in sct notice the consistency between the products produced by the same centers ncep r1 csfsr r20c ecwmf era40 erai era20c and jma jra25 jra55 the recently released products have higher occurrence of elevated wave heights hs 10 m which is due to the fact that the spatial resolution increases physical parameterizations improve and satellite observations at extremes improve it is clear that the bulk statistics are different for the upper wave heights so two particular storms are analyzed to further highlight the differences the largest altimeter record for 2001 hs 16 m was recorded in a southern ocean extra tropical storm by gfo this storm from april 10 to april 13 traveled south of australia in the southern ocean fig 9 a as the storm intensified on april 10 at 17 00 the spatial patterns of the hs exceeding 9 m are different for each hindcast fig 9 c era40 has the smallest spatial coverage of hs 9 m at 1 6 105 km2 while most hindcasts jra25 cfsr erai r20c era20c and sct have areas with hs 9 m within 2 8 3 8 10 5 km2 r1 jr55 merra and ccmp have enhanced sea states with regions of hs 9 m exceeding 4 105 km2 and hs larger than 12 m notice that nearly all hindcasts have the storm in nearly the same position the exception is r1 which places the storm slightly ahead of the others when the storm is nearly at its peak intensity gfo crosses the storm center on april 12 at 03 45 the storm contours are given in fig 9 d and all hindcasts have the storm in the same position with the exception of r1 the spatial coverage of hs 9 m between hindcasts varies by 7 105 km2 with maximum being r20c and minimum era40 the altimeter observations in fig 9 b give insight to which models best capture the maximum hs and spatial extent of the storm waves it is confirmed that storm location in r1 is incorrect ignoring cfdda and r1 the hindcasts have the maximum hs ranging from 12 to 18 m for this event jra55 captures the maximum of the storm very well with only a small displacement to the south merra is the only hindcast that overestimates the peak of the event by 1 3 m in addition jra25 r20c era20c perform well and underestimate the altimeter hs of 16 4 m by 50 cm erai ccmp and sct moderately underestimate the peak hs by 1 2 m while cfsr and era40 unreasonably underestimates the peak hs by 3 m towards the end of the event on april 12 at 22 00 there is large variability in the spatial coverage of hs 9 m that exceeds 6 106 km2 between hindcasts fig 9 e some hindcasts fall below the hs threshold of 9 m and are not plotted the time evolution of the maximum hs and area of hs 9 m are given in fig 9 f g it is clear that towards the end of the storm there is more variability in the spatial distribution of the largest waves also notice that the hindcasts have maximum hs that vary from 4 to 8 m for the duration of the event in fig 7 f it is clear that regions affected by tropical cyclones have larger variability with hs standard deviations exceeding 2 m we pick the tropical cyclone utor in the western pacific near the philippines that occurred july 1 5 to demonstrate the large variability of the hindcasts under extreme tropical cyclone wind forcing this event is clearly seen in fig 7 c utor grazed the island of lazon in the philippines and then made landfall in southeast china on july 6 the cyclone overview is given in fig 10 a there was a tpx pass that intersected the storm center on july 3 07 11 the spatial distribution of the hs 8 m on july 2 is similar for the various hindcasts and the h s 8 m contours have a c pattern fig 10 c note that r1 has the storm in different location relative to the other hindcasts similar to the last case when tpx crosses the storm on july 3 in fig 10 b there is a large range of hs profiles merra overestimates hs and it is confirmed that the location of utor in r1 is mis located compared to the altimeter observations in this case erai best matches the tpx hs but with an underestimation of 1 m all other hindcasts era40 jra25 cfsr jra55 cfdda r20c era20c ccmp and sct underestimate the maximum hs of the event h s 11 2 m by 2 to 5 m the positions of the storm in era40 ccmp erai and merra are approximately correct since the hs profiles follow the tpx observations the spatial coverage of hs 8 m varies greatly between products 10 105 km2 fig 10 c d e g towards the end of the event and as the storm moves into the south china sea the spatial patterns of hs 8 m vary by 3 105 km2 fig 10 f g shows the time series of the maximum hs and storm area with hs 8 m it is clear that the maximum hs has a large variability between products of course some products like r20c and era20c are not specifically designed to capture the small scale features of tropical cyclones this particular example shows that the range in hs can be 8 m between the hindcasts therefore extreme caution should be used when using these hindcasts to understand extreme sea states especially for tropical cyclones 5 discussion and recommendations in this work we calibrated 12 different wind products by adjusting the βmax parameter that describes the wind to wave growth in the janssen 1991 formulation we demonstrate that modifying βmax reduces errors in the wave field this is due to the fact that each wind product has different characteristics this exercise was performed on a 0 5 global grid and we used altimeter observations as reference for the calibration then we compare the hindcasts to ndbc moored buoys to assess hs tm02 and θavr our procedure can be adapted to regional domains with different resolutions however one should take caution when applying this approach especially with a sufficiently small domain because βmax could be incorrectly compensating for missing or improper model parameterizations our criteria was to best match the hs pdfs and we ensured the largest sea states hs p99 are not underestimated we specifically summarize the advantages and disadvantages of each hindcast in table 4 and here we generalize the conclusions after calibration even the older reanalysis datasets such as r1 era40 and jra25 perform well with respect to bulk statistics our results clearly demonstrate that the more recent reanalysis wind fields from cfsr erai jra55 and merra are better forcing wind fields for wave hindcasting compared to their predecessors the ncep 4d var reanalysis that uses a mesoscale model cfdda is not suitable for wave hindcasting this wind forcing cannot capture the high sea states there is an extreme underestimation the 20th century reanalysis datasets r20c and era20c have similar performance these hindcasts do not perform as well as the higher resolution products and have less fidelity than the other hindcasts however it is important to note that they capture the magnitude of the extreme events especially in the extra tropics r20c and era20c poorly capture tropical cyclones the hindcasts driven by satellite observations ccmp and sct perform well and are as good if not better than the reanalysis products however their 6 h time step might not be sufficient for some cases such as rapidly intensifying storms the buoy comparison gives an independent check of the calibrated wave hindcasts the hs error metrics between the buoys and altimeters are similar however regional areas such as the northeast pacific and gulf of mexico have larger errors the rmses for the tm02 are typically 1 s and exceed 1 6 s in the gulf of mexico all wave hindcasts have similar performance for average wave directions which is most likely due to the same model source term parameterization and implementation of the dia in the gulf of mexico the θavr are poor with rmses of 50 suggesting model improvements are needed to better capture the directionality of the wave field all hindcasts have similar average sea states p50 and the variability between hindcasts is negligible 5 even up to the 95th percentile the variability between hindcasts is typically less than 10 the hindcasts deviate only at the largest sea states extra tropical storms are well captured by the hindcasts however the variability for the largest events and the occurrence of these events varies greatly between products for the example storms the maximum hs can exceed 6 m for a large extra tropical event and vary by 8 m for a tropical cyclone for practical applications it is important to understand that each forcing wind field will give very different results for high sea states using an ensemble approach such as this to study extreme events will help quantify some of the uncertainty in general it is clear that tropical cyclones are not well captured some of the reanalysis products are able to capture the tropical events better than others murakami 2014 hodges et al 2017 for wave hindcasting we recommend cfsr erai jra55 merra ccmp and sct for extreme waves cfsr jra55 merra ccmp and sct perform well in terms of bulk statistics however the case studies revealed that cfsr underestimated both of the peak hs events by 2 3 m on the other hand erai has the storm in the correct position but maximum hs was underestimated typically by 1 m erai reanalysis is one of the most precise forcing fields and the sis from wave parameters are typically the lowest jra55 matches the extreme waves very well and is expected to better capture tropical cyclones since they are blended into the product through use of a parametric model kobayashi et al 2015 murakami 2014 merra overestimates the largest waves of course βmax can be reduced but this affects the entire hs pdf see fig 3 a βmax 1 45 matches the peak hs of 16 4 and 11 1 m for the extra and tropical cases studies but the overall error metrics degraded and a global underestimation was observed not shown otherwise most of the hindcasts underestimate the extreme sea states for climate studies the consistency of the products in time is key and this is a topic of future work now with properly calibrated hindcasts this task can be performed more diligently in particular r20c and era20c might have the advantage of being less affected by changes in the quantity and quality of the assimilated data another critical point is the need for continual observations from scatterometers and radiometers which provide a tremendous resource for the community as the reanalysis products continually improve there is a need to assess their ability to reproduce the wave field through hindcasts additional and improved measurements of the winds and increased spatial resolution will provide further insights and explanations of regions with large uncertainties especially for high sea states acknowledgments this work is supported by labexmer via grant anr 10 labx 19 01 eu fp7 project swarp under grant agreement 607476 and onr grant number n0001416wx01117 i thank fabrice ardhuin and alexis mouche for their input of early versions of this work i appreciate the three anonymous reviewers for their comments that have improved this paper the altimeter dataset can be obtained from ftp ifremer fr ifremer cersat products swath altimeters waves the ifremer cersat ssmi daily ice concentrations are available from ftp ifremer fr ifremer cersat the ndbc buoy data can be accessed from www ndbc noaa gov the r1 jra25 era40 cfsr erai jra55 and cfdda wind fields and ice concentrations can be obtained from rda ucar edu merrav2 wind fields and ice concentration can be obtained from gmao gsfc nasa gov reanalysis merra 2 ccmpv2 is available via remote sensing systems ftp2 remss com ccmp the ifremer blended product of satellite wind observations sct is available ftp ifremer fr ifremer lops blended wind longterm analysis 
24104,wave hindcasts are tools to study climate and are regularly used in offshore and coastal engineering applications the growing number of wind datasets and reanalysis products create more opportunity for generating wave hindcasts each wind dataset or reanalysis product has different resolution model implementation and assimilation scheme and if the wave model implementation is not calibrated to the input wind field the resulting wave field can have large biases solely due to the wind in this work we calibrate the wind to wave growth parameter within the spectral wave model wavewatch iii for 10 reanalysis datasets and 2 datasets composed of merged satellite observations the calibration is performed globally by minimizing the differences between altimeter wave height observations and the model output for the year of 2001 we place special emphasis on ensuring the largest sea states are well captured and are not underestimated because of the important engineering applications of these data after the calibration we compare the datasets and find each product reproduces the average sea states similarly but high sea states have large discrepancies we demonstrate that the space time distribution of the extreme waves are very different even after calibration we summarize by providing recommendations of the most accurate wind datasets to generate wave hindcasts keywords wave hindcast wavewatch iii wave climate cowclip extreme waves reanalysis inter comparison 1 introduction understanding the wave climate is essential to understanding integrated ocean atmosphere wave interactions and mitigating damages caused by ocean surface waves the design of structures in offshore and coastal regions is still largely based on data generated from wave hindcasts this is due to the fact that they have high time and space resolution are of high fidelity and some are openly available e g rascle and ardhuin 2013 chawla et al 2013 perez et al 2017 in remote areas with limited in situ and remote sensing observations wave hindcasts are an attractive option to understand the wave climate variability stopa et al 2016b thomson et al 2016 there are uncertainties in the input wind fields and these impact the wave field for example the noted overestimation of the wind speeds in the southern ocean before 1994 creates distinct positive biases in the wave field chawla et al 2013 rascle and ardhuin 2013 stopa and cheung 2014 wave hindcasts are typically generated using reanalysis datasets because they are evenly spaced in time and have high resolution there have been many successful implementations of reanalysis driven wave hindcasts e g cox and swail 2001 caires and sterl 2005 chawla et al 2013 rascle and ardhuin 2013 perez et al 2017 there are a growing number of accurate wind products creating more opportunity for generating wave hindcasts reanalysis assimilates observations into models which sometimes consist of atmospheric oceanic land and ice models and generate evenly distributed global data the first notable release of a comprehensive reanalysis dataset started with the national center for environmental prediction ncep reanalysis 1 r1 kalnay et al 1996 the european center for medium range weather forecasts ecmwf 15 year and 40 year reanalyzes era15 era40 uppala et al 2005 and the japanese meteorological agency s jma 25 year reanalysis jra25 onogi et al 2007 followed suit with improvements these efforts established best practices to collect manage and archive observations that are the backbone of the reanalysis products kistler et al 2001 now most weather centers have released updated and improved reanalysis versions the ncep the climate forecast system cfsr 1979 present versions 1 and 2 saha et al 2010 2014 the ecmwf era interim erai 1979 present dee et al 2011 the jma 55 year jra55 1958 present kobayashi et al 2015 and the nasa modern era retrospective analysis for research and applications v2 merra gelaro et al 2017 many of these datasets start in 1979 with the modern satellite era or when global radiosonde observations were established in 1958 in addition there are reanalysis datasets that are constrained by atmospheric pressure observations to recreate the entire 20th century such as the cooperative institute for research in environmental sciences cires r20c compo et al 2011 and the ecmwf era20c stickler et al 2014 with the large amount of satellite wind observations from scatterometers and radiometers collected in the last 25 years there have been efforts to create merged and gridded products at regular time intervals atlas et al 2011 bentamy et al 2016 as improvements to models computing power increases and better quality satellite observations become available it is expected that there will be continued efforts to generate reanalysis products every 5 to 10 years therefore there are many options to generate wave hindcasts and there needs to be continual efforts to assess these products and their suitability to generate wave hindcasts e g caires et al 2004 stopa and cheung 2014 each wind dataset has different space time resolution and the reanalysis datasets have different physical parameterizations assimilation schemes and assimilate different observations all of these aspects change the characteristics of the surface wind field and when used to force a model will generate different wave fields to introduce this idea probability density functions pdf and quantile quantile qq plots are given in fig 1 for the near surface wind speed u10 and the significant wave height hs using several of the noted datasets it is clear the u10 pdfs are different especially for high wind speeds 25 ms 1 when using the same wave model implementation as in fig 1 d e f the generated wave field may not be consistent with wind forcing e g r20c has no occurrences of u10 35 ms 1 but has the largest sea states the details of these plots will be discussed throughout the manuscript our first goal is to demonstrate that some biases in the wave field can be corrected by calibrating the wave model parameterization to the input wind field since the wave field is a smoothed version of the atmosphere it is unclear how each of the differences in the forcing wind fields impact the wave field therefore after calibration we compare the output wave fields to understand their differences we place special emphasis on high sea states and provide recommendations of more accurate products to drive a wave hindcast the manuscript is organized as follows in section 2 we describe the datasets various reanalysis products and wave model implementation used to create 1 year wave hindcasts in section 3 we calibrate the wave model parameterization to the different wind datasets by comparing hs to satellite altimeters for 2001 in section 4 we compare the 12 different calibrated one year hindcasts to understand their behavior our recommendations and conclusions follow in section 5 2 datasets and model implementation in this section we describe the satellite and buoy observations input wind fields and model implementation 2 1 observations merged altimeter dataset and moored buoys the multi platform altimeter product abbreviated alt herein is quality controlled and calibrated between platforms and to moored buoys queffeulou and croize fillon 2015 in this work we chose the year of 2001 for the analysis since all datasets overlapped during this period in 2001 there are three altimeter platforms in orbit european remote sensing 2 ers2 1996 2011 topex poseidon tpx 1993 2005 and geosat follow on gfo 2000 2007 the multi mission dataset is calibrated between platforms and thus we expect it to be a fairly homogeneous dataset since the 1 hz altimeter measurements capture the instantaneous hs it is an unfair comparison with the time space averaged spectral wave model therefore we smooth the altimeter tracks for each platform within the wave model grid cell 0 5 by taking a running mean of 5 points since each platform has a spatial footprint of 7 10 km this dataset includes calibrated hs and u10 the national data buoy center ndbc provides quality controlled wave data from their network our model implementation is at the global scale 55 km so we chose buoys sufficiently far 30 km from the coastlines and located in deep water in total there are 32 buoys that met our criteria and they grouped by regions hawaii haw 51001 51002 51003 51004 north pacific nop 46001 46035 46066 northeast pacific nep 46002 46005 46006 46011 46012 46014 46022 46023 46025 46028 46042 2d 46047 46053 46054 46059 46063 gulf of mexico gom 42001 d 42002 2d 42003 2d 42039 2d 42040 2d northwest atlantic nwa 41001 41002 41010 44004 only a select number of buoys have frequency direction spectra 2d available for comparison to the wave model as noted above see fig 7 a for their locations which are limited to the northern hemisphere near the united states coastlines the frequency direction wave spectra are created using the maximum entropy method mem earle et al 1999 the highest frequency adequately resolved by the buoys is 0 4 hz the model spectra are interpolated in time and space to match the buoy observations 2 2 forcing fields wind and sea ice datasets in the following subsections we will briefly describe the model forcing datasets used in this study consisting of reanalysis and merged satellite products reanalysis assimilate various in situ and satellite observations using the same assimilation method and model settings some reanalysis assimilate data in 4 dimensions 4d var x y z t e g dee et al 2011 while others use 3 dimensions 3d var x y z for an initialization time step followed by a short forecast typically 6h e g saha et al 2010 most of the reanalysis datasets with the exception of cfsr have prescribed sea ice concentrations from external sources such as radiometers and sea surface temperatures e g dee et al 2011 hirahara et al 2014 we summarize pertinent information below and in table 1 the readers are referred to each of the references for detail on each product 2 2 1 ncep r1 the ncep r1 was the first long term reanalysis and has been used in a wide array of studies kalnay et al 1996 kistler et al 2001 this product starts in 1949 and continues to update the time series using the same model and assimilation scheme the atmospheric model is spectral and uses a spherical grid spacing the spatial resolution in atmospheric models is commonly specified by t followed by a number r1 has a resolution of t62 210 km which indicates spectral triangular truncation at wavenumber 62 with a linear grid r1 uses 3d var 2 2 2 ecmwf era40 era40 is based on its predecessor era15 developed at ecmwf and uses 3d var uppala et al 2005 this system has a truncated gaussian atmospheric model t159 n80 nominally 140 km these data were re gridded onto a regularly spaced longitude latitude grid using a spline interpolation this system includes a wave model which assimilates satellite altimeter observations but this does not affect our independent hindcasts 2 2 3 jma jra25 jma25 is the first long term atmospheric reanalysis produced by jma onogi et al 2007 it uses the jma assimilation system and observations from satellites from centers world wide including the national climatic data center nodc and ecmwf the atmospheric model resolution is t106 125 km and uses 3d var ice concentrations were included using the special sensor microwave imager ssmi and scanning multichannel microwave radiometer smmr 2 2 4 ncep cfsr the ncep cfsr is a global coupled system composed of atmosphere ocean land and ice models and begins with the modern satellite era 1979 2010 v1 saha et al 2010 the atmospheric resolution is 38 km t382 and uses 3d var initialized every 6 h version 2 starts in 2011 and has shown improvement in the product especially in the tropical regions with increased resolution 22 km t574 saha et al 2014 cfsr uses 3d var with assimilations being updated every 6 h cfsr is the only reanalysis product that has a dynamic sea ice model it uses the elastic viscous model of hunke and dukowicz 1997 2 2 5 ecmwf erai the ecmwf erai improved atmospheric model and assimilation system compared to its predecessor era40 dee et al 2011 erai established the 4d var assimilation scheme used in reanalysis the atmospheric model is 76 km t255 this system contains a coupled wave atmosphere component and the wave model assimilates altimeter observations 2 2 6 jma jra55 jra55 is the jma second official release of a reanalysis starting in 1958 when the use of global radiosondes were established kobayashi et al 2015 this product improves many of the aspects for jra25 by implementing 4d var with variational bias correction for satellite radiances including a new radiation scheme and introducing greenhouse gases that vary with time the atmospheric resolution is 62 km t319 a notable impact to wave modeling is the inclusion of an embedded parametric model to best capture the intensity of the tropical cyclones using information for the best track database it captures 95 of the events murakami 2014 2 2 7 nasa merra v2 the merra v2 called merra herein is a nasa reanalysis that uses the goddard earth observing system data assimilation system geos rienecker et al 2011 gelaro et al 2017 one of the original goals of the project v1 was to simulate the hydrological cycle correctly rienecker et al 2011 the latest release of the product improves many aspects including the model observing system data radiance assimilation and the boundary conditions for sea surface temperature and sea ice concentration based on reynolds et al 2002 the atmospheric resolution is 55 70 km and uses 3d var with assimilations being updated every 6h 2 2 8 cires r20c the noaa cooperative institute for research in environmental sciences cires climate diagnostics center led an effort to produce a reanalysis dataset spanning the entire 20th century assimilating only surface observations of air pressure and boundary conditions observed from monthly sea surface temperature and sea ice concentration compo et al 2006 2011 r20c has been extended to 1851 and has an advantage of not being subject to changes in the quality or quantity of data assimilated in the modern era this reanalysis applies a kalman filter for each 6 h analysis pressure field 3d var with an atmospheric model of 200 km t62 2 2 9 ecmwf era20c the ecmwf follows r20c practices and created a reanalysis for the 20th century stickler et al 2014 in addition to atmospheric pressure surface winds are assimilated into the reanalysis it includes a coupled land and ocean wave model the resolution is 125 km t159 and uses a 4d var assimilation scheme which is input approximately at 210 km 2 2 10 ncar cfdda the national center for atmospheric research ncar climate four dimensional data assimilation system cfdda established a method to downscale a mesoscale model hahmann et al 2010 ncar produced a 21 year 1985 2005 reanalysis based on the ncep reanalysis 2 r2 kanamitsu et al 2002 the mesoscale model mm5 is implemented at 40 km resolution using 4d var we chose to include this reanalysis to give insights on using downscaling through a mesoscale model also it uses a 4d var instead of the other ncep products which use 3d var 2 2 11 rss ccmp v2 remote sensing systems rss produced a cross calibrated multi platform ccmp gridded surface vector winds at regularly spaced time interval 6 h atlas et al 2011 data is combined from 7 radiometer missions 2 scatterometer missions quikscat ascat moored buoys and atmospheric models using a variational analysis method to produce global maps at 0 25 27 km the most recent release v2 uses updated satellite observations compared to its predecessor atlas et al 2011 we use sea ice concentrations from radiometers produced by institut francais pour la recherche et lexploitation de la mer ifremer making the forcing fields completely derived by satellite observations the ice coverage is produced by using a transfer equation that relates the polarization difference to ice concentration kaleschke et al 2001 the daily sea ice concentrations have an original spatial resolution of 12 5 km covering both poles this dataset was used in an arctic wave hindcast and captures the daily ice features well stopa et al 2016b 2 2 12 ifremer sct ifremer created a merged satellite product consisting of radiometers and scatterometers from 1992 to 2016 bentamy et al 2016 desbiolles et al 2017 this product includes wind vectors from ifremer ers 1 and ers 2 nasa quikscat and eumetsat ascat a ascat b and radiometers from rss ssm i ssmis and windsat the use of ancillary data sources such as radiometer data ssmi ssmis windsat and erai has enabled a blended product available at spatial resolution and every 6 h with spatial resolution of 0 25 27 km by using optimal interpolation and kriging methods note that data contained in either ccmp or sct has also been assimilated into the reanalysis datasets with the exclusion of r20c and era20c indeed ccmp and sct use the same datasets but the geophysical model functions which relate the measured mean radar cross section to u10 are different ccmp uses the rss gmf s which are expected to be more accurate for high wind speeds e g ricciardulli and wentz 2015 we use the sea ice concentration dataset produced by ifremer as input like ccmp 2 3 model implementation the wave datasets are generated using wavewatch iii version 5 16 abbreviated ww3 herein ww3 integrates the spectral wave action equation in space and time with discretized wave numbers and directions conservative wave processes like propagation represented by the local rate of change and spatial and spectral transport terms are balanced by the nonconservative sources and sinks we implement the same global model setup as rascle and ardhuin 2013 the model has a spatial grid of 0 5 in longitude and latitude covering 78 s 80 n and 0 e 360 e with spectra composed of 24 directions and 32 frequencies exponentially spaced from 0 037 to 0 7 hz at an increment of 10 obstructions such as islands smaller than the spatial resolution are accounted by apportioning the energy in the x and y directions chawla and tolman 2008 the nonlinear wavewave interactions are modeled using the discrete interaction approximation dia of hasselmann et al 1985 dissipation due to bottom friction uses the showex formulation to parameterize sandy bottoms here with a constant sand grain size of 0 2 mm ardhuin et al 2003 the ultimate quickest third order propagation scheme is implemented along with garden sprinkler reduction tolman 2002 all model simulations are forced with the listed wind fields and sea ice concentrations in table 1 we implement physical formulations that describe the wind input and dissipation of ardhuin et al 2010 this package of physical parameterizations performs well especially in terms of higher order moments of the wave spectrum and treatment of swell stopa et al 2016a one major advance when using this package is its treatment of swell which is described by a laminar to turbulent boundary within the atmosphere and was formulated and calibrated by tracking swells from synthetic aperture radar ardhuin et al 2009 stopa et al 2016c the wind input is adapted from the janssen 1991 formulation with an important reduction of input at high frequencies necessary to achieve a balance with the whitecapping term the original formulation from janssen 1991 is written in terms of the wave action n k θ for each wavenumber k and direction θ 1 s i n k θ β m a x ρ a ρ w 1 κ 2 e z z 4 u c z α 2 cos p i n θ θ u σ n k θ where ρ a w are the atmosphere and water densities κ is the von karman constant pin is a constant that controls the directional distribution of sin σ is the wave frequency zα is a wave age dependent tuning parameter u is the friction velocity and z is a parameterized sea surface roughness the term βmax is a non dimensional growth parameter that controls the wind to wave growth in this work we modify βmax to reduce the overall significant wave height bias it is expected that other variables such as the roughness length zα or even parameters in the dissipation source term could be modified to reduce the errors associated with different wind forcing 3 calibration and validation in the following each wind dataset is optimally calibrated and then each 1 year hindcast is compared to the altimeter and buoy observations to establish their performance our goal is to establish the optimal βmax that reduces the global sea state errors for the 0 5 model implementation there is a distinct seasonality in the hs ratios model altimeter as shown in chawla et al 2013 therefore we use a 1 year hindcast to avoid any over fitting that would occur if a particular month or season was used the year 2001 is used since all datasets overlap during this period there are 3 altimeter platforms in operation and it is the middle of the modern reanalysis period from 1979 to 2016 3 1 calibration as briefly discussed in the introduction in fig 1 there are notable differences of the wind products the u10 pdfs have similar shapes and the pdf maximum is within 6 to 8 ms 1 fig 1 a for upper wind speeds u10 25 ms 1 there are distinct differences and the maximum u10 ranges from 24 to 43 ms 1 the lower spatial resolution products era40 era20c r1 have less occurrences of high wind speeds which is expected since they cannot resolve the fine scale features the high resolution mesoscale model implemented by cfdda has lower wind speeds near the mean and upper wind speeds relative to the other products and altimeters fig 1 b r20c with its 210 km spatial resolution consistently has higher wind speeds in the range 20 u10 26 ms 1 compared to the altimeters in fig 1 b near the u10 average most datasets are shifted to the left of the altimeter the geophysical model function gmf relates the measured satellite normalized radar cross section nrcs of the altimeter to estimate u10 when waves are present this 1 parameter fit can result in an overestimation of u10 gourrion et al 2002 the u10 from alt deviates from all other products near the 5th through 30 percentile it is expected that this systematic over estimation of the derived u10 from altimeters at low wind speeds causes the shift in the pdf relative to the other datasets the cause of the overestimated u10 from altimeters under light wind speeds 4 ms 1 could be due to specular reflection of the nadir looking altimeter and or sea state impact to the radar cross section notice that when u10 8 ms 1 cfsr ccmp and sct more closely match the observations the same data is plotted in qq plots in fig 1 c it is clear most products have reduced wind speeds relative to the altimeters in the range 3 10 ms 1 and when u10 12 ms 1 the products begin to deviate from each other with the most drastic deviation when u10 20 ms 1 cfsr and ccmp perform well with their u10 within 0 5 ms 1 of the altimeter observations even at the 99th percentile the growth parameter βmax is arbitrarily set to 1 45 for all hindcasts in fig 1 d e f there are some consistent features between the u10 and hs pdfs the coarser spatial resolution products r1 era40 jra25 era20c erai also have lower hs in fig 1 d the shapes of the pdfs are similar and the mean is within 1 5 2 2 m cfdda has a higher occurrence of small wave heights while r20c has the lowest occurrence of small wave heights when hs 1 5 m when hs 5 6 m r20c systematically has the largest probability relative to all other hindcasts even though ccmp and sct both incorporate data from scatterometers they use different gmfs and these differences are clearly seen in the wave heights when comparing to the altimeters fig 1 e most datasets follow the features seen in the winds and the pdfs are shifted the left of the altimeters close to the average sea states 1 hs 2 2 m we have more confidence in the hs from altimeters so most of the forcing wind products might indeed have difficulties in estimating calm wind speeds which also contributes to the differences observed in the u10 pdfs fig 1 b the calm winds located in the tropics are expected to have larger uncertainties saha et al 2014 the qq plot fig 1 f shows a wide range of the wave heights from the hindcasts so simply using the same βmax for every input wind dataset results in a wide range of hs errors for the highest sea states hs 10 m the 99 9 percentile r1 era40 erai era20c underestimate hs and jra55 ccmp and r20c overestimate hs when βmax 1 45 using cfsr as an example βmax is varied and the corresponding hs pdfs and qq plots co located with alt are given in fig 2 it is clear that larger values of βmax result in taller wave heights our goal is to optimally determine the value for βmax where the hs pdfs output from the wave model and the altimeter observations best align the optimal βmax is determined for each dataset by searching the entire space of βmax which is typically within 1 0 2 1 with the exception of cfdda we require the 50 percentile p50 and p99 of the significant wave height are well matched between the hindcasts and the altimeters 0 1 m p 50 99 w w 3 h s p 50 99 a l t h s 0 1 m and require that p99 does not underestimate hs this second criteria is due to the important engineering applications of capturing the extreme wave heights in general we place more emphasis on capturing the largest sea states often at the expense of moderate seas in this example fig 2 the hindcast using βmax 1 385 best matches the p50 p99 and the upper wave heights hs 10 m in the qq plot fig 2 b βmax 1 385 closely fits the bisector line in fig 3 we objectively adjust βmax to determine the optimal value to reduce hs residuals of the p50 and p99 these plots show βmax x axis versus various percentile differences ww3 alt and the root means square error the coarser resolution products such as r1 era40 era20c have optimal performance when βmax is larger 1 7 on the other hand the higher resolution products such as cfsr ccmp and sct have lower values for βmax but in general this is not a rule since r20c with 210 km spatial resolution has an optimal performance when βmax is close to 1 10 an ideal behavior is when all percentiles intersect with negligible residual this means the pdfs are well matched for all sea states therefore era40 cfsr erai ccmp and sct all have good agreement with the altimeters for the majority of the sea states the only datasets which do not match our criteria of having hs residuals 10 cm are r20c and cfdda for r20c the median hs residual is underestimated by 12 cm and the p99 hs residual overestimated by 15 cm for cfdda we chose β m a x 2 55 because the rmse has a very subtle minimum we tested larger values of βmax up to 3 5 to get a better match of the extreme seas but the pdfs did not resemble the altimeter observations clearly this dataset is not suitable to drive a wave hindcast these plots can be used to understand how to calibrate the models for different applications for example to study the average sea states different criteria can be implemented it is important to reinforce the fact that these charts are valid for the spatial resolution of 0 5 and applicable for a global implementation models with different spatial resolution and coverage will need refinement and possible re calibration 3 2 validation the optimal βmax values are given in table 2 and are chosen from fig 3 here we summarize the overall performance of the 12 1 year hindcasts that use different wind forcing we compute standard error metrics the bias root mean square error rmse scatter index si and slope of the linear regression see stopa et al 2016a for equations there are clear differences in the performance of the older reanalysis datasets r1 era40 jr25 and cfdda compared to the recent reanalysis datasets cfsr erai jra55 and merra the older reanalysis r1 era40 jra25 cfdda have higher rmses and sis of 0 43 m and 15 compared to 0 41 m and 15 for more recent reanalysis cfsr erai jra55 and merra the 20th century reanalysis datasets r20c and era20c perform worse than the other reanalysis datasets both r20c and era20c have similar error metrics r20c underestimates the hs but has slightly better match of the linear regression slope both of the merged satellite observation datasets ccmp and sct perform well with rmse 35 cm and si 13 we generate similar error metrics for the extreme sea states hs 10 m the values are provided in parenthesis in table 2 the performance of all hindcasts degrade at the extremes all hindcasts have hs rmses that exceed 1 m and some have biases that underestimate hs by at least 1 5 m such as r1 cfdda r20c era20c the hindcasts that best capture the largest waves are cfsr merra ccmp and sct shown by the rmses 1 5 m and linear regression slopes between 0 88 and 1 14 erai is a precise forcing wind field si 10 but underestimates the largest heights as reported by others rascle and ardhuin 2013 stopa and cheung 2014 cfdda is out of the reasonable range and significantly underestimates the largest waves the pdfs and qq plots are given in fig 4 after calibration to complement fig 1 now the hs pdfs fig 4 a b closely resemble each other and the altimeter observations with the exception of cfdda at the extreme sea states the lower resolution products r1 era20c era40 still have reduced probability relative to the others and altimeter observations the qq plots are relatively close for all products and deviate less than 0 5 m up hs 8 4 m p99 5 notice we calibrated βmax at p99 and required all products do not underestimate hs at the largest quantile shown p99 9 the hs range is about 1 m between products often in engineering and oceanographic applications other variables besides hs such as the wave period and direction are important we use the buoys from the ndbc network to compare hs average wave periods tm02 2 t m 02 m 0 m 2 where m i 0 037 0 4 2 π f i e f d f is a frequency f moment of the wave spectrum e and the average wave direction θavr 3 θ a v r a r c tan 0 037 0 4 0 2 π sin θ e f θ 0 037 0 4 0 2 π cos θ e f θ we truncate the integration of the buoys at 0 4 hz since beyond this frequency the data is often noisy we use the same frequency range in the wave model output to ensure a fair comparison between the computed parameters the results summarized in table 3 the rmses and sis are given for both the hs and tm02 for θavr the rmse is reported as well as the normalized standard deviation nstd 4 n s t d s t d θ a v r h i n d c a s t s t d θ a v r b u o y 1 100 where std is the standard deviation and the nstd is given in a percentage note that we are using circular mathematics for the θavr error metrics we see the hs rmses are typically between 0 2 and 0 6 m and the sis are between 9 and 37 for tm02 the rmses are between 0 7 and 1 7 s and the sis are typically between 6 and 20 nearly all the hindcasts have θavr rmses of 30 for the northeast pacific and 50 in the gulf of mexico therefore the directional components of the wave model need improvement similar to the findings of stopa et al 2016a the θavr nstds of the hindcasts are typically 0 to 43 less than the buoy observations this means the directional components are relatively smooth compared to the observations this is particularly true for the northeast pacific in the northeast pacific and gulf of mexico the hindcasts are performing the worst with the largest hs and tm02 rmses in the gulf of mexico the θavr rmses are large and possibly small scale atmospheric features are not well captured by the products notice erai has some of the lowest sis for both hs and tm02 demonstrating it is a precise forcing wind field cfsr systematically has the lowest rmses and sis for tm02 some other credible forcing fields are modern reanalyzes cfsr jra55 merra and the satellite datasets ccmp and sct the spatial view of the hindcast performances relative to alt are given in figs 5 and 6 for the normalized rmse nrmse and the si respectively these error metrics show the hindcasts accuracy and precision respectively the wave hindcasts are interpolated in space and time to match the altimeters and the error metrics are computed in 2 bins for each 1 year hindcast for the nrmse fig 5 it is clear that r1 r20c era20c and cfdda have worse performance compared to the other products since the nrmse is often 15 it is interesting to note that the older reanalysis datasets such as era40 and jra25 perform reasonably well once they are properly calibrated however their performance is worse than their successors erai and jra55 respectively jra55 has larger errors in the tropics compared to the other recent hindcasts cfsr erai and merra era20c and r20c have similar spatial patterns and clearly have improved performance in the northern hemisphere nh compared to the southern hemisphere sh this is expected since the majority of the pressure observations were recorded in the nh cfsr erai jra55 merra ccmp and sct all perform well ccmp has the best performance with approximately 68 of the oceans having a nrmse 8 the second best performance is sct with 65 of the oceans having a nrmse 8 for hindcasts driven by reanalyses csfr and merra and have best performance and have nrsmes less than 8 for 62 and 58 of the oceans respectively the corresponding plots for the si are given in fig 6 r1 cfdda r20c and er20c have worse performance than the other hindcasts with si 15 r20c and era20c have lower precision higher sis in the sh the sis are less than 10 in the majority of the oceans for cfsr erai jra55 merra ccmp and sct ccmp sct cfsr and merra are the top 4 best forcing fields with sis less than 10 for 87 86 82 and 79 of the oceans respectively in general all wave hindcasts have larger nrmses and sis that are typically 2 5 higher near the equator compared to surrounding regions in addition near the ice edge in the southern ocean all hindcasts have larger errors and these features are more pronounced in the older reanalysis products like r1 era40 and jra25 therefore either ice edge location and or the atmospheric models are performing better in the more recent reanalysis datasets cfsr erai jra55 merra 4 comparison and extremes to assess the different hindcasts we compute the average and standard deviation of different statistics from the ensemble fig 7 in this analysis we remove cfdda since this hindcast was not in the reasonable range compared to the observations the median in fig 7 a b shows the sh has larger sea states than the nh more importantly the variability shown by the standard deviation of these 11 hindcasts is typically less than 30 cm globally in fact 68 88 and 97 of the ocean has standard deviation less than 10 15 and 20 cm respectively note that in pacific near the equator there is a region with standard deviations of 10 to 20 cm and the hs p50 is only 1 5 m so this region has a large relative variability approx 15 compared to the extra tropics 5 for hs p95 fig 7 c d the nh and sh now have similar magnitudes with maximum in the indian ocean sector of the southern ocean the magnitude of hs p95 is relatively smooth and the standard deviation is mostly less than 20 cm specifically 64 90 and 97 of the ocean has standard deviations less than 20 30 and 40 cm respectively the maximum hs in fig 7 e f does not have a smooth pattern and impact from individual storms can be identified the standard deviation shows particular events can have very large hs differences exceeding 2 5 m in the lower latitudes the standard deviations of the hindcasts are less than 50 cm with the exception of tropical cyclone regions that are most notable in the western pacific and atlantic most of the variability is in the extra tropics and it is common to have standard deviations greater than 1 m the maximum hs differences come from variations in the magnitude of the forcing wind fields or space time deviations of the storm locations in short all hindcasts reproduce the average sea state conditions and have hs within 10 cm of each other even the hs p95 is well matched between hindcasts the largest sea states have greater variability between the hindcasts and these differences are quantified by calculating the occurrence of hs 10 m based on hourly data the results are presented in fig 8 it is clear that the extra tropics have the strongest and most persistent storms tropical cyclones can indeed breach this threshold but their occurrence is low compared to extra tropical events r1 era40 and jra25 have similar patterns jra25 has slightly larger waves in both hemispheres cfdda is not applicable to capture these high sea states and most of the ocean has hs 10 m cfsr erai jra55 and merra have similar spatial patterns erai has the least energy at high sea states and it is known that erai underestimates these conditions stopa and cheung 2014 in the sh cfsr has reduced seas compared to jra55 and merra in the nh merra and cfsr have similar occurrence of hs 10 m but jra55 has less occurrences of elevated seas r20c and era20c have similar patterns however r20c has more occurrences of elevated seas in the sh especially in the indian ocean and perhaps this is too high with respect to the other hindcasts ccmp and sct have nearly the same pattern with slightly more wave activity in sct notice the consistency between the products produced by the same centers ncep r1 csfsr r20c ecwmf era40 erai era20c and jma jra25 jra55 the recently released products have higher occurrence of elevated wave heights hs 10 m which is due to the fact that the spatial resolution increases physical parameterizations improve and satellite observations at extremes improve it is clear that the bulk statistics are different for the upper wave heights so two particular storms are analyzed to further highlight the differences the largest altimeter record for 2001 hs 16 m was recorded in a southern ocean extra tropical storm by gfo this storm from april 10 to april 13 traveled south of australia in the southern ocean fig 9 a as the storm intensified on april 10 at 17 00 the spatial patterns of the hs exceeding 9 m are different for each hindcast fig 9 c era40 has the smallest spatial coverage of hs 9 m at 1 6 105 km2 while most hindcasts jra25 cfsr erai r20c era20c and sct have areas with hs 9 m within 2 8 3 8 10 5 km2 r1 jr55 merra and ccmp have enhanced sea states with regions of hs 9 m exceeding 4 105 km2 and hs larger than 12 m notice that nearly all hindcasts have the storm in nearly the same position the exception is r1 which places the storm slightly ahead of the others when the storm is nearly at its peak intensity gfo crosses the storm center on april 12 at 03 45 the storm contours are given in fig 9 d and all hindcasts have the storm in the same position with the exception of r1 the spatial coverage of hs 9 m between hindcasts varies by 7 105 km2 with maximum being r20c and minimum era40 the altimeter observations in fig 9 b give insight to which models best capture the maximum hs and spatial extent of the storm waves it is confirmed that storm location in r1 is incorrect ignoring cfdda and r1 the hindcasts have the maximum hs ranging from 12 to 18 m for this event jra55 captures the maximum of the storm very well with only a small displacement to the south merra is the only hindcast that overestimates the peak of the event by 1 3 m in addition jra25 r20c era20c perform well and underestimate the altimeter hs of 16 4 m by 50 cm erai ccmp and sct moderately underestimate the peak hs by 1 2 m while cfsr and era40 unreasonably underestimates the peak hs by 3 m towards the end of the event on april 12 at 22 00 there is large variability in the spatial coverage of hs 9 m that exceeds 6 106 km2 between hindcasts fig 9 e some hindcasts fall below the hs threshold of 9 m and are not plotted the time evolution of the maximum hs and area of hs 9 m are given in fig 9 f g it is clear that towards the end of the storm there is more variability in the spatial distribution of the largest waves also notice that the hindcasts have maximum hs that vary from 4 to 8 m for the duration of the event in fig 7 f it is clear that regions affected by tropical cyclones have larger variability with hs standard deviations exceeding 2 m we pick the tropical cyclone utor in the western pacific near the philippines that occurred july 1 5 to demonstrate the large variability of the hindcasts under extreme tropical cyclone wind forcing this event is clearly seen in fig 7 c utor grazed the island of lazon in the philippines and then made landfall in southeast china on july 6 the cyclone overview is given in fig 10 a there was a tpx pass that intersected the storm center on july 3 07 11 the spatial distribution of the hs 8 m on july 2 is similar for the various hindcasts and the h s 8 m contours have a c pattern fig 10 c note that r1 has the storm in different location relative to the other hindcasts similar to the last case when tpx crosses the storm on july 3 in fig 10 b there is a large range of hs profiles merra overestimates hs and it is confirmed that the location of utor in r1 is mis located compared to the altimeter observations in this case erai best matches the tpx hs but with an underestimation of 1 m all other hindcasts era40 jra25 cfsr jra55 cfdda r20c era20c ccmp and sct underestimate the maximum hs of the event h s 11 2 m by 2 to 5 m the positions of the storm in era40 ccmp erai and merra are approximately correct since the hs profiles follow the tpx observations the spatial coverage of hs 8 m varies greatly between products 10 105 km2 fig 10 c d e g towards the end of the event and as the storm moves into the south china sea the spatial patterns of hs 8 m vary by 3 105 km2 fig 10 f g shows the time series of the maximum hs and storm area with hs 8 m it is clear that the maximum hs has a large variability between products of course some products like r20c and era20c are not specifically designed to capture the small scale features of tropical cyclones this particular example shows that the range in hs can be 8 m between the hindcasts therefore extreme caution should be used when using these hindcasts to understand extreme sea states especially for tropical cyclones 5 discussion and recommendations in this work we calibrated 12 different wind products by adjusting the βmax parameter that describes the wind to wave growth in the janssen 1991 formulation we demonstrate that modifying βmax reduces errors in the wave field this is due to the fact that each wind product has different characteristics this exercise was performed on a 0 5 global grid and we used altimeter observations as reference for the calibration then we compare the hindcasts to ndbc moored buoys to assess hs tm02 and θavr our procedure can be adapted to regional domains with different resolutions however one should take caution when applying this approach especially with a sufficiently small domain because βmax could be incorrectly compensating for missing or improper model parameterizations our criteria was to best match the hs pdfs and we ensured the largest sea states hs p99 are not underestimated we specifically summarize the advantages and disadvantages of each hindcast in table 4 and here we generalize the conclusions after calibration even the older reanalysis datasets such as r1 era40 and jra25 perform well with respect to bulk statistics our results clearly demonstrate that the more recent reanalysis wind fields from cfsr erai jra55 and merra are better forcing wind fields for wave hindcasting compared to their predecessors the ncep 4d var reanalysis that uses a mesoscale model cfdda is not suitable for wave hindcasting this wind forcing cannot capture the high sea states there is an extreme underestimation the 20th century reanalysis datasets r20c and era20c have similar performance these hindcasts do not perform as well as the higher resolution products and have less fidelity than the other hindcasts however it is important to note that they capture the magnitude of the extreme events especially in the extra tropics r20c and era20c poorly capture tropical cyclones the hindcasts driven by satellite observations ccmp and sct perform well and are as good if not better than the reanalysis products however their 6 h time step might not be sufficient for some cases such as rapidly intensifying storms the buoy comparison gives an independent check of the calibrated wave hindcasts the hs error metrics between the buoys and altimeters are similar however regional areas such as the northeast pacific and gulf of mexico have larger errors the rmses for the tm02 are typically 1 s and exceed 1 6 s in the gulf of mexico all wave hindcasts have similar performance for average wave directions which is most likely due to the same model source term parameterization and implementation of the dia in the gulf of mexico the θavr are poor with rmses of 50 suggesting model improvements are needed to better capture the directionality of the wave field all hindcasts have similar average sea states p50 and the variability between hindcasts is negligible 5 even up to the 95th percentile the variability between hindcasts is typically less than 10 the hindcasts deviate only at the largest sea states extra tropical storms are well captured by the hindcasts however the variability for the largest events and the occurrence of these events varies greatly between products for the example storms the maximum hs can exceed 6 m for a large extra tropical event and vary by 8 m for a tropical cyclone for practical applications it is important to understand that each forcing wind field will give very different results for high sea states using an ensemble approach such as this to study extreme events will help quantify some of the uncertainty in general it is clear that tropical cyclones are not well captured some of the reanalysis products are able to capture the tropical events better than others murakami 2014 hodges et al 2017 for wave hindcasting we recommend cfsr erai jra55 merra ccmp and sct for extreme waves cfsr jra55 merra ccmp and sct perform well in terms of bulk statistics however the case studies revealed that cfsr underestimated both of the peak hs events by 2 3 m on the other hand erai has the storm in the correct position but maximum hs was underestimated typically by 1 m erai reanalysis is one of the most precise forcing fields and the sis from wave parameters are typically the lowest jra55 matches the extreme waves very well and is expected to better capture tropical cyclones since they are blended into the product through use of a parametric model kobayashi et al 2015 murakami 2014 merra overestimates the largest waves of course βmax can be reduced but this affects the entire hs pdf see fig 3 a βmax 1 45 matches the peak hs of 16 4 and 11 1 m for the extra and tropical cases studies but the overall error metrics degraded and a global underestimation was observed not shown otherwise most of the hindcasts underestimate the extreme sea states for climate studies the consistency of the products in time is key and this is a topic of future work now with properly calibrated hindcasts this task can be performed more diligently in particular r20c and era20c might have the advantage of being less affected by changes in the quantity and quality of the assimilated data another critical point is the need for continual observations from scatterometers and radiometers which provide a tremendous resource for the community as the reanalysis products continually improve there is a need to assess their ability to reproduce the wave field through hindcasts additional and improved measurements of the winds and increased spatial resolution will provide further insights and explanations of regions with large uncertainties especially for high sea states acknowledgments this work is supported by labexmer via grant anr 10 labx 19 01 eu fp7 project swarp under grant agreement 607476 and onr grant number n0001416wx01117 i thank fabrice ardhuin and alexis mouche for their input of early versions of this work i appreciate the three anonymous reviewers for their comments that have improved this paper the altimeter dataset can be obtained from ftp ifremer fr ifremer cersat products swath altimeters waves the ifremer cersat ssmi daily ice concentrations are available from ftp ifremer fr ifremer cersat the ndbc buoy data can be accessed from www ndbc noaa gov the r1 jra25 era40 cfsr erai jra55 and cfdda wind fields and ice concentrations can be obtained from rda ucar edu merrav2 wind fields and ice concentration can be obtained from gmao gsfc nasa gov reanalysis merra 2 ccmpv2 is available via remote sensing systems ftp2 remss com ccmp the ifremer blended product of satellite wind observations sct is available ftp ifremer fr ifremer lops blended wind longterm analysis 
