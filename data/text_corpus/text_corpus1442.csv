index,text
7210,in this paper a comprehensive and interdisciplinary framework for management of eutrophication in off stream artificial lakes in semi arid and arid regions is proposed identification of the lake s water resources system components and stakeholders simulation of phosphorus p export from upstream watershed simulation of the lake water quality as well as simulation of water demands and supply development of management scenarios for the lake and selecting the best scenario using social choice methods i e discrete and fuzzy borda counts are the four main parts of the framework the proposed framework is applied on chitgar artificial lake chal the largest intra urban artificial lake in tehran which has been constructed in 2010 2013 for recreational purposes the load apportionment model lam is used for the simulation of p loads from the point and non point diffusive sources and the lakemab model is used for the simulation of p dynamics in the lake the management scenarios contain optimized rule curves for water intake outtake blended with p management plans i e removal of point sources of p load in the upstream watershed construction of a hydroponic bio filter or an advanced water treatment plant beside the lake for reduction of external loading of p and recycling lake water alum treatment of lake sediments for controlling the internal loading of p as well as construction of a dry detention basin the most preferred scenarios selected by the discrete borda count are the low cost alum treatment and dry detention basin while the most preferred scenario according to fuzzy borda count which considers the uncertainty of model inputs is the costly water treatment plant in all preferred scenarios water intake is conducted from flood flows in order to avoid conflict with downstream agricultural demands in addition to decentralized decision making and stakeholders participation the proposed framework promotes the integration of the technical aspects such as the role of internal loading in lake eutrophication and separation of flood and non flood flows in the off stream lakes systems keywords eutrophication phosphorus optimization fuzzy social choice off stream lakes chitgar 1 introduction population growth combined with an increase in living standards is heightening the pressure on quantity and quality of freshwater resources and the consequential problems are intensified under a lack of sound management in addition to relatively large changes that damming imposes on down streamflow the artificial lakes are also subject to serious pollutions hence artificial lake system planning and management is of crucial importance zhang et al 2017 eutrophication is one of the main issues in both natural and artificial lakes lake eutrophication by nature refers to the process of lake aging in which lake is gradually filled with the sediment inflow and the accumulation of dead flora and fauna in the bottom rast et al 1996 the increased entry of nutrients into the water bodies due to human activities accelerates the growth of algae and aquatic plants which is referred to as cultural eutrophication smith et al 2006 nitrogen n and phosphorus p are long considered to be the most important limiting nutrients for the growth of phytoplankton blomqvist et al 2004 hecky and kilham 1988 the dominant paradigm in freshwater limnology is that p limits phytoplankton growth and though some scientists questioned this paradigm lewis and wurtsbaugh 2008 it is widely accepted that reducing p is the most feasible approach to oligotrophication schindler 2012 smith and schindler 2009 methods of management and restoration of eutrophication in lakes are well reviewed and categorized in the literature cooke et al 2005 hickey and gibbs 2009 le et al 2010 lürling et al 2016 zamparas and zacharias 2014 eutrophication is spotted as a wicked complex problem that there is not a single or even a fixed number of methods for resolving it thornton et al 2013 reddy et al 2018 has thoroughly investigated the interactions and trade offs of eutrophication as a result of the high amount of fertilizers used in the food sector with the water and energy sector and highlighted the need for using holistic decision making approaches toward sustainable development the first step for improving lake water quality is to reduce the excessive external loading of nutrients but since lakes trap and recycle substances a second step for manipulating internal recycling processes might be required cooke et al 2005 there have been many efforts to link lake water quality models to watershed models to evaluate the response of lakes to different best management practices bmps in watershed through scenario analysis karamouz et al 2015 mateus et al 2014 morales marín et al 2017 motew et al 2017 white et al 2010 yazdi and moridi 2017 searching for the optimal set of bmps employing simulation optimization methods is another field of study in eutrophication management huang et al 2012 karamouz et al 2010 kuo et al 2008 however due to land ownership issues the final applicable decision may deviate from optimal solution hsieh et al 2010 hydrologic manipulations for eutrophication management i e dilution flushing and hypolimnetic water withdrawal require large amounts of low nutrient water cooke et al 2005 modeling the response of lakes to water transfer plans has recently received paramount scrutiny dai et al 2016 huang et al 2016 li et al 2011 liu et al 2014b zhang et al 2016 zou et al 2014 apart from whether water transfer improves the lake water quality conflicts among stakeholders may rise and the above mentioned researchers do not appropriately address the impacts of water transfer plans on both water donor and receiving basins decision making in the presence of different stakeholders with various interests almost unavoidably prompt conflicts in order to resolve and manage conflicts group decision making theory is often employed in which the decision makers as a group select a choice among available ones this choice is not attributed to any individual and it is the whole group s decision based on the nature of decision problem and the behavior of decision makers various solution methodologies such as multi criteria decision making mcdm social choice and game theory can be selected mcdm approaches assume full cooperation among a few decision makers criteria and that a supreme and impartial power criterion specifies the final decision from a set of pareto optimal solutions madani and lund 2011 srdjevic 2007 for decision making problems with partial cooperative decision makers social choice methods are supposed to help to avert the poor outcomes of fully non cooperative behavior madani et al 2014 complexities of the eutrophication management stem from the fact that stakeholders in the upstream region may have to adapt to new practices and they may resist changing also the in lake management practices and different outflow patterns will change flow regime in downstream which also affect stakeholders by considering a combination of upstream in lake and downstream issues some researchers have tried to solve the problems of artificial lakes with mcdm approaches liu et al 2014a developed a methodology for simultaneously maximizing economic benefits of water allocation minimizing the water shortages and maximizing waste load allocation in a complex river reservoir region of china masoumi et al 2016 linked a water quality model ce qual w2 with an optimization algorithm in karkheh river reservoir system in order to minimize water deficit in the downstream and maximize the total p tp load allocation however reaching such high levels of cooperation as assumed by aforementioned researchers in the real world can be an ambitious goal due to divergent interests and conflicting objectives of different stakeholders involved in decision making process given that water withdrawals and water quality are not necessarily conflicting targets efstratiadis and hadjibiros 2011 some level of cooperation can be expected to exist among water users and environmentalists to reach an agreeable management plan social choice methods aim to reach a collective choice by ranking the alternatives regarding each criterion the limited applications of social choice methods in water resources management have been well reviewed in recent publications alizadeh et al 2017 de almeida filho et al 2017 ghodsi et al 2016 mahjouri and abbasi 2015 zolfagharipoor and ahmadi 2016 silva et al 2010 developed a group decision making model by collective alternative ranking using promethee ii method to combine the rankings conducted by water users industry and agriculture public sector and civil society to reach the whole group decision regarding eutrophication management in a watershed even though uncertainty analysis is overlooked the model provides a tool for promoting decentralized decision making estalaki et al 2016 proposed 15 combinations of water supply and water quality management plans for chitgar artificial lake as an urban lake employing swmm model to predict lake inflow water quality and vollenweider static model for lake response to different water management plans they used evidential reasoning as an mcdm and fuzzy borda count as a social choice method to select the best available lake water management scenario considering a group of stakeholders although the proposed methods were able to prevent conflicts among stakeholders none of the plans fully prevented the eutrophication of the lake the main aim of this paper is to provide a comprehensive framework for the management of quality and quantity of water in artificial lakes considering the utilities and constraints of the stakeholders the proposed methodology is employed to define and rank a set of 16 management scenarios for the chitgar artificial lake chal in tehran considering the main existing uncertainties in the river lake model in this framework the interactions of the upstream region as the source of pollution to the lake and the downstream region as the impacted area by the construction of the artificial lake are taken into account in the remainder of the paper first the proposed methodology is discussed in detail then the components of chitgar artificial lake system and its stakeholders are described in the next section the results of simulation models scenario developments and selecting the most preferred scenario is presented in the last section concluding remarks are provided 2 methodology a flowchart for the proposed framework is shown in fig 1 in the following sections main components of the proposed framework are discussed 2 1 identification of the system identification of the system is a process which gives a clear explanation of the system to be used in the next steps and includes identification and clustering of stakeholders as well as their viewpoints defining the objectives and boundaries of the system are the main outputs of system identification 2 1 1 identification of the system components this step is about data and information gathering and an initial assessment to define the purpose and boundaries of the system necessary information needs to be collected and be provided to stakeholders in order to help them to understand the system and properly identify their priorities at this stage as it can be seen in fig 1 identification of components can be conducted at various levels the selection of the level of identifications highly depends on the anticipated depth of identification and is limited by time and budget conducting the first level is mandatory but more thorough investigations are discretionary the aim of the first layer is to form an initial overall view of water resources and consumptions as well as the pollutions this provides the stakeholders with basic information to use as the starting point to find a common ground the aim of the second layer is to establish a basis for delving deeper into the issue by separating the surface and ground water resources various consumptions as well as point and diffusive sources of pollutions the third layer provides thorough and detailed information for specialist identification of system components by separating every water resource and source of pollution as well as the efficiency of every water consumption section regardless of the level of components identification ecological status and issues of the lake should be meticulously explored to have a clear vision of artificial lake s water quality problem indices consisting of one or more variables for lake eutrophication assessment can be used but the trophic state is the integrated definition of the lake s nutritional status thus it is commonly accepted that there is no single trophic variable able to completely describe the concept of eutrophication carlson 1977 developed a method for trophic classification of lakes based on nutrient concentration algal biomass and particulate matter in the water column namely the trophic state index tsi the trophic state concept was later developed to visually identify the limiting factor of algal growth by carlson 1991 as well as carlson and havens 2005 the graphical interpretation of tsi indices for tp and chlorophyll a concentrations as well as secchi disk transparency depth used in this paper is from carlson and havens 2005 2 1 2 identification of the stakeholders identification of the stakeholders and the components is a requirement for system identification the steps of stakeholder participation in environmental projects as presented in fig 1 consist of stakeholder identification stakeholder characterization and structuration the definition of the degree of involvement selection of the participatory techniques and implementation the aforementioned steps are thoroughly reviewed and explained by luyet et al 2012 the main goal of the system is selected according to results of experts analyses and consultation with stakeholders delineation of system boundaries is a very critical step since the inappropriate boundaries raise resistance against ratified policies the boundaries can be defined at the scale in which the impacts of issues are observed or at the scale in which the impact of responses to the issues is predicted to be observed however these boundaries do not necessarily coexist and as a consequence the boundaries rely on the specific issue of interest and the type of the problem atkins et al 2011 svarstad et al 2008 2 2 simulation models generally a lake water quantity and quality simulation model along with a water resources allocation model should be developed at this stage the selection of models in terms of their complexity and accuracy highly depends on the requirements which are defined in the identification of the system process and the availability of data 2 2 1 modeling p losses in the watershed generally p inputs to water bodies are from point and nonpoint diffusive sources although some overlap may exist between the two sources unlike point sources which are directly discharged into the river diffusive sources are transported into the rivers through indirect paths e g through snowmelt or rainfall events with the wash of manure and fertilizer in order to simulate the p export from a watershed with the allotment of point and diffusive sources load apportionment modeling lam method is employed lam is a statistical regression based approach developed by bowes et al 2008 which expresses the load of p export from a watershed as a function of its volumetric flow rate bowes et al 2008 1 f tp f p f d a q b c q d 2 c tp a q b 1 c q d 1 where f tp is the tp load mgp s f p and f d are respectively the load from point and diffusive sources mgp s q is the volumetric flow rate m3 s and c tp is the tp concentration mgp m3 the parameters a b c and d are empirical coefficients which should be calibrated eq 2 is derived from eq 1 by dividing the sides of equation by volumetric flow rate the p loads from point sources are constantly discharging into river thus with the increase of river flow the contribution of point sources to total load should be reduced because of dilution hence b is assumed to be smaller than 1 the diffusive sources of p are supposed to increase with the increase of river flow as the sediment production increases due to rainfall or snowmelt hence d is assumed to be equal or greater than 1 bowes et al 2008 greene et al 2011 assumed typical values of b 0 and d 2 and added a third term to eq 1 for relating the depletion of diffusive sources and transformed respectively eqs 1 and 2 to eqs 3 and 4 3 f tp f p f d a b q 2 c q 3 4 c tp a q 1 b q c q 2 where a b and c are model s empirical parameters to be set once the lam model is calibrated and validated against a set of observations of river discharges and tp concentrations the model can be used to generate the tp concentrations using daily river flow rates and apportion the share of point and diffusive sources in any given time span with a daily time step 2 2 2 modeling the lake quantity and quality there exist a wide variety of lake ecosystem simulation models from static models to predict lake tp concentration as a function of the tp concentration in the river and the lake theoretical retention time to dynamic models with static or dynamic structures to individual agent based models for simulating the individuals behavior and interactions brett and benjamin 2007 jørgensen and fath 2011 robson 2014 choosing the appropriate depends on the availability of data and the aim of modeling in this paper a general dynamic process based mass balance model for tp in natural lakes i e lakemab is coupled with a water balance model for an artificial lake the proposed steps for developing the water balance model as well as steps for adapting the lakemab model to the artificial lakes is explained in appendix a 2 2 3 water demands and supply model the components of water demands and supply model are selected based on the results of the system identification phase with some computational effort it is possible to simulate the water demands and supply with mass balance modeling in arid and semi arid regions rivers play an important role in recharging the underlying aquifers thus in this paper the simple routing method for water losing rivers developed by rao and maurer 1996 is used for estimating the infiltration along rivers 5 o i γ d 1 γ 6 γ b 1 b 7 q ah b where o and i are respectively daily inflow and outflow of the river reach m3 s γ is a parameter calculated by eq 6 and d is a parameter to be calibrated against a set of observational data of inflows and outflows the b parameter in eq 6 is the power of flow depth h m in the stage discharge relation of eq 7 where q is the river discharge m3 s the difference between inflow and outflow of the river is the transmission loss which is assumed as aquifer recharge 2 3 scenario development in this stage a number of lake water management scenarios are developed to be used in the social choice stage in order to engage all or at least most of the upstream and downstream stakeholders in the voting process each scenario is comprised of one water intake and outtake rule curve and one set of upstream and in lake management practices the operation of artificial lakes is a complex and nonlinear problem thus rule curves as static and simple operational rules are used for the real time operation of the artificial lake hydrologic manipulations are arbitrary water transfer or withdrawal plans for a lake with the aim to improve the water quality and prevent or mitigate eutrophication in this paper an attempt to find the best attainable set of hydrological manipulations in terms of eutrophication is conducted by development of water intake outtake rule curves using the following optimization model 2 3 1 optimization of operational rule curves the proposed optimization model includes two objectives the first one is to minimize the pollutant concentration in the lake and the second one is to minimize the deviation from the rule curve during operation in regard to the eutrophication indicators e g tp and chlorophyll a concentrations the variation of values during the year is more important than the annual mean values håkanson and boulion 2002 by considering the eutrophication as the exceedance from mesotrophic state i e chl a 10 mg m3 and c tp 40 mgp m3 the probability of eutrophication pe intensity of eutrophication ie and risk of eutrophication re indices are defined as follows 8 pe n e n t 9 ie i 1 n t c tp i c tp all n e i c tp i c tp all 10 re pe ie i 1 n t c tp i c tp all n t i c tp i c tp all where c tp i is the mean tp concentration in the i th month of simulation mgp m3 c tp all is the allowed mean monthly tp concentration which in this study is set to 40 mgp m3 based on lake classification by håkanson and boulion 2002 n e is the number of months that c tp i exceeds the c tp all and n t is the total number of months in the planning horizon the response of the lake to hydrologic manipulations in the study area specifies which index should be considered as the criterion for defining the first objective function of the optimization model in the case study of this paper previous studies e g mahmoudi anzabi 2014 as well as some initial optimizations showed that hydrologic manipulations cannot fully prevent eutrophication hence considering minimization of the intensity of eutrophication as the first objective function the optimization model is defined as follows 11 min z 1 j 1 m i n 1 n 2 c tp i j c tp all n e i j c tp i j c tp all 12 min z 2 m i 1 12 rci i j 1 m i 1 12 ri i j m subject to 13 0 rci i rci max 14 0 rco i rco max 15 s i 1 j s i j ri i j rain i j evap i j rco i loss i j 16 s min s i j s max 17 ri i j rci i 18 if s i 1 j s max then ri i j s max s i j rain i j evap i j rco i loss i j where c tp i j is the mean tp concentration in the i th month of the j th year mgp m3 and rci i is the rule curve water intake for the i th month million cubic meters mcm month which is limited between zero no water intake month and rci max which is set to be the intake facility capacity ri i j is the real water intake in the i th month of the j th year mcm month which is equal to the rule curve water intake of the month unless it causes the lake to spill which is then restricted to the value which only fills the lake to its maximum capacity rco i is the rule curve for water outtake in the i th month mcm month which is repeated each year without any allowed deviation because the source of deviation from outtake rule curve is that lake storage will fall below minimum storage which is an unfavorable situation water outtake rule curve is restricted to zero no water outtake and rco max which is determined by the stability of dam and capacity of outlets s i j is the storage of lake in the i th month of the j th year mcm which is restricted by minimum and maximum operational values of the lake rain i j is the direct precipitation onto lake surface mcm month evap i j is the estimated evaporation of water from lake surface mcm month and loss i j is the water loss from lakebed mcm month in the i th month of the j th year the proposed optimization model is solved using non dominated sorting genetic algorithm nsga ii with two objectives and the result is a set of non dominated solutions termed as the pareto front selecting a fair solution among them is conducted using technique for order preference by similarity to ideal solution topsis mcdm method the basic concept of topsis method is that the best alternative should have the closest distance from the positive ideal solution most preferable and simultaneously the remotest distance from the negative ideal solution least preferable hwang and yoon 1981 here the positive ideal solution is corresponding to the minimum attainable value of eutrophication intensity and minimum attainable deviation from water intake rule curve on the contrary the negative ideal solution is the maximum attainable value of the two objective functions since topsis uses the normalized values of criteria and weighted euclidean distance to ideal solutions the incommensurability of values does not appear as a problem hwang et al 1993 for more details on the topsis method the reader is referred to hwang and yoon 1981 2 3 2 evaluating the eutrophication risk management practices generating rational alternatives for the management of eutrophication needs the satisfaction of the components of the threefold framework of practicability evaluation i e i scientific validity ii economic consideration and iii sociopolitical considerations as discussed by gibson et al 2000 according to this framework a feasible management plan should be tested and verified to be scientifically valid financially affordable and socially and politically acceptable controlling point and diffusive sources of p in the watershed reducing p in water after diversion for the lake as well as recycling the lake water i e withdrawal of lake water reduction of its p and returning the water to the lake and controlling internal sources of p are eutrophication risk management practices which can aim at preventing algal bloom as opposed to the end of pipe practices which aim at reducing the current high algal mass see lürling et al 2016 for more details reduction of p sources in the watershed is simulated by a reduction coefficient in lam model based on the impact on point and diffusive sources recycling is also simulated using the lakemab fluxes concept and these fluxes are incorporated into mass balance differential equations alum al2 so4 3 treatment is used to control the internal loads and it is supposed to reduce the internal diffusion from sediments from 80 to more than 95 with a conservative mean of 85 cooke et al 2005 thus the rate of diffusion in lakemab is considered to be reduced by 85 for simulation of alum treatment 2 4 social choice in this section the principals of discrete and fuzzy social choice using the borda count method are presented social choice procedures are used to aggregate the preferences and interests of a group of voters decision makers in order to achieve a collective and fair decision among a number of alternatives in case of the high reliability of knowledge about the system the discrete borda count can be used in which all models parameters are expected to be known with high certainty in this method each stakeholder makes a pairwise comparison between available alternatives and assigns a score of 1 to the preferred alternative while the less preferable alternative receives a score of 0 hence the total score each alternative receives from each stakeholder is equal to the number of times that it is preferred to other alternatives by that stakeholder after summing the total scores of alternatives multiplied by stakeholders relative weight the collective group decision is the alternative with the highest score garcía lapresta and martínez panero 2002 uncertainty in the structure inputs and parameters of the models can affect the accuracy of their results thus finding an appropriate way to account for uncertainties is necessary in order to take the uncertainties of the simulation models into consideration the fuzzy borda count method proposed by garcía lapresta and martínez panero 2002 is employed some additional steps for defining the uncertain and sensitive parameters and inputs should be done and among all model parameters those which have more impact on the results should be determined by sensitivity analysis the sensitivity analysis is to repeat the simulations by changing model s parameters and comparing the results with those of modeling with initial deterministic values the relative change in the model outputs in this process is a measure to select sensitive parameters among all uncertain parameters in fuzzy borda count method stakeholders not only choose the preferred alternative to the others but also present numerically how much the alternative is preferred to the others with magnitudes from 0 to 1 the calculation of the degree of preference in this paper is conducted using interval numbers proposed by jiang et al 2008 the details and formulae of both discrete and fuzzy borda count procedures as well as the interval numbers used in this paper are presented in the on line supplementary material 3 case study chitgar artificial lake in tehran iran 3 1 identification of the system s components a schematic representation of the system s important components which are described in the identification process is presented in fig 2 a more detailed map of the study area is provided in the on line supplementary material 3 1 1 chitgar artificial lake chitgar artificial lake chal is countrywide the largest intra urban artificial lake for recreational purposes located in district 22 of tehran 35 44 20 35 45 03 n 51 12 21 51 13 21 e the physical characteristics of chal and its dam are presented in table 1 the basic plan of chal in the 1960s was to serve as a flood retention pond for its upstream urban watershed but after four decades of postponing the construction due to lack of funding and low priority it was constructed as a recreational off stream lake between 2010 and 2013 mgcec and pöyry 2011 several studies before the construction of the lake revealed that chal is susceptible to eutrophication and among the water supply scenarios for the lake the more the lake receives urban runoff and treated wastewater the more the risk of its eutrophication e g shamabadi 2007 vatanparast 2011 thus to reduce the concentration of nutrients chal is hydrologically isolated from its urban watershed i e the urban runoff channels bypass the lake and the main water supply source for the lake is kan river although water infiltration into the adjacent aquifer through the lake bed could be a significant recharge source for groundwater the lake bed is insulated with a geomembrane layer in order to maintain the lake at a stable water level for recreational purposes year round hence the sole water output is currently evaporation which is estimated to be about 2 mcm year stpcec 2012 the outtake of water from the valve of the chal dam at the maximum rate of 0 4 m3 s is supposed to be diverted again to kan river due to the problems it can impose on urban downstream channels the water transfer system from kan river to chal consists of a small concrete dam on kan river and a fiberglass pipeline the diversion dam with 4 7 m height and 38 3 m width provides enough head for water to flow through the 7 1 km long pipeline which has the capacity of 1 2 m3 s the chal diversion dam 35 45 54 n 51 15 55 e very well separates the mountainous rural and undeveloped upstream kan watershed from its flat plain urbanized and agriculturally developed downstream a summary of the water quality in chal and the comparison with the water quality standards of iran department of environment idoe 2016 for recreational purposes and conservation of aquatic ecosystems is presented in table 2 as it can be seen most of the chemical parameters are well maintained in the standard range e g dissolved oxygen ph chlorophyll a and the coliform bacteria some of the parameters have slight exceedances of the standard e g the biological oxygen demand especially in spring exceeds the standard and it seems that presence of tourists trying to feed the fish and the migrant birds is a reason for it although nitrite an intermediate product in nitrification processes exceeds the standard its values are well maintained below the protective concentration level of 0 1 mgn l lewis and morris 1986 in addition to the fact that the total nitrogen concentration is completely below the drinking water standard of 10 mgn l and the nitrogen does not seem to be a critical issue as the lake volume gradually decreases from spring to fall the concentration of total phosphorus increases and exceeds the standard and approaches the eutrophic level for more thorough investigation of chal eutrophication issue 12 trios of simultaneous measurements of c tp chl a and sd from spring to autumn of 2014 are used considering the average the values of tsi tp tsi sd and tsi chl are respectively equal to 58 4 39 3 and 31 0 which show that although the lake is in mesotrophic level in terms of sd and chl a it is in eutrophic level in terms of c tp håkanson and boulion 2002 when the tsi chl is smaller than the tsi sd particulate matters in the lake water are not necessarily related to algae and the fact that tsi tp is greater than both of them indicates that factors other than p e g n or high grazing pressure is limiting the growth of phytoplankton carlson and havens 2005 the graphical presentation of the details fig 3 indicates that almost always there is p surplus in chal the molar ratios of c n n p and c p are respectively equal to 7 4 117 and 868 which indicate that c and n exist in abundance and are not limiting nutrients for algal growth wetzel 2001 it seems that the biomanipulation conducted by the lake manager by releasing more than two million fishes of which 95 are aggressive species that feed on phytoplankton ramin et al 2016 is the limiting factor of algae growth attayde et al 2010 however in case the current limiting factor fails to control the algae growth due to the fact that the tsi tp is in the eutrophic level the algae biomass will grow to the eutrophic level hence the lake management plans should focus on restricting the tp concentration in mesotrophic levels i e 40 mgp m3 also the fact that osgood index of chal table 1 is smaller than 6 indicates that the chal is a shallow and polymictic lake and that internal loading of p can be significant osgood 1988 3 1 2 upstream kan watershed upstream of diversion dam kan river is the largest river by discharge running through tehran city and the upstream kan river watershed hereafter only referred to as kan watershed is located in the northwest of the city the area of kan watershed is 215 km2 and with an average rainfall of 640 mm year the total discharge of watershed is 76 3 mcm year on long term average with 82 of watershed surface comprised of low permeable rocks kan watershed is prone to floods and no significant aquifer is developed there water research institute 2011 more than 90 of kan watershed land is covered with varieties of grassland from poor to rich and no more than 5 of the land is covered with good vegetation cover which is mainly the fruit orchards located on the river banks at the very bottom of valleys there are seven villages in the kan watershed with the population of 4637 as of the 2011 census the population of the upstream region has increased with the low rate of 1 2 from 1966 to 2011 compared to the nationwide rate of 4 2 over the same period the low rate is mainly due to the depopulation of rural areas thus a significant increase in the population is not anticipated more investigations regarding the sources of pollution in the kan watershed is presented in the on line supplementary material 3 1 3 downstream kan river watershed and related water transfer plans downstream of diversion dam after the chal diversion dam kan river flows on a permeable riverbed with coarse materials on top of an alluvial fan hence during summer this section of the river is dried up the spent filter backwash water of the water treatment plant no 2 of tehran is discharged to kan river in 3 8 km downstream of the diversion dam with the amount of 5 3 mcm year the west flood diversion channel wfdc which is comprised of tehran s northwestern rivers urban runoff and treated domestic wastewater discharges into kan river at about 6 1 km downstream of diversion dam the amount of water discharged from wfdc to kan river is 58 mcm year based on the sole observation period in 2007 2008 yekom consulting engineers 2009 the wfdc flow variation is less than that of kan river and the water flow in the kan river in dry seasons is actually from wfdc discharge after exiting the tehran city kan river enters the southern agricultural region of tehran which is irrigated with a complex network consisting of channels of treated untreated domestic wastewater and urban runoff the agricultural fields linked with kan river are divided into three groups namely kan1 navvab2 and kan2 the area under cultivation and the demand for surface water in each agricultural region are presented in table 3 the kan1 region is located upstream of navvab diversion facility which diverts the kan river to navvab2 channel the navvab2 channel flow is comprised of diverted flow from kan river as well as a 0 4 m3 s of water flow from navvab1 channel which is originated from salehabad qanat in the southern urban watershed of tehran maogce 2012 kashanak hydrometric station measures the flow in navvab2 channel which is 44 8 mcm year of which 32 8 mcm year is from kan river the navvab2 channel empties to fashafouyeh plain the very downstream plain of karaj river basin which suffers a prolonged water shortage the 3812 ha of arable land in this plain is highly dependent upon flow from navvab2 channel which is 19 0 mcm year as measured in fashafouyeh hydrometric station the floods greater than the navvab2 capacity designed for 5 m3 s but operated at 2 m3 s due to high sedimentation rate flow through the natural kan river pathway toward the kan2 agricultural region maogce 2012 yekom consulting engineers 2009 the janahabad hydrometric station measures the flow in this section which is 42 0 mcm year however field observations show that the irrigation in kan2 region is solely dependent upon the stable flow from salehabad primary treated urban surface runoff originated from the southern urban watershed of tehran rather than the seasonal floods in the kan river the kan river joins the jajrood river which finally flows to bandalikhan wetland and its downstream grasslands which shows the importance of kan floods to implement environmental flows 3 2 identification of stakeholders for identification of system stakeholders after developing the initial list of stakeholders related to management of chal and its water resources system it was found out that most of them are fully or partly governmental hence characterization and structuration of stakeholders are conducted using their rank in the pyramid of power and the result is presented in fig 4 the stakeholders are grouped into four levels according to their relative powers with the first and second levels having legislative power and the third and fourth levels with more operational aspects which act as law enforcement agents for the upper levels the relationship between stakeholders is shown with either two way arrows which represent the cooperation or one way arrows which stand for the commanding power of the organization and its ability to veto the dominated organization s decisions the relationships are presented in table 4 in addition more information regarding the objectives and tasks of the stakeholders is provided in the on line supplementary material 3 3 the boundaries and the main goal of the system considering the identified system components the downstream boundary of the kan river watershed is assumed to be jahanabad station due to the transfer of water from kan river to fashafouyeh plain the delivered water in the fashafouyeh station is also taken into account the system boundaries that indicate which components of the system should be included in the simulation model are presented in fig 2 for defining the main goal of the system technical reports regarding water related aspects of the identified stakeholders are reviewed and some experts in different organizations are interviewed the main issues of the system are categorized into three groups hydrological imbalance of groundwater resources rising and falling water tables in different locations the large quantity of wastewater discharged into the aquifer and downstream rivers and flood related issues see on line supplementary material for more details the goal of the system regarding chal management is defined as management of quality and quantity of chitgar artificial lake with minimized negative impacts on the stakeholders in the study area 4 results 4 1 simulation models 4 1 1 load apportionment model lam the dataset to be used in the calibration and validation of lam model is comprised of 56 pairs of tp concentration and discharge data of which 43 data are weekly or bi weekly observations from april 2012 to march 2013 and 13 data are monthly observations from the winter to the summer of 2011 as well as the spring and the autumn of 2014 the former is used for the calibration of model and separation of dry and wet periods due to better coherence and the latter is used for the validation of the calibrated model although the dry period in tehran region is often from may to october the observations of tp concentration in april also followed that of the dry period hence two models are developed one for the dry period from the beginning of april to the end of october and the other for the wet period among the two versions the first one developed by bowes et al 2008 and the second one by greene et al 2011 of lam model which were calibrated against the observations in both periods the first one overperformed as presented in table 5 the calibrated parameters and the 95 confidence bounds for model parameters are presented in table 6 the load apportionment models for both dry and wet periods the data which were used for training the models as well as the confidence bounds for model parameters are also presented in fig 5 using the lam model the load of tp is simulated in both calibration and validation periods as presented in fig 6 the results indicate that 7 4 3 5 14 9 tonp year is transported out of kan watershed via the river the contribution of point sources is estimated to be 0 7 0 5 0 9 tonp year and the contribution of diffusive sources is estimated to be 6 7 3 0 14 0 tonp year although the diffusive sources have negligible loss of p during the dry period table 6 they are the dominant contributor to p load year around and the contribution of them is estimated to be 91 with lower bound of 77 and upper bound of 97 the annual average of tp concentration is also estimated to be 68 mgp m3 ranging from 32 to 136 mgp m3 it is worth considering that the separation of periods may differ from year to year and more observations with at least weekly frequencies are required to conclude more general results moreover during the rising limb and peak of flood hydrograph the deposited p in the riverbed is washed off and daily or even intra daily observations are required to model the load of p from the watershed with high certainty bowes et al 2008 4 1 2 lakemab for modeling the phosphorus dynamics in chal at first the water balance model of the lake is developed using the area volume elevation curves for chal see fig 7 maximum depth and surface area of chal is modeled as a function of lake volume in every step as follows 19 d max 4 151 v 0 389 0 001445 v 3 169 20 area 60 85 v 0 584 0 v 1 91 77 70 v 59 64 1 91 v 2 32 1 64 v 116 60 2 32 v where d max is the maximum depth of lake m v is the volume of the lake mcm and area is the surface area ha for the simulation of evaporation detrended data from mehrabad airport synoptic station 35 41 36 n 51 18 32 e and elevation of 1196 m a s l which is located 10 km south east of chal is employed mean monthly long term data of air temperature dew point and wind speed from 1951 to 2013 are obtained and trend analyses are conducted using the trend software which has been developed on the basis of grayson et al 1996 and kundzewicz and robson 2000 based on the results of trend detection methods the temperature and dew point show a statistically significant increasing trend at a significance level of 0 01 while the wind speed and rainfall show no statistically significant trend the long term detrended average of monthly data as presented in table 7 and fig 8 are used for simulation of water balance model of chal from march 2014 to january 2016 given the initial volume of 5 mcm at the beginning of march 2014 and 23 monthly data of water intake for the lake the lake volume is calculated at the end of january 2016 in order to verify the developed water balance model the lake volume at the end of verification period is 6 95 mcm while the model prediction is 6 82 mcm i e a relative error of 1 9 the temperature submodel of lakemab underestimates the mean annual epilimnion temperature of chal with a great error i e 12 c instead of the real value of 18 c thus the mean monthly temperatures of chal are manually inputted based on the observations the temperature data also show that chal is a warm polymictic lake and has not experienced any iced surface the calibration and validation of lakemab against 25 mean monthly data of tp from march 2014 to april 2016 are conducted using the genetic algorithm based on limited observations the concentration of tp in the collected rainwater near chal is estimated to be at least 45 mgp m3 hence the wet deposition of p is at least 12 1 mgp m2 year supposing that wet deposition account for one third of total deposition of p in semi arid regions tipping et al 2014 vet et al 2014 wetzel 2001 the total deposition of p on chal is at least 36 3 mgp m2 year however in a try and error effort outside the calibration and validation process the atmospheric deposition of p is set to global average which is 43 mgp m2 year with uniform distribution during the year tipping et al 2014 the calibrated parameters and their boundaries are presented in table 8 the r squared values are respectively equal to 0 70 and 0 64 for the calibration and validation periods and the results are presented in fig 9 in the calibration and validation period 64 of the total load of tp to the water column is internal loading 54 diffusion from sediments in accumulation areas and 10 resuspension from sediments in et areas and the rest 36 is from external loading 30 from kan river and groundwater and 6 from atmospheric deposition since sediments act as both a source and a sink of p the internal loading can be expressed as gross and net loadings which the settlement of particulate p is considered in the latter nürnberg 2009 the gross internal loading in chal is 438 mgp m2 year and the external loading is 249 mgp m2 year the annual amount of net internal loading is 204 mgp m2 year in which the negative value indicates that generally the sediments act as sink of p although the net internal loading in most of the months is negative it bears positive value in the spring after the water intake has just finished as presented in fig 10 this is due to the fact that the settlement of newly entered particulate matters which increases the rate of diffusion is coupled with warm water i e temperatures higher than 12 c which increases the bioturbation håkanson and bryhn 2008 søndergaard et al 2013 4 1 3 water demands and supply model although the water demands and supply model has monthly time steps in order to differentiate between flood and non flood flows the calculations are conducted using daily data of flows and a sub model is employed to convert the daily data to monthly data the monthly water intake for chal is subtracted from the daily discharge of kan river in allowable days i e days in which discharge is lower or higher than defined flood threshold the outtake of chal is supposed to be discharged into the kan river in the upstream section of wfdc the wfdc does not have any hydrometric station hence the flow data for it should be produced which is conducted using the artificial neural network ann method in this study using average rainfall on wfdc watershed and the number of months in the hydrological year an ann with one hidden layer is developed the developed network is trained validated and tested against 37 observational data on wfdc flow from march 2007 to april 2008 the results indicate that the network can simulate the flow of wfdc with good accuracy and the r squared value for simulation of average discharge from march 2007 to april 2008 is 0 97 the developed ann model is used for simulation of average discharge of wfdc from october 1992 to september 2013 it is supposed that the daily discharge of wfdc is equal to the average monthly value since not only the generation of daily data needs more complex rainfall runoff models but also the field observations show that this simplifying hypothesis is justified for the calculation of aquifer recharge from the kan river bed the parameter b in eq 7 is set to 2 5 as a typical value for a wide range of rivers leopold and maddock 1953 park 1977 the parameter d in the eq 5 is set to 0 53 so that the recharge of the aquifer from kan river bed in the upstream of navvab diversion facility from march 2011 to february 2012 equals 42 0 mcm as calculated by malakpour estalaki 2018 the flow discharges up to 2 m3 s at the navvab diversion facility are diverted to navvab2 channel and the rest in days that discharge flow is greater than 2 m3 s flows through the natural kan river pathway the verification of the developed model is conducted using the 21 years of historical data at two checkpoints i e the navvab diversion facility sum of flows at jahanabad and kashanak hydrometric stations with r 2 0 74 as well as the flow of water delivered to fashafouyeh plain the fashafouyeh hydrometric station with r 2 0 51 as presented in fig 11 4 2 scenario development 4 2 1 water intake and outtake plans the kan river in the chal diversion dam section is often dry from june to october and the few exceptions are mostly the summer flash floods high in suspended matters and sediments hence these five months are excluded from all of the water intake plans two types of optimized and non optimized rules for water intake are developed which the former is called water intake rule curve since the rule curves represent the best achievable hydrologic manipulation for the control of eutrophication it is assumed that the water intake rule curve is only applied in days with the lowest tp concentration namely the non flood flows based on the engineering judgment and the results of lam model the non flood flows are assumed as days in which the discharge is between 0 2 and 3 m3 s in the wet period november march and from 0 2 to 8 m3 s in the allowable months of dry period april and may the rci max for chal is 3 1 mcm month and the rco max is set to 1 mcm month the s min and s max are respectively set as 4 5 and 7 0 mcm and the loss of water from lakebed is set to zero due to its strict insulation with geomembrane since the initial optimizations showed that there is no water intake rule curve which can completely keep the lake tp concentration below the allowed 40 mgp m3 during the 21 years of long term model the minimization of the intensity of eutrophication in the high algal growth months of year i e april october is selected as the first objective function the optimizations are conducted using five plans which the first four plans assume no water outtake from lake thus the lake is closed but in the fifth plan the lake outtake rule curve is also allowed to be optimized the difference among the closed lake rule curves is the allowable months for water intake in which all start in november and end in varying months from february to may lasting for 4 7 months the obtained pareto optimal solutions are ranked using topsis with the weight of 0 7 for eutrophication intensity and 0 3 for the deviation from the rule curve and the best solution is selected as presented in fig 12 and table 9 it should be noticed that the results showed that the 5 months water intake rule curve is similar to the 4 months rule curve since all days of the march in most of the years have the discharge flow greater than flood threshold thus 5 months water intake rule curve was removed from the water intake plans although the non flood flows have lower p and sediment which is favorable for chal managers the navvab2 and fashafouyeh farmers rely on the transferred water from the kan river which is derived from non flood flows due to the limited capacity of the channel hence three plans for water intake for chal from flood flows are developed the first plan namely closed lake and water intake from flood flows assumes that in all the days that flow discharge is greater than a defined flood threshold water can be withdrawn for chal and the lake manager lets water to be transferred to lake till the lake is filled up to its capacity in the allowable months i e november may as presented in fig 13 by selecting the 3 m3 s as the threshold the volume of water transferred to navvab2 channel does not reduce the second plan namely open lake and water intake from flood flows assumes that in all the days that flow discharge is greater than a defined flood threshold water is withdrawn for chal and as long as the lake volume is 7 mcm the water is also outtaken with the capacity of 0 4 m3 s actually in this plan the water intake is limited by the capacity of outtake system the flood threshold for this plan so that the water transfer to navvab2 channel is not reduced is 2 75 m3 s the third plan is similar to the first plan namely closed lake and water intake from selected non flood flows in which water is withdrawn from flow discharges between 2 5 and 3 m3 s in november march and from flow discharges between 2 5 and 8 m3 s in april and may this plan intends to establish a balance between chal and downstream agricultural lands needs for non flood flows 4 2 2 p reduction plans since none of the aforementioned water intake outtake plans can keep the lake in mesotrophic level they are integrated with p management plans as it is explained in section 2 3 2 it is recommended that management plans be assessed using the threefold framework of practicability gibson et al 2000 not only should the plans have scientific validity but they also should be financially affordable by the community and socially and politically acceptable since a scientifically rational and cost effective plan but conflicting with local community s collective values will most probably be unsuccessful the water intake outtake plans which were developed in section 4 2 1 are coupled with three phosphorus management plans which finally resulted in 16 management scenarios as presented in table 10 the more detailed explanation of the plans as well as the practicability analysis of them is provided in appendix b 4 3 social choice 4 3 1 the utility of stakeholders in this section the utility of stakeholders in the management of chal for achieving social choice is developed some of the stakeholders which are close to each other in terms of goals and tasks can form a coalition the tpg as the most powerful stakeholder is interested in maintaining a balance between conflicting stakeholders so that the security of the system is not affected hence its utility is a mixture of other stakeholders utilities with the same weight idoe is interested in environmental facets of the system i e highest environmental flow highest inflow to fashafouyeh plain highest recharge of the aquifer and lowest risk of eutrophication for trwc the recharge of the aquifer is the most important utility while it is interested in selling more water to chal managers since the price of water for chal is 10 billion iranian rials irr per mcm while supplying the demand of downstream agriculture tcc and tehran municipality form a coalition and their utility is the lowest risk of eutrophication as well as the lowest operational cost for chal including the price of water twwc and trwwc form a coalition and highest recharge of the aquifer is their utility moreover the scenarios containing the treatment of wastewater in kan watershed are preferred receiving the score equal to 1 to other scenarios receiving the score of 0 by this coalition tajo and dnrwmt form a coalition and their utility is the supply of water for downstream agriculture as well as environmental flow the relative weight of each agricultural unit is calculated using their cultivated area and the relative weight for environmental flow is considered to be equal to the one for kan1 agricultural unit the standardized weights of stakeholders according to their power and the weight of each criterion in calculating the total utility of each stakeholder as determined by engineering judgment is presented in table 11 4 3 2 sensitivity analysis of uncertain parameters due to the lack of sufficient data newness of the chal as well as its unique characteristics such as being a closed lake the insulation of lake bed from infiltration lack of macrophytes and the intense biomanipulation in lake by releasing aggressive fish species and difficulties in conducting field measurements the model parameters and consequently the results are uncertain the selection of uncertain parameters is conducted based on engineering judgments and the insights gained into the problem during the data preparation and simulation models development by reason of the relatively short time span on which the quality of kan river was measured the calibrated parameters of lam model are selected for sensitivity analysis over their 95 confidence bound the existence of surplus p in chal water fig 3 beside the alteration of fish species makes the particulate fraction pf of phosphorus in both intake and no intake months a candidate for uncertain parameters atmospheric deposition of p adp as an external sources of p was set to the average global value reported by tipping et al 2014 is an uncertain parameter and one standard deviation interval is selected for its sensitivity analysis due to lack of macrophytes in the newly constructed lake the rate of diffusion of p from sediments r diff is an uncertain parameter the interval of uncertain parameters and the basis for selecting the intervals is presented in table 12 the changes in the risk of eutrophication are expressed as relative changes in the lower and upper values of the interval of parameters in order to achieve a comprehensive view of the sensitivity analysis the analysis is conducted in different water intake outtake plans as presented in fig 14 a more thorough investigation of fig 14 shows that the risk of eutrophication is highly sensitive to the external load of p from kan watershed especially when the closed lake is operated under an open lake scheme i e continuous and simultaneous water intake and outtake fig 14d the particulate fraction pf of p especially in no intake periods is also a very sensitive parameter in terms of the risk of eutrophication as is the atmospheric deposition of p adp especially in closed lake management plans given the threshold of 25 change in the risk of eutrophication for changes over the interval of uncertain parameters the lam parameters pf no intake and adp are selected as uncertain and sensitive parameters the high sensitivity of the risk of eutrophication to particulate fraction of p in no intake months highlights the importance of internal recycling processes of p in closed chal which should be meticulously investigated in addition the very high sensitivity of the risk of eutrophication index to external loading in open lake management plan puts an emphasis on the importance of external loading of p in eutrophication of chal in case its managers decide to operate it as an open lake 4 3 3 the borda count in this section firstly the performance criteria that constitute the utility of stakeholders are presented in table 13 two of the criteria i e risk of eutrophication and cost of lake management are also presented as interval numbers beside their deterministic value in order to be used in the fuzzy borda count the initial costs are considered for the base year i e 2015 and the operation and maintenance costs are all transferred to the base year with the assumption of similar inflation and interest rates over the course of 21 years of simulation the average scores of different scenarios in the discrete and fuzzy borda count are presented in fig 15 scenario number 14 outstandingly dominates the other scenarios in the discrete approach followed by scenarios number 9 and 11 actually five out of seven scenarios that contain alum treatment are the first ranked scenarios due to the dominance of internal loading as the main source of p to the water column in the lake which is well controlled by the cost effective alum treatment which is strongly in accordance with the results of huser et al 2016b in the fuzzy approach scenario number 16 dominates other scenarios followed by scenarios number 12 and 14 the significant uncertainties associated with the external loadings both kan river and atmospheric deposition with a great contribution to the load of p to water column is the main reason for relatively expensive water treatment plant to be the dominant scenario however in both approaches the dominant scenario is comprised of water intake from floods or selected non flood flows which is due to the importance of non flood flows for the recharge of the aquifer and downstream agricultural demands the utilities of stakeholders for the three first ranked scenarios of each approach are presented in fig 16 5 summary and conclusion in this paper a comprehensive framework was proposed for the management of quantity and quality of water in off stream artificial lakes in semi arid and arid regions considering the utilities of existing stakeholders the proposed framework was applied to the newly constructed chitgar artificial lake chal in tehran which is blamed for reducing the availability of water for the southern agricultural lands of tehran as well as its risk of eutrophication and algal bloom which impede its recreational purpose the lam and lakemab models respectively for simulation of p loss from kan watershed and simulation of p dynamics in chal were used in the context of a mass balance water demands and supply model a set of 16 scenarios for water intake and outtake plans as well as p management plans was developed considering their scientific validity economic and socio political considerations ranking the scenarios was also conducted using discrete and fuzzy borda count as a social choice method the results indicate that in the discrete approach scenario 14 was obviously the most preferred management plan for chal in this scenario not only water intake for lake is from flood flows flow discharges greater than 3 m3 s and the chal does not compete with downstream agricultural demands but also the cost of alum treatment for the control of internal loading which is the main source of p to water column of chal is relatively low however due to uncertainties associated with external loading of p in the fuzzy approach scenario 16 was ranked as the best solution it is due to the strict p reduction in the relatively expensive water treatment facility which is considered to be built beside the chal for the treatment of intake water as well as lake water in the no intake period the ranking of scenarios 12 and 14 as the second and the third best solutions in the fuzzy approach shows that by reducing the uncertainties associated with the external loadings the alum treatment is possible to be selected as the first solution in both approaches although specifically developed for the off stream artificial lakes in arid and semi arid regions the proposed framework is capable of being easily adapted for more conventional on stream artificial lakes in these regions especially in river systems where the construction of a large dam can impose the more significant and radical changes in the downstream region the incorporation of the concept of water food energy nexus in the framework is highly recommended the most important limitations of this study stem from the lack of high quality field observations for example measurement of different forms of particulate and dissolved p in lake water and the direct measurement of atmospheric deposition of p would be very useful in addition the frequency of sampling and measurement of kan river water quality parameters should be increased especially during the flood flows in the future works the methodology can be extended in order to take the fuzziness of the stakeholders utilities into account investigating the impacts of climate change on quality and quantity of river and lake can be another aspect of extending the proposed methodology in the case of chal investigating the impact of reversing the current biomanipulation by releasing carnivorous fishes to reduce planktivory and filter feeding pressure on zooplanktons as well as reducing the benthivory by carps seems to be necessary waajen et al 2016 also the share of kan watershed orchards in the diffusive sources of p is suggested to be investigated with appropriate models which can take into account the densely wooded aspect of the orchards exploring a management plan which not only reduces p in kan river but also reduces river degradation seems to be beneficial for almost all of the stakeholders acknowledgment helps from dr m tajrishy and dr d r arab for providing the observational data of the chitgar artificial lake and dr a bryhn for providing the source code of lakemab are kindly hereby appreciated appendix a lakemab is the latest version of a series of lake ecosystem models with a focus on eutrophication håkanson and bryhn 2008 from a mass balance viewpoint lakemab takes four compartments of p into consideration i surface water epilimnion ii deep water hypolimnion iii active sediments in erosion and transportation et areas iv active sediments in accumulation areas the separation of surface and deep water compartment as well as sediments in et and accumulation areas is conducted by a theoretical wave base the internal fluxes of tp amongst the four compartments include sedimentation of particulate p pp from epilimnion to hypolimnion and sediments in et areas and from hypolimnion to sediments in accumulation areas resuspension of pp from et areas to epilimnion and hypolimnion diffusion of dissolved p dp from sediments in accumulation areas to hypolimnion and the mixing of tp between surface and deep water under unstratified situation in lake the input fluxes include tp from watershed and atmosphere and the output flux of tp from epilimnion as well as the burial flux of tp under the 10 cm depth of active sediments in accumulation areas håkanson and bryhn 2008 the original lakemab code considers constant volume for lake during simulation period and contains a submodel for estimation of runoff from lake watershed in order to evaluate the input of tp as well as a submodel to estimate evaporation for evaluation of the output of tp these assumptions and water balance submodels work well for most european and north american natural lakes but not from a water resources management perspective for artificial lake systems most of the artificial lakes especially off stream lakes employ inflow and outflow rule curves in order to confine the framework to off stream artificial lakes both arbitrary water intake and outtake are considered arbitrary water intake can be simply replaced with a runoff simulation model or data from the upstream hydrometric station for adapting the framework to on stream artificial lakes for the simulation of evaporation well known aerodynamic method which models the evaporation as the production of vapor pressure deficit between the surface of water and air and a wind function is used in this paper the site specific wind function developed by mcjannet et al 2012 which considers the area of the water body and uses the conventional land based meteorological data is employed a 1 e f u 2 e sat e a a 2 f u 2 2 36 1 67 u 2 a 0 05 where e is the evaporation rate mm day e sat and e a are respectively saturated and partial vapor pressure of air kpa f u 2 is the wind function mm day kpa u 2 is the wind speed over land at the height of two meters m s and a is the area of water body m2 which ranges from 0 07 m2 to 33 5 km2 for the proposed wind function in addition to the significance of direct precipitation on lake which should be considered in lake water balance atmospheric deposition of p on lake can be an important source of nutrient for algal growth brahney et al 2015 tsugeki et al 2012 if not the main source of bioavailable p as in the case of lake kinneret eckert and nishri 2014 lakemab considers tp concentration of 5 mgp m3 in rainfall which is rational for high latitudes e g sweden where the lakemab has been developed recent studies by using global modeling of geographical patterns of p deposition have revealed a higher atmospheric deposition of p in lower latitudes wang et al 2014 as well as a significant contribution of local sources e g agricultural lands to deposition of p on lakes and land tipping et al 2014 under the lack of direct measurements of wet and dry atmospheric depositions the use of either the former s maps and depicted ranges or the latter s statistical mean and standard deviation in different continents is proposed for the estimation of atmospheric deposition of p the mixing between epilimnion and hypolimnion layers depends on the stratification lakemab contains a submodel developed by ottosson and abrahamsson 1998 to calculate the mean monthly temperature of the two layers the submodel calculates the mean annual temperature of epilimnion as a function of latitude n altitude in meters above sea level m a s l and distance from the ocean km and converts it to mean monthly temperatures of both epilimnion and hypolimnion based on physical characteristics of the lake calculation of mixing rate r mix 1 month is followed by a simple algorithm that is if the absolute difference between mean monthly epilimnion and hypolimnion temperature is smaller than 4 c then r mix is equal to 1 1 month i e lake is completely mixed as the difference between the two layers temperature increases r mix drastically drops with inverse proportion to the difference of temperature between the two layers the lake temperature submodel has been developed using data of european lakes and may be inappropriate for lakes outside of tested lakemab geographical domain thus for the artificial lakes which do not fall within spatial domain of the model lake s monthly mean epilimnion and hypolimnion temperature should be simulated or measured and be entered to model manually in order to participate only pp in lakemab sedimentation fluxes a particulate fraction pf which is the pp divided by tp is employed based on mean annual data from 10 swedish natural lakes håkanson and boulion 2002 showed that pf can be assumed as a constant value of 0 56 year round however with data from 51 natural and artificial american lakes smith 1982 suggested a simple relation between pp and tp which implies that pf is a function of tp and the more the tp the more the pf recently serrano et al 2017 found that when the tp input to shallow lakes is more than the sediments natural adsorption capacity the pf becomes 0 50 due to saturation of p binding capacity of sediments and biological uptake which is termed anthropogenic eutrophication in an attempt to adapt lakemab model to meromictic lakes bryhn et al 2010 set the pf ratio to 0 60 0 50 and 0 30 respectively for the surface middle and deep water layers thus the pf ratio should be calibrated for artificial lakes since there may be differences between them and natural lakes regarding sediments the thickness of bioactive sediments in accumulation areas in lakemab is assumed to be 10 cm and the burial flux is defined as the deactivated sediment layer beneath the 10 cm active sediment layer since the whole thickness of sediments in newly constructed artificial lakes is 10 cm we let the lakemab evaluate the thickness of sediments and the burial flux will not be activated until the thickness of sediments reaches 10 cm an algorithm for the proposed procedure adapted from håkanson and bryhn 2008 is as follows a 3 if n 1 st n st 0 else st n 1 st n sed n 12 dt where st n is the thickness of sediments cm at n th time step and st 0 is the thickness of sediments cm at the start of simulation sed n is the sedimentation rate cm year which is divided by the number of months and dt is the step size for solving the differential equations of lakemab by euler s method which in the original code of lakemab is 1 10 but in this paper is set to 1 30 for increasing the accuracy of results the burial flux is not activated until the thickness of sediments reaches to 10 cm and the depth of active sediments d as is selected as the minimum value of whole sediments thickness and 10 cm for a complete explanation of other lakemab parts the reader is referred to håkanson and bryhn 2008 appendix b reduction of the external load of p can be conducted via controlling the point or diffusive sources a 10 reduction of tp load from diffusive sources by terracing technique in kan watershed is predicted by delkash 2013 although the cost of terracing in 133 suitable locations is estimated to be 0 7 billion iranian rials water research institute 2011 which is affordable more recent studies abhari rashtabadi 2015 haghparast 2015 have shown that kan river bed both in upstream and in tehran city is degrading and terracing intensifies this issue due to the risk of bridge scour imposed by river degradation deng and cai 2010 the terracing is not considered in plans using p export coefficients water research institute 2011 estimated that 59 0 of p load from diffusive sources in the kan watershed originates from agricultural lands while delkash et al 2014 estimated the 30 4 contribution of agricultural lands to the diffusive sources in the wet period however there is some evidence that the contribution of orchards to total p load is not much not only the canopy of the densely wooded kan orchards reduces the kinetic energy of raindrops ghafari et al 2014 but also the orchardists actively protect their limited arable land from erosion by construction and maintenance of terraces babaei et al 2016 hence the consideration of agricultural bmps for orchards is conditioned by future investigations due to lack of certain scientific validity the first plan consists of a hydroponic bio filter beside the lake as well as wastewater treatment facilities for villages in kan watershed investigating the case studies of using hydroponics to remove tp at low concentrations as well as ability to be used in winter led to the selection of nasturtium officinale plant commonly known as watercress li et al 2009 li et al 2009 used hydroponic bio filters for purification of a lake with tp concentration of 40 210 mgp m3 and their results showed that as long as the hydraulic load of water to bio filter is 0 5 4 m3 m2 day the tp removal efficiency is almost constant with average value of 15 9 in winter december march and 35 4 in non winter months april november in their case study the particulate p forms about 80 of the total p and the major mechanism of removal is adsorption of particulate p to plant roots while the removal efficiency for orthophosphate is just 10 considering the capacity of water transfer pipeline to chal i e 1 2 m3 s the area of the hydroponic bed should be 2 6 ha so that the hydraulic load does not exceed 4 m3 m2 day in months with no water intake or 0 4 mcm month water intake a pump with the capacity of 0 6 m3 s transfers the water of the lake to the bio filter this ensures that the hydraulic load of bio filter is not 2 m3 m2 day due to the low concentration of particulate p in lake water in no intake months pf 0 10 the removal of tp from lake water in calculated according to the orthophosphate removal efficiency as the historical data show that 60 of tp in lake water is in the form of orthophosphate the initial investment for the construction of bio filter is estimated to be 10 30 billion iranian rials irr in 2015 and the annual maintenance cost ranging from 1 to 3 billion irr in order to ascertain that the particulate p is the dominant form in the kan river the point sources should be removed for this purpose the proposed methods by gray and booker 2003 for removal of nutrients from wastewater of small communities with 10 000 population is used among their scenarios the local blackwater treatment which removes 87 of tp from household wastewater at capital price of 930 aud in 2003 is selected the initial investment for these facilities is estimated to be 160 180 billion irr in 2015 and annual maintenance cost is 10 18 billion irr the aforestated plan reduces the risk of eutrophication between 70 and 90 based on the water intake outtake plan the second plan mostly relies on the controlling of internal loading and inactivation of p considering the fact that the ph is not higher than 8 5 and the alkalinity is not lower than 80 mg caco3 l chal is an appropriate lake for alum treatment cooke et al 2005 among three methods for estimation of the amount of alum that can be applied to the lakes as described by cooke et al 2005 the mass balance approach using gross diffusion of p from sediments in accumulation areas in 4 months rule curve gives the need for 9 95 gral m2 i e 106 62 ton al2 so4 3 16h2o aluminum sulfate powder to be applied over accumulation areas every five years the amount of required powder is calculated internally in every water intake outtake plan and converted to cost with the unit price of 0 01 billion irr per ton of aluminum sulfate powder as well as 5 billion irr estimated cost for distribution of alum on the lake the five year period used in this method is in accordance with the mean 5 7 years longevity of al treatment in shallow polymictic lakes as reviewed by huser et al 2016a in order to succeed in reducing internal p loading it is crucial to reduce the external loading of p at the same time zamparas and zacharias 2014 therefore a dry detention basin for p removal is considered to be built beside the lake for the calculation of p removal in the detention basin the proposed model by walker 1987 is used the area of detention basin is supposed to be equal to one hectare with the average depth of 10 m initial assessments revealed that the p removal in this case is very minute and is not greater than 10 since the assumed size of detention basin is big enough it is not well justified to make the basin larger hence the use of alum in order to reduce the ratio of orthophosphate to tp is considered not only has shown the experiments on kan river water that the addition of 4 mgal l can effectively remove tp from water column sharif university of technology 2014 but also the study of pilgrim and brezonik 2005 on a river with similar tp concentration to kan river has shown that addition of 2 8 mgal l can convert no 90 of orthophosphate to particulate non reactive p by converting 90 of orthophosphate with alum the tp removal percentage in detention basin reaches to 20 40 based on the water intake plan considering the least amount of alkalinity in kan river water which is 91 mgcaco3 l the use of this amount of alum is safe but since this addition is repeated annually buffered alum is used in order to minimize the risk of low ph in the lake cooke et al 2005 the unit price of buffered alum is 0 015 billion irr per ton and the annual cost of transfer and mixing with the withdrawn water in the chal diversion dam is 0 7 billion irr although it is anticipated that due to the annual addition of low concentration alum to intaken water there would be no need for repetition of alum treatment on lake sediments every five years the cost of the five year operation is kept within this plan the alum plan reduces the risk of eutrophication more than 90 in all water intake outtake plans the third plan is the construction of an advanced water treatment plant beside chal due to the limited capacity of treatment plants in this plan water intake cannot be conducted with the full capacity of chal pipeline but at the maximum discharge of 0 4 m3 s two assumptions for water intake using the water treatment are defined in the first assumption as proposed by tcec 2013 in 5 months november march water is withdrawn for chal regardless of the discharge of river and water intake in each month is stopped only if the lake volume reaches the 7 mcm in the second assumption in 6 months november april water is withdrawn only in days in which the volumetric discharge is greater than 1 4 m3 s as it is presented in fig b1 the minimum volume of the lake during 21 years using the 1 4 m3 s discharge threshold is 4 4 mcm the treatment plant will be in operation for 11 months of the year except for october which is allotted to the repair and maintenance of the plant if the water intake is less than the capacity of the treatment plant which is 1 mcm month the unused capacity is filled by pumping the lake water to the treatment plant the efficiency of tp removal is dependent on consumed chemicals and concentration of tp however based on the technical calculations related to the design of chal treatment plant tcec 2013 for a fixed cost the percentage of phosphorus removal is a function of tp concentration input as follows b 1 prp 0 098 c tp 0 358 where prp is the tp removal percentage appendix c supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 04 052 appendix c supplementary data supplementary data 
7210,in this paper a comprehensive and interdisciplinary framework for management of eutrophication in off stream artificial lakes in semi arid and arid regions is proposed identification of the lake s water resources system components and stakeholders simulation of phosphorus p export from upstream watershed simulation of the lake water quality as well as simulation of water demands and supply development of management scenarios for the lake and selecting the best scenario using social choice methods i e discrete and fuzzy borda counts are the four main parts of the framework the proposed framework is applied on chitgar artificial lake chal the largest intra urban artificial lake in tehran which has been constructed in 2010 2013 for recreational purposes the load apportionment model lam is used for the simulation of p loads from the point and non point diffusive sources and the lakemab model is used for the simulation of p dynamics in the lake the management scenarios contain optimized rule curves for water intake outtake blended with p management plans i e removal of point sources of p load in the upstream watershed construction of a hydroponic bio filter or an advanced water treatment plant beside the lake for reduction of external loading of p and recycling lake water alum treatment of lake sediments for controlling the internal loading of p as well as construction of a dry detention basin the most preferred scenarios selected by the discrete borda count are the low cost alum treatment and dry detention basin while the most preferred scenario according to fuzzy borda count which considers the uncertainty of model inputs is the costly water treatment plant in all preferred scenarios water intake is conducted from flood flows in order to avoid conflict with downstream agricultural demands in addition to decentralized decision making and stakeholders participation the proposed framework promotes the integration of the technical aspects such as the role of internal loading in lake eutrophication and separation of flood and non flood flows in the off stream lakes systems keywords eutrophication phosphorus optimization fuzzy social choice off stream lakes chitgar 1 introduction population growth combined with an increase in living standards is heightening the pressure on quantity and quality of freshwater resources and the consequential problems are intensified under a lack of sound management in addition to relatively large changes that damming imposes on down streamflow the artificial lakes are also subject to serious pollutions hence artificial lake system planning and management is of crucial importance zhang et al 2017 eutrophication is one of the main issues in both natural and artificial lakes lake eutrophication by nature refers to the process of lake aging in which lake is gradually filled with the sediment inflow and the accumulation of dead flora and fauna in the bottom rast et al 1996 the increased entry of nutrients into the water bodies due to human activities accelerates the growth of algae and aquatic plants which is referred to as cultural eutrophication smith et al 2006 nitrogen n and phosphorus p are long considered to be the most important limiting nutrients for the growth of phytoplankton blomqvist et al 2004 hecky and kilham 1988 the dominant paradigm in freshwater limnology is that p limits phytoplankton growth and though some scientists questioned this paradigm lewis and wurtsbaugh 2008 it is widely accepted that reducing p is the most feasible approach to oligotrophication schindler 2012 smith and schindler 2009 methods of management and restoration of eutrophication in lakes are well reviewed and categorized in the literature cooke et al 2005 hickey and gibbs 2009 le et al 2010 lürling et al 2016 zamparas and zacharias 2014 eutrophication is spotted as a wicked complex problem that there is not a single or even a fixed number of methods for resolving it thornton et al 2013 reddy et al 2018 has thoroughly investigated the interactions and trade offs of eutrophication as a result of the high amount of fertilizers used in the food sector with the water and energy sector and highlighted the need for using holistic decision making approaches toward sustainable development the first step for improving lake water quality is to reduce the excessive external loading of nutrients but since lakes trap and recycle substances a second step for manipulating internal recycling processes might be required cooke et al 2005 there have been many efforts to link lake water quality models to watershed models to evaluate the response of lakes to different best management practices bmps in watershed through scenario analysis karamouz et al 2015 mateus et al 2014 morales marín et al 2017 motew et al 2017 white et al 2010 yazdi and moridi 2017 searching for the optimal set of bmps employing simulation optimization methods is another field of study in eutrophication management huang et al 2012 karamouz et al 2010 kuo et al 2008 however due to land ownership issues the final applicable decision may deviate from optimal solution hsieh et al 2010 hydrologic manipulations for eutrophication management i e dilution flushing and hypolimnetic water withdrawal require large amounts of low nutrient water cooke et al 2005 modeling the response of lakes to water transfer plans has recently received paramount scrutiny dai et al 2016 huang et al 2016 li et al 2011 liu et al 2014b zhang et al 2016 zou et al 2014 apart from whether water transfer improves the lake water quality conflicts among stakeholders may rise and the above mentioned researchers do not appropriately address the impacts of water transfer plans on both water donor and receiving basins decision making in the presence of different stakeholders with various interests almost unavoidably prompt conflicts in order to resolve and manage conflicts group decision making theory is often employed in which the decision makers as a group select a choice among available ones this choice is not attributed to any individual and it is the whole group s decision based on the nature of decision problem and the behavior of decision makers various solution methodologies such as multi criteria decision making mcdm social choice and game theory can be selected mcdm approaches assume full cooperation among a few decision makers criteria and that a supreme and impartial power criterion specifies the final decision from a set of pareto optimal solutions madani and lund 2011 srdjevic 2007 for decision making problems with partial cooperative decision makers social choice methods are supposed to help to avert the poor outcomes of fully non cooperative behavior madani et al 2014 complexities of the eutrophication management stem from the fact that stakeholders in the upstream region may have to adapt to new practices and they may resist changing also the in lake management practices and different outflow patterns will change flow regime in downstream which also affect stakeholders by considering a combination of upstream in lake and downstream issues some researchers have tried to solve the problems of artificial lakes with mcdm approaches liu et al 2014a developed a methodology for simultaneously maximizing economic benefits of water allocation minimizing the water shortages and maximizing waste load allocation in a complex river reservoir region of china masoumi et al 2016 linked a water quality model ce qual w2 with an optimization algorithm in karkheh river reservoir system in order to minimize water deficit in the downstream and maximize the total p tp load allocation however reaching such high levels of cooperation as assumed by aforementioned researchers in the real world can be an ambitious goal due to divergent interests and conflicting objectives of different stakeholders involved in decision making process given that water withdrawals and water quality are not necessarily conflicting targets efstratiadis and hadjibiros 2011 some level of cooperation can be expected to exist among water users and environmentalists to reach an agreeable management plan social choice methods aim to reach a collective choice by ranking the alternatives regarding each criterion the limited applications of social choice methods in water resources management have been well reviewed in recent publications alizadeh et al 2017 de almeida filho et al 2017 ghodsi et al 2016 mahjouri and abbasi 2015 zolfagharipoor and ahmadi 2016 silva et al 2010 developed a group decision making model by collective alternative ranking using promethee ii method to combine the rankings conducted by water users industry and agriculture public sector and civil society to reach the whole group decision regarding eutrophication management in a watershed even though uncertainty analysis is overlooked the model provides a tool for promoting decentralized decision making estalaki et al 2016 proposed 15 combinations of water supply and water quality management plans for chitgar artificial lake as an urban lake employing swmm model to predict lake inflow water quality and vollenweider static model for lake response to different water management plans they used evidential reasoning as an mcdm and fuzzy borda count as a social choice method to select the best available lake water management scenario considering a group of stakeholders although the proposed methods were able to prevent conflicts among stakeholders none of the plans fully prevented the eutrophication of the lake the main aim of this paper is to provide a comprehensive framework for the management of quality and quantity of water in artificial lakes considering the utilities and constraints of the stakeholders the proposed methodology is employed to define and rank a set of 16 management scenarios for the chitgar artificial lake chal in tehran considering the main existing uncertainties in the river lake model in this framework the interactions of the upstream region as the source of pollution to the lake and the downstream region as the impacted area by the construction of the artificial lake are taken into account in the remainder of the paper first the proposed methodology is discussed in detail then the components of chitgar artificial lake system and its stakeholders are described in the next section the results of simulation models scenario developments and selecting the most preferred scenario is presented in the last section concluding remarks are provided 2 methodology a flowchart for the proposed framework is shown in fig 1 in the following sections main components of the proposed framework are discussed 2 1 identification of the system identification of the system is a process which gives a clear explanation of the system to be used in the next steps and includes identification and clustering of stakeholders as well as their viewpoints defining the objectives and boundaries of the system are the main outputs of system identification 2 1 1 identification of the system components this step is about data and information gathering and an initial assessment to define the purpose and boundaries of the system necessary information needs to be collected and be provided to stakeholders in order to help them to understand the system and properly identify their priorities at this stage as it can be seen in fig 1 identification of components can be conducted at various levels the selection of the level of identifications highly depends on the anticipated depth of identification and is limited by time and budget conducting the first level is mandatory but more thorough investigations are discretionary the aim of the first layer is to form an initial overall view of water resources and consumptions as well as the pollutions this provides the stakeholders with basic information to use as the starting point to find a common ground the aim of the second layer is to establish a basis for delving deeper into the issue by separating the surface and ground water resources various consumptions as well as point and diffusive sources of pollutions the third layer provides thorough and detailed information for specialist identification of system components by separating every water resource and source of pollution as well as the efficiency of every water consumption section regardless of the level of components identification ecological status and issues of the lake should be meticulously explored to have a clear vision of artificial lake s water quality problem indices consisting of one or more variables for lake eutrophication assessment can be used but the trophic state is the integrated definition of the lake s nutritional status thus it is commonly accepted that there is no single trophic variable able to completely describe the concept of eutrophication carlson 1977 developed a method for trophic classification of lakes based on nutrient concentration algal biomass and particulate matter in the water column namely the trophic state index tsi the trophic state concept was later developed to visually identify the limiting factor of algal growth by carlson 1991 as well as carlson and havens 2005 the graphical interpretation of tsi indices for tp and chlorophyll a concentrations as well as secchi disk transparency depth used in this paper is from carlson and havens 2005 2 1 2 identification of the stakeholders identification of the stakeholders and the components is a requirement for system identification the steps of stakeholder participation in environmental projects as presented in fig 1 consist of stakeholder identification stakeholder characterization and structuration the definition of the degree of involvement selection of the participatory techniques and implementation the aforementioned steps are thoroughly reviewed and explained by luyet et al 2012 the main goal of the system is selected according to results of experts analyses and consultation with stakeholders delineation of system boundaries is a very critical step since the inappropriate boundaries raise resistance against ratified policies the boundaries can be defined at the scale in which the impacts of issues are observed or at the scale in which the impact of responses to the issues is predicted to be observed however these boundaries do not necessarily coexist and as a consequence the boundaries rely on the specific issue of interest and the type of the problem atkins et al 2011 svarstad et al 2008 2 2 simulation models generally a lake water quantity and quality simulation model along with a water resources allocation model should be developed at this stage the selection of models in terms of their complexity and accuracy highly depends on the requirements which are defined in the identification of the system process and the availability of data 2 2 1 modeling p losses in the watershed generally p inputs to water bodies are from point and nonpoint diffusive sources although some overlap may exist between the two sources unlike point sources which are directly discharged into the river diffusive sources are transported into the rivers through indirect paths e g through snowmelt or rainfall events with the wash of manure and fertilizer in order to simulate the p export from a watershed with the allotment of point and diffusive sources load apportionment modeling lam method is employed lam is a statistical regression based approach developed by bowes et al 2008 which expresses the load of p export from a watershed as a function of its volumetric flow rate bowes et al 2008 1 f tp f p f d a q b c q d 2 c tp a q b 1 c q d 1 where f tp is the tp load mgp s f p and f d are respectively the load from point and diffusive sources mgp s q is the volumetric flow rate m3 s and c tp is the tp concentration mgp m3 the parameters a b c and d are empirical coefficients which should be calibrated eq 2 is derived from eq 1 by dividing the sides of equation by volumetric flow rate the p loads from point sources are constantly discharging into river thus with the increase of river flow the contribution of point sources to total load should be reduced because of dilution hence b is assumed to be smaller than 1 the diffusive sources of p are supposed to increase with the increase of river flow as the sediment production increases due to rainfall or snowmelt hence d is assumed to be equal or greater than 1 bowes et al 2008 greene et al 2011 assumed typical values of b 0 and d 2 and added a third term to eq 1 for relating the depletion of diffusive sources and transformed respectively eqs 1 and 2 to eqs 3 and 4 3 f tp f p f d a b q 2 c q 3 4 c tp a q 1 b q c q 2 where a b and c are model s empirical parameters to be set once the lam model is calibrated and validated against a set of observations of river discharges and tp concentrations the model can be used to generate the tp concentrations using daily river flow rates and apportion the share of point and diffusive sources in any given time span with a daily time step 2 2 2 modeling the lake quantity and quality there exist a wide variety of lake ecosystem simulation models from static models to predict lake tp concentration as a function of the tp concentration in the river and the lake theoretical retention time to dynamic models with static or dynamic structures to individual agent based models for simulating the individuals behavior and interactions brett and benjamin 2007 jørgensen and fath 2011 robson 2014 choosing the appropriate depends on the availability of data and the aim of modeling in this paper a general dynamic process based mass balance model for tp in natural lakes i e lakemab is coupled with a water balance model for an artificial lake the proposed steps for developing the water balance model as well as steps for adapting the lakemab model to the artificial lakes is explained in appendix a 2 2 3 water demands and supply model the components of water demands and supply model are selected based on the results of the system identification phase with some computational effort it is possible to simulate the water demands and supply with mass balance modeling in arid and semi arid regions rivers play an important role in recharging the underlying aquifers thus in this paper the simple routing method for water losing rivers developed by rao and maurer 1996 is used for estimating the infiltration along rivers 5 o i γ d 1 γ 6 γ b 1 b 7 q ah b where o and i are respectively daily inflow and outflow of the river reach m3 s γ is a parameter calculated by eq 6 and d is a parameter to be calibrated against a set of observational data of inflows and outflows the b parameter in eq 6 is the power of flow depth h m in the stage discharge relation of eq 7 where q is the river discharge m3 s the difference between inflow and outflow of the river is the transmission loss which is assumed as aquifer recharge 2 3 scenario development in this stage a number of lake water management scenarios are developed to be used in the social choice stage in order to engage all or at least most of the upstream and downstream stakeholders in the voting process each scenario is comprised of one water intake and outtake rule curve and one set of upstream and in lake management practices the operation of artificial lakes is a complex and nonlinear problem thus rule curves as static and simple operational rules are used for the real time operation of the artificial lake hydrologic manipulations are arbitrary water transfer or withdrawal plans for a lake with the aim to improve the water quality and prevent or mitigate eutrophication in this paper an attempt to find the best attainable set of hydrological manipulations in terms of eutrophication is conducted by development of water intake outtake rule curves using the following optimization model 2 3 1 optimization of operational rule curves the proposed optimization model includes two objectives the first one is to minimize the pollutant concentration in the lake and the second one is to minimize the deviation from the rule curve during operation in regard to the eutrophication indicators e g tp and chlorophyll a concentrations the variation of values during the year is more important than the annual mean values håkanson and boulion 2002 by considering the eutrophication as the exceedance from mesotrophic state i e chl a 10 mg m3 and c tp 40 mgp m3 the probability of eutrophication pe intensity of eutrophication ie and risk of eutrophication re indices are defined as follows 8 pe n e n t 9 ie i 1 n t c tp i c tp all n e i c tp i c tp all 10 re pe ie i 1 n t c tp i c tp all n t i c tp i c tp all where c tp i is the mean tp concentration in the i th month of simulation mgp m3 c tp all is the allowed mean monthly tp concentration which in this study is set to 40 mgp m3 based on lake classification by håkanson and boulion 2002 n e is the number of months that c tp i exceeds the c tp all and n t is the total number of months in the planning horizon the response of the lake to hydrologic manipulations in the study area specifies which index should be considered as the criterion for defining the first objective function of the optimization model in the case study of this paper previous studies e g mahmoudi anzabi 2014 as well as some initial optimizations showed that hydrologic manipulations cannot fully prevent eutrophication hence considering minimization of the intensity of eutrophication as the first objective function the optimization model is defined as follows 11 min z 1 j 1 m i n 1 n 2 c tp i j c tp all n e i j c tp i j c tp all 12 min z 2 m i 1 12 rci i j 1 m i 1 12 ri i j m subject to 13 0 rci i rci max 14 0 rco i rco max 15 s i 1 j s i j ri i j rain i j evap i j rco i loss i j 16 s min s i j s max 17 ri i j rci i 18 if s i 1 j s max then ri i j s max s i j rain i j evap i j rco i loss i j where c tp i j is the mean tp concentration in the i th month of the j th year mgp m3 and rci i is the rule curve water intake for the i th month million cubic meters mcm month which is limited between zero no water intake month and rci max which is set to be the intake facility capacity ri i j is the real water intake in the i th month of the j th year mcm month which is equal to the rule curve water intake of the month unless it causes the lake to spill which is then restricted to the value which only fills the lake to its maximum capacity rco i is the rule curve for water outtake in the i th month mcm month which is repeated each year without any allowed deviation because the source of deviation from outtake rule curve is that lake storage will fall below minimum storage which is an unfavorable situation water outtake rule curve is restricted to zero no water outtake and rco max which is determined by the stability of dam and capacity of outlets s i j is the storage of lake in the i th month of the j th year mcm which is restricted by minimum and maximum operational values of the lake rain i j is the direct precipitation onto lake surface mcm month evap i j is the estimated evaporation of water from lake surface mcm month and loss i j is the water loss from lakebed mcm month in the i th month of the j th year the proposed optimization model is solved using non dominated sorting genetic algorithm nsga ii with two objectives and the result is a set of non dominated solutions termed as the pareto front selecting a fair solution among them is conducted using technique for order preference by similarity to ideal solution topsis mcdm method the basic concept of topsis method is that the best alternative should have the closest distance from the positive ideal solution most preferable and simultaneously the remotest distance from the negative ideal solution least preferable hwang and yoon 1981 here the positive ideal solution is corresponding to the minimum attainable value of eutrophication intensity and minimum attainable deviation from water intake rule curve on the contrary the negative ideal solution is the maximum attainable value of the two objective functions since topsis uses the normalized values of criteria and weighted euclidean distance to ideal solutions the incommensurability of values does not appear as a problem hwang et al 1993 for more details on the topsis method the reader is referred to hwang and yoon 1981 2 3 2 evaluating the eutrophication risk management practices generating rational alternatives for the management of eutrophication needs the satisfaction of the components of the threefold framework of practicability evaluation i e i scientific validity ii economic consideration and iii sociopolitical considerations as discussed by gibson et al 2000 according to this framework a feasible management plan should be tested and verified to be scientifically valid financially affordable and socially and politically acceptable controlling point and diffusive sources of p in the watershed reducing p in water after diversion for the lake as well as recycling the lake water i e withdrawal of lake water reduction of its p and returning the water to the lake and controlling internal sources of p are eutrophication risk management practices which can aim at preventing algal bloom as opposed to the end of pipe practices which aim at reducing the current high algal mass see lürling et al 2016 for more details reduction of p sources in the watershed is simulated by a reduction coefficient in lam model based on the impact on point and diffusive sources recycling is also simulated using the lakemab fluxes concept and these fluxes are incorporated into mass balance differential equations alum al2 so4 3 treatment is used to control the internal loads and it is supposed to reduce the internal diffusion from sediments from 80 to more than 95 with a conservative mean of 85 cooke et al 2005 thus the rate of diffusion in lakemab is considered to be reduced by 85 for simulation of alum treatment 2 4 social choice in this section the principals of discrete and fuzzy social choice using the borda count method are presented social choice procedures are used to aggregate the preferences and interests of a group of voters decision makers in order to achieve a collective and fair decision among a number of alternatives in case of the high reliability of knowledge about the system the discrete borda count can be used in which all models parameters are expected to be known with high certainty in this method each stakeholder makes a pairwise comparison between available alternatives and assigns a score of 1 to the preferred alternative while the less preferable alternative receives a score of 0 hence the total score each alternative receives from each stakeholder is equal to the number of times that it is preferred to other alternatives by that stakeholder after summing the total scores of alternatives multiplied by stakeholders relative weight the collective group decision is the alternative with the highest score garcía lapresta and martínez panero 2002 uncertainty in the structure inputs and parameters of the models can affect the accuracy of their results thus finding an appropriate way to account for uncertainties is necessary in order to take the uncertainties of the simulation models into consideration the fuzzy borda count method proposed by garcía lapresta and martínez panero 2002 is employed some additional steps for defining the uncertain and sensitive parameters and inputs should be done and among all model parameters those which have more impact on the results should be determined by sensitivity analysis the sensitivity analysis is to repeat the simulations by changing model s parameters and comparing the results with those of modeling with initial deterministic values the relative change in the model outputs in this process is a measure to select sensitive parameters among all uncertain parameters in fuzzy borda count method stakeholders not only choose the preferred alternative to the others but also present numerically how much the alternative is preferred to the others with magnitudes from 0 to 1 the calculation of the degree of preference in this paper is conducted using interval numbers proposed by jiang et al 2008 the details and formulae of both discrete and fuzzy borda count procedures as well as the interval numbers used in this paper are presented in the on line supplementary material 3 case study chitgar artificial lake in tehran iran 3 1 identification of the system s components a schematic representation of the system s important components which are described in the identification process is presented in fig 2 a more detailed map of the study area is provided in the on line supplementary material 3 1 1 chitgar artificial lake chitgar artificial lake chal is countrywide the largest intra urban artificial lake for recreational purposes located in district 22 of tehran 35 44 20 35 45 03 n 51 12 21 51 13 21 e the physical characteristics of chal and its dam are presented in table 1 the basic plan of chal in the 1960s was to serve as a flood retention pond for its upstream urban watershed but after four decades of postponing the construction due to lack of funding and low priority it was constructed as a recreational off stream lake between 2010 and 2013 mgcec and pöyry 2011 several studies before the construction of the lake revealed that chal is susceptible to eutrophication and among the water supply scenarios for the lake the more the lake receives urban runoff and treated wastewater the more the risk of its eutrophication e g shamabadi 2007 vatanparast 2011 thus to reduce the concentration of nutrients chal is hydrologically isolated from its urban watershed i e the urban runoff channels bypass the lake and the main water supply source for the lake is kan river although water infiltration into the adjacent aquifer through the lake bed could be a significant recharge source for groundwater the lake bed is insulated with a geomembrane layer in order to maintain the lake at a stable water level for recreational purposes year round hence the sole water output is currently evaporation which is estimated to be about 2 mcm year stpcec 2012 the outtake of water from the valve of the chal dam at the maximum rate of 0 4 m3 s is supposed to be diverted again to kan river due to the problems it can impose on urban downstream channels the water transfer system from kan river to chal consists of a small concrete dam on kan river and a fiberglass pipeline the diversion dam with 4 7 m height and 38 3 m width provides enough head for water to flow through the 7 1 km long pipeline which has the capacity of 1 2 m3 s the chal diversion dam 35 45 54 n 51 15 55 e very well separates the mountainous rural and undeveloped upstream kan watershed from its flat plain urbanized and agriculturally developed downstream a summary of the water quality in chal and the comparison with the water quality standards of iran department of environment idoe 2016 for recreational purposes and conservation of aquatic ecosystems is presented in table 2 as it can be seen most of the chemical parameters are well maintained in the standard range e g dissolved oxygen ph chlorophyll a and the coliform bacteria some of the parameters have slight exceedances of the standard e g the biological oxygen demand especially in spring exceeds the standard and it seems that presence of tourists trying to feed the fish and the migrant birds is a reason for it although nitrite an intermediate product in nitrification processes exceeds the standard its values are well maintained below the protective concentration level of 0 1 mgn l lewis and morris 1986 in addition to the fact that the total nitrogen concentration is completely below the drinking water standard of 10 mgn l and the nitrogen does not seem to be a critical issue as the lake volume gradually decreases from spring to fall the concentration of total phosphorus increases and exceeds the standard and approaches the eutrophic level for more thorough investigation of chal eutrophication issue 12 trios of simultaneous measurements of c tp chl a and sd from spring to autumn of 2014 are used considering the average the values of tsi tp tsi sd and tsi chl are respectively equal to 58 4 39 3 and 31 0 which show that although the lake is in mesotrophic level in terms of sd and chl a it is in eutrophic level in terms of c tp håkanson and boulion 2002 when the tsi chl is smaller than the tsi sd particulate matters in the lake water are not necessarily related to algae and the fact that tsi tp is greater than both of them indicates that factors other than p e g n or high grazing pressure is limiting the growth of phytoplankton carlson and havens 2005 the graphical presentation of the details fig 3 indicates that almost always there is p surplus in chal the molar ratios of c n n p and c p are respectively equal to 7 4 117 and 868 which indicate that c and n exist in abundance and are not limiting nutrients for algal growth wetzel 2001 it seems that the biomanipulation conducted by the lake manager by releasing more than two million fishes of which 95 are aggressive species that feed on phytoplankton ramin et al 2016 is the limiting factor of algae growth attayde et al 2010 however in case the current limiting factor fails to control the algae growth due to the fact that the tsi tp is in the eutrophic level the algae biomass will grow to the eutrophic level hence the lake management plans should focus on restricting the tp concentration in mesotrophic levels i e 40 mgp m3 also the fact that osgood index of chal table 1 is smaller than 6 indicates that the chal is a shallow and polymictic lake and that internal loading of p can be significant osgood 1988 3 1 2 upstream kan watershed upstream of diversion dam kan river is the largest river by discharge running through tehran city and the upstream kan river watershed hereafter only referred to as kan watershed is located in the northwest of the city the area of kan watershed is 215 km2 and with an average rainfall of 640 mm year the total discharge of watershed is 76 3 mcm year on long term average with 82 of watershed surface comprised of low permeable rocks kan watershed is prone to floods and no significant aquifer is developed there water research institute 2011 more than 90 of kan watershed land is covered with varieties of grassland from poor to rich and no more than 5 of the land is covered with good vegetation cover which is mainly the fruit orchards located on the river banks at the very bottom of valleys there are seven villages in the kan watershed with the population of 4637 as of the 2011 census the population of the upstream region has increased with the low rate of 1 2 from 1966 to 2011 compared to the nationwide rate of 4 2 over the same period the low rate is mainly due to the depopulation of rural areas thus a significant increase in the population is not anticipated more investigations regarding the sources of pollution in the kan watershed is presented in the on line supplementary material 3 1 3 downstream kan river watershed and related water transfer plans downstream of diversion dam after the chal diversion dam kan river flows on a permeable riverbed with coarse materials on top of an alluvial fan hence during summer this section of the river is dried up the spent filter backwash water of the water treatment plant no 2 of tehran is discharged to kan river in 3 8 km downstream of the diversion dam with the amount of 5 3 mcm year the west flood diversion channel wfdc which is comprised of tehran s northwestern rivers urban runoff and treated domestic wastewater discharges into kan river at about 6 1 km downstream of diversion dam the amount of water discharged from wfdc to kan river is 58 mcm year based on the sole observation period in 2007 2008 yekom consulting engineers 2009 the wfdc flow variation is less than that of kan river and the water flow in the kan river in dry seasons is actually from wfdc discharge after exiting the tehran city kan river enters the southern agricultural region of tehran which is irrigated with a complex network consisting of channels of treated untreated domestic wastewater and urban runoff the agricultural fields linked with kan river are divided into three groups namely kan1 navvab2 and kan2 the area under cultivation and the demand for surface water in each agricultural region are presented in table 3 the kan1 region is located upstream of navvab diversion facility which diverts the kan river to navvab2 channel the navvab2 channel flow is comprised of diverted flow from kan river as well as a 0 4 m3 s of water flow from navvab1 channel which is originated from salehabad qanat in the southern urban watershed of tehran maogce 2012 kashanak hydrometric station measures the flow in navvab2 channel which is 44 8 mcm year of which 32 8 mcm year is from kan river the navvab2 channel empties to fashafouyeh plain the very downstream plain of karaj river basin which suffers a prolonged water shortage the 3812 ha of arable land in this plain is highly dependent upon flow from navvab2 channel which is 19 0 mcm year as measured in fashafouyeh hydrometric station the floods greater than the navvab2 capacity designed for 5 m3 s but operated at 2 m3 s due to high sedimentation rate flow through the natural kan river pathway toward the kan2 agricultural region maogce 2012 yekom consulting engineers 2009 the janahabad hydrometric station measures the flow in this section which is 42 0 mcm year however field observations show that the irrigation in kan2 region is solely dependent upon the stable flow from salehabad primary treated urban surface runoff originated from the southern urban watershed of tehran rather than the seasonal floods in the kan river the kan river joins the jajrood river which finally flows to bandalikhan wetland and its downstream grasslands which shows the importance of kan floods to implement environmental flows 3 2 identification of stakeholders for identification of system stakeholders after developing the initial list of stakeholders related to management of chal and its water resources system it was found out that most of them are fully or partly governmental hence characterization and structuration of stakeholders are conducted using their rank in the pyramid of power and the result is presented in fig 4 the stakeholders are grouped into four levels according to their relative powers with the first and second levels having legislative power and the third and fourth levels with more operational aspects which act as law enforcement agents for the upper levels the relationship between stakeholders is shown with either two way arrows which represent the cooperation or one way arrows which stand for the commanding power of the organization and its ability to veto the dominated organization s decisions the relationships are presented in table 4 in addition more information regarding the objectives and tasks of the stakeholders is provided in the on line supplementary material 3 3 the boundaries and the main goal of the system considering the identified system components the downstream boundary of the kan river watershed is assumed to be jahanabad station due to the transfer of water from kan river to fashafouyeh plain the delivered water in the fashafouyeh station is also taken into account the system boundaries that indicate which components of the system should be included in the simulation model are presented in fig 2 for defining the main goal of the system technical reports regarding water related aspects of the identified stakeholders are reviewed and some experts in different organizations are interviewed the main issues of the system are categorized into three groups hydrological imbalance of groundwater resources rising and falling water tables in different locations the large quantity of wastewater discharged into the aquifer and downstream rivers and flood related issues see on line supplementary material for more details the goal of the system regarding chal management is defined as management of quality and quantity of chitgar artificial lake with minimized negative impacts on the stakeholders in the study area 4 results 4 1 simulation models 4 1 1 load apportionment model lam the dataset to be used in the calibration and validation of lam model is comprised of 56 pairs of tp concentration and discharge data of which 43 data are weekly or bi weekly observations from april 2012 to march 2013 and 13 data are monthly observations from the winter to the summer of 2011 as well as the spring and the autumn of 2014 the former is used for the calibration of model and separation of dry and wet periods due to better coherence and the latter is used for the validation of the calibrated model although the dry period in tehran region is often from may to october the observations of tp concentration in april also followed that of the dry period hence two models are developed one for the dry period from the beginning of april to the end of october and the other for the wet period among the two versions the first one developed by bowes et al 2008 and the second one by greene et al 2011 of lam model which were calibrated against the observations in both periods the first one overperformed as presented in table 5 the calibrated parameters and the 95 confidence bounds for model parameters are presented in table 6 the load apportionment models for both dry and wet periods the data which were used for training the models as well as the confidence bounds for model parameters are also presented in fig 5 using the lam model the load of tp is simulated in both calibration and validation periods as presented in fig 6 the results indicate that 7 4 3 5 14 9 tonp year is transported out of kan watershed via the river the contribution of point sources is estimated to be 0 7 0 5 0 9 tonp year and the contribution of diffusive sources is estimated to be 6 7 3 0 14 0 tonp year although the diffusive sources have negligible loss of p during the dry period table 6 they are the dominant contributor to p load year around and the contribution of them is estimated to be 91 with lower bound of 77 and upper bound of 97 the annual average of tp concentration is also estimated to be 68 mgp m3 ranging from 32 to 136 mgp m3 it is worth considering that the separation of periods may differ from year to year and more observations with at least weekly frequencies are required to conclude more general results moreover during the rising limb and peak of flood hydrograph the deposited p in the riverbed is washed off and daily or even intra daily observations are required to model the load of p from the watershed with high certainty bowes et al 2008 4 1 2 lakemab for modeling the phosphorus dynamics in chal at first the water balance model of the lake is developed using the area volume elevation curves for chal see fig 7 maximum depth and surface area of chal is modeled as a function of lake volume in every step as follows 19 d max 4 151 v 0 389 0 001445 v 3 169 20 area 60 85 v 0 584 0 v 1 91 77 70 v 59 64 1 91 v 2 32 1 64 v 116 60 2 32 v where d max is the maximum depth of lake m v is the volume of the lake mcm and area is the surface area ha for the simulation of evaporation detrended data from mehrabad airport synoptic station 35 41 36 n 51 18 32 e and elevation of 1196 m a s l which is located 10 km south east of chal is employed mean monthly long term data of air temperature dew point and wind speed from 1951 to 2013 are obtained and trend analyses are conducted using the trend software which has been developed on the basis of grayson et al 1996 and kundzewicz and robson 2000 based on the results of trend detection methods the temperature and dew point show a statistically significant increasing trend at a significance level of 0 01 while the wind speed and rainfall show no statistically significant trend the long term detrended average of monthly data as presented in table 7 and fig 8 are used for simulation of water balance model of chal from march 2014 to january 2016 given the initial volume of 5 mcm at the beginning of march 2014 and 23 monthly data of water intake for the lake the lake volume is calculated at the end of january 2016 in order to verify the developed water balance model the lake volume at the end of verification period is 6 95 mcm while the model prediction is 6 82 mcm i e a relative error of 1 9 the temperature submodel of lakemab underestimates the mean annual epilimnion temperature of chal with a great error i e 12 c instead of the real value of 18 c thus the mean monthly temperatures of chal are manually inputted based on the observations the temperature data also show that chal is a warm polymictic lake and has not experienced any iced surface the calibration and validation of lakemab against 25 mean monthly data of tp from march 2014 to april 2016 are conducted using the genetic algorithm based on limited observations the concentration of tp in the collected rainwater near chal is estimated to be at least 45 mgp m3 hence the wet deposition of p is at least 12 1 mgp m2 year supposing that wet deposition account for one third of total deposition of p in semi arid regions tipping et al 2014 vet et al 2014 wetzel 2001 the total deposition of p on chal is at least 36 3 mgp m2 year however in a try and error effort outside the calibration and validation process the atmospheric deposition of p is set to global average which is 43 mgp m2 year with uniform distribution during the year tipping et al 2014 the calibrated parameters and their boundaries are presented in table 8 the r squared values are respectively equal to 0 70 and 0 64 for the calibration and validation periods and the results are presented in fig 9 in the calibration and validation period 64 of the total load of tp to the water column is internal loading 54 diffusion from sediments in accumulation areas and 10 resuspension from sediments in et areas and the rest 36 is from external loading 30 from kan river and groundwater and 6 from atmospheric deposition since sediments act as both a source and a sink of p the internal loading can be expressed as gross and net loadings which the settlement of particulate p is considered in the latter nürnberg 2009 the gross internal loading in chal is 438 mgp m2 year and the external loading is 249 mgp m2 year the annual amount of net internal loading is 204 mgp m2 year in which the negative value indicates that generally the sediments act as sink of p although the net internal loading in most of the months is negative it bears positive value in the spring after the water intake has just finished as presented in fig 10 this is due to the fact that the settlement of newly entered particulate matters which increases the rate of diffusion is coupled with warm water i e temperatures higher than 12 c which increases the bioturbation håkanson and bryhn 2008 søndergaard et al 2013 4 1 3 water demands and supply model although the water demands and supply model has monthly time steps in order to differentiate between flood and non flood flows the calculations are conducted using daily data of flows and a sub model is employed to convert the daily data to monthly data the monthly water intake for chal is subtracted from the daily discharge of kan river in allowable days i e days in which discharge is lower or higher than defined flood threshold the outtake of chal is supposed to be discharged into the kan river in the upstream section of wfdc the wfdc does not have any hydrometric station hence the flow data for it should be produced which is conducted using the artificial neural network ann method in this study using average rainfall on wfdc watershed and the number of months in the hydrological year an ann with one hidden layer is developed the developed network is trained validated and tested against 37 observational data on wfdc flow from march 2007 to april 2008 the results indicate that the network can simulate the flow of wfdc with good accuracy and the r squared value for simulation of average discharge from march 2007 to april 2008 is 0 97 the developed ann model is used for simulation of average discharge of wfdc from october 1992 to september 2013 it is supposed that the daily discharge of wfdc is equal to the average monthly value since not only the generation of daily data needs more complex rainfall runoff models but also the field observations show that this simplifying hypothesis is justified for the calculation of aquifer recharge from the kan river bed the parameter b in eq 7 is set to 2 5 as a typical value for a wide range of rivers leopold and maddock 1953 park 1977 the parameter d in the eq 5 is set to 0 53 so that the recharge of the aquifer from kan river bed in the upstream of navvab diversion facility from march 2011 to february 2012 equals 42 0 mcm as calculated by malakpour estalaki 2018 the flow discharges up to 2 m3 s at the navvab diversion facility are diverted to navvab2 channel and the rest in days that discharge flow is greater than 2 m3 s flows through the natural kan river pathway the verification of the developed model is conducted using the 21 years of historical data at two checkpoints i e the navvab diversion facility sum of flows at jahanabad and kashanak hydrometric stations with r 2 0 74 as well as the flow of water delivered to fashafouyeh plain the fashafouyeh hydrometric station with r 2 0 51 as presented in fig 11 4 2 scenario development 4 2 1 water intake and outtake plans the kan river in the chal diversion dam section is often dry from june to october and the few exceptions are mostly the summer flash floods high in suspended matters and sediments hence these five months are excluded from all of the water intake plans two types of optimized and non optimized rules for water intake are developed which the former is called water intake rule curve since the rule curves represent the best achievable hydrologic manipulation for the control of eutrophication it is assumed that the water intake rule curve is only applied in days with the lowest tp concentration namely the non flood flows based on the engineering judgment and the results of lam model the non flood flows are assumed as days in which the discharge is between 0 2 and 3 m3 s in the wet period november march and from 0 2 to 8 m3 s in the allowable months of dry period april and may the rci max for chal is 3 1 mcm month and the rco max is set to 1 mcm month the s min and s max are respectively set as 4 5 and 7 0 mcm and the loss of water from lakebed is set to zero due to its strict insulation with geomembrane since the initial optimizations showed that there is no water intake rule curve which can completely keep the lake tp concentration below the allowed 40 mgp m3 during the 21 years of long term model the minimization of the intensity of eutrophication in the high algal growth months of year i e april october is selected as the first objective function the optimizations are conducted using five plans which the first four plans assume no water outtake from lake thus the lake is closed but in the fifth plan the lake outtake rule curve is also allowed to be optimized the difference among the closed lake rule curves is the allowable months for water intake in which all start in november and end in varying months from february to may lasting for 4 7 months the obtained pareto optimal solutions are ranked using topsis with the weight of 0 7 for eutrophication intensity and 0 3 for the deviation from the rule curve and the best solution is selected as presented in fig 12 and table 9 it should be noticed that the results showed that the 5 months water intake rule curve is similar to the 4 months rule curve since all days of the march in most of the years have the discharge flow greater than flood threshold thus 5 months water intake rule curve was removed from the water intake plans although the non flood flows have lower p and sediment which is favorable for chal managers the navvab2 and fashafouyeh farmers rely on the transferred water from the kan river which is derived from non flood flows due to the limited capacity of the channel hence three plans for water intake for chal from flood flows are developed the first plan namely closed lake and water intake from flood flows assumes that in all the days that flow discharge is greater than a defined flood threshold water can be withdrawn for chal and the lake manager lets water to be transferred to lake till the lake is filled up to its capacity in the allowable months i e november may as presented in fig 13 by selecting the 3 m3 s as the threshold the volume of water transferred to navvab2 channel does not reduce the second plan namely open lake and water intake from flood flows assumes that in all the days that flow discharge is greater than a defined flood threshold water is withdrawn for chal and as long as the lake volume is 7 mcm the water is also outtaken with the capacity of 0 4 m3 s actually in this plan the water intake is limited by the capacity of outtake system the flood threshold for this plan so that the water transfer to navvab2 channel is not reduced is 2 75 m3 s the third plan is similar to the first plan namely closed lake and water intake from selected non flood flows in which water is withdrawn from flow discharges between 2 5 and 3 m3 s in november march and from flow discharges between 2 5 and 8 m3 s in april and may this plan intends to establish a balance between chal and downstream agricultural lands needs for non flood flows 4 2 2 p reduction plans since none of the aforementioned water intake outtake plans can keep the lake in mesotrophic level they are integrated with p management plans as it is explained in section 2 3 2 it is recommended that management plans be assessed using the threefold framework of practicability gibson et al 2000 not only should the plans have scientific validity but they also should be financially affordable by the community and socially and politically acceptable since a scientifically rational and cost effective plan but conflicting with local community s collective values will most probably be unsuccessful the water intake outtake plans which were developed in section 4 2 1 are coupled with three phosphorus management plans which finally resulted in 16 management scenarios as presented in table 10 the more detailed explanation of the plans as well as the practicability analysis of them is provided in appendix b 4 3 social choice 4 3 1 the utility of stakeholders in this section the utility of stakeholders in the management of chal for achieving social choice is developed some of the stakeholders which are close to each other in terms of goals and tasks can form a coalition the tpg as the most powerful stakeholder is interested in maintaining a balance between conflicting stakeholders so that the security of the system is not affected hence its utility is a mixture of other stakeholders utilities with the same weight idoe is interested in environmental facets of the system i e highest environmental flow highest inflow to fashafouyeh plain highest recharge of the aquifer and lowest risk of eutrophication for trwc the recharge of the aquifer is the most important utility while it is interested in selling more water to chal managers since the price of water for chal is 10 billion iranian rials irr per mcm while supplying the demand of downstream agriculture tcc and tehran municipality form a coalition and their utility is the lowest risk of eutrophication as well as the lowest operational cost for chal including the price of water twwc and trwwc form a coalition and highest recharge of the aquifer is their utility moreover the scenarios containing the treatment of wastewater in kan watershed are preferred receiving the score equal to 1 to other scenarios receiving the score of 0 by this coalition tajo and dnrwmt form a coalition and their utility is the supply of water for downstream agriculture as well as environmental flow the relative weight of each agricultural unit is calculated using their cultivated area and the relative weight for environmental flow is considered to be equal to the one for kan1 agricultural unit the standardized weights of stakeholders according to their power and the weight of each criterion in calculating the total utility of each stakeholder as determined by engineering judgment is presented in table 11 4 3 2 sensitivity analysis of uncertain parameters due to the lack of sufficient data newness of the chal as well as its unique characteristics such as being a closed lake the insulation of lake bed from infiltration lack of macrophytes and the intense biomanipulation in lake by releasing aggressive fish species and difficulties in conducting field measurements the model parameters and consequently the results are uncertain the selection of uncertain parameters is conducted based on engineering judgments and the insights gained into the problem during the data preparation and simulation models development by reason of the relatively short time span on which the quality of kan river was measured the calibrated parameters of lam model are selected for sensitivity analysis over their 95 confidence bound the existence of surplus p in chal water fig 3 beside the alteration of fish species makes the particulate fraction pf of phosphorus in both intake and no intake months a candidate for uncertain parameters atmospheric deposition of p adp as an external sources of p was set to the average global value reported by tipping et al 2014 is an uncertain parameter and one standard deviation interval is selected for its sensitivity analysis due to lack of macrophytes in the newly constructed lake the rate of diffusion of p from sediments r diff is an uncertain parameter the interval of uncertain parameters and the basis for selecting the intervals is presented in table 12 the changes in the risk of eutrophication are expressed as relative changes in the lower and upper values of the interval of parameters in order to achieve a comprehensive view of the sensitivity analysis the analysis is conducted in different water intake outtake plans as presented in fig 14 a more thorough investigation of fig 14 shows that the risk of eutrophication is highly sensitive to the external load of p from kan watershed especially when the closed lake is operated under an open lake scheme i e continuous and simultaneous water intake and outtake fig 14d the particulate fraction pf of p especially in no intake periods is also a very sensitive parameter in terms of the risk of eutrophication as is the atmospheric deposition of p adp especially in closed lake management plans given the threshold of 25 change in the risk of eutrophication for changes over the interval of uncertain parameters the lam parameters pf no intake and adp are selected as uncertain and sensitive parameters the high sensitivity of the risk of eutrophication to particulate fraction of p in no intake months highlights the importance of internal recycling processes of p in closed chal which should be meticulously investigated in addition the very high sensitivity of the risk of eutrophication index to external loading in open lake management plan puts an emphasis on the importance of external loading of p in eutrophication of chal in case its managers decide to operate it as an open lake 4 3 3 the borda count in this section firstly the performance criteria that constitute the utility of stakeholders are presented in table 13 two of the criteria i e risk of eutrophication and cost of lake management are also presented as interval numbers beside their deterministic value in order to be used in the fuzzy borda count the initial costs are considered for the base year i e 2015 and the operation and maintenance costs are all transferred to the base year with the assumption of similar inflation and interest rates over the course of 21 years of simulation the average scores of different scenarios in the discrete and fuzzy borda count are presented in fig 15 scenario number 14 outstandingly dominates the other scenarios in the discrete approach followed by scenarios number 9 and 11 actually five out of seven scenarios that contain alum treatment are the first ranked scenarios due to the dominance of internal loading as the main source of p to the water column in the lake which is well controlled by the cost effective alum treatment which is strongly in accordance with the results of huser et al 2016b in the fuzzy approach scenario number 16 dominates other scenarios followed by scenarios number 12 and 14 the significant uncertainties associated with the external loadings both kan river and atmospheric deposition with a great contribution to the load of p to water column is the main reason for relatively expensive water treatment plant to be the dominant scenario however in both approaches the dominant scenario is comprised of water intake from floods or selected non flood flows which is due to the importance of non flood flows for the recharge of the aquifer and downstream agricultural demands the utilities of stakeholders for the three first ranked scenarios of each approach are presented in fig 16 5 summary and conclusion in this paper a comprehensive framework was proposed for the management of quantity and quality of water in off stream artificial lakes in semi arid and arid regions considering the utilities of existing stakeholders the proposed framework was applied to the newly constructed chitgar artificial lake chal in tehran which is blamed for reducing the availability of water for the southern agricultural lands of tehran as well as its risk of eutrophication and algal bloom which impede its recreational purpose the lam and lakemab models respectively for simulation of p loss from kan watershed and simulation of p dynamics in chal were used in the context of a mass balance water demands and supply model a set of 16 scenarios for water intake and outtake plans as well as p management plans was developed considering their scientific validity economic and socio political considerations ranking the scenarios was also conducted using discrete and fuzzy borda count as a social choice method the results indicate that in the discrete approach scenario 14 was obviously the most preferred management plan for chal in this scenario not only water intake for lake is from flood flows flow discharges greater than 3 m3 s and the chal does not compete with downstream agricultural demands but also the cost of alum treatment for the control of internal loading which is the main source of p to water column of chal is relatively low however due to uncertainties associated with external loading of p in the fuzzy approach scenario 16 was ranked as the best solution it is due to the strict p reduction in the relatively expensive water treatment facility which is considered to be built beside the chal for the treatment of intake water as well as lake water in the no intake period the ranking of scenarios 12 and 14 as the second and the third best solutions in the fuzzy approach shows that by reducing the uncertainties associated with the external loadings the alum treatment is possible to be selected as the first solution in both approaches although specifically developed for the off stream artificial lakes in arid and semi arid regions the proposed framework is capable of being easily adapted for more conventional on stream artificial lakes in these regions especially in river systems where the construction of a large dam can impose the more significant and radical changes in the downstream region the incorporation of the concept of water food energy nexus in the framework is highly recommended the most important limitations of this study stem from the lack of high quality field observations for example measurement of different forms of particulate and dissolved p in lake water and the direct measurement of atmospheric deposition of p would be very useful in addition the frequency of sampling and measurement of kan river water quality parameters should be increased especially during the flood flows in the future works the methodology can be extended in order to take the fuzziness of the stakeholders utilities into account investigating the impacts of climate change on quality and quantity of river and lake can be another aspect of extending the proposed methodology in the case of chal investigating the impact of reversing the current biomanipulation by releasing carnivorous fishes to reduce planktivory and filter feeding pressure on zooplanktons as well as reducing the benthivory by carps seems to be necessary waajen et al 2016 also the share of kan watershed orchards in the diffusive sources of p is suggested to be investigated with appropriate models which can take into account the densely wooded aspect of the orchards exploring a management plan which not only reduces p in kan river but also reduces river degradation seems to be beneficial for almost all of the stakeholders acknowledgment helps from dr m tajrishy and dr d r arab for providing the observational data of the chitgar artificial lake and dr a bryhn for providing the source code of lakemab are kindly hereby appreciated appendix a lakemab is the latest version of a series of lake ecosystem models with a focus on eutrophication håkanson and bryhn 2008 from a mass balance viewpoint lakemab takes four compartments of p into consideration i surface water epilimnion ii deep water hypolimnion iii active sediments in erosion and transportation et areas iv active sediments in accumulation areas the separation of surface and deep water compartment as well as sediments in et and accumulation areas is conducted by a theoretical wave base the internal fluxes of tp amongst the four compartments include sedimentation of particulate p pp from epilimnion to hypolimnion and sediments in et areas and from hypolimnion to sediments in accumulation areas resuspension of pp from et areas to epilimnion and hypolimnion diffusion of dissolved p dp from sediments in accumulation areas to hypolimnion and the mixing of tp between surface and deep water under unstratified situation in lake the input fluxes include tp from watershed and atmosphere and the output flux of tp from epilimnion as well as the burial flux of tp under the 10 cm depth of active sediments in accumulation areas håkanson and bryhn 2008 the original lakemab code considers constant volume for lake during simulation period and contains a submodel for estimation of runoff from lake watershed in order to evaluate the input of tp as well as a submodel to estimate evaporation for evaluation of the output of tp these assumptions and water balance submodels work well for most european and north american natural lakes but not from a water resources management perspective for artificial lake systems most of the artificial lakes especially off stream lakes employ inflow and outflow rule curves in order to confine the framework to off stream artificial lakes both arbitrary water intake and outtake are considered arbitrary water intake can be simply replaced with a runoff simulation model or data from the upstream hydrometric station for adapting the framework to on stream artificial lakes for the simulation of evaporation well known aerodynamic method which models the evaporation as the production of vapor pressure deficit between the surface of water and air and a wind function is used in this paper the site specific wind function developed by mcjannet et al 2012 which considers the area of the water body and uses the conventional land based meteorological data is employed a 1 e f u 2 e sat e a a 2 f u 2 2 36 1 67 u 2 a 0 05 where e is the evaporation rate mm day e sat and e a are respectively saturated and partial vapor pressure of air kpa f u 2 is the wind function mm day kpa u 2 is the wind speed over land at the height of two meters m s and a is the area of water body m2 which ranges from 0 07 m2 to 33 5 km2 for the proposed wind function in addition to the significance of direct precipitation on lake which should be considered in lake water balance atmospheric deposition of p on lake can be an important source of nutrient for algal growth brahney et al 2015 tsugeki et al 2012 if not the main source of bioavailable p as in the case of lake kinneret eckert and nishri 2014 lakemab considers tp concentration of 5 mgp m3 in rainfall which is rational for high latitudes e g sweden where the lakemab has been developed recent studies by using global modeling of geographical patterns of p deposition have revealed a higher atmospheric deposition of p in lower latitudes wang et al 2014 as well as a significant contribution of local sources e g agricultural lands to deposition of p on lakes and land tipping et al 2014 under the lack of direct measurements of wet and dry atmospheric depositions the use of either the former s maps and depicted ranges or the latter s statistical mean and standard deviation in different continents is proposed for the estimation of atmospheric deposition of p the mixing between epilimnion and hypolimnion layers depends on the stratification lakemab contains a submodel developed by ottosson and abrahamsson 1998 to calculate the mean monthly temperature of the two layers the submodel calculates the mean annual temperature of epilimnion as a function of latitude n altitude in meters above sea level m a s l and distance from the ocean km and converts it to mean monthly temperatures of both epilimnion and hypolimnion based on physical characteristics of the lake calculation of mixing rate r mix 1 month is followed by a simple algorithm that is if the absolute difference between mean monthly epilimnion and hypolimnion temperature is smaller than 4 c then r mix is equal to 1 1 month i e lake is completely mixed as the difference between the two layers temperature increases r mix drastically drops with inverse proportion to the difference of temperature between the two layers the lake temperature submodel has been developed using data of european lakes and may be inappropriate for lakes outside of tested lakemab geographical domain thus for the artificial lakes which do not fall within spatial domain of the model lake s monthly mean epilimnion and hypolimnion temperature should be simulated or measured and be entered to model manually in order to participate only pp in lakemab sedimentation fluxes a particulate fraction pf which is the pp divided by tp is employed based on mean annual data from 10 swedish natural lakes håkanson and boulion 2002 showed that pf can be assumed as a constant value of 0 56 year round however with data from 51 natural and artificial american lakes smith 1982 suggested a simple relation between pp and tp which implies that pf is a function of tp and the more the tp the more the pf recently serrano et al 2017 found that when the tp input to shallow lakes is more than the sediments natural adsorption capacity the pf becomes 0 50 due to saturation of p binding capacity of sediments and biological uptake which is termed anthropogenic eutrophication in an attempt to adapt lakemab model to meromictic lakes bryhn et al 2010 set the pf ratio to 0 60 0 50 and 0 30 respectively for the surface middle and deep water layers thus the pf ratio should be calibrated for artificial lakes since there may be differences between them and natural lakes regarding sediments the thickness of bioactive sediments in accumulation areas in lakemab is assumed to be 10 cm and the burial flux is defined as the deactivated sediment layer beneath the 10 cm active sediment layer since the whole thickness of sediments in newly constructed artificial lakes is 10 cm we let the lakemab evaluate the thickness of sediments and the burial flux will not be activated until the thickness of sediments reaches 10 cm an algorithm for the proposed procedure adapted from håkanson and bryhn 2008 is as follows a 3 if n 1 st n st 0 else st n 1 st n sed n 12 dt where st n is the thickness of sediments cm at n th time step and st 0 is the thickness of sediments cm at the start of simulation sed n is the sedimentation rate cm year which is divided by the number of months and dt is the step size for solving the differential equations of lakemab by euler s method which in the original code of lakemab is 1 10 but in this paper is set to 1 30 for increasing the accuracy of results the burial flux is not activated until the thickness of sediments reaches to 10 cm and the depth of active sediments d as is selected as the minimum value of whole sediments thickness and 10 cm for a complete explanation of other lakemab parts the reader is referred to håkanson and bryhn 2008 appendix b reduction of the external load of p can be conducted via controlling the point or diffusive sources a 10 reduction of tp load from diffusive sources by terracing technique in kan watershed is predicted by delkash 2013 although the cost of terracing in 133 suitable locations is estimated to be 0 7 billion iranian rials water research institute 2011 which is affordable more recent studies abhari rashtabadi 2015 haghparast 2015 have shown that kan river bed both in upstream and in tehran city is degrading and terracing intensifies this issue due to the risk of bridge scour imposed by river degradation deng and cai 2010 the terracing is not considered in plans using p export coefficients water research institute 2011 estimated that 59 0 of p load from diffusive sources in the kan watershed originates from agricultural lands while delkash et al 2014 estimated the 30 4 contribution of agricultural lands to the diffusive sources in the wet period however there is some evidence that the contribution of orchards to total p load is not much not only the canopy of the densely wooded kan orchards reduces the kinetic energy of raindrops ghafari et al 2014 but also the orchardists actively protect their limited arable land from erosion by construction and maintenance of terraces babaei et al 2016 hence the consideration of agricultural bmps for orchards is conditioned by future investigations due to lack of certain scientific validity the first plan consists of a hydroponic bio filter beside the lake as well as wastewater treatment facilities for villages in kan watershed investigating the case studies of using hydroponics to remove tp at low concentrations as well as ability to be used in winter led to the selection of nasturtium officinale plant commonly known as watercress li et al 2009 li et al 2009 used hydroponic bio filters for purification of a lake with tp concentration of 40 210 mgp m3 and their results showed that as long as the hydraulic load of water to bio filter is 0 5 4 m3 m2 day the tp removal efficiency is almost constant with average value of 15 9 in winter december march and 35 4 in non winter months april november in their case study the particulate p forms about 80 of the total p and the major mechanism of removal is adsorption of particulate p to plant roots while the removal efficiency for orthophosphate is just 10 considering the capacity of water transfer pipeline to chal i e 1 2 m3 s the area of the hydroponic bed should be 2 6 ha so that the hydraulic load does not exceed 4 m3 m2 day in months with no water intake or 0 4 mcm month water intake a pump with the capacity of 0 6 m3 s transfers the water of the lake to the bio filter this ensures that the hydraulic load of bio filter is not 2 m3 m2 day due to the low concentration of particulate p in lake water in no intake months pf 0 10 the removal of tp from lake water in calculated according to the orthophosphate removal efficiency as the historical data show that 60 of tp in lake water is in the form of orthophosphate the initial investment for the construction of bio filter is estimated to be 10 30 billion iranian rials irr in 2015 and the annual maintenance cost ranging from 1 to 3 billion irr in order to ascertain that the particulate p is the dominant form in the kan river the point sources should be removed for this purpose the proposed methods by gray and booker 2003 for removal of nutrients from wastewater of small communities with 10 000 population is used among their scenarios the local blackwater treatment which removes 87 of tp from household wastewater at capital price of 930 aud in 2003 is selected the initial investment for these facilities is estimated to be 160 180 billion irr in 2015 and annual maintenance cost is 10 18 billion irr the aforestated plan reduces the risk of eutrophication between 70 and 90 based on the water intake outtake plan the second plan mostly relies on the controlling of internal loading and inactivation of p considering the fact that the ph is not higher than 8 5 and the alkalinity is not lower than 80 mg caco3 l chal is an appropriate lake for alum treatment cooke et al 2005 among three methods for estimation of the amount of alum that can be applied to the lakes as described by cooke et al 2005 the mass balance approach using gross diffusion of p from sediments in accumulation areas in 4 months rule curve gives the need for 9 95 gral m2 i e 106 62 ton al2 so4 3 16h2o aluminum sulfate powder to be applied over accumulation areas every five years the amount of required powder is calculated internally in every water intake outtake plan and converted to cost with the unit price of 0 01 billion irr per ton of aluminum sulfate powder as well as 5 billion irr estimated cost for distribution of alum on the lake the five year period used in this method is in accordance with the mean 5 7 years longevity of al treatment in shallow polymictic lakes as reviewed by huser et al 2016a in order to succeed in reducing internal p loading it is crucial to reduce the external loading of p at the same time zamparas and zacharias 2014 therefore a dry detention basin for p removal is considered to be built beside the lake for the calculation of p removal in the detention basin the proposed model by walker 1987 is used the area of detention basin is supposed to be equal to one hectare with the average depth of 10 m initial assessments revealed that the p removal in this case is very minute and is not greater than 10 since the assumed size of detention basin is big enough it is not well justified to make the basin larger hence the use of alum in order to reduce the ratio of orthophosphate to tp is considered not only has shown the experiments on kan river water that the addition of 4 mgal l can effectively remove tp from water column sharif university of technology 2014 but also the study of pilgrim and brezonik 2005 on a river with similar tp concentration to kan river has shown that addition of 2 8 mgal l can convert no 90 of orthophosphate to particulate non reactive p by converting 90 of orthophosphate with alum the tp removal percentage in detention basin reaches to 20 40 based on the water intake plan considering the least amount of alkalinity in kan river water which is 91 mgcaco3 l the use of this amount of alum is safe but since this addition is repeated annually buffered alum is used in order to minimize the risk of low ph in the lake cooke et al 2005 the unit price of buffered alum is 0 015 billion irr per ton and the annual cost of transfer and mixing with the withdrawn water in the chal diversion dam is 0 7 billion irr although it is anticipated that due to the annual addition of low concentration alum to intaken water there would be no need for repetition of alum treatment on lake sediments every five years the cost of the five year operation is kept within this plan the alum plan reduces the risk of eutrophication more than 90 in all water intake outtake plans the third plan is the construction of an advanced water treatment plant beside chal due to the limited capacity of treatment plants in this plan water intake cannot be conducted with the full capacity of chal pipeline but at the maximum discharge of 0 4 m3 s two assumptions for water intake using the water treatment are defined in the first assumption as proposed by tcec 2013 in 5 months november march water is withdrawn for chal regardless of the discharge of river and water intake in each month is stopped only if the lake volume reaches the 7 mcm in the second assumption in 6 months november april water is withdrawn only in days in which the volumetric discharge is greater than 1 4 m3 s as it is presented in fig b1 the minimum volume of the lake during 21 years using the 1 4 m3 s discharge threshold is 4 4 mcm the treatment plant will be in operation for 11 months of the year except for october which is allotted to the repair and maintenance of the plant if the water intake is less than the capacity of the treatment plant which is 1 mcm month the unused capacity is filled by pumping the lake water to the treatment plant the efficiency of tp removal is dependent on consumed chemicals and concentration of tp however based on the technical calculations related to the design of chal treatment plant tcec 2013 for a fixed cost the percentage of phosphorus removal is a function of tp concentration input as follows b 1 prp 0 098 c tp 0 358 where prp is the tp removal percentage appendix c supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 04 052 appendix c supplementary data supplementary data 
7211,the present paper proposes a smoothing analysis of hydraulic head data sets obtained by means of different slug tests introduced in a confined aquifer laboratory experiments were performed through a 3d large scale physical model built at the university of calabria the hydraulic head data were obtained by a pressure transducer placed in the injection well and subjected to a processing operation to smooth out the high frequency noise occurring in the recorded signals the adopted smoothing techniques working in time frequency and time frequency domain are the savitzky golay filter modeled by third order polynomial the fourier transform and two types of wavelet transform mexican hat and morlet the performances of the filtered time series of the hydraulic heads for different slug volumes and measurement frequencies were statistically analyzed in terms of optimal fitting of the classical cooper s equation for practical purposes the hydraulic heads smoothed by the involved techniques were used to determine the hydraulic conductivity of the aquifer the energy contents and the frequency oscillations of the hydraulic head variations in the aquifer were exploited in the time frequency domain by means of wavelet transform as well as the non linear features of the observed hydraulic head oscillations around the theoretical cooper s equation keywords slug tests hydraulic head smoothing hydraulic conductivity wavelet analysis 1 introduction among the most commonly used methods to characterize aquifers it is necessary to consider pumping tests and slug tests it is well known that pumping tests allow the obtainment of more reliable measurements of large scale aquifer parameters however these tests are more complex to conduct requiring expensive equipment and one or more observation wells neuman 1975 zlotnik et al 2000 zhang and tang 2013 although they seem more vulnerable to errors and uncertainty slug tests are conversely characterized by simplicity of execution and a relatively low cost moreover the latter not requiring water extraction from the aquifer are very suitable for use in surveys regarding contaminants transport in groundwater severino 2011a severino et al 2011 severino et al 2012 therefore slug tests are increasingly used and often preferred compared to pumping tests in other words it is possible to state that slug tests are a common test procedure for aquifer characterization butler et al 1996 butler 1997 lee and lee 1999 beckie and harvey 2002 zurbuchen et al 2002 dietrich et al 2008 chiasson 2012 lewis 2013 slug tests to which reference is exclusively made in the following consist of an abrupt addition extraction or displacement of a known water volume in the well and the subsequent monitoring of changes in the water level hydraulic head as initial equilibrium conditions return butler 1997 sageev 1986 astm standard d4044 2006 on the basis of hydraulic head data thus detected it is possible to estimate the values of transmissivity t hydraulic conductivity k and in some cases even the storage coefficient s hvorslev 1951 cooper et al 1967 bouwer and rice 1976 swamee and singh 2007 severino et al 2008 koussis and akylas 2011 severino 2011b slug tests have been widely discussed in scientific literature and numerous historical overviews of the background can be found on this topic like those of yang and yeh 2004 and cardiff et al 2011 the many aspects related to slug tests have been studied in detail such as the influence of the skin effect chirlin 1989 hyder et al 1994 the influence of errors hyder et al 1994 chiasson 2012 the use of various numerical semi analytical and analytical models beckie and harvey 2002 butler and zhan 2004 influence of storage on the slug test analysis bredehoeft and papadopulos 1980 chapuis 1998 considerations and analysis on fissured aquifers barker 1988 quinn et al 2013 the development of the multiwell slug tests analysis mcelwee et al 1995 yang et al 2015 the oscillations of the water level around the equilibrium level induced by abrupt pressure change mcelwee 2002 audouin and bodin 2007 koussis and akylas 2011 the influence of heterogeneity and the upscaling processes beckie and harvey 2002 severino 2011b chen et al 2012 nevertheless it is possible to identify some aspects related to slug tests which can still be investigated in an appropriate manner such as the use of large data sets discussed in this study the difficulties of interpreting large data sets obtained from slug tests have already been appropriately highlighted chapuis 2009 however investigations on the influence of an adequate data smoothing analysis which is a topic poorly discussed in the scientific literature can be considered a novelty allowing for new and interesting contributions to be made to this subject during a slug test the time needed for the hydraulic head to return to its initial value before the test namely the duration of its variation depends on slug volume well geometry and aquifer characteristics related to the use of the field e g mcelwee 2002 or laboratory scale e g baptiste and chapuis 2015 the measurement frequency able to acquire a number of hydraulic head values sufficient to ensure a reliable estimate of the aquifer parameters should be based on this test duration therefore suitable automatic instrumentations such as electronic or vibrating wire pressure transducers placed in the water column and able to provide hydraulic head values at predetermined measurement frequencies are commonly used e g zarriello 1995 zurbuchen et al 2002 tools of this kind often allow the selection of the measurement frequency to record the hydraulic head variation see for more details post and von asmund 2013 obviously this selection must be made taking into due account the type of test performed in fact for a pumping test the sampling frequency may be suitably low e g jiménez martinez et al 2013 on the contrary for slug tests where variations of hydraulic head generally occur in very limited times the use of high measurement frequencies is common mcelwee 2002 audouin and bodin 2007 the optimal measurement frequency for the investigated physical process is linked to the different characteristics of the aquifer and well and the water volume injected into the well in this context the data number that can be obtained during a slug test depending heavily on the value of the measurement frequency is often quite high the analysis of a large data set to determine the characteristic parameters of an aquifer could also be considered advantageous to discover possible non linear effects in the time series of the hydraulic head e g butler et al 1996 however it should be considered that by increasing the number of data which are processed for the assumption of a high frequency of measurement the computational cost of the processing operation tends to grow moreover it should be noted that the acquired data can contain errors of different types systematic and random and alterations or experimental disturbances chargeable to various causes such as conditions of initial speed or acceleration in the groundwater electrical signal variations and still others mcelwee 2002 chiasson 2012 furthermore it is necessary to take into account that the increase in the data number can give rise to phenomena of errors propagation phillips and harris 1990 therefore the importance of being able to reduce the data number to be analyzed for the determination of the parameters under consideration is evident however this must be done without risking degrading of the quality of the data acquired by measurement i e without altering the reliability of the final result mainly in terms of reliability of the aquifer parameters values namely of energy contents and shapes of the pressure signal as in the present case in the experimental field a suitable filtering of recorded raw data is a common problem in various disciplines such as spectroscopy chemistry and biomedical monitoring and there are numerous methodologies developed to smooth out unwanted high and low frequency oscillations in particular smoothing approaches such as decimation statistical methods the use of convolution formulas based on simplified procedures of the least squares method and spectral analyses both in time and time frequency domain were adopted savitzky and golay 1964 box and jenkins 1970 comaniciu and meer 2002 dagum 2002 nie et al 2002 schmidt and skidmore 2004 audouin and bodin 2007 browne et al 2007 damiani et al 2011 the same kind of problem to smooth out the noise in the pressure field correctly also occurs in numerical modeling when the flow is considered as a weakly compressible medium by assuming an artificial sound of speed lower than the real one for computational reasons as in the case of the application of the popular lagrangian particle approach called smoothed particle hydrodynamics sph e g aristodemo et al 2017 the use of a weakly compressible model then leads to high frequency acoustic perturbations which should be removed from the numerical pressure field to recover the correct incompressible solution meringolo et al 2017 moreover several studies showed that with proper precautions the smoothing of the time series data related to the parameter measured often leads to a reduction of the uncertainty noise affecting these igbp 1992 viovy et al 1992 chen et al 2004 obviously each smoothing method has positive and negative aspects therefore it is of paramount importance to proceed with a careful and prudent choice of the method to be used phillips and harris 1990 schmidt and skidmore 2004 ruffin et al 2008 the aim of this study is to highlight the opportuneness of carrying out smoothing in cases where the data sets obtained by slug tests are particularly extensive providing a valid methodology and useful indications regarding the choice of the specific smoothing method to be used in the constant search to reduce times and costs the present study is based on a 3d experimental investigation carried out on a physical model reproducing a confined aquifer built for this purpose in the gmi laboratory at the department of civil engineering of the university of calabria italy of course the results obtained while highlighting the problem and the methodology to be used cannot be directly extended to field investigations although the problem of managing large data sets can also exist in the field depending on the test duration measurement device and frequency used this is also due to the significant difference between the slug volumes considered in the laboratory and in the field respectively and the consequent different aquifer volumes involved in the slug tests essentially this inequality between the two corresponding scales implies possible differences concerning the influence that the heterogeneity exerts on the flow phenomena induced by slug tests severino et al 2008 dagan et al 2009 severino 2011b fallico et al 2016 moreover the results of this experimental investigation allowed useful comments to be made on some characteristic aspects of slug tests related to hydraulic head variation in this context seven slug tests were performed through the injection of a specific water volume from 30 to 90 ml in the central well of the aquifer the hydraulic head variation was recorded by a high frequency pressure transducer placed in the injection well the raw data were processed using four smoothing techniques with different working principles in time frequency and time frequency domain specifically a savitzky golay filter based on local least squares polynomial approximation of a certain order savitzky and golay 1964 a fourier transform e g cooley and tukey 1965 and two kinds of wavelet transform like mexican hat and morlet e g morlet et al 1982 torrence and compo 1998 were used historically several approaches were carried out to smooth and analyze hydraulic head variations in an aquifer under various hydrodynamic forcings such as linear programming for the analysis of a karst aquifer dreiss 1989 moving average filter under radial flow conditions desbarats 1994 kernel density estimation to investigate groundwater discharges at springs manga 1999 hanning window method in karst aquifers long and derickson 1999 geostatistical methods to analyze bank filtrations cirpka et al 2007 fourier transform to smooth and analyze the recorded hydraulic head for pumping and slug tests in field conditions beckie 1996 audouin and bodin 2007 and a savitzky golay filter to investigate the hydraulic response of fractured aquifers jiménez martinez et al 2013 it can be noticed that several field studies monitored the hydraulic head with a low frequency of measurement and raw data were used to evaluate the characteristics of an aquifer e g mcelwee 2002 the smoothing operation proves to be conversely crucial when laboratory tests on smaller scales and then on smaller involved water volumes than field conditions were performed however to the authors knowledge no specific attention has been addressed to understanding the effects of smoothing techniques in the time series of the hydraulic head and the optimal measurement frequency to record it in the context of laboratory slug tests on the basis of experimental high frequency noise in the time series of the hydraulic head measured at the injection well specific time spans and cut off frequency were chosen for data smoothing using the selected methods and different frequency measurements the performances of the adopted techniques to smooth the hydraulic head data were analyzed in terms of correlation coefficient relative error and bias to accurately reproduce the cooper equation cooper et al 1967 an analysis of the time variation of the shape and the frequency oscillation of the hydraulic head variation was conducted in the time frequency domain by means of wavelet transform the results deduced from the smoothed hydraulic heads were adopted to perform a sensitivity analysis in determining a stable value of the hydraulic conductivity of the involved confined aquifer the wavelet transform was also applied to discover physical insights occurring in the decreasing part of the hydraulic head variation paying attention to the energy and frequency contents of the oscillations around the cooper equation able to theoretically represent the time history of the hydraulic head in slug test conditions the contents of the present paper are organized as follows section 2 describes the laboratory set up of the confined aquifer with specific information on the instrument to measure the hydraulic head afterwards the selected techniques to filter the raw time series of the experimental hydraulic head are illustrated in section 3 the method to assess the aquifer hydraulic conductivity is then recalled in section 4 the raw and smoothed time variations of the hydraulic head are then analyzed in section 5 by comparing the performances of the processing techniques to fit the reference empirical curve and to determine the hydraulic conductivity moreover physical insights exploited in the time frequency domain of the involved hydrodynamic processes are highlighted finally in section 6 the salient parts of the methodology proposed are briefly recalled highlighting the results obtained 2 experimental set up a large scale 3d homogeneous and confined aquifer was built in the gmi laboratory at the department of civil engineering of the university of calabria fig 1 a the physical model was built within a metal box with a square bottom a side 2 m in length and with a height of 1 m along the entire perimeter of the steel box at a distance of 5 cm from the vertical wall a fine wire mesh was fixed so to form a compartment inside which the water flows through the connection with two external loading reservoirs placed on opposite sides of the metal box the wire also provides a robust support for the porous medium placed inside the box a geotextile was suitably used covering the steel containment grid to prevent the porous material from passing through the wire mesh while allowing the water flow to and from the perimeter interspace later 10 wells were built one of which was central the others were positioned at increasing distances from the center and located in different directions to avoid mutual flow disturbances as shown in the plan view of fig 1b the wells were made of smooth pvc pipes polyvinyl chloride with a diameter of 2 8 cm completely penetrating sliced along the thickness of the considered confined aquifer and appropriately covered with geo textile to prevent soil particles from entering starting from the bottom of the metal box a layer of porous material with a thickness ts 0 25 m was placed to form the confined aquifer on which the experimental tests were to be conducted see lateral section a a sketched in fig 1c the granular material of this layer shows a high sand percentage 83 and a small gravel percentage 17 with an effective grain diameter d 10 0 188 mm the laying of this material constituting the solid matrix of the confined aquifer was carried out by repeating several water loading and unloading cycles to reach a natural packing the top of the groundwater system was achieved by a thin impermeable plastic panel this waterproof panel suitably folded and sealed at the walls of the box and wells was covered with additional sandy material to counter the water thrust exerted on it and also consequent possible and unwanted deformations preliminary tests were carried out to verify the seal of the waterproof plastic panel and the good working of the experimental apparatus fallico et al 2018 the aquifer built in this way even if it can be considered granulometrically homogeneous due to the random arrangement of the grains of the solid matrix has different sized pores and therefore can be considered intrinsically heterogeneous in fact the micro and macro pores within the considered porous medium give rise to heterogeneity at the laboratory scale which influences the flow phenomena several slug tests were performed using the present experimental set up an initial undisturbed hydraulic head of approximately 0 4 m was used for all the experiments this condition caused the confined aquifer with a thickness of 0 25 m to be slightly under pressure in particular seven slug tests were executed by injecting an increasing water volume v 30 40 50 60 70 80 and 90 ml in the central well these volumes were calibrated according to water quantities which were acceptable as a function of the dimensions of the laboratory set up without causing unwanted overflow and ensuring that the perturbed hydraulic head in the aquifer did not interact with the solid walls surrounding the experimental aquifer the occurrence of the mentioned flow conditions was checked for each test through the monitoring of the hydraulic head in the injection and observation wells specifically the monitoring of hydraulic heads in the observation wells was also performed to verify the suitability of the boundary conditions related to the analysis method of the hydraulic heads data detected in the inlet central well for each slug test appropriately recalled below moreover attention was also paid to check the reaching of the initial undisturbed conditions between successive tests in each well of the aquifer the time variation of the hydraulic head was recorded by a submersible pressure transducer placed at the bottom of the metal box in particular the adopted sensor was the pdcr1830 model by druck ranging from 0 to 3 5 m h2o and an accuracy of 0 1 of the full scale reading all sensor measurements were acquired in differential mode owing to the wheatstone bridge configuration by a data acquisition board a national instrument cdaq9184 chassis with a national instrument 9205 module the latter was connected to the pci bus of a personal computer by an ethernet cable in order to guarantee efficient synchronism and noise rejection the hardware software implementation was developed by the nexus electronic laboratory of the same university see for more details tripepi et al 2017 for all tests the measurement frequency of the transducers was fixed at 1000 hz and particular care was addressed to calibrate the transducer in the expected pressure range of the water level in the aquifer with a dynamic component induced by the inserted water volume as usually performed for slug tests e g butler 1997 the pressure measurements recorded in central well no 1 subjected to the water injection will be taken into account for the analysis of smoothing and the successive derivation of the hydraulic conductivity 3 smoothing techniques in this section the techniques adopted to filter the raw time series of the experimental hydraulic heads deduced from the measurements obtained by means of the pressure transducer in the injection well are illustrated since high frequency noise appears in the time variation of the observed hydraulic heads during the experiments the family of low pass filters should be adopted in this context savitzky golay filter sg fourier transform ft and two types of wavelet transform wt are taken into account the basic features of the above approaches are recalled in order to understand their characteristics in the presence of unsteady flow processes as in the current case i e the time decay of the hydraulic head due to aquifer response under the insertion of a specific water volume into an injection well 3 1 savitzky golay filter savitzky and golay 1964 proposed a data smoothing approach based on local least squares polynomial approximation the authors showed that fitting a polynomial of a given order to a set of input samples and then evaluating the resulting polynomial at a single point within the approximation interval is equivalent to discrete convolution with a fixed impulse response the low pass filters derived from this approach refer to the family of savitzky golay sg filters also known as digital smoothing polynomial filters or least squares smoothing filters see for more details phillips and harris 1990 and largely applied for data smoothing in remote sensing studies e g schmidt and skidmore 2004 it was noticed that this filter performs much better than the standard moving average which tends to filter out a relevant part of the signal at high frequencies along with the noise e g jiménez martinez et al 2013 following this time domain method a polynomial pi t of degree d which is to be fitted through the observed time series xi t is determined as 1 p i t j 0 d c j t t i δ t j in which the generic time ti t is equispaced by an imposed time step δt t the coefficients cj in eq 1 can be calculated by minimizing the mean squared error on input data xi t so that 2 sum k i n l i n r p i t k x k t 2 min where nl and nr represent the number of time instants to the left and the right of data points respectively as performed by aristodemo et al 2011 and contestabile et al 2012 in smoothing hydraulic heads for a partially saturated beach subjected to water waves and successfully comparing the results with dipmeters an sg filter with d 3 is adopted a specific span length l nl nr 1 and according to the specific sampling frequency will be chosen in the successive analyses 3 2 fourier transform the fourier transform ft is a method for transforming a function of time into a function of frequency and represents one of the most popular algorithms in signal processing and data analysis considering an input data signal x t an ft allows a translation from the time to the frequency domain as in the present case given by 3 x ω x t e i ω t dt where ω angular frequency 2πf t 1 being f the frequency t 1 and i is root square of 1 the function x t is determined through x ω using a inverse fourier transform ift which is defined as 4 x t x ω e i ω t d ω the present algorithm is related to the extraction of the series of sines and cosines which reconstruct the input function when superimposed as a result the fourier analysis is not local owing to its space filling nature and thus this approach is solely suitable for the analysis of stationary signals i e signals whose properties do not change with time when transforming to the frequency domain with the ft the time information is lost and the time instant when a specific physical process occurs is unknown a fourier transform is known as discrete fourier transform dft which can be calculated by a fast fourier transform fft or by its inverse i e the inverse fast fourier transform ifft allowing reduction of the complexityof computing the dft from o n 2 to o nlogn n being the number of data cooley and tukey 1965 in the range of possible frequencies a low pass filtering will be applied by choosing a cut off frequency fc to smooth out the high frequency oscillations linked to the noise in the time series of the raw pressure signals 3 3 wavelet transform the wavelet transform wt first introduced by morlet et al 1982 for the study of seismic signals is usually adopted to investigate time series containing non stationary energy contents at several different frequencies e g mallat 2009 in the wavelet analysis a generic function x t is analyzed both in the time and in the frequency domain by using a windowing function g t this approach is attained by a convolution of eq 3 as follows 5 x ω τ x t g t τ e i ω t dt where the time τ aτ0 and the angular frequency ω bω0 the parameters a re and b re represent respectively the values adopted to scale in frequency and to shift the function in time g t moreover re and re define the respective domains of coefficients a and b under this transformation the localized function g t becomes 6 g ab t g t a τ 0 e ib ω 0 t eq 6 can be replaced by a basic function named mother wavelet ψ 7 ψ ab t 1 a ψ t b a the wt of eq 5 is therefore defined as 8 ψ a b 1 a f t ψ t b a dt the constraint to be a mother wavelet is represented by the so called admissibility condition e g torrence and compo 1998 given by 9 c ψ 1 a ψ ω 2 ω d ω the function of the input data signal x t i e the inverse continuous wavelet transform icwt can be deduced from the wavelet ψab and the wavelet transform ψ a b as follows 10 x t 1 c ψ ψ a b ψ ab t dadb a 2 various families of mother wavelets were historically proposed in the wavelet framework in general the use of a specific mother wavelet is dependent on the studied physical process which can be characterized by the occurrence of slow or fast dynamics e g meringolo et al 2017 this choice can be driven by the fact that the shape of the wavelet should tend to well approximate the involved input signal in the large possibility of options of mother wavelets two types of wavelets namely mexican hat and morlet are here chosen heuristically in the following analyses because of their broad application in the field of flow dynamics when unsteady phenomena occur as in the analyzed slug tests for example the mexican hat wavelet was successfully applied to study the flow field behind two flat plates higuchi et al 1994 wedge slamming impacts and sloshing processes meringolo et al 2017 and wave loads at submerged cylinders aristodemo et al 2017 the morlet wavelet was instead adopted to investigate fluid processes such as surface ocean waves massel 2001 landslide generated waves panizzo et al 2002 and flow at two side by side cylinders wang et al 2007 the first adopted mother function is represented by the marr wavelet commonly known as mexican hat owing to its specific shape the mathematical representation of the mother wavelet ψ derived from the second derivative of a gaussian function and shown in fig 2 a is given by 11 ψ t 2 3 π 1 4 1 t 2 e t 2 2 the corresponding fourier transform of the mexican hat mother wavelet see fig 2b leads to 12 ψ ω 8 3 π 1 4 ω 2 e ω 2 2 the second mother wavelet adopted in this study is the morlet function represented as a plane wave modulated by a gaussian see fig 2c it is described by the following equation 13 ψ t π 1 4 e jk m t e t 2 2 where the wavevector km is set at 6 in order to satisfy the admissibility condition given by eq 8 as shown in fig 2d the wavelet transform of this mother wavelet is equal to 14 ψ ω π 1 4 ω 2 e ω k m 2 2 with reference to the comparison between the used mother wavelets and their related wavelet transform represented in fig 2 it can be noticed that the mexican hat shape is narrower in the time domain and broader in the spectral domain than the morlet the resulting wt of the former one is sharper in time and more stretched in scale if compared to the latter one this effect is due to the fact that the mexican hat mother wavelet presents only real values and takes into account both positive and negative oscillations in the time series as separate peaks in the wt the morlet also considers complex values and has more oscillations than the mexican hat by matching both positive and negative peaks into a single broad peak e g torrence and compo 1998 as performed for ft an ad hoc value of fc will be set to smooth out the noise in the high frequency band of the measured hydraulic heads using both mexican hat and morlet wavelets 4 estimation method of aquifer hydraulic conductivity the slug tests carried out in fully penetrating wells in confined aquifers reproduced at laboratory scale in the metallic box here considered were analyzed by the method of cooper et al 1967 this consists in a semilog type curve matching method that allows estimation of the aquifer transmissivity of the hydraulic conductivity and the specific storage coefficient this method is based on a relationship expressing the fact that the rate of flow of water into or out of the aquifer is equal to the water volume decrease or increase rate in the well the mathematical model respects the following assumptions homogeneous formation darcian flow instantaneous slug introduction and negligible well losses cooper et al 1967 butler 1997 cooper s analytical solution can be represented in the following form 15 h t h 0 f β α in which β represents a dimensionless time parameter 16 β kbt r c 2 and α represents a dimensionless storage parameter given by 17 α r w 2 s s b r c 2 where t is the time t b the aquifer thickness l k the radial component of the hydraulic conductivity lt 1 ss the specific storage l 1 h t the variation at time t of the hydraulic head in the well from the initial undisturbed conditions l h0 the initial variation of the hydraulic head in well l rw the effective radius of well screen l rc the effective radius of well casing l and r the radial direction l eq 15 plotted as normalized hydraulic head varying the logarithm of β forms a series of type curves each of which corresponds to a different α value this method via curve matching either manual or automated allows the determination of the radial component of the hydraulic conductivity for β 1 by the following relationship 18 k r c 2 bt 1 0 where t 1 0 is the real time corresponding to β 1 t and the meaning of the other values has already been specified cooper et al 1967 butler 1997 the cooper et al 1967 method also allows estimation of the specific storage coefficient it should be noted that both the values of t thus of k and ss determined by this method cannot be very reliable as a consequence of both the measured data uncertainty and the difficulty in distinguishing adjacent theoretical curves of matching method cooper et al 1967 papadopulos et al 1973 bredehoeft and papadopulos 1980 butler 1997 chapuis 1998 chapuis 2009 however under the assumption that the inertia of the water column in the well is negligible many studies show that the error in the determination of transmissivity would commonly be small for α 10 1 in fact in this case even with an uncertainty of α equal to 2 orders of magnitude the error on the transmissivity remains less than 30 papadopulos et al 1973 bredehoeft and papadopulos 1980 the error in transmissivity increases with increasing α values on the contrary the determination of ss by this method has always had questionable reliability as also stated by cooper et al 1967 and papadopulos et al 1973 therefore it can be assumed that in order to determine transmissivity the method of cooper et al 1967 is suitable only for α 10 1 5 results and discussion the hydraulic head time series in the well h were determined by subtracting the undisturbed hydraulic head from the pressure transducer measurements then the raw values of h were smoothed using savitzky golay filter sg fourier transform ft and two wavelets wt namely mexican hat mexh and morlet morl the data sets sampled with the measurement frequency f 1000 hz were subjected to a decimation considering time series with f 100 hz and 10 hz hereinafter the above three measurement frequencies will be respectively called f10 f100 and f1000 in order to accurately assess the hydraulic conductivity of the laboratory aquifer the raw hydraulic heads will also be processed by analyzing the optimal frequency to study the aquifer characteristics in terms of best fitting of the empirical law deduced from the general relation given by eq 15 and successive derivation of the hydraulic conductivity the filtering approach to eliminate the high frequency noise on h was carried out by setting a specific quantity related to the involved methods in time frequency and time frequency domain for sg characterized by a 3 degree polynomial a variable span length as a function of the measurement frequency was adopted specifically l 21 for f10 l 207 for f100 and l 2131 for f1000 for ft and wt cases an independent unique value of fc 0 65 hz was set to leave out the high frequency noise in the pressure field due to specific experimental disturbances however an ad hoc calibration to smooth raw data sets must be carried out in each measurement campaign and for each adopted instrument it should be stressed that particular care was paid to find an optimal setting of the involved parameters in all smoothing analyses with the aim of preserving the global and local energy contents and shapes of the time series of h in the following analyses a time window of about 50 s was considered as representative to analyze the progressive decrease of the hydraulic head due to the aquifer response under the perturbation given by the injected water volume indeed residual small oscillations of the hydraulic head are less than 1 of the maximum value of h after the considered time interval 5 1 analysis of hydraulic head data the raw and smoothed time series of h adopting the aforementioned approaches in the time frequency and time frequency domain were analyzed to determine the hydraulic conductivity of the laboratory aquifer for this purpose the resulting time variations of h were fitted through a specific law given by an exponential decay form and generally expressed by eq 15 under specific boundary conditions of cooper et al 1967 the fitting operation was performed for all slug volumes ranging from 30 to 90 ml and using the three adopted measurement frequencies fig 3 shows the time variation of the raw and smoothed sg ft mexh and morl hydraulic heads h for v 90 ml and using f10 f100 and f1000 the reference time t 0 corresponds to the appearance of the peak of h the corresponding fitting exponential curves and the 95 prediction intervals are also plotted in fig 3 the representative case with 90 ml was considered due to the fact that highest variations of h occur among the experimental tests particularly for the smoothed time series the hydraulic head variation is reasonably fitted by the reference exponential equation with an overall underestimation in the first decreasing part and an overestimation in the following one the smoothing effect of the involved techniques is evident when compared to the raw ones which are conversely affected by a relevant level of high frequency noise nevertheless the preservation of the peak through the setting of the quantities involved in the filtering operation of each technique has led to highlighting non linear effects in the overall time decreasing of smoothed h for all measurement frequencies specifically deviations from the theoretical time variation of h given by aquifer response at different energy and frequency oscillation occur whose magnitude is dependent on the adopted measurement frequency this feature is linked to the impossibility of recovering the theoretical assumptions of the cooper solution even though controlled laboratory conditions were adopted we presume that the observed smoothed oscillations on h can derive from a combination of realistic effects such as the finite operation of slug injection the hydraulic losses in the well and the aquifer system moreover the use of more refined frequency measurement compared to other laboratory e g baptiste and chapuis 2015 or field e g mcelwee 2002 tests can lead to highlight these non linear effects the above features will be successively exploited in terms of energy contents and frequency oscillations in order to assess the best processing approach the performances of raw and smoothed sg ft morl and mexh hydraulic head data sets for the accurate reproduction of the reference analytical solution by a specific measurement frequency were here investigated from a statistical viewpoint through the calculation of the correlation coefficient r2 the relative error se and the bias for raw and smoothed data the values of r2 are shown in table 1 as a function of v and using f10 f100 and f1000 it can be observed that the use of the widest measurement frequency f10 leads to the lowest values of r2 while the assumption of f100 and f1000 show similar results even if the highest r2 are generally associated with f1000 apart from some cases with v equal to 60 and 70 ml the values of r2 increase when high v are involved indeed for v 70 ml the values of r2 are larger than 0 9 by adopting raw and smoothed h to highlight the differences deriving from the use of different measurement frequencies and the consequent choice of the optimal value of f to be adopted in evaluation of the hydraulic conductivity the relative differences on the calculation of r2 between f10 and f100 and between f10 and f1000 lead to very similar results ranging from 0 6 for 90 ml to 14 6 for 30 ml indeed relative differences on r2 between f100 and f1000 oscillate between 0 04 and 0 08 by changing the measurement frequency relative differences on r2 are higher for raw data up to 7 2 and lower when the smoothed h with mexh and morl wavelet are considered regarding the various smoothing techniques the mexh wavelet gives the highest r2 followed respectively by morl ft and sg this result is in agreement with the shape of the hydraulic head variations at various v see fig 3 that better resemble the native shape of the mexican hat wavelet see fig 2a with respect to the morlet wavelet see fig 2c and the ft based on sinusoidal periodic signals the suitable performances of mexh wavelet were also underlined by meringolo et al 2017 for unsteady flow processes due to fluid structure interactions such as wedge slamming and sloshing phenomena on the other hand the very slight difference on r2 using f100 and f1000 suggests the assumption of f100 as a representative measurement frequency since the computational cost of the processing phase is reduced the time to run the developed in house matlab code using the adopted measurement frequencies f10 f100 and f1000 and the slug water volumes from 30 to 90 ml was referred to the different operations linked to the loading of the input hydraulic head data sets their processing i e the use of execute and conditional statements and of specific matlab toolboxes and the different plotting of the results in particular we roughly estimated that about 3 and 6 min were required to run the in house matlab code adopting respectively f10 and f100 while about 25 min was the run time when f1000 was used with reference to se table 2 highlights their values as a function of v and the raw and smoothing data using f10 f100 and f1000 the obtained results were found to be quite similar to those determined for r2 see table 1 the lowest values of se refer to the application of mexh to smooth the input raw time series of h followed in this case by smoothed morl sg and ft data and raw ones respectively as noticed for r2 the highest measurement frequency f1000 shows lowest values of se however the relative differences on se using f100 and f1000 are only slightly higher than the cases analyzed through r2 and about 2 moreover a not well defined trend is observed as a function of v and the lowest se are linked to 60 and 70 ml concerning the bias table 3 shows their values for raw and smoothed data as a function of v and adopting f10 f100 and f1000 apart from some cases with low values of v and measurement frequency equals to 10 hz the lowest bias are linked to the use of mexh if compared to the other smoothing techniques for this statistical parameter it can be observed that the smoothed values of h using mexh better follow the reference cooper solution than the smoothed morl sg and ft data and raw ones the obtained results generally confirm that performed for r2 and se indeed the lowest bias refer to f1000 and increase when high v are considered moreover the differences on bias using f100 and f1000 are very small and less than 1 6 on the basis of the results obtained by the statistical analyses it can be stated that the use of a mexican hat wavelet to smooth the raw time variation of h gives the best results in terms of r2 highest values se lowest values and bias lowest values for the related measurement frequency the use of f100 as a representative measurement frequency can be considered a good compromise between accuracy in fitting eq 15 and time saving in the smoothing operation if compared to f1000 the suitable results deduced from the application of the mexican hat wavelet allow the features of the hydraulic head variations in the time frequency domain to be discovered this approach is superior compared to the other approaches since savitzky golay acts only in the time domain ft allows an exploration of the physical process only in the frequency domain and the morlet wavelet suffers from the appearing of unwanted gibbs like effects in the presence of fast changes of pressure e g meringolo et al 2017 the feature of the hydraulic head for various slug volumes recorded by the transducer in the injection well is represented by an unsteady flow whose magnitude of the impulse i e the time integration of the pressure signal varies as a function of the injected slug volumes and aquifer characteristics for all slug volumes fig 4 shows the wavelet coefficients ψ deduced from the mexican hat wavelet and related to the energy contents of h occurring in the time and frequency variation of the raw hydraulic heads using the representative measurement frequency f100 a larger time window was taken into account to consider the initial fast rise of h after the insertion of the water volume in the well and the successive decay of h given by the aquifer characteristics the vertical coordinate is represented by a log scale in order to stretch the wavelet coefficients for a better visualization in fig 4 the peak frequencies fp associated with the maximum values of ψ for each frequency are superimposed on the wavelet coefficients and plotted by white dots the horizontal dashed black line refers to the cut off frequency fc adopted in wt to smooth out the high frequency noise in the input raw data with reference to the magnitude of the wavelet coefficients high positive values of ψ are related to high correlation between the observed pressure signal and the wavelet at a given frequency meaning that they are in phase when h and wavelet are in anti phase i e high negative values of ψ the shape of the hydraulic head for a certain f is negatively correlated with the adopted kind of wavelet conversely wavelet coefficients close to 0 represent values of h associated with a very low energy content and generally linked to the high frequency noise as highlighted in fig 4 for f fc by inspecting the general characteristics of the wavelet power spectra of fig 4 the rapid increase of h due to the injected slug volume leads to high negative values of ψ while the following decrease of h gives high positive wavelet coefficients until about 20 s in which the maximum absolute value of ψ occurs about after few seconds afterwards the change of concavity of the hydraulic head represented by the overestimation of the fitting curve see graphs l m and n of fig 3 related to mexican hat leads to high negative values of ψ as expected the magnitude of positive and negative values of ψ increases proportionally to v as regards the features of the peak frequencies associated with maximum positive or negative ψ they range within a low frequency band leading to high energetic oscillations that are related to long waves of order of the time window adopted to study the present physical process the values of fp are substantially independent of the injected slug volume and oscillate weakly in a narrow frequency range the characteristics of the filtered time series of h obtained by the mexican hat in terms of mean energy contents i e wavelet coefficients and mean frequency oscillations are investigated in fig 5 for various slug volumes and each adopted frequency measurement in particular fig 5a shows the ratio ψmax m h ψmax h where ψmax m h represents the mean value of maximum wavelet coefficients on h and ψmax h is the maximum value among the maximum wavelet coefficients on h the ratio ψmax m h ψmax h ranges from about 0 3 to 1 that correspond to 30 and 90 ml respectively higher ratios are generally linked to higher v a small increase in energy contents can be noticed when f1000 is applied with respect to f10 and f100 fig 5b illustrates the variation of the mean peak frequency fpm h as a function of different slug volumes and measurement frequencies as previously introduced for fig 4 the values of fpm h are quite constant and appear in a limited frequency band ranging from 0 024 and 0 027 hz that means the persistence of long oscillations with wave periods between about 38 and 42 s in which slight longer waves are linked to the use of f1000 in other words a unique great oscillation characterizes the time window of the involved slug laboratory tests by analyzing the features of energy and frequency characteristics of the smoothed time series of h with mexican hat it can be stated that the phenomenon is generally weakly dependent on the choice of the measurement frequency and that the mean peak frequency does not vary with the injected slug volume 5 2 assessment of hydraulic conductivity adopting the raw time series of h and smoothed ones deduced from savitzky golay fourier transform and mexican hat and morlet wavelets table 4 illustrates the obtained values of k using different slug volumes v and the involved measurement frequencies f10 f100 and f1000 the k values reported in table 4 were obtained by the method of cooper et al 1967 using the eq 15 and verifying the accomplishment of the initial and boundary conditions by monitoring hydraulic heads in observation wells from the analysis of hydraulic conductivity data shown in table 4 an overall small variation of k can be observed in the range of slug volumes and measurement frequencies implying the good quality of the laboratory dataset with reference to other experimental investigations butler et al 1996 butler 1997 consistently with the results shown in section 5 1 the above result proves to be particularly emphasized for the values of k derived from the application of smoothed hydraulic head data moreover a slight increasing trend of k proportionally to v can be noticed except for k deduced from raw hydraulic head data the use of f10 leads to the lowest hydraulic conductivities while the use of f1000 furnishes the highest k as highlighted in the statistical analysis performed in section 5 1 the differences on k comparing the values of k linked to f100 and f1000 are however very small to better analyze the general tendency of k at the present laboratory scale the obtained values were averaged over the related slug volumes fig 6 shows the variation of the related mean hydraulic conductivity km derived from raw and filtered data and for the considered measurement frequencies a substantial constant trend of km can be noticed when smoothed values of h are taken into account ranging from 1 63 10 4 to 2 78 10 4 m s as regards the measurement frequencies the mean percentage relative difference on k is approximately 26 comparing f10 and f100 or f10 and f1000 while this value is only about 4 when f100 and f1000 are compared paying attention to the smoothing techniques on the time variation of hydraulic head the application of the mexican hat wavelet gives the lowest variability on km among other processing methods in particular a variation of about 12 on km is observed for the mexican hat using the three measurement frequencies while the variation is about 26 when savitzky golay is adopted as a further indication it should be noted that the value of specific storage ss determined by the method of cooper et al 1967 for measuring frequency equal to 100 and mexican hat smoothing technique was included in a rather wide range between 2 63 10 7 m 1 and 1 77 10 3 m 1 around an average value equal to 2 95 10 4 m 1 5 3 analysis of oscillations of hydraulic head the smoothed time series of h related to the progressive decay after the peak are here inspected by analyzing the energy and frequency contents of the oscillations around the reference analytical solution derived from eq 15 the analysis is addressed to investigate the characteristics of the present aquifer at laboratory scale in terms of non linear effects in comparison with the widely adopted theoretical and simplified analytical equation by cooper et al 1967 owing to the best results previously obtained from a statistical viewpoint in terms of r2 and se the processed values of h obtained by means of the mexican hat wavelet were taken into account the investigated hydraulic head oscillations δh are considered as the difference between the time series of h filtered by the mexican hat and the fitting curve deduced starting from eq 15 for different v and for the adopted three measurement frequencies fig 7 displays the time series of δh smoothed by the mexican hat around δh 0 i e the reference theoretical curve it can be observed that amplitudes and periods of the oscillations are generally not linked to the magnitude of the slug volume inspecting the measurement frequency the use of the less refined f10 gives the highest magnitude of positive and negative values of δh and highest occurrence of oscillations around δh 0 the obtained results with f100 and f1000 show similar features and for computational reasons f100 can be considered as also underlined in section 5 1 by using f100 and f1000 the positive and negative values of δh are reduced in comparison with f10 even if a considerable contribution of time oscillations persists the assumption of f100 and f1000 to model the feature of the hydraulic head also lead to a lower occurrence of time instants when δh 0 and consequently longer wave periods with reference to the cooper equation the application of the mexican hat wavelet as a suitable smoothing technique to filter the hydraulic head data sets allowed exploitation of the features of δh in the time frequency domain as also carried out for h in section 5 1 along the lines of the previous fig 4 the wavelet coefficients and the related peak frequencies white dots of the hydraulic head oscillations are illustrated in fig 8 for all v the values of δh were smoothed by the mexican hat using the representative measurement frequency f100 for each frequency band high positive wavelet coefficients associated with positive values of δh occur for a few initial seconds followed by high negative ψ and δh until about 20 s and an occurrence of positive ψ and δh in the final time window this feature is observed to be weakly dependent on the magnitude of the injected slug volume obviously the magnitude of ψon the hydraulic head oscillations is much lower than that related to h apart for some frequencies related to v 40 ml the peak frequencies on δh range in a narrow frequency band low energetic contributions appear at higher frequencies and specifically in a frequency window between about 0 1 and 1 hz the order of magnitude of the energy contents and frequency oscillations occurring on the hydraulic head oscillations was described along the lines of the analysis performed for the hydraulic heads see fig 5 fig 9 a shows the ratio ψmax m δ h ψmax h where ψmax m δh represents the mean value of maximum wavelet coefficients on δh while fig 9b shows the mean peak frequency fpm δ h related to the hydraulic head oscillations around δh 0 the mean energy contents on δh given by wavelet coefficients present an overall tendency to increase when v increases and their values range from 4 to 11 of the maximum value of maximum wavelet coefficients on h as also noticeable in fig 7 higher energy contents of δh are associated with the application of f10 and nearly equal results are obtained by means of f100 and f1000 it can be observed in fig 9b that except for two values related to 40 and 50 ml with f10 very similar results are obtained comparing the variation range of fpm δ h with fpm h see fig 5b a relevant amount of mean peak frequencies derived from the hydraulic head oscillations is concentrated in a narrow frequency band associated with long waves in this case the frequencies on δh range in a slightly larger band compared to those related to h and specifically from 0 022 hz to 0 032 hz with reference to the fitting analytical curve on h a representative long wave with an initial trough and a successive crest appears in the involved time window of the present slug experiments owing to a higher occurrence of time instants with δh 0 the use of f10 leads to higher frequencies than f100 and f1000 6 conclusions a laboratory campaign was conducted on the hydraulic response of a 3d large scale homogeneous and confined aquifer to slug tests obtaining large data sets to provide useful information on the groundwater system an analysis on the limits and capabilities of smoothing methods to process laboratory hydraulic head data was carried out for this purpose savitzky golay filter fourier transform and mexican hat and morlet wavelet transforms were used to smooth out the high frequency noise in the experimental hydraulic heads recorded by a pressure transducer arranged within the injection well the suitability of the adopted approaches was investigated by comparing the resulting smoothed time series of h with the canonical cooper equation by varying the slug volume from 30 to 90 ml and the measurement frequency 10 100 and 1000 hz it was highlighted that the mexican hat wavelet performs better than the other techniques in terms of correlation coefficient relative error and bias this result was associated with the nature of the involved hydrodynamic phenomenon i e an unsteady flow which better resembles the mother wavelet mexican hat compared to the other shapes since their native signal is quite different from the experimental one the obtained time series of h were found to be generally independent of the injected water volume moreover the measurement frequency of 100 hz was taken as representative of the observed hydraulic heads and more advisable to 1000 hz due to the time saved in processing analyses the smoothed data sets were adopted to assess the hydraulic conductivity of the aquifer confirming the superiority of the mexican hat wavelet in comparisons with other techniques indeed a more stable value of k was derived applying the smoothed h deduced from the mexican hat the use of high frequency measurements allowed the discovery of non linear effects in the time decay of h whose energy contents and frequency oscillations were exploited in the time frequency domain through application of the mexican hat wavelet transform it was shown that the mean energy contents increase proportionally to v and mean frequencies occur in a restricted low frequency band with associated wave periods of about 40 s the above wavelet transform was also adopted to study the hydraulic head oscillations around the theoretical cooper equation the initial underestimation and the successive overestimation of the reference curve has led to similar mean frequency oscillations of the values of δh if compared to h the mean of maximum energy contents in time of δh has been evaluated to be 4 to 11 of the maximum energy in time of h the present study shows that if slug tests provide large data sets it is appropriate to perform a careful smoothing analysis for this purpose valid methodological indications were given highlighting the most appropriate smoothing methods to be taken into account and other aspects connected with the choice of the most appropriate measurement frequency however it should be noted that the results obtained in the experimental investigation considered here remain confined to the laboratory scale and cannot be considered valid for field survey in fact at the field scale the heterogeneity of the aquifer could influence the phenomenon in a different way justifying uncertainties on the results and possible discrepancies with those obtained in the present investigation further field scale experimental investigations could be very useful to verify the influence of heterogeneity on the investigated aspects and to make comparisons with the results obtained at laboratory scale possible acknowledgment the authors are grateful to the editor and reviewers for their valuable suggestions which allowed them to significantly improve the paper 
7211,the present paper proposes a smoothing analysis of hydraulic head data sets obtained by means of different slug tests introduced in a confined aquifer laboratory experiments were performed through a 3d large scale physical model built at the university of calabria the hydraulic head data were obtained by a pressure transducer placed in the injection well and subjected to a processing operation to smooth out the high frequency noise occurring in the recorded signals the adopted smoothing techniques working in time frequency and time frequency domain are the savitzky golay filter modeled by third order polynomial the fourier transform and two types of wavelet transform mexican hat and morlet the performances of the filtered time series of the hydraulic heads for different slug volumes and measurement frequencies were statistically analyzed in terms of optimal fitting of the classical cooper s equation for practical purposes the hydraulic heads smoothed by the involved techniques were used to determine the hydraulic conductivity of the aquifer the energy contents and the frequency oscillations of the hydraulic head variations in the aquifer were exploited in the time frequency domain by means of wavelet transform as well as the non linear features of the observed hydraulic head oscillations around the theoretical cooper s equation keywords slug tests hydraulic head smoothing hydraulic conductivity wavelet analysis 1 introduction among the most commonly used methods to characterize aquifers it is necessary to consider pumping tests and slug tests it is well known that pumping tests allow the obtainment of more reliable measurements of large scale aquifer parameters however these tests are more complex to conduct requiring expensive equipment and one or more observation wells neuman 1975 zlotnik et al 2000 zhang and tang 2013 although they seem more vulnerable to errors and uncertainty slug tests are conversely characterized by simplicity of execution and a relatively low cost moreover the latter not requiring water extraction from the aquifer are very suitable for use in surveys regarding contaminants transport in groundwater severino 2011a severino et al 2011 severino et al 2012 therefore slug tests are increasingly used and often preferred compared to pumping tests in other words it is possible to state that slug tests are a common test procedure for aquifer characterization butler et al 1996 butler 1997 lee and lee 1999 beckie and harvey 2002 zurbuchen et al 2002 dietrich et al 2008 chiasson 2012 lewis 2013 slug tests to which reference is exclusively made in the following consist of an abrupt addition extraction or displacement of a known water volume in the well and the subsequent monitoring of changes in the water level hydraulic head as initial equilibrium conditions return butler 1997 sageev 1986 astm standard d4044 2006 on the basis of hydraulic head data thus detected it is possible to estimate the values of transmissivity t hydraulic conductivity k and in some cases even the storage coefficient s hvorslev 1951 cooper et al 1967 bouwer and rice 1976 swamee and singh 2007 severino et al 2008 koussis and akylas 2011 severino 2011b slug tests have been widely discussed in scientific literature and numerous historical overviews of the background can be found on this topic like those of yang and yeh 2004 and cardiff et al 2011 the many aspects related to slug tests have been studied in detail such as the influence of the skin effect chirlin 1989 hyder et al 1994 the influence of errors hyder et al 1994 chiasson 2012 the use of various numerical semi analytical and analytical models beckie and harvey 2002 butler and zhan 2004 influence of storage on the slug test analysis bredehoeft and papadopulos 1980 chapuis 1998 considerations and analysis on fissured aquifers barker 1988 quinn et al 2013 the development of the multiwell slug tests analysis mcelwee et al 1995 yang et al 2015 the oscillations of the water level around the equilibrium level induced by abrupt pressure change mcelwee 2002 audouin and bodin 2007 koussis and akylas 2011 the influence of heterogeneity and the upscaling processes beckie and harvey 2002 severino 2011b chen et al 2012 nevertheless it is possible to identify some aspects related to slug tests which can still be investigated in an appropriate manner such as the use of large data sets discussed in this study the difficulties of interpreting large data sets obtained from slug tests have already been appropriately highlighted chapuis 2009 however investigations on the influence of an adequate data smoothing analysis which is a topic poorly discussed in the scientific literature can be considered a novelty allowing for new and interesting contributions to be made to this subject during a slug test the time needed for the hydraulic head to return to its initial value before the test namely the duration of its variation depends on slug volume well geometry and aquifer characteristics related to the use of the field e g mcelwee 2002 or laboratory scale e g baptiste and chapuis 2015 the measurement frequency able to acquire a number of hydraulic head values sufficient to ensure a reliable estimate of the aquifer parameters should be based on this test duration therefore suitable automatic instrumentations such as electronic or vibrating wire pressure transducers placed in the water column and able to provide hydraulic head values at predetermined measurement frequencies are commonly used e g zarriello 1995 zurbuchen et al 2002 tools of this kind often allow the selection of the measurement frequency to record the hydraulic head variation see for more details post and von asmund 2013 obviously this selection must be made taking into due account the type of test performed in fact for a pumping test the sampling frequency may be suitably low e g jiménez martinez et al 2013 on the contrary for slug tests where variations of hydraulic head generally occur in very limited times the use of high measurement frequencies is common mcelwee 2002 audouin and bodin 2007 the optimal measurement frequency for the investigated physical process is linked to the different characteristics of the aquifer and well and the water volume injected into the well in this context the data number that can be obtained during a slug test depending heavily on the value of the measurement frequency is often quite high the analysis of a large data set to determine the characteristic parameters of an aquifer could also be considered advantageous to discover possible non linear effects in the time series of the hydraulic head e g butler et al 1996 however it should be considered that by increasing the number of data which are processed for the assumption of a high frequency of measurement the computational cost of the processing operation tends to grow moreover it should be noted that the acquired data can contain errors of different types systematic and random and alterations or experimental disturbances chargeable to various causes such as conditions of initial speed or acceleration in the groundwater electrical signal variations and still others mcelwee 2002 chiasson 2012 furthermore it is necessary to take into account that the increase in the data number can give rise to phenomena of errors propagation phillips and harris 1990 therefore the importance of being able to reduce the data number to be analyzed for the determination of the parameters under consideration is evident however this must be done without risking degrading of the quality of the data acquired by measurement i e without altering the reliability of the final result mainly in terms of reliability of the aquifer parameters values namely of energy contents and shapes of the pressure signal as in the present case in the experimental field a suitable filtering of recorded raw data is a common problem in various disciplines such as spectroscopy chemistry and biomedical monitoring and there are numerous methodologies developed to smooth out unwanted high and low frequency oscillations in particular smoothing approaches such as decimation statistical methods the use of convolution formulas based on simplified procedures of the least squares method and spectral analyses both in time and time frequency domain were adopted savitzky and golay 1964 box and jenkins 1970 comaniciu and meer 2002 dagum 2002 nie et al 2002 schmidt and skidmore 2004 audouin and bodin 2007 browne et al 2007 damiani et al 2011 the same kind of problem to smooth out the noise in the pressure field correctly also occurs in numerical modeling when the flow is considered as a weakly compressible medium by assuming an artificial sound of speed lower than the real one for computational reasons as in the case of the application of the popular lagrangian particle approach called smoothed particle hydrodynamics sph e g aristodemo et al 2017 the use of a weakly compressible model then leads to high frequency acoustic perturbations which should be removed from the numerical pressure field to recover the correct incompressible solution meringolo et al 2017 moreover several studies showed that with proper precautions the smoothing of the time series data related to the parameter measured often leads to a reduction of the uncertainty noise affecting these igbp 1992 viovy et al 1992 chen et al 2004 obviously each smoothing method has positive and negative aspects therefore it is of paramount importance to proceed with a careful and prudent choice of the method to be used phillips and harris 1990 schmidt and skidmore 2004 ruffin et al 2008 the aim of this study is to highlight the opportuneness of carrying out smoothing in cases where the data sets obtained by slug tests are particularly extensive providing a valid methodology and useful indications regarding the choice of the specific smoothing method to be used in the constant search to reduce times and costs the present study is based on a 3d experimental investigation carried out on a physical model reproducing a confined aquifer built for this purpose in the gmi laboratory at the department of civil engineering of the university of calabria italy of course the results obtained while highlighting the problem and the methodology to be used cannot be directly extended to field investigations although the problem of managing large data sets can also exist in the field depending on the test duration measurement device and frequency used this is also due to the significant difference between the slug volumes considered in the laboratory and in the field respectively and the consequent different aquifer volumes involved in the slug tests essentially this inequality between the two corresponding scales implies possible differences concerning the influence that the heterogeneity exerts on the flow phenomena induced by slug tests severino et al 2008 dagan et al 2009 severino 2011b fallico et al 2016 moreover the results of this experimental investigation allowed useful comments to be made on some characteristic aspects of slug tests related to hydraulic head variation in this context seven slug tests were performed through the injection of a specific water volume from 30 to 90 ml in the central well of the aquifer the hydraulic head variation was recorded by a high frequency pressure transducer placed in the injection well the raw data were processed using four smoothing techniques with different working principles in time frequency and time frequency domain specifically a savitzky golay filter based on local least squares polynomial approximation of a certain order savitzky and golay 1964 a fourier transform e g cooley and tukey 1965 and two kinds of wavelet transform like mexican hat and morlet e g morlet et al 1982 torrence and compo 1998 were used historically several approaches were carried out to smooth and analyze hydraulic head variations in an aquifer under various hydrodynamic forcings such as linear programming for the analysis of a karst aquifer dreiss 1989 moving average filter under radial flow conditions desbarats 1994 kernel density estimation to investigate groundwater discharges at springs manga 1999 hanning window method in karst aquifers long and derickson 1999 geostatistical methods to analyze bank filtrations cirpka et al 2007 fourier transform to smooth and analyze the recorded hydraulic head for pumping and slug tests in field conditions beckie 1996 audouin and bodin 2007 and a savitzky golay filter to investigate the hydraulic response of fractured aquifers jiménez martinez et al 2013 it can be noticed that several field studies monitored the hydraulic head with a low frequency of measurement and raw data were used to evaluate the characteristics of an aquifer e g mcelwee 2002 the smoothing operation proves to be conversely crucial when laboratory tests on smaller scales and then on smaller involved water volumes than field conditions were performed however to the authors knowledge no specific attention has been addressed to understanding the effects of smoothing techniques in the time series of the hydraulic head and the optimal measurement frequency to record it in the context of laboratory slug tests on the basis of experimental high frequency noise in the time series of the hydraulic head measured at the injection well specific time spans and cut off frequency were chosen for data smoothing using the selected methods and different frequency measurements the performances of the adopted techniques to smooth the hydraulic head data were analyzed in terms of correlation coefficient relative error and bias to accurately reproduce the cooper equation cooper et al 1967 an analysis of the time variation of the shape and the frequency oscillation of the hydraulic head variation was conducted in the time frequency domain by means of wavelet transform the results deduced from the smoothed hydraulic heads were adopted to perform a sensitivity analysis in determining a stable value of the hydraulic conductivity of the involved confined aquifer the wavelet transform was also applied to discover physical insights occurring in the decreasing part of the hydraulic head variation paying attention to the energy and frequency contents of the oscillations around the cooper equation able to theoretically represent the time history of the hydraulic head in slug test conditions the contents of the present paper are organized as follows section 2 describes the laboratory set up of the confined aquifer with specific information on the instrument to measure the hydraulic head afterwards the selected techniques to filter the raw time series of the experimental hydraulic head are illustrated in section 3 the method to assess the aquifer hydraulic conductivity is then recalled in section 4 the raw and smoothed time variations of the hydraulic head are then analyzed in section 5 by comparing the performances of the processing techniques to fit the reference empirical curve and to determine the hydraulic conductivity moreover physical insights exploited in the time frequency domain of the involved hydrodynamic processes are highlighted finally in section 6 the salient parts of the methodology proposed are briefly recalled highlighting the results obtained 2 experimental set up a large scale 3d homogeneous and confined aquifer was built in the gmi laboratory at the department of civil engineering of the university of calabria fig 1 a the physical model was built within a metal box with a square bottom a side 2 m in length and with a height of 1 m along the entire perimeter of the steel box at a distance of 5 cm from the vertical wall a fine wire mesh was fixed so to form a compartment inside which the water flows through the connection with two external loading reservoirs placed on opposite sides of the metal box the wire also provides a robust support for the porous medium placed inside the box a geotextile was suitably used covering the steel containment grid to prevent the porous material from passing through the wire mesh while allowing the water flow to and from the perimeter interspace later 10 wells were built one of which was central the others were positioned at increasing distances from the center and located in different directions to avoid mutual flow disturbances as shown in the plan view of fig 1b the wells were made of smooth pvc pipes polyvinyl chloride with a diameter of 2 8 cm completely penetrating sliced along the thickness of the considered confined aquifer and appropriately covered with geo textile to prevent soil particles from entering starting from the bottom of the metal box a layer of porous material with a thickness ts 0 25 m was placed to form the confined aquifer on which the experimental tests were to be conducted see lateral section a a sketched in fig 1c the granular material of this layer shows a high sand percentage 83 and a small gravel percentage 17 with an effective grain diameter d 10 0 188 mm the laying of this material constituting the solid matrix of the confined aquifer was carried out by repeating several water loading and unloading cycles to reach a natural packing the top of the groundwater system was achieved by a thin impermeable plastic panel this waterproof panel suitably folded and sealed at the walls of the box and wells was covered with additional sandy material to counter the water thrust exerted on it and also consequent possible and unwanted deformations preliminary tests were carried out to verify the seal of the waterproof plastic panel and the good working of the experimental apparatus fallico et al 2018 the aquifer built in this way even if it can be considered granulometrically homogeneous due to the random arrangement of the grains of the solid matrix has different sized pores and therefore can be considered intrinsically heterogeneous in fact the micro and macro pores within the considered porous medium give rise to heterogeneity at the laboratory scale which influences the flow phenomena several slug tests were performed using the present experimental set up an initial undisturbed hydraulic head of approximately 0 4 m was used for all the experiments this condition caused the confined aquifer with a thickness of 0 25 m to be slightly under pressure in particular seven slug tests were executed by injecting an increasing water volume v 30 40 50 60 70 80 and 90 ml in the central well these volumes were calibrated according to water quantities which were acceptable as a function of the dimensions of the laboratory set up without causing unwanted overflow and ensuring that the perturbed hydraulic head in the aquifer did not interact with the solid walls surrounding the experimental aquifer the occurrence of the mentioned flow conditions was checked for each test through the monitoring of the hydraulic head in the injection and observation wells specifically the monitoring of hydraulic heads in the observation wells was also performed to verify the suitability of the boundary conditions related to the analysis method of the hydraulic heads data detected in the inlet central well for each slug test appropriately recalled below moreover attention was also paid to check the reaching of the initial undisturbed conditions between successive tests in each well of the aquifer the time variation of the hydraulic head was recorded by a submersible pressure transducer placed at the bottom of the metal box in particular the adopted sensor was the pdcr1830 model by druck ranging from 0 to 3 5 m h2o and an accuracy of 0 1 of the full scale reading all sensor measurements were acquired in differential mode owing to the wheatstone bridge configuration by a data acquisition board a national instrument cdaq9184 chassis with a national instrument 9205 module the latter was connected to the pci bus of a personal computer by an ethernet cable in order to guarantee efficient synchronism and noise rejection the hardware software implementation was developed by the nexus electronic laboratory of the same university see for more details tripepi et al 2017 for all tests the measurement frequency of the transducers was fixed at 1000 hz and particular care was addressed to calibrate the transducer in the expected pressure range of the water level in the aquifer with a dynamic component induced by the inserted water volume as usually performed for slug tests e g butler 1997 the pressure measurements recorded in central well no 1 subjected to the water injection will be taken into account for the analysis of smoothing and the successive derivation of the hydraulic conductivity 3 smoothing techniques in this section the techniques adopted to filter the raw time series of the experimental hydraulic heads deduced from the measurements obtained by means of the pressure transducer in the injection well are illustrated since high frequency noise appears in the time variation of the observed hydraulic heads during the experiments the family of low pass filters should be adopted in this context savitzky golay filter sg fourier transform ft and two types of wavelet transform wt are taken into account the basic features of the above approaches are recalled in order to understand their characteristics in the presence of unsteady flow processes as in the current case i e the time decay of the hydraulic head due to aquifer response under the insertion of a specific water volume into an injection well 3 1 savitzky golay filter savitzky and golay 1964 proposed a data smoothing approach based on local least squares polynomial approximation the authors showed that fitting a polynomial of a given order to a set of input samples and then evaluating the resulting polynomial at a single point within the approximation interval is equivalent to discrete convolution with a fixed impulse response the low pass filters derived from this approach refer to the family of savitzky golay sg filters also known as digital smoothing polynomial filters or least squares smoothing filters see for more details phillips and harris 1990 and largely applied for data smoothing in remote sensing studies e g schmidt and skidmore 2004 it was noticed that this filter performs much better than the standard moving average which tends to filter out a relevant part of the signal at high frequencies along with the noise e g jiménez martinez et al 2013 following this time domain method a polynomial pi t of degree d which is to be fitted through the observed time series xi t is determined as 1 p i t j 0 d c j t t i δ t j in which the generic time ti t is equispaced by an imposed time step δt t the coefficients cj in eq 1 can be calculated by minimizing the mean squared error on input data xi t so that 2 sum k i n l i n r p i t k x k t 2 min where nl and nr represent the number of time instants to the left and the right of data points respectively as performed by aristodemo et al 2011 and contestabile et al 2012 in smoothing hydraulic heads for a partially saturated beach subjected to water waves and successfully comparing the results with dipmeters an sg filter with d 3 is adopted a specific span length l nl nr 1 and according to the specific sampling frequency will be chosen in the successive analyses 3 2 fourier transform the fourier transform ft is a method for transforming a function of time into a function of frequency and represents one of the most popular algorithms in signal processing and data analysis considering an input data signal x t an ft allows a translation from the time to the frequency domain as in the present case given by 3 x ω x t e i ω t dt where ω angular frequency 2πf t 1 being f the frequency t 1 and i is root square of 1 the function x t is determined through x ω using a inverse fourier transform ift which is defined as 4 x t x ω e i ω t d ω the present algorithm is related to the extraction of the series of sines and cosines which reconstruct the input function when superimposed as a result the fourier analysis is not local owing to its space filling nature and thus this approach is solely suitable for the analysis of stationary signals i e signals whose properties do not change with time when transforming to the frequency domain with the ft the time information is lost and the time instant when a specific physical process occurs is unknown a fourier transform is known as discrete fourier transform dft which can be calculated by a fast fourier transform fft or by its inverse i e the inverse fast fourier transform ifft allowing reduction of the complexityof computing the dft from o n 2 to o nlogn n being the number of data cooley and tukey 1965 in the range of possible frequencies a low pass filtering will be applied by choosing a cut off frequency fc to smooth out the high frequency oscillations linked to the noise in the time series of the raw pressure signals 3 3 wavelet transform the wavelet transform wt first introduced by morlet et al 1982 for the study of seismic signals is usually adopted to investigate time series containing non stationary energy contents at several different frequencies e g mallat 2009 in the wavelet analysis a generic function x t is analyzed both in the time and in the frequency domain by using a windowing function g t this approach is attained by a convolution of eq 3 as follows 5 x ω τ x t g t τ e i ω t dt where the time τ aτ0 and the angular frequency ω bω0 the parameters a re and b re represent respectively the values adopted to scale in frequency and to shift the function in time g t moreover re and re define the respective domains of coefficients a and b under this transformation the localized function g t becomes 6 g ab t g t a τ 0 e ib ω 0 t eq 6 can be replaced by a basic function named mother wavelet ψ 7 ψ ab t 1 a ψ t b a the wt of eq 5 is therefore defined as 8 ψ a b 1 a f t ψ t b a dt the constraint to be a mother wavelet is represented by the so called admissibility condition e g torrence and compo 1998 given by 9 c ψ 1 a ψ ω 2 ω d ω the function of the input data signal x t i e the inverse continuous wavelet transform icwt can be deduced from the wavelet ψab and the wavelet transform ψ a b as follows 10 x t 1 c ψ ψ a b ψ ab t dadb a 2 various families of mother wavelets were historically proposed in the wavelet framework in general the use of a specific mother wavelet is dependent on the studied physical process which can be characterized by the occurrence of slow or fast dynamics e g meringolo et al 2017 this choice can be driven by the fact that the shape of the wavelet should tend to well approximate the involved input signal in the large possibility of options of mother wavelets two types of wavelets namely mexican hat and morlet are here chosen heuristically in the following analyses because of their broad application in the field of flow dynamics when unsteady phenomena occur as in the analyzed slug tests for example the mexican hat wavelet was successfully applied to study the flow field behind two flat plates higuchi et al 1994 wedge slamming impacts and sloshing processes meringolo et al 2017 and wave loads at submerged cylinders aristodemo et al 2017 the morlet wavelet was instead adopted to investigate fluid processes such as surface ocean waves massel 2001 landslide generated waves panizzo et al 2002 and flow at two side by side cylinders wang et al 2007 the first adopted mother function is represented by the marr wavelet commonly known as mexican hat owing to its specific shape the mathematical representation of the mother wavelet ψ derived from the second derivative of a gaussian function and shown in fig 2 a is given by 11 ψ t 2 3 π 1 4 1 t 2 e t 2 2 the corresponding fourier transform of the mexican hat mother wavelet see fig 2b leads to 12 ψ ω 8 3 π 1 4 ω 2 e ω 2 2 the second mother wavelet adopted in this study is the morlet function represented as a plane wave modulated by a gaussian see fig 2c it is described by the following equation 13 ψ t π 1 4 e jk m t e t 2 2 where the wavevector km is set at 6 in order to satisfy the admissibility condition given by eq 8 as shown in fig 2d the wavelet transform of this mother wavelet is equal to 14 ψ ω π 1 4 ω 2 e ω k m 2 2 with reference to the comparison between the used mother wavelets and their related wavelet transform represented in fig 2 it can be noticed that the mexican hat shape is narrower in the time domain and broader in the spectral domain than the morlet the resulting wt of the former one is sharper in time and more stretched in scale if compared to the latter one this effect is due to the fact that the mexican hat mother wavelet presents only real values and takes into account both positive and negative oscillations in the time series as separate peaks in the wt the morlet also considers complex values and has more oscillations than the mexican hat by matching both positive and negative peaks into a single broad peak e g torrence and compo 1998 as performed for ft an ad hoc value of fc will be set to smooth out the noise in the high frequency band of the measured hydraulic heads using both mexican hat and morlet wavelets 4 estimation method of aquifer hydraulic conductivity the slug tests carried out in fully penetrating wells in confined aquifers reproduced at laboratory scale in the metallic box here considered were analyzed by the method of cooper et al 1967 this consists in a semilog type curve matching method that allows estimation of the aquifer transmissivity of the hydraulic conductivity and the specific storage coefficient this method is based on a relationship expressing the fact that the rate of flow of water into or out of the aquifer is equal to the water volume decrease or increase rate in the well the mathematical model respects the following assumptions homogeneous formation darcian flow instantaneous slug introduction and negligible well losses cooper et al 1967 butler 1997 cooper s analytical solution can be represented in the following form 15 h t h 0 f β α in which β represents a dimensionless time parameter 16 β kbt r c 2 and α represents a dimensionless storage parameter given by 17 α r w 2 s s b r c 2 where t is the time t b the aquifer thickness l k the radial component of the hydraulic conductivity lt 1 ss the specific storage l 1 h t the variation at time t of the hydraulic head in the well from the initial undisturbed conditions l h0 the initial variation of the hydraulic head in well l rw the effective radius of well screen l rc the effective radius of well casing l and r the radial direction l eq 15 plotted as normalized hydraulic head varying the logarithm of β forms a series of type curves each of which corresponds to a different α value this method via curve matching either manual or automated allows the determination of the radial component of the hydraulic conductivity for β 1 by the following relationship 18 k r c 2 bt 1 0 where t 1 0 is the real time corresponding to β 1 t and the meaning of the other values has already been specified cooper et al 1967 butler 1997 the cooper et al 1967 method also allows estimation of the specific storage coefficient it should be noted that both the values of t thus of k and ss determined by this method cannot be very reliable as a consequence of both the measured data uncertainty and the difficulty in distinguishing adjacent theoretical curves of matching method cooper et al 1967 papadopulos et al 1973 bredehoeft and papadopulos 1980 butler 1997 chapuis 1998 chapuis 2009 however under the assumption that the inertia of the water column in the well is negligible many studies show that the error in the determination of transmissivity would commonly be small for α 10 1 in fact in this case even with an uncertainty of α equal to 2 orders of magnitude the error on the transmissivity remains less than 30 papadopulos et al 1973 bredehoeft and papadopulos 1980 the error in transmissivity increases with increasing α values on the contrary the determination of ss by this method has always had questionable reliability as also stated by cooper et al 1967 and papadopulos et al 1973 therefore it can be assumed that in order to determine transmissivity the method of cooper et al 1967 is suitable only for α 10 1 5 results and discussion the hydraulic head time series in the well h were determined by subtracting the undisturbed hydraulic head from the pressure transducer measurements then the raw values of h were smoothed using savitzky golay filter sg fourier transform ft and two wavelets wt namely mexican hat mexh and morlet morl the data sets sampled with the measurement frequency f 1000 hz were subjected to a decimation considering time series with f 100 hz and 10 hz hereinafter the above three measurement frequencies will be respectively called f10 f100 and f1000 in order to accurately assess the hydraulic conductivity of the laboratory aquifer the raw hydraulic heads will also be processed by analyzing the optimal frequency to study the aquifer characteristics in terms of best fitting of the empirical law deduced from the general relation given by eq 15 and successive derivation of the hydraulic conductivity the filtering approach to eliminate the high frequency noise on h was carried out by setting a specific quantity related to the involved methods in time frequency and time frequency domain for sg characterized by a 3 degree polynomial a variable span length as a function of the measurement frequency was adopted specifically l 21 for f10 l 207 for f100 and l 2131 for f1000 for ft and wt cases an independent unique value of fc 0 65 hz was set to leave out the high frequency noise in the pressure field due to specific experimental disturbances however an ad hoc calibration to smooth raw data sets must be carried out in each measurement campaign and for each adopted instrument it should be stressed that particular care was paid to find an optimal setting of the involved parameters in all smoothing analyses with the aim of preserving the global and local energy contents and shapes of the time series of h in the following analyses a time window of about 50 s was considered as representative to analyze the progressive decrease of the hydraulic head due to the aquifer response under the perturbation given by the injected water volume indeed residual small oscillations of the hydraulic head are less than 1 of the maximum value of h after the considered time interval 5 1 analysis of hydraulic head data the raw and smoothed time series of h adopting the aforementioned approaches in the time frequency and time frequency domain were analyzed to determine the hydraulic conductivity of the laboratory aquifer for this purpose the resulting time variations of h were fitted through a specific law given by an exponential decay form and generally expressed by eq 15 under specific boundary conditions of cooper et al 1967 the fitting operation was performed for all slug volumes ranging from 30 to 90 ml and using the three adopted measurement frequencies fig 3 shows the time variation of the raw and smoothed sg ft mexh and morl hydraulic heads h for v 90 ml and using f10 f100 and f1000 the reference time t 0 corresponds to the appearance of the peak of h the corresponding fitting exponential curves and the 95 prediction intervals are also plotted in fig 3 the representative case with 90 ml was considered due to the fact that highest variations of h occur among the experimental tests particularly for the smoothed time series the hydraulic head variation is reasonably fitted by the reference exponential equation with an overall underestimation in the first decreasing part and an overestimation in the following one the smoothing effect of the involved techniques is evident when compared to the raw ones which are conversely affected by a relevant level of high frequency noise nevertheless the preservation of the peak through the setting of the quantities involved in the filtering operation of each technique has led to highlighting non linear effects in the overall time decreasing of smoothed h for all measurement frequencies specifically deviations from the theoretical time variation of h given by aquifer response at different energy and frequency oscillation occur whose magnitude is dependent on the adopted measurement frequency this feature is linked to the impossibility of recovering the theoretical assumptions of the cooper solution even though controlled laboratory conditions were adopted we presume that the observed smoothed oscillations on h can derive from a combination of realistic effects such as the finite operation of slug injection the hydraulic losses in the well and the aquifer system moreover the use of more refined frequency measurement compared to other laboratory e g baptiste and chapuis 2015 or field e g mcelwee 2002 tests can lead to highlight these non linear effects the above features will be successively exploited in terms of energy contents and frequency oscillations in order to assess the best processing approach the performances of raw and smoothed sg ft morl and mexh hydraulic head data sets for the accurate reproduction of the reference analytical solution by a specific measurement frequency were here investigated from a statistical viewpoint through the calculation of the correlation coefficient r2 the relative error se and the bias for raw and smoothed data the values of r2 are shown in table 1 as a function of v and using f10 f100 and f1000 it can be observed that the use of the widest measurement frequency f10 leads to the lowest values of r2 while the assumption of f100 and f1000 show similar results even if the highest r2 are generally associated with f1000 apart from some cases with v equal to 60 and 70 ml the values of r2 increase when high v are involved indeed for v 70 ml the values of r2 are larger than 0 9 by adopting raw and smoothed h to highlight the differences deriving from the use of different measurement frequencies and the consequent choice of the optimal value of f to be adopted in evaluation of the hydraulic conductivity the relative differences on the calculation of r2 between f10 and f100 and between f10 and f1000 lead to very similar results ranging from 0 6 for 90 ml to 14 6 for 30 ml indeed relative differences on r2 between f100 and f1000 oscillate between 0 04 and 0 08 by changing the measurement frequency relative differences on r2 are higher for raw data up to 7 2 and lower when the smoothed h with mexh and morl wavelet are considered regarding the various smoothing techniques the mexh wavelet gives the highest r2 followed respectively by morl ft and sg this result is in agreement with the shape of the hydraulic head variations at various v see fig 3 that better resemble the native shape of the mexican hat wavelet see fig 2a with respect to the morlet wavelet see fig 2c and the ft based on sinusoidal periodic signals the suitable performances of mexh wavelet were also underlined by meringolo et al 2017 for unsteady flow processes due to fluid structure interactions such as wedge slamming and sloshing phenomena on the other hand the very slight difference on r2 using f100 and f1000 suggests the assumption of f100 as a representative measurement frequency since the computational cost of the processing phase is reduced the time to run the developed in house matlab code using the adopted measurement frequencies f10 f100 and f1000 and the slug water volumes from 30 to 90 ml was referred to the different operations linked to the loading of the input hydraulic head data sets their processing i e the use of execute and conditional statements and of specific matlab toolboxes and the different plotting of the results in particular we roughly estimated that about 3 and 6 min were required to run the in house matlab code adopting respectively f10 and f100 while about 25 min was the run time when f1000 was used with reference to se table 2 highlights their values as a function of v and the raw and smoothing data using f10 f100 and f1000 the obtained results were found to be quite similar to those determined for r2 see table 1 the lowest values of se refer to the application of mexh to smooth the input raw time series of h followed in this case by smoothed morl sg and ft data and raw ones respectively as noticed for r2 the highest measurement frequency f1000 shows lowest values of se however the relative differences on se using f100 and f1000 are only slightly higher than the cases analyzed through r2 and about 2 moreover a not well defined trend is observed as a function of v and the lowest se are linked to 60 and 70 ml concerning the bias table 3 shows their values for raw and smoothed data as a function of v and adopting f10 f100 and f1000 apart from some cases with low values of v and measurement frequency equals to 10 hz the lowest bias are linked to the use of mexh if compared to the other smoothing techniques for this statistical parameter it can be observed that the smoothed values of h using mexh better follow the reference cooper solution than the smoothed morl sg and ft data and raw ones the obtained results generally confirm that performed for r2 and se indeed the lowest bias refer to f1000 and increase when high v are considered moreover the differences on bias using f100 and f1000 are very small and less than 1 6 on the basis of the results obtained by the statistical analyses it can be stated that the use of a mexican hat wavelet to smooth the raw time variation of h gives the best results in terms of r2 highest values se lowest values and bias lowest values for the related measurement frequency the use of f100 as a representative measurement frequency can be considered a good compromise between accuracy in fitting eq 15 and time saving in the smoothing operation if compared to f1000 the suitable results deduced from the application of the mexican hat wavelet allow the features of the hydraulic head variations in the time frequency domain to be discovered this approach is superior compared to the other approaches since savitzky golay acts only in the time domain ft allows an exploration of the physical process only in the frequency domain and the morlet wavelet suffers from the appearing of unwanted gibbs like effects in the presence of fast changes of pressure e g meringolo et al 2017 the feature of the hydraulic head for various slug volumes recorded by the transducer in the injection well is represented by an unsteady flow whose magnitude of the impulse i e the time integration of the pressure signal varies as a function of the injected slug volumes and aquifer characteristics for all slug volumes fig 4 shows the wavelet coefficients ψ deduced from the mexican hat wavelet and related to the energy contents of h occurring in the time and frequency variation of the raw hydraulic heads using the representative measurement frequency f100 a larger time window was taken into account to consider the initial fast rise of h after the insertion of the water volume in the well and the successive decay of h given by the aquifer characteristics the vertical coordinate is represented by a log scale in order to stretch the wavelet coefficients for a better visualization in fig 4 the peak frequencies fp associated with the maximum values of ψ for each frequency are superimposed on the wavelet coefficients and plotted by white dots the horizontal dashed black line refers to the cut off frequency fc adopted in wt to smooth out the high frequency noise in the input raw data with reference to the magnitude of the wavelet coefficients high positive values of ψ are related to high correlation between the observed pressure signal and the wavelet at a given frequency meaning that they are in phase when h and wavelet are in anti phase i e high negative values of ψ the shape of the hydraulic head for a certain f is negatively correlated with the adopted kind of wavelet conversely wavelet coefficients close to 0 represent values of h associated with a very low energy content and generally linked to the high frequency noise as highlighted in fig 4 for f fc by inspecting the general characteristics of the wavelet power spectra of fig 4 the rapid increase of h due to the injected slug volume leads to high negative values of ψ while the following decrease of h gives high positive wavelet coefficients until about 20 s in which the maximum absolute value of ψ occurs about after few seconds afterwards the change of concavity of the hydraulic head represented by the overestimation of the fitting curve see graphs l m and n of fig 3 related to mexican hat leads to high negative values of ψ as expected the magnitude of positive and negative values of ψ increases proportionally to v as regards the features of the peak frequencies associated with maximum positive or negative ψ they range within a low frequency band leading to high energetic oscillations that are related to long waves of order of the time window adopted to study the present physical process the values of fp are substantially independent of the injected slug volume and oscillate weakly in a narrow frequency range the characteristics of the filtered time series of h obtained by the mexican hat in terms of mean energy contents i e wavelet coefficients and mean frequency oscillations are investigated in fig 5 for various slug volumes and each adopted frequency measurement in particular fig 5a shows the ratio ψmax m h ψmax h where ψmax m h represents the mean value of maximum wavelet coefficients on h and ψmax h is the maximum value among the maximum wavelet coefficients on h the ratio ψmax m h ψmax h ranges from about 0 3 to 1 that correspond to 30 and 90 ml respectively higher ratios are generally linked to higher v a small increase in energy contents can be noticed when f1000 is applied with respect to f10 and f100 fig 5b illustrates the variation of the mean peak frequency fpm h as a function of different slug volumes and measurement frequencies as previously introduced for fig 4 the values of fpm h are quite constant and appear in a limited frequency band ranging from 0 024 and 0 027 hz that means the persistence of long oscillations with wave periods between about 38 and 42 s in which slight longer waves are linked to the use of f1000 in other words a unique great oscillation characterizes the time window of the involved slug laboratory tests by analyzing the features of energy and frequency characteristics of the smoothed time series of h with mexican hat it can be stated that the phenomenon is generally weakly dependent on the choice of the measurement frequency and that the mean peak frequency does not vary with the injected slug volume 5 2 assessment of hydraulic conductivity adopting the raw time series of h and smoothed ones deduced from savitzky golay fourier transform and mexican hat and morlet wavelets table 4 illustrates the obtained values of k using different slug volumes v and the involved measurement frequencies f10 f100 and f1000 the k values reported in table 4 were obtained by the method of cooper et al 1967 using the eq 15 and verifying the accomplishment of the initial and boundary conditions by monitoring hydraulic heads in observation wells from the analysis of hydraulic conductivity data shown in table 4 an overall small variation of k can be observed in the range of slug volumes and measurement frequencies implying the good quality of the laboratory dataset with reference to other experimental investigations butler et al 1996 butler 1997 consistently with the results shown in section 5 1 the above result proves to be particularly emphasized for the values of k derived from the application of smoothed hydraulic head data moreover a slight increasing trend of k proportionally to v can be noticed except for k deduced from raw hydraulic head data the use of f10 leads to the lowest hydraulic conductivities while the use of f1000 furnishes the highest k as highlighted in the statistical analysis performed in section 5 1 the differences on k comparing the values of k linked to f100 and f1000 are however very small to better analyze the general tendency of k at the present laboratory scale the obtained values were averaged over the related slug volumes fig 6 shows the variation of the related mean hydraulic conductivity km derived from raw and filtered data and for the considered measurement frequencies a substantial constant trend of km can be noticed when smoothed values of h are taken into account ranging from 1 63 10 4 to 2 78 10 4 m s as regards the measurement frequencies the mean percentage relative difference on k is approximately 26 comparing f10 and f100 or f10 and f1000 while this value is only about 4 when f100 and f1000 are compared paying attention to the smoothing techniques on the time variation of hydraulic head the application of the mexican hat wavelet gives the lowest variability on km among other processing methods in particular a variation of about 12 on km is observed for the mexican hat using the three measurement frequencies while the variation is about 26 when savitzky golay is adopted as a further indication it should be noted that the value of specific storage ss determined by the method of cooper et al 1967 for measuring frequency equal to 100 and mexican hat smoothing technique was included in a rather wide range between 2 63 10 7 m 1 and 1 77 10 3 m 1 around an average value equal to 2 95 10 4 m 1 5 3 analysis of oscillations of hydraulic head the smoothed time series of h related to the progressive decay after the peak are here inspected by analyzing the energy and frequency contents of the oscillations around the reference analytical solution derived from eq 15 the analysis is addressed to investigate the characteristics of the present aquifer at laboratory scale in terms of non linear effects in comparison with the widely adopted theoretical and simplified analytical equation by cooper et al 1967 owing to the best results previously obtained from a statistical viewpoint in terms of r2 and se the processed values of h obtained by means of the mexican hat wavelet were taken into account the investigated hydraulic head oscillations δh are considered as the difference between the time series of h filtered by the mexican hat and the fitting curve deduced starting from eq 15 for different v and for the adopted three measurement frequencies fig 7 displays the time series of δh smoothed by the mexican hat around δh 0 i e the reference theoretical curve it can be observed that amplitudes and periods of the oscillations are generally not linked to the magnitude of the slug volume inspecting the measurement frequency the use of the less refined f10 gives the highest magnitude of positive and negative values of δh and highest occurrence of oscillations around δh 0 the obtained results with f100 and f1000 show similar features and for computational reasons f100 can be considered as also underlined in section 5 1 by using f100 and f1000 the positive and negative values of δh are reduced in comparison with f10 even if a considerable contribution of time oscillations persists the assumption of f100 and f1000 to model the feature of the hydraulic head also lead to a lower occurrence of time instants when δh 0 and consequently longer wave periods with reference to the cooper equation the application of the mexican hat wavelet as a suitable smoothing technique to filter the hydraulic head data sets allowed exploitation of the features of δh in the time frequency domain as also carried out for h in section 5 1 along the lines of the previous fig 4 the wavelet coefficients and the related peak frequencies white dots of the hydraulic head oscillations are illustrated in fig 8 for all v the values of δh were smoothed by the mexican hat using the representative measurement frequency f100 for each frequency band high positive wavelet coefficients associated with positive values of δh occur for a few initial seconds followed by high negative ψ and δh until about 20 s and an occurrence of positive ψ and δh in the final time window this feature is observed to be weakly dependent on the magnitude of the injected slug volume obviously the magnitude of ψon the hydraulic head oscillations is much lower than that related to h apart for some frequencies related to v 40 ml the peak frequencies on δh range in a narrow frequency band low energetic contributions appear at higher frequencies and specifically in a frequency window between about 0 1 and 1 hz the order of magnitude of the energy contents and frequency oscillations occurring on the hydraulic head oscillations was described along the lines of the analysis performed for the hydraulic heads see fig 5 fig 9 a shows the ratio ψmax m δ h ψmax h where ψmax m δh represents the mean value of maximum wavelet coefficients on δh while fig 9b shows the mean peak frequency fpm δ h related to the hydraulic head oscillations around δh 0 the mean energy contents on δh given by wavelet coefficients present an overall tendency to increase when v increases and their values range from 4 to 11 of the maximum value of maximum wavelet coefficients on h as also noticeable in fig 7 higher energy contents of δh are associated with the application of f10 and nearly equal results are obtained by means of f100 and f1000 it can be observed in fig 9b that except for two values related to 40 and 50 ml with f10 very similar results are obtained comparing the variation range of fpm δ h with fpm h see fig 5b a relevant amount of mean peak frequencies derived from the hydraulic head oscillations is concentrated in a narrow frequency band associated with long waves in this case the frequencies on δh range in a slightly larger band compared to those related to h and specifically from 0 022 hz to 0 032 hz with reference to the fitting analytical curve on h a representative long wave with an initial trough and a successive crest appears in the involved time window of the present slug experiments owing to a higher occurrence of time instants with δh 0 the use of f10 leads to higher frequencies than f100 and f1000 6 conclusions a laboratory campaign was conducted on the hydraulic response of a 3d large scale homogeneous and confined aquifer to slug tests obtaining large data sets to provide useful information on the groundwater system an analysis on the limits and capabilities of smoothing methods to process laboratory hydraulic head data was carried out for this purpose savitzky golay filter fourier transform and mexican hat and morlet wavelet transforms were used to smooth out the high frequency noise in the experimental hydraulic heads recorded by a pressure transducer arranged within the injection well the suitability of the adopted approaches was investigated by comparing the resulting smoothed time series of h with the canonical cooper equation by varying the slug volume from 30 to 90 ml and the measurement frequency 10 100 and 1000 hz it was highlighted that the mexican hat wavelet performs better than the other techniques in terms of correlation coefficient relative error and bias this result was associated with the nature of the involved hydrodynamic phenomenon i e an unsteady flow which better resembles the mother wavelet mexican hat compared to the other shapes since their native signal is quite different from the experimental one the obtained time series of h were found to be generally independent of the injected water volume moreover the measurement frequency of 100 hz was taken as representative of the observed hydraulic heads and more advisable to 1000 hz due to the time saved in processing analyses the smoothed data sets were adopted to assess the hydraulic conductivity of the aquifer confirming the superiority of the mexican hat wavelet in comparisons with other techniques indeed a more stable value of k was derived applying the smoothed h deduced from the mexican hat the use of high frequency measurements allowed the discovery of non linear effects in the time decay of h whose energy contents and frequency oscillations were exploited in the time frequency domain through application of the mexican hat wavelet transform it was shown that the mean energy contents increase proportionally to v and mean frequencies occur in a restricted low frequency band with associated wave periods of about 40 s the above wavelet transform was also adopted to study the hydraulic head oscillations around the theoretical cooper equation the initial underestimation and the successive overestimation of the reference curve has led to similar mean frequency oscillations of the values of δh if compared to h the mean of maximum energy contents in time of δh has been evaluated to be 4 to 11 of the maximum energy in time of h the present study shows that if slug tests provide large data sets it is appropriate to perform a careful smoothing analysis for this purpose valid methodological indications were given highlighting the most appropriate smoothing methods to be taken into account and other aspects connected with the choice of the most appropriate measurement frequency however it should be noted that the results obtained in the experimental investigation considered here remain confined to the laboratory scale and cannot be considered valid for field survey in fact at the field scale the heterogeneity of the aquifer could influence the phenomenon in a different way justifying uncertainties on the results and possible discrepancies with those obtained in the present investigation further field scale experimental investigations could be very useful to verify the influence of heterogeneity on the investigated aspects and to make comparisons with the results obtained at laboratory scale possible acknowledgment the authors are grateful to the editor and reviewers for their valuable suggestions which allowed them to significantly improve the paper 
7212,real time flood forecasting is important for decision making with regards to flood control and disaster reduction the conventional approach involves a postprocessor calibration strategy that first calibrates the hydrological model and then estimates errors this procedure can simulate streamflow consistent with observations but obtained parameters are not optimal joint calibration strategies address this issue by refining hydrological model parameters jointly with the autoregressive ar model in this study five alternative schemes are used to forecast floods scheme i uses only the hydrological model while scheme ii includes an ar model for error correction in scheme iii differencing is used to remove non stationarity in the error series a joint inference strategy employed in scheme iv calibrates the hydrological and ar models simultaneously the back fitting algorithm a basic approach for training an additive model is adopted in scheme v to alternately recalibrate hydrological and ar model parameters the performance of the five schemes is compared with a case study of 15 recorded flood events from china s baiyunshan reservoir basin our results show that 1 schemes iv and v outperform scheme iii during the calibration and validation periods and 2 scheme v is inferior to scheme iv in the calibration period but provides better results in the validation period joint calibration strategies can therefore improve the accuracy of flood forecasting additionally the back fitting recalibration strategy produces weaker overcorrection and a more robust performance compared with the joint inference strategy keywords real time flood forecasting error updating back fitting algorithm recalibration 1 introduction accurate hydrologic forecasting plays an important role in flood control and disaster prevention chen et al 2016 for instance reliable flood forecasting can efficiently help the real time operation and management of water systems deng et al 2015 li et al 2010 liu et al 2015 forecast accuracy is largely controlled by hydrologic models based on current catchment status e g soil moisture runoff base flow and system inputs e g precipitation and evapotranspiration bao et al 2014 however errors produced in the forecasting process are unavoidable due to uncertainties in the state input model structure and parameters yang et al 2007 a real time updating technique is defined as a feedback process that integrates input data from the most recent measurement prior to issuing a forecast and has been widely used to improve forecast accuracy madsen and skotner 2005 refsgaard 1997 real time updating techniques are classified according to modified variables i e input and output variables model states parameters wmo 1992 the process of input variable updating focuses mostly on precipitation coustau et al 2013 shamseldin and o connor 1999 while state updating aims to produce model states that are consistent with observations li et al 2014 liu et al 2012 a kalman filter and its extensions are commonly applied in this classification barthelemy et al 2017 mure ravaud et al 2016 ocio et al 2017 another flexible but more computationally expensive approach is the sequential monte carlo method e g particle filtering arulampalam et al 2002 plaza et al 2012 model parameter updating is based on parameter estimation or optimization and includes a variety of model calibration techniques and global searching algorithms li et al 2014 vrugt et al 2003 output variable updating namely error updating or correction is used to predict the error series between hydrologic forecasts and observations chen et al 2015 pagano et al 2011 the most popular updating method among the above methods is the autoregressive ar model it has a simple structure minimal computational cost and distinct model improvement capacity li et al 2014 xiong and o connor 2002 conventional ar updating calibrates the hydrological model to obtain the best simulated streamflow and then uses the ar model to estimate errors i e postprocessor calibration strategy the forecasted streamflow is calculated by summing simulated streamflow and estimated errors goswami et al 2005 it is worth noting that this procedure guarantees simulated streamflow consistent with observations but not forecasted streamflow as a result parameters obtained from the hydrological model are not optimal and require improved forecast performance using joint calibration strategies unlike the postprocessor calibration strategy joint calibration strategies refine hydrological model parameters jointly with ar model parameters evin et al 2014 for example the joint inference strategy which simultaneously estimates hydrological and ar model parameters is widely used in rainfall runoff modeling e g yang et al 2007 evin et al 2014 however calibrating all parameters together can lead to strong parameter interference and heavy computational burden evin et al 2013 a back fitting recalibration strategy using the back fitting algorithm is proposed to address this issue the back fitting algorithm is a simple iterative procedure for fitting a generalized additive model sorokina et al 2007 the back fitting recalibration strategy is undertaken in two stages the hydrological model is first recalibrated keeping estimated errors fixed and the ar model is then recalibrated keeping simulated streamflow fixed this approach is computationally appealing because it focuses individually on either the hydrological or ar model during each recalibration another benefit of alternately estimating hydrological and ar model parameters includes lower parameter interaction compared with that of the joint inference strategy in this study we intercompare three calibration strategies and recommend avenues for improved real time flood forecasting three calibration strategies are 1 postprocessor i e hydrological model is calibrated first followed by error estimation 2 joint inference i e hydrological and ar model parameters are inferred simultaneously and 3 back fitting recalibration i e hydrological and ar models are recalibrated alternately a description of methodologies is given in section 2 and a case study within china s baiyunshan reservoir basin is explored in section 3 results and discussion are presented in section 4 and a summary given in section 5 2 methodology we employ the xinanjiang model as the hydrological model and the ar model for error updating tests for stationarity and differencing are conducted on the error series and three calibration strategies are used for estimating model parameters the link between methodologies is shown schematically in fig 1 2 1 xinanjiang model the xinanjiang model zhao 1992 has been widely applied across china for hydrologic forecasting and water resource management li et al 2015b the basic concept is that runoff forms upon storage repletion this indicates that runoff is generated only when the soil moisture content of the unsaturated zone reaches field capacity and that subsequent runoff equals rainfall excess without further loss yao et al 2014 the total runoff is divided into three components surface and groundwater runoff and interflow surface runoff is routed by an instantaneous unit hydrograph while interflow and groundwater are obtained by linear reservoirs lin et al 2014 a flowchart of the xinanjiang model is shown in fig 2 there are 15 parameters in the xinanjiang model including evapotranspiration parameters wum wlm wdm k c runoff production parameters b imp runoff separation parameters sm ex ki kg and flow concentration parameters ci cg n nk deng et al 2015 li et al 2013 a list of xinanjiang model parameters and their physical meanings are presented in table 1 an optimal set of these parameters is refined using combined optimization algorithms consisting of the genetic wang 1991 zhou et al 2017 rosenbrock rosenbrock 1960 and simplex algorithms nelder and mead 1965 the genetic algorithm is used first and the calibrated parameters are subsequently used as initial values for the rosenbrock algorithm the results from the rosenbrock algorithm are then treated as initial values for the simplex algorithm which optimizes the final parameter values the combined optimization algorithm has been used to good effect in a number of studies chen et al 2012 liu et al 2016a 2 2 error updating model prior to modeling error series differencing requirements are verified by observing the behavior of the autocorrelation function acf plots of the acf are commonly used to determine stationarity adamowski et al 2012 ch et al 2014 if the acf decreases slowly and remains outside of the 95 confidence interval the time series is determined to be non stationary otherwise the time series is considered stationary valenzuela et al 2008 if the differencing step needs to be performed the differenced error ε i is generated by first order differencing according to 1 ε i e i e i 1 where e i is the error at time step i and e i 1 is the error at time step i 1 the estimated differenced error at time step i can be given as follows goswami et al 2005 nguyen and chua 2012 2 ε i 1 ε i 1 2 ε i 2 p ε i p where ε i 1 ε i 2 and ε i p are differenced errors at time steps i 1 i 2 and i 3 respectively 1 2 p are autoregressive parameters that can be estimated using the least squares method and p is the order in order to reduce the overcorrection of ar updating the estimated differenced error is set to equal or smaller than the last raw error li et al 2015a the estimated error is expressed as 3 e i ε i e i 1 ε i ε i 1 ε i 1 e i 1 otherwise 2 3 postprocessor calibration strategy the conventional objective function is given by 4 minf 1 n i 1 n q obs i q sim i 2 where q obs i and q sim i are the observed and simulated streamflow respectively and n is data length this strategy is widely used in ar updating however it depends only on differences between observed and simulated streamflow while ignoring interactions between hydrological and ar model parameters hence optimal parameters are not identified by the postprocessor calibration strategy 2 4 two joint calibration strategies 2 4 1 joint inference strategy a joint calibration strategy is introduced in this study in order to improve forecast accuracy given that θ denotes 15 xinanjiang parameters and denotes the autoregressive parameters the objective function of the joint inference strategy is expressed as 5 minf 1 θ 1 n i 1 n q obs i q for i 2 1 n i 1 n q obs i q sim i e i 2 where q for i is forecasted streamflow and e i is the estimated error the joint inference strategy depends on differences between observed and forecasted streamflow parameters of the hydrological and ar models are estimated simultaneously using eq 5 2 4 2 back fitting recalibration strategy the back fitting algorithm is a useful tool for fitting an additive model with a fixed number of components trevor 1990 for an additive model the back fitting algorithm estimates one component while fixing the other components at each step and proceeds component by component until convergence ansley and kohn 1994 details of this technique are given in hastie et al 2001 since the hydrological and error updating models are arranged additively in this study the back fitting algorithm can be used for training these components unlike the joint inference strategy the back fitting recalibration strategy infers parameters of hydrological and ar models alternately the optimal parameter set is obtained as follows fig 3 i the hydrological model is recalibrated keeping estimated errors fixed the objective function in the recalibration is expressed as 6 minf 2 θ 1 n i 1 n q obs i e i q sim i 2 ii the ar model is recalibrated keeping simulated streamflow fixed iii steps i and ii are repeated for recalibration with a pre determined number e g 2000 times 2 5 model evaluations forecasting results are compared using six evaluation metrics i nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 ii persistence index pi kitanidis and bras 1980 iii mean absolute relative error mare khalil et al 2001 iv critical success index csi jolliffe and stephenson 2012 wilks 2011 v percent error in peak pep green and stephenson 1986 and vi error in time to peak flow δt lin and chen 2004 these metrics can be computed as 7 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 8 pi 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs i 1 2 9 mare 1 n i 1 n q obs i q sim i q obs i 10 csi n hits n hits n misses n falsealarms 11 pep 1 m i 1 m peak obs i peak sim i peak obs i 12 δ t 1 m i 1 m t obs i t sim i where q obs i and q sim i are the observed and simulated values at time step i respectively and q obs is the mean of the observed values n is the total length of the flow data n hits indicates the number of times that both the observation and simulation value meet the threshold streamflow q n misses refers to the number of times q was missed by the simulation n falsealarms refers to the number of times q was identified by the simulation but not confirmed by observations peak obs i and peak sim i are the observed and simulated peak flood values at time step i respectively and m is the number of selected flood events t obs i and t sim i are the observed and simulated occurrence times of the peak floods respectively these metrics evaluate the efficacy of different aspects of the developed models dawson et al 2007 pi is similar to nse but it uses the last observed value as the forecast barbetta et al 2017 mare is more sensitive to lower flows than nse and pi because the errors are not squared jain and srinivasulu 2006 lin and jhong 2015 csi investigates the ratio of the number of streamflow values detected by the forecasting model pep evaluates the difference between the peak observation and simulation values instead of measuring the overall agreement lin and chen 2004 δt is an important index indicating whether peak discharge forecasts can be issued in a timely manner nanda et al 2016 in a perfect model analysis indicates that nse pi and fcsi would be equal to 1 whereas mare pep and δt would be equal to 0 3 case study 3 1 study areas and data used the baiyunshan reservoir basin located in southeastern china was selected for this study the basin bears a tropical monsoon climate that contributes to river floods fang et al 2007 rainfall is widely variable between different seasons with dramatic rises and drops of peak flow from a hydro meteorological perspective the underlying surface conditions and streamflow and rainfall runoff processes are characteristic of an excess storage pattern as a consequence the xinanjiang model is particularly appropriate for application in this selected basin the area of the baiyunshan reservoir basin is 464 km2 and contains three hydrologic gauged stations nine rain gauged stations and one water level gauged station fig 4 liu et al 2016b hourly rainfall evaporation and streamflow data are available for the period 1994 2000 areal precipitation was obtained by the thiessen polygon method considering spatial variation huang et al 2016 wu et al 2017 areal pan evaporation was computed using the average value of the three measured evaporation stations the data were divided into two sets data from 1994 to 1997 were used for calibration and data from 1998 to 1999 were used for validation fifteen flood events were identified table 2 ten of these occurred in the calibration period and the other five occurred in the validation period 3 2 modeling schemes five schemes are developed as follows fig 5 i the xinanjiang model is directly used to simulate streamflow ii an ar model is applied to the raw errors obtained from xinanjiang modeling iii a differencing step is applied to render non stationary errors stationary and the ar model is then used to model differenced errors iv the joint inference strategy is used to calibrate the xinanjiang and ar models simultaneously v the back fitting recalibration strategy is used to recalibrate the xinanjiang and ar models alternately the five schemes described above were implemented using data obtained from the baiyunshan reservoir calibration processes are described in sections 4 1 4 4 verification of the obtained parameters and a performance comparison of the different calibration strategies are given in section 4 5 4 results and discussion 4 1 results of the xinanjiang model scheme i the xinanjiang model is calibrated using eq 4 as the objective function fifteen parameters are estimated including wum wld wdm c k b sm ex kss kkss kg imp n and nk the obtained parameters are listed in table 3 the nse is 92 3 in the calibration period 4 2 modeling of the error series schemes ii iii the error series consists of the differences between the observed and simulated streamflow the stationarity of the error series can be checked using the acf method from fig 6 a the acf of the error series is slowly decaying this suggests that the errors are nonstationary and hence differencing is required the acf plot of the differenced error series is shown in fig 6 b the acf decays exponentially and converges to zero which indicates the stationarity of differenced errors hence the differencing step should be applied to the errors note that lower orders i e orders less than or equal to 2 are widely used to reduce the heavy computational burden and complexity of optimization bennett et al 2016 lundberg 1982 sun et al 2017 wu et al 2012 we have conducted an experiment using the autoregressive integrated moving average arima model with different lags results show that the ar 2 arima 1 1 1 and other lower order arima models do not significantly decrease the akaike s information criteria aic value than the ar 1 the ar model of order 1 is therefore used to estimate the errors in scheme ii and the differenced errors in schemes iii v the nse of schemes ii and iii are 95 2 and 97 7 respectively which implies that the latter yields a better simulation than the former and that the differencing step is effective 4 3 calibration of models using the joint inference strategy scheme iv scheme iv uses eq 5 as the objective function to simultaneously refine xinanjiang and ar model parameters during the calibration period the results yield an nse of 98 1 obtained parameters are listed in table 3 4 4 calibration of models using the back fitting recalibration strategy scheme v in the back fitting recalibration approach estimated errors obtained in scheme iii are held fixed as initial values to recalibrate the xinanjiang model using eq 6 as the objective function estimated errors are then updated by keeping simulated streamflow fixed the process where the xinanjiang and ar models are recalibrated alternately is repeated 2000 times the optimal parameter set is obtained with an nse of 97 9 during the calibration period table 3 4 5 comparison of results with different calibration strategies hydrological model parameters of schemes iii iv and v table 3 are obtained as described in sections 4 1 4 3 and 4 4 respectively and are then used individually to forecast floods in the validation period summarized results are presented in tables 4 and 5 it can be observed that the performances of schemes iii iv and v are consistent in terms of nse and pi whereas they differ with respect to mare specifically scheme iv provides the highest values of nse and pi followed by scheme v in the calibration period scheme v outperforms schemes iv and iii giving the highest nse and pi values in the validation period however scheme iii performs best in terms of the lowest mare value in both the calibration and validation periods the difference is mainly due to the squared errors in the objective functions used by the developed models this indicates that the joint calibration strategy can further optimize the model parameters overall the joint inference and back fitting recalibration strategies are more sensitive to higher flows and the postprocessor calibration strategy is more sensitive to lower flows additionally the back fitting recalibration strategy is more robust than the joint inference strategy during the validation period fig 7 illustrates the csi for threshold discharges q of 20 420 m3 s the csi value decreases as q increases making higher flows more difficult to capture from fig 7 a it appears that schemes iv and v can capture higher discharges better especially scheme v in the calibration period scheme v is clearly superior for threshold discharges above 300 m3 s whereas it shows more discrepancy than scheme iii for threshold discharges below 300 m3 s similarly in the validation period scheme iii performs better than scheme v for threshold discharges of 150 250 m3 s whereas the opposite is true for threshold discharges below 150 m3 s and above 250 m3 s once again these results demonstrate that higher flows can easily be detected by the joint inference and back fitting recalibration strategies and that the postprocessor calibration strategy is more appropriate for lower flows moreover the results can be assessed based on the selected flood event fig 8 a d presents hydrographs of schemes iii iv and v from flood events in may 1994 july 1997 june 1998 and may 1999 the first two occur in the calibration period and the latter two occur in the validation period the results show that the three schemes can forecast the flood events specifically table 5 indicates that scheme v best captures the peak discharge and scheme iv gives the smallest time to peak flow in the validation period however scheme iii performs best in terms of pep and scheme v is the most accurate in terms of δt during the validation period radar maps of schemes iii iv and v using the six evaluation metrics are summarized in fig 9 scheme v best captures the peak flow in the calibration period achieving a score of 3 whereas scheme iii scores 1 for giving the highest pep in fig 9 a and b scheme iv clearly achieves the best performance during the calibration period and scheme v gives the most accurate forecasts in the validation period note that schemes iv and v are more sensitive to high flows fig 9 b and d whereas the postprocessor calibration strategy performs well for lower flows fig 9 a and c a six hour streamflow series from may 1994 is shown in fig 10 where it can be seen that the xinanjiang models noted as base in figures of schemes iii iv and v all underestimate the streamflow at 19 00 the underestimation is identified and corrected by ar updating procedures however the estimated error of scheme iii at 20 00 is notably large as a result the forecasted streamflow at 20 00 is overestimated and the compensated error estimate at 21 00 is substantially smaller this implies that the updating procedure of scheme iii leads to overcorrection in contrast schemes iv and v work well in this situation because their objective functions allow interaction between xinanjiang and ar model parameters we conclude that both joint inference and back fitting recalibration strategies can reduce the overcorrection inherent in the postprocessor calibration strategy from table 5 and fig 8c and d it can be further observed that scheme v works best during the validation period an example is presented in fig 11 here the joint inference strategy causes more overcorrection than the back fitting recalibration strategy in this case the xinanjiang model of scheme iv overestimates streamflow between 5 00 and 6 00 while the simulated streamflow of schemes iii and v are lower than observed values simulation of the xinanjiang model is therefore crucial for real time flood forecasting the xinanjiang model simulation of scheme v is superior to that of scheme iv table 4 suggesting better forecast performance using the back fitting recalibration strategy a comparison of simulated and observed streamflow is presented in fig 12 it can be seen in fig 12 a and b that scheme iv performs best in the calibration period while scheme v is superior in the validation period especially at high streamflow the xinanjiang model simulations of schemes iii iv and v are compared in fig 12 c and d it is worth noting that the xinanjiang model of scheme iii produces substantial overestimation of streamflow a slight overestimation is observed in scheme iv in this case the streamflow overestimation is compensated by the ar model which can result in overcorrection such as the unreasonably large or small estimated errors shown in figs 10 and 11 the xinanjiang model simulation of scheme v produces neither an overestimate nor an underestimate to some extent this finding demonstrates the best performance of scheme v using the back fitting recalibration strategy 5 conclusions three joint calibration strategies are examined in this study the first is the conventional approach of postprocessor calibration the second is the joint inference strategy where ar and hydrological model parameters are estimated simultaneously the third strategy is back fitting recalibration that alternately recalibrates the hydrological and ar models in order to compare the efficiency of the three joint calibration strategies five schemes are used to forecast 15 flood events in the baiyunshan reservoir basin the following conclusions can be drawn 1 joint calibration strategies can reduce overcorrection produced by the ar model and yield better forecasting than the postprocessor calibration strategy 2 the back fitting algorithm is superior to the joint inference strategy in the validation period due to a more robust simulation provided by the hydrological model furthermore the back fitting algorithm has great potential for joint calibration in cases where the forecast system has more complex models and a larger number of parameters which can be explored in future studies acknowledgements this study was supported by the national key research and development program 2016yfc0400907 the innovative research groups of the natural science foundation of hubei china 2017cfa015 and the national natural science foundation of china 51579180 the authors would like to thank the editor and anonymous reviewers for their comments that helped improve the quality of the paper 
7212,real time flood forecasting is important for decision making with regards to flood control and disaster reduction the conventional approach involves a postprocessor calibration strategy that first calibrates the hydrological model and then estimates errors this procedure can simulate streamflow consistent with observations but obtained parameters are not optimal joint calibration strategies address this issue by refining hydrological model parameters jointly with the autoregressive ar model in this study five alternative schemes are used to forecast floods scheme i uses only the hydrological model while scheme ii includes an ar model for error correction in scheme iii differencing is used to remove non stationarity in the error series a joint inference strategy employed in scheme iv calibrates the hydrological and ar models simultaneously the back fitting algorithm a basic approach for training an additive model is adopted in scheme v to alternately recalibrate hydrological and ar model parameters the performance of the five schemes is compared with a case study of 15 recorded flood events from china s baiyunshan reservoir basin our results show that 1 schemes iv and v outperform scheme iii during the calibration and validation periods and 2 scheme v is inferior to scheme iv in the calibration period but provides better results in the validation period joint calibration strategies can therefore improve the accuracy of flood forecasting additionally the back fitting recalibration strategy produces weaker overcorrection and a more robust performance compared with the joint inference strategy keywords real time flood forecasting error updating back fitting algorithm recalibration 1 introduction accurate hydrologic forecasting plays an important role in flood control and disaster prevention chen et al 2016 for instance reliable flood forecasting can efficiently help the real time operation and management of water systems deng et al 2015 li et al 2010 liu et al 2015 forecast accuracy is largely controlled by hydrologic models based on current catchment status e g soil moisture runoff base flow and system inputs e g precipitation and evapotranspiration bao et al 2014 however errors produced in the forecasting process are unavoidable due to uncertainties in the state input model structure and parameters yang et al 2007 a real time updating technique is defined as a feedback process that integrates input data from the most recent measurement prior to issuing a forecast and has been widely used to improve forecast accuracy madsen and skotner 2005 refsgaard 1997 real time updating techniques are classified according to modified variables i e input and output variables model states parameters wmo 1992 the process of input variable updating focuses mostly on precipitation coustau et al 2013 shamseldin and o connor 1999 while state updating aims to produce model states that are consistent with observations li et al 2014 liu et al 2012 a kalman filter and its extensions are commonly applied in this classification barthelemy et al 2017 mure ravaud et al 2016 ocio et al 2017 another flexible but more computationally expensive approach is the sequential monte carlo method e g particle filtering arulampalam et al 2002 plaza et al 2012 model parameter updating is based on parameter estimation or optimization and includes a variety of model calibration techniques and global searching algorithms li et al 2014 vrugt et al 2003 output variable updating namely error updating or correction is used to predict the error series between hydrologic forecasts and observations chen et al 2015 pagano et al 2011 the most popular updating method among the above methods is the autoregressive ar model it has a simple structure minimal computational cost and distinct model improvement capacity li et al 2014 xiong and o connor 2002 conventional ar updating calibrates the hydrological model to obtain the best simulated streamflow and then uses the ar model to estimate errors i e postprocessor calibration strategy the forecasted streamflow is calculated by summing simulated streamflow and estimated errors goswami et al 2005 it is worth noting that this procedure guarantees simulated streamflow consistent with observations but not forecasted streamflow as a result parameters obtained from the hydrological model are not optimal and require improved forecast performance using joint calibration strategies unlike the postprocessor calibration strategy joint calibration strategies refine hydrological model parameters jointly with ar model parameters evin et al 2014 for example the joint inference strategy which simultaneously estimates hydrological and ar model parameters is widely used in rainfall runoff modeling e g yang et al 2007 evin et al 2014 however calibrating all parameters together can lead to strong parameter interference and heavy computational burden evin et al 2013 a back fitting recalibration strategy using the back fitting algorithm is proposed to address this issue the back fitting algorithm is a simple iterative procedure for fitting a generalized additive model sorokina et al 2007 the back fitting recalibration strategy is undertaken in two stages the hydrological model is first recalibrated keeping estimated errors fixed and the ar model is then recalibrated keeping simulated streamflow fixed this approach is computationally appealing because it focuses individually on either the hydrological or ar model during each recalibration another benefit of alternately estimating hydrological and ar model parameters includes lower parameter interaction compared with that of the joint inference strategy in this study we intercompare three calibration strategies and recommend avenues for improved real time flood forecasting three calibration strategies are 1 postprocessor i e hydrological model is calibrated first followed by error estimation 2 joint inference i e hydrological and ar model parameters are inferred simultaneously and 3 back fitting recalibration i e hydrological and ar models are recalibrated alternately a description of methodologies is given in section 2 and a case study within china s baiyunshan reservoir basin is explored in section 3 results and discussion are presented in section 4 and a summary given in section 5 2 methodology we employ the xinanjiang model as the hydrological model and the ar model for error updating tests for stationarity and differencing are conducted on the error series and three calibration strategies are used for estimating model parameters the link between methodologies is shown schematically in fig 1 2 1 xinanjiang model the xinanjiang model zhao 1992 has been widely applied across china for hydrologic forecasting and water resource management li et al 2015b the basic concept is that runoff forms upon storage repletion this indicates that runoff is generated only when the soil moisture content of the unsaturated zone reaches field capacity and that subsequent runoff equals rainfall excess without further loss yao et al 2014 the total runoff is divided into three components surface and groundwater runoff and interflow surface runoff is routed by an instantaneous unit hydrograph while interflow and groundwater are obtained by linear reservoirs lin et al 2014 a flowchart of the xinanjiang model is shown in fig 2 there are 15 parameters in the xinanjiang model including evapotranspiration parameters wum wlm wdm k c runoff production parameters b imp runoff separation parameters sm ex ki kg and flow concentration parameters ci cg n nk deng et al 2015 li et al 2013 a list of xinanjiang model parameters and their physical meanings are presented in table 1 an optimal set of these parameters is refined using combined optimization algorithms consisting of the genetic wang 1991 zhou et al 2017 rosenbrock rosenbrock 1960 and simplex algorithms nelder and mead 1965 the genetic algorithm is used first and the calibrated parameters are subsequently used as initial values for the rosenbrock algorithm the results from the rosenbrock algorithm are then treated as initial values for the simplex algorithm which optimizes the final parameter values the combined optimization algorithm has been used to good effect in a number of studies chen et al 2012 liu et al 2016a 2 2 error updating model prior to modeling error series differencing requirements are verified by observing the behavior of the autocorrelation function acf plots of the acf are commonly used to determine stationarity adamowski et al 2012 ch et al 2014 if the acf decreases slowly and remains outside of the 95 confidence interval the time series is determined to be non stationary otherwise the time series is considered stationary valenzuela et al 2008 if the differencing step needs to be performed the differenced error ε i is generated by first order differencing according to 1 ε i e i e i 1 where e i is the error at time step i and e i 1 is the error at time step i 1 the estimated differenced error at time step i can be given as follows goswami et al 2005 nguyen and chua 2012 2 ε i 1 ε i 1 2 ε i 2 p ε i p where ε i 1 ε i 2 and ε i p are differenced errors at time steps i 1 i 2 and i 3 respectively 1 2 p are autoregressive parameters that can be estimated using the least squares method and p is the order in order to reduce the overcorrection of ar updating the estimated differenced error is set to equal or smaller than the last raw error li et al 2015a the estimated error is expressed as 3 e i ε i e i 1 ε i ε i 1 ε i 1 e i 1 otherwise 2 3 postprocessor calibration strategy the conventional objective function is given by 4 minf 1 n i 1 n q obs i q sim i 2 where q obs i and q sim i are the observed and simulated streamflow respectively and n is data length this strategy is widely used in ar updating however it depends only on differences between observed and simulated streamflow while ignoring interactions between hydrological and ar model parameters hence optimal parameters are not identified by the postprocessor calibration strategy 2 4 two joint calibration strategies 2 4 1 joint inference strategy a joint calibration strategy is introduced in this study in order to improve forecast accuracy given that θ denotes 15 xinanjiang parameters and denotes the autoregressive parameters the objective function of the joint inference strategy is expressed as 5 minf 1 θ 1 n i 1 n q obs i q for i 2 1 n i 1 n q obs i q sim i e i 2 where q for i is forecasted streamflow and e i is the estimated error the joint inference strategy depends on differences between observed and forecasted streamflow parameters of the hydrological and ar models are estimated simultaneously using eq 5 2 4 2 back fitting recalibration strategy the back fitting algorithm is a useful tool for fitting an additive model with a fixed number of components trevor 1990 for an additive model the back fitting algorithm estimates one component while fixing the other components at each step and proceeds component by component until convergence ansley and kohn 1994 details of this technique are given in hastie et al 2001 since the hydrological and error updating models are arranged additively in this study the back fitting algorithm can be used for training these components unlike the joint inference strategy the back fitting recalibration strategy infers parameters of hydrological and ar models alternately the optimal parameter set is obtained as follows fig 3 i the hydrological model is recalibrated keeping estimated errors fixed the objective function in the recalibration is expressed as 6 minf 2 θ 1 n i 1 n q obs i e i q sim i 2 ii the ar model is recalibrated keeping simulated streamflow fixed iii steps i and ii are repeated for recalibration with a pre determined number e g 2000 times 2 5 model evaluations forecasting results are compared using six evaluation metrics i nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 ii persistence index pi kitanidis and bras 1980 iii mean absolute relative error mare khalil et al 2001 iv critical success index csi jolliffe and stephenson 2012 wilks 2011 v percent error in peak pep green and stephenson 1986 and vi error in time to peak flow δt lin and chen 2004 these metrics can be computed as 7 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 8 pi 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs i 1 2 9 mare 1 n i 1 n q obs i q sim i q obs i 10 csi n hits n hits n misses n falsealarms 11 pep 1 m i 1 m peak obs i peak sim i peak obs i 12 δ t 1 m i 1 m t obs i t sim i where q obs i and q sim i are the observed and simulated values at time step i respectively and q obs is the mean of the observed values n is the total length of the flow data n hits indicates the number of times that both the observation and simulation value meet the threshold streamflow q n misses refers to the number of times q was missed by the simulation n falsealarms refers to the number of times q was identified by the simulation but not confirmed by observations peak obs i and peak sim i are the observed and simulated peak flood values at time step i respectively and m is the number of selected flood events t obs i and t sim i are the observed and simulated occurrence times of the peak floods respectively these metrics evaluate the efficacy of different aspects of the developed models dawson et al 2007 pi is similar to nse but it uses the last observed value as the forecast barbetta et al 2017 mare is more sensitive to lower flows than nse and pi because the errors are not squared jain and srinivasulu 2006 lin and jhong 2015 csi investigates the ratio of the number of streamflow values detected by the forecasting model pep evaluates the difference between the peak observation and simulation values instead of measuring the overall agreement lin and chen 2004 δt is an important index indicating whether peak discharge forecasts can be issued in a timely manner nanda et al 2016 in a perfect model analysis indicates that nse pi and fcsi would be equal to 1 whereas mare pep and δt would be equal to 0 3 case study 3 1 study areas and data used the baiyunshan reservoir basin located in southeastern china was selected for this study the basin bears a tropical monsoon climate that contributes to river floods fang et al 2007 rainfall is widely variable between different seasons with dramatic rises and drops of peak flow from a hydro meteorological perspective the underlying surface conditions and streamflow and rainfall runoff processes are characteristic of an excess storage pattern as a consequence the xinanjiang model is particularly appropriate for application in this selected basin the area of the baiyunshan reservoir basin is 464 km2 and contains three hydrologic gauged stations nine rain gauged stations and one water level gauged station fig 4 liu et al 2016b hourly rainfall evaporation and streamflow data are available for the period 1994 2000 areal precipitation was obtained by the thiessen polygon method considering spatial variation huang et al 2016 wu et al 2017 areal pan evaporation was computed using the average value of the three measured evaporation stations the data were divided into two sets data from 1994 to 1997 were used for calibration and data from 1998 to 1999 were used for validation fifteen flood events were identified table 2 ten of these occurred in the calibration period and the other five occurred in the validation period 3 2 modeling schemes five schemes are developed as follows fig 5 i the xinanjiang model is directly used to simulate streamflow ii an ar model is applied to the raw errors obtained from xinanjiang modeling iii a differencing step is applied to render non stationary errors stationary and the ar model is then used to model differenced errors iv the joint inference strategy is used to calibrate the xinanjiang and ar models simultaneously v the back fitting recalibration strategy is used to recalibrate the xinanjiang and ar models alternately the five schemes described above were implemented using data obtained from the baiyunshan reservoir calibration processes are described in sections 4 1 4 4 verification of the obtained parameters and a performance comparison of the different calibration strategies are given in section 4 5 4 results and discussion 4 1 results of the xinanjiang model scheme i the xinanjiang model is calibrated using eq 4 as the objective function fifteen parameters are estimated including wum wld wdm c k b sm ex kss kkss kg imp n and nk the obtained parameters are listed in table 3 the nse is 92 3 in the calibration period 4 2 modeling of the error series schemes ii iii the error series consists of the differences between the observed and simulated streamflow the stationarity of the error series can be checked using the acf method from fig 6 a the acf of the error series is slowly decaying this suggests that the errors are nonstationary and hence differencing is required the acf plot of the differenced error series is shown in fig 6 b the acf decays exponentially and converges to zero which indicates the stationarity of differenced errors hence the differencing step should be applied to the errors note that lower orders i e orders less than or equal to 2 are widely used to reduce the heavy computational burden and complexity of optimization bennett et al 2016 lundberg 1982 sun et al 2017 wu et al 2012 we have conducted an experiment using the autoregressive integrated moving average arima model with different lags results show that the ar 2 arima 1 1 1 and other lower order arima models do not significantly decrease the akaike s information criteria aic value than the ar 1 the ar model of order 1 is therefore used to estimate the errors in scheme ii and the differenced errors in schemes iii v the nse of schemes ii and iii are 95 2 and 97 7 respectively which implies that the latter yields a better simulation than the former and that the differencing step is effective 4 3 calibration of models using the joint inference strategy scheme iv scheme iv uses eq 5 as the objective function to simultaneously refine xinanjiang and ar model parameters during the calibration period the results yield an nse of 98 1 obtained parameters are listed in table 3 4 4 calibration of models using the back fitting recalibration strategy scheme v in the back fitting recalibration approach estimated errors obtained in scheme iii are held fixed as initial values to recalibrate the xinanjiang model using eq 6 as the objective function estimated errors are then updated by keeping simulated streamflow fixed the process where the xinanjiang and ar models are recalibrated alternately is repeated 2000 times the optimal parameter set is obtained with an nse of 97 9 during the calibration period table 3 4 5 comparison of results with different calibration strategies hydrological model parameters of schemes iii iv and v table 3 are obtained as described in sections 4 1 4 3 and 4 4 respectively and are then used individually to forecast floods in the validation period summarized results are presented in tables 4 and 5 it can be observed that the performances of schemes iii iv and v are consistent in terms of nse and pi whereas they differ with respect to mare specifically scheme iv provides the highest values of nse and pi followed by scheme v in the calibration period scheme v outperforms schemes iv and iii giving the highest nse and pi values in the validation period however scheme iii performs best in terms of the lowest mare value in both the calibration and validation periods the difference is mainly due to the squared errors in the objective functions used by the developed models this indicates that the joint calibration strategy can further optimize the model parameters overall the joint inference and back fitting recalibration strategies are more sensitive to higher flows and the postprocessor calibration strategy is more sensitive to lower flows additionally the back fitting recalibration strategy is more robust than the joint inference strategy during the validation period fig 7 illustrates the csi for threshold discharges q of 20 420 m3 s the csi value decreases as q increases making higher flows more difficult to capture from fig 7 a it appears that schemes iv and v can capture higher discharges better especially scheme v in the calibration period scheme v is clearly superior for threshold discharges above 300 m3 s whereas it shows more discrepancy than scheme iii for threshold discharges below 300 m3 s similarly in the validation period scheme iii performs better than scheme v for threshold discharges of 150 250 m3 s whereas the opposite is true for threshold discharges below 150 m3 s and above 250 m3 s once again these results demonstrate that higher flows can easily be detected by the joint inference and back fitting recalibration strategies and that the postprocessor calibration strategy is more appropriate for lower flows moreover the results can be assessed based on the selected flood event fig 8 a d presents hydrographs of schemes iii iv and v from flood events in may 1994 july 1997 june 1998 and may 1999 the first two occur in the calibration period and the latter two occur in the validation period the results show that the three schemes can forecast the flood events specifically table 5 indicates that scheme v best captures the peak discharge and scheme iv gives the smallest time to peak flow in the validation period however scheme iii performs best in terms of pep and scheme v is the most accurate in terms of δt during the validation period radar maps of schemes iii iv and v using the six evaluation metrics are summarized in fig 9 scheme v best captures the peak flow in the calibration period achieving a score of 3 whereas scheme iii scores 1 for giving the highest pep in fig 9 a and b scheme iv clearly achieves the best performance during the calibration period and scheme v gives the most accurate forecasts in the validation period note that schemes iv and v are more sensitive to high flows fig 9 b and d whereas the postprocessor calibration strategy performs well for lower flows fig 9 a and c a six hour streamflow series from may 1994 is shown in fig 10 where it can be seen that the xinanjiang models noted as base in figures of schemes iii iv and v all underestimate the streamflow at 19 00 the underestimation is identified and corrected by ar updating procedures however the estimated error of scheme iii at 20 00 is notably large as a result the forecasted streamflow at 20 00 is overestimated and the compensated error estimate at 21 00 is substantially smaller this implies that the updating procedure of scheme iii leads to overcorrection in contrast schemes iv and v work well in this situation because their objective functions allow interaction between xinanjiang and ar model parameters we conclude that both joint inference and back fitting recalibration strategies can reduce the overcorrection inherent in the postprocessor calibration strategy from table 5 and fig 8c and d it can be further observed that scheme v works best during the validation period an example is presented in fig 11 here the joint inference strategy causes more overcorrection than the back fitting recalibration strategy in this case the xinanjiang model of scheme iv overestimates streamflow between 5 00 and 6 00 while the simulated streamflow of schemes iii and v are lower than observed values simulation of the xinanjiang model is therefore crucial for real time flood forecasting the xinanjiang model simulation of scheme v is superior to that of scheme iv table 4 suggesting better forecast performance using the back fitting recalibration strategy a comparison of simulated and observed streamflow is presented in fig 12 it can be seen in fig 12 a and b that scheme iv performs best in the calibration period while scheme v is superior in the validation period especially at high streamflow the xinanjiang model simulations of schemes iii iv and v are compared in fig 12 c and d it is worth noting that the xinanjiang model of scheme iii produces substantial overestimation of streamflow a slight overestimation is observed in scheme iv in this case the streamflow overestimation is compensated by the ar model which can result in overcorrection such as the unreasonably large or small estimated errors shown in figs 10 and 11 the xinanjiang model simulation of scheme v produces neither an overestimate nor an underestimate to some extent this finding demonstrates the best performance of scheme v using the back fitting recalibration strategy 5 conclusions three joint calibration strategies are examined in this study the first is the conventional approach of postprocessor calibration the second is the joint inference strategy where ar and hydrological model parameters are estimated simultaneously the third strategy is back fitting recalibration that alternately recalibrates the hydrological and ar models in order to compare the efficiency of the three joint calibration strategies five schemes are used to forecast 15 flood events in the baiyunshan reservoir basin the following conclusions can be drawn 1 joint calibration strategies can reduce overcorrection produced by the ar model and yield better forecasting than the postprocessor calibration strategy 2 the back fitting algorithm is superior to the joint inference strategy in the validation period due to a more robust simulation provided by the hydrological model furthermore the back fitting algorithm has great potential for joint calibration in cases where the forecast system has more complex models and a larger number of parameters which can be explored in future studies acknowledgements this study was supported by the national key research and development program 2016yfc0400907 the innovative research groups of the natural science foundation of hubei china 2017cfa015 and the national natural science foundation of china 51579180 the authors would like to thank the editor and anonymous reviewers for their comments that helped improve the quality of the paper 
7213,river monitoring is a critical issue for hydrological modelling that relies strongly on the use of flow rating curves frcs in most cases these functions are derived by least squares fitting which usually leads to good performance indices even when based on a limited range of data that especially lack high flow observations in this context cross section geometry is a controlling factor which is not fully exploited in classical approaches in fact river discharge is obtained as the product of two factors 1 the area of the wetted cross section and 2 the cross sectionally averaged velocity both factors can be expressed as a function of the river stage defining a viable alternative in the derivation of frcs this makes it possible to exploit information about cross section geometry limiting at least partially the uncertainty in the extrapolation of discharge at higher flow values numerical analyses and field data confirm the reliability of the proposed procedure for the derivation of frcs keywords environmental monitoring flow rating curves frcs flow velocity discharge 1 introduction and methodology flow rating curves frcs are at the core of any hydrological estimation but their calibration is generally limited by the number of discharge measurements available on a given cross section e g fulton and ostrowski 2008 di baldassarre and montanari 2009 moreover frc may vary over time in alluvial rivers whereas river bed characteristics change over time westerberg et al 2011 this implies the need for frequent time consuming and expensive field campaigns that do not always provide an adequate dataset frcs are generally obtained using curve fitting methods with river stage h and discharge q observations the most common equation used to describe the relationship between h and q is lambie 1978 mosley and mckerchar 1993 clarke 1999 1 q α h h 0 β where α β and h 0 are calibration parameters eq 1 is fitted to the n observations of hi qi neglecting the origin of these data i e the procedure used to derive q in fact this data is originally obtained from a river survey aimed at measuring the averaged flow velocity vi and the associated wetted area of the cross section ωi both features vary with river stage and can be expressed as a function of h but ω can be easily measured at higher river stage values with topographic surveys providing a critical constraint for the extrapolation of the flow rating curves at the higher values of h therefore the model or the regression function used to interpret the relationship between discharge and river stage can be decoupled into two components following the suggestions contained in a recent manuscript by manfreda et al 2018 the authors introduced a methodology that decomposes calibration procedures in different phases related to the hydrological process taken into consideration e g runoff snowmelt and baseflow the decoupling of the calibration of a hydrological model leads to a relevant increase in its reliability following this idea the rating curve can be obtained as the product of two functions 2 q v h h 0 ω h h 0 where v h h 0 and ω h h 0 are fitting functions describing the relationship between the mean flow velocity and the wetted area as a function of the river stage these functions can be fitted using available observations and cross section surveys as demonstrated below this simple idea is surprisingly efficient in improving the reliability of frcs and it has great potential for applications in data scarce environments in fact any field survey is based on measurements of wetted flow area and of the averaged flow velocity the product of these two variables is the discharge that is the variable used for calibration of the classical form of rating curves eq 1 therefore the two regression functions of the measurements v and ω can be used to derive river discharge as well but with the great advantage that the geometrical relationship ω h h 0 can be obtained also from the topographic survey of the cross section moreover the use of geometrical information about the river cross section can be exploited to gain additional information about the local hydraulic conditions which can be easily extracted for higher river stage values the use of such an alternative procedure for the derivation of flow rating curves is explored and tested using two numerical case studies and with field data collected on the basento river in southern italy in the first case the problem of identifying an appropriate fitting function is performed by extracting a random number of samples from a theoretical estimated rating curve while in the second case several permutations of a real dataset are used to derive the frcs with both the classical and vω methods 2 numerical experiment the proposed vω method was tested using the frc estimated assuming a uniform flow in a triangular and trapezoidal channel as preliminary benchmark the resistance equation adopted is the classical manning equation manning 1891 3 v 1 n r 2 3 i 1 2 where n is the manning s roughness coefficient r is the hydraulic radius and i is the bed slope for this specific case the parameter n was assumed as equal to 0 025 s m1 3 the hydraulic radius was derived from the specific geometry and the channel slope was set at 0 01 m m the two channels were assumed to have simple geometry the first as a triangular channel with an apex angle of 60 the second one trapezoidal with a base width of 2 m and sides inclined at 60 to the horizontal given the hydraulic characteristics of the problem the application of any flow resistance formula may lead to a reference frc for uniform flow see red line in fig 1 a and b that can be used as a reference gold standard supposing that these cross sections are monitored for a short period of time obtaining in total 20 discharge samples this data can be used to fit one of the two models described in the previous section more specifically the regression will consider the discharge values in one case and the flow velocity in the second case this kind of experiments can be performed several times in order to explore the performances of the two methods on different subsets of data extracted from the same series for this reason 100 random permutations were extracted from the theoretical frc derived for the two ideal case studies it must be stated that the regression function ω h comes with a high level of detail using the available information about the cross section geometry in the second case in all considered approaches the regression functions adopted for discharge velocity and wetted area are simple power laws moreover it is necessary to clarify that the permutations were extracted from the theoretical frc in the range of h between 0 and 6 while the fitted curves were plotted over a wider range of h up to 10 m in order to visually highlight the impact of extrapolation and bias at the higher flows the obtained frcs are described in fig 1a triangular and b trapezoidal depicting a buffer around the original theoretical frc solid line in red that highlights the uncertainty associated to each methodology this result may be influenced by the random sampling employed and it is likely that a stratified sampling would lead to better results of the fitting exercise but such a dataset is very unlikely in reality in fact discharge measurements are taken at random in different seasons and very rarely during high flows in most field campaigns therefore the suggested approach explores the impact of random sampling in hydraulic monitoring campaigns the graph in fig 1 clearly shows that the vω method produces frcs that are much closer to the theoretical frc used to generate the samples this is due to the fact that in the fitting exercise a portion of uncertainty is removed from the problem by adopting the known geometry of the cross section to describe the regression function of ω h a regression function on 20 samples of mean flow velocity still produces some variability but much smaller than the one observed in the classical approach nevertheless it must be acknowledged that in the case of triangular cross section the vω method provided few frcs that significantly underestimated the discharge when all sampled velocities fell in a range of very low values in order to provide a quantitative measure of the performances of the two proposed methods a box plot of the rmse root mean square error obtained in the different configurations is presented in fig 1c such plot quantifies the relative mean reduction of the errors and also the reduced variability of the performances of the proposed approach which is also a measure of its robustness finally performance measures in terms of mean and standard deviation in parenthesis of the rmse of the mape mean absolute perceptual error and of the correlation coefficient are given in table 1 here it is possible to note that all frcs are almost indistinguishable in terms of correlation coefficients which is an evidence of the fact that this metric is not a good indicator of performance especially for frcs in fact this latter index is always very high even if relevant differences are observed in terms of rmse and mape these two error indices confirm that on the average the proposed methodology provides better results and lower variability of the results 3 field data in several study cases we deal with a limited amount of data and it is mandatory to exploit the available information as much as possible therefore the proposed approach may be beneficial in data scarce environments exploiting easily accessible data regarding the cross section geometry along with the available information regarding the averaged mean flow velocity the vω method was tested on a cross section of the basento river in the basilicata region southern italy which is an area with limited hydrological information and flow measurements the station selected was torre accio which drains an area of about 1394 km2 and has a mean annual discharge of about 6 m3 s exploiting the limited information available the relationships between the averaged flow velocity and the wetted areas as a function of the hydraulic river stage have been explored results are summarized in fig 2 where the dataset is introduced along with an application of the proposed methodology and of the classical method the dataset is composed of 20 discharge measurements which include contemporary mean flow velocity and wetted area measurements and 16 additional cross section area measurements extracted from a topographic survey these latter include river stage values not explored during flow measurements fig 2a the averaged stream flow velocity data is plotted in fig 2b using full blue circles the ensemble of cross section area measurements is used to derive a unique fitting function reliable also at higher water level stages as described in the numerical example this may be extremely beneficial to reduce uncertainty of frcs on the contrary the flow velocity measurements are always limited as are the discharge observations thus the only available information that can be used to describe such relationship between v and h is represented by the field measurements which do not exceed values measured at h 6 4 m in the present case mean flow velocity observations display a clear linear trend fig 2b this is not necessarily true over the entire range of values of v but it is likely that the relationship is a power law with an exponent closer to one while the exponent of the ω function generally assumes values in the range 1 5 2 5 this is not a marginal aspect because using v for the model calibration may be beneficial for its lower non linearity compared to the function ω h therefore the possibility to describe with higher reliability the function ω h should increase the reliability of the suggested method in fig 2a the area function ω h is plotted using both values derived from flow discharge measurements and topographic surveys full red circles in particular all points above 6 4 m of water level have been derived from the topographic survey while values associated to lower river stages are associated to flow velocity measurements it can be notied that the range of h values is extended for river stage values higher than those associated with flow velocity measurements compare with fig 2b moreover it should be also underlined that some scattering even if limited is visible for the measurements of ω which may be due to the difficulties of properly measuring the position of the river bed during streamflow surveys nevertheless the fitted power law function provides an overall good description of ω h the choice of a power law function is not necessarily the best one for all cases but it was preferred for sake of simplicity and also to keep the level of complexity for the two adopted methods similar in order to explore the reliability of the two proposed methods the same approach adopted in the numerical experiments was replicated to a certain extent in this case given the limited amount of information available it was possible to generate 4845 permutations of 16 values of discharge for method 1 classical method or flow velocity measurements for method 2 vω method extracted from the dataset to explore the sensitivity of each method to the available information and also to understand each method s reliability moreover the four values excluded each time from the selected sample have been used to evaluate the performances of the methods on the data not used for calibration this is a critical test because an interpolating function is always able to properly capture the trend of measured data calibration but the real challenge is to capture the real dynamics of a river system for values not used for calibration validation overall assessment of the performances of the two methods is given in fig 2c and d here the frcs obtained from different permutations of the same dataset are displayed fig 2c showing strong differences between the two methodologies in particular the variability of the frcs obtained with the classical method for values higher than 6 m is significantly greater than that observed with the proposed methodology in the reality both methods properly interpret the calibration data with fairly good performance indices see table 2 the outcomes of the calibrations change according to the error metrics adopted for instance there are no differences in terms of correlation coefficients the classical method performs slightly better in terms of rmse and the vω method shows better results in terms of mape nevertheless the results change significantly when focusing on the validation phase in fact these statistics are all in favour of the v ω method which shows on the average better performances and also a lower variability of the performances this is also clearly described in the box plot of the rmse given in fig 2d 4 conclusion in conclusion following the original idea proposed by manfreda et al 2018 the proposed procedure breaks down the estimation of the flow rating curve using flow velocity and wetted cross section functions in fact ω can be derived directly from topographic surveys while the study of averaged flow velocities can be related to the river stage and used to derive the v ω rating curve this method represents a suitable alternative for the derivation of frcs allowing exploitation of the available information about the characteristics of river cross section geometry this critical information varies non linearly with the river stage impacting significantly on the reliability of the method used thus it is reasonable to use the available topographic surveys for its description in both the numerical analyses and the analyses based on experimental data the vω method provided a clear benefit in the derivation of the frcs in both cases the numerical experiment and the experiment based on real data the assessment was carried out exploring a wide range of possible dataset combinations providing a validation of the two procedures on data not used in the calibration phase the overall results highlighted that the proposed methodology does not necessarily improve model performances in calibration but it represents a strategy to increase reliability of frcs in data scarce environments in fact the analysis clearly shows that even with a limited dataset the vω method provided lower performance variability and errors therefore the use of additional physical information such as cross section geometry was properly adopted to reduce the structural uncertainty of the model scheme it must be stated that this approach does not overcome the problem of alluvial rivers where the river cross section may change significantly especially during floods but it represents a viable alternative in more stable rivers in such cases this simple methodology improves the physical consistency of frcs and it has great potential for application in data scarce environments acknowledgements this work was carried out within a scientific agreement between the civil protection department of basilicata the interuniversity consortium for hydrology cinid and the university of basilicata for the start up the basilicata hydrologic risk center the author also thank the two anonymous reviewers for their insightful comments on the paper 
7213,river monitoring is a critical issue for hydrological modelling that relies strongly on the use of flow rating curves frcs in most cases these functions are derived by least squares fitting which usually leads to good performance indices even when based on a limited range of data that especially lack high flow observations in this context cross section geometry is a controlling factor which is not fully exploited in classical approaches in fact river discharge is obtained as the product of two factors 1 the area of the wetted cross section and 2 the cross sectionally averaged velocity both factors can be expressed as a function of the river stage defining a viable alternative in the derivation of frcs this makes it possible to exploit information about cross section geometry limiting at least partially the uncertainty in the extrapolation of discharge at higher flow values numerical analyses and field data confirm the reliability of the proposed procedure for the derivation of frcs keywords environmental monitoring flow rating curves frcs flow velocity discharge 1 introduction and methodology flow rating curves frcs are at the core of any hydrological estimation but their calibration is generally limited by the number of discharge measurements available on a given cross section e g fulton and ostrowski 2008 di baldassarre and montanari 2009 moreover frc may vary over time in alluvial rivers whereas river bed characteristics change over time westerberg et al 2011 this implies the need for frequent time consuming and expensive field campaigns that do not always provide an adequate dataset frcs are generally obtained using curve fitting methods with river stage h and discharge q observations the most common equation used to describe the relationship between h and q is lambie 1978 mosley and mckerchar 1993 clarke 1999 1 q α h h 0 β where α β and h 0 are calibration parameters eq 1 is fitted to the n observations of hi qi neglecting the origin of these data i e the procedure used to derive q in fact this data is originally obtained from a river survey aimed at measuring the averaged flow velocity vi and the associated wetted area of the cross section ωi both features vary with river stage and can be expressed as a function of h but ω can be easily measured at higher river stage values with topographic surveys providing a critical constraint for the extrapolation of the flow rating curves at the higher values of h therefore the model or the regression function used to interpret the relationship between discharge and river stage can be decoupled into two components following the suggestions contained in a recent manuscript by manfreda et al 2018 the authors introduced a methodology that decomposes calibration procedures in different phases related to the hydrological process taken into consideration e g runoff snowmelt and baseflow the decoupling of the calibration of a hydrological model leads to a relevant increase in its reliability following this idea the rating curve can be obtained as the product of two functions 2 q v h h 0 ω h h 0 where v h h 0 and ω h h 0 are fitting functions describing the relationship between the mean flow velocity and the wetted area as a function of the river stage these functions can be fitted using available observations and cross section surveys as demonstrated below this simple idea is surprisingly efficient in improving the reliability of frcs and it has great potential for applications in data scarce environments in fact any field survey is based on measurements of wetted flow area and of the averaged flow velocity the product of these two variables is the discharge that is the variable used for calibration of the classical form of rating curves eq 1 therefore the two regression functions of the measurements v and ω can be used to derive river discharge as well but with the great advantage that the geometrical relationship ω h h 0 can be obtained also from the topographic survey of the cross section moreover the use of geometrical information about the river cross section can be exploited to gain additional information about the local hydraulic conditions which can be easily extracted for higher river stage values the use of such an alternative procedure for the derivation of flow rating curves is explored and tested using two numerical case studies and with field data collected on the basento river in southern italy in the first case the problem of identifying an appropriate fitting function is performed by extracting a random number of samples from a theoretical estimated rating curve while in the second case several permutations of a real dataset are used to derive the frcs with both the classical and vω methods 2 numerical experiment the proposed vω method was tested using the frc estimated assuming a uniform flow in a triangular and trapezoidal channel as preliminary benchmark the resistance equation adopted is the classical manning equation manning 1891 3 v 1 n r 2 3 i 1 2 where n is the manning s roughness coefficient r is the hydraulic radius and i is the bed slope for this specific case the parameter n was assumed as equal to 0 025 s m1 3 the hydraulic radius was derived from the specific geometry and the channel slope was set at 0 01 m m the two channels were assumed to have simple geometry the first as a triangular channel with an apex angle of 60 the second one trapezoidal with a base width of 2 m and sides inclined at 60 to the horizontal given the hydraulic characteristics of the problem the application of any flow resistance formula may lead to a reference frc for uniform flow see red line in fig 1 a and b that can be used as a reference gold standard supposing that these cross sections are monitored for a short period of time obtaining in total 20 discharge samples this data can be used to fit one of the two models described in the previous section more specifically the regression will consider the discharge values in one case and the flow velocity in the second case this kind of experiments can be performed several times in order to explore the performances of the two methods on different subsets of data extracted from the same series for this reason 100 random permutations were extracted from the theoretical frc derived for the two ideal case studies it must be stated that the regression function ω h comes with a high level of detail using the available information about the cross section geometry in the second case in all considered approaches the regression functions adopted for discharge velocity and wetted area are simple power laws moreover it is necessary to clarify that the permutations were extracted from the theoretical frc in the range of h between 0 and 6 while the fitted curves were plotted over a wider range of h up to 10 m in order to visually highlight the impact of extrapolation and bias at the higher flows the obtained frcs are described in fig 1a triangular and b trapezoidal depicting a buffer around the original theoretical frc solid line in red that highlights the uncertainty associated to each methodology this result may be influenced by the random sampling employed and it is likely that a stratified sampling would lead to better results of the fitting exercise but such a dataset is very unlikely in reality in fact discharge measurements are taken at random in different seasons and very rarely during high flows in most field campaigns therefore the suggested approach explores the impact of random sampling in hydraulic monitoring campaigns the graph in fig 1 clearly shows that the vω method produces frcs that are much closer to the theoretical frc used to generate the samples this is due to the fact that in the fitting exercise a portion of uncertainty is removed from the problem by adopting the known geometry of the cross section to describe the regression function of ω h a regression function on 20 samples of mean flow velocity still produces some variability but much smaller than the one observed in the classical approach nevertheless it must be acknowledged that in the case of triangular cross section the vω method provided few frcs that significantly underestimated the discharge when all sampled velocities fell in a range of very low values in order to provide a quantitative measure of the performances of the two proposed methods a box plot of the rmse root mean square error obtained in the different configurations is presented in fig 1c such plot quantifies the relative mean reduction of the errors and also the reduced variability of the performances of the proposed approach which is also a measure of its robustness finally performance measures in terms of mean and standard deviation in parenthesis of the rmse of the mape mean absolute perceptual error and of the correlation coefficient are given in table 1 here it is possible to note that all frcs are almost indistinguishable in terms of correlation coefficients which is an evidence of the fact that this metric is not a good indicator of performance especially for frcs in fact this latter index is always very high even if relevant differences are observed in terms of rmse and mape these two error indices confirm that on the average the proposed methodology provides better results and lower variability of the results 3 field data in several study cases we deal with a limited amount of data and it is mandatory to exploit the available information as much as possible therefore the proposed approach may be beneficial in data scarce environments exploiting easily accessible data regarding the cross section geometry along with the available information regarding the averaged mean flow velocity the vω method was tested on a cross section of the basento river in the basilicata region southern italy which is an area with limited hydrological information and flow measurements the station selected was torre accio which drains an area of about 1394 km2 and has a mean annual discharge of about 6 m3 s exploiting the limited information available the relationships between the averaged flow velocity and the wetted areas as a function of the hydraulic river stage have been explored results are summarized in fig 2 where the dataset is introduced along with an application of the proposed methodology and of the classical method the dataset is composed of 20 discharge measurements which include contemporary mean flow velocity and wetted area measurements and 16 additional cross section area measurements extracted from a topographic survey these latter include river stage values not explored during flow measurements fig 2a the averaged stream flow velocity data is plotted in fig 2b using full blue circles the ensemble of cross section area measurements is used to derive a unique fitting function reliable also at higher water level stages as described in the numerical example this may be extremely beneficial to reduce uncertainty of frcs on the contrary the flow velocity measurements are always limited as are the discharge observations thus the only available information that can be used to describe such relationship between v and h is represented by the field measurements which do not exceed values measured at h 6 4 m in the present case mean flow velocity observations display a clear linear trend fig 2b this is not necessarily true over the entire range of values of v but it is likely that the relationship is a power law with an exponent closer to one while the exponent of the ω function generally assumes values in the range 1 5 2 5 this is not a marginal aspect because using v for the model calibration may be beneficial for its lower non linearity compared to the function ω h therefore the possibility to describe with higher reliability the function ω h should increase the reliability of the suggested method in fig 2a the area function ω h is plotted using both values derived from flow discharge measurements and topographic surveys full red circles in particular all points above 6 4 m of water level have been derived from the topographic survey while values associated to lower river stages are associated to flow velocity measurements it can be notied that the range of h values is extended for river stage values higher than those associated with flow velocity measurements compare with fig 2b moreover it should be also underlined that some scattering even if limited is visible for the measurements of ω which may be due to the difficulties of properly measuring the position of the river bed during streamflow surveys nevertheless the fitted power law function provides an overall good description of ω h the choice of a power law function is not necessarily the best one for all cases but it was preferred for sake of simplicity and also to keep the level of complexity for the two adopted methods similar in order to explore the reliability of the two proposed methods the same approach adopted in the numerical experiments was replicated to a certain extent in this case given the limited amount of information available it was possible to generate 4845 permutations of 16 values of discharge for method 1 classical method or flow velocity measurements for method 2 vω method extracted from the dataset to explore the sensitivity of each method to the available information and also to understand each method s reliability moreover the four values excluded each time from the selected sample have been used to evaluate the performances of the methods on the data not used for calibration this is a critical test because an interpolating function is always able to properly capture the trend of measured data calibration but the real challenge is to capture the real dynamics of a river system for values not used for calibration validation overall assessment of the performances of the two methods is given in fig 2c and d here the frcs obtained from different permutations of the same dataset are displayed fig 2c showing strong differences between the two methodologies in particular the variability of the frcs obtained with the classical method for values higher than 6 m is significantly greater than that observed with the proposed methodology in the reality both methods properly interpret the calibration data with fairly good performance indices see table 2 the outcomes of the calibrations change according to the error metrics adopted for instance there are no differences in terms of correlation coefficients the classical method performs slightly better in terms of rmse and the vω method shows better results in terms of mape nevertheless the results change significantly when focusing on the validation phase in fact these statistics are all in favour of the v ω method which shows on the average better performances and also a lower variability of the performances this is also clearly described in the box plot of the rmse given in fig 2d 4 conclusion in conclusion following the original idea proposed by manfreda et al 2018 the proposed procedure breaks down the estimation of the flow rating curve using flow velocity and wetted cross section functions in fact ω can be derived directly from topographic surveys while the study of averaged flow velocities can be related to the river stage and used to derive the v ω rating curve this method represents a suitable alternative for the derivation of frcs allowing exploitation of the available information about the characteristics of river cross section geometry this critical information varies non linearly with the river stage impacting significantly on the reliability of the method used thus it is reasonable to use the available topographic surveys for its description in both the numerical analyses and the analyses based on experimental data the vω method provided a clear benefit in the derivation of the frcs in both cases the numerical experiment and the experiment based on real data the assessment was carried out exploring a wide range of possible dataset combinations providing a validation of the two procedures on data not used in the calibration phase the overall results highlighted that the proposed methodology does not necessarily improve model performances in calibration but it represents a strategy to increase reliability of frcs in data scarce environments in fact the analysis clearly shows that even with a limited dataset the vω method provided lower performance variability and errors therefore the use of additional physical information such as cross section geometry was properly adopted to reduce the structural uncertainty of the model scheme it must be stated that this approach does not overcome the problem of alluvial rivers where the river cross section may change significantly especially during floods but it represents a viable alternative in more stable rivers in such cases this simple methodology improves the physical consistency of frcs and it has great potential for application in data scarce environments acknowledgements this work was carried out within a scientific agreement between the civil protection department of basilicata the interuniversity consortium for hydrology cinid and the university of basilicata for the start up the basilicata hydrologic risk center the author also thank the two anonymous reviewers for their insightful comments on the paper 
7214,evaporation plays a major role in lake systems as it affects the water energy and solutes budgets water salinity reduces evaporation and as a result affects the energy budget of the lake including stored heat in this study we explore the seasonal and diurnal variations of evaporation and other energy fluxes over the dead sea the deepest and saltiest hypersaline lake on earth we present two consecutive years observations using eddy covariance system meteorological stations and a buoy station measuring the water column properties these observations reveal the effects of synoptic and mesoscale atmospheric circulation on lake evaporation the seasonal cycle of evaporation is characterized by two peaks the summer evaporation peak is related to high radiation inputs the winter peak stem from the high heat storage of the deep lake with evaporation driven by high vapor pressure demand combined with synoptic scale wind systems and thermal instability in summer the synoptic circulation is stable providing a weak background wind velocity persian trough hence the dominant diurnal wind pattern is induced by the mediterranean sea breeze mesoscale circulation the two years of eddy covariance measurements in the hypersaline dead sea located in a hyperarid region revealed annual evaporation rate of 1 13 0 13 m yr 1 we explored several evaporation models versus the directly measured evaporation and found that the most reliable is a mass transfer model that was calibrated here for the dead sea keywords eddy covariance net radiation wind speed vapor pressure difference water activity thermal stability 1 introduction 1 1 evaporation from saline lakes evaporation is the connecting link between the water salt and energy budgets of lakes water molecules consume energy to change phase from liquid to vapor while leaving the dissolved ions in the remaining water brutsaert 1982 assouline 1993 lensky et al 2005 evaporation is driven by the vapor pressure difference δe between the water surface es and the overlying air ea brutsaert 1982 dalton 1802 δe is a function of water surface and air temperatures and relative humidity ts ta rh and in saline water it is also a function of water activity β 1 δ e β e sat t s rh e sat t a where esat is the saturation vapor pressure eq 2 esat is multiplied by β and rh to obtain vapor pressure of brine surface and overlying air es and ea respectively as water salinity rises the water activity decreases salhotra et al 1985 from eq 1 it appears that under given conditions the evaporation rate from saline water will be lower compared to that from fresh water following the reduction of δe mor et al 2018 in addition to the driving force given by eq 1 evaporation is controlled by wind speed and thermal stability of the overlying boundary layer i e the vapor transport agents which affect the resistance in the process the depth of the water body has a great influence on evaporation since the heat stored in the water column dictates the surface water temperature and hereby affects δe and thermal stability a deep lake will have a slower response to varying atmospheric conditions than a shallow pond due to its higher thermal inertia which provides heat flux for evaporation over longer times in the diurnal and seasonal cycles thus evaporation from deep lakes is expected to be influenced by both the properties and dynamics of the water body including the water thermal stratification and the surface water salinity and by the properties and dynamics of the overlying atmospheric boundary layer the dead sea is the saltiest deep lake on earth providing a rare opportunity to explore diurnal and seasonal evaporation and surface heat fluxes from a deep hypersaline lake located in a hyper arid region and the lake s response to the forcing of the atmospheric conditions 1 2 evaporation from the dead sea the dead sea fig 1 is a hypersaline salinity 277 g kg 1 terminal lake located at the lowest subaerial surface on earth 431 m amsl at observation period with the highest surface water density 1 24 gr cm 3 arnon et al 2016 hect and gertman 2003 sirota et al 2016 among earths deep lakes depth 290 m and surface area of 630 km2 sade et al 2014 it is a holomictic lake vertically mixed during winter and stratified during the warm summer anati 1997 arnon et al 2016 hect and gertman 2003 nehorai et al 2009 r nehorai et al 2013a 2013b sirota et al 2016 during the past decades the dead sea is experiencing a dramatic level decline 1 m yr 1 due to the diversion of water resources from this terminal lake mainly from the jordan river drainage basin lensky and dente 2017 as a result the salinity increased until reaching the saturation of halite and since then steinhorn 1983 steinhorn and assaf 1980 halite is continuously deposited in the lake floor at a rate of 0 1 m yr 1 lensky et al 2005 stiller et al 1997 the persian trough is the dominant synoptic scale atmospheric circulation pattern prevailing during the summer mid may to mid september over the eastern mediterranean including the dead sea region it is an extension of a low pressure system over the persian gulf reaching the eastern mediterranean region lensky and dayan 2015 the persian trough provides weak synoptic scale forcing favorable for mesoscale flows like the mediterranean sea breeze generated by the daytime differential surface heating between land and sea lensky and dayan 2012 levy et al 2010 in all other seasons the synoptic scale circulation is dominant varying on scale of few days proper characterization of evaporation and other energy fluxes over the dead sea across various time scales are very important for understanding the dynamics of hypersaline deep water bodies including the water and heat budgets and the salt deposit spatio temporal dynamics sirota et al 2016 sirota et al 2017 evaporation estimations from water bodies can be made by direct or indirect methods the eddy covariance technique is a direct method that under certain limitations considered to be the most accurate and reliable technique for evaporation measurements itier and brunet 1996 however it requires expensive instruments and highly demanding data analysis the indirect methods for evaporation estimation are more commonly used and include mass water and salt balance energy budgets and mass transfer models brutsaert 2005 however these could be associated with relatively large uncertainties assouline 1993 the water balance approach should be quite straightforward to estimate evaporation in the dead sea since it is a terminal lake meaning that knowing the changes in the volume of the lake and the inflows evaporation can be calculated as the residual flux however whereas the lake level and bathymetry are measured with minor uncertainties 1 on an annual basis the inflows discharge pumping of the potash industries and the discharged end brine are not well monitored leading to uncertain evaporation estimates following the approach applied in lake kinneret assouline 1993 lensky et al 2005 proposed a water energy and salt budgets scheme for the dead sea to reduce the large uncertainties associated with the balance approach in estimating evaporation the estimates of mean annual evaporation from the dead sea based on these indirect approaches range from 1 m yr 1 stanhill 1994 to 2 m yr 1 salameh and el naser 1999 direct evaporation measurements can be used for comparison with evaporation models as was done in freshwater surfaces assouline and mahrer 1993 stannard and rosenberry 1991 tanny et al 2008 2011 direct measurements of evaporation and sensible heat flux were conducted by means of eddy covariance over lakes reservoirs and seas with variable salinity from freshwater up to the salinity of ocean water allen and tasumi 2005 assouline et al 2008 liu et al 2012 2009 mackellar and mcgowan 2010 mcgowan and sturman 2010 recently eddy covariance evaporation measurements were conducted in the dead sea lensky et al 2018 showed that during summer evaporation is characterized by a diurnal double peak one peak related to radiative heat supply and the second related to high wind speed during nighttime mor et al 2018 examined the effect of water surface salinity on the evaporation by simultaneous measurements over a diluted low salinity plume and over the highly saline brine of the open lake metzger et al 2018 compared eddy covariance evaporation measurements with modeling during one year due to lack of actual measurements of the water surface and column temperatures and radiation from the water surface they utilized several assumptions these enabled indirect calculations of water surface temperature vapor pressure difference and energy budget components which were later used for the evaporation models the above review shows that as yet whole year seasonal and diurnal patterns of evaporation and heat fluxes in the dead sea still call for a systematic study with direct measurements we hypothesize that the synoptic and mesoscale atmospheric circulations will affect evaporation in different manners hence the objectives of this study are i characterize the seasonal and diurnal variations of evaporation and heat fluxes over the dead sea and their forcing hydro meteorological variables during a whole year by means of direct measurements over two consecutive years ii investigate the applicability of various evaporation models for the deep hypersaline dead sea 2 methods 2 1 sites and sensors measurements were conducted from onshore and offshore stations at the dead sea fig 1 as described below measurements were made during 2 years from march 2015 to april 2017 with some gap periods as depicted below 2 1 1 onshore station the onshore station hereafter denoted as mishmar coastal station ms was located at the waterline 1 20 m onshore on the tip of an elongated peninsula at the west coast of the lake 239863 588405 itm fig 1b the station was equipped with an eddy covariance system measuring evaporation rate e and sensible heat flux h the sensors were mounted 4 33 m above the water surface on an aluminum tower anchored to the shore salt bed fig 1c the eddy covariance system consisted of a three dimensional sonic anemometer windmaster pro gill instruments ltd uk and an open path carbon dioxide water vapor co2 h2o infrared gas analyzer irga model li 7500rs li cor inc usa the 20 hz raw data were processed and corrected to obtain half hourly eddy fluxes using the eddypro software by li cor most data processing was done on site using the smart flux system by li cor with embedded eddypro software eddy fluxes were measured from 29 mar 2015 until 3 apr 2017 gaps in data collection caused by instrument failure and repair are 17 mainly during the intervals 26 oct 2015 30 dec 2015 and 04 apr 2016 31 may 2016 from the available data 72 is considered valid flux measurements the 28 of invalid measurements are due to i 17 8 wind directions from land between azimuth of 180 300 degrees clockwise and ii 10 2 data flagged by eddypro as low quality due to unsteady conditions only valid data were used in the following analyses other meteorological variables measurements at the station were conducted with an air temperature ta and relative humidity rh probe model ee181 campbell scientific inc usa and a two dimensional sonic anemometer windsonic gill instruments inc uk which measured every 5 s and recorded the 10 min averages of mean wind speed and direction meteorological variables were recorded on a data logger model cr1000 campbell scientific inc usa the latter instruments are identical to those on the offshore station as described below and enable comparing the data from both stations 2 1 2 offshore station a meteorological buoy eg100 fig 1b 1d located about 5 km northeast of the onshore station 241500 593059 itm measured air temperature air humidity and wind speed and direction using similar sensor types and recording intervals as the onshore station in addition the buoy measured radiation fluxes at a height of 2 m above water surface for calculating net radiation rn cnr4 kipp zonen b v the netherlands water surface temperature ts using an infrared radiometer si 4h1 apogee instruments inc at 3 m above water surface and water temperature profile of the upper 40 m using a thermistor chain 12 19 thermistors data averaged every 20 min we found that the offshore station well represented the onshore station as was indicated by the close relation between u ta and rh at the two stations lensky et al 2018 2 2 data analysis the vapor pressure difference δe eq 1 is calculated using measured dead sea water activity β 0 65 mor et al 2018 measured water surface and air temperatures and relative humidity the magnus tetens formula is used for the saturation vapor pressure 2 e sat t 6 105 exp 17 27 t t 237 7 where t is temperature in c and esat is in mbar barenburg 1974 the half hourly flux data obtained by the eddypro software was further processed for different purposes i a mean diurnal course was calculated as half hourly average of 7 days ii the seasonal variation of the diurnal course was characterized similarly but along their variations within the seasonal course iii the seasonal variation of the daily average evaporation and other fluxes was calculated as the sum of the 48 half hours a day and was further smoothed using a 7 day window moving average every error bar presented in this work represents the standard deviation normalized by n 1 where n is the number of data entries being averaged for the estimation of the heat storage change g we divided the lake water body into horizontal layers assuming uniform temperature in each layer the measured temperature using the 19 thermistors along the 40 m was interpolated to 40 layers one meter thick the total heat storage of the lake qt is the sum of the layers heat storage where the heat storage of the i th layer qi was calculated by 3 q i ρ ds cp ds t i a i z i where dead sea water density is ρds 1244 kg m 3 arnon et al 2016 sirota et al 2016 heat capacity of the dead sea brine cpds 3030 j kg 1k 1 steinhorn 1981 ti is the water temperature of the layer in k ai is the area of the layer normalized by the water surface area and zi is the layer s thickness the monthly heat storage change g dq t dt was calculated according to the best fit linear slope of the total heat storage for the diurnal course of g we used a moving mean of four hours and the maximal depth for integration was chosen as 15 m in order to reduce the impact of internal waves on the calculations of g arnon et al 2014 for more details see lensky et al 2018 3 results 3 1 measurements 3 1 1 general presentation of measured data figs 2 and 3 below present in two different manners the whole two years measured and analyzed data set including meteorological and limnological measurements evaporation and heat fluxes later figs 4 and 5 present diurnal courses of selected variables during typical seasons seasonal and diurnal variations of the governing meteorological conditions evaporation and energy fluxes are shown in fig 2 based on half hourly averaged data in fig 2 horizontally correlated regions horizontal continuous stripes are evidence for a diurnal course that is repeatedly maintained by atmospheric meso scale flows along the summer season whereas vertically correlated regions vertical stripes indicate events lasting longer than a day representing synoptic scale events see introduction fig 3 presents monthly means daytime and nighttime values of the sensible and latent heat fluxes meteorological variables ts ta u δe and monthly means of net radiation and heat storage change fig 3 is a more intuitive and conventional plot however fig 2 provides the entire dataset so these figures are complementary fig 3 provides another perspective to determine the dominance of the diurnal separation of day and night and seasonal cycles in this study nighttime is defined as the period where the incoming solar radiation s 0 is negligible 0 5 w m 2 monthly averaged values of the measured meteorological variables are shown in tables 1 and 2 appendix 3 1 2 climatic and meteorological conditions seasonal and diurnal variations the net radiation is characterized by seasonal and diurnal cycles fig 2a the seasonal course has a typical sinuous shape fig 3f with monthly averages ranging from 20 w m 2 in december to 220 w m 2 in june the diurnal cycle is characterized by positive values during daytime with maximum values at midday and nighttime negative values the seasonal and diurnal patterns of wind speed u are presented in fig 2e and fig 3b during summer the diurnal cycle dominates with high winds at night and low wind speed during the day this diurnal pattern is attributed to the mediterranean sea breeze a mesoscale circulation system induced by the daytime differential surface heating between land and mediterranean sea the sea breeze front reaches the dead sea at sunset and blows during night as dry and warm northerly wind alpert et al 1997 gertman and hecht 2002 lensky and dayan 2012 lensky et al 2018 during winter synoptic scale circulation patterns alternate typically every few days with periods of strong winds 6 m s 1 that last over a day vertical stripes in fig 2e therefore the wind diurnal cycle during winter is not dominant fig 3b the seasonal variation of the monthly mean wind speed is apparent only through the diurnal cycle prominent in the summer disappearing in the winter fig 3b air temperature is characterized by a seasonal cycle with an amplitude larger δ t 16 c than the diurnal cycle δ t 5 c fig 2b winter daily maximum is in the afternoon and summer daily maximum is at sunset the monthly averaged t a table 1 varied with a typical seasonal sinuous pattern these observations are consistent with the long term four decadal measurements from the buoy eg100 gertman and hecht 2002 and the database of i gertman it is notable that the second winter was colder than the first note color index in fig 2b both seasonal and diurnal courses of air temperature show a lagged response to rn due to the thermal inertia of the air while the diurnal cycle is also subject to the effect of the retarded arrival of mediterranean sea breeze see hereafter water surface temperature fig 2c exhibited diurnal and seasonal cycles similar to air temperature behavior the diurnal and seasonal variations of ts are moderated compared to ta additionally ts lags ta in the seasonal scale month these effects are attributed to the high thermal inertia of the lake water 3 1 3 water heat storage change the water heat storage change g eq 3 fig 2i is characterized by seasonal and diurnal cycles with high heat flux values 1000 w m 2 similar to r n the seasonal cycle of g is in phase with r n fig 3f however it remains positive for two months after r n has reached its maximum in june indicating that the lake is still heating even though r n is already diminishing also observed in t s the diurnal course of g along the warm season is characterized by positive values during the daytime and negative values at nighttime indicating that the lake is storing energy during the day and dissipating it during the night the amplitude of the diurnal cycle varies seasonally similarly to r n i e the red strip narrows toward the winter in fig 2i in winter the lake is vertically homogeneous and the dominance of the diurnal pattern of g is reduced blue domains in fig 2i 3 1 4 vapor pressure difference the vapor pressure difference δ e seasonal and diurnal patterns are presented in fig 2d and fig 3a a diurnal cycle is dominant in summer with a triple peak in the morning afternoon and evening with higher values during daytime in winter and in the transition seasons the diurnal cycle is not evident since different synoptic conditions dominate the seasonal cycle presents a summer peak and a winter peak overall the vapor pressure difference in this hyper arid environment remained positive along the entire observation period 3 1 5 vapor transport agents the major vapor transport agents are the wind represented here by wind speed section 3 1 and the thermal stability of the air overlying the water surface the temperature difference between the water surface and the air is an indicator of the thermal stability of the air above the water surface assouline and mahrer 1993 positive values red color in fig 2f are related to unstable conditions that enhance mixing and turbulence of the air above the water while negative values blue color represent stable conditions which diminish these effects these processes are significant in transporting vapor from the water surface and enhancing or depressing evaporation assouline and mahrer 1993 during winter t s t a is positive red regions in fig 2f along the diurnal cycle hence during winter a destabilizing vertical temperature gradient is generated between the water surface and the cool air which may enhance evaporation rate it is notable that t s t a was greater during the second and cooler winter of measurements dec 2016 jan feb 2017 due to lower air temperature in the warm season t s t a is mostly negative blue domains with more negative values during nighttime than daytime fig 3c during summer evenings warm air increases thermal stability which may explain the low evening evaporation in spite of the peak in δe see discussion 3 1 6 evaporation to analyze seasonal and diurnal cycles of evaporation in addition to fig 2g and fig 3d we plotted in figs 4 and 5 data from three seasonal regimes summer jun sep winter dec feb and transition seasons mar may oct nov in summer a diurnal cycle dominates with a clear double peak an evaporation peak at night and a second peak in the afternoon horizontal stripes in fig 2g fig 4a this phenomenon that was analyzed in detail by lensky et al 2018 based on one week of observations and is validated here based on data from the entire summer season during winter when the synoptic scale atmospheric circulation patterns are much more dominant than the mesoscale flow there is no evident repeated diurnal cycle vertical stripes in fig 2g fig 4c consequently due to the different synoptic events the winter diurnal patterns are different in the two consecutive years unlike the summer diurnal patterns that are reproduced each year in the transitional seasons a gradual change in the diurnal patterns from winter to summer prevails with a small evaporation peak in the morning and a daily maximum at night fig 4d during autumn oct nov as the daytime differential surface heating between land and sea weakens the mediterranean sea breeze weakens lensky and dayan 2012 as well as the night evaporation peak fig 4c due to the nature of synoptic influence in winter and transition seasons it is notable that the diurnal cycles of e ts ta δe u have a weaker variation as is indicated in fig 4b c d the diurnal amplitude is within their standard deviation error fig 5 presents averaged monthly diurnal courses of the net radiation and heat storage change and the latent and sensible heat fluxes in the seasonal time scale evaporation is high in summer with a clear peak in the summer months which is evident in both years with average maximum e in july of 0 174 mm hr 1 during winter evaporation is variable since it is subject to synoptic events it can have either high values i e january 2017 0 144 mm hr 1 leading to evaporation winter peak in addition to summer peak or have low values i e january 2016 0 065 mm hr 1 during the transition seasons evaporation was low these monthly means accumulate to a two year mean annual evaporation rate of 1 13 m yr 1 0 13 mm hr 1 3 1 7 sensible heat flux the sensible heat flux h is the lowest among the major fluxes fig 3e and fig 5 h is characterized by a diurnal cycle with daytime positive values peaking at afternoon and nighttime negative values fig 2h excluding the winter of 2016 17 which was dominated by positive values throughout the diurnal cycle fig 2h the magnitude of the daily peak in h changes seasonally fig 5 it is relatively low in summer i e 30 w m 2 in july 2015 fig 5a but larger in winter during winter h peak reached the magnitude of le peak i e about 50 w m 2 in january 2016 fig 5c in december 2016 h increased and was positive through most of the day with highest monthly mean fig 2h fig 3e with these changes between the two years no typical seasonal cycle could be identified note that the sensible heat is not well correlated to ts ta as would be expected from flux gradient law we do not have a proper explanation for that yet we can hypothesize that this observation is related to the phenomenon of counter gradient flux deardorff 1966 i e a flux which is in opposite direction to the mean gradient of its driving force this phenomenon may occur when transport is dominated by moving air parcels not by the local scalar gradient but this calls for a more systematic study on sensible heat which is beyond the scope of this paper 3 2 evaporation models for hypersaline water surface the estimates by different evaporation models are compared to evaporation rates measured by means of the eddy covariance system eec in order to evaluate their applicability to deep hypersaline waterbodies the models are 1 a mass transfer model mt model harbeck 1958 4 e mt n u δ e where e mt is the evaporation rate mm hr 1 n is the mass transfer coefficient u ms 1 is the wind speed and δ e mbar is the vapor pressure difference eq 1 this model inherently accounts for water salinity through δe eq 1 and requires the calibration of the coefficient n 2 a modified penman model for hypersaline water surfaces with a lowered water activity developed by calder and neal 1984 cn model this model takes into account the available energy rn g while the vapor pressure deficit vpd is corrected for the reduced activity of the saline water β 5 e cn δ r n g γ 3 6 2 5 u e sat t a rh β e sat t a l δ γ β here ecn is the evaporation rate in mm hr 1 δ mbar c 1 is the rate of increase of saturation pressure with temperature rn and g w m 2 are the net radiation and water heat storage change respectively γ is the psychrometric constant mbar c 1 t a is air temperature c and esat mbar is saturation vapor pressure eq 2 3 an aerodynamic model ad includes a transport coefficient ce based on the logarithmic wind profile and the friction velocity derived from high frequency data brutsaert 2005 tanny et al 2008 6 e ad 0 622 ρ w p c e ρ a u 3 6 10 6 δ e c e k 2 ln z 2 z 0 v ln z 1 z 0 m here ρw and ρa denote water and air density kg m 3 u is wind speed m s 1 p is air pressure mbar z 1 and z 2 are the heights m of wind speed and vapor density measurements respectively and z 0 m u 2 81 g m is the momentum roughness length where u ms 1 is the measured friction velocity g is the gravitation acceleration m s 2 k 0 41 is the von karman constant and z 0 v 7 4z 0 m exp 2 25 u ν 1 4 brutsaert 1982 eq 5 28 and p 124 where ν m2 s 1 is air kinematic viscosity here too the impact of water salinity is expressed through δe eq 1 fig 6 present the monthly average evaporation rates measured and calculated along the two years observation period the mt model was calibrated by calculating the mass transfer coefficient n that best fits the monthly averaged measured evaporation eec with the monthly averages of measured u δ e the best fit for the entire data set is n 0 0039 0 0001 with r2 0 97 we also split the dataset to a first year of calibration and second for validation and vice versa which yielded very similar results n 0 0040 r2 0 97 and n 0 0038 r2 0 98 respectively fig 7 presents regression of daily averages for the whole period of calculated evaporation based on the three models emt ecn ead versus the measured evaporation eec including quantifiable correlation indexes the calibrated mass transfer model emt n 0 0039 matches best the observations slope 1 05 however it overestimates in cases of low measured evaporation rates partly in unstable thermal stability conditions the aerodynamic model ead underestimates measured data by about thirty percent slope 0 69 ead closely fits eec at low values the ad model uses friction velocity derived from high frequency wind speed measurements the need of measuring the friction velocity is a disadvantage for a practical evaporation formula since common meteorological stations does not include sonic anemometers that are required for such measurements the modified penman model ecn overestimated the daily evaporation by 150 besides it is less suitable due to the inclusion of g the stored heat flux in the lake whose measurement is prone to large errors and is not available from routine measurements to summarize the mass transfer mt model with n 0 0039 best matches the observations besides it is a simple formulation based on common meteorological data and therefore an excellent candidate for management of water resources 4 discussion 4 1 available energy for evaporation the dead sea is a deep lake and thus has a large heat capacity the heat stored in the lake water is used for evaporation and sensible heat flux net radiation is the primary energy source for heating the water body r n daily averages are positive along the year whereas the heat storage change alternates seasonally from positive to negative values the water body gained heat from march until july and lost heat from august to february approximately fig 3f in addition our results showed that evaporation rates in the two consecutive winters could vary in magnitude 0 065 mm hr 1 in january 2016 and 0 144 mm hr 1 in january 2017 these observations suggest that the dead sea operates as a source of stored energy available for evaporation and sensible heat flux even in times of low net radiation hence all year long including nighttime and winter winter evaporation rate may vary annually depending on surface weather events associated with the varying synoptic scale atmospheric circulation patterns while in summer the evaporation rate is annually uniform as the persian trough is steady along the summer giving place to the mesoscale flows as the mediterranean sea breeze 4 2 evaporation peaks environmental controls and timing the vapor pressure difference in the dead sea is constantly positive and hence without any transport resistance evaporation is expected to follow δe pattern at any time scale however transport resistance plays a major role on evaporation diurnal evaporation patterns vary seasonally in summer jun sep the synoptic circulation is stable providing weak background wind velocity persian trough thus the diurnal mediterranean sea breeze mesoscale circulation is the dominant wind pattern evaporation is temporally correlated by the vapor pressure difference and the transport mechanism of the vapor i e wind speed resulting in a double peaked pattern the first e maximum results from the high noontime net radiation and is associated with the daily peak of δe in the afternoon while the second e maximum is attributed to the nightly high wind speed as shown in fig 4a and for two summers in fig 2 the evening evaporation is suppressed by thermally stable conditions in spite of δe peak in winter dec feb as sunlight duration shortens and its intensity weakens the diurnal cycles weaken and are undetected with respect to the dominant synoptic scale circulation continuous positive δ e and thermal instability fig 2f fig 3c fig 4c along with events of high wind speed associated with synoptic scale atmospheric circulation induce evaporation regardless of the time of day resulting in small difference between nighttime and daytime fig 3d these synoptic events may last several days with high wind speed and high evaporation rate vertical columns in fig 2e fig 2g and change the winter average monthly mean of evaporation table 1 since summer evaporation was nearly the same in the two years of measurements winter changes in evaporation are accountable for the change in total evaporation between the years transitional seasons are also subject to synoptic scale events in spring mar may while the nighttime boundary layer is thermally unstable fig 2d there is an increase in the night peak and gradual transition from winter patterns to summer like diurnal course in autumn oct nov there was only a morning peak temporally correlated with a daily maximum in wind speed hence during the transition seasons the evaporation is dependent on wind speed as the daily cycles of e follow those of u and the evaporation peaks are aligned with wind speed peaks fig 4b fig 4d 4 3 wind controls the diurnal evaporation course limited by thermal stability in the diurnal time scale there is a good temporal correlation between the evaporation rate and wind speed fig 2 fig 4 in summer as the strong winds are at night nighttime evaporation is higher than daytime e g 0 181 mm h 1 vs 0 150 mm h 1 in august 2015 and is thus a large contributor to annual water loss from the dead sea in the summer evenings the vapor pressure difference and wind speed are high yet evaporation is at its lowest at this time of day the mediterranean sea breeze brings warm air so the thermally stable boundary layer fig 4a fig 2d inhibits evaporation similar effect was documented by assouline and mahrer 1993 later the sea breeze cools down thermal stability decreases and evaporation rate increases the superposition of wind speed and vapor pressure difference might result in high evaporation rates but the thermal stability plays a significant role thermal stability can reduce evaporation like in summer evenings or enhance evaporation like in the winter when the boundary layer is constantly thermally unstable based on these observations it seems that wind regime and boundary layer properties dominate the diurnal evaporation cycle in the dead sea 4 4 measured and modeled evaporation relations with forcing variables diurnal courses of measured and modeled evaporation rates are presented in fig 8 in order to relate them to the governing processes we present the monthly averaged diurnal course of july 2015 characterized by double diurnal evaporation peak as presented by lensky et al 2018 for one week and in the present paper it is expanded to the entire season to illustrate the relation between the governing meteorological factors and the resulted evaporation we present in fig 8 also the temperature difference between water and overlying air vapor pressure difference wind speed net radiation and stored water heat flux at the diurnal time scale all three models could not reliably reproduce the diurnal course of measured evaporation here again emt n 0 0039 seems to provide the best simulation of the measured evaporation eec however in the evening emt predicts an evaporation peak instead of the actual night peak since it does not take into account the thermal stability see the negative vertical temperature difference in the top panel which inhibits evening evaporation the modified penman model ecn over estimates evaporation with a very large peak at 3am which is related to the large rn g fig 8 this overestimate appears to be caused mainly by the very large and negative g fig 8 note that g has very large error bars illustrating the difficulty in a reliable estimation of this term in a deep hypersaline lake like the dead sea hence it suggests that penman type models which include the energy storage term are less reliable for evaporation estimates in such large deep and hypersaline water bodies the aerodynamic model ead generally underestimates evaporation and follows the daily course pattern except for overestimating evaporation in evening instead of during nighttime similar to the emt although ead is based on measured friction velocity through the roughness length term in ce which represents the turbulence of the flow it does not take into account explicitly the atmospheric stability induced by the negative temperature difference since ce assumes neutral stability therefore it overestimates evaporation during evening 4 5 vapor pressure difference controls the seasonal evaporation cycle on the seasonal time scale patterns of vapor pressure difference are temporally correlated to those of measured evaporation and evaporation models estimations fig 3a d fig 6 respectively this correlation is also valid for the calculated evaporation using the mass transfer model the vapor pressure difference dominates the seasonal variations in evaporation with possible inter annual differences between winters that are attributed to the magnitude of synoptic events 5 conclusions evaporation from the dead sea was measured directly with an eddy covariance system during a two year period along with corresponding energy fluxes and meteorological variables data is analyzed on diurnal and seasonal timescales the following main conclusions can be drawn from this study 1 the dead sea stores heat during the day providing energy for evaporation at night in summer and stores heat during summer providing heat for evaporation in winter 2 the annual rate of evaporation from the dead sea is 1 13 m yr 1 with a significant contribution of nighttime evaporation in summer and during winter 3 evaporation in the dead sea is governed by vapor pressure difference in the seasonal time scale and wind speed in the diurnal time scale 4 thermal stability of the overlying boundary layer is also a significant factor on evaporation stable conditions can depress the evaporation rate despite high wind and vapor pressure difference 5 after being calibrated and validated against measured data the mass transfer model gives a good estimation for monthly evaporation rate and can be applied for the dead sea brine using emt n u δe n 0 0039 0 0001 acknowledgments we thank the two anonymous reviewers associate editor di long and the editor in chief marco borga for insightful comments that significantly improved the manuscript we thank the geological survey of israel team for the intensive field and lab assistance raanan bodzin hallel lutzky uri malik alon peretz ali arnon ido sirota haggai eyal and yohai magen tal ozer and boris katsenelson from israel limnology and oceanographic research for field assistance and maintenance of the meteorological buoy denis kuchuk from meteo tech for technical support with the eddy covariance system taglit r v team silvy gonen shahar gan el and meir yifrach for operating the r v in the harsh conditions of the dead sea for install and maintenance of the stations the research was funded by the israeli government under gsi ds project 40572 n g l is involved in the palex project paleohydrology and extreme floods from the dead sea icdp core funded by the dfg grant no br2208 13 1 2 appendix a table of monthly averaged meteorological variables and components of the surface energy budget appendix b table of monthly averaged daytime and nighttime values of meteorological variables and components of the surface energy budget 
7214,evaporation plays a major role in lake systems as it affects the water energy and solutes budgets water salinity reduces evaporation and as a result affects the energy budget of the lake including stored heat in this study we explore the seasonal and diurnal variations of evaporation and other energy fluxes over the dead sea the deepest and saltiest hypersaline lake on earth we present two consecutive years observations using eddy covariance system meteorological stations and a buoy station measuring the water column properties these observations reveal the effects of synoptic and mesoscale atmospheric circulation on lake evaporation the seasonal cycle of evaporation is characterized by two peaks the summer evaporation peak is related to high radiation inputs the winter peak stem from the high heat storage of the deep lake with evaporation driven by high vapor pressure demand combined with synoptic scale wind systems and thermal instability in summer the synoptic circulation is stable providing a weak background wind velocity persian trough hence the dominant diurnal wind pattern is induced by the mediterranean sea breeze mesoscale circulation the two years of eddy covariance measurements in the hypersaline dead sea located in a hyperarid region revealed annual evaporation rate of 1 13 0 13 m yr 1 we explored several evaporation models versus the directly measured evaporation and found that the most reliable is a mass transfer model that was calibrated here for the dead sea keywords eddy covariance net radiation wind speed vapor pressure difference water activity thermal stability 1 introduction 1 1 evaporation from saline lakes evaporation is the connecting link between the water salt and energy budgets of lakes water molecules consume energy to change phase from liquid to vapor while leaving the dissolved ions in the remaining water brutsaert 1982 assouline 1993 lensky et al 2005 evaporation is driven by the vapor pressure difference δe between the water surface es and the overlying air ea brutsaert 1982 dalton 1802 δe is a function of water surface and air temperatures and relative humidity ts ta rh and in saline water it is also a function of water activity β 1 δ e β e sat t s rh e sat t a where esat is the saturation vapor pressure eq 2 esat is multiplied by β and rh to obtain vapor pressure of brine surface and overlying air es and ea respectively as water salinity rises the water activity decreases salhotra et al 1985 from eq 1 it appears that under given conditions the evaporation rate from saline water will be lower compared to that from fresh water following the reduction of δe mor et al 2018 in addition to the driving force given by eq 1 evaporation is controlled by wind speed and thermal stability of the overlying boundary layer i e the vapor transport agents which affect the resistance in the process the depth of the water body has a great influence on evaporation since the heat stored in the water column dictates the surface water temperature and hereby affects δe and thermal stability a deep lake will have a slower response to varying atmospheric conditions than a shallow pond due to its higher thermal inertia which provides heat flux for evaporation over longer times in the diurnal and seasonal cycles thus evaporation from deep lakes is expected to be influenced by both the properties and dynamics of the water body including the water thermal stratification and the surface water salinity and by the properties and dynamics of the overlying atmospheric boundary layer the dead sea is the saltiest deep lake on earth providing a rare opportunity to explore diurnal and seasonal evaporation and surface heat fluxes from a deep hypersaline lake located in a hyper arid region and the lake s response to the forcing of the atmospheric conditions 1 2 evaporation from the dead sea the dead sea fig 1 is a hypersaline salinity 277 g kg 1 terminal lake located at the lowest subaerial surface on earth 431 m amsl at observation period with the highest surface water density 1 24 gr cm 3 arnon et al 2016 hect and gertman 2003 sirota et al 2016 among earths deep lakes depth 290 m and surface area of 630 km2 sade et al 2014 it is a holomictic lake vertically mixed during winter and stratified during the warm summer anati 1997 arnon et al 2016 hect and gertman 2003 nehorai et al 2009 r nehorai et al 2013a 2013b sirota et al 2016 during the past decades the dead sea is experiencing a dramatic level decline 1 m yr 1 due to the diversion of water resources from this terminal lake mainly from the jordan river drainage basin lensky and dente 2017 as a result the salinity increased until reaching the saturation of halite and since then steinhorn 1983 steinhorn and assaf 1980 halite is continuously deposited in the lake floor at a rate of 0 1 m yr 1 lensky et al 2005 stiller et al 1997 the persian trough is the dominant synoptic scale atmospheric circulation pattern prevailing during the summer mid may to mid september over the eastern mediterranean including the dead sea region it is an extension of a low pressure system over the persian gulf reaching the eastern mediterranean region lensky and dayan 2015 the persian trough provides weak synoptic scale forcing favorable for mesoscale flows like the mediterranean sea breeze generated by the daytime differential surface heating between land and sea lensky and dayan 2012 levy et al 2010 in all other seasons the synoptic scale circulation is dominant varying on scale of few days proper characterization of evaporation and other energy fluxes over the dead sea across various time scales are very important for understanding the dynamics of hypersaline deep water bodies including the water and heat budgets and the salt deposit spatio temporal dynamics sirota et al 2016 sirota et al 2017 evaporation estimations from water bodies can be made by direct or indirect methods the eddy covariance technique is a direct method that under certain limitations considered to be the most accurate and reliable technique for evaporation measurements itier and brunet 1996 however it requires expensive instruments and highly demanding data analysis the indirect methods for evaporation estimation are more commonly used and include mass water and salt balance energy budgets and mass transfer models brutsaert 2005 however these could be associated with relatively large uncertainties assouline 1993 the water balance approach should be quite straightforward to estimate evaporation in the dead sea since it is a terminal lake meaning that knowing the changes in the volume of the lake and the inflows evaporation can be calculated as the residual flux however whereas the lake level and bathymetry are measured with minor uncertainties 1 on an annual basis the inflows discharge pumping of the potash industries and the discharged end brine are not well monitored leading to uncertain evaporation estimates following the approach applied in lake kinneret assouline 1993 lensky et al 2005 proposed a water energy and salt budgets scheme for the dead sea to reduce the large uncertainties associated with the balance approach in estimating evaporation the estimates of mean annual evaporation from the dead sea based on these indirect approaches range from 1 m yr 1 stanhill 1994 to 2 m yr 1 salameh and el naser 1999 direct evaporation measurements can be used for comparison with evaporation models as was done in freshwater surfaces assouline and mahrer 1993 stannard and rosenberry 1991 tanny et al 2008 2011 direct measurements of evaporation and sensible heat flux were conducted by means of eddy covariance over lakes reservoirs and seas with variable salinity from freshwater up to the salinity of ocean water allen and tasumi 2005 assouline et al 2008 liu et al 2012 2009 mackellar and mcgowan 2010 mcgowan and sturman 2010 recently eddy covariance evaporation measurements were conducted in the dead sea lensky et al 2018 showed that during summer evaporation is characterized by a diurnal double peak one peak related to radiative heat supply and the second related to high wind speed during nighttime mor et al 2018 examined the effect of water surface salinity on the evaporation by simultaneous measurements over a diluted low salinity plume and over the highly saline brine of the open lake metzger et al 2018 compared eddy covariance evaporation measurements with modeling during one year due to lack of actual measurements of the water surface and column temperatures and radiation from the water surface they utilized several assumptions these enabled indirect calculations of water surface temperature vapor pressure difference and energy budget components which were later used for the evaporation models the above review shows that as yet whole year seasonal and diurnal patterns of evaporation and heat fluxes in the dead sea still call for a systematic study with direct measurements we hypothesize that the synoptic and mesoscale atmospheric circulations will affect evaporation in different manners hence the objectives of this study are i characterize the seasonal and diurnal variations of evaporation and heat fluxes over the dead sea and their forcing hydro meteorological variables during a whole year by means of direct measurements over two consecutive years ii investigate the applicability of various evaporation models for the deep hypersaline dead sea 2 methods 2 1 sites and sensors measurements were conducted from onshore and offshore stations at the dead sea fig 1 as described below measurements were made during 2 years from march 2015 to april 2017 with some gap periods as depicted below 2 1 1 onshore station the onshore station hereafter denoted as mishmar coastal station ms was located at the waterline 1 20 m onshore on the tip of an elongated peninsula at the west coast of the lake 239863 588405 itm fig 1b the station was equipped with an eddy covariance system measuring evaporation rate e and sensible heat flux h the sensors were mounted 4 33 m above the water surface on an aluminum tower anchored to the shore salt bed fig 1c the eddy covariance system consisted of a three dimensional sonic anemometer windmaster pro gill instruments ltd uk and an open path carbon dioxide water vapor co2 h2o infrared gas analyzer irga model li 7500rs li cor inc usa the 20 hz raw data were processed and corrected to obtain half hourly eddy fluxes using the eddypro software by li cor most data processing was done on site using the smart flux system by li cor with embedded eddypro software eddy fluxes were measured from 29 mar 2015 until 3 apr 2017 gaps in data collection caused by instrument failure and repair are 17 mainly during the intervals 26 oct 2015 30 dec 2015 and 04 apr 2016 31 may 2016 from the available data 72 is considered valid flux measurements the 28 of invalid measurements are due to i 17 8 wind directions from land between azimuth of 180 300 degrees clockwise and ii 10 2 data flagged by eddypro as low quality due to unsteady conditions only valid data were used in the following analyses other meteorological variables measurements at the station were conducted with an air temperature ta and relative humidity rh probe model ee181 campbell scientific inc usa and a two dimensional sonic anemometer windsonic gill instruments inc uk which measured every 5 s and recorded the 10 min averages of mean wind speed and direction meteorological variables were recorded on a data logger model cr1000 campbell scientific inc usa the latter instruments are identical to those on the offshore station as described below and enable comparing the data from both stations 2 1 2 offshore station a meteorological buoy eg100 fig 1b 1d located about 5 km northeast of the onshore station 241500 593059 itm measured air temperature air humidity and wind speed and direction using similar sensor types and recording intervals as the onshore station in addition the buoy measured radiation fluxes at a height of 2 m above water surface for calculating net radiation rn cnr4 kipp zonen b v the netherlands water surface temperature ts using an infrared radiometer si 4h1 apogee instruments inc at 3 m above water surface and water temperature profile of the upper 40 m using a thermistor chain 12 19 thermistors data averaged every 20 min we found that the offshore station well represented the onshore station as was indicated by the close relation between u ta and rh at the two stations lensky et al 2018 2 2 data analysis the vapor pressure difference δe eq 1 is calculated using measured dead sea water activity β 0 65 mor et al 2018 measured water surface and air temperatures and relative humidity the magnus tetens formula is used for the saturation vapor pressure 2 e sat t 6 105 exp 17 27 t t 237 7 where t is temperature in c and esat is in mbar barenburg 1974 the half hourly flux data obtained by the eddypro software was further processed for different purposes i a mean diurnal course was calculated as half hourly average of 7 days ii the seasonal variation of the diurnal course was characterized similarly but along their variations within the seasonal course iii the seasonal variation of the daily average evaporation and other fluxes was calculated as the sum of the 48 half hours a day and was further smoothed using a 7 day window moving average every error bar presented in this work represents the standard deviation normalized by n 1 where n is the number of data entries being averaged for the estimation of the heat storage change g we divided the lake water body into horizontal layers assuming uniform temperature in each layer the measured temperature using the 19 thermistors along the 40 m was interpolated to 40 layers one meter thick the total heat storage of the lake qt is the sum of the layers heat storage where the heat storage of the i th layer qi was calculated by 3 q i ρ ds cp ds t i a i z i where dead sea water density is ρds 1244 kg m 3 arnon et al 2016 sirota et al 2016 heat capacity of the dead sea brine cpds 3030 j kg 1k 1 steinhorn 1981 ti is the water temperature of the layer in k ai is the area of the layer normalized by the water surface area and zi is the layer s thickness the monthly heat storage change g dq t dt was calculated according to the best fit linear slope of the total heat storage for the diurnal course of g we used a moving mean of four hours and the maximal depth for integration was chosen as 15 m in order to reduce the impact of internal waves on the calculations of g arnon et al 2014 for more details see lensky et al 2018 3 results 3 1 measurements 3 1 1 general presentation of measured data figs 2 and 3 below present in two different manners the whole two years measured and analyzed data set including meteorological and limnological measurements evaporation and heat fluxes later figs 4 and 5 present diurnal courses of selected variables during typical seasons seasonal and diurnal variations of the governing meteorological conditions evaporation and energy fluxes are shown in fig 2 based on half hourly averaged data in fig 2 horizontally correlated regions horizontal continuous stripes are evidence for a diurnal course that is repeatedly maintained by atmospheric meso scale flows along the summer season whereas vertically correlated regions vertical stripes indicate events lasting longer than a day representing synoptic scale events see introduction fig 3 presents monthly means daytime and nighttime values of the sensible and latent heat fluxes meteorological variables ts ta u δe and monthly means of net radiation and heat storage change fig 3 is a more intuitive and conventional plot however fig 2 provides the entire dataset so these figures are complementary fig 3 provides another perspective to determine the dominance of the diurnal separation of day and night and seasonal cycles in this study nighttime is defined as the period where the incoming solar radiation s 0 is negligible 0 5 w m 2 monthly averaged values of the measured meteorological variables are shown in tables 1 and 2 appendix 3 1 2 climatic and meteorological conditions seasonal and diurnal variations the net radiation is characterized by seasonal and diurnal cycles fig 2a the seasonal course has a typical sinuous shape fig 3f with monthly averages ranging from 20 w m 2 in december to 220 w m 2 in june the diurnal cycle is characterized by positive values during daytime with maximum values at midday and nighttime negative values the seasonal and diurnal patterns of wind speed u are presented in fig 2e and fig 3b during summer the diurnal cycle dominates with high winds at night and low wind speed during the day this diurnal pattern is attributed to the mediterranean sea breeze a mesoscale circulation system induced by the daytime differential surface heating between land and mediterranean sea the sea breeze front reaches the dead sea at sunset and blows during night as dry and warm northerly wind alpert et al 1997 gertman and hecht 2002 lensky and dayan 2012 lensky et al 2018 during winter synoptic scale circulation patterns alternate typically every few days with periods of strong winds 6 m s 1 that last over a day vertical stripes in fig 2e therefore the wind diurnal cycle during winter is not dominant fig 3b the seasonal variation of the monthly mean wind speed is apparent only through the diurnal cycle prominent in the summer disappearing in the winter fig 3b air temperature is characterized by a seasonal cycle with an amplitude larger δ t 16 c than the diurnal cycle δ t 5 c fig 2b winter daily maximum is in the afternoon and summer daily maximum is at sunset the monthly averaged t a table 1 varied with a typical seasonal sinuous pattern these observations are consistent with the long term four decadal measurements from the buoy eg100 gertman and hecht 2002 and the database of i gertman it is notable that the second winter was colder than the first note color index in fig 2b both seasonal and diurnal courses of air temperature show a lagged response to rn due to the thermal inertia of the air while the diurnal cycle is also subject to the effect of the retarded arrival of mediterranean sea breeze see hereafter water surface temperature fig 2c exhibited diurnal and seasonal cycles similar to air temperature behavior the diurnal and seasonal variations of ts are moderated compared to ta additionally ts lags ta in the seasonal scale month these effects are attributed to the high thermal inertia of the lake water 3 1 3 water heat storage change the water heat storage change g eq 3 fig 2i is characterized by seasonal and diurnal cycles with high heat flux values 1000 w m 2 similar to r n the seasonal cycle of g is in phase with r n fig 3f however it remains positive for two months after r n has reached its maximum in june indicating that the lake is still heating even though r n is already diminishing also observed in t s the diurnal course of g along the warm season is characterized by positive values during the daytime and negative values at nighttime indicating that the lake is storing energy during the day and dissipating it during the night the amplitude of the diurnal cycle varies seasonally similarly to r n i e the red strip narrows toward the winter in fig 2i in winter the lake is vertically homogeneous and the dominance of the diurnal pattern of g is reduced blue domains in fig 2i 3 1 4 vapor pressure difference the vapor pressure difference δ e seasonal and diurnal patterns are presented in fig 2d and fig 3a a diurnal cycle is dominant in summer with a triple peak in the morning afternoon and evening with higher values during daytime in winter and in the transition seasons the diurnal cycle is not evident since different synoptic conditions dominate the seasonal cycle presents a summer peak and a winter peak overall the vapor pressure difference in this hyper arid environment remained positive along the entire observation period 3 1 5 vapor transport agents the major vapor transport agents are the wind represented here by wind speed section 3 1 and the thermal stability of the air overlying the water surface the temperature difference between the water surface and the air is an indicator of the thermal stability of the air above the water surface assouline and mahrer 1993 positive values red color in fig 2f are related to unstable conditions that enhance mixing and turbulence of the air above the water while negative values blue color represent stable conditions which diminish these effects these processes are significant in transporting vapor from the water surface and enhancing or depressing evaporation assouline and mahrer 1993 during winter t s t a is positive red regions in fig 2f along the diurnal cycle hence during winter a destabilizing vertical temperature gradient is generated between the water surface and the cool air which may enhance evaporation rate it is notable that t s t a was greater during the second and cooler winter of measurements dec 2016 jan feb 2017 due to lower air temperature in the warm season t s t a is mostly negative blue domains with more negative values during nighttime than daytime fig 3c during summer evenings warm air increases thermal stability which may explain the low evening evaporation in spite of the peak in δe see discussion 3 1 6 evaporation to analyze seasonal and diurnal cycles of evaporation in addition to fig 2g and fig 3d we plotted in figs 4 and 5 data from three seasonal regimes summer jun sep winter dec feb and transition seasons mar may oct nov in summer a diurnal cycle dominates with a clear double peak an evaporation peak at night and a second peak in the afternoon horizontal stripes in fig 2g fig 4a this phenomenon that was analyzed in detail by lensky et al 2018 based on one week of observations and is validated here based on data from the entire summer season during winter when the synoptic scale atmospheric circulation patterns are much more dominant than the mesoscale flow there is no evident repeated diurnal cycle vertical stripes in fig 2g fig 4c consequently due to the different synoptic events the winter diurnal patterns are different in the two consecutive years unlike the summer diurnal patterns that are reproduced each year in the transitional seasons a gradual change in the diurnal patterns from winter to summer prevails with a small evaporation peak in the morning and a daily maximum at night fig 4d during autumn oct nov as the daytime differential surface heating between land and sea weakens the mediterranean sea breeze weakens lensky and dayan 2012 as well as the night evaporation peak fig 4c due to the nature of synoptic influence in winter and transition seasons it is notable that the diurnal cycles of e ts ta δe u have a weaker variation as is indicated in fig 4b c d the diurnal amplitude is within their standard deviation error fig 5 presents averaged monthly diurnal courses of the net radiation and heat storage change and the latent and sensible heat fluxes in the seasonal time scale evaporation is high in summer with a clear peak in the summer months which is evident in both years with average maximum e in july of 0 174 mm hr 1 during winter evaporation is variable since it is subject to synoptic events it can have either high values i e january 2017 0 144 mm hr 1 leading to evaporation winter peak in addition to summer peak or have low values i e january 2016 0 065 mm hr 1 during the transition seasons evaporation was low these monthly means accumulate to a two year mean annual evaporation rate of 1 13 m yr 1 0 13 mm hr 1 3 1 7 sensible heat flux the sensible heat flux h is the lowest among the major fluxes fig 3e and fig 5 h is characterized by a diurnal cycle with daytime positive values peaking at afternoon and nighttime negative values fig 2h excluding the winter of 2016 17 which was dominated by positive values throughout the diurnal cycle fig 2h the magnitude of the daily peak in h changes seasonally fig 5 it is relatively low in summer i e 30 w m 2 in july 2015 fig 5a but larger in winter during winter h peak reached the magnitude of le peak i e about 50 w m 2 in january 2016 fig 5c in december 2016 h increased and was positive through most of the day with highest monthly mean fig 2h fig 3e with these changes between the two years no typical seasonal cycle could be identified note that the sensible heat is not well correlated to ts ta as would be expected from flux gradient law we do not have a proper explanation for that yet we can hypothesize that this observation is related to the phenomenon of counter gradient flux deardorff 1966 i e a flux which is in opposite direction to the mean gradient of its driving force this phenomenon may occur when transport is dominated by moving air parcels not by the local scalar gradient but this calls for a more systematic study on sensible heat which is beyond the scope of this paper 3 2 evaporation models for hypersaline water surface the estimates by different evaporation models are compared to evaporation rates measured by means of the eddy covariance system eec in order to evaluate their applicability to deep hypersaline waterbodies the models are 1 a mass transfer model mt model harbeck 1958 4 e mt n u δ e where e mt is the evaporation rate mm hr 1 n is the mass transfer coefficient u ms 1 is the wind speed and δ e mbar is the vapor pressure difference eq 1 this model inherently accounts for water salinity through δe eq 1 and requires the calibration of the coefficient n 2 a modified penman model for hypersaline water surfaces with a lowered water activity developed by calder and neal 1984 cn model this model takes into account the available energy rn g while the vapor pressure deficit vpd is corrected for the reduced activity of the saline water β 5 e cn δ r n g γ 3 6 2 5 u e sat t a rh β e sat t a l δ γ β here ecn is the evaporation rate in mm hr 1 δ mbar c 1 is the rate of increase of saturation pressure with temperature rn and g w m 2 are the net radiation and water heat storage change respectively γ is the psychrometric constant mbar c 1 t a is air temperature c and esat mbar is saturation vapor pressure eq 2 3 an aerodynamic model ad includes a transport coefficient ce based on the logarithmic wind profile and the friction velocity derived from high frequency data brutsaert 2005 tanny et al 2008 6 e ad 0 622 ρ w p c e ρ a u 3 6 10 6 δ e c e k 2 ln z 2 z 0 v ln z 1 z 0 m here ρw and ρa denote water and air density kg m 3 u is wind speed m s 1 p is air pressure mbar z 1 and z 2 are the heights m of wind speed and vapor density measurements respectively and z 0 m u 2 81 g m is the momentum roughness length where u ms 1 is the measured friction velocity g is the gravitation acceleration m s 2 k 0 41 is the von karman constant and z 0 v 7 4z 0 m exp 2 25 u ν 1 4 brutsaert 1982 eq 5 28 and p 124 where ν m2 s 1 is air kinematic viscosity here too the impact of water salinity is expressed through δe eq 1 fig 6 present the monthly average evaporation rates measured and calculated along the two years observation period the mt model was calibrated by calculating the mass transfer coefficient n that best fits the monthly averaged measured evaporation eec with the monthly averages of measured u δ e the best fit for the entire data set is n 0 0039 0 0001 with r2 0 97 we also split the dataset to a first year of calibration and second for validation and vice versa which yielded very similar results n 0 0040 r2 0 97 and n 0 0038 r2 0 98 respectively fig 7 presents regression of daily averages for the whole period of calculated evaporation based on the three models emt ecn ead versus the measured evaporation eec including quantifiable correlation indexes the calibrated mass transfer model emt n 0 0039 matches best the observations slope 1 05 however it overestimates in cases of low measured evaporation rates partly in unstable thermal stability conditions the aerodynamic model ead underestimates measured data by about thirty percent slope 0 69 ead closely fits eec at low values the ad model uses friction velocity derived from high frequency wind speed measurements the need of measuring the friction velocity is a disadvantage for a practical evaporation formula since common meteorological stations does not include sonic anemometers that are required for such measurements the modified penman model ecn overestimated the daily evaporation by 150 besides it is less suitable due to the inclusion of g the stored heat flux in the lake whose measurement is prone to large errors and is not available from routine measurements to summarize the mass transfer mt model with n 0 0039 best matches the observations besides it is a simple formulation based on common meteorological data and therefore an excellent candidate for management of water resources 4 discussion 4 1 available energy for evaporation the dead sea is a deep lake and thus has a large heat capacity the heat stored in the lake water is used for evaporation and sensible heat flux net radiation is the primary energy source for heating the water body r n daily averages are positive along the year whereas the heat storage change alternates seasonally from positive to negative values the water body gained heat from march until july and lost heat from august to february approximately fig 3f in addition our results showed that evaporation rates in the two consecutive winters could vary in magnitude 0 065 mm hr 1 in january 2016 and 0 144 mm hr 1 in january 2017 these observations suggest that the dead sea operates as a source of stored energy available for evaporation and sensible heat flux even in times of low net radiation hence all year long including nighttime and winter winter evaporation rate may vary annually depending on surface weather events associated with the varying synoptic scale atmospheric circulation patterns while in summer the evaporation rate is annually uniform as the persian trough is steady along the summer giving place to the mesoscale flows as the mediterranean sea breeze 4 2 evaporation peaks environmental controls and timing the vapor pressure difference in the dead sea is constantly positive and hence without any transport resistance evaporation is expected to follow δe pattern at any time scale however transport resistance plays a major role on evaporation diurnal evaporation patterns vary seasonally in summer jun sep the synoptic circulation is stable providing weak background wind velocity persian trough thus the diurnal mediterranean sea breeze mesoscale circulation is the dominant wind pattern evaporation is temporally correlated by the vapor pressure difference and the transport mechanism of the vapor i e wind speed resulting in a double peaked pattern the first e maximum results from the high noontime net radiation and is associated with the daily peak of δe in the afternoon while the second e maximum is attributed to the nightly high wind speed as shown in fig 4a and for two summers in fig 2 the evening evaporation is suppressed by thermally stable conditions in spite of δe peak in winter dec feb as sunlight duration shortens and its intensity weakens the diurnal cycles weaken and are undetected with respect to the dominant synoptic scale circulation continuous positive δ e and thermal instability fig 2f fig 3c fig 4c along with events of high wind speed associated with synoptic scale atmospheric circulation induce evaporation regardless of the time of day resulting in small difference between nighttime and daytime fig 3d these synoptic events may last several days with high wind speed and high evaporation rate vertical columns in fig 2e fig 2g and change the winter average monthly mean of evaporation table 1 since summer evaporation was nearly the same in the two years of measurements winter changes in evaporation are accountable for the change in total evaporation between the years transitional seasons are also subject to synoptic scale events in spring mar may while the nighttime boundary layer is thermally unstable fig 2d there is an increase in the night peak and gradual transition from winter patterns to summer like diurnal course in autumn oct nov there was only a morning peak temporally correlated with a daily maximum in wind speed hence during the transition seasons the evaporation is dependent on wind speed as the daily cycles of e follow those of u and the evaporation peaks are aligned with wind speed peaks fig 4b fig 4d 4 3 wind controls the diurnal evaporation course limited by thermal stability in the diurnal time scale there is a good temporal correlation between the evaporation rate and wind speed fig 2 fig 4 in summer as the strong winds are at night nighttime evaporation is higher than daytime e g 0 181 mm h 1 vs 0 150 mm h 1 in august 2015 and is thus a large contributor to annual water loss from the dead sea in the summer evenings the vapor pressure difference and wind speed are high yet evaporation is at its lowest at this time of day the mediterranean sea breeze brings warm air so the thermally stable boundary layer fig 4a fig 2d inhibits evaporation similar effect was documented by assouline and mahrer 1993 later the sea breeze cools down thermal stability decreases and evaporation rate increases the superposition of wind speed and vapor pressure difference might result in high evaporation rates but the thermal stability plays a significant role thermal stability can reduce evaporation like in summer evenings or enhance evaporation like in the winter when the boundary layer is constantly thermally unstable based on these observations it seems that wind regime and boundary layer properties dominate the diurnal evaporation cycle in the dead sea 4 4 measured and modeled evaporation relations with forcing variables diurnal courses of measured and modeled evaporation rates are presented in fig 8 in order to relate them to the governing processes we present the monthly averaged diurnal course of july 2015 characterized by double diurnal evaporation peak as presented by lensky et al 2018 for one week and in the present paper it is expanded to the entire season to illustrate the relation between the governing meteorological factors and the resulted evaporation we present in fig 8 also the temperature difference between water and overlying air vapor pressure difference wind speed net radiation and stored water heat flux at the diurnal time scale all three models could not reliably reproduce the diurnal course of measured evaporation here again emt n 0 0039 seems to provide the best simulation of the measured evaporation eec however in the evening emt predicts an evaporation peak instead of the actual night peak since it does not take into account the thermal stability see the negative vertical temperature difference in the top panel which inhibits evening evaporation the modified penman model ecn over estimates evaporation with a very large peak at 3am which is related to the large rn g fig 8 this overestimate appears to be caused mainly by the very large and negative g fig 8 note that g has very large error bars illustrating the difficulty in a reliable estimation of this term in a deep hypersaline lake like the dead sea hence it suggests that penman type models which include the energy storage term are less reliable for evaporation estimates in such large deep and hypersaline water bodies the aerodynamic model ead generally underestimates evaporation and follows the daily course pattern except for overestimating evaporation in evening instead of during nighttime similar to the emt although ead is based on measured friction velocity through the roughness length term in ce which represents the turbulence of the flow it does not take into account explicitly the atmospheric stability induced by the negative temperature difference since ce assumes neutral stability therefore it overestimates evaporation during evening 4 5 vapor pressure difference controls the seasonal evaporation cycle on the seasonal time scale patterns of vapor pressure difference are temporally correlated to those of measured evaporation and evaporation models estimations fig 3a d fig 6 respectively this correlation is also valid for the calculated evaporation using the mass transfer model the vapor pressure difference dominates the seasonal variations in evaporation with possible inter annual differences between winters that are attributed to the magnitude of synoptic events 5 conclusions evaporation from the dead sea was measured directly with an eddy covariance system during a two year period along with corresponding energy fluxes and meteorological variables data is analyzed on diurnal and seasonal timescales the following main conclusions can be drawn from this study 1 the dead sea stores heat during the day providing energy for evaporation at night in summer and stores heat during summer providing heat for evaporation in winter 2 the annual rate of evaporation from the dead sea is 1 13 m yr 1 with a significant contribution of nighttime evaporation in summer and during winter 3 evaporation in the dead sea is governed by vapor pressure difference in the seasonal time scale and wind speed in the diurnal time scale 4 thermal stability of the overlying boundary layer is also a significant factor on evaporation stable conditions can depress the evaporation rate despite high wind and vapor pressure difference 5 after being calibrated and validated against measured data the mass transfer model gives a good estimation for monthly evaporation rate and can be applied for the dead sea brine using emt n u δe n 0 0039 0 0001 acknowledgments we thank the two anonymous reviewers associate editor di long and the editor in chief marco borga for insightful comments that significantly improved the manuscript we thank the geological survey of israel team for the intensive field and lab assistance raanan bodzin hallel lutzky uri malik alon peretz ali arnon ido sirota haggai eyal and yohai magen tal ozer and boris katsenelson from israel limnology and oceanographic research for field assistance and maintenance of the meteorological buoy denis kuchuk from meteo tech for technical support with the eddy covariance system taglit r v team silvy gonen shahar gan el and meir yifrach for operating the r v in the harsh conditions of the dead sea for install and maintenance of the stations the research was funded by the israeli government under gsi ds project 40572 n g l is involved in the palex project paleohydrology and extreme floods from the dead sea icdp core funded by the dfg grant no br2208 13 1 2 appendix a table of monthly averaged meteorological variables and components of the surface energy budget appendix b table of monthly averaged daytime and nighttime values of meteorological variables and components of the surface energy budget 
