index,text
18305,levels of fecal indicator bacteria fib provide a surrogate measure of the microbial quality of water used for a wide range of applications despite the common use of these measures a significant limitation is a delay in results due to the time required for cultivation and enumeration of fib testing requires at least 18 24 h and therefore fib cannot be used to identify current or real time microbial water quality an approach of nowcasting or empirical modelling approaches that incorporate water quality environmental and weather variables to predict fib levels in real time has been developed with some success however fib levels are dependent on a complex interaction of numerous variables which can be challenging to model with ordinary linear regression or classification methods most commonly applied in this study novel use of bayesian belief networks bbns that allow for a probabilistic representation of complex variable interactions is investigated for real time modelling of fib levels surface waters in particular the integration of both water quality measures and current historical weather for prediction of fecal coliforms and escherichia coli levels is achieved using bbns for 4 bin classification of fecal coliform levels bbns increased prediction accuracy by 25 54 compared to other previously used techniques including logistic regression naïve bayes and random forests binary prediction of e coli levels exceeding a threshold of 20 cfu 100 ml was also significantly improved using bbns with prediction accuracies 90 for all monitoring sites advantages of the bbn approach are also demonstrated identifying the ability to make predictions from incomplete monitoring data as well as probabilistic inference of variable importance in fib levels in particular the results indicate that water quality surrogates such as conductivity are essential to real time prediction of fib the results and models described in this work can be readily utilized to provide accurate and real time assessments of fib levels in surface waters utilizing commonly monitored parameters 1 introduction fecal indicator bacteria fib such as fecal or thermotolerant coliforms fc or escherichia coli e coli are the most commonly monitored parameters for assessment of the microbial quality of water used for recreation drinking and other uses allen et al 2015 payment and locas 2011 thoe et al 2014 there is a broad association of fib levels and waterborne pathogens however there are several known limitations to this relationship avila et al 2018 edberg et al 2000 in particular fib are often poorly associated with non bacterial pathogens including protozoa and viruses and fibs do not provide consistent relationships with specific pathogens bradshaw et al 2016 poma et al 2012 although an indirect approach of utilizing indicator organisms is not ideal direct measurement of pathogens in natural waters is challenging due to the low expected concentrations non uniform distributions and transient occurrence field and samadpour 2007 there is still recognized value in using fibs for microbial risk assessments and surveillance of drinking water source waters petterson et al 2016 world health organization 2014 often fibs are the only available information on source water quality since techniques for monitoring waterborne pathogens are generally expensive and time consuming making an indicator approach necessary for protecting public health edberg et al 2000 despite the widespread use of fib measurements testing requires 18 24 h for cultivation and consequently results are only known a significant time after a potential exposure avila et al 2018 as such there is interest in empirical models that can predict microbial quality based on real time data sources and inform water management in a timely manner ashbolt et al 2010 mohammed et al 2018 however it should be considered that the microbial community is under the influence of a wide variety of factors bradshaw et al 2016 therefore models require the inclusion of both direct and indirect parameters to accurately model microbial water quality previous fib modelling approaches primarily applied in the context of bathing water standards have recognized the importance of weather and hydrological variables for predicting fib weather events such as rainfall and time of the year will significantly impact transport and growth conditions of the indicator organism chu et al 2014 eregno et al 2018 francy 2009 mcphail and stidson 2009 shahid iqbal et al 2017 the results from several studies suggest positive relationships between rainfall schilling et al 2009 tolouei et al 2019 vermeulen and hofstra 2014 flow rates kay et al 2007 muirhead et al 2004 and temperature aragonés et al 2016 islam et al 2017 with indicator organisms however it should be considered that the interaction between weather or environmental factors and microbiological water quality is not linear or positive in all cases for example passerat et al 2011 found reduced indicator organisms with increasing precipitation which was ascribed to dilution previous studies have also identified relationships between microbial levels and water quality parameters including turbidity ph and conductivity francy 2009 mohammed et al 2018 while water quality parameters such as conductivity or turbidity are often not direct measures of microbial levels they can be indicative of changes that would be associated with increased probability of contamination cho et al 2016 morgan et al 2012 although it is recognized that both weather and water quality variables are correlated with fib levels few studies combine these variables in predictive models a study by gonzalez et al 2012 identified that weather data including 5 day antecedent rainfall as well as water quality parameters of dissolved oxygen and salinity were most important for predicting e coli and enterococci levels in estuarine waters francy 2009 included turbidity along with wave height rainfall and day of the year to predict the probability of exceeding bathing water standards in ohio above below 235 colony forming units 100 ml with some success depending on the year and location a wide variety of regression mechanistic and data driven methods have been applied for modelling indicator organisms in water bodies this has included but has not been limited to linear regression methods david and haggard 2011 francy 2009 bayesian hierarchical regression farnham and lall 2015 gronewold et al 2009 neural network approaches lin et al 2008 2003 thoe et al 2014 classification tree type methods mohammed et al 2018 stidson et al 2012 and mechanistic or transport and decay models reder et al 2015 the type of model used for predicting fib is essential to the overall accuracy and applicability thoe et al 2014 carried out a comprehensive comparison of five different modelling approaches for predicting fib from environmental conditions at santa monica beach california variables utilized included rainfall tide level wave characteristics air and water temperature as well as other weather variables such as cloud cover and air pressure they found a classification tree approach worked best 42 of regulatory exceedances classified correctly followed by an artificial neural network thoe et al 2014 similarly brooks et al 2016 found that a random forest approach was the most accurate for predicting fib at 7 wisconsin beaches in the context of raw water sources for drinking water mohammed et al 2018 identified high prediction accuracies of fib based on water quality data using the random forest and zero inflated regression models bayesian belief networks bbns are a probabilistic belief system that allows for modelling with conditional dependence relationships and uncertainty fenton and neil 2012 bbns are used to construct conditional probability tables cpts that represent the probability of any given observation based on other variable states they are particularly well suited for complex scenarios where physical or mechanistic models are not appropriate kragt 2009 attractive properties of bbns for modelling environmental systems include the probabilistic confidence in hypothesis and predictions the ability to utilize incomplete data and efficiency for modelling complex systems aguilera et al 2011 although several successful applications of this method has been reported to model complex phenomenon in environmental systems aguilera et al 2011 dlamini 2010 kabir et al 2015 li et al 2013 marcot 2012 there have been limited implementations of bbns for prediction of microbial water quality avila et al 2018 compared several statistical models including random forests and bayesian networks to predict recreational water quality in new zealand this study identified the substantial predictive accuracy of bayesian networks for high levels of e coli the study was limited in terms of water quality measures included in the model and only considered river flow and 48 h rainfall although temperature would be expected to have a significant influence on e coli concentrations data was considered too sparse to be included avila et al 2018 in this paper we investigate the application of bbns to predict discreet fib levels in surface waters using both water quality measures and historical weather data to our knowledge there have been no previous reports of utilizing bbns with combined water quality and weather data to predict fibs we analyze both fecal coliform and e coli levels at seven freshwater monitoring sites with records spanning from 2000 to 2019 and compare prediction accuracies with several baseline methods the ability of bbns to make predictions using incomplete data is explicitly tested furthermore the strength of relationships determined by the bbn is analyzed and interpreted in the context of the monitoring sites this work demonstrates that bbns can provide significant improvements to accuracy in predicting fib levels in real time using simple water quality measures and weather conditions the developed modelling approach can be utilized by regulators and water users to assess the microbial quality of the water in real time for more informed risk based management and treatment targets 2 methods 2 1 monitoring data water quality data was obtained from canada s national long term water quality monitoring database published under canada s open government licence environment and climate change canada 2019 in total seven monitoring sites were chosen in british columbia based on the availability of consistent monitored parameters and range of representative regions table 1 monitored parameters available at each site differ however several water quality measures were common across the selected sites turbidity conductivity water temperature and hardness three of the datasets included both e coli and faecal coliform values while the remaining four only monitored faecal coliforms based on the coordinates of the water quality monitoring point weather data were obtained from environment canada s closest weather station all 12 km from the water quality site weather data obtained included the daily mean of air temperature and daily total precipitation along with air temperature two measures were created precipitation on the sample day and total precipitation for the three days prior data from several weather stations did not specify if precipitation was as rain or snow and as such total precipitation was used for all datasets the season was a derived categorical variable based on the date of sample collection with winter december february spring march may summer june august fall september november monitoring data was discretized into several classes for this analysis discretization facilitates the calculation of probability tables for each node in the bbn and removes the need for assuming continuous probability distributions furthermore the binning of microbial and monitoring data allows for capturing some uncertainty or variability in monitoring data interpretation of source water monitoring is often carried out by observing exceedance of thresholds e g 20 cfu 100 ml and therefore most water quality policies are inherently discretized a uniform approach was taken to set 4 bins or classes for each variable decisions on how to divide the data was primarily based on maintaining equally weighted bins with consideration for relevant thresholds e g air temperature 0 c the discretization method applied will impact the overall performance of each model and it is of future interest to convert the bbn to utilize continuous probability distributions nojavan et al 2017 the bins used for each variable and dataset are listed in the supplementary information 2 2 bayesian belief networks bayesian belief networks are probabilistic graphical models that can be used for predicting the probability of an outcome of interest from known variables pearl 1988 nodes in the graph represent the variables and arcs or links with direction between nodes represent relationships between the variables kabir et al 2015 underlying bbns is the application of bayes rule shown below for two random variables x 1 and x 2 p x 1 x 2 p x 2 x 1 p x 1 p x 2 p x 1 x 2 also known as the posterior denotes the probability for x 1 with the evidence of x 2 p x 2 x 1 or likelihood denotes the conditional probability for x 2 given x 1 p x 1 is the probability of x 1 referred to the prior in this context fenton and neil 2012 the numerator is equivalent to the joint probability of the model and can be calculated based on observed data p x 2 x 1 p x 2 x 1 p x 1 for a set of k variables x 1 x k in the model the joint probability can be expanded by the chain rule p x 1 x k i 1 k p x i x i 1 x k the calculation of joint probabilities given many variables can become difficult for complex modelling tasks bbns simplify this process by explicitly identifying the key parents to each variable instead of considering all possible influences for example if x 1 is only influenced by x 2 and x 7 p x 1 x 2 x k can be simplified to p x 1 x 2 x 7 fenton and neil 2012 therefore in a bbn with explicit connections defined between variables the joint probability is p x 1 x k i 1 k p x i p a r e n t s x i for this work the software genie bayesfusion llc pittsburgh pa was used for developing and testing bbns relationships between the variables were identified based on observed linear correlations between measured parameters and expert knowledge once the relations were established through links in the bbn structure or directed acyclic graph dag learning of the cpts for each node was carried out using the software 2 3 other classification models naïve bayes was applied using the genie software for naïve bayes the network structure was such that the target variable fc or e coli was a function of each predictor independently i e no connections between predictors naïve bayes is a simple technique based on bayesian theorem where all conditional probabilities are assumed to be independent using the assumption of independence of k covariates a i a k and bayes rule the posterior probability of some variable b j can be written as p b j a i a k p b j i 1 k p a i b j although it is not always accurate to assume that conditional probabilities of the predictor variables as independent it makes the classification simpler by reducing the multidimensional task into several one dimensional tasks developing the trained model with naïve bayes approach is fast as we only need to calculate the probability of every class and the probability of that class given the input data logistic regression is a linear model for classification that utilizes a logistic function on a linear function of the predictor variables bishop 2006 logistic regression was implemented using the sklearn library in python 3 7 in the multi class prediction case a one vs rest approach was used other libraries including pandas and numpy were used to carry out a randomized 5 fold cross validation procedure to replicate the functionality in genie random forest rf is a tree based model prevalent in machine learning as it has been shown to produce accurate predictions with less overfitting breiman 2001 rfs aggregate many decision trees that are each grown with a subset of variables and data from the overall dataset the end leaf in the decision tree is the predictor of interest fib for this study the final decision is made by averaging the class assignment probabilities from all the decision trees in the random forest the rf approach was implemented using the sklearn library in python 3 7 the number of trees included was set to 2000 with other hyperparameters adjusted to optimize model performance to optimize the hyperparameters for rf regression a cross validation grid search was carried out that sequentially varied the maximum tree depth minimum samples per leaf and minimum samples to make a split the parameters which resulted in highest cv accuracy were then chosen 2 4 assessment of model performance performance of the model was based on results of a 5 fold cross validation procedure the dataset was first randomly split into 5 subsets n 13 66 for each fold depending on dataset for each fold a test dataset is excluded and the remaining 4 subsets are used to train a model the excluded set is then used to assess performance on a set of data not used in training the performance of each fold was assessed in terms of accuracy correct number of predictions and cohen s kappa over the 4 endpoint classes for fecal coliforms or 2 classes for e coli for bayesian classification the predicted class or bin is the one with the highest posterior probability the probability of each class can also be used to assess the strength of prediction these statistics can be calculated from the confusion matrix which visualizes the number of predicted classes versus true classes an example binary confusion matrix is shown as table 2 where class 1 is taken as a positive condition e g e coli 20 cfu accurate predictions can be seen as the diagonal of the matrix accuracy was calculated as a c c u r a c y t r u e p o s i t i v e s t r u e n e g a t i v e s n where n is the total number of predictions compared to truth values when considering binary classification measures of sensitivity or true positive rate and specificity true negative rate are calculated as identified below high performing models will have both high sensitivity and specificity implying new false negatives and few false positives s e n s i t i v i t y t r u e p o s i t i v e r a t e t r u e p o s i t i v e s t r u e p o s i t i v e s f a l s e n e g a t i v e s s p e c i f i c i t y t r u e n e g a t i v e r a t e t r u e n e g a t i v e s t r u e n e g a t i v e s f a l s e p o s i t i v e s cohen s kappa κ is a measure of agreement that accounts for the portion that may be attributed to chance and is calculated as ben david 2008 κ p o p c 1 p c where p o is the total probability of agreement or accuracy p c is the agreement probability due to chance both p o and p c can be calculated from the confusion matrix for an arbitrary number of classes n p o i 1 n t r u e p r e d i c t i o n s i n p c i 1 n t r u e p r e d i c t i o n s i n u m b e r o f t r u e c a s e s i n 2 2 5 strength of influence and variable importance strength of influence in a bayesian network gives insight into the importance of variables in the posterior probability of a target node for two connected nodes a parent b child a measure of this strength can be carried out in genie by calculating the distance between the distribution given evidence p b a a i and without evidence p b koiter 2006 the intuition is for distance 0 between probability distributions with or without evidence it follows the evidence has no impact on the belief for the strength of influence analysis in this work euclidean distance between the two discrete probability distributions was used given two discrete probability distributions p q euclidean distance is e u c l i d e a n d i s t a n c e p q i 1 n p i q i 2 where p i q i are probabilities 0 1 of observations in distributions p and q with n levels 3 results and discussion 3 1 water quality and weather correlations the datasets were initially analyzed for linear correlations between variables this baseline approach can identify relative trends between water quality variables weather data and fib using continuous data fig 1 shows examples of correlation matrices for the three monitoring sites that included both e coli and fecal coliform data strong correlations between fecal coliforms and e coli were seen for two sites fraser river and cheakamus river r 0 95 however only a moderate positive correlation was seen at the englishman river site r 0 63 a positive correlation between fc and e coli is not unexpected although the variability of this relationship points to the challenges with utilizing one fib to estimate other microorganism levels between different sites correlations of fib with turbidity were weak and not consistent ranging from 0 06 to 0 25 for e coli fig 1 and 0 11 to 0 28 with fecal coliforms over all datasets analyzed other general water quality parameters of conductivity and hardness also were observed to have variable positive or negative correlations depending on the site monitored r ranged from 0 46 to 0 62 these results suggest that water quality parameters are poor universal indicators of fib levels and site specific conditions determine the nature of the relationship it was expected that increasing temperatures would increase microbiological activity in a water body cha et al 2016 however only weak positive relationships r 0 03 0 41 for 4 out of 7 of the monitored sites for remaining monitoring sites such as for the fraser and cheakamus rivers fig 1 the water temperature was moderately negatively associated with fib levels r 0 33 to 0 55 it is hypothesized that land use patterns and source of fib e g run off in stream suspension growth wastewater impacts contribute to these variable observations weather events were anticipated to have a high degree of influence on the microbiological levels in source waters francy 2009 however weak linear correlations were identified between precipitation day of or prior 3 days and fib variability in the relative importance of day of precipitation versus precipitation over the last 3 days was also noted across sites cheakamus river showed increased strength of correlation with day of precipitation with turbidity while turbidity for englishman river and sumas river sites were more highly correlated with total precipitation over the last 3 days as with water quality variables these results reinforce the perception that surrogate measures and weather variables are likely correlated with fib levels but the nature of this relationship is highly complex and site specific furthermore there is a high degree of variable inter correlations between water quality and weather variables being used as predictors of fib 3 2 defining the bayesian belief network variables used for prediction were chosen based on previously reported use the potential for near real time results and the common availability of the data across monitoring sites to address the delay involved in measuring fib it is imperative that the models used are based solely on water quality or weather variables that can be determined in a rapid time frame as such we chose to only use water quality measures of turbidity conductivity hardness and temperature based on historical weather data day of precipitation and total precipitation for the previous 3 days were used along with air temperature for this study the structure of the bbn was primarily set based on expert knowledge and expected interconnections between water quality variables observed correlations between variables e g fig 1 were used as an additional guide to indicate related variables for example the correlation between conductivity and hardness is observed both in the strong correlations shown in fig 1 as well as fundamental knowledge that with increasing calcium or magnesium concentrations measured conductivity will be higher fig 2 shows the directed acyclic graph dag or the bbn structure that was used within the dag expected dependencies can be represented precipitation was anticipated to have an impact on turbidity which in turn also represents an indicator for a potential increase in fc levels scenarios where turbidity increases without correlations to precipitation can also be possible for instance the influence of a wastewater discharge or snowmelt the model structure is likely to have a significant impact the overall performance of the models furthermore the optimal structure for each monitoring site is likely to differ since the focus of this study was to preliminarily explore the capabilities of bbns on an equal basis across several monitoring sites in depth optimization of the model structure was not carried out however as a point of comparison results for algorithmically learned structures are also considered several methods exist to automatically generate network structures based on observed data including algorithms that maximize the score and constraint based algorithms that look for dependencies between variables chen and pollino 2012 in this work a score maximizing greedy thick thinning method in the genie software was applied based on the method described by cheng et al 1997 in brief this method iteratively adds connections between nodes in the dag and only keeps the connection if the marginal likelihood is increased following additions the algorithm then iteratively thins the dag by removing connections that do not improve the likelihood more in depth structure comparison and optimization is planned for future work 3 3 model performances for fc prediction four modelling approaches are compared for classifying fc levels logistic regression naïve bayes random forests and bbns each model was constructed for multi class classification 4 bins and each variable was also discretized into 4 classes as described in the methods section binning was site specific with the primary objective of keeping each bin size as equal as possible a balanced bin size approach was taken to ensure there were a sufficient number of observations in each category by using site specific historical data the range of values expected at each monitoring site could be captured in a straightforward way some modifications to the thresholds of each bin were made to represent realistic and more interpretable divisions for instance turbidity 1 ntu or air temperature 0 c for all datasets analyzed the bbn method resulted in the highest classification method across 4 classes results in table 3 identify an increase of 25 32 54 54 in overall accuracy over other methods naïve bayes and rf classification showed modest improvements over logistic regression 6 4 8 37 for the fraser river nechako river and englishman river however improvements were not consistently observed for other datasets with approximately equal or decreased performance the trend in results and improved performance of the bbn were also evident from cohen s kappa values by accounting for the probability of an observation by chance bias from the unbalanced dataset on accuracy is mitigated by this measure the statistic will range from 1 to 1 with 0 representing random classification and 1 representing perfect classification ben david 2008 while classification by baseline methods logistic regression naïve bayes and random forests ranged from κ 0 02 to 0 35 indicating random to low performance the bbn showed strong performance of κ 0 65 0 92 across all datasets a study carried by mohammed et al 2018 on predicting fib using water quality parameters such as ph turbidity alkalinity conductance colour and temperature stated that rf models had difficulty predicting peak or high counts results from utilizing the bbn show improved classification of high fc levels with accuracies ranging from 84 44 100 00 for the highest bin at each site in all cases the accuracy of predicting high levels of fc was greater than the average accuracy reported in table 3 for all bins thoe et al 2014 found a prediction sensitivity of 42 for fecal coliform exceedances 400 mpn 100 ml at santa monica beach using a classification tree approach these findings are in line with rf results found here 34 56 accuracy with consideration of differences in number of bins and thresholds the dag used fig 2 results in a large number of combinations in the conditional probability table cpt for coliforms 16 384 combinations this can make the cpt intractable or otherwise difficult to interpret marcot et al 2006 taking a closer look at the cpt tables the majority of combinations were not observed 89 98 across all datasets and therefore defaulted to the proportionality of those states in the dataset this was interpreted as the model making a guess based on frequency if no observed information is available despite this limitation in the size of the cpt the prediction results are high suggesting that although every combination is considered there is a much smaller sub set of observed combinations which are relevant to the application e g high water temperature with low air temperature is unlikely an observed combination as a point of comparison two simplified structures were tested for each dataset one where only the water quality variables turbidity water temperature and conductivity were directly connected to the coliform levels and therefore reducing the cpt size to 64 the second was a structure learned from the data utilizing the greedy thick thinning gtt algorithm results from these two simplified structures are reported in table 4 the results of comparing alternative structures indicates that simplifying the cpt comes at the cost of performance both in terms of accuracy and cohen s kappa for all datasets table 4 furthermore bbn structures generated through data did not improve performance related to a specific node of interest coliforms these results demonstrate that the structure of the bbn will have a strong influence on the overall results and further work is needed to elucidate optimal strategies for developing and testing bbn structures a particular challenge with the structure learning algorithm chosen the structures generated were not consistent between monitoring sites furthermore several variables were often excluded from the final structure in so far as no significant arcs or connections between the variable and the prediction node coliforms was formed by the algorithm an example structure generated by gtt is shown as fig 3 it can be observed that precipitation variables although linked together were found to have no interaction with coliform levels 3 4 e coli predictions three of the water quality datasets also included e coli monitoring in addition to fc e coli is thought to be a better indicator of fecal contamination than fecal or thermotolerant coliforms since the latter may originate from non fecal sources and are prevalent in temperate environments allen et al 2015 odonkor and ampofo 2013 using the same predictor variables as for fc a new bbn was created for the binary prediction of e coli the threshold for the two class or binary classification was taken as 20 cfu e coli 100 ml this threshold was chosen to be relatable to a source water criterion for drinking water in british columbia where water sources with less than 20 cfu e coli 100 ml in 90 of weekly samples over 6 months may be allowed to operate without filtration b c ministry of health 2012 using the same structure as illustrated in fig 1 the fc node was replaced with e coli for each of the applicable monitoring sites all bins for nodes were unchanged with 4 states however now the target node was binary above or below the threshold reported in table 5 are the performances of the 4 models for binary prediction of e coli above or below 20 cfu 100 ml as was seen with fc modelling the bbn models consistently achieved the highest accuracy 90 in all cases or kappa values 0 8 for binary predictions the sensitivity true positive rate and specificity true negative rate can also be calculated and is reported in table 5 using a bbn the sensitivity and specificity were consistently similar to overall accuracy indicating no overall bias of the model this was not the case for other approaches such as naïve bayes or logistic regression applied to the fraser gravesend dataset with reduced sensitivity 36 while specificity was high 68 for the cheakamus river dataset these classification techniques resulted in high sensitivity 81 with lower specificity 61 the high cross validation accuracies suggest that a trained bbn could be used to estimate if water quality will exceed the 20 cfu 100 ml of e coli on any given day given routine water quality measures coupled with weather data results found in this study are comparable to those reported by avila et al 2018 with cross validation error rates of 0 21 or 79 accuracy using a bbn for 3 bin classification of e coli levels at a recreational site in new zealand 3 5 predictions from incomplete data in the previous section high prediction accuracies of e coli exceeding a threshold were observed using complete data a distinct advantage to bbns is the ability to utilize incomplete observations or data where not all the variables are measured furthermore the network will output the degree of confidence or probability an observation belongs to a specific class to assess the ability of a bbn to utilize incomplete data for classification of e coli levels a separated test set of the last 20 of data in the time series was created network parameters were learned from the training data first 80 and then predictions on the test set were carried out under three scenarios 1 complete data 2 only weather data and 3 only water quality data weather data included precipitation and air temperature while water quality variables included conductivity hardness turbidity and water temperature a comparison of prediction results for the three scenarios is presented in fig 4 with reference to the correct classes shown at the bottom of each set of figures complete data or all variables results in the highest prediction accuracy 90 48 100 model performance decreased with the exclusion of either water quality or weather data however accuracy for the cheakamus river dataset was impacted to a lesser degree when only using water quality variables no water quality 65 96 no weather variables 82 98 although overall accuracy was not impacted the model confidence of incorrect decisions improved when using only water quality variables in the englishman river dataset the results suggest that while the inclusion of weather data will improve the overall predictive power of the bbn model complete water quality data is crucial for accurate predictions for the fraser river and cheakamus river not including water quality data results in the model just predicting the most frequent class essentially making predictions not useful non informative models were likely due to choosing a threshold based on water quality policy making e coli classes highly unbalanced for example in the fraser river dataset only 31 25 of e coli levels were below 20 cfu 100 ml however the probability of class prediction changes given the number and type of variables included it is possible that with improved data availability and increasing the size of the training dataset the model parameters will be better tuned to make more meaningful predictions with incomplete data 3 6 factors affecting fib predictions the strength of influence can be calculated for arcs or links in the dag indicating the variables which are most impactful on fib counts the output to quantify the strength of influence euclidean distance between discrete probability distributions is only insightful in a relative sense and normalized between 0 and 1 for comparing two separate networks fig 5 summarizes the normalized strength of influence of variables directly linked to fib levels in the dag for the prediction of fib levels it is evident that each predictor has variable importance or influence depending on the location general trends are observed that water temperature and conductivity are strongly associated with fc or e coli levels strength of influence between turbidity and fc was significantly higher with corresponding lower strength with conductivity for the nechako river site at prince george compared to other locations this site is surrounded by mostly by urban settlement along with some forested areas as determined qualitatively by a land use map from agriculture and agri food canada government of canada 2010 however other monitoring sites with significant surrounding settlement such as fraser river at gravesend did not display the same relationship between fc and turbidity all other sites were observed to show a substantial degree of influence between conductivity and fc similar conclusions can be drawn from e coli results fig 5 b where conductivity was observed to have more consistently strong associations conductivity is a standard indicator of disturbances to an aquatic water body with elevated conductivity over background levels occurring due to runoff from urban areas sewage impacts and other landscape disturbances morgan et al 2012 these events that would result in increased conductivity are also expected to raise fc or e coli levels cho et al 2016 the results from the bbn suggest that for all sites except for the nechako river conductivity is a better indicator of fc levels compared to turbidity two well divided categories of sites can be identified based on the direct importance of seasonality on fc or e coli levels generally more areas with more settlement including the fraser river nechako river and sumas river had weak relationships between seasonality and fib in contrast watersheds with significant amounts of forest cropland or grassland coverage including the cheakamus river okanagan river and similkameen river had stronger relationships with seasonality government of canada 2010 it is hypothesized this distinction is exemplifying the possible sources of fc for each site either from land runoff or growth direct input into the water body dependence of possible growth or die off of fc and e coli with seasonality and temperature have been previously identified cho et al 2016 it was anticipated that surface runoff after rainfall would be expected to increase fib levels in surrounding water bodies eregno et al 2018 surrounding land use and characteristics will impact the pollutants introduced from surface runoff with some evidence that flushing from urban areas will increase turbidity but not fib to a significant level hathaway and hunt 2011 however increasing surface permeability in urban areas has also been observed to reduce fib in stormwater following rainfall tota maharaj and scholz 2010 results of this study based on the strength of relationships in the bbn identified the inconsistent impact on the relationship between fib and predictors across monitoring sites it was observed that typically the fib levels were either impacted more strongly by precipitation on the sampling day or over the last 3 days while this is a hypothesized function of surrounding land use the relationships are not clear from the results of this study for example two monitoring sites in predominantly agricultural areas okanagan river and sumas river show opposite trends with precipitation and fc levels this is possibly a function of agricultural practices in the area flow rates and distance from settlement areas which should be captured in future work results for e coli are distinct between the fraser river and englishman river vs cheakamus river on a qualitative basis there is a greater settlement area surrounding the first two sites in contrast to the cheakamus river which is predominantly surrounded by forested land the cheakamus river monitoring site is downstream of the wastewater outfall from the resort municipality of whistler this may explain the lack of importance of precipitation on e coli levels and the importance of seasonality for this site average e coli levels in the winter were 224 cfu 100 ml compared to 3 cfu 100 ml in the summer which corresponds with the highest effluent flows during winter months resort municipality of whistler 2018 4 conclusions initial analysis of linear correlations between water quality measures weather conditions and fib levels in surface waters identified the complex and variable nature of these relationships this exemplifies the challenge in building a predictive model for fib primarily if based on generalized expected mechanisms such as increasing water temperatures being associated with a higher level of microbiological activity using bbns accuracy for 4 bin classification of fecal coliforms 81 accuracy for all sites compared to conventional and previously investigated modelling approaches 49 accuracy for all sites was achieved furthermore for the binary prediction of e coli exceeding a threshold of 20 cfu 100 ml accuracy was greater than 90 a unique advantage of bbns is the ability to make probabilistic based decisions from incomplete data for a separated test set e coli predictions were most accurate when complete data was utilized and identifies significant value in incorporating weather conditions into predictive fib models however it was observed that water quality surrogates were particularly essential and prediction accuracy was impacted to a lesser degree when weather data were excluded based on the strengths of influence within the bbn the importance of water quality measures was further reinforced with consistent high relationship strengths between fib and conductivity measures however the overall importance of analyzed variables was highly variable between sites and is hypothesized to be due to site specific conditions such as land use or overall interactions with the watershed as such this work suggests a strong need for site specific models and further work to incorporate land use directly into the bbn real time knowledge of fib levels in natural waters is of significance to environmental management as well as a wide range of water uses accurate predictive models can ultimately assist in protecting public health through improving the information for developing risk assessments or setting precise drinking water treatment targets this work shows significant promise of bbns for providing accurate fib predictions and producing an interpretable and flexible model declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by the natural sciences and engineering research council of canada nserc discovery grant program appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 115349 
18305,levels of fecal indicator bacteria fib provide a surrogate measure of the microbial quality of water used for a wide range of applications despite the common use of these measures a significant limitation is a delay in results due to the time required for cultivation and enumeration of fib testing requires at least 18 24 h and therefore fib cannot be used to identify current or real time microbial water quality an approach of nowcasting or empirical modelling approaches that incorporate water quality environmental and weather variables to predict fib levels in real time has been developed with some success however fib levels are dependent on a complex interaction of numerous variables which can be challenging to model with ordinary linear regression or classification methods most commonly applied in this study novel use of bayesian belief networks bbns that allow for a probabilistic representation of complex variable interactions is investigated for real time modelling of fib levels surface waters in particular the integration of both water quality measures and current historical weather for prediction of fecal coliforms and escherichia coli levels is achieved using bbns for 4 bin classification of fecal coliform levels bbns increased prediction accuracy by 25 54 compared to other previously used techniques including logistic regression naïve bayes and random forests binary prediction of e coli levels exceeding a threshold of 20 cfu 100 ml was also significantly improved using bbns with prediction accuracies 90 for all monitoring sites advantages of the bbn approach are also demonstrated identifying the ability to make predictions from incomplete monitoring data as well as probabilistic inference of variable importance in fib levels in particular the results indicate that water quality surrogates such as conductivity are essential to real time prediction of fib the results and models described in this work can be readily utilized to provide accurate and real time assessments of fib levels in surface waters utilizing commonly monitored parameters 1 introduction fecal indicator bacteria fib such as fecal or thermotolerant coliforms fc or escherichia coli e coli are the most commonly monitored parameters for assessment of the microbial quality of water used for recreation drinking and other uses allen et al 2015 payment and locas 2011 thoe et al 2014 there is a broad association of fib levels and waterborne pathogens however there are several known limitations to this relationship avila et al 2018 edberg et al 2000 in particular fib are often poorly associated with non bacterial pathogens including protozoa and viruses and fibs do not provide consistent relationships with specific pathogens bradshaw et al 2016 poma et al 2012 although an indirect approach of utilizing indicator organisms is not ideal direct measurement of pathogens in natural waters is challenging due to the low expected concentrations non uniform distributions and transient occurrence field and samadpour 2007 there is still recognized value in using fibs for microbial risk assessments and surveillance of drinking water source waters petterson et al 2016 world health organization 2014 often fibs are the only available information on source water quality since techniques for monitoring waterborne pathogens are generally expensive and time consuming making an indicator approach necessary for protecting public health edberg et al 2000 despite the widespread use of fib measurements testing requires 18 24 h for cultivation and consequently results are only known a significant time after a potential exposure avila et al 2018 as such there is interest in empirical models that can predict microbial quality based on real time data sources and inform water management in a timely manner ashbolt et al 2010 mohammed et al 2018 however it should be considered that the microbial community is under the influence of a wide variety of factors bradshaw et al 2016 therefore models require the inclusion of both direct and indirect parameters to accurately model microbial water quality previous fib modelling approaches primarily applied in the context of bathing water standards have recognized the importance of weather and hydrological variables for predicting fib weather events such as rainfall and time of the year will significantly impact transport and growth conditions of the indicator organism chu et al 2014 eregno et al 2018 francy 2009 mcphail and stidson 2009 shahid iqbal et al 2017 the results from several studies suggest positive relationships between rainfall schilling et al 2009 tolouei et al 2019 vermeulen and hofstra 2014 flow rates kay et al 2007 muirhead et al 2004 and temperature aragonés et al 2016 islam et al 2017 with indicator organisms however it should be considered that the interaction between weather or environmental factors and microbiological water quality is not linear or positive in all cases for example passerat et al 2011 found reduced indicator organisms with increasing precipitation which was ascribed to dilution previous studies have also identified relationships between microbial levels and water quality parameters including turbidity ph and conductivity francy 2009 mohammed et al 2018 while water quality parameters such as conductivity or turbidity are often not direct measures of microbial levels they can be indicative of changes that would be associated with increased probability of contamination cho et al 2016 morgan et al 2012 although it is recognized that both weather and water quality variables are correlated with fib levels few studies combine these variables in predictive models a study by gonzalez et al 2012 identified that weather data including 5 day antecedent rainfall as well as water quality parameters of dissolved oxygen and salinity were most important for predicting e coli and enterococci levels in estuarine waters francy 2009 included turbidity along with wave height rainfall and day of the year to predict the probability of exceeding bathing water standards in ohio above below 235 colony forming units 100 ml with some success depending on the year and location a wide variety of regression mechanistic and data driven methods have been applied for modelling indicator organisms in water bodies this has included but has not been limited to linear regression methods david and haggard 2011 francy 2009 bayesian hierarchical regression farnham and lall 2015 gronewold et al 2009 neural network approaches lin et al 2008 2003 thoe et al 2014 classification tree type methods mohammed et al 2018 stidson et al 2012 and mechanistic or transport and decay models reder et al 2015 the type of model used for predicting fib is essential to the overall accuracy and applicability thoe et al 2014 carried out a comprehensive comparison of five different modelling approaches for predicting fib from environmental conditions at santa monica beach california variables utilized included rainfall tide level wave characteristics air and water temperature as well as other weather variables such as cloud cover and air pressure they found a classification tree approach worked best 42 of regulatory exceedances classified correctly followed by an artificial neural network thoe et al 2014 similarly brooks et al 2016 found that a random forest approach was the most accurate for predicting fib at 7 wisconsin beaches in the context of raw water sources for drinking water mohammed et al 2018 identified high prediction accuracies of fib based on water quality data using the random forest and zero inflated regression models bayesian belief networks bbns are a probabilistic belief system that allows for modelling with conditional dependence relationships and uncertainty fenton and neil 2012 bbns are used to construct conditional probability tables cpts that represent the probability of any given observation based on other variable states they are particularly well suited for complex scenarios where physical or mechanistic models are not appropriate kragt 2009 attractive properties of bbns for modelling environmental systems include the probabilistic confidence in hypothesis and predictions the ability to utilize incomplete data and efficiency for modelling complex systems aguilera et al 2011 although several successful applications of this method has been reported to model complex phenomenon in environmental systems aguilera et al 2011 dlamini 2010 kabir et al 2015 li et al 2013 marcot 2012 there have been limited implementations of bbns for prediction of microbial water quality avila et al 2018 compared several statistical models including random forests and bayesian networks to predict recreational water quality in new zealand this study identified the substantial predictive accuracy of bayesian networks for high levels of e coli the study was limited in terms of water quality measures included in the model and only considered river flow and 48 h rainfall although temperature would be expected to have a significant influence on e coli concentrations data was considered too sparse to be included avila et al 2018 in this paper we investigate the application of bbns to predict discreet fib levels in surface waters using both water quality measures and historical weather data to our knowledge there have been no previous reports of utilizing bbns with combined water quality and weather data to predict fibs we analyze both fecal coliform and e coli levels at seven freshwater monitoring sites with records spanning from 2000 to 2019 and compare prediction accuracies with several baseline methods the ability of bbns to make predictions using incomplete data is explicitly tested furthermore the strength of relationships determined by the bbn is analyzed and interpreted in the context of the monitoring sites this work demonstrates that bbns can provide significant improvements to accuracy in predicting fib levels in real time using simple water quality measures and weather conditions the developed modelling approach can be utilized by regulators and water users to assess the microbial quality of the water in real time for more informed risk based management and treatment targets 2 methods 2 1 monitoring data water quality data was obtained from canada s national long term water quality monitoring database published under canada s open government licence environment and climate change canada 2019 in total seven monitoring sites were chosen in british columbia based on the availability of consistent monitored parameters and range of representative regions table 1 monitored parameters available at each site differ however several water quality measures were common across the selected sites turbidity conductivity water temperature and hardness three of the datasets included both e coli and faecal coliform values while the remaining four only monitored faecal coliforms based on the coordinates of the water quality monitoring point weather data were obtained from environment canada s closest weather station all 12 km from the water quality site weather data obtained included the daily mean of air temperature and daily total precipitation along with air temperature two measures were created precipitation on the sample day and total precipitation for the three days prior data from several weather stations did not specify if precipitation was as rain or snow and as such total precipitation was used for all datasets the season was a derived categorical variable based on the date of sample collection with winter december february spring march may summer june august fall september november monitoring data was discretized into several classes for this analysis discretization facilitates the calculation of probability tables for each node in the bbn and removes the need for assuming continuous probability distributions furthermore the binning of microbial and monitoring data allows for capturing some uncertainty or variability in monitoring data interpretation of source water monitoring is often carried out by observing exceedance of thresholds e g 20 cfu 100 ml and therefore most water quality policies are inherently discretized a uniform approach was taken to set 4 bins or classes for each variable decisions on how to divide the data was primarily based on maintaining equally weighted bins with consideration for relevant thresholds e g air temperature 0 c the discretization method applied will impact the overall performance of each model and it is of future interest to convert the bbn to utilize continuous probability distributions nojavan et al 2017 the bins used for each variable and dataset are listed in the supplementary information 2 2 bayesian belief networks bayesian belief networks are probabilistic graphical models that can be used for predicting the probability of an outcome of interest from known variables pearl 1988 nodes in the graph represent the variables and arcs or links with direction between nodes represent relationships between the variables kabir et al 2015 underlying bbns is the application of bayes rule shown below for two random variables x 1 and x 2 p x 1 x 2 p x 2 x 1 p x 1 p x 2 p x 1 x 2 also known as the posterior denotes the probability for x 1 with the evidence of x 2 p x 2 x 1 or likelihood denotes the conditional probability for x 2 given x 1 p x 1 is the probability of x 1 referred to the prior in this context fenton and neil 2012 the numerator is equivalent to the joint probability of the model and can be calculated based on observed data p x 2 x 1 p x 2 x 1 p x 1 for a set of k variables x 1 x k in the model the joint probability can be expanded by the chain rule p x 1 x k i 1 k p x i x i 1 x k the calculation of joint probabilities given many variables can become difficult for complex modelling tasks bbns simplify this process by explicitly identifying the key parents to each variable instead of considering all possible influences for example if x 1 is only influenced by x 2 and x 7 p x 1 x 2 x k can be simplified to p x 1 x 2 x 7 fenton and neil 2012 therefore in a bbn with explicit connections defined between variables the joint probability is p x 1 x k i 1 k p x i p a r e n t s x i for this work the software genie bayesfusion llc pittsburgh pa was used for developing and testing bbns relationships between the variables were identified based on observed linear correlations between measured parameters and expert knowledge once the relations were established through links in the bbn structure or directed acyclic graph dag learning of the cpts for each node was carried out using the software 2 3 other classification models naïve bayes was applied using the genie software for naïve bayes the network structure was such that the target variable fc or e coli was a function of each predictor independently i e no connections between predictors naïve bayes is a simple technique based on bayesian theorem where all conditional probabilities are assumed to be independent using the assumption of independence of k covariates a i a k and bayes rule the posterior probability of some variable b j can be written as p b j a i a k p b j i 1 k p a i b j although it is not always accurate to assume that conditional probabilities of the predictor variables as independent it makes the classification simpler by reducing the multidimensional task into several one dimensional tasks developing the trained model with naïve bayes approach is fast as we only need to calculate the probability of every class and the probability of that class given the input data logistic regression is a linear model for classification that utilizes a logistic function on a linear function of the predictor variables bishop 2006 logistic regression was implemented using the sklearn library in python 3 7 in the multi class prediction case a one vs rest approach was used other libraries including pandas and numpy were used to carry out a randomized 5 fold cross validation procedure to replicate the functionality in genie random forest rf is a tree based model prevalent in machine learning as it has been shown to produce accurate predictions with less overfitting breiman 2001 rfs aggregate many decision trees that are each grown with a subset of variables and data from the overall dataset the end leaf in the decision tree is the predictor of interest fib for this study the final decision is made by averaging the class assignment probabilities from all the decision trees in the random forest the rf approach was implemented using the sklearn library in python 3 7 the number of trees included was set to 2000 with other hyperparameters adjusted to optimize model performance to optimize the hyperparameters for rf regression a cross validation grid search was carried out that sequentially varied the maximum tree depth minimum samples per leaf and minimum samples to make a split the parameters which resulted in highest cv accuracy were then chosen 2 4 assessment of model performance performance of the model was based on results of a 5 fold cross validation procedure the dataset was first randomly split into 5 subsets n 13 66 for each fold depending on dataset for each fold a test dataset is excluded and the remaining 4 subsets are used to train a model the excluded set is then used to assess performance on a set of data not used in training the performance of each fold was assessed in terms of accuracy correct number of predictions and cohen s kappa over the 4 endpoint classes for fecal coliforms or 2 classes for e coli for bayesian classification the predicted class or bin is the one with the highest posterior probability the probability of each class can also be used to assess the strength of prediction these statistics can be calculated from the confusion matrix which visualizes the number of predicted classes versus true classes an example binary confusion matrix is shown as table 2 where class 1 is taken as a positive condition e g e coli 20 cfu accurate predictions can be seen as the diagonal of the matrix accuracy was calculated as a c c u r a c y t r u e p o s i t i v e s t r u e n e g a t i v e s n where n is the total number of predictions compared to truth values when considering binary classification measures of sensitivity or true positive rate and specificity true negative rate are calculated as identified below high performing models will have both high sensitivity and specificity implying new false negatives and few false positives s e n s i t i v i t y t r u e p o s i t i v e r a t e t r u e p o s i t i v e s t r u e p o s i t i v e s f a l s e n e g a t i v e s s p e c i f i c i t y t r u e n e g a t i v e r a t e t r u e n e g a t i v e s t r u e n e g a t i v e s f a l s e p o s i t i v e s cohen s kappa κ is a measure of agreement that accounts for the portion that may be attributed to chance and is calculated as ben david 2008 κ p o p c 1 p c where p o is the total probability of agreement or accuracy p c is the agreement probability due to chance both p o and p c can be calculated from the confusion matrix for an arbitrary number of classes n p o i 1 n t r u e p r e d i c t i o n s i n p c i 1 n t r u e p r e d i c t i o n s i n u m b e r o f t r u e c a s e s i n 2 2 5 strength of influence and variable importance strength of influence in a bayesian network gives insight into the importance of variables in the posterior probability of a target node for two connected nodes a parent b child a measure of this strength can be carried out in genie by calculating the distance between the distribution given evidence p b a a i and without evidence p b koiter 2006 the intuition is for distance 0 between probability distributions with or without evidence it follows the evidence has no impact on the belief for the strength of influence analysis in this work euclidean distance between the two discrete probability distributions was used given two discrete probability distributions p q euclidean distance is e u c l i d e a n d i s t a n c e p q i 1 n p i q i 2 where p i q i are probabilities 0 1 of observations in distributions p and q with n levels 3 results and discussion 3 1 water quality and weather correlations the datasets were initially analyzed for linear correlations between variables this baseline approach can identify relative trends between water quality variables weather data and fib using continuous data fig 1 shows examples of correlation matrices for the three monitoring sites that included both e coli and fecal coliform data strong correlations between fecal coliforms and e coli were seen for two sites fraser river and cheakamus river r 0 95 however only a moderate positive correlation was seen at the englishman river site r 0 63 a positive correlation between fc and e coli is not unexpected although the variability of this relationship points to the challenges with utilizing one fib to estimate other microorganism levels between different sites correlations of fib with turbidity were weak and not consistent ranging from 0 06 to 0 25 for e coli fig 1 and 0 11 to 0 28 with fecal coliforms over all datasets analyzed other general water quality parameters of conductivity and hardness also were observed to have variable positive or negative correlations depending on the site monitored r ranged from 0 46 to 0 62 these results suggest that water quality parameters are poor universal indicators of fib levels and site specific conditions determine the nature of the relationship it was expected that increasing temperatures would increase microbiological activity in a water body cha et al 2016 however only weak positive relationships r 0 03 0 41 for 4 out of 7 of the monitored sites for remaining monitoring sites such as for the fraser and cheakamus rivers fig 1 the water temperature was moderately negatively associated with fib levels r 0 33 to 0 55 it is hypothesized that land use patterns and source of fib e g run off in stream suspension growth wastewater impacts contribute to these variable observations weather events were anticipated to have a high degree of influence on the microbiological levels in source waters francy 2009 however weak linear correlations were identified between precipitation day of or prior 3 days and fib variability in the relative importance of day of precipitation versus precipitation over the last 3 days was also noted across sites cheakamus river showed increased strength of correlation with day of precipitation with turbidity while turbidity for englishman river and sumas river sites were more highly correlated with total precipitation over the last 3 days as with water quality variables these results reinforce the perception that surrogate measures and weather variables are likely correlated with fib levels but the nature of this relationship is highly complex and site specific furthermore there is a high degree of variable inter correlations between water quality and weather variables being used as predictors of fib 3 2 defining the bayesian belief network variables used for prediction were chosen based on previously reported use the potential for near real time results and the common availability of the data across monitoring sites to address the delay involved in measuring fib it is imperative that the models used are based solely on water quality or weather variables that can be determined in a rapid time frame as such we chose to only use water quality measures of turbidity conductivity hardness and temperature based on historical weather data day of precipitation and total precipitation for the previous 3 days were used along with air temperature for this study the structure of the bbn was primarily set based on expert knowledge and expected interconnections between water quality variables observed correlations between variables e g fig 1 were used as an additional guide to indicate related variables for example the correlation between conductivity and hardness is observed both in the strong correlations shown in fig 1 as well as fundamental knowledge that with increasing calcium or magnesium concentrations measured conductivity will be higher fig 2 shows the directed acyclic graph dag or the bbn structure that was used within the dag expected dependencies can be represented precipitation was anticipated to have an impact on turbidity which in turn also represents an indicator for a potential increase in fc levels scenarios where turbidity increases without correlations to precipitation can also be possible for instance the influence of a wastewater discharge or snowmelt the model structure is likely to have a significant impact the overall performance of the models furthermore the optimal structure for each monitoring site is likely to differ since the focus of this study was to preliminarily explore the capabilities of bbns on an equal basis across several monitoring sites in depth optimization of the model structure was not carried out however as a point of comparison results for algorithmically learned structures are also considered several methods exist to automatically generate network structures based on observed data including algorithms that maximize the score and constraint based algorithms that look for dependencies between variables chen and pollino 2012 in this work a score maximizing greedy thick thinning method in the genie software was applied based on the method described by cheng et al 1997 in brief this method iteratively adds connections between nodes in the dag and only keeps the connection if the marginal likelihood is increased following additions the algorithm then iteratively thins the dag by removing connections that do not improve the likelihood more in depth structure comparison and optimization is planned for future work 3 3 model performances for fc prediction four modelling approaches are compared for classifying fc levels logistic regression naïve bayes random forests and bbns each model was constructed for multi class classification 4 bins and each variable was also discretized into 4 classes as described in the methods section binning was site specific with the primary objective of keeping each bin size as equal as possible a balanced bin size approach was taken to ensure there were a sufficient number of observations in each category by using site specific historical data the range of values expected at each monitoring site could be captured in a straightforward way some modifications to the thresholds of each bin were made to represent realistic and more interpretable divisions for instance turbidity 1 ntu or air temperature 0 c for all datasets analyzed the bbn method resulted in the highest classification method across 4 classes results in table 3 identify an increase of 25 32 54 54 in overall accuracy over other methods naïve bayes and rf classification showed modest improvements over logistic regression 6 4 8 37 for the fraser river nechako river and englishman river however improvements were not consistently observed for other datasets with approximately equal or decreased performance the trend in results and improved performance of the bbn were also evident from cohen s kappa values by accounting for the probability of an observation by chance bias from the unbalanced dataset on accuracy is mitigated by this measure the statistic will range from 1 to 1 with 0 representing random classification and 1 representing perfect classification ben david 2008 while classification by baseline methods logistic regression naïve bayes and random forests ranged from κ 0 02 to 0 35 indicating random to low performance the bbn showed strong performance of κ 0 65 0 92 across all datasets a study carried by mohammed et al 2018 on predicting fib using water quality parameters such as ph turbidity alkalinity conductance colour and temperature stated that rf models had difficulty predicting peak or high counts results from utilizing the bbn show improved classification of high fc levels with accuracies ranging from 84 44 100 00 for the highest bin at each site in all cases the accuracy of predicting high levels of fc was greater than the average accuracy reported in table 3 for all bins thoe et al 2014 found a prediction sensitivity of 42 for fecal coliform exceedances 400 mpn 100 ml at santa monica beach using a classification tree approach these findings are in line with rf results found here 34 56 accuracy with consideration of differences in number of bins and thresholds the dag used fig 2 results in a large number of combinations in the conditional probability table cpt for coliforms 16 384 combinations this can make the cpt intractable or otherwise difficult to interpret marcot et al 2006 taking a closer look at the cpt tables the majority of combinations were not observed 89 98 across all datasets and therefore defaulted to the proportionality of those states in the dataset this was interpreted as the model making a guess based on frequency if no observed information is available despite this limitation in the size of the cpt the prediction results are high suggesting that although every combination is considered there is a much smaller sub set of observed combinations which are relevant to the application e g high water temperature with low air temperature is unlikely an observed combination as a point of comparison two simplified structures were tested for each dataset one where only the water quality variables turbidity water temperature and conductivity were directly connected to the coliform levels and therefore reducing the cpt size to 64 the second was a structure learned from the data utilizing the greedy thick thinning gtt algorithm results from these two simplified structures are reported in table 4 the results of comparing alternative structures indicates that simplifying the cpt comes at the cost of performance both in terms of accuracy and cohen s kappa for all datasets table 4 furthermore bbn structures generated through data did not improve performance related to a specific node of interest coliforms these results demonstrate that the structure of the bbn will have a strong influence on the overall results and further work is needed to elucidate optimal strategies for developing and testing bbn structures a particular challenge with the structure learning algorithm chosen the structures generated were not consistent between monitoring sites furthermore several variables were often excluded from the final structure in so far as no significant arcs or connections between the variable and the prediction node coliforms was formed by the algorithm an example structure generated by gtt is shown as fig 3 it can be observed that precipitation variables although linked together were found to have no interaction with coliform levels 3 4 e coli predictions three of the water quality datasets also included e coli monitoring in addition to fc e coli is thought to be a better indicator of fecal contamination than fecal or thermotolerant coliforms since the latter may originate from non fecal sources and are prevalent in temperate environments allen et al 2015 odonkor and ampofo 2013 using the same predictor variables as for fc a new bbn was created for the binary prediction of e coli the threshold for the two class or binary classification was taken as 20 cfu e coli 100 ml this threshold was chosen to be relatable to a source water criterion for drinking water in british columbia where water sources with less than 20 cfu e coli 100 ml in 90 of weekly samples over 6 months may be allowed to operate without filtration b c ministry of health 2012 using the same structure as illustrated in fig 1 the fc node was replaced with e coli for each of the applicable monitoring sites all bins for nodes were unchanged with 4 states however now the target node was binary above or below the threshold reported in table 5 are the performances of the 4 models for binary prediction of e coli above or below 20 cfu 100 ml as was seen with fc modelling the bbn models consistently achieved the highest accuracy 90 in all cases or kappa values 0 8 for binary predictions the sensitivity true positive rate and specificity true negative rate can also be calculated and is reported in table 5 using a bbn the sensitivity and specificity were consistently similar to overall accuracy indicating no overall bias of the model this was not the case for other approaches such as naïve bayes or logistic regression applied to the fraser gravesend dataset with reduced sensitivity 36 while specificity was high 68 for the cheakamus river dataset these classification techniques resulted in high sensitivity 81 with lower specificity 61 the high cross validation accuracies suggest that a trained bbn could be used to estimate if water quality will exceed the 20 cfu 100 ml of e coli on any given day given routine water quality measures coupled with weather data results found in this study are comparable to those reported by avila et al 2018 with cross validation error rates of 0 21 or 79 accuracy using a bbn for 3 bin classification of e coli levels at a recreational site in new zealand 3 5 predictions from incomplete data in the previous section high prediction accuracies of e coli exceeding a threshold were observed using complete data a distinct advantage to bbns is the ability to utilize incomplete observations or data where not all the variables are measured furthermore the network will output the degree of confidence or probability an observation belongs to a specific class to assess the ability of a bbn to utilize incomplete data for classification of e coli levels a separated test set of the last 20 of data in the time series was created network parameters were learned from the training data first 80 and then predictions on the test set were carried out under three scenarios 1 complete data 2 only weather data and 3 only water quality data weather data included precipitation and air temperature while water quality variables included conductivity hardness turbidity and water temperature a comparison of prediction results for the three scenarios is presented in fig 4 with reference to the correct classes shown at the bottom of each set of figures complete data or all variables results in the highest prediction accuracy 90 48 100 model performance decreased with the exclusion of either water quality or weather data however accuracy for the cheakamus river dataset was impacted to a lesser degree when only using water quality variables no water quality 65 96 no weather variables 82 98 although overall accuracy was not impacted the model confidence of incorrect decisions improved when using only water quality variables in the englishman river dataset the results suggest that while the inclusion of weather data will improve the overall predictive power of the bbn model complete water quality data is crucial for accurate predictions for the fraser river and cheakamus river not including water quality data results in the model just predicting the most frequent class essentially making predictions not useful non informative models were likely due to choosing a threshold based on water quality policy making e coli classes highly unbalanced for example in the fraser river dataset only 31 25 of e coli levels were below 20 cfu 100 ml however the probability of class prediction changes given the number and type of variables included it is possible that with improved data availability and increasing the size of the training dataset the model parameters will be better tuned to make more meaningful predictions with incomplete data 3 6 factors affecting fib predictions the strength of influence can be calculated for arcs or links in the dag indicating the variables which are most impactful on fib counts the output to quantify the strength of influence euclidean distance between discrete probability distributions is only insightful in a relative sense and normalized between 0 and 1 for comparing two separate networks fig 5 summarizes the normalized strength of influence of variables directly linked to fib levels in the dag for the prediction of fib levels it is evident that each predictor has variable importance or influence depending on the location general trends are observed that water temperature and conductivity are strongly associated with fc or e coli levels strength of influence between turbidity and fc was significantly higher with corresponding lower strength with conductivity for the nechako river site at prince george compared to other locations this site is surrounded by mostly by urban settlement along with some forested areas as determined qualitatively by a land use map from agriculture and agri food canada government of canada 2010 however other monitoring sites with significant surrounding settlement such as fraser river at gravesend did not display the same relationship between fc and turbidity all other sites were observed to show a substantial degree of influence between conductivity and fc similar conclusions can be drawn from e coli results fig 5 b where conductivity was observed to have more consistently strong associations conductivity is a standard indicator of disturbances to an aquatic water body with elevated conductivity over background levels occurring due to runoff from urban areas sewage impacts and other landscape disturbances morgan et al 2012 these events that would result in increased conductivity are also expected to raise fc or e coli levels cho et al 2016 the results from the bbn suggest that for all sites except for the nechako river conductivity is a better indicator of fc levels compared to turbidity two well divided categories of sites can be identified based on the direct importance of seasonality on fc or e coli levels generally more areas with more settlement including the fraser river nechako river and sumas river had weak relationships between seasonality and fib in contrast watersheds with significant amounts of forest cropland or grassland coverage including the cheakamus river okanagan river and similkameen river had stronger relationships with seasonality government of canada 2010 it is hypothesized this distinction is exemplifying the possible sources of fc for each site either from land runoff or growth direct input into the water body dependence of possible growth or die off of fc and e coli with seasonality and temperature have been previously identified cho et al 2016 it was anticipated that surface runoff after rainfall would be expected to increase fib levels in surrounding water bodies eregno et al 2018 surrounding land use and characteristics will impact the pollutants introduced from surface runoff with some evidence that flushing from urban areas will increase turbidity but not fib to a significant level hathaway and hunt 2011 however increasing surface permeability in urban areas has also been observed to reduce fib in stormwater following rainfall tota maharaj and scholz 2010 results of this study based on the strength of relationships in the bbn identified the inconsistent impact on the relationship between fib and predictors across monitoring sites it was observed that typically the fib levels were either impacted more strongly by precipitation on the sampling day or over the last 3 days while this is a hypothesized function of surrounding land use the relationships are not clear from the results of this study for example two monitoring sites in predominantly agricultural areas okanagan river and sumas river show opposite trends with precipitation and fc levels this is possibly a function of agricultural practices in the area flow rates and distance from settlement areas which should be captured in future work results for e coli are distinct between the fraser river and englishman river vs cheakamus river on a qualitative basis there is a greater settlement area surrounding the first two sites in contrast to the cheakamus river which is predominantly surrounded by forested land the cheakamus river monitoring site is downstream of the wastewater outfall from the resort municipality of whistler this may explain the lack of importance of precipitation on e coli levels and the importance of seasonality for this site average e coli levels in the winter were 224 cfu 100 ml compared to 3 cfu 100 ml in the summer which corresponds with the highest effluent flows during winter months resort municipality of whistler 2018 4 conclusions initial analysis of linear correlations between water quality measures weather conditions and fib levels in surface waters identified the complex and variable nature of these relationships this exemplifies the challenge in building a predictive model for fib primarily if based on generalized expected mechanisms such as increasing water temperatures being associated with a higher level of microbiological activity using bbns accuracy for 4 bin classification of fecal coliforms 81 accuracy for all sites compared to conventional and previously investigated modelling approaches 49 accuracy for all sites was achieved furthermore for the binary prediction of e coli exceeding a threshold of 20 cfu 100 ml accuracy was greater than 90 a unique advantage of bbns is the ability to make probabilistic based decisions from incomplete data for a separated test set e coli predictions were most accurate when complete data was utilized and identifies significant value in incorporating weather conditions into predictive fib models however it was observed that water quality surrogates were particularly essential and prediction accuracy was impacted to a lesser degree when weather data were excluded based on the strengths of influence within the bbn the importance of water quality measures was further reinforced with consistent high relationship strengths between fib and conductivity measures however the overall importance of analyzed variables was highly variable between sites and is hypothesized to be due to site specific conditions such as land use or overall interactions with the watershed as such this work suggests a strong need for site specific models and further work to incorporate land use directly into the bbn real time knowledge of fib levels in natural waters is of significance to environmental management as well as a wide range of water uses accurate predictive models can ultimately assist in protecting public health through improving the information for developing risk assessments or setting precise drinking water treatment targets this work shows significant promise of bbns for providing accurate fib predictions and producing an interpretable and flexible model declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by the natural sciences and engineering research council of canada nserc discovery grant program appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 115349 
18306,to better control and manage harbor water quality is an important mission for coastal cities such as new york city nyc to achieve this managers and governors need keep track of key quality indicators such as temperature ph and dissolved oxygen among these the biochemical oxygen demand bod over five days is a critical indicator that requires much time and effort to detect causing great inconvenience in both academia and industry existing experimental and statistical methods cannot effectively solve the detection time problem or provide limited accuracy also due to various human made mistakes or facility issues the data used for bod detection and prediction contain many missing values resulting in a sparse matrix few studies have addressed the sparse matrix problem while developing statistical detection methods to address these gaps we propose a deep learning based model that combines deep matrix factorization dmf and deep neural network dnn the model was able to solve the sparse matrix problem more intelligently and predict the bod value more accurately to test its effectiveness we conducted a case study on the nyc harbor water based on 32 323 water samples the results showed that the proposed method achieved 11 54 17 23 lower rmse than conventional matrix completion methods and 19 20 25 16 lower rmse than traditional machine learning algorithms keywords biochemical oxygen demand deep matrix factorization deep neural network sparse matrix harbor water 1 introduction 1 1 background harbor water which refers to a body of water sheltered by natural or artificial barriers is one of the most important surface water sectors hellweger et al 2004 for cities such as new york san francisco hong kong and shanghai the harbors receive most of the urban stormwater and municipal wastewater ma and cheng 2016b however in some cases such effluent has received little treatment and causes various kinds of water pollution in the city harbors bacteria excessive nutrients toxic chemicals and other pollutants can make swimmers sick and also endanger marine life hua et al 2008 to reduce such dire impacts on the environment city managers have devoted considerable effort to control and improve harbor water quality for example new york city has invested more than 12 billion in the last decade to upgrade the city sewer system and reduce the environmental impact on harbor water o neil et al 2016 san francisco has appropriated over 50 million to the san francisco bay water quality improvement fund since 2008 beck et al 2018 hong kong had pushed different kinds of master plans including a polluter pays policy for the protection of harbor water hua et al 2008 to better control and manage harbor water quality it is essential to keep track of the key quality indicators such as temperature dissolved oxygen ph nutrients and metals hellweger et al 2004 many of these water quality indicators can now be detected through modern sensors in a real time manner zhu et al 2018 however there is one key indicator that reveals not only critical information about water quality but also requires much time and effort to detect the biochemical oxygen demand bod indicator jouanneau et al 2014 this parameter is defined as the amount of dissolved oxygen demanded by aerobic biological organisms to break down organic material in the water at a particular temperature usually 20 c over a specific period usually five days and marked as b o d 5 jouanneau et al 2014 if the bod is too high the dissolved oxygen can be depleted making it difficult for aerobic organisms to survive ma and cheng 2016c therefore it is essential to measure b o d 5 when monitoring water quality although b o d 5 provides valuable information the time constraints associated with the measurement impose potential limitations according to the standards jouanneau et al 2014 the holding time for a bod sample is 48 h from collection and the test itself requires a five day incubation period cheng and ma 2015b such a temporal constraint causes various kinds of drawbacks for management and research jouanneau et al 2014 and the problem has drawn a lot of attention 1 2 literature review existing literature on this topic in recent years can be classified into two groups the first group involves chemical or electrochemical measurement focusing on improvements in the standard reference method from various aspects such as increasing the stability and accuracy simplifying the procedure reducing the working area or enlarging the measurement ranges jouanneau et al 2014 zhu et al 2018 commonly used methods include the reference method the modified reference method and the photometric method xiong et al 2006 mcdonagh et al 2001 klimant et al 1995 the advantage of these methods is that they are very stable and can provide real b o d 5 values however the problem remains that these methods do not address the time issue in the standard method and the applicability is still limited compared with the first group the second group of methods is more mathematical and this type of detection is referred to as the soft sensor method zhu et al 2018 the methods do not directly detect the bod values but use statistical models or machine learning algorithms to predict the bod values based on other easy detectable indicators for example noori et al 2015 analyzed the uncertainty for online prediction of b o d 5 using support vector machine svm heddam et al 2016 proposed a generalized regression neural network grnn to predict the concentration of effluent biochemical oxygen demand b o d e f f based on five other water indicators zhu et al 2018 predicted the b o d 5 values for conventional water reclamation plants wrp using a hybrid model that combines multiple linear regression mlr and artificial neural network ann many of these methods have reported good prediction accuracy with an r 2 value higher than 0 7 because of convenient procedures that provide acceptable accuracy these approaches have become more prevalent in recent years however most of the reported soft sensor methods rely on traditional linear based statistical models such as mlr or traditional machine learning algorithms such as ann or svm and their modeling accuracy is not state of the art few studies have explored the capability of advanced deep learning technologies in predicting b o d 5 values due to the rapid development in artificial intelligence ai deep learning has become one of the hottest techniques in recent research on smart city and water management ma et al 2019e it has re formed many research domains such as imaging processing language processing smart city and urban computing ma et al 2019b studies that experiment with deep learning networks on bod prediction are necessarily required to explore state of the art performance another issue in the existing research on soft methods is the lack of study on exploring the sparse matrix the term sparse matrix means that the data used for training predicting bod have a large number of missing values in fact the raw data from the nyc harbor water in this experiment have a overall sparsity degree or missing rate of 63 20 most of the reported procedures on managing missing values would either selectively pick the experimental samples and features while excluding those with high rates of missing values or using basic statistics mean median or mode to impute the missing values fijani et al 2019 ma and cheng 2017 ma et al 2019a these methods and procedures either introduce considerable noise when there are many missing values or result in a smaller dataset therefore methods that are more intelligent in dealing with the sparse matrix problem in b o d 5 detection need to be developed 1 3 objectives this study was undertaken to address the limitations mentioned above the authors propose a deep learning model that integrates deep matrix factorization dmf and deep neural networks dnn to soft detect and predict b o d 5 values the main objective of this study is to test the following two hypotheses 1 the proposed deep learning based method is expected to provide more accurate results on the soft detection of b o d 5 than the results from traditional statistical methods and machine learning algorithms 2 the proposed dmf and dnn method is better at handling missing value sparse matrix problems than the traditional methods to achieve the objectives we conducted some numerical experiments on the nyc harbor water samples results showed that the proposed method was able to achieve 17 23 lower rmse compared with the traditional mean value imputation and 25 16 lower rmse compared with traditional machine learning algorithms like svm the following article is structured as follows section 2 introduces the proposed methods section 3 presents a case study in nyc section 4 presents the results section 5 and section 6 provide discussion and conclusions 2 methodology fig 1 presents the methodology framework of this study which consists of two parts 1 data collection and preprocessing and 2 dmf dnn modeling preprocessing cleans and processes the data into a format that is more convenient for modeling and commonly seen procedures include noise removal data normalization and feature selection the methods in these procedures are typical in data mining so they are not discussed in detail here 2 1 dmf dnn model the dmf dnn model is the core part of the proposed methodology the functionalities of this model lie in two aspects the first is using dmf to reform the sparse matrix into a full matrix the second is the prediction of b o d 5 using dnn as shown in fig 1 this study integrates these two networks dnn uses the full matrix generated by dmf to train the model for b o d 5 prediction and dmf uses the model loss calculated in the end dnn model to adjust and optimize its parameters the whole model is developed based on deep learning technologies both dmf and dnn are more complex networks than the traditional ann the traditional ann is a three layer structure including the input layer the hidden layer and the output layer it uses a back propagation technique to calculate the weights and the bias ma and cheng 2016a theoretically deeper networks have more potential to produce better results jun and cheng 2017 although limited studies have explored the applicability of deep learning in bod prediction other topics in water research have pioneered some studies using deep learning for example isikdogan et al 2017 used deep learning to map a surface water area based on satellite data pan et al 2018 implemented deep learning to observe and predict water levels chen et al 2018 identified the water bodies in an urban map using deep learning techniques and achieved 99 14 accuracy 2 1 1 deep matrix factorization dmf as mentioned before a vital contribution in this study is to address the sparse matrix problem using a deep learning technique namely deep matrix factorization dmf fan and cheng 2018 the sparse matrix is in fact the problem of matrix completion it refers to recovering the missing entries through the observed entries wen et al 2012 traditionally researchers would use the mean median value to fill the missing positions feature by feature ma and cheng 2016b this method of matrix completion overlooks the diversity of the real world data and therefore the generalizability is limited especially when the sparsity degree is large in computer science scholars uses a more advanced group of methods called matrix factorization mf fan and cheng 2018 mf has been reported to obtain excellent performance in recommendation systems or image recovery the basic concept of mf involves decomposing the matrix m r m n into the linear product of two rectangular matrices p r m r and q r r n based on the least square approach however the problem of the traditional mf is the linear transformation it does not fit the nonlinearity in real world problems to solve this fan and cheng 2018 proposed the implementation of artificial neural network ann to model the product of the two matrices non linearly equation 1 presents the mathematical format 1 m p q g w q b where g x is the activation function w and b are respectively the weight vector and the bias vector in the ann layer the optimization problem can then be formalized into equation 2 2 min f q 1 2 n i x g w q b 2 β 2 n q 2 λ 2 w 2 where x is the initialized low dimension matrix λ and β are parameters and is the hadamard product equation 2 can be viewed as a single layer ann mf the proposed deep neural network based matrix factorization deep matrix factorization or dmf method upgrades the network deeper fig 2 shows the structure of dmf in this study like typical ann networks it consists of three kinds of layers the input layer the latent input vector the hidden layer and the output layer since mf is a procedure for generating a high dimension matrix based on a low dimension initial matrix the number of neurons in each layer should be increasing this means 3 r h 1 h 2 h k m n where r is the dimension of the neurons in the initial matrix and the h i values represent the dimensions of the neurons in hidden layers in dmf the most significant difference between dmf and a typical deep neural network dnn is that for dnn the inputs are known while for dmf the initial matrix is unknown fan and cheng 2018 in most cases zero vectors are used in practice fan and cheng 2018 and this is also how ann initializes its weights another difference between ann and dmf is in the supervising target generally ann dnn uses the model label to optimize the parameters ma et al 2019c while for dmf as shown in fig 2 the loss is calculated using the error between the known values and the imputed values at the same positions fan and cheng 2018 because the loss at the missing value positions is unknown therefore popular ann techniques like mini batch gradient descent mbgd are no longer efficient in dmf fan and cheng 2018 another novel point in the proposed dmf part is the end to end optimization the traditional ways of mf testing often cause an over fitting problem which means it is optimized well for the existing values but sacrifices accuracy on the missing values and eventually leads to a larger prediction error fan and cheng 2018 our study therefore proposes a separated procedure but an end to end method for the weights and parameters for dmf when dmf updates and trains its weights and bias its error loss is from the error between the known values and the imputed values at the same positions in testing the algorithm parameters of dmf this study uses the error loss calculated in the whole dmf dnn model so the probability of over fitting drops 2 1 2 deep neural network dnn after matrix completion typical training and testing of the regression models is required and we implemented deep neural network dnn dnn is an artificial neural network with multiple layers between the input and output layers schmidhuber 2015 besides the deeper structures the main difference between dnn and traditional ann lies in two aspects first is the activation function where ann models usually use sigmoid softsign or tanh functions to activate the results in each layer however as the network gets deeper and deeper these activation functions may not help the model converge therefore increasing the difficulty in training schmidhuber 2015 in deep learning many other advanced activation functions have been proposed to address the problem commonly seen techniques include relu prelu elu schmidhuber 2015 ioffe and szegedy 2015 our study implemented elu in the proposed dnn because it combines the advantages of relu and sigmoid as shown in fig 3 elu not only avoids the hard value problem ioffe and szegedy 2015 in the left relu but also adds adjustable parameters to increase the robustness to noise a more detailed comparison between these techniques is presented in the case study the second important difference is the inclusion of the batch normalization bn layer this technique is proposed by google ioffe and szegedy 2015 to target the problem of convergence in deep learning the idea of bn is to normalize the outputs of every layer in dnn using the following equation 4 x i ˆ x i μ b σ b 2 ε where μ b and σ b are the batch mean and the batch standard deviation of the original layer outputs ε is a non zero small number used to avoid 0 denominators after normalization the bn layer then models and outputs its values using equation 5 5 y i b n γ β x i γ x i ˆ β where γ and β are respectively the weights and the bias in the bn layer as shown in fig 4 bn can effectively help avoid the models falling on the dead flat zone ioffe and szegedy 2015 and therefore reduces the probability of having no convergence and over fitting in this case it has a better tolerance for high learning rates and therefore reduces the difficulty for parameter optimization and also decreases the training time therefore this study proposes a dnn network combining elu activation and bn layers fig 5 presents the structure of the dnn network in this study the inputs are the results of the dmf network fc means the fully connected layer typical ann layer bn and elu are only implemented in the hidden layers while for the output layer the typical sigmoid activation function is used this design is developed because the output layer has only one neuron with a 0 1 output range 3 case study 3 1 data collection to test the effectiveness of the proposed methodology framework we conducted a case study in new york city nyc the data were collected from nyc open data and include the harbor water quality data from 87 sampling locations up to 2018 these stations are scattered throughout the new york harbor area fig 6 after removing the records that did not have bod data we obtained 32 608 samples in total and the mean b o d 5 value of these samples is 2 42 mg l table 1 3 2 preprocessing to better fit the model the collected data samples need to be preprocessed first preprocessing in this study included noise removal and data normalization after an inspection of the b o d 5 data we found there were extreme values that seemed to be abnormal these extreme values might result from recording mistakes or abnormal situations both of which were not helpful when modeling and analyzing the data for general insights therefore we applied the three sigma rule to remove the outliers based on the b o d 5 value the three sigma rule is a statistical method that has been widely used to detect outliers ma and cheng 2017 the samples with extreme values that are more than three times of standard deviation away from the mean values either higher or lower are defined as outliers and they were excluded in the following experiments the equation format of the outliers is shown as follows 6 v o u t l i e r s v i v i μ 3 σ v i μ 3 σ where μ and σ are the mean and standard deviation of the variable a statistical summary of the b o d 5 values before and after noise removal is shown in table 1 besides the noise removal the features and the target were normalized into 0 1 based on the following min max transformation to facilitate the nonlinear transformation in the proposed dmf model 7 v i v i v m i n v m a x v m i n where v is the normalized value and v m i n and v m a x are the minimum and maximum values of the feature another problem with the collected samples is data sparsity due to human mistakes or other issues the recorded data set has many missing values table 2 summarizes the sparsity of each feature almost all of the critical features have missing values and the missing rates range from 0 05 to 0 96 and more than half of the features have more than 80 of the values missing the overall missing rate for the collected 32 323 samples is 63 20 this number means for the collected 32 323 samples they all have b o d 5 values but their features such as ph and transparency on average have 63 20 missing values large amounts of missing values can cause significant problems in modeling and forecasting the b o d 5 values therefore the dmf dnn model is proposed 3 3 experiment setup after preprocessing the samples can be used in the dmf dnn model for the experiment by setting the b o d 5 values as the targets and other features in table 2 as the variables in this way the performance of dmf dnn on the dataset with a missing rate of 63 20 can be tested however this can only test the hypothesis that the proposed model performs better than traditional methods when the missing rate is as high as 63 20 what will be the performance when the missing rates are lower is the method robust enough to deal with different levels of missing rates to explore these questions we need to test the extended hypothesis that the proposed model performs better than traditional methods with different missing rates to verify this hypothesis we used a sparse matrix segmentation sms method to set up the experimental datasets assume the features used to train and predict b o d 5 form matrix m r m n m can be expressed as follows 8 m s 1 s 2 s n where s i r m 1 refers to a sample case n is the total number of samples and m is the total number of features the traditional way of calculating sparsity f t s divides the number of blanks missing values in the matrix by the total number of the elements cheng and ma 2015a the calculation is given as follows 9 f t s m n m m n where n m refers to the number of missing blanks in the matrix the proposed sms method f s m s can select samples under different sparsity thresholds and form a new dataset the calculation is shown in equation 10 10 f s m s m ρ s i s i m f t s s i ρ where ρ is the threshold of the sample sparsity f t s s i represents the sparsity of a sample and f s m s m ρ filters out the samples that have a sparsity degree lower than ρ it can be inferred from equation 10 that smaller ρ selects samples with fewer missing values while larger ρ provides a dataset with larger sparsity when ρ 1 all the samples in the original dataset are selected after applying the sms method using different values of ρ the original dataset in table 1 is transformed into ten datasets as shown in table 3 note that ρ in table 3 is the sparsity threshold of a single sample while the sparsity degree missing rate in table 3 refers to the percentage of missing blanks in the generated dataset for example the line ρ 0 6 in table 3 means 6313 samples have sparsity lower than 0 6 and the overall sparse degree or missing rate of the 6313 samples is 0 3919 table 3 indicates that when ρ 0 there will be no features and samples so there is no need to discuss this case further also when ρ 0 8 all the 32 323 samples are included so there is no need to analyze ρ 0 9 or 1 0 as well as a result the following experiments were conducted on the eight data sets when ρ was 0 1 0 8 after data segmentation the proposed dmf dnn model was applied to the eight different data sets as mentioned in section 2 the dmf dnn parameters significantly affect the model performance therefore these parameters need to be tuned for a better result the initial parameters of the model were as follows epochs was 1000 the structure of the dmf network was 15 18 21 24 the hidden layer structure of dnn was 64 64 the activation function was the sigmoid function the optimizer used adam and the early stop mechanism was also applied schmidhuber 2015 the model performance of this initial set of parameters is shown in table 4 from which it can be seen that as ρ increases the model performance drops this phenomenon is quite reasonable since samples with higher sparsity provide less information for the model to learn the best performing model is the one for samples with sparsity less than 0 1 where the r 2 can reach 0 9013 note that the results were calculated based on the samples generated in table 3 using a 7 3 training and testing partition the calculation results in the following contents are all based on the testing datasets because for training data the numbers are usually overfitted and can be misleading 4 optimization and results 4 1 dmf optimization after obtaining the initial models for different ρ values the procedure for optimization is conducted first is the dmf network as introduced in section 2 this part is mainly designed to address the sparsity problem based on the performance of the testing sets using the end to end dmf dnn model the following parameters in dmf were optimized using the data set when ρ 0 1 as an example for illustration 1 epoch epoch learning rate and iterations are three crucial parameters for deep learning fan and cheng 2018 ioffe and szegedy 2015 usually scholars use a relatively small learning rate but a sizable maximum epoch by using the early stop mechanism the model can obtain an optimal setting however in this study the dmf network is trained using the existing values in the data set but is tested and optimized by the end prediction model the mechanism is different from the dnn part and therefore the optimal epochs cannot be detected early and the iterations cannot be stopped in time as a result the epochs for dmf need to be identified individually using an end to end method we tested the range 20 1000 for this parameter and as in an example shown in fig 7 when e p o c h 500 the model provides optimal results on the testing dataset so the epoch is optimized as 500 for dmf also fig 7 reflects the advantage of the proposed end to end method if dmf uses its own loss to find the optimal value it will pick e p o c h 1000 which makes the whole model error increase to 0 0586 and it is clearly resulting in overfitting 2 network structure this parameter refers to the number of layers and the number of neurons in each hidden layer the layers and neurons provide the framework of the network this study followed the approach by fan and cheng 2018 implementing an arithmetic progression route to optimization since this dataset has 26 features the number of the neurons in the dmf output layer is 26 by setting different common differences between successive members the combinations shown in table 5 were tested for example for ρ 0 1 the optimal value occurred when the structure of dmf was set as 10 18 26 indicating ten neurons in the first layer 18 in the hidden layer and 26 in the output layer 3 activation functions we also tested the influence using different activation functions including linear sigmoid softsign tanh relu prelu elu the results for ρ 0 1 are shown in fig 8 the best performance sigmoid 0 0527 was 15 better than the worst relu 0 0620 in rmse 4 2 dnn optimization after optimization on the dmf network the dnn part was optimized although both structures belong to the deep learning domain the optimizations between dmf and dnn are somewhat different following some existing studies schmidhuber 2015 ma and cheng 2016b shen 2018 we optimized the following parameters in dnn on the models upgraded in the last section note that the results are also from the models when ρ 0 1 as an example 1 hidden layer structure for dnn the number of neurons in the input layer equals to that of the dmf output layer so the remaining part in the dnn structure referred to the hidden layers differing from dmf we set the number of neurons in each dnn hidden layer the same in order to simplify the structure shen 2018 and different combinations of n l a y e r and n n e u r o n s per layer were tested the model with four hidden layers and 512 neurons in each layer provided the optimal result table 6 2 activation functions the same as for the dmf network this study also tested the performance of different activation functions for dnn fig 9 shows the results differing from dmf here elu performed the best with the lowest rmse 3 batch normalization bn this is a technique that normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation such an approach can reduce the complexity of the gradient descent and therefore potentially improve the performance ioffe and szegedy 2015 the effectiveness of bn in our model was also tested results show that the inclusion of bn can significantly improve the rmse and r 2 performance of the models under different ρ values table 7 especially when ρ 0 1 0 2 0 4 0 6 0 8 r 2 values of the no bn models even become negative according to the definition of r 2 in equation 11 negative values happen when the estimations of the model have larger variances than the mean estimator perform worse such a phenomenon may occur because the un normalized values are harder to converge and probably require more iterations or further adjustments 11 r 2 1 y i y i 2 y i y 2 where y i is the estimated output of the model and y is the mean value of y i s after the optimizations on the dmf dnn model we obtained a set of results under different sparsity thresholds as shown in table 8 the improvements over the models with initial settings were also calculated and it can be seen that 1 the rmse improvements range from 5 to 16 and as the sparsity level increases the improvements from the parameter optimization decreases this phenomenon is understandable because when the data become more sparse the limitation from having less information becomes more severe while the room for algorithm optimization gets smaller on the other hand 2 the r 2 values also improved after the optimizations but differing from the rmse values their improvements became higher as ρ increased this phenomenon shows that parameter optimizations can help the proposed model outperform the mean estimator more when the sparsity gets larger overall the experiments and results presented in this section proved one aspect that has been overlooked in some similar deep learning related studies ma and cheng 2016b zhu et al 2018 parameter optimization deep learning is more than just implementing the existing models for different problems in water research parameter optimization is essential in our experience a proper setting may help deep learning provide 5 20 better results however in deep learning the optimization process is more like a black box problem and can sometime be very difficult and time consuming to find the global optimum different optimization strategies can help to get closer we implemented a grid search like strategy in optimizing the parameters which in mathematically speaking was not very efficient ma et al 2019d further research should be conducted to explore more efficient ways for this task 5 discussion the previous section presented the optimized prediction outcomes on b o d 5 based on sparse data sets using the proposed dmf dnn model however does the model outperform other existing methods on the sparse matrix to investigate this question we conducted several other experiments 5 1 other methods on filling sparse matrix the proposed dmf dnn model has two functionalities the first is filling the sparse matrix and the second is predicting b o d 5 based on the filled data sets therefore we separate the comparison into different filling methods and different prediction methods for different matrix filling methods this is in fact the missing value problem since the data set in this study is quite sparse a proper filling method can very much affect the prediction performance commonly seen methods for the sparse matrix include constant filling methods model based filling methods and matrix decomposition methods fan and cheng 2018 wen et al 2012 cheng and ma 2015b constant filling methods use a constant estimator such as zeros the mean value and the median value to fill all the missing values model based methods construct regression models or supervise learning models using different machine learning deep learning algorithms like support vector regression svr k nearest neighbor knn artificial neural network ann and gradient boosted decision trees gbdt ma and cheng 2016b witten et al 2016 matrix decomposition md methods involve factorization of a matrix into a product of matrices commonly seen approaches include matrix factorization mf and singular value decomposition svd fan and cheng 2018 the proposed dmf is also one kind md method but incorporated with more nonlinearity and a powerful modeling ability using deep learning table 9 presents the prediction performance of different dnn models that utilize different matrix filling methods note that for the mean and the median in the constant filling methods the missing values are filled using the mean or median values of the corresponding feature instead of the whole matrix for model based methods the target is the feature with missing values and the variables are the other features if the variables have empty values they are initialized using feature means and updated using the model predictions since nineteen of the features here contain missing values for each model based methods nineteen models will be built to fill the values it can be seen from table 9 that 1 the mean imputation method has the highest rmse and lowest r 2 while the proposed dmf has the lowest rmse and the highest r 2 the rmse improvement is around 17 23 which supports the effectiveness of the proposed dmf dnn model 2 for different method types the md methods have the best average performance the model based methods second and the constant filling methods the last this comparison reflects one possible conclusion that in spite of some model based methods such as gbdt having also achieved acceptable performance the md methods are more capable of dealing with high sparse matrix on average 3 dmf outperforms svd and mf in the md methods this improvement is also understandable because dmf is a nonlinear deep learning method while the other two rely more or less on linear assumptions 5 2 other prediction methods besides the different filling methods we also compared other different prediction methods as shown in table 10 the compared prediction methods in this study can also be classified into three categories traditional linear methods nonlinear machine learning algorithms ml and neural networks nn each type of method contains several commonly used algorithms including lr lasso ridge svr rf gbdt it can be seen from table 10 that 1 on average nn has the best performance with the lowest rmse and the highest r 2 ml the second and the linear methods the last this is reasonable since both ml and nn can handle nonlinear modeling and have a better fit on real world problems 2 for the tested ann and dnn dnn achieved 23 89 lower rmse and 24 04 higher rmse these improvements proved the effectiveness of the advanced features in deep nns including the deeper structure the bn layers and the advanced activation functions 5 3 suggestions to the nyc government the study of the data sparsity and the prediction of b o d 5 can provide some practical suggestions to the nyc government for example fig 10 presented the inverse distance weighted idw spatial interpolation of some important indicators in this study including the distribution of rmse feature sparsity and b o d 5 values for better presentation the figures are drawn based on the water area in nyc with 500 m buffered region these figures reveal some interesting discoveries 1 it can be seen from fig 10 b that areas b d and f have relatively higher rmse by referring to the sparsity map in fig 10 c it can be inferred that the high prediction errors in b and d may result from insufficient features therefore in those areas the government should enhance the sampling coverage to obtain more data features to follow other locations 2 for area f the situation is a bit more complicated the data collected are not very sparse while the prediction rmse is high this phenomenon reflects that the water quality is more complicated than in other areas and the current factors and features are insufficient to describe the b o d 5 values there in this case the government is recommended to conduct more field experiments in this area and include more kinds of features in addition the average b o d 5 values in fig 10 d around f are also high so this area needs more attention from the government 3 area c has a high b o d 5 value a median rmse and sufficient data these characteristics reflect that the water situation there may not be very complicated but more effort is needed to control the quality 4 area a and area e are two locations that have the best water quality according to the b o d 5 values especially for area e its prediction accuracy is also very high these two locations can be the role models for quality control in nyc the data in area a is very sparse this may be because the water quality there is good and does not require much additional information to support the management overall although the nyc government has provided significant resources and effort on managing the harbor water quality our study unearthed a number of problems especially for areas f d and c and supervision and management there need to be strengthened 6 conclusions this study proposed a method for detecting the b o d 5 value in harbor water using deep learning technology the proposed method was able to deal with the sparse matrix problem using deep matrix factorization dmf a case study in nyc harbor water was conducted to verify the effectiveness of the method the results show that the method can achieve better prediction performance with lower rmse compared with traditional matrix completion methods and traditional machine learning algorithms the contributions of this study can be summarized as follows 1 this study involves pioneering research that explores the capability of deep learning technology related to bod detection the results of the case study showed significant improvements over traditional machine learning algorithms 2 to the best of the authors knowledge this is also the first study that has examined the sparse matrix problem using deep learning methods this problem is commonly encountered but was often overlooked in previous studies 3 parameter optimization is a procedure that is often overlooked in studies using deep learning techniques in water research this study proved its importance 4 by using the proposed method the case study conducted in nyc harbor water provides valuable and practical suggestions to the government on water quality control the limitation of the study mainly lies in the data quality the number of samples included in this study is not small but a large number of the samples were collected before 2010 the sampling accuracy of some water indicators in those years may not be as accurate as those from the modern sensors the old data possibly provided some noise in our study and could therefore affect the results future work can be targeted at recognizing the temporal spatial pattern of the harbor water for better management the proposed method can also be expanded to include the temporal spatial effects between different water samples declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
18306,to better control and manage harbor water quality is an important mission for coastal cities such as new york city nyc to achieve this managers and governors need keep track of key quality indicators such as temperature ph and dissolved oxygen among these the biochemical oxygen demand bod over five days is a critical indicator that requires much time and effort to detect causing great inconvenience in both academia and industry existing experimental and statistical methods cannot effectively solve the detection time problem or provide limited accuracy also due to various human made mistakes or facility issues the data used for bod detection and prediction contain many missing values resulting in a sparse matrix few studies have addressed the sparse matrix problem while developing statistical detection methods to address these gaps we propose a deep learning based model that combines deep matrix factorization dmf and deep neural network dnn the model was able to solve the sparse matrix problem more intelligently and predict the bod value more accurately to test its effectiveness we conducted a case study on the nyc harbor water based on 32 323 water samples the results showed that the proposed method achieved 11 54 17 23 lower rmse than conventional matrix completion methods and 19 20 25 16 lower rmse than traditional machine learning algorithms keywords biochemical oxygen demand deep matrix factorization deep neural network sparse matrix harbor water 1 introduction 1 1 background harbor water which refers to a body of water sheltered by natural or artificial barriers is one of the most important surface water sectors hellweger et al 2004 for cities such as new york san francisco hong kong and shanghai the harbors receive most of the urban stormwater and municipal wastewater ma and cheng 2016b however in some cases such effluent has received little treatment and causes various kinds of water pollution in the city harbors bacteria excessive nutrients toxic chemicals and other pollutants can make swimmers sick and also endanger marine life hua et al 2008 to reduce such dire impacts on the environment city managers have devoted considerable effort to control and improve harbor water quality for example new york city has invested more than 12 billion in the last decade to upgrade the city sewer system and reduce the environmental impact on harbor water o neil et al 2016 san francisco has appropriated over 50 million to the san francisco bay water quality improvement fund since 2008 beck et al 2018 hong kong had pushed different kinds of master plans including a polluter pays policy for the protection of harbor water hua et al 2008 to better control and manage harbor water quality it is essential to keep track of the key quality indicators such as temperature dissolved oxygen ph nutrients and metals hellweger et al 2004 many of these water quality indicators can now be detected through modern sensors in a real time manner zhu et al 2018 however there is one key indicator that reveals not only critical information about water quality but also requires much time and effort to detect the biochemical oxygen demand bod indicator jouanneau et al 2014 this parameter is defined as the amount of dissolved oxygen demanded by aerobic biological organisms to break down organic material in the water at a particular temperature usually 20 c over a specific period usually five days and marked as b o d 5 jouanneau et al 2014 if the bod is too high the dissolved oxygen can be depleted making it difficult for aerobic organisms to survive ma and cheng 2016c therefore it is essential to measure b o d 5 when monitoring water quality although b o d 5 provides valuable information the time constraints associated with the measurement impose potential limitations according to the standards jouanneau et al 2014 the holding time for a bod sample is 48 h from collection and the test itself requires a five day incubation period cheng and ma 2015b such a temporal constraint causes various kinds of drawbacks for management and research jouanneau et al 2014 and the problem has drawn a lot of attention 1 2 literature review existing literature on this topic in recent years can be classified into two groups the first group involves chemical or electrochemical measurement focusing on improvements in the standard reference method from various aspects such as increasing the stability and accuracy simplifying the procedure reducing the working area or enlarging the measurement ranges jouanneau et al 2014 zhu et al 2018 commonly used methods include the reference method the modified reference method and the photometric method xiong et al 2006 mcdonagh et al 2001 klimant et al 1995 the advantage of these methods is that they are very stable and can provide real b o d 5 values however the problem remains that these methods do not address the time issue in the standard method and the applicability is still limited compared with the first group the second group of methods is more mathematical and this type of detection is referred to as the soft sensor method zhu et al 2018 the methods do not directly detect the bod values but use statistical models or machine learning algorithms to predict the bod values based on other easy detectable indicators for example noori et al 2015 analyzed the uncertainty for online prediction of b o d 5 using support vector machine svm heddam et al 2016 proposed a generalized regression neural network grnn to predict the concentration of effluent biochemical oxygen demand b o d e f f based on five other water indicators zhu et al 2018 predicted the b o d 5 values for conventional water reclamation plants wrp using a hybrid model that combines multiple linear regression mlr and artificial neural network ann many of these methods have reported good prediction accuracy with an r 2 value higher than 0 7 because of convenient procedures that provide acceptable accuracy these approaches have become more prevalent in recent years however most of the reported soft sensor methods rely on traditional linear based statistical models such as mlr or traditional machine learning algorithms such as ann or svm and their modeling accuracy is not state of the art few studies have explored the capability of advanced deep learning technologies in predicting b o d 5 values due to the rapid development in artificial intelligence ai deep learning has become one of the hottest techniques in recent research on smart city and water management ma et al 2019e it has re formed many research domains such as imaging processing language processing smart city and urban computing ma et al 2019b studies that experiment with deep learning networks on bod prediction are necessarily required to explore state of the art performance another issue in the existing research on soft methods is the lack of study on exploring the sparse matrix the term sparse matrix means that the data used for training predicting bod have a large number of missing values in fact the raw data from the nyc harbor water in this experiment have a overall sparsity degree or missing rate of 63 20 most of the reported procedures on managing missing values would either selectively pick the experimental samples and features while excluding those with high rates of missing values or using basic statistics mean median or mode to impute the missing values fijani et al 2019 ma and cheng 2017 ma et al 2019a these methods and procedures either introduce considerable noise when there are many missing values or result in a smaller dataset therefore methods that are more intelligent in dealing with the sparse matrix problem in b o d 5 detection need to be developed 1 3 objectives this study was undertaken to address the limitations mentioned above the authors propose a deep learning model that integrates deep matrix factorization dmf and deep neural networks dnn to soft detect and predict b o d 5 values the main objective of this study is to test the following two hypotheses 1 the proposed deep learning based method is expected to provide more accurate results on the soft detection of b o d 5 than the results from traditional statistical methods and machine learning algorithms 2 the proposed dmf and dnn method is better at handling missing value sparse matrix problems than the traditional methods to achieve the objectives we conducted some numerical experiments on the nyc harbor water samples results showed that the proposed method was able to achieve 17 23 lower rmse compared with the traditional mean value imputation and 25 16 lower rmse compared with traditional machine learning algorithms like svm the following article is structured as follows section 2 introduces the proposed methods section 3 presents a case study in nyc section 4 presents the results section 5 and section 6 provide discussion and conclusions 2 methodology fig 1 presents the methodology framework of this study which consists of two parts 1 data collection and preprocessing and 2 dmf dnn modeling preprocessing cleans and processes the data into a format that is more convenient for modeling and commonly seen procedures include noise removal data normalization and feature selection the methods in these procedures are typical in data mining so they are not discussed in detail here 2 1 dmf dnn model the dmf dnn model is the core part of the proposed methodology the functionalities of this model lie in two aspects the first is using dmf to reform the sparse matrix into a full matrix the second is the prediction of b o d 5 using dnn as shown in fig 1 this study integrates these two networks dnn uses the full matrix generated by dmf to train the model for b o d 5 prediction and dmf uses the model loss calculated in the end dnn model to adjust and optimize its parameters the whole model is developed based on deep learning technologies both dmf and dnn are more complex networks than the traditional ann the traditional ann is a three layer structure including the input layer the hidden layer and the output layer it uses a back propagation technique to calculate the weights and the bias ma and cheng 2016a theoretically deeper networks have more potential to produce better results jun and cheng 2017 although limited studies have explored the applicability of deep learning in bod prediction other topics in water research have pioneered some studies using deep learning for example isikdogan et al 2017 used deep learning to map a surface water area based on satellite data pan et al 2018 implemented deep learning to observe and predict water levels chen et al 2018 identified the water bodies in an urban map using deep learning techniques and achieved 99 14 accuracy 2 1 1 deep matrix factorization dmf as mentioned before a vital contribution in this study is to address the sparse matrix problem using a deep learning technique namely deep matrix factorization dmf fan and cheng 2018 the sparse matrix is in fact the problem of matrix completion it refers to recovering the missing entries through the observed entries wen et al 2012 traditionally researchers would use the mean median value to fill the missing positions feature by feature ma and cheng 2016b this method of matrix completion overlooks the diversity of the real world data and therefore the generalizability is limited especially when the sparsity degree is large in computer science scholars uses a more advanced group of methods called matrix factorization mf fan and cheng 2018 mf has been reported to obtain excellent performance in recommendation systems or image recovery the basic concept of mf involves decomposing the matrix m r m n into the linear product of two rectangular matrices p r m r and q r r n based on the least square approach however the problem of the traditional mf is the linear transformation it does not fit the nonlinearity in real world problems to solve this fan and cheng 2018 proposed the implementation of artificial neural network ann to model the product of the two matrices non linearly equation 1 presents the mathematical format 1 m p q g w q b where g x is the activation function w and b are respectively the weight vector and the bias vector in the ann layer the optimization problem can then be formalized into equation 2 2 min f q 1 2 n i x g w q b 2 β 2 n q 2 λ 2 w 2 where x is the initialized low dimension matrix λ and β are parameters and is the hadamard product equation 2 can be viewed as a single layer ann mf the proposed deep neural network based matrix factorization deep matrix factorization or dmf method upgrades the network deeper fig 2 shows the structure of dmf in this study like typical ann networks it consists of three kinds of layers the input layer the latent input vector the hidden layer and the output layer since mf is a procedure for generating a high dimension matrix based on a low dimension initial matrix the number of neurons in each layer should be increasing this means 3 r h 1 h 2 h k m n where r is the dimension of the neurons in the initial matrix and the h i values represent the dimensions of the neurons in hidden layers in dmf the most significant difference between dmf and a typical deep neural network dnn is that for dnn the inputs are known while for dmf the initial matrix is unknown fan and cheng 2018 in most cases zero vectors are used in practice fan and cheng 2018 and this is also how ann initializes its weights another difference between ann and dmf is in the supervising target generally ann dnn uses the model label to optimize the parameters ma et al 2019c while for dmf as shown in fig 2 the loss is calculated using the error between the known values and the imputed values at the same positions fan and cheng 2018 because the loss at the missing value positions is unknown therefore popular ann techniques like mini batch gradient descent mbgd are no longer efficient in dmf fan and cheng 2018 another novel point in the proposed dmf part is the end to end optimization the traditional ways of mf testing often cause an over fitting problem which means it is optimized well for the existing values but sacrifices accuracy on the missing values and eventually leads to a larger prediction error fan and cheng 2018 our study therefore proposes a separated procedure but an end to end method for the weights and parameters for dmf when dmf updates and trains its weights and bias its error loss is from the error between the known values and the imputed values at the same positions in testing the algorithm parameters of dmf this study uses the error loss calculated in the whole dmf dnn model so the probability of over fitting drops 2 1 2 deep neural network dnn after matrix completion typical training and testing of the regression models is required and we implemented deep neural network dnn dnn is an artificial neural network with multiple layers between the input and output layers schmidhuber 2015 besides the deeper structures the main difference between dnn and traditional ann lies in two aspects first is the activation function where ann models usually use sigmoid softsign or tanh functions to activate the results in each layer however as the network gets deeper and deeper these activation functions may not help the model converge therefore increasing the difficulty in training schmidhuber 2015 in deep learning many other advanced activation functions have been proposed to address the problem commonly seen techniques include relu prelu elu schmidhuber 2015 ioffe and szegedy 2015 our study implemented elu in the proposed dnn because it combines the advantages of relu and sigmoid as shown in fig 3 elu not only avoids the hard value problem ioffe and szegedy 2015 in the left relu but also adds adjustable parameters to increase the robustness to noise a more detailed comparison between these techniques is presented in the case study the second important difference is the inclusion of the batch normalization bn layer this technique is proposed by google ioffe and szegedy 2015 to target the problem of convergence in deep learning the idea of bn is to normalize the outputs of every layer in dnn using the following equation 4 x i ˆ x i μ b σ b 2 ε where μ b and σ b are the batch mean and the batch standard deviation of the original layer outputs ε is a non zero small number used to avoid 0 denominators after normalization the bn layer then models and outputs its values using equation 5 5 y i b n γ β x i γ x i ˆ β where γ and β are respectively the weights and the bias in the bn layer as shown in fig 4 bn can effectively help avoid the models falling on the dead flat zone ioffe and szegedy 2015 and therefore reduces the probability of having no convergence and over fitting in this case it has a better tolerance for high learning rates and therefore reduces the difficulty for parameter optimization and also decreases the training time therefore this study proposes a dnn network combining elu activation and bn layers fig 5 presents the structure of the dnn network in this study the inputs are the results of the dmf network fc means the fully connected layer typical ann layer bn and elu are only implemented in the hidden layers while for the output layer the typical sigmoid activation function is used this design is developed because the output layer has only one neuron with a 0 1 output range 3 case study 3 1 data collection to test the effectiveness of the proposed methodology framework we conducted a case study in new york city nyc the data were collected from nyc open data and include the harbor water quality data from 87 sampling locations up to 2018 these stations are scattered throughout the new york harbor area fig 6 after removing the records that did not have bod data we obtained 32 608 samples in total and the mean b o d 5 value of these samples is 2 42 mg l table 1 3 2 preprocessing to better fit the model the collected data samples need to be preprocessed first preprocessing in this study included noise removal and data normalization after an inspection of the b o d 5 data we found there were extreme values that seemed to be abnormal these extreme values might result from recording mistakes or abnormal situations both of which were not helpful when modeling and analyzing the data for general insights therefore we applied the three sigma rule to remove the outliers based on the b o d 5 value the three sigma rule is a statistical method that has been widely used to detect outliers ma and cheng 2017 the samples with extreme values that are more than three times of standard deviation away from the mean values either higher or lower are defined as outliers and they were excluded in the following experiments the equation format of the outliers is shown as follows 6 v o u t l i e r s v i v i μ 3 σ v i μ 3 σ where μ and σ are the mean and standard deviation of the variable a statistical summary of the b o d 5 values before and after noise removal is shown in table 1 besides the noise removal the features and the target were normalized into 0 1 based on the following min max transformation to facilitate the nonlinear transformation in the proposed dmf model 7 v i v i v m i n v m a x v m i n where v is the normalized value and v m i n and v m a x are the minimum and maximum values of the feature another problem with the collected samples is data sparsity due to human mistakes or other issues the recorded data set has many missing values table 2 summarizes the sparsity of each feature almost all of the critical features have missing values and the missing rates range from 0 05 to 0 96 and more than half of the features have more than 80 of the values missing the overall missing rate for the collected 32 323 samples is 63 20 this number means for the collected 32 323 samples they all have b o d 5 values but their features such as ph and transparency on average have 63 20 missing values large amounts of missing values can cause significant problems in modeling and forecasting the b o d 5 values therefore the dmf dnn model is proposed 3 3 experiment setup after preprocessing the samples can be used in the dmf dnn model for the experiment by setting the b o d 5 values as the targets and other features in table 2 as the variables in this way the performance of dmf dnn on the dataset with a missing rate of 63 20 can be tested however this can only test the hypothesis that the proposed model performs better than traditional methods when the missing rate is as high as 63 20 what will be the performance when the missing rates are lower is the method robust enough to deal with different levels of missing rates to explore these questions we need to test the extended hypothesis that the proposed model performs better than traditional methods with different missing rates to verify this hypothesis we used a sparse matrix segmentation sms method to set up the experimental datasets assume the features used to train and predict b o d 5 form matrix m r m n m can be expressed as follows 8 m s 1 s 2 s n where s i r m 1 refers to a sample case n is the total number of samples and m is the total number of features the traditional way of calculating sparsity f t s divides the number of blanks missing values in the matrix by the total number of the elements cheng and ma 2015a the calculation is given as follows 9 f t s m n m m n where n m refers to the number of missing blanks in the matrix the proposed sms method f s m s can select samples under different sparsity thresholds and form a new dataset the calculation is shown in equation 10 10 f s m s m ρ s i s i m f t s s i ρ where ρ is the threshold of the sample sparsity f t s s i represents the sparsity of a sample and f s m s m ρ filters out the samples that have a sparsity degree lower than ρ it can be inferred from equation 10 that smaller ρ selects samples with fewer missing values while larger ρ provides a dataset with larger sparsity when ρ 1 all the samples in the original dataset are selected after applying the sms method using different values of ρ the original dataset in table 1 is transformed into ten datasets as shown in table 3 note that ρ in table 3 is the sparsity threshold of a single sample while the sparsity degree missing rate in table 3 refers to the percentage of missing blanks in the generated dataset for example the line ρ 0 6 in table 3 means 6313 samples have sparsity lower than 0 6 and the overall sparse degree or missing rate of the 6313 samples is 0 3919 table 3 indicates that when ρ 0 there will be no features and samples so there is no need to discuss this case further also when ρ 0 8 all the 32 323 samples are included so there is no need to analyze ρ 0 9 or 1 0 as well as a result the following experiments were conducted on the eight data sets when ρ was 0 1 0 8 after data segmentation the proposed dmf dnn model was applied to the eight different data sets as mentioned in section 2 the dmf dnn parameters significantly affect the model performance therefore these parameters need to be tuned for a better result the initial parameters of the model were as follows epochs was 1000 the structure of the dmf network was 15 18 21 24 the hidden layer structure of dnn was 64 64 the activation function was the sigmoid function the optimizer used adam and the early stop mechanism was also applied schmidhuber 2015 the model performance of this initial set of parameters is shown in table 4 from which it can be seen that as ρ increases the model performance drops this phenomenon is quite reasonable since samples with higher sparsity provide less information for the model to learn the best performing model is the one for samples with sparsity less than 0 1 where the r 2 can reach 0 9013 note that the results were calculated based on the samples generated in table 3 using a 7 3 training and testing partition the calculation results in the following contents are all based on the testing datasets because for training data the numbers are usually overfitted and can be misleading 4 optimization and results 4 1 dmf optimization after obtaining the initial models for different ρ values the procedure for optimization is conducted first is the dmf network as introduced in section 2 this part is mainly designed to address the sparsity problem based on the performance of the testing sets using the end to end dmf dnn model the following parameters in dmf were optimized using the data set when ρ 0 1 as an example for illustration 1 epoch epoch learning rate and iterations are three crucial parameters for deep learning fan and cheng 2018 ioffe and szegedy 2015 usually scholars use a relatively small learning rate but a sizable maximum epoch by using the early stop mechanism the model can obtain an optimal setting however in this study the dmf network is trained using the existing values in the data set but is tested and optimized by the end prediction model the mechanism is different from the dnn part and therefore the optimal epochs cannot be detected early and the iterations cannot be stopped in time as a result the epochs for dmf need to be identified individually using an end to end method we tested the range 20 1000 for this parameter and as in an example shown in fig 7 when e p o c h 500 the model provides optimal results on the testing dataset so the epoch is optimized as 500 for dmf also fig 7 reflects the advantage of the proposed end to end method if dmf uses its own loss to find the optimal value it will pick e p o c h 1000 which makes the whole model error increase to 0 0586 and it is clearly resulting in overfitting 2 network structure this parameter refers to the number of layers and the number of neurons in each hidden layer the layers and neurons provide the framework of the network this study followed the approach by fan and cheng 2018 implementing an arithmetic progression route to optimization since this dataset has 26 features the number of the neurons in the dmf output layer is 26 by setting different common differences between successive members the combinations shown in table 5 were tested for example for ρ 0 1 the optimal value occurred when the structure of dmf was set as 10 18 26 indicating ten neurons in the first layer 18 in the hidden layer and 26 in the output layer 3 activation functions we also tested the influence using different activation functions including linear sigmoid softsign tanh relu prelu elu the results for ρ 0 1 are shown in fig 8 the best performance sigmoid 0 0527 was 15 better than the worst relu 0 0620 in rmse 4 2 dnn optimization after optimization on the dmf network the dnn part was optimized although both structures belong to the deep learning domain the optimizations between dmf and dnn are somewhat different following some existing studies schmidhuber 2015 ma and cheng 2016b shen 2018 we optimized the following parameters in dnn on the models upgraded in the last section note that the results are also from the models when ρ 0 1 as an example 1 hidden layer structure for dnn the number of neurons in the input layer equals to that of the dmf output layer so the remaining part in the dnn structure referred to the hidden layers differing from dmf we set the number of neurons in each dnn hidden layer the same in order to simplify the structure shen 2018 and different combinations of n l a y e r and n n e u r o n s per layer were tested the model with four hidden layers and 512 neurons in each layer provided the optimal result table 6 2 activation functions the same as for the dmf network this study also tested the performance of different activation functions for dnn fig 9 shows the results differing from dmf here elu performed the best with the lowest rmse 3 batch normalization bn this is a technique that normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation such an approach can reduce the complexity of the gradient descent and therefore potentially improve the performance ioffe and szegedy 2015 the effectiveness of bn in our model was also tested results show that the inclusion of bn can significantly improve the rmse and r 2 performance of the models under different ρ values table 7 especially when ρ 0 1 0 2 0 4 0 6 0 8 r 2 values of the no bn models even become negative according to the definition of r 2 in equation 11 negative values happen when the estimations of the model have larger variances than the mean estimator perform worse such a phenomenon may occur because the un normalized values are harder to converge and probably require more iterations or further adjustments 11 r 2 1 y i y i 2 y i y 2 where y i is the estimated output of the model and y is the mean value of y i s after the optimizations on the dmf dnn model we obtained a set of results under different sparsity thresholds as shown in table 8 the improvements over the models with initial settings were also calculated and it can be seen that 1 the rmse improvements range from 5 to 16 and as the sparsity level increases the improvements from the parameter optimization decreases this phenomenon is understandable because when the data become more sparse the limitation from having less information becomes more severe while the room for algorithm optimization gets smaller on the other hand 2 the r 2 values also improved after the optimizations but differing from the rmse values their improvements became higher as ρ increased this phenomenon shows that parameter optimizations can help the proposed model outperform the mean estimator more when the sparsity gets larger overall the experiments and results presented in this section proved one aspect that has been overlooked in some similar deep learning related studies ma and cheng 2016b zhu et al 2018 parameter optimization deep learning is more than just implementing the existing models for different problems in water research parameter optimization is essential in our experience a proper setting may help deep learning provide 5 20 better results however in deep learning the optimization process is more like a black box problem and can sometime be very difficult and time consuming to find the global optimum different optimization strategies can help to get closer we implemented a grid search like strategy in optimizing the parameters which in mathematically speaking was not very efficient ma et al 2019d further research should be conducted to explore more efficient ways for this task 5 discussion the previous section presented the optimized prediction outcomes on b o d 5 based on sparse data sets using the proposed dmf dnn model however does the model outperform other existing methods on the sparse matrix to investigate this question we conducted several other experiments 5 1 other methods on filling sparse matrix the proposed dmf dnn model has two functionalities the first is filling the sparse matrix and the second is predicting b o d 5 based on the filled data sets therefore we separate the comparison into different filling methods and different prediction methods for different matrix filling methods this is in fact the missing value problem since the data set in this study is quite sparse a proper filling method can very much affect the prediction performance commonly seen methods for the sparse matrix include constant filling methods model based filling methods and matrix decomposition methods fan and cheng 2018 wen et al 2012 cheng and ma 2015b constant filling methods use a constant estimator such as zeros the mean value and the median value to fill all the missing values model based methods construct regression models or supervise learning models using different machine learning deep learning algorithms like support vector regression svr k nearest neighbor knn artificial neural network ann and gradient boosted decision trees gbdt ma and cheng 2016b witten et al 2016 matrix decomposition md methods involve factorization of a matrix into a product of matrices commonly seen approaches include matrix factorization mf and singular value decomposition svd fan and cheng 2018 the proposed dmf is also one kind md method but incorporated with more nonlinearity and a powerful modeling ability using deep learning table 9 presents the prediction performance of different dnn models that utilize different matrix filling methods note that for the mean and the median in the constant filling methods the missing values are filled using the mean or median values of the corresponding feature instead of the whole matrix for model based methods the target is the feature with missing values and the variables are the other features if the variables have empty values they are initialized using feature means and updated using the model predictions since nineteen of the features here contain missing values for each model based methods nineteen models will be built to fill the values it can be seen from table 9 that 1 the mean imputation method has the highest rmse and lowest r 2 while the proposed dmf has the lowest rmse and the highest r 2 the rmse improvement is around 17 23 which supports the effectiveness of the proposed dmf dnn model 2 for different method types the md methods have the best average performance the model based methods second and the constant filling methods the last this comparison reflects one possible conclusion that in spite of some model based methods such as gbdt having also achieved acceptable performance the md methods are more capable of dealing with high sparse matrix on average 3 dmf outperforms svd and mf in the md methods this improvement is also understandable because dmf is a nonlinear deep learning method while the other two rely more or less on linear assumptions 5 2 other prediction methods besides the different filling methods we also compared other different prediction methods as shown in table 10 the compared prediction methods in this study can also be classified into three categories traditional linear methods nonlinear machine learning algorithms ml and neural networks nn each type of method contains several commonly used algorithms including lr lasso ridge svr rf gbdt it can be seen from table 10 that 1 on average nn has the best performance with the lowest rmse and the highest r 2 ml the second and the linear methods the last this is reasonable since both ml and nn can handle nonlinear modeling and have a better fit on real world problems 2 for the tested ann and dnn dnn achieved 23 89 lower rmse and 24 04 higher rmse these improvements proved the effectiveness of the advanced features in deep nns including the deeper structure the bn layers and the advanced activation functions 5 3 suggestions to the nyc government the study of the data sparsity and the prediction of b o d 5 can provide some practical suggestions to the nyc government for example fig 10 presented the inverse distance weighted idw spatial interpolation of some important indicators in this study including the distribution of rmse feature sparsity and b o d 5 values for better presentation the figures are drawn based on the water area in nyc with 500 m buffered region these figures reveal some interesting discoveries 1 it can be seen from fig 10 b that areas b d and f have relatively higher rmse by referring to the sparsity map in fig 10 c it can be inferred that the high prediction errors in b and d may result from insufficient features therefore in those areas the government should enhance the sampling coverage to obtain more data features to follow other locations 2 for area f the situation is a bit more complicated the data collected are not very sparse while the prediction rmse is high this phenomenon reflects that the water quality is more complicated than in other areas and the current factors and features are insufficient to describe the b o d 5 values there in this case the government is recommended to conduct more field experiments in this area and include more kinds of features in addition the average b o d 5 values in fig 10 d around f are also high so this area needs more attention from the government 3 area c has a high b o d 5 value a median rmse and sufficient data these characteristics reflect that the water situation there may not be very complicated but more effort is needed to control the quality 4 area a and area e are two locations that have the best water quality according to the b o d 5 values especially for area e its prediction accuracy is also very high these two locations can be the role models for quality control in nyc the data in area a is very sparse this may be because the water quality there is good and does not require much additional information to support the management overall although the nyc government has provided significant resources and effort on managing the harbor water quality our study unearthed a number of problems especially for areas f d and c and supervision and management there need to be strengthened 6 conclusions this study proposed a method for detecting the b o d 5 value in harbor water using deep learning technology the proposed method was able to deal with the sparse matrix problem using deep matrix factorization dmf a case study in nyc harbor water was conducted to verify the effectiveness of the method the results show that the method can achieve better prediction performance with lower rmse compared with traditional matrix completion methods and traditional machine learning algorithms the contributions of this study can be summarized as follows 1 this study involves pioneering research that explores the capability of deep learning technology related to bod detection the results of the case study showed significant improvements over traditional machine learning algorithms 2 to the best of the authors knowledge this is also the first study that has examined the sparse matrix problem using deep learning methods this problem is commonly encountered but was often overlooked in previous studies 3 parameter optimization is a procedure that is often overlooked in studies using deep learning techniques in water research this study proved its importance 4 by using the proposed method the case study conducted in nyc harbor water provides valuable and practical suggestions to the government on water quality control the limitation of the study mainly lies in the data quality the number of samples included in this study is not small but a large number of the samples were collected before 2010 the sampling accuracy of some water indicators in those years may not be as accurate as those from the modern sensors the old data possibly provided some noise in our study and could therefore affect the results future work can be targeted at recognizing the temporal spatial pattern of the harbor water for better management the proposed method can also be expanded to include the temporal spatial effects between different water samples declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
18307,unlike most unit processes in drinking water treatment the performance of deep bed filtration processes vary systematically on short time scales the particle removal capacity changes with time since the previous backwash even when the influent water quality is stable for microorganisms the removal efficiency may vary by orders of magnitude in this note the potential impact of such dynamics on microbial risk estimates is studied using representative experimental filtration data for viruses and bacteria in conjunction with single hit dose response models for microbial infection assuming that filtration is the only source of variation in pathogen concentrations on the time scale of a single filter cycle it is concluded that such variations are unlikely to substantially affect risk estimates except possibly in an outbreak situation with extremely high pathogen concentrations it is generally sufficient to know the mean pathogen concentrations future studies should include concurrent variation in the performance of other unit processes and raw water pathogen concentrations experimental work should focus on capturing the variation in filtration performance in order to correctly estimate mean removal rates keywords microbial risk qmra drinking water filtration dynamics 1 introduction a treatment train involving some combination of coagulation flocculation sedimentation and deep bed filtration is common in water treatment plants throughout the world while designed for removing particles and or natural organic matter nom in general coagulation filtration processes also account for a significant portion of the overall microorganism removal including pathogens hijnen and medema 2010 there are several sources of variation in the microbial removal efficiency of filtration processes variation among plants exists due to differences in design raw water quality and operational practices there may be slow variations in time e g because of a changing raw water composition throughout the year westrell et al 2006 or there may be rapid and more random variations as a result of raw water contamination events signor et al 2005 åström et al 2013 or failures in the treatment processes hijnen and medema 2010 huck et al 2002 emelko et al 2003 however superimposed on the variations already mentioned there may be systematic short term variations in removal efficiency originating from the inherently dynamic character of the deep bed filtration process during normal operation even if influent water quality characteristics remain constant typically as measured by filter effluent turbidity there is an initial period of improvement in performance as the filter begins to collect particles the ripening period followed by a period of relatively stable performance until the performance eventually deteriorates the breakthrough phase when the particle collection capacity is exhausted the filter must then be taken out of service to be backwashed so that the particle collection capacity can be restored to its initial state i e the process is discontinuous and essentially periodic these dynamic characteristics distinguish the filtration process from other typical unit processes in conventional treatment sedimentation flotation chlorination uv irradiation that are comparatively stable and uninterrupted during normal operation and when subjected to a constant influent water quality turbidity removal dynamics during filtration is not entirely representative of microbial filtration dynamics though since turbidity measurements lump the contribution of all particle types into a single parameter several studies have shown that the ripening and breakthrough behavior is dependent on among several physico chemical properties particle size clark et al 1992 kim and lawler 2008 moran et al 1993 with smaller particles typically taking longer to both ripen and break through as compared to larger particles some studies have shown a marked reduction in microorganism removal early and late in the filter cycle robeck et al 1962 harrington et al 2003 emelko et al 2003 templeton et al 2007 still studies that aim to characterize microbial removal rates of filtration processes are usually focused on typical removal rates i e removal rates during periods of stable effluent turbidity often employing sampling regimes that are unable to capture the full variation in treatment efficiency throughout the filter cycle recently we undertook a pilot scale dual media contact filtration study in an attempt to generate a high resolution sample of such microbial filtration dynamics during an entire filter cycle nilsen et al 2019 the instantaneous removal efficiency of model viruses and bacteria varied by a factor of about 50 and 200 respectively during the period when effluent turbidity was less than 0 1 ntu indicating that the dynamic character of filtration processes should not a priori be overlooked in risk assessment in quantitative microbial risk assessment qmra haas et al 2014 variations in removal rates may be modeled by fitting appropriate probability distributions to data from filter influent and effluent samples teunis et al 1999 2009 smeets et al 2008 such fitted distributions may be used together with data on raw water quality and other treatment processes to estimate the exposure of water consumers to pathogens data on exposure is subsequently used as input to dose response models haas 1983 nilsen and wyller 2016a for estimating microbial risks associated with drinking water consumption the effect of short term systematic variations in microbial filtration efficiency that are present during normal operation has received comparatively less attention in the microbial risk literature in this note we will use our example high resolution dataset nilsen et al 2019 to compute probability distributions for microorganism removal in a single filter during one filter cycle evaluate the effect on risk estimates when assuming that concentration variations from filtration persist until a point of consumption and there are no other sources of variation discuss the overall relevance of filtration dynamics for qmra in most water supply systems variation in filter effluent concentrations will be subject to smoothing by e g storage tanks and mixing of effluents from filters operating in parallel thus the assumption that variations in concentration actually reach the consumer is a limiting case i will return to this issue in the discussion 2 data and methods 2 1 example data the filtration experiment that generated the example data is reported in full elsewhere nilsen et al 2019 the experimental setup was representative of norwegian filtration practice ødegaard et al 2010 three model microorganisms were used bacteriophage ms2 icosahedral 27 nm bacteriophage salmonella typhimurium 28b icosahedral 60 nm and indicator bacterium e coli rod shaped approx 1 μm 3 μm these were chosen mainly because more data on virus removal has been sought in norway and it was relatively simple to include e coli as an additional organism the approach velocity was constant fig 1 shows the logarithm of π the instantaneous probability of passage for each organism as a function of elapsed time in the filter cycle t more precisely 1 π t c out t c in t here c out and c in are respectively the effluent and influent concentrations as number of microorganisms unit volume of the filter the commonly used log removal rate is simply log 10 π note that in formulating 1 we ignored the travel time between filter inlet and outlet which is short compared to the time scale of changes in π the strict interpretation of π as the probability of passage of a single organism requires π to be independent of both influent and attached microorganism concentrations see nilsen et al 2019 for further details the data shows that bacteria were generally removed better than viruses and the results are also consistent with expectations based on the size difference between the organisms ripening for bacteria occurred more rapidly than for viruses and bacteria broke through before viruses we define breakthrough here as the onset of persistently increasing passage both organisms broke through before turbidity though confirming that there are limitations in using turbidity as a surrogate for microorganism removal it is noted that the breakthrough of viruses is rather abrupt compared to the more gradual breakthrough of bacteria computations reported in this note were performed directly on the experimental data interpolating linearly between data points to construct a continuous function π t the most important implication for risk assessment related to filtration dynamics is probably the challenge it poses to correctly estimating mean removal efficiencies over a full filter cycle this part of the problem was studied in nilsen et al 2019 where it was shown that true mean removal efficiencies may deviate from mid cycle instantaneous removal efficiencies by more than one log10 unit the present note explores further the impact of filtration dynamics itself for qmra given that the mean removal is already known 2 2 probability distribution for π from π t filtration dynamics may induce systematic variations but these must be treated as random from a consumer s point of view since a consumer essentially samples a random volume from the water supply for use in risk assessment applications it is of interest to derive a proper probability distribution for a random variable π representing the observed variation in microbial removal efficiency during filtration some precision is needed in describing this mathematically in general a consumer is assumed to sample uniformly from the total volume produced flow proportional sampling which if the flow rate q t is non constant is not equivalent to sampling uniformly in time the flow rate was constant in our filtration experiment but that is not always how filters are operated the accumulated volume of water v t produced in the time interval 0 t is given by 2 v t 0 t q τ d τ d v d t q t since q t is positive v t is one to one and may be inverted to give a function t v when π t is given we may therefore express π as a function of v π t v and use the theory of functions of random variables appendix a to obtain the probability distribution for the random variable π t v when v is a uniformly distributed random variable on 0 v it is assumed here that the sample volume is so small that we may treat π t as constant during the time interval needed to sample a small volume 2 3 the effect of variation in π on risk estimates in qmra data on pathogen concentrations with variations are used as input to dose response models to estimate the probability of infection from drinking water since dose response models are non linear in the dose variable knowing the mean dose is generally insufficient the full dose distribution is required for a precise calculation of risk it is therefore of interest to study the effect of variations in π from filtration as it affects the dose distribution on risk estimates from dose response models the single hit dose response framework haas 1983 nilsen and wyller 2016a of which the exponential and beta poisson models are examples has served as the de facto standard modeling approach for drinking water a generic formulation is given by 3 p i 1 0 1 g x 1 r f r r d r where p i is the probability of infection g x is the probability generating function pgf of the dose variable x number of organisms ingested and f r is the probability density function pdf of the so called single hit probability r which may vary between hosts but variation between individual pathogens is integrated out fazekas de st groth and moran 1955 haas 2002 schmidt et al 2013 nilsen and wyller 2016b in the simplest case of constant pathogen concentration the dose x is taken to be poisson distributed with mean λ c v s where v s is the sample volume if concentrations vary x is typically constructed as a mixed poisson distribution with random poisson parameter λ c v s furthermore if one assumes that on the time scale of a filter cycle the only source of variation in concentrations is filtration performance one may write λ k π where k is a constant with units of dose for such mixed poisson dose distributions equation 3 can be written 4 p i 1 0 1 m λ r f r r d r 1 0 1 m π k r f r r d r where m is a moment generating function mgf and the latter equality applies when λ k π the evaluation of 4 using experimental data is treated in appendix a in order to gain an understanding of the potential effects of filtration dynamics on risk estimates the following risk ratio may be evaluated where for simplicity we have assumed a constant single hit probability r 5 p i dist p i mean 1 m π r k 1 e r k e π the numerator is the single exposure risk computed with the full distribution of λ k π the denominator is the single exposure risk computed with the exponential model with mean dose e λ k e π i e the mean dose is the same in both cases the risk computed with a mixed poisson dose distribution is always less than the risk computed with a poisson distribution with the same mean nilsen and wyller 2016b proposition 2 the treatment above assumed that x is the mixed poisson dose distribution resulting from a single exposure the risk resulting from n doses independent and identically distributed as x is given by nilsen and wyller 2016a 6 p i 1 0 1 m λ r n f r r d r 3 analysis and results 3 1 probability distribution for π from π t for given start and end times of the production period end of filter to waste and initiation of backwashing respectively the probability distribution of π may be derived from π t using the relationships described in section 2 2 and appendix a this has been done with our example data to produce fig 2 which shows cumulative distribution functions cdf for three different production periods for viruses and bacteria for viruses we have also included a comparison with a cdf derived by teunis et al 2009 they used data on f specific coliphages from two plants in the netherlands to estimate a beta distribution for the removal during coagulation filtration assuming paired influent and effluent samples and gamma distributed influent concentrations as seen in fig 2 the distribution for bacteria is generally displaced to the left compared to the viruses reflecting its better removal also seen in fig 1 the near vertical parts of the distributions stem from the near horizontal parts of the curves in fig 1 restricting the length of the production period displaces probability mass to the left it is clear that the estimated beta cdf of teunis et al 2009 is vastly more spread out than our empirical cdfs from a single filter run although the median values of π are close to each other however the data that went into estimating the beta cdf was of a very different nature high volume sampling with a subsequent concentration step two different plants only 17 samples in total than our experimental data and there was no detailed information on process characteristics or consideration of filtration dynamics the difference is nevertheless consistent with the observation that highly variable virus removal efficiencies for filtration are reported in the literature nilsen et al 2019 supplementary data such cdfs as generated here from our filtration experiment or perhaps some smoother versions of them may potentially be used as input for monte carlo simulations in detailed risk assessment models 3 2 the effect of variation in π on risk estimates plots of the risk ratio in equation 5 are shown in fig 3 a and b for viruses 28b and bacteria respectively they show the influence of 1 varying the production period by restricting the effluent turbidity and 2 the parameter r k through its effect on the exponential model risk horizontal axes also shown in fig 3a is the risk ratio computed with the beta distributed π from teunis et al 2009 for which the mgf in equation 5 becomes f 1 1 α α β r k where f 1 1 is kummer s confluent hypergeometric function and α and β are parameters of the beta distribution as dictated by theory fig 3a and b shows that the ratio in equation 5 is less than 1 we see that the effect of variation in π on risk estimates tends to be more pronounced when lesser restrictions are placed on effluent turbidity it should be noted that under normal operating conditions when the single exposure risk is typically less than 10 6 variation in π alone appears to have negligible influence on risk estimates this applies also when using the very wide π distribution from teunis et al 2009 these observations are related to the well known fact that single hit models become approximately linear at low doses variation in π only seems to become important under severe outbreak conditions when the single exposure risk is higher than 0 01 and somewhat away from 1 for fig 3b for bacteria we find the same tendencies as for viruses but slightly more pronounced due to the characteristics of the π variation as an example of an equivalent calculation using a model with a variable single hit probability r fig 4 shows the following risk ratio for norovirus 7 p i dist p i mean 1 0 1 f 1 1 α α β k π f π π d π 1 f 1 1 α α β k e π the denominator is the risk computed using the ordinary exact beta poisson model and the numerator is the risk computed with a variable π the norovirus parameters α 0 040 and β 0 055 are taken from teunis et al 2008 and gives a very dispersed distribution the results are qualitatively similar to the results in fig 3 1 1 no results are shown for the π distribution from teunis et al 2009 as the required numerical integration was problematic in matlab these figures apply to the single exposure case for the multiple exposure case n exposures we have the corresponding ratio 8 p i nd p i d 1 m π r k n 1 e n r k e π it is readily shown that this ratio increases towards 1 as n increases since m π r k e r k e π thus the effect of variations in π only tend to become less important as the number of exposures increases 4 discussion here we will first address some limitations associated with our example dataset and computational model before briefly discussing the overall relevance of filtration dynamics for risk assessment 4 1 limitations of the example data and computations 4 1 1 example data the example dataset represents the most highly resolved characterization of microbial removal in a single deep bed filter cycle that we are aware of at least for viruses the observed variation in performance throughout the filter cycle was substantial qualitatively as expected based on virus and bacteria relative sizes clark et al 1992 moran et al 1993 and is believed to represent real world phenomena occurring in water treatment plants still the data has been obtained under a single set of experimental conditions corresponding to common filtration practice in the nordic countries and is not necessarily representative of filtration processes that operate under different conditions specifically one may wish to conduct high resolution characterizations using pre sedimentation dedicated flocculation steps different filter rates declining rate filtration different filter materials different coagulants filter aids polymers and more particle rich raw water furthermore other surrogate organisms for pathogens should be tested in future high resolution characterizations 4 1 2 computations some of the limitations of the computational model that could be investigated in future research efforts include unaccounted for variation in our computations the only varying quantity on the time scale of a filter cycle was the filtration passage probability in reality there may be random variations in raw water concentrations and the performance of other unit processes e g because of operational failure that are relevant on similar time scales if such variations are present and can be taken as independent of the variation in filtration performance it will lead to increased variation in the dose distributions filters in parallel our example computations relied on the passage probabilities through a single filter in a real water treatment plant there will be a gallery of filters operating in parallel with the effluents from each filter being mixed at some downstream junction the filters will be at different stages in their filter cycles and the mixing of effluents will have a certain smoothing effect on the dose distribution a rudimentary model of such effects may be found in nilsen 2016 another effect to consider is the hydraulic step when one filter is taken out of service for backwashing the filtration rate through the remaining filters may increase and may affect the removal efficiency the effect of distribution systems the relevance of filtration dynamics depends on the extent to which the distribution system disperses pathogens and smooths out the variations that exist at the treatment plant this will likely depend on the layout of the pipe network and storage tanks in the system the distribution of water demands and the location of each individual consumer within the network dose response models single hit dose response models are routinely used for drinking water risk assessment and have been shown to fit data well for medium to high doses it is however a remaining scientific challenge to verify their applicability for low doses so that extrapolations beyond the range of observations is typically necessary for drinking water studies if the true dose response model is non linear even for low doses this will affect the results of modeling efforts where variation in doses is accounted for furthermore we considered only one case of variable single hit probability r in our examples such models are flatter than their constant r counterparts nilsen and wyller 2016a proposition 1 but qualitatively similar we do not expect the main conclusions to change with such models and further calculations not shown using equation 7 with combinations of α and β in the range 0 5 5 support this 4 2 filtration dynamics and risk assessment the existence of filtration dynamics poses two main challenges to microbial risk assessment correctly estimating the mean passage probability and hence mean pathogen concentrations and doses and the possibility that variations around the mean concentration may significantly affect risk estimates the plots in figs 3 and 4 indicate that concentration variations around the mean exert all but negligible influence in our risk model with the example dataset except possibly in a situation where pathogen concentrations approach levels associated with extreme risk and attack rates this applies even when using the π distribution from teunis et al 2009 which is significantly more spread out than our experimental π distributions we stress that this result applies to a situation where we ignore other sources of variation in the dose distribution on the time scale of a filter cycle the conclusion seems robust as several assumptions were made in this study that will overexaggerate the variation in the dose distribution including ignoring effects of parallel filters ignoring mixing in the distribution system and ignoring the effect of multiple exposures correctly estimating and minimizing the mean passage probability of deep bed filters therefore seems to be the more important aspect of filtration dynamics for risk assessment and management this aspect was studied in detail in nilsen et al 2019 for long term risk assessments it may still be useful to include empirical distributions such as those given in fig 2 into monte carlo simulations of risk the distributions in fig 2 are available from the author upon request 5 conclusions in this note we have studied the effect of short term deep bed filtration dynamics on microbial risk estimates using high resolution data on filtration performance that is believed to be representative of real world effects under the given conditions together with a simplified conceptual model under the assumption that filtration performance is the only variable quantity on the time scale of a single filter cycle it was shown that concentration variations induced by filtration are unlikely to affect risk estimates when compared with a model that uses an equivalent mean concentration except possibly in an outbreak situation with extremely high pathogen concentrations future studies should probe this result further by studying the effect of concurrent variation in filtration performance and other unit processes as well as raw water concentrations until further studies along the suggestions made above can be carried out the main consequence for qmra of systematic short term dynamic effects in microbial filtration performance is to motivate filtration experiments to correctly estimate mean passage probabilities under a wider range of conditions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements discussions with profs arve heistad and john wyller were very helpful in the preparation of this manuscript appendix a the transformation rule for functions of random variables assume that we have a random variable v with associated probability density function f v v and a differentiable function g r r that induces a new random variable π g v assume that the domain of the function g may be partitioned into n intervals such that the function g is monotonic on each interval denote the restriction of g to interval i by g i then the probability density of π is given by a 1 f π π i 1 n f v g i 1 π d g i 1 π d π it is assumed here that pr g v 0 0 if that is not the case the above rule can be generalized and the density f π π becomes a mixed discrete continuous probability distribution i e it has some point masses of probability when v is uniformly distributed on v 1 v 2 the rule simplifies to a 2 f π π 1 v 2 v 1 i 1 n d g i 1 π d π this expression may be evaluated numerically from the example experimental data in fig 1 from which the associated cumulative distributions shown in fig 2 can be computed in parentheses it is noted that this procedure closely parallels the construction of flow duration curves in hydrology now introduce another function h r 0 1 that maps π to h π for the expected value e h π we have according to a 2 and a change of variables a 3 e h π π h π f π π d π 1 v 2 v 1 v 1 v 2 h g v d v thus expectations over π are equivalent to simple averages over v when v is uniformly distributed which is of course in agreement with intuition as stated in equation 4 when the dose variable λ k π the single hit dose response model is constructed with the moment generating function mgf of π evaluated at r k the mgf of π is an expectation value on the form given in a 3 with h π e z π when π g v with v uniformly distributed the mgf of π may be computed as a 4 m π z e e z π 1 v 2 v 1 v 1 v 2 e z g v d v this quantity can be straightforwardly evaluated numerically from the example experimental data in fig 1 
18307,unlike most unit processes in drinking water treatment the performance of deep bed filtration processes vary systematically on short time scales the particle removal capacity changes with time since the previous backwash even when the influent water quality is stable for microorganisms the removal efficiency may vary by orders of magnitude in this note the potential impact of such dynamics on microbial risk estimates is studied using representative experimental filtration data for viruses and bacteria in conjunction with single hit dose response models for microbial infection assuming that filtration is the only source of variation in pathogen concentrations on the time scale of a single filter cycle it is concluded that such variations are unlikely to substantially affect risk estimates except possibly in an outbreak situation with extremely high pathogen concentrations it is generally sufficient to know the mean pathogen concentrations future studies should include concurrent variation in the performance of other unit processes and raw water pathogen concentrations experimental work should focus on capturing the variation in filtration performance in order to correctly estimate mean removal rates keywords microbial risk qmra drinking water filtration dynamics 1 introduction a treatment train involving some combination of coagulation flocculation sedimentation and deep bed filtration is common in water treatment plants throughout the world while designed for removing particles and or natural organic matter nom in general coagulation filtration processes also account for a significant portion of the overall microorganism removal including pathogens hijnen and medema 2010 there are several sources of variation in the microbial removal efficiency of filtration processes variation among plants exists due to differences in design raw water quality and operational practices there may be slow variations in time e g because of a changing raw water composition throughout the year westrell et al 2006 or there may be rapid and more random variations as a result of raw water contamination events signor et al 2005 åström et al 2013 or failures in the treatment processes hijnen and medema 2010 huck et al 2002 emelko et al 2003 however superimposed on the variations already mentioned there may be systematic short term variations in removal efficiency originating from the inherently dynamic character of the deep bed filtration process during normal operation even if influent water quality characteristics remain constant typically as measured by filter effluent turbidity there is an initial period of improvement in performance as the filter begins to collect particles the ripening period followed by a period of relatively stable performance until the performance eventually deteriorates the breakthrough phase when the particle collection capacity is exhausted the filter must then be taken out of service to be backwashed so that the particle collection capacity can be restored to its initial state i e the process is discontinuous and essentially periodic these dynamic characteristics distinguish the filtration process from other typical unit processes in conventional treatment sedimentation flotation chlorination uv irradiation that are comparatively stable and uninterrupted during normal operation and when subjected to a constant influent water quality turbidity removal dynamics during filtration is not entirely representative of microbial filtration dynamics though since turbidity measurements lump the contribution of all particle types into a single parameter several studies have shown that the ripening and breakthrough behavior is dependent on among several physico chemical properties particle size clark et al 1992 kim and lawler 2008 moran et al 1993 with smaller particles typically taking longer to both ripen and break through as compared to larger particles some studies have shown a marked reduction in microorganism removal early and late in the filter cycle robeck et al 1962 harrington et al 2003 emelko et al 2003 templeton et al 2007 still studies that aim to characterize microbial removal rates of filtration processes are usually focused on typical removal rates i e removal rates during periods of stable effluent turbidity often employing sampling regimes that are unable to capture the full variation in treatment efficiency throughout the filter cycle recently we undertook a pilot scale dual media contact filtration study in an attempt to generate a high resolution sample of such microbial filtration dynamics during an entire filter cycle nilsen et al 2019 the instantaneous removal efficiency of model viruses and bacteria varied by a factor of about 50 and 200 respectively during the period when effluent turbidity was less than 0 1 ntu indicating that the dynamic character of filtration processes should not a priori be overlooked in risk assessment in quantitative microbial risk assessment qmra haas et al 2014 variations in removal rates may be modeled by fitting appropriate probability distributions to data from filter influent and effluent samples teunis et al 1999 2009 smeets et al 2008 such fitted distributions may be used together with data on raw water quality and other treatment processes to estimate the exposure of water consumers to pathogens data on exposure is subsequently used as input to dose response models haas 1983 nilsen and wyller 2016a for estimating microbial risks associated with drinking water consumption the effect of short term systematic variations in microbial filtration efficiency that are present during normal operation has received comparatively less attention in the microbial risk literature in this note we will use our example high resolution dataset nilsen et al 2019 to compute probability distributions for microorganism removal in a single filter during one filter cycle evaluate the effect on risk estimates when assuming that concentration variations from filtration persist until a point of consumption and there are no other sources of variation discuss the overall relevance of filtration dynamics for qmra in most water supply systems variation in filter effluent concentrations will be subject to smoothing by e g storage tanks and mixing of effluents from filters operating in parallel thus the assumption that variations in concentration actually reach the consumer is a limiting case i will return to this issue in the discussion 2 data and methods 2 1 example data the filtration experiment that generated the example data is reported in full elsewhere nilsen et al 2019 the experimental setup was representative of norwegian filtration practice ødegaard et al 2010 three model microorganisms were used bacteriophage ms2 icosahedral 27 nm bacteriophage salmonella typhimurium 28b icosahedral 60 nm and indicator bacterium e coli rod shaped approx 1 μm 3 μm these were chosen mainly because more data on virus removal has been sought in norway and it was relatively simple to include e coli as an additional organism the approach velocity was constant fig 1 shows the logarithm of π the instantaneous probability of passage for each organism as a function of elapsed time in the filter cycle t more precisely 1 π t c out t c in t here c out and c in are respectively the effluent and influent concentrations as number of microorganisms unit volume of the filter the commonly used log removal rate is simply log 10 π note that in formulating 1 we ignored the travel time between filter inlet and outlet which is short compared to the time scale of changes in π the strict interpretation of π as the probability of passage of a single organism requires π to be independent of both influent and attached microorganism concentrations see nilsen et al 2019 for further details the data shows that bacteria were generally removed better than viruses and the results are also consistent with expectations based on the size difference between the organisms ripening for bacteria occurred more rapidly than for viruses and bacteria broke through before viruses we define breakthrough here as the onset of persistently increasing passage both organisms broke through before turbidity though confirming that there are limitations in using turbidity as a surrogate for microorganism removal it is noted that the breakthrough of viruses is rather abrupt compared to the more gradual breakthrough of bacteria computations reported in this note were performed directly on the experimental data interpolating linearly between data points to construct a continuous function π t the most important implication for risk assessment related to filtration dynamics is probably the challenge it poses to correctly estimating mean removal efficiencies over a full filter cycle this part of the problem was studied in nilsen et al 2019 where it was shown that true mean removal efficiencies may deviate from mid cycle instantaneous removal efficiencies by more than one log10 unit the present note explores further the impact of filtration dynamics itself for qmra given that the mean removal is already known 2 2 probability distribution for π from π t filtration dynamics may induce systematic variations but these must be treated as random from a consumer s point of view since a consumer essentially samples a random volume from the water supply for use in risk assessment applications it is of interest to derive a proper probability distribution for a random variable π representing the observed variation in microbial removal efficiency during filtration some precision is needed in describing this mathematically in general a consumer is assumed to sample uniformly from the total volume produced flow proportional sampling which if the flow rate q t is non constant is not equivalent to sampling uniformly in time the flow rate was constant in our filtration experiment but that is not always how filters are operated the accumulated volume of water v t produced in the time interval 0 t is given by 2 v t 0 t q τ d τ d v d t q t since q t is positive v t is one to one and may be inverted to give a function t v when π t is given we may therefore express π as a function of v π t v and use the theory of functions of random variables appendix a to obtain the probability distribution for the random variable π t v when v is a uniformly distributed random variable on 0 v it is assumed here that the sample volume is so small that we may treat π t as constant during the time interval needed to sample a small volume 2 3 the effect of variation in π on risk estimates in qmra data on pathogen concentrations with variations are used as input to dose response models to estimate the probability of infection from drinking water since dose response models are non linear in the dose variable knowing the mean dose is generally insufficient the full dose distribution is required for a precise calculation of risk it is therefore of interest to study the effect of variations in π from filtration as it affects the dose distribution on risk estimates from dose response models the single hit dose response framework haas 1983 nilsen and wyller 2016a of which the exponential and beta poisson models are examples has served as the de facto standard modeling approach for drinking water a generic formulation is given by 3 p i 1 0 1 g x 1 r f r r d r where p i is the probability of infection g x is the probability generating function pgf of the dose variable x number of organisms ingested and f r is the probability density function pdf of the so called single hit probability r which may vary between hosts but variation between individual pathogens is integrated out fazekas de st groth and moran 1955 haas 2002 schmidt et al 2013 nilsen and wyller 2016b in the simplest case of constant pathogen concentration the dose x is taken to be poisson distributed with mean λ c v s where v s is the sample volume if concentrations vary x is typically constructed as a mixed poisson distribution with random poisson parameter λ c v s furthermore if one assumes that on the time scale of a filter cycle the only source of variation in concentrations is filtration performance one may write λ k π where k is a constant with units of dose for such mixed poisson dose distributions equation 3 can be written 4 p i 1 0 1 m λ r f r r d r 1 0 1 m π k r f r r d r where m is a moment generating function mgf and the latter equality applies when λ k π the evaluation of 4 using experimental data is treated in appendix a in order to gain an understanding of the potential effects of filtration dynamics on risk estimates the following risk ratio may be evaluated where for simplicity we have assumed a constant single hit probability r 5 p i dist p i mean 1 m π r k 1 e r k e π the numerator is the single exposure risk computed with the full distribution of λ k π the denominator is the single exposure risk computed with the exponential model with mean dose e λ k e π i e the mean dose is the same in both cases the risk computed with a mixed poisson dose distribution is always less than the risk computed with a poisson distribution with the same mean nilsen and wyller 2016b proposition 2 the treatment above assumed that x is the mixed poisson dose distribution resulting from a single exposure the risk resulting from n doses independent and identically distributed as x is given by nilsen and wyller 2016a 6 p i 1 0 1 m λ r n f r r d r 3 analysis and results 3 1 probability distribution for π from π t for given start and end times of the production period end of filter to waste and initiation of backwashing respectively the probability distribution of π may be derived from π t using the relationships described in section 2 2 and appendix a this has been done with our example data to produce fig 2 which shows cumulative distribution functions cdf for three different production periods for viruses and bacteria for viruses we have also included a comparison with a cdf derived by teunis et al 2009 they used data on f specific coliphages from two plants in the netherlands to estimate a beta distribution for the removal during coagulation filtration assuming paired influent and effluent samples and gamma distributed influent concentrations as seen in fig 2 the distribution for bacteria is generally displaced to the left compared to the viruses reflecting its better removal also seen in fig 1 the near vertical parts of the distributions stem from the near horizontal parts of the curves in fig 1 restricting the length of the production period displaces probability mass to the left it is clear that the estimated beta cdf of teunis et al 2009 is vastly more spread out than our empirical cdfs from a single filter run although the median values of π are close to each other however the data that went into estimating the beta cdf was of a very different nature high volume sampling with a subsequent concentration step two different plants only 17 samples in total than our experimental data and there was no detailed information on process characteristics or consideration of filtration dynamics the difference is nevertheless consistent with the observation that highly variable virus removal efficiencies for filtration are reported in the literature nilsen et al 2019 supplementary data such cdfs as generated here from our filtration experiment or perhaps some smoother versions of them may potentially be used as input for monte carlo simulations in detailed risk assessment models 3 2 the effect of variation in π on risk estimates plots of the risk ratio in equation 5 are shown in fig 3 a and b for viruses 28b and bacteria respectively they show the influence of 1 varying the production period by restricting the effluent turbidity and 2 the parameter r k through its effect on the exponential model risk horizontal axes also shown in fig 3a is the risk ratio computed with the beta distributed π from teunis et al 2009 for which the mgf in equation 5 becomes f 1 1 α α β r k where f 1 1 is kummer s confluent hypergeometric function and α and β are parameters of the beta distribution as dictated by theory fig 3a and b shows that the ratio in equation 5 is less than 1 we see that the effect of variation in π on risk estimates tends to be more pronounced when lesser restrictions are placed on effluent turbidity it should be noted that under normal operating conditions when the single exposure risk is typically less than 10 6 variation in π alone appears to have negligible influence on risk estimates this applies also when using the very wide π distribution from teunis et al 2009 these observations are related to the well known fact that single hit models become approximately linear at low doses variation in π only seems to become important under severe outbreak conditions when the single exposure risk is higher than 0 01 and somewhat away from 1 for fig 3b for bacteria we find the same tendencies as for viruses but slightly more pronounced due to the characteristics of the π variation as an example of an equivalent calculation using a model with a variable single hit probability r fig 4 shows the following risk ratio for norovirus 7 p i dist p i mean 1 0 1 f 1 1 α α β k π f π π d π 1 f 1 1 α α β k e π the denominator is the risk computed using the ordinary exact beta poisson model and the numerator is the risk computed with a variable π the norovirus parameters α 0 040 and β 0 055 are taken from teunis et al 2008 and gives a very dispersed distribution the results are qualitatively similar to the results in fig 3 1 1 no results are shown for the π distribution from teunis et al 2009 as the required numerical integration was problematic in matlab these figures apply to the single exposure case for the multiple exposure case n exposures we have the corresponding ratio 8 p i nd p i d 1 m π r k n 1 e n r k e π it is readily shown that this ratio increases towards 1 as n increases since m π r k e r k e π thus the effect of variations in π only tend to become less important as the number of exposures increases 4 discussion here we will first address some limitations associated with our example dataset and computational model before briefly discussing the overall relevance of filtration dynamics for risk assessment 4 1 limitations of the example data and computations 4 1 1 example data the example dataset represents the most highly resolved characterization of microbial removal in a single deep bed filter cycle that we are aware of at least for viruses the observed variation in performance throughout the filter cycle was substantial qualitatively as expected based on virus and bacteria relative sizes clark et al 1992 moran et al 1993 and is believed to represent real world phenomena occurring in water treatment plants still the data has been obtained under a single set of experimental conditions corresponding to common filtration practice in the nordic countries and is not necessarily representative of filtration processes that operate under different conditions specifically one may wish to conduct high resolution characterizations using pre sedimentation dedicated flocculation steps different filter rates declining rate filtration different filter materials different coagulants filter aids polymers and more particle rich raw water furthermore other surrogate organisms for pathogens should be tested in future high resolution characterizations 4 1 2 computations some of the limitations of the computational model that could be investigated in future research efforts include unaccounted for variation in our computations the only varying quantity on the time scale of a filter cycle was the filtration passage probability in reality there may be random variations in raw water concentrations and the performance of other unit processes e g because of operational failure that are relevant on similar time scales if such variations are present and can be taken as independent of the variation in filtration performance it will lead to increased variation in the dose distributions filters in parallel our example computations relied on the passage probabilities through a single filter in a real water treatment plant there will be a gallery of filters operating in parallel with the effluents from each filter being mixed at some downstream junction the filters will be at different stages in their filter cycles and the mixing of effluents will have a certain smoothing effect on the dose distribution a rudimentary model of such effects may be found in nilsen 2016 another effect to consider is the hydraulic step when one filter is taken out of service for backwashing the filtration rate through the remaining filters may increase and may affect the removal efficiency the effect of distribution systems the relevance of filtration dynamics depends on the extent to which the distribution system disperses pathogens and smooths out the variations that exist at the treatment plant this will likely depend on the layout of the pipe network and storage tanks in the system the distribution of water demands and the location of each individual consumer within the network dose response models single hit dose response models are routinely used for drinking water risk assessment and have been shown to fit data well for medium to high doses it is however a remaining scientific challenge to verify their applicability for low doses so that extrapolations beyond the range of observations is typically necessary for drinking water studies if the true dose response model is non linear even for low doses this will affect the results of modeling efforts where variation in doses is accounted for furthermore we considered only one case of variable single hit probability r in our examples such models are flatter than their constant r counterparts nilsen and wyller 2016a proposition 1 but qualitatively similar we do not expect the main conclusions to change with such models and further calculations not shown using equation 7 with combinations of α and β in the range 0 5 5 support this 4 2 filtration dynamics and risk assessment the existence of filtration dynamics poses two main challenges to microbial risk assessment correctly estimating the mean passage probability and hence mean pathogen concentrations and doses and the possibility that variations around the mean concentration may significantly affect risk estimates the plots in figs 3 and 4 indicate that concentration variations around the mean exert all but negligible influence in our risk model with the example dataset except possibly in a situation where pathogen concentrations approach levels associated with extreme risk and attack rates this applies even when using the π distribution from teunis et al 2009 which is significantly more spread out than our experimental π distributions we stress that this result applies to a situation where we ignore other sources of variation in the dose distribution on the time scale of a filter cycle the conclusion seems robust as several assumptions were made in this study that will overexaggerate the variation in the dose distribution including ignoring effects of parallel filters ignoring mixing in the distribution system and ignoring the effect of multiple exposures correctly estimating and minimizing the mean passage probability of deep bed filters therefore seems to be the more important aspect of filtration dynamics for risk assessment and management this aspect was studied in detail in nilsen et al 2019 for long term risk assessments it may still be useful to include empirical distributions such as those given in fig 2 into monte carlo simulations of risk the distributions in fig 2 are available from the author upon request 5 conclusions in this note we have studied the effect of short term deep bed filtration dynamics on microbial risk estimates using high resolution data on filtration performance that is believed to be representative of real world effects under the given conditions together with a simplified conceptual model under the assumption that filtration performance is the only variable quantity on the time scale of a single filter cycle it was shown that concentration variations induced by filtration are unlikely to affect risk estimates when compared with a model that uses an equivalent mean concentration except possibly in an outbreak situation with extremely high pathogen concentrations future studies should probe this result further by studying the effect of concurrent variation in filtration performance and other unit processes as well as raw water concentrations until further studies along the suggestions made above can be carried out the main consequence for qmra of systematic short term dynamic effects in microbial filtration performance is to motivate filtration experiments to correctly estimate mean passage probabilities under a wider range of conditions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements discussions with profs arve heistad and john wyller were very helpful in the preparation of this manuscript appendix a the transformation rule for functions of random variables assume that we have a random variable v with associated probability density function f v v and a differentiable function g r r that induces a new random variable π g v assume that the domain of the function g may be partitioned into n intervals such that the function g is monotonic on each interval denote the restriction of g to interval i by g i then the probability density of π is given by a 1 f π π i 1 n f v g i 1 π d g i 1 π d π it is assumed here that pr g v 0 0 if that is not the case the above rule can be generalized and the density f π π becomes a mixed discrete continuous probability distribution i e it has some point masses of probability when v is uniformly distributed on v 1 v 2 the rule simplifies to a 2 f π π 1 v 2 v 1 i 1 n d g i 1 π d π this expression may be evaluated numerically from the example experimental data in fig 1 from which the associated cumulative distributions shown in fig 2 can be computed in parentheses it is noted that this procedure closely parallels the construction of flow duration curves in hydrology now introduce another function h r 0 1 that maps π to h π for the expected value e h π we have according to a 2 and a change of variables a 3 e h π π h π f π π d π 1 v 2 v 1 v 1 v 2 h g v d v thus expectations over π are equivalent to simple averages over v when v is uniformly distributed which is of course in agreement with intuition as stated in equation 4 when the dose variable λ k π the single hit dose response model is constructed with the moment generating function mgf of π evaluated at r k the mgf of π is an expectation value on the form given in a 3 with h π e z π when π g v with v uniformly distributed the mgf of π may be computed as a 4 m π z e e z π 1 v 2 v 1 v 1 v 2 e z g v d v this quantity can be straightforwardly evaluated numerically from the example experimental data in fig 1 
18308,boreal lakes are considered hot spots of dissolved organic matter dom processing within the global carbon cycle this study has used ft icr mass spectrometry and comprehensive data evaluation to assess the molecular differences of spe dom between lake column water spe dom and sedimentary pore water spe dom in 10 swedish boreal lakes of the malingsbo area which were selected for their large diversity of physicochemical and morphological characteristics while lake column water is well mixed and fairly oxygenated sedimentary pore water is subject to depletion of oxygen and to confinement of molecules robust trends were deduced from molecular compositions present in all compartments and in all 10 lakes common compositions with recognition of relative abundance sedimentary pore water spe dom featured higher proportions of heteroatoms n and s higher average h c ratios in presence of higher dbe c ratios and higher average oxygenation than lake column water spe dom these trends were observed in all lakes except ljustjärn which is a ground water fed kettle lake with an unique lake biogeochemistry analogous trends were also observed in case of single or a few lakes and operated also for compounds present solely in either lake column water or sedimentary pore water unique compounds detected in either compartments and or in a few lakes showed higher molecular diversity than the common compositions processing of dom molecules in sediments included selective preservation for polyphenolic compounds and microbial resynthesis of selected molecules of considerable diversity keywords solid phase extraction dom fticr ms lake sediment microbial oxidation 1 introduction a substantial fraction of the total organic carbon in the ecosphere is stored in forest vegetation and soils especially in the boreal zone dixon et al 1994 and dissolved organic carbon doc can move from the terrestrial to the aquatic systems ide et al 2017 dom in boreal lakes which account for more than half of european natural lakes european environment agency 2003 originates from benthic and pelagic primary production in the lake itself premke et al 2010 and from riverine and to lesser extent from groundwater inflow of microbially processed terrestrial derived dissolved organic matter dom kortelainen et al 2006 lake dom participates in a series of ecological processes acting as an energy source for microorganisms and further trophic levels qualls and haines 1992 tranvik 1989 influences water chemistry e g ph color meili 1992 and is associated with speciation of metals hertkorn et al 2004 and nutrients koenings and hooper 1976 mierle and ingram 1991 winch et al 2002 freshwater ecosystems have been considered hot spots for carbon cycling cole et al 2007 because dom carried from the watershed is either processed mineralized or buried in such systems in the water column dom can be photochemically amaral et al 2013 bertilsson and tranvik 2000 gonsior et al 2009 or biologically degraded giorgio et al 1998 medeiros et al 2015 seidel et al 2015 mainly through aerobic processes such mineralization processes result in a transfer of co2 from the lakes to the atmosphere raymond et al 2013 sobek et al 2006 valle et al 2018 in boreal lakes flocculation and subsequent sedimentation of doc are the major sources for sediment organic carbon gudasz et al 2012 extent and selectivity of flocculation are influenced by temperature microbial activity presence of oxygen diversity and abundance of metal ions and ph von wachenfeldt et al 2009 both increased temperature and increased microbial activity have proved to enhance particle formation von wachenfeldt et al 2009 besides the contribution of microbial activity in the formation of autochthonous organic matter it has been proposed that extracellular polymeric substances secreted by bacteria could be relevant for stabilizing the suspended material droppo 2001 droppo and ongley 1994 although decreased ph abate and masini 2003 and anoxic conditions gao and zepp 1998 have been pointed as favoring flocculation it was also proposed that those parameters were indirectly affecting flocculation due to their influence on the microbial activity itself von wachenfeldt et al 2009 in the water column sunlight can play an important role in the transformation of allochthonous doc into particulate organic carbon poc von wachenfeldt et al 2008 allochthonous inflow photo and biodegradation processes in the water column determine the selectivity of dom sedimentation the presence of oxygen which depends on the mixing of the water column tranvik et al 2009 determines the extent of aerobic degradation processes that can happen in this compartment small streams often carry substantial loads of deeply colored waters into boreal lakes and strong gradients are encountered on mixing terrestrial colored dissolved organic matter cdom is rich in lignin and tannin derived compounds which readily complex redox active transition metal ions such as fe2 3 but also main group metal ions such as ca2 in the lake water column sedimentation of poc and mineralization to co2 remove about equal amounts of carbon from the dissolved phase in boreal lakes throughout the year von wachenfeldt and tranvik 2008 flocculation primarily affects allochthonous dom and might be assisted by the aid presence of metal ions under changing conditions of ph and ionic strength killops and killops 2005 microorganisms prefer to attach to surfaces like those provided by pom where they will use high concentrations and gradients of organic and inorganic nutrients and redox conditions to enable sustenance and growth pomeroy et al 2007 sinking particles then accumulate at the lake bottom trapping lake water in the interstitial pore spaces however continual microbial processing of dom in near surface sediments under conditions of now limited diffusion will quickly cause a substantial increase in relative concentration of interstitial pore water dom which will reflect the conditions of their particulate environment rather than that of open lake water valle et al 2018 singer et al 2010 furthermore oxygen stratification and low light penetration will facilitate microbial anaerobic degradation processes in the sediments jonsson et al 2001 increased concentrations of dom and a highly complex microbial community conrad 2007 can produce an individual signature of dom composition with higher proportions of nitrogen and sulfur containing molecules valle et al 2018 since organic matter processing depends on the initial dom pool composition and availability under given redox conditions we expect that water column and sedimentary dom pools show different molecular characteristics here we used negative mode electrospray ionization esi fourier transform ion cyclotron resonance mass spectrometry fticr ms to contrast the molecular diversity of lake water column and sediment pore water solid phase extractable spe dom in 10 swedish boreal lakes fticr ms has been widely used to characterize dom from freshwater ecosystems gonsior et al 2016 jaffé et al 2012 kellerman 2015 to trace changes in dom composition after photo and biodegradation within natural gradients gonsior et al 2014 2009 ide et al 2017 medeiros et al 2015 schmidt et al 2017 2011 tremblay et al 2007 and incubation experiments hodgkins et al 2014 seidel et al 2016 valle et al 2018 the capacity of ultrahigh resolution fticr ms to resolve thousands of individual molecular formulae within natural dom samples hertkorn et al 2008 allowed us to trace molecular differences between distinct dom pools within individual and across multiple lakes 2 material and methods 2 1 site description we collected water column and sediment samples from 10 lakes in the malingsbo area sweden in august 2012 fig 1 description of the investigated lakes can be found in table 1 2 2 sampling we obtained water samples by boat just below the surface approximately at the largest water depth of the lake sediment samples were collected with a small gravity corer we took the upper 10 cm of sediment homogenized it and transferred the samples into 125 ml polyethylene bottles which were completely filled avoiding air bubbles inside solid phase extraction spe of the water samples was done at the field whereas spe of sediment pore water was performed in the laboratory the sediment bottles were kept cold 4 c stored in the dark and shipped by air to the helmholtz zentrum münchen research unit analytical biogeochemistry germany for further experiments 2 3 chemical analysis the water column dom was extracted by a previously described spe method using ppl resin dittmar et al 2008 the detailed sediment pore water spe dom extraction was described elsewhere valle et al 2018 the eluates were stored in the freezer 20 c until mass spectrometry analysis water samples from the lakes were analyzed for dissolved organic carbon doc total nitrogen tn and total phosphorus tp doc was measured with a toc analyzer shimadzu 5000 japan tn and tp were analyzed colourimetrically following persulfate oxidation using an aa3 autoanalyzer bran luebbe germany organic carbon oc content in the sediments was measured in one of the replicates of each sample samples were acidified to remove possibly present carbonates and dried the carbon content was analyzed at the centre for stable isotope research and analysis kosi at göttingen university germany using an elemental analyzer na 2500 ce instruments rodano italy 2 4 ft icr mass spectrometry negative electrospray ionization fourier transform ion cyclotron resonance esi ft icr mass spectra were acquired using a 12t bruker solarix mass spectrometer bruker daltonics bremen germany and an apollo ii electrospray ionization esi source in negative mode hertkorn et al 2016 spe samples were injected using a 223 sample changer gilson inc middleton usa with an adapted in house made software to ft icr ms nebulizer gas pressure drying gas pressure and the source heater temperature were 138 kpa 103 kpa and 200 c respectively the spectra were acquired with a time domain of 4 mw and five hundred scans were accumulated for each mass spectrum all spectra were first externally calibrated on clusters of arginine in meoh 0 57 μmol l and internally calibrated using appropriate reference mass lists of common natural organic matter molecules reaching accuracy values lower than 500 ppb data processing was done using compass data analysis 4 1 bruker bremen germany and formula assignment by an in house made software netcalc tziotis et al 2011 the molecular formula assignments were based on the following elements 1h0 200 12c0 100 16o0 80 32s0 3 14n0 3 as well as the 13c0 1 and 34s0 1 isotopomers the generated formulae were validated by setting sensible chemical constraints n rule o c ratio 1 h c ratio 2n 2 cnh2n 2 restriction on nitrogen and sulfur atoms to counts up to three was based on previous studies of natural organic matter nom where mass assignments with more than three atoms of n and s were commonly not observed at all hertkorn et al 2013 schmitt kopplin et al 2011 mass spectra were acquired from the existing single replicates of lake water column spe dom and from five replicate distinct isolates of sedimentary pore water spe dom valle et al 2018 however to increase consistency we have selected only ions common to the most similar three replicates of sedimentary pore water spe dom for further analysis the reasoning was as follows lake water is well mixed and hence expected to be rather uniform whereas sedimentary pore water composition depends on chemical and microbial reactions occurring in small spatial scales e g singer et al 2010 given the consistently superior stability of our mass spectrometer and the resulting excellent reproducibility of mass spectra acquired from identical samples we had the choice to acquire a single mass spectrum or several mass spectra in a given fixed total acquisition time because we rate excellent definition of mass spectra in the x axis mass resolution and mass accuracy as well as in y direction mass peak amplitude as equally important to discriminate among dom samples we have chosen to use the disposable acquisition time to acquire a single mass spectrum from lake column water spe dom the final assigned molecular formulas were categorized into groups containing cho chno chos and chnos molecular compositions which were used to reconstruct the group selective mass spectra table s1 molecular compositions present in both water column and sediment pore water within each individual lake from now on referred as common mass assignments and molecular compositions unique to each compartment number and percentage of molecular formulas containing cho chno chos or chnos molecular series and the computed average of h c n o s atoms and h c o c c n c s as well as m z mass to charge ratios and other relevant bulk parameters are shown in tables s2 s3 and s4 an important tool in data visualization of mass spectra is the van krevelen diagram van krevelen 1950 based on their elemental ratios commonly h c versus o c derived from assigned molecular formulas each data point is a projection of a given elemental ratio regardless of the molecular mass schmitt kopplin et al 2012 main chemical classes found in dom often show characteristic h c and o c ratios and cluster within specific regions of van krevelen diagrams kim et al 2003 rivas ubach et al 2018 thus evolution of patterns in van krevelen diagrams of dom reflects not only the source material but may also indicate changes in bulk dom composition due to degradation and hint at possible chemical reactions during dom evolution methylation oxidation and hydrogenation for example kim et al 2003 the kendrick mass defect analysis kmd is another important visualization tool of ft icr mass spectra hughey et al 2001 of which the kmd z diagram is a useful extension shakeri yekta et al 2012 here the kendrick mass defect is divided by an empirical integer sorting parameter z introduced by hsu et al 1992 which is defined by the molecular moiety under investigation for instance methylene ch2 with a nominal mass of 14 implies a range for z from 1 to 14 kmd z diagrams remove projections present in standard kmd diagrams by dividing the single kmd diagram into 14 subpanels this might offer viable leads into the compositional characterization of nom processing cf fig s7 and fig s8 in kmd z versus mass diagrams shakeri yekta et al 2012 valle et al 2018 molecular compositions with identical kmd z represent unique homologous series naturally the most relevant homologous series present in dom are methylene and dbe based moieties reflecting mass difference of homologous molecules δm ch2 by 14 0156 da providing horizontal lines in kmd z diagrams δm h2 by 2 0157 da providing upward sloped lines in kmd z diagrams and δm ch4 o by 36 4 mda providing vertical lines in kmd z diagrams gonsior et al 2014 hsu et al 1992 perdue and green 2015 shakeri yekta et al 2012 stenson et al 2003 2 5 statistical analysis hierarchical cluster analysis hca was performed using the hierarchical clustering explorer 3 0 hce http www cs umd edu hcil multi cluster with clustering of the dataset using the average linkage upgma method and the pearson correlation coefficient pearson s r as the similarity distance measure principal component analysis pca was performed with the software simca p 9 0 umetrics ab sweden determination of unique molecular formulas in each compartment was done based on presence and absence 3 results and discussion in this study we investigated open lake water and sediment pore water spe dom ppl obtained from 10 boreal lakes located in malingsbo region sweden fig 1 which were selected for their large diversity of physico chemical and morphological characteristics table 1 for instance water column doc ranged from 3 9 mg l 1 lustjärn to 25 7 mg l 1 svärttjärn whereas sedimentary organic carbon ranged from 8 5 svarttjärn to 34 8 ljustjärn table 1 lakes svarttjärn skittjärn and oppsveten showed the highest values for water doc tn and tp lake ljustjärn showed the lowest concentration of lake water column doc but the highest values for both sediment orgc and n the larger lakes were övre skärsjön 165 ha oppsveten stora snesnaren bisen and lilla sången 24 ha while the smallest lake covered merely 0 7 ha svärttjärn water residence time is a function of area and depth and therefore followed the same gross order in analogy to the bulk characteristics of individual lakes the molecular diversity of lake water and sediment pore water spe dom as observed by esi fticr mass spectra showed general and individual trends that helped us to comprehend the mechanisms of dom processing in freshwater lakes and sediments fig 2 for most of the lakes with exception of grästjärn lilla sången and ljustjärn sediment pore water spe dom showed larger counts of assigned mass peaks than the water column spe dom pool table s1 a general feature was a higher proportion of heteroatom containing compounds in sediment pore water spe dom compared with lake water spe dom as expressed by c n and c s ratios table s1 all lakes presented higher relative abundance of n containing molecules average n in the sediment pore water spe dom the percentage of s containing compounds average s was however higher in the sediments of the majority of the lakes but with the exceptions of stora snesnaren and skotttjärn virtually same values for water column and sediment pore water and bisen and oppsveten higher percentage of sulfur in the water column spe dom pool table s1 molecular formulas present in the water column spe dom pool were usually more saturated than the ones in the sediment pore water spe dom pool table s1 fig 3 additionally sediment pore water spe dom was overall more oxygenated than water column spe dom with lakes grästjärn and ljustjärn being near equal in general sediment pore water spe dom molecules covered a larger area in van krevelen diagrams for all boreal lakes fig s2 fig 2 fig 4 this feature reflected an overall higher molecular diversity of sedimentary porewater spe dom compared with those found in the lake water column spe dom pools this is expected because sediment pore water composition depends on distinct and heterogeneous consortia of microorganisms separated by open ground singer et al 2010 as well as mineral composition and texture with much steeper gradients of concentration composition and redox conditions than observed in the well mixed open water column burdige 2001 komada et al 2013 krause et al 2009 siljanen et al 2011 the mass peak distribution for lake water column and sedimentary pore water spe dom showed the typical skewed near gaussian distribution common for environmental spe dom fig s1 with sedimentary pore water spe dom occupying a higher mass range m z 160 820 figs s1d and a lees steep decline at higher mass than observed for lake water spe dom m z 160 750 fig s1b the molecular compositions common to both lake water column and sedimentary pore water spe dom fig s1c showed a narrower and more even distribution indicative of substantial averaging between these two compartments the compounds unique to sedimentary pore water spe dom fig s1e extended to higher mass and showed a smooth decrease of mass peak amplitudes from m z 500 this indicated a fairly processed organic matter rather than selected classes of metabolites at higher mass as opposed to a noticeable patterning at m z 500 which resulted from selective degradation and re synthesis of biomolecules and metabolites roth et al 2019 in comparison the mass peak distribution of compounds unique to the lake water column showed distinctive patterning which is improbable to arise from processing intrinsic to the well mixed water column instead the omission of mass peaks from m z 290 320 fig s1a blue shade and m z 380 410 fig s1a purple shade most probably arose from selective processing of sedimentary pore water spe dom which preferentially produced compounds within these selected mass ranges even if these compounds were not conspicuous with respect to mass peak amplitude fig s1d their presence strongly affected the computed mass peak distributions of compounds unique to the lake water column spe dom fig s1a furthermore this trend did not appear in either van krevelen or h c against mass diagrams this in part derived from the fact that compounds from both compartments occupied analogous areas in these diagrams with considerable density fig s3 based on the mass spectra acquired for both water column and sediment pore water spe dom we first determined the ubiquitous assigned molecular compositions which were present in both water column and sedimentary spe dom and in all 10 lakes table s1 fig s1 the exclusion of molecular compositions with variable extent of uniqueness e g found in a single to a few lakes and or sedimentary pore water implied a substantial averaging cf fig s1c but this procedure revealed fundamental and robust trends of dom evolution in boreal lakes when relative abundances were recognized the entire data set of common molecular compositions observed in all 10 lakes was at first decomposed into compounds relatively more abundant in open lake water spe dom and in those relatively more abundant in sedimentary pore water spe dom compared with mass spectra of individual spe dom which commonly showed mass peaks ranging from m z 180 820 fig s1 the mass range for averaged water column spe dom was reduced to m z 220 400 and that for sedimentary spe dom to m z 200 370 fig 2c fig s2 average h c and o c values derived from molecular compositions common to both compartments in individual lakes table s2 ranged in between those of lake water and sediment pore water spe dom exceptions were grästjärn and ljustjärn for h c ratios whereas mass weighted averages followed non uniform trends table s2 we used differences in relative abundance of the assigned molecular compositions which were present in lake water and in sedimentary pore water spe dom and in all 10 lakes common to all 10 lakes to perform hierarchical cluster analysis hca fig 2a principal component analysis pca fig 2b and to compute differential mass spectra spe dom sediment spe dom water column fig 2c based on normalized mass spectra total amplitude of assigned molecular compositions 100 distinct clustering between water column and sediment pore water spe dom was observed in hca and pca for nine lakes with the exception of lustjärn which showed resemblance of both spe dom and an overall molecular composition distinct from that of all other lakes hence spe dom pools from each compartment i e lake water column or sedimentary spe dom were more similar among themselves than pools from different compartments within identical lakes in fact lake ljustjärn was an exception among the swedish boreal lakes used in this study because it was influenced by groundwater inflow and received low amounts of organic matter from the rather tiny drainage area as a result low doc concentration and low water color were found in this lake von wachenfeldt and tranvik 2008 however results from previous studies have shown that groundwater transport of allochthonous carbon is highly unlikely to be of importance for poc and that most of the sedimentation has autochthonous origin in this lake von wachenfeldt and tranvik 2008 another feature deserves mentioning lake ljustjärn features the lowest content of doc and the highest proportion of sedimentary organic carbon table 1 lake ljustjarn sediments have a peaty layer below a sand layer of which we are aware of because of past coring ljustjärn is a ground water fed kettle lake but at some time in the past there must have been extensive benthic macrophyte growth or floating sphagnum mats that sank to the bottom difference ftms spectra display linear relationships between all data points and were far better suited to depict the rather gradual variations among all pairs of spectra than a ratio analysis here compounds with higher relative abundance in the sediment pore water showed positive amplitude and compounds with higher relative abundance in the water column showed negative amplitude fig 2c fig s2 already at the level of visual inspection lake water column spe dom common to all lakes showed rather regular skewed gaussian distribution of mass peaks ranging from m z 220 370 da which was dominated by mass spacing dbe h2 δm 2 0157 da not visible in figures and ch2 δm 14 0156 da representing freshwater dom with the typical characteristics of an evolved biogeochemical material schmitt kopplin et al 2012 in comparison compounds more abundant in sediment pore water showed a rather bimodal distribution with a minimum of abundance from 330 to 370 da extending to lower mass 180 da and showing rather irregular patterning which is characteristic of mixtures of biomolecules zhang et al 2014 while the mass weighted average of sediment pore water spe dom was commonly by 10 25 da larger than that of lake water column spe dom table s1 some water column dom molecules extended to higher mass than those found in sediment pore water spe dom fig 2c at the level of individual lakes clear patterning was observed for lake 10 sedimentary spe dom övre skärsjön whereas abundant low mass peaks m z 200 320 indicative of biological activity were present in most sedimentary spe dom fig s2 the display of common molecular assignments in the van krevelen and mass edited h c ratio diagrams with recognition of relative abundance fig 2d m also revealed specific trends in each compartment first no chos compounds showed increased relative abundance in the lake water column spe dom the fact that not any single chos compound was relatively more abundant in the lake water column indicates either chemoselective removal of chos compounds in the lake water column e g by photooxidation ossola et al 2019 or and rather effective production of chos compounds in the sediment e g by reductive sulfurization under conditions of oxygen limitation hebting et al 2006 second the cho fig 2d and chno compounds fig 2f with higher relative abundance in the sediment pore water spe dom occupied larger areas in the van krevelen diagrams reflecting a higher molecular diversity of sedimentary spe dom related to synthesis and selective preservation of organic molecules in sediments roth et al 2019 raven et al 2016 while assigned mass peaks with increased relative abundance in sediment pore water spe dom occupied sections indicative of more saturated lipid like and more oxygendated and hydrogen deficient lignin and tannin like compounds fig 2d lake water column spe dom was enriched in carboxyl rich alicyclic compounds cram fig 2e of more average h c and o c ratios the alternate display of common molecular compositions between lake water column and sediment pore water spe dom bulk characteristics table s2 produced sawtooth like patterns indicative of regular variations between those materials for nine lakes again with the exception of lake ljustjärn fig 3 the average h c ratios and the relative proportions of cho compounds were larger in the water column spe dom whereas the average o c ratios relative unsaturation as expressed by dbe c ratio and the proportions of chno and chos compounds were larger in the sedimentary porewater spe dom table s2 fig 3 these features conformed to key characteristics of microbial oxidation of dom and formation of cram in which sizable proportions of alicyclic rings decreasing the h c ratio and increasing the dbe c ratio and carboxylic acids increasing both the o c ratio and the dbe c ratio are generated hertkorn et al 2016 in general average mass increased from lake water column water spe dom to sedimentary pore water spe dom however gäddjärn showed near unchanged average mass whereas average mass of svärttjärn grästjärn lilla sången and in particular ljustjärn decreased from lake water column spe dom to sediment pore water spe dom fig 3 table s2 this indicated that in general higher proportions of aliphatic compounds and smaller proportions of oxygenated compounds were observed in lake water spe dom one plausible reason is photodegradation of dom in the well mixed and oxygenated open water column which initiates partial photomineralization to produce the oxygen rich byproducts co2 and h2o amaral et al 2013 chupakova et al 2018 wolf et al 2018 hence carbon in the form of co2 and various oxygen rich functional groups will then no longer be available for resynthesis of dom molecules this leads to an apparent deoxygenation of residual dom even in case of its oxidative degradation einsiedl et al 2007 aromatic and unsaturated compounds are in general susceptible to photodegradation owing to their csp2 based chromophoric groups von wachenfeldt et al 2009 gonsior et al 2009 another key feature was the presence of higher proportions of chno and chos compounds in the sedimentary pore water this higher abundance of heteroatoms in sediment spe dom likely results from an intense bioactivity in the sediments which will produce a succession of microbial metabolites in complex foodwebs herzsprung et al 2010 hodgkins et al 2014 2016 roth et al 2014 2019 seidel et al 2014 all these compounds will be subject to reductive sulfurization reactions under oxygen limited conditions hebting et al 2006 contributing to elevated abundance of chos compounds of which some will accumulate structural motifs with certain resistance against enzymatic degradation next we investigated the molecular compositions which were unique in either the water column or in the sediment pore water spe dom in all of the 10 lakes tables s3 and s4 fig s4 van krevelen diagrams showing these unique features present in all 10 investigated lakes covered a larger diversity of compounds fig 4 compared with the respective compounds common to all 10 lakes fig 2 this is expected because common features present within all lakes were subject to far higher intrinsic averaging than the respective unique features fig s1 fig s2 fig s3 this intrinsic averaging favours presence of compounds with average h c and o c ratios for which the count of feasible isomeric structures for given molecular formulas is maximal hertkorn et al 2007 fig 2e h fig 2j m the situation is different for cho compounds in sedimentary pore water spe dom fig 2d 2i for which distinctive microbial and chemical transformations have produced lipid like compounds with large h c and low o c ratios on one hand and polyphenol type compounds with low h c and high o c ratios on the other hand these two main classes of abundant compounds enveloped the section of cram in van krevelen diagrams of lake column water causing a distinctive gap in the van krevelen diagram of cho molecules unique to sedimentary pore water fig 2d 2i water column cho and chno compounds showed similar patterning in van krevelen diagrams with chno compounds being more compacted and ranging toward higher relative unsaturation fig 4a fig 4b however chno compounds showed considerably smaller masses than cho compounds in the h c against mass diagrams fig 4a fig 4b this indicates that cho and chno compounds in lake column spe dom differed greatly in their chemical structures the chos compounds found more abundant in lake column spe dom were widely scattered in van krevelen diagrams and h c against mass diagrams while lightly following distributions found for cho compounds this observation concurs with a supposed functionalization of selected cho compounds with oxygenated sulfur containing functional groups however with no distinctive structural preference in general trends observed for unique compounds fig 4 fig s4 were analogous to those observed for abundance weighted common molecular compositions fig 2 chos compounds covered relative large areas in the van krevelen diagrams in both compartments indicating a rather large chemical diversity while a sizable proportion of lake water chos compounds occupied the same area as cram the chos compounds in sediment pore water reflected rather saturated lipid like compounds and s derivatives of lignin and tannin like compounds possibly modified products of these rather stable constituents gonsior et al 2016 herzsprung et al 2010 furthermore both common and unique compositions showed an apparent trend towards an increased mass weighted average in the sediment pore water when compared to the water column samples fig s1 indicative of preferential microbial processing of low mass molecules and or selective preservation of larger size molecules hodgkins et al 2016 seidel et al 2014 roth et al 2019 and selective preservation of more refractory compounds such as polyphenols guillemette et al 2017 kellerman et al 2015 valle et al 2018 taking the common molecular assignments into consideration fig 2 table s2 we decided not only to visualize the standard ch2 based kmd diagrams fig s5 but also to visualize the kmd z diagrams for each individual z value fig s6 in addition we have plotted the respective molecular compositions in van krevelen diagrams fig s6a introducing the z sorting parameter removed projection and revealed a clear clustering of cho compounds which were found more abundant in lake column water spe dom on one hand and of those found more abundant in sedimentary pore water spe dom on the other hand which were obscured in standard kmd diagrams fig s5 interestingly but not overly surprising compounds with odd z values were mainly chn1o whereas compounds with even z values were mainly cho with a few chos compounds we have investigated the kmd z versus m z plots for z 4 fig s7 and z 5 fig s8 in some more detail while the kmd z 5 diagram showed only four series of chn1o compounds with ascending counts of dbe related by a nominal exchange of δm c1h4o 1 36 4 mda which were relatively more abundant in sedimentary pore water spe dom fig s7 the respective kmd z 4 diagram was rather elaborate with two major series with ascending counts of dbe related by a nominal exchange of δm c1h4o 1 36 39 mda fig s8 these two series derived from ch2 based homologous series with c10h10o3 showing the lowest mass yellow shaded molecular series in fig s8 with increasing counts of dbe related by δm c1h4o 1 36 39 mda this molecular series was more abundant in lake column water spe dom at low kmd z values whereas at higher kmd z values lower mass molecules of this series were more abundant in sedimentary pore water spe dom however higher mass members of this ch2 based molecular series were consistently more abundant in lake water column spe dom fig s8 the other ch2 based series was offset from the first series by δm c4o 3 15 26 mda fig s8 and showed the low mass member c11h20o6 which was considerably more saturated and oxygenated than the base molecule c10h10o3 of the other series these relationships were also depicted in the van krevelen diagram in which the yellow shaded molecular series with z 4 corresponded to the respective contiguous assembly with lower h c and o c ratios fig s6a these initial elaborations suggest that significant information can be drawn from kmd z diagrams when more precise compositional relationships during processing of dom molecules in environmental settings will be investigated a detailed elaboration is however beyond the scope of this contribution in summary sediment pore water spe dom showed higher aliphaticity oxygenation and a higher proportion of chos and chno compounds analogous trends have been recently observed in anoxic incubation experiments of sedimentary pore water itself valle et al 2018 and were attributed to lake specific large scale transformations of organic matter through microbial activity the transition from lake water column to sedimentary pore water itself is initiated by flocculation biotic flocculation pom abiotic flocculation photochemistry and metal complexation sinking particles accumulate at the bottom of the lakes and impede the rather unrestricted mixing of water which is characteristic of the commonly oxic lake water column diffusion from organic rich particles and microbial processing of dom quickly build up higher doc concentrations and lead to depletion of oxygen depending on individual conditions liikanen et al 2003 production of n rich microbial metabolites and large scale sulfurization reactions under conditions of oxygen limitation produced a substantial range of chno and chos compounds hodgkins et al 2016 shakeri yekta et al 2012 4 conclusion this study revealed that selectivity of dom degradation in the mixed and oxic water column and subsequent processing preservation of dom in the sediments left distinct imprints on dom composition among boreal lakes notwithstanding individual characteristics of each system despite lake specific features in each of the boreal lakes studied both common and unique compounds showed similar trends when lake water column and sediment pore water spe dom pools were confronted those trends even prevailed when only molecular compositions common to all lakes and compartments were considered necessarily with recognition of the relative abundance photochemical processing and microbial degradation of dom were key reactions moreover increased proportions of heteroatoms in the sediment pore water spe dom revealed enhanced microbial activity in this compartment in comparison with the water column these results demonstrate that high resolution mass spectra of freshwater dom in lakes followed by mathematical data analysis revealed significant molecular changes these in turn contributed to a better understanding of mechanisms governing the temporal evolution of carbon chemical environments in freshwater ecosystems already the comparison of cho and chno compounds revealed that current science offers still very rudimentary understanding of even basic features of compositional and structural characteristics of dom author contributions j v m g p s and n h collected samples from swedish lakes in august 2012 d b generated funding in support of this research a p and d b contributed to the study design j v m g and m h performed the ft icr ms acquisition data analyses and participated in data interpretation p s k provided support for the ft icr ms analyses and general data interpretations data interpretation was performed by all authors j v m h and n h actively participated in the writing of the manuscript all authors provided significant input on the final manuscript declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the financial support from the swedish research councils vr 2012 00048 stint 2012 2085 and european research council erc grant no 725546 j v thanks the brazilian national council of technological and scientific development cnpq 290004 2014 4 and the alexander von humboldt foundation for fellowship and financial support research group linkage brazil germany connecting the diversity of dissolved organic matter and co2 and ch4 production in tropical lakes a p is a research fellow from cnpq and cientista do estado from faperj fundação de amparo à pesquisa do estado do rio de janeiro and uses financial resources from these two funding agencies and also from capes coordenação de aperfeiçoamento de pessoal de nível superior and stint the swedish foundation for international cooperation in research and higher education for this research m h thanks daad for the ppp exchange program with the federal university of rio de janeiro appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 115320 
18308,boreal lakes are considered hot spots of dissolved organic matter dom processing within the global carbon cycle this study has used ft icr mass spectrometry and comprehensive data evaluation to assess the molecular differences of spe dom between lake column water spe dom and sedimentary pore water spe dom in 10 swedish boreal lakes of the malingsbo area which were selected for their large diversity of physicochemical and morphological characteristics while lake column water is well mixed and fairly oxygenated sedimentary pore water is subject to depletion of oxygen and to confinement of molecules robust trends were deduced from molecular compositions present in all compartments and in all 10 lakes common compositions with recognition of relative abundance sedimentary pore water spe dom featured higher proportions of heteroatoms n and s higher average h c ratios in presence of higher dbe c ratios and higher average oxygenation than lake column water spe dom these trends were observed in all lakes except ljustjärn which is a ground water fed kettle lake with an unique lake biogeochemistry analogous trends were also observed in case of single or a few lakes and operated also for compounds present solely in either lake column water or sedimentary pore water unique compounds detected in either compartments and or in a few lakes showed higher molecular diversity than the common compositions processing of dom molecules in sediments included selective preservation for polyphenolic compounds and microbial resynthesis of selected molecules of considerable diversity keywords solid phase extraction dom fticr ms lake sediment microbial oxidation 1 introduction a substantial fraction of the total organic carbon in the ecosphere is stored in forest vegetation and soils especially in the boreal zone dixon et al 1994 and dissolved organic carbon doc can move from the terrestrial to the aquatic systems ide et al 2017 dom in boreal lakes which account for more than half of european natural lakes european environment agency 2003 originates from benthic and pelagic primary production in the lake itself premke et al 2010 and from riverine and to lesser extent from groundwater inflow of microbially processed terrestrial derived dissolved organic matter dom kortelainen et al 2006 lake dom participates in a series of ecological processes acting as an energy source for microorganisms and further trophic levels qualls and haines 1992 tranvik 1989 influences water chemistry e g ph color meili 1992 and is associated with speciation of metals hertkorn et al 2004 and nutrients koenings and hooper 1976 mierle and ingram 1991 winch et al 2002 freshwater ecosystems have been considered hot spots for carbon cycling cole et al 2007 because dom carried from the watershed is either processed mineralized or buried in such systems in the water column dom can be photochemically amaral et al 2013 bertilsson and tranvik 2000 gonsior et al 2009 or biologically degraded giorgio et al 1998 medeiros et al 2015 seidel et al 2015 mainly through aerobic processes such mineralization processes result in a transfer of co2 from the lakes to the atmosphere raymond et al 2013 sobek et al 2006 valle et al 2018 in boreal lakes flocculation and subsequent sedimentation of doc are the major sources for sediment organic carbon gudasz et al 2012 extent and selectivity of flocculation are influenced by temperature microbial activity presence of oxygen diversity and abundance of metal ions and ph von wachenfeldt et al 2009 both increased temperature and increased microbial activity have proved to enhance particle formation von wachenfeldt et al 2009 besides the contribution of microbial activity in the formation of autochthonous organic matter it has been proposed that extracellular polymeric substances secreted by bacteria could be relevant for stabilizing the suspended material droppo 2001 droppo and ongley 1994 although decreased ph abate and masini 2003 and anoxic conditions gao and zepp 1998 have been pointed as favoring flocculation it was also proposed that those parameters were indirectly affecting flocculation due to their influence on the microbial activity itself von wachenfeldt et al 2009 in the water column sunlight can play an important role in the transformation of allochthonous doc into particulate organic carbon poc von wachenfeldt et al 2008 allochthonous inflow photo and biodegradation processes in the water column determine the selectivity of dom sedimentation the presence of oxygen which depends on the mixing of the water column tranvik et al 2009 determines the extent of aerobic degradation processes that can happen in this compartment small streams often carry substantial loads of deeply colored waters into boreal lakes and strong gradients are encountered on mixing terrestrial colored dissolved organic matter cdom is rich in lignin and tannin derived compounds which readily complex redox active transition metal ions such as fe2 3 but also main group metal ions such as ca2 in the lake water column sedimentation of poc and mineralization to co2 remove about equal amounts of carbon from the dissolved phase in boreal lakes throughout the year von wachenfeldt and tranvik 2008 flocculation primarily affects allochthonous dom and might be assisted by the aid presence of metal ions under changing conditions of ph and ionic strength killops and killops 2005 microorganisms prefer to attach to surfaces like those provided by pom where they will use high concentrations and gradients of organic and inorganic nutrients and redox conditions to enable sustenance and growth pomeroy et al 2007 sinking particles then accumulate at the lake bottom trapping lake water in the interstitial pore spaces however continual microbial processing of dom in near surface sediments under conditions of now limited diffusion will quickly cause a substantial increase in relative concentration of interstitial pore water dom which will reflect the conditions of their particulate environment rather than that of open lake water valle et al 2018 singer et al 2010 furthermore oxygen stratification and low light penetration will facilitate microbial anaerobic degradation processes in the sediments jonsson et al 2001 increased concentrations of dom and a highly complex microbial community conrad 2007 can produce an individual signature of dom composition with higher proportions of nitrogen and sulfur containing molecules valle et al 2018 since organic matter processing depends on the initial dom pool composition and availability under given redox conditions we expect that water column and sedimentary dom pools show different molecular characteristics here we used negative mode electrospray ionization esi fourier transform ion cyclotron resonance mass spectrometry fticr ms to contrast the molecular diversity of lake water column and sediment pore water solid phase extractable spe dom in 10 swedish boreal lakes fticr ms has been widely used to characterize dom from freshwater ecosystems gonsior et al 2016 jaffé et al 2012 kellerman 2015 to trace changes in dom composition after photo and biodegradation within natural gradients gonsior et al 2014 2009 ide et al 2017 medeiros et al 2015 schmidt et al 2017 2011 tremblay et al 2007 and incubation experiments hodgkins et al 2014 seidel et al 2016 valle et al 2018 the capacity of ultrahigh resolution fticr ms to resolve thousands of individual molecular formulae within natural dom samples hertkorn et al 2008 allowed us to trace molecular differences between distinct dom pools within individual and across multiple lakes 2 material and methods 2 1 site description we collected water column and sediment samples from 10 lakes in the malingsbo area sweden in august 2012 fig 1 description of the investigated lakes can be found in table 1 2 2 sampling we obtained water samples by boat just below the surface approximately at the largest water depth of the lake sediment samples were collected with a small gravity corer we took the upper 10 cm of sediment homogenized it and transferred the samples into 125 ml polyethylene bottles which were completely filled avoiding air bubbles inside solid phase extraction spe of the water samples was done at the field whereas spe of sediment pore water was performed in the laboratory the sediment bottles were kept cold 4 c stored in the dark and shipped by air to the helmholtz zentrum münchen research unit analytical biogeochemistry germany for further experiments 2 3 chemical analysis the water column dom was extracted by a previously described spe method using ppl resin dittmar et al 2008 the detailed sediment pore water spe dom extraction was described elsewhere valle et al 2018 the eluates were stored in the freezer 20 c until mass spectrometry analysis water samples from the lakes were analyzed for dissolved organic carbon doc total nitrogen tn and total phosphorus tp doc was measured with a toc analyzer shimadzu 5000 japan tn and tp were analyzed colourimetrically following persulfate oxidation using an aa3 autoanalyzer bran luebbe germany organic carbon oc content in the sediments was measured in one of the replicates of each sample samples were acidified to remove possibly present carbonates and dried the carbon content was analyzed at the centre for stable isotope research and analysis kosi at göttingen university germany using an elemental analyzer na 2500 ce instruments rodano italy 2 4 ft icr mass spectrometry negative electrospray ionization fourier transform ion cyclotron resonance esi ft icr mass spectra were acquired using a 12t bruker solarix mass spectrometer bruker daltonics bremen germany and an apollo ii electrospray ionization esi source in negative mode hertkorn et al 2016 spe samples were injected using a 223 sample changer gilson inc middleton usa with an adapted in house made software to ft icr ms nebulizer gas pressure drying gas pressure and the source heater temperature were 138 kpa 103 kpa and 200 c respectively the spectra were acquired with a time domain of 4 mw and five hundred scans were accumulated for each mass spectrum all spectra were first externally calibrated on clusters of arginine in meoh 0 57 μmol l and internally calibrated using appropriate reference mass lists of common natural organic matter molecules reaching accuracy values lower than 500 ppb data processing was done using compass data analysis 4 1 bruker bremen germany and formula assignment by an in house made software netcalc tziotis et al 2011 the molecular formula assignments were based on the following elements 1h0 200 12c0 100 16o0 80 32s0 3 14n0 3 as well as the 13c0 1 and 34s0 1 isotopomers the generated formulae were validated by setting sensible chemical constraints n rule o c ratio 1 h c ratio 2n 2 cnh2n 2 restriction on nitrogen and sulfur atoms to counts up to three was based on previous studies of natural organic matter nom where mass assignments with more than three atoms of n and s were commonly not observed at all hertkorn et al 2013 schmitt kopplin et al 2011 mass spectra were acquired from the existing single replicates of lake water column spe dom and from five replicate distinct isolates of sedimentary pore water spe dom valle et al 2018 however to increase consistency we have selected only ions common to the most similar three replicates of sedimentary pore water spe dom for further analysis the reasoning was as follows lake water is well mixed and hence expected to be rather uniform whereas sedimentary pore water composition depends on chemical and microbial reactions occurring in small spatial scales e g singer et al 2010 given the consistently superior stability of our mass spectrometer and the resulting excellent reproducibility of mass spectra acquired from identical samples we had the choice to acquire a single mass spectrum or several mass spectra in a given fixed total acquisition time because we rate excellent definition of mass spectra in the x axis mass resolution and mass accuracy as well as in y direction mass peak amplitude as equally important to discriminate among dom samples we have chosen to use the disposable acquisition time to acquire a single mass spectrum from lake column water spe dom the final assigned molecular formulas were categorized into groups containing cho chno chos and chnos molecular compositions which were used to reconstruct the group selective mass spectra table s1 molecular compositions present in both water column and sediment pore water within each individual lake from now on referred as common mass assignments and molecular compositions unique to each compartment number and percentage of molecular formulas containing cho chno chos or chnos molecular series and the computed average of h c n o s atoms and h c o c c n c s as well as m z mass to charge ratios and other relevant bulk parameters are shown in tables s2 s3 and s4 an important tool in data visualization of mass spectra is the van krevelen diagram van krevelen 1950 based on their elemental ratios commonly h c versus o c derived from assigned molecular formulas each data point is a projection of a given elemental ratio regardless of the molecular mass schmitt kopplin et al 2012 main chemical classes found in dom often show characteristic h c and o c ratios and cluster within specific regions of van krevelen diagrams kim et al 2003 rivas ubach et al 2018 thus evolution of patterns in van krevelen diagrams of dom reflects not only the source material but may also indicate changes in bulk dom composition due to degradation and hint at possible chemical reactions during dom evolution methylation oxidation and hydrogenation for example kim et al 2003 the kendrick mass defect analysis kmd is another important visualization tool of ft icr mass spectra hughey et al 2001 of which the kmd z diagram is a useful extension shakeri yekta et al 2012 here the kendrick mass defect is divided by an empirical integer sorting parameter z introduced by hsu et al 1992 which is defined by the molecular moiety under investigation for instance methylene ch2 with a nominal mass of 14 implies a range for z from 1 to 14 kmd z diagrams remove projections present in standard kmd diagrams by dividing the single kmd diagram into 14 subpanels this might offer viable leads into the compositional characterization of nom processing cf fig s7 and fig s8 in kmd z versus mass diagrams shakeri yekta et al 2012 valle et al 2018 molecular compositions with identical kmd z represent unique homologous series naturally the most relevant homologous series present in dom are methylene and dbe based moieties reflecting mass difference of homologous molecules δm ch2 by 14 0156 da providing horizontal lines in kmd z diagrams δm h2 by 2 0157 da providing upward sloped lines in kmd z diagrams and δm ch4 o by 36 4 mda providing vertical lines in kmd z diagrams gonsior et al 2014 hsu et al 1992 perdue and green 2015 shakeri yekta et al 2012 stenson et al 2003 2 5 statistical analysis hierarchical cluster analysis hca was performed using the hierarchical clustering explorer 3 0 hce http www cs umd edu hcil multi cluster with clustering of the dataset using the average linkage upgma method and the pearson correlation coefficient pearson s r as the similarity distance measure principal component analysis pca was performed with the software simca p 9 0 umetrics ab sweden determination of unique molecular formulas in each compartment was done based on presence and absence 3 results and discussion in this study we investigated open lake water and sediment pore water spe dom ppl obtained from 10 boreal lakes located in malingsbo region sweden fig 1 which were selected for their large diversity of physico chemical and morphological characteristics table 1 for instance water column doc ranged from 3 9 mg l 1 lustjärn to 25 7 mg l 1 svärttjärn whereas sedimentary organic carbon ranged from 8 5 svarttjärn to 34 8 ljustjärn table 1 lakes svarttjärn skittjärn and oppsveten showed the highest values for water doc tn and tp lake ljustjärn showed the lowest concentration of lake water column doc but the highest values for both sediment orgc and n the larger lakes were övre skärsjön 165 ha oppsveten stora snesnaren bisen and lilla sången 24 ha while the smallest lake covered merely 0 7 ha svärttjärn water residence time is a function of area and depth and therefore followed the same gross order in analogy to the bulk characteristics of individual lakes the molecular diversity of lake water and sediment pore water spe dom as observed by esi fticr mass spectra showed general and individual trends that helped us to comprehend the mechanisms of dom processing in freshwater lakes and sediments fig 2 for most of the lakes with exception of grästjärn lilla sången and ljustjärn sediment pore water spe dom showed larger counts of assigned mass peaks than the water column spe dom pool table s1 a general feature was a higher proportion of heteroatom containing compounds in sediment pore water spe dom compared with lake water spe dom as expressed by c n and c s ratios table s1 all lakes presented higher relative abundance of n containing molecules average n in the sediment pore water spe dom the percentage of s containing compounds average s was however higher in the sediments of the majority of the lakes but with the exceptions of stora snesnaren and skotttjärn virtually same values for water column and sediment pore water and bisen and oppsveten higher percentage of sulfur in the water column spe dom pool table s1 molecular formulas present in the water column spe dom pool were usually more saturated than the ones in the sediment pore water spe dom pool table s1 fig 3 additionally sediment pore water spe dom was overall more oxygenated than water column spe dom with lakes grästjärn and ljustjärn being near equal in general sediment pore water spe dom molecules covered a larger area in van krevelen diagrams for all boreal lakes fig s2 fig 2 fig 4 this feature reflected an overall higher molecular diversity of sedimentary porewater spe dom compared with those found in the lake water column spe dom pools this is expected because sediment pore water composition depends on distinct and heterogeneous consortia of microorganisms separated by open ground singer et al 2010 as well as mineral composition and texture with much steeper gradients of concentration composition and redox conditions than observed in the well mixed open water column burdige 2001 komada et al 2013 krause et al 2009 siljanen et al 2011 the mass peak distribution for lake water column and sedimentary pore water spe dom showed the typical skewed near gaussian distribution common for environmental spe dom fig s1 with sedimentary pore water spe dom occupying a higher mass range m z 160 820 figs s1d and a lees steep decline at higher mass than observed for lake water spe dom m z 160 750 fig s1b the molecular compositions common to both lake water column and sedimentary pore water spe dom fig s1c showed a narrower and more even distribution indicative of substantial averaging between these two compartments the compounds unique to sedimentary pore water spe dom fig s1e extended to higher mass and showed a smooth decrease of mass peak amplitudes from m z 500 this indicated a fairly processed organic matter rather than selected classes of metabolites at higher mass as opposed to a noticeable patterning at m z 500 which resulted from selective degradation and re synthesis of biomolecules and metabolites roth et al 2019 in comparison the mass peak distribution of compounds unique to the lake water column showed distinctive patterning which is improbable to arise from processing intrinsic to the well mixed water column instead the omission of mass peaks from m z 290 320 fig s1a blue shade and m z 380 410 fig s1a purple shade most probably arose from selective processing of sedimentary pore water spe dom which preferentially produced compounds within these selected mass ranges even if these compounds were not conspicuous with respect to mass peak amplitude fig s1d their presence strongly affected the computed mass peak distributions of compounds unique to the lake water column spe dom fig s1a furthermore this trend did not appear in either van krevelen or h c against mass diagrams this in part derived from the fact that compounds from both compartments occupied analogous areas in these diagrams with considerable density fig s3 based on the mass spectra acquired for both water column and sediment pore water spe dom we first determined the ubiquitous assigned molecular compositions which were present in both water column and sedimentary spe dom and in all 10 lakes table s1 fig s1 the exclusion of molecular compositions with variable extent of uniqueness e g found in a single to a few lakes and or sedimentary pore water implied a substantial averaging cf fig s1c but this procedure revealed fundamental and robust trends of dom evolution in boreal lakes when relative abundances were recognized the entire data set of common molecular compositions observed in all 10 lakes was at first decomposed into compounds relatively more abundant in open lake water spe dom and in those relatively more abundant in sedimentary pore water spe dom compared with mass spectra of individual spe dom which commonly showed mass peaks ranging from m z 180 820 fig s1 the mass range for averaged water column spe dom was reduced to m z 220 400 and that for sedimentary spe dom to m z 200 370 fig 2c fig s2 average h c and o c values derived from molecular compositions common to both compartments in individual lakes table s2 ranged in between those of lake water and sediment pore water spe dom exceptions were grästjärn and ljustjärn for h c ratios whereas mass weighted averages followed non uniform trends table s2 we used differences in relative abundance of the assigned molecular compositions which were present in lake water and in sedimentary pore water spe dom and in all 10 lakes common to all 10 lakes to perform hierarchical cluster analysis hca fig 2a principal component analysis pca fig 2b and to compute differential mass spectra spe dom sediment spe dom water column fig 2c based on normalized mass spectra total amplitude of assigned molecular compositions 100 distinct clustering between water column and sediment pore water spe dom was observed in hca and pca for nine lakes with the exception of lustjärn which showed resemblance of both spe dom and an overall molecular composition distinct from that of all other lakes hence spe dom pools from each compartment i e lake water column or sedimentary spe dom were more similar among themselves than pools from different compartments within identical lakes in fact lake ljustjärn was an exception among the swedish boreal lakes used in this study because it was influenced by groundwater inflow and received low amounts of organic matter from the rather tiny drainage area as a result low doc concentration and low water color were found in this lake von wachenfeldt and tranvik 2008 however results from previous studies have shown that groundwater transport of allochthonous carbon is highly unlikely to be of importance for poc and that most of the sedimentation has autochthonous origin in this lake von wachenfeldt and tranvik 2008 another feature deserves mentioning lake ljustjärn features the lowest content of doc and the highest proportion of sedimentary organic carbon table 1 lake ljustjarn sediments have a peaty layer below a sand layer of which we are aware of because of past coring ljustjärn is a ground water fed kettle lake but at some time in the past there must have been extensive benthic macrophyte growth or floating sphagnum mats that sank to the bottom difference ftms spectra display linear relationships between all data points and were far better suited to depict the rather gradual variations among all pairs of spectra than a ratio analysis here compounds with higher relative abundance in the sediment pore water showed positive amplitude and compounds with higher relative abundance in the water column showed negative amplitude fig 2c fig s2 already at the level of visual inspection lake water column spe dom common to all lakes showed rather regular skewed gaussian distribution of mass peaks ranging from m z 220 370 da which was dominated by mass spacing dbe h2 δm 2 0157 da not visible in figures and ch2 δm 14 0156 da representing freshwater dom with the typical characteristics of an evolved biogeochemical material schmitt kopplin et al 2012 in comparison compounds more abundant in sediment pore water showed a rather bimodal distribution with a minimum of abundance from 330 to 370 da extending to lower mass 180 da and showing rather irregular patterning which is characteristic of mixtures of biomolecules zhang et al 2014 while the mass weighted average of sediment pore water spe dom was commonly by 10 25 da larger than that of lake water column spe dom table s1 some water column dom molecules extended to higher mass than those found in sediment pore water spe dom fig 2c at the level of individual lakes clear patterning was observed for lake 10 sedimentary spe dom övre skärsjön whereas abundant low mass peaks m z 200 320 indicative of biological activity were present in most sedimentary spe dom fig s2 the display of common molecular assignments in the van krevelen and mass edited h c ratio diagrams with recognition of relative abundance fig 2d m also revealed specific trends in each compartment first no chos compounds showed increased relative abundance in the lake water column spe dom the fact that not any single chos compound was relatively more abundant in the lake water column indicates either chemoselective removal of chos compounds in the lake water column e g by photooxidation ossola et al 2019 or and rather effective production of chos compounds in the sediment e g by reductive sulfurization under conditions of oxygen limitation hebting et al 2006 second the cho fig 2d and chno compounds fig 2f with higher relative abundance in the sediment pore water spe dom occupied larger areas in the van krevelen diagrams reflecting a higher molecular diversity of sedimentary spe dom related to synthesis and selective preservation of organic molecules in sediments roth et al 2019 raven et al 2016 while assigned mass peaks with increased relative abundance in sediment pore water spe dom occupied sections indicative of more saturated lipid like and more oxygendated and hydrogen deficient lignin and tannin like compounds fig 2d lake water column spe dom was enriched in carboxyl rich alicyclic compounds cram fig 2e of more average h c and o c ratios the alternate display of common molecular compositions between lake water column and sediment pore water spe dom bulk characteristics table s2 produced sawtooth like patterns indicative of regular variations between those materials for nine lakes again with the exception of lake ljustjärn fig 3 the average h c ratios and the relative proportions of cho compounds were larger in the water column spe dom whereas the average o c ratios relative unsaturation as expressed by dbe c ratio and the proportions of chno and chos compounds were larger in the sedimentary porewater spe dom table s2 fig 3 these features conformed to key characteristics of microbial oxidation of dom and formation of cram in which sizable proportions of alicyclic rings decreasing the h c ratio and increasing the dbe c ratio and carboxylic acids increasing both the o c ratio and the dbe c ratio are generated hertkorn et al 2016 in general average mass increased from lake water column water spe dom to sedimentary pore water spe dom however gäddjärn showed near unchanged average mass whereas average mass of svärttjärn grästjärn lilla sången and in particular ljustjärn decreased from lake water column spe dom to sediment pore water spe dom fig 3 table s2 this indicated that in general higher proportions of aliphatic compounds and smaller proportions of oxygenated compounds were observed in lake water spe dom one plausible reason is photodegradation of dom in the well mixed and oxygenated open water column which initiates partial photomineralization to produce the oxygen rich byproducts co2 and h2o amaral et al 2013 chupakova et al 2018 wolf et al 2018 hence carbon in the form of co2 and various oxygen rich functional groups will then no longer be available for resynthesis of dom molecules this leads to an apparent deoxygenation of residual dom even in case of its oxidative degradation einsiedl et al 2007 aromatic and unsaturated compounds are in general susceptible to photodegradation owing to their csp2 based chromophoric groups von wachenfeldt et al 2009 gonsior et al 2009 another key feature was the presence of higher proportions of chno and chos compounds in the sedimentary pore water this higher abundance of heteroatoms in sediment spe dom likely results from an intense bioactivity in the sediments which will produce a succession of microbial metabolites in complex foodwebs herzsprung et al 2010 hodgkins et al 2014 2016 roth et al 2014 2019 seidel et al 2014 all these compounds will be subject to reductive sulfurization reactions under oxygen limited conditions hebting et al 2006 contributing to elevated abundance of chos compounds of which some will accumulate structural motifs with certain resistance against enzymatic degradation next we investigated the molecular compositions which were unique in either the water column or in the sediment pore water spe dom in all of the 10 lakes tables s3 and s4 fig s4 van krevelen diagrams showing these unique features present in all 10 investigated lakes covered a larger diversity of compounds fig 4 compared with the respective compounds common to all 10 lakes fig 2 this is expected because common features present within all lakes were subject to far higher intrinsic averaging than the respective unique features fig s1 fig s2 fig s3 this intrinsic averaging favours presence of compounds with average h c and o c ratios for which the count of feasible isomeric structures for given molecular formulas is maximal hertkorn et al 2007 fig 2e h fig 2j m the situation is different for cho compounds in sedimentary pore water spe dom fig 2d 2i for which distinctive microbial and chemical transformations have produced lipid like compounds with large h c and low o c ratios on one hand and polyphenol type compounds with low h c and high o c ratios on the other hand these two main classes of abundant compounds enveloped the section of cram in van krevelen diagrams of lake column water causing a distinctive gap in the van krevelen diagram of cho molecules unique to sedimentary pore water fig 2d 2i water column cho and chno compounds showed similar patterning in van krevelen diagrams with chno compounds being more compacted and ranging toward higher relative unsaturation fig 4a fig 4b however chno compounds showed considerably smaller masses than cho compounds in the h c against mass diagrams fig 4a fig 4b this indicates that cho and chno compounds in lake column spe dom differed greatly in their chemical structures the chos compounds found more abundant in lake column spe dom were widely scattered in van krevelen diagrams and h c against mass diagrams while lightly following distributions found for cho compounds this observation concurs with a supposed functionalization of selected cho compounds with oxygenated sulfur containing functional groups however with no distinctive structural preference in general trends observed for unique compounds fig 4 fig s4 were analogous to those observed for abundance weighted common molecular compositions fig 2 chos compounds covered relative large areas in the van krevelen diagrams in both compartments indicating a rather large chemical diversity while a sizable proportion of lake water chos compounds occupied the same area as cram the chos compounds in sediment pore water reflected rather saturated lipid like compounds and s derivatives of lignin and tannin like compounds possibly modified products of these rather stable constituents gonsior et al 2016 herzsprung et al 2010 furthermore both common and unique compositions showed an apparent trend towards an increased mass weighted average in the sediment pore water when compared to the water column samples fig s1 indicative of preferential microbial processing of low mass molecules and or selective preservation of larger size molecules hodgkins et al 2016 seidel et al 2014 roth et al 2019 and selective preservation of more refractory compounds such as polyphenols guillemette et al 2017 kellerman et al 2015 valle et al 2018 taking the common molecular assignments into consideration fig 2 table s2 we decided not only to visualize the standard ch2 based kmd diagrams fig s5 but also to visualize the kmd z diagrams for each individual z value fig s6 in addition we have plotted the respective molecular compositions in van krevelen diagrams fig s6a introducing the z sorting parameter removed projection and revealed a clear clustering of cho compounds which were found more abundant in lake column water spe dom on one hand and of those found more abundant in sedimentary pore water spe dom on the other hand which were obscured in standard kmd diagrams fig s5 interestingly but not overly surprising compounds with odd z values were mainly chn1o whereas compounds with even z values were mainly cho with a few chos compounds we have investigated the kmd z versus m z plots for z 4 fig s7 and z 5 fig s8 in some more detail while the kmd z 5 diagram showed only four series of chn1o compounds with ascending counts of dbe related by a nominal exchange of δm c1h4o 1 36 4 mda which were relatively more abundant in sedimentary pore water spe dom fig s7 the respective kmd z 4 diagram was rather elaborate with two major series with ascending counts of dbe related by a nominal exchange of δm c1h4o 1 36 39 mda fig s8 these two series derived from ch2 based homologous series with c10h10o3 showing the lowest mass yellow shaded molecular series in fig s8 with increasing counts of dbe related by δm c1h4o 1 36 39 mda this molecular series was more abundant in lake column water spe dom at low kmd z values whereas at higher kmd z values lower mass molecules of this series were more abundant in sedimentary pore water spe dom however higher mass members of this ch2 based molecular series were consistently more abundant in lake water column spe dom fig s8 the other ch2 based series was offset from the first series by δm c4o 3 15 26 mda fig s8 and showed the low mass member c11h20o6 which was considerably more saturated and oxygenated than the base molecule c10h10o3 of the other series these relationships were also depicted in the van krevelen diagram in which the yellow shaded molecular series with z 4 corresponded to the respective contiguous assembly with lower h c and o c ratios fig s6a these initial elaborations suggest that significant information can be drawn from kmd z diagrams when more precise compositional relationships during processing of dom molecules in environmental settings will be investigated a detailed elaboration is however beyond the scope of this contribution in summary sediment pore water spe dom showed higher aliphaticity oxygenation and a higher proportion of chos and chno compounds analogous trends have been recently observed in anoxic incubation experiments of sedimentary pore water itself valle et al 2018 and were attributed to lake specific large scale transformations of organic matter through microbial activity the transition from lake water column to sedimentary pore water itself is initiated by flocculation biotic flocculation pom abiotic flocculation photochemistry and metal complexation sinking particles accumulate at the bottom of the lakes and impede the rather unrestricted mixing of water which is characteristic of the commonly oxic lake water column diffusion from organic rich particles and microbial processing of dom quickly build up higher doc concentrations and lead to depletion of oxygen depending on individual conditions liikanen et al 2003 production of n rich microbial metabolites and large scale sulfurization reactions under conditions of oxygen limitation produced a substantial range of chno and chos compounds hodgkins et al 2016 shakeri yekta et al 2012 4 conclusion this study revealed that selectivity of dom degradation in the mixed and oxic water column and subsequent processing preservation of dom in the sediments left distinct imprints on dom composition among boreal lakes notwithstanding individual characteristics of each system despite lake specific features in each of the boreal lakes studied both common and unique compounds showed similar trends when lake water column and sediment pore water spe dom pools were confronted those trends even prevailed when only molecular compositions common to all lakes and compartments were considered necessarily with recognition of the relative abundance photochemical processing and microbial degradation of dom were key reactions moreover increased proportions of heteroatoms in the sediment pore water spe dom revealed enhanced microbial activity in this compartment in comparison with the water column these results demonstrate that high resolution mass spectra of freshwater dom in lakes followed by mathematical data analysis revealed significant molecular changes these in turn contributed to a better understanding of mechanisms governing the temporal evolution of carbon chemical environments in freshwater ecosystems already the comparison of cho and chno compounds revealed that current science offers still very rudimentary understanding of even basic features of compositional and structural characteristics of dom author contributions j v m g p s and n h collected samples from swedish lakes in august 2012 d b generated funding in support of this research a p and d b contributed to the study design j v m g and m h performed the ft icr ms acquisition data analyses and participated in data interpretation p s k provided support for the ft icr ms analyses and general data interpretations data interpretation was performed by all authors j v m h and n h actively participated in the writing of the manuscript all authors provided significant input on the final manuscript declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the financial support from the swedish research councils vr 2012 00048 stint 2012 2085 and european research council erc grant no 725546 j v thanks the brazilian national council of technological and scientific development cnpq 290004 2014 4 and the alexander von humboldt foundation for fellowship and financial support research group linkage brazil germany connecting the diversity of dissolved organic matter and co2 and ch4 production in tropical lakes a p is a research fellow from cnpq and cientista do estado from faperj fundação de amparo à pesquisa do estado do rio de janeiro and uses financial resources from these two funding agencies and also from capes coordenação de aperfeiçoamento de pessoal de nível superior and stint the swedish foundation for international cooperation in research and higher education for this research m h thanks daad for the ppp exchange program with the federal university of rio de janeiro appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 115320 
18309,solar driven evaporation has been proposed as an efficient way to harvest solar energy for water treatment and desalination however the complex preparation process and the degradation of photothermal absorbers restrict their practical applications in solar thermal technology herein a solar assisted fabrication of three dimensional dimpled mos2 membrane dmm sa with an open macroporous 1 2 μm network is fabricated by folding and overlapping nanosheets under solar illumination dmm sa exhibits superior water permeability 334 461 lmh bar and extraordinary chemical and structural stability compared to the 1t and mixed phase dmm sa samples 2h dmm sa floating on the water surface generates high heat localization and achieves high evaporation efficiencies of 83 8 0 8 and 91 5 1 1 at 1 and 3 sun illumination respectively after multiple illumination and regeneration cycles 2h dmm sa presents high water evaporation and salt rejection performance after desalination the salinity level of permeate water is far below the world health organization who standard numerical simulations verify that the inner spaces between two nanosheets and the nanochannels contribute to the high bulk water and vapor fluxes during desalination the facile and efficient design of 3d 2h dmm sa provides a novel avenue for seawater utilization by harvesting solar energy graphical abstract image 1 keywords desalination dimpled mos2 membrane photothermal conversion steam generation 1t and 2h phases 1 introduction with serious water pollution and the energy saving demands for water purification major developments in water treatment have focused on desalination such as membrane based designs of reverse osmosis ro and thermal based designs of membrane distillation technology bai et al 2019 tong et al 2017 noticeably the energy intensive ro systems are extremely challenging for low energy efficiency high operating pressure and irreversible degradation of membranes the efficient utilization of solar energy as the only energy source to generate clean water from seawater and industrial wastewater is a promising approach for solving water resource scarcity issues wilson et al 2019 kim et al 2018 recent developments in innovative plasmonic photothermal membrane distillation hold immense promise for producing desalinated water at a high thermal efficiency and relatively low energy input yu et al 2018a b mu et al 2019 during the membrane distillation process water purification is driven by a vapor pressure gradient across a floating porous membrane the heat localization system efficiently transfers the solar energy to nearby water for steam generation while minimizing heat loss to the air and bulk water mu et al 2019 until now a variety of photothermal materials were utilized for efficient light absorption such as graphene reduced graphene oxide rgo yang et al 2018 zhang et al 2017 graphene oxide go li et al 2017 carbon nanotubes cnt yin et al 2017 layer and cermet coated on a copper sheet ni et al 2016 on a thermal insulator however these absorbers or photothermal materials suffer from complex preparation procedures or high energy consumption jia et al 2014 it is important and urgent for solar thermal water treatment in addition hydrophobic graphene cnt and black carbon could not maintain effectively contact with water li et al 2018 seo et al 2018 dong et al 2018 shao et al 2018 and hydrophilic go suffered swelling and dissolving in aqueous solution wang et al 2017a yeh et al 2015 in addition the chemical and structural alterations after long time irradiation and the degradation of the membrane performance by diverse contaminants and challenging environments lin et al 2016 lu et al 2016 affect the performance in membrane distillation guo et al 2019a b moreover conventional hydrophobic membranes have limited effectiveness to minimize heat loss to the air and bulk water and transfer heat to water within the pores of membrane for water evaporation zhang et al 2015 both organic solvent addition and surface modification are general methods to fabricate hydrophobic membranes but not energy saving or environmentally friendly for practical applications hydrophilic membranes for distillation should possess broadband and efficient solar absorption and a porous network to provide vapor channels monolayer mos2 a typical transition metal dichalcogenide tmd possesses unique electronic and optical properties kurapati et al 2016 krasian et al 2019 alam et al 2019 monolayer mos2 exists as a polymorph and can display different phases such as the metallic 1t phase and the semiconductor 2h phase liu et al 2018 kurapati et al 2016 several strategies have been used to synthesize monolayer mos2 such as physical exfoliation radisavljevic et al 2011 electron beam irradiation fan et al 2015 colloidal synthesis kurapati et al 2016 and chemical vapor deposition cvd kim et al 2016 however the 1t phase of mos2 is metastable and can easily be converted into the stable 2h phase thus fabricating monolayer mos2 with a high phase purity remains a great challenge as a promising solar absorber monolayer mos2 absorbed 5 10 2 3 for monolayer graphene of incident sunlight in a thickness of less than 1 nm exhibiting 1 order of magnitude stronger sunlight absorption than monolayer gaas and si two of the most commonly used absorbers in solar cells tsai et al 2014 wang and sambur 2019 mos2 nanosheets in a membrane formation may exhibit thermal and mechanical stability wang et al 2017a 2017b moreover the designed surface topography of membrane was helpful to improve the water transport guo et al 2019a b tsou et al 2015 and the pores and defects on the mos2 nanosheets were expected to be highly ion selective and water permeable thiruraman et al 2018 the regulation of the surface topography and porosity of mos2 nanosheet layers may enable the fabrication of new membranes for highly efficient water desalination under solar irradiation herein we report a facile and efficient method for achieving the crystal phase controlled synthesis of 2h and 1t mos2 nanosheets the excellent photothermal conversion of mos2 provides thermally responsive water transport channels solar assisted fabrication of dimpled mos2 membrane dmm sa facilitating rapid water transport through the mos2 membrane superior to the membranes of most previous reports 2h dmm sa exhibits high bulk water and vapor fluxes salt rejection high efficiency removal of heavy metal and stability 72 h as well as solar steam efficiencies of 83 8 0 8 and 91 5 1 1 under one sun and 3 sun illumination respectively moreover computational simulations reveal the mechanism of water vapor permeation in 2h dmm sa which occurs through the inherent nanochannels of the sharply dimpled surfaces 2 materials and methods 2 1 preparation of 1t 2h and mixed phase mos2 nanosheets mos2 nanosheets were prepared by a chemical exfoliation method in a nitrogen filled glovebox 500 mg of mos2 powder nanjing xfnano materials tech co ltd china was dispersed into 10 ml of 1 6 m n butyllithium in hexane solution sigma aldrich usa under moderate stirring for lithium intercalation after reacting for 2 days the intercalated samples were retrieved by centrifugation and washed using hexane to remove excess lithium and organic residue then the samples were sonicated at 250 w in an ice bath for 1 h to obtain the exfoliated nanosheets followed by centrifugation at 1510 x g for 10 min to obtain mp mos2 nanosheets the dispersions of chemically exfoliated mos2 samples were stored in a glovebox the 1t phased mos2 nanosheets were synthesized in the solution phase by a microwave assisted method the pre exfoliated mos2 were dispersed in a 1 mg ml solution of koh then the samples 10 ml were irradiated using a single mode microwave at 200 w and 2 45 ghz mas ii plus china the temperature of the suspension was increased from room temperature to 180 c 30 c min and the sample was held at temperature for 40 min the synthesized 1t mos2 sample was annealed in a quartz tube furnace at 300 c for 3 h to obtain 2h phase mos2 nanosheets 2 2 preparation of the solar assisted fabrication of three dimensional dimpled mos2 membrane the laminar mos2 membrane was assembled by vacuum filtration in a stirred cell 30 ml on a porous poly ether sulfone substrate sterlitech kent usa with a nominal pore size of approximately 0 22 μm the thickness of the membrane was controlled by controlling the volume and concentration of the mos2 solution with 10 ml at 0 2 mg ml leading to a membrane thickness of approximately 1 6 μm to obtain three dimensional dimpled mos2 membrane the freshly prepared wet membranes were irradiated for 3 h at 1 kw m2 one sun by a solar simulator cel pf300 t8e beijing au light china to test the permeance and rejection of various salts nacl cacl2 pbcl2 and fecl3 the mos2 membrane was first stabilized at 0 98 bar for 30 min 2 3 nanomaterial and membrane characterization the morphologies of the nanomaterials were characterized by tem jeol jem 200cx japan and atomic force microscopy afm bruker multimode germany the membrane morphology and microstructure were investigated by sem jsm 7500f japan the ζ potential measurements were conducted on a zeta nanosizer malvern instruments uk x ray photoelectron spectroscopy xps analysis of the samples was carried out using an escalab 250xi spectrometer thermo scientific usa the xrd patterns of the nanomaterials were obtained using an x ray diffractometer xrd rigaku smart lab japan operating at 40 kv and 40 ma with cu kα radiation λ 1 542 å 2 4 steam generation experiments the circular mos2 membrane samples 15 mm in diameter allowed to float on water in a glass tube 20 ml by positioning them on a piece of a polystyrene sheet approximately 5 mm thick as a control a raised configuration was evaluated in which the glass tube hold 15 ml deionized water and the mos2 membranes were placed on the top of water by positioning it on a piece of polystyrene sheet with a distance of 2 cm from water surface to bottom surface of polystyrene foam water was transported from the bulk water to the mos2 membranes by capillary action through a fiber the samples were irradiated by a 300 w solar simulator with a wavelength range of 200 1100 nm and 21 a cel pf300 t8e beijing au light china the evaporation rate was calculated based on the change in the recorded mass of water lost over time using an electronic mass balance with an accuracy of 0 0001 g the temperature evolution was monitored by taking infrared images with an infrared thermal imaging camera uw aaa seek thermal usa before and after irradiation time interval was 10 min during irradiation the simulated wastewater with metal ions cr3 pb2 cd2 zn2 and cu2 was prepared by dissolving chromic chloride lead nitrate zinc chloride nickel chloride and cupric nitrate in ultrapure water the mass concentration was 100 mg ml for the individual ions the solar thermal conversion efficiency η is given by η mhlv i where η is solar thermal conversion efficiency m kg m 2 h 1 is the evaporation mass flux hlv j g 1 is the total enthalpy of sensible heat and phase change of liquid to water and i j m 2 s 1 is the power density of solar illumination 2 5 numerical simulations the first principles calculations were based on density functional theory dft using the vienna ab initio simulation package vasp klemm et al 2011 the generalized gradient approximation gga in the form of the perdew burke ernzerhof functional was used to approximate the exchange and correlation potential interactions between the electrons and ion cores were described by the projector augmented wave paw potential a cutoff energy of 300 ev was employed for the planewave expansion of the wavefunctions the energy barrier for water molecules penetrating through the slit between two mos2 nanosheets in the same layer was obtained by using the climbing image nudged elastic band ci neb method henkelman et al 2000 a large scale atomic molecular massively parallel simulator lammps program package was used for the md simulations and to visualize the md the simulated system for water molecule intercalation consisted of two mos2 layers and reservoirs of water the area of the simulated mos2 layer was 46 8 å 50 6 å for the md simulations the atomic positions of the mos2 layers were fixed and the interlayer distance was defined as 0 6 nm the simulated system of water permeation through the layered structure of the mos2 membrane was constructed from seven mos2 nanosheets each mos2 nanosheet was built with a size of 45 2 å 50 6 å a fixed slit of 22 2 å and a nanochannel between two layers of 6 å each of the mos2 nanosheets with a 45 incline represented the solar induced protrusions in the mos2 membrane for the force models the interactions between water molecules were computed using an extended simple point charge smidstrup et al 2014 spc e water model with a long range coulomb particle particle particle mesh method for the van der waals interactions between water molecules and the mos2 nanosheets the lennard jones parameters were fit to the potential energy curves obtained from the dft calculations of a model system with a single water molecule in the present study the membrane mo and s atoms were kept fixed in position the production run lasted for 1000 ps and the water and ion permeation rates were measured in terms of the number of water molecules or na and cl entering the permeated region 3 results and discussion 3 1 fabricating phase pure and stable mos2 nanosheets mp mos2 nanosheets were prepared from the bulk mos2 via li intercalation which was facile to produce mos2 nanosheets in a large scale li et al 2019 the preparation method for the 1t and 2h mos2 nanosheets and their respective membranes is provided in fig 1 a d the crystal structures of 1t and 2h mos2 are shown in fig 1f and h respectively showing trigonal prismatic coordinated 2h mos2 and distorted octahedral coordinated 1t mos2 voiry et al 2015 primo et al 2019 the transmission electron microscopy tem and atomic force microscopy afm images in fig s1 show that the obtained mos2 nanosheets exhibit an approximately 1 2 μm lateral size and approximately 1 1 1 3 nm thickness respectively and are mostly monolayer or bilayer structures high resolution tem fig 1f shows regions of clustered mo on the basal plane of 1t mos2 characterized by zigzag chain clusters wang et al 2017a 2017b after annealing a hexagonal lattice of 2h mos2 is clearly visible in the basal plane fig 1h with the mo atoms of one layer overlapping with the sulfur atoms in another layer chhowalla et al 2013 nanopores with diameters of approximately 10 20 nm fig s1 and vacancy defects sizes less than 1 nm fig s2 are introduced into the exfoliated mos2 nanosheets after the phase transition the 2h and 1t mos2 nanosheets tend to be wrinkled forming several overlapping folds and the nanopores in the mos2 surface are maintained figs s1d and f the open nanoporous structure of the mos2 nanosheets was expected to facilitate water molecule transport and ion selective filtration thiruraman et al 2018 jang et al 2017 as studied in the following sections as shown in fig 1i the mo 3d5 2 and mo 3d3 2 peaks of the pristine exfoliated mos2 nanosheets were deconvoluted into two independent components with 33 6 of the 1t phase and 66 4 of the 2h phase the nanosheets were converted into 92 5 of the 1t phase and approximately 100 of the 2h phase after the microwave irradiation and heat annealing treatments respectively in fig s3a the raman spectra show typical j1 j2 j3 and e1g precursor peaks for the metastable 1t mos2 nanosheets and two main raman modes a1g and e2g in thermodynamically stable 2h mos2 nanosheets li et al 2012 all these distinct changes confirmed the successful synthesis of high phase purity mos2 nanosheets the present method is easily scaled up and low cost for the phase controlled synthesis of mos2 nanosheets compared to other strategies such as chemical vapor deposition li et al 2019 infrared laser irradiation yu et al 2018a b and other chemical activations chang et al 2016 the fabricated mos2 samples presented a highly negative charge density with electrophoretic mobilities of approximately 3 0 10 15 m2 v under neutral ph conditions fig s3b which is favorable for desalination applications as confirmed in the following sections 3 2 solar responsive microstructure and anti swelling properties of 2h dmm sa a 10 ml mos2 suspension at 0 2 mg ml led to a membrane thickness of approximately 1 6 μm with a laminar structure fig 2 a the orientation of the vacuum assisted nanosheets in the mos2 membranes was found to be a well packed layer by layer pattern and layers further from the substrate became comparatively random which favors the introduction of water into the interface of the membrane the surface morphology of the membrane is shown in fig 2c and fig s4 where slight surface wrinkles are observed and the mos2 nanosheets partially overlap to form spaces serving as fluidic nanochannels for molecular separation the solar pre treatment was used to fabricate the dimpled surface and open microstructures for later solar steam generation after 3 h solar illumination 1 kw m2 the lamellar spaces of the mos2 nanosheets were obviously widened and the thickness of membrane increased to approximately 2 1 μm and the orientation of the nanosheets became random and loose fig 2b the solar accelerated water evaporation flux disrupted the sheets and created the dimpled and loose structure of membrane leading to the increase of membrane thickness after drying off water the microstructures of membrane were in an open state and the pores in the microstructures were widened or merged together to the sizes of approximately 1 2 μm fig 2d a large number of protrusions with different heights and valleys appearing similar to a mountain range are formed as seen in fig 2d and fig s4 the ridges which act as a skeleton are formed from the nanosheets folding or overlapping micrometre sized pores have been shown to be more appropriate than nanopores for efficient capillary pumping of water ito et al 2015 the pores in the solar assisted fabrication of dimpled mos2 membrane 3d dmm sa exhibited a highly interconnected macroporous structure which enables the effective access and diffusion of various ions and molecules in addition the hydrophilic surface fig s5 of the 2h mos2 membranes could maintain contact with water and thus provide effective heat transfer to water during the solar evaporation experiments as confirmed in the following sections compared to the fabrication of 3d frameworks via polymer cross linking post incorporation of polymers reduction self assembly and mixing polymer templates this solar assisted deformation method is a green resource efficient and scalable method for producing 3d dmm sa barner kowollik et al 2017 tian et al 2017 lethien et al 2019 the xrd pattern fig 2e of the mos2 membrane shows a hexagonal structure and the 002 peak of 2h mos2 exhibited obvious red shift with the interlayer spacing increasing to 0 64 nm consistent with the crystal structure symmetric distribution and ordered stacking of the 2d layers the interlayer space may serve as a nanochannel for water to pass through williams et al 2019 the anti swelling property of hydrophilic 2h mos2 was investigated to evaluate its mechanical stability in water after 1 3 days of soaking in water there was no significant change in the interlayer spacing of a hydrated mos2 membrane fig 2f the peak of the air dried 2h mos2 membrane became stronger and the peak position was almost unchanged confirming the structural stability of the mos2 membrane the fully hydrated mos2 membranes remained intact in hcl 3 m and naoh 3 m solutions after iterative soaking and agitation processes movie s1 and fig s6 in contrast the free standing graphene oxide go membrane disintegrated immediately upon hydration without any mechanical agitation yeh et al 2015 the released mo and s species of the fully hydrated 2h mos2 membrane were 0 73 and 0 46 mg l respectively and accounted for less than 2 of the membrane mass fig s7 after sunlight treatment for 72 h at 1 kw m2 one sun which were much lower than that of reported mos2 nanosheets dispersed in aqueous solution wang et al 2016 zou et al 2019 xps analyses raman spectrum and dry mass of mos2 membrane fig s8 confirmed no obvious degradation of layer stacked 2h mos2 membrane supplementary data related to this article can be found at https doi org 10 1016 j watres 2019 115367 the following is the supplementary data related to this article multimedia component 1 multimedia component 1 3 3 high water flux and stability of 3d dmm sa under solar illumination of 0 3 sun the surface temperatures of 2h mixed phase mp and 1t dmm sa significantly p 0 05 increase from 29 2 0 6 to 82 9 1 3 78 2 0 8 and 88 3 0 9 c respectively fig 2g and fig s9 after 180 min of solar illumination at 1 kw m2 one sun the water fluxes of 2h mp and 1t dmm sa are 461 1 8 403 2 2 and 334 1 5 lmh bar fig 3 a and fig s10 representing 63 55 and 52 enhancements respectively compared to those of the pristine flat mos2 membranes the water flux values of the 3d dmm sa samples are much higher than those of other laminar membranes with similar thicknesses such as go rgo membranes huang et al 2013 1 8 μm 71 lmh bar mos2 membranes 1 μm 30 lmh bar wang et al 2017a 1 7 μm 245 lmh bar sun et al 2013 fig 3b solar irradiation treatment also reduced the saturated water content of mos2 membrane fig 3c with an approximately 20 decrease compared to that of mos2 membrane in the absence of sunlight the open macropores in membrane facilitated the loss of water in laminar space and then reduced the water holding capacity of the membrane especially for the 2h dmm sa samples as shown in fig 3e rejection experiments were carried out to evaluate the ability of fabricated mos2 membrane preventing ionic species passing through the membrane as shown in fig s7 the membranes exhibit high rejection rates 50 80 for all ionic species at low ionic strengths 1000 mg l which were better than those of pristine go that suffered from swelling mi et al 2018 ma and sasaki 2015 importantly the 2h dmm sa exhibited higher ion rejection than the pristine 2h mos2 membrane especially at high ionic strengths e g more than 500 mm 2 9 104 mg l fig s11a the ion rejection rates of dmm sa were significantly improved by 10 3 13 5 for mixed solution the initial concentrations nacl at 2925 mg l kcl at 5500 mg l cacl2 at 3725 mg and mgcl2 at 4750 mg l compared to that of pristine mos2 membrane in the absence of sunlight irradiation fig s11b the presence of 10 20 nm in diameter nanopores on mos2 nanosheets was expected to increase the bulk water flux and vapor flux the abundant vacancy defects 1 nm fig s2 formed by the chemical exfoliation and phase transition and high negative charge density of membrane were beneficial for ions capturing and excluding during the rejection experiments the 2h dmm sa sample possesses a high and stable water flux even in a 500 mm nacl 2 9 104 mg l solution 450 lmh bar over 12 h fig 3d confirming the rigidity and stability of 2h dmm sa under high ionic strength conditions 3 4 excellent solar evaporation performance using 2h dmm sa given its solar responsive macroporosity and broad and efficient light absorption fig s12 2h dmm sa was further applied towards solar powered desalination photothermal steam generation the 2h dmm sample achieved approximately 80 90 absorption of solar irradiation over the range from 250 to 2500 nm and the high solar thermal conversion performance may be due to the surface roughness and porous structure increasing the degree of internal light scattering to reduce the downward heat conduction from the solar absorber to the underlying water a thermal insulator polystyrene foam was introduced into the evaporation system as a floater below the dmm layer after 60 min of solar illumination at one sun the water temperature with a dmm layer increased much faster than that without a dmm layer only polystyrene foam fig 4 a and b and the water temperatures increased by 9 1 0 7 c when using 2h dmm which was significantly lower than that using 1t dmm 12 8 0 9 c fig s13 the low thermal conductivity of the 2h dmm layer contributed to the low sunlight absorption fig s12 and photothermal conversion efficiency of 2h dmm layer fig 2g compared to that of 1t dmm layer and energy was facile to be spent vaporizing water furthermore we found that the water evaporation rate of the 2h dmm sample in the floating configuration was higher than that in the raised configuration fig s14 compared with traditional floating hydrophobic photothermal membranes at the evaporative air water interface the hydrophilicity of 2h dmm improved the capillary effect and enabled effective water infiltration as a result the water evaporation rates of the 2h mos2 layer were the highest at 1 68 0 08 kg m2 h under one sun illumination more than double the evaporation rate of the control configurations with only the polystyrene layer and with an open water surface fig 4c the evaporation rate increased approximately linearly with increasing light intensity from 1 to 3 kw m2 fig 4d the corresponding solar thermal conversion efficiencies were 83 8 0 8 and 91 5 1 1 under one and three sun illumination respectively the efficiency of 2h dmm was better than those of previously reported carbon based materials such as porous graphene ito et al 2015 one sun 80 and single walled nanotube mos2 hybrid yang et al 2018 one sun 81 the high performance of 2h dmm resulted from its surface topography and excellent hydrophilicity leading to an enhanced heat flux and more effective diffusion of a small amount of water towards the evaporation front facilitating rapid water evaporation water desalination tests were performed using real unprocessed seawater samples bohai sea tianjin china 2h mp and 1t dmm sa exhibited steady water evaporation with the average rates at 1 51 1 06 and 0 65 lmh bar after 12 h operation under one sun irradiation respectively fig 4e the evaporation rates remained stable with 72 h 6 cycles operation reflecting the reusability and stability of the membranes fig s15 the concentrations of the four primary cations na mg2 ca2 and k in evaporated water were dramatically decreased to 1 mg l indicating superior performance for salt rejection 99 5 fig 4f the concentrations of mo2 initial concentration 50 mg l were 0 011 0 07 mg l after purification the salt rejection of 2h dmm sa in the floating configuration was higher than that of the control configuration without 2h dmm sa layer fig s16a demonstrating the efficient ion sieving of 2h dmm sa layer fig s16 after treatment the salinities of the evaporated water by floating configuration with 2h dmm sa layer had all dramatically decreased to levels far below the world health organization who standard during the solar steam generation limited heavy metal ions transferred to the mos2 membrane with evaporated water which was captured and sieved by the nanopores and abundant defects of mos2 nanosheets in the membranes the heavy metal ions in drinking water inactivated the enzymes and proteins in the human body causing chronic poisoning camsari et al 2016 choi and park 2017 thus the purification of heavy metal ions was tested by adding these ions the concentrations of heavy metal ions such as pb2 cd2 cu2 zn2 and cr3 50 mg l were below 0 05 mg l after purification achieving ionic rejections 99 9 fig 4g which were higher than that of the control configuration without 2h dmm sa layer fig s16b moreover the 2h dmm sa layer also worked well under extreme ph ph 1 3 and 10 12 2 9 104 mg l nacl and strongly acidic and alkaline solutions could be neutralized for evaporated water fig 4h above results indicated the potential of dmm sa on highly effective desalination and water treatment of the toxic metals from aqueous system a simple practical water purification device using 2h dmm sa was set up in april 2019 on the roof of the school of environmental science engineering building at nankai university tianjin china as shown in fig s17a the 2h dmm sa membrane was floating in a glass beaker of seawater 50 ml the breaker was wrapped in tinfoil and placed in the center of a glass jar steam was generated under solar irradiation and then condensed into a liquid when it arrived at the cold condenser plastic wrap the condensed water automatically flowed along the glass surfaces of the container and into the condensing receptacle under gravity water purification with the device was carried out from 7 00 to 19 00 under natural sunlight the water purification rate was 10 l m2 day 0 8 lmh bar after desalination the salinity level of the permeate water had dramatically decreased from 3 47 104 mg l to less than 10 mg l the conductivity value of the treated seawater was 76 8 ms cm much lower than those of drinking water 408 μs cm and tap water 492 μs cm fig s17b for large scale practical application the cover horizontal film can be designed into sloping film to efficiently gather the evaporated water slipping along the slope 3 5 mechanisms of water permeation depending on the membrane structure to explore the mechanisms of the above excellent water permeation first principles solid nudged elastic band sneb analysis and molecular dynamics md simulations were conducted the first principles sneb method was used to evaluate the energy barrier of water migration through the space between two mos2 layers the water molecules cause the mo s bond angle to distort fig 5 a and the calculated energy barrier of 2h mos2 e 0 18 ev is much smaller than that of 1t mos2 e 0 35 ev fig 5b the energy barrier could be overcome spontaneously implied by the negative values supporting the fast water vapor permeation of stacked 2h mos2 membrane thus water molecules easily pass through the open nanopores in the interlayer space two layers of 2h dmm furthermore an md simulation was used to predict water transport confined to the nanochannels of mismatched mos2 domains the simulated system consists of two 2h or 1t mos2 layers and reservoirs of water as shown in supplementary fig s18 the water molecules trickled from the reservoirs and rapidly filled the space between the 2h and 1t mos2 layers within 45 and 74 ps respectively under a pressure of 100 mpa to reach the final saturated equilibrium density fig 5c under a 2000 bar pressure the velocity of the water molecules in the 2h mos2 nanochannel was an one order of magnitude faster than that in the 1t mos2 nanochannel fig 5d and e to simulate the effects of surface topography solar irradiation alters the membrane structures see fig 2 on the water flux and rejection of salt ions a flat surface and dimpled surface for the mos2 layer representing the protruding structures of the mos2 membrane tilted 45 were constructed as shown in figs s19a and b respectively according to the references ying et al 2018 song et al 2018 wang et al 2017a the inter edge space of two close mos2 nanosheets was fixed to 22 å and the hydrated ions could enter mos2 interlayer almost freely the dynamics of the water molecules and nacl ions can be observed in supplementary movies 2 7 and the water permeation and salt rejection behavior are quantified in fig 5f h similar to the experimental observations 2h mos2 exhibits high water flux and salt rejection values and the numerical permeability values derived from the dimpled surface are approximately 5 fold higher than those of the flat surface of the membrane under a pressure of 500 bar supplementary video related to this article can be found at https doi org 10 1016 j watres 2019 115367 the following are the supplementary data related to this article multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 multimedia component 4 multimedia component 4 multimedia component 5 multimedia component 5 multimedia component 6 multimedia component 6 multimedia component 7 multimedia component 7 4 conclusions to summarize we propose a facile and low cost approach for the phase controlled synthesis of 2h dmm sa with a high density of nanopores the 2h dmm sa layers possess dimpled surfaces with an open macroporous network under sunlight illumination leading to a massive improvement in the bulk water flux 461 lmh bar 2h dmm sa as a localized photothermal membrane has a high light absorption capacity a hydrophilic nature for efficient water supply and an extraordinary structural stability enabling highly efficient solar steam generation the floating configuration with 2h dmm sa layer and polystyrene insulating layer exhibits an excellent evaporation flux 1 68 0 08 kg m2 h one sun with a solar thermal conversion efficiency of 83 8 0 8 under one sun illumination after desalination the salinity level of permeate water is far below the who standard in addition 2h dmm sa can be reused for multiple illumination cycles without degradation of the water evaporation and salt rejection performance this work opens up a new avenue for utilizing seawater by harvesting solar energy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was financially supported by the national natural science foundation of china grant nos 21722703 21876092 21677080 and 31770550 the ministry of education people s republic of china as an innovative team rolling project grant no irt 17r58 a 111 program grant no t2017002 the natural science foundation of tianjin grant no 18jcybjc23600 and 16jcqnjc08400 appendix a supplementary data the following are the supplementary data to this article tem and afm images raman spectra and zeta potential of mos2 nanosheets are characterized the solar assisted fabrication of macroporous structures stability water permeance and ionic rejections of dmm sa including details of steam generation and practical seawater purification are measured multimedia component 8 multimedia component 8 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 115367 
18309,solar driven evaporation has been proposed as an efficient way to harvest solar energy for water treatment and desalination however the complex preparation process and the degradation of photothermal absorbers restrict their practical applications in solar thermal technology herein a solar assisted fabrication of three dimensional dimpled mos2 membrane dmm sa with an open macroporous 1 2 μm network is fabricated by folding and overlapping nanosheets under solar illumination dmm sa exhibits superior water permeability 334 461 lmh bar and extraordinary chemical and structural stability compared to the 1t and mixed phase dmm sa samples 2h dmm sa floating on the water surface generates high heat localization and achieves high evaporation efficiencies of 83 8 0 8 and 91 5 1 1 at 1 and 3 sun illumination respectively after multiple illumination and regeneration cycles 2h dmm sa presents high water evaporation and salt rejection performance after desalination the salinity level of permeate water is far below the world health organization who standard numerical simulations verify that the inner spaces between two nanosheets and the nanochannels contribute to the high bulk water and vapor fluxes during desalination the facile and efficient design of 3d 2h dmm sa provides a novel avenue for seawater utilization by harvesting solar energy graphical abstract image 1 keywords desalination dimpled mos2 membrane photothermal conversion steam generation 1t and 2h phases 1 introduction with serious water pollution and the energy saving demands for water purification major developments in water treatment have focused on desalination such as membrane based designs of reverse osmosis ro and thermal based designs of membrane distillation technology bai et al 2019 tong et al 2017 noticeably the energy intensive ro systems are extremely challenging for low energy efficiency high operating pressure and irreversible degradation of membranes the efficient utilization of solar energy as the only energy source to generate clean water from seawater and industrial wastewater is a promising approach for solving water resource scarcity issues wilson et al 2019 kim et al 2018 recent developments in innovative plasmonic photothermal membrane distillation hold immense promise for producing desalinated water at a high thermal efficiency and relatively low energy input yu et al 2018a b mu et al 2019 during the membrane distillation process water purification is driven by a vapor pressure gradient across a floating porous membrane the heat localization system efficiently transfers the solar energy to nearby water for steam generation while minimizing heat loss to the air and bulk water mu et al 2019 until now a variety of photothermal materials were utilized for efficient light absorption such as graphene reduced graphene oxide rgo yang et al 2018 zhang et al 2017 graphene oxide go li et al 2017 carbon nanotubes cnt yin et al 2017 layer and cermet coated on a copper sheet ni et al 2016 on a thermal insulator however these absorbers or photothermal materials suffer from complex preparation procedures or high energy consumption jia et al 2014 it is important and urgent for solar thermal water treatment in addition hydrophobic graphene cnt and black carbon could not maintain effectively contact with water li et al 2018 seo et al 2018 dong et al 2018 shao et al 2018 and hydrophilic go suffered swelling and dissolving in aqueous solution wang et al 2017a yeh et al 2015 in addition the chemical and structural alterations after long time irradiation and the degradation of the membrane performance by diverse contaminants and challenging environments lin et al 2016 lu et al 2016 affect the performance in membrane distillation guo et al 2019a b moreover conventional hydrophobic membranes have limited effectiveness to minimize heat loss to the air and bulk water and transfer heat to water within the pores of membrane for water evaporation zhang et al 2015 both organic solvent addition and surface modification are general methods to fabricate hydrophobic membranes but not energy saving or environmentally friendly for practical applications hydrophilic membranes for distillation should possess broadband and efficient solar absorption and a porous network to provide vapor channels monolayer mos2 a typical transition metal dichalcogenide tmd possesses unique electronic and optical properties kurapati et al 2016 krasian et al 2019 alam et al 2019 monolayer mos2 exists as a polymorph and can display different phases such as the metallic 1t phase and the semiconductor 2h phase liu et al 2018 kurapati et al 2016 several strategies have been used to synthesize monolayer mos2 such as physical exfoliation radisavljevic et al 2011 electron beam irradiation fan et al 2015 colloidal synthesis kurapati et al 2016 and chemical vapor deposition cvd kim et al 2016 however the 1t phase of mos2 is metastable and can easily be converted into the stable 2h phase thus fabricating monolayer mos2 with a high phase purity remains a great challenge as a promising solar absorber monolayer mos2 absorbed 5 10 2 3 for monolayer graphene of incident sunlight in a thickness of less than 1 nm exhibiting 1 order of magnitude stronger sunlight absorption than monolayer gaas and si two of the most commonly used absorbers in solar cells tsai et al 2014 wang and sambur 2019 mos2 nanosheets in a membrane formation may exhibit thermal and mechanical stability wang et al 2017a 2017b moreover the designed surface topography of membrane was helpful to improve the water transport guo et al 2019a b tsou et al 2015 and the pores and defects on the mos2 nanosheets were expected to be highly ion selective and water permeable thiruraman et al 2018 the regulation of the surface topography and porosity of mos2 nanosheet layers may enable the fabrication of new membranes for highly efficient water desalination under solar irradiation herein we report a facile and efficient method for achieving the crystal phase controlled synthesis of 2h and 1t mos2 nanosheets the excellent photothermal conversion of mos2 provides thermally responsive water transport channels solar assisted fabrication of dimpled mos2 membrane dmm sa facilitating rapid water transport through the mos2 membrane superior to the membranes of most previous reports 2h dmm sa exhibits high bulk water and vapor fluxes salt rejection high efficiency removal of heavy metal and stability 72 h as well as solar steam efficiencies of 83 8 0 8 and 91 5 1 1 under one sun and 3 sun illumination respectively moreover computational simulations reveal the mechanism of water vapor permeation in 2h dmm sa which occurs through the inherent nanochannels of the sharply dimpled surfaces 2 materials and methods 2 1 preparation of 1t 2h and mixed phase mos2 nanosheets mos2 nanosheets were prepared by a chemical exfoliation method in a nitrogen filled glovebox 500 mg of mos2 powder nanjing xfnano materials tech co ltd china was dispersed into 10 ml of 1 6 m n butyllithium in hexane solution sigma aldrich usa under moderate stirring for lithium intercalation after reacting for 2 days the intercalated samples were retrieved by centrifugation and washed using hexane to remove excess lithium and organic residue then the samples were sonicated at 250 w in an ice bath for 1 h to obtain the exfoliated nanosheets followed by centrifugation at 1510 x g for 10 min to obtain mp mos2 nanosheets the dispersions of chemically exfoliated mos2 samples were stored in a glovebox the 1t phased mos2 nanosheets were synthesized in the solution phase by a microwave assisted method the pre exfoliated mos2 were dispersed in a 1 mg ml solution of koh then the samples 10 ml were irradiated using a single mode microwave at 200 w and 2 45 ghz mas ii plus china the temperature of the suspension was increased from room temperature to 180 c 30 c min and the sample was held at temperature for 40 min the synthesized 1t mos2 sample was annealed in a quartz tube furnace at 300 c for 3 h to obtain 2h phase mos2 nanosheets 2 2 preparation of the solar assisted fabrication of three dimensional dimpled mos2 membrane the laminar mos2 membrane was assembled by vacuum filtration in a stirred cell 30 ml on a porous poly ether sulfone substrate sterlitech kent usa with a nominal pore size of approximately 0 22 μm the thickness of the membrane was controlled by controlling the volume and concentration of the mos2 solution with 10 ml at 0 2 mg ml leading to a membrane thickness of approximately 1 6 μm to obtain three dimensional dimpled mos2 membrane the freshly prepared wet membranes were irradiated for 3 h at 1 kw m2 one sun by a solar simulator cel pf300 t8e beijing au light china to test the permeance and rejection of various salts nacl cacl2 pbcl2 and fecl3 the mos2 membrane was first stabilized at 0 98 bar for 30 min 2 3 nanomaterial and membrane characterization the morphologies of the nanomaterials were characterized by tem jeol jem 200cx japan and atomic force microscopy afm bruker multimode germany the membrane morphology and microstructure were investigated by sem jsm 7500f japan the ζ potential measurements were conducted on a zeta nanosizer malvern instruments uk x ray photoelectron spectroscopy xps analysis of the samples was carried out using an escalab 250xi spectrometer thermo scientific usa the xrd patterns of the nanomaterials were obtained using an x ray diffractometer xrd rigaku smart lab japan operating at 40 kv and 40 ma with cu kα radiation λ 1 542 å 2 4 steam generation experiments the circular mos2 membrane samples 15 mm in diameter allowed to float on water in a glass tube 20 ml by positioning them on a piece of a polystyrene sheet approximately 5 mm thick as a control a raised configuration was evaluated in which the glass tube hold 15 ml deionized water and the mos2 membranes were placed on the top of water by positioning it on a piece of polystyrene sheet with a distance of 2 cm from water surface to bottom surface of polystyrene foam water was transported from the bulk water to the mos2 membranes by capillary action through a fiber the samples were irradiated by a 300 w solar simulator with a wavelength range of 200 1100 nm and 21 a cel pf300 t8e beijing au light china the evaporation rate was calculated based on the change in the recorded mass of water lost over time using an electronic mass balance with an accuracy of 0 0001 g the temperature evolution was monitored by taking infrared images with an infrared thermal imaging camera uw aaa seek thermal usa before and after irradiation time interval was 10 min during irradiation the simulated wastewater with metal ions cr3 pb2 cd2 zn2 and cu2 was prepared by dissolving chromic chloride lead nitrate zinc chloride nickel chloride and cupric nitrate in ultrapure water the mass concentration was 100 mg ml for the individual ions the solar thermal conversion efficiency η is given by η mhlv i where η is solar thermal conversion efficiency m kg m 2 h 1 is the evaporation mass flux hlv j g 1 is the total enthalpy of sensible heat and phase change of liquid to water and i j m 2 s 1 is the power density of solar illumination 2 5 numerical simulations the first principles calculations were based on density functional theory dft using the vienna ab initio simulation package vasp klemm et al 2011 the generalized gradient approximation gga in the form of the perdew burke ernzerhof functional was used to approximate the exchange and correlation potential interactions between the electrons and ion cores were described by the projector augmented wave paw potential a cutoff energy of 300 ev was employed for the planewave expansion of the wavefunctions the energy barrier for water molecules penetrating through the slit between two mos2 nanosheets in the same layer was obtained by using the climbing image nudged elastic band ci neb method henkelman et al 2000 a large scale atomic molecular massively parallel simulator lammps program package was used for the md simulations and to visualize the md the simulated system for water molecule intercalation consisted of two mos2 layers and reservoirs of water the area of the simulated mos2 layer was 46 8 å 50 6 å for the md simulations the atomic positions of the mos2 layers were fixed and the interlayer distance was defined as 0 6 nm the simulated system of water permeation through the layered structure of the mos2 membrane was constructed from seven mos2 nanosheets each mos2 nanosheet was built with a size of 45 2 å 50 6 å a fixed slit of 22 2 å and a nanochannel between two layers of 6 å each of the mos2 nanosheets with a 45 incline represented the solar induced protrusions in the mos2 membrane for the force models the interactions between water molecules were computed using an extended simple point charge smidstrup et al 2014 spc e water model with a long range coulomb particle particle particle mesh method for the van der waals interactions between water molecules and the mos2 nanosheets the lennard jones parameters were fit to the potential energy curves obtained from the dft calculations of a model system with a single water molecule in the present study the membrane mo and s atoms were kept fixed in position the production run lasted for 1000 ps and the water and ion permeation rates were measured in terms of the number of water molecules or na and cl entering the permeated region 3 results and discussion 3 1 fabricating phase pure and stable mos2 nanosheets mp mos2 nanosheets were prepared from the bulk mos2 via li intercalation which was facile to produce mos2 nanosheets in a large scale li et al 2019 the preparation method for the 1t and 2h mos2 nanosheets and their respective membranes is provided in fig 1 a d the crystal structures of 1t and 2h mos2 are shown in fig 1f and h respectively showing trigonal prismatic coordinated 2h mos2 and distorted octahedral coordinated 1t mos2 voiry et al 2015 primo et al 2019 the transmission electron microscopy tem and atomic force microscopy afm images in fig s1 show that the obtained mos2 nanosheets exhibit an approximately 1 2 μm lateral size and approximately 1 1 1 3 nm thickness respectively and are mostly monolayer or bilayer structures high resolution tem fig 1f shows regions of clustered mo on the basal plane of 1t mos2 characterized by zigzag chain clusters wang et al 2017a 2017b after annealing a hexagonal lattice of 2h mos2 is clearly visible in the basal plane fig 1h with the mo atoms of one layer overlapping with the sulfur atoms in another layer chhowalla et al 2013 nanopores with diameters of approximately 10 20 nm fig s1 and vacancy defects sizes less than 1 nm fig s2 are introduced into the exfoliated mos2 nanosheets after the phase transition the 2h and 1t mos2 nanosheets tend to be wrinkled forming several overlapping folds and the nanopores in the mos2 surface are maintained figs s1d and f the open nanoporous structure of the mos2 nanosheets was expected to facilitate water molecule transport and ion selective filtration thiruraman et al 2018 jang et al 2017 as studied in the following sections as shown in fig 1i the mo 3d5 2 and mo 3d3 2 peaks of the pristine exfoliated mos2 nanosheets were deconvoluted into two independent components with 33 6 of the 1t phase and 66 4 of the 2h phase the nanosheets were converted into 92 5 of the 1t phase and approximately 100 of the 2h phase after the microwave irradiation and heat annealing treatments respectively in fig s3a the raman spectra show typical j1 j2 j3 and e1g precursor peaks for the metastable 1t mos2 nanosheets and two main raman modes a1g and e2g in thermodynamically stable 2h mos2 nanosheets li et al 2012 all these distinct changes confirmed the successful synthesis of high phase purity mos2 nanosheets the present method is easily scaled up and low cost for the phase controlled synthesis of mos2 nanosheets compared to other strategies such as chemical vapor deposition li et al 2019 infrared laser irradiation yu et al 2018a b and other chemical activations chang et al 2016 the fabricated mos2 samples presented a highly negative charge density with electrophoretic mobilities of approximately 3 0 10 15 m2 v under neutral ph conditions fig s3b which is favorable for desalination applications as confirmed in the following sections 3 2 solar responsive microstructure and anti swelling properties of 2h dmm sa a 10 ml mos2 suspension at 0 2 mg ml led to a membrane thickness of approximately 1 6 μm with a laminar structure fig 2 a the orientation of the vacuum assisted nanosheets in the mos2 membranes was found to be a well packed layer by layer pattern and layers further from the substrate became comparatively random which favors the introduction of water into the interface of the membrane the surface morphology of the membrane is shown in fig 2c and fig s4 where slight surface wrinkles are observed and the mos2 nanosheets partially overlap to form spaces serving as fluidic nanochannels for molecular separation the solar pre treatment was used to fabricate the dimpled surface and open microstructures for later solar steam generation after 3 h solar illumination 1 kw m2 the lamellar spaces of the mos2 nanosheets were obviously widened and the thickness of membrane increased to approximately 2 1 μm and the orientation of the nanosheets became random and loose fig 2b the solar accelerated water evaporation flux disrupted the sheets and created the dimpled and loose structure of membrane leading to the increase of membrane thickness after drying off water the microstructures of membrane were in an open state and the pores in the microstructures were widened or merged together to the sizes of approximately 1 2 μm fig 2d a large number of protrusions with different heights and valleys appearing similar to a mountain range are formed as seen in fig 2d and fig s4 the ridges which act as a skeleton are formed from the nanosheets folding or overlapping micrometre sized pores have been shown to be more appropriate than nanopores for efficient capillary pumping of water ito et al 2015 the pores in the solar assisted fabrication of dimpled mos2 membrane 3d dmm sa exhibited a highly interconnected macroporous structure which enables the effective access and diffusion of various ions and molecules in addition the hydrophilic surface fig s5 of the 2h mos2 membranes could maintain contact with water and thus provide effective heat transfer to water during the solar evaporation experiments as confirmed in the following sections compared to the fabrication of 3d frameworks via polymer cross linking post incorporation of polymers reduction self assembly and mixing polymer templates this solar assisted deformation method is a green resource efficient and scalable method for producing 3d dmm sa barner kowollik et al 2017 tian et al 2017 lethien et al 2019 the xrd pattern fig 2e of the mos2 membrane shows a hexagonal structure and the 002 peak of 2h mos2 exhibited obvious red shift with the interlayer spacing increasing to 0 64 nm consistent with the crystal structure symmetric distribution and ordered stacking of the 2d layers the interlayer space may serve as a nanochannel for water to pass through williams et al 2019 the anti swelling property of hydrophilic 2h mos2 was investigated to evaluate its mechanical stability in water after 1 3 days of soaking in water there was no significant change in the interlayer spacing of a hydrated mos2 membrane fig 2f the peak of the air dried 2h mos2 membrane became stronger and the peak position was almost unchanged confirming the structural stability of the mos2 membrane the fully hydrated mos2 membranes remained intact in hcl 3 m and naoh 3 m solutions after iterative soaking and agitation processes movie s1 and fig s6 in contrast the free standing graphene oxide go membrane disintegrated immediately upon hydration without any mechanical agitation yeh et al 2015 the released mo and s species of the fully hydrated 2h mos2 membrane were 0 73 and 0 46 mg l respectively and accounted for less than 2 of the membrane mass fig s7 after sunlight treatment for 72 h at 1 kw m2 one sun which were much lower than that of reported mos2 nanosheets dispersed in aqueous solution wang et al 2016 zou et al 2019 xps analyses raman spectrum and dry mass of mos2 membrane fig s8 confirmed no obvious degradation of layer stacked 2h mos2 membrane supplementary data related to this article can be found at https doi org 10 1016 j watres 2019 115367 the following is the supplementary data related to this article multimedia component 1 multimedia component 1 3 3 high water flux and stability of 3d dmm sa under solar illumination of 0 3 sun the surface temperatures of 2h mixed phase mp and 1t dmm sa significantly p 0 05 increase from 29 2 0 6 to 82 9 1 3 78 2 0 8 and 88 3 0 9 c respectively fig 2g and fig s9 after 180 min of solar illumination at 1 kw m2 one sun the water fluxes of 2h mp and 1t dmm sa are 461 1 8 403 2 2 and 334 1 5 lmh bar fig 3 a and fig s10 representing 63 55 and 52 enhancements respectively compared to those of the pristine flat mos2 membranes the water flux values of the 3d dmm sa samples are much higher than those of other laminar membranes with similar thicknesses such as go rgo membranes huang et al 2013 1 8 μm 71 lmh bar mos2 membranes 1 μm 30 lmh bar wang et al 2017a 1 7 μm 245 lmh bar sun et al 2013 fig 3b solar irradiation treatment also reduced the saturated water content of mos2 membrane fig 3c with an approximately 20 decrease compared to that of mos2 membrane in the absence of sunlight the open macropores in membrane facilitated the loss of water in laminar space and then reduced the water holding capacity of the membrane especially for the 2h dmm sa samples as shown in fig 3e rejection experiments were carried out to evaluate the ability of fabricated mos2 membrane preventing ionic species passing through the membrane as shown in fig s7 the membranes exhibit high rejection rates 50 80 for all ionic species at low ionic strengths 1000 mg l which were better than those of pristine go that suffered from swelling mi et al 2018 ma and sasaki 2015 importantly the 2h dmm sa exhibited higher ion rejection than the pristine 2h mos2 membrane especially at high ionic strengths e g more than 500 mm 2 9 104 mg l fig s11a the ion rejection rates of dmm sa were significantly improved by 10 3 13 5 for mixed solution the initial concentrations nacl at 2925 mg l kcl at 5500 mg l cacl2 at 3725 mg and mgcl2 at 4750 mg l compared to that of pristine mos2 membrane in the absence of sunlight irradiation fig s11b the presence of 10 20 nm in diameter nanopores on mos2 nanosheets was expected to increase the bulk water flux and vapor flux the abundant vacancy defects 1 nm fig s2 formed by the chemical exfoliation and phase transition and high negative charge density of membrane were beneficial for ions capturing and excluding during the rejection experiments the 2h dmm sa sample possesses a high and stable water flux even in a 500 mm nacl 2 9 104 mg l solution 450 lmh bar over 12 h fig 3d confirming the rigidity and stability of 2h dmm sa under high ionic strength conditions 3 4 excellent solar evaporation performance using 2h dmm sa given its solar responsive macroporosity and broad and efficient light absorption fig s12 2h dmm sa was further applied towards solar powered desalination photothermal steam generation the 2h dmm sample achieved approximately 80 90 absorption of solar irradiation over the range from 250 to 2500 nm and the high solar thermal conversion performance may be due to the surface roughness and porous structure increasing the degree of internal light scattering to reduce the downward heat conduction from the solar absorber to the underlying water a thermal insulator polystyrene foam was introduced into the evaporation system as a floater below the dmm layer after 60 min of solar illumination at one sun the water temperature with a dmm layer increased much faster than that without a dmm layer only polystyrene foam fig 4 a and b and the water temperatures increased by 9 1 0 7 c when using 2h dmm which was significantly lower than that using 1t dmm 12 8 0 9 c fig s13 the low thermal conductivity of the 2h dmm layer contributed to the low sunlight absorption fig s12 and photothermal conversion efficiency of 2h dmm layer fig 2g compared to that of 1t dmm layer and energy was facile to be spent vaporizing water furthermore we found that the water evaporation rate of the 2h dmm sample in the floating configuration was higher than that in the raised configuration fig s14 compared with traditional floating hydrophobic photothermal membranes at the evaporative air water interface the hydrophilicity of 2h dmm improved the capillary effect and enabled effective water infiltration as a result the water evaporation rates of the 2h mos2 layer were the highest at 1 68 0 08 kg m2 h under one sun illumination more than double the evaporation rate of the control configurations with only the polystyrene layer and with an open water surface fig 4c the evaporation rate increased approximately linearly with increasing light intensity from 1 to 3 kw m2 fig 4d the corresponding solar thermal conversion efficiencies were 83 8 0 8 and 91 5 1 1 under one and three sun illumination respectively the efficiency of 2h dmm was better than those of previously reported carbon based materials such as porous graphene ito et al 2015 one sun 80 and single walled nanotube mos2 hybrid yang et al 2018 one sun 81 the high performance of 2h dmm resulted from its surface topography and excellent hydrophilicity leading to an enhanced heat flux and more effective diffusion of a small amount of water towards the evaporation front facilitating rapid water evaporation water desalination tests were performed using real unprocessed seawater samples bohai sea tianjin china 2h mp and 1t dmm sa exhibited steady water evaporation with the average rates at 1 51 1 06 and 0 65 lmh bar after 12 h operation under one sun irradiation respectively fig 4e the evaporation rates remained stable with 72 h 6 cycles operation reflecting the reusability and stability of the membranes fig s15 the concentrations of the four primary cations na mg2 ca2 and k in evaporated water were dramatically decreased to 1 mg l indicating superior performance for salt rejection 99 5 fig 4f the concentrations of mo2 initial concentration 50 mg l were 0 011 0 07 mg l after purification the salt rejection of 2h dmm sa in the floating configuration was higher than that of the control configuration without 2h dmm sa layer fig s16a demonstrating the efficient ion sieving of 2h dmm sa layer fig s16 after treatment the salinities of the evaporated water by floating configuration with 2h dmm sa layer had all dramatically decreased to levels far below the world health organization who standard during the solar steam generation limited heavy metal ions transferred to the mos2 membrane with evaporated water which was captured and sieved by the nanopores and abundant defects of mos2 nanosheets in the membranes the heavy metal ions in drinking water inactivated the enzymes and proteins in the human body causing chronic poisoning camsari et al 2016 choi and park 2017 thus the purification of heavy metal ions was tested by adding these ions the concentrations of heavy metal ions such as pb2 cd2 cu2 zn2 and cr3 50 mg l were below 0 05 mg l after purification achieving ionic rejections 99 9 fig 4g which were higher than that of the control configuration without 2h dmm sa layer fig s16b moreover the 2h dmm sa layer also worked well under extreme ph ph 1 3 and 10 12 2 9 104 mg l nacl and strongly acidic and alkaline solutions could be neutralized for evaporated water fig 4h above results indicated the potential of dmm sa on highly effective desalination and water treatment of the toxic metals from aqueous system a simple practical water purification device using 2h dmm sa was set up in april 2019 on the roof of the school of environmental science engineering building at nankai university tianjin china as shown in fig s17a the 2h dmm sa membrane was floating in a glass beaker of seawater 50 ml the breaker was wrapped in tinfoil and placed in the center of a glass jar steam was generated under solar irradiation and then condensed into a liquid when it arrived at the cold condenser plastic wrap the condensed water automatically flowed along the glass surfaces of the container and into the condensing receptacle under gravity water purification with the device was carried out from 7 00 to 19 00 under natural sunlight the water purification rate was 10 l m2 day 0 8 lmh bar after desalination the salinity level of the permeate water had dramatically decreased from 3 47 104 mg l to less than 10 mg l the conductivity value of the treated seawater was 76 8 ms cm much lower than those of drinking water 408 μs cm and tap water 492 μs cm fig s17b for large scale practical application the cover horizontal film can be designed into sloping film to efficiently gather the evaporated water slipping along the slope 3 5 mechanisms of water permeation depending on the membrane structure to explore the mechanisms of the above excellent water permeation first principles solid nudged elastic band sneb analysis and molecular dynamics md simulations were conducted the first principles sneb method was used to evaluate the energy barrier of water migration through the space between two mos2 layers the water molecules cause the mo s bond angle to distort fig 5 a and the calculated energy barrier of 2h mos2 e 0 18 ev is much smaller than that of 1t mos2 e 0 35 ev fig 5b the energy barrier could be overcome spontaneously implied by the negative values supporting the fast water vapor permeation of stacked 2h mos2 membrane thus water molecules easily pass through the open nanopores in the interlayer space two layers of 2h dmm furthermore an md simulation was used to predict water transport confined to the nanochannels of mismatched mos2 domains the simulated system consists of two 2h or 1t mos2 layers and reservoirs of water as shown in supplementary fig s18 the water molecules trickled from the reservoirs and rapidly filled the space between the 2h and 1t mos2 layers within 45 and 74 ps respectively under a pressure of 100 mpa to reach the final saturated equilibrium density fig 5c under a 2000 bar pressure the velocity of the water molecules in the 2h mos2 nanochannel was an one order of magnitude faster than that in the 1t mos2 nanochannel fig 5d and e to simulate the effects of surface topography solar irradiation alters the membrane structures see fig 2 on the water flux and rejection of salt ions a flat surface and dimpled surface for the mos2 layer representing the protruding structures of the mos2 membrane tilted 45 were constructed as shown in figs s19a and b respectively according to the references ying et al 2018 song et al 2018 wang et al 2017a the inter edge space of two close mos2 nanosheets was fixed to 22 å and the hydrated ions could enter mos2 interlayer almost freely the dynamics of the water molecules and nacl ions can be observed in supplementary movies 2 7 and the water permeation and salt rejection behavior are quantified in fig 5f h similar to the experimental observations 2h mos2 exhibits high water flux and salt rejection values and the numerical permeability values derived from the dimpled surface are approximately 5 fold higher than those of the flat surface of the membrane under a pressure of 500 bar supplementary video related to this article can be found at https doi org 10 1016 j watres 2019 115367 the following are the supplementary data related to this article multimedia component 2 multimedia component 2 multimedia component 3 multimedia component 3 multimedia component 4 multimedia component 4 multimedia component 5 multimedia component 5 multimedia component 6 multimedia component 6 multimedia component 7 multimedia component 7 4 conclusions to summarize we propose a facile and low cost approach for the phase controlled synthesis of 2h dmm sa with a high density of nanopores the 2h dmm sa layers possess dimpled surfaces with an open macroporous network under sunlight illumination leading to a massive improvement in the bulk water flux 461 lmh bar 2h dmm sa as a localized photothermal membrane has a high light absorption capacity a hydrophilic nature for efficient water supply and an extraordinary structural stability enabling highly efficient solar steam generation the floating configuration with 2h dmm sa layer and polystyrene insulating layer exhibits an excellent evaporation flux 1 68 0 08 kg m2 h one sun with a solar thermal conversion efficiency of 83 8 0 8 under one sun illumination after desalination the salinity level of permeate water is far below the who standard in addition 2h dmm sa can be reused for multiple illumination cycles without degradation of the water evaporation and salt rejection performance this work opens up a new avenue for utilizing seawater by harvesting solar energy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was financially supported by the national natural science foundation of china grant nos 21722703 21876092 21677080 and 31770550 the ministry of education people s republic of china as an innovative team rolling project grant no irt 17r58 a 111 program grant no t2017002 the natural science foundation of tianjin grant no 18jcybjc23600 and 16jcqnjc08400 appendix a supplementary data the following are the supplementary data to this article tem and afm images raman spectra and zeta potential of mos2 nanosheets are characterized the solar assisted fabrication of macroporous structures stability water permeance and ionic rejections of dmm sa including details of steam generation and practical seawater purification are measured multimedia component 8 multimedia component 8 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 115367 
