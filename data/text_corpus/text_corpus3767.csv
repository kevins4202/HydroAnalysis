index,text
18835,sulfite has been widely employed as a key agent in many industrial processes leading to a large amount of sulfite laden wastes generated given its antimicrobial function and destructive ability on cell walls detailed mechanisms for impacts of sulfite on waste activated sludge was and outcomes of methane production after the sulfite pretreatment have not been clear so far in this study the feasibility of methane production from sulfite pretreated was was verified and investigated biochemical methane potential tests demonstrated that methane production from was after the pretreatment at 800 mg s l of sulfite a typical level in sulfite laden wastes increased by up to 25 kinetic analysis of the test results indicated that sulfite pretreatment increased the sludge hydrolysis rate k hyd by 1 71 times while the ultimate biochemical methane potential b u by 1 20 times further study investigated the effects of sulfite on was from the macro scale i e sludge physicochemical properties to the micro scale i e bacterial viability microbial community sulfite concentrations of up to 800 mg s l substantially enhanced was disintegration and solubilization reducing the particle size by up to 39 boosting substrate release by 87 and improving cell lysis by 43 through the direct destruction of gram positive microorganisms e g norank p saccharibacteria in was adverse impact on anaerobic digestion by introduction of sulfite was not observed in this study though a long term evaluation is needed in the future work based on the findings of the present study sulfite laden by products or wastes from industrial processes may be co treated with was when overall cost effectiveness is concerned graphical abstract image 1 keywords sulfite sulfite wastes methane production waste activated sludge 1 introduction substantial amounts of waste activated sludge was are produced mainly from organics in biological wastewater treatment the high disposal cost of was and sanitation concerns have been attracting growing attention lakshmi et al 2014 low and chase 1999 more importantly wastewater contains chemical energy which is a useful resource that unfortunately simply ends up in was liu 2003 mccarty et al 2011 there is thus a strong incentive to recover this resource energy while reducing the cost and difficulty of disposal to this end anaerobic digestion ad is an effective process not only for the stabilization of was but also for recovery of bioenergy in the form of methane appels et al 2008 kavitha et al 2014 mccarty et al 2011 sanscartier et al 2012 zaks et al 2011 however the efficacy of methane production via ad is often hampered by the low hydrolysis rates as well as poor biochemical methane potential bmp of was ascribed to the protective presence of extracellular polymeric substances eps and the rigid structure of the microbial cell walls appels et al 2008 ma et al 2019 rani et al 2012 shimizu et al 1993 zhang et al 2015 to increase methane production various pretreatment techniques such as biological hydrolysis with enzymes free nitrous acid ultrasonication ozone chlorination alkaline and thermal techniques have been extensively investigated ahn et al 2002 ayol et al 2008 barjenbruch and kopplow 2003 lin et al 2007 pham et al 2009 saby et al 2002 wang et al 2013 zhao et al 2018 however most of the aforementioned approaches are extremely costly due to high energy input or excessive chemical consumption foladori et al 2010 it is therefore deemed necessary to explore a novel pretreatment method at low cost sulfite has been employed as a key agent in many industrial processes for instance wine making industry taking advantage of its antimicrobial function while wood pulp industry applying it for lignin extraction both inevitably generate large amount of sulfite laden wastes that require proper treatment chang et al 1997 pokhrel and viraraghavan 2004 on the other hand impacts of sulfite on the disintegration of recalcitrant cell walls through the dissolution of hemicelluloses the degradation of celluloses and the rising hydrophilicity of lignin via sulfonation were reported wang et al 2009 zhang et al 2013 zhu et al 2009 through the evaluation of biogenic sulfide production tests we recently confirmed that the biodegradability of was after sulfite pretreatment can be significantly enhanced zan et al 2016 the substrates released from was pretreated with sulfite exhibited a positive correlation with increasing sulfite exposure time and decreasing ph an observation based hypothesis was thus proposed that sulfite irreversibly destroys the sulfite sensitive cell wall structures of the microorganisms in was kitamura and yamamoto 1981 zan et al 2016 however underlying mechanism of impacts of sulfite on was and outcomes of methane production of sulfite pretreated was are not clear so far specifically what is the exact role of sulfite in the was pretreatment in terms of substrates release or cell wall disintegration is the biodegradability enhancement via sulfite pretreatment still effective in ad system and can that be reflected by methane production to address these unknowns the present work is thus to investigate energy recovery potential of the was after sulfite pretreatment with emphasis on kinetic analysis of bmp to reveal the productivity of methane i e sludge hydrolysis rate and ultimate biochemical methane potential furthermore changes in properties of was with sulfite pretreatment were conducted for the assessment of sludge disintegration and solubilization viability of microorganisms and microbial community in was after sulfite pretreatment were analyzed to provide insights into the biocidal effects of sulfite last but not least potential applications of using sulfite laden wastes to pretreat was are explored and discussed co treatment of waste streams achieving waste reduction and energy recovery enhancement in this study provides a possible alternative to face up to the challenges of massive sludge production and low energy recovery rate certainly a long term evaluation is indispensable concerning sulfite in the ad system 2 materials and methods 2 1 sludge sources and characteristics was was collected from the local freshwater wastewater treatment plant wwtp at shek wu hui in hong kong which treats an influent with a low sulfate concentration of 12 6 mg s l and is operated at a sludge retention time srt of approximately 15 days the total solids ts volatile solids vs total chemical oxygen demand tcod of the was were 4 83 0 12 g l 3 69 0 07 g l and 4 13 0 18 g l respectively and the ph was 6 47 0 02 inoculum for bmp tests was harvested from a mesophilic anaerobic digester ad at the same wwtp with 23 4 0 46 g ts l 16 7 0 57 g vs l 16 88 0 88 g tcod l and a ph of 6 94 0 01 2 2 sulfite pretreatment batch tests were conducted in triplicate to investigate the effects of sulfite on the was the sludge was washed three times with a buffered saline solution of 0 01 m phosphate to eliminate the residual substrates 0 1 l of washed was was then added to each batch reactor 120 ml serum bottle the designated sulfite level was achieved by spiking with a solution of sodium sulfite based on the typical characteristics of industrial sulfite laden wastes jiang et al 2013 zan et al 2016 ph of the washed was was adjusted to around 6 0 0 02 with 0 1 m hydrochloric acid sodium hydroxide nitrogen gas was bubbled into the batch reactors for 15 min to establish anaerobic conditions sealed batch reactors were incubated for 24 h on a multi channel orbital shaker rotating at 60 rpm under a temperature of 20 2 c the sulfite level as the major operational parameter was examined as summarized in table 1 with 0 mg s l as control in all tests ts vs total suspended solids tss volatile suspended solids vss particle size zeta potential soluble chemical oxygen demand scod sulfite so3 2 sulfate so4 2 soluble nitrogen sn soluble kjeldahl nitrogen no2 no3 soluble proteins soluble polysaccharides and volatile fatty acids vfas were measured in triplicate the measured changes were expressed as a biomass specific value by dividing the value by the corresponding vs of was measured before the test 2 3 biochemical methane potential bmp tests the bmp test was used to assess the biodegradability of was with and without sulfite pretreatment from 0 to 800 mg s l tests were carried out in 120 ml serum bottles with a working volume of 80 ml containing 24 ml of inoculum and 56 ml of sulfite pretreated was with an inoculum to was ratio of 2 on a dry vs basis test samples after 15 min of nitrogen gas sparging the bottles were sealed with a rubber stopper by an aluminum crimp cap the serum bottles were placed on a rotator spinning at 60 rpm in a water bath at 37 1 c blanks inoculum only containing inoculum milli q water and different concentrations of sulfite 0 100 300 500 and 800 mg s l without was were set up to evaluate the effect of sulfite on biogas production from the inoculum only all tests were conducted in triplicate and lasted for 30 days loosdrecht et al 2016 the biogas production was monitored every two days in the first week and every three to four days afterwards the net biogas production from was was only was recorded by subtracting biogas production in test samples inoculum was from the blank samples inoculum only the methane production was presented as the volume of methane produced per kilogram of vs added l ch4 kg vsadded to investigate the reaction rates and efficiency of the sulfite pretreated was and the inoculum via bmp tests a first order kinetic model eq 1 batstone et al 2009 lu et al 2018 rao et al 2000 was applied to fit the cumulative methane production data two key kinetic parameters i e the hydrolysis rate k hyd and the ultimate bmp b u were obtained by minimizing the least square difference between the observed and predicted values to examine and compare the methane production kinetics and potential of the was with and without sulfite pretreatment 1 b t b u 1 exp k h y d t where b t represents the cumulative methane production l ch4 kg vsadded at time t b u is the ultimate biochemical methane potential l ch4 kg vsadded k hyd is the hydrolysis rate 1 d and t is the test duration d based on the predicted value of b u the degradation extent f d unitless of sludge can be determined using eq 2 wang et al 2013 2 f d b u 380 r s l u d g e the theoretical bmp of sludge of 380 was assumed in this work under standard conditions 25 c and 1 atm l ch4 kg tcod metcalf and eddy 1980 r sludge is the measured ratio of vs to tcod of sludge i e 0 89 for was and 0 98 for the inoculum in this study 2 4 viability test and microbial community analysis sulfite effects on was were examined with live dead staining viability tests of microorganisms in the was were conducted at the end of each test the live dead baclight bacterial viability kits molecular probes l 7012 were adopted for viability examination containing two nucleic acid stains red fluorescent propidium iodide pi and green syto 9 the syto 9 stain labels total microorganisms with intact or damaged membranes the pi stain shows microorganisms with damaged membranes inducing a reduction in the fluorescence of syto 9 when both dyes are applied the stained was samples were examined under a confocal laser scanning microscope zeiss lsm7 duo live and dead microorganisms were quantified based on the relative abundance of green and red pixels in 20 or more images in imagej national institutes of health usa to ensure representativeness zan et al 2019 microbial community of was after sulfite pretreatment was determined using high throughput sequencing of the 16s rrna gene as described in hao et al 2015 the analytical procedure involved dna extraction polymerase chain reaction pcr amplification pyrosequencing and data analysis 2 5 analytical methods samples of dissolved organic carbon doc sn so3 2 so4 2 sulfide soluble proteins soluble polysaccharides and vfas were prepared and filtered through disposable millipore filters with pore size of 0 45 μm so3 2 ts vs tss and vss were determined according to the standard methods apha 2005 so4 2 was measured using an ion chromatograph hic 20a super shimadzu japan equipped with a conductivity detector and an ic sa2 analytical column hs h2s was measured with the methylene blue method apha 2005 the doc and sn were assessed using a total organic carbon total nitrogen analyzer toc 5000a shimadzu japan organic scod was calculated with a theoretical ratio cod c 2 67 soluble proteins were measured by the bicinchoninic acid assay with bovine serum albumin as standard smith et al 1985 while soluble polysaccharides were determined using the colorimetric method dubois et al 1956 specific vfas e g acetate propionate and butyrate were determined with a high performance liquid chromatograph hic 20a super shimadzu japan equipped with a conductivity detector and an ic sa3 analytical column zeta potential was measured with a zeta potential analyzer zetaplus brookhaven usa particle size of was was assessed with a laser diffraction particle size analyzer ls 13 320 beckman coulter usa the biogas volume was determined using inflated samco glass syringes with a volume of 50 ml at each sampling event cumulative volumetric biogas production was calculated from the combination of inflated syringes volume and headspace volume of the serum bottles i e 40 ml and expressed under the standard conditions 25 c and 1 atm the biogas contents ch4 co2 and n2 were detected using an agilent 7890b gas chromatograph equipped with an electron capture detector 2 6 statistical analysis principal component analysis pca was applied to compare the differences in microbial community of was after sulfite pretreatment at different levels 0 800 mg s l using r with vegan package correlations between sulfite levels and microbial communities at genus level were evaluated by using pearson correlation coefficient the coefficient reflects the linear correlation between two variables with a value from 1 to 1 where 1 represents total negative linear correlation 0 indicates no linear correlation and 1 represents total positive linear correlation the analysis was conducted in the software spss version 21 ibm usa a 95 confidence level p 0 05 was adopted for determining statistical significance 3 results and discussion 3 1 methane production from was with sulfite pretreatment the main purpose of sludge pretreatment is to maximize energy recovery via ad effects of sulfite on methane production were assessed from two perspectives a the cumulative methane production from the inoculum only fig 1 a and b the cumulative methane production from was only fig 1b this is coupled with the kinetic analysis with the first order kinetic model eq 1 which simulated well the methane production rates observed in the bmp tests i e b u k hyd and f d fig 2 and table 2 the coefficients of determination r2 of the simulation were higher than 0 92 in all cases inoculum only and was only indicating a satisfactory fit of the kinetic model to the observed cumulative methane production was treated with sulfite was directly used for bmp tests and thus a certain level of sulfite or sulfate from sulfite oxidization was present in bmp tests during the course of the entire experiment the amounts of dissolved sulfide in liquid phase and hydrogen sulfide in gas phase were negligible in all samples inocumlum only and inoculum was this may be attributed to the was and inoculum from the freshwater wwtp with a low concentration 12 6 mg s l of sulfate in the influent sewage and thus sulfate reducing bacteria were not abundant or active in the obtained was and inoculum ad sludge the impact of sulfite addition in ad should be evaluated for the long term sulfite pretreatment stimulated significant increases in methane production throughout the bmp test period in both inoculum and was fig 1 for the blanks inoculum only the increase in methane production was approximately twofold as sulfite concentration rose from 0 27 73 l ch4 kg vsadded to 800 mg s l 54 69 l ch4 kg vsadded suggesting that sulfite could directly induce the inoculum to produce more methane organic matter residues of the inoculum may partially contribute to methane production this is further confirmed by the increases in b u k hyd and f d table 2 the improvement in b u and f d was around 50 and the k hyd rate increased sharply by 356 at sulfite level of 800 mg s l compared with the control this implies that even the hydrolysis rate of the digestate i e inoculum in this study can be substantially improved by sulfite dosage because the ad biomass makes up only a small fraction of the vs concentration in ads most of the vs in ad are unbiodegradable particulate organics upo and residual biodegradable particulate organics bpo such a large increase in b u and f d suggest that upo may have been converted to bpo by the sulfite specific tests to validate this will have to be conducted the impact of sulfite dosing on sludge reduction and the inoculum in ad deserves further investigation as for the was with sulfite pretreatment was only methane production grew gradually with the increase in sulfite concentration from 0 to 800 mg s l fig 1b there was a slight increase in the cumulative methane production at sulfite levels below 300 mg s l up to 1 25 times higher than the controls cumulative methane productions was observed when 800 mg s l of sulfite were used in the pretreatment values of b u k hyd and f d clearly increased with sulfite concentration table 2 a significant increase in b u and k hyd by up to 83 and 221 respectively indicates that the sulfite pretreatment directly accelerated the hydrolysis rate and methane production potential in this study the degradation extent f d fell into the range of 0 29 0 35 which is consistent with other studies where f d ranged from 0 27 to 0 55 in five wwtps paul et al 2012 from 0 3 to 0 6 wei et al 2017 and from 0 33 to 0 53 wang et al 2013 however it should be noted that the characteristics of was vary naturally over time and space particularly when the sludge is from a moderate sludge age plant which may significantly influence the methane production from inoculum and sludge wei et al 2018 both k hyd and b u or f d were improved in this study thus sulfite pretreatment could be considered an efficient means for was pretreatment improving methane production given little is known about the effects of sulfite pretreatment on was there is a need to further investigate the changes of was during sulfite pretreatment from different aspects 3 2 effect of sulfite pretreatment on was sulfite pretreatment 0 800 mg s l at a ph of 6 for 24 h induced significant changes in was properties i e particle size zeta potential and vss tss ratio fig 3 these properties were observed to decrease with increasing sulfite concentration after sulfite pretreatment the zeta potential of was decreased from 1 4 mv with zero sulfite to 27 mv with 800 mg s l of sulfite fig 3a an increase in the amount of negative charges on the was surface can lead to a rise in electrostatic repulsion and a drop in interaction energy implying that sulfite pretreatment induced the destabilization of the floc structure of was correspondingly the average particle size in terms of d10 d50 and d90 defined as the equivalent diameters in volume of 10 50 and 90 of total particles respectively of was decreased 39 29 and 29 respectively fig 3b this indicates that sulfite pretreatment could cause the floc structure to disintegrate when was breaks up into smaller pieces with sulfite pretreatment the deterioration of the protective structure would cause intra extracellular materials to be released appels et al 2008 harrison 1991 concomitant with was disintegration the vss tss ratios with increased sulfite levels were reduced by up to 15 61 fig 3c consistent with the changes in particle size of was after sulfite pretreatment particles in was tended to be disintegrated by sulfite treatment and then passed through the filter pore size of 1 2 μm causing a reduction of vss tss the decrease in the vss tss ratio further confirmed that sulfite pretreatment could convert particulate organic substances into soluble ones and reduce the particulate organic content in was solubilization of was through disintegration of the floc structure and reduction of the organic solid content are required for effective was disposal tiehm et al 2001 it is also necessary to verify and quantify the changes in soluble substrates in was after sulfite pretreatment 3 3 effect of sulfite pretreatment on was solubilization the increased solubilization of was after sulfite pretreatment was investigated and quantified and the results are shown in fig 4 was pretreated with different levels 0 800 mg s l of sulfite resulted in the release and or production of scod sn soluble proteins soluble polysaccharides and vfas mainly acetate propionate and butyrate the highest production of scod occurred at a sulfite level of 800 mg s l and it was around 1 87 times higher than that of the control fig 4a similarly the release of sn and soluble polysaccharides from was solubilization increased by 1 21 and 1 94 times respectively fig 4a and b approximately 4 26 times more soluble proteins were produced at a sulfite level of 500 mg s l after which a slight decrease was observed from 9 78 mg g vs 500 mg s l to 8 38 mg g vs 800 mg s l fig 4b proteins play a more important role than polysaccharides in the floc matrix for both aggregating bacteria into flocs and consolidating the water binding capability of was higgins and novak 1997 shao et al 2009 substantial quantities of water can reside at the protein surface and be buried inside the protein which in turn stabilizes the structure of protein macromolecules in flocs halle and denisov 1995 hence large scale release of soluble proteins after sulfite pretreatment can further enhance the disintegration of was vfas in soluble phase were quantified after sulfite pretreatment the production of total vfas was observed to rise with the sulfite level fig 4c up to 1 80 times more vfas were produced than in the control acetate was the major vfa component accounting for around 77 0 mg s l to 86 800 mg s l of the vfa concentrations the majority of the cod in was occurs in particulate form i e scod tcod ranges from 1 to 10 ji et al 2010 and the production of vfas through the hydrolysis of particulate organic matter is limited in conventional sludge treatment processes lee et al 2014 this limits the possibility of recovering valuable resources from was zan et al 2018 in this study substantial amounts of vfas were produced during was solubilization demonstrating that sulfite pretreatment can directly improve was hydrolysis 3 4 effect of sulfite pretreatment on viable cells in was the percentages of viable cells in was after sulfite pretreatment decreased with increasing sulfite concentration fig 5 from 56 without sulfite dosage to 40 at a sulfite level of 100 mg s l at higher sulfite the percentage of viable cells reduced by a further 8 from 100 mg s l to 800 mg s l sulfite has been proven to be effective in reducing microbial viability through its biocidal effect on cells in was zan et al 2016 this is consistent with other observations that the cell walls or cells of microorganisms with sulfite sensitive cell walls and saccharomyces cerevisiae could be destroyed or inactivated in the presence of sulfite kitamura and yamamoto 1981 schimz 1980 enhanced lysis of the microbial cells in was due to sulfite could contribute to was solubilization 3 5 effect of sulfite pretreatment on microbial communities in was microbial community analysis was further assessed in was pretreated by different sulfite concentrations principal component analysis pca revealed that microbial communities in was with sulfite from 100 to 800 mg s l became very distinct from that with no dosage of sulfite i e 0 mg s l indicating that sulfite may significantly affect microorganisms in was during the pretreatment fig 6 a subsequent to that detailed bacteria groups at genus level were further illustrated in fig 6b the relative abundance of norank p saccharibacteria was regarded as the dominant bacterial group in was pretreated with no dosage of sulfite however a substantial reduction was clearly observed from 24 83 to 8 13 with sulfite level from 0 to 800 mg s l suggesting a strong biocidal effect of sulfite on this microbe the candidate phylum saccharibacteria are abundant and widespread in nature especially in activated sludge albertsen et al 2013 hugenholtz et al 2001 kindaichi et al 2016 thomsen et al 2002 these microbial groups have been verified as a phylogenetically diverse community with the ability of degrading various organic compounds and sugar compounds under aerobic nitrate reducing and anaerobic conditions kindaichi et al 2016 however little knowledge about the physiological and phenotypic characteristics of norank p saccharibacteria is available for the clarification of the role of sulfite in order to gain insights into the possible mechanisms pearson correlation was carried out between sulfite levels and microbial communities at genus level table 3 strong negative correlations were found in norank p saccharibacteria and norank p wwe3 whereas strong positive correlations were observed in microbial groups of denitratisoma and denitromonas interestingly both saccharibacteria and wwe3 are reported as gram positive bacteria and both denitratisoma and denitromonas are gram negative fahrbach et al 2006 kantor et al 2013 luef et al 2015 marcy et al 2007 wang et al 2011 more importantly the gram positive organisms of yeast saccharomyces cerevisiae was also reported to be irreversible destroyed by sulfite kitamura and yamamoto 1981 salton 1963 wilding et al 2000 the main difference between gram positive and gram negative microorganisms is the structure of cell walls gram positive microorganisms have a thick peptidoglycan layer with teichoic acids embedded bott 2014 given sulfite is capable of dissolving hemicellulose and degrading cellulose wang et al 2009 zhang et al 2013 zhu et al 2009 we hypothesize that sulfite could react with polysaccharides e g peptidoglycan and teichoic acids in the cell wall thus directly destroying gram positive cell walls of microorganisms however more studies are further necessary for verification 3 6 potential role of sulfite the functional species of sulfite so2 h2so3 hso3 and so3 2 in the lysis of microorganism are still unclear so2 in aqueous solution has been found to be an active agent in atp depletion and dna damage in yeast and lactic acid bacteria under acidic conditions ph 6 schimz 1980 our previous study has shown a strong correlation between sulfurous acid h2so3 and scod implying that h2so3 may be responsible for the lysis of microorganisms zan et al 2016 however that tentative conclusion was drawn based on mathematical correlation rather than direct experimental observation in this study over 90 of sulfite occurred in the form of bisulfite hso3 at a ph of around 6 which presumably could be the functional sulfur species hso3 has been reported to be toxic to microorganisms fungi and coliphages at both the biochemical and cellular levels babich and stotzky 1978 moreover hso3 is active in many reactions involving biomolecules such as the aldehyde ketone structures of polysaccharides disulfide linkages of proteins and enzyme cofactors nad fmn and fad petering and shih 1975 hso3 can also deaminate cytosine derivatives to uracil compounds petering and shih 1975 inactivate mrna shapiro and braverman 1972 and inhibit ion transport across cell membranes lüttge et al 1972 in this study the results of cell lysis and microbial community changes indicates that sulfite has biocidal effect on gram positive microorganisms which may result from the distinct structure of their cell walls with high amounts of polysaccharides as major components however more detailed knowledge should be gained in further studies 3 7 potential applications and environmental impact this work demonstrated that was can be disintegrated and methane production improved by pretreating it with sulfite prior to ad the sulfite can be obtained from sulfite laden wastes this provides a possible alternative for co treating activated sludge with industrial wastes and at the same time enhances methane production for ad the enhanced biodegradability of sulfite pretreated was would induce higher biogas production and improve anaerobic treatment efficiency by increasing the hydrolysis rate and reducing the ad hydraulic retention time carrère et al 2010 pijuan et al 2012 although the hydrolysis rate and methane production can be accelerated by sulfite pretreatment through stimulating the solubilization and cell lysis of was sulfite concentration was critical to the biodegradability improvement of was table s1 sulfite concentration is regarded as a crucial factor for a well operated and efficient ad system since the presence of sulfite may provoke competition between sulfate or sulfite reducing bacteria and methanogenic archaea ahmed and rodríguez 2018 barrera et al 2015 yang et al 1997 1994 it was reported that there was no significant inhibition with the presence of sulfite with 700 2000 mg s l in the ad in which sulfide could be elevated to 200 mg s l as a result of reducing methane content in biogas athanassopoulos et al 1989 moreover in ad of hong kong s sha tin sewage treatment works over the past 30 years only limited inhibition has been observed with the presence of up to 372 mg s l of sulfate which induces hydrogen sulfide at 100 4705 ppm in biogas fung and yeung 2012 a recent study has also demonstrated the limited influence on methane production and microbial diversity with a cod sulfate ratio of 0 5 1 5 and 5 although sulfate reduction occurred in various efficiencies during the ad process cetecioglu et al 2019 that constitutes a strong endorsement for the feasibility of this work and it legitimates a further long term evaluation of the optimal sulfite concentration on was pretreatment for disintegration and solubilization changes in microbial communities of srb and ma and the efficiency of methane production during the ad process most sludge pretreatment methods seeking to reduce sludge production and or enhance biodegradability for energy recovery either require intensive energy input or consume large amounts of chemicals more importantly although many pretreatment technologies have been proven to enhance the methane production of was most do not produce enough energy to sustain themselves and thus cannot be implemented in a wwtp cano et al 2015 sulfite laden wastes were widely generated from many industrial processes li et al 2014 poullikkas 2015 srivastava and jozewicz 2001 zhu et al 2009 for instance the flue gas desulfurization fgd at fossil fuel power stations with application of fgd scrubber systems results in large amounts of sulfite laden waste with concentrations of up to 40 g so3 2 l or 40 70 of caso3 by mass as the main fgd by products poullikkas 2015 which typically end up in landfills graves et al 2017 the generated sulfite laden wastes can be reused after proper treatment for was management making sulfite pretreatment an environmentally friendly and economically viable technology although the feasibility of sulfite pretreatment has been verified in this study precisely how sulfite can be harvested from waste requires deeper investigation 4 conclusions feasibility of methane production from was with sulfite pretreatment has been verified in this study provided there are no biological sulfate reducing organisms in the ad biomass the following notable observations were made sulfite pretreatment boosted the hydrolysis rate and methane production potential of was thereby enhancing methane production from was by up to 25 sulfite pretreatment stimulated sludge disintegration and solubilization of was caused cell lysis by destructing gram positive cell walls of microorganisms pretreatment or onsite treatment of using sulfite laden wastes is a potentially viable technology for was digestion that can increase energy recovery declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the national natural science foundation of china grant no 51778165 key program of national natural science of china grant no 51638005 hong kong s research grants council grant number c6033 14g the science and technology development fund of macau grant no 0040 2018 a1 and the hong kong innovation and technology commission grant no itc cnerc14eg03 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 04 048 
18835,sulfite has been widely employed as a key agent in many industrial processes leading to a large amount of sulfite laden wastes generated given its antimicrobial function and destructive ability on cell walls detailed mechanisms for impacts of sulfite on waste activated sludge was and outcomes of methane production after the sulfite pretreatment have not been clear so far in this study the feasibility of methane production from sulfite pretreated was was verified and investigated biochemical methane potential tests demonstrated that methane production from was after the pretreatment at 800 mg s l of sulfite a typical level in sulfite laden wastes increased by up to 25 kinetic analysis of the test results indicated that sulfite pretreatment increased the sludge hydrolysis rate k hyd by 1 71 times while the ultimate biochemical methane potential b u by 1 20 times further study investigated the effects of sulfite on was from the macro scale i e sludge physicochemical properties to the micro scale i e bacterial viability microbial community sulfite concentrations of up to 800 mg s l substantially enhanced was disintegration and solubilization reducing the particle size by up to 39 boosting substrate release by 87 and improving cell lysis by 43 through the direct destruction of gram positive microorganisms e g norank p saccharibacteria in was adverse impact on anaerobic digestion by introduction of sulfite was not observed in this study though a long term evaluation is needed in the future work based on the findings of the present study sulfite laden by products or wastes from industrial processes may be co treated with was when overall cost effectiveness is concerned graphical abstract image 1 keywords sulfite sulfite wastes methane production waste activated sludge 1 introduction substantial amounts of waste activated sludge was are produced mainly from organics in biological wastewater treatment the high disposal cost of was and sanitation concerns have been attracting growing attention lakshmi et al 2014 low and chase 1999 more importantly wastewater contains chemical energy which is a useful resource that unfortunately simply ends up in was liu 2003 mccarty et al 2011 there is thus a strong incentive to recover this resource energy while reducing the cost and difficulty of disposal to this end anaerobic digestion ad is an effective process not only for the stabilization of was but also for recovery of bioenergy in the form of methane appels et al 2008 kavitha et al 2014 mccarty et al 2011 sanscartier et al 2012 zaks et al 2011 however the efficacy of methane production via ad is often hampered by the low hydrolysis rates as well as poor biochemical methane potential bmp of was ascribed to the protective presence of extracellular polymeric substances eps and the rigid structure of the microbial cell walls appels et al 2008 ma et al 2019 rani et al 2012 shimizu et al 1993 zhang et al 2015 to increase methane production various pretreatment techniques such as biological hydrolysis with enzymes free nitrous acid ultrasonication ozone chlorination alkaline and thermal techniques have been extensively investigated ahn et al 2002 ayol et al 2008 barjenbruch and kopplow 2003 lin et al 2007 pham et al 2009 saby et al 2002 wang et al 2013 zhao et al 2018 however most of the aforementioned approaches are extremely costly due to high energy input or excessive chemical consumption foladori et al 2010 it is therefore deemed necessary to explore a novel pretreatment method at low cost sulfite has been employed as a key agent in many industrial processes for instance wine making industry taking advantage of its antimicrobial function while wood pulp industry applying it for lignin extraction both inevitably generate large amount of sulfite laden wastes that require proper treatment chang et al 1997 pokhrel and viraraghavan 2004 on the other hand impacts of sulfite on the disintegration of recalcitrant cell walls through the dissolution of hemicelluloses the degradation of celluloses and the rising hydrophilicity of lignin via sulfonation were reported wang et al 2009 zhang et al 2013 zhu et al 2009 through the evaluation of biogenic sulfide production tests we recently confirmed that the biodegradability of was after sulfite pretreatment can be significantly enhanced zan et al 2016 the substrates released from was pretreated with sulfite exhibited a positive correlation with increasing sulfite exposure time and decreasing ph an observation based hypothesis was thus proposed that sulfite irreversibly destroys the sulfite sensitive cell wall structures of the microorganisms in was kitamura and yamamoto 1981 zan et al 2016 however underlying mechanism of impacts of sulfite on was and outcomes of methane production of sulfite pretreated was are not clear so far specifically what is the exact role of sulfite in the was pretreatment in terms of substrates release or cell wall disintegration is the biodegradability enhancement via sulfite pretreatment still effective in ad system and can that be reflected by methane production to address these unknowns the present work is thus to investigate energy recovery potential of the was after sulfite pretreatment with emphasis on kinetic analysis of bmp to reveal the productivity of methane i e sludge hydrolysis rate and ultimate biochemical methane potential furthermore changes in properties of was with sulfite pretreatment were conducted for the assessment of sludge disintegration and solubilization viability of microorganisms and microbial community in was after sulfite pretreatment were analyzed to provide insights into the biocidal effects of sulfite last but not least potential applications of using sulfite laden wastes to pretreat was are explored and discussed co treatment of waste streams achieving waste reduction and energy recovery enhancement in this study provides a possible alternative to face up to the challenges of massive sludge production and low energy recovery rate certainly a long term evaluation is indispensable concerning sulfite in the ad system 2 materials and methods 2 1 sludge sources and characteristics was was collected from the local freshwater wastewater treatment plant wwtp at shek wu hui in hong kong which treats an influent with a low sulfate concentration of 12 6 mg s l and is operated at a sludge retention time srt of approximately 15 days the total solids ts volatile solids vs total chemical oxygen demand tcod of the was were 4 83 0 12 g l 3 69 0 07 g l and 4 13 0 18 g l respectively and the ph was 6 47 0 02 inoculum for bmp tests was harvested from a mesophilic anaerobic digester ad at the same wwtp with 23 4 0 46 g ts l 16 7 0 57 g vs l 16 88 0 88 g tcod l and a ph of 6 94 0 01 2 2 sulfite pretreatment batch tests were conducted in triplicate to investigate the effects of sulfite on the was the sludge was washed three times with a buffered saline solution of 0 01 m phosphate to eliminate the residual substrates 0 1 l of washed was was then added to each batch reactor 120 ml serum bottle the designated sulfite level was achieved by spiking with a solution of sodium sulfite based on the typical characteristics of industrial sulfite laden wastes jiang et al 2013 zan et al 2016 ph of the washed was was adjusted to around 6 0 0 02 with 0 1 m hydrochloric acid sodium hydroxide nitrogen gas was bubbled into the batch reactors for 15 min to establish anaerobic conditions sealed batch reactors were incubated for 24 h on a multi channel orbital shaker rotating at 60 rpm under a temperature of 20 2 c the sulfite level as the major operational parameter was examined as summarized in table 1 with 0 mg s l as control in all tests ts vs total suspended solids tss volatile suspended solids vss particle size zeta potential soluble chemical oxygen demand scod sulfite so3 2 sulfate so4 2 soluble nitrogen sn soluble kjeldahl nitrogen no2 no3 soluble proteins soluble polysaccharides and volatile fatty acids vfas were measured in triplicate the measured changes were expressed as a biomass specific value by dividing the value by the corresponding vs of was measured before the test 2 3 biochemical methane potential bmp tests the bmp test was used to assess the biodegradability of was with and without sulfite pretreatment from 0 to 800 mg s l tests were carried out in 120 ml serum bottles with a working volume of 80 ml containing 24 ml of inoculum and 56 ml of sulfite pretreated was with an inoculum to was ratio of 2 on a dry vs basis test samples after 15 min of nitrogen gas sparging the bottles were sealed with a rubber stopper by an aluminum crimp cap the serum bottles were placed on a rotator spinning at 60 rpm in a water bath at 37 1 c blanks inoculum only containing inoculum milli q water and different concentrations of sulfite 0 100 300 500 and 800 mg s l without was were set up to evaluate the effect of sulfite on biogas production from the inoculum only all tests were conducted in triplicate and lasted for 30 days loosdrecht et al 2016 the biogas production was monitored every two days in the first week and every three to four days afterwards the net biogas production from was was only was recorded by subtracting biogas production in test samples inoculum was from the blank samples inoculum only the methane production was presented as the volume of methane produced per kilogram of vs added l ch4 kg vsadded to investigate the reaction rates and efficiency of the sulfite pretreated was and the inoculum via bmp tests a first order kinetic model eq 1 batstone et al 2009 lu et al 2018 rao et al 2000 was applied to fit the cumulative methane production data two key kinetic parameters i e the hydrolysis rate k hyd and the ultimate bmp b u were obtained by minimizing the least square difference between the observed and predicted values to examine and compare the methane production kinetics and potential of the was with and without sulfite pretreatment 1 b t b u 1 exp k h y d t where b t represents the cumulative methane production l ch4 kg vsadded at time t b u is the ultimate biochemical methane potential l ch4 kg vsadded k hyd is the hydrolysis rate 1 d and t is the test duration d based on the predicted value of b u the degradation extent f d unitless of sludge can be determined using eq 2 wang et al 2013 2 f d b u 380 r s l u d g e the theoretical bmp of sludge of 380 was assumed in this work under standard conditions 25 c and 1 atm l ch4 kg tcod metcalf and eddy 1980 r sludge is the measured ratio of vs to tcod of sludge i e 0 89 for was and 0 98 for the inoculum in this study 2 4 viability test and microbial community analysis sulfite effects on was were examined with live dead staining viability tests of microorganisms in the was were conducted at the end of each test the live dead baclight bacterial viability kits molecular probes l 7012 were adopted for viability examination containing two nucleic acid stains red fluorescent propidium iodide pi and green syto 9 the syto 9 stain labels total microorganisms with intact or damaged membranes the pi stain shows microorganisms with damaged membranes inducing a reduction in the fluorescence of syto 9 when both dyes are applied the stained was samples were examined under a confocal laser scanning microscope zeiss lsm7 duo live and dead microorganisms were quantified based on the relative abundance of green and red pixels in 20 or more images in imagej national institutes of health usa to ensure representativeness zan et al 2019 microbial community of was after sulfite pretreatment was determined using high throughput sequencing of the 16s rrna gene as described in hao et al 2015 the analytical procedure involved dna extraction polymerase chain reaction pcr amplification pyrosequencing and data analysis 2 5 analytical methods samples of dissolved organic carbon doc sn so3 2 so4 2 sulfide soluble proteins soluble polysaccharides and vfas were prepared and filtered through disposable millipore filters with pore size of 0 45 μm so3 2 ts vs tss and vss were determined according to the standard methods apha 2005 so4 2 was measured using an ion chromatograph hic 20a super shimadzu japan equipped with a conductivity detector and an ic sa2 analytical column hs h2s was measured with the methylene blue method apha 2005 the doc and sn were assessed using a total organic carbon total nitrogen analyzer toc 5000a shimadzu japan organic scod was calculated with a theoretical ratio cod c 2 67 soluble proteins were measured by the bicinchoninic acid assay with bovine serum albumin as standard smith et al 1985 while soluble polysaccharides were determined using the colorimetric method dubois et al 1956 specific vfas e g acetate propionate and butyrate were determined with a high performance liquid chromatograph hic 20a super shimadzu japan equipped with a conductivity detector and an ic sa3 analytical column zeta potential was measured with a zeta potential analyzer zetaplus brookhaven usa particle size of was was assessed with a laser diffraction particle size analyzer ls 13 320 beckman coulter usa the biogas volume was determined using inflated samco glass syringes with a volume of 50 ml at each sampling event cumulative volumetric biogas production was calculated from the combination of inflated syringes volume and headspace volume of the serum bottles i e 40 ml and expressed under the standard conditions 25 c and 1 atm the biogas contents ch4 co2 and n2 were detected using an agilent 7890b gas chromatograph equipped with an electron capture detector 2 6 statistical analysis principal component analysis pca was applied to compare the differences in microbial community of was after sulfite pretreatment at different levels 0 800 mg s l using r with vegan package correlations between sulfite levels and microbial communities at genus level were evaluated by using pearson correlation coefficient the coefficient reflects the linear correlation between two variables with a value from 1 to 1 where 1 represents total negative linear correlation 0 indicates no linear correlation and 1 represents total positive linear correlation the analysis was conducted in the software spss version 21 ibm usa a 95 confidence level p 0 05 was adopted for determining statistical significance 3 results and discussion 3 1 methane production from was with sulfite pretreatment the main purpose of sludge pretreatment is to maximize energy recovery via ad effects of sulfite on methane production were assessed from two perspectives a the cumulative methane production from the inoculum only fig 1 a and b the cumulative methane production from was only fig 1b this is coupled with the kinetic analysis with the first order kinetic model eq 1 which simulated well the methane production rates observed in the bmp tests i e b u k hyd and f d fig 2 and table 2 the coefficients of determination r2 of the simulation were higher than 0 92 in all cases inoculum only and was only indicating a satisfactory fit of the kinetic model to the observed cumulative methane production was treated with sulfite was directly used for bmp tests and thus a certain level of sulfite or sulfate from sulfite oxidization was present in bmp tests during the course of the entire experiment the amounts of dissolved sulfide in liquid phase and hydrogen sulfide in gas phase were negligible in all samples inocumlum only and inoculum was this may be attributed to the was and inoculum from the freshwater wwtp with a low concentration 12 6 mg s l of sulfate in the influent sewage and thus sulfate reducing bacteria were not abundant or active in the obtained was and inoculum ad sludge the impact of sulfite addition in ad should be evaluated for the long term sulfite pretreatment stimulated significant increases in methane production throughout the bmp test period in both inoculum and was fig 1 for the blanks inoculum only the increase in methane production was approximately twofold as sulfite concentration rose from 0 27 73 l ch4 kg vsadded to 800 mg s l 54 69 l ch4 kg vsadded suggesting that sulfite could directly induce the inoculum to produce more methane organic matter residues of the inoculum may partially contribute to methane production this is further confirmed by the increases in b u k hyd and f d table 2 the improvement in b u and f d was around 50 and the k hyd rate increased sharply by 356 at sulfite level of 800 mg s l compared with the control this implies that even the hydrolysis rate of the digestate i e inoculum in this study can be substantially improved by sulfite dosage because the ad biomass makes up only a small fraction of the vs concentration in ads most of the vs in ad are unbiodegradable particulate organics upo and residual biodegradable particulate organics bpo such a large increase in b u and f d suggest that upo may have been converted to bpo by the sulfite specific tests to validate this will have to be conducted the impact of sulfite dosing on sludge reduction and the inoculum in ad deserves further investigation as for the was with sulfite pretreatment was only methane production grew gradually with the increase in sulfite concentration from 0 to 800 mg s l fig 1b there was a slight increase in the cumulative methane production at sulfite levels below 300 mg s l up to 1 25 times higher than the controls cumulative methane productions was observed when 800 mg s l of sulfite were used in the pretreatment values of b u k hyd and f d clearly increased with sulfite concentration table 2 a significant increase in b u and k hyd by up to 83 and 221 respectively indicates that the sulfite pretreatment directly accelerated the hydrolysis rate and methane production potential in this study the degradation extent f d fell into the range of 0 29 0 35 which is consistent with other studies where f d ranged from 0 27 to 0 55 in five wwtps paul et al 2012 from 0 3 to 0 6 wei et al 2017 and from 0 33 to 0 53 wang et al 2013 however it should be noted that the characteristics of was vary naturally over time and space particularly when the sludge is from a moderate sludge age plant which may significantly influence the methane production from inoculum and sludge wei et al 2018 both k hyd and b u or f d were improved in this study thus sulfite pretreatment could be considered an efficient means for was pretreatment improving methane production given little is known about the effects of sulfite pretreatment on was there is a need to further investigate the changes of was during sulfite pretreatment from different aspects 3 2 effect of sulfite pretreatment on was sulfite pretreatment 0 800 mg s l at a ph of 6 for 24 h induced significant changes in was properties i e particle size zeta potential and vss tss ratio fig 3 these properties were observed to decrease with increasing sulfite concentration after sulfite pretreatment the zeta potential of was decreased from 1 4 mv with zero sulfite to 27 mv with 800 mg s l of sulfite fig 3a an increase in the amount of negative charges on the was surface can lead to a rise in electrostatic repulsion and a drop in interaction energy implying that sulfite pretreatment induced the destabilization of the floc structure of was correspondingly the average particle size in terms of d10 d50 and d90 defined as the equivalent diameters in volume of 10 50 and 90 of total particles respectively of was decreased 39 29 and 29 respectively fig 3b this indicates that sulfite pretreatment could cause the floc structure to disintegrate when was breaks up into smaller pieces with sulfite pretreatment the deterioration of the protective structure would cause intra extracellular materials to be released appels et al 2008 harrison 1991 concomitant with was disintegration the vss tss ratios with increased sulfite levels were reduced by up to 15 61 fig 3c consistent with the changes in particle size of was after sulfite pretreatment particles in was tended to be disintegrated by sulfite treatment and then passed through the filter pore size of 1 2 μm causing a reduction of vss tss the decrease in the vss tss ratio further confirmed that sulfite pretreatment could convert particulate organic substances into soluble ones and reduce the particulate organic content in was solubilization of was through disintegration of the floc structure and reduction of the organic solid content are required for effective was disposal tiehm et al 2001 it is also necessary to verify and quantify the changes in soluble substrates in was after sulfite pretreatment 3 3 effect of sulfite pretreatment on was solubilization the increased solubilization of was after sulfite pretreatment was investigated and quantified and the results are shown in fig 4 was pretreated with different levels 0 800 mg s l of sulfite resulted in the release and or production of scod sn soluble proteins soluble polysaccharides and vfas mainly acetate propionate and butyrate the highest production of scod occurred at a sulfite level of 800 mg s l and it was around 1 87 times higher than that of the control fig 4a similarly the release of sn and soluble polysaccharides from was solubilization increased by 1 21 and 1 94 times respectively fig 4a and b approximately 4 26 times more soluble proteins were produced at a sulfite level of 500 mg s l after which a slight decrease was observed from 9 78 mg g vs 500 mg s l to 8 38 mg g vs 800 mg s l fig 4b proteins play a more important role than polysaccharides in the floc matrix for both aggregating bacteria into flocs and consolidating the water binding capability of was higgins and novak 1997 shao et al 2009 substantial quantities of water can reside at the protein surface and be buried inside the protein which in turn stabilizes the structure of protein macromolecules in flocs halle and denisov 1995 hence large scale release of soluble proteins after sulfite pretreatment can further enhance the disintegration of was vfas in soluble phase were quantified after sulfite pretreatment the production of total vfas was observed to rise with the sulfite level fig 4c up to 1 80 times more vfas were produced than in the control acetate was the major vfa component accounting for around 77 0 mg s l to 86 800 mg s l of the vfa concentrations the majority of the cod in was occurs in particulate form i e scod tcod ranges from 1 to 10 ji et al 2010 and the production of vfas through the hydrolysis of particulate organic matter is limited in conventional sludge treatment processes lee et al 2014 this limits the possibility of recovering valuable resources from was zan et al 2018 in this study substantial amounts of vfas were produced during was solubilization demonstrating that sulfite pretreatment can directly improve was hydrolysis 3 4 effect of sulfite pretreatment on viable cells in was the percentages of viable cells in was after sulfite pretreatment decreased with increasing sulfite concentration fig 5 from 56 without sulfite dosage to 40 at a sulfite level of 100 mg s l at higher sulfite the percentage of viable cells reduced by a further 8 from 100 mg s l to 800 mg s l sulfite has been proven to be effective in reducing microbial viability through its biocidal effect on cells in was zan et al 2016 this is consistent with other observations that the cell walls or cells of microorganisms with sulfite sensitive cell walls and saccharomyces cerevisiae could be destroyed or inactivated in the presence of sulfite kitamura and yamamoto 1981 schimz 1980 enhanced lysis of the microbial cells in was due to sulfite could contribute to was solubilization 3 5 effect of sulfite pretreatment on microbial communities in was microbial community analysis was further assessed in was pretreated by different sulfite concentrations principal component analysis pca revealed that microbial communities in was with sulfite from 100 to 800 mg s l became very distinct from that with no dosage of sulfite i e 0 mg s l indicating that sulfite may significantly affect microorganisms in was during the pretreatment fig 6 a subsequent to that detailed bacteria groups at genus level were further illustrated in fig 6b the relative abundance of norank p saccharibacteria was regarded as the dominant bacterial group in was pretreated with no dosage of sulfite however a substantial reduction was clearly observed from 24 83 to 8 13 with sulfite level from 0 to 800 mg s l suggesting a strong biocidal effect of sulfite on this microbe the candidate phylum saccharibacteria are abundant and widespread in nature especially in activated sludge albertsen et al 2013 hugenholtz et al 2001 kindaichi et al 2016 thomsen et al 2002 these microbial groups have been verified as a phylogenetically diverse community with the ability of degrading various organic compounds and sugar compounds under aerobic nitrate reducing and anaerobic conditions kindaichi et al 2016 however little knowledge about the physiological and phenotypic characteristics of norank p saccharibacteria is available for the clarification of the role of sulfite in order to gain insights into the possible mechanisms pearson correlation was carried out between sulfite levels and microbial communities at genus level table 3 strong negative correlations were found in norank p saccharibacteria and norank p wwe3 whereas strong positive correlations were observed in microbial groups of denitratisoma and denitromonas interestingly both saccharibacteria and wwe3 are reported as gram positive bacteria and both denitratisoma and denitromonas are gram negative fahrbach et al 2006 kantor et al 2013 luef et al 2015 marcy et al 2007 wang et al 2011 more importantly the gram positive organisms of yeast saccharomyces cerevisiae was also reported to be irreversible destroyed by sulfite kitamura and yamamoto 1981 salton 1963 wilding et al 2000 the main difference between gram positive and gram negative microorganisms is the structure of cell walls gram positive microorganisms have a thick peptidoglycan layer with teichoic acids embedded bott 2014 given sulfite is capable of dissolving hemicellulose and degrading cellulose wang et al 2009 zhang et al 2013 zhu et al 2009 we hypothesize that sulfite could react with polysaccharides e g peptidoglycan and teichoic acids in the cell wall thus directly destroying gram positive cell walls of microorganisms however more studies are further necessary for verification 3 6 potential role of sulfite the functional species of sulfite so2 h2so3 hso3 and so3 2 in the lysis of microorganism are still unclear so2 in aqueous solution has been found to be an active agent in atp depletion and dna damage in yeast and lactic acid bacteria under acidic conditions ph 6 schimz 1980 our previous study has shown a strong correlation between sulfurous acid h2so3 and scod implying that h2so3 may be responsible for the lysis of microorganisms zan et al 2016 however that tentative conclusion was drawn based on mathematical correlation rather than direct experimental observation in this study over 90 of sulfite occurred in the form of bisulfite hso3 at a ph of around 6 which presumably could be the functional sulfur species hso3 has been reported to be toxic to microorganisms fungi and coliphages at both the biochemical and cellular levels babich and stotzky 1978 moreover hso3 is active in many reactions involving biomolecules such as the aldehyde ketone structures of polysaccharides disulfide linkages of proteins and enzyme cofactors nad fmn and fad petering and shih 1975 hso3 can also deaminate cytosine derivatives to uracil compounds petering and shih 1975 inactivate mrna shapiro and braverman 1972 and inhibit ion transport across cell membranes lüttge et al 1972 in this study the results of cell lysis and microbial community changes indicates that sulfite has biocidal effect on gram positive microorganisms which may result from the distinct structure of their cell walls with high amounts of polysaccharides as major components however more detailed knowledge should be gained in further studies 3 7 potential applications and environmental impact this work demonstrated that was can be disintegrated and methane production improved by pretreating it with sulfite prior to ad the sulfite can be obtained from sulfite laden wastes this provides a possible alternative for co treating activated sludge with industrial wastes and at the same time enhances methane production for ad the enhanced biodegradability of sulfite pretreated was would induce higher biogas production and improve anaerobic treatment efficiency by increasing the hydrolysis rate and reducing the ad hydraulic retention time carrère et al 2010 pijuan et al 2012 although the hydrolysis rate and methane production can be accelerated by sulfite pretreatment through stimulating the solubilization and cell lysis of was sulfite concentration was critical to the biodegradability improvement of was table s1 sulfite concentration is regarded as a crucial factor for a well operated and efficient ad system since the presence of sulfite may provoke competition between sulfate or sulfite reducing bacteria and methanogenic archaea ahmed and rodríguez 2018 barrera et al 2015 yang et al 1997 1994 it was reported that there was no significant inhibition with the presence of sulfite with 700 2000 mg s l in the ad in which sulfide could be elevated to 200 mg s l as a result of reducing methane content in biogas athanassopoulos et al 1989 moreover in ad of hong kong s sha tin sewage treatment works over the past 30 years only limited inhibition has been observed with the presence of up to 372 mg s l of sulfate which induces hydrogen sulfide at 100 4705 ppm in biogas fung and yeung 2012 a recent study has also demonstrated the limited influence on methane production and microbial diversity with a cod sulfate ratio of 0 5 1 5 and 5 although sulfate reduction occurred in various efficiencies during the ad process cetecioglu et al 2019 that constitutes a strong endorsement for the feasibility of this work and it legitimates a further long term evaluation of the optimal sulfite concentration on was pretreatment for disintegration and solubilization changes in microbial communities of srb and ma and the efficiency of methane production during the ad process most sludge pretreatment methods seeking to reduce sludge production and or enhance biodegradability for energy recovery either require intensive energy input or consume large amounts of chemicals more importantly although many pretreatment technologies have been proven to enhance the methane production of was most do not produce enough energy to sustain themselves and thus cannot be implemented in a wwtp cano et al 2015 sulfite laden wastes were widely generated from many industrial processes li et al 2014 poullikkas 2015 srivastava and jozewicz 2001 zhu et al 2009 for instance the flue gas desulfurization fgd at fossil fuel power stations with application of fgd scrubber systems results in large amounts of sulfite laden waste with concentrations of up to 40 g so3 2 l or 40 70 of caso3 by mass as the main fgd by products poullikkas 2015 which typically end up in landfills graves et al 2017 the generated sulfite laden wastes can be reused after proper treatment for was management making sulfite pretreatment an environmentally friendly and economically viable technology although the feasibility of sulfite pretreatment has been verified in this study precisely how sulfite can be harvested from waste requires deeper investigation 4 conclusions feasibility of methane production from was with sulfite pretreatment has been verified in this study provided there are no biological sulfate reducing organisms in the ad biomass the following notable observations were made sulfite pretreatment boosted the hydrolysis rate and methane production potential of was thereby enhancing methane production from was by up to 25 sulfite pretreatment stimulated sludge disintegration and solubilization of was caused cell lysis by destructing gram positive cell walls of microorganisms pretreatment or onsite treatment of using sulfite laden wastes is a potentially viable technology for was digestion that can increase energy recovery declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the national natural science foundation of china grant no 51778165 key program of national natural science of china grant no 51638005 hong kong s research grants council grant number c6033 14g the science and technology development fund of macau grant no 0040 2018 a1 and the hong kong innovation and technology commission grant no itc cnerc14eg03 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j watres 2019 04 048 
18836,the virtual water hypothesis offers the reasonable proposition that if water abundant regions export water intensive products to water scarce regions the latter could devote their scarce resources instead to uses yielding higher economic returns zhao et al show that trade flows in china do not adhere to this hypothesis use the economic theory of comparative advantage to explore why and seek a solution where both the hypothesis and the theory are apparently satisfied however they have not fully utilized the power of the theory this is made evident by the fact that their calculations quantify what they call the comparative advantage of land labor and water as stated in the title of the article this comment describes the significance of comparative advantage for this inquiry and our comparable investigation for the regions of mexico it concludes with the case for a collaborative effort to situate such single country studies in the context of a model of global comparative advantages keywords virtual water hypothesis economic theory of comparative advantage input output model of inter regional trade 1 the economic theory of comparative advantage resources do not have comparative advantages economic entities do comparative advantage explains why nations or regions trade with each other in the absence of barriers to trade they all stand to benefit in terms of lower systemwide prices and lower resource use if each one specializes in producing and exporting products for which it is a relatively low cost producer and relies on imports for other products the qualifiers comparative and relative are essential if costs of production in one region are twice those in all other trade partners for most products but only one and a half times as great for some products the region has a comparative advantage in specializing in the latter products even though it has an absolute advantage in none the theory is also relative in that if a single region adopts a new cost saving technology or discovers an additional source of a critical resource the comparative advantages of all regions can in principle change each potential trade partner is characterized by its consumption demand production technologies resource availability also called endowments of factors of production and baseline resource prices if the relatively lowest cost producer cannot satisfy total systemwide demand higher cost producers will supplement the former s output the highest cost among them sets the price for the product and lower cost producers earn so called scarcity rents on resource limits that prevented their expanding production the magnitudes of the rents received by a producer are determined by the difference between the established price and the producer s lower costs e g saudi arabia enhances its scarcity rents on petroleum by limiting extraction requiring higher cost producers to enter the market the world trade model see below provides a concise and faithful representation of the theory of comparative advantage as a constrained optimization problem that makes the underlying logic transparent it is applicable to global or domestic inter regional trade duchin and levine 2012 2 the case of mexico zhao et al cite a paper of ours that evaluates the response to policies that curb the unsustainable use of water for agriculture in mexico in a way that is consistent with the comparative advantages of its 13 hydro economic regions duchin and lópez morales 2012 under the baseline scenario the analysis shows that it is the water scarce regions that possess comparative advantages in agricultural production alternative scenarios impose constraints on water withdrawals effectively obliging the water scarce regions to cut back on agricultural output we discover that regions with moderate water endowments not the water rich regions take up the slack it should come as no surprise that the quantity of available water alone should fail to be decisive our analysis applies the world trade model with rectangular choice of technologies wtm rcot to a database including region specific production technologies and their endowments of agricultural land water built capital and labor a follow up study lópez morales and duchin 2015 further distinguishes surface water from groundwater sources zhao et al conclude that land yields in the water rich regions of china need to be raised while shifting land away from agriculture to more remunerative service sectors in water scarce regions one could apply the wtm model to analyze scenarios that specify concrete options for changes in technology by which the water rich regions might be able to achieve the desired increases of agricultural output a change in technology involves replacing a column of coefficients in an input output matrix and resource endowments would need to be quantified the outcomes would reveal where the comparative advantages in agricultural production would actually lie as well as changes in resource use costs and prices under different assumptions about the yield enhancing technologies based on our results for mexico we would not be surprised if it is in regions other than those with the largest endowments of water in addition land now used for agriculture could be made available to other sectors in all regions not only for services and not only in the water scarce regions while these exercises would require additional data and perhaps minor customization of the model this is generally the case for applying a research model to a new inquiry to go further and allow for endogenous competition over land among sectors of the economy a taxonomy distinguishing land surfaces on the basis of attributes important for different uses would increase the realism of shifts in land use juliá and duchin 2013 take a next step in this direction by offering a taxonomy for agricultural land however this added complexity is required only if zhao et al wish to claim that the proposed solution is the optimal provincial division of labor for china 3 conclusion the need for collaboration as zhao et al point out dynamics of interregional trade structure within china would have significant implications for the global trade and global economy p 305 while governments often subsidize high cost domestic food production and tolerate unsustainable use of resources to avoid over reliance on imports they clearly benefit economically to the extent that international trade is based on country level comparative advantages to assure future access to imported food a number of nations acquire rights to arable land in other countries most of the global growth in population and dietary improvements are anticipated for precisely these latter countries it may well be the case that china and other countries could benefit economically from devoting their scarce resources to producing modern services and manufactured goods while importing more food from countries in southeast asia sub saharan africa and south america and that the latter countries would also benefit from these exchanges a model of the global economy is needed to investigate both the global capacity to satisfy increased food demand over the next several decades and the distribution of the benefits juliá and duchin 2013 and springer and duchin 2014 have begun the inquiry into likely future global shifts in comparative advantages in food production by mid century however this body of analysis requires collaborations that draw on country specific knowledge and diverse disciplinary perspectives as a basis for formulating assumptions about future human diets suitable agricultural technologies availability of resources and domestic policies the body of work of zhao and colleagues on china and ours on mexico have benefitted from this kind of familiarity and engagement the analytic framework that includes the wtm rcot input output model is well suited to conducting these kinds of experiments conflicts of interest the authors declare no conflicts of interest 
18836,the virtual water hypothesis offers the reasonable proposition that if water abundant regions export water intensive products to water scarce regions the latter could devote their scarce resources instead to uses yielding higher economic returns zhao et al show that trade flows in china do not adhere to this hypothesis use the economic theory of comparative advantage to explore why and seek a solution where both the hypothesis and the theory are apparently satisfied however they have not fully utilized the power of the theory this is made evident by the fact that their calculations quantify what they call the comparative advantage of land labor and water as stated in the title of the article this comment describes the significance of comparative advantage for this inquiry and our comparable investigation for the regions of mexico it concludes with the case for a collaborative effort to situate such single country studies in the context of a model of global comparative advantages keywords virtual water hypothesis economic theory of comparative advantage input output model of inter regional trade 1 the economic theory of comparative advantage resources do not have comparative advantages economic entities do comparative advantage explains why nations or regions trade with each other in the absence of barriers to trade they all stand to benefit in terms of lower systemwide prices and lower resource use if each one specializes in producing and exporting products for which it is a relatively low cost producer and relies on imports for other products the qualifiers comparative and relative are essential if costs of production in one region are twice those in all other trade partners for most products but only one and a half times as great for some products the region has a comparative advantage in specializing in the latter products even though it has an absolute advantage in none the theory is also relative in that if a single region adopts a new cost saving technology or discovers an additional source of a critical resource the comparative advantages of all regions can in principle change each potential trade partner is characterized by its consumption demand production technologies resource availability also called endowments of factors of production and baseline resource prices if the relatively lowest cost producer cannot satisfy total systemwide demand higher cost producers will supplement the former s output the highest cost among them sets the price for the product and lower cost producers earn so called scarcity rents on resource limits that prevented their expanding production the magnitudes of the rents received by a producer are determined by the difference between the established price and the producer s lower costs e g saudi arabia enhances its scarcity rents on petroleum by limiting extraction requiring higher cost producers to enter the market the world trade model see below provides a concise and faithful representation of the theory of comparative advantage as a constrained optimization problem that makes the underlying logic transparent it is applicable to global or domestic inter regional trade duchin and levine 2012 2 the case of mexico zhao et al cite a paper of ours that evaluates the response to policies that curb the unsustainable use of water for agriculture in mexico in a way that is consistent with the comparative advantages of its 13 hydro economic regions duchin and lópez morales 2012 under the baseline scenario the analysis shows that it is the water scarce regions that possess comparative advantages in agricultural production alternative scenarios impose constraints on water withdrawals effectively obliging the water scarce regions to cut back on agricultural output we discover that regions with moderate water endowments not the water rich regions take up the slack it should come as no surprise that the quantity of available water alone should fail to be decisive our analysis applies the world trade model with rectangular choice of technologies wtm rcot to a database including region specific production technologies and their endowments of agricultural land water built capital and labor a follow up study lópez morales and duchin 2015 further distinguishes surface water from groundwater sources zhao et al conclude that land yields in the water rich regions of china need to be raised while shifting land away from agriculture to more remunerative service sectors in water scarce regions one could apply the wtm model to analyze scenarios that specify concrete options for changes in technology by which the water rich regions might be able to achieve the desired increases of agricultural output a change in technology involves replacing a column of coefficients in an input output matrix and resource endowments would need to be quantified the outcomes would reveal where the comparative advantages in agricultural production would actually lie as well as changes in resource use costs and prices under different assumptions about the yield enhancing technologies based on our results for mexico we would not be surprised if it is in regions other than those with the largest endowments of water in addition land now used for agriculture could be made available to other sectors in all regions not only for services and not only in the water scarce regions while these exercises would require additional data and perhaps minor customization of the model this is generally the case for applying a research model to a new inquiry to go further and allow for endogenous competition over land among sectors of the economy a taxonomy distinguishing land surfaces on the basis of attributes important for different uses would increase the realism of shifts in land use juliá and duchin 2013 take a next step in this direction by offering a taxonomy for agricultural land however this added complexity is required only if zhao et al wish to claim that the proposed solution is the optimal provincial division of labor for china 3 conclusion the need for collaboration as zhao et al point out dynamics of interregional trade structure within china would have significant implications for the global trade and global economy p 305 while governments often subsidize high cost domestic food production and tolerate unsustainable use of resources to avoid over reliance on imports they clearly benefit economically to the extent that international trade is based on country level comparative advantages to assure future access to imported food a number of nations acquire rights to arable land in other countries most of the global growth in population and dietary improvements are anticipated for precisely these latter countries it may well be the case that china and other countries could benefit economically from devoting their scarce resources to producing modern services and manufactured goods while importing more food from countries in southeast asia sub saharan africa and south america and that the latter countries would also benefit from these exchanges a model of the global economy is needed to investigate both the global capacity to satisfy increased food demand over the next several decades and the distribution of the benefits juliá and duchin 2013 and springer and duchin 2014 have begun the inquiry into likely future global shifts in comparative advantages in food production by mid century however this body of analysis requires collaborations that draw on country specific knowledge and diverse disciplinary perspectives as a basis for formulating assumptions about future human diets suitable agricultural technologies availability of resources and domestic policies the body of work of zhao and colleagues on china and ours on mexico have benefitted from this kind of familiarity and engagement the analytic framework that includes the wtm rcot input output model is well suited to conducting these kinds of experiments conflicts of interest the authors declare no conflicts of interest 
18837,current application of clean water aeration test standards for wastewater treatment systems is reviewed with a focus on problematic interpretations and practices of the most commonly and internationally used standards edited by the asce usa cen eu efta and dwa germany remedy is proposed for these practices with a view to inspire revision of existing standards toward better understanding and achievement of test accuracy with regard to oxygen transfer rate themes are i the importance of mixing for testing and ii the importance of mixing for the relevance of standard oxygen transfer rate for the treatment process iii loop reactor testing and the impact of aeration layout the circulation time scale and dispersion iv tapered aeration testing v impact of probe response time vi sulfite interference at low temperatures vii the effective depth concept for the dissolved oxygen saturation concentration and standard corrections to the in situ saturation concentration viii uncertainty estimates on oxygen transfer capacity and efficiency and ix the prospect for simplification and harmonization among existing standards it is suggested that tests based on an improved understanding of the effects of mixing probe lag sulfite oxidation kinetics and fluctuations will eventually result in the reduction of costly oversizing of aeration systems and improve the understanding of aeration system design and oxygen transfer rate vis a vis energy consumption and substrate conversion in biological wastewater treatment keywords aeration mixing oxygen transfer standard testing nomenclature symbols bo bodenstein dispersion number c lt concentration of oxygen or liquid tracer dissolved in water kg m3 c a surface saturation concentration kg m3 c s saturation concentration of gas species e g oxygen in water kg m3 c s st standard saturation concentration of oxygen in water at 20 c p st and zero dissolved solids concentration 9 09 g m3 c end value of concentration kg m3 d dispersion coefficient m2 s for gas species e g oxygen dissolved in the liquid da damköhler i number i e transfer coefficient normalized by rate of recirculation q 1 or k l a k m total mass of dissolved oxygen kg n number of independent data points in time series q liquid recirculation rate between aerated and unaerated zones mixing flow rate m3 s q a air flow rate in aeration system nm3 h r ratio of gas tracer to liquid tracer concentration s source term in the dimensional model kg m3s t p linear lag time of instrument s v liquid volume in tank m3 z diffuser submergence m a ratio of flow rates between cells within a zone and between zones b lag factor c kr t normalized oxygen or krypton tritium concentration c c s c global volume average of c c p dimensionless oxygen probe signal k rate or pulse or recirculation frequency s 1 k l a oxygen or other gas species transfer coefficient s 1 k p probe response rate t p 1 s 1 p fraction of liquid volume exposed to aeration p a ambient atmospheric barometric pressure pa p st standard ambient pressure 101325 pa q normalized liquid mixing or recirculation rate q k l a v or da 1 r ratio of k l a of one zone to that of the previous zone s 1 2 normalized source term s k l a c s t time s u u flow velocity vector magnitude m s x space coordinate m γ percentage of gap closure δ model misfit or shift to data δ uncertainty ζ effective do submergence of z κ ef apparent transfer coefficient transfer coefficient based on exponential fit normalized with the true oxygen transfer coefficient κ ζ transfer rate scale in intermittent mixing two zone model κ ζα oxygen transfer rate scale in two zone model κ ζμ mixing rate scale in two zone model ρ liquid density kg m3 σ standard deviation τ time normalized by oxygen transfer rate k l a t τ p linear delay or probe lag time normalized by some rate k t p θ liquid temperature oc del operator m 1 abbreviations adm axial dispersion model cfd computational fluid dynamics bod biochemical oxygen demand kg m3 do dissolved oxygen concentration kg m3 sae standard aeration efficiency kg o2 kwh sote standard oxygen transfer efficiency sotr standard oxygen transfer rate kg o2 h tds total dissolved solids concentration kg m3 1 introduction specification and commissioning of aeration systems for biological wastewater treatment is routinely based on the standard oxygen requirement sor and the standard oxygen transfer rate sotr i e the oxygen transfer performance of the system under standardized conditions standard conditions include the use of clean water in order to separate the aeration system performance from the variability and uncertainty in unclean or process water composition sotr testing may be made for technical or commercial purposes in the design and commissioning phases narrow negative tolerances are often specified and imposed on tests performance underestimates due to incorrect application of test methods may lead to excessive capital and operating cost equipment and process r d may likewise be stifled by incorrect understanding of the oxygen transfer capacity precise test methods and sound uncertainty estimates are thus in the interest of the water community the most often used test standards in the experience of the author are those by asce 2007 following 1984 and 1992 editions cen 2003 and dwa 2007 following a 1996 edition referring to cen 2003 while adding discussion and options in particular the early asce committee work is well documented e g boyle ed 1978 boyle ed 1983 in summary the test and analysis procedures are as follows 1 the tank and clean water are prepared by aerating the water for a period and ensuring the tank is closed 2 the do dissolved oxygen concentration is displaced from its saturation level using oxidation of chemicals or gas stripping 3 do versus time curves are recorded at several points in the tank during reaeration for recovery of saturation 4 fitting of a mathematical model to these curves results in the onsite values for c s and k l a 5 this data is corrected for pressure temperature and potentially salinity effects to standard conditions and then averaged to obtain globally representative values 6 the resulting sotr value also depends on the water volume 1 s o t r c s k l a v 7 the sotr value is defined as the instantaneous oxygen transfer rate under standard conditions and at zero do 8 values of sote standard oxygen transfer efficiency and sae standard aeration efficiency may be calculated upon measurement of air flow rate if applicable and power consumption respectively the areas listed in table 1 and their current stand with the mentioned standards are discussed in this work the impact of mixing on the aeration process is briefly discussed as a complement to the test related mixing issues further harmonization or simplification points are proposed in the outlook some general remarks on the presentation follow here first dimensionless equations and entities have been used where possible to simplify the presentation the dimensionless time is defined as τ k l a t when a mass transfer coefficient is involved and as τ k t when a circulation rate is involved in practical application k l a is of course unknown and cannot be used for a priori normalization second in this work nonlinear parameter fitting is applied item 4 in the above test method summary nonlinear models play an important role and computational software and hardware no longer severely limits nonlinear fitting as in the past fitting of models to do data series is made between 20 and 98 of saturation for absorption testing as advised by asce 2007 unless otherwise stated the number of data points per time series is taken to be high enough to capture several features of each series the data range and density are further considered in section 6 3 1 1 finally the computations involved in nonlinear model parameter fitting to test data and in solving increasingly complex models are easily done using high level mathematics software the present work uses the commercial software package mathematica version 11 3 other commercial systems e g matlab maple and open source or free software e g scilab and octave are available in the author s experience spreadsheet applications may be too lightweight as the model complexity and number of fitting parameters increase 2 the perfect mixing assumption and its limitations while the invalidity of some present day application of current standards can easily be understood on a mathematical basis intuitive and mathematically simple models are used below to highlight important effects of inhomogeneity and mixing time scales a complete computational fluid dynamics cfd model is briefly reported in order to relieve the limitation of the simplistic models and prove the concept to be valid in realistic flows the terms complete mix and limited mix are used to denote completely mixed reactors and incompletely mixed reactors respectively as defined below the transport equation for a dissolved substance tracer like oxygen in clean water is 2 c t u c d c s with the classical gas liquid mass transfer source term 3 s k l a c s c the complete mix model c 0 or q removes any spatial dependence and for a reaeration process eq 4 is a valid solution 4 c t c 1 e k l a t t 0 c c c 0 1 e k l a t the mid form of eq 4 accentuates the time of onset from an imagined zero concentration as a shift parameter whereas the right hand form describes onset from concentration c 0 at time zero and allows for c 0 c desorption testing the standards referred to prefer nonlinear fitting of eq 4 to test data to obtain the value of the mass transfer coefficient k l a and potentially c s c implicitly understood in this work for complete mix systems this is referred to as exponential fitting ef below when applied to limited mix systems the exponential factor obtained by such fitting is termed apparent kla below a fairly homogeneous source distribution such as given by complete floor coverage diffused aeration can maintain the c 0 condition and is therefore understood as complete mix in the following asce commentary f 2007 state that limited mix reactors must be resolved by representative spatial sampling whereas cen 2003 and dwa 2007 state the test method to be invalid for such reactors these references accept closed loop reactors as complete mix systems while the latter two limit the applicability to da 0 25 for normal test precision and add some margin for da 0 25 the errors in these approaches are substantial and systematically negative as will be shown the value of c s varies with static pressure and thus the vertical coordinate while this dependence reinforces the importance of mixing for simplicity it is disregarded in the discussion about k l a estimation and is considered separately in section 5 the models introduced next illustrate the departure of the apparent from the true k l a value and of the do curve from eq 4 2 1 two zone models an insightful discussion based on a two zone aeration model by salzman and lakin 1978 demonstrates the effect of limited mixing their conclusions regarding mixing and k l a evaluation seem to have passed unnoticed although baillod and brown 1983 discussed a trivial case c 1 c 2 implying q the complete mix case of a similar model the latter possibly underlies the incorrect idea of using volume representative apparent i e based on eq 4 k l a values the other trivial limit q 0 reproduces eq 4 for zone 1 in isolation fonade et al 2001 also discussed the implications of a similar system the two zone model made slightly simpler and dimensionless here is illustrated in fig 1 gas liquid oxygen transfer takes place in zone 1 only which may include the free surface the terms zone 1 and zone 2 will henceforth be used for zones with and without such oxygen transfer respectively the aerated volume fraction is p and for continuous mixing the dimensionless inter zonal flow rate is q q k l a v oxygen transfer with the transfer coefficient 1 p is constantly active in zone 1 and each zone is complete mix reaeration curves satisfy eq 5 9 5 d c 1 d τ q p c 1 c 2 s 1 6 d c 2 d τ q 1 p c 1 c 2 s 2 7 c 1 0 c 2 0 0 8 s 1 1 p 1 c 1 9 s 2 0 salzman and lakin used 10 s 1 1 p 1 c 2 to describe the mass transfer driving force on a stream from zone 2 passing an aerator into zone 1 whereas in eq 8 the gas liquid mixture is considered to be in a pure zone 1 state the complete mix assumption per zone a source term reconciling the two views is given in appendix a the solution to eqs 5 9 is 11 c 1 τ 1 1 κ z m κ z a e κ z a τ κ z m 1 p e κ z m τ κ z a 1 p 12 c 2 τ 1 1 κ z m κ z a κ z m e κ z a τ κ z a e κ z m τ details of the solution are given in appendix a example curves and example apparent k l a values κ ef are shown in figs 2 and 3 respectively the fully intermixed curve q recovers eq 4 the exponential with an early slope 1 p of the c 1 curve is interrupted when the mixing rate κ zm scale begins to influence the curve the first three curves have κ ef values of 0 76 0 64 and 0 64 respectively as seen in fig 3 underestimate of the mass transfer κ ef 1 occurs for all non degenerate conditions except in zone 1 when the deviation from exponential behavior is apparent as in fig 2 the first three curves for zone 1 have several data with a poor fit δ 1 see eq 49 and visible systematic residuals all curve fits in zone 2 and the last in zone 1 have error norms δ 1 for q 5 both zones show the same values substantially short of 1 for low values of p the true value is recovered for all cases as p 1 as a numerical example consider the test data set m1 see section 6 3 and fig 19 the onset time shift between probes indicates q 3 to 4 or less because k l a is underestimated and the maximum time shift in the tank is greater than indicated by a few probes the value of p for the surface aerator is likely to be far less than 0 5 an underestimate of k l a by 10 30 is indicated by fig 3 to be compared with the analysis in section 6 3 an even simpler way of illustrating the issue with the apparent k l a is to replace the constant flow q with intermittent bursts of complete inter zonal mixing at the frequency q f formally using dirac s function 13 q n 1 δ τ n q f the reaeration data during mixing cycle n n 1 2 3 in the respective zone is 14 c 1 τ 1 e n 1 τ q p q n 1 κ z 15 c 2 τ 1 e n 1 κ z where the subscript has been dropped from q f to emphasize its role as a mixing rate and 16 κ z l o g 1 p 1 e 1 p q the volume average concentration is 17 c τ p c 1 τ 1 p c 2 τ 1 e n 1 κ z p e n 1 τ q p q 1 p an example of the curves given by 14 17 and exponential fits made between τ 0 and the mixing cycle reaching 98 saturation are shown in fig 4 with p 0 3 and q 1 apparent k l a factors in zones 1 and 2 are κ ef 1 2 24 and κ ef 2 0 29 while for c κ ef 0 37 is close to κ ζ 0 34 the average of the two zones values is 1 27 and the volume weighted average is 0 88 no reasonable combination of these comes acceptably close to 1 this example makes it clear that the accelerated saturation where aeration is concentrated reduces the mass transfer rate unless complete mixing is at hand thus individual apparent k l a values obtained for each zone average to less than the true global value and the average do curve shares this fate the volume average do curve was discussed by e g boyle et al 1989 as a means for correcting for mixing slowness and it may produce an exponential looking curve baillod et al 1986 refuted this idea considering the implications of incomplete mixing the curve for c displayed in fig 4 underlines the argument against it the apparent k l a value obtained using a volumetric average do curve eq 17 is shown for a variety of p q sets in fig 5 short of 1 for all non trivial cases an analysis of the average or equivalently total do evolution highlights the issue further with no reactor inlets or outlets the volume integral of eqs 2 and 3 is 18 dm dt m k l a c dv with a homogeneous k l a this simplifies to 19 dm dt m k l a m with a spatially uniform solution like eq 4 and same holds if c is homogeneous and k l a is interpreted as the true volume average inhomogeneous k l a and c invalidate eq 19 for instance for the two zone model the last term in eq 19 becomes k l a p m a where m a is the dissolved mass in the aerated volume only differing from m with the dissolved mass in the unaerated volume only with very rapid mixing can it be said that m a p m and the simple form 19 is recovered as made evident by the above models the signature of the correct mass transfer value is present in the slopes of the do curves at time t 0 volume weighted averaging of these values produces the global k l a value but an exact representativeness of the probe locations is required excerpts from a cfd model are used in section 2 3 to show that this cannot be achieved in practice a simple mechanism behind non standard do curves was described above deviation of the do curve from a perfect exponential saturation curve and even inflection can thus be explained by limited mixing of aerated and unaerated liquid see also talvy et al 2007 while dispersion leads to a smoothing of the early part of the curve see section 2 2 the effect of delayed sensor response is discussed in section 3 the presence of an inflection point in the do curve is ascribed by asce 2007 to the lingering of oxygen depletion chemicals whereas this inflection can also be weakened to a smoothing of the do curve 2 2 advection dispersion and aeration layout in loop reactors among the test standards and guidelines known to the author only stora 1980 referenced by stowa 2009 provides guidance on analysis of test results in limited mix reactors but only for mechanical point aeration in loop reactors limitations of their approach were identified by abusam et al 2001 and van bentem and de bruin 2009 both demonstrating improvement by a tanks in series approach taken further by nakamachi et al 2012 who used tracers to characterize advection and dispersion dudley 1995 proposed an advection model to analyze test data taken in process water stamou 1994 lesage et al 2003 and several others motivated the use of the axial dispersion model adm for oxidation ditches haouech 2012 while reviewing the upside of the adm over the tanks in series model in reproducing abundant real system data pointed out lab scale experiments on reaeration that have had very low da values and did not therefore require spatially resolved modelling as opposed to full scale systems full scale application of the adm to reaeration was demonstrated and analyzed by uby 2019 who further illuminated the long known relationship between the tanks in series model and the adm values of da q 1 have been seen to vary at least between 1 10 and 1 1 5 the adm is a one dimensional version of eqs 2 and 3 with a fixed constant velocity and for the present purpose a gas liquid mass transfer source term neglecting the dispersion term which includes molecular and turbulent diffusion and spatial dispersion allows for analytical solution of the model in a periodic domain and forms the basis for the stora 1980 approach see fig 6 whereas dudley 1995 used a numerical procedure and included a constant respiration term the stair stepping indicated in fig 6 is sometimes seen in loop reactor testing but strongly smoothed by dispersion see fig 8 and oxidation of residual sulfite sulfite may change the expected correlation between probes in different parts of the reactor while cen 2003 mention the importance of the da value to the effect of circulation the value of p and the detailed distribution of the mass transfer is equally important uby 2019 the effect of dispersion is also required to accurately capture the oxygen dynamics abusam et al 2001 van bentem and de bruin 2009 the effect of dispersion alone is illustrated by considering the dispersion of the advected oxygen along an advection line with the source term s in eq 2 replaced by the boundary condition that eq 4 holds at x 0 corresponding to an aerated complete mix reservoir feeding the line the numerical solution to this problem and exponential fits are shown in fig 7 however it is known that dispersion alone without advection would distort the initial linear part of the curve by the factor 1 x 2dt 1 2 8 π 1 2 x 2dt 1 2 1 as it penetrates the line dispersion thus causes onset to strongly precede the expected time the fits have systematic residuals even between 20 and 98 of saturation the κ ef values obtained at x 1 and x 2 are 0 90 and 0 81 respectively a high growth rate in the reservoir causing large gradients and a large diffusion coefficient enhance the effect of dispersion to reduce κ ef 2 3 complete 3 dimensional data cfd model the ultimate extension of the above models to high fidelity cfd is resource intensive but may be used occasionally to corroborate less expensive approaches the growing literature on cfd simulation of wastewater applications has recently been reviewed karpinska and bridgeman 2016 and is beyond the scope of this work however fayolle 2006 has reported oxidation ditch reaeration curves see below a fully 3 dimensional cfd model of a loop reactor with 56 million cells as opposed to two zones or a one dimensional model illustrates the impact of time scales in practically realizable flow eqs 2 and 3 embedded in the liquid phase with the higbie boussinesq mass transfer model known to produce realistic results e g talvy et al 2007 were applied to an eulerian disperse phase flow solution using cfd version 16 5 when modelling fully mixed tanks nitrogen transfer and the gas side depletion of oxygen has had a negligible influence on the reaeration curve for which reason these effects could be excluded although this model is well validated the important feature is the realistic representation of the flow air and oxygen distributions versus field testing cfd has the advantage that the local k l a is known everywhere in the tank fig 8 shows the do curve for the volume average and two of the 116 probes not physically modelled from around the whole loop reactor that were recorded during simulation exponential fitting gave k l a values of 5 21 5 95 h 1 8 20 short of the actual value 6 49 h 1 sotr being equivalent to dm dt at c 0 was evaluated initial slopes equal to local c s k l a and taken between 0 5 and 5 of saturation of 54 probe curves symmetrically located around the reactor average to 204 of the volumetric average the same product of the pointwise apparent values averages to 87 the slope for the first second of the volume average which leads to 0 18 of saturation only reaches 98 2 of the true product thus the representative volume can definitely not be relied on in practice fayolle 2006 similarly reports a 22 deficit of k l a in a cfd simulation of an annular loop reactor when using do curves as compared to obtaining the true volume average k l a value directly 2 4 mixing and the relevance of sotr the sotr concept focuses on the idealized transfer rate regardless of mixing and has only been intended for use in complete mix reactors in the activated sludge process typically differing from the test standard situation with oxygen consumption through flow and an increased effective viscosity the importance of mixing for bod biochemical oxygen demand and nutrient removal and for sludge characteristics is easy to imagine this importance was emphasized by fonade et al 2001 consider for instance a pre anoxic zone connected to a well mixed conventional aerobic reactor operating at a do of 2 g m3 with mixed liquor recirculation to the anoxic zone this can be described as a two zone system with q 0 1 aerobic sludge age and conversion of bod and ammonium increase if aeration is introduced in the first zone given the same load and oxygen transfer rate while on the other hand denitrification occurs in the normal case a more refined point is made by rehman et al 2017 who use cfd coupled with the activated sludge model asm1 to identify a number of important consequences of incomplete mixing for process control and evaluation the combined aeration and mixing performance affects overall process performance and the mixing time scale should be optimally related to residence and kinetic time scales present style sotr performance characterization for incompletely mixed reactors is unsuitable because the sotr concept is blind to mixing and kinetics and test practice hesitates between the sotr definition and incorrect application to limited mix reactors on the other hand the importance of improved mixing can be highlighted by an aeration test establishing whether insufficient gas liquid oxygen transfer or insufficient mixing is at hand is important to identify the most viable remedy for instance the zone of influence of surface aerators may be increased using draft tubes or added mixers whereas an increased aeration power or number of aerators would be required to increase the gas liquid transfer per se in oxidation ditches surface aerators are being supplemented by submersible mixers to achieve a stronger circulation and thus transport of oxygenated liquid bottom diffused aeration often relies completely on submersible mixers to achieve circulation and maximized oxygen transfer in oxidation ditches the impact of mixing as well as of oxygen transfer rate on process performance should be considered when selecting an aeration system mixing should even be separately specified for certain aeration reactors as is already commonplace for oxidation ditches 2 5 accounting for limited mixing the previous sections demonstrate the need to account for the effect of mixing on the distribution of dissolved oxygen do data is notoriously difficult to use for accurate mixing quantification the best strategy is to extend tests to capture mixing characteristics but devising a general mixing test method for an incomplete mix aeration tank remains a challenge three approaches to the mixing problem are discussed two of them by a detailed example 1 maintain the incorrect model eq 4 and account for the bias and uncertainty thus introduced e g for tapered aeration 2 apply a more appropriate model based on more extensive testing e g for tracer testing in loop reactors 3 extend testing and reinterpret the incorrect model the inert tracer technique an alternative test method based on do mass balance between liquid entering and leaving the aerated zone was attempted boyle et al 1989 however the need to capture detailed flow dispersion and do profiles with a high accuracy could not be met 2 5 1 tapered aeration tapered diffused aeration systems are usually designed for uniformly sized zones of gradually decreasing mass transfer coefficient along the reactor a compartmental model for several cells and several levels of k l a can be used to estimate the maximal impact of tapering on aeration test results knowing the uncertainty or bias introduced by tapering testing can often be carried out without the need to separate the zones with baffles and without abandoning eq 4 the successive transfer coefficient ratio r is usually between 0 50 and 1 00 i e the k l a value in one zone is some 50 100 of that in the preceding zone setting all values of r equal to the lowest value of a certain design produces a bounding case for a class of designs with regard to the applicability of eq 4 for instance a common 4 zone tapering has the r values 0 67 0 50 0 67 and another one has 0 75 0 84 1 00 the former is thus bounded by r 0 50 for all zones while the latter is bounded by r 0 75 reactors with 2 3 or 4 tapered zones were analyzed each zone was modelled as either 1 2 3 or 4 cells in series see fig 9 however this made a difference of at most 0 1 for the limiting values in the apparent k l a intuitively 1 or 2 cells per zone is reasonable the water flow rate between cells in neighboring zones was varied within 0 2 q 50 for each such flow the water flow a q between the successive cells within a zone was within 0 1 a 2 0 since water flow is orders of magnitude faster than gas liquid oxygen transfer in aeration tanks the upper values of q are the more representative for real tests and values of a of order 1 are realistic the small variability of results in this regime made extension to other flux values superfluous any flow of bubbles is assumed to increase the value of r toward 1 and is thus disregarded in the search for a conservative bound exponential fitting to eq 4 within 5 98 and 20 98 of saturation in all cells exhibits no substantial difference in the average κ ef between the two intervals the greatest variability was found for small values of a and q where up to 2 3 overshoot in κ ef was obtained with 4 zones in the opposite practically relevant regime variability was lower within each taper class and undershoot down to 6 0 was found for r 0 5 3 5 for r 0 60 and 1 2 for r 0 75 for 2 and 3 zone tapering undershoot was correspondingly smaller see fig 10 based on the three values of r linear interpolation of lower κ ef bounds versus 1 r appears accurate for all zone counts considered missing the point 1 1 by less than 0 5 thus sampling with do probes evenly distributed centrally in each taper zone and with a standard vertical distribution along a commonly tapered reactor under these conditions will not add more than 6 undershoot in k l a and no overshoot can be expected to the general uncertainty the insistence of dwa 2007 to locate at least two probes in each zone should secure data quality and redundance against probe failure the original two zone model r 0 reached an undershoot of about 20 when fitting 100 data points within 20 98 of saturation with p 1 2 and one cell per zone 2 5 2 tracer testing in loop reactors the combined effect of periodic circulation and dispersion as well as a complete testing methodology and data for bottom diffused aeration in loop reactors precursed by nakamachi et al 2012 and based on an extension of methods used for airlift loop reactors is presented in extenso in a separate paper uby 2019 in brief inert tracer testing is used to obtain velocity and dispersion characteristics while local velocity testing using e g adv technology is of limited value tracer data must be well resolved and online fluorometry and fluorescent tracers are more likely to be used today than exotic isotopes as by e g boyle et al 1989 the adm is then solved using these characteristics and fitted to do data which requires an accurate account of aeration and do probe layout typically 6 8 probes must be rather evenly distributed around the loop to capture the spatial resolution of the do concentration and any time shift of the onset while observing a standard vertical distribution while fitting of the exponential model takes seconds fitting of the adm can take minutes on a modern portable computer 2 5 3 inert tracer technique early work e g neal and tsivoglou 1974 presents a tracer method endorsed by asce 1996 claimed to account for mixing and compares it to the standard test it consists of seeding the test basin with a sample of water with a dissolved inert tracer originally 3h2o or t for tritium whereas licl and rhodamine wt have also been used and a dissolved tracer gas originally 85kr whereas stable kr or other gases have been used later aeration causes tracer gas desorption to the practically zero saturation level and the desorption curve normalized with the inert tracer concentration in test points is interpreted as a time exponential the ratio of k l a for krypton and oxygen was reported to be 0 83 and was subsequently reduced for submerged aeration on account of secondary effects the idea of accounting for the dispersion of the seeded gas by normalization with the inert tracer concentration can be analyzed using the two zone models with burst mixing and seeding in zone 1 after just one mixing cycle the liquid tracer is completely mixed but the inhomogeneity of gas liquid mass transfer remains and the liquid tracer no longer adds information though this effect is less pronounced in more realistic systems this model best explains the failure of the method the continuous two zone mixing model is also easily implemented with the two tracers using eqs 11 and 12 for each of the two species with s 1 0 for the liquid tracer using the ratio curve reduces the κ ef undershoot slightly for instance introducing this technique for p 0 2 and q 2 in zone 1 κ ef increases from 0 80 to 0 83 and in zone 2 it increases from 0 75 to 0 77 still leaving 17 and 23 undershoot respectively this must be considered a failure the similarity between the standard and the tracer method can be more precisely analyzed and stated as follows gas species oxygen or krypton transfer is described by eqs 2 and 3 with k l a being different between the two gases by just a constant factor and krypton having c s 0 the dispersion of an inert liquid tracer e g tritiated or normal water follows eq 2 and 20 s 0 for either method the ratio of gas to liquid tracer concentration evolves according to the same equation 21 r t u d r k l a c s c l t r 2 d ln c l t r the complexity of the source terms on the right hand side surpasses that of eq 3 when c lt is inhomogeneous due to for instance the initial conditions in which case the inert tracer model becomes different from the complete mix model and the exponential model eq 4 is clearly incorrect for the ratio r for incompletely mixed reactors as a more detailed example with the adm modified to accommodate the source terms in eq 21 exponential fitting to the function r shown in fig 11 yields 0 91 κ ef 0 93 converging toward 0 92 as less early data is used the curve obtained by direct division of the two tracer curves is indistinguishable from the solution r calculated from c t and eq 21 demonstrating the consistency of this equation fig 11 is based on estimated data for the opelika loop reactor in boyle et al 1989 where the application of a simple exponential fit was made to both a reaeration test and an inert tracer test with a point injection the adm and eq 21 both robustly indicate a k l a undershoot by 6 8 by the exponential fits with da 0 25 a similar systematic deviation between the exponential function and the tracer ratio can be divined in plots in boyle et al 1989 and in neal and tsivoglou 1974 though their use of a lin log plot naturally reduces the impression more importantly k l a underestimates of up to 32 were observed for certain probes and early truncations when da 0 56 in a test where p 0 075 uby 2019 and for most locations and truncations the underestimate remained between 10 and 20 an alternative view of the inert tracer technique is that it assumes that a solution to eqs 2 and 20 becomes a solution to eqs 2 and 3 just by multiplication with a time exponential even with c s 0 this can only be fulfilled for a very special k l a distribution principally the standard and the inert tracer methods differ in the effective k l a value the dissolved gas saturation value and the initial conditions only the initial condition for the inert tracer normal water is trivial for the oxygen water system clt 1 and clt 0 whereas the seed is localized in the tritium krypton tests if a submerged aeration system were operated with pure nitrogen or with air and seeding were made with oxygen supersaturated tritiated water the similarity of the test to a standard desorption test with nitrogen or even air coming through the aerators would be even more striking thus in complete mix reactors the two approaches are trivially equivalent and the exponential decay model can be applied to the inert tracer method only under the same assumptions as in the standard method the errors in limited mix systems are of the same order of magnitude 3 effect of linear probe response 3 1 rationale the linear probe response time in terms of τ p t p k l a is required not to exceed 0 02 asce 2007 or 0 05 cen 2003 in order to avoid an undesired influence on the shape of the do curve and thus a confusion of time scales to reduce the confusion caused by probe lag truncation of do data for values below 20 asce 2007 raising the τ p limit to 0 05 or 25 cen 2003 of saturation is allowed philichi and stenstrom 1989 this can also be helpful in filtering the influence of unreacted sulfite see section 4 common probe response times of 10 30 s are to be compared with oxygen transfer times ranging over the orders of hundreds to thousands of seconds thus for very high rate systems the above requirements can impose restrictions on the probe selection however the importance of understanding mixing limitations as discussed in section 2 raises the need for a qualitative understanding of the effect of probe lag on data signals affected by a mixing time scale for instance one might want to test a spatially resolved model for the do data as a simple application the two zone model can be attempted its relation to the lagged version of eq 4 is discussed below if the presence of sulfite is not an issue and probe lag effects are known important qualitative information about mixing can be obtained in particular if including early do data in the analysis see section 6 3 linear probe response formulae are presented the lagged reaeration function appears repeatedly in the literature starting perhaps with mueller et al 1967 and has occasionally been overlooked but a simple analytical derivation of the lag formula and its repeated application and interpretation is given here for the benefit of loop reactor testing probe lag effects on tracer recirculation curves are also discussed the analytical method applied here promotes intuitive understanding and computational ease while being easily extended to other models 3 2 linear probe response equations the first order lag transform that often relates the output of optical and electrochemical probes to the ambient concentration via the probe lag time t p k p 1 has been validated for a number of probes the first order lag equations are 22 d c p d t k p c t c p t 23 c p t 1 c p 1 24 c t 1 c 1 eq 22 is multiplied with the integrating factor exp k p t and then simply integrated to give c p t for t t 1 as 25 c p t e k p t c p 1 e k p t 1 k p t 1 t e k p t c t d t slightly differently phrased by mueller et al 1967 it is instructive to consider some special cases of eqs 23 25 setting t 1 0 for convenience and c t 0 for t 0 these are given in table 2 and discussed in the following subsections 3 2 1 lagging of a step change the exponential decay c p 1 c 0 e k p t of an initial discrepancy c p 0 c 0 known as a step change if c t is kept fix is always of this form and is therefore noted in the head of table 2 asce 2007 encourage a step test to confirm the probe lag characteristics fig 12 shows the result of moving a fluorometer between containers with clean water and water with rhodamine wt fahlgren 2016 the nonlinear fits solid and dashed to the exponential decay give t p 11 9 s in both directions and linearity is confirmed by the excellent fit water temperature was between 16 6 and 16 9 c the inset of fig 12 shows lin log representations of the exponentials revealing truncation and poor fit near equilibrium however deviations are small in the lower part and including these noisy parts only changes t p by 0 4 and 0 2 respectively the influence of fluctuating data and probe precision is discussed in section 6 3 the step change response may also be seen as an exponential decay of the initial signal c p superposed on the exponential growth to the ambient value of c 0 from 0 both views are equally valid on account of the linearity of the lag transform the complication of an initial state c p1 c 1 is avoided by probe equilibration in a constant c c 0 environment for the duration of a certain multiple n of t p for instance only 2 of the initial discrepancy remains with n 3 9 equilibration of do probes in desorption testing requires supplying a balanced air oxygen mixture producing the desired saturation level sometimes t p is called t 63 because in this time a gap is reduced by 63 2 some sensor suppliers share values of e g t 90 but for any value of γ the linear response value of t p can be deduced using 36 t p t γ ln 1 γ 100 3 2 2 lagging of linear quadratic and exponential signals the linear signal clearly gets a time shift t p combined with a catch up term responding to the abrupt acceleration at t 0 eq 26 this combination is seen for signals with limited growth in general for the quadratic signal eq 27 the probe only catches up to within the time shift t p and a constant shift in c as time grows for faster signal growth the c shift increases until for exponential growth the catch up term is combined with a constant amplitude reduction factor eq 29 for τ p 1 this factor comes close to exp τ p which again signifies a time shift by t p for exponential decay eq 30 the catch up term and the reduction factor are the same as for the exponential growth but accounting for the sign of the exponential it is concluded that linearly lagged data of an exponential signal retains the growth rate k of the original signal after the catch up phase which takes a few times τ p after onset the respective shift and scaling due to probe lag can thus be comfortably identified and the exponential catch up terms to both step changes and abrupt accelerations appear similar for most situations 3 2 3 lagging of periodic signals the sinus understanding of the lagged sinus signal eq 28 facilitates the analysis of a non sinusoidal disperse pulse train below the exponential catch up term is again easy to identify the amplitude of fast oscillations i e for τ p 1 is damped by lag but up to τ p 0 045 only 0 1 is lost the underlying frequency is conserved with just a phase lag to the signal this conservation is expected since eq 22 forces c p to turn when the ambient data crosses the probe data in the opposite direction the phase lag increases from 0 at no lag to maximum π 2 90 for very strong lag 3 2 4 lagging of reaeration curves the probe appears as an unaerated zone with first order dynamics and k k l a and the correspondence between eqs 12 and 31 by k κ za k p κ zm is perfect with c s 1 and c 0 0 to match the setup of the dimensionless model the interpretation of the probe as a zone 2 with p 1 makes sense in the light of this observation the reaeration curve is a linear combination of a constant and an exponential which enables adoption of their respective lag properties given above in particular lag causes a catch up phase and a time shift t p and the growth rate k is conserved the factor cs c0 is noticeably augmented even for small values of τ p affecting the fitted c 0 value based on the lagged do time series negative c0 values may thus occur low end truncation of data reduces the magnitude of the lagged signal deviation from the shifted original signal for instance if τ p 0 05 truncation of all data below c 0 1 i e 10 of the concentration range keeps pointwise do data error due to lag below 0 5 of the range while truncation at c 0 15 keeps the error below 0 1 asce 2007 and cen 2003 guidelines that τ p 0 05 for truncation at c 0 20 and 0 25 respectively correspond to a maximum point error of less than 0 1 more importantly the error in fitted oxygen transfer parameters is kept under control see fig 13 fits can be improved using a high data density but for real data the influence of fluctuations is generally more important see also section 6 3 the effect of probe lag on eq 4 is thus mainly a shift by the lag time except for 37 t t 0 n t p with n safely taken between 2 and 4 and equal to 1 for practical purposes eq 31 may be fitted to data truncated earlier fitting of test data to the non normalized version of eq 31 provides the mass transfer coefficient k l a and the saturation value c s along with the initial concentration c 0 or time shift t 0 and probe datum c p1 but the value of τ p must and can be ascertained independently otherwise the lag cannot be separated from the effect of limited tank mixing the difference between a fitted value of τ p and the true lag is a mixing delay time scale see section 6 3 1 2 with complete mixing and a known value of τ p fitting of lagged exponential data with a small gaussian noise 0 5 superposed is summarized for a range of τ p values in fig 13 the decline in fitting quality seen for moderate to small values of τ p was noted by philichi and stenstrom 1989 but can be thus avoided for both k l a and c s constraints additional to eq 37 must be put on the data as the noise grows see section 6 3 1 it is straightforward to calculate the effect of probe lag in zone 1 of the two zone model eq 11 the influence of lag on the oxygen transfer like term and on the mixing like term respectively is quite similar with the respective exponential terms being reduced by a lag term like a zone 2 eq 12 the increase in the number of parameters causes degeneracy and does not improve the fit when τ p κ zm 1 3 2 5 lagging of tracer pulses and pulse trains the mathematically ideal delta pulse causes an immediate response because of the infinite amplitude and then the usual exponential decay follows based on the probe lag time eq 32 the response amplitude is limited by the probe lag time in a situation where a known pulse mass passes the response peak amplitude thus contains information about the probe lag time this ideal pulse response behavior translates in part to the dispersed pulse the general lag form of the universal dispersed pulse eq 33 has the two special cases eqs 34 and 35 which are computationally less demanding the lagged behavior is shown in fig 14 the close fit of the lagged pulse to an unlagged pulse is also demonstrated eqs 33 35 satisfy the same axial dispersion equation and thus conservation laws as the original pulse but with appropriate shifts in bo k x and amplitude hence incorrect fits to test data of e g bo may arise due to probe lag this need not be if the origin in time and space of a perfect pulse is known but usually an injected imperfect pulse develops to the universal form and the virtual origin must also be found by fitting by fitting lagged data of the same pulse recurring periodically as in a loop reactor to a train of unlagged pulses the shift in bo and pulse frequency k caused by the lag τ p is suppressed cf the lagged sinus in section 3 2 3 the peaks of the lagged signal approach a rigid time shift t p as time grows leaving fitted values of f and bo increasingly accurate for instance fitting the collection of the third to fourth peak lagged pulses to an unlagged pulse train shows that the fitted values of bo are less than 0 3 short of the true values when kτ p 0 16 and 25 bo 95 while the fitted values of f are less than 0 03 short the errors are a factor 10 smaller for kτ p 0 08 for 10 bo 20 the error in bo value can reach 4 and in f value 2 see fig 15 moderate probe lag should thus not present a problem to accurately determining advection and dispersion data for loop reactors uby 2019 4 impact of sulfite and cobalt chemistry depletion of the dissolved oxygen as a final preparation of the thoroughly aerated test water is done by either sparging nitrogen gas through the aeration system or by dissolving stoichiometric amounts with some excess of sodium bisulfite while the nitrogen method is more popular in laboratory work and appears more reliable and environmentally friendly it requires gas flasks or a pressure vessel perhaps a trailer and some connection work on the air mains if unpressurized mechanical aeration is tested a temporary sparging system must be provided using the sulfite method a small amount 0 1 0 5 g m3 asce 2007 of cobalt must already be dissolved and well mixed to catalyze the sulfite oxidation the dissolved mass of oxygen is usually in the range of 10 14 g m3 and stoichiometrically it requires 2 126 32 7 88 times as much about 100 g m3 sodium bisulfite plus excess to cater for the oxygen transfer still occurring during the final water preparation and do probe equilibration if an extended time of mixing is required and mixing is in part or wholly done by aeration the amount of sulfite required for maintaining the do depression throughout the volume during this phase can be a few times 100 g m3 thus tons of salt can be required for a single test in larger tanks notably large oxidation ditches asce 2007 mention stripping of oxygen by nitrogen gas as a reference method for small scale tests to check the sulfite quality and probe zero setting and the pure oxygen based desorption method wagner et al 1998 in a commentary as being further evaluated cen 2003 affirm the use of any of the mentioned methods while dwa 2007 even provide guidelines for calculating the required nitrogen and oxygen masses while the interchangeability of these methods is briefly considered in section 6 1 an issue with the sulfite method is addressed here the sulfite method thus remains popular in particular where the asce guidelines are in use though its chemistry is not completely understood for instance numerous observations of insufficient deoxygenation by the first sulfite batch in repeat test water e g naimie and nelson 1978 paulson 1983 underlie the recommendation to use the first test as a system stability check and only conditionally use it for compliance evaluation unwanted effects may also occur when testing at low water temperature test water even in thousands of cubic metres comes as is sometimes cold the caveat of asce 2007 that sulfite may not be quickly oxidized under about 10 c needs to be supplemented with clear guidelines for how to avoid the lingering sulfite issue which results in smeared and slowed re oxygenation data field observations of maximum practically constant do reduction rates for near instant sulfite dumping of the order of 10 2 10 1 cs s and for slow sulfite pouring in loop reactors at correspondingly lower rates e g 10 3 cs s most often exceed the oxygen transfer rates by far see section 3 1 with higher order oxidation kinetics at the lower temperatures and as do and sulfite concentrations decrease a loss of oxidation rate by orders of magnitude can cause dire interference between the two time scales sulfite oxidation kinetics research was reviewed by linek and vacek 1981 and was considered by early contributors to the asce standard see reviews by e g naimie and nelson 1978 and paulson 1983 disagreement was observed regarding the wanted and unwanted effects of cobalt under different conditions it remains that reaction order and reaction speed varies with the dissolved concentration and heterogeneous availability of oxygen and sulfite and with temperature ph and catalyst type and concentration observation of incomplete oxidation can be made by monitoring ph which rises temporarily during dissolution of sulfite and drops back with the formation of sulfate conductivity can be used to monitor the dissolution process if required but quantitative conclusions on oxidation are not necessarily obtained if the oxygen transfer rate is well known a sulfite mass balance can be made but such an a posteriori analysis does not address the measurement accuracy issue a maximum cobalt dose was stipulated in order to avoid the interference with the winkler test that is observed for ph 6 7 and loss of cobalt to complex formation should be detected by testing the cobalt concentration for each aeration test there does not seem to be conclusive evidence that this covers all common situations it is proposed that the use of the sulfite method be strictly limited to water temperatures above 10 c or that the effect of an increase in cobalt concentration is examined in order to accelerate the oxidation of the sulfite at low temperature with tracer testing for loop reactors a deeper understanding of the interaction between cobalt sulfite and fluorescent dye tracers such as rhodamine wt and uranine is also required it was observed that at 18 1 c the addition of up to 100 ppb of rhodamine wt did not affect oxygen absorption characteristics mass transfer coefficient and saturation value after using 0 55 g m3 of cobalt and 300 g m3 of sodium sulfite to deplete the oxygen however cobalt absorption by amines could play a role at lower cobalt concentrations while rhodamine could be partially quenched by cobalt a brief interruption of the sulfite oxidation was observed as a concentrated cloud of rhodamine wt passed do probes uby 2019 conversely the addition of 300 g m3 of sodium sulfite was seen to reduce a rhodamine wt reading from 73 to 53 ppb at the same pace as conductivity rose due to the addition fahlgren 2016 rhodamine loses some fluorescence intensity when ph 5 or ph 9 and at high salinity leibundgut et al 2009 which could explain the latter observation chlorine and oxygen highly supersaturated or ozone may also reduce the intensity performing the tracer test after all sulfite has been oxidized but during a reaeration data uptake could thus yield uncorrupted oxygen transfer and mixing data uby 2019 5 saturation value 5 1 the effective depth for the value of cs the global reactor average value of the oxygen saturation concentration has a direct influence on the test result the oxygen saturation equilibrium concentration is proportional to the static pressure according to henry s law which has been used as an argument for selecting the half depth value of ζ 50 for submerged aeration this is at variance with extensive testing experience that indicates a smaller effective depth e g brown 1978 which can still today only be obtained by testing baillod et al 1986 found ζ 21 44 for fine bubble diffused aeration ζ 26 34 for coarse bubble diffused aeration and ζ 5 7 for low speed surface aeration gillot et al 2005 observed ζ 33 based on numerous absorption tests with dissolved oxygen do probes at mid lower and upper depths asce 2007 stipulate volumetrically and depth wise representative sampling as the only method of arriving at the global saturation value further supported by jiang and stenstrom 2012 cen 2003 propose ζ 50 for a theoretical calculation of the saturation concentration to avoid the need for accurate do probe calibration if agreed between the parties concerned while referring to this dwa 2007 put forward 40 ζ 50 unless depth is greater than 7 m for which ζ 33 is stated for 6 m diffuser submergence assuming ζ 50 where ζ 33 would be detected by testing an overestimate of sotr by 8 results a considerable bias the empirical approach appears to be the only reasonable way to obtaining the global saturation value or equivalently the effective submergence the effects of liquid mixing at a rate considerably faster than the oxygen transfer time scale and to a lesser extent nitrogen transfer bubble diameter dynamics and free surface oxygen exchange should be harnessed to reconcile theoretical argument with the observed data when vertical mixing of liquid occurs at a faster time scale typically 101 s than oxygen transfer typically 102 103 s henry s law is dominated by mixing and the concept of a well defined local saturation value must be replaced by the empirical terminal concentration 5 2 correction from site to standard conditions of cs test standards refer to a standard ambient pressure close to p st and the standard surface saturation value c s st is fixed the ambient barometric pressure p a and the ratio of the global saturation value to the quiescent surface saturation value can be used for the calculation of the standard saturation value and subsequently sotr should this be preferred in summary the probe calibration procedure given by asce 2007 annex d item 2 2 2 is extended to account for the effective mixed water depth and water content after do curves have been recorded from the installed probes at representative depths put the probes in a clean bucket with enough test water say 5 cm depth to continue measuring the do conserve the temperature of the test water by keeping the bucket in a larger bucket with test water or in the reactor stir the small bucket water until each probe reaches an equilibrium corresponding to its onsite surface do saturation value ca in the test water the normalized effective depth and the standard saturation value are 38 ζ c s c a 1 p a ρ θ g z 39 c s c s s t ρ 20 g ζ z p s t p s t c s s t c s c a 1 p a p s t ρ 20 ρ θ 1 c s s t c s c a 1 p a p s t 1 the density ratio in eq 39 equals 1 to within less than a third of a percent between 0 and 30 c the absolute density effect of permitted amounts of sodium sulfite 2000 g m3 on water is also less thus ρ20 ρθ 1000 kg m3 can be used for quick calculations the procedure should be repeated after each do curve capture but has the advantage that effects of temperature and water content on cs are eliminated without correlations relying on empirical data narrow parameter intervals etc 6 uncertainty estimates on oxygen transfer capacity and efficiency uncertainty analysis repeat testing and test method benchmarking should be revisited to establish a sound basis for documented uncertainty in test results in particular for each test an uncertainty budget should be reported this includes values or best estimates of all base data uncertainties and estimates of the uncertainty of the end result if repeat test variability is greater than single test uncertainty causes for this must be sought 6 1 is the clean water test method correct benchmarking between the standard desorption or absorption and inert tracer test method cannot corroborate either method because of their commonality see section 2 5 3 though it can be argued that they are both correct in the complete mix case and only then see section 2 the off gas test based on measuring the residual oxygen in air leaving a reactor with diffused aeration qualifies as independent it finds its easiest application when constant oxygen consumption secures stationary conditions lab or pilot scale fermenter testing using a mass balance of a constant feed of for instance na2so3 and air or o2 shows a very strong agreement between this method and the re equilibration method under certain conditions where for instance gas side depletion of oxygen is avoided linek et al 1989 attempts at comparing the off gas method with re equilibration methods reaeration after aeration shutdown or step change or desorption after supersaturation using h2o2 in full scale have met with difficulties in maintaining a constant oxygen uptake under process conditions stability of and agreement within 10 between the off gas and h2o2 methods were noted by capela et al 2004 mueller and boyle 1988 noted a similar scatter between these methods including the tracer method among the cen and dwa standard test methods no result dependence on initial conditions supersaturation or depletion of oxygen and nitrogen has been detected wagner 1991 but a rigorous uncertainty analysis is lacking this has been fully accepted in german and european practice dwa 2007 cen 2003 gas side depletion of oxygen from air bubbles has been shown to be a minor concern under common conditions baillod and brown 1983 jiang and stenstrom 2012 corroborating this approach in the interest of standardization and uncertainty quantification the difference should be quantified though experience speaks for at most a minor impact the above benchmarks are assumed in the following to justify the principle of the standard test method in the sense that when correctly applied see sections 2 and 3 it is able to yield a true quantity value as an average of many replicate tests 6 2 uncertainty budget cen 2003 state that the accuracy sotr and precision sae and specific sote is typically within 5 8 and 10 respectively with 5 percentage points added for variation due to sulfite distribution issues for large 3000 m3 rectangular tanks referring to the 1992 edition of asce 2007 and for loop reactors with da 0 25 in tanks with a homogeneous diffuser distribution only local k l a values within 5 of the average are kept dwa 2007 simply relay the former using the term measurement uncertainty asce 2007 give data acceptance criteria in terms of maximum 10 spatial variability and within 15 pointwise reproducibility for kla and refer to baillod et al 1986 who report 5 spatial variability of kla in a part of a study with 2 5 replicate tests in 7 different tanks the exception 15 was seen in a circular 3240 m3 tank with four low speed surface aerators and 5 54 m water depth it is noteworthy that asce 2007 claim applicability to limited mix tanks and require volume representative sampling and an increased number of probes if failing the spatial homogeneity criterion none of these standards requires an uncertainty estimate sotr acceptance criteria are given by dwa 2007 and asce 2007 the former states that the mean of repeat results plus the measurement uncertainty must meet or exceed the specified value the latter requires that the mean of at least three repeat results and the upper two thirds of the repeat results meet or exceed the specified value with no provision for tolerance assuming a normally distributed experimental scatter around the true quantity value with a standard deviation σ converging monte carlo simulations using 102 through 106 triplets show that the asce criteria shift the probability distribution for a pass by 0 13 σ from the specified value and to a standard deviation of 0 61 σ thus 58 of all test triplets obtained on an exactly compliant aeration system will fail and an aeration supplier is wise to oversize the system with 1 13 σ to pass the test with 95 confidence design uncertainty can be included in σ by summation of variances the generally accepted uncertainty quantification methodology jcgm 200 2012 is adopted here and the validity of the central limit theorem is not questioned for instance the confidence level coverage probability is 95 that the mean of an infinitely extended and perfected measurement series would result within 2 0 times the standard error or standard deviation of the mean equal to σ n of the mean of a statistical dataset if the set contains at least 60 data for instance fluctuations around the terminal do concentration can be quantified this way and monte carlo simulations are interpreted in similar terms instrument accuracy for a single measurement can be interpreted as 2 standard errors based on a sufficient calibration dataset this permits summation of variances to reduce the influence of random and systematic effects to a single uncertainty statement and carries over to data of less apparently statistical nature such as the geometric measurement of the liquid volume the linear dependence of uncertainty on base data uncertainty is recalled here jcgm 100 2008 assume any measurement datum c i is obtained with some relatively small uncertainty δc i set equal to two standard errors or according to best judgement the uncertainty in a derived quantity f c i is then 40 δ f i d f d c i δ c i and for several statistically independent parameters the variances accumulate 41 δ f i δ c i 2 d f d c i 2 considering the special case when f is just a product of parameters relative errors can be directly collected 42 δ f f δ l n f i δ c i c i 2 this holds true for eq 1 the uncertainty in sotr is thus 43 δ s o t r s o t r δ v v 2 δ k l a k l a 2 δ c s c s 2 the three factors in eq 1 have the following uncertainties application of eq 41 to the conventional assumed exact temperature correction of k l a 44 k l a 20 k l a θ 1 024 20 θ gives 45 δ k l a 20 δ k l a θ 1 024 20 θ 2 δ θ l n 1 024 k l a θ 2 where temperature uncertainty is composed of instrument uncertainty and test variability the uncertainty of the saturation concentration based on eq 39 with the fixed density ratio is 46 δ c s c s s t c s c a p a p s t δ c s c s 2 δ c a c a 2 1 c a c s 2 δ p a p a 2 the liquid volume value v directly influences the sotr value and must be as diligently handled as any other aspect of aeration testing a full calculation and uncertainty estimate based on the above principles should be performed with due attention paid to any object reducing the liquid volume for a given liquid height it has also been proposed to replace the geometric method with a tracer dilution test as an example of a geometric liquid volume uncertainty calculation assume a rectangular basin and filling depth with dimensions l w h eq 43 based on v l w h yields 47 δ v v δ l l 2 δ w w 2 δ h h 2 for sote sotr c g o2 q a 48 δ s o t e s o t e δ s o t r s o t r 2 δ c g o 2 c g o 2 2 δ q a q a 2 assuming that the composition of air c g o2 kg o2 nm3 is well defined its uncertainty term in eq 48 is omitted in practice the uncertainty of the air flow rate q a is a major concern in aeration testing and must be carefully estimated 6 3 uncertainty of parameters fitted to time series the uncertainty relations given in section 6 2 depend heavily on the uncertainties δ k l a and δ c s sampling control and estimation of these values using the monte carlo technique is addressed next which is also applied to tracer pulse train data the test data set m1 obtained on 2013 08 20 using the asce 2007 method and ysi model 58 do probes with thin membranes is used to illustrate these considerations it was taken with three up pumping surface aerators operating in a tank 43 1 m 15 5 m 3 85 m liquid height with seven probes distributed along the tank diagonal at one end there were small openings allowing the tank to communicate with an anoxic zone however the influence of this was not considered to be important at the time of testing the disagreement between a test data set c i and a model fit c t i is quantified as the relative root mean square error 49 δ 100 i c i c t i 2 i c i 2 100 1 r 2 where r 2 is the coefficient of correlation while this measure is typically dependent on the number of noisy data included and is unsuitable for data spanning several orders of magnitude it suffices as a measure of goodness of fit for this work as a prefix δ denotes the bias shift in an entity 6 3 1 reaeration data uncertainty 6 3 1 1 data range and density besides the importance of fitting test data to the correct model the range and density of test data must be chosen to resolve important curve features while addressed already e g brown 1978 this point merits further discussion in the light of uncertainties discussed in this work whereas asce 2007 propose fitting between 20 and 98 of saturation for absorption tests cen 2003 propose a lower data limit of at most 25 in the presence of an inflexion point the former permit an increase of the lower limit by a factor 1 5 to at most 30 asce 2007 require a time non uniform sampling if fewer than 21 data are taken dwa and cen require at least 30 explicitly or even 36 data cen as 3 5 times 10 intervals a summary of the ranges for nonlinear fitting is given in fig 16 it can even be motivated to use different data subsets and different models for different parameters in reasonably well mixed tanks for instance the late part of the reaeration curve is likely to follow the shape of eq 4 albeit with an exponential factor differing from the true k l a this provides the terminal value c using a simple fitting procedure while reducing the number of parameters to be fitted to a more complex model for the early part or the whole of the curve when applying an apparently incorrect model for want of better valid partial results may similarly be obtained the dependence of the exponential fit on the precise selection of fitting data is illustrated in figs 17 and 18 in fig 17 the low end truncation varies from 1 to 90 of saturation the normalized product c s k l a ef is shown but the major part of the variation stems from variation in κ ef the early variation is due to slow uptake and then variation is caused by the system departure from the ideal exponential model approaching saturation variation is instead mainly caused by fluctuations as illustrated by the exponential model with a normal 0 25 noise imposed this level was selected to mimic the fluctuations of the probe data see inset the variation of the incorrectly inferred transfer rate spans about two times 7 whereas a total sotr uncertainty of 5 is tolerated by dwa 2007 the inadequacy of the exponential model to fit the data manifests itself but the actual transfer rate remains unknown the common use of fast online do probes rather than taking bottled samples enables a high data capture rate in fig 18 the data density varies by keeping data at different strides but is always extended at a constant time rate between 20 and 98 of saturation for low data density asce 2007 requires a different distribution see fig 16 figs 17 and 18 imply that a large data density is required to reduce the uncertainty in e g sotr and that the effect of fluctuations must be avoided or quantified the data density may be reduced if data adhere closely to the selected model which requires the correct model to be applied and fluctuations to be small with present day do probes a data density of say 200 points between 5 and 98 of saturation should be feasible and should cover the need to keep errors down for most cases 6 3 1 2 fluctuation and lag effects the impact of the uncertainty of the individual do readings is hard to deduce when the values of k l a and c s are obtained by nonlinear regression assuming probe timing to be very accurate uncertainty in the do readings must be addressed the probe may have a stated uncertainty such as 1 of the measurement interval or maximum value and fluctuations may be present around the terminal concentration or curve end with some variance summation of variances translates these to some value of δc i c s using monte carlo simulation press et al 1992 jcgm 101 2008 the impact of this uncertainty on the uncertainty of the fitted parameters can be found do data sets corresponding to do curves were generated with different data density and random normal reading fluctuation superposed on the model statistics of nonlinear parameter fits were collected and summarized in simple correlations for eq 4 convergence in uncertainty to within 0 5 was found using 1000 data sets uncertainties for moderate σ 4 do reading uncertainties obtained using 1000 data sets turn out to be practically proportional to the reading standard error 50 δ k l a k l a 9 0 n 0 46 δ c i c s 51 δ c s c s 2 4 n 0 48 δ c i c s note that δc a should be estimated in a manner similar to δc s with a fixed moderate probe lag τ p 0 30 the same expressions hold for fitting to eq 31 the data range of 5 98 of saturation for absorption tests was used as well as 195 102 for desorption tests with 20 n 300 data separated in time by much less than t p may be regarded as independent when lag is included in the model or when lag mainly imposes a time shift if the value of t p must be fitted to account for delays due to e g mixing eq 31 may be used with success if eq 37 and 52 k l at p 10 δc i c s are fulfilled the former condition requires truncation taken here at 5 of saturation to keep probe lag catch up effects and the latter appeared empirically as a numerical condition for fluctuations not to quench the effect of lag applying these conditions to the same uncertainties but to a wider lag interval 0 30 τ p 0 90 adds further complexity for instance the fitted values may experience a mean shift in addition to the propagated uncertainty application of the monte carlo approach to the data for probe 1 of dataset m1 see inset of fig 17 is given here with a data summary in table 3 the fitted parameters obtained for eqs 4 and 31 columns 2 and 3 differ somewhat assuming an instrument uncertainty δc c s equal to 1 of the terminal concentration this should be 1 of the instrument range maximum and collecting the standard deviation given by fluctuations of the last 60 data points column 4 out of 446 points in total between 1 and 98 of saturation the root sum square of these values column 5 is used for monte carlo simulation more than 60 data points is often available at the flat part of the curve ensembles of 1000 and 1500 data series were produced using the data for eq 31 while eqs 50 51 were used for the exponential fit there was no significant difference in the result of the two ensemble sizes uncertainties obtained as statistics of fits of the parameters to these series in c s k l a and their product are given in columns 6 7 and 8 eq 4 has a final uncertainty column 8 of 0 6 but the inappropriateness of this model was not accounted for in the analysis the scatter in time of onset see fig 19 and in k l a values between the probes between 9 74 and 10 77 h 1 and the large misfit column 10 remain indicators of caution the end result of eq 31 has an uncertainty of 0 8 though with a smaller misfit than for eq 4 while eq 31 is not proven correct it better accounts for the slow mixing the fitted τ p is 3 times the real probe response time and the range of times of onset of the seven probes is 2 times the fitted value of τ p see fig 19 the model does not in detail explain the scatter in onset between the probes and it exhibits a large scatter in k l a between 10 10 and 13 14 h 1 conditions 37 and 52 were not fulfilled when data was cut off at 5 of saturation which illustrates a common dilemma mixing characterization by do curves alone is not very accurate dataset m1 was fitted to the exponential model with and without lag and for different data intervals from 1 5 and 20 to 98 of saturation see table 4 using more fitting parameters naturally produces a smaller misfit but the identified mixing time scale 2 5 min apparently plays an important role while keeping the lag to 0 or 13 s results remain fairly constant but introducing the mixing time scale k l a and sotr come out some 15 higher truncation made a greater impact when fitting t p as expected for three probes eq 37 had n between 5 and 10 when truncating at 20 and two probes were between 4 and 5 when truncating at 5 making the fit overdetermined discarding these brings the c s k l a product to 136 and 132 g m3 h respectively and the mixing time increases to about 200 s eq 52 was violated by three probes including probe 1 see above when truncating at 5 and one probe each for the other truncations causing a slight increase in the uncertainty whether lingering sodium sulfite influences the curves or not decaying oscillation of the residuals to either model and shifts in onset indicate a recirculation dispersion model is suitable an adequate definition potentially aided by cfd simulation and fitting of such a model for similar surface aerator systems remains to be done most likely a mixing test is required to enable accurate model settings 6 3 2 tracer pulse train data uncertainty for mixing characterization in loop reactors the recurring tracer pulse solution based on the lag free version of eq 33 voncken 1966 requires an uncertainty estimate as in the case of probe lag parameter space is hard to cover in a single figure but the following exercise can be repeated with a focus on the parameter range of each practical case ensembles of 700 data sets ensuring less than 0 5 variation in the resulting uncertainties of bo and f with 50 n 1000 data points per set were generated for 25 bo 95 and gaussian distributed data uncertainty up to σ 4 of the terminal concentration the complete third and fourth tracer pulses of the pulse train delimited by minima were fitted to the ideal pulse train equation with fewer than 200 data points large uncertainties occurred in particular for bo 25 the monotonic dependence of uncertainty on the number of data and bo value is shown in table 5 it should be noted that a shift δbo in the fitted bodenstein number is observed in addition to the uncertainties with 1000 data points at bo 95 the shift has practically vanished and the relative uncertainty in bo and f are reduced to fractions of δc c for this case the relative uncertainty in f is at most 0 029 times the relative uncertainty of c which is the maximum 4 the difference when moving from 2 to 4 base data uncertainty is striking for low values of bo the strong impact of the number of data points is expected but the pulse sharpness is another crucial factor this is reinforced by fig 20 where bo uncertainty is shown versus the two factors for a base data uncertainty of 1 and 2 the values in table 5 give guidance to the number of data points to use the common rate for many probes is 1 s and should be used to secure hundreds of points the probe uncertainty must be small and fluctuations observed during the constant phase before or after the pulse train should be quantified as for the do probes 7 conclusions the asce 2007 test standard appears intended to secure verification of an sotr value without a negative tolerance and most likely succeeds in this even for limited mix and loop reactors but at times with margins counted in tens of per cents the cen 2003 and dwa 2007 test standards on the other hand strive toward accuracy a low uncertainty in the measured sotr and at present abstain from including limited mix reactors except loop reactors the confusion arising when applying the former standard to such reactors while seeking a high accuracy as intended by the latter two for instance to avoid systematic over investment and subsequent operation at lower than intended efficiency could be partly resolved by observing the following and working toward a development of the present standards in the indicated directions 1 for limited mix aeration reactors 1 1 existing clean water test standard analysis based on absorption or desorption curves and intended for complete mix aeration reactors cannot be used to infer oxygen transfer rate to within commonly specified tolerances 1 2 averaging the apparent k l a values obtained by applying such test standard analysis to a large number of distributed probes does not produce a correct value of the global oxygen transfer rate it undershoots 1 3 averaging the do curves of a large number of distributed probes and subjecting the resulting curve to the analysis of such test standards likewise fails in producing a correct value of the mean global k l a it undershoots but not necessarily as badly as the individual probes 1 4 the concept of volumetric representativeness in a single reactor is not generally possible to apply in practice with today s models 1 5 sotr testing of aeration equipment installed in a tank laterally reduced in size such that the equipment effectively creates complete mix conditions likely gives a more accurate value of performance than in situ testing in a large reactor 1 6 the mixing characteristics of an aerated reactor influence the do curves and must hence be included in the analysis to obtain a correct sotr value 1 7 such mixing parameters must be obtained by careful testing do curves alone can rarely give accurate values of such parameters 1 8 for better relevance to process performance the sotr concept needs to be supplemented with a mixing performance characteristic this requires further research 1 9 the two zone model or the lagged exponential model can be used to highlight the potential undershoot of the exponential model 1 10 for loop reactors tracer recirculation tests should be used to enable a more suitable model such as the axial dispersion model to be fitted to test data when the damköhler number and aeration coverage conditions so require 1 11 previous claims that the exponential model and inert tracer technique are accurate for loop reactors are principally incorrect for low damköhler numbers and approaching uniform aerator distribution the sotr undershoot introduced by these methods can be moderate 1 12 for tapered aeration systems the uncertainty in test results caused by use of the exponential model has been estimated using a compartmental model for common parameters undershoot of down to 6 in k l a was found 2 probe lag can be accounted for in the analysis of the data curves under certain conditions probe lag mainly causes a time or phase shift and has a minor influence on data fitting 3 sulfite oxidation kinetics causes confusion and data corruption in particular at temperatures below 10 c increased cobalt catalyst concentration or switching to nitrogen or oxygen methods should be considered for such cold water 4 no theoretical estimate of the effective saturation depth is plausible without a detailed account of the mixing thus measured depth representative data should be used 5 a complementary method of establishing the effective standard oxygen saturation value for a test is proposed 6 existing clean water test standard analysis based on absorption or desorption curves should be subject to standard uncertainty analysis to quantify the uncertainty of the results 7 data sampling and model selection should be reconsidered in the light of uncertainty analysis including the effects of mixing probe lag and fluctuations besides the topics discussed above some additional topics have been identified and ventilated with the cen tc 165 wg 40 mainly in the spirit of harmonization simplification or clarification of existing standards these are listed here to inspire discussion in the aeration community 8 enabling the use of easily accessible water given the cost of potable quality water by relaxing conditions on test water quality and supplementing with alpha tests when e g treated effluent is used 9 correction of k l a test data to a standardized sodium sulfite tds value as suggested by asce 2007 1000 mg l 10 clarification that sae shall be based on the electric power of all aeration and mixing equipment required for operation 11 specification of probe instrument performance e g probe stability accuracy and response time without limitation to type of technology 12 optimization and unification between standards of do data density and collection and fitting ranges 13 development of the sulfite dumping method for loop reactors as sketched by asce 2007 and inclusion in other standards declaration of interest the author works for xylem www xylem com a supplier of equipment and solutions for the water cycle including aeration and mixing equipment the submitted work has been part of the author s assignment at xylem and thus fully funded by xylem acknowledgements dataset m1 was kindly provided by chris liu xylem the cfd simulation data was kindly provided by maximilian tomac and alexei loubenets xylem discussions with david redmon ian trillo andries visser yannick fayolle martin wagner maximilian schwarz jenny riit and extensively magnus fahlgren are gratefully acknowledged on tc 165 wg 40 of the cen discussions regarding the en 12255 15 aeration test standard with in particular markus roediger have been very rewarding chris fell suggested incorporation of tapered systems in the scope of work the referees have significantly contributed to the final form of this paper appendix a continuous flow two zone model the solution to the continuous mixing two zone model is related to the equation parameters by a 1 κ z a 1 p q 1 1 4 1 p p q 1 p q 2 2 1 p p a 2 κ z m 1 p q 1 1 4 1 p p q 1 p q 2 2 1 p p and inversely a 3 q κ z a κ z m 1 κ z a 1 κ z m κ z a κ z m κ z a κ z m 2 a 4 p 1 κ z a κ z m κ z a κ z m the limiting behaviors of the exponential rates are shown in table a 1 table a 1 tabele a 1 p 0 p 1 q 0 q κ za q 1 q 1 q 1 p 1 κ zm 1 q p q 1 p 1 p q p 1 p when p 1 or q κ zm rapid mixing between zones and κ za 1 recovering the complete mix solution for zone 1 and it is clear that κ za plays the role of oxygen transfer rate while κ zm is a mixing related rate expanding the solutions 11 and 12 and their volume weighted sum for small time τ the qualitative early behavior can be understood a 5 c 1 τ 1 e τ p q τ p 2 2 a 6 c 2 τ q p 1 p τ p 2 2 a 7 c τ p c 1 τ 1 p c 2 τ p 1 e τ p p q τ p 3 6 the first term of eqs a 5 and a 7 represents the isolated zone 1 complete mixing the parameter q and for zone 2 the volume ratio p 1 p introduce second order time effects the solution for zone 2 is second order in time with zero initial slope of the do curve because gas liquid mass transfer in zone 1 is followed by advection into zone 2 when q 0 all curves are distorted from a simple saturating exponential a source term accounting for the mass transfer driving force on liquid from zone 2 as well as on liquid mixed in zone 1 is a 8 s 1 1 p 1 q 1 c 1 q p 1 q 1 c 2 it keeps the system linear and second order with two rates with asymptotic behavior essentially but not exactly similar to that in table a 1 while it changes eqs a 5 and a 7 slightly the linear two zone model is clearly seen to retain its functional form 11 and 12 regardless of the detailed source setup the qualitative conclusions regarding the influence of both mixing and oxygen transfer time scales hold for this and similar two zone models 
18837,current application of clean water aeration test standards for wastewater treatment systems is reviewed with a focus on problematic interpretations and practices of the most commonly and internationally used standards edited by the asce usa cen eu efta and dwa germany remedy is proposed for these practices with a view to inspire revision of existing standards toward better understanding and achievement of test accuracy with regard to oxygen transfer rate themes are i the importance of mixing for testing and ii the importance of mixing for the relevance of standard oxygen transfer rate for the treatment process iii loop reactor testing and the impact of aeration layout the circulation time scale and dispersion iv tapered aeration testing v impact of probe response time vi sulfite interference at low temperatures vii the effective depth concept for the dissolved oxygen saturation concentration and standard corrections to the in situ saturation concentration viii uncertainty estimates on oxygen transfer capacity and efficiency and ix the prospect for simplification and harmonization among existing standards it is suggested that tests based on an improved understanding of the effects of mixing probe lag sulfite oxidation kinetics and fluctuations will eventually result in the reduction of costly oversizing of aeration systems and improve the understanding of aeration system design and oxygen transfer rate vis a vis energy consumption and substrate conversion in biological wastewater treatment keywords aeration mixing oxygen transfer standard testing nomenclature symbols bo bodenstein dispersion number c lt concentration of oxygen or liquid tracer dissolved in water kg m3 c a surface saturation concentration kg m3 c s saturation concentration of gas species e g oxygen in water kg m3 c s st standard saturation concentration of oxygen in water at 20 c p st and zero dissolved solids concentration 9 09 g m3 c end value of concentration kg m3 d dispersion coefficient m2 s for gas species e g oxygen dissolved in the liquid da damköhler i number i e transfer coefficient normalized by rate of recirculation q 1 or k l a k m total mass of dissolved oxygen kg n number of independent data points in time series q liquid recirculation rate between aerated and unaerated zones mixing flow rate m3 s q a air flow rate in aeration system nm3 h r ratio of gas tracer to liquid tracer concentration s source term in the dimensional model kg m3s t p linear lag time of instrument s v liquid volume in tank m3 z diffuser submergence m a ratio of flow rates between cells within a zone and between zones b lag factor c kr t normalized oxygen or krypton tritium concentration c c s c global volume average of c c p dimensionless oxygen probe signal k rate or pulse or recirculation frequency s 1 k l a oxygen or other gas species transfer coefficient s 1 k p probe response rate t p 1 s 1 p fraction of liquid volume exposed to aeration p a ambient atmospheric barometric pressure pa p st standard ambient pressure 101325 pa q normalized liquid mixing or recirculation rate q k l a v or da 1 r ratio of k l a of one zone to that of the previous zone s 1 2 normalized source term s k l a c s t time s u u flow velocity vector magnitude m s x space coordinate m γ percentage of gap closure δ model misfit or shift to data δ uncertainty ζ effective do submergence of z κ ef apparent transfer coefficient transfer coefficient based on exponential fit normalized with the true oxygen transfer coefficient κ ζ transfer rate scale in intermittent mixing two zone model κ ζα oxygen transfer rate scale in two zone model κ ζμ mixing rate scale in two zone model ρ liquid density kg m3 σ standard deviation τ time normalized by oxygen transfer rate k l a t τ p linear delay or probe lag time normalized by some rate k t p θ liquid temperature oc del operator m 1 abbreviations adm axial dispersion model cfd computational fluid dynamics bod biochemical oxygen demand kg m3 do dissolved oxygen concentration kg m3 sae standard aeration efficiency kg o2 kwh sote standard oxygen transfer efficiency sotr standard oxygen transfer rate kg o2 h tds total dissolved solids concentration kg m3 1 introduction specification and commissioning of aeration systems for biological wastewater treatment is routinely based on the standard oxygen requirement sor and the standard oxygen transfer rate sotr i e the oxygen transfer performance of the system under standardized conditions standard conditions include the use of clean water in order to separate the aeration system performance from the variability and uncertainty in unclean or process water composition sotr testing may be made for technical or commercial purposes in the design and commissioning phases narrow negative tolerances are often specified and imposed on tests performance underestimates due to incorrect application of test methods may lead to excessive capital and operating cost equipment and process r d may likewise be stifled by incorrect understanding of the oxygen transfer capacity precise test methods and sound uncertainty estimates are thus in the interest of the water community the most often used test standards in the experience of the author are those by asce 2007 following 1984 and 1992 editions cen 2003 and dwa 2007 following a 1996 edition referring to cen 2003 while adding discussion and options in particular the early asce committee work is well documented e g boyle ed 1978 boyle ed 1983 in summary the test and analysis procedures are as follows 1 the tank and clean water are prepared by aerating the water for a period and ensuring the tank is closed 2 the do dissolved oxygen concentration is displaced from its saturation level using oxidation of chemicals or gas stripping 3 do versus time curves are recorded at several points in the tank during reaeration for recovery of saturation 4 fitting of a mathematical model to these curves results in the onsite values for c s and k l a 5 this data is corrected for pressure temperature and potentially salinity effects to standard conditions and then averaged to obtain globally representative values 6 the resulting sotr value also depends on the water volume 1 s o t r c s k l a v 7 the sotr value is defined as the instantaneous oxygen transfer rate under standard conditions and at zero do 8 values of sote standard oxygen transfer efficiency and sae standard aeration efficiency may be calculated upon measurement of air flow rate if applicable and power consumption respectively the areas listed in table 1 and their current stand with the mentioned standards are discussed in this work the impact of mixing on the aeration process is briefly discussed as a complement to the test related mixing issues further harmonization or simplification points are proposed in the outlook some general remarks on the presentation follow here first dimensionless equations and entities have been used where possible to simplify the presentation the dimensionless time is defined as τ k l a t when a mass transfer coefficient is involved and as τ k t when a circulation rate is involved in practical application k l a is of course unknown and cannot be used for a priori normalization second in this work nonlinear parameter fitting is applied item 4 in the above test method summary nonlinear models play an important role and computational software and hardware no longer severely limits nonlinear fitting as in the past fitting of models to do data series is made between 20 and 98 of saturation for absorption testing as advised by asce 2007 unless otherwise stated the number of data points per time series is taken to be high enough to capture several features of each series the data range and density are further considered in section 6 3 1 1 finally the computations involved in nonlinear model parameter fitting to test data and in solving increasingly complex models are easily done using high level mathematics software the present work uses the commercial software package mathematica version 11 3 other commercial systems e g matlab maple and open source or free software e g scilab and octave are available in the author s experience spreadsheet applications may be too lightweight as the model complexity and number of fitting parameters increase 2 the perfect mixing assumption and its limitations while the invalidity of some present day application of current standards can easily be understood on a mathematical basis intuitive and mathematically simple models are used below to highlight important effects of inhomogeneity and mixing time scales a complete computational fluid dynamics cfd model is briefly reported in order to relieve the limitation of the simplistic models and prove the concept to be valid in realistic flows the terms complete mix and limited mix are used to denote completely mixed reactors and incompletely mixed reactors respectively as defined below the transport equation for a dissolved substance tracer like oxygen in clean water is 2 c t u c d c s with the classical gas liquid mass transfer source term 3 s k l a c s c the complete mix model c 0 or q removes any spatial dependence and for a reaeration process eq 4 is a valid solution 4 c t c 1 e k l a t t 0 c c c 0 1 e k l a t the mid form of eq 4 accentuates the time of onset from an imagined zero concentration as a shift parameter whereas the right hand form describes onset from concentration c 0 at time zero and allows for c 0 c desorption testing the standards referred to prefer nonlinear fitting of eq 4 to test data to obtain the value of the mass transfer coefficient k l a and potentially c s c implicitly understood in this work for complete mix systems this is referred to as exponential fitting ef below when applied to limited mix systems the exponential factor obtained by such fitting is termed apparent kla below a fairly homogeneous source distribution such as given by complete floor coverage diffused aeration can maintain the c 0 condition and is therefore understood as complete mix in the following asce commentary f 2007 state that limited mix reactors must be resolved by representative spatial sampling whereas cen 2003 and dwa 2007 state the test method to be invalid for such reactors these references accept closed loop reactors as complete mix systems while the latter two limit the applicability to da 0 25 for normal test precision and add some margin for da 0 25 the errors in these approaches are substantial and systematically negative as will be shown the value of c s varies with static pressure and thus the vertical coordinate while this dependence reinforces the importance of mixing for simplicity it is disregarded in the discussion about k l a estimation and is considered separately in section 5 the models introduced next illustrate the departure of the apparent from the true k l a value and of the do curve from eq 4 2 1 two zone models an insightful discussion based on a two zone aeration model by salzman and lakin 1978 demonstrates the effect of limited mixing their conclusions regarding mixing and k l a evaluation seem to have passed unnoticed although baillod and brown 1983 discussed a trivial case c 1 c 2 implying q the complete mix case of a similar model the latter possibly underlies the incorrect idea of using volume representative apparent i e based on eq 4 k l a values the other trivial limit q 0 reproduces eq 4 for zone 1 in isolation fonade et al 2001 also discussed the implications of a similar system the two zone model made slightly simpler and dimensionless here is illustrated in fig 1 gas liquid oxygen transfer takes place in zone 1 only which may include the free surface the terms zone 1 and zone 2 will henceforth be used for zones with and without such oxygen transfer respectively the aerated volume fraction is p and for continuous mixing the dimensionless inter zonal flow rate is q q k l a v oxygen transfer with the transfer coefficient 1 p is constantly active in zone 1 and each zone is complete mix reaeration curves satisfy eq 5 9 5 d c 1 d τ q p c 1 c 2 s 1 6 d c 2 d τ q 1 p c 1 c 2 s 2 7 c 1 0 c 2 0 0 8 s 1 1 p 1 c 1 9 s 2 0 salzman and lakin used 10 s 1 1 p 1 c 2 to describe the mass transfer driving force on a stream from zone 2 passing an aerator into zone 1 whereas in eq 8 the gas liquid mixture is considered to be in a pure zone 1 state the complete mix assumption per zone a source term reconciling the two views is given in appendix a the solution to eqs 5 9 is 11 c 1 τ 1 1 κ z m κ z a e κ z a τ κ z m 1 p e κ z m τ κ z a 1 p 12 c 2 τ 1 1 κ z m κ z a κ z m e κ z a τ κ z a e κ z m τ details of the solution are given in appendix a example curves and example apparent k l a values κ ef are shown in figs 2 and 3 respectively the fully intermixed curve q recovers eq 4 the exponential with an early slope 1 p of the c 1 curve is interrupted when the mixing rate κ zm scale begins to influence the curve the first three curves have κ ef values of 0 76 0 64 and 0 64 respectively as seen in fig 3 underestimate of the mass transfer κ ef 1 occurs for all non degenerate conditions except in zone 1 when the deviation from exponential behavior is apparent as in fig 2 the first three curves for zone 1 have several data with a poor fit δ 1 see eq 49 and visible systematic residuals all curve fits in zone 2 and the last in zone 1 have error norms δ 1 for q 5 both zones show the same values substantially short of 1 for low values of p the true value is recovered for all cases as p 1 as a numerical example consider the test data set m1 see section 6 3 and fig 19 the onset time shift between probes indicates q 3 to 4 or less because k l a is underestimated and the maximum time shift in the tank is greater than indicated by a few probes the value of p for the surface aerator is likely to be far less than 0 5 an underestimate of k l a by 10 30 is indicated by fig 3 to be compared with the analysis in section 6 3 an even simpler way of illustrating the issue with the apparent k l a is to replace the constant flow q with intermittent bursts of complete inter zonal mixing at the frequency q f formally using dirac s function 13 q n 1 δ τ n q f the reaeration data during mixing cycle n n 1 2 3 in the respective zone is 14 c 1 τ 1 e n 1 τ q p q n 1 κ z 15 c 2 τ 1 e n 1 κ z where the subscript has been dropped from q f to emphasize its role as a mixing rate and 16 κ z l o g 1 p 1 e 1 p q the volume average concentration is 17 c τ p c 1 τ 1 p c 2 τ 1 e n 1 κ z p e n 1 τ q p q 1 p an example of the curves given by 14 17 and exponential fits made between τ 0 and the mixing cycle reaching 98 saturation are shown in fig 4 with p 0 3 and q 1 apparent k l a factors in zones 1 and 2 are κ ef 1 2 24 and κ ef 2 0 29 while for c κ ef 0 37 is close to κ ζ 0 34 the average of the two zones values is 1 27 and the volume weighted average is 0 88 no reasonable combination of these comes acceptably close to 1 this example makes it clear that the accelerated saturation where aeration is concentrated reduces the mass transfer rate unless complete mixing is at hand thus individual apparent k l a values obtained for each zone average to less than the true global value and the average do curve shares this fate the volume average do curve was discussed by e g boyle et al 1989 as a means for correcting for mixing slowness and it may produce an exponential looking curve baillod et al 1986 refuted this idea considering the implications of incomplete mixing the curve for c displayed in fig 4 underlines the argument against it the apparent k l a value obtained using a volumetric average do curve eq 17 is shown for a variety of p q sets in fig 5 short of 1 for all non trivial cases an analysis of the average or equivalently total do evolution highlights the issue further with no reactor inlets or outlets the volume integral of eqs 2 and 3 is 18 dm dt m k l a c dv with a homogeneous k l a this simplifies to 19 dm dt m k l a m with a spatially uniform solution like eq 4 and same holds if c is homogeneous and k l a is interpreted as the true volume average inhomogeneous k l a and c invalidate eq 19 for instance for the two zone model the last term in eq 19 becomes k l a p m a where m a is the dissolved mass in the aerated volume only differing from m with the dissolved mass in the unaerated volume only with very rapid mixing can it be said that m a p m and the simple form 19 is recovered as made evident by the above models the signature of the correct mass transfer value is present in the slopes of the do curves at time t 0 volume weighted averaging of these values produces the global k l a value but an exact representativeness of the probe locations is required excerpts from a cfd model are used in section 2 3 to show that this cannot be achieved in practice a simple mechanism behind non standard do curves was described above deviation of the do curve from a perfect exponential saturation curve and even inflection can thus be explained by limited mixing of aerated and unaerated liquid see also talvy et al 2007 while dispersion leads to a smoothing of the early part of the curve see section 2 2 the effect of delayed sensor response is discussed in section 3 the presence of an inflection point in the do curve is ascribed by asce 2007 to the lingering of oxygen depletion chemicals whereas this inflection can also be weakened to a smoothing of the do curve 2 2 advection dispersion and aeration layout in loop reactors among the test standards and guidelines known to the author only stora 1980 referenced by stowa 2009 provides guidance on analysis of test results in limited mix reactors but only for mechanical point aeration in loop reactors limitations of their approach were identified by abusam et al 2001 and van bentem and de bruin 2009 both demonstrating improvement by a tanks in series approach taken further by nakamachi et al 2012 who used tracers to characterize advection and dispersion dudley 1995 proposed an advection model to analyze test data taken in process water stamou 1994 lesage et al 2003 and several others motivated the use of the axial dispersion model adm for oxidation ditches haouech 2012 while reviewing the upside of the adm over the tanks in series model in reproducing abundant real system data pointed out lab scale experiments on reaeration that have had very low da values and did not therefore require spatially resolved modelling as opposed to full scale systems full scale application of the adm to reaeration was demonstrated and analyzed by uby 2019 who further illuminated the long known relationship between the tanks in series model and the adm values of da q 1 have been seen to vary at least between 1 10 and 1 1 5 the adm is a one dimensional version of eqs 2 and 3 with a fixed constant velocity and for the present purpose a gas liquid mass transfer source term neglecting the dispersion term which includes molecular and turbulent diffusion and spatial dispersion allows for analytical solution of the model in a periodic domain and forms the basis for the stora 1980 approach see fig 6 whereas dudley 1995 used a numerical procedure and included a constant respiration term the stair stepping indicated in fig 6 is sometimes seen in loop reactor testing but strongly smoothed by dispersion see fig 8 and oxidation of residual sulfite sulfite may change the expected correlation between probes in different parts of the reactor while cen 2003 mention the importance of the da value to the effect of circulation the value of p and the detailed distribution of the mass transfer is equally important uby 2019 the effect of dispersion is also required to accurately capture the oxygen dynamics abusam et al 2001 van bentem and de bruin 2009 the effect of dispersion alone is illustrated by considering the dispersion of the advected oxygen along an advection line with the source term s in eq 2 replaced by the boundary condition that eq 4 holds at x 0 corresponding to an aerated complete mix reservoir feeding the line the numerical solution to this problem and exponential fits are shown in fig 7 however it is known that dispersion alone without advection would distort the initial linear part of the curve by the factor 1 x 2dt 1 2 8 π 1 2 x 2dt 1 2 1 as it penetrates the line dispersion thus causes onset to strongly precede the expected time the fits have systematic residuals even between 20 and 98 of saturation the κ ef values obtained at x 1 and x 2 are 0 90 and 0 81 respectively a high growth rate in the reservoir causing large gradients and a large diffusion coefficient enhance the effect of dispersion to reduce κ ef 2 3 complete 3 dimensional data cfd model the ultimate extension of the above models to high fidelity cfd is resource intensive but may be used occasionally to corroborate less expensive approaches the growing literature on cfd simulation of wastewater applications has recently been reviewed karpinska and bridgeman 2016 and is beyond the scope of this work however fayolle 2006 has reported oxidation ditch reaeration curves see below a fully 3 dimensional cfd model of a loop reactor with 56 million cells as opposed to two zones or a one dimensional model illustrates the impact of time scales in practically realizable flow eqs 2 and 3 embedded in the liquid phase with the higbie boussinesq mass transfer model known to produce realistic results e g talvy et al 2007 were applied to an eulerian disperse phase flow solution using cfd version 16 5 when modelling fully mixed tanks nitrogen transfer and the gas side depletion of oxygen has had a negligible influence on the reaeration curve for which reason these effects could be excluded although this model is well validated the important feature is the realistic representation of the flow air and oxygen distributions versus field testing cfd has the advantage that the local k l a is known everywhere in the tank fig 8 shows the do curve for the volume average and two of the 116 probes not physically modelled from around the whole loop reactor that were recorded during simulation exponential fitting gave k l a values of 5 21 5 95 h 1 8 20 short of the actual value 6 49 h 1 sotr being equivalent to dm dt at c 0 was evaluated initial slopes equal to local c s k l a and taken between 0 5 and 5 of saturation of 54 probe curves symmetrically located around the reactor average to 204 of the volumetric average the same product of the pointwise apparent values averages to 87 the slope for the first second of the volume average which leads to 0 18 of saturation only reaches 98 2 of the true product thus the representative volume can definitely not be relied on in practice fayolle 2006 similarly reports a 22 deficit of k l a in a cfd simulation of an annular loop reactor when using do curves as compared to obtaining the true volume average k l a value directly 2 4 mixing and the relevance of sotr the sotr concept focuses on the idealized transfer rate regardless of mixing and has only been intended for use in complete mix reactors in the activated sludge process typically differing from the test standard situation with oxygen consumption through flow and an increased effective viscosity the importance of mixing for bod biochemical oxygen demand and nutrient removal and for sludge characteristics is easy to imagine this importance was emphasized by fonade et al 2001 consider for instance a pre anoxic zone connected to a well mixed conventional aerobic reactor operating at a do of 2 g m3 with mixed liquor recirculation to the anoxic zone this can be described as a two zone system with q 0 1 aerobic sludge age and conversion of bod and ammonium increase if aeration is introduced in the first zone given the same load and oxygen transfer rate while on the other hand denitrification occurs in the normal case a more refined point is made by rehman et al 2017 who use cfd coupled with the activated sludge model asm1 to identify a number of important consequences of incomplete mixing for process control and evaluation the combined aeration and mixing performance affects overall process performance and the mixing time scale should be optimally related to residence and kinetic time scales present style sotr performance characterization for incompletely mixed reactors is unsuitable because the sotr concept is blind to mixing and kinetics and test practice hesitates between the sotr definition and incorrect application to limited mix reactors on the other hand the importance of improved mixing can be highlighted by an aeration test establishing whether insufficient gas liquid oxygen transfer or insufficient mixing is at hand is important to identify the most viable remedy for instance the zone of influence of surface aerators may be increased using draft tubes or added mixers whereas an increased aeration power or number of aerators would be required to increase the gas liquid transfer per se in oxidation ditches surface aerators are being supplemented by submersible mixers to achieve a stronger circulation and thus transport of oxygenated liquid bottom diffused aeration often relies completely on submersible mixers to achieve circulation and maximized oxygen transfer in oxidation ditches the impact of mixing as well as of oxygen transfer rate on process performance should be considered when selecting an aeration system mixing should even be separately specified for certain aeration reactors as is already commonplace for oxidation ditches 2 5 accounting for limited mixing the previous sections demonstrate the need to account for the effect of mixing on the distribution of dissolved oxygen do data is notoriously difficult to use for accurate mixing quantification the best strategy is to extend tests to capture mixing characteristics but devising a general mixing test method for an incomplete mix aeration tank remains a challenge three approaches to the mixing problem are discussed two of them by a detailed example 1 maintain the incorrect model eq 4 and account for the bias and uncertainty thus introduced e g for tapered aeration 2 apply a more appropriate model based on more extensive testing e g for tracer testing in loop reactors 3 extend testing and reinterpret the incorrect model the inert tracer technique an alternative test method based on do mass balance between liquid entering and leaving the aerated zone was attempted boyle et al 1989 however the need to capture detailed flow dispersion and do profiles with a high accuracy could not be met 2 5 1 tapered aeration tapered diffused aeration systems are usually designed for uniformly sized zones of gradually decreasing mass transfer coefficient along the reactor a compartmental model for several cells and several levels of k l a can be used to estimate the maximal impact of tapering on aeration test results knowing the uncertainty or bias introduced by tapering testing can often be carried out without the need to separate the zones with baffles and without abandoning eq 4 the successive transfer coefficient ratio r is usually between 0 50 and 1 00 i e the k l a value in one zone is some 50 100 of that in the preceding zone setting all values of r equal to the lowest value of a certain design produces a bounding case for a class of designs with regard to the applicability of eq 4 for instance a common 4 zone tapering has the r values 0 67 0 50 0 67 and another one has 0 75 0 84 1 00 the former is thus bounded by r 0 50 for all zones while the latter is bounded by r 0 75 reactors with 2 3 or 4 tapered zones were analyzed each zone was modelled as either 1 2 3 or 4 cells in series see fig 9 however this made a difference of at most 0 1 for the limiting values in the apparent k l a intuitively 1 or 2 cells per zone is reasonable the water flow rate between cells in neighboring zones was varied within 0 2 q 50 for each such flow the water flow a q between the successive cells within a zone was within 0 1 a 2 0 since water flow is orders of magnitude faster than gas liquid oxygen transfer in aeration tanks the upper values of q are the more representative for real tests and values of a of order 1 are realistic the small variability of results in this regime made extension to other flux values superfluous any flow of bubbles is assumed to increase the value of r toward 1 and is thus disregarded in the search for a conservative bound exponential fitting to eq 4 within 5 98 and 20 98 of saturation in all cells exhibits no substantial difference in the average κ ef between the two intervals the greatest variability was found for small values of a and q where up to 2 3 overshoot in κ ef was obtained with 4 zones in the opposite practically relevant regime variability was lower within each taper class and undershoot down to 6 0 was found for r 0 5 3 5 for r 0 60 and 1 2 for r 0 75 for 2 and 3 zone tapering undershoot was correspondingly smaller see fig 10 based on the three values of r linear interpolation of lower κ ef bounds versus 1 r appears accurate for all zone counts considered missing the point 1 1 by less than 0 5 thus sampling with do probes evenly distributed centrally in each taper zone and with a standard vertical distribution along a commonly tapered reactor under these conditions will not add more than 6 undershoot in k l a and no overshoot can be expected to the general uncertainty the insistence of dwa 2007 to locate at least two probes in each zone should secure data quality and redundance against probe failure the original two zone model r 0 reached an undershoot of about 20 when fitting 100 data points within 20 98 of saturation with p 1 2 and one cell per zone 2 5 2 tracer testing in loop reactors the combined effect of periodic circulation and dispersion as well as a complete testing methodology and data for bottom diffused aeration in loop reactors precursed by nakamachi et al 2012 and based on an extension of methods used for airlift loop reactors is presented in extenso in a separate paper uby 2019 in brief inert tracer testing is used to obtain velocity and dispersion characteristics while local velocity testing using e g adv technology is of limited value tracer data must be well resolved and online fluorometry and fluorescent tracers are more likely to be used today than exotic isotopes as by e g boyle et al 1989 the adm is then solved using these characteristics and fitted to do data which requires an accurate account of aeration and do probe layout typically 6 8 probes must be rather evenly distributed around the loop to capture the spatial resolution of the do concentration and any time shift of the onset while observing a standard vertical distribution while fitting of the exponential model takes seconds fitting of the adm can take minutes on a modern portable computer 2 5 3 inert tracer technique early work e g neal and tsivoglou 1974 presents a tracer method endorsed by asce 1996 claimed to account for mixing and compares it to the standard test it consists of seeding the test basin with a sample of water with a dissolved inert tracer originally 3h2o or t for tritium whereas licl and rhodamine wt have also been used and a dissolved tracer gas originally 85kr whereas stable kr or other gases have been used later aeration causes tracer gas desorption to the practically zero saturation level and the desorption curve normalized with the inert tracer concentration in test points is interpreted as a time exponential the ratio of k l a for krypton and oxygen was reported to be 0 83 and was subsequently reduced for submerged aeration on account of secondary effects the idea of accounting for the dispersion of the seeded gas by normalization with the inert tracer concentration can be analyzed using the two zone models with burst mixing and seeding in zone 1 after just one mixing cycle the liquid tracer is completely mixed but the inhomogeneity of gas liquid mass transfer remains and the liquid tracer no longer adds information though this effect is less pronounced in more realistic systems this model best explains the failure of the method the continuous two zone mixing model is also easily implemented with the two tracers using eqs 11 and 12 for each of the two species with s 1 0 for the liquid tracer using the ratio curve reduces the κ ef undershoot slightly for instance introducing this technique for p 0 2 and q 2 in zone 1 κ ef increases from 0 80 to 0 83 and in zone 2 it increases from 0 75 to 0 77 still leaving 17 and 23 undershoot respectively this must be considered a failure the similarity between the standard and the tracer method can be more precisely analyzed and stated as follows gas species oxygen or krypton transfer is described by eqs 2 and 3 with k l a being different between the two gases by just a constant factor and krypton having c s 0 the dispersion of an inert liquid tracer e g tritiated or normal water follows eq 2 and 20 s 0 for either method the ratio of gas to liquid tracer concentration evolves according to the same equation 21 r t u d r k l a c s c l t r 2 d ln c l t r the complexity of the source terms on the right hand side surpasses that of eq 3 when c lt is inhomogeneous due to for instance the initial conditions in which case the inert tracer model becomes different from the complete mix model and the exponential model eq 4 is clearly incorrect for the ratio r for incompletely mixed reactors as a more detailed example with the adm modified to accommodate the source terms in eq 21 exponential fitting to the function r shown in fig 11 yields 0 91 κ ef 0 93 converging toward 0 92 as less early data is used the curve obtained by direct division of the two tracer curves is indistinguishable from the solution r calculated from c t and eq 21 demonstrating the consistency of this equation fig 11 is based on estimated data for the opelika loop reactor in boyle et al 1989 where the application of a simple exponential fit was made to both a reaeration test and an inert tracer test with a point injection the adm and eq 21 both robustly indicate a k l a undershoot by 6 8 by the exponential fits with da 0 25 a similar systematic deviation between the exponential function and the tracer ratio can be divined in plots in boyle et al 1989 and in neal and tsivoglou 1974 though their use of a lin log plot naturally reduces the impression more importantly k l a underestimates of up to 32 were observed for certain probes and early truncations when da 0 56 in a test where p 0 075 uby 2019 and for most locations and truncations the underestimate remained between 10 and 20 an alternative view of the inert tracer technique is that it assumes that a solution to eqs 2 and 20 becomes a solution to eqs 2 and 3 just by multiplication with a time exponential even with c s 0 this can only be fulfilled for a very special k l a distribution principally the standard and the inert tracer methods differ in the effective k l a value the dissolved gas saturation value and the initial conditions only the initial condition for the inert tracer normal water is trivial for the oxygen water system clt 1 and clt 0 whereas the seed is localized in the tritium krypton tests if a submerged aeration system were operated with pure nitrogen or with air and seeding were made with oxygen supersaturated tritiated water the similarity of the test to a standard desorption test with nitrogen or even air coming through the aerators would be even more striking thus in complete mix reactors the two approaches are trivially equivalent and the exponential decay model can be applied to the inert tracer method only under the same assumptions as in the standard method the errors in limited mix systems are of the same order of magnitude 3 effect of linear probe response 3 1 rationale the linear probe response time in terms of τ p t p k l a is required not to exceed 0 02 asce 2007 or 0 05 cen 2003 in order to avoid an undesired influence on the shape of the do curve and thus a confusion of time scales to reduce the confusion caused by probe lag truncation of do data for values below 20 asce 2007 raising the τ p limit to 0 05 or 25 cen 2003 of saturation is allowed philichi and stenstrom 1989 this can also be helpful in filtering the influence of unreacted sulfite see section 4 common probe response times of 10 30 s are to be compared with oxygen transfer times ranging over the orders of hundreds to thousands of seconds thus for very high rate systems the above requirements can impose restrictions on the probe selection however the importance of understanding mixing limitations as discussed in section 2 raises the need for a qualitative understanding of the effect of probe lag on data signals affected by a mixing time scale for instance one might want to test a spatially resolved model for the do data as a simple application the two zone model can be attempted its relation to the lagged version of eq 4 is discussed below if the presence of sulfite is not an issue and probe lag effects are known important qualitative information about mixing can be obtained in particular if including early do data in the analysis see section 6 3 linear probe response formulae are presented the lagged reaeration function appears repeatedly in the literature starting perhaps with mueller et al 1967 and has occasionally been overlooked but a simple analytical derivation of the lag formula and its repeated application and interpretation is given here for the benefit of loop reactor testing probe lag effects on tracer recirculation curves are also discussed the analytical method applied here promotes intuitive understanding and computational ease while being easily extended to other models 3 2 linear probe response equations the first order lag transform that often relates the output of optical and electrochemical probes to the ambient concentration via the probe lag time t p k p 1 has been validated for a number of probes the first order lag equations are 22 d c p d t k p c t c p t 23 c p t 1 c p 1 24 c t 1 c 1 eq 22 is multiplied with the integrating factor exp k p t and then simply integrated to give c p t for t t 1 as 25 c p t e k p t c p 1 e k p t 1 k p t 1 t e k p t c t d t slightly differently phrased by mueller et al 1967 it is instructive to consider some special cases of eqs 23 25 setting t 1 0 for convenience and c t 0 for t 0 these are given in table 2 and discussed in the following subsections 3 2 1 lagging of a step change the exponential decay c p 1 c 0 e k p t of an initial discrepancy c p 0 c 0 known as a step change if c t is kept fix is always of this form and is therefore noted in the head of table 2 asce 2007 encourage a step test to confirm the probe lag characteristics fig 12 shows the result of moving a fluorometer between containers with clean water and water with rhodamine wt fahlgren 2016 the nonlinear fits solid and dashed to the exponential decay give t p 11 9 s in both directions and linearity is confirmed by the excellent fit water temperature was between 16 6 and 16 9 c the inset of fig 12 shows lin log representations of the exponentials revealing truncation and poor fit near equilibrium however deviations are small in the lower part and including these noisy parts only changes t p by 0 4 and 0 2 respectively the influence of fluctuating data and probe precision is discussed in section 6 3 the step change response may also be seen as an exponential decay of the initial signal c p superposed on the exponential growth to the ambient value of c 0 from 0 both views are equally valid on account of the linearity of the lag transform the complication of an initial state c p1 c 1 is avoided by probe equilibration in a constant c c 0 environment for the duration of a certain multiple n of t p for instance only 2 of the initial discrepancy remains with n 3 9 equilibration of do probes in desorption testing requires supplying a balanced air oxygen mixture producing the desired saturation level sometimes t p is called t 63 because in this time a gap is reduced by 63 2 some sensor suppliers share values of e g t 90 but for any value of γ the linear response value of t p can be deduced using 36 t p t γ ln 1 γ 100 3 2 2 lagging of linear quadratic and exponential signals the linear signal clearly gets a time shift t p combined with a catch up term responding to the abrupt acceleration at t 0 eq 26 this combination is seen for signals with limited growth in general for the quadratic signal eq 27 the probe only catches up to within the time shift t p and a constant shift in c as time grows for faster signal growth the c shift increases until for exponential growth the catch up term is combined with a constant amplitude reduction factor eq 29 for τ p 1 this factor comes close to exp τ p which again signifies a time shift by t p for exponential decay eq 30 the catch up term and the reduction factor are the same as for the exponential growth but accounting for the sign of the exponential it is concluded that linearly lagged data of an exponential signal retains the growth rate k of the original signal after the catch up phase which takes a few times τ p after onset the respective shift and scaling due to probe lag can thus be comfortably identified and the exponential catch up terms to both step changes and abrupt accelerations appear similar for most situations 3 2 3 lagging of periodic signals the sinus understanding of the lagged sinus signal eq 28 facilitates the analysis of a non sinusoidal disperse pulse train below the exponential catch up term is again easy to identify the amplitude of fast oscillations i e for τ p 1 is damped by lag but up to τ p 0 045 only 0 1 is lost the underlying frequency is conserved with just a phase lag to the signal this conservation is expected since eq 22 forces c p to turn when the ambient data crosses the probe data in the opposite direction the phase lag increases from 0 at no lag to maximum π 2 90 for very strong lag 3 2 4 lagging of reaeration curves the probe appears as an unaerated zone with first order dynamics and k k l a and the correspondence between eqs 12 and 31 by k κ za k p κ zm is perfect with c s 1 and c 0 0 to match the setup of the dimensionless model the interpretation of the probe as a zone 2 with p 1 makes sense in the light of this observation the reaeration curve is a linear combination of a constant and an exponential which enables adoption of their respective lag properties given above in particular lag causes a catch up phase and a time shift t p and the growth rate k is conserved the factor cs c0 is noticeably augmented even for small values of τ p affecting the fitted c 0 value based on the lagged do time series negative c0 values may thus occur low end truncation of data reduces the magnitude of the lagged signal deviation from the shifted original signal for instance if τ p 0 05 truncation of all data below c 0 1 i e 10 of the concentration range keeps pointwise do data error due to lag below 0 5 of the range while truncation at c 0 15 keeps the error below 0 1 asce 2007 and cen 2003 guidelines that τ p 0 05 for truncation at c 0 20 and 0 25 respectively correspond to a maximum point error of less than 0 1 more importantly the error in fitted oxygen transfer parameters is kept under control see fig 13 fits can be improved using a high data density but for real data the influence of fluctuations is generally more important see also section 6 3 the effect of probe lag on eq 4 is thus mainly a shift by the lag time except for 37 t t 0 n t p with n safely taken between 2 and 4 and equal to 1 for practical purposes eq 31 may be fitted to data truncated earlier fitting of test data to the non normalized version of eq 31 provides the mass transfer coefficient k l a and the saturation value c s along with the initial concentration c 0 or time shift t 0 and probe datum c p1 but the value of τ p must and can be ascertained independently otherwise the lag cannot be separated from the effect of limited tank mixing the difference between a fitted value of τ p and the true lag is a mixing delay time scale see section 6 3 1 2 with complete mixing and a known value of τ p fitting of lagged exponential data with a small gaussian noise 0 5 superposed is summarized for a range of τ p values in fig 13 the decline in fitting quality seen for moderate to small values of τ p was noted by philichi and stenstrom 1989 but can be thus avoided for both k l a and c s constraints additional to eq 37 must be put on the data as the noise grows see section 6 3 1 it is straightforward to calculate the effect of probe lag in zone 1 of the two zone model eq 11 the influence of lag on the oxygen transfer like term and on the mixing like term respectively is quite similar with the respective exponential terms being reduced by a lag term like a zone 2 eq 12 the increase in the number of parameters causes degeneracy and does not improve the fit when τ p κ zm 1 3 2 5 lagging of tracer pulses and pulse trains the mathematically ideal delta pulse causes an immediate response because of the infinite amplitude and then the usual exponential decay follows based on the probe lag time eq 32 the response amplitude is limited by the probe lag time in a situation where a known pulse mass passes the response peak amplitude thus contains information about the probe lag time this ideal pulse response behavior translates in part to the dispersed pulse the general lag form of the universal dispersed pulse eq 33 has the two special cases eqs 34 and 35 which are computationally less demanding the lagged behavior is shown in fig 14 the close fit of the lagged pulse to an unlagged pulse is also demonstrated eqs 33 35 satisfy the same axial dispersion equation and thus conservation laws as the original pulse but with appropriate shifts in bo k x and amplitude hence incorrect fits to test data of e g bo may arise due to probe lag this need not be if the origin in time and space of a perfect pulse is known but usually an injected imperfect pulse develops to the universal form and the virtual origin must also be found by fitting by fitting lagged data of the same pulse recurring periodically as in a loop reactor to a train of unlagged pulses the shift in bo and pulse frequency k caused by the lag τ p is suppressed cf the lagged sinus in section 3 2 3 the peaks of the lagged signal approach a rigid time shift t p as time grows leaving fitted values of f and bo increasingly accurate for instance fitting the collection of the third to fourth peak lagged pulses to an unlagged pulse train shows that the fitted values of bo are less than 0 3 short of the true values when kτ p 0 16 and 25 bo 95 while the fitted values of f are less than 0 03 short the errors are a factor 10 smaller for kτ p 0 08 for 10 bo 20 the error in bo value can reach 4 and in f value 2 see fig 15 moderate probe lag should thus not present a problem to accurately determining advection and dispersion data for loop reactors uby 2019 4 impact of sulfite and cobalt chemistry depletion of the dissolved oxygen as a final preparation of the thoroughly aerated test water is done by either sparging nitrogen gas through the aeration system or by dissolving stoichiometric amounts with some excess of sodium bisulfite while the nitrogen method is more popular in laboratory work and appears more reliable and environmentally friendly it requires gas flasks or a pressure vessel perhaps a trailer and some connection work on the air mains if unpressurized mechanical aeration is tested a temporary sparging system must be provided using the sulfite method a small amount 0 1 0 5 g m3 asce 2007 of cobalt must already be dissolved and well mixed to catalyze the sulfite oxidation the dissolved mass of oxygen is usually in the range of 10 14 g m3 and stoichiometrically it requires 2 126 32 7 88 times as much about 100 g m3 sodium bisulfite plus excess to cater for the oxygen transfer still occurring during the final water preparation and do probe equilibration if an extended time of mixing is required and mixing is in part or wholly done by aeration the amount of sulfite required for maintaining the do depression throughout the volume during this phase can be a few times 100 g m3 thus tons of salt can be required for a single test in larger tanks notably large oxidation ditches asce 2007 mention stripping of oxygen by nitrogen gas as a reference method for small scale tests to check the sulfite quality and probe zero setting and the pure oxygen based desorption method wagner et al 1998 in a commentary as being further evaluated cen 2003 affirm the use of any of the mentioned methods while dwa 2007 even provide guidelines for calculating the required nitrogen and oxygen masses while the interchangeability of these methods is briefly considered in section 6 1 an issue with the sulfite method is addressed here the sulfite method thus remains popular in particular where the asce guidelines are in use though its chemistry is not completely understood for instance numerous observations of insufficient deoxygenation by the first sulfite batch in repeat test water e g naimie and nelson 1978 paulson 1983 underlie the recommendation to use the first test as a system stability check and only conditionally use it for compliance evaluation unwanted effects may also occur when testing at low water temperature test water even in thousands of cubic metres comes as is sometimes cold the caveat of asce 2007 that sulfite may not be quickly oxidized under about 10 c needs to be supplemented with clear guidelines for how to avoid the lingering sulfite issue which results in smeared and slowed re oxygenation data field observations of maximum practically constant do reduction rates for near instant sulfite dumping of the order of 10 2 10 1 cs s and for slow sulfite pouring in loop reactors at correspondingly lower rates e g 10 3 cs s most often exceed the oxygen transfer rates by far see section 3 1 with higher order oxidation kinetics at the lower temperatures and as do and sulfite concentrations decrease a loss of oxidation rate by orders of magnitude can cause dire interference between the two time scales sulfite oxidation kinetics research was reviewed by linek and vacek 1981 and was considered by early contributors to the asce standard see reviews by e g naimie and nelson 1978 and paulson 1983 disagreement was observed regarding the wanted and unwanted effects of cobalt under different conditions it remains that reaction order and reaction speed varies with the dissolved concentration and heterogeneous availability of oxygen and sulfite and with temperature ph and catalyst type and concentration observation of incomplete oxidation can be made by monitoring ph which rises temporarily during dissolution of sulfite and drops back with the formation of sulfate conductivity can be used to monitor the dissolution process if required but quantitative conclusions on oxidation are not necessarily obtained if the oxygen transfer rate is well known a sulfite mass balance can be made but such an a posteriori analysis does not address the measurement accuracy issue a maximum cobalt dose was stipulated in order to avoid the interference with the winkler test that is observed for ph 6 7 and loss of cobalt to complex formation should be detected by testing the cobalt concentration for each aeration test there does not seem to be conclusive evidence that this covers all common situations it is proposed that the use of the sulfite method be strictly limited to water temperatures above 10 c or that the effect of an increase in cobalt concentration is examined in order to accelerate the oxidation of the sulfite at low temperature with tracer testing for loop reactors a deeper understanding of the interaction between cobalt sulfite and fluorescent dye tracers such as rhodamine wt and uranine is also required it was observed that at 18 1 c the addition of up to 100 ppb of rhodamine wt did not affect oxygen absorption characteristics mass transfer coefficient and saturation value after using 0 55 g m3 of cobalt and 300 g m3 of sodium sulfite to deplete the oxygen however cobalt absorption by amines could play a role at lower cobalt concentrations while rhodamine could be partially quenched by cobalt a brief interruption of the sulfite oxidation was observed as a concentrated cloud of rhodamine wt passed do probes uby 2019 conversely the addition of 300 g m3 of sodium sulfite was seen to reduce a rhodamine wt reading from 73 to 53 ppb at the same pace as conductivity rose due to the addition fahlgren 2016 rhodamine loses some fluorescence intensity when ph 5 or ph 9 and at high salinity leibundgut et al 2009 which could explain the latter observation chlorine and oxygen highly supersaturated or ozone may also reduce the intensity performing the tracer test after all sulfite has been oxidized but during a reaeration data uptake could thus yield uncorrupted oxygen transfer and mixing data uby 2019 5 saturation value 5 1 the effective depth for the value of cs the global reactor average value of the oxygen saturation concentration has a direct influence on the test result the oxygen saturation equilibrium concentration is proportional to the static pressure according to henry s law which has been used as an argument for selecting the half depth value of ζ 50 for submerged aeration this is at variance with extensive testing experience that indicates a smaller effective depth e g brown 1978 which can still today only be obtained by testing baillod et al 1986 found ζ 21 44 for fine bubble diffused aeration ζ 26 34 for coarse bubble diffused aeration and ζ 5 7 for low speed surface aeration gillot et al 2005 observed ζ 33 based on numerous absorption tests with dissolved oxygen do probes at mid lower and upper depths asce 2007 stipulate volumetrically and depth wise representative sampling as the only method of arriving at the global saturation value further supported by jiang and stenstrom 2012 cen 2003 propose ζ 50 for a theoretical calculation of the saturation concentration to avoid the need for accurate do probe calibration if agreed between the parties concerned while referring to this dwa 2007 put forward 40 ζ 50 unless depth is greater than 7 m for which ζ 33 is stated for 6 m diffuser submergence assuming ζ 50 where ζ 33 would be detected by testing an overestimate of sotr by 8 results a considerable bias the empirical approach appears to be the only reasonable way to obtaining the global saturation value or equivalently the effective submergence the effects of liquid mixing at a rate considerably faster than the oxygen transfer time scale and to a lesser extent nitrogen transfer bubble diameter dynamics and free surface oxygen exchange should be harnessed to reconcile theoretical argument with the observed data when vertical mixing of liquid occurs at a faster time scale typically 101 s than oxygen transfer typically 102 103 s henry s law is dominated by mixing and the concept of a well defined local saturation value must be replaced by the empirical terminal concentration 5 2 correction from site to standard conditions of cs test standards refer to a standard ambient pressure close to p st and the standard surface saturation value c s st is fixed the ambient barometric pressure p a and the ratio of the global saturation value to the quiescent surface saturation value can be used for the calculation of the standard saturation value and subsequently sotr should this be preferred in summary the probe calibration procedure given by asce 2007 annex d item 2 2 2 is extended to account for the effective mixed water depth and water content after do curves have been recorded from the installed probes at representative depths put the probes in a clean bucket with enough test water say 5 cm depth to continue measuring the do conserve the temperature of the test water by keeping the bucket in a larger bucket with test water or in the reactor stir the small bucket water until each probe reaches an equilibrium corresponding to its onsite surface do saturation value ca in the test water the normalized effective depth and the standard saturation value are 38 ζ c s c a 1 p a ρ θ g z 39 c s c s s t ρ 20 g ζ z p s t p s t c s s t c s c a 1 p a p s t ρ 20 ρ θ 1 c s s t c s c a 1 p a p s t 1 the density ratio in eq 39 equals 1 to within less than a third of a percent between 0 and 30 c the absolute density effect of permitted amounts of sodium sulfite 2000 g m3 on water is also less thus ρ20 ρθ 1000 kg m3 can be used for quick calculations the procedure should be repeated after each do curve capture but has the advantage that effects of temperature and water content on cs are eliminated without correlations relying on empirical data narrow parameter intervals etc 6 uncertainty estimates on oxygen transfer capacity and efficiency uncertainty analysis repeat testing and test method benchmarking should be revisited to establish a sound basis for documented uncertainty in test results in particular for each test an uncertainty budget should be reported this includes values or best estimates of all base data uncertainties and estimates of the uncertainty of the end result if repeat test variability is greater than single test uncertainty causes for this must be sought 6 1 is the clean water test method correct benchmarking between the standard desorption or absorption and inert tracer test method cannot corroborate either method because of their commonality see section 2 5 3 though it can be argued that they are both correct in the complete mix case and only then see section 2 the off gas test based on measuring the residual oxygen in air leaving a reactor with diffused aeration qualifies as independent it finds its easiest application when constant oxygen consumption secures stationary conditions lab or pilot scale fermenter testing using a mass balance of a constant feed of for instance na2so3 and air or o2 shows a very strong agreement between this method and the re equilibration method under certain conditions where for instance gas side depletion of oxygen is avoided linek et al 1989 attempts at comparing the off gas method with re equilibration methods reaeration after aeration shutdown or step change or desorption after supersaturation using h2o2 in full scale have met with difficulties in maintaining a constant oxygen uptake under process conditions stability of and agreement within 10 between the off gas and h2o2 methods were noted by capela et al 2004 mueller and boyle 1988 noted a similar scatter between these methods including the tracer method among the cen and dwa standard test methods no result dependence on initial conditions supersaturation or depletion of oxygen and nitrogen has been detected wagner 1991 but a rigorous uncertainty analysis is lacking this has been fully accepted in german and european practice dwa 2007 cen 2003 gas side depletion of oxygen from air bubbles has been shown to be a minor concern under common conditions baillod and brown 1983 jiang and stenstrom 2012 corroborating this approach in the interest of standardization and uncertainty quantification the difference should be quantified though experience speaks for at most a minor impact the above benchmarks are assumed in the following to justify the principle of the standard test method in the sense that when correctly applied see sections 2 and 3 it is able to yield a true quantity value as an average of many replicate tests 6 2 uncertainty budget cen 2003 state that the accuracy sotr and precision sae and specific sote is typically within 5 8 and 10 respectively with 5 percentage points added for variation due to sulfite distribution issues for large 3000 m3 rectangular tanks referring to the 1992 edition of asce 2007 and for loop reactors with da 0 25 in tanks with a homogeneous diffuser distribution only local k l a values within 5 of the average are kept dwa 2007 simply relay the former using the term measurement uncertainty asce 2007 give data acceptance criteria in terms of maximum 10 spatial variability and within 15 pointwise reproducibility for kla and refer to baillod et al 1986 who report 5 spatial variability of kla in a part of a study with 2 5 replicate tests in 7 different tanks the exception 15 was seen in a circular 3240 m3 tank with four low speed surface aerators and 5 54 m water depth it is noteworthy that asce 2007 claim applicability to limited mix tanks and require volume representative sampling and an increased number of probes if failing the spatial homogeneity criterion none of these standards requires an uncertainty estimate sotr acceptance criteria are given by dwa 2007 and asce 2007 the former states that the mean of repeat results plus the measurement uncertainty must meet or exceed the specified value the latter requires that the mean of at least three repeat results and the upper two thirds of the repeat results meet or exceed the specified value with no provision for tolerance assuming a normally distributed experimental scatter around the true quantity value with a standard deviation σ converging monte carlo simulations using 102 through 106 triplets show that the asce criteria shift the probability distribution for a pass by 0 13 σ from the specified value and to a standard deviation of 0 61 σ thus 58 of all test triplets obtained on an exactly compliant aeration system will fail and an aeration supplier is wise to oversize the system with 1 13 σ to pass the test with 95 confidence design uncertainty can be included in σ by summation of variances the generally accepted uncertainty quantification methodology jcgm 200 2012 is adopted here and the validity of the central limit theorem is not questioned for instance the confidence level coverage probability is 95 that the mean of an infinitely extended and perfected measurement series would result within 2 0 times the standard error or standard deviation of the mean equal to σ n of the mean of a statistical dataset if the set contains at least 60 data for instance fluctuations around the terminal do concentration can be quantified this way and monte carlo simulations are interpreted in similar terms instrument accuracy for a single measurement can be interpreted as 2 standard errors based on a sufficient calibration dataset this permits summation of variances to reduce the influence of random and systematic effects to a single uncertainty statement and carries over to data of less apparently statistical nature such as the geometric measurement of the liquid volume the linear dependence of uncertainty on base data uncertainty is recalled here jcgm 100 2008 assume any measurement datum c i is obtained with some relatively small uncertainty δc i set equal to two standard errors or according to best judgement the uncertainty in a derived quantity f c i is then 40 δ f i d f d c i δ c i and for several statistically independent parameters the variances accumulate 41 δ f i δ c i 2 d f d c i 2 considering the special case when f is just a product of parameters relative errors can be directly collected 42 δ f f δ l n f i δ c i c i 2 this holds true for eq 1 the uncertainty in sotr is thus 43 δ s o t r s o t r δ v v 2 δ k l a k l a 2 δ c s c s 2 the three factors in eq 1 have the following uncertainties application of eq 41 to the conventional assumed exact temperature correction of k l a 44 k l a 20 k l a θ 1 024 20 θ gives 45 δ k l a 20 δ k l a θ 1 024 20 θ 2 δ θ l n 1 024 k l a θ 2 where temperature uncertainty is composed of instrument uncertainty and test variability the uncertainty of the saturation concentration based on eq 39 with the fixed density ratio is 46 δ c s c s s t c s c a p a p s t δ c s c s 2 δ c a c a 2 1 c a c s 2 δ p a p a 2 the liquid volume value v directly influences the sotr value and must be as diligently handled as any other aspect of aeration testing a full calculation and uncertainty estimate based on the above principles should be performed with due attention paid to any object reducing the liquid volume for a given liquid height it has also been proposed to replace the geometric method with a tracer dilution test as an example of a geometric liquid volume uncertainty calculation assume a rectangular basin and filling depth with dimensions l w h eq 43 based on v l w h yields 47 δ v v δ l l 2 δ w w 2 δ h h 2 for sote sotr c g o2 q a 48 δ s o t e s o t e δ s o t r s o t r 2 δ c g o 2 c g o 2 2 δ q a q a 2 assuming that the composition of air c g o2 kg o2 nm3 is well defined its uncertainty term in eq 48 is omitted in practice the uncertainty of the air flow rate q a is a major concern in aeration testing and must be carefully estimated 6 3 uncertainty of parameters fitted to time series the uncertainty relations given in section 6 2 depend heavily on the uncertainties δ k l a and δ c s sampling control and estimation of these values using the monte carlo technique is addressed next which is also applied to tracer pulse train data the test data set m1 obtained on 2013 08 20 using the asce 2007 method and ysi model 58 do probes with thin membranes is used to illustrate these considerations it was taken with three up pumping surface aerators operating in a tank 43 1 m 15 5 m 3 85 m liquid height with seven probes distributed along the tank diagonal at one end there were small openings allowing the tank to communicate with an anoxic zone however the influence of this was not considered to be important at the time of testing the disagreement between a test data set c i and a model fit c t i is quantified as the relative root mean square error 49 δ 100 i c i c t i 2 i c i 2 100 1 r 2 where r 2 is the coefficient of correlation while this measure is typically dependent on the number of noisy data included and is unsuitable for data spanning several orders of magnitude it suffices as a measure of goodness of fit for this work as a prefix δ denotes the bias shift in an entity 6 3 1 reaeration data uncertainty 6 3 1 1 data range and density besides the importance of fitting test data to the correct model the range and density of test data must be chosen to resolve important curve features while addressed already e g brown 1978 this point merits further discussion in the light of uncertainties discussed in this work whereas asce 2007 propose fitting between 20 and 98 of saturation for absorption tests cen 2003 propose a lower data limit of at most 25 in the presence of an inflexion point the former permit an increase of the lower limit by a factor 1 5 to at most 30 asce 2007 require a time non uniform sampling if fewer than 21 data are taken dwa and cen require at least 30 explicitly or even 36 data cen as 3 5 times 10 intervals a summary of the ranges for nonlinear fitting is given in fig 16 it can even be motivated to use different data subsets and different models for different parameters in reasonably well mixed tanks for instance the late part of the reaeration curve is likely to follow the shape of eq 4 albeit with an exponential factor differing from the true k l a this provides the terminal value c using a simple fitting procedure while reducing the number of parameters to be fitted to a more complex model for the early part or the whole of the curve when applying an apparently incorrect model for want of better valid partial results may similarly be obtained the dependence of the exponential fit on the precise selection of fitting data is illustrated in figs 17 and 18 in fig 17 the low end truncation varies from 1 to 90 of saturation the normalized product c s k l a ef is shown but the major part of the variation stems from variation in κ ef the early variation is due to slow uptake and then variation is caused by the system departure from the ideal exponential model approaching saturation variation is instead mainly caused by fluctuations as illustrated by the exponential model with a normal 0 25 noise imposed this level was selected to mimic the fluctuations of the probe data see inset the variation of the incorrectly inferred transfer rate spans about two times 7 whereas a total sotr uncertainty of 5 is tolerated by dwa 2007 the inadequacy of the exponential model to fit the data manifests itself but the actual transfer rate remains unknown the common use of fast online do probes rather than taking bottled samples enables a high data capture rate in fig 18 the data density varies by keeping data at different strides but is always extended at a constant time rate between 20 and 98 of saturation for low data density asce 2007 requires a different distribution see fig 16 figs 17 and 18 imply that a large data density is required to reduce the uncertainty in e g sotr and that the effect of fluctuations must be avoided or quantified the data density may be reduced if data adhere closely to the selected model which requires the correct model to be applied and fluctuations to be small with present day do probes a data density of say 200 points between 5 and 98 of saturation should be feasible and should cover the need to keep errors down for most cases 6 3 1 2 fluctuation and lag effects the impact of the uncertainty of the individual do readings is hard to deduce when the values of k l a and c s are obtained by nonlinear regression assuming probe timing to be very accurate uncertainty in the do readings must be addressed the probe may have a stated uncertainty such as 1 of the measurement interval or maximum value and fluctuations may be present around the terminal concentration or curve end with some variance summation of variances translates these to some value of δc i c s using monte carlo simulation press et al 1992 jcgm 101 2008 the impact of this uncertainty on the uncertainty of the fitted parameters can be found do data sets corresponding to do curves were generated with different data density and random normal reading fluctuation superposed on the model statistics of nonlinear parameter fits were collected and summarized in simple correlations for eq 4 convergence in uncertainty to within 0 5 was found using 1000 data sets uncertainties for moderate σ 4 do reading uncertainties obtained using 1000 data sets turn out to be practically proportional to the reading standard error 50 δ k l a k l a 9 0 n 0 46 δ c i c s 51 δ c s c s 2 4 n 0 48 δ c i c s note that δc a should be estimated in a manner similar to δc s with a fixed moderate probe lag τ p 0 30 the same expressions hold for fitting to eq 31 the data range of 5 98 of saturation for absorption tests was used as well as 195 102 for desorption tests with 20 n 300 data separated in time by much less than t p may be regarded as independent when lag is included in the model or when lag mainly imposes a time shift if the value of t p must be fitted to account for delays due to e g mixing eq 31 may be used with success if eq 37 and 52 k l at p 10 δc i c s are fulfilled the former condition requires truncation taken here at 5 of saturation to keep probe lag catch up effects and the latter appeared empirically as a numerical condition for fluctuations not to quench the effect of lag applying these conditions to the same uncertainties but to a wider lag interval 0 30 τ p 0 90 adds further complexity for instance the fitted values may experience a mean shift in addition to the propagated uncertainty application of the monte carlo approach to the data for probe 1 of dataset m1 see inset of fig 17 is given here with a data summary in table 3 the fitted parameters obtained for eqs 4 and 31 columns 2 and 3 differ somewhat assuming an instrument uncertainty δc c s equal to 1 of the terminal concentration this should be 1 of the instrument range maximum and collecting the standard deviation given by fluctuations of the last 60 data points column 4 out of 446 points in total between 1 and 98 of saturation the root sum square of these values column 5 is used for monte carlo simulation more than 60 data points is often available at the flat part of the curve ensembles of 1000 and 1500 data series were produced using the data for eq 31 while eqs 50 51 were used for the exponential fit there was no significant difference in the result of the two ensemble sizes uncertainties obtained as statistics of fits of the parameters to these series in c s k l a and their product are given in columns 6 7 and 8 eq 4 has a final uncertainty column 8 of 0 6 but the inappropriateness of this model was not accounted for in the analysis the scatter in time of onset see fig 19 and in k l a values between the probes between 9 74 and 10 77 h 1 and the large misfit column 10 remain indicators of caution the end result of eq 31 has an uncertainty of 0 8 though with a smaller misfit than for eq 4 while eq 31 is not proven correct it better accounts for the slow mixing the fitted τ p is 3 times the real probe response time and the range of times of onset of the seven probes is 2 times the fitted value of τ p see fig 19 the model does not in detail explain the scatter in onset between the probes and it exhibits a large scatter in k l a between 10 10 and 13 14 h 1 conditions 37 and 52 were not fulfilled when data was cut off at 5 of saturation which illustrates a common dilemma mixing characterization by do curves alone is not very accurate dataset m1 was fitted to the exponential model with and without lag and for different data intervals from 1 5 and 20 to 98 of saturation see table 4 using more fitting parameters naturally produces a smaller misfit but the identified mixing time scale 2 5 min apparently plays an important role while keeping the lag to 0 or 13 s results remain fairly constant but introducing the mixing time scale k l a and sotr come out some 15 higher truncation made a greater impact when fitting t p as expected for three probes eq 37 had n between 5 and 10 when truncating at 20 and two probes were between 4 and 5 when truncating at 5 making the fit overdetermined discarding these brings the c s k l a product to 136 and 132 g m3 h respectively and the mixing time increases to about 200 s eq 52 was violated by three probes including probe 1 see above when truncating at 5 and one probe each for the other truncations causing a slight increase in the uncertainty whether lingering sodium sulfite influences the curves or not decaying oscillation of the residuals to either model and shifts in onset indicate a recirculation dispersion model is suitable an adequate definition potentially aided by cfd simulation and fitting of such a model for similar surface aerator systems remains to be done most likely a mixing test is required to enable accurate model settings 6 3 2 tracer pulse train data uncertainty for mixing characterization in loop reactors the recurring tracer pulse solution based on the lag free version of eq 33 voncken 1966 requires an uncertainty estimate as in the case of probe lag parameter space is hard to cover in a single figure but the following exercise can be repeated with a focus on the parameter range of each practical case ensembles of 700 data sets ensuring less than 0 5 variation in the resulting uncertainties of bo and f with 50 n 1000 data points per set were generated for 25 bo 95 and gaussian distributed data uncertainty up to σ 4 of the terminal concentration the complete third and fourth tracer pulses of the pulse train delimited by minima were fitted to the ideal pulse train equation with fewer than 200 data points large uncertainties occurred in particular for bo 25 the monotonic dependence of uncertainty on the number of data and bo value is shown in table 5 it should be noted that a shift δbo in the fitted bodenstein number is observed in addition to the uncertainties with 1000 data points at bo 95 the shift has practically vanished and the relative uncertainty in bo and f are reduced to fractions of δc c for this case the relative uncertainty in f is at most 0 029 times the relative uncertainty of c which is the maximum 4 the difference when moving from 2 to 4 base data uncertainty is striking for low values of bo the strong impact of the number of data points is expected but the pulse sharpness is another crucial factor this is reinforced by fig 20 where bo uncertainty is shown versus the two factors for a base data uncertainty of 1 and 2 the values in table 5 give guidance to the number of data points to use the common rate for many probes is 1 s and should be used to secure hundreds of points the probe uncertainty must be small and fluctuations observed during the constant phase before or after the pulse train should be quantified as for the do probes 7 conclusions the asce 2007 test standard appears intended to secure verification of an sotr value without a negative tolerance and most likely succeeds in this even for limited mix and loop reactors but at times with margins counted in tens of per cents the cen 2003 and dwa 2007 test standards on the other hand strive toward accuracy a low uncertainty in the measured sotr and at present abstain from including limited mix reactors except loop reactors the confusion arising when applying the former standard to such reactors while seeking a high accuracy as intended by the latter two for instance to avoid systematic over investment and subsequent operation at lower than intended efficiency could be partly resolved by observing the following and working toward a development of the present standards in the indicated directions 1 for limited mix aeration reactors 1 1 existing clean water test standard analysis based on absorption or desorption curves and intended for complete mix aeration reactors cannot be used to infer oxygen transfer rate to within commonly specified tolerances 1 2 averaging the apparent k l a values obtained by applying such test standard analysis to a large number of distributed probes does not produce a correct value of the global oxygen transfer rate it undershoots 1 3 averaging the do curves of a large number of distributed probes and subjecting the resulting curve to the analysis of such test standards likewise fails in producing a correct value of the mean global k l a it undershoots but not necessarily as badly as the individual probes 1 4 the concept of volumetric representativeness in a single reactor is not generally possible to apply in practice with today s models 1 5 sotr testing of aeration equipment installed in a tank laterally reduced in size such that the equipment effectively creates complete mix conditions likely gives a more accurate value of performance than in situ testing in a large reactor 1 6 the mixing characteristics of an aerated reactor influence the do curves and must hence be included in the analysis to obtain a correct sotr value 1 7 such mixing parameters must be obtained by careful testing do curves alone can rarely give accurate values of such parameters 1 8 for better relevance to process performance the sotr concept needs to be supplemented with a mixing performance characteristic this requires further research 1 9 the two zone model or the lagged exponential model can be used to highlight the potential undershoot of the exponential model 1 10 for loop reactors tracer recirculation tests should be used to enable a more suitable model such as the axial dispersion model to be fitted to test data when the damköhler number and aeration coverage conditions so require 1 11 previous claims that the exponential model and inert tracer technique are accurate for loop reactors are principally incorrect for low damköhler numbers and approaching uniform aerator distribution the sotr undershoot introduced by these methods can be moderate 1 12 for tapered aeration systems the uncertainty in test results caused by use of the exponential model has been estimated using a compartmental model for common parameters undershoot of down to 6 in k l a was found 2 probe lag can be accounted for in the analysis of the data curves under certain conditions probe lag mainly causes a time or phase shift and has a minor influence on data fitting 3 sulfite oxidation kinetics causes confusion and data corruption in particular at temperatures below 10 c increased cobalt catalyst concentration or switching to nitrogen or oxygen methods should be considered for such cold water 4 no theoretical estimate of the effective saturation depth is plausible without a detailed account of the mixing thus measured depth representative data should be used 5 a complementary method of establishing the effective standard oxygen saturation value for a test is proposed 6 existing clean water test standard analysis based on absorption or desorption curves should be subject to standard uncertainty analysis to quantify the uncertainty of the results 7 data sampling and model selection should be reconsidered in the light of uncertainty analysis including the effects of mixing probe lag and fluctuations besides the topics discussed above some additional topics have been identified and ventilated with the cen tc 165 wg 40 mainly in the spirit of harmonization simplification or clarification of existing standards these are listed here to inspire discussion in the aeration community 8 enabling the use of easily accessible water given the cost of potable quality water by relaxing conditions on test water quality and supplementing with alpha tests when e g treated effluent is used 9 correction of k l a test data to a standardized sodium sulfite tds value as suggested by asce 2007 1000 mg l 10 clarification that sae shall be based on the electric power of all aeration and mixing equipment required for operation 11 specification of probe instrument performance e g probe stability accuracy and response time without limitation to type of technology 12 optimization and unification between standards of do data density and collection and fitting ranges 13 development of the sulfite dumping method for loop reactors as sketched by asce 2007 and inclusion in other standards declaration of interest the author works for xylem www xylem com a supplier of equipment and solutions for the water cycle including aeration and mixing equipment the submitted work has been part of the author s assignment at xylem and thus fully funded by xylem acknowledgements dataset m1 was kindly provided by chris liu xylem the cfd simulation data was kindly provided by maximilian tomac and alexei loubenets xylem discussions with david redmon ian trillo andries visser yannick fayolle martin wagner maximilian schwarz jenny riit and extensively magnus fahlgren are gratefully acknowledged on tc 165 wg 40 of the cen discussions regarding the en 12255 15 aeration test standard with in particular markus roediger have been very rewarding chris fell suggested incorporation of tapered systems in the scope of work the referees have significantly contributed to the final form of this paper appendix a continuous flow two zone model the solution to the continuous mixing two zone model is related to the equation parameters by a 1 κ z a 1 p q 1 1 4 1 p p q 1 p q 2 2 1 p p a 2 κ z m 1 p q 1 1 4 1 p p q 1 p q 2 2 1 p p and inversely a 3 q κ z a κ z m 1 κ z a 1 κ z m κ z a κ z m κ z a κ z m 2 a 4 p 1 κ z a κ z m κ z a κ z m the limiting behaviors of the exponential rates are shown in table a 1 table a 1 tabele a 1 p 0 p 1 q 0 q κ za q 1 q 1 q 1 p 1 κ zm 1 q p q 1 p 1 p q p 1 p when p 1 or q κ zm rapid mixing between zones and κ za 1 recovering the complete mix solution for zone 1 and it is clear that κ za plays the role of oxygen transfer rate while κ zm is a mixing related rate expanding the solutions 11 and 12 and their volume weighted sum for small time τ the qualitative early behavior can be understood a 5 c 1 τ 1 e τ p q τ p 2 2 a 6 c 2 τ q p 1 p τ p 2 2 a 7 c τ p c 1 τ 1 p c 2 τ p 1 e τ p p q τ p 3 6 the first term of eqs a 5 and a 7 represents the isolated zone 1 complete mixing the parameter q and for zone 2 the volume ratio p 1 p introduce second order time effects the solution for zone 2 is second order in time with zero initial slope of the do curve because gas liquid mass transfer in zone 1 is followed by advection into zone 2 when q 0 all curves are distorted from a simple saturating exponential a source term accounting for the mass transfer driving force on liquid from zone 2 as well as on liquid mixed in zone 1 is a 8 s 1 1 p 1 q 1 c 1 q p 1 q 1 c 2 it keeps the system linear and second order with two rates with asymptotic behavior essentially but not exactly similar to that in table a 1 while it changes eqs a 5 and a 7 slightly the linear two zone model is clearly seen to retain its functional form 11 and 12 regardless of the detailed source setup the qualitative conclusions regarding the influence of both mixing and oxygen transfer time scales hold for this and similar two zone models 
18838,recent advancements in data driven process control and performance analysis could provide the wastewater treatment industry with an opportunity to reduce costs and improve operations however big data in wastewater treatment plants wwtp is widely underutilized due in part to a workforce that lacks background knowledge of data science required to fully analyze the unique characteristics of wwtp wastewater treatment processes exhibit nonlinear nonstationary autocorrelated and co correlated behavior that i is very difficult to model using first principals and ii must be considered when implementing data driven methods this review provides an overview of data driven methods of achieving fault detection variable prediction and advanced control of wwtp we present how big data has been used in the context of wwtp and much of the discussion can also be applied to water treatment due to the assumptions inherent in different data driven modeling approaches e g control charts statistical process control model predictive control neural networks transfer functions fuzzy logic not all methods are appropriate for every goal or every dataset practical guidance is given for matching a desired goal with a particular methodology along with considerations regarding the assumed data structure for further reading are provided and an overall analysis framework is presented graphical abstract image 1 keywords wastewater treatment big data statistical process control process optimization monitoring 1 introduction municipal wastewater treatment plants wwtp continuously monitor and collect data from unit processes but the data are often underutilized due to the size and complexity of datasets currently generated by wwtp and the lack of data science background for wwtp professionals it can be challenging to efficiently collect manage and analyze the data diebold 2003 kadiyala 2018 manyika et al 2011 regmi et al 2018 despite widespread interest in big data integration at wwtp most raw data are stored in their original format for potential future performance analyses with little consideration to their structure or the organization of the data repository to extract information from this data lake multiple factors need to be considered including the unique characteristics of wwtp data and the goals of an individual wwtp this review describes different data driven methods and how they can be used to address problems specific to wwtp while reviews exist for academic applications corominas et al 2018 hadjimichael et al 2016 olsson 2012 this review is from an applied perspective designed to demystify what methods should be used and under what circumstances if operations data were analyzed in real time with data driven tools wwtp could promptly detect and respond to process failures inefficiencies and abnormalities early correction of these wwtp faults could reduce i downtime ii effluent discharge violation and iii resource consumption such as energy chemicals and labor additional applications of big data to improve wwtp operation include data validation online monitoring of difficult to measure variables predictive maintenance golhar and dallas 2016 system and energy optimization and tailored water reuse i e producing water of distinct qualities for different reuse purposes big data integration at wwtp will have the most substantial impact on process control wwtp primarily use fixed upper and lower limits of process variables to monitor and control treatment processes these limits are adjusted based on a wwtp operator s background knowledge of the specific system as well as online and offline water quality data but rarely are more advanced methods of determining process limits i e modeling used in part this is due to the variability in the sensors that provide the data water quality is monitored in real time by online digital sensors that transmit a voltage or current corresponding to an electrochemical reaction or physical change inside the sensors as they interact with the environment e g constituent concentration flowrate pressure level to calibrate these sensors measurements using analog devices or laboratory analyses are correlated to voltage or current changes from the sensor however solids deposition biofilm formation and precipitates can interfere with the sensor s voltage or current change and thus with the sensor s measurement accuracy offline analyses to calibrate sensors and monitor process performance is performed either on or off site and the time required for each analysis can range from minutes to days depending on the laboratory equipment and available staff the resulting datasets often have missing values contain outliers and are sensitive to the interdependent nonlinear and nonstationary nature of wwtp data olsson et al 2005 rosen and lennox 2001 which makes wwtp difficult to model mathematically for the purpose of performing process control dürrenmatt and gujer 2012 consequently big data tools can provide an alternative approach see section 3 3 1 to address the unique features of wwtp processes and the resulting data wwtp need access to a labor pool of wwtp professionals with backgrounds in data science kadiyala 2018 sirkiä et al 2017 and need more practical guidance on full scale big data implementation us epa 2014 this paper serves as a wwtp engineer s guide to understanding the advantages and limitations of applying different data driven methods for process control and optimization we present how big data has been used in the context of wwtp and review the academic literature that describes state of the art methods of analyzing wwtp data for advanced control and process optimization noting that state of the art in wwtp does not reflect state of the art in the data sciences many more advanced methodologies have been developed but not yet tested in the wwtp context for further reading for each broad category of methods are given along with suggestions for methods that have promise for the water industry additionally much of this discussion can also be applied to water treatment section 2 provides the reader with an introduction to big data and data driven analysis wwtp and the prominent data characteristics of wwtp processes that may impact the results of data analysis section 3 follows with analytical methods to improve process control using examples of real wwtp for the purpose of fault detection variable prediction and advanced automated control fig 1 some methods listed in section 3 have multiple applications thus the full description is provided when the method is first presented section 4 concludes with lessons learned from this review of advanced data analysis at wwtp outlines the challenges facing modern wwtp as they integrate data driven solutions into their operations and identifies some existing methodologies that have not yet been tested with wwtp data 2 background 2 1 big data the term big data encompasses the modern overabundance of data produced by online and offline analysis and the innovative tools used to analyze the data big data can be broadly characterized by the 5 vs which are volume variety velocity veracity and value golhar and dallas 2016 laney 2001 slawecki et al 2016 volume is the physical storage size required to save collected data wwtp rarely monitor the total size of the collected data as storage is inexpensive relative to the operating budget of a facility variety refers to the different types of data collected including file type and data structure maintenance notes are considered unstructured but measured sensor values are structured because they have a quantifiable measurable significance and are stored in a separate database velocity is the rate of data storage and analysis in real time the computer processing speed i e velocity to monitor a wwtp needs to be sufficiently fast able to collect sort clean analyze and interpret data quickly and effectively veracity is the quality and trustworthiness of the data and can be considered a measure of uncertainty one data source in wwtp with questionable veracity is sensing technology even with regular maintenance and calibration sensor measurements drift over time and the drift may differ between sensors of the same model exposed to the same environmental conditions haimi et al 2013 olsson 2012 vanrolleghem and lee 2003 finally value is a subjective characterization of data quality referring to i the cost of data collection and storage relative to the value it produces and ii if analyses are performed to produce information from the data the two general steps for extracting information from industrial processes are data management and data analysis gandomi and haider 2015 labrinidis and jagadish 2012 broadly speaking data management includes the acquisition aggregation and cleaning of raw data to prepare it for analysis analysis may include modeling or advanced statistics to make inferences about the process and can provide site specific actionable knowledge in this paper we primarily discuss the second step approaches to data analysis for addressing problems in modern wwtp to maximize value in data driven analysis engineers need to engage with statisticians data scientists and computers scientists to develop industry specific tools for wwtp there are few data driven tools that are commercially available and most are designed as black box turnkey solutions with limited insight into computational details and causal factors given the nature of wwtp in which an operator receives information from multiple sources and makes an educated decision black box systems are frequently not trusted by wwtp generic data driven tools also exist but the average wwtp engineer lacks the background in data science to apply these tools to a complex system like wwtp in order to produce impactful and accurate results big data analyses need to be implemented with wwtp specific process knowledge and informed data characterization in the next section we provide a brief introduction to the types of processes in wwtp that are the focus of this paper 2 2 water wastewater treatment in the us wwtp receive raw wastewater from sanitary sewer networks and use multiple unit processes to remove contaminants until the water meets standards for discharge or reuse as regulated under the clean water act clean water act 1977 municipal wastewater treatment begins with physical treatment processes such as screening and grit trapping to remove large material and debris from the raw wastewater followed by biological treatment the most common method of biological wastewater treatment is the conventional activated sludge cas process aeration and recirculation of biologically active solids biosolids or solids maintain diverse communities of microorganisms in cas to degrade a wide range of organic compounds and nutrients clarification gravity settling separates treated water from the biosolids followed by disinfection and discharge to the environment depending on the initial quality of the water advanced treatment may also be required e g diffusive membrane technology or advanced oxidation processes to remove salts or contaminants of emerging concern e g pharmaceuticals personal care products synthetic organic compounds the quantity and quality of water and solids are measured from the headworks of a facility through the treatment train to the final discharge point fig 2 some variables are a general measure of the health of a system such as ph other variables are included in control loops with pumps valves and air blowers to optimize treatment such as dissolved oxygen do ammonia nh4 and nitrate no3 concentrations additional variables indicate the operating state of a system such as normal or peak operation in the event of unexpectedly high influent flow these variables are categorical and can be assigned surrogate numerical values such as 0 off and 1 on depending on whether a piece of equipment is in operation unit processes can be designed to treat a continuous flow e g disinfection plug flow basin or a batch e g sequencing batch reactor batch reactors have the additional variable of batch runtime as contaminant transformation is time dependent a non exhaustive list of wwtp variables that produce data of interest to process control are summarized in table 1 2 3 data considerations 2 3 1 structure data driven analytical methods are heavily dependent on the type of data collected it is important to understand the unique structure and characteristics of the data used to determine how the data are organized and utilized cormen et al 2009 data at wwtp are acquired from a variety of sources laboratory analysis online sensor measurements operations and maintenance management and customer and technology manufacturer information each source produces data that are structured differently and can include numerical sensor readings categorical on or off or unstructured notes variables differentiating between numerical or categorical variables is important for data driven analysis for example an operator may determine the amount of time during a batch cycle that an air blower is on or off which dictates what a normal do concentration in a reactor should be if a controller is used the speed of a blower can also be adjusted to meet a desired do concentration in this case there is also a distinction between a controlled variable air blower speed and a variable that responds to the control do concentration by measuring the effect of explanatory variables i e control variables or other covariates on response variables data driven methods can be developed to predict the outcome of a process however not all analyses differentiate between explanatory and response additionally not all explanatory variables directly or measurably affect a process output especially in a large process scheme like wwtp methods applied solely to explanatory variables are generally referred to as unsupervised meaning that the goal is simply to identify patterns in the data without any advance knowledge of the relationships being sought on the other hand supervised learning occurs when the observations are labelled by their response values and the goal is to characterize the link between the explanatory and response variables when a distinction between variable types is required it is mentioned in the first instance of the method in section 3 2 3 2 frequency and temporal variability wwtp data are collected at a variety of time intervals from continuous online sensor measurements to quarterly laboratory results for example wwtp monitoring is considered continuous if data are collected at 15 min intervals or less us epa 2015 but some effluent quality variables are measured only every few months such as disinfection byproducts traditional data management segregates data by source primarily due to the difficulty of merging data of different frequencies and formats a common mathematical approach to handle different data frequencies is to scale data to a single time interval odom et al 2018 however datasets with a very large difference in frequencies cannot use this method because wwtp data are time dependent co correlated i e the relationships among variables are related to one another and nonlinearly related making downscaling challenging effluent quality variables may change either suddenly or gradually over time table 2 and they often change nonlinearly in relation to other process variables which can make attributing the cause of change between sampling events difficult the monitoring frequency of the treatment process strongly depends on the goal of the analysis and the characteristics of the process venkatasubramanian 1995 in process control the data collection frequency should be sufficiently high to account for instrument noise and to track typical irregularities but not so frequent that excessive computational power is required for full analysis short term faults like a clog in a pipe that can occur on the order of minutes to hours require a different monitoring window of time than long term faults like an increase in transmembrane pressure due to biological fouling of a membrane that occurs on the order of days to weeks table 2 dürrenmatt and gujer 2012 recommend a window width of at least three times the length of time over which the fault occurs to be detected 2 3 3 variable characteristics many wwtp process variables exhibit unique characteristics such as time dependence and nonstationarity e g the strong diurnal and seasonal swings of ambient temperature but conventional control strategies rarely account for such relationships that need to be considered for data driven fault detection variable prediction or automated control stationary variables have constant mean variance and covariances making them predictable and more easily modeled conversely the means and or variances of nonstationary variables change over time if a variable s measurements are correlated from one time step to the next the variable is said to be dependent over time wwtp data exhibit these properties because of the dynamic nature of wwtp processes fig 3 a constantly changing influent batch as opposed to continuous processes temperature internal shifts in microbial ecology and process control instability are a few causes of the nonstationarity and temporal dependence many statistical methods assume data are normally distributed a normal distribution is symmetric unimodal and bell shaped and is characterized by two statistical parameters its mean and variance the multivariate case is additionally characterized by its covariances i e the variance between each pair of variables when the data are normally distributed exact inferences can be made about the mean variance and covariances e g confidence intervals predictions or hypothesis tests because the distribution of the test statistics adhere to proven mathematical theories when the assumption of normality is not met it is more difficult to identify the distribution of the statistic without making assumptions about the data s distribution the uncertainty in the estimate of interest cannot be accurately inferred the assumption of normality does not typically hold in wwtp due to boundary limits of variables i e sensor operating range process variation and outliers in the event of a hardware malfunction a contaminated lab sample or a data entry error observations may be missing or abnormal compromising normality analysis power and reliability of results kwak and kim 2017 each error can potentially bias features that are of interest to model and the removal or correction of erroneous values i e data cleaning should be a high priority prior to data analysis to limit incorrect conclusions haimi et al 2013 kadlec et al 2009 particular attention needs to be paid to how a data driven methodology is implemented in the event that nonlinear and nonstationary behavior is detected there are two approaches for modeling nonstationary behavior accounting for a known or predictable underlying trend or limiting the window of time over which a model is trained given the difficulty in modeling nonstationary behavior in wwtp fig 3 relatively short windows of time e g 3 to 10 days may be the best option to achieve approximate stationary and normal behavior in addition to simple modifications of existing methods e g using short training windows distribution free statistical methods such as kernel density estimation kde and bootstrapping can be applied kde estimates a distribution using local smoothing allowing practitioners to work around the normality assumption however kde is very sensitive to the choice of tuning parameters izenman 2013 conversely bootstrapping does not require any tuning parameters but is more computationally demanding from a dataset observations are randomly drawn with replacement the statistic of interest is computed and then these two steps are repeated many times to produce a distribution of the statistic efron and tibshirani 1994 james et al 2013 provide a simple introduction to the bootstrap method 2 4 exploratory data analysis identifying the structure and characteristics of a dataset requires familiarity with the source of the data and the process itself plotting and visualizing data should be the first step in any analysis but no one size fits all approach exists observations recorded over time can be visualized in time series plots fig 3 the strength of the temporal dependence can be assessed with autocorrelation function plots potential outliers can be observed in boxplots and the entire distribution can be plotted in a histogram these plots work well for monitoring a single variable but wwtp are often interested in the relationships among multiple variables pairwise scatterplots multiple boxplots functional boxplots and cross correlation function plots are just a few ways additional features can be assessed examples of some of these plots can be found in pfluger et al 2018 there are many tests available to assess multivariate normality including the mardia test henze zirkler test royston test doornik hansen test and the e statistic korkmaz et al 2014 unsupervised learning methods for clustering or outlier detection are commonly used to identify structure in the data james et al 2013 manual data inspection can be time intensive so the inclusion of more advanced statistical tools can provide rapid insight into the data characteristics 3 methods examples in this section we present the current use of process data in wwtp and a review of recent academic literature demonstrating the possibilities for advanced data driven process control in wwtp the focus of this review is on control methods that have been tested on actual wwtp systems to provide practitioners with realistic examples simulation studies serve a valuable purpose but do not always represent the wwtp process realistically due to simplifying assumptions about data characteristics and the processes corominas et al 2018 primarily data driven analysis in wwtp can be used for fault detection variable prediction and automated control each requires a different and increasingly complex data processing analysis and control framework the data driven methods are therefore discussed in the context of the goal of each process control application fault detection variable prediction or advanced control we begin with a brief review of historical methods of process control in wwtp 3 1 historical process control data driven process control has historically been sparse in wwtp with daily operational decisions considered more of an art than a science metcalf and eddy 2013 o day 2004 as early as the 1920s statistical tools like histograms and control charts were used for informal diagnostics control during this time relied on manual adjustments and observations as digital control was not an option prior to the 1960s the cost of computers and instrumentation was high treatment dynamics were not well understood facilities were not designed with additional flexibility and control theory was not sufficiently developed olsson 2012 in the 1980s affordable computing power facilitated simple first principle models although their complexity and lack of reliability made them poor advisory systems olsson et al 1998 by the early 2000s the digital revolution reached wwtp and most wwtp had integrated their own version of direct digital control into process monitoring in the form of programmable logic controllers plc and supervisory control and data acquisition scada systems despite the unique challenges posed by wwtp data data driven system automation and real time control are integral to modern wwtp operation the most common process control practice is to maintain a set point i e target value using online sensor readings and feedback control for example do concentrations can be controlled by adjusting air blower speed i e aeration intensity rather than operating at a single blower speed online measurements provide feedback to the scada system that determines whether blower speed should increase decrease or stay constant relative to a measured value like do concentration chemical dosing to enhance contaminant precipitation and additional carbon for biological processes are other examples of feedback control based on in situ nutrient concentrations this method of process control is commonly achieved by a controller with a variable frequency drive to change operating conditions in a continuous smooth and automated manner establishing target values for process variables is one of the simplest methods of control and is a widespread practice in wwtp this single variable monitoring paradigm is the foundation for fault detection at most modern wwtp in which a measured value is either within or outside of an operator specified range while this approach has a low false alarm rate e g if a flow rate measurement is below a set point a fault of unknown cause has certainly occurred somewhere in the system that affects flow rate it can be very slow to detect faults does not forecast future values and does not account for correlations among variables plant operators must be available to respond quickly to a system fault to prevent equipment damage or system failure putting additional stress on equipment and staff to reduce a fault s impact on effluent water quality proactive and comprehensive approaches to fault detection and forecasting are being developed capizzi and masarotto 2017 jiang et al 2012 kazor et al 2016 odom et al 2018 wang and jiang 2009 which could help reduce cost and improve efficiency of wwtp systems some data driven fault detection methods are currently being implemented and the results are discussed in the next section 3 2 fault detection a multitude of system faults or changes in conditions can cause process irregularities in wwtp these include a change in influent quality e g snowmelt industrial discharge an outbreak of microorganisms that inhibit treatment e g filamentous bacteria algae irregularities or damage to treatment units e g membranes clarifiers mechanical failures e g pumps air blowers or sensor failure e g drift bias electrical interference each type of fault can alter system performance differently and it is important to consider the versatility of an analytical approach i e which types of faults can be detected when designing a fault detection program for example if a sensor failure occurs and the sensor s measurements are included in a control loop many variables could be affected in contrast if the sensor s measurements are not included in a control loop a sensor fault may only affect the measured sensor variable a fault is an unintentional deviation of a process characteristic that limits the process ability to achieve its purpose isermann 1984 typical single variable faults that occur in wwtp are easier to diagnose qualitatively and are illustrated in table 3 however multivariate faults can be much more difficult to discern visually to detect faults in the dynamic nonstationary multivariate data found in wwtp a quantitative approach such as statistical process control spc is needed in spc a fault is identified when a consecutive series of observations are flagged as abnormal olsson and newell 1999 suggested data collection frequency be chosen to be at least one fifth of the length of time over which the event of interest occurs the distinction between normal in control or ic and abnormal out of control or oc observations is determined by a statistical hypothesis test hypothesis tests are used to quantify the likelihood that an individual observation from a dataset is consistent with observations collected under ic conditions ic observations are usually used to train an spc model which is a type of supervised learning because the initial data are known to be ic many spc methods exist but few have been implemented in wwtp the following is a discussion of different spc methods used in wwtp to determine if a significant change or fault has occurred 3 2 1 control charts control charts are useful tools to determine at a glance if a process is ic the most popular statistical control chart was outlined by walter shewhart of bell labs the shewhart control chart uses upper and lower control limits ucl and lcl for a process variable or statistic by adding or subtracting k standard deviations from the variable s mean with k 3 being the industry standard nist sematech 2003 shewhart 1926 if an observation is above the ucl or conversely below the lcl a statistically significant change has most likely occurred shewhart control charts employed at wwtp are typically constructed with a 3 or 5 day arithmetic moving average for variables designed to be stationary such as solids retention time srt in a bioreactor or percent water recovery of a membrane treatment unit additionally control charts can be used in wwtp analytical labs for quality control e g a sensor s measurements of a standard solution over time rice et al 2017 or other variables that change slowly table 2 however the shewhart method of calculating control limits is only valid for a variable that is normally distributed and whose observations are independent and stationary montgomery 2009 updating the ucl and lcl to adapt to changing conditions using methods such as exponentially weighted moving average ewma can account for some nonstationarity found in wwtp data wold 1994 the shewhart control chart assumes the process is stationary and weighs all past observations equally ignoring trends montgomery 2009 the ewma gives more weight to the most recent observations adapting to some process variation nist sematech 2003 and is frequently used as a data smoothing technique berthouex and box 1996 mina and verde 2007 the ewma accounts for both the most recent observation and past behavior by multiplying the most recent observation by a forgetting factor 0 05 λ 0 25 and the geometric moving average by 1 λ hunter 1986 montgomery 2009 roberts 1959 however the ewma is not a good measure to distinguish between ic and oc for every wwtp process like many data driven performance monitoring methods the ewma control limits are heavily impacted by outliers rosen et al 2003 in both panels of fig 4 the assimilation of oc observations immediately widens the range of values that are considered ic thus control chart limits should only be updated with ic observations as explored by corominas et al 2011 additionally some sensors have a lower operating limit which invalidates the standard ewma lcl fig 4a in this case a turbidity sensor outputs a current between 4 and 20 ma which is converted to turbidity units ntus using a calibrated linear regression here 4 ma correlates to 0 04 ntu when the turbidity is below this threshold the sensor continues to output 4 ma which truncates the distribution of the turbidity data and invalidates the lcl for small datasets e g fewer than two variables in the case of flow and pressure of a water distribution system univariate ewma has shown to be better at detecting faults than multivariate ewma mewma jung et al 2013 however most wwtp process variables violate the assumptions required for the shewhart s or the ewma control chart berthouex 1989 resulting in a high percentage of false alarms making them poor choices for fault detection for larger datasets e g monitoring more than 2 process variables multivariate control charts can reduce a complicated dataset to a single measurement reflecting the health of the wwtp monitoring multivariate processes as opposed to individual variable monitoring with a control chart method may provide wwtp operators with a better sense of the overall state of operating conditions schraa et al 2006 multivariate process statistics such as mewma lowry et al 1992 multivariate cumulative sum mcusum crosier 1988 and hotelling s t 2 hotelling 1947 can be used to examine the mean and dispersion of multiple variables but have rarely been implemented in industrial process monitoring due to the complex matrix algebra required nist sematech 2003 mewma and mcusum have been shown to be good at detecting small changes in the mean compared to hotelling s t 2 but can have a high false alarm rate alves et al 2013 however the assumption of multivariate normality is also required for these methods and as mentioned previously this is rarely observed in wwtp a nonparametric approach such as bootstrapping may yield better results for a multivariate control chart in wwtp phaladiganon et al 2011 3 2 2 principal component analysis a widely used statistical method for monitoring multiple variables simultaneously is to capture the relationships among linear combinations of variables rather than the variables themselves by principal component analysis pca jackson 1991 pca identifies independent linear combinations of variables principal components or pcs by effectively calculating lines of best fit through a dataset wise and gallagher 1996 pcs account for as much variation as possible given the assumption of linearity and can therefore reduce the number of model variables and eliminate noise and redundancy for example unsupervised pca is frequently used to reduce the number of predictor input variables for multiple regression models discussed further in section 3 3 3 wallace et al 2016 wang et al 2017 and can be used to identify clusters of related microbiological sample properties jałowiecki et al 2016 to use pca for supervised data driven analysis a training dataset that represents ic conditions is used to calculate the pc then testing data are transformed into the model subspace defined by the pc if the overall distance from a new observation to the pca model is above a desired control limit similar to the control chart methodology described above then the new observation is considered abnormal and is a possible indication of a process fault the benefit of performing pca prior to calculating the control statistic e g squared prediction error spe hotelling s t 2 etc is the reduction in false alarms due to the reduction in noise and removal of dependence among the features pca has many applications in wwtp from direct fault detection king et al 2006 to data reconstruction lee et al 2006a schraa et al 2006 for dynamic wwtp data variations of pca are often used with adaptive pca being the most common baggiani and marsili libelli 2009 kazor et al 2016 lee and vanrolleghem 2004 rosen and lennox 2001 adaptive pca updates the model based on a rolling window of training observations the training window is set to n observations and as time passes the oldest observations are removed from the training dataset and new observations are added to maintain a constant number of observations the rolling training window can thereby account for temporal nonstationarity found in wwtp i e conditions that change over time however if the training window is too large faults could be ignored baggiani and marsili libelli 2009 if the training window is too small normal observations could be flagged as faults rosen and lennox 2001 given the type of process changes that a wwtp needs to detect exploratory data analysis section 2 4 should be used to identify the shortest training window that achieves the desired true detection rate some argue that the underlying correlation structure should not change with time and therefore the rolling window concept defeats the purpose of pca mina and verde 2007 this assumption may be valid for simulated wwtp data but is unlikely for real wwtp data and is demonstrated by the improved performance of adaptive pca as opposed to conventional pca kazor et al 2016 dynamic pca is another common modification to pca for fault detection in wwtp lee et al 2006a lee et al 2006b mina and verde 2007 the dynamic extension accounts for autocorrelation among variables by lagging observations i e shifting a dataset back by a given timestep and including the lagged values as new variables kruger et al 2004 ku et al 1995 for most wwtp applications a lag of a single timestep is sufficient to account for how previous conditions affect current performance however if the process is cyclical i e processes occur as a function of runtime and the system returns to its initial state by the end of the cycle then the lag should be the size of the cycle itself kazor et al 2016 cyclical i e batch operations may also require a unique modification called multiway analysis smilde et al 2005 multiway pca unfolds a dataset indexed in three dimensions e g cycle runtime batch monitored variables to a long two dimensional array by combining two of the three dimensions e g cycle runtime and monitored variables that can be analyzed with traditional spc methods like pca fig 5 lee and vanrolleghem 2004 macgregor et al 1994 macgregor and kourti 1995 nomikos and macgregor 1994 yoo et al 2004 in wwtp this approach is particularly useful for sequencing batch reactors sbr villez 2007 the new two dimensional dataset can account for variability in the monitored variables across batches and variables measured at different temporal frequencies the major drawback of pca and many other spc methods like partial least squares for wwtp is the assumption that process variables are linearly related to each other to account for the nonlinear components of wwtp data can first be mapped into a higher dimensional nonlinear space where observations are more likely to be linear haykin 1999 one such nonlinear pca method is kernel pca kpca kernel methods avoid computationally intensive nonlinear optimization and different nonlinearities can be captured using different kernel functions popular kernels are the polynomial gaussian and sigmoid but the most commonly used is the gaussian because its associated parameter provides precise tuning of the model fit izenman 2013 nguyen and golinval 2010 kpca has shown slightly better performance in simulated wwtp lee et al 2004 xiao et al 2017 however kazor et al 2016 found limited improvement in kpca over pca for fault detection in a decentralized wwtp and lee et al 2006c saw similar limited improvement for the performance of anaerobic filters 3 2 3 partial least squares similar to pca partial least squares pls identifies independent linear combinations of the measured variables and outliers can be identified with t 2 and spe statistics chen et al 2016 unlike pca pls differentiates between input variables e g initial water quality operational information and output variables e g effluent water quality and performs dimension reduction on each set of variables separately hoskuldsson 1996 pls is an example of supervised dimension reduction pls only monitors output variables that are affected by the input variables whereas pca is used to monitor all variables in the process simultaneously if an observation is abnormal but does not impact the final water quality pls will not flag the process as oc but pca will chiang et al 2001 nomikos and macgregor 1995 hence pls is more frequently used in variable prediction than in fault detection in complex systems fault detection may improve by dividing the process into units multiblock pls mb pls subsets input variables into logical subsystems e g primary sedimentation aeration basin prior to analysis wangen and kowalski 1989 experimentally mb pls does not improve prediction compared to the standard pls however the results may be easier to interpret for fault diagnosis choi and lee 2005 3 2 4 neural networks conventional mechanistic models use complex formulas that are connected in mathematically simple ways i e mass balance formulations to describe the sum of all unit processes in contrast neural networks nn use simple mathematical expressions that have complex relationships in which process inputs are nonlinearly linked to outputs without prior knowledge of an underlying mechanism dreyfus 2005 nielsen 2015 olsson and newell 1999 process inputs and outputs are connected by neurons that are organized in layers fig 6 a neuron in the input layer distributes an actual process input variable to neurons in the first hidden layer neurons in a hidden layer normalize and weigh multiple inputs transform the value with an activation function and produce a normalized output signal nn can have one or multiple hidden layers connected by input transformations and output signals the output layer is a weighted sum of the final hidden layer s output signal in contrast to linear statistical models e g multiple regression pca pls nn model parameters do not have the same interpretability i e no physical chemical or biological significance to identify the parameters of each neuron in a nn model learning algorithms are needed due to the extensive intricacies of the different learning algorithms for nn development this paper will focus on the two types of nn training supervised or unsupervised supervised training requires data to be labelled in such a way that inputs and outputs are defined there are many different learning algorithms for fitting a supervised nn and each requires an iterative process in which parameters are estimated based on a large historical dataset dreyfus 2005 one of the most common is the back propagation learning algorithm that starts by randomly assigning parameter values calculating an estimated output and minimizing the error between the estimated and the actual output node by node and layer by layer starting with the hidden layer directly connected to the output hundreds of iterations must be performed to determine the best network for a particular dataset requiring a substantial amount of computing power wei 2013 hence it is valuable to minimize the number of variables used to construct the model unsupervised training of a nn uses data that are unlabeled i e the model is supplied with defined inputs but no outputs and uses fundamentally different learning algorithms than the error correction method in supervised training unsupervised nn act best as classifiers for pattern recognition in fault detection unsupervised nn can be trained to model a process by estimating the values of inputs and comparing the estimation to the actual values also known as an auto encoder nn ann xiao et al 2017 used anns with bottleneck layers i e the middle hidden layer contains fewer nodes than the preceding or succeeding layers which force the nn to effectively capture the principal components of the data to detect faults at a wwtp spe was calculated from the difference between actual and estimated values and similar to pca an spe threshold was calculated to determine if the process was ic or oc xiao et al 2017 concluded that ann based fault detection was more sensitive to changes than conventional pca additionally xiao et al 2017 compared deep and shallow ann until recently training nn with many layers and nodes deep nn was not computationally efficient hinton et al 2006 however shallow nn are generally unable to capture highly nonlinear systems in this case there was no conclusive evidence that the deep ann performed better than the shallow ann 3 3 variable prediction spc can be used to assess if a system is ic or oc but this is a generic measure of product water quality and system health to predict what a variable value should be under given conditions model based control could be used model predictive control mpc compares mechanistic model predictions to actual process measurements then deviations from the model are identified as faults the model can be derived from theory i e fluid dynamics microbial kinetics or empirical trends i e data driven and can be used to approximate additional process variables in lieu of directly monitoring the variable of interest a link may be found among variables in this way a software sensor or soft sensor also referred to as inferential sensors virtual online analyzers or observer based sensors can be developed for the online monitoring of variables that are too time consuming or expensive to consistently monitor with lab based analyses chéruy 1997 kadlec et al 2009 many different approaches to variable prediction have been proposed and here we review the most commonly observed in literature 3 3 1 activated sludge models some water quality variables can be adequately predicted with calibrated first principal models the activated sludge model no 1 asm1 is the most widely used deterministic model for biological carbon and nitrogen removal in wwtp henze et al 1987 asm1 was developed in 1985 by compiling novel research about the kinetic behavior and mechanisms of the cas process subsequent cas models e g asm2 and asm2d have additional parameters that account for fermentation enhanced biological phosphorus removal and chemical phosphorus removal gujer et al 1999 henze et al 1999 1995 models based on first principals also exist for clarifiers settlers but due to a lack of a mathematical relationship between floc characteristics and settleability they are still limited to process design and research purposes metcalf and eddy 2013 olsson 2012 uncertainty in the model inputs and the simplified mathematical framework fundamentally limits the accuracy of the model however in many cases pilot or full scale calibration can account for some of the error in the asm metcalf and eddy 2013 additional sources of error are model parameter estimates not all unit processes share a common set of state variables i e variables that indicate the operating conditions of a process as opposed to variables that measure a constituent in the water and linking models with variable estimates can lead to substantial error in the plant wide model volcke et al 2006 for example asm and secondary clarifier models are frequently coupled but the models differ in how total suspended solids tss concentration is calculated and incorporated without calibration and only parameter estimates the asm may produce results that are only accurate within an order of magnitude illustrating the variability of wwtp gujer 2011 olsson and newell 1999 considered other sources of error for model predictions including inaccurate or incorrect calibration non ideal process behavior and lump sum parameter assumptions for these reasons mpc with the asm is rarely used in full scale biological wwtp operations for variable prediction or fault detection to standardize control strategy testing at biological wwtp a simulation benchmark was developed from the asm1 henze et al 1987 under eu cost actions 682 and 624 alex et al 1999 jeppsson and pons 2004 spanjers et al 1998 the benchmark simulation model no 1 bsm1 includes a mathematical model of a five reactor cas treatment system followed by a clarifier fig 2 asm specific parameters from literature and simulated influent datasets for different weather events copp 2002 the newest version bsm2 incorporates extensions proposed in recent literature a longer simulation study timeframe inclusion of temporally dynamic parameters and more realistic sensor behavior and failure jeppsson et al 2007 nopens et al 2010 rosen et al 2004 there are hundreds of proposed control strategies for the bsm but simulation benchmarks do not yet exist for all common wastewater treatment technologies while simulation studies are important to understand the potential behaviors of control strategies the actual dynamics of a wwtp are nearly impossible to reproduce artificially this is most evident when control strategies perform well on bsm but cannot be replicated with real wwtp data sin et al 2006 oppong et al 2013 compared simulated datasets from the bsm models to real industrial wwtp data using anaerobic digestion in an attempt to develop a soft sensor however the variable of interest volatile solids concentration had substantially different co correlation structure both in magnitude and direction among the simulated and actual process variables the difference was attributed to infrequent sampling and a stable process with little change but it is also possible that the bsm is inadequate for mpc in this case 3 3 2 transfer function models transfer function models are a general class of models that describe the relationship between an input and output of a linear system using a mathematical function when the system is not too complex i e the number of output parameters is 2 transfer functions can be a good approximation for dynamic systems box et al 1994 univariate autoregressive integrated moving average arima models are a special case of transfer function models that do not depend on the input variables and are widely used for linear time series forecasting chen et al 2007 the autoregressive ar portion predicts values that are mathematically related to the previous time step s i e lag the moving average ma predicts values that are mathematically related to the error of the past time steps the integrated i portion of the arima model indicates that the difference between observations one or more is modeled instead of the observation itself and this step can remove some of the nonstationarity present in the data the primary application of arima models in wwtp is to predict an effluent variable park and koo 2015 showed that an arima model can be used to predict effluent turbidity of a sedimentation basin berthouex and box 1996 and west et al 2002 successfully used an arima model to predict effluent 5 day biochemical oxygen demand bod5 of a wwtp however the arima model s integration step is often insufficient to account for wwtp data nonstationarity in the long term west et al 2002 as the prediction horizon increases the accuracy of arima models declines substantially unable to account for nonlinear behavior in wwtp dellana and west 2009 3 3 3 multiple regression multiple regression is an extension of a simple linear regression using multiple independent variables x i i 1 2 k to model a single dependent variable y via y β 0 β 1 x 1 β k x k e the model parameters are commonly estimated by ordinary least squares and more information about multiple regression model fitting can be found in sheather 2009 when all independent variables are standardized i e zero mean and unit variance the strength of an input variable s impact on the output variable is directly proportional to the magnitude of βi giving tangible meaning to the model parameters categorical information can also be integrated by the use of dummy variables d i i 1 2 k which take on binary values e g if a blower is on then d i 1 if off then d i 0 however problems can arise when fitting a multiple regression model if the explanatory variables are exactly linearly related multicollinearity are highly variable or are autocorrelated miah 2016 as in wwtp ebrahimi et al 2017 used multiple regression models to predict various water quality variables like phosphorus nitrogen and tss concentrations in a full scale wastewater treatment plant with reasonable results r2 0 71 0 87 meaning the model explains 71 87 of total variation in the dependent variable but they did not demonstrate sufficient accuracy for stand alone fault detection however multiple regression techniques may have applications in soft sensor and empirical model development pls regression is a combination of pls and multiple regression and can be used to predict the output variables from the input abdi 2003 because of this property pls is commonly used for industrial soft sensors and water quality variables in wwtp such as chemical oxygen demand cod tss nitrate and oil and grease concentrations langergraber et al 2003 qin et al 2012 the use of nonlinear mapping with pls kernel pls or kpls also shows promise for methane production from a full scale anaerobic filter lee et al 2006c and cod total nitrogen and cyanide concentration in cas woo et al 2009 in these cases kpls performed better than conventional pls which demonstrates the importance of accounting for nonlinearities for some data driven applications 3 3 4 neural networks supervised nn have been used to predict raw wastewater flow from online rainfall data and historical influent data wei 2013 yang et al 2008 reconstructed cod concentration from uv 254 and ph measurements using a back propagation nn ömer faruk 2009 used a hybrid nn arima to predict boron and do concentrations and water temperature of a river over time while the arima model performed very poorly r2 0 23 0 55 the hybrid model performed only slightly better r2 0 79 0 83 than the nn model r2 0 77 0 81 nn arima hybridization has been a popular research topic because in theory both linear and nonlinear behavior could be described with the resulting model venkatasubramanian 1995 however few case studies exist that demonstrate a significant improvement of a hybrid model over a nn model chen et al 2007 a nn hybrid model was successfully used by lee et al 2008 to predict cod total nitrogen and total phosphorus concentrations in the effluent of small cas wwtp from conductivity temperature ph do oxidation reduction potential orp and turbidity input and output variables were lagged to account for dynamic process variation combined with a transfer function model auto regressive representations with exogenous inputs or arx lee et al s 2008 approach showed good results for variable prediction r2 0 92 0 95 and is promising for soft sensor development lee et al 2002 also used a hybrid nn structure for prediction of wwtp effluent quality in principle the hybridization of mechanistic and nn models bridges the gap between first principal and statistical approaches the nn was placed in parallel and in series with the asm1 model to estimate the model error or input parameters respectively the parallel hybrid nn model performed well at predicting effluent variables e g cyanide r2 0 93 0 96 but the series hybrid nn model did not perform better than the nn alone indicating that there exists some error for which the asm1 model itself does not account models to determine sorption kinetics and the capacity of carbon to adsorb contaminants can also be mapped by nn vasanth kumar et al 2008 trained an nn model with batch experimental data under various conditions to predict equilibrium concentrations after the uptake of dye by powdered activated carbon pac the resulting predictions were nearly perfect r2 0 96 however hundreds of data points were needed to calibrate the model prior to the predictions there was not significant variation among the input variables only a single contaminant was used and separate testing data was not used to verify results given the complexity of biological treatment modeling generating a carbon adsorption isotherm for pac treatment is very well understood computationally straightforward and accurate for design purposes unless nn can demonstrate the ability to account for large variations in initial water quality of which the current isotherm paradigm cannot use of the traditional adsorption isotherm models will continue to be used a potential application that has not yet been explored is for the generation of isotherm models for micropollutants e g per and polyfluoroalkyl substances in the presence of bulk organic carbon 3 4 advanced control the goal of wwtp optimization is to achieve the desired effluent quality with fewer inputs i e chemicals energy manpower future wwtp will also need to be able to adjust their effluent quality to meet new demands without risk of disturbance as water resources dwindle and demand increases in urban centers customizable water quality based on need and time of year known as tailored water has become an attractive option vuono et al 2013 using historical data and system knowledge a function can be developed to minimize cost or energy while maintaining effluent quality in order to identify the best set of setpoints and control decisions this is a fundamentally different approach than heuristically adjusting variable setpoints and observing the system s response various methods to achieve data driven control advanced or automated control are discussed in this section however advanced control is still in its infancy for wwtp and few full scale demonstrations or installations exist 3 4 1 model predictive control mpc uses a mechanistic model of a process to predict a process variable accounting for the physical constraints of a system s actual process variable measurements richalet et al 1978 the model predicts future process behavior over a time interval known as the prediction horizon and predictions are compared to online measurements to determine if a change has occurred fig 7 mpc is less common in wwtp because most individual wwtp processes especially biological processes are too complex to develop sufficiently accurate first principal models section 3 3 1 for advanced control purposes due to their deviation from ideal steady state conditions patton et al 2000 furthermore the computing power required to handle the nonlinearities has not been well documented mpc in wwtp takes on many forms but all must address wwtp data s nonlinear behavior nonlinear models are computationally intensive to solve and accounting for too many nonlinearities can substantially slow a controller s response a less computationally intensive option is to use piecewise linear mpc in which multiple linear models approximate a nonlinear model ocampo martinez 2010 olsson and newell 1999 another method is to update or adapt linear model parameters to fit current operating conditions zhang and zhang 2006 adaptive mpc controllers have been shown to perform better than conventional pid controllers for nonlinear processes however strong nonlinearities are still better handled by alternative control approaches such as nn hermansson and syafiie 2015 mpc has been implemented for dynamically simplistic wwtp unit processes such as membrane based treatment that can be controlled by a single variable membrane systems can be easily modeled using known relationships of fluid flow mass transfer and thermodynamics bartman et al 2009 derived such a model to control a valve on a pilot scale reverse osmosis ro membrane treatment system the reject concentrate flowrate was controlled by the dynamic nonlinear lumped parameter model and was validated with experimental data in general the system performed better when controlled by the dynamic model as opposed to a traditional controller not all wwtp unit processes are fit for mpc simply because accurate analytical models do not yet exist and the number of possible inputs makes real time control computationally unreasonable attempts have been made in the literature to adapt mpc for wwtp including cas and membrane systems but more research is needed to develop realistic and system specific models before mpc can be implemented as a control strategy in full scale wwtp alternatively non deterministic nonlinear data driven models are an option for mpc of activated sludge systems i e nn 3 4 2 neural networks as discussed in section 3 3 4 each parameter and layer in an nn model adds an additional degree of flexibility that can address the problem of nonlinear model fitting however a large number of nn model parameters can risk overfitting to noise in the data rather than the process itself and can unnecessarily increase computation the computational power required to use an nn model for control applications is not well documented and most studies in wwtp literature utilize only a few water quality variables to predict a single value i e soft sensor development the availability of reliable and plentiful online sensor data can also be a major constraint more research is needed with constructing larger wwtp nn before the practicality of nn control strategies in wwtp can be assessed to begin wwtp nn model development should be performed incrementally so that an unexpected and unmanageable amount of computational power is not required to achieve simple goals one proposed method of using nn in nonlinear dynamic process control is to adjust the nn structure i e number of hidden neurons and parameters i e node weights during the training phase also referred to as an unsupervised self organizing nn at each node an optimization function determines if the node should be deleted kept the same or split into two and the node parameters are adjusted accordingly post training self organizing nn have been shown to perform better i e lower computation time and testing error than nn where the structure is fixed i e number of nodes han et al 2010 han and qiao 2014 used a self organizing nn to model aeration and recirculation i e do and nitrate concentration and a multiple objective controller to optimize control of a pilot scale cas system however the authors did not compare system performance to a conventional controller making it difficult to justify implementation for the purpose of do and nitrate concentration control given computational requirements for real time control of a larger system nn controllers are also being designed to detect nonlinear time varying data features that indicate the end of a reaction such as orp in cas fig 8 luccarini et al 2010 used an nn program to control and optimize biological nitrogen removal for a pilot scale sbr the end of denitrification i e a biological process to remove nitrate could not be detected well due to a 50 historical completion rate at the pilot facility the end of nitrification is difficult to detect because of noise and the small change in the rising orp and do the lack of detection in this case demonstrates a common drawback of many data driven systems the desired performance must be demonstrated consistently 3 4 3 transfer function models transfer function models can be used for mpc and optimization in addition to variable prediction discussed in section 3 3 2 o brian et al 2011 demonstrated the ability of a first order six variable arx mpc to optimize energy consumption by reducing aeration by 25 at a full scale cas wwtp compared to the facility s original plc based control strategy however in this case providing aeration based on influent organic loading is not a novel concept and much of the improvement can be attributed to a poorly calibrated or performing controller 3 4 4 fuzzy logic in diagnosing process upsets multiple wwtp operators may logically reach different conclusions regarding the cause of a problem unlike computers human decision making is not always logical and choices are not always binary i e true or false fuzzy logic mimics the attributes of human reasoning by blurring the inputs and rules to allow for partial truth to achieve this fuzzy logic uses linguistic variables in place of numerical variables defines relationships among variables clustering with if then statements that allow for different degrees of truth and characterizes the relationships by fuzzy algorithms the seminal paper describing fuzzy logic by zadeh 1973 is recommended for readers interested in more details on fuzzy model structure the classic rule development approach for fuzzy models is to write if then relationships explicitly which is time consuming for both computer scientists and wwtp operators this process can be simplified by using an nn to map operator observations into fuzzy rules enbutsu et al 1993 re structured the traditional nn model with fuzzy neurons in the input and output layers to model pac dosing and established rules that were more accurate than those derived from interviews with water treatment operators taw hwan et al 1997 also used a hybrid fuzzy model nn approach but calculated pac dosing rate with a fuzzy model under normal conditions and used an nn model when abnormalities were detected i e turbidity 30 ntu jar tests were used to collect data to build both the fuzzy model and nn model which predicted pac dosing rate very accurately during a one year field test at a full scale water treatment plant yoo et al 2003 used pca combined with fuzzy clustering and a fuzzy model to predict cod removal from a full scale industrial wwtp pca was used to reduce the complexity of the fuzzy model as well as to reduce co linearity results were able to generally predict cod removal but could not be used for direct control demonstrating that not all combinations of data driven solutions are always effective bello et al 2014 used fuzzy clustering to define rules for a multi input multi output coagulant dosing system in a water treatment plant the ph predictions were calculated from previous ph values and flowrates of three coagulants and coagulant aids in this case fuzzy mpc performed slightly better than a nonlinear model approximated by linearization if conditions were to change substantially over time i e if the model parameters needed to adapt over time fuzzy models may be a practical alternative to nonlinear mpc 4 conclusions and recommendations the future of data driven and big data analytics in wwtp and water treatment is in improving process control to reduce energy demand ensure effluent water quality and prevent system failure to achieve this wwtp need to incorporate data driven fault detection variable prediction and automation into their current process control paradigms despite a large body of literature on many data driven process control methods in wwtp there is no consensus on a singular best approach for fault detection and diagnosis wwtp need to understand past and present behavior in terms of ic or oc control charts are good for monitoring single variables that are measured daily to monthly and do not contain a lot of noise e g laboratory analysis srt to evaluate multiple variables for fault detection and diagnosis pca is good for use with composite samples because it does not distinguish between input and output variables like pls to use big data in wastewater treatment to predict future performance the monitored variable s must have a high sample frequency and number of historical observations but do not need to be linearly related or parametrically distributed a small decentralized facility may experience so much operational variability that mpc is not effective thus spc may be implemented to detect faults and reduce the number or length of time on site operations staff must be present for a large centralized facility with the buffering capacity to operate at quasi steady state compared to the decentralized case mpc may be useful for reducing chemical inputs and energy optimization an additional consideration is the development of tools to optimize operations at the unit process scale e g aeration basin with recycling membrane bioreactor in addition to the plant wide scale different tasks will employ different problem solving methodologies models that reveal more mechanistic information to assist with diagnosis tend to have poor fault detection accuracy in highly nonlinear systems hence a hybrid method combining model and statistical process control may be a superior problem solving approach each approach will come at a computational cost which is rarely reported in the literature with the major limiting factor being the quality and quantity of data generated by wwtp to develop high quality and accurate big data tools for wastewater treatment industry data scientists computer scientists and engineers must continue to collaborate to maximize data s potential the effectiveness of many state of the art data science tools have not yet been tested in wwtp random forests support vector machines and reinforcement learning have the potential to accommodate many of the features of wwtp data but they still require large training datasets to fit and must produce reliable results kusiak et al 2013 verma et al 2013 with wwtp operations transparency in methodology is one of the keys to adoption so some advanced methodologies may continue to be eschewed in favor of simpler but interpretable methodologies in summary wwtp looking to integrate data driven control should 1 define the scope of the problem and desired goals 2 identify which variables are currently being monitored or should be monitored to effectively capture the scope of the problem 3 use plotting tools to investigate the characteristics of each variable as well as the relationships between variables 4 based on the features observed in the data and analysis goals identify the appropriate method to implement recommendations for further reading on each broad category of methods are given throughout the text 5 fit the models and assess their validity visualize results to ensure that the conclusions are logical and realistic 6 share the results with other wwtp via industry specific publications and conferences to develop mainstream data driven process control tools for wwtp acknowledgments support for this study was provided by the national science foundation partnership for innovation building innovation capacity project 1632227 and by the national science foundation engineering research center program under cooperative agreement eec 1028968 renuwit the authors would also like to thank dr tanja rauch williams and dr eric dickenson for their comments on earlier drafts the anonymous comments from three reviewers also greatly contributed to framing the content of this review acronyms ann auto encoder nn ar autoregressive arima autoregressive integrated moving average arx auto regressive representations with exogenous inputs asm activated sludge model bod5 5 day biochemical oxygen demand bsm benchmark simulation model cas conventional activated sludge cod chemical oxygen demand do dissolved oxygen ewma exponentially weighted moving average ic in control kde kernel density estimation kpca kernel pca lcl lower control limits mcusum multivariate cumulative sum ma moving average mb pls multiblock pls mewma multivariate ewma mpc model predictive control nh4 ammonia nn neural networks no3 nitrate ntu nephelometric turbidity unit oc out of control orp oxidation reduction potential pac powder activated carbon pca principal component analysis plc programmable logic controllers pls partial least squares sbr sequencing batch reactors scada supervisory control and data acquisition spc statistical process control spe squared prediction error srt solids retention time tss total suspended solids ucl upper control limits wwtp wastewater treatment plant 
18838,recent advancements in data driven process control and performance analysis could provide the wastewater treatment industry with an opportunity to reduce costs and improve operations however big data in wastewater treatment plants wwtp is widely underutilized due in part to a workforce that lacks background knowledge of data science required to fully analyze the unique characteristics of wwtp wastewater treatment processes exhibit nonlinear nonstationary autocorrelated and co correlated behavior that i is very difficult to model using first principals and ii must be considered when implementing data driven methods this review provides an overview of data driven methods of achieving fault detection variable prediction and advanced control of wwtp we present how big data has been used in the context of wwtp and much of the discussion can also be applied to water treatment due to the assumptions inherent in different data driven modeling approaches e g control charts statistical process control model predictive control neural networks transfer functions fuzzy logic not all methods are appropriate for every goal or every dataset practical guidance is given for matching a desired goal with a particular methodology along with considerations regarding the assumed data structure for further reading are provided and an overall analysis framework is presented graphical abstract image 1 keywords wastewater treatment big data statistical process control process optimization monitoring 1 introduction municipal wastewater treatment plants wwtp continuously monitor and collect data from unit processes but the data are often underutilized due to the size and complexity of datasets currently generated by wwtp and the lack of data science background for wwtp professionals it can be challenging to efficiently collect manage and analyze the data diebold 2003 kadiyala 2018 manyika et al 2011 regmi et al 2018 despite widespread interest in big data integration at wwtp most raw data are stored in their original format for potential future performance analyses with little consideration to their structure or the organization of the data repository to extract information from this data lake multiple factors need to be considered including the unique characteristics of wwtp data and the goals of an individual wwtp this review describes different data driven methods and how they can be used to address problems specific to wwtp while reviews exist for academic applications corominas et al 2018 hadjimichael et al 2016 olsson 2012 this review is from an applied perspective designed to demystify what methods should be used and under what circumstances if operations data were analyzed in real time with data driven tools wwtp could promptly detect and respond to process failures inefficiencies and abnormalities early correction of these wwtp faults could reduce i downtime ii effluent discharge violation and iii resource consumption such as energy chemicals and labor additional applications of big data to improve wwtp operation include data validation online monitoring of difficult to measure variables predictive maintenance golhar and dallas 2016 system and energy optimization and tailored water reuse i e producing water of distinct qualities for different reuse purposes big data integration at wwtp will have the most substantial impact on process control wwtp primarily use fixed upper and lower limits of process variables to monitor and control treatment processes these limits are adjusted based on a wwtp operator s background knowledge of the specific system as well as online and offline water quality data but rarely are more advanced methods of determining process limits i e modeling used in part this is due to the variability in the sensors that provide the data water quality is monitored in real time by online digital sensors that transmit a voltage or current corresponding to an electrochemical reaction or physical change inside the sensors as they interact with the environment e g constituent concentration flowrate pressure level to calibrate these sensors measurements using analog devices or laboratory analyses are correlated to voltage or current changes from the sensor however solids deposition biofilm formation and precipitates can interfere with the sensor s voltage or current change and thus with the sensor s measurement accuracy offline analyses to calibrate sensors and monitor process performance is performed either on or off site and the time required for each analysis can range from minutes to days depending on the laboratory equipment and available staff the resulting datasets often have missing values contain outliers and are sensitive to the interdependent nonlinear and nonstationary nature of wwtp data olsson et al 2005 rosen and lennox 2001 which makes wwtp difficult to model mathematically for the purpose of performing process control dürrenmatt and gujer 2012 consequently big data tools can provide an alternative approach see section 3 3 1 to address the unique features of wwtp processes and the resulting data wwtp need access to a labor pool of wwtp professionals with backgrounds in data science kadiyala 2018 sirkiä et al 2017 and need more practical guidance on full scale big data implementation us epa 2014 this paper serves as a wwtp engineer s guide to understanding the advantages and limitations of applying different data driven methods for process control and optimization we present how big data has been used in the context of wwtp and review the academic literature that describes state of the art methods of analyzing wwtp data for advanced control and process optimization noting that state of the art in wwtp does not reflect state of the art in the data sciences many more advanced methodologies have been developed but not yet tested in the wwtp context for further reading for each broad category of methods are given along with suggestions for methods that have promise for the water industry additionally much of this discussion can also be applied to water treatment section 2 provides the reader with an introduction to big data and data driven analysis wwtp and the prominent data characteristics of wwtp processes that may impact the results of data analysis section 3 follows with analytical methods to improve process control using examples of real wwtp for the purpose of fault detection variable prediction and advanced automated control fig 1 some methods listed in section 3 have multiple applications thus the full description is provided when the method is first presented section 4 concludes with lessons learned from this review of advanced data analysis at wwtp outlines the challenges facing modern wwtp as they integrate data driven solutions into their operations and identifies some existing methodologies that have not yet been tested with wwtp data 2 background 2 1 big data the term big data encompasses the modern overabundance of data produced by online and offline analysis and the innovative tools used to analyze the data big data can be broadly characterized by the 5 vs which are volume variety velocity veracity and value golhar and dallas 2016 laney 2001 slawecki et al 2016 volume is the physical storage size required to save collected data wwtp rarely monitor the total size of the collected data as storage is inexpensive relative to the operating budget of a facility variety refers to the different types of data collected including file type and data structure maintenance notes are considered unstructured but measured sensor values are structured because they have a quantifiable measurable significance and are stored in a separate database velocity is the rate of data storage and analysis in real time the computer processing speed i e velocity to monitor a wwtp needs to be sufficiently fast able to collect sort clean analyze and interpret data quickly and effectively veracity is the quality and trustworthiness of the data and can be considered a measure of uncertainty one data source in wwtp with questionable veracity is sensing technology even with regular maintenance and calibration sensor measurements drift over time and the drift may differ between sensors of the same model exposed to the same environmental conditions haimi et al 2013 olsson 2012 vanrolleghem and lee 2003 finally value is a subjective characterization of data quality referring to i the cost of data collection and storage relative to the value it produces and ii if analyses are performed to produce information from the data the two general steps for extracting information from industrial processes are data management and data analysis gandomi and haider 2015 labrinidis and jagadish 2012 broadly speaking data management includes the acquisition aggregation and cleaning of raw data to prepare it for analysis analysis may include modeling or advanced statistics to make inferences about the process and can provide site specific actionable knowledge in this paper we primarily discuss the second step approaches to data analysis for addressing problems in modern wwtp to maximize value in data driven analysis engineers need to engage with statisticians data scientists and computers scientists to develop industry specific tools for wwtp there are few data driven tools that are commercially available and most are designed as black box turnkey solutions with limited insight into computational details and causal factors given the nature of wwtp in which an operator receives information from multiple sources and makes an educated decision black box systems are frequently not trusted by wwtp generic data driven tools also exist but the average wwtp engineer lacks the background in data science to apply these tools to a complex system like wwtp in order to produce impactful and accurate results big data analyses need to be implemented with wwtp specific process knowledge and informed data characterization in the next section we provide a brief introduction to the types of processes in wwtp that are the focus of this paper 2 2 water wastewater treatment in the us wwtp receive raw wastewater from sanitary sewer networks and use multiple unit processes to remove contaminants until the water meets standards for discharge or reuse as regulated under the clean water act clean water act 1977 municipal wastewater treatment begins with physical treatment processes such as screening and grit trapping to remove large material and debris from the raw wastewater followed by biological treatment the most common method of biological wastewater treatment is the conventional activated sludge cas process aeration and recirculation of biologically active solids biosolids or solids maintain diverse communities of microorganisms in cas to degrade a wide range of organic compounds and nutrients clarification gravity settling separates treated water from the biosolids followed by disinfection and discharge to the environment depending on the initial quality of the water advanced treatment may also be required e g diffusive membrane technology or advanced oxidation processes to remove salts or contaminants of emerging concern e g pharmaceuticals personal care products synthetic organic compounds the quantity and quality of water and solids are measured from the headworks of a facility through the treatment train to the final discharge point fig 2 some variables are a general measure of the health of a system such as ph other variables are included in control loops with pumps valves and air blowers to optimize treatment such as dissolved oxygen do ammonia nh4 and nitrate no3 concentrations additional variables indicate the operating state of a system such as normal or peak operation in the event of unexpectedly high influent flow these variables are categorical and can be assigned surrogate numerical values such as 0 off and 1 on depending on whether a piece of equipment is in operation unit processes can be designed to treat a continuous flow e g disinfection plug flow basin or a batch e g sequencing batch reactor batch reactors have the additional variable of batch runtime as contaminant transformation is time dependent a non exhaustive list of wwtp variables that produce data of interest to process control are summarized in table 1 2 3 data considerations 2 3 1 structure data driven analytical methods are heavily dependent on the type of data collected it is important to understand the unique structure and characteristics of the data used to determine how the data are organized and utilized cormen et al 2009 data at wwtp are acquired from a variety of sources laboratory analysis online sensor measurements operations and maintenance management and customer and technology manufacturer information each source produces data that are structured differently and can include numerical sensor readings categorical on or off or unstructured notes variables differentiating between numerical or categorical variables is important for data driven analysis for example an operator may determine the amount of time during a batch cycle that an air blower is on or off which dictates what a normal do concentration in a reactor should be if a controller is used the speed of a blower can also be adjusted to meet a desired do concentration in this case there is also a distinction between a controlled variable air blower speed and a variable that responds to the control do concentration by measuring the effect of explanatory variables i e control variables or other covariates on response variables data driven methods can be developed to predict the outcome of a process however not all analyses differentiate between explanatory and response additionally not all explanatory variables directly or measurably affect a process output especially in a large process scheme like wwtp methods applied solely to explanatory variables are generally referred to as unsupervised meaning that the goal is simply to identify patterns in the data without any advance knowledge of the relationships being sought on the other hand supervised learning occurs when the observations are labelled by their response values and the goal is to characterize the link between the explanatory and response variables when a distinction between variable types is required it is mentioned in the first instance of the method in section 3 2 3 2 frequency and temporal variability wwtp data are collected at a variety of time intervals from continuous online sensor measurements to quarterly laboratory results for example wwtp monitoring is considered continuous if data are collected at 15 min intervals or less us epa 2015 but some effluent quality variables are measured only every few months such as disinfection byproducts traditional data management segregates data by source primarily due to the difficulty of merging data of different frequencies and formats a common mathematical approach to handle different data frequencies is to scale data to a single time interval odom et al 2018 however datasets with a very large difference in frequencies cannot use this method because wwtp data are time dependent co correlated i e the relationships among variables are related to one another and nonlinearly related making downscaling challenging effluent quality variables may change either suddenly or gradually over time table 2 and they often change nonlinearly in relation to other process variables which can make attributing the cause of change between sampling events difficult the monitoring frequency of the treatment process strongly depends on the goal of the analysis and the characteristics of the process venkatasubramanian 1995 in process control the data collection frequency should be sufficiently high to account for instrument noise and to track typical irregularities but not so frequent that excessive computational power is required for full analysis short term faults like a clog in a pipe that can occur on the order of minutes to hours require a different monitoring window of time than long term faults like an increase in transmembrane pressure due to biological fouling of a membrane that occurs on the order of days to weeks table 2 dürrenmatt and gujer 2012 recommend a window width of at least three times the length of time over which the fault occurs to be detected 2 3 3 variable characteristics many wwtp process variables exhibit unique characteristics such as time dependence and nonstationarity e g the strong diurnal and seasonal swings of ambient temperature but conventional control strategies rarely account for such relationships that need to be considered for data driven fault detection variable prediction or automated control stationary variables have constant mean variance and covariances making them predictable and more easily modeled conversely the means and or variances of nonstationary variables change over time if a variable s measurements are correlated from one time step to the next the variable is said to be dependent over time wwtp data exhibit these properties because of the dynamic nature of wwtp processes fig 3 a constantly changing influent batch as opposed to continuous processes temperature internal shifts in microbial ecology and process control instability are a few causes of the nonstationarity and temporal dependence many statistical methods assume data are normally distributed a normal distribution is symmetric unimodal and bell shaped and is characterized by two statistical parameters its mean and variance the multivariate case is additionally characterized by its covariances i e the variance between each pair of variables when the data are normally distributed exact inferences can be made about the mean variance and covariances e g confidence intervals predictions or hypothesis tests because the distribution of the test statistics adhere to proven mathematical theories when the assumption of normality is not met it is more difficult to identify the distribution of the statistic without making assumptions about the data s distribution the uncertainty in the estimate of interest cannot be accurately inferred the assumption of normality does not typically hold in wwtp due to boundary limits of variables i e sensor operating range process variation and outliers in the event of a hardware malfunction a contaminated lab sample or a data entry error observations may be missing or abnormal compromising normality analysis power and reliability of results kwak and kim 2017 each error can potentially bias features that are of interest to model and the removal or correction of erroneous values i e data cleaning should be a high priority prior to data analysis to limit incorrect conclusions haimi et al 2013 kadlec et al 2009 particular attention needs to be paid to how a data driven methodology is implemented in the event that nonlinear and nonstationary behavior is detected there are two approaches for modeling nonstationary behavior accounting for a known or predictable underlying trend or limiting the window of time over which a model is trained given the difficulty in modeling nonstationary behavior in wwtp fig 3 relatively short windows of time e g 3 to 10 days may be the best option to achieve approximate stationary and normal behavior in addition to simple modifications of existing methods e g using short training windows distribution free statistical methods such as kernel density estimation kde and bootstrapping can be applied kde estimates a distribution using local smoothing allowing practitioners to work around the normality assumption however kde is very sensitive to the choice of tuning parameters izenman 2013 conversely bootstrapping does not require any tuning parameters but is more computationally demanding from a dataset observations are randomly drawn with replacement the statistic of interest is computed and then these two steps are repeated many times to produce a distribution of the statistic efron and tibshirani 1994 james et al 2013 provide a simple introduction to the bootstrap method 2 4 exploratory data analysis identifying the structure and characteristics of a dataset requires familiarity with the source of the data and the process itself plotting and visualizing data should be the first step in any analysis but no one size fits all approach exists observations recorded over time can be visualized in time series plots fig 3 the strength of the temporal dependence can be assessed with autocorrelation function plots potential outliers can be observed in boxplots and the entire distribution can be plotted in a histogram these plots work well for monitoring a single variable but wwtp are often interested in the relationships among multiple variables pairwise scatterplots multiple boxplots functional boxplots and cross correlation function plots are just a few ways additional features can be assessed examples of some of these plots can be found in pfluger et al 2018 there are many tests available to assess multivariate normality including the mardia test henze zirkler test royston test doornik hansen test and the e statistic korkmaz et al 2014 unsupervised learning methods for clustering or outlier detection are commonly used to identify structure in the data james et al 2013 manual data inspection can be time intensive so the inclusion of more advanced statistical tools can provide rapid insight into the data characteristics 3 methods examples in this section we present the current use of process data in wwtp and a review of recent academic literature demonstrating the possibilities for advanced data driven process control in wwtp the focus of this review is on control methods that have been tested on actual wwtp systems to provide practitioners with realistic examples simulation studies serve a valuable purpose but do not always represent the wwtp process realistically due to simplifying assumptions about data characteristics and the processes corominas et al 2018 primarily data driven analysis in wwtp can be used for fault detection variable prediction and automated control each requires a different and increasingly complex data processing analysis and control framework the data driven methods are therefore discussed in the context of the goal of each process control application fault detection variable prediction or advanced control we begin with a brief review of historical methods of process control in wwtp 3 1 historical process control data driven process control has historically been sparse in wwtp with daily operational decisions considered more of an art than a science metcalf and eddy 2013 o day 2004 as early as the 1920s statistical tools like histograms and control charts were used for informal diagnostics control during this time relied on manual adjustments and observations as digital control was not an option prior to the 1960s the cost of computers and instrumentation was high treatment dynamics were not well understood facilities were not designed with additional flexibility and control theory was not sufficiently developed olsson 2012 in the 1980s affordable computing power facilitated simple first principle models although their complexity and lack of reliability made them poor advisory systems olsson et al 1998 by the early 2000s the digital revolution reached wwtp and most wwtp had integrated their own version of direct digital control into process monitoring in the form of programmable logic controllers plc and supervisory control and data acquisition scada systems despite the unique challenges posed by wwtp data data driven system automation and real time control are integral to modern wwtp operation the most common process control practice is to maintain a set point i e target value using online sensor readings and feedback control for example do concentrations can be controlled by adjusting air blower speed i e aeration intensity rather than operating at a single blower speed online measurements provide feedback to the scada system that determines whether blower speed should increase decrease or stay constant relative to a measured value like do concentration chemical dosing to enhance contaminant precipitation and additional carbon for biological processes are other examples of feedback control based on in situ nutrient concentrations this method of process control is commonly achieved by a controller with a variable frequency drive to change operating conditions in a continuous smooth and automated manner establishing target values for process variables is one of the simplest methods of control and is a widespread practice in wwtp this single variable monitoring paradigm is the foundation for fault detection at most modern wwtp in which a measured value is either within or outside of an operator specified range while this approach has a low false alarm rate e g if a flow rate measurement is below a set point a fault of unknown cause has certainly occurred somewhere in the system that affects flow rate it can be very slow to detect faults does not forecast future values and does not account for correlations among variables plant operators must be available to respond quickly to a system fault to prevent equipment damage or system failure putting additional stress on equipment and staff to reduce a fault s impact on effluent water quality proactive and comprehensive approaches to fault detection and forecasting are being developed capizzi and masarotto 2017 jiang et al 2012 kazor et al 2016 odom et al 2018 wang and jiang 2009 which could help reduce cost and improve efficiency of wwtp systems some data driven fault detection methods are currently being implemented and the results are discussed in the next section 3 2 fault detection a multitude of system faults or changes in conditions can cause process irregularities in wwtp these include a change in influent quality e g snowmelt industrial discharge an outbreak of microorganisms that inhibit treatment e g filamentous bacteria algae irregularities or damage to treatment units e g membranes clarifiers mechanical failures e g pumps air blowers or sensor failure e g drift bias electrical interference each type of fault can alter system performance differently and it is important to consider the versatility of an analytical approach i e which types of faults can be detected when designing a fault detection program for example if a sensor failure occurs and the sensor s measurements are included in a control loop many variables could be affected in contrast if the sensor s measurements are not included in a control loop a sensor fault may only affect the measured sensor variable a fault is an unintentional deviation of a process characteristic that limits the process ability to achieve its purpose isermann 1984 typical single variable faults that occur in wwtp are easier to diagnose qualitatively and are illustrated in table 3 however multivariate faults can be much more difficult to discern visually to detect faults in the dynamic nonstationary multivariate data found in wwtp a quantitative approach such as statistical process control spc is needed in spc a fault is identified when a consecutive series of observations are flagged as abnormal olsson and newell 1999 suggested data collection frequency be chosen to be at least one fifth of the length of time over which the event of interest occurs the distinction between normal in control or ic and abnormal out of control or oc observations is determined by a statistical hypothesis test hypothesis tests are used to quantify the likelihood that an individual observation from a dataset is consistent with observations collected under ic conditions ic observations are usually used to train an spc model which is a type of supervised learning because the initial data are known to be ic many spc methods exist but few have been implemented in wwtp the following is a discussion of different spc methods used in wwtp to determine if a significant change or fault has occurred 3 2 1 control charts control charts are useful tools to determine at a glance if a process is ic the most popular statistical control chart was outlined by walter shewhart of bell labs the shewhart control chart uses upper and lower control limits ucl and lcl for a process variable or statistic by adding or subtracting k standard deviations from the variable s mean with k 3 being the industry standard nist sematech 2003 shewhart 1926 if an observation is above the ucl or conversely below the lcl a statistically significant change has most likely occurred shewhart control charts employed at wwtp are typically constructed with a 3 or 5 day arithmetic moving average for variables designed to be stationary such as solids retention time srt in a bioreactor or percent water recovery of a membrane treatment unit additionally control charts can be used in wwtp analytical labs for quality control e g a sensor s measurements of a standard solution over time rice et al 2017 or other variables that change slowly table 2 however the shewhart method of calculating control limits is only valid for a variable that is normally distributed and whose observations are independent and stationary montgomery 2009 updating the ucl and lcl to adapt to changing conditions using methods such as exponentially weighted moving average ewma can account for some nonstationarity found in wwtp data wold 1994 the shewhart control chart assumes the process is stationary and weighs all past observations equally ignoring trends montgomery 2009 the ewma gives more weight to the most recent observations adapting to some process variation nist sematech 2003 and is frequently used as a data smoothing technique berthouex and box 1996 mina and verde 2007 the ewma accounts for both the most recent observation and past behavior by multiplying the most recent observation by a forgetting factor 0 05 λ 0 25 and the geometric moving average by 1 λ hunter 1986 montgomery 2009 roberts 1959 however the ewma is not a good measure to distinguish between ic and oc for every wwtp process like many data driven performance monitoring methods the ewma control limits are heavily impacted by outliers rosen et al 2003 in both panels of fig 4 the assimilation of oc observations immediately widens the range of values that are considered ic thus control chart limits should only be updated with ic observations as explored by corominas et al 2011 additionally some sensors have a lower operating limit which invalidates the standard ewma lcl fig 4a in this case a turbidity sensor outputs a current between 4 and 20 ma which is converted to turbidity units ntus using a calibrated linear regression here 4 ma correlates to 0 04 ntu when the turbidity is below this threshold the sensor continues to output 4 ma which truncates the distribution of the turbidity data and invalidates the lcl for small datasets e g fewer than two variables in the case of flow and pressure of a water distribution system univariate ewma has shown to be better at detecting faults than multivariate ewma mewma jung et al 2013 however most wwtp process variables violate the assumptions required for the shewhart s or the ewma control chart berthouex 1989 resulting in a high percentage of false alarms making them poor choices for fault detection for larger datasets e g monitoring more than 2 process variables multivariate control charts can reduce a complicated dataset to a single measurement reflecting the health of the wwtp monitoring multivariate processes as opposed to individual variable monitoring with a control chart method may provide wwtp operators with a better sense of the overall state of operating conditions schraa et al 2006 multivariate process statistics such as mewma lowry et al 1992 multivariate cumulative sum mcusum crosier 1988 and hotelling s t 2 hotelling 1947 can be used to examine the mean and dispersion of multiple variables but have rarely been implemented in industrial process monitoring due to the complex matrix algebra required nist sematech 2003 mewma and mcusum have been shown to be good at detecting small changes in the mean compared to hotelling s t 2 but can have a high false alarm rate alves et al 2013 however the assumption of multivariate normality is also required for these methods and as mentioned previously this is rarely observed in wwtp a nonparametric approach such as bootstrapping may yield better results for a multivariate control chart in wwtp phaladiganon et al 2011 3 2 2 principal component analysis a widely used statistical method for monitoring multiple variables simultaneously is to capture the relationships among linear combinations of variables rather than the variables themselves by principal component analysis pca jackson 1991 pca identifies independent linear combinations of variables principal components or pcs by effectively calculating lines of best fit through a dataset wise and gallagher 1996 pcs account for as much variation as possible given the assumption of linearity and can therefore reduce the number of model variables and eliminate noise and redundancy for example unsupervised pca is frequently used to reduce the number of predictor input variables for multiple regression models discussed further in section 3 3 3 wallace et al 2016 wang et al 2017 and can be used to identify clusters of related microbiological sample properties jałowiecki et al 2016 to use pca for supervised data driven analysis a training dataset that represents ic conditions is used to calculate the pc then testing data are transformed into the model subspace defined by the pc if the overall distance from a new observation to the pca model is above a desired control limit similar to the control chart methodology described above then the new observation is considered abnormal and is a possible indication of a process fault the benefit of performing pca prior to calculating the control statistic e g squared prediction error spe hotelling s t 2 etc is the reduction in false alarms due to the reduction in noise and removal of dependence among the features pca has many applications in wwtp from direct fault detection king et al 2006 to data reconstruction lee et al 2006a schraa et al 2006 for dynamic wwtp data variations of pca are often used with adaptive pca being the most common baggiani and marsili libelli 2009 kazor et al 2016 lee and vanrolleghem 2004 rosen and lennox 2001 adaptive pca updates the model based on a rolling window of training observations the training window is set to n observations and as time passes the oldest observations are removed from the training dataset and new observations are added to maintain a constant number of observations the rolling training window can thereby account for temporal nonstationarity found in wwtp i e conditions that change over time however if the training window is too large faults could be ignored baggiani and marsili libelli 2009 if the training window is too small normal observations could be flagged as faults rosen and lennox 2001 given the type of process changes that a wwtp needs to detect exploratory data analysis section 2 4 should be used to identify the shortest training window that achieves the desired true detection rate some argue that the underlying correlation structure should not change with time and therefore the rolling window concept defeats the purpose of pca mina and verde 2007 this assumption may be valid for simulated wwtp data but is unlikely for real wwtp data and is demonstrated by the improved performance of adaptive pca as opposed to conventional pca kazor et al 2016 dynamic pca is another common modification to pca for fault detection in wwtp lee et al 2006a lee et al 2006b mina and verde 2007 the dynamic extension accounts for autocorrelation among variables by lagging observations i e shifting a dataset back by a given timestep and including the lagged values as new variables kruger et al 2004 ku et al 1995 for most wwtp applications a lag of a single timestep is sufficient to account for how previous conditions affect current performance however if the process is cyclical i e processes occur as a function of runtime and the system returns to its initial state by the end of the cycle then the lag should be the size of the cycle itself kazor et al 2016 cyclical i e batch operations may also require a unique modification called multiway analysis smilde et al 2005 multiway pca unfolds a dataset indexed in three dimensions e g cycle runtime batch monitored variables to a long two dimensional array by combining two of the three dimensions e g cycle runtime and monitored variables that can be analyzed with traditional spc methods like pca fig 5 lee and vanrolleghem 2004 macgregor et al 1994 macgregor and kourti 1995 nomikos and macgregor 1994 yoo et al 2004 in wwtp this approach is particularly useful for sequencing batch reactors sbr villez 2007 the new two dimensional dataset can account for variability in the monitored variables across batches and variables measured at different temporal frequencies the major drawback of pca and many other spc methods like partial least squares for wwtp is the assumption that process variables are linearly related to each other to account for the nonlinear components of wwtp data can first be mapped into a higher dimensional nonlinear space where observations are more likely to be linear haykin 1999 one such nonlinear pca method is kernel pca kpca kernel methods avoid computationally intensive nonlinear optimization and different nonlinearities can be captured using different kernel functions popular kernels are the polynomial gaussian and sigmoid but the most commonly used is the gaussian because its associated parameter provides precise tuning of the model fit izenman 2013 nguyen and golinval 2010 kpca has shown slightly better performance in simulated wwtp lee et al 2004 xiao et al 2017 however kazor et al 2016 found limited improvement in kpca over pca for fault detection in a decentralized wwtp and lee et al 2006c saw similar limited improvement for the performance of anaerobic filters 3 2 3 partial least squares similar to pca partial least squares pls identifies independent linear combinations of the measured variables and outliers can be identified with t 2 and spe statistics chen et al 2016 unlike pca pls differentiates between input variables e g initial water quality operational information and output variables e g effluent water quality and performs dimension reduction on each set of variables separately hoskuldsson 1996 pls is an example of supervised dimension reduction pls only monitors output variables that are affected by the input variables whereas pca is used to monitor all variables in the process simultaneously if an observation is abnormal but does not impact the final water quality pls will not flag the process as oc but pca will chiang et al 2001 nomikos and macgregor 1995 hence pls is more frequently used in variable prediction than in fault detection in complex systems fault detection may improve by dividing the process into units multiblock pls mb pls subsets input variables into logical subsystems e g primary sedimentation aeration basin prior to analysis wangen and kowalski 1989 experimentally mb pls does not improve prediction compared to the standard pls however the results may be easier to interpret for fault diagnosis choi and lee 2005 3 2 4 neural networks conventional mechanistic models use complex formulas that are connected in mathematically simple ways i e mass balance formulations to describe the sum of all unit processes in contrast neural networks nn use simple mathematical expressions that have complex relationships in which process inputs are nonlinearly linked to outputs without prior knowledge of an underlying mechanism dreyfus 2005 nielsen 2015 olsson and newell 1999 process inputs and outputs are connected by neurons that are organized in layers fig 6 a neuron in the input layer distributes an actual process input variable to neurons in the first hidden layer neurons in a hidden layer normalize and weigh multiple inputs transform the value with an activation function and produce a normalized output signal nn can have one or multiple hidden layers connected by input transformations and output signals the output layer is a weighted sum of the final hidden layer s output signal in contrast to linear statistical models e g multiple regression pca pls nn model parameters do not have the same interpretability i e no physical chemical or biological significance to identify the parameters of each neuron in a nn model learning algorithms are needed due to the extensive intricacies of the different learning algorithms for nn development this paper will focus on the two types of nn training supervised or unsupervised supervised training requires data to be labelled in such a way that inputs and outputs are defined there are many different learning algorithms for fitting a supervised nn and each requires an iterative process in which parameters are estimated based on a large historical dataset dreyfus 2005 one of the most common is the back propagation learning algorithm that starts by randomly assigning parameter values calculating an estimated output and minimizing the error between the estimated and the actual output node by node and layer by layer starting with the hidden layer directly connected to the output hundreds of iterations must be performed to determine the best network for a particular dataset requiring a substantial amount of computing power wei 2013 hence it is valuable to minimize the number of variables used to construct the model unsupervised training of a nn uses data that are unlabeled i e the model is supplied with defined inputs but no outputs and uses fundamentally different learning algorithms than the error correction method in supervised training unsupervised nn act best as classifiers for pattern recognition in fault detection unsupervised nn can be trained to model a process by estimating the values of inputs and comparing the estimation to the actual values also known as an auto encoder nn ann xiao et al 2017 used anns with bottleneck layers i e the middle hidden layer contains fewer nodes than the preceding or succeeding layers which force the nn to effectively capture the principal components of the data to detect faults at a wwtp spe was calculated from the difference between actual and estimated values and similar to pca an spe threshold was calculated to determine if the process was ic or oc xiao et al 2017 concluded that ann based fault detection was more sensitive to changes than conventional pca additionally xiao et al 2017 compared deep and shallow ann until recently training nn with many layers and nodes deep nn was not computationally efficient hinton et al 2006 however shallow nn are generally unable to capture highly nonlinear systems in this case there was no conclusive evidence that the deep ann performed better than the shallow ann 3 3 variable prediction spc can be used to assess if a system is ic or oc but this is a generic measure of product water quality and system health to predict what a variable value should be under given conditions model based control could be used model predictive control mpc compares mechanistic model predictions to actual process measurements then deviations from the model are identified as faults the model can be derived from theory i e fluid dynamics microbial kinetics or empirical trends i e data driven and can be used to approximate additional process variables in lieu of directly monitoring the variable of interest a link may be found among variables in this way a software sensor or soft sensor also referred to as inferential sensors virtual online analyzers or observer based sensors can be developed for the online monitoring of variables that are too time consuming or expensive to consistently monitor with lab based analyses chéruy 1997 kadlec et al 2009 many different approaches to variable prediction have been proposed and here we review the most commonly observed in literature 3 3 1 activated sludge models some water quality variables can be adequately predicted with calibrated first principal models the activated sludge model no 1 asm1 is the most widely used deterministic model for biological carbon and nitrogen removal in wwtp henze et al 1987 asm1 was developed in 1985 by compiling novel research about the kinetic behavior and mechanisms of the cas process subsequent cas models e g asm2 and asm2d have additional parameters that account for fermentation enhanced biological phosphorus removal and chemical phosphorus removal gujer et al 1999 henze et al 1999 1995 models based on first principals also exist for clarifiers settlers but due to a lack of a mathematical relationship between floc characteristics and settleability they are still limited to process design and research purposes metcalf and eddy 2013 olsson 2012 uncertainty in the model inputs and the simplified mathematical framework fundamentally limits the accuracy of the model however in many cases pilot or full scale calibration can account for some of the error in the asm metcalf and eddy 2013 additional sources of error are model parameter estimates not all unit processes share a common set of state variables i e variables that indicate the operating conditions of a process as opposed to variables that measure a constituent in the water and linking models with variable estimates can lead to substantial error in the plant wide model volcke et al 2006 for example asm and secondary clarifier models are frequently coupled but the models differ in how total suspended solids tss concentration is calculated and incorporated without calibration and only parameter estimates the asm may produce results that are only accurate within an order of magnitude illustrating the variability of wwtp gujer 2011 olsson and newell 1999 considered other sources of error for model predictions including inaccurate or incorrect calibration non ideal process behavior and lump sum parameter assumptions for these reasons mpc with the asm is rarely used in full scale biological wwtp operations for variable prediction or fault detection to standardize control strategy testing at biological wwtp a simulation benchmark was developed from the asm1 henze et al 1987 under eu cost actions 682 and 624 alex et al 1999 jeppsson and pons 2004 spanjers et al 1998 the benchmark simulation model no 1 bsm1 includes a mathematical model of a five reactor cas treatment system followed by a clarifier fig 2 asm specific parameters from literature and simulated influent datasets for different weather events copp 2002 the newest version bsm2 incorporates extensions proposed in recent literature a longer simulation study timeframe inclusion of temporally dynamic parameters and more realistic sensor behavior and failure jeppsson et al 2007 nopens et al 2010 rosen et al 2004 there are hundreds of proposed control strategies for the bsm but simulation benchmarks do not yet exist for all common wastewater treatment technologies while simulation studies are important to understand the potential behaviors of control strategies the actual dynamics of a wwtp are nearly impossible to reproduce artificially this is most evident when control strategies perform well on bsm but cannot be replicated with real wwtp data sin et al 2006 oppong et al 2013 compared simulated datasets from the bsm models to real industrial wwtp data using anaerobic digestion in an attempt to develop a soft sensor however the variable of interest volatile solids concentration had substantially different co correlation structure both in magnitude and direction among the simulated and actual process variables the difference was attributed to infrequent sampling and a stable process with little change but it is also possible that the bsm is inadequate for mpc in this case 3 3 2 transfer function models transfer function models are a general class of models that describe the relationship between an input and output of a linear system using a mathematical function when the system is not too complex i e the number of output parameters is 2 transfer functions can be a good approximation for dynamic systems box et al 1994 univariate autoregressive integrated moving average arima models are a special case of transfer function models that do not depend on the input variables and are widely used for linear time series forecasting chen et al 2007 the autoregressive ar portion predicts values that are mathematically related to the previous time step s i e lag the moving average ma predicts values that are mathematically related to the error of the past time steps the integrated i portion of the arima model indicates that the difference between observations one or more is modeled instead of the observation itself and this step can remove some of the nonstationarity present in the data the primary application of arima models in wwtp is to predict an effluent variable park and koo 2015 showed that an arima model can be used to predict effluent turbidity of a sedimentation basin berthouex and box 1996 and west et al 2002 successfully used an arima model to predict effluent 5 day biochemical oxygen demand bod5 of a wwtp however the arima model s integration step is often insufficient to account for wwtp data nonstationarity in the long term west et al 2002 as the prediction horizon increases the accuracy of arima models declines substantially unable to account for nonlinear behavior in wwtp dellana and west 2009 3 3 3 multiple regression multiple regression is an extension of a simple linear regression using multiple independent variables x i i 1 2 k to model a single dependent variable y via y β 0 β 1 x 1 β k x k e the model parameters are commonly estimated by ordinary least squares and more information about multiple regression model fitting can be found in sheather 2009 when all independent variables are standardized i e zero mean and unit variance the strength of an input variable s impact on the output variable is directly proportional to the magnitude of βi giving tangible meaning to the model parameters categorical information can also be integrated by the use of dummy variables d i i 1 2 k which take on binary values e g if a blower is on then d i 1 if off then d i 0 however problems can arise when fitting a multiple regression model if the explanatory variables are exactly linearly related multicollinearity are highly variable or are autocorrelated miah 2016 as in wwtp ebrahimi et al 2017 used multiple regression models to predict various water quality variables like phosphorus nitrogen and tss concentrations in a full scale wastewater treatment plant with reasonable results r2 0 71 0 87 meaning the model explains 71 87 of total variation in the dependent variable but they did not demonstrate sufficient accuracy for stand alone fault detection however multiple regression techniques may have applications in soft sensor and empirical model development pls regression is a combination of pls and multiple regression and can be used to predict the output variables from the input abdi 2003 because of this property pls is commonly used for industrial soft sensors and water quality variables in wwtp such as chemical oxygen demand cod tss nitrate and oil and grease concentrations langergraber et al 2003 qin et al 2012 the use of nonlinear mapping with pls kernel pls or kpls also shows promise for methane production from a full scale anaerobic filter lee et al 2006c and cod total nitrogen and cyanide concentration in cas woo et al 2009 in these cases kpls performed better than conventional pls which demonstrates the importance of accounting for nonlinearities for some data driven applications 3 3 4 neural networks supervised nn have been used to predict raw wastewater flow from online rainfall data and historical influent data wei 2013 yang et al 2008 reconstructed cod concentration from uv 254 and ph measurements using a back propagation nn ömer faruk 2009 used a hybrid nn arima to predict boron and do concentrations and water temperature of a river over time while the arima model performed very poorly r2 0 23 0 55 the hybrid model performed only slightly better r2 0 79 0 83 than the nn model r2 0 77 0 81 nn arima hybridization has been a popular research topic because in theory both linear and nonlinear behavior could be described with the resulting model venkatasubramanian 1995 however few case studies exist that demonstrate a significant improvement of a hybrid model over a nn model chen et al 2007 a nn hybrid model was successfully used by lee et al 2008 to predict cod total nitrogen and total phosphorus concentrations in the effluent of small cas wwtp from conductivity temperature ph do oxidation reduction potential orp and turbidity input and output variables were lagged to account for dynamic process variation combined with a transfer function model auto regressive representations with exogenous inputs or arx lee et al s 2008 approach showed good results for variable prediction r2 0 92 0 95 and is promising for soft sensor development lee et al 2002 also used a hybrid nn structure for prediction of wwtp effluent quality in principle the hybridization of mechanistic and nn models bridges the gap between first principal and statistical approaches the nn was placed in parallel and in series with the asm1 model to estimate the model error or input parameters respectively the parallel hybrid nn model performed well at predicting effluent variables e g cyanide r2 0 93 0 96 but the series hybrid nn model did not perform better than the nn alone indicating that there exists some error for which the asm1 model itself does not account models to determine sorption kinetics and the capacity of carbon to adsorb contaminants can also be mapped by nn vasanth kumar et al 2008 trained an nn model with batch experimental data under various conditions to predict equilibrium concentrations after the uptake of dye by powdered activated carbon pac the resulting predictions were nearly perfect r2 0 96 however hundreds of data points were needed to calibrate the model prior to the predictions there was not significant variation among the input variables only a single contaminant was used and separate testing data was not used to verify results given the complexity of biological treatment modeling generating a carbon adsorption isotherm for pac treatment is very well understood computationally straightforward and accurate for design purposes unless nn can demonstrate the ability to account for large variations in initial water quality of which the current isotherm paradigm cannot use of the traditional adsorption isotherm models will continue to be used a potential application that has not yet been explored is for the generation of isotherm models for micropollutants e g per and polyfluoroalkyl substances in the presence of bulk organic carbon 3 4 advanced control the goal of wwtp optimization is to achieve the desired effluent quality with fewer inputs i e chemicals energy manpower future wwtp will also need to be able to adjust their effluent quality to meet new demands without risk of disturbance as water resources dwindle and demand increases in urban centers customizable water quality based on need and time of year known as tailored water has become an attractive option vuono et al 2013 using historical data and system knowledge a function can be developed to minimize cost or energy while maintaining effluent quality in order to identify the best set of setpoints and control decisions this is a fundamentally different approach than heuristically adjusting variable setpoints and observing the system s response various methods to achieve data driven control advanced or automated control are discussed in this section however advanced control is still in its infancy for wwtp and few full scale demonstrations or installations exist 3 4 1 model predictive control mpc uses a mechanistic model of a process to predict a process variable accounting for the physical constraints of a system s actual process variable measurements richalet et al 1978 the model predicts future process behavior over a time interval known as the prediction horizon and predictions are compared to online measurements to determine if a change has occurred fig 7 mpc is less common in wwtp because most individual wwtp processes especially biological processes are too complex to develop sufficiently accurate first principal models section 3 3 1 for advanced control purposes due to their deviation from ideal steady state conditions patton et al 2000 furthermore the computing power required to handle the nonlinearities has not been well documented mpc in wwtp takes on many forms but all must address wwtp data s nonlinear behavior nonlinear models are computationally intensive to solve and accounting for too many nonlinearities can substantially slow a controller s response a less computationally intensive option is to use piecewise linear mpc in which multiple linear models approximate a nonlinear model ocampo martinez 2010 olsson and newell 1999 another method is to update or adapt linear model parameters to fit current operating conditions zhang and zhang 2006 adaptive mpc controllers have been shown to perform better than conventional pid controllers for nonlinear processes however strong nonlinearities are still better handled by alternative control approaches such as nn hermansson and syafiie 2015 mpc has been implemented for dynamically simplistic wwtp unit processes such as membrane based treatment that can be controlled by a single variable membrane systems can be easily modeled using known relationships of fluid flow mass transfer and thermodynamics bartman et al 2009 derived such a model to control a valve on a pilot scale reverse osmosis ro membrane treatment system the reject concentrate flowrate was controlled by the dynamic nonlinear lumped parameter model and was validated with experimental data in general the system performed better when controlled by the dynamic model as opposed to a traditional controller not all wwtp unit processes are fit for mpc simply because accurate analytical models do not yet exist and the number of possible inputs makes real time control computationally unreasonable attempts have been made in the literature to adapt mpc for wwtp including cas and membrane systems but more research is needed to develop realistic and system specific models before mpc can be implemented as a control strategy in full scale wwtp alternatively non deterministic nonlinear data driven models are an option for mpc of activated sludge systems i e nn 3 4 2 neural networks as discussed in section 3 3 4 each parameter and layer in an nn model adds an additional degree of flexibility that can address the problem of nonlinear model fitting however a large number of nn model parameters can risk overfitting to noise in the data rather than the process itself and can unnecessarily increase computation the computational power required to use an nn model for control applications is not well documented and most studies in wwtp literature utilize only a few water quality variables to predict a single value i e soft sensor development the availability of reliable and plentiful online sensor data can also be a major constraint more research is needed with constructing larger wwtp nn before the practicality of nn control strategies in wwtp can be assessed to begin wwtp nn model development should be performed incrementally so that an unexpected and unmanageable amount of computational power is not required to achieve simple goals one proposed method of using nn in nonlinear dynamic process control is to adjust the nn structure i e number of hidden neurons and parameters i e node weights during the training phase also referred to as an unsupervised self organizing nn at each node an optimization function determines if the node should be deleted kept the same or split into two and the node parameters are adjusted accordingly post training self organizing nn have been shown to perform better i e lower computation time and testing error than nn where the structure is fixed i e number of nodes han et al 2010 han and qiao 2014 used a self organizing nn to model aeration and recirculation i e do and nitrate concentration and a multiple objective controller to optimize control of a pilot scale cas system however the authors did not compare system performance to a conventional controller making it difficult to justify implementation for the purpose of do and nitrate concentration control given computational requirements for real time control of a larger system nn controllers are also being designed to detect nonlinear time varying data features that indicate the end of a reaction such as orp in cas fig 8 luccarini et al 2010 used an nn program to control and optimize biological nitrogen removal for a pilot scale sbr the end of denitrification i e a biological process to remove nitrate could not be detected well due to a 50 historical completion rate at the pilot facility the end of nitrification is difficult to detect because of noise and the small change in the rising orp and do the lack of detection in this case demonstrates a common drawback of many data driven systems the desired performance must be demonstrated consistently 3 4 3 transfer function models transfer function models can be used for mpc and optimization in addition to variable prediction discussed in section 3 3 2 o brian et al 2011 demonstrated the ability of a first order six variable arx mpc to optimize energy consumption by reducing aeration by 25 at a full scale cas wwtp compared to the facility s original plc based control strategy however in this case providing aeration based on influent organic loading is not a novel concept and much of the improvement can be attributed to a poorly calibrated or performing controller 3 4 4 fuzzy logic in diagnosing process upsets multiple wwtp operators may logically reach different conclusions regarding the cause of a problem unlike computers human decision making is not always logical and choices are not always binary i e true or false fuzzy logic mimics the attributes of human reasoning by blurring the inputs and rules to allow for partial truth to achieve this fuzzy logic uses linguistic variables in place of numerical variables defines relationships among variables clustering with if then statements that allow for different degrees of truth and characterizes the relationships by fuzzy algorithms the seminal paper describing fuzzy logic by zadeh 1973 is recommended for readers interested in more details on fuzzy model structure the classic rule development approach for fuzzy models is to write if then relationships explicitly which is time consuming for both computer scientists and wwtp operators this process can be simplified by using an nn to map operator observations into fuzzy rules enbutsu et al 1993 re structured the traditional nn model with fuzzy neurons in the input and output layers to model pac dosing and established rules that were more accurate than those derived from interviews with water treatment operators taw hwan et al 1997 also used a hybrid fuzzy model nn approach but calculated pac dosing rate with a fuzzy model under normal conditions and used an nn model when abnormalities were detected i e turbidity 30 ntu jar tests were used to collect data to build both the fuzzy model and nn model which predicted pac dosing rate very accurately during a one year field test at a full scale water treatment plant yoo et al 2003 used pca combined with fuzzy clustering and a fuzzy model to predict cod removal from a full scale industrial wwtp pca was used to reduce the complexity of the fuzzy model as well as to reduce co linearity results were able to generally predict cod removal but could not be used for direct control demonstrating that not all combinations of data driven solutions are always effective bello et al 2014 used fuzzy clustering to define rules for a multi input multi output coagulant dosing system in a water treatment plant the ph predictions were calculated from previous ph values and flowrates of three coagulants and coagulant aids in this case fuzzy mpc performed slightly better than a nonlinear model approximated by linearization if conditions were to change substantially over time i e if the model parameters needed to adapt over time fuzzy models may be a practical alternative to nonlinear mpc 4 conclusions and recommendations the future of data driven and big data analytics in wwtp and water treatment is in improving process control to reduce energy demand ensure effluent water quality and prevent system failure to achieve this wwtp need to incorporate data driven fault detection variable prediction and automation into their current process control paradigms despite a large body of literature on many data driven process control methods in wwtp there is no consensus on a singular best approach for fault detection and diagnosis wwtp need to understand past and present behavior in terms of ic or oc control charts are good for monitoring single variables that are measured daily to monthly and do not contain a lot of noise e g laboratory analysis srt to evaluate multiple variables for fault detection and diagnosis pca is good for use with composite samples because it does not distinguish between input and output variables like pls to use big data in wastewater treatment to predict future performance the monitored variable s must have a high sample frequency and number of historical observations but do not need to be linearly related or parametrically distributed a small decentralized facility may experience so much operational variability that mpc is not effective thus spc may be implemented to detect faults and reduce the number or length of time on site operations staff must be present for a large centralized facility with the buffering capacity to operate at quasi steady state compared to the decentralized case mpc may be useful for reducing chemical inputs and energy optimization an additional consideration is the development of tools to optimize operations at the unit process scale e g aeration basin with recycling membrane bioreactor in addition to the plant wide scale different tasks will employ different problem solving methodologies models that reveal more mechanistic information to assist with diagnosis tend to have poor fault detection accuracy in highly nonlinear systems hence a hybrid method combining model and statistical process control may be a superior problem solving approach each approach will come at a computational cost which is rarely reported in the literature with the major limiting factor being the quality and quantity of data generated by wwtp to develop high quality and accurate big data tools for wastewater treatment industry data scientists computer scientists and engineers must continue to collaborate to maximize data s potential the effectiveness of many state of the art data science tools have not yet been tested in wwtp random forests support vector machines and reinforcement learning have the potential to accommodate many of the features of wwtp data but they still require large training datasets to fit and must produce reliable results kusiak et al 2013 verma et al 2013 with wwtp operations transparency in methodology is one of the keys to adoption so some advanced methodologies may continue to be eschewed in favor of simpler but interpretable methodologies in summary wwtp looking to integrate data driven control should 1 define the scope of the problem and desired goals 2 identify which variables are currently being monitored or should be monitored to effectively capture the scope of the problem 3 use plotting tools to investigate the characteristics of each variable as well as the relationships between variables 4 based on the features observed in the data and analysis goals identify the appropriate method to implement recommendations for further reading on each broad category of methods are given throughout the text 5 fit the models and assess their validity visualize results to ensure that the conclusions are logical and realistic 6 share the results with other wwtp via industry specific publications and conferences to develop mainstream data driven process control tools for wwtp acknowledgments support for this study was provided by the national science foundation partnership for innovation building innovation capacity project 1632227 and by the national science foundation engineering research center program under cooperative agreement eec 1028968 renuwit the authors would also like to thank dr tanja rauch williams and dr eric dickenson for their comments on earlier drafts the anonymous comments from three reviewers also greatly contributed to framing the content of this review acronyms ann auto encoder nn ar autoregressive arima autoregressive integrated moving average arx auto regressive representations with exogenous inputs asm activated sludge model bod5 5 day biochemical oxygen demand bsm benchmark simulation model cas conventional activated sludge cod chemical oxygen demand do dissolved oxygen ewma exponentially weighted moving average ic in control kde kernel density estimation kpca kernel pca lcl lower control limits mcusum multivariate cumulative sum ma moving average mb pls multiblock pls mewma multivariate ewma mpc model predictive control nh4 ammonia nn neural networks no3 nitrate ntu nephelometric turbidity unit oc out of control orp oxidation reduction potential pac powder activated carbon pca principal component analysis plc programmable logic controllers pls partial least squares sbr sequencing batch reactors scada supervisory control and data acquisition spc statistical process control spe squared prediction error srt solids retention time tss total suspended solids ucl upper control limits wwtp wastewater treatment plant 
18839,natural source zone depletion of lnapl a critical review supporting modelling approaches kaveh sookhak lari a b greg b davis a c john l rayner a trevor p bastow a geoffrey j puzon a a csiro land and water private bag no 5 wembley wa 6913 australia csiro land and water private bag no 5 wembley wa 6913 australia b school of engineering edith cowan university 270 joondalup drive joondalup wa 6027 australia school of engineering edith cowan university 270 joondalup drive joondalup wa 6027 australia c school of earth sciences the university of western australia 35 stirling highway crawley wa 6009 australia school of earth sciences the university of western australia 35 stirling highway crawley wa 6009 australia corresponding author csiro land and water private bag no 5 wembley wa 6913 australia csiro land and water private bag no 5 wembley wa 6913 australia natural source zone depletion nszd of light non aqueous phase liquids lnapls includes partitioning transport and degradation of lnapl components nszd is being considered as a site closure option during later stages of active remediation of lnapl contaminated sites and where lnapl mass removal is limiting to ensure nszd meets compliance criteria and to design enhanced nszd actions if required residual risks posed by lnapl and its long term behaviour require estimation prediction of long term nszd trends requires linking physicochemical partitioning and transport processes with bioprocesses at multiple scales within a modelling framework here we expand and build on the knowledge base of a recent review of nszd to establish the key processes and understanding required to model nszd long term we describe key challenges to our understanding inclusive of the dominance of methanogenic or aerobic biodegradation processes the potentially changeability of rates due to the weathering profile of lnapl product types and ages and linkages to underlying bioprocesses we critically discuss different scales in subsurface simulation and modelling of nszd focusing on processes at darcy scale 36 models addressing processes of importance to nszd are investigated we investigate the capabilities of models to accommodate more than 20 subsurface transport and transformation phenomena and present comparisons in several tables we discuss the applicability of each group of models for specific site conditions keywords lnapl nszd modelling biodegradation petroleum contamination 1 introduction natural source zone depletion nszd of light non aqueous phase liquids lnapls in subsurface environments comprises the superposition and linking of several natural processes which result in lnapl mass loss the processes include movement of the parent lnapl relative to air soil and water phases the partitioning of lnapl components e g benzene into other phases air water soil and degradation through biochemical reactions the magnitude of rates of nszd is a critical decision making parameter to compare to active remediation endpoints at lnapl impacted sites sookhak lari et al 2018b furthermore a good estimate of the nszd rate results in an appropriate estimate of the longevity and associated risks of the contamination blanc et al 1996 davis et al 1999 2009 garg et al 2017 mulligan and yong 2004 rivett et al 2011 the history of nszd as an emerging remediation approach and the paradigm shift from monitored natural attenuation mna focusing on fate and transport of dissolved phase hydrocarbon plumes in the saturated zone to nszd was reported in garg et al 2017 where key publications johnson et al 2006 and itrc 2009 were highlighted in particular the paradigm shift from mna to nszd was due to the finding that rates of degradation and mass loss in the vadose zone were being found to be orders of magnitude higher than mna in groundwater garg et al 2017 historically estimates of mass loss and biodegradation had been undertaken separately for groundwater for vadose zones and through direct lnapl fingerprinting lnapls can consist of a range of different petroleum product types including gasolines jet fuels kerosenes diesels lube oils coal tars and crude oils which are likely to undergo nszd at differing rates due to their differing compositions and environmental factors depending on their solubility and vapour pressure lnapl components may partition into groundwater or the soil gas phase prior to biodegradation or perhaps biodegrade without entering the aqueous phase for example for alkanes abreu et al 2009 ng et al 2014 2015 the rate of nszd is a function of the complexity of the lnapl distribution in the subsurface christensen and larsen 1993 sookhak lari et al 2018b the partitioning attributes of components in the lnapl lang et al 2009 lekmine et al 2017 vasudevan et al 2016a geo physical properties of media fluid flow conditions sookhak lari et al 2016a types of microorganisms and their predators franzmann et al 1999 availability of nutrients and electron acceptors wiedemeier et al 1999a and ambient parameters such as ph and temperature garg et al 2017 biodegradation and partitioning processes can result in compositional changes to the lnapl and an apparent stepwise depletion of components in a specific order based on their susceptibilities to biodegradation and partitioning christensen and larsen 1993 peters and moldowan 1993 volkman et al 1984 suggesting that different compound types undergo nszd at different rates together these processes form a highly non linear system to investigate blagodatsky and smith 2012 blanc et al 1996 garg et al 2017 miller et al 2013 traditional approaches for monitoring and determining the rate of nszd also used for mna include measuring several indicators of the biotic processes franzmann et al 1999 2002 either at site scales chaplin et al 2002 johnson et al 2006 or through pore scale sampling hallett et al 2013 commonly these include measuring the abundance of electron acceptors mainly with a focus on oxygen nitrate sulfate and reactions products such as ferrous iron and methane required for biological respiration fermentation and methanogenesis garg et al 2017 the latter is reported to be the dominant lnapl mass loss reaction at many sites garg et al 2017 furthermore various approaches have been used to collect and measure soil gas sookhak lari et al 2017 sweeney and todd ririe 2017 and determine the proportionality of important compounds such as oxygen carbon dioxide and methane these indicators are then converted through stoichiometric approaches to determine the degree of nszd amos et al 2005 chaplin et al 2002 cohen et al 2016 davis et al 1998 2013 eichert et al 2017 johnson et al 2006 lahvis et al 1999 lundegard and johnson 2006 also pilot tests are widely used to estimate the rate of nszd in typical site conditions dobson et al 2007 rockhold et al 2005 despite field scale measurements and pilot tests providing vital data regarding current rates of nszd at a site it is not trivial to extrapolate the data and predict long term rates as nszd rates can differ due to differing lnapl compositions extents of weathering and environmental factors indeed the complex mix of processes combined with weathering and biodegradation can significantly impact the composition and longevity of a lnapl meckenstock et al 2015 modelling biotic degradation of chemicals in porous media is a field of study in various engineering applications examples include municipal landfills lowry et al 2008 visscher and cleemput 2003 storage of greenhouse gases ebigbo et al 2010 enhanced oil recovery landa marbán et al 2017 li et al 2011 natural attenuation and biodegradation in groundwater plumes prommer et al 1999 2002 and intrusion of biodegradable volatile organic compounds through the vadose zone into buildings akbariyeh et al 2016 knight and davis 2013 parker 2003 here we focus on key understandings that allow modelling nszd of lnapls karapanagioti et al 2003 mulligan and yong 2004 rivett et al 2011 under four broad groupings we discuss 21 critical processes affecting the rate of nszd we discuss how different modelling strategies address or accommodate these processes we provide a critical review of the capabilities of 36 models that may have application to modelling nszd we investigate to what extent these models address each of the 21 processes and recommend a limited number with capability for further application and development the analysis is presented in several tables to ease comparison of the models in section 2 we discuss major processes affecting nszd categorized into four main groups different modelling strategies to model these processes are discussed in section 3 in section 4 we discuss capabilities of available models with respect to accommodating the processes discussed in section 2 2 critical processes affecting nszd fig 1 depicts 21 of the major subsurface processes both physical and biological which may affect the overall rate of nszd blanc et al 1996 garg et al 2017 mulligan and yong 2004 rivett et al 2011 sookhak lari et al 2018b a brief description of these and relevant references is also provided in table 1 in this section we describe the key features of the processes in relation to nszd and the necessity for modelling we categorize the processes into four broad groups i physicochemical processes governing fluid transport ii lnapl partitioning and compositional changes iii nszd processes in the vadose zone and groundwater and iv fundamental microbiological processes underpinning effective nszd 2 1 physicochemical processes governing fluid transport subsurface multi phase transport of fluids including lnapl vapour soil gas and groundwater flow has considerable impact on the rate of nszd spatial and temporal dynamics of the fluids alter saturation and interphase surface area in the porous media this consequently affects the rate of mass transfer between phases and influences partitioning of the lnapl compounds into other phases as well as the rate and type of biochemical reactions multi phase fluid dynamics in the subsurface is a complex function of fluid characteristics and ambient parameters a key parameter affecting lnapl transport and consequently vapour and soil gas flow see e g sookhak lari et al 2016a sweeney and todd ririe 2017 is the characteristics of the lnapl release chronic or catastrophic release incidents at different depths cause different morphology and evolution paths of the lnapl plume these also affect the volume of trapped residual and free lnapl as well as the lnapl composition sookhak lari et al 2016b another key controlling feature is the soil formation the soil moisture characteristic parameters lenhard and parker 1990 sookhak lari et al 2018b the heterogeneity of the formation johnston and trefry 2009 and the permeability and hydraulic conductivity sookhak lari et al 2017 are among the soil intrinsic features affecting subsurface fluid flow for instance the soil van genuchten parameters have a great impact on capillary pressure and vertical distribution of lnapl in the soil profile lenhard et al 2018 sookhak lari et al 2018b these also impact the volume of trapped and residual lnapl and the interphase surface area between different fluid pairs lenhard et al 2018 furthermore ambient phenomena such as biofilm growth or even gas bubble formation as a result of biological processes are believed by some researchers to alter the soil intrinsic features such as permeability and hydraulic conductivity amos and mayer 2006 tartakovsky et al 2013 lnapl physical characteristics such as viscosity and density have been shown to significantly impact distribution recovery and nszd of the lnapl lenhard and parker 1990 sookhak lari et al 2015 2018b along with the soil moisture characteristic curve parameters density and viscosity are the major parameters determining lnapl plume evolution and distribution the value of density and viscosity of the lnapl may significantly change as a result of nszd compositional changes and biogenic heat formation e g due to biological activities beyer et al 2016 sookhak lari et al 2016a 2018a groundwater dynamics also play a significant role soil water or capillary hysteresis depends on the saturation path history and is a function of variations in the groundwater table elevation e g during the initial penetration of the lnapl or following seasonal water table fluctuations it alters the relative permeability of the soil and the capillary pressure saturation relationship it is shown that hysteresis can considerably change the morphology and homogeneity of the lnapl plume furthermore water table fluctuations increase the volume of immobile lnapl residual or trapped lnapl lenhard et al 2018 pasha et al 2014 sookhak lari et al 2016a immobile lnapl is not easily recoverable through active remediation approaches and may remain as an ongoing source of contamination lekmine et al 2017 groundwater flow also augments the rate of lnapl dissolution into the aqueous phase the magnitude of the interphase mass transfer of mass is a function of the interfacial velocity of the fluids lekmine et al 2017 sookhak lari et al 2015 depending on the dynamics of an lnapl plume in the subsurface a suitable strategy for modelling nszd should accommodate a number or all of the above processes and parameters for instance multi phase transport may be of particular importance for modelling an evolving lnapl plume subjected to variable groundwater table compared to a quasi static subsurface condition similarly lnapls comprising highly partitioning components may require a multi component modelling strategy 2 2 lnapl partitioning and compositional changes the composition of lnapls can vary dramatically in their properties components and carbon ranges depending on the product type crude oil gasoline kerosene jet fuels diesel and lube oil range products major partitioning processes that an lnapl can undergo in the subsurface will depend on the proportion of volatile non volatile soluble insoluble and the carbon skeleton configuration complexity of components that comprise the lnapl partitioning of lnapl components into other phases volatilisation and dissolution can result in significant changes to the composition due to physical processes brauner et al 2004 these may alter the lnapl properties such as increasing the viscosity and alter the potential transport of lnapl through the porous media newell et al 1995 physical losses of the volatile and soluble components generally affects the lighter components c10 with the aromatic and aliphatic components both affected by volatilisation and mainly the aromatics affected by dissolution into water with partitioning of lnapl into gas and water phases largely governed by raoult s law and the mole fractions of the components in the lnapl lekmine et al 2017 for example lnapl components such as benzene toluene ethylbenzene and xylenes have lower molecular weights and higher solubilities compared to other constituents vasudevan et al 2016a these are readily volatilised and partition into groundwater thus leaving behind heavier molecular weight constituents in the source zone suthersan et al 2017 see also the discussion in section 2 4 gasolines are the main product types affected by volatilisation and dissolution because they contain a high proportion of volatile c4 to c10 components and water soluble compounds aromatics mainly alkylbenzenes so for fresh gasolines the major early changes to the composition are largely due to volatilisation and dissolution depending on the subsurface environment and the contact with groundwater over time such processes may allow a weathered gasoline to eventually resemble kerosene on the other hand crude oils and mixtures of different product types are more complicated and can vary dramatically in their compositions and range from light products like gasoline to heavy products like lube oils and any combination of light medium and heavy product types gasoline kerosene diesel and lube oil mass losses and nszd rates the lnapl has experienced can often be calculated from compositional changes in lnapls using a conservative tracer over a specified time period the conservative tracers used can vary and selection of a conservative tracer is generally based on it being one of the most non volatile water insoluble and biodegradation resistant components present in the lnapl samples in sufficient relative abundances to measure concentration increases of the selected conservative tracers in the lnapl samples allow losses to partitioning and biodegradation to be calculated baedecker et al 2018 douglas et al 1996 2012 johnston et al 2007 despite this providing estimates of the current rate of lnapl mass loss it does not estimate rates over future years e g over decades therefore key features of lnapl partitioning and compositional changes during nszd need to be embedded into nszd models 2 3 nszd processes in the vadose zone and groundwater extensive investigations have been carried out over the last 20 30 years on partitioning of lnapl components to groundwater dissolution and into the vadose zone volatilisation and their subsequent biodegradation and attenuation along with biodegradation and compositional changes in the lnapl itself these primarily constitute the nszd processes linking these partitioning and biodegradation processes holistically across the water saturated and unsaturated zones is a primary challenge lnapl resides across these zones johnston and trefry 2009 lenhard and parker 1990 tomlinson et al 2017 and seasonal and other transient affects vary lnapl and water saturations and air filled porosities and relative interfacial areas and flow dynamics to yield variable component concentrations fluxes and biodegradation above and below the water table davis et al 1993 steffy et al 1995 these also commonly drive the risk profile of an lnapl source but also feed the mass loss mechanisms of nszd for dissolved contaminant plumes mna is an accepted biodegradation remedial strategy a broad range of science has been brought together to quantify mna processes in groundwater multiple electron acceptors such as oxygen nitrate sulfate iron and manganese oxides and methanogenic processes davis et al 1999 dolfing et al 2008 essaid et al 2011 2015 patterson et al 1993 rivett and thornton 2008 wiedemeier et al 1999b novel ways of determining degradation rates gillham et al 1990 thierrin et al 1995 and the role of microorganisms franzmann et al 2002 commonly the feasibility of the application of mna as a site closure option assumes the lnapl source has been or is being removed wadwer 2004 huntley and beckett 2002 indicated that almost all lnapl mass removal was required in a homogeneous aquifer to decrease plume concentrations huntley and beckett 2002 removal of lnapl mass to such a degree was often not feasible apart from shallow and readily accessible lnapl sources in contrast and through describing a general discharge versus mass model falta et al 2005 determined that if aquifers indeed were heterogeneous then the mass flux of dissolved components into a groundwater plume from a napl source decreased in proportion to the mass removed from the napl source zone falta et al 2005 exponential decay of a source where mass discharge is proportional to source mass has also been considered newell et al 1996 for groundwater mna commonly the complexity of the lnapl distribution its saturation and its depletion over time has not been accommodated in models these traits and the underlying processes are critical to capture in a conceptual and actual model of nszd in soils and vadose zones gas transport and its compositional change and biotransformation have been topics of research for many decades barber et al 1990 glinski and stepniewski 1985 the connection to lnapl sources and mass loss has a more recent history due to the threats posed to human health by potential inhalation of hydrocarbon vapours in buildings abreu and johnson 2005 2006 patterson and davis 2009 and possible production of methane research on petroleum vapours focused on its biodegradation to quantify the mitigated threat compared to chlorinated vapours that may persist more in vadose zones davis et al 2004 key to mitigating petroleum vapour threats was the availability of oxygen in the subsurface to sustain biodegradation davis et al 2005 2009 devaull 2007 knight and davis 2013 lahvis et al 1999 ostendorf and kampbell 1991 patterson and davis 2009 in some studies methane was the hydrocarbon that was being biodegraded by the available oxygen rather than volatile components of the lnapl such as benzene toluene etc garg et al 2017 lundegard et al 2008 there appears ample evidence that in some circumstances methane is the dominant hydrocarbon in the vadose zone above an lnapl garg et al 2017 and in other cases vocs are dominant davis et al 2005 in some cases neither vocs nor methane seem present whereby biodegradation processes may occur in close proximity to the lnapl itself where it is distributed across the capillary fringe and or into the vadose zone davis et al 1998 2013 apart from the fundamental transport and biodegradation mechanisms in the vadose zone triggers for the dominance of methanogenesis compared to the volatilisation of other vocs as drivers of mass depletion or neither during nszd need to be embedded into models of nszd over time the dominance of vocs perhaps associated with a recent release or methane as the major mass loss from lnapl may transition from one to the other models need to be able to accommodate this apart from partitioning from the lnapl and subsequent processes in groundwater and vadose zones critical to quantifying nszd processes is also understanding of the partitioning behaviour of gases and volatile compounds within and across the capillary fringe barber and briegel 1987 barber et al 1990 beyond the downgradient edge of lnapl zones reactions within a dissolved groundwater plume may continue to produce methane and carbon dioxide and or release volatile compounds such as benzene that may migrate vertically upwards towards the water table and capillary fringe some studies sought to quantify transfer mechanisms and attenuation in this zone which is sometimes quite dynamic barber et al 1990 mccarthy and johnson 1993 rivett et al 2011 a model of nszd should also be able to consider such features 2 4 fundamental microbiological processes the microbial degradation of petroleum hydrocarbons has been widely explored using single or mixed cultures in the laboratory salanitro 2001 with degradation pathways described for alkanes alkenes isoalkanes cycloalkanes polyaromatic heterocyclic and btex compounds salanitro 2001 biodegradation of petroleum lnapls can result in an apparent stepwise depletion of compounds in a specific order based on their susceptibilities to biodegradation abreu et al 2009 christensen and larsen 1993 kaplan et al 1996 peters and moldowan 1993 volkman et al 1984 wade 2001 fuel types are variably affected by biodegradation in the subsurface gasoline contains a greater mass of relatively highly volatile and soluble components which would subsequently degrade in the vadose zone soil or groundwater whereas kerosene diesel and lube oils contain mainly semi and non volatile compounds typically with carbon ranges c9 despite the limited volatile or soluble components diesel for example has been reported to have all of the n alkanes removed after approximately 20 years due to biodegradation under some conditions christensen and larsen 1993 leaving more complex compound types like branched and cyclic alkanes unaltered at this extent of biodegradation an open question here is regarding the nszd of different compound types long chained alkanes short chained alkanes branched alkanes aromatics resin and asphaltenes for example as modelled by ng et al 2015 and ng et al 2014 and ambient parameters controlling long term rates of nszd we try to highlight the necessity of understanding the complexity and interaction of such parameters while considering modelling strategies for nszd these recent models assume the non volatile dissolved organic carbon nvdocs or polar compounds present in the groundwater are sourced from the partial degradation of aromatics resin and asphaltenes ng et al 2014 or only aromatics garg et al 2017 ng et al 2015 based on work by thorn and aiken 1998 however recent data from the site shows that after 30 years that the aromatics alkylbenzenes and naphthalenes like the alkylcyclohexanes and isoprenoids were the most recalcitrant components measured in the lnapl baedecker et al 2018 which may suggest the aromatics are not be the source of the nvdocs the resins or the more water soluble portion of the resins are a potential source of the nvdocs as the bedmidji crude oil contains 4 6 resins eganhouse et al 1993 the resins do not seem to have been investigated as a source of the ndvocs and contain the components combinations of a range of functional groups such as alcohols ketones aldehydes and carboxylic acids that could partition nvdocs directly from the lnapl to groundwater related to this is the in place biodegradation of insoluble components of lnapl like n alkanes which change the composition of lnapl itself intrinsically we perceive biodegradation to occur in a water phase but lnapls contain components that are largely insoluble investigations suggest that microbial communities are capable of residing in residual water at the lnapl interface and access these insoluble components via biosurfactant emulsification and associated mechanisms all of which are expected to enhance the rates of biodegradation marchant and banat 2012 the conceptual understanding is microbial communities reside in water surrounded by the lnapl and access the lnapl directly or create micelles smaller components of lnapl preferentially consuming lnapl portions and leaving modified residual levels of lnapl behind e g without the n alkanes these complexities need to be further investigated and incorporated into models where we are seeking to predict lnapl nszd and lnapl weathering features over decadal timeframes the rate of nszd through biodegradation is also impacted and can vary depending on the ambient conditions present at the site contaminant bioavailability and chemical composition microbial community composition and electron acceptors available to the microbial community to utilise davis et al 1999 franzmann et al 2002 röling and van verseveld 2002 in addition the biodegrading microbial community itself has been shown to depend on other factors such as temperature rayner et al 2007 ph or salinity shelton et al 2014 which affects the presence of degrading organisms microbial activity and the biodegradation rate shelton et al 2016 at highly contaminated legacy sites low biodegradation rates can also result from the presence of toxic contaminant concentrations accumulation of toxic metabolites and low bioavailability of the contaminant or other unfavourable environmental conditions ham et al 2004 liang et al 2009 prommer et al 2002 recharge and transport of micronutrients through the vadose zone can also have an effect on biodegradation at the bemidji site the amount of weathering of the crude oil was higher in zones with higher recharge from the ground surface bekins et al 2005 garg et al 2017 this showed the potential effect of the transport of microbial growth nutrients through downward fluid flow most likely phosphorus gray et al 2010 also indicated that adding inorganic growth essentials nutrients could enhance methanogenesis similarly aldén et al 2001 and gallego et al 2001 described the addition of nutrients nitrogen and phosphorous to improve microbial growth and bioremediation the discussion above shows that in the natural environment at micro scales the exact mechanism s of biodegradation is quite complex and not fully understood meckenstock et al 2015 schmidt et al 2017 there is promise to understand underlying patterns of the microbial community composition activity and function through molecule and other advanced techniques kimes et al 2013 mason et al 2014 yergeau et al 2015 but embedding molecular and genetic information in scaled models seems a future activity however an average response of microorganisms to the abundance of substrates and other growth and maintenance prerequisites is well established at meso and macro scales microorganisms use lnapl compounds as a source of energy and or carbon along with nutrients electron acceptors and enzymes for catabolism and anabolism together metabolism biotic processes are mainly through aerobic and anaerobic respiration e g nitrate sulfate or methanogenesis or fermentation the carbon source also acts as the electron acceptor blanc et al 1996 garg et al 2017 the native microbial community has been demonstrated to be readily capable of degrading lnapl however changes in the lnapl composition due to biotic and abiotic processes may also result in changes in associated microbial community composition and diversity due to enhancement of niche degrading microbes or recalcitrance and or toxicity of the lnapl and residual products bruckberger et al 2018 salanitro 2001 types and sequences of the biotic processes depend on multiple factors including the complexity and age weathering of lnapl chemicals abundance of the electron acceptors and reduction potential of the aquifer temperature most favourable range is 20 c 30 c and ph most favourable range is near neutral condition can play significant roles in nszd blanc et al 1996 garg et al 2017 less critical factors seemed to be parameters relating to predation by protozoans and biofilm sloughing since there may be less impact on the rate of biodegradation essaid et al 2015 garg et al 2017 it is still not very clear as to the role of chemotaxis and whether this enhances the rate of degradation due to enabling organism to access less bioavailable lnapl products adadevoh et al 2017 wang et al 2016 3 modelling strategies the necessity of modelling critical parameters affecting nszd was discussed in the previous section in general individual or combinations of nszd processes have been modelled through three different modelling strategies karapanagioti et al 2003 miller et al 2013 including mass balance models analytical approaches and numerical simulations hybrid models benefiting from a combination of these have also been applied mass balance models are site specific models and simplify site conditions both temporally and spatially adamson and newell 2009 newell and adamson 2005 ng et al 2014 basic mass conservation equations are utilised without linking nszd processes to flow or mass transport such models are useful as a basis for further detailed analytical and numerical studies or to give preliminary estimates of process rates johnson et al 2006 verginelli and baciocchi 2013 analytical models rely on solutions to simplified differential equations describing the system as such solutions only exist for certain conditions analytical models are only applicable for cases where the model assumptions hold these are mostly equilibrium conditions in the flow field simplified representations for reactions and symmetricity of the problem berlin et al 2015 bouchard et al 2011 chen et al 2016 numerical models approximate a solution to the governing differential equations through discretization techniques these models are computationally more demanding and require more effort to implement however their flexibility in comparison with analytical models in dealing with multiple processes and parameter variability is significant miller et al 2013 numerical models can be further categorized based on their representations of the nszd processes and parameters 3 1 the scale of the problem numerical modelling of physio chemical processes and microbial activities in porous media can be either at a molecular scale wu and coulon 2016 pore scale schmidt et al 2017 or a meso and macro scale sookhak lari et al 2018a the physics of micro scale flow and mass transport have been extensively addressed in the literature liu and mostaghimi 2017 however pore scale understanding of microbial growth and biochemical reactions is yet to be developed meckenstock et al 2015 pore scale modelling of microbial growth is mostly conducted through direct simulation of individual microorganisms wu and coulon 2016 modified lattice boltzman lb equations or pore network modelling yan et al 2017 however morphology of biological colonies and mutation in their genes are among the existing ambiguities schmidt et al 2017 xiong et al 2016 also pore scale mass transfer limitations in particular into the biofilm is poorly understood gharasoo et al 2015 liu and mostaghimi 2017 xiong et al 2016 these prohibit adequate approaches for upscaling the understandings from a pore scale to meso and macro scales bahar et al 2016 ebigbo et al 2010 tartakovsky et al 2013 nszd is mostly modelled at a darcy scale in such case the navier stokes and continuity equations are averaged for the flow field similarly biochemical processes are modelled through empirical correlations mimicking an average behaviour of microbial populations rivett et al 2011 these are studied in more details in section 3 3 1 3 2 flow field representation at a pore scale either a navier stokes equation or its simplified versions stokes equation or hagen poiseuille equation are used for direct simulation of single or multi phase flow field approaches like lb are also used to minimize computational costs yan et al 2017 however such a detailed level of calculation is still not practical for macro e g field scales the flow field at a macro scale is modelled based on the conceptual model of the site this may vary from analytical models to darcy and transport equations for the saturated zone richards and transport equations for saturated and unsaturated zones and two and multi phase flow and transport equations for the entire domain miller et al 2013 details of these models are presented in section 4 3 3 modelling microorganisms microbial processes and growth models are either unstructured or structured in unstructured growth models only one indicator of the microbial population is studied usually the mass or number of the microbes on the other hand various features of the microbes are studied in structured models these may include the structure of their deoxyribonucleic acid dna and adenosine tri phosphate atp blanc et al 1996 tartakovsky et al 2013 microbial growth models can also be segregated or unsegregated foe segregated models individual microbes and their behaviour are studied in contrast unsegregated models study an average representation of the microbial colonies in the form of a continuum models for nszd are mostly unstructured and unsegregated blanc et al 1996 most of the nszd models consider microbes as a biofilm attached to the grains however there are models considering a concentration of floating microorganisms movement of these are modelled in the form of an advection diffusion process and sometimes their precipitation is also included through application of the stokes law bradford et al 2014 microbial chemotaxis in which microorganisms actively chase and move towards a food source regardless of the flow field has also been modelled through modified advection diffusion equations adadevoh et al 2017 wang et al 2016 3 3 1 mathematical representation of biotic processes at a darcy scale biochemical reactions are either at equilibrium or time dependant kinetic blanc et al 1996 rivett et al 2011 and sometimes instantaneous davis et al 2009 a zero order reaction is expressed as 1 d s d t c o n s t a n t in which s represents the substrate m l3 and t is time t the non dimensional sherwood peclet and damkohler numbers are used to identify to what extent the assumption of zero order reactions hold barry et al 2002 rifai and bedient 1990 sookhak lari and moeini 2015 a commonly assumed kinetic reaction for substrate consumption is first order 2 d s d t α 1 s where α 1 is a constant a single monod equation the michaelis menten equation with a time varying term for biomass population is the most popular equation describing the substrate consumption rate as a function of the biomass 3 r s d s d t k x s k s s where x is the biomass concentration m l3 k s is the half saturation m l3 and 4 k μ m a x y where μ max is the maximum specific growth rate t 1 and y is the biomass yield coefficient blanc et al 1996 the microbial growth is limited by the excess amount of substrate 5 r s k x s k s s s 2 k i where k i is a constant also for a non competitive inhibitor e g end product 6 r s k x i s k s s i 1 c i k i 7 r s k x s k s i s i 1 c i k i or 8 r s k x s k s s i i 1 c i k i where i is an inhibiting factor and c i is the concentration of the non competitive inhibitor other forms of modelling inhibition are presented in the literature blanc et al 1996 more advanced representations for the substrate utilization rate and counterpart microbial growth rate include the abundance of electron acceptors barry et al 2002 battistelli 2004 9 r s k x s k s s i 1 n a i k a i a i where a i is the concentration of the electron acceptor i and k ai is its half saturation the competition process for two substrates is represented as huang et al 2006 rerp 2000 10 r s 1 k 1 x s 1 k s 1 s 1 k s 1 s 2 k s 2 r s 2 k 2 x s 2 k s 2 s 2 k s 2 s 1 k s 1 where k 1 k 2 k s1 and k s2 are constant values the first order growth of biomass is used in some models 11 d x d t α 2 x where α 2 is a constant in more sophisticated models the substrate utilization and biomass formation are connected through the yield coefficient the monod based growth and decay of the biomass can simply be represented by 12 d x d t μ m a x x s k s s b x where b t 1 is the first order decay coefficient however infinite growth of the biomass is impossible some models have options to limit the biomass growth for a multi component monod based equation this can be expressed as 13 d x d t μ m a x x i b s k s s i 1 n a i k a i a i b x where i b is the inhibitor for biomass formation if i b 1 there is no growth limit otherwise the growth inhibitor is usually expressed as 14 i b 1 x k b where k b is a constant or 15 i b ρ x β x where β is a constant and ρ x is the biomass density m l3 4 available models depending on the problem and phenomenon to be studied subsurface modelling is conducted through various approaches freedman et al 2017 rivett et al 2011 table 2 introduces 36 models the table presents the models capabilities in dealing with nszd processes and parameters depicted in fig 1 also in table 3 the complexity of the biodegradation module in each model is referenced to the governing equations in section 3 3 1 the information in both tables are based on the models features introduced in theoretical reports if available and relevant publications reporting application of the models further capabilities of some models as e g amendments to open source codes may also exist below we categorize these models based on their representation of the flow field and discuss the conditions under which the models may be applicable we also discuss the emerging needs and tools for representative modelling of nszd at the end of this section 4 1 analytical models analytical models have been used to study the partitioning of lnapl compounds hers et al 2000 and their biodegradation lahvis et al 1999 luo et al 2015 siddique et al 2008 in groundwater and in vadose zone soils the analytical models in table 2 are those with biodegradation modules and include biochlor bioscreen brknapl ecosys remchlor remfuel and r unsat the models include zero or first order reactions to model biodegradation except for brknapl these are mostly 1 dimensional models with limited capabilities for modelling flow and mass transport in general no biomass growth or multi component reactions are considered however bioscreen has an option to model plume attenuation by entering key electron acceptors also biochlor simulates the generation of chlorinated solvent degradation products there are also some other analytical models in the literature with no capability of modelling biodegradation which are used as parts of other modelling packages i e to form hybrid models for nszd essaid et al 2011 fernández et al 2016 gallo and hassanizadeh 2002 jacques et al 2008 marruffo et al 2012 yoon et al 2009 despite inherent limitations of analytical models some notable application of these also exist for example modelling first order decay of btex by bioscreen jeong et al 2005 biological and monod based decay of phenanthrene in a batch experiment no flow by brknapl sandrin et al 2006 first order decay of ethylene dibromide and 1 2 dichloroethane plumes at a site by remchlor henderson et al 2009 and identifying unsaturated zone biodegradation mass removal rates at bemidji site by calibrating r unsat essaid et al 2011 also some separate analytical modelling approaches have been undertaken of vadose zone partitioning and biodegradation which are mostly based on derivation of solutions to the transport equations in the vadose zone baehr 1987 lahvis et al 1999 4 2 saturated flow and transport models saturated flow models darcy equation mimic the aqueous phase flow regime in the saturated zone miller et al 2013 zheng and wang 1999 16 s s h t k h s w where s s is the specific storage h indicated the hydraulic head l t is the time t and k represents the hydraulic conductivity tensor also s w in equation 16 is the source term many such models implement forms of the advection dispersion equation to model multi species solute mass transport for a single component 17 c t d c v c r where c is the concentration ml 3 v is the darcy velocity vector lt 1 and d is the dispersion tensor l2t 1 the sink source term is also represented by r ml 3t 1 discussions on the rate limited and equilibrium interphase mass transfer are also presented in section 4 4 linking relevant groundwater transport and attenuation processes together to form saturated flow models for nszd was attempted for multiple soluble species in the 1990s clement et al 1998 with more sophisticated geochemical models being developed to accommodate all electron acceptor donor and ancillary reactions prommer et al 1999 and to understand the limitations and complexities of controls on plume mna such controls include reactions on the fringes of plumes governed by small scale lateral dispersivities leading to limited mixing of dissolved lnapl components and electron acceptors ham et al 2004 and the implications of seasonal and transient effects e g prommer et al 2002 since the 1990s similar concepts have been applied in a number of saturated flow models to study nszd well known models in this category are biomoc bioredox bioplumeiii bionapl3d gsim mt3dms pht3d rt3d and seam3d among these pht3d has a strong capability for accommodating and calculating geochemical conditions including ph biomoc bionapl3d gsim and seam3d are able to consider different types of microorganisms bioplumeiii and rt3d can consider transport of microorganisms through an advection diffusion equations as introduced in table 3 the models include different forms of monod based equations for biochemical reactions saturated flow models are applicable for steady lnapl plumes in which the equilibrium or rate limiting dissolution process can be modelled as a boundary condition and also partitioning into the gaseous phase is negligible a number of notable field or pilot scale applications of these models to study aspects of nszd include sequential use of electron acceptors at bemidji site by biomoc essaid et al 2011 field scale first order decay of benzene by bioplumeiii suarez and rifai 2004 field scale monod based decay of various gasoline ingredients by bionapl3d freitas et al 2011b molson et al 2002a vaezihir et al 2012 anaerobic degradation of organic matters at bemidji site by pht3d ng et al 2015 and a series of monod based btex degradation processes at a site in usa by rt3d lu et al 1999 in addition to the models named above some in house codes have also been used to study nszd in fully saturated conditions jahan et al 1999 vasudevan et al 2016b 4 3 unsaturated flow and transport models unsaturated flow models are based on the richards equation and constitutive relationships for the flow field to mimic the aqueous phase flow regime in the saturated and unsaturated zones miller et al 2013 panday and huyakorn 2008 18 s s s w h t ε s w t k h z s w where ε is the porosity z is the elevation l and s w is the water saturation constitutive relationships are required to relate the hydraulic conductivity saturation and pressure head including capillary effects transport equations like that in equation 17 apply models in this category include pflotran hp1 hydrogeochem min3p min3pdusty opengeosys surfact swms3d and tough2react n a number of these models include gas diffusion transport through the vadose zone e g pflotran min3pdusty surfact and swms3d among these models surfact was developed based on rt3d and therefore inherits the parent model capabilities including options for transport of microorganism models min3p and hydrogeochem include options to introduce customized biochemical reaction kinetics min3p also enables the user to model gas bubble formation in the aqueous phase as a result of biochemical reactions pflotran is an open source and parallel flow and multicomponent reactive transport code with options for complex biochemical reactions unsaturated flow models are applicable for steady lnapl plumes and residuals in which the equilibrium or rate limiting dissolution and evaporation process can be modelled as boundary conditions notable field or pilot scale application of these models to study nszd processes include dynamic changes in microbial characteristics at a bioremediation site in colorado usa by a modified version of hydrogeochem fang et al 2011 multi component monod based degradation at a kerosene contaminated site in germany by min3p miles et al 2008 and multi component monod based degradation of toluene and o xylene at a site in norway by swms3d in house codes have also been used to study nszd in unsaturated flow fields abreu et al 2009 molins et al 2010 rockhold et al 2004 2005 in particular a generalised representation of biochemical reactions is applied in an unsaturated flow and transport model mayer et al 2002 4 4 two phase and multi phase models two phase and multi phase flow models are able to model the flow of aqueous and gaseous phases for two phase models and gaseous aqueous and lnapl phases for three phase models for multicomponent models the mass balance equation is miller et al 2013 pruess and battistelli 2002 19 c i t β 1 n p c β i v β d c β i r i where i and β refer to the component number i and phase β respectively with n p as the total number of phases the velocity is calculated through the darcy law equation 20 v β k k r β μ β p β ρ β g with constitutive relationships to relate relative permeability of each phase pressure p including capillary and the phase saturation here k and k rβ are the absolute and relative permeability to phase β l2 and respectively ρ β and μ β are the density ml 3 and viscosity of phase β ml 1t 1 and g is the acceleration vector lt 2 most of the models also include partitioning either by considering equilibrium conditions raoult s and henry s law or through rate limited mass transfer 21 r m k c β i c β i e q where m k is the mass transfer coefficient for species i across the boundary layer lt 1 and c β i and c β i eq are the mass concentrations in the bulk aqueous solution and at equilibrium respectively r is then the rate of mass transfer ml 2t 1 the mass transfer coefficient is determined through empirical or analytical sherwood number correlations rerp 2000 sookhak lari et al 2015 the models we investigate in table 2 include 3dmm bioslurp miser mofat napl simulator stomp tmvoc tmvocbio and utchem among these miser napl simulator and mofat are two dimensional utchem tmvoc and tmvocbio have options for high performance computing and parallel processing utchem and tmvocbio are able to model heat transport complex biochemical reactions inhibitors and different microorganisms competitive reactions are possible in these two as well as 3dmm utchem is also able to model microbes transport and their growth effects on the media multi phase models usually require greater computational resources to be applied despite their significant modelling capabilities these requirements limit their application to study the dynamics of lnapl in subsurface systems active remediation approaches and nszd falta and kueper 2014 miller et al 2013 sookhak lari et al 2018a sookhak lari et al 2019 a number of notable field or pilot scale applications of these models to study nszd processes includes monod based degradation of btex in a pilot test to study bioremediation by 3dmm huang et al 2006 single component first order decay of a mixture of volatile organic compounds in the vadose zone by mofat gaganis et al 2004 and first order degradation of benzene in an anonymous coastal alluvial site subjected to hysteresis water table fluctuations by napl simulator yang et al 2013 in house codes have also been used to study two and multi phase cases of nszd gallo and manzini 2001 hron et al 2015 4 5 multi physics models multi physics package are adjustable and multi purpose scientific software for numerical approximation of user specified systems of partial differential equations miller et al 2013 most packages can be implemented on clusters and supercomputers to conduct parallel processing calculations however application of such tools to model nszd is not extensive multi physics packages such as comsol and ug have been used to model subsurface biochemical reactions at pore and macro scales pore scale processes like chemotaxis have been modelled through application of comsol adadevoh et al 2017 wang et al 2016 ug has also been used to model multi component monod based degradation of various hydrocarbons in saturated flows both at pilot and field scales watson et al 2005 4 6 emerging needs and tools for representative modelling the previous sections have revealed the current level of complexity that existing modelling frameworks can handle among these multi phase multi component models are able to address some of the more critical transport and partitioning phenomena required to describe nszd processes models like tmvocbio and utchem include options for simulating heat generation and transport variations in ph degradation and partitioning to different phases jung and battistelli 2016 rerp 2000 as these require massive computational effort a number of multi phase multi component models are now configured as parallel processing versions enabling application of clusters and supercomputers to conduct heavy simulations jung et al 2017 regardless application of these to address all processes applicable to nszd and even active remediation is not yet common sookhak lari et al 2018a sookhak lari et al 2018b 2019 especially over long time periods decades and at fine spatial scales the sequence and type of biochemical reactions which can be modelled are determined through built in libraries in simulation packages these are based on the current level of understanding from application and observations garg et al 2017 as previously discussed the current concepts for the class and sequence of reactions as e g in ng et al 2014 and ng et al 2015 may include assumptions that may need further focus to ensure assumptions about lnapl weathering over long time periods is accurately accommodated in models similarly research advances regarding other key nszd processes whilst informing models of nszd processes and their evolution over time will challenge the ability of currently available models accommodating all process concurrently and accurately in one code and being able to deliver simulations in a timely manner seems still a future challenge in order to link site scale observations and built in libraries in numerical models time and length scales are inevitably integrated and therefore some information and or prediction accuracy may be lost key to progress will be the scalability of micro and meso scale experimentation to elucidate nszd processes at field scale these can be used to better quantify relationships between ambient parameters ph temperature etc types of hydrocarbons and reactions e g exact mechanism of complex syntrophic fermentation methanogenic reactions and geo physical features at short time and length scales this provides improved insights for modelling purposes with less assumptions furthermore pore scale simulations may also provide additional understandings regarding the dynamics of biochemical reactions and microorganisms e g biofilm growth and sloughing mutation in genes and food chain not in any of the models as a function of flow field characteristics and therefore a better upscaling from pore scale to darcy scale of the governing equations bahar et al 2016 tartakovsky et al 2013 wang et al 2016 xiong et al 2016 advanced mathematical approaches like converting the governing partial differential equations into their lattice boltzmann representations can also significantly reduce the pore scale computational costs yan et al 2017 5 conclusions active remediation of sites contaminated with lnapl is an expensive and often prolonged task the efficiency of active remediation decreases over time and may become less than the rate of nszd garg et al 2017 this provides a motivation to consider nszd as a continuous and passive clean up option with insignificant side effects and reduced costs however it is vital to measure current and estimate future rates of nszd to enable a comparison with active remediation efforts and also to estimate the longevity of risk factors and lnapl itself the long term effectiveness of nszd needs to be quantified this enjoins a nszd modelling approach we provide a critical review across the literature on the key processes that might need to be considered in conceptual and actual models of nszd compositional changes of lnapl due to partitioning and subsequent biodegradation and further weathering means nszd rates are likely to change over decadal time frames various classes of chemicals might control the long term rate of lnapl nszd methanogenesis may dominate at some time periods garg et al 2017 as might aerobic biodegradation of volatile compounds in vadose zone soils davis et al 2005 mna in groundwater might also be a dominant process at some point of time despite seemingly orders of magnitude biodegradation rate differences at other points in time lnapl fingerprinting and changes in composition provides indicators of historic weathering and in part provides measures of the scale of volatilisation dissolution and intrinsic biodegradation and overall mass loss the key understandings are in place but transitions between times of dominant nszd processes need refinement as do the geochemical and hydrogeological conditions under which they may occur and be dominant coupled to this are differences predicated by product type gasoline crude diesel etc and scale and size of release events a significant gap exists in upscaling micro scale biological processes to meso and macro scales schmidt et al 2017 even though darcy scale lumped parameter equations have been widely used to quantify the nszd processes at pilot and field scales the physio chemical understanding of the processes is yet to be improved a number of existing questions have been presented in the literature garg et al 2017 schmidt et al 2017 furthermore processes like assimilation and existence of food chains have rarely been studied at darcy scales this is mostly due to the lack of appropriate mathematical representations averaging and verifying the pore scale governing equations may be of some help xiong et al 2016 we noted the necessity for models capable of handling extremely complex syntrophic fermentation methanogenic reactions that are sensitive to ambient parameters not typically included in transport models e g ph and temperature we highlighted the needs for meso scale experiments and pore scale simulations to provide more universal input libraries and upscaled governing equations for modelling nszd multi phase multi component models have rarely been used to study nszd across 36 models considered these seem to have a strong basis for future nszd modelling despite their strong modelling capabilities application of these models requires an adequate level of team expertise in the geo physics geo chemistry and geo biology often access to supercomputing and parallel processing facilities is needed however it has been shown that detailed field scale multi phase and multi component transport phenomena can be modelled through such modelling frameworks miller et al 2013 sookhak lari et al 2016a sookhak lari et al 2018a linking these to the relevant level of microbial geochemical and biodegradation processes under potentially transient subsurface conditions remain challenges for long term estimation of nszd and lnapl longevity but a challenge that needs to be addressed advanced computational algorithms are progressively implemented in simulators to reduce computational costs of modelling highly nonlinear systems advances in parallel processing clusters and supercomputers promise improved capabilities of the models to investigate complex interconnected biochemical reactions miller et al 2013 machine learning can be used to analysed massive data collected from field measurements to shape site specific models for nszd wu and coulon 2016 these seem to form the basis for new generations of representative nszd models that can address the challenges outlined finally it is recognised that nszd processes operate concurrently with active remedial efforts at lnapl sites an appropriately capable code could be used to simulate mass removal via both approaches and to determine at what stage nszd becomes the dominant mass removal mechanism compared to active mass removal efforts sookhak lari et al 2018a sookhak lari et al 2018b 2019 this provides the basis for decisions around proceeding with active remediation at lnapl impacted sites or transitioning to a nszd site closure regime acknowledgements the authors thank the anonymous reviewers for their valuable comments we would also like to thank our colleagues at csiro and collaborators for their extensive insights and support over an extended period we thank chris barber for initiating the work 30 years ago colin johnston for his pioneering lnapl research brad patterson for making transients visible via online probes peter franzmann for microbial insights rod lukatelich for championing the value of research in industry andrew king for driving practical outcomes and to bp for being a consistent and strong supporter of our research over several decades 
18839,natural source zone depletion of lnapl a critical review supporting modelling approaches kaveh sookhak lari a b greg b davis a c john l rayner a trevor p bastow a geoffrey j puzon a a csiro land and water private bag no 5 wembley wa 6913 australia csiro land and water private bag no 5 wembley wa 6913 australia b school of engineering edith cowan university 270 joondalup drive joondalup wa 6027 australia school of engineering edith cowan university 270 joondalup drive joondalup wa 6027 australia c school of earth sciences the university of western australia 35 stirling highway crawley wa 6009 australia school of earth sciences the university of western australia 35 stirling highway crawley wa 6009 australia corresponding author csiro land and water private bag no 5 wembley wa 6913 australia csiro land and water private bag no 5 wembley wa 6913 australia natural source zone depletion nszd of light non aqueous phase liquids lnapls includes partitioning transport and degradation of lnapl components nszd is being considered as a site closure option during later stages of active remediation of lnapl contaminated sites and where lnapl mass removal is limiting to ensure nszd meets compliance criteria and to design enhanced nszd actions if required residual risks posed by lnapl and its long term behaviour require estimation prediction of long term nszd trends requires linking physicochemical partitioning and transport processes with bioprocesses at multiple scales within a modelling framework here we expand and build on the knowledge base of a recent review of nszd to establish the key processes and understanding required to model nszd long term we describe key challenges to our understanding inclusive of the dominance of methanogenic or aerobic biodegradation processes the potentially changeability of rates due to the weathering profile of lnapl product types and ages and linkages to underlying bioprocesses we critically discuss different scales in subsurface simulation and modelling of nszd focusing on processes at darcy scale 36 models addressing processes of importance to nszd are investigated we investigate the capabilities of models to accommodate more than 20 subsurface transport and transformation phenomena and present comparisons in several tables we discuss the applicability of each group of models for specific site conditions keywords lnapl nszd modelling biodegradation petroleum contamination 1 introduction natural source zone depletion nszd of light non aqueous phase liquids lnapls in subsurface environments comprises the superposition and linking of several natural processes which result in lnapl mass loss the processes include movement of the parent lnapl relative to air soil and water phases the partitioning of lnapl components e g benzene into other phases air water soil and degradation through biochemical reactions the magnitude of rates of nszd is a critical decision making parameter to compare to active remediation endpoints at lnapl impacted sites sookhak lari et al 2018b furthermore a good estimate of the nszd rate results in an appropriate estimate of the longevity and associated risks of the contamination blanc et al 1996 davis et al 1999 2009 garg et al 2017 mulligan and yong 2004 rivett et al 2011 the history of nszd as an emerging remediation approach and the paradigm shift from monitored natural attenuation mna focusing on fate and transport of dissolved phase hydrocarbon plumes in the saturated zone to nszd was reported in garg et al 2017 where key publications johnson et al 2006 and itrc 2009 were highlighted in particular the paradigm shift from mna to nszd was due to the finding that rates of degradation and mass loss in the vadose zone were being found to be orders of magnitude higher than mna in groundwater garg et al 2017 historically estimates of mass loss and biodegradation had been undertaken separately for groundwater for vadose zones and through direct lnapl fingerprinting lnapls can consist of a range of different petroleum product types including gasolines jet fuels kerosenes diesels lube oils coal tars and crude oils which are likely to undergo nszd at differing rates due to their differing compositions and environmental factors depending on their solubility and vapour pressure lnapl components may partition into groundwater or the soil gas phase prior to biodegradation or perhaps biodegrade without entering the aqueous phase for example for alkanes abreu et al 2009 ng et al 2014 2015 the rate of nszd is a function of the complexity of the lnapl distribution in the subsurface christensen and larsen 1993 sookhak lari et al 2018b the partitioning attributes of components in the lnapl lang et al 2009 lekmine et al 2017 vasudevan et al 2016a geo physical properties of media fluid flow conditions sookhak lari et al 2016a types of microorganisms and their predators franzmann et al 1999 availability of nutrients and electron acceptors wiedemeier et al 1999a and ambient parameters such as ph and temperature garg et al 2017 biodegradation and partitioning processes can result in compositional changes to the lnapl and an apparent stepwise depletion of components in a specific order based on their susceptibilities to biodegradation and partitioning christensen and larsen 1993 peters and moldowan 1993 volkman et al 1984 suggesting that different compound types undergo nszd at different rates together these processes form a highly non linear system to investigate blagodatsky and smith 2012 blanc et al 1996 garg et al 2017 miller et al 2013 traditional approaches for monitoring and determining the rate of nszd also used for mna include measuring several indicators of the biotic processes franzmann et al 1999 2002 either at site scales chaplin et al 2002 johnson et al 2006 or through pore scale sampling hallett et al 2013 commonly these include measuring the abundance of electron acceptors mainly with a focus on oxygen nitrate sulfate and reactions products such as ferrous iron and methane required for biological respiration fermentation and methanogenesis garg et al 2017 the latter is reported to be the dominant lnapl mass loss reaction at many sites garg et al 2017 furthermore various approaches have been used to collect and measure soil gas sookhak lari et al 2017 sweeney and todd ririe 2017 and determine the proportionality of important compounds such as oxygen carbon dioxide and methane these indicators are then converted through stoichiometric approaches to determine the degree of nszd amos et al 2005 chaplin et al 2002 cohen et al 2016 davis et al 1998 2013 eichert et al 2017 johnson et al 2006 lahvis et al 1999 lundegard and johnson 2006 also pilot tests are widely used to estimate the rate of nszd in typical site conditions dobson et al 2007 rockhold et al 2005 despite field scale measurements and pilot tests providing vital data regarding current rates of nszd at a site it is not trivial to extrapolate the data and predict long term rates as nszd rates can differ due to differing lnapl compositions extents of weathering and environmental factors indeed the complex mix of processes combined with weathering and biodegradation can significantly impact the composition and longevity of a lnapl meckenstock et al 2015 modelling biotic degradation of chemicals in porous media is a field of study in various engineering applications examples include municipal landfills lowry et al 2008 visscher and cleemput 2003 storage of greenhouse gases ebigbo et al 2010 enhanced oil recovery landa marbán et al 2017 li et al 2011 natural attenuation and biodegradation in groundwater plumes prommer et al 1999 2002 and intrusion of biodegradable volatile organic compounds through the vadose zone into buildings akbariyeh et al 2016 knight and davis 2013 parker 2003 here we focus on key understandings that allow modelling nszd of lnapls karapanagioti et al 2003 mulligan and yong 2004 rivett et al 2011 under four broad groupings we discuss 21 critical processes affecting the rate of nszd we discuss how different modelling strategies address or accommodate these processes we provide a critical review of the capabilities of 36 models that may have application to modelling nszd we investigate to what extent these models address each of the 21 processes and recommend a limited number with capability for further application and development the analysis is presented in several tables to ease comparison of the models in section 2 we discuss major processes affecting nszd categorized into four main groups different modelling strategies to model these processes are discussed in section 3 in section 4 we discuss capabilities of available models with respect to accommodating the processes discussed in section 2 2 critical processes affecting nszd fig 1 depicts 21 of the major subsurface processes both physical and biological which may affect the overall rate of nszd blanc et al 1996 garg et al 2017 mulligan and yong 2004 rivett et al 2011 sookhak lari et al 2018b a brief description of these and relevant references is also provided in table 1 in this section we describe the key features of the processes in relation to nszd and the necessity for modelling we categorize the processes into four broad groups i physicochemical processes governing fluid transport ii lnapl partitioning and compositional changes iii nszd processes in the vadose zone and groundwater and iv fundamental microbiological processes underpinning effective nszd 2 1 physicochemical processes governing fluid transport subsurface multi phase transport of fluids including lnapl vapour soil gas and groundwater flow has considerable impact on the rate of nszd spatial and temporal dynamics of the fluids alter saturation and interphase surface area in the porous media this consequently affects the rate of mass transfer between phases and influences partitioning of the lnapl compounds into other phases as well as the rate and type of biochemical reactions multi phase fluid dynamics in the subsurface is a complex function of fluid characteristics and ambient parameters a key parameter affecting lnapl transport and consequently vapour and soil gas flow see e g sookhak lari et al 2016a sweeney and todd ririe 2017 is the characteristics of the lnapl release chronic or catastrophic release incidents at different depths cause different morphology and evolution paths of the lnapl plume these also affect the volume of trapped residual and free lnapl as well as the lnapl composition sookhak lari et al 2016b another key controlling feature is the soil formation the soil moisture characteristic parameters lenhard and parker 1990 sookhak lari et al 2018b the heterogeneity of the formation johnston and trefry 2009 and the permeability and hydraulic conductivity sookhak lari et al 2017 are among the soil intrinsic features affecting subsurface fluid flow for instance the soil van genuchten parameters have a great impact on capillary pressure and vertical distribution of lnapl in the soil profile lenhard et al 2018 sookhak lari et al 2018b these also impact the volume of trapped and residual lnapl and the interphase surface area between different fluid pairs lenhard et al 2018 furthermore ambient phenomena such as biofilm growth or even gas bubble formation as a result of biological processes are believed by some researchers to alter the soil intrinsic features such as permeability and hydraulic conductivity amos and mayer 2006 tartakovsky et al 2013 lnapl physical characteristics such as viscosity and density have been shown to significantly impact distribution recovery and nszd of the lnapl lenhard and parker 1990 sookhak lari et al 2015 2018b along with the soil moisture characteristic curve parameters density and viscosity are the major parameters determining lnapl plume evolution and distribution the value of density and viscosity of the lnapl may significantly change as a result of nszd compositional changes and biogenic heat formation e g due to biological activities beyer et al 2016 sookhak lari et al 2016a 2018a groundwater dynamics also play a significant role soil water or capillary hysteresis depends on the saturation path history and is a function of variations in the groundwater table elevation e g during the initial penetration of the lnapl or following seasonal water table fluctuations it alters the relative permeability of the soil and the capillary pressure saturation relationship it is shown that hysteresis can considerably change the morphology and homogeneity of the lnapl plume furthermore water table fluctuations increase the volume of immobile lnapl residual or trapped lnapl lenhard et al 2018 pasha et al 2014 sookhak lari et al 2016a immobile lnapl is not easily recoverable through active remediation approaches and may remain as an ongoing source of contamination lekmine et al 2017 groundwater flow also augments the rate of lnapl dissolution into the aqueous phase the magnitude of the interphase mass transfer of mass is a function of the interfacial velocity of the fluids lekmine et al 2017 sookhak lari et al 2015 depending on the dynamics of an lnapl plume in the subsurface a suitable strategy for modelling nszd should accommodate a number or all of the above processes and parameters for instance multi phase transport may be of particular importance for modelling an evolving lnapl plume subjected to variable groundwater table compared to a quasi static subsurface condition similarly lnapls comprising highly partitioning components may require a multi component modelling strategy 2 2 lnapl partitioning and compositional changes the composition of lnapls can vary dramatically in their properties components and carbon ranges depending on the product type crude oil gasoline kerosene jet fuels diesel and lube oil range products major partitioning processes that an lnapl can undergo in the subsurface will depend on the proportion of volatile non volatile soluble insoluble and the carbon skeleton configuration complexity of components that comprise the lnapl partitioning of lnapl components into other phases volatilisation and dissolution can result in significant changes to the composition due to physical processes brauner et al 2004 these may alter the lnapl properties such as increasing the viscosity and alter the potential transport of lnapl through the porous media newell et al 1995 physical losses of the volatile and soluble components generally affects the lighter components c10 with the aromatic and aliphatic components both affected by volatilisation and mainly the aromatics affected by dissolution into water with partitioning of lnapl into gas and water phases largely governed by raoult s law and the mole fractions of the components in the lnapl lekmine et al 2017 for example lnapl components such as benzene toluene ethylbenzene and xylenes have lower molecular weights and higher solubilities compared to other constituents vasudevan et al 2016a these are readily volatilised and partition into groundwater thus leaving behind heavier molecular weight constituents in the source zone suthersan et al 2017 see also the discussion in section 2 4 gasolines are the main product types affected by volatilisation and dissolution because they contain a high proportion of volatile c4 to c10 components and water soluble compounds aromatics mainly alkylbenzenes so for fresh gasolines the major early changes to the composition are largely due to volatilisation and dissolution depending on the subsurface environment and the contact with groundwater over time such processes may allow a weathered gasoline to eventually resemble kerosene on the other hand crude oils and mixtures of different product types are more complicated and can vary dramatically in their compositions and range from light products like gasoline to heavy products like lube oils and any combination of light medium and heavy product types gasoline kerosene diesel and lube oil mass losses and nszd rates the lnapl has experienced can often be calculated from compositional changes in lnapls using a conservative tracer over a specified time period the conservative tracers used can vary and selection of a conservative tracer is generally based on it being one of the most non volatile water insoluble and biodegradation resistant components present in the lnapl samples in sufficient relative abundances to measure concentration increases of the selected conservative tracers in the lnapl samples allow losses to partitioning and biodegradation to be calculated baedecker et al 2018 douglas et al 1996 2012 johnston et al 2007 despite this providing estimates of the current rate of lnapl mass loss it does not estimate rates over future years e g over decades therefore key features of lnapl partitioning and compositional changes during nszd need to be embedded into nszd models 2 3 nszd processes in the vadose zone and groundwater extensive investigations have been carried out over the last 20 30 years on partitioning of lnapl components to groundwater dissolution and into the vadose zone volatilisation and their subsequent biodegradation and attenuation along with biodegradation and compositional changes in the lnapl itself these primarily constitute the nszd processes linking these partitioning and biodegradation processes holistically across the water saturated and unsaturated zones is a primary challenge lnapl resides across these zones johnston and trefry 2009 lenhard and parker 1990 tomlinson et al 2017 and seasonal and other transient affects vary lnapl and water saturations and air filled porosities and relative interfacial areas and flow dynamics to yield variable component concentrations fluxes and biodegradation above and below the water table davis et al 1993 steffy et al 1995 these also commonly drive the risk profile of an lnapl source but also feed the mass loss mechanisms of nszd for dissolved contaminant plumes mna is an accepted biodegradation remedial strategy a broad range of science has been brought together to quantify mna processes in groundwater multiple electron acceptors such as oxygen nitrate sulfate iron and manganese oxides and methanogenic processes davis et al 1999 dolfing et al 2008 essaid et al 2011 2015 patterson et al 1993 rivett and thornton 2008 wiedemeier et al 1999b novel ways of determining degradation rates gillham et al 1990 thierrin et al 1995 and the role of microorganisms franzmann et al 2002 commonly the feasibility of the application of mna as a site closure option assumes the lnapl source has been or is being removed wadwer 2004 huntley and beckett 2002 indicated that almost all lnapl mass removal was required in a homogeneous aquifer to decrease plume concentrations huntley and beckett 2002 removal of lnapl mass to such a degree was often not feasible apart from shallow and readily accessible lnapl sources in contrast and through describing a general discharge versus mass model falta et al 2005 determined that if aquifers indeed were heterogeneous then the mass flux of dissolved components into a groundwater plume from a napl source decreased in proportion to the mass removed from the napl source zone falta et al 2005 exponential decay of a source where mass discharge is proportional to source mass has also been considered newell et al 1996 for groundwater mna commonly the complexity of the lnapl distribution its saturation and its depletion over time has not been accommodated in models these traits and the underlying processes are critical to capture in a conceptual and actual model of nszd in soils and vadose zones gas transport and its compositional change and biotransformation have been topics of research for many decades barber et al 1990 glinski and stepniewski 1985 the connection to lnapl sources and mass loss has a more recent history due to the threats posed to human health by potential inhalation of hydrocarbon vapours in buildings abreu and johnson 2005 2006 patterson and davis 2009 and possible production of methane research on petroleum vapours focused on its biodegradation to quantify the mitigated threat compared to chlorinated vapours that may persist more in vadose zones davis et al 2004 key to mitigating petroleum vapour threats was the availability of oxygen in the subsurface to sustain biodegradation davis et al 2005 2009 devaull 2007 knight and davis 2013 lahvis et al 1999 ostendorf and kampbell 1991 patterson and davis 2009 in some studies methane was the hydrocarbon that was being biodegraded by the available oxygen rather than volatile components of the lnapl such as benzene toluene etc garg et al 2017 lundegard et al 2008 there appears ample evidence that in some circumstances methane is the dominant hydrocarbon in the vadose zone above an lnapl garg et al 2017 and in other cases vocs are dominant davis et al 2005 in some cases neither vocs nor methane seem present whereby biodegradation processes may occur in close proximity to the lnapl itself where it is distributed across the capillary fringe and or into the vadose zone davis et al 1998 2013 apart from the fundamental transport and biodegradation mechanisms in the vadose zone triggers for the dominance of methanogenesis compared to the volatilisation of other vocs as drivers of mass depletion or neither during nszd need to be embedded into models of nszd over time the dominance of vocs perhaps associated with a recent release or methane as the major mass loss from lnapl may transition from one to the other models need to be able to accommodate this apart from partitioning from the lnapl and subsequent processes in groundwater and vadose zones critical to quantifying nszd processes is also understanding of the partitioning behaviour of gases and volatile compounds within and across the capillary fringe barber and briegel 1987 barber et al 1990 beyond the downgradient edge of lnapl zones reactions within a dissolved groundwater plume may continue to produce methane and carbon dioxide and or release volatile compounds such as benzene that may migrate vertically upwards towards the water table and capillary fringe some studies sought to quantify transfer mechanisms and attenuation in this zone which is sometimes quite dynamic barber et al 1990 mccarthy and johnson 1993 rivett et al 2011 a model of nszd should also be able to consider such features 2 4 fundamental microbiological processes the microbial degradation of petroleum hydrocarbons has been widely explored using single or mixed cultures in the laboratory salanitro 2001 with degradation pathways described for alkanes alkenes isoalkanes cycloalkanes polyaromatic heterocyclic and btex compounds salanitro 2001 biodegradation of petroleum lnapls can result in an apparent stepwise depletion of compounds in a specific order based on their susceptibilities to biodegradation abreu et al 2009 christensen and larsen 1993 kaplan et al 1996 peters and moldowan 1993 volkman et al 1984 wade 2001 fuel types are variably affected by biodegradation in the subsurface gasoline contains a greater mass of relatively highly volatile and soluble components which would subsequently degrade in the vadose zone soil or groundwater whereas kerosene diesel and lube oils contain mainly semi and non volatile compounds typically with carbon ranges c9 despite the limited volatile or soluble components diesel for example has been reported to have all of the n alkanes removed after approximately 20 years due to biodegradation under some conditions christensen and larsen 1993 leaving more complex compound types like branched and cyclic alkanes unaltered at this extent of biodegradation an open question here is regarding the nszd of different compound types long chained alkanes short chained alkanes branched alkanes aromatics resin and asphaltenes for example as modelled by ng et al 2015 and ng et al 2014 and ambient parameters controlling long term rates of nszd we try to highlight the necessity of understanding the complexity and interaction of such parameters while considering modelling strategies for nszd these recent models assume the non volatile dissolved organic carbon nvdocs or polar compounds present in the groundwater are sourced from the partial degradation of aromatics resin and asphaltenes ng et al 2014 or only aromatics garg et al 2017 ng et al 2015 based on work by thorn and aiken 1998 however recent data from the site shows that after 30 years that the aromatics alkylbenzenes and naphthalenes like the alkylcyclohexanes and isoprenoids were the most recalcitrant components measured in the lnapl baedecker et al 2018 which may suggest the aromatics are not be the source of the nvdocs the resins or the more water soluble portion of the resins are a potential source of the nvdocs as the bedmidji crude oil contains 4 6 resins eganhouse et al 1993 the resins do not seem to have been investigated as a source of the ndvocs and contain the components combinations of a range of functional groups such as alcohols ketones aldehydes and carboxylic acids that could partition nvdocs directly from the lnapl to groundwater related to this is the in place biodegradation of insoluble components of lnapl like n alkanes which change the composition of lnapl itself intrinsically we perceive biodegradation to occur in a water phase but lnapls contain components that are largely insoluble investigations suggest that microbial communities are capable of residing in residual water at the lnapl interface and access these insoluble components via biosurfactant emulsification and associated mechanisms all of which are expected to enhance the rates of biodegradation marchant and banat 2012 the conceptual understanding is microbial communities reside in water surrounded by the lnapl and access the lnapl directly or create micelles smaller components of lnapl preferentially consuming lnapl portions and leaving modified residual levels of lnapl behind e g without the n alkanes these complexities need to be further investigated and incorporated into models where we are seeking to predict lnapl nszd and lnapl weathering features over decadal timeframes the rate of nszd through biodegradation is also impacted and can vary depending on the ambient conditions present at the site contaminant bioavailability and chemical composition microbial community composition and electron acceptors available to the microbial community to utilise davis et al 1999 franzmann et al 2002 röling and van verseveld 2002 in addition the biodegrading microbial community itself has been shown to depend on other factors such as temperature rayner et al 2007 ph or salinity shelton et al 2014 which affects the presence of degrading organisms microbial activity and the biodegradation rate shelton et al 2016 at highly contaminated legacy sites low biodegradation rates can also result from the presence of toxic contaminant concentrations accumulation of toxic metabolites and low bioavailability of the contaminant or other unfavourable environmental conditions ham et al 2004 liang et al 2009 prommer et al 2002 recharge and transport of micronutrients through the vadose zone can also have an effect on biodegradation at the bemidji site the amount of weathering of the crude oil was higher in zones with higher recharge from the ground surface bekins et al 2005 garg et al 2017 this showed the potential effect of the transport of microbial growth nutrients through downward fluid flow most likely phosphorus gray et al 2010 also indicated that adding inorganic growth essentials nutrients could enhance methanogenesis similarly aldén et al 2001 and gallego et al 2001 described the addition of nutrients nitrogen and phosphorous to improve microbial growth and bioremediation the discussion above shows that in the natural environment at micro scales the exact mechanism s of biodegradation is quite complex and not fully understood meckenstock et al 2015 schmidt et al 2017 there is promise to understand underlying patterns of the microbial community composition activity and function through molecule and other advanced techniques kimes et al 2013 mason et al 2014 yergeau et al 2015 but embedding molecular and genetic information in scaled models seems a future activity however an average response of microorganisms to the abundance of substrates and other growth and maintenance prerequisites is well established at meso and macro scales microorganisms use lnapl compounds as a source of energy and or carbon along with nutrients electron acceptors and enzymes for catabolism and anabolism together metabolism biotic processes are mainly through aerobic and anaerobic respiration e g nitrate sulfate or methanogenesis or fermentation the carbon source also acts as the electron acceptor blanc et al 1996 garg et al 2017 the native microbial community has been demonstrated to be readily capable of degrading lnapl however changes in the lnapl composition due to biotic and abiotic processes may also result in changes in associated microbial community composition and diversity due to enhancement of niche degrading microbes or recalcitrance and or toxicity of the lnapl and residual products bruckberger et al 2018 salanitro 2001 types and sequences of the biotic processes depend on multiple factors including the complexity and age weathering of lnapl chemicals abundance of the electron acceptors and reduction potential of the aquifer temperature most favourable range is 20 c 30 c and ph most favourable range is near neutral condition can play significant roles in nszd blanc et al 1996 garg et al 2017 less critical factors seemed to be parameters relating to predation by protozoans and biofilm sloughing since there may be less impact on the rate of biodegradation essaid et al 2015 garg et al 2017 it is still not very clear as to the role of chemotaxis and whether this enhances the rate of degradation due to enabling organism to access less bioavailable lnapl products adadevoh et al 2017 wang et al 2016 3 modelling strategies the necessity of modelling critical parameters affecting nszd was discussed in the previous section in general individual or combinations of nszd processes have been modelled through three different modelling strategies karapanagioti et al 2003 miller et al 2013 including mass balance models analytical approaches and numerical simulations hybrid models benefiting from a combination of these have also been applied mass balance models are site specific models and simplify site conditions both temporally and spatially adamson and newell 2009 newell and adamson 2005 ng et al 2014 basic mass conservation equations are utilised without linking nszd processes to flow or mass transport such models are useful as a basis for further detailed analytical and numerical studies or to give preliminary estimates of process rates johnson et al 2006 verginelli and baciocchi 2013 analytical models rely on solutions to simplified differential equations describing the system as such solutions only exist for certain conditions analytical models are only applicable for cases where the model assumptions hold these are mostly equilibrium conditions in the flow field simplified representations for reactions and symmetricity of the problem berlin et al 2015 bouchard et al 2011 chen et al 2016 numerical models approximate a solution to the governing differential equations through discretization techniques these models are computationally more demanding and require more effort to implement however their flexibility in comparison with analytical models in dealing with multiple processes and parameter variability is significant miller et al 2013 numerical models can be further categorized based on their representations of the nszd processes and parameters 3 1 the scale of the problem numerical modelling of physio chemical processes and microbial activities in porous media can be either at a molecular scale wu and coulon 2016 pore scale schmidt et al 2017 or a meso and macro scale sookhak lari et al 2018a the physics of micro scale flow and mass transport have been extensively addressed in the literature liu and mostaghimi 2017 however pore scale understanding of microbial growth and biochemical reactions is yet to be developed meckenstock et al 2015 pore scale modelling of microbial growth is mostly conducted through direct simulation of individual microorganisms wu and coulon 2016 modified lattice boltzman lb equations or pore network modelling yan et al 2017 however morphology of biological colonies and mutation in their genes are among the existing ambiguities schmidt et al 2017 xiong et al 2016 also pore scale mass transfer limitations in particular into the biofilm is poorly understood gharasoo et al 2015 liu and mostaghimi 2017 xiong et al 2016 these prohibit adequate approaches for upscaling the understandings from a pore scale to meso and macro scales bahar et al 2016 ebigbo et al 2010 tartakovsky et al 2013 nszd is mostly modelled at a darcy scale in such case the navier stokes and continuity equations are averaged for the flow field similarly biochemical processes are modelled through empirical correlations mimicking an average behaviour of microbial populations rivett et al 2011 these are studied in more details in section 3 3 1 3 2 flow field representation at a pore scale either a navier stokes equation or its simplified versions stokes equation or hagen poiseuille equation are used for direct simulation of single or multi phase flow field approaches like lb are also used to minimize computational costs yan et al 2017 however such a detailed level of calculation is still not practical for macro e g field scales the flow field at a macro scale is modelled based on the conceptual model of the site this may vary from analytical models to darcy and transport equations for the saturated zone richards and transport equations for saturated and unsaturated zones and two and multi phase flow and transport equations for the entire domain miller et al 2013 details of these models are presented in section 4 3 3 modelling microorganisms microbial processes and growth models are either unstructured or structured in unstructured growth models only one indicator of the microbial population is studied usually the mass or number of the microbes on the other hand various features of the microbes are studied in structured models these may include the structure of their deoxyribonucleic acid dna and adenosine tri phosphate atp blanc et al 1996 tartakovsky et al 2013 microbial growth models can also be segregated or unsegregated foe segregated models individual microbes and their behaviour are studied in contrast unsegregated models study an average representation of the microbial colonies in the form of a continuum models for nszd are mostly unstructured and unsegregated blanc et al 1996 most of the nszd models consider microbes as a biofilm attached to the grains however there are models considering a concentration of floating microorganisms movement of these are modelled in the form of an advection diffusion process and sometimes their precipitation is also included through application of the stokes law bradford et al 2014 microbial chemotaxis in which microorganisms actively chase and move towards a food source regardless of the flow field has also been modelled through modified advection diffusion equations adadevoh et al 2017 wang et al 2016 3 3 1 mathematical representation of biotic processes at a darcy scale biochemical reactions are either at equilibrium or time dependant kinetic blanc et al 1996 rivett et al 2011 and sometimes instantaneous davis et al 2009 a zero order reaction is expressed as 1 d s d t c o n s t a n t in which s represents the substrate m l3 and t is time t the non dimensional sherwood peclet and damkohler numbers are used to identify to what extent the assumption of zero order reactions hold barry et al 2002 rifai and bedient 1990 sookhak lari and moeini 2015 a commonly assumed kinetic reaction for substrate consumption is first order 2 d s d t α 1 s where α 1 is a constant a single monod equation the michaelis menten equation with a time varying term for biomass population is the most popular equation describing the substrate consumption rate as a function of the biomass 3 r s d s d t k x s k s s where x is the biomass concentration m l3 k s is the half saturation m l3 and 4 k μ m a x y where μ max is the maximum specific growth rate t 1 and y is the biomass yield coefficient blanc et al 1996 the microbial growth is limited by the excess amount of substrate 5 r s k x s k s s s 2 k i where k i is a constant also for a non competitive inhibitor e g end product 6 r s k x i s k s s i 1 c i k i 7 r s k x s k s i s i 1 c i k i or 8 r s k x s k s s i i 1 c i k i where i is an inhibiting factor and c i is the concentration of the non competitive inhibitor other forms of modelling inhibition are presented in the literature blanc et al 1996 more advanced representations for the substrate utilization rate and counterpart microbial growth rate include the abundance of electron acceptors barry et al 2002 battistelli 2004 9 r s k x s k s s i 1 n a i k a i a i where a i is the concentration of the electron acceptor i and k ai is its half saturation the competition process for two substrates is represented as huang et al 2006 rerp 2000 10 r s 1 k 1 x s 1 k s 1 s 1 k s 1 s 2 k s 2 r s 2 k 2 x s 2 k s 2 s 2 k s 2 s 1 k s 1 where k 1 k 2 k s1 and k s2 are constant values the first order growth of biomass is used in some models 11 d x d t α 2 x where α 2 is a constant in more sophisticated models the substrate utilization and biomass formation are connected through the yield coefficient the monod based growth and decay of the biomass can simply be represented by 12 d x d t μ m a x x s k s s b x where b t 1 is the first order decay coefficient however infinite growth of the biomass is impossible some models have options to limit the biomass growth for a multi component monod based equation this can be expressed as 13 d x d t μ m a x x i b s k s s i 1 n a i k a i a i b x where i b is the inhibitor for biomass formation if i b 1 there is no growth limit otherwise the growth inhibitor is usually expressed as 14 i b 1 x k b where k b is a constant or 15 i b ρ x β x where β is a constant and ρ x is the biomass density m l3 4 available models depending on the problem and phenomenon to be studied subsurface modelling is conducted through various approaches freedman et al 2017 rivett et al 2011 table 2 introduces 36 models the table presents the models capabilities in dealing with nszd processes and parameters depicted in fig 1 also in table 3 the complexity of the biodegradation module in each model is referenced to the governing equations in section 3 3 1 the information in both tables are based on the models features introduced in theoretical reports if available and relevant publications reporting application of the models further capabilities of some models as e g amendments to open source codes may also exist below we categorize these models based on their representation of the flow field and discuss the conditions under which the models may be applicable we also discuss the emerging needs and tools for representative modelling of nszd at the end of this section 4 1 analytical models analytical models have been used to study the partitioning of lnapl compounds hers et al 2000 and their biodegradation lahvis et al 1999 luo et al 2015 siddique et al 2008 in groundwater and in vadose zone soils the analytical models in table 2 are those with biodegradation modules and include biochlor bioscreen brknapl ecosys remchlor remfuel and r unsat the models include zero or first order reactions to model biodegradation except for brknapl these are mostly 1 dimensional models with limited capabilities for modelling flow and mass transport in general no biomass growth or multi component reactions are considered however bioscreen has an option to model plume attenuation by entering key electron acceptors also biochlor simulates the generation of chlorinated solvent degradation products there are also some other analytical models in the literature with no capability of modelling biodegradation which are used as parts of other modelling packages i e to form hybrid models for nszd essaid et al 2011 fernández et al 2016 gallo and hassanizadeh 2002 jacques et al 2008 marruffo et al 2012 yoon et al 2009 despite inherent limitations of analytical models some notable application of these also exist for example modelling first order decay of btex by bioscreen jeong et al 2005 biological and monod based decay of phenanthrene in a batch experiment no flow by brknapl sandrin et al 2006 first order decay of ethylene dibromide and 1 2 dichloroethane plumes at a site by remchlor henderson et al 2009 and identifying unsaturated zone biodegradation mass removal rates at bemidji site by calibrating r unsat essaid et al 2011 also some separate analytical modelling approaches have been undertaken of vadose zone partitioning and biodegradation which are mostly based on derivation of solutions to the transport equations in the vadose zone baehr 1987 lahvis et al 1999 4 2 saturated flow and transport models saturated flow models darcy equation mimic the aqueous phase flow regime in the saturated zone miller et al 2013 zheng and wang 1999 16 s s h t k h s w where s s is the specific storage h indicated the hydraulic head l t is the time t and k represents the hydraulic conductivity tensor also s w in equation 16 is the source term many such models implement forms of the advection dispersion equation to model multi species solute mass transport for a single component 17 c t d c v c r where c is the concentration ml 3 v is the darcy velocity vector lt 1 and d is the dispersion tensor l2t 1 the sink source term is also represented by r ml 3t 1 discussions on the rate limited and equilibrium interphase mass transfer are also presented in section 4 4 linking relevant groundwater transport and attenuation processes together to form saturated flow models for nszd was attempted for multiple soluble species in the 1990s clement et al 1998 with more sophisticated geochemical models being developed to accommodate all electron acceptor donor and ancillary reactions prommer et al 1999 and to understand the limitations and complexities of controls on plume mna such controls include reactions on the fringes of plumes governed by small scale lateral dispersivities leading to limited mixing of dissolved lnapl components and electron acceptors ham et al 2004 and the implications of seasonal and transient effects e g prommer et al 2002 since the 1990s similar concepts have been applied in a number of saturated flow models to study nszd well known models in this category are biomoc bioredox bioplumeiii bionapl3d gsim mt3dms pht3d rt3d and seam3d among these pht3d has a strong capability for accommodating and calculating geochemical conditions including ph biomoc bionapl3d gsim and seam3d are able to consider different types of microorganisms bioplumeiii and rt3d can consider transport of microorganisms through an advection diffusion equations as introduced in table 3 the models include different forms of monod based equations for biochemical reactions saturated flow models are applicable for steady lnapl plumes in which the equilibrium or rate limiting dissolution process can be modelled as a boundary condition and also partitioning into the gaseous phase is negligible a number of notable field or pilot scale applications of these models to study aspects of nszd include sequential use of electron acceptors at bemidji site by biomoc essaid et al 2011 field scale first order decay of benzene by bioplumeiii suarez and rifai 2004 field scale monod based decay of various gasoline ingredients by bionapl3d freitas et al 2011b molson et al 2002a vaezihir et al 2012 anaerobic degradation of organic matters at bemidji site by pht3d ng et al 2015 and a series of monod based btex degradation processes at a site in usa by rt3d lu et al 1999 in addition to the models named above some in house codes have also been used to study nszd in fully saturated conditions jahan et al 1999 vasudevan et al 2016b 4 3 unsaturated flow and transport models unsaturated flow models are based on the richards equation and constitutive relationships for the flow field to mimic the aqueous phase flow regime in the saturated and unsaturated zones miller et al 2013 panday and huyakorn 2008 18 s s s w h t ε s w t k h z s w where ε is the porosity z is the elevation l and s w is the water saturation constitutive relationships are required to relate the hydraulic conductivity saturation and pressure head including capillary effects transport equations like that in equation 17 apply models in this category include pflotran hp1 hydrogeochem min3p min3pdusty opengeosys surfact swms3d and tough2react n a number of these models include gas diffusion transport through the vadose zone e g pflotran min3pdusty surfact and swms3d among these models surfact was developed based on rt3d and therefore inherits the parent model capabilities including options for transport of microorganism models min3p and hydrogeochem include options to introduce customized biochemical reaction kinetics min3p also enables the user to model gas bubble formation in the aqueous phase as a result of biochemical reactions pflotran is an open source and parallel flow and multicomponent reactive transport code with options for complex biochemical reactions unsaturated flow models are applicable for steady lnapl plumes and residuals in which the equilibrium or rate limiting dissolution and evaporation process can be modelled as boundary conditions notable field or pilot scale application of these models to study nszd processes include dynamic changes in microbial characteristics at a bioremediation site in colorado usa by a modified version of hydrogeochem fang et al 2011 multi component monod based degradation at a kerosene contaminated site in germany by min3p miles et al 2008 and multi component monod based degradation of toluene and o xylene at a site in norway by swms3d in house codes have also been used to study nszd in unsaturated flow fields abreu et al 2009 molins et al 2010 rockhold et al 2004 2005 in particular a generalised representation of biochemical reactions is applied in an unsaturated flow and transport model mayer et al 2002 4 4 two phase and multi phase models two phase and multi phase flow models are able to model the flow of aqueous and gaseous phases for two phase models and gaseous aqueous and lnapl phases for three phase models for multicomponent models the mass balance equation is miller et al 2013 pruess and battistelli 2002 19 c i t β 1 n p c β i v β d c β i r i where i and β refer to the component number i and phase β respectively with n p as the total number of phases the velocity is calculated through the darcy law equation 20 v β k k r β μ β p β ρ β g with constitutive relationships to relate relative permeability of each phase pressure p including capillary and the phase saturation here k and k rβ are the absolute and relative permeability to phase β l2 and respectively ρ β and μ β are the density ml 3 and viscosity of phase β ml 1t 1 and g is the acceleration vector lt 2 most of the models also include partitioning either by considering equilibrium conditions raoult s and henry s law or through rate limited mass transfer 21 r m k c β i c β i e q where m k is the mass transfer coefficient for species i across the boundary layer lt 1 and c β i and c β i eq are the mass concentrations in the bulk aqueous solution and at equilibrium respectively r is then the rate of mass transfer ml 2t 1 the mass transfer coefficient is determined through empirical or analytical sherwood number correlations rerp 2000 sookhak lari et al 2015 the models we investigate in table 2 include 3dmm bioslurp miser mofat napl simulator stomp tmvoc tmvocbio and utchem among these miser napl simulator and mofat are two dimensional utchem tmvoc and tmvocbio have options for high performance computing and parallel processing utchem and tmvocbio are able to model heat transport complex biochemical reactions inhibitors and different microorganisms competitive reactions are possible in these two as well as 3dmm utchem is also able to model microbes transport and their growth effects on the media multi phase models usually require greater computational resources to be applied despite their significant modelling capabilities these requirements limit their application to study the dynamics of lnapl in subsurface systems active remediation approaches and nszd falta and kueper 2014 miller et al 2013 sookhak lari et al 2018a sookhak lari et al 2019 a number of notable field or pilot scale applications of these models to study nszd processes includes monod based degradation of btex in a pilot test to study bioremediation by 3dmm huang et al 2006 single component first order decay of a mixture of volatile organic compounds in the vadose zone by mofat gaganis et al 2004 and first order degradation of benzene in an anonymous coastal alluvial site subjected to hysteresis water table fluctuations by napl simulator yang et al 2013 in house codes have also been used to study two and multi phase cases of nszd gallo and manzini 2001 hron et al 2015 4 5 multi physics models multi physics package are adjustable and multi purpose scientific software for numerical approximation of user specified systems of partial differential equations miller et al 2013 most packages can be implemented on clusters and supercomputers to conduct parallel processing calculations however application of such tools to model nszd is not extensive multi physics packages such as comsol and ug have been used to model subsurface biochemical reactions at pore and macro scales pore scale processes like chemotaxis have been modelled through application of comsol adadevoh et al 2017 wang et al 2016 ug has also been used to model multi component monod based degradation of various hydrocarbons in saturated flows both at pilot and field scales watson et al 2005 4 6 emerging needs and tools for representative modelling the previous sections have revealed the current level of complexity that existing modelling frameworks can handle among these multi phase multi component models are able to address some of the more critical transport and partitioning phenomena required to describe nszd processes models like tmvocbio and utchem include options for simulating heat generation and transport variations in ph degradation and partitioning to different phases jung and battistelli 2016 rerp 2000 as these require massive computational effort a number of multi phase multi component models are now configured as parallel processing versions enabling application of clusters and supercomputers to conduct heavy simulations jung et al 2017 regardless application of these to address all processes applicable to nszd and even active remediation is not yet common sookhak lari et al 2018a sookhak lari et al 2018b 2019 especially over long time periods decades and at fine spatial scales the sequence and type of biochemical reactions which can be modelled are determined through built in libraries in simulation packages these are based on the current level of understanding from application and observations garg et al 2017 as previously discussed the current concepts for the class and sequence of reactions as e g in ng et al 2014 and ng et al 2015 may include assumptions that may need further focus to ensure assumptions about lnapl weathering over long time periods is accurately accommodated in models similarly research advances regarding other key nszd processes whilst informing models of nszd processes and their evolution over time will challenge the ability of currently available models accommodating all process concurrently and accurately in one code and being able to deliver simulations in a timely manner seems still a future challenge in order to link site scale observations and built in libraries in numerical models time and length scales are inevitably integrated and therefore some information and or prediction accuracy may be lost key to progress will be the scalability of micro and meso scale experimentation to elucidate nszd processes at field scale these can be used to better quantify relationships between ambient parameters ph temperature etc types of hydrocarbons and reactions e g exact mechanism of complex syntrophic fermentation methanogenic reactions and geo physical features at short time and length scales this provides improved insights for modelling purposes with less assumptions furthermore pore scale simulations may also provide additional understandings regarding the dynamics of biochemical reactions and microorganisms e g biofilm growth and sloughing mutation in genes and food chain not in any of the models as a function of flow field characteristics and therefore a better upscaling from pore scale to darcy scale of the governing equations bahar et al 2016 tartakovsky et al 2013 wang et al 2016 xiong et al 2016 advanced mathematical approaches like converting the governing partial differential equations into their lattice boltzmann representations can also significantly reduce the pore scale computational costs yan et al 2017 5 conclusions active remediation of sites contaminated with lnapl is an expensive and often prolonged task the efficiency of active remediation decreases over time and may become less than the rate of nszd garg et al 2017 this provides a motivation to consider nszd as a continuous and passive clean up option with insignificant side effects and reduced costs however it is vital to measure current and estimate future rates of nszd to enable a comparison with active remediation efforts and also to estimate the longevity of risk factors and lnapl itself the long term effectiveness of nszd needs to be quantified this enjoins a nszd modelling approach we provide a critical review across the literature on the key processes that might need to be considered in conceptual and actual models of nszd compositional changes of lnapl due to partitioning and subsequent biodegradation and further weathering means nszd rates are likely to change over decadal time frames various classes of chemicals might control the long term rate of lnapl nszd methanogenesis may dominate at some time periods garg et al 2017 as might aerobic biodegradation of volatile compounds in vadose zone soils davis et al 2005 mna in groundwater might also be a dominant process at some point of time despite seemingly orders of magnitude biodegradation rate differences at other points in time lnapl fingerprinting and changes in composition provides indicators of historic weathering and in part provides measures of the scale of volatilisation dissolution and intrinsic biodegradation and overall mass loss the key understandings are in place but transitions between times of dominant nszd processes need refinement as do the geochemical and hydrogeological conditions under which they may occur and be dominant coupled to this are differences predicated by product type gasoline crude diesel etc and scale and size of release events a significant gap exists in upscaling micro scale biological processes to meso and macro scales schmidt et al 2017 even though darcy scale lumped parameter equations have been widely used to quantify the nszd processes at pilot and field scales the physio chemical understanding of the processes is yet to be improved a number of existing questions have been presented in the literature garg et al 2017 schmidt et al 2017 furthermore processes like assimilation and existence of food chains have rarely been studied at darcy scales this is mostly due to the lack of appropriate mathematical representations averaging and verifying the pore scale governing equations may be of some help xiong et al 2016 we noted the necessity for models capable of handling extremely complex syntrophic fermentation methanogenic reactions that are sensitive to ambient parameters not typically included in transport models e g ph and temperature we highlighted the needs for meso scale experiments and pore scale simulations to provide more universal input libraries and upscaled governing equations for modelling nszd multi phase multi component models have rarely been used to study nszd across 36 models considered these seem to have a strong basis for future nszd modelling despite their strong modelling capabilities application of these models requires an adequate level of team expertise in the geo physics geo chemistry and geo biology often access to supercomputing and parallel processing facilities is needed however it has been shown that detailed field scale multi phase and multi component transport phenomena can be modelled through such modelling frameworks miller et al 2013 sookhak lari et al 2016a sookhak lari et al 2018a linking these to the relevant level of microbial geochemical and biodegradation processes under potentially transient subsurface conditions remain challenges for long term estimation of nszd and lnapl longevity but a challenge that needs to be addressed advanced computational algorithms are progressively implemented in simulators to reduce computational costs of modelling highly nonlinear systems advances in parallel processing clusters and supercomputers promise improved capabilities of the models to investigate complex interconnected biochemical reactions miller et al 2013 machine learning can be used to analysed massive data collected from field measurements to shape site specific models for nszd wu and coulon 2016 these seem to form the basis for new generations of representative nszd models that can address the challenges outlined finally it is recognised that nszd processes operate concurrently with active remedial efforts at lnapl sites an appropriately capable code could be used to simulate mass removal via both approaches and to determine at what stage nszd becomes the dominant mass removal mechanism compared to active mass removal efforts sookhak lari et al 2018a sookhak lari et al 2018b 2019 this provides the basis for decisions around proceeding with active remediation at lnapl impacted sites or transitioning to a nszd site closure regime acknowledgements the authors thank the anonymous reviewers for their valuable comments we would also like to thank our colleagues at csiro and collaborators for their extensive insights and support over an extended period we thank chris barber for initiating the work 30 years ago colin johnston for his pioneering lnapl research brad patterson for making transients visible via online probes peter franzmann for microbial insights rod lukatelich for championing the value of research in industry andrew king for driving practical outcomes and to bp for being a consistent and strong supporter of our research over several decades 
