index,text
26330,a richards equation based soil moisture module was developed and integrated within the soil and water assessment tool swat four years of daily soil moisture measurements from 10 monitoring stations at three depths i e 5 10 and 50 cm in the choptank river watershed maryland were used to test the module performance results show that as compared with the original swat soil moisture module the richards equation based soil moisture module improved r2 from 0 12 to 0 45 and reduced soil moisture simulation bias mean simulation mean measurement from 0 10 to 0 02 m3 m 3 averaged across the 10 stations at soil surface layer i e 5 cm depth noticeable improvements were also observed for deeper soil layers and for both dry and wet periods notably the soil moisture coupling strength between different soil layers was substantially improved with the new module the enhanced swat model is expected to better inform soil water and irrigation management keywords land surface processes soil water modeling richards equation software availability name of software richards equation based soil and water assessment tool rswat developer junyu qi and xuesong zhang program language fortran 90 availability and cost free of charge available upon request 1 introduction soil moisture is considered as one of the most important state variables in land surface process research li et al 2010 narasimhan and srinivasan 2005 narasimhan et al 2005 information on the spatial temporal variations of soil moisture is critical in climate change studies due to the fact that soil moisture governs the processes of energy and water transfer between land surface and atmosphere li et al 2010 seneviratne et al 2010 state of soil moisture is also critical for crop growth and yield denmead and shaw 1962 irrigation scheduling campbell and campbell 1982 chen et al 2018 flood and droughts prediction entekhabi et al 2010 and best management practices implementation emerson and traver 2008 because it has significant impacts on the rainfall runoff process on the land surface liu et al 2017 rajib and merwade 2016 in addition soil moisture has a close relationship with co2 accumulation and consumption in soils through microbial activity orchard and cook 1983 which has profound implications in global carbon cycle and balance raich and schlesinger 1992 soil moisture can be measured through various instruments however point measurements alone are insufficient for watershed or reginal scale studies due to great heterogeneity across a large area narasimhan et al 2005 remote sensing on the other hand has become an important alternative for regional studies engman 1991 however remotely sensed soil moisture information is limited to top 5 cm of the soil whereas crop root systems normally extend to deeper soil layers to extract soil water jackson et al 1996 as a result more information is required for accurate estimation of soil water flow and regional scale water balance korres et al 2013 distributed hydrologic models can be used to simulate soil moisture across the vertical profile of the root zone and spatial variations over a large area beven et al 1995 manfreda et al 2005 quinn et al 1991 wang et al 1996 wigmosta et al 1994 however non physical representation of soil moisture algorithm in many watershed scale models remains a critical concern for model users rajib and merwade 2016 as a watershed scale model soil and water assessment tool swat is designed to simulate hydrological processes and predict water quantity and quality as affected by landuse management practices and climate change arnold et al 1998 it provides a flexible framework that allows for evaluating the impact of a broad range of best management practices bmps such as cover crops filter strips conservation tillage irrigation management and terraces gassman et al 2005 liu et al 2008 ullrich and volk 2009 zhang 2018 zhang et al 2013 the swat model has been used worldwide to solve complex watershed management problems and modified for different study purposes b√§rlund et al 2007 enlow et al 2018 fu et al 2014 hoang et al 2017 krysanova and arnold 2008 qi et al 2016a 2016b 2017a 2017b srinivasan et al 2010 van griensven et al 2012 wu and liu 2012 recent uncertainty analysis efforts highlight the need for further improvements in the swat model s hydrology algorithms leta et al 2015 yang et al 2018 in swat a storage routing technique is used to simulate water flow through each soil layer downward flow occurs when upper layer soil water content exceeds field capacity and the lower layer is not saturated the hydraulic conductivity that has a direct relationship with soil water content also controls the rate of downward flow or infiltration this simple storage routing method has been tested in several studies and the results suggested that swat could provide useful prediction of long term soil moisture profile variation after careful calibration li et al 2010 luo et al 2008 mapfumo et al 2004 for example mapfumo et al 2004 found that calibrated swat tended to overpredict soil moisture under dry conditions but under predict soil moisture under wet conditions at three watersheds in alberta canada overall the model performed satisfactorily in simulating profile soil water distribution patterns in all three watersheds however luo et al 2008 pointed out that calibrated swat performed quite unsatisfactorily in estimating soil moisture under dry soil conditions in an irrigation district of the yellow river china they however revised groundwater evaporation representing groundwater loss by direct evaporation from water table formula by coupling soil profile dynamics with groundwater table changes and were able to improve soil moisture simulation in dry conditions li et al 2010 suggested that uncalibrated swat generated large biases against soil moisture measurements but could reasonably simulate the long term trend and the spatial temporal variability of soil moisture in shaanxi province china note that none of these studies have used long term daily soil moisture measurement to test swat performance nor did they explicitly discuss the performance of swat on surface soil moisture simulation recently efforts have been devoted in improving soil moisture and hydrology simulation through data assimilation of field measurement and remote sensing to reduce uncertainties arising from data input and model parameters chen et al 2011 han et al 2010 liu et al 2017 narasimhan and srinivasan 2005 park et al 2014 sun 2016 sun et al 2016 tischler et al 2007 however several studies found that surface soil moisture prediction was noticeably improved whereas deeper soil layers or root zone soil moisture simulation has not changed noticeably thus limited successes were achieved in improving stream flow simulation with remote sensing data assimilation as pointed out by chen et al 2011 vertical soil moisture coupling issues in swat must be resolved before soil moisture data assimilation can be applied successfully therefore an accurate and scientifically based description of water flow in the soil profile is needed not only for performing reliable hydrological modeling but also for efficient data assimilation processes soil moisture models range from simple tipping bucket approaches to more sophisticated physically based formulations that usually use partial differential equations to represent processes associated with soil water dynamics sheikh et al 2009 in the present study we hypothesized that soil moisture description based on richards equation could provide a more accurate prediction option concerns may emerge with respect to which mathematical models pressure head based or water content based should be used in the context of swat application pressure head based formulation can be used for saturated and unsaturated soils as well as layered soils however it suffers from poor mass balances for unsaturated soils and unacceptable time step limitations for very dry soils on the other hand water content based formulation can preserve water balance but has difficulty in maintaining continuity between heterogeneous soil layers and simulating water flow in saturated regions over the last several decades many efforts have been devoted to overcoming these problems and numerous advances in modeling soil moisture have been achieved celia et al 1990 hills et al 1989 ross 2003 zeng and decker 2009 in the present study based on the previous advancements made we have adapted a version of water content based formulation and integrated it into the swat hydrologic model structure this formulation has also been used in the community land model clm and tested in several studies with satisfying results for large area simulations kim et al 2015 liu et al 2009 oleson et al 2010 the objectives of the present study were to 1 develop a physically based soil moisture module and integrate it with swat 2 test the new soil moisture module against in situ soil moisture measurements at the u s department of agriculture usda long term agricultural research ltar sites within or near the choptank watershed in maryland and 3 compare performances between the new and original soil moisture modules in swat the resulting enhanced swat with physically based representation of soil moisture routing was expected to address soil moisture simulation issues identified in previous swat studies thereby increasing the capability of swat to leverage field measurements and remote sensing products to better support soil moisture management and ecosystem sustainability assessment 2 existing soil moisture simulation in swat in swat a watershed is partitioned into a number of subbasins which are further discretized into hydrological response units hrus based on specific combinations of land use soils and slopes hydrological processes crop growth nutrient cycling and pesticide movement are simulated within each hru swat can simulate surface runoff using either the modified curve number cn method neitsch et al 2011 or the green ampt infiltration model based on an infiltration excess approach green and ampt 1911 depending on the availability of daily or hourly precipitation data water infiltrated into the soil profile after surface runoff generation is redistributed using a storage routing technique narasimhan et al 2005 the daily water balance for each soil layer can be expressed as 1 Œ¥ s w i q p i 1 q p i q l i e e i e t i where Œ¥sw i is the change of soil water content mm at ith soil layer q p i 1 is the percolation received from i 1 th layer mm q p i is the percolation out of ith soil layer mm q l i is the lateral flow generated from ith soil layer mm and e e i and e t i are evaporation and transpiration drawn from the ith soil layer mm the percolation q p i for the ith layer is calculated as 2 q p i s w i f c i 1 e x p 24 k s a t i s a t i f c i where fc i is the soil water content at field capacity mm k sat i is the saturated hydraulic conductivity mm h 1 sat i is the amount of water when completely saturated mm for ith layer percolation from the bottom of the soil profile becomes ground water recharge lateral flow is modeled using a kinematic storage routing method based on slope slope length and saturated conductivity there are three options for estimating potential evapotranspiration et hargreaves priestley taylor and penman monteith monteith 1965 swat computes evaporation from soils and transpiration from plants separately ritchie 1972 evaporation is estimated as an exponential function of soil depth and water content based on potential et and a soil cover index transpiration is simulated as a linear function of potential et leaf area index root depth and soil water content actual soil water evaporation and plant uptake are constrained by available soil water of a given layer and allowed to be compensated by deeper soil layers 3 new soil moisture module based on richards equation the general richards equation richards 1931 for one dimensional vertical water flow is in the form of 3 Œ∏ t z k h z 1 q where Œ∏ is the volumetric soil water content mm3 mm 3 t is time s z is the depth below soil surface mm positive downwards k is the hydraulic conductivity mm s 1 h is the soil matric potential mm and q is a soil water sink term mm mm 1 s 1 zeng and decker 2009 pointed out that this form of richards equation could not maintain the soil moisture distribution under hydrostatic equilibrium due to the truncation errors introduced by the finite difference scheme to overcome this deficiency zeng and decker 2009 proposed a modified richards equation 4 Œ∏ t z k h h e z q where h e is the equilibrium soil matric potential mm accordingly a modified version of darcy s equation can be written as 5 q k h h e z where q is soil water flux mm s 1 positive downwards 3 1 numerical solution soil water is predicted from a multi layer model as shown in fig 1 the conversion of mass for one dimensional vertical water flow in soils is defined as 6 Œ∏ t q z q equation 6 can be integrated over each soil layer positive downwards and taken finite difference with time using the fully implicit scheme resulting in a discretized equation as 7 Œ¥ z i Œ∏ i n 1 Œ∏ i n Œ¥ t q i 1 n 1 q i n 1 s i where Œ¥z i is the thickness mm of soil layer i Œ¥t is the time step s Œ∏ i n 1 and Œ∏ i n are water content of soil layer i for n 1 and n time step q i n 1 is the water flux across the interface zld i q i 1 n 1 is the water flux across interface zld i 1 and s i is a layer averaged water sink term defined positive for flow out of the layers mm s 1 for time step n 1 fig 1 since soil water fluxes in eq 7 are functions of Œ∏ i and Œ∏ i 1 it can be approximated using taylor expansion over time step ross 2003 zeng and decker 2009 i e 8 q i n 1 q i n q i Œ∏ i Œ¥ Œ∏ i q i Œ∏ i 1 Œ¥ Œ∏ i 1 9 q i 1 n 1 q i 1 n q i 1 Œ∏ i 1 Œ¥ Œ∏ i 1 q i 1 Œ∏ i Œ¥ Œ∏ i substituting eqs 8 and 9 into eq 7 results in a set of tridiagonal equations of Œ¥Œ∏ 10 a i Œ¥ Œ∏ i b i Œ¥ Œ∏ i 1 c i Œ¥ Œ∏ i 1 d i where 11 a i q i Œ∏ i q i 1 Œ∏ i Œ¥ z i Œ¥ t 12 b i q i Œ∏ i 1 13 c i q i 1 Œ∏ i 1 14 d i q i 1 n q i n s i the tridiagonal equations are solved over i 1 nly according to patankar 1980 where nly is the total number of soil layers fig 1 the fluxes and partial derivatives in eqs 11 14 can be obtained from the modified version of darcy s equation relationships of matric potential water content and hydraulic conductivity the detailed results are shown in appendix a upon solution of the tridiagonal equation the water content is updated for each soil layer as 15 Œ∏ i n 1 Œ∏ i n Œ¥ Œ∏ i 3 1 1 soil water retention parameters application of richards equation requires knowledge of the relationships among matric potential water content and hydraulic conductivity curves of matric potential versus water content the moisture characteristic and hydraulic conductivity versus either matric potential or water content are determined according to clapp and hornberger 1978 and cosby et al 1984 in the present study the soil matric potential mm is defined at the node depth znd mm of each layer i fig 1 16 h i h s a t i Œ∏ i Œ∏ s a t i b i 1 10 8 where h sat is the saturated soil matric potential Œ∏ sat is the saturated soil water content and b is an exponential coefficient the hydraulic conductivity is defined at the depth of the interface of two adjacent layers zld mm as 17 k i œï i k s a t i Œ∏ i Œ∏ i 1 Œ∏ s a t i Œ∏ s a t i 1 2 b i 3 1 i n l y 1 œï i k s a t i Œ∏ i Œ∏ s a t i 2 b i 3 i n l y where œï is the ice impedance factor and k sat is the saturated hydraulic conductivity the ice impedance factor is used to quantify the increased tortuosity of water flow when a soil layer i is partially filled with ice according to swenson et al 2012 18 œï i 10 6 Œ∏ i c e i Œ∏ s a t i the bulk hydraulic properties of each soil layer are defined by weighted averages of mineral and organic material properties the saturated water content at soil layer i is 19 Œ∏ s a t i 1 f o m i Œ∏ s a t m i n i f o m i Œ∏ s a t o m i where f om is the soil organic matter fraction and Œ∏ sat min and Œ∏ sat om are the porosity of mineral and organic soils according to lawrence and slater 2008 Œ∏ sat om 0 9 and 20 Œ∏ s a t m i n j 0 489 0 00126 s o l s a n d i where sol sand is the sand content for each soil layer as defined in swat similarly the saturated soil matric potential is 21 h s a t i 1 f o m i h s a t m i n i f o m i h s a t o m i where h sat min and h sat om are saturated mineral and organic matter matric potentials mm according to letts et al 2000 h sat om 10 3 mm and 22 h s a t m i n i 10 10 1 88 0 0131 s o l s a n d i mm the exponential coefficient b is defined as 23 b i 1 f o m i b m i n i f o m i b o m i where b min and b om are exponential coefficients for mineral and organic matters for each soil layer according to letts et al 2000 b om 2 7 and 24 b m i n i 2 91 0 259 s o l c l a y i where sol clay is the clay content in each soil layer as defined in swat the soil organic matter fraction is defined in this study as 25 f o m s o l b d i s o l c b n i 13 where sol bd is the soil bulk density mg m 3 and sol cbn is the carbon content for each soil layer as defined in swat 3 1 2 equilibrium soil matric potential and water content according to zeng and decker 2009 the equilibrium soil matric potential h e is defined as 26 h e i h s a t i Œ∏ e i Œ∏ s a t i b i where Œ∏ e is the equilibrium volumetric water content for each soil layer and defined as 27 Œ∏ e i Œ∏ s a t i h s a t i z w t z n d i h s a t i 1 b i where z wt is the water table depth mm which is determined with a water table algorithm in swat 3 2 integration of new soil moisture module into swat based on the default configuration of soil layers within swat we further divided the second soil layer into two sub layers and the third and remaining layers into three sub layers fig 1 those new soil layers were equal in thickness and had the same physical and chemical properties of the default soil layers where they were derived from it is worth noting that the first soil layer 10 mm remained unchanged the new soil moisture module run at a sub daily time step e g hourly or half hourly depending on temporal resolution of precipitation data the vertical soil moisture transport was governed by infiltration surface and lateral flow gradient diffusion gravity as well as transpiration through root extraction and evaporation from soil surface in the present study we used the green ampt method to generate daily surface runoff and sub daily infiltration as the surface boundary flux for the new soil moisture module in addition free draining was assumed for the bottom boundary condition the coefficients of the tridiagonal equations for surface and bottom boundary conditions can be found in appendix b we also employed the penman monteith equation to calculate evaporation and transpiration and used the existing swat dynamic storage equation to estimate lateral flow neitsch et al 2011 these three terms were combined as the sink term in the new soil moisture module in general we did not intend to alter other components in swat except for those relevant to soil water flow the integration of the new soil moisture module with swat is also illustrated in fig 2 4 data description and model evaluation 4 1 study area the tuckahoe creek watershed tcw 220 7 km2 is located on the headwater of the choptank river watershed crw fig 3 the crw is located on eastern shore of chesapeake bay in maryland md fig 3 it is also located within the lower chesapeake bay ltar lcb ltar that encompass areas of the chesapeake bay watershed south of the susquehanna river basin the ltar program was initiated by usda ars to provide focal points for long term agricultural research to fill in the gap of the long term ecosystem research lter program which focuses on natural settings the lcb ltar is primarily operated by the hydrology and remote sensing laboratory hrsl at the beltsville md the crw is an important component of the lcb ltar and is also one of the watersheds in the conservation effects assessment project ceap a joint ars and nrcs program initiated in 2004 to evaluate the impact of conservation practices efforts on water quality which is critical to the health of the chesapeake bay for example lee et al 2016 applied the swat model to simulate responses of water quality to various agricultural conservation practices such as winter cover crop in the crw 4 2 data collection a total of 10 meteorological stations are distributed in crw and its surrounding area hourly soil moisture m3 m 3 data at 5 10 20 and 50 cm soil depths have been monitored since may of 2014 these measurements are made by the installation of stevens water hydra probes soil moisture sensors in addition hourly precipitation data is collected by a texas electronics 525 tipping bucket rain gages located at each station these stations were installed on the edges of agricultural fields in grassland or a short maintained lawn in this study soil properties are derived from the usda natural resources conservation service nrcs soil survey geographic database ssurgo https websoilsurvey nrcs usda gov in addition in situ measurements of hourly precipitation and temperature were employed as climate forcing 4 3 model performance evaluation for each of the 10 monitoring stations shown in fig 3 we built a swat project that only contains one hydrologic response unit hru the soil types for those stations were identified using arcgis based on the ssurgo soil database the soil properties at each station are shown in table 1 we assumed the same landuse type for those monitoring stations i e range grasses rnge for the present study we only considered measured soil moisture data with daily average air temperature above 4 c as they were more reliable than those measured in colder weather simulated daily soil water content was compared with measurement at three depths i e 5 10 and 50 cm representing surface to deeper soil layers since the soil moisture simulated at numerical nodes were assumed homogenous in respective soil layers the closest numerical nodes to measurement points were chosen for comparison model performance were measured using coefficient of determination r2 nagelkerke 1991 and bias bi mean simulation mean measurement m3 m 3 daily comparison was made between swat and richards equation based swat rswat the swat model only generates daily values while rswat can produce sub daily soil moisture hourly time step was set up for the new soil moisture module and hourly values were averaged to generate daily values for rswat it is worth noting that both versions of swat were not calibrated as we attempted to test model performance under ungauged conditions 4 4 wet and dry periods many swat model application studies have pointed out that swat tends to underestimate soil moisture in relatively dry conditions therefore biases between measured and simulated soil moisture were analyzed and compared between swat and rswat during the dry and wet periods respectively for each station the dry period was defined as days when surface soil moisture at 5 cm depth was above the average of the used dataset while the wet period was defined as days when surface soil moisture was below the average 4 5 soil moisture coupling strength the soil moisture coupling strength is an important indicator of model performance with respect to soil moisture variation and coupling between different soil layers chen et al 2011 here soil moisture coupling strength was denoted by pearson correlation coefficient between different soil layers and the coupling strength was compared between measurements and simulations of swat and rswat for 10 stations during wet and dry periods respectively 5 results and discussion 5 1 model performances of swat and rswat simulated and measured soil water content m3 m 3 at 5 10 and 50 cm depths for the 10 monitoring stations are compared in figs 4 6 model performances as indicated by r2 and bi m3 m 3 are shown in table 2 in general swat severely underestimated soil water content at 5 and 10 m soil depths while rswat simulated soil water content more consistent with measurements for all 10 stations figs 4 and 5 for 50 cm soil depth swat also tended to generate damped temporal variation in soil water content while rswat simulated very well the dynamic variation of soil water content for all 10 stations fig 6 it is worth noting that there are data gaps in several stations e g station 5 and 10 due to missing data or poor data quality figs 4 6 at soil depth of 5 cm r2 ranged from 0 03 station 5 to 0 15 station 1and 2 for swat compared to r2 ranging from 0 31 station 5 to 0 58 for rswat station 9 table 2 the absolute value of bi m3 m 3 ranged from 0 03 station 7 to 0 18 station 4 for swat while it ranged from 0 02 station 1 0 07 station 4 and 9 for rswat table 2 rswat improved r2 by 0 33 and reduced bias by 0 08 m3 m 3 averaged across all 10 stations except for station 7 because rswat had a slightly smaller absolute value of bi than that of swat table 2 at soil depth of 10 cm r2 ranged from 0 22 station 10 to 0 55 station 3 for swat while for rswat r2 ranged from 0 35 station 5 to 0 64 station 9 table 2 the absolute value of bi m3 m 3 ranged from 0 00 station 3 to 0 14 station 9 for swat while it ranged from 0 01 station 1 to 0 07 station 5 and 9 table 2 for rswat rswat improved r2 by 0 11 and reduced bias by 0 04 m3 m 3 averaged across the 10 stations except for station 2 3 and 7 because swat attained slightly smaller absolute values of bi than those of rswat table 2 for station 3 rswat did not show noticeable advantage over swat based on r2 and bi at soil depth of 50 cm r2 ranged from 0 00 station 10 to 0 43 station 2 for swat while for rswat r2 ranged from 0 01 station 10 to 0 43 station 2 and 6 table 2 the absolute value of bi m3 m 3 ranged from 0 01 station 4 and 8 to 0 11 station 9 for swat while that for the rswat ranged from 0 01 station 4 and 10 to 0 16 station 5 table 2 on average rswat improved r2 by 0 11 at the 10 stations while for bi there was no pronounced improvement because only five out of 10 stations had reduced absolute biases swat generally failed in predicting soil surface moisture in contrast the physically based module has greatly improved the simulation in surface soil moisture fig 4 table 2 compared with measurements at 5 cm depth rswat generated more dramatic variation of soil moisture for the 10 stations the discrepancies could be partly explained by the difference 4 5 cm between simulated nodes 0 5 cm and measured points 5 cm fig 4 this is understandable that the surface soil moisture is highly variable in space and time for the depth of 0 5 cm much higher chance of saturation during rainfall events and soil moisture reaching wilting point during droughts can be expected improvement in soil surface moisture prediction has many important implications for instance swat hydrology simulation and as a result biochemical processes could be improved data assimilation of remote sensing information and field data could also be more efficient and accurate rswat also improved soil moisture prediction in deeper soil layers 10 and 50 cm depths as indicated by r2 except for station 3 at depth of 10 cm r2 of rswat were all increased for different stations and at different depths compared with those of swat table 2 this indicates that the physically based soil moisture module could capture the variation of soil moisture much better than the original algorithm it is worth noting that there were three and five stations with smaller absolute bi generated by swat than those of rswat at 10 and 50 cm soil depths respectively this shows that the original soil moisture algorithm in swat can reasonably simulate overall soil water balance in deeper soil layers systematic biases in soil moisture simulation has been found for several soils at different depths for both versions of swat figs 4 6 for example both versions of swat severely underestimated soil water content at 10 and 50 cm depths at station 5 and 9 and overestimated soil water content at 10 and 50 cm depths at station 3 table 2 this may be attributed to the uncertainty in soil data used in the present study soil properties including bulk density texture and organic matter content determines soil porosity field capacity and wilting point as well as hydraulic conductivity which define the range of expected soil moisture variations soil properties also control the relationships between water content matric potential and hydraulic conductivity which are crucial in the richards equation based module since the simulation bias for soil moisture was very sensitive to soil physical properties correct soil input data are important for accurate soil moisture prediction for both swat and rswat in addition large biases may be caused by incorrect parametrization of soil hydraulic properties it is understandable that the parameterization methods employed in the present study may not be applicable to all soils more tests are needed to evaluate different parameterization methods for different soil types 5 2 dry and wet periods simulation soil moisture biases m3 m 3 for swat and rswat at three depths i e 5 10 and 50 cm for the 10 stations during dry and wet periods are shown in table 3 in the table shaded areas indicated that the absolute value of biases calculated by rswat were greater than those calculated by swat at a certain depth average biases for the 10 stations were also calculated at different depths for both swat and rswat table 3 for the dry period all stations had negative biases for swat except for station 3 with zero bias whereas five stations had positive biases for rswat at 5 cm depth at 10 cm depth only one station had positive bias station 3 for swat while rswat had six stations with positive bias meanwhile the average absolute bias m3 m 3 reduced from 0 06 to 0 at 5 cm depth and 0 04 to 0 01 at 10 cm depth for the 10 stations table 3 at 50 cm depth most stations had positive biases and the average biases were equal for swat and rswat for the wet period all biases were negative for swat at 5 and 10 cm depths and only three and four stations had positive biases for rswat at those two depths respectively like the dry period the average absolute bias m3 m 3 was reduced from 0 16 to 0 03 and from 0 09 to 0 02 at 5 and 10 cm depths respectively at 50 cm depth four and six stations had positive biases for swat and rswat respectively with slightly reduced average absolute biases from 0 02 to 0 m3 m 3 the results showed that swat tended to underestimate soil moisture at surface layers at 5 and 10 cm depths for both the dry and wet periods the average absolute bias for the wet period was much greater than that for the dry period indicating weak water retention capacity for swat during the wet period this is because swat tended to easily remove excessive water above field capacity through paths such as evaporation percolation and lateral flow calibration against measured soil moisture may improve simulation however most studies would not have sufficient data to calibrate soil moisture at the watershed scale we hesitate to believe that soil moisture prediction could be improved by merely calibrating stream flow at the watershed outlet rswat on the other hand had greatly improved soil moisture prediction as indicated by reduced biases for surface soil layers though it still had underestimation problem for the wet period figs 4 and 5 table 3 for the deeper soil layer at 50 cm depth no distinct improvement was detected based on bias evaluation for both wet and dry periods in swat most evapotranspiration is drawn from surface soil layers indicating less involvement of lower layers in the evapotranspiration process which also explains the damped temporal variation of swat since rswat employed the same evapotranspiration algorithm as swat it is not surprising that rswat behaved similarity to swat in deeper soil layers despite this rswat could simulate dynamic variations of soil moisture as opposed to the damped variation simulated by swat 5 3 soil moisture coupling between different layers summary of vertical soil moisture coupling strengths indicated by pearson correlation coefficient between different soil layers for measurements and simulations by swat and rswat is shown in table 4 in the table the soil water content at 5 10 and 50 cm depths is denoted as Œ∏5 Œ∏10 and Œ∏50 for the dry period coupling strengths between Œ∏5 and Œ∏10 between Œ∏5 and Œ∏50 and between Œ∏10 and Œ∏50 for rswat were much greater than those for swat and close to those derived from measurements respectively table 4 for the wet period coupling strengths between Œ∏5 and Œ∏10 between Œ∏5 and Œ∏50 and between Œ∏10 and Œ∏50 were greater than those from the dry period for swat respectively however coupling strengths between those three soil layers based on rswat were still greater than those for swat and close to those derived from measurements respectively table 4 fig 7 shows the average coupling strengths between three soil layers during dry and wet periods for the 10 stations apparently swat could reproduce the pattern of actual vertical coupling variations for dry and wet periods but the modeled coupling strengths were significantly weaker than those of measurements or simulated with rswat complete decoupling occurred between 5 and 50 cm depths as indicated by negative values in table 4 at several stations in contrast rswat successfully reproduced the variation pattern and magnitude of vertical coupling strengths shown in the measurement the improvement in simulated soil moisture coupling strengths between different soil layers has profound implications for field data and remotely sensed data assimilation into swat it can be expected that using rswat soil moisture simulation and therefore hydrology prediction would be improved the reduction in model structure errors in swat soil moisture simulation hold the potential to translate into reduced uncertainty in watershed modeling by swat which is a topic beyond the scope of the present study but deserves future studies 6 conclusion in the present study we developed a physically based soil moisture module based on richards equation and integrated it with swat to improve model structure the new module took the water content based form and run at a sub daily time step e g hourly it was coupled with the green ampt method to generate surface runoff and infiltration and evaporation and transpiration as well as lateral flow were treated as a combined sink term in the new module we tested the new soil moisture module using four years of daily soil moisture measurements from 10 monitoring stations at three depths i e 5 10 and 50 cm in and around the choptank river watershed maryland usa simulation results were compared between the original swat soil moisture algorithm and the new module we found that the original algorithm largely failed in predicting soil surface moisture while the new soil moisture module in general improved soil moisture simulation as indicated by increases in r2 and decreases in simulation biases the new module also improved soil moisture variation prediction in deeper soil layers 10 and 50 cm depths as indicated by r2 notably not all stations have experienced reduced biases especially for soil depth of 50 cm overall the physically based soil moisture module outperformed the original swat algorithm especially for surface soil layers comparison was also conducted for the dry and wet periods respectively results showed that original swat tended to underestimate soil moisture at surface layers at 5 and 10 cm depths for the dry and wet periods the new module achieved much reduction in biases for surface soil layers though it still underestimated soil moisture for the wet period for the deeper soil layer at 50 cm depth no substantial improvement was detected based on bias evaluation for both wet and dry periods despite this the new module can better capture dynamic variations of soil moisture as opposed to the damped variation simulated by the original algorithm vertical soil moisture coupling strengths between different soil layers derived from measurements and simulations were also analyzed results showed that the simulated coupling strengths using the original algorithm was significantly weaker than those derived from measurements in contrast the new module could reproduce the measured variation pattern and magnitude of vertical soil moisture coupling strengths the improvement in simulated soil moisture coupling strengths between different soil layers has profound implications for assimilating field measurements and remoted sensed data into swat the richards equation based soil moisture module improved swat model structure in hydrology future studies will address the effects of different surface runoff and infiltration partition methods e g curve number method and green ampt method coupled with the richards equation based soil moisture module on soil moisture and stream flow at watershed scale acknowledgement the funding support for this project was provided by nasa nnx17ae66g and nnh13zda001n and usda 2017 67003 26485 and nsf infews 1639327 funding was also provided in part by the usda natural resources conservation service conservation effects assessment project nrcs ceap appendix asupplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 024 appendix a the discretized form of the modified version of darcy s equation and its partial derivatives can be obtained from eq 5 a1 q i 1 n k i 1 h i 1 h i h e i h e i 1 z i z i 1 a2 q i n k i h i h i 1 h e i 1 h e i z i 1 z i a3 q i 1 Œ∏ i 1 k i 1 z i z i 1 h i 1 Œ∏ i 1 k i 1 Œ∏ i 1 h i 1 h i h e i h e i 1 z i z i 1 a4 q i 1 Œ∏ i k i 1 z i z i 1 h i Œ∏ i k i 1 Œ∏ i h i 1 h i h e i h e i 1 z i z i 1 a5 q i Œ∏ i k i z i 1 z i h i Œ∏ i k i Œ∏ i h i h i 1 h e i 1 h e i z i 1 z i a6 q i Œ∏ i 1 k i z i 1 z i h i 1 Œ∏ i 1 k i Œ∏ i 1 h i h i 1 h e i 1 h e i z i 1 z i the derivatives of the soil matric potential at the node depth are derived from eq 16 a7 h i 1 Œ∏ i 1 b i 1 h i 1 Œ∏ i 1 a8 h i Œ∏ i b i h i Œ∏ i a9 h i 1 Œ∏ i 1 b i 1 h i 1 Œ∏ i 1 with the constraint 0 01 Œ∏ i Œ∏ s a t i 1 the derivatives of the hydraulic conductivity at the layer interface are derived from eq 17 a10 k i 1 Œ∏ i 1 k i 1 Œ∏ i œï i 1 k s a t i 1 2 b i 1 3 Œ∏ i 1 Œ∏ i Œ∏ s a t i 1 Œ∏ s a t i 2 b i 1 2 1 Œ∏ s a t i 1 Œ∏ s a t i a11 k i Œ∏ i k i Œ∏ i 1 œï i k s a t i 2 b i 3 Œ∏ i Œ∏ i 1 Œ∏ s a t i Œ∏ s a t i 1 2 b i 2 1 Œ∏ s a t i Œ∏ s a t i 1 appendix b surface boundary condition for the top soil layer q i 1 n 1 i n f l i t r a t i o n thus the coefficients of the tridiagonal equation for i 1 are b1 a i q i Œ∏ i Œ¥ z i Œ¥ t b2 b i q i Œ∏ i 1 b3 c i 0 b4 d i i n f l i t r a t i o n q i n s i bottom boundary condition for the lowest soil layer q i n k i 1 n free draining thus the coefficients of the tridiagonal equation for i nly are b5 a i q i Œ∏ i q i 1 Œ∏ i Œ¥ z i Œ¥ t b6 b i q i Œ∏ i 1 b7 c i q i 1 Œ∏ i 1 b8 d i q i 1 n k i 1 n s i 
26330,a richards equation based soil moisture module was developed and integrated within the soil and water assessment tool swat four years of daily soil moisture measurements from 10 monitoring stations at three depths i e 5 10 and 50 cm in the choptank river watershed maryland were used to test the module performance results show that as compared with the original swat soil moisture module the richards equation based soil moisture module improved r2 from 0 12 to 0 45 and reduced soil moisture simulation bias mean simulation mean measurement from 0 10 to 0 02 m3 m 3 averaged across the 10 stations at soil surface layer i e 5 cm depth noticeable improvements were also observed for deeper soil layers and for both dry and wet periods notably the soil moisture coupling strength between different soil layers was substantially improved with the new module the enhanced swat model is expected to better inform soil water and irrigation management keywords land surface processes soil water modeling richards equation software availability name of software richards equation based soil and water assessment tool rswat developer junyu qi and xuesong zhang program language fortran 90 availability and cost free of charge available upon request 1 introduction soil moisture is considered as one of the most important state variables in land surface process research li et al 2010 narasimhan and srinivasan 2005 narasimhan et al 2005 information on the spatial temporal variations of soil moisture is critical in climate change studies due to the fact that soil moisture governs the processes of energy and water transfer between land surface and atmosphere li et al 2010 seneviratne et al 2010 state of soil moisture is also critical for crop growth and yield denmead and shaw 1962 irrigation scheduling campbell and campbell 1982 chen et al 2018 flood and droughts prediction entekhabi et al 2010 and best management practices implementation emerson and traver 2008 because it has significant impacts on the rainfall runoff process on the land surface liu et al 2017 rajib and merwade 2016 in addition soil moisture has a close relationship with co2 accumulation and consumption in soils through microbial activity orchard and cook 1983 which has profound implications in global carbon cycle and balance raich and schlesinger 1992 soil moisture can be measured through various instruments however point measurements alone are insufficient for watershed or reginal scale studies due to great heterogeneity across a large area narasimhan et al 2005 remote sensing on the other hand has become an important alternative for regional studies engman 1991 however remotely sensed soil moisture information is limited to top 5 cm of the soil whereas crop root systems normally extend to deeper soil layers to extract soil water jackson et al 1996 as a result more information is required for accurate estimation of soil water flow and regional scale water balance korres et al 2013 distributed hydrologic models can be used to simulate soil moisture across the vertical profile of the root zone and spatial variations over a large area beven et al 1995 manfreda et al 2005 quinn et al 1991 wang et al 1996 wigmosta et al 1994 however non physical representation of soil moisture algorithm in many watershed scale models remains a critical concern for model users rajib and merwade 2016 as a watershed scale model soil and water assessment tool swat is designed to simulate hydrological processes and predict water quantity and quality as affected by landuse management practices and climate change arnold et al 1998 it provides a flexible framework that allows for evaluating the impact of a broad range of best management practices bmps such as cover crops filter strips conservation tillage irrigation management and terraces gassman et al 2005 liu et al 2008 ullrich and volk 2009 zhang 2018 zhang et al 2013 the swat model has been used worldwide to solve complex watershed management problems and modified for different study purposes b√§rlund et al 2007 enlow et al 2018 fu et al 2014 hoang et al 2017 krysanova and arnold 2008 qi et al 2016a 2016b 2017a 2017b srinivasan et al 2010 van griensven et al 2012 wu and liu 2012 recent uncertainty analysis efforts highlight the need for further improvements in the swat model s hydrology algorithms leta et al 2015 yang et al 2018 in swat a storage routing technique is used to simulate water flow through each soil layer downward flow occurs when upper layer soil water content exceeds field capacity and the lower layer is not saturated the hydraulic conductivity that has a direct relationship with soil water content also controls the rate of downward flow or infiltration this simple storage routing method has been tested in several studies and the results suggested that swat could provide useful prediction of long term soil moisture profile variation after careful calibration li et al 2010 luo et al 2008 mapfumo et al 2004 for example mapfumo et al 2004 found that calibrated swat tended to overpredict soil moisture under dry conditions but under predict soil moisture under wet conditions at three watersheds in alberta canada overall the model performed satisfactorily in simulating profile soil water distribution patterns in all three watersheds however luo et al 2008 pointed out that calibrated swat performed quite unsatisfactorily in estimating soil moisture under dry soil conditions in an irrigation district of the yellow river china they however revised groundwater evaporation representing groundwater loss by direct evaporation from water table formula by coupling soil profile dynamics with groundwater table changes and were able to improve soil moisture simulation in dry conditions li et al 2010 suggested that uncalibrated swat generated large biases against soil moisture measurements but could reasonably simulate the long term trend and the spatial temporal variability of soil moisture in shaanxi province china note that none of these studies have used long term daily soil moisture measurement to test swat performance nor did they explicitly discuss the performance of swat on surface soil moisture simulation recently efforts have been devoted in improving soil moisture and hydrology simulation through data assimilation of field measurement and remote sensing to reduce uncertainties arising from data input and model parameters chen et al 2011 han et al 2010 liu et al 2017 narasimhan and srinivasan 2005 park et al 2014 sun 2016 sun et al 2016 tischler et al 2007 however several studies found that surface soil moisture prediction was noticeably improved whereas deeper soil layers or root zone soil moisture simulation has not changed noticeably thus limited successes were achieved in improving stream flow simulation with remote sensing data assimilation as pointed out by chen et al 2011 vertical soil moisture coupling issues in swat must be resolved before soil moisture data assimilation can be applied successfully therefore an accurate and scientifically based description of water flow in the soil profile is needed not only for performing reliable hydrological modeling but also for efficient data assimilation processes soil moisture models range from simple tipping bucket approaches to more sophisticated physically based formulations that usually use partial differential equations to represent processes associated with soil water dynamics sheikh et al 2009 in the present study we hypothesized that soil moisture description based on richards equation could provide a more accurate prediction option concerns may emerge with respect to which mathematical models pressure head based or water content based should be used in the context of swat application pressure head based formulation can be used for saturated and unsaturated soils as well as layered soils however it suffers from poor mass balances for unsaturated soils and unacceptable time step limitations for very dry soils on the other hand water content based formulation can preserve water balance but has difficulty in maintaining continuity between heterogeneous soil layers and simulating water flow in saturated regions over the last several decades many efforts have been devoted to overcoming these problems and numerous advances in modeling soil moisture have been achieved celia et al 1990 hills et al 1989 ross 2003 zeng and decker 2009 in the present study based on the previous advancements made we have adapted a version of water content based formulation and integrated it into the swat hydrologic model structure this formulation has also been used in the community land model clm and tested in several studies with satisfying results for large area simulations kim et al 2015 liu et al 2009 oleson et al 2010 the objectives of the present study were to 1 develop a physically based soil moisture module and integrate it with swat 2 test the new soil moisture module against in situ soil moisture measurements at the u s department of agriculture usda long term agricultural research ltar sites within or near the choptank watershed in maryland and 3 compare performances between the new and original soil moisture modules in swat the resulting enhanced swat with physically based representation of soil moisture routing was expected to address soil moisture simulation issues identified in previous swat studies thereby increasing the capability of swat to leverage field measurements and remote sensing products to better support soil moisture management and ecosystem sustainability assessment 2 existing soil moisture simulation in swat in swat a watershed is partitioned into a number of subbasins which are further discretized into hydrological response units hrus based on specific combinations of land use soils and slopes hydrological processes crop growth nutrient cycling and pesticide movement are simulated within each hru swat can simulate surface runoff using either the modified curve number cn method neitsch et al 2011 or the green ampt infiltration model based on an infiltration excess approach green and ampt 1911 depending on the availability of daily or hourly precipitation data water infiltrated into the soil profile after surface runoff generation is redistributed using a storage routing technique narasimhan et al 2005 the daily water balance for each soil layer can be expressed as 1 Œ¥ s w i q p i 1 q p i q l i e e i e t i where Œ¥sw i is the change of soil water content mm at ith soil layer q p i 1 is the percolation received from i 1 th layer mm q p i is the percolation out of ith soil layer mm q l i is the lateral flow generated from ith soil layer mm and e e i and e t i are evaporation and transpiration drawn from the ith soil layer mm the percolation q p i for the ith layer is calculated as 2 q p i s w i f c i 1 e x p 24 k s a t i s a t i f c i where fc i is the soil water content at field capacity mm k sat i is the saturated hydraulic conductivity mm h 1 sat i is the amount of water when completely saturated mm for ith layer percolation from the bottom of the soil profile becomes ground water recharge lateral flow is modeled using a kinematic storage routing method based on slope slope length and saturated conductivity there are three options for estimating potential evapotranspiration et hargreaves priestley taylor and penman monteith monteith 1965 swat computes evaporation from soils and transpiration from plants separately ritchie 1972 evaporation is estimated as an exponential function of soil depth and water content based on potential et and a soil cover index transpiration is simulated as a linear function of potential et leaf area index root depth and soil water content actual soil water evaporation and plant uptake are constrained by available soil water of a given layer and allowed to be compensated by deeper soil layers 3 new soil moisture module based on richards equation the general richards equation richards 1931 for one dimensional vertical water flow is in the form of 3 Œ∏ t z k h z 1 q where Œ∏ is the volumetric soil water content mm3 mm 3 t is time s z is the depth below soil surface mm positive downwards k is the hydraulic conductivity mm s 1 h is the soil matric potential mm and q is a soil water sink term mm mm 1 s 1 zeng and decker 2009 pointed out that this form of richards equation could not maintain the soil moisture distribution under hydrostatic equilibrium due to the truncation errors introduced by the finite difference scheme to overcome this deficiency zeng and decker 2009 proposed a modified richards equation 4 Œ∏ t z k h h e z q where h e is the equilibrium soil matric potential mm accordingly a modified version of darcy s equation can be written as 5 q k h h e z where q is soil water flux mm s 1 positive downwards 3 1 numerical solution soil water is predicted from a multi layer model as shown in fig 1 the conversion of mass for one dimensional vertical water flow in soils is defined as 6 Œ∏ t q z q equation 6 can be integrated over each soil layer positive downwards and taken finite difference with time using the fully implicit scheme resulting in a discretized equation as 7 Œ¥ z i Œ∏ i n 1 Œ∏ i n Œ¥ t q i 1 n 1 q i n 1 s i where Œ¥z i is the thickness mm of soil layer i Œ¥t is the time step s Œ∏ i n 1 and Œ∏ i n are water content of soil layer i for n 1 and n time step q i n 1 is the water flux across the interface zld i q i 1 n 1 is the water flux across interface zld i 1 and s i is a layer averaged water sink term defined positive for flow out of the layers mm s 1 for time step n 1 fig 1 since soil water fluxes in eq 7 are functions of Œ∏ i and Œ∏ i 1 it can be approximated using taylor expansion over time step ross 2003 zeng and decker 2009 i e 8 q i n 1 q i n q i Œ∏ i Œ¥ Œ∏ i q i Œ∏ i 1 Œ¥ Œ∏ i 1 9 q i 1 n 1 q i 1 n q i 1 Œ∏ i 1 Œ¥ Œ∏ i 1 q i 1 Œ∏ i Œ¥ Œ∏ i substituting eqs 8 and 9 into eq 7 results in a set of tridiagonal equations of Œ¥Œ∏ 10 a i Œ¥ Œ∏ i b i Œ¥ Œ∏ i 1 c i Œ¥ Œ∏ i 1 d i where 11 a i q i Œ∏ i q i 1 Œ∏ i Œ¥ z i Œ¥ t 12 b i q i Œ∏ i 1 13 c i q i 1 Œ∏ i 1 14 d i q i 1 n q i n s i the tridiagonal equations are solved over i 1 nly according to patankar 1980 where nly is the total number of soil layers fig 1 the fluxes and partial derivatives in eqs 11 14 can be obtained from the modified version of darcy s equation relationships of matric potential water content and hydraulic conductivity the detailed results are shown in appendix a upon solution of the tridiagonal equation the water content is updated for each soil layer as 15 Œ∏ i n 1 Œ∏ i n Œ¥ Œ∏ i 3 1 1 soil water retention parameters application of richards equation requires knowledge of the relationships among matric potential water content and hydraulic conductivity curves of matric potential versus water content the moisture characteristic and hydraulic conductivity versus either matric potential or water content are determined according to clapp and hornberger 1978 and cosby et al 1984 in the present study the soil matric potential mm is defined at the node depth znd mm of each layer i fig 1 16 h i h s a t i Œ∏ i Œ∏ s a t i b i 1 10 8 where h sat is the saturated soil matric potential Œ∏ sat is the saturated soil water content and b is an exponential coefficient the hydraulic conductivity is defined at the depth of the interface of two adjacent layers zld mm as 17 k i œï i k s a t i Œ∏ i Œ∏ i 1 Œ∏ s a t i Œ∏ s a t i 1 2 b i 3 1 i n l y 1 œï i k s a t i Œ∏ i Œ∏ s a t i 2 b i 3 i n l y where œï is the ice impedance factor and k sat is the saturated hydraulic conductivity the ice impedance factor is used to quantify the increased tortuosity of water flow when a soil layer i is partially filled with ice according to swenson et al 2012 18 œï i 10 6 Œ∏ i c e i Œ∏ s a t i the bulk hydraulic properties of each soil layer are defined by weighted averages of mineral and organic material properties the saturated water content at soil layer i is 19 Œ∏ s a t i 1 f o m i Œ∏ s a t m i n i f o m i Œ∏ s a t o m i where f om is the soil organic matter fraction and Œ∏ sat min and Œ∏ sat om are the porosity of mineral and organic soils according to lawrence and slater 2008 Œ∏ sat om 0 9 and 20 Œ∏ s a t m i n j 0 489 0 00126 s o l s a n d i where sol sand is the sand content for each soil layer as defined in swat similarly the saturated soil matric potential is 21 h s a t i 1 f o m i h s a t m i n i f o m i h s a t o m i where h sat min and h sat om are saturated mineral and organic matter matric potentials mm according to letts et al 2000 h sat om 10 3 mm and 22 h s a t m i n i 10 10 1 88 0 0131 s o l s a n d i mm the exponential coefficient b is defined as 23 b i 1 f o m i b m i n i f o m i b o m i where b min and b om are exponential coefficients for mineral and organic matters for each soil layer according to letts et al 2000 b om 2 7 and 24 b m i n i 2 91 0 259 s o l c l a y i where sol clay is the clay content in each soil layer as defined in swat the soil organic matter fraction is defined in this study as 25 f o m s o l b d i s o l c b n i 13 where sol bd is the soil bulk density mg m 3 and sol cbn is the carbon content for each soil layer as defined in swat 3 1 2 equilibrium soil matric potential and water content according to zeng and decker 2009 the equilibrium soil matric potential h e is defined as 26 h e i h s a t i Œ∏ e i Œ∏ s a t i b i where Œ∏ e is the equilibrium volumetric water content for each soil layer and defined as 27 Œ∏ e i Œ∏ s a t i h s a t i z w t z n d i h s a t i 1 b i where z wt is the water table depth mm which is determined with a water table algorithm in swat 3 2 integration of new soil moisture module into swat based on the default configuration of soil layers within swat we further divided the second soil layer into two sub layers and the third and remaining layers into three sub layers fig 1 those new soil layers were equal in thickness and had the same physical and chemical properties of the default soil layers where they were derived from it is worth noting that the first soil layer 10 mm remained unchanged the new soil moisture module run at a sub daily time step e g hourly or half hourly depending on temporal resolution of precipitation data the vertical soil moisture transport was governed by infiltration surface and lateral flow gradient diffusion gravity as well as transpiration through root extraction and evaporation from soil surface in the present study we used the green ampt method to generate daily surface runoff and sub daily infiltration as the surface boundary flux for the new soil moisture module in addition free draining was assumed for the bottom boundary condition the coefficients of the tridiagonal equations for surface and bottom boundary conditions can be found in appendix b we also employed the penman monteith equation to calculate evaporation and transpiration and used the existing swat dynamic storage equation to estimate lateral flow neitsch et al 2011 these three terms were combined as the sink term in the new soil moisture module in general we did not intend to alter other components in swat except for those relevant to soil water flow the integration of the new soil moisture module with swat is also illustrated in fig 2 4 data description and model evaluation 4 1 study area the tuckahoe creek watershed tcw 220 7 km2 is located on the headwater of the choptank river watershed crw fig 3 the crw is located on eastern shore of chesapeake bay in maryland md fig 3 it is also located within the lower chesapeake bay ltar lcb ltar that encompass areas of the chesapeake bay watershed south of the susquehanna river basin the ltar program was initiated by usda ars to provide focal points for long term agricultural research to fill in the gap of the long term ecosystem research lter program which focuses on natural settings the lcb ltar is primarily operated by the hydrology and remote sensing laboratory hrsl at the beltsville md the crw is an important component of the lcb ltar and is also one of the watersheds in the conservation effects assessment project ceap a joint ars and nrcs program initiated in 2004 to evaluate the impact of conservation practices efforts on water quality which is critical to the health of the chesapeake bay for example lee et al 2016 applied the swat model to simulate responses of water quality to various agricultural conservation practices such as winter cover crop in the crw 4 2 data collection a total of 10 meteorological stations are distributed in crw and its surrounding area hourly soil moisture m3 m 3 data at 5 10 20 and 50 cm soil depths have been monitored since may of 2014 these measurements are made by the installation of stevens water hydra probes soil moisture sensors in addition hourly precipitation data is collected by a texas electronics 525 tipping bucket rain gages located at each station these stations were installed on the edges of agricultural fields in grassland or a short maintained lawn in this study soil properties are derived from the usda natural resources conservation service nrcs soil survey geographic database ssurgo https websoilsurvey nrcs usda gov in addition in situ measurements of hourly precipitation and temperature were employed as climate forcing 4 3 model performance evaluation for each of the 10 monitoring stations shown in fig 3 we built a swat project that only contains one hydrologic response unit hru the soil types for those stations were identified using arcgis based on the ssurgo soil database the soil properties at each station are shown in table 1 we assumed the same landuse type for those monitoring stations i e range grasses rnge for the present study we only considered measured soil moisture data with daily average air temperature above 4 c as they were more reliable than those measured in colder weather simulated daily soil water content was compared with measurement at three depths i e 5 10 and 50 cm representing surface to deeper soil layers since the soil moisture simulated at numerical nodes were assumed homogenous in respective soil layers the closest numerical nodes to measurement points were chosen for comparison model performance were measured using coefficient of determination r2 nagelkerke 1991 and bias bi mean simulation mean measurement m3 m 3 daily comparison was made between swat and richards equation based swat rswat the swat model only generates daily values while rswat can produce sub daily soil moisture hourly time step was set up for the new soil moisture module and hourly values were averaged to generate daily values for rswat it is worth noting that both versions of swat were not calibrated as we attempted to test model performance under ungauged conditions 4 4 wet and dry periods many swat model application studies have pointed out that swat tends to underestimate soil moisture in relatively dry conditions therefore biases between measured and simulated soil moisture were analyzed and compared between swat and rswat during the dry and wet periods respectively for each station the dry period was defined as days when surface soil moisture at 5 cm depth was above the average of the used dataset while the wet period was defined as days when surface soil moisture was below the average 4 5 soil moisture coupling strength the soil moisture coupling strength is an important indicator of model performance with respect to soil moisture variation and coupling between different soil layers chen et al 2011 here soil moisture coupling strength was denoted by pearson correlation coefficient between different soil layers and the coupling strength was compared between measurements and simulations of swat and rswat for 10 stations during wet and dry periods respectively 5 results and discussion 5 1 model performances of swat and rswat simulated and measured soil water content m3 m 3 at 5 10 and 50 cm depths for the 10 monitoring stations are compared in figs 4 6 model performances as indicated by r2 and bi m3 m 3 are shown in table 2 in general swat severely underestimated soil water content at 5 and 10 m soil depths while rswat simulated soil water content more consistent with measurements for all 10 stations figs 4 and 5 for 50 cm soil depth swat also tended to generate damped temporal variation in soil water content while rswat simulated very well the dynamic variation of soil water content for all 10 stations fig 6 it is worth noting that there are data gaps in several stations e g station 5 and 10 due to missing data or poor data quality figs 4 6 at soil depth of 5 cm r2 ranged from 0 03 station 5 to 0 15 station 1and 2 for swat compared to r2 ranging from 0 31 station 5 to 0 58 for rswat station 9 table 2 the absolute value of bi m3 m 3 ranged from 0 03 station 7 to 0 18 station 4 for swat while it ranged from 0 02 station 1 0 07 station 4 and 9 for rswat table 2 rswat improved r2 by 0 33 and reduced bias by 0 08 m3 m 3 averaged across all 10 stations except for station 7 because rswat had a slightly smaller absolute value of bi than that of swat table 2 at soil depth of 10 cm r2 ranged from 0 22 station 10 to 0 55 station 3 for swat while for rswat r2 ranged from 0 35 station 5 to 0 64 station 9 table 2 the absolute value of bi m3 m 3 ranged from 0 00 station 3 to 0 14 station 9 for swat while it ranged from 0 01 station 1 to 0 07 station 5 and 9 table 2 for rswat rswat improved r2 by 0 11 and reduced bias by 0 04 m3 m 3 averaged across the 10 stations except for station 2 3 and 7 because swat attained slightly smaller absolute values of bi than those of rswat table 2 for station 3 rswat did not show noticeable advantage over swat based on r2 and bi at soil depth of 50 cm r2 ranged from 0 00 station 10 to 0 43 station 2 for swat while for rswat r2 ranged from 0 01 station 10 to 0 43 station 2 and 6 table 2 the absolute value of bi m3 m 3 ranged from 0 01 station 4 and 8 to 0 11 station 9 for swat while that for the rswat ranged from 0 01 station 4 and 10 to 0 16 station 5 table 2 on average rswat improved r2 by 0 11 at the 10 stations while for bi there was no pronounced improvement because only five out of 10 stations had reduced absolute biases swat generally failed in predicting soil surface moisture in contrast the physically based module has greatly improved the simulation in surface soil moisture fig 4 table 2 compared with measurements at 5 cm depth rswat generated more dramatic variation of soil moisture for the 10 stations the discrepancies could be partly explained by the difference 4 5 cm between simulated nodes 0 5 cm and measured points 5 cm fig 4 this is understandable that the surface soil moisture is highly variable in space and time for the depth of 0 5 cm much higher chance of saturation during rainfall events and soil moisture reaching wilting point during droughts can be expected improvement in soil surface moisture prediction has many important implications for instance swat hydrology simulation and as a result biochemical processes could be improved data assimilation of remote sensing information and field data could also be more efficient and accurate rswat also improved soil moisture prediction in deeper soil layers 10 and 50 cm depths as indicated by r2 except for station 3 at depth of 10 cm r2 of rswat were all increased for different stations and at different depths compared with those of swat table 2 this indicates that the physically based soil moisture module could capture the variation of soil moisture much better than the original algorithm it is worth noting that there were three and five stations with smaller absolute bi generated by swat than those of rswat at 10 and 50 cm soil depths respectively this shows that the original soil moisture algorithm in swat can reasonably simulate overall soil water balance in deeper soil layers systematic biases in soil moisture simulation has been found for several soils at different depths for both versions of swat figs 4 6 for example both versions of swat severely underestimated soil water content at 10 and 50 cm depths at station 5 and 9 and overestimated soil water content at 10 and 50 cm depths at station 3 table 2 this may be attributed to the uncertainty in soil data used in the present study soil properties including bulk density texture and organic matter content determines soil porosity field capacity and wilting point as well as hydraulic conductivity which define the range of expected soil moisture variations soil properties also control the relationships between water content matric potential and hydraulic conductivity which are crucial in the richards equation based module since the simulation bias for soil moisture was very sensitive to soil physical properties correct soil input data are important for accurate soil moisture prediction for both swat and rswat in addition large biases may be caused by incorrect parametrization of soil hydraulic properties it is understandable that the parameterization methods employed in the present study may not be applicable to all soils more tests are needed to evaluate different parameterization methods for different soil types 5 2 dry and wet periods simulation soil moisture biases m3 m 3 for swat and rswat at three depths i e 5 10 and 50 cm for the 10 stations during dry and wet periods are shown in table 3 in the table shaded areas indicated that the absolute value of biases calculated by rswat were greater than those calculated by swat at a certain depth average biases for the 10 stations were also calculated at different depths for both swat and rswat table 3 for the dry period all stations had negative biases for swat except for station 3 with zero bias whereas five stations had positive biases for rswat at 5 cm depth at 10 cm depth only one station had positive bias station 3 for swat while rswat had six stations with positive bias meanwhile the average absolute bias m3 m 3 reduced from 0 06 to 0 at 5 cm depth and 0 04 to 0 01 at 10 cm depth for the 10 stations table 3 at 50 cm depth most stations had positive biases and the average biases were equal for swat and rswat for the wet period all biases were negative for swat at 5 and 10 cm depths and only three and four stations had positive biases for rswat at those two depths respectively like the dry period the average absolute bias m3 m 3 was reduced from 0 16 to 0 03 and from 0 09 to 0 02 at 5 and 10 cm depths respectively at 50 cm depth four and six stations had positive biases for swat and rswat respectively with slightly reduced average absolute biases from 0 02 to 0 m3 m 3 the results showed that swat tended to underestimate soil moisture at surface layers at 5 and 10 cm depths for both the dry and wet periods the average absolute bias for the wet period was much greater than that for the dry period indicating weak water retention capacity for swat during the wet period this is because swat tended to easily remove excessive water above field capacity through paths such as evaporation percolation and lateral flow calibration against measured soil moisture may improve simulation however most studies would not have sufficient data to calibrate soil moisture at the watershed scale we hesitate to believe that soil moisture prediction could be improved by merely calibrating stream flow at the watershed outlet rswat on the other hand had greatly improved soil moisture prediction as indicated by reduced biases for surface soil layers though it still had underestimation problem for the wet period figs 4 and 5 table 3 for the deeper soil layer at 50 cm depth no distinct improvement was detected based on bias evaluation for both wet and dry periods in swat most evapotranspiration is drawn from surface soil layers indicating less involvement of lower layers in the evapotranspiration process which also explains the damped temporal variation of swat since rswat employed the same evapotranspiration algorithm as swat it is not surprising that rswat behaved similarity to swat in deeper soil layers despite this rswat could simulate dynamic variations of soil moisture as opposed to the damped variation simulated by swat 5 3 soil moisture coupling between different layers summary of vertical soil moisture coupling strengths indicated by pearson correlation coefficient between different soil layers for measurements and simulations by swat and rswat is shown in table 4 in the table the soil water content at 5 10 and 50 cm depths is denoted as Œ∏5 Œ∏10 and Œ∏50 for the dry period coupling strengths between Œ∏5 and Œ∏10 between Œ∏5 and Œ∏50 and between Œ∏10 and Œ∏50 for rswat were much greater than those for swat and close to those derived from measurements respectively table 4 for the wet period coupling strengths between Œ∏5 and Œ∏10 between Œ∏5 and Œ∏50 and between Œ∏10 and Œ∏50 were greater than those from the dry period for swat respectively however coupling strengths between those three soil layers based on rswat were still greater than those for swat and close to those derived from measurements respectively table 4 fig 7 shows the average coupling strengths between three soil layers during dry and wet periods for the 10 stations apparently swat could reproduce the pattern of actual vertical coupling variations for dry and wet periods but the modeled coupling strengths were significantly weaker than those of measurements or simulated with rswat complete decoupling occurred between 5 and 50 cm depths as indicated by negative values in table 4 at several stations in contrast rswat successfully reproduced the variation pattern and magnitude of vertical coupling strengths shown in the measurement the improvement in simulated soil moisture coupling strengths between different soil layers has profound implications for field data and remotely sensed data assimilation into swat it can be expected that using rswat soil moisture simulation and therefore hydrology prediction would be improved the reduction in model structure errors in swat soil moisture simulation hold the potential to translate into reduced uncertainty in watershed modeling by swat which is a topic beyond the scope of the present study but deserves future studies 6 conclusion in the present study we developed a physically based soil moisture module based on richards equation and integrated it with swat to improve model structure the new module took the water content based form and run at a sub daily time step e g hourly it was coupled with the green ampt method to generate surface runoff and infiltration and evaporation and transpiration as well as lateral flow were treated as a combined sink term in the new module we tested the new soil moisture module using four years of daily soil moisture measurements from 10 monitoring stations at three depths i e 5 10 and 50 cm in and around the choptank river watershed maryland usa simulation results were compared between the original swat soil moisture algorithm and the new module we found that the original algorithm largely failed in predicting soil surface moisture while the new soil moisture module in general improved soil moisture simulation as indicated by increases in r2 and decreases in simulation biases the new module also improved soil moisture variation prediction in deeper soil layers 10 and 50 cm depths as indicated by r2 notably not all stations have experienced reduced biases especially for soil depth of 50 cm overall the physically based soil moisture module outperformed the original swat algorithm especially for surface soil layers comparison was also conducted for the dry and wet periods respectively results showed that original swat tended to underestimate soil moisture at surface layers at 5 and 10 cm depths for the dry and wet periods the new module achieved much reduction in biases for surface soil layers though it still underestimated soil moisture for the wet period for the deeper soil layer at 50 cm depth no substantial improvement was detected based on bias evaluation for both wet and dry periods despite this the new module can better capture dynamic variations of soil moisture as opposed to the damped variation simulated by the original algorithm vertical soil moisture coupling strengths between different soil layers derived from measurements and simulations were also analyzed results showed that the simulated coupling strengths using the original algorithm was significantly weaker than those derived from measurements in contrast the new module could reproduce the measured variation pattern and magnitude of vertical soil moisture coupling strengths the improvement in simulated soil moisture coupling strengths between different soil layers has profound implications for assimilating field measurements and remoted sensed data into swat the richards equation based soil moisture module improved swat model structure in hydrology future studies will address the effects of different surface runoff and infiltration partition methods e g curve number method and green ampt method coupled with the richards equation based soil moisture module on soil moisture and stream flow at watershed scale acknowledgement the funding support for this project was provided by nasa nnx17ae66g and nnh13zda001n and usda 2017 67003 26485 and nsf infews 1639327 funding was also provided in part by the usda natural resources conservation service conservation effects assessment project nrcs ceap appendix asupplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 024 appendix a the discretized form of the modified version of darcy s equation and its partial derivatives can be obtained from eq 5 a1 q i 1 n k i 1 h i 1 h i h e i h e i 1 z i z i 1 a2 q i n k i h i h i 1 h e i 1 h e i z i 1 z i a3 q i 1 Œ∏ i 1 k i 1 z i z i 1 h i 1 Œ∏ i 1 k i 1 Œ∏ i 1 h i 1 h i h e i h e i 1 z i z i 1 a4 q i 1 Œ∏ i k i 1 z i z i 1 h i Œ∏ i k i 1 Œ∏ i h i 1 h i h e i h e i 1 z i z i 1 a5 q i Œ∏ i k i z i 1 z i h i Œ∏ i k i Œ∏ i h i h i 1 h e i 1 h e i z i 1 z i a6 q i Œ∏ i 1 k i z i 1 z i h i 1 Œ∏ i 1 k i Œ∏ i 1 h i h i 1 h e i 1 h e i z i 1 z i the derivatives of the soil matric potential at the node depth are derived from eq 16 a7 h i 1 Œ∏ i 1 b i 1 h i 1 Œ∏ i 1 a8 h i Œ∏ i b i h i Œ∏ i a9 h i 1 Œ∏ i 1 b i 1 h i 1 Œ∏ i 1 with the constraint 0 01 Œ∏ i Œ∏ s a t i 1 the derivatives of the hydraulic conductivity at the layer interface are derived from eq 17 a10 k i 1 Œ∏ i 1 k i 1 Œ∏ i œï i 1 k s a t i 1 2 b i 1 3 Œ∏ i 1 Œ∏ i Œ∏ s a t i 1 Œ∏ s a t i 2 b i 1 2 1 Œ∏ s a t i 1 Œ∏ s a t i a11 k i Œ∏ i k i Œ∏ i 1 œï i k s a t i 2 b i 3 Œ∏ i Œ∏ i 1 Œ∏ s a t i Œ∏ s a t i 1 2 b i 2 1 Œ∏ s a t i Œ∏ s a t i 1 appendix b surface boundary condition for the top soil layer q i 1 n 1 i n f l i t r a t i o n thus the coefficients of the tridiagonal equation for i 1 are b1 a i q i Œ∏ i Œ¥ z i Œ¥ t b2 b i q i Œ∏ i 1 b3 c i 0 b4 d i i n f l i t r a t i o n q i n s i bottom boundary condition for the lowest soil layer q i n k i 1 n free draining thus the coefficients of the tridiagonal equation for i nly are b5 a i q i Œ∏ i q i 1 Œ∏ i Œ¥ z i Œ¥ t b6 b i q i Œ∏ i 1 b7 c i q i 1 Œ∏ i 1 b8 d i q i 1 n k i 1 n s i 
26331,modelling of pesticide leaching is paramount to managing the environmental risks associated with the chemical protection of crops but it involves large uncertainties in relation to climate agricultural practices soil and pesticide properties we used latin hypercube sampling to estimate the contribution of these input factors with the stics macro model in the context of a 400 km2 catchment in france and two herbicides applied to maize bentazone and s metolachlor for both herbicides the most influential input factors on modelling of pesticide leaching were the inter annual variability of climate the pesticide adsorption coefficient and the soil boundary hydraulic conductivity followed by the pesticide degradation half life and the rainfall spatial variability this work helps to identify the factors requiring greater accuracy to ensure better pesticide risk assessment and to improve environmental management and decision making processes by quantifying the probability and reliability of prediction of pesticide concentrations in groundwater with stics macro keywords uncertainty analysis latin hypercube sampling meta model pesticide leaching stics macro 1 introduction modelling the leaching of pesticides can help prevent and manage groundwater contamination as groundwater protection is a key issue for human health and resources sustainability however the prediction of pesticide leaching by process based models is fraught with considerable uncertainties vanderborght et al 2011 key sources of uncertainties include i primary data basic physical chemical and environmental properties either directly fed into a model or used to derive input parameters because of spatial and temporal variability of environmental variables sampling procedures in the field and analysis in the laboratory ii procedures to derive some input parameters for lack of experimental data although the latter are recommended in general use of first order kinetics to derive dt50 values use of pedotransfer functions and iii modelling model error i e structural error or model inadequacy non inclusion or inappropriate representation of significant processes in the model modeller subjectivity dubus et al 2003a understanding the type and degree of uncertainties identified in the assessment helps to characterise the level of risk to the recipients and is therefore essential for informed decision making efsa 2016 sohrabi et al 2002 one of the objectives of sustainable agriculture is to reduce the risks and impacts of pesticide use on the environment by encouraging the development of new cropping systems relying on integrated pest management or low input programmes directive 2009 128 ec 2009 hossard et al 2016 reliable information on the sustainability of each potential new system can be obtained from field experiments for example crop residues management and tillage practices were shown to have strong effects on water percolation and pesticide leaching the presence of a mulch could increase soil water content so water percolation and pesticide leaching and conventional tillage generally decreases pesticide leaching compared to no till alletto et al 2010 lammoglia et al 2017b however there are a wide diversity of possible combinations of crops agricultural practices tillage organic matter management mulch soils and climates it is therefore time consuming and expensive to carry out comprehensive in situ experiments of each potential new system especially since results are site specific consequently models such as rzwqm malone et al 2004 stics pest queyrel et al 2016 or stics macro lammoglia et al 2017a have been developed as potentially effective and inexpensive tools to assess numerous options and to identify the best cropping systems the stics macro model combines the performances of an agro ecosystem model stics brisson et al 1998 2009 and of a pesticide fate model macro larsbo and jarvis 2003 it allows to quantify the environmental impacts of pesticides i e concentrations in soil and water taking into account the effects of pedoclimatic conditions agricultural practices and cropping systems compared to rzwqm and stics pest stics macro i does not need calibration step ii considers non linear sorption which can be decisive to simulate the fate of pesticides in the environment beltman et al 2008 iii allows improvement of the simulation of crop growth that leads to better estimate of crop transpiration therefore of water balance iv allows better estimate of pesticide interception by the crop so of the amount of pesticide reaching the soil which is crucial for the prediction of pesticide concentrations in water v allows to consider some agricultural practices such as fertilization mulch crop residues management and vi allows to obtain various environmental outputs such as the dynamic of nitrogen compounds and crop yields lammoglia et al 2017a 2017b the ability of stics macro to accurately predict the crop growth and development and to predict water and pesticides leaching has been evaluated through a test of the model and a sensitivity analysis in different agro pedoclimatic contexts lammoglia et al 2017a 2017b the results showed that the performance of the model was acceptable although it depended on the pedoclimatic context lammoglia et al 2017a uncertainty analysis is one of the most important elements in the development and implementation of models sohrabi et al 2002 uncertainty analysis permits to quantify how the uncertainties of some of the model components inputs parameters equations translate into uncertainties in model output of interest for the study a complementary sensitivity analysis allows determining of the relative contribution of the different sources of uncertainty considered wallach et al 2014 there are numerous techniques to propagate uncertainty in models such as differential analysis e g diaz diaz et al 1999 monte carlo analysis e g dubus and brown 2002 generalised likelihood uncertainty estimation glue e g beven and binley 1992 or fuzzy logic e g freissinet et al 1999 some uncertainty analyses have been done on macro sohrabi et al 2002 steffens et al 2013 2014 stenemo and jarvis 2007 uncertainties associated to some soil hydraulic and pesticide properties and pedotransfer functions were shown to cause large variation in simulation results sohrabi et al 2002 stenemo and jarvis 2007 moreover the parameter uncertainty can overshadow the effects of model structural error due to equations on predicted leaching losses steffens et al 2013 considering climate uncertainty through several expected future time series of climate data steffens et al 2014 showed that the effect of parameter uncertainty was less important than climate uncertainty however the combined effects of uncertainties related to the spatial variability of climate at a small catchment scale soil hydraulic properties and pesticides properties on pesticide leaching have never been studied among the various climatic variables rainfall is a key input for all models because it activates flow and mass transport chaubey et al 1999 lewan et al 2009 since rainfall is a driving force behind many kind of pesticide release and subsequent transport mechanisms ignoring this property of rainfall in the application of models will put a limit on the accuracy of the model results chaubey et al 1999 uncertainty analyses performed on the stics model mainly focused on the effects of climate variability on crop yields dumont et al 2015 j√©go et al 2015 to the best of our knowledge no uncertainty analysis considering the other stics input parameters such as those related to cropping practices has been done therefore the objectives of this work were i to assess the effect of spatial and temporal rainfall variability on stics macro modelling of pesticide leaching assessed through local concentrations in the leachate at a 400 km2 catchment scale ii to assess the effect of the uncertainties of climate agricultural practices and soil and pesticides properties on the modelling of pesticides leaching through an uncertainty analysis of the stics macro model and iii to quantify the contribution of each input factor to the uncertainties in simulated pesticide leaching this work will help to improve environmental management and decision making processes 2 materials and methods 2 1 stics macro model macro larsbo and jarvis 2003 is a one dimensional dual permeability model of water flow and solute transport in macroporous soil the water and solute are partitioned into two domains micropores where flow and transport occur represented by the richards and the convection dispersion equations and macropores where gravity driven flow occurs pesticide sorption is described using the freundlich isotherm while degradation follows first order kinetics and depends on soil temperature and moisture content the representation of crop development is simply based on crops emergence and harvest dates maximum leaf area index lai maximum root depth and maximum crop height as user defined input parameters no agricultural practices such as mulching or tillage can be considered under conventional crop management the performance of macro is known to be good enough to allow acceptable predictions of pesticides leaching e g mar√≠n benito et al 2014 the stics crop model brisson et al 1998 2009 is a dynamic daily time step model which simulates plant growth water dynamics and c and n cycles over several growing seasons stics describes in details the physical and biological processes occurring in the soil crop environment system considering a broad diversity of crop varieties and management practices stics predicts many output variables related to the crop production lai crop yield to the environment water carbon and nitrogen fluxes and to the evolution of soil water and nitrate contents stics has been widely tested for a variety of cropping situations and was shown to be good to predict crop and soil variables under various agricultural practices brisson et al 2003 coucheney et al 2015 stics macro results in the combined use of stics and macro in order to simulate crop growth and pesticide fate in complex cropping systems fig 1 lammoglia et al 2017a dedicated r packages r development core team 2016 were developed to automate the forcing of macro inputs with some stics output variables the packages allow to sequentially 1 import predefined stics and macro parameterization sets one for each model 2 simulate the crop rotation crop development water and nitrogen requirements under agricultural practices such as fertilization or crop residues management with stics model 3 extract from stics output files the estimated potential evapotranspiration as well as the estimated green and total lai the crop height and the maximum root depth for each time step 4 convert these to macro input file format and adapt macro parameterization 5 estimate the fraction of the sprayed pesticide intercepted by the crop based on stics total lai when the pesticide is sprayed 6 run the macro model with crop shape variables and potential evapotranspiration coming from stics and finally 7 import macro simulation results into the r environment i e water balance and pesticide concentrations in soils and water as a function of time the results can either be analyzed and visualized in r or exported in different formats internally the tools use existing command line modes of stics and macro but do not use the graphical user interfaces of the two models as indicated above the performance of stics macro to simulate the fate of pesticides under different cropping systems was shown to be acceptable although it depended on the pedoclimatic context the performance of stics macro was found to be better in a clayey calcic cambisol under average precipitation of 820 mm per year and average annual temperature of 11 c than in stagnic luvisol with 630 mm per year and 13 5 c lammoglia et al 2017a 2 2 climate soil and pesticides characteristics this work is based on a geographic area corresponding to the catchment of auzeville which surrounds an experimental site of inra southwest of france 43 31 n 1 30 e the catchment area is defined as a square zone of 400 km2 20 km 20 km divided into grid cells of 1 km2 1 1 km imposed by the resolution of the rainfall data see 2 2 1 the dominant land use is maize crop production sown from 1st april to 31st may maize monoculture has therefore been considered in this study also taking into account it is one of the most cultivated crop in france with a sowing area about 3 11 million ha grain maize and forage maize agreste 2016 2 2 1 climate stics macro requires daily climatic inputs because despite macro can be run with hourly rainfall data stics cannot nevertheless in macro daily rainfall data are converted internally into hourly rainfall data moeys et al 2012 the daily meteorological variables used in the study cover the 2007 2013 period the daily minimum mean annual ranging from 8 4 c in 2010 to 9 7 c in 2011 and maximum 17 9 c in 2010 to 19 8 c in 2011 air temperatures global solar radiation 1304 j cm 2 in 2013 to 1403 j cm 2 in 2011 relative humidity 72 in 2012 to 77 in 2008 and wind speed 2 2 cm s 1 in 2009 to 2 4 cm s 1 in 2008 were obtained from the inra auzeville meteorological station located close to the catchment climatik 2016 rainfall data were obtained from meteo france they correspond to radar c band dual polarization data with a spatial resolution of 1 1 km and a temporal resolution of 5 min the 5 min rainfall data were aggregated to daily values needed as input by the model fig 2 2 2 2 soil properties the loamy clayey soil of the experimental site of auzeville was selected as representative of the catchment the soil textural characteristics such as sand silt clay and organic carbon contents bulk density and ph were measured table 1 retc retention curve van genuchten et al 1991 was used to estimate the soil hydraulic parameters as required in stics macro such as the water contents at wilting point wilt and field capacity hccf and the water retention parameters tporv saturated water content xmpor boundary i e between macropores and micropores water content resid residual water content ksatmin saturated hydraulic conductivity and alpha and n van genuchten s soil water retention parameters the boundary soil water tension cten and the tortuosity pore size distribution factor zn were estimated from beulke et al 2002 table 1 the two soil parameters that were selected for the uncertainty analysis see 2 4 1 the boundary hydraulic conductivity ksm and the diffusion pathlength ascale were estimated according to steffens et al 2013 and are shown in table 2 2 2 3 pesticides two herbicides bentazone and s metolachlor were selected because they are among the most used on maize crop for weed control and because they are frequently detected in groundwater alletto et al 2013 steffens et al 2013 table 2 s metolachlor is used in pre emergence and early post emergence bentazone is used in post emergence consequently its interception by the crop canopy during spraying is higher than that of s metolachlor sorption was assumed to be proportional to the soil organic carbon content degradation rates in the subsoil were corrected from those in the topsoil according to focus 2000 following the recommendations for application in france bentazone and s metolachlor were considered to be applied on maize at rates ranging from 0 750 to 1 392 kg ha 1 and from 1 500 to 1 921 kg ha 1 respectively table 2 bentazone was sprayed from 30 to 80 days after sowing the earliest s metolachlor application was done 5 days before the sowing date and the latest was done 30 days after the sowing date table 2 2 3 assessment of the effects of spatial and temporal variability of rainfall on the modelling of pesticides leaching to assess the effects of spatial and temporal rainfall variability on the modelling of bentazone and s metolachlor leaching stics macro was run from 2007 to 2013 at every 1 km2 grid of the 400 km2 auzeville catchment from one grid cell to another the rainfall time series varied while all other stics macro parameters were held constant the uncertain parameters at their nominal values defined as mean values of the range table 2 the results were summarized for each year by their mean values over the catchment and their coefficients of variation cv 2 4 uncertainty analysis following the assessment of the effects of rainfall variability on the modelling of pesticides leaching the uncertainty analysis of stics macro combining uncertainties related to climate agricultural practices soil and pesticide properties was performed to allow within a reasonable calculation time the characterization of the spatial variability of rainfall in the uncertainty analysis four evenly spaced grid cells were selected among the 400 because they exhibited different ranges of annual rainfall fig 2 combining the seven rainfall series of the four selected grid cells for every climatic year from 2007 to 2013 led to 28 rainfall series that were used to study the effects of uncertainty related to spatial and temporal rainfall variability 2 4 1 selection of input factors based on the results of previous sensitivity and uncertainty analyses carried out with stics ruget et al 2002 varella et al 2010 macro dubus and brown 2002 dubus et al 2003b larsbo and jarvis 2005 roulier and jarvis 2003 and stics macro lammoglia et al 2017b seventeen input factors were first considered these input factors have then been analyzed with the morris screening method morris 1991 to determine those that had a strong influence on the predictions of bentazone and s metolachlor leaching this step avoided spending a large effort to carefully characterise factors that have little impact on the uncertainty of stics macro outputs among the seventeen input factors eight of them were found to have low or negligible impact on stics macro outputs data not shown on the contrary nine input factors were identified as influential table 2 the date of sowing iplt0 the amount of organic residues added to soil qres the number of days from sowing to pesticide application datepest the dose of pesticide dose the freundlich adsorption coefficient kf the freundlich exponent nf the degradation half life dt50 the boundary hydraulic conductivity ksm and the effective diffusion pathlength ascale the nominal values the lower and upper bounds of these input factors are presented in table 2 their distribution was assumed to be uniform both for the uncertainty analysis and the sensitivity analysis see 2 5 2 4 2 propagation of the uncertainties of the selected input factors monte carlo methods are often recommended to analyze the propagation of uncertainties through complex environmental models helton and davis 2003 wallach et al 2014 they are probabilistic methods based on the sampling of the output variable space the deterministic output of the model is computed for the set of sampled inputs according to distribution functions the model output uncertainty is defined by descriptive statistics such as mean standard deviation and quantiles which are computed based on the deterministic set of outputs helton and davis 2003 to limit computational cost we used the latin hypercube sampling lhs scheme mckay et al 2000 which guarantees that full coverage by stratification over the range of each input variable is represented first lhs uniformly divides the range of each input variable into disjoint intervals of equal probability then a value from each interval is randomly selected with respect to the specific probability density function in that interval finally one of the random values for each input variable is randomly chosen to form a sampling element previous studies have shown that for a given sample size or number of simulation lhs can more exhaustively explore model parameter space than simple random sampling helton and davis 2003 mckay et al 2000 when using monte carlo method the sample size has to be carefully determined to obtain reliable results the more samples are used the more reliable the statistical inference will be made on the other hand an increase in sample size is accompanied by more computational cost which is a major limiting factor with our model therefore the accuracy and the computational cost must be appropriately balanced helton and davis 2003 mckay et al 2000 to investigate how the sample size affects the stability of the simulations and to choose the appropriate sample size for the uncertainty analysis lhs was undertaken with several sample sizes of 100 500 1000 2000 and 5000 for the s metolachlor case study the relationships between the concentrations of s metolachlor and the different sample sizes were visualized by presenting the 10th quantile the 90th quantile and the mean annual pesticide concentration at 1 m depth c annual fig 3 a see 2 4 3 this relationship has also been plotted with the logarithmic transformation of the c annual of s metolachlor fig 3b this logarithmic transformation procedure is further explained in section 2 5 following logarithmic transformation the sample size was found to have little influence on the 10th and 90th quantiles fig 3a and b and a sample size of 500 seemed adequate however without this transformation fig 3a shows that even with a sample size of 5000 the results of c annual were not completely stable consequently in order to keep an acceptable computing cost while minimizing potential sample size effects on the concentrations of s metolachlor a sample size of 2000 have been used using the ranges of variation assigned to the nine input factors table 2 and the 28 rainfall series 7 years 4 positions the monte carlo simulation with lhs was performed by running stics macro with 2000 as sample size for both bentazone and s metolachlor this design resulted in 112 000 simulations 2 pesticides 2000 samples 7 years 4 positions which needed 25 days calculation parallel computing on a quad core xeon processor at 3 06 ghz 2 4 3 outputs the effects of the uncertainties were assessed on the following two outputs of stics macro for each grid cell i the arithmetic mean annual concentration of pesticide leached at 1 m depth c annual Œºg l 1 i e occurring during one year starting at the pesticide application date named here as annual concentration ii the maximal daily pesticide concentration at 1 m depth over one year period c max Œºg l 1 starting at the pesticide application date 1 c a n n u a l 1 365 n 1 365 m n v n 2 c m a x m a x m 1 v 1 m 365 v 365 where n is the day after the pesticide application date mn m1 m365 is the mass of leached pesticide on the day n on day 1 365 ¬µg and v n v 1 v 365 is the volume of percolated water on the day n on day 1 365 l then the arithmetic mean of the c annual the 10th quantile and the 90th quantile of the distribution for all combinations of the 7 years 4 spatial positions and 2000 parameters of lhs design were calculated each of the seven selected climatic years was simulated independently from the others to study the effect of climate on pesticide leaching consequently there is no residual amount of pesticide from the previous year in one simulation 2 5 sensitivity analysis once the uncertainties in stics macro outputs have been quantified a sensitivity analysis has to be done to identify the input factors that contribute the most to uncertainties in the outputs there are several sensitivity analysis methods that can be used and wallach et al 2014 recommend to implement several methods and to compare their results the 112 000 simulations performed for the uncertainty analysis produced a high number of input output pairs therefore due to the high computational cost of stics macro the sensitivity analysis explored those input output pairs instead of running again stics macro with another sampling first the pearson product moment correlation pear coefficients were determined for the nine input factors the pear coefficient measures the degree of linear association between the variations of stics macro output the c annual was retained for these calculations and the variation of the studied input factors a correlation close to 1 or 1 indicates a strong influence of the input factor on pesticide concentrations while a correlation close to zero indicates that the input factor is not influential wallach et al 2014 the pear coefficients were determined from the logarithmic transformation of concentrations see below then we built and used a meta model of stics macro a meta model consists in a mathematical function built from a set of simulations of the original model over the domain of variation of the input factor this approach has already been used in environmental modelling permitting to apply powerful sensitivity methods faivre et al 2013 uusitalo et al 2015 linear regression is the most commonly used method for meta model construction because of its simplicity however it performs better when the relationship between inputs and outputs is approximately linear storlie et al 2009 therefore we built the meta model on the logarithmic transformation of the outputs to take into account low concentration values of bentazone and s metolachlor using the linear regression function lm and the stepwise procedure step implemented in the r statistical software r development core team 2016 we used the log threshold x transformation where x is c annual or c max of bentazone and s metolachlor as predicted by stics macro the value of the threshold was set to 10 6 ¬µg l 1 as a compromise to give weight to low concentrations but not too much weight to very low values the nine quantitative input factors presented in table 2 were considered as quantitative variables and the seven climatic years year and the four spatial positions pos of the selected meteorological data were considered as qualitative input factors we limited the model to the interactions of order 2 thus sensitivity indices were computed using anova method which assesses the main contribution of each input factor to the total variance of the model outputs as well as the interactions between factors wallach et al 2017 the performance of the meta model was assessed performing new simulations with stics macro and with the meta model with a new and independent lhs sample of size 100 two statistical indices were calculated to assess this performance the efficiency ef and the bias b 3 e f 1 i 1 n s i o i 2 i 1 n o i o m 2 4 b i 1 n s i o i i 1 n o i where s i is the concentrations simulated by the meta model o i is the concentrations simulated by stics macro o m is the mean of the simulations of stics macro and n is the number of simulations ef ranges from to 1 with ef 1 indicating a perfect match between stics macro and the meta model when the bias b 0 it indicates a perfect match if b 0 it indicates an overestimation by the meta model while b 0 indicates an underestimation by the meta model 3 results and discussion 3 1 effects of the spatial and temporal variability of rainfall on the modelling of pesticides leaching the total annual amounts of rainfall on the period of one year after pesticide application were highly variable among the seven years with a mean value averaged over the 400 km2 area ranging from 504 mm in 2010 to 1000 mm in 2008 for bentazone and from 488 mm in 2011 to 1062 mm in 2008 for s metolachlor fig 4 table 3 these values are different from one pesticide to another because they are considered from the pesticide application date the coefficients of spatial variation cv of annual rainfall ranged from 4 1 in 2008 to 6 9 in 2010 for bentazone and from 3 9 in 2008 to 7 4 in 2007 for s metolachlor table 3 the largest annual rainfall occurred in 2008 corresponding to the lowest variability over the catchment cv 4 1 and 3 9 for bentazone and s metolachlor respectively table 3 for both bentazone and s metolachlor the influence of the spatial and temporal rainfall variabilities was analyzed by running stics macro at each of the 400 grid cells from 2007 to 2013 while all other parameters were held constant very large differences were found between the simulated annual concentrations at 1 m depth c annual of bentazone and s metolachlor fig 4 the effects of rainfall variability on the leaching of bentazone and s metolachlor were also found to be amplified through the stics macro model the cv of the c annual of bentazone and s metolachlor were considerably larger than the corresponding ones for rainfall from 98 to 663 for bentazone and from 68 to 347 for s metolachlor table 3 the biggest variations in the c annual of bentazone and s metolachlor occurred in 2009 when annual rainfalls were low whereas the smallest variations occurred in 2008 when rainfalls were maximal table 3 therefore assuming a linear transfer of rainfall variability through the stics macro model would have led to underestimation of the concentrations of bentazone and s metolachlor bentazone is more mobile and more persistent than s metolachlor table 2 so as expected its maximal concentrations at 1 m depth c max were higher than those of s metolachlor boesten and van der linden 1991 fig 5 in general the spatial variation of the concentrations of bentazone was also 2 times higher than that of s metolachlor table 3 finally a significant positive correlation was found between the annual rainfall amounts and the logarithmic transformation of the concentrations of both bentazone and s metolachlor at 1 m depth r2 0 63 and 0 45 respectively meaning that pesticide leaching increases exponentially with annual rainfall this is consistent with many results showing that pesticide leaching increases with increasing annual rainfall amounts e g tiktak et al 2004 overall this assessment of the influence of rainfall variability on leaching prediction reveals the non linear effects of annual rainfall on the concentrations of both herbicides and the importance of taking into account the uncertainties related to spatial and temporal variability of annual rainfall for the estimation of pesticides concentrations in groundwater 3 2 uncertainty analysis the results of the 112 000 simulations led to annual concentrations at 1 m depth cannual ranging over the seven years of simulation from 0 to 570 Œºg l 1 for bentazone and from 0 to 750 Œºg l 1 for s metolachlor while the maximal concentrations at 1 m depth c max were found to range from 0 to 2 0 105 Œºg l 1 for bentazone and from 0 to 2 5 105 Œºg l 1 for s metolachlor any value below the threshold of 10 6 ¬µg l 1 has been considered as 0 for the 2007 2013 simulated period the average c annual of bentazone was 0 287 Œºg l 1 and was lower than that of s metolachlor of 1 55 Œºg l 1 and the corresponding median values were 5 5 10 7 Œºg l 1 for bentazone and 3 3 10 6 Œºg l 1 for s metolachlor table 4 the average c max were high 16 6 Œºg l 1 for bentazone and 65 2 Œºg l 1 for s metolachlor while the median values were lower 1 0 10 5 Œºg l 1 and 5 7 10 5 Œºg l 1 respectively table 4 the logarithmic transformation of concentrations was found to be suitable to represent the distribution of the concentrations of bentazone and s metolachlor fig 6 it is of importance for meta model building see 3 3 2 and it avoids to give too much weight to values less than this threshold and thus to improve the quality of prediction for higher values the concentrations of both bentazone and s metolachlor were strongly skewed and did not fit any standard distribution fig 6 among other things because of numerous null or quasi null concentrations the results predicted with 80 confidence that the c annual of bentazone would be between 0 and 0 035 Œºg l 1 and that the c annual of s metolachlor would be between 0 and 0 494 Œºg l 1 table 4 however the means of the distributions of the c annual of bentazone and s metolachlor are superior to the 90th quantile table 4 reflecting the sensitivity of the arithmetic mean to extreme values here high concentrations this result comes from a very non linear response of the model on the variable of concentration if the number of low concentrations is 10 times that of high concentrations then the mean values are greater than the 90th quantile it emphasizes the difficulty to estimate precisely extreme quantiles and even the simple mean with such models who require high computational time to go further it may be interesting to consider the existing correlations within the input factors but it arises lots of questions on how to qualify these correlations which are poorly documented in the scientific literature and technical databases finally these results mean that there is high probabilities that stics macro simulates concentrations lower than the mean of the distribution which will have some consequences on risk assessment because of underestimation of the average leached concentrations of pesticides finally it was shown that the predicted annual concentrations of bentazone and s metolachlor could exceed the regulatory threshold of 0 1 Œºg l 1 at 1 m depth focus 2000 commission regulation eu 546 2011 2011 in 6 and 15 of the situations respectively considering their maximal concentrations during the first one year following application bentazone and s metolachlor could exceed this regulatory threshold in 17 and 24 of the situations respectively 3 3 contribution of the different sources of uncertainty 3 3 1 correlation based sensitivity analysis the pear coefficients were calculated to identify the correlations between c annual of pesticides and the 9 input factors using the 112 000 lhs monte carlo simulations they were computed on the logarithmic values of the concentrations the mean values of the pear coefficients and the sensitivity ranking were different for bentazone and s metolachlor and they varied from one climatic scenario to another table 5 for both pesticides the freundlich adsorption coefficient kf and the boundary hydraulic conductivity ksm were found to be very influential with a stronger influence of kf for the pre emergence herbicide s metolachlor table 5 an increase in the values of kf and ksm decreased the concentrations of both bentazone and s metolachlor which is consistent with the findings of dubus and brown 2002 and may reflect the fact that the higher ksm the less frequently preferential flow is triggered however ksm was found more important for the post emergence herbicide bentazone though preferential flow and related factors ksm are known to be more important in determining the leaching of more strongly sorbed pesticides dubus and brown 2002 larsson and jarvis 2000 a possible explanation might be that a larger ksm values induces a relatively faster bulk transport in the soil matrix of mobile compounds such as bentazone the degradation half life dt50 was also influential and an increase in the values of dt50 increased the concentrations of both bentazone and s metolachlor however an increase in dt50 could also lead to a decrease in the concentrations of bentazone depending on the climatic conditions table 5 the influence of the effective diffusion pathlength ascale on the concentrations of bentazone also seemed to be climate dependant while this was not observed for s metolachlor table 5 the other pear coefficients were low but they may show that the crop management factor qres amount of organic residues added to soil could be more influent than the pesticide application date datepest and dose dose table 5 for both bentazone and s metolachlor an increase in the values of qres increased the concentrations in agreement with the findings of lammoglia et al 2017b nevertheless the qres and datepest factors could have more influence on the concentrations of bentazone than those of s metolachlor and their influence could be increased by the climatic conditions these differences between the ranking of bentazone and s metolachlor can be explained by the interception of bentazone by the crop canopy as the application date of bentazone was 43 days later than that of s metolachlor table 2 this effect seems to be reinforced with lower annual rainfall 3 3 2 quantitative meta model based sensitivity analysis based on the logarithmic transformations of the predicted concentrations of bentazone and s metolachlor a meta model of stics macro was built the quality of the prediction of this meta model was evaluated on an independent lhs sample of size 100 fig 7 for bentazone the stepwise procedure selected a model with 129 parameters instead of 154 parameters with the complete model and an adjusted r2 of 0 88 the quality of the prediction was quite satisfying with an efficiency ef of 0 66 and a bias b of 0 015 for s metolachlor the stepwise procedure selected a model with 124 parameters instead of 154 and an adjusted r2 of 0 84 the quality of the prediction was also satisfactory with ef 0 64 and b 0 008 for both bentazone and s metolachlor the meta model underestimated the annual concentrations c annual for some dry years 2009 2010 2011 fig 7 table 3 the anova computed on these meta models explained 81 and 80 of the total variability of the concentrations of bentazone and s metolachlor respectively fig 8 the climatic years year the kf and the ksm were the three most influencing factors for modelling of the concentrations of both bentazone and s metolachlor with stics macro for the weakly sorbed herbicide bentazone year was the most influential factor it explained 49 of the total variability of the concentrations of bentazone fig 8 however year only explained 27 of the total variability of the concentrations of s metolachlor while the kf explained 34 fig 8 the effects of the kf were less important for the leaching of bentazone 7 3 the three most influent factors year ksm kf are followed by the dt50 and the rainfall spatial variability pos fig 8 the rainfall spatial variability pos contributed to the variability of the predicted concentrations more than the pesticide properties nf the crop management properties qres iplt0 dose datepest and the soil property ascale these results agree with those of steffens et al 2014 who indicated that uncertainty in model parameters was less important for the prediction of pesticide leaching than climate uncertainty the qualitative and quantitative sensitivity analysis methods led to the same conclusions except that for s metolachlor the pear coefficient emphasized higher influence of the freundlich exponent nf than of ascale contrary to the results obtained with the meta model table 5 fig 8 in line with the results obtained for the pear coefficients table 5 the ksm had higher influence on the variability of the concentrations of bentazone than of s metolachlor 16 and 13 respectively the interactions between the factors were found to be important between climate year and pesticide kf and soil ksm properties fig 8 the interactions effect were very small for the crop management properties qres iplt0 dose datepest despite previous studies found interaction effects between climate variables pesticide application scenarios and pesticide use steffens et al 2014 2015 since the sum of the total effects is high 81 for bentazone and 80 for s metolachlor the input factors have major additive effects on the logarithmic values of the concentrations of bentazone and s metolachlor this indicates that stics macro behaved as an additive model with important parameter interactions when the predicted concentrations are logarithmically transformed however it is worth remembering that the results of this study only stand in the bounds defined for each input factor and are specific to the soil crop conditions and the climate characteristics of the catchment assessed 4 conclusion the objective of this work was to study the effects of the uncertainties related to climate agricultural practices soil and pesticide properties on the prediction of pesticides leaching with stics macro first the effect of spatial and temporal rainfall variability on mean annual pesticides concentrations at 1 m depth was assessed the interactions between the concentrations of bentazone and s metolachlor and the annual rainfall were shown to be non linear and the variability of the concentrations was higher than that in the annual rainfall amounts spatial coefficients of variation of annual rainfall ranging from 4 to 7 produced 68 663 of variation in the concentrations these results suggest that the spatial and temporal heterogeneity are paramount when defining representative rainfall data for pesticide leaching prediction then using a monte carlo method with latin hypercube sampling the uncertainties of input factors related to climate agricultural practices and soil and pesticide properties were propagated through stics macro there was a high probability of predicting concentrations of both bentazone and s metolachlor lower than the means of their respective distributions because the distributions of their concentrations were strongly skewed and showed mean values superior to the 90th quantile this has to be considered in risk assessment because of the probable underestimation of the average leached concentrations of pesticides even if bentazone is more mobile and persistent than s metolachlor there are half less risks that the annual concentrations of bentazone exceed the regulatory threshold of 0 1 Œºg l 1 because of higher interception of bentazone than of s metolachlor by crop canopy then a sensitivity analysis was done based on the pearson coefficient and on the anova method using a meta model of stics macro the climate temporal variability the freundlich adsorption coefficient and the boundary hydraulic conductivity followed by the degradation half life and the rainfall spatial variability have been identified by both sensitivity analysis methods as the main input factors involved in the uncertainties in the prediction of the leaching of bentazone and s metolachlor the leaching of s metolachlor used in pre emergence and early post emergence was mostly affected by the parameter related to adsorption factors related to agricultural practices were most influential on the leaching of the post emergence pesticide bentazone stics macro also showed non linear but additive effects on the logarithmic values of the concentrations of bentazone and s metolachlor these results depend on the specific soil crop climate characteristics considered nevertheless they confirm the strong effects of the uncertainties in climate pesticide soil and agricultural practices input factors on the uncertainties in the prediction of pesticides leaching extending this uncertainty analysis to other crops soil types and different catchment scale will provide additional guidance and information that should be taken into account when using the stics macro model to predict pesticides leaching in innovative cropping systems this identification is a valuable indication for model users which may choose to fix little relevant parameters to their nominal values while focusing efforts on measuring the parameters that have shown the strongest impact acknowledgments the authors are grateful to dr robert faivre inra for his help in building the meta model and for constructive discussions and to dr eric justes inra for providing soil data this work was supported by the french ecophyto plan managed by the onema through two french research programs for the ecophyto plan pspe1 managed by the ministry in charge of agriculture perform project and assessing and reducing environmental risks from plant protection products managed by the french ministry in charge of ecology ecopest project sabine karen lammoglia was supported by inra smach metaprogram and by the perform project appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 007 
26331,modelling of pesticide leaching is paramount to managing the environmental risks associated with the chemical protection of crops but it involves large uncertainties in relation to climate agricultural practices soil and pesticide properties we used latin hypercube sampling to estimate the contribution of these input factors with the stics macro model in the context of a 400 km2 catchment in france and two herbicides applied to maize bentazone and s metolachlor for both herbicides the most influential input factors on modelling of pesticide leaching were the inter annual variability of climate the pesticide adsorption coefficient and the soil boundary hydraulic conductivity followed by the pesticide degradation half life and the rainfall spatial variability this work helps to identify the factors requiring greater accuracy to ensure better pesticide risk assessment and to improve environmental management and decision making processes by quantifying the probability and reliability of prediction of pesticide concentrations in groundwater with stics macro keywords uncertainty analysis latin hypercube sampling meta model pesticide leaching stics macro 1 introduction modelling the leaching of pesticides can help prevent and manage groundwater contamination as groundwater protection is a key issue for human health and resources sustainability however the prediction of pesticide leaching by process based models is fraught with considerable uncertainties vanderborght et al 2011 key sources of uncertainties include i primary data basic physical chemical and environmental properties either directly fed into a model or used to derive input parameters because of spatial and temporal variability of environmental variables sampling procedures in the field and analysis in the laboratory ii procedures to derive some input parameters for lack of experimental data although the latter are recommended in general use of first order kinetics to derive dt50 values use of pedotransfer functions and iii modelling model error i e structural error or model inadequacy non inclusion or inappropriate representation of significant processes in the model modeller subjectivity dubus et al 2003a understanding the type and degree of uncertainties identified in the assessment helps to characterise the level of risk to the recipients and is therefore essential for informed decision making efsa 2016 sohrabi et al 2002 one of the objectives of sustainable agriculture is to reduce the risks and impacts of pesticide use on the environment by encouraging the development of new cropping systems relying on integrated pest management or low input programmes directive 2009 128 ec 2009 hossard et al 2016 reliable information on the sustainability of each potential new system can be obtained from field experiments for example crop residues management and tillage practices were shown to have strong effects on water percolation and pesticide leaching the presence of a mulch could increase soil water content so water percolation and pesticide leaching and conventional tillage generally decreases pesticide leaching compared to no till alletto et al 2010 lammoglia et al 2017b however there are a wide diversity of possible combinations of crops agricultural practices tillage organic matter management mulch soils and climates it is therefore time consuming and expensive to carry out comprehensive in situ experiments of each potential new system especially since results are site specific consequently models such as rzwqm malone et al 2004 stics pest queyrel et al 2016 or stics macro lammoglia et al 2017a have been developed as potentially effective and inexpensive tools to assess numerous options and to identify the best cropping systems the stics macro model combines the performances of an agro ecosystem model stics brisson et al 1998 2009 and of a pesticide fate model macro larsbo and jarvis 2003 it allows to quantify the environmental impacts of pesticides i e concentrations in soil and water taking into account the effects of pedoclimatic conditions agricultural practices and cropping systems compared to rzwqm and stics pest stics macro i does not need calibration step ii considers non linear sorption which can be decisive to simulate the fate of pesticides in the environment beltman et al 2008 iii allows improvement of the simulation of crop growth that leads to better estimate of crop transpiration therefore of water balance iv allows better estimate of pesticide interception by the crop so of the amount of pesticide reaching the soil which is crucial for the prediction of pesticide concentrations in water v allows to consider some agricultural practices such as fertilization mulch crop residues management and vi allows to obtain various environmental outputs such as the dynamic of nitrogen compounds and crop yields lammoglia et al 2017a 2017b the ability of stics macro to accurately predict the crop growth and development and to predict water and pesticides leaching has been evaluated through a test of the model and a sensitivity analysis in different agro pedoclimatic contexts lammoglia et al 2017a 2017b the results showed that the performance of the model was acceptable although it depended on the pedoclimatic context lammoglia et al 2017a uncertainty analysis is one of the most important elements in the development and implementation of models sohrabi et al 2002 uncertainty analysis permits to quantify how the uncertainties of some of the model components inputs parameters equations translate into uncertainties in model output of interest for the study a complementary sensitivity analysis allows determining of the relative contribution of the different sources of uncertainty considered wallach et al 2014 there are numerous techniques to propagate uncertainty in models such as differential analysis e g diaz diaz et al 1999 monte carlo analysis e g dubus and brown 2002 generalised likelihood uncertainty estimation glue e g beven and binley 1992 or fuzzy logic e g freissinet et al 1999 some uncertainty analyses have been done on macro sohrabi et al 2002 steffens et al 2013 2014 stenemo and jarvis 2007 uncertainties associated to some soil hydraulic and pesticide properties and pedotransfer functions were shown to cause large variation in simulation results sohrabi et al 2002 stenemo and jarvis 2007 moreover the parameter uncertainty can overshadow the effects of model structural error due to equations on predicted leaching losses steffens et al 2013 considering climate uncertainty through several expected future time series of climate data steffens et al 2014 showed that the effect of parameter uncertainty was less important than climate uncertainty however the combined effects of uncertainties related to the spatial variability of climate at a small catchment scale soil hydraulic properties and pesticides properties on pesticide leaching have never been studied among the various climatic variables rainfall is a key input for all models because it activates flow and mass transport chaubey et al 1999 lewan et al 2009 since rainfall is a driving force behind many kind of pesticide release and subsequent transport mechanisms ignoring this property of rainfall in the application of models will put a limit on the accuracy of the model results chaubey et al 1999 uncertainty analyses performed on the stics model mainly focused on the effects of climate variability on crop yields dumont et al 2015 j√©go et al 2015 to the best of our knowledge no uncertainty analysis considering the other stics input parameters such as those related to cropping practices has been done therefore the objectives of this work were i to assess the effect of spatial and temporal rainfall variability on stics macro modelling of pesticide leaching assessed through local concentrations in the leachate at a 400 km2 catchment scale ii to assess the effect of the uncertainties of climate agricultural practices and soil and pesticides properties on the modelling of pesticides leaching through an uncertainty analysis of the stics macro model and iii to quantify the contribution of each input factor to the uncertainties in simulated pesticide leaching this work will help to improve environmental management and decision making processes 2 materials and methods 2 1 stics macro model macro larsbo and jarvis 2003 is a one dimensional dual permeability model of water flow and solute transport in macroporous soil the water and solute are partitioned into two domains micropores where flow and transport occur represented by the richards and the convection dispersion equations and macropores where gravity driven flow occurs pesticide sorption is described using the freundlich isotherm while degradation follows first order kinetics and depends on soil temperature and moisture content the representation of crop development is simply based on crops emergence and harvest dates maximum leaf area index lai maximum root depth and maximum crop height as user defined input parameters no agricultural practices such as mulching or tillage can be considered under conventional crop management the performance of macro is known to be good enough to allow acceptable predictions of pesticides leaching e g mar√≠n benito et al 2014 the stics crop model brisson et al 1998 2009 is a dynamic daily time step model which simulates plant growth water dynamics and c and n cycles over several growing seasons stics describes in details the physical and biological processes occurring in the soil crop environment system considering a broad diversity of crop varieties and management practices stics predicts many output variables related to the crop production lai crop yield to the environment water carbon and nitrogen fluxes and to the evolution of soil water and nitrate contents stics has been widely tested for a variety of cropping situations and was shown to be good to predict crop and soil variables under various agricultural practices brisson et al 2003 coucheney et al 2015 stics macro results in the combined use of stics and macro in order to simulate crop growth and pesticide fate in complex cropping systems fig 1 lammoglia et al 2017a dedicated r packages r development core team 2016 were developed to automate the forcing of macro inputs with some stics output variables the packages allow to sequentially 1 import predefined stics and macro parameterization sets one for each model 2 simulate the crop rotation crop development water and nitrogen requirements under agricultural practices such as fertilization or crop residues management with stics model 3 extract from stics output files the estimated potential evapotranspiration as well as the estimated green and total lai the crop height and the maximum root depth for each time step 4 convert these to macro input file format and adapt macro parameterization 5 estimate the fraction of the sprayed pesticide intercepted by the crop based on stics total lai when the pesticide is sprayed 6 run the macro model with crop shape variables and potential evapotranspiration coming from stics and finally 7 import macro simulation results into the r environment i e water balance and pesticide concentrations in soils and water as a function of time the results can either be analyzed and visualized in r or exported in different formats internally the tools use existing command line modes of stics and macro but do not use the graphical user interfaces of the two models as indicated above the performance of stics macro to simulate the fate of pesticides under different cropping systems was shown to be acceptable although it depended on the pedoclimatic context the performance of stics macro was found to be better in a clayey calcic cambisol under average precipitation of 820 mm per year and average annual temperature of 11 c than in stagnic luvisol with 630 mm per year and 13 5 c lammoglia et al 2017a 2 2 climate soil and pesticides characteristics this work is based on a geographic area corresponding to the catchment of auzeville which surrounds an experimental site of inra southwest of france 43 31 n 1 30 e the catchment area is defined as a square zone of 400 km2 20 km 20 km divided into grid cells of 1 km2 1 1 km imposed by the resolution of the rainfall data see 2 2 1 the dominant land use is maize crop production sown from 1st april to 31st may maize monoculture has therefore been considered in this study also taking into account it is one of the most cultivated crop in france with a sowing area about 3 11 million ha grain maize and forage maize agreste 2016 2 2 1 climate stics macro requires daily climatic inputs because despite macro can be run with hourly rainfall data stics cannot nevertheless in macro daily rainfall data are converted internally into hourly rainfall data moeys et al 2012 the daily meteorological variables used in the study cover the 2007 2013 period the daily minimum mean annual ranging from 8 4 c in 2010 to 9 7 c in 2011 and maximum 17 9 c in 2010 to 19 8 c in 2011 air temperatures global solar radiation 1304 j cm 2 in 2013 to 1403 j cm 2 in 2011 relative humidity 72 in 2012 to 77 in 2008 and wind speed 2 2 cm s 1 in 2009 to 2 4 cm s 1 in 2008 were obtained from the inra auzeville meteorological station located close to the catchment climatik 2016 rainfall data were obtained from meteo france they correspond to radar c band dual polarization data with a spatial resolution of 1 1 km and a temporal resolution of 5 min the 5 min rainfall data were aggregated to daily values needed as input by the model fig 2 2 2 2 soil properties the loamy clayey soil of the experimental site of auzeville was selected as representative of the catchment the soil textural characteristics such as sand silt clay and organic carbon contents bulk density and ph were measured table 1 retc retention curve van genuchten et al 1991 was used to estimate the soil hydraulic parameters as required in stics macro such as the water contents at wilting point wilt and field capacity hccf and the water retention parameters tporv saturated water content xmpor boundary i e between macropores and micropores water content resid residual water content ksatmin saturated hydraulic conductivity and alpha and n van genuchten s soil water retention parameters the boundary soil water tension cten and the tortuosity pore size distribution factor zn were estimated from beulke et al 2002 table 1 the two soil parameters that were selected for the uncertainty analysis see 2 4 1 the boundary hydraulic conductivity ksm and the diffusion pathlength ascale were estimated according to steffens et al 2013 and are shown in table 2 2 2 3 pesticides two herbicides bentazone and s metolachlor were selected because they are among the most used on maize crop for weed control and because they are frequently detected in groundwater alletto et al 2013 steffens et al 2013 table 2 s metolachlor is used in pre emergence and early post emergence bentazone is used in post emergence consequently its interception by the crop canopy during spraying is higher than that of s metolachlor sorption was assumed to be proportional to the soil organic carbon content degradation rates in the subsoil were corrected from those in the topsoil according to focus 2000 following the recommendations for application in france bentazone and s metolachlor were considered to be applied on maize at rates ranging from 0 750 to 1 392 kg ha 1 and from 1 500 to 1 921 kg ha 1 respectively table 2 bentazone was sprayed from 30 to 80 days after sowing the earliest s metolachlor application was done 5 days before the sowing date and the latest was done 30 days after the sowing date table 2 2 3 assessment of the effects of spatial and temporal variability of rainfall on the modelling of pesticides leaching to assess the effects of spatial and temporal rainfall variability on the modelling of bentazone and s metolachlor leaching stics macro was run from 2007 to 2013 at every 1 km2 grid of the 400 km2 auzeville catchment from one grid cell to another the rainfall time series varied while all other stics macro parameters were held constant the uncertain parameters at their nominal values defined as mean values of the range table 2 the results were summarized for each year by their mean values over the catchment and their coefficients of variation cv 2 4 uncertainty analysis following the assessment of the effects of rainfall variability on the modelling of pesticides leaching the uncertainty analysis of stics macro combining uncertainties related to climate agricultural practices soil and pesticide properties was performed to allow within a reasonable calculation time the characterization of the spatial variability of rainfall in the uncertainty analysis four evenly spaced grid cells were selected among the 400 because they exhibited different ranges of annual rainfall fig 2 combining the seven rainfall series of the four selected grid cells for every climatic year from 2007 to 2013 led to 28 rainfall series that were used to study the effects of uncertainty related to spatial and temporal rainfall variability 2 4 1 selection of input factors based on the results of previous sensitivity and uncertainty analyses carried out with stics ruget et al 2002 varella et al 2010 macro dubus and brown 2002 dubus et al 2003b larsbo and jarvis 2005 roulier and jarvis 2003 and stics macro lammoglia et al 2017b seventeen input factors were first considered these input factors have then been analyzed with the morris screening method morris 1991 to determine those that had a strong influence on the predictions of bentazone and s metolachlor leaching this step avoided spending a large effort to carefully characterise factors that have little impact on the uncertainty of stics macro outputs among the seventeen input factors eight of them were found to have low or negligible impact on stics macro outputs data not shown on the contrary nine input factors were identified as influential table 2 the date of sowing iplt0 the amount of organic residues added to soil qres the number of days from sowing to pesticide application datepest the dose of pesticide dose the freundlich adsorption coefficient kf the freundlich exponent nf the degradation half life dt50 the boundary hydraulic conductivity ksm and the effective diffusion pathlength ascale the nominal values the lower and upper bounds of these input factors are presented in table 2 their distribution was assumed to be uniform both for the uncertainty analysis and the sensitivity analysis see 2 5 2 4 2 propagation of the uncertainties of the selected input factors monte carlo methods are often recommended to analyze the propagation of uncertainties through complex environmental models helton and davis 2003 wallach et al 2014 they are probabilistic methods based on the sampling of the output variable space the deterministic output of the model is computed for the set of sampled inputs according to distribution functions the model output uncertainty is defined by descriptive statistics such as mean standard deviation and quantiles which are computed based on the deterministic set of outputs helton and davis 2003 to limit computational cost we used the latin hypercube sampling lhs scheme mckay et al 2000 which guarantees that full coverage by stratification over the range of each input variable is represented first lhs uniformly divides the range of each input variable into disjoint intervals of equal probability then a value from each interval is randomly selected with respect to the specific probability density function in that interval finally one of the random values for each input variable is randomly chosen to form a sampling element previous studies have shown that for a given sample size or number of simulation lhs can more exhaustively explore model parameter space than simple random sampling helton and davis 2003 mckay et al 2000 when using monte carlo method the sample size has to be carefully determined to obtain reliable results the more samples are used the more reliable the statistical inference will be made on the other hand an increase in sample size is accompanied by more computational cost which is a major limiting factor with our model therefore the accuracy and the computational cost must be appropriately balanced helton and davis 2003 mckay et al 2000 to investigate how the sample size affects the stability of the simulations and to choose the appropriate sample size for the uncertainty analysis lhs was undertaken with several sample sizes of 100 500 1000 2000 and 5000 for the s metolachlor case study the relationships between the concentrations of s metolachlor and the different sample sizes were visualized by presenting the 10th quantile the 90th quantile and the mean annual pesticide concentration at 1 m depth c annual fig 3 a see 2 4 3 this relationship has also been plotted with the logarithmic transformation of the c annual of s metolachlor fig 3b this logarithmic transformation procedure is further explained in section 2 5 following logarithmic transformation the sample size was found to have little influence on the 10th and 90th quantiles fig 3a and b and a sample size of 500 seemed adequate however without this transformation fig 3a shows that even with a sample size of 5000 the results of c annual were not completely stable consequently in order to keep an acceptable computing cost while minimizing potential sample size effects on the concentrations of s metolachlor a sample size of 2000 have been used using the ranges of variation assigned to the nine input factors table 2 and the 28 rainfall series 7 years 4 positions the monte carlo simulation with lhs was performed by running stics macro with 2000 as sample size for both bentazone and s metolachlor this design resulted in 112 000 simulations 2 pesticides 2000 samples 7 years 4 positions which needed 25 days calculation parallel computing on a quad core xeon processor at 3 06 ghz 2 4 3 outputs the effects of the uncertainties were assessed on the following two outputs of stics macro for each grid cell i the arithmetic mean annual concentration of pesticide leached at 1 m depth c annual Œºg l 1 i e occurring during one year starting at the pesticide application date named here as annual concentration ii the maximal daily pesticide concentration at 1 m depth over one year period c max Œºg l 1 starting at the pesticide application date 1 c a n n u a l 1 365 n 1 365 m n v n 2 c m a x m a x m 1 v 1 m 365 v 365 where n is the day after the pesticide application date mn m1 m365 is the mass of leached pesticide on the day n on day 1 365 ¬µg and v n v 1 v 365 is the volume of percolated water on the day n on day 1 365 l then the arithmetic mean of the c annual the 10th quantile and the 90th quantile of the distribution for all combinations of the 7 years 4 spatial positions and 2000 parameters of lhs design were calculated each of the seven selected climatic years was simulated independently from the others to study the effect of climate on pesticide leaching consequently there is no residual amount of pesticide from the previous year in one simulation 2 5 sensitivity analysis once the uncertainties in stics macro outputs have been quantified a sensitivity analysis has to be done to identify the input factors that contribute the most to uncertainties in the outputs there are several sensitivity analysis methods that can be used and wallach et al 2014 recommend to implement several methods and to compare their results the 112 000 simulations performed for the uncertainty analysis produced a high number of input output pairs therefore due to the high computational cost of stics macro the sensitivity analysis explored those input output pairs instead of running again stics macro with another sampling first the pearson product moment correlation pear coefficients were determined for the nine input factors the pear coefficient measures the degree of linear association between the variations of stics macro output the c annual was retained for these calculations and the variation of the studied input factors a correlation close to 1 or 1 indicates a strong influence of the input factor on pesticide concentrations while a correlation close to zero indicates that the input factor is not influential wallach et al 2014 the pear coefficients were determined from the logarithmic transformation of concentrations see below then we built and used a meta model of stics macro a meta model consists in a mathematical function built from a set of simulations of the original model over the domain of variation of the input factor this approach has already been used in environmental modelling permitting to apply powerful sensitivity methods faivre et al 2013 uusitalo et al 2015 linear regression is the most commonly used method for meta model construction because of its simplicity however it performs better when the relationship between inputs and outputs is approximately linear storlie et al 2009 therefore we built the meta model on the logarithmic transformation of the outputs to take into account low concentration values of bentazone and s metolachlor using the linear regression function lm and the stepwise procedure step implemented in the r statistical software r development core team 2016 we used the log threshold x transformation where x is c annual or c max of bentazone and s metolachlor as predicted by stics macro the value of the threshold was set to 10 6 ¬µg l 1 as a compromise to give weight to low concentrations but not too much weight to very low values the nine quantitative input factors presented in table 2 were considered as quantitative variables and the seven climatic years year and the four spatial positions pos of the selected meteorological data were considered as qualitative input factors we limited the model to the interactions of order 2 thus sensitivity indices were computed using anova method which assesses the main contribution of each input factor to the total variance of the model outputs as well as the interactions between factors wallach et al 2017 the performance of the meta model was assessed performing new simulations with stics macro and with the meta model with a new and independent lhs sample of size 100 two statistical indices were calculated to assess this performance the efficiency ef and the bias b 3 e f 1 i 1 n s i o i 2 i 1 n o i o m 2 4 b i 1 n s i o i i 1 n o i where s i is the concentrations simulated by the meta model o i is the concentrations simulated by stics macro o m is the mean of the simulations of stics macro and n is the number of simulations ef ranges from to 1 with ef 1 indicating a perfect match between stics macro and the meta model when the bias b 0 it indicates a perfect match if b 0 it indicates an overestimation by the meta model while b 0 indicates an underestimation by the meta model 3 results and discussion 3 1 effects of the spatial and temporal variability of rainfall on the modelling of pesticides leaching the total annual amounts of rainfall on the period of one year after pesticide application were highly variable among the seven years with a mean value averaged over the 400 km2 area ranging from 504 mm in 2010 to 1000 mm in 2008 for bentazone and from 488 mm in 2011 to 1062 mm in 2008 for s metolachlor fig 4 table 3 these values are different from one pesticide to another because they are considered from the pesticide application date the coefficients of spatial variation cv of annual rainfall ranged from 4 1 in 2008 to 6 9 in 2010 for bentazone and from 3 9 in 2008 to 7 4 in 2007 for s metolachlor table 3 the largest annual rainfall occurred in 2008 corresponding to the lowest variability over the catchment cv 4 1 and 3 9 for bentazone and s metolachlor respectively table 3 for both bentazone and s metolachlor the influence of the spatial and temporal rainfall variabilities was analyzed by running stics macro at each of the 400 grid cells from 2007 to 2013 while all other parameters were held constant very large differences were found between the simulated annual concentrations at 1 m depth c annual of bentazone and s metolachlor fig 4 the effects of rainfall variability on the leaching of bentazone and s metolachlor were also found to be amplified through the stics macro model the cv of the c annual of bentazone and s metolachlor were considerably larger than the corresponding ones for rainfall from 98 to 663 for bentazone and from 68 to 347 for s metolachlor table 3 the biggest variations in the c annual of bentazone and s metolachlor occurred in 2009 when annual rainfalls were low whereas the smallest variations occurred in 2008 when rainfalls were maximal table 3 therefore assuming a linear transfer of rainfall variability through the stics macro model would have led to underestimation of the concentrations of bentazone and s metolachlor bentazone is more mobile and more persistent than s metolachlor table 2 so as expected its maximal concentrations at 1 m depth c max were higher than those of s metolachlor boesten and van der linden 1991 fig 5 in general the spatial variation of the concentrations of bentazone was also 2 times higher than that of s metolachlor table 3 finally a significant positive correlation was found between the annual rainfall amounts and the logarithmic transformation of the concentrations of both bentazone and s metolachlor at 1 m depth r2 0 63 and 0 45 respectively meaning that pesticide leaching increases exponentially with annual rainfall this is consistent with many results showing that pesticide leaching increases with increasing annual rainfall amounts e g tiktak et al 2004 overall this assessment of the influence of rainfall variability on leaching prediction reveals the non linear effects of annual rainfall on the concentrations of both herbicides and the importance of taking into account the uncertainties related to spatial and temporal variability of annual rainfall for the estimation of pesticides concentrations in groundwater 3 2 uncertainty analysis the results of the 112 000 simulations led to annual concentrations at 1 m depth cannual ranging over the seven years of simulation from 0 to 570 Œºg l 1 for bentazone and from 0 to 750 Œºg l 1 for s metolachlor while the maximal concentrations at 1 m depth c max were found to range from 0 to 2 0 105 Œºg l 1 for bentazone and from 0 to 2 5 105 Œºg l 1 for s metolachlor any value below the threshold of 10 6 ¬µg l 1 has been considered as 0 for the 2007 2013 simulated period the average c annual of bentazone was 0 287 Œºg l 1 and was lower than that of s metolachlor of 1 55 Œºg l 1 and the corresponding median values were 5 5 10 7 Œºg l 1 for bentazone and 3 3 10 6 Œºg l 1 for s metolachlor table 4 the average c max were high 16 6 Œºg l 1 for bentazone and 65 2 Œºg l 1 for s metolachlor while the median values were lower 1 0 10 5 Œºg l 1 and 5 7 10 5 Œºg l 1 respectively table 4 the logarithmic transformation of concentrations was found to be suitable to represent the distribution of the concentrations of bentazone and s metolachlor fig 6 it is of importance for meta model building see 3 3 2 and it avoids to give too much weight to values less than this threshold and thus to improve the quality of prediction for higher values the concentrations of both bentazone and s metolachlor were strongly skewed and did not fit any standard distribution fig 6 among other things because of numerous null or quasi null concentrations the results predicted with 80 confidence that the c annual of bentazone would be between 0 and 0 035 Œºg l 1 and that the c annual of s metolachlor would be between 0 and 0 494 Œºg l 1 table 4 however the means of the distributions of the c annual of bentazone and s metolachlor are superior to the 90th quantile table 4 reflecting the sensitivity of the arithmetic mean to extreme values here high concentrations this result comes from a very non linear response of the model on the variable of concentration if the number of low concentrations is 10 times that of high concentrations then the mean values are greater than the 90th quantile it emphasizes the difficulty to estimate precisely extreme quantiles and even the simple mean with such models who require high computational time to go further it may be interesting to consider the existing correlations within the input factors but it arises lots of questions on how to qualify these correlations which are poorly documented in the scientific literature and technical databases finally these results mean that there is high probabilities that stics macro simulates concentrations lower than the mean of the distribution which will have some consequences on risk assessment because of underestimation of the average leached concentrations of pesticides finally it was shown that the predicted annual concentrations of bentazone and s metolachlor could exceed the regulatory threshold of 0 1 Œºg l 1 at 1 m depth focus 2000 commission regulation eu 546 2011 2011 in 6 and 15 of the situations respectively considering their maximal concentrations during the first one year following application bentazone and s metolachlor could exceed this regulatory threshold in 17 and 24 of the situations respectively 3 3 contribution of the different sources of uncertainty 3 3 1 correlation based sensitivity analysis the pear coefficients were calculated to identify the correlations between c annual of pesticides and the 9 input factors using the 112 000 lhs monte carlo simulations they were computed on the logarithmic values of the concentrations the mean values of the pear coefficients and the sensitivity ranking were different for bentazone and s metolachlor and they varied from one climatic scenario to another table 5 for both pesticides the freundlich adsorption coefficient kf and the boundary hydraulic conductivity ksm were found to be very influential with a stronger influence of kf for the pre emergence herbicide s metolachlor table 5 an increase in the values of kf and ksm decreased the concentrations of both bentazone and s metolachlor which is consistent with the findings of dubus and brown 2002 and may reflect the fact that the higher ksm the less frequently preferential flow is triggered however ksm was found more important for the post emergence herbicide bentazone though preferential flow and related factors ksm are known to be more important in determining the leaching of more strongly sorbed pesticides dubus and brown 2002 larsson and jarvis 2000 a possible explanation might be that a larger ksm values induces a relatively faster bulk transport in the soil matrix of mobile compounds such as bentazone the degradation half life dt50 was also influential and an increase in the values of dt50 increased the concentrations of both bentazone and s metolachlor however an increase in dt50 could also lead to a decrease in the concentrations of bentazone depending on the climatic conditions table 5 the influence of the effective diffusion pathlength ascale on the concentrations of bentazone also seemed to be climate dependant while this was not observed for s metolachlor table 5 the other pear coefficients were low but they may show that the crop management factor qres amount of organic residues added to soil could be more influent than the pesticide application date datepest and dose dose table 5 for both bentazone and s metolachlor an increase in the values of qres increased the concentrations in agreement with the findings of lammoglia et al 2017b nevertheless the qres and datepest factors could have more influence on the concentrations of bentazone than those of s metolachlor and their influence could be increased by the climatic conditions these differences between the ranking of bentazone and s metolachlor can be explained by the interception of bentazone by the crop canopy as the application date of bentazone was 43 days later than that of s metolachlor table 2 this effect seems to be reinforced with lower annual rainfall 3 3 2 quantitative meta model based sensitivity analysis based on the logarithmic transformations of the predicted concentrations of bentazone and s metolachlor a meta model of stics macro was built the quality of the prediction of this meta model was evaluated on an independent lhs sample of size 100 fig 7 for bentazone the stepwise procedure selected a model with 129 parameters instead of 154 parameters with the complete model and an adjusted r2 of 0 88 the quality of the prediction was quite satisfying with an efficiency ef of 0 66 and a bias b of 0 015 for s metolachlor the stepwise procedure selected a model with 124 parameters instead of 154 and an adjusted r2 of 0 84 the quality of the prediction was also satisfactory with ef 0 64 and b 0 008 for both bentazone and s metolachlor the meta model underestimated the annual concentrations c annual for some dry years 2009 2010 2011 fig 7 table 3 the anova computed on these meta models explained 81 and 80 of the total variability of the concentrations of bentazone and s metolachlor respectively fig 8 the climatic years year the kf and the ksm were the three most influencing factors for modelling of the concentrations of both bentazone and s metolachlor with stics macro for the weakly sorbed herbicide bentazone year was the most influential factor it explained 49 of the total variability of the concentrations of bentazone fig 8 however year only explained 27 of the total variability of the concentrations of s metolachlor while the kf explained 34 fig 8 the effects of the kf were less important for the leaching of bentazone 7 3 the three most influent factors year ksm kf are followed by the dt50 and the rainfall spatial variability pos fig 8 the rainfall spatial variability pos contributed to the variability of the predicted concentrations more than the pesticide properties nf the crop management properties qres iplt0 dose datepest and the soil property ascale these results agree with those of steffens et al 2014 who indicated that uncertainty in model parameters was less important for the prediction of pesticide leaching than climate uncertainty the qualitative and quantitative sensitivity analysis methods led to the same conclusions except that for s metolachlor the pear coefficient emphasized higher influence of the freundlich exponent nf than of ascale contrary to the results obtained with the meta model table 5 fig 8 in line with the results obtained for the pear coefficients table 5 the ksm had higher influence on the variability of the concentrations of bentazone than of s metolachlor 16 and 13 respectively the interactions between the factors were found to be important between climate year and pesticide kf and soil ksm properties fig 8 the interactions effect were very small for the crop management properties qres iplt0 dose datepest despite previous studies found interaction effects between climate variables pesticide application scenarios and pesticide use steffens et al 2014 2015 since the sum of the total effects is high 81 for bentazone and 80 for s metolachlor the input factors have major additive effects on the logarithmic values of the concentrations of bentazone and s metolachlor this indicates that stics macro behaved as an additive model with important parameter interactions when the predicted concentrations are logarithmically transformed however it is worth remembering that the results of this study only stand in the bounds defined for each input factor and are specific to the soil crop conditions and the climate characteristics of the catchment assessed 4 conclusion the objective of this work was to study the effects of the uncertainties related to climate agricultural practices soil and pesticide properties on the prediction of pesticides leaching with stics macro first the effect of spatial and temporal rainfall variability on mean annual pesticides concentrations at 1 m depth was assessed the interactions between the concentrations of bentazone and s metolachlor and the annual rainfall were shown to be non linear and the variability of the concentrations was higher than that in the annual rainfall amounts spatial coefficients of variation of annual rainfall ranging from 4 to 7 produced 68 663 of variation in the concentrations these results suggest that the spatial and temporal heterogeneity are paramount when defining representative rainfall data for pesticide leaching prediction then using a monte carlo method with latin hypercube sampling the uncertainties of input factors related to climate agricultural practices and soil and pesticide properties were propagated through stics macro there was a high probability of predicting concentrations of both bentazone and s metolachlor lower than the means of their respective distributions because the distributions of their concentrations were strongly skewed and showed mean values superior to the 90th quantile this has to be considered in risk assessment because of the probable underestimation of the average leached concentrations of pesticides even if bentazone is more mobile and persistent than s metolachlor there are half less risks that the annual concentrations of bentazone exceed the regulatory threshold of 0 1 Œºg l 1 because of higher interception of bentazone than of s metolachlor by crop canopy then a sensitivity analysis was done based on the pearson coefficient and on the anova method using a meta model of stics macro the climate temporal variability the freundlich adsorption coefficient and the boundary hydraulic conductivity followed by the degradation half life and the rainfall spatial variability have been identified by both sensitivity analysis methods as the main input factors involved in the uncertainties in the prediction of the leaching of bentazone and s metolachlor the leaching of s metolachlor used in pre emergence and early post emergence was mostly affected by the parameter related to adsorption factors related to agricultural practices were most influential on the leaching of the post emergence pesticide bentazone stics macro also showed non linear but additive effects on the logarithmic values of the concentrations of bentazone and s metolachlor these results depend on the specific soil crop climate characteristics considered nevertheless they confirm the strong effects of the uncertainties in climate pesticide soil and agricultural practices input factors on the uncertainties in the prediction of pesticides leaching extending this uncertainty analysis to other crops soil types and different catchment scale will provide additional guidance and information that should be taken into account when using the stics macro model to predict pesticides leaching in innovative cropping systems this identification is a valuable indication for model users which may choose to fix little relevant parameters to their nominal values while focusing efforts on measuring the parameters that have shown the strongest impact acknowledgments the authors are grateful to dr robert faivre inra for his help in building the meta model and for constructive discussions and to dr eric justes inra for providing soil data this work was supported by the french ecophyto plan managed by the onema through two french research programs for the ecophyto plan pspe1 managed by the ministry in charge of agriculture perform project and assessing and reducing environmental risks from plant protection products managed by the french ministry in charge of ecology ecopest project sabine karen lammoglia was supported by inra smach metaprogram and by the perform project appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 007 
26332,a crucial decision in defining the scope of an environmental impact assessment is to delineate the initial assessment area we developed a probabilistic methodology to determine this area which starts by identifying a key environmental variable maximum acceptable change and acceptable probability of exceeding that threshold the exceedance probability is determined with a limits of acceptability rejection sampling of informed prior parameter distributions a qualitative uncertainty analysis a formal and systematic discussion of the main assumptions and model choices is complemented with global sensitivity analysis of the model results to identify the major sources of uncertainty and provide guidance for further research and data collection for the case study on coal development in the gloucester basin nsw australia the initial assessment extent is unlikely to extend more than 5 km from the edge of the planned coal mines the major source of uncertainty is the planned mine water production rate keywords environmental impact assessment uncertainty analysis hydrogeology coal bed methane coal mining 1 introduction defining the system boundaries and the zone of interest is part of the scoping phase of an environmental impact assessment hamilton et al 2015 this can be a daunting task especially in open systems without well defined natural boundaries an overly limited initial spatial extent of the study area compromises the environmental impact assessment as it can lead to missing impacts in the analysis or underestimating the impacts however being overly conservative can lead to a large increase in the initial spatial extent of the study which can also compromise the quality of the assessment especially if the available time and or budget for the assessment are limited in the context of cumulative impact assessments eccleston 2011 states that the spatial extent of an assessment should comprise the area in which a significant effect can be reasonably evaluated the extent should vary in function of the effect examined e g the spatial extent for noise impacts will be different to hydrological or ecological impacts it is however left to practitioners to define the threshold for a significant effect and the acceptable level of risk exceeding this threshold in this study we focus on potential cumulative water mediated economic social and environmental impacts of coal resources development kerr 2010 johnson et al 2013 measham et al 2016 establishing the initial assessment extent requires firstly to define which aspects of the hydrological system can be affected by coal development and would result in relevant economic social and environmental impact examples of these can be groundwater levels in a bore low flow duration in a river reach or the inundation regime of a floodplain wetland the second step in the methodology once a selection of these variables is made is to define the maximum acceptable level of hydrological change the level of hydrological change that would lead to a noticeable change in the economic social or environmental values affected by that variable uncertainty in the impact assessment extent can be expressed as the probability the threshold will be exceeded given the current state of knowledge the third and final aspect to define for the zone of potential change is the maximal acceptable probability of threshold exceedance the probabilistic assessment of environmental impacts has been researched since the 1970s suter et al 1987 leung et al 2015 most of the papers focus on uncertainty quantification the problem of statistical inference in which the mismatch between historical observations and simulated equivalents is used to constrain a model and to quantify the predictive uncertainty of a model carrera et al 2005 gupta et al 2012 bennett et al 2013 maier et al 2014 the seminal work by walker et al 2003 provided a wider view on the uncertainty analysis problem by developing a structured classification of sources of uncertainty which in turn influenced later guidance and frameworks such as those proposed by jakeman et al 2006 refsgaard et al 2007 and beven and alcock 2012 while the core of these frameworks still revolve around the quantification of uncertainty they all emphasise the need to systematically discuss assumptions underpinning the modelling as advocated by saltelli and funtowicz 2014 a prime example of this approach is performance assessment for proposed high level radioactive waste disposal helton et al 2014 in which the quantification of uncertainty in numerical models is balanced with discussions and analysis of the assumptions underpinning these models such discussion aims to elucidate whether or not an assumption will lead to an overestimate of change such conservatism helps to build confidence in the assessment but overly conservative assumptions can lead to missed opportunities as illustrated in freedman et al 2017 and underschultz et al 2018 most of the guidance and framework literature emphasises the need for an iterative process in model building for environmental impact assessment e g jakeman et al 2006 in which complexity of the numerical modelling and uncertainty assessment approach evolves as more data become available and system knowledge increases schwartz et al 2017 the probabilistic screening methodology we develop and apply in this paper is a pragmatic workflow to incorporate rigorous uncertainty assessment into the earliest stages of an assessment the delineation of the initial assessment extent this approach provides a more robust and justifiable spatial delineation of the assessment area with the insights potentially guiding further data collection and modelling efforts in subsequent stages of the impact assessment the probabilistic screening methodology allows to determine a zone of potential change which requires the explicit definition of the i nature of change ii threshold of acceptable change and iii probability of exceeding this threshold the methodology is based on a quantitative and qualitative uncertainty analysis in which the quantitative uncertainty analysis provides the probability of exceeding a pre defined hydrological change threshold while the qualitative uncertainty analysis is a systematic scoring and discussion of the assumptions underpinning the hydrological change computation the approach is illustrated with a case study for the potential of groundwater related impacts of coal resource development in the gloucester basin in new south wales australia the supplementary material provides the details of the implementation as a jupyter notebook and a table guiding the interested reader to the technical reports underpinning this research 2 methods the screening methodology developed for this study consists of four components which documented in turn are 1 objectives model outcomes and conceptualization 2 qualitative uncertainty analysis 3 quantitative uncertainty analysis and 4 synthesis and communication 2 1 objectives model outcomes and conceptualization in this study we focus on defining the hydrological change the acceptable change threshold and exceedance probability in the context of coal mining and coal seam gas extraction also known as coal bed methane extraction based on a formal process of defining the most likely coal resource development pathway lewis 2014 identifying hazards through impact modes and effect analysis ford et al 2016 and developing causal pathways henderson et al 2016 linking the coal development to potential impact on water related assets mount et al 2017 it is established that the most relevant hydrological change for groundwater is the maximum drawdown i e change in groundwater level in time at the location of the asset in the aquifer hosting the water table holland et al 2017 within the relevant legislative context the smallest drawdown threshold defined is 0 2 m for springs and groundwater dependent ecosystems in the new south wales aquifer interference policy office of water 2012 as the intended use is to rule out areas where impact is unlikely a low probability threshold of 5 is chosen the formal definition of the zone of potential hydrological change for groundwater thus becomes the zone in which the probability of exceeding 0 2 m of drawdown due to coal development in the aquifer hosting the water table is greater than 5 this statement however does not include a time frame viney 2016 suggested a time frame of 90 years as a suitable trade off between capturing long term effects and developing realistic long term scenarios 2 2 qualitative uncertainty analysis a qualitative uncertainty analysis tries to capture the sources of uncertainty that are not part of the probabilistic uncertainty quantification most of these uncertainties can be classified as epistemic uncertainty walker et al 2003 uncertainty due to imperfect knowledge and models which can be reduced through more research efforts this uncertainty manifests itself through the numerous choices and assumptions required during conceptualization and subsequent implementation in a numerical model refsgaard et al 2006 and kloprogge et al 2011 provide examples of methods to formally account for the uncertainty introduced by such model assumptions the pivotal aspects of these methodologies are the structured listing of model assumptions and the analysis of the implications and influence of those assumptions a pedigree analysis through peer review or a workshop with experts and stakeholders finding and listing all key assumptions requires as argued by saltelli et al 2013 p 9 an assumption hunting attitude to find important assumptions before they find you the pedigree analysis in kloprogge et al 2011 suggests scoring each assumption on aspects such as the practical motivation plausibility availability of alternatives agreement among peers and stakeholders and most importantly the perceived influence on the final prediction while it is recognized that these scoring systems are prone to subjectivity and their results can be heavily influenced by the scoring system used such methods are nevertheless useful as they provide a structured way of considering and analysing model assumptions this in turn helps in the open and transparent communication of model uncertainty guillaume et al 2015 this is a recurring theme in the framework of jakeman et al 2006 which highlights the need to explicitly consider alternative conceptualizations we follow the qualitative uncertainty analysis presented in peeters 2017 which is primarily inspired by kloprogge et al 2011 the major assumptions and model choices underpinning the environmental model are listed in a table with scoring of the attributes data resources technical and likely effect on predictions the goal of the table is to provide a non technical audience with a systematic overview of the model assumptions their justification and effect on predictions as judged by the modelling team this table is aimed to assist in an open and transparent review of the modelling in the table each assumption is scored on the four attributes using three levels high medium and low beneath the table each of the assumptions are discussed in detail including the rationale for the scoring the data column reports the degree to which the question if more or different data were available would this assumption choice still have been made would be answered positively a low score means that the assumption is not influenced by data availability while a high score indicates that this choice would be revisited if more data were available closely related is the resources attribute this column captures the extent to which resources available for the modelling such as computing resources personnel and time influenced this assumption or model choice again a low score indicates the same assumption would have been made with unlimited resources while a high score indicates the assumption is driven by resource constraints the third attribute deals with the technical and computational issues high is assigned to assumptions and model choices that are predominantly driven by computational or technical limitations of the model code the final and most important column is the effect of the assumption or model choice on the predictions this is a qualitative assessment by the modelling team regarding the extent to which a model choice will affect the model predictions with low indicating a minimal effect and high a large effect the scoring of the effect on the predictions can be justified through various strategies a formal sensitivity analysis is the most objective as it quantifies the effect of parameters on predictions for assumptions or choices that are not parameterised in the uncertainty analysis the effect on predictions can be explored through comparison with analogue situations documented in literature and or through an argumentation based on the underpinning physical laws and system understanding table 1 illustrates the concept of a qualitative uncertainty analysis with an assumption that is often made in groundwater modelling studies representing aquifer properties as spatially uniform the table captures both the scoring and its justification the example highlights that it is possible to score low on the prediction attribute despite scoring high on the data and resources attributes the qualitative uncertainty analysis critically examines the various aspects of the system conceptualization and model implementation it results in an assessment of conceptual and model uncertainty systematically identifying major knowledge and data gaps 2 3 quantitative uncertainty analysis the traditional modelling workflow as for example the groundwater modelling workflow in barnett et al 2012 follows the scheme of conceptualize implement calibrate predict and as a final step quantify uncertainty the notion of a calibrated model assumes that it is possible to infer an optimal set of model parameters and structure from state observations that allow the model to be used to make a wide variety of predictions harmel et al 2014 in groundwater modelling the validity of this assumption has shown to be tenuous at best as the parameters most salient to predictions are often not well constrained by the available observations e g white et al 2014 this problem is exacerbated when modelling greenfield conditions i e sites with no previous development in which the planned stresses on the system are unprecedented and limited historical observations are available this issue is implicitly recognized in the confidence classification of groundwater models barnett et al 2012 in which models assessing greenfield conditions are awarded the lowest confidence classification regardless of the complexity of the model in a traditional inference workflow the numerical model is evaluated repeatedly for different parameter combinations the selection of the parameter combinations and the acceptance of these into the posterior parameter distributions is determined by the prior parameter distributions and the likelihood function this sampling procedure often requires a large amount of model evaluations to ensure the posterior parameter distributions converge once a converged posterior parameter distribution is obtained a limited number of samples of this distribution is generally sufficient to robustly represent summary statistics of the distribution such as the median 5th or 95th percentile we designed the workflow for the probabilistic screening method to be 1 more flexible such that a change in prior parameter distributions or likelihood function will not necessitate evaluating the numerical model again for a large number of times and 2 provide insight in the numerical model to aid in discussing the effect of model assumptions and guide further model development and monitoring strategies in subsequent stages of the environmental impact assessment this workflow consists of three components 1 a global sensitivity analysis based on a wide initial range for all model parameters 2 statistical inference of the posterior predictive distribution and 3 replacing the numerical model with an emulator the model is first evaluated a large predefined number of times with parameters chosen randomly from uninformed prior parameter distributions this dataset of parameter combinations with corresponding model outputs serves a dual purpose the primary use is to perform a global sensitivity analysis to gain insight in model behaviour the secondary use is to train an emulator that can replace the original model during statistical inference we opted for a limits of acceptability inference approach in which a rejection sampler is used to sample informative priors the emulator is trained to classify parameter combinations into behavioural and non behavioural based on the predefined limits of acceptability this emulator allows to sample the parameter space comprehensively at a fraction of the computational cost the model output used to constrain the parameter space in the inference step is however not the model output required for the environmental impact assessment the model is for instance constrained with historical observations while the quantity of interest for the environmental impact assessment is a future state of the system subject to an unprecedented stress the posterior parameter distribution obtained by emulator assisted inference is therefore sampled a limited number of times and evaluated with the numerical model to provide the posterior predictive distributions the number of samples required to characterise robustly the 5th 50th and 95th percentile of a known distribution is generally much less than the number of samples required to infer a posterior distribution from prior distributions and a likelihood function in turn the following subsections provide more detail on the 1 global sensitivity analysis 2 limits of acceptability inference and 3 emulator and sampling of posterior parameter and predictive distributions 2 3 1 global sensitivity analysis a crucial step in the model design as pointed out by jakeman et al 2006 is the parameterisation of a numerical model the selection of model components allowed to vary during parameter inference and how they are allowed to vary while discussing the rationale behind such choices is part of the qualitative uncertainty analysis it is often not straight forward to identify beforehand to what extent a parameter is going to affect the predictions especially in complex non linear models a formal sensitivity analysis saltelli et al 2008 allows identification of the parameters most influential to the predictions and the parameters that can be constrained by observations in addition to this the response of predictions to changes in parameters provides insight into the model dynamics a valuable diagnostic check of model conceptualization herbst and casper 2008 peeters et al 2013 and model behaviour bennett et al 2013 from the wide variety of sensitivity analysis techniques available pianosi et al 2016 the density based sensitivity metric developed by plischke et al 2013 is chosen here as it provides an estimate of the sensitivity of a prediction to various model parameters that can accommodate non linearities in model response peeters et al 2014 and unlike most other sensitivity indices does not require specific sampling designs in this methodology we opted for a maximin latin hypercube sampling of an initial uniform parameter distribution within wide bounds of minimum and maximum values iman 2008 the sensitivity index Œ¥ i the sensitivity of output y to parameter x i is formally defined as plischke et al 2013 Œ¥ i Œ¥ y x i 1 2 œá i f x i x œÖ f y y f y x i x y d y d x where œá i and œÖ are the spaces containing output y and parameter x i respectively and f represents the density function the goal of this sampling is to compute sensitivity indices of the parameters to the model predictions to diagnose model behaviour the parameter distributions are intentionally chosen to uniformly cover the range considered plausible as to capture a wide spectrum of model responses to provide context for interpretation two dummy variables d1 and d2 are added to the sensitivity analysis both dummy variables are random values uniformly sampled in the 0 1 interval and have no effect on the prediction the effect of model parameters with sensitivity indices similar to those of the dummy variables is so small that it is not distinguishable from random noise with this sample size 2 3 2 statistical inference the bayesian paradigm allows updating of prior information with observations and system knowledge it is therefore essential for the prior parameter distributions to capture the existing knowledge of the system ellison 2004 the uniform parameter distributions used in the sensitivity analysis are non informative and do not encapsulate the full prior knowledge of the system in the next step of the methodology these uniform parameter distributions are therefore revisited by using measurements analogues and or expert opinion to create an informative prior that reflects the current understanding of the system this is especially important for the parameters identified in the sensitivity analysis as having a large influence on the prediction and low potential to be constrained by observations the inference approach used here is inspired by the approximate bayesian computation abc and generalized likelihood uncertainty estimation glue methodologies vrugt and beven 2018 which finds its origins in the limits of acceptability methodology e g hornberger and spear 1981 a problem specific single criterion or set of criteria are chosen by the modelling team to evaluate the model any parameter set sampled from the prior parameter distributions that satisfies these criteria is accepted into the posterior parameter distribution the random sampling of the priors is continued until a predefined number of samples in the posterior parameter distribution is reached or preferably the moments of the posterior predictive distribution stabilise this process can be more formally described as follows consider a model g with multivariate parameter vector x the model simulates a vector of future predictions y p and a vector of system state variables y s y p y s g x a function k maps the vector y s to a vector of quantities q that can be compared to a vector q that captures historical observations and system knowledge q k y s a proposal vector x randomly sampled from a prior parameter distribution is considered acceptable or behavioural if the corresponding vector q satisfies inequality d q q Œµ where d is a function that formalises comparison of vectors q and q such that it can be compared to an acceptability threshold Œµ in case q consists solely of historical system state observations k d and Œµ need to be chosen such that system state variables simulated with behavioural parameter vectors cannot be distinguished from observed system state variables when taking into account observational uncertainty should q also contain system knowledge that does not correspond to historical observations e g as expressed by domain experts k d and Œµ need to be chosen such that behavioural parameter sets result in system state variables that domain experts consider plausible or realistic 2 3 3 emulation one of the drawbacks of an inference scheme as outlined in section 2 3 2 is that it requires a large number of model evaluations before the posterior parameter distributions stabilise a pragmatic approach to improve computational efficiency is to replace the numerical model during inference with an emulator or surrogate model razavi et al 2012 asher et al 2015 here it is not necessary for an emulator to exactly mimic the model behaviour it is sufficient for the emulator to classify parameter combinations as behavioural meets threshold conditions or non behavioural does not meet threshold conditions this effectively recasts the emulation from a regression problem in which an emulator aims to reproduce a response surface to a classification problem among the plethora of classification algorithms available gradient tree boosting classifiers friedman 2001 are well established as robust and efficient classifiers caruana and niculescu mizil 2006 we used the implementation in pedregosa et al 2011 after assuring adequate performance of the classifier through cross validation the classifier is used to evaluate a large number of parameter combinations from the prior parameter distributions the samples classified as behavioural are retained in the posterior parameter distributions the posterior parameter distributions are subsequently sampled and evaluated with the numerical model to compute maximum additional drawdown in time in the aquifer containing the watertable throughout the model domain these predictive posterior distributions are summarised as the probability of exceeding the 0 2 m threshold at a large number of model nodes these posterior distributions need to be interpolated to locations other than these model nodes to generate a spatially consistent predictive distribution of drawdown the first step in the interpolation is to generate a delaunay triangulation dt from the model nodes chapter 9 in de berg et al 2008 next for any new location within the convex hull formed by the dt we identify the nodes that form the corners of the enclosing triangle for that new location any quantile of interest at the new location can now be obtained by linearly interpolating the same quantiles obtained at each of the corners of the enclosing triangle linear interpolation ensures that the ordering of the quantiles is preserved and so that a valid distribution function can be built up at the new location 2 4 synthesis and communication the ultimate result of the spatial delineation of the zone of potential hydrological change is a polygon corresponding to a contour line of an acceptable exceedance probability it is recommended that this polygon is not just described as the initial impact extent but with more descriptive phrases such as the area in which the probability of exceeding a drawdown of 0 2 m in the watertable aquifer is greater than 5 or outside this area there is at least a 95 probability that drawdown in the watertable aquifer is less than 0 2 m these phrases are not only a more accurate reflection of the screening process the alternating framing reduces the risk of cognitive bias spiegelhalter 2017 the table summarising the qualitative uncertainty analysis complements this by providing a succinct readily digestible overview of the main assumptions that can affect the initial assessment extent this qualitative uncertainty analysis can then be used as a starting point to identify knowledge and data gaps guide future data collection and monitoring strategies as well as focussing subsequent numerical modelling referring to the initial spatial extent in explicit probabilistic terms as well as highlighting the underpinning assumptions emphasise that this is a first step in the analysis and that impacts outside of this zone although unlikely cannot be fully excluded 3 study area the 348 km2 gloucester geological basin is situated about 250 km north east of sydney australia fig 1 the region has a sub tropical climate with summer dominant precipitation the average rainfall between 1982 and 2012 was 1095 mm yr and potential evapotranspiration 1587 mm yr jones et al 2009 hydrogeologically the gloucester basin can be divided into three main hydrogeological units frery et al 2018 fig 2 1 alluvium a 1 2 km wide unconfined aquifer up to 15 m thick along the main rivers 2 shallow weathered and fractured rocks a confined to semi confined aquifer up to 150 m thick and 3 water bearing strata interburden units alternating with coal seams to a maximum depth of about 2500 m the shallow weathered and fractured rocks underlie the alluvium entirely and outcrop extensively across the rest of the gloucester geological basin except for the alluvium the water table is hosted in the shallow weathered and fractured rock aquifer the most likely coal resource development pathway at the time of the study 2014 in the gloucester basin consisted of i the expansion of two existing open pit coal mines ii a new open pit mine and iii a coal seam gas well field consisting of 110 wells hodgkinson et al 2014 for coal seam gas extraction several vertical and horizontal wells are drilled to reduce the water pressure in coal seams this allows gases adsorbed onto the coal surface to desorb and be pumped to the surface the propagation of the depressurization through the sedimentary basin can potentially lead to changes in groundwater levels the extent of this propagation depends on the hydraulic properties of the sedimentary basin and on the stratigraphic and structural connectivity of the aquifers where faults and fractures can both increase or decrease aquifer connectivity bense et al 2013 in open pit coal mining the coal seams and overlying sedimentary layers are dewatered to ensure the mine pit is dry the propagation of the drawdown throughout the aquifer system caused by pumping groundwater will also depend on the hydrogeological connectivity of the aquifers 4 application 4 1 objectives model outcomes and numerical model as outlined in section 2 1 to delineate the zone of potential change the probability of exceeding 0 2 m drawdown needs to be estimated throughout the shallow weathered and fractured rock aquifer this section provides a succinct summary of the groundwater model developed for this purpose see peeters et al 2018 for a full description the model outcome sought is limited to the change in groundwater levels due to pumping associated with coal development both open pit mining and csg this allows simplification of the modelling by invoking the principle of superposition reilly et al 1987 the additional drawdown due to coal development can be simulated by only accounting for the fluxes that change due to development provided the system behaves linearly barlow and leake 2012 the numerical model developed with the analytic element code ttim bakker 2015 is depicted schematically in fig 3 the aquifer system is represented by a system of alternating aquifers and aquitards with lateral no flow boundaries coinciding with the extent of the geological gloucester basin dawes et al 2018 the coal seams are considered aquifers separated by interburden layers that act as aquitards based on well logs frery et al 2018 the thickness of the coal seams is set to 6 m while the number of coal seams is different for each realisation a randomly selected number between 6 and 12 the depth of each coal seams is also randomly varied between 250 m and 1000 m with higher likelihood for depth intervals where bore logs indicate higher density of coal seams the top most aquifer layer represents the shallow weathered and fractured rock aquifer with a nominal thickness of 150 m hydraulic conductivity and specific storage decreases exponentially with depth d according to p a 1 e x p a 2 d where p is either hydraulic conductivity or specific storage and a 1 and a 2 are the intercept and scale coefficients as this equation can lead to physically unrealistic values of hydraulic conductivity and specific storage values of hydraulic conductivity less than 1e 7 m d are replaced with 1e 7 m d a similar approach for specific storage uses a threshold value of 1e 6 1 m there are several major and minor faults present in the gloucester basin frery et al 2018 that can compromise the integrity of aquitards and thus potentially connect coal seams and the shallow aquifer the location of major faults connecting the entire sequence of aquifers is in accordance with geological mapping whether a fault is present in a single realisation depends on the probability of occurrence assigned to it i e a fault with 75 probability of occurrence is simulated in 7500 of the 10 000 simulations minor faults connecting at most two coal seams have been identified in drill holes but are not mapped at the scale of the available 1 100 000 geological maps covering the entire basin for these minor faults the stochastic sampling process generates a fault network in which the location fault length and orientation are varied stochastically consistent with the tectonic regime of the study area the fault density i e the number of faults is fixed at 40 based on local structural geological analysis frery et al 2018 faults are planar features in the groundwater model for which the hydraulic conductivity perpendicular to the fault plane and the hydraulic conductivity along the fault plane need to be specified open pit coal mines are represented as polygons from which a flux is extracted equal to the total pumping rate provided by the mining proponents the coal seam gas field is implemented as a head dependent boundary condition with the target groundwater level set 30 m above the top of the upper coal seam the model computes the coal seam gas flux and the change in groundwater level at 148 existing bore locations and at a 1000 additional locations throughout the model domain with greater density where large head gradients are expected i e close to the coal developments 4 2 quantitative uncertainty analysis 4 2 1 sensitivity analysis the parameterisation of the groundwater model is summarised in tables 2 and 3 the minimum and maximum values represent the plausible range over which these parameters are expected to vary based on a comprehensive review of international and local data sets presented in dawes et al 2018 frery et al 2018 and peeters et al 2018 these parameter ranges are uniformly sampled with a minimax latin hypercube sampling algorithm of these 10 000 parameter combinations 94 failed to converge and are excluded from further analysis this dataset of model runs is used to calculate density based sensitivity indices for the coal seam gas water production rate q c s g and maximum drawdown over time at the output locations in the shallow aquifer d m a x fig 4 the coal seam gas extraction rate is most sensitive to the hydraulic conductivity of the coal seam parameters k a1 cs and k a2 cs while maximum drawdown is most sensitive the specific storage of the shallow aquifer s a1 cs and the hydraulic conductivity of k a1 cs the coal seam gas water production appears not to be very sensitive to the specific storage of the coal seams s a1 cs and s a2 cs this implies that the coal seam gas water production rate has little potential to constrain s a1 cs the parameter d m a x is most sensitive to it is noteworthy that the parameters controlling hydraulic conductivity of the fault network kfv and kfh do not appear to influence the coal seam gas production rates or the maximum drawdown 4 2 2 inference the median of maximum water production rate over the life of the project is estimated by the coal seam gas proponent through detailed local modelling to be 0 6 ml d the 90 t h percentile is estimated to be 0 9 ml d agl energy limited 2015 for the abc algorithm we consider parameter combinations that result in water production rates in excess of 1 1 ml d not to be consistent with the current understanding of the sedimentary basin encapsulated in the detailed modelling brinkerhoff 2015 and therefore not acceptable the percentage of behavioural parameter combinations from the 9906 converging model runs is 54 04 these data are used to train a gradient tree boosting classifier implemented in the scikit learn package for python pedregosa et al 2011 a 30 fold cross validation resulted in a mean classifying accuracy of 95 with a standard deviation of 1 5 table 4 presents the confusion matrix for the classifier based on the training samples the prior parameter distributions that will be sampled in the bayesian inference are chosen to be multivariate normal after transformation summarised in tables 2 and 3 the values of the mean are chosen to be close to the centre of the range for each parameter while the variance is chosen such that approximately 99 of the prior distributions is within the uniform parameter range specified for the sensitivity analysis all parameters are considered to be independent except for hydraulic conductivity and specific storage and for vertical and horizontal hydraulic conductivity for the former for both coefficients of the depth hydraulic property equation covariance is specified in such a way that it represents a weak correlation while there is very limited information available in the observational record or literature to justify an exact covariance value a weak correlation is justified as both values ultimately depend on the lithology and diagenesis of the material the covariance specified for the vertical and horizontal fault hydraulic conductivity is chosen to represent a stronger correlation capturing the conceptual fault behaviour where faults act as barriers to flow horizontally and conduits of flow vertically bense et al 2013 a total of 1e6 samples are randomly drawn from the multivariate normal distribution and classified into behavioural parameter combination that will result in calculated coal seam gas water production rate less than 1 1 ml d and non behavioural parameter combination that will result in calculated coal seam gas water production rate greater than 1 1 ml d using the gradient tree boosting classifier this results in a posterior parameter distribution of 2 4e4 samples acceptance rate of 2 4 histograms of the posterior marginal parameter distributions are shown in fig 5 the convergence of the moments of these posterior distributions is presented in the supplementary material the results shown in fig 5 are consistent with the sensitivity analysis presented in fig 4 the parameters that are constrained the most through the inference are those controlling the hydraulic conductivity of the coal seams k a1 cs and k a2 cs the posterior marginal distribution of parameter s a1 cs is noticeably different from the prior distribution although the sensitivity analysis did not indicate that the coal seam gas water production rate is sensitive to this parameter the difference between prior and posterior in this case is due to the covariance specified in the prior distribution between hydraulic conductivity and specific storage the preference for lower values for k a1 cs in the posterior resulted in a shift towards lower values in s a1 cs as well 4 2 3 prediction a set of 200 parameter combinations is randomly drawn from the posterior parameter combinations and evaluated with the analytic element model the maximum drawdown values are simulated at 1000 model node locations the results are summarised in a map of the probability of exceeding 0 2 m fig 6 fig 6 shows that the zone of potential hydrological change the contour of 0 05 probability of exceeding 0 2 m drawdown extends about 5 km from the edge of the coal mines 4 3 qualitative uncertainty analysis the qualitative uncertainty analysis is a systematic discussion of the main model choices and assumptions and a subjective scoring of the importance of these on the model predictions the following table and discussion is the result of a workshop with the modelling team the authors of this paper a complete discussion of the assumptions in table 5 and the rationale behind the scoring of each attribute is provided in the supplementary material to illustrate the concept a detailed discussion of two assumptions are presented in turn in the following subsections i open cut mines as prescribed pumping rate and ii specification of prior distributions 4 3 1 open cut mines as prescribed pumping rate pumping rates to dewater open cut coal mines depend largely on local conditions as local conditions are not well captured in the analytic element model the choice was made to use reported historical pumping rates and rates estimated by the mining proponents based on local groundwater modelling the data attribute is scored high to implement open pit mine dewatering it is essential to know the exact elevation of the mine dewatering level and the proposed dewatering scheme this information is beyond the spatial resolution of the geological model underpinning the groundwater model the resources and technical attributes are scored low as it is trivial to specify the mine pit dewatering as head dependent flux boundary conditions and it does not appreciably increase the computational demand or processing time the effect on predictions is scored high as a change in pumping rate will greatly affect predictions and the reliability of the predictions of this model hinge on the quality of the pumping rates reported by the mining proponents the prescribed pumping rates are at least consistent with the modelling done by the mining proponents which incorporates a large amount of local detail on the geology and mine planning that is beyond the resolution of this regional scale modelling 4 3 2 specification of prior parameter distributions the specification of prior distributions is of great importance in any uncertainty analysis the process to specify the prior distributions is outlined in the results section the data attribute is scored high reflecting the limited data availability in the region frery et al 2018 due to operational constraints it was not possible to collect more data or to engage with local experts to establish the prior distributions the resources attribute is therefore scored medium the technical column is scored low as the uncertainty analysis methodology allows specification of a wide variety of prior distributions the effect on predictions is scored medium as the parameter the maximum drawdown is most sensitive to s a1 cs is not greatly constrained by the coal seam gas water production rate the effect is mitigated by specifying prior distributions with a high variance in the case of hydraulic properties to cover at least one order of magnitude this is likely to represent a conservative estimate of the actual parameter distributions 4 4 synthesis and communication the contour line of 5 probability of exceeding 0 2 m drawdown in fig 6 forms the polygon defining the initial extent of the impact assessment this zone of potential hydrological change is referred to as the area in which the probability of exceeding 0 2m drawdown in the watertable aquifer is less than 5 or outside this polygon there is at least a 95 probability that the drawdown in the watertable aquifer is less than 0 2 m the qualitative uncertainty summarised in table 5 emphasises that this analysis is largely conditioned on way the water take from the open pit mines and the coal seam gas wells is implemented while the effect of using uniform hydraulic properties and limiting the simulation period on the predict initial assessment area is considered to be minor 5 discussion 5 1 objectives and model outcomes the causal pathway analysis in conjunction with the impact modes and effect analysis provides a systematic framework to identify groundwater drawdown as the most important hydrological variable to consider to delineate the zone of potential hydrological change in the case study area reducing all complexities of the public debate on coal development to this zone of hydrological change would however be overly simplistic decision makers need to factor in many other aspects such as noise dust and greenhouse gas emissions from the produced coal and gas buchanan 2016 saltelli and giampietro 2017 for illustrative purposes the case study focussed on groundwater drawdown as it was identified as the prime hydrological variable the potential change in surface water hydrology can however although limited to the river network extend beyond the zone of potential hydrological change defined solely on groundwater drawdown the methodology presented here can easily be applied to impacts on surface water hydrology the final zone of potential hydrological change would then become the union of both impact zones mcvicar et al 2015 in addition to the type of impact the zone does rely greatly on the subjective choice of threshold and exceedance probability in this case the 0 2 m drawdown threshold and 5 exceedance probability the observational accuracy of groundwater level measurements in regional monitoring networks is in the order of centimetres together with the natural variability of groundwater levels the 0 2 m drawdown threshold comes close to the minimum drawdown that would be able to be observed this drawdown threshold in combination with the low threshold of 5 exceedance probability makes for a very conservative estimate of the zone of potential hydrologic change which is well suited to inform a risk averse decision making process in communication of the potential impact however this level of conservatism needs to be emphasised and placed in context underschultz et al 2018 for instance highlight how conservativism at various levels of assessment in the context of csg production in queensland australia greatly overestimates water production 5 2 quantitative uncertainty analysis the uncertainty quantification methodology provides insight in the model behaviour through the sensitivity analysis and transparency in inference through the choice of summary statistic and acceptance threshold the sensitivity analysis allows to objectively assess and communicate the extent to which the available observation data can constrain the parameters relevant to the predictions formal sensitivity analysis that go beyond local one at a time analysis such as presented in doherty and hunt 2009 are gaining popularity in other disciplines pianosi et al 2016 petropoulos et al 2017 borgonovo 2017 are still not common practice in groundwater modelling hill et al 2015 borgonovo et al 2017 the inference scheme using a rejection sampler of informative prior parameter distributions with a summary statistic is inherently subjective which is its main drawback however the need to define an acceptance threshold for the observations forces the inference process to go beyond minimising the residuals carrera et al 2005 to an active consideration of what is considered to be an acceptable model to measurement mismatch for the problem at hand this is a crucial yet often under appreciated step in uncertainty quantification moore and doherty 2005 tonkin and doherty 2009 the use of an emulator in the inference step is a major pragmatic advantage a single set of predefined parameter combinations is relatively straight forward to evaluate especially with the ever increasing availability of high performance and cloud computing services hunt et al 2010 hayley 2017 training an emulator based on this data set of model runs allows flexibility in specifying summary statistics acceptance thresholds and prior parameter distributions the high accuracy of the classifier 95 accuracy implies that the error introduced by using the classifier rather than the original model in inference is limited provided the parameter combinations evaluated are within the range used to train the classifier a more formal method of incorporating the emulation error would be to use the probability of a parameter combination to be classified as behavioural in a markov chain monte carlo approach this additional complexity in the uncertainty quantification was considered not warranted as the potential effect of misclassification in the inference on the predicted initial extent of the assessment area is much smaller than the other sources of uncertainty such as the development scenario another approach would be to directly emulate the quantity of interest in this case the produced water volume from coal seam gas extraction as performed by gladish et al 2017 and cui et al 2018 accurately reproducing the response surface of the entire parameter range is however much more challenging especially for non linear models castaings et al 2012 when evaluating many parameter combinations ensuring model convergence and model verification becomes much more important ince et al 2012 hutton et al 2016 the spatial and temporal results of a single deterministic model run can easily be visually inspected for modelling artefacts in contrast when evaluating a model that has been run thousands of times these checks need to be formalized to ensure that extreme parameter combination do not give rise to model artefacts 5 3 qualitative uncertainty analysis the qualitative uncertainty analysis presented in table 5 addresses numerous conceptual model and epistemic uncertainty issues nilsson et al 2007 refsgaard et al 2006 the structured analysis forms a starting point to identify and prioritize data and knowledge gaps as well as future research and monitoring opportunities the scoring system used in table 5 is subjective however and the actual scoring depends on personal judgments of the modelling team or in the case of very complex integrated environmental impact assessments multiple modelling teams as documented in bark et al 2016 such interdisciplinary cooperation has considerable challenges in some situations individual modellers stakeholders or domain experts may have limited knowledge or different opinions on evaluation of some assumptions group decision making techniques noor e alam et al 2011 can be integrated to capture their judgments in a more objective manner additionally linguistic uncertainty regan et al 2002 is an often overlooked yet pervasive source of uncertainty in the face to face and language based assessment process gao and hailu 2012 2013 nevertheless the mere fact that the attributes need to be scored and the scoring needs to be justified enforces a systematic evaluation of model assumptions and choices the qualitative uncertainty analysis is performed in two stages firstly the initial qualitative uncertainty analysis is during the early stages of numerical modelling such as during the conceptualization this ensures that the modelling is focused on the predictions and that potential bottle necks or limitations of the modelling can be identified and remedied secondly qualitative uncertainty analysis was performed after the numerical modelling and quantitative uncertainty analysis are finalized while this reduces the qualitative uncertainty analysis almost to a post mortem examination of the modelling it provides an excellent starting position for a post audit of the modelling oreskes et al 1994 the discussion of the assumptions requires a very critical attitude of the modelling team towards their own modelling although many researchers initially did not feel comfortable with this brutally honest way of reporting such a self reflective attitude can greatly improve forecasts herzog et al 2009 a broadening of the forum in which to have this discussion to various stakeholders and local domain experts will make the qualitative uncertainty analysis even more robust yaniv et al 2007 the highly technical nature of these discussions requires however that the participants are well versed in both the technical aspect of the modelling as well as the local physical reality additionally especially when conflicting interests are at play the role of the facilitator is crucial in such discussions to ensure all of the assumptions and model choices are discussed in the appropriate context aspinall 2010 6 conclusion the screening methodology to determine spatial extent of hydrological change is focused on explicitly defining the hydrogeological change threshold a comprehensive and flexible uncertainty quantification and sensitivity analysis complemented by a systematic evaluation of model assumptions the pragmatic use of model emulation techniques enables a flexible prediction focused uncertainty quantification the formal qualitative uncertainty analysis contributes to an open and transparent communication of the uncertainty associated with the model results this analysis provides decision makers with a sound knowledge base to allow informed decisions on the initial extent of environmental impact analysis the probabilistic nature of the results together with the qualitative uncertainty analysis enable decision makers to appreciate the level of conservatism in the extent delineation and make it explicit that impacts beyond the initial extent cannot fully be excluded the application of the methodology to delineate the zone of potential hydrological change in the gloucester basin in new south wales australia shows that the area in which there is more than 5 probability of exceeding more than 0 2 m drawdown due to coal development does not extend more than 5 km beyond the footprint of the open cut mines the method developed and applied is generic and can be used to delineate initial extent for environmental assessments provided a relevant environmental simulation model is available acknowledgments this research is part of the bioregional assessment programme which is funded by the australian government department of the environment and energy the bioregional assessment programme is a transparent and accessible programme of baseline assessments that increase the available science for decision making associated with the impacts of coal seam gas and coal mining development on water resources bioregional assessments are being undertaken in a collaboration between the department of the environment the bureau of meteorology csiro and geoscience australia for more information www bioregionalassessments gov au the authors would like to thank the scientific leadership and the external review panel of this research project for the many recommendations that improved the methodology the implementation and the manuscript in particular the authors want to thank neil viney david post brent henderson rebecca schmidt steve lewis peter baker and dirk mallants appendix a supplementary data the following are the supplementary data related to this article supplementary material supplementary material appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 020 
26332,a crucial decision in defining the scope of an environmental impact assessment is to delineate the initial assessment area we developed a probabilistic methodology to determine this area which starts by identifying a key environmental variable maximum acceptable change and acceptable probability of exceeding that threshold the exceedance probability is determined with a limits of acceptability rejection sampling of informed prior parameter distributions a qualitative uncertainty analysis a formal and systematic discussion of the main assumptions and model choices is complemented with global sensitivity analysis of the model results to identify the major sources of uncertainty and provide guidance for further research and data collection for the case study on coal development in the gloucester basin nsw australia the initial assessment extent is unlikely to extend more than 5 km from the edge of the planned coal mines the major source of uncertainty is the planned mine water production rate keywords environmental impact assessment uncertainty analysis hydrogeology coal bed methane coal mining 1 introduction defining the system boundaries and the zone of interest is part of the scoping phase of an environmental impact assessment hamilton et al 2015 this can be a daunting task especially in open systems without well defined natural boundaries an overly limited initial spatial extent of the study area compromises the environmental impact assessment as it can lead to missing impacts in the analysis or underestimating the impacts however being overly conservative can lead to a large increase in the initial spatial extent of the study which can also compromise the quality of the assessment especially if the available time and or budget for the assessment are limited in the context of cumulative impact assessments eccleston 2011 states that the spatial extent of an assessment should comprise the area in which a significant effect can be reasonably evaluated the extent should vary in function of the effect examined e g the spatial extent for noise impacts will be different to hydrological or ecological impacts it is however left to practitioners to define the threshold for a significant effect and the acceptable level of risk exceeding this threshold in this study we focus on potential cumulative water mediated economic social and environmental impacts of coal resources development kerr 2010 johnson et al 2013 measham et al 2016 establishing the initial assessment extent requires firstly to define which aspects of the hydrological system can be affected by coal development and would result in relevant economic social and environmental impact examples of these can be groundwater levels in a bore low flow duration in a river reach or the inundation regime of a floodplain wetland the second step in the methodology once a selection of these variables is made is to define the maximum acceptable level of hydrological change the level of hydrological change that would lead to a noticeable change in the economic social or environmental values affected by that variable uncertainty in the impact assessment extent can be expressed as the probability the threshold will be exceeded given the current state of knowledge the third and final aspect to define for the zone of potential change is the maximal acceptable probability of threshold exceedance the probabilistic assessment of environmental impacts has been researched since the 1970s suter et al 1987 leung et al 2015 most of the papers focus on uncertainty quantification the problem of statistical inference in which the mismatch between historical observations and simulated equivalents is used to constrain a model and to quantify the predictive uncertainty of a model carrera et al 2005 gupta et al 2012 bennett et al 2013 maier et al 2014 the seminal work by walker et al 2003 provided a wider view on the uncertainty analysis problem by developing a structured classification of sources of uncertainty which in turn influenced later guidance and frameworks such as those proposed by jakeman et al 2006 refsgaard et al 2007 and beven and alcock 2012 while the core of these frameworks still revolve around the quantification of uncertainty they all emphasise the need to systematically discuss assumptions underpinning the modelling as advocated by saltelli and funtowicz 2014 a prime example of this approach is performance assessment for proposed high level radioactive waste disposal helton et al 2014 in which the quantification of uncertainty in numerical models is balanced with discussions and analysis of the assumptions underpinning these models such discussion aims to elucidate whether or not an assumption will lead to an overestimate of change such conservatism helps to build confidence in the assessment but overly conservative assumptions can lead to missed opportunities as illustrated in freedman et al 2017 and underschultz et al 2018 most of the guidance and framework literature emphasises the need for an iterative process in model building for environmental impact assessment e g jakeman et al 2006 in which complexity of the numerical modelling and uncertainty assessment approach evolves as more data become available and system knowledge increases schwartz et al 2017 the probabilistic screening methodology we develop and apply in this paper is a pragmatic workflow to incorporate rigorous uncertainty assessment into the earliest stages of an assessment the delineation of the initial assessment extent this approach provides a more robust and justifiable spatial delineation of the assessment area with the insights potentially guiding further data collection and modelling efforts in subsequent stages of the impact assessment the probabilistic screening methodology allows to determine a zone of potential change which requires the explicit definition of the i nature of change ii threshold of acceptable change and iii probability of exceeding this threshold the methodology is based on a quantitative and qualitative uncertainty analysis in which the quantitative uncertainty analysis provides the probability of exceeding a pre defined hydrological change threshold while the qualitative uncertainty analysis is a systematic scoring and discussion of the assumptions underpinning the hydrological change computation the approach is illustrated with a case study for the potential of groundwater related impacts of coal resource development in the gloucester basin in new south wales australia the supplementary material provides the details of the implementation as a jupyter notebook and a table guiding the interested reader to the technical reports underpinning this research 2 methods the screening methodology developed for this study consists of four components which documented in turn are 1 objectives model outcomes and conceptualization 2 qualitative uncertainty analysis 3 quantitative uncertainty analysis and 4 synthesis and communication 2 1 objectives model outcomes and conceptualization in this study we focus on defining the hydrological change the acceptable change threshold and exceedance probability in the context of coal mining and coal seam gas extraction also known as coal bed methane extraction based on a formal process of defining the most likely coal resource development pathway lewis 2014 identifying hazards through impact modes and effect analysis ford et al 2016 and developing causal pathways henderson et al 2016 linking the coal development to potential impact on water related assets mount et al 2017 it is established that the most relevant hydrological change for groundwater is the maximum drawdown i e change in groundwater level in time at the location of the asset in the aquifer hosting the water table holland et al 2017 within the relevant legislative context the smallest drawdown threshold defined is 0 2 m for springs and groundwater dependent ecosystems in the new south wales aquifer interference policy office of water 2012 as the intended use is to rule out areas where impact is unlikely a low probability threshold of 5 is chosen the formal definition of the zone of potential hydrological change for groundwater thus becomes the zone in which the probability of exceeding 0 2 m of drawdown due to coal development in the aquifer hosting the water table is greater than 5 this statement however does not include a time frame viney 2016 suggested a time frame of 90 years as a suitable trade off between capturing long term effects and developing realistic long term scenarios 2 2 qualitative uncertainty analysis a qualitative uncertainty analysis tries to capture the sources of uncertainty that are not part of the probabilistic uncertainty quantification most of these uncertainties can be classified as epistemic uncertainty walker et al 2003 uncertainty due to imperfect knowledge and models which can be reduced through more research efforts this uncertainty manifests itself through the numerous choices and assumptions required during conceptualization and subsequent implementation in a numerical model refsgaard et al 2006 and kloprogge et al 2011 provide examples of methods to formally account for the uncertainty introduced by such model assumptions the pivotal aspects of these methodologies are the structured listing of model assumptions and the analysis of the implications and influence of those assumptions a pedigree analysis through peer review or a workshop with experts and stakeholders finding and listing all key assumptions requires as argued by saltelli et al 2013 p 9 an assumption hunting attitude to find important assumptions before they find you the pedigree analysis in kloprogge et al 2011 suggests scoring each assumption on aspects such as the practical motivation plausibility availability of alternatives agreement among peers and stakeholders and most importantly the perceived influence on the final prediction while it is recognized that these scoring systems are prone to subjectivity and their results can be heavily influenced by the scoring system used such methods are nevertheless useful as they provide a structured way of considering and analysing model assumptions this in turn helps in the open and transparent communication of model uncertainty guillaume et al 2015 this is a recurring theme in the framework of jakeman et al 2006 which highlights the need to explicitly consider alternative conceptualizations we follow the qualitative uncertainty analysis presented in peeters 2017 which is primarily inspired by kloprogge et al 2011 the major assumptions and model choices underpinning the environmental model are listed in a table with scoring of the attributes data resources technical and likely effect on predictions the goal of the table is to provide a non technical audience with a systematic overview of the model assumptions their justification and effect on predictions as judged by the modelling team this table is aimed to assist in an open and transparent review of the modelling in the table each assumption is scored on the four attributes using three levels high medium and low beneath the table each of the assumptions are discussed in detail including the rationale for the scoring the data column reports the degree to which the question if more or different data were available would this assumption choice still have been made would be answered positively a low score means that the assumption is not influenced by data availability while a high score indicates that this choice would be revisited if more data were available closely related is the resources attribute this column captures the extent to which resources available for the modelling such as computing resources personnel and time influenced this assumption or model choice again a low score indicates the same assumption would have been made with unlimited resources while a high score indicates the assumption is driven by resource constraints the third attribute deals with the technical and computational issues high is assigned to assumptions and model choices that are predominantly driven by computational or technical limitations of the model code the final and most important column is the effect of the assumption or model choice on the predictions this is a qualitative assessment by the modelling team regarding the extent to which a model choice will affect the model predictions with low indicating a minimal effect and high a large effect the scoring of the effect on the predictions can be justified through various strategies a formal sensitivity analysis is the most objective as it quantifies the effect of parameters on predictions for assumptions or choices that are not parameterised in the uncertainty analysis the effect on predictions can be explored through comparison with analogue situations documented in literature and or through an argumentation based on the underpinning physical laws and system understanding table 1 illustrates the concept of a qualitative uncertainty analysis with an assumption that is often made in groundwater modelling studies representing aquifer properties as spatially uniform the table captures both the scoring and its justification the example highlights that it is possible to score low on the prediction attribute despite scoring high on the data and resources attributes the qualitative uncertainty analysis critically examines the various aspects of the system conceptualization and model implementation it results in an assessment of conceptual and model uncertainty systematically identifying major knowledge and data gaps 2 3 quantitative uncertainty analysis the traditional modelling workflow as for example the groundwater modelling workflow in barnett et al 2012 follows the scheme of conceptualize implement calibrate predict and as a final step quantify uncertainty the notion of a calibrated model assumes that it is possible to infer an optimal set of model parameters and structure from state observations that allow the model to be used to make a wide variety of predictions harmel et al 2014 in groundwater modelling the validity of this assumption has shown to be tenuous at best as the parameters most salient to predictions are often not well constrained by the available observations e g white et al 2014 this problem is exacerbated when modelling greenfield conditions i e sites with no previous development in which the planned stresses on the system are unprecedented and limited historical observations are available this issue is implicitly recognized in the confidence classification of groundwater models barnett et al 2012 in which models assessing greenfield conditions are awarded the lowest confidence classification regardless of the complexity of the model in a traditional inference workflow the numerical model is evaluated repeatedly for different parameter combinations the selection of the parameter combinations and the acceptance of these into the posterior parameter distributions is determined by the prior parameter distributions and the likelihood function this sampling procedure often requires a large amount of model evaluations to ensure the posterior parameter distributions converge once a converged posterior parameter distribution is obtained a limited number of samples of this distribution is generally sufficient to robustly represent summary statistics of the distribution such as the median 5th or 95th percentile we designed the workflow for the probabilistic screening method to be 1 more flexible such that a change in prior parameter distributions or likelihood function will not necessitate evaluating the numerical model again for a large number of times and 2 provide insight in the numerical model to aid in discussing the effect of model assumptions and guide further model development and monitoring strategies in subsequent stages of the environmental impact assessment this workflow consists of three components 1 a global sensitivity analysis based on a wide initial range for all model parameters 2 statistical inference of the posterior predictive distribution and 3 replacing the numerical model with an emulator the model is first evaluated a large predefined number of times with parameters chosen randomly from uninformed prior parameter distributions this dataset of parameter combinations with corresponding model outputs serves a dual purpose the primary use is to perform a global sensitivity analysis to gain insight in model behaviour the secondary use is to train an emulator that can replace the original model during statistical inference we opted for a limits of acceptability inference approach in which a rejection sampler is used to sample informative priors the emulator is trained to classify parameter combinations into behavioural and non behavioural based on the predefined limits of acceptability this emulator allows to sample the parameter space comprehensively at a fraction of the computational cost the model output used to constrain the parameter space in the inference step is however not the model output required for the environmental impact assessment the model is for instance constrained with historical observations while the quantity of interest for the environmental impact assessment is a future state of the system subject to an unprecedented stress the posterior parameter distribution obtained by emulator assisted inference is therefore sampled a limited number of times and evaluated with the numerical model to provide the posterior predictive distributions the number of samples required to characterise robustly the 5th 50th and 95th percentile of a known distribution is generally much less than the number of samples required to infer a posterior distribution from prior distributions and a likelihood function in turn the following subsections provide more detail on the 1 global sensitivity analysis 2 limits of acceptability inference and 3 emulator and sampling of posterior parameter and predictive distributions 2 3 1 global sensitivity analysis a crucial step in the model design as pointed out by jakeman et al 2006 is the parameterisation of a numerical model the selection of model components allowed to vary during parameter inference and how they are allowed to vary while discussing the rationale behind such choices is part of the qualitative uncertainty analysis it is often not straight forward to identify beforehand to what extent a parameter is going to affect the predictions especially in complex non linear models a formal sensitivity analysis saltelli et al 2008 allows identification of the parameters most influential to the predictions and the parameters that can be constrained by observations in addition to this the response of predictions to changes in parameters provides insight into the model dynamics a valuable diagnostic check of model conceptualization herbst and casper 2008 peeters et al 2013 and model behaviour bennett et al 2013 from the wide variety of sensitivity analysis techniques available pianosi et al 2016 the density based sensitivity metric developed by plischke et al 2013 is chosen here as it provides an estimate of the sensitivity of a prediction to various model parameters that can accommodate non linearities in model response peeters et al 2014 and unlike most other sensitivity indices does not require specific sampling designs in this methodology we opted for a maximin latin hypercube sampling of an initial uniform parameter distribution within wide bounds of minimum and maximum values iman 2008 the sensitivity index Œ¥ i the sensitivity of output y to parameter x i is formally defined as plischke et al 2013 Œ¥ i Œ¥ y x i 1 2 œá i f x i x œÖ f y y f y x i x y d y d x where œá i and œÖ are the spaces containing output y and parameter x i respectively and f represents the density function the goal of this sampling is to compute sensitivity indices of the parameters to the model predictions to diagnose model behaviour the parameter distributions are intentionally chosen to uniformly cover the range considered plausible as to capture a wide spectrum of model responses to provide context for interpretation two dummy variables d1 and d2 are added to the sensitivity analysis both dummy variables are random values uniformly sampled in the 0 1 interval and have no effect on the prediction the effect of model parameters with sensitivity indices similar to those of the dummy variables is so small that it is not distinguishable from random noise with this sample size 2 3 2 statistical inference the bayesian paradigm allows updating of prior information with observations and system knowledge it is therefore essential for the prior parameter distributions to capture the existing knowledge of the system ellison 2004 the uniform parameter distributions used in the sensitivity analysis are non informative and do not encapsulate the full prior knowledge of the system in the next step of the methodology these uniform parameter distributions are therefore revisited by using measurements analogues and or expert opinion to create an informative prior that reflects the current understanding of the system this is especially important for the parameters identified in the sensitivity analysis as having a large influence on the prediction and low potential to be constrained by observations the inference approach used here is inspired by the approximate bayesian computation abc and generalized likelihood uncertainty estimation glue methodologies vrugt and beven 2018 which finds its origins in the limits of acceptability methodology e g hornberger and spear 1981 a problem specific single criterion or set of criteria are chosen by the modelling team to evaluate the model any parameter set sampled from the prior parameter distributions that satisfies these criteria is accepted into the posterior parameter distribution the random sampling of the priors is continued until a predefined number of samples in the posterior parameter distribution is reached or preferably the moments of the posterior predictive distribution stabilise this process can be more formally described as follows consider a model g with multivariate parameter vector x the model simulates a vector of future predictions y p and a vector of system state variables y s y p y s g x a function k maps the vector y s to a vector of quantities q that can be compared to a vector q that captures historical observations and system knowledge q k y s a proposal vector x randomly sampled from a prior parameter distribution is considered acceptable or behavioural if the corresponding vector q satisfies inequality d q q Œµ where d is a function that formalises comparison of vectors q and q such that it can be compared to an acceptability threshold Œµ in case q consists solely of historical system state observations k d and Œµ need to be chosen such that system state variables simulated with behavioural parameter vectors cannot be distinguished from observed system state variables when taking into account observational uncertainty should q also contain system knowledge that does not correspond to historical observations e g as expressed by domain experts k d and Œµ need to be chosen such that behavioural parameter sets result in system state variables that domain experts consider plausible or realistic 2 3 3 emulation one of the drawbacks of an inference scheme as outlined in section 2 3 2 is that it requires a large number of model evaluations before the posterior parameter distributions stabilise a pragmatic approach to improve computational efficiency is to replace the numerical model during inference with an emulator or surrogate model razavi et al 2012 asher et al 2015 here it is not necessary for an emulator to exactly mimic the model behaviour it is sufficient for the emulator to classify parameter combinations as behavioural meets threshold conditions or non behavioural does not meet threshold conditions this effectively recasts the emulation from a regression problem in which an emulator aims to reproduce a response surface to a classification problem among the plethora of classification algorithms available gradient tree boosting classifiers friedman 2001 are well established as robust and efficient classifiers caruana and niculescu mizil 2006 we used the implementation in pedregosa et al 2011 after assuring adequate performance of the classifier through cross validation the classifier is used to evaluate a large number of parameter combinations from the prior parameter distributions the samples classified as behavioural are retained in the posterior parameter distributions the posterior parameter distributions are subsequently sampled and evaluated with the numerical model to compute maximum additional drawdown in time in the aquifer containing the watertable throughout the model domain these predictive posterior distributions are summarised as the probability of exceeding the 0 2 m threshold at a large number of model nodes these posterior distributions need to be interpolated to locations other than these model nodes to generate a spatially consistent predictive distribution of drawdown the first step in the interpolation is to generate a delaunay triangulation dt from the model nodes chapter 9 in de berg et al 2008 next for any new location within the convex hull formed by the dt we identify the nodes that form the corners of the enclosing triangle for that new location any quantile of interest at the new location can now be obtained by linearly interpolating the same quantiles obtained at each of the corners of the enclosing triangle linear interpolation ensures that the ordering of the quantiles is preserved and so that a valid distribution function can be built up at the new location 2 4 synthesis and communication the ultimate result of the spatial delineation of the zone of potential hydrological change is a polygon corresponding to a contour line of an acceptable exceedance probability it is recommended that this polygon is not just described as the initial impact extent but with more descriptive phrases such as the area in which the probability of exceeding a drawdown of 0 2 m in the watertable aquifer is greater than 5 or outside this area there is at least a 95 probability that drawdown in the watertable aquifer is less than 0 2 m these phrases are not only a more accurate reflection of the screening process the alternating framing reduces the risk of cognitive bias spiegelhalter 2017 the table summarising the qualitative uncertainty analysis complements this by providing a succinct readily digestible overview of the main assumptions that can affect the initial assessment extent this qualitative uncertainty analysis can then be used as a starting point to identify knowledge and data gaps guide future data collection and monitoring strategies as well as focussing subsequent numerical modelling referring to the initial spatial extent in explicit probabilistic terms as well as highlighting the underpinning assumptions emphasise that this is a first step in the analysis and that impacts outside of this zone although unlikely cannot be fully excluded 3 study area the 348 km2 gloucester geological basin is situated about 250 km north east of sydney australia fig 1 the region has a sub tropical climate with summer dominant precipitation the average rainfall between 1982 and 2012 was 1095 mm yr and potential evapotranspiration 1587 mm yr jones et al 2009 hydrogeologically the gloucester basin can be divided into three main hydrogeological units frery et al 2018 fig 2 1 alluvium a 1 2 km wide unconfined aquifer up to 15 m thick along the main rivers 2 shallow weathered and fractured rocks a confined to semi confined aquifer up to 150 m thick and 3 water bearing strata interburden units alternating with coal seams to a maximum depth of about 2500 m the shallow weathered and fractured rocks underlie the alluvium entirely and outcrop extensively across the rest of the gloucester geological basin except for the alluvium the water table is hosted in the shallow weathered and fractured rock aquifer the most likely coal resource development pathway at the time of the study 2014 in the gloucester basin consisted of i the expansion of two existing open pit coal mines ii a new open pit mine and iii a coal seam gas well field consisting of 110 wells hodgkinson et al 2014 for coal seam gas extraction several vertical and horizontal wells are drilled to reduce the water pressure in coal seams this allows gases adsorbed onto the coal surface to desorb and be pumped to the surface the propagation of the depressurization through the sedimentary basin can potentially lead to changes in groundwater levels the extent of this propagation depends on the hydraulic properties of the sedimentary basin and on the stratigraphic and structural connectivity of the aquifers where faults and fractures can both increase or decrease aquifer connectivity bense et al 2013 in open pit coal mining the coal seams and overlying sedimentary layers are dewatered to ensure the mine pit is dry the propagation of the drawdown throughout the aquifer system caused by pumping groundwater will also depend on the hydrogeological connectivity of the aquifers 4 application 4 1 objectives model outcomes and numerical model as outlined in section 2 1 to delineate the zone of potential change the probability of exceeding 0 2 m drawdown needs to be estimated throughout the shallow weathered and fractured rock aquifer this section provides a succinct summary of the groundwater model developed for this purpose see peeters et al 2018 for a full description the model outcome sought is limited to the change in groundwater levels due to pumping associated with coal development both open pit mining and csg this allows simplification of the modelling by invoking the principle of superposition reilly et al 1987 the additional drawdown due to coal development can be simulated by only accounting for the fluxes that change due to development provided the system behaves linearly barlow and leake 2012 the numerical model developed with the analytic element code ttim bakker 2015 is depicted schematically in fig 3 the aquifer system is represented by a system of alternating aquifers and aquitards with lateral no flow boundaries coinciding with the extent of the geological gloucester basin dawes et al 2018 the coal seams are considered aquifers separated by interburden layers that act as aquitards based on well logs frery et al 2018 the thickness of the coal seams is set to 6 m while the number of coal seams is different for each realisation a randomly selected number between 6 and 12 the depth of each coal seams is also randomly varied between 250 m and 1000 m with higher likelihood for depth intervals where bore logs indicate higher density of coal seams the top most aquifer layer represents the shallow weathered and fractured rock aquifer with a nominal thickness of 150 m hydraulic conductivity and specific storage decreases exponentially with depth d according to p a 1 e x p a 2 d where p is either hydraulic conductivity or specific storage and a 1 and a 2 are the intercept and scale coefficients as this equation can lead to physically unrealistic values of hydraulic conductivity and specific storage values of hydraulic conductivity less than 1e 7 m d are replaced with 1e 7 m d a similar approach for specific storage uses a threshold value of 1e 6 1 m there are several major and minor faults present in the gloucester basin frery et al 2018 that can compromise the integrity of aquitards and thus potentially connect coal seams and the shallow aquifer the location of major faults connecting the entire sequence of aquifers is in accordance with geological mapping whether a fault is present in a single realisation depends on the probability of occurrence assigned to it i e a fault with 75 probability of occurrence is simulated in 7500 of the 10 000 simulations minor faults connecting at most two coal seams have been identified in drill holes but are not mapped at the scale of the available 1 100 000 geological maps covering the entire basin for these minor faults the stochastic sampling process generates a fault network in which the location fault length and orientation are varied stochastically consistent with the tectonic regime of the study area the fault density i e the number of faults is fixed at 40 based on local structural geological analysis frery et al 2018 faults are planar features in the groundwater model for which the hydraulic conductivity perpendicular to the fault plane and the hydraulic conductivity along the fault plane need to be specified open pit coal mines are represented as polygons from which a flux is extracted equal to the total pumping rate provided by the mining proponents the coal seam gas field is implemented as a head dependent boundary condition with the target groundwater level set 30 m above the top of the upper coal seam the model computes the coal seam gas flux and the change in groundwater level at 148 existing bore locations and at a 1000 additional locations throughout the model domain with greater density where large head gradients are expected i e close to the coal developments 4 2 quantitative uncertainty analysis 4 2 1 sensitivity analysis the parameterisation of the groundwater model is summarised in tables 2 and 3 the minimum and maximum values represent the plausible range over which these parameters are expected to vary based on a comprehensive review of international and local data sets presented in dawes et al 2018 frery et al 2018 and peeters et al 2018 these parameter ranges are uniformly sampled with a minimax latin hypercube sampling algorithm of these 10 000 parameter combinations 94 failed to converge and are excluded from further analysis this dataset of model runs is used to calculate density based sensitivity indices for the coal seam gas water production rate q c s g and maximum drawdown over time at the output locations in the shallow aquifer d m a x fig 4 the coal seam gas extraction rate is most sensitive to the hydraulic conductivity of the coal seam parameters k a1 cs and k a2 cs while maximum drawdown is most sensitive the specific storage of the shallow aquifer s a1 cs and the hydraulic conductivity of k a1 cs the coal seam gas water production appears not to be very sensitive to the specific storage of the coal seams s a1 cs and s a2 cs this implies that the coal seam gas water production rate has little potential to constrain s a1 cs the parameter d m a x is most sensitive to it is noteworthy that the parameters controlling hydraulic conductivity of the fault network kfv and kfh do not appear to influence the coal seam gas production rates or the maximum drawdown 4 2 2 inference the median of maximum water production rate over the life of the project is estimated by the coal seam gas proponent through detailed local modelling to be 0 6 ml d the 90 t h percentile is estimated to be 0 9 ml d agl energy limited 2015 for the abc algorithm we consider parameter combinations that result in water production rates in excess of 1 1 ml d not to be consistent with the current understanding of the sedimentary basin encapsulated in the detailed modelling brinkerhoff 2015 and therefore not acceptable the percentage of behavioural parameter combinations from the 9906 converging model runs is 54 04 these data are used to train a gradient tree boosting classifier implemented in the scikit learn package for python pedregosa et al 2011 a 30 fold cross validation resulted in a mean classifying accuracy of 95 with a standard deviation of 1 5 table 4 presents the confusion matrix for the classifier based on the training samples the prior parameter distributions that will be sampled in the bayesian inference are chosen to be multivariate normal after transformation summarised in tables 2 and 3 the values of the mean are chosen to be close to the centre of the range for each parameter while the variance is chosen such that approximately 99 of the prior distributions is within the uniform parameter range specified for the sensitivity analysis all parameters are considered to be independent except for hydraulic conductivity and specific storage and for vertical and horizontal hydraulic conductivity for the former for both coefficients of the depth hydraulic property equation covariance is specified in such a way that it represents a weak correlation while there is very limited information available in the observational record or literature to justify an exact covariance value a weak correlation is justified as both values ultimately depend on the lithology and diagenesis of the material the covariance specified for the vertical and horizontal fault hydraulic conductivity is chosen to represent a stronger correlation capturing the conceptual fault behaviour where faults act as barriers to flow horizontally and conduits of flow vertically bense et al 2013 a total of 1e6 samples are randomly drawn from the multivariate normal distribution and classified into behavioural parameter combination that will result in calculated coal seam gas water production rate less than 1 1 ml d and non behavioural parameter combination that will result in calculated coal seam gas water production rate greater than 1 1 ml d using the gradient tree boosting classifier this results in a posterior parameter distribution of 2 4e4 samples acceptance rate of 2 4 histograms of the posterior marginal parameter distributions are shown in fig 5 the convergence of the moments of these posterior distributions is presented in the supplementary material the results shown in fig 5 are consistent with the sensitivity analysis presented in fig 4 the parameters that are constrained the most through the inference are those controlling the hydraulic conductivity of the coal seams k a1 cs and k a2 cs the posterior marginal distribution of parameter s a1 cs is noticeably different from the prior distribution although the sensitivity analysis did not indicate that the coal seam gas water production rate is sensitive to this parameter the difference between prior and posterior in this case is due to the covariance specified in the prior distribution between hydraulic conductivity and specific storage the preference for lower values for k a1 cs in the posterior resulted in a shift towards lower values in s a1 cs as well 4 2 3 prediction a set of 200 parameter combinations is randomly drawn from the posterior parameter combinations and evaluated with the analytic element model the maximum drawdown values are simulated at 1000 model node locations the results are summarised in a map of the probability of exceeding 0 2 m fig 6 fig 6 shows that the zone of potential hydrological change the contour of 0 05 probability of exceeding 0 2 m drawdown extends about 5 km from the edge of the coal mines 4 3 qualitative uncertainty analysis the qualitative uncertainty analysis is a systematic discussion of the main model choices and assumptions and a subjective scoring of the importance of these on the model predictions the following table and discussion is the result of a workshop with the modelling team the authors of this paper a complete discussion of the assumptions in table 5 and the rationale behind the scoring of each attribute is provided in the supplementary material to illustrate the concept a detailed discussion of two assumptions are presented in turn in the following subsections i open cut mines as prescribed pumping rate and ii specification of prior distributions 4 3 1 open cut mines as prescribed pumping rate pumping rates to dewater open cut coal mines depend largely on local conditions as local conditions are not well captured in the analytic element model the choice was made to use reported historical pumping rates and rates estimated by the mining proponents based on local groundwater modelling the data attribute is scored high to implement open pit mine dewatering it is essential to know the exact elevation of the mine dewatering level and the proposed dewatering scheme this information is beyond the spatial resolution of the geological model underpinning the groundwater model the resources and technical attributes are scored low as it is trivial to specify the mine pit dewatering as head dependent flux boundary conditions and it does not appreciably increase the computational demand or processing time the effect on predictions is scored high as a change in pumping rate will greatly affect predictions and the reliability of the predictions of this model hinge on the quality of the pumping rates reported by the mining proponents the prescribed pumping rates are at least consistent with the modelling done by the mining proponents which incorporates a large amount of local detail on the geology and mine planning that is beyond the resolution of this regional scale modelling 4 3 2 specification of prior parameter distributions the specification of prior distributions is of great importance in any uncertainty analysis the process to specify the prior distributions is outlined in the results section the data attribute is scored high reflecting the limited data availability in the region frery et al 2018 due to operational constraints it was not possible to collect more data or to engage with local experts to establish the prior distributions the resources attribute is therefore scored medium the technical column is scored low as the uncertainty analysis methodology allows specification of a wide variety of prior distributions the effect on predictions is scored medium as the parameter the maximum drawdown is most sensitive to s a1 cs is not greatly constrained by the coal seam gas water production rate the effect is mitigated by specifying prior distributions with a high variance in the case of hydraulic properties to cover at least one order of magnitude this is likely to represent a conservative estimate of the actual parameter distributions 4 4 synthesis and communication the contour line of 5 probability of exceeding 0 2 m drawdown in fig 6 forms the polygon defining the initial extent of the impact assessment this zone of potential hydrological change is referred to as the area in which the probability of exceeding 0 2m drawdown in the watertable aquifer is less than 5 or outside this polygon there is at least a 95 probability that the drawdown in the watertable aquifer is less than 0 2 m the qualitative uncertainty summarised in table 5 emphasises that this analysis is largely conditioned on way the water take from the open pit mines and the coal seam gas wells is implemented while the effect of using uniform hydraulic properties and limiting the simulation period on the predict initial assessment area is considered to be minor 5 discussion 5 1 objectives and model outcomes the causal pathway analysis in conjunction with the impact modes and effect analysis provides a systematic framework to identify groundwater drawdown as the most important hydrological variable to consider to delineate the zone of potential hydrological change in the case study area reducing all complexities of the public debate on coal development to this zone of hydrological change would however be overly simplistic decision makers need to factor in many other aspects such as noise dust and greenhouse gas emissions from the produced coal and gas buchanan 2016 saltelli and giampietro 2017 for illustrative purposes the case study focussed on groundwater drawdown as it was identified as the prime hydrological variable the potential change in surface water hydrology can however although limited to the river network extend beyond the zone of potential hydrological change defined solely on groundwater drawdown the methodology presented here can easily be applied to impacts on surface water hydrology the final zone of potential hydrological change would then become the union of both impact zones mcvicar et al 2015 in addition to the type of impact the zone does rely greatly on the subjective choice of threshold and exceedance probability in this case the 0 2 m drawdown threshold and 5 exceedance probability the observational accuracy of groundwater level measurements in regional monitoring networks is in the order of centimetres together with the natural variability of groundwater levels the 0 2 m drawdown threshold comes close to the minimum drawdown that would be able to be observed this drawdown threshold in combination with the low threshold of 5 exceedance probability makes for a very conservative estimate of the zone of potential hydrologic change which is well suited to inform a risk averse decision making process in communication of the potential impact however this level of conservatism needs to be emphasised and placed in context underschultz et al 2018 for instance highlight how conservativism at various levels of assessment in the context of csg production in queensland australia greatly overestimates water production 5 2 quantitative uncertainty analysis the uncertainty quantification methodology provides insight in the model behaviour through the sensitivity analysis and transparency in inference through the choice of summary statistic and acceptance threshold the sensitivity analysis allows to objectively assess and communicate the extent to which the available observation data can constrain the parameters relevant to the predictions formal sensitivity analysis that go beyond local one at a time analysis such as presented in doherty and hunt 2009 are gaining popularity in other disciplines pianosi et al 2016 petropoulos et al 2017 borgonovo 2017 are still not common practice in groundwater modelling hill et al 2015 borgonovo et al 2017 the inference scheme using a rejection sampler of informative prior parameter distributions with a summary statistic is inherently subjective which is its main drawback however the need to define an acceptance threshold for the observations forces the inference process to go beyond minimising the residuals carrera et al 2005 to an active consideration of what is considered to be an acceptable model to measurement mismatch for the problem at hand this is a crucial yet often under appreciated step in uncertainty quantification moore and doherty 2005 tonkin and doherty 2009 the use of an emulator in the inference step is a major pragmatic advantage a single set of predefined parameter combinations is relatively straight forward to evaluate especially with the ever increasing availability of high performance and cloud computing services hunt et al 2010 hayley 2017 training an emulator based on this data set of model runs allows flexibility in specifying summary statistics acceptance thresholds and prior parameter distributions the high accuracy of the classifier 95 accuracy implies that the error introduced by using the classifier rather than the original model in inference is limited provided the parameter combinations evaluated are within the range used to train the classifier a more formal method of incorporating the emulation error would be to use the probability of a parameter combination to be classified as behavioural in a markov chain monte carlo approach this additional complexity in the uncertainty quantification was considered not warranted as the potential effect of misclassification in the inference on the predicted initial extent of the assessment area is much smaller than the other sources of uncertainty such as the development scenario another approach would be to directly emulate the quantity of interest in this case the produced water volume from coal seam gas extraction as performed by gladish et al 2017 and cui et al 2018 accurately reproducing the response surface of the entire parameter range is however much more challenging especially for non linear models castaings et al 2012 when evaluating many parameter combinations ensuring model convergence and model verification becomes much more important ince et al 2012 hutton et al 2016 the spatial and temporal results of a single deterministic model run can easily be visually inspected for modelling artefacts in contrast when evaluating a model that has been run thousands of times these checks need to be formalized to ensure that extreme parameter combination do not give rise to model artefacts 5 3 qualitative uncertainty analysis the qualitative uncertainty analysis presented in table 5 addresses numerous conceptual model and epistemic uncertainty issues nilsson et al 2007 refsgaard et al 2006 the structured analysis forms a starting point to identify and prioritize data and knowledge gaps as well as future research and monitoring opportunities the scoring system used in table 5 is subjective however and the actual scoring depends on personal judgments of the modelling team or in the case of very complex integrated environmental impact assessments multiple modelling teams as documented in bark et al 2016 such interdisciplinary cooperation has considerable challenges in some situations individual modellers stakeholders or domain experts may have limited knowledge or different opinions on evaluation of some assumptions group decision making techniques noor e alam et al 2011 can be integrated to capture their judgments in a more objective manner additionally linguistic uncertainty regan et al 2002 is an often overlooked yet pervasive source of uncertainty in the face to face and language based assessment process gao and hailu 2012 2013 nevertheless the mere fact that the attributes need to be scored and the scoring needs to be justified enforces a systematic evaluation of model assumptions and choices the qualitative uncertainty analysis is performed in two stages firstly the initial qualitative uncertainty analysis is during the early stages of numerical modelling such as during the conceptualization this ensures that the modelling is focused on the predictions and that potential bottle necks or limitations of the modelling can be identified and remedied secondly qualitative uncertainty analysis was performed after the numerical modelling and quantitative uncertainty analysis are finalized while this reduces the qualitative uncertainty analysis almost to a post mortem examination of the modelling it provides an excellent starting position for a post audit of the modelling oreskes et al 1994 the discussion of the assumptions requires a very critical attitude of the modelling team towards their own modelling although many researchers initially did not feel comfortable with this brutally honest way of reporting such a self reflective attitude can greatly improve forecasts herzog et al 2009 a broadening of the forum in which to have this discussion to various stakeholders and local domain experts will make the qualitative uncertainty analysis even more robust yaniv et al 2007 the highly technical nature of these discussions requires however that the participants are well versed in both the technical aspect of the modelling as well as the local physical reality additionally especially when conflicting interests are at play the role of the facilitator is crucial in such discussions to ensure all of the assumptions and model choices are discussed in the appropriate context aspinall 2010 6 conclusion the screening methodology to determine spatial extent of hydrological change is focused on explicitly defining the hydrogeological change threshold a comprehensive and flexible uncertainty quantification and sensitivity analysis complemented by a systematic evaluation of model assumptions the pragmatic use of model emulation techniques enables a flexible prediction focused uncertainty quantification the formal qualitative uncertainty analysis contributes to an open and transparent communication of the uncertainty associated with the model results this analysis provides decision makers with a sound knowledge base to allow informed decisions on the initial extent of environmental impact analysis the probabilistic nature of the results together with the qualitative uncertainty analysis enable decision makers to appreciate the level of conservatism in the extent delineation and make it explicit that impacts beyond the initial extent cannot fully be excluded the application of the methodology to delineate the zone of potential hydrological change in the gloucester basin in new south wales australia shows that the area in which there is more than 5 probability of exceeding more than 0 2 m drawdown due to coal development does not extend more than 5 km beyond the footprint of the open cut mines the method developed and applied is generic and can be used to delineate initial extent for environmental assessments provided a relevant environmental simulation model is available acknowledgments this research is part of the bioregional assessment programme which is funded by the australian government department of the environment and energy the bioregional assessment programme is a transparent and accessible programme of baseline assessments that increase the available science for decision making associated with the impacts of coal seam gas and coal mining development on water resources bioregional assessments are being undertaken in a collaboration between the department of the environment the bureau of meteorology csiro and geoscience australia for more information www bioregionalassessments gov au the authors would like to thank the scientific leadership and the external review panel of this research project for the many recommendations that improved the methodology the implementation and the manuscript in particular the authors want to thank neil viney david post brent henderson rebecca schmidt steve lewis peter baker and dirk mallants appendix a supplementary data the following are the supplementary data related to this article supplementary material supplementary material appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 020 
26333,mobile augmented reality for flood visualisation paul haynes sigrid hehl lange eckart lange department of landscape university of sheffield floor 13 the arts tower sheffield s10 2tn uk department of landscape university of sheffield floor 13 the arts tower sheffield s10 2tn uk corresponding author corresponding author mobile augmented reality mar for environmental planning and design has hardly been touched upon yet mobile smart devices are now capable of complex interactive and immersive real time visualisations we present a real time immersive prototype mar app for on site content authoring and flood visualisation combining available technologies to reduce implementation complexity networked access to live sensor readings provides rich real time annotations our main goal was to develop a novel mar app to complement existing flood risk management frm tools and to understand how it is judged by water experts we present app development in context of the literature and conduct a small user study going beyond the presented work the flexibility of the app permits a broad range of applications in planning design and environmental management graphical abstract image 1 keywords mobile augmented reality flood visualisation browser authoring mobile real time flood modeling 1 introduction appropriate use of tools for visualisation in flood risk management frm depends on the problem at hand in particular flood visualisation often employs inundation mapping methods similar to those reported in maidment et al 2016 systems such as the iowa flood information system ifis web platform demir and krajewski 2013 for example combine inundation maps sensor readings and other data to inform community flood risk assessors fra s these are important tools in frm providing clear orthographic views of potential risks over wide areas which help facilitate expert analysis virtual reality vr augmented reality ar and more recently mobile ar mar chatzopoulos et al 2017 and citizen science montargil and santos 2017 o grady et al 2016 degrossi et al 2017 create new opportunities to investigate alternative modes of visualisation and interaction for citizen volunteer and expert fra engagement this is important due to an increased need to communicate flood risks as a precautionary measure hagemeier klose and wagner 2009 in this direction our main goal is to firstly develop a mar app to enable the user to track an unspecified location populate it with building geometry and visualise an augmented reality flooding of the environment secondly we seek to understand how such an app is received by water experts hence we seek to apply the aforementioned technologies to frm in particular how ar may be applied and how it is received by fra s as a complementary flood visualisation tool as part of the frm process it is important to note that we do not seek to replace existing frm tools but to enhance them using immersive ar technology and to investigate the usefulness of such tools to support discussion about planning proposals previous works have identified user preference towards immersive 3d visualisation gill et al 2013 and experimental mobile applications were designed to take vr into the field see e g gill and lange 2015 unlike laboratory based 3d and vr simulations mar offers new levels of engagement linking simulations with an on site experience nowadays powerful smart phones and emerging technologies such as mar provide an opportunity to immerse the user in a visualisation whilst simultaneously experiencing the observed world environment observed and augmented realities may be perceived separately or together depending on how the user chooses to experience the ar a user for example may choose to intentionally note differences between the observed and augmented realities or engage directly with the augmented reality in place of the observed reality in general ar presents a range of benefits to the planning and design process lange 2011 such as location based information applications to support understanding of landscape futures and the environment bishop 2015 for example demonstrates a variety of potential prototype applications to urban and landscape planning including a simple prototype flood app mobile devices with 3d graphics capabilities are increasingly ubiquitous but their potential use in landscape and urban planning has hardly been touched upon which we seek to explore grainger et al 2016 emphasize the need for environmental data visualisation for non scientific contexts such as public engagement and expert application in the field morgan et al 2010 presented workshop based rapid prototyping of urban river corridors using 3d interactive real time graphics where lab based modeling and visualisation software sketchup and symmetry 3d was used to prototype models for the urban river corridors and sustainable living agendas ursula project in later work gill and lange 2015 explored on site vr visualisation of planning and design models where complex visualisations ordinarily viewed on laboratory projectors were streamed to a remote smart device and viewed in a web browser bringing mobile vr to the field via portable lightweight smart device technology traditional support and risk management systems appear predominantly desktop or lab based making use of inundation maps maidment et al 2016 with systems such as the ifis demir and krajewski 2013 mentioned earlier on the other hand amirebrahimi et al 2016 for example presented decision support for the evaluation of building risks in flood prone areas with 3d visualisations of water flow around and evaluation of damage to new builds van ackere et al 2016 showed web based flood damage visualisations of large coastal regions with the aim of encouraging people to mitigate and adapt to climate change an early ar environmental management system developed by rom√£o et al 2004 was augmented environments ants a system of technological infrastructure which augmented contextual information with physical structures and natural elements within the environment infrastructure consisted of a wearable laptop a head mounted display hmd motion tracker video camera gps system and mobile phones for communications pilot applications included monitoring water quality levels visualising temporal evolution of landscape pasts and futures and sub soil structure visualisation except for hmd s smart phones are remarkably sophisticated enough to contain all this infrastructure in a single lightweight device with huge potential for applications to environmental management planning and design bishop 2015 for example presents a variety of ar applications related to understanding landscape futures one such application is a mar flood visualisation concept app in which a terrain model of the snowy river flood plains was statically clipped above one metre manual positioning of the clipped geometry achieved a perceived alignment of terrain model and live image feed through the camera of the mobile phone with a flood visualisation one metre in height on site in situ modeling is a difficult problem and potentially important to environment planning and design applications since decisions made in the field e g the inclusion of design features might otherwise be overlooked in a laboratory setting lange 2011 in particular a major problem in ar is that of registering points in the real world with points on the device display and displaying 3d graphics correctly in perspective e g see chatzopoulos et al 2017 one solution demonstrated by demir 2014 in lab based ar used fiducial markers to augment a 3d model of pre defined scenarios in which students could control environmental parameters to learn about hydrological processes such as flooding and flood damage an hmd oculus rift option enabled users to experience the visualisation stereographically for an alternative immersive experience systems which use fiducial markers rely on known and physically placed markers to track the environment which can be problematic in open outdoor environments see kato and billinghurst 1999 fiducial markers often find use where inventories of objects may be identified such as in the museum guide by mata et al 2011 for example the novelty of our approach is in combining real time population of building models interactive flood visualisation and integration with the wesenseit citizen water observatory web platform mazumdar et al 2016 lanfranchi et al 2014 for live sensor readings such as water level humidity and soil moisture overall we aim to elucidate expert perceptions of mar technology applied to frm we first present our methodology detailing software architecture design and data flow novel algorithms testing and evaluation then show the actual implementation of the software as an app with results of testing and the evaluation plan a discussion then follows and conclusions are drawn supplementary video related to this article can be found at https doi org 10 1016 j envsoft 2018 05 012 the following is the supplementary data related to this article video video 2 methodology the presented work is based on previous work by the authors shown in fig 1 where primitive cuboids were manually transformed into position using the touch screen haynes and lange 2016a 2016b to visually align with the live image feed in much the same way bishop 2015 aligned a terrain model of the snowy river flood plains a constructive solid geometry csg difference operation applied to building geometry and flood plane simulated water flow where the building geometry could be made transparent and the flood plane translated vertically to different water levels in the presented work we add the following functionality i an improved strategy to more precisely populate a site with geometric primitives cuboids and arches ii cloud server capability for project storage retrieval iii integration with the wesenseit web service iv water height interpolation as a function of flood plane height and pre defined extremity values and v real time annotation visualisation and editing to convey historical information evacuation routes and real time sensor annotations 2 1 user experience a summary of user experience is now given to aid in the understanding of the remaining figures in this section the app is formed of three distinct activities for i main menu ii project information and options and iii authoring and browser the former two enable the user to create new projects find select and view existing project information and options whereas the latter activity is where authoring and or browsing i e visualisation occurs return to previous activities is achieved by pressing the device back button authoring browser activity interaction occurs via a retractable side menu a typical authoring use case would see the user select the triangulate menu option to triangulate a point by focusing a central annulus on a desired point and tapping the touch screen three times from three different viewpoints repeating this process to triangulate further points then selecting to add geometry from the menu allows the user to attach or hang geometry to these triangulated points model parameters may be adjusted via the menu to adapt the model to the existing natural features additionally textual annotations may be attached to triangulated points such as sensor readings which appear as spinning information cubes to be selected during browsing lastly a flood plane may be turned on see early prototype in fig 1 and the building geometry turned off revealing a flood plain obstructed by the invisible building geometry this flood plane may be moved up and down via the touch screen and low high water levels set as the user moves the flood plane up and down these flood level extremities are automatically interpolated to give the user a feel for flood depth 2 2 software architecture design and data flow a high level overview of application architecture is shown in fig 2 which was built on the android system using java hence the java virtual machine jvm and java development kit application programming interface jvm api libraries and tools form the core technology higher layers include opengl es 2 0 for rendering graphics and the vuforia software development kit sdk to provide ar support a http connection is required intermittently to communicate with the wesenseit rest server api data is represented in the json file format fig 3 shows core application design with the application at the base activity flow proceeds in the directions indicated with recourse to previous activities via the device s back button the json rest interface indicates the web service which manages database access and is accessed from all three activities detailed sequence diagrams of each activity functions and interactions between the different software architectures in fig 2 may be found in appendix c 2 3 algorithms our approach to point registration uses the well known method of triangulation see e g slabaugh et al 2001 where the coordinate of a perceived point to be triangulated is computed as the closest point to three rays r 1 r 2 and r 3 in model space the novelty however is in using the ar sdk to compute rays normal to the screen at various different viewpoints for triangulation when triangulating points a ray r in model space central and normal to the current screen orientation is continually computed using the ar sdk and recorded when the user taps the screen three such rays registered in sequence are used to triangulate a single point x in model space for visualisation purposes these triangulated model space points when transformed by the ar sdk produce points corresponding to perceived features in the environment as displayed on the device display once triangulated a point is visualised on the device display invariant of device pose this in turn enables the user to populate the environment with geometry to match perceived expectations another procedure involves the way in which building of geometric shapes in an augmented space is achieved a first attempt was to triangulate corners of whole building facades or natural features from which polygons were then constructed but it was soon realised that three points were often not in the required plane or that four or more points were not exactly co planar which led to undesirable or imprecise models of buildings or natural features and hindered flood visualisation the employed solution was to attach the top left and right corners of pre defined model facades to two triangulated points internal model parameters may be changed in real time to alter model particulars to match perceived building or natural feature details e g to widen an internal arch or stretch a model in depth or height this approach worked well and combined model positioning control with co planar model facades the pre defined models are not so specific as to hinder general application especially with the ability to change model parameters to match the surrounding environment 2 4 testing and evaluation besides the usual progressive developmental unit tests carried out functional testing of the app was performed on site at fishlake doncaster uk to ensure the app worked as expected reveal any technical problems and raise any remaining usability issues testing centered around checking the following aspects of the app 1 main menu activity including map location automatic project list and project search 2 information options activity including operation under difficult conditions such as disabled wifi or gps 3 create new project including target image capture point triangulation attaching and changing geometry parameters defining flood plane extremities and annotating points 4 open existing project browsing the project selecting information bubbles observing the flood plane software was evaluated by means of a small user study of experts in cooperation with doncaster city council in the uk the study is in a very narrow field with a very limited number of specialised experts however we were able to assemble eleven experts aged 25 to 65 plus whose professions included emergency planners flood risk engineers local government officers bridge inspectors civil engineers resilience coordinators and flood wardens see bogner et al 2009 participants were i shown a power point presentation of app operation at stainforth bridge fishlake doncaster uk ii shown video footage of the app in use on site iii given the opportunity to try the app for themselves and lastly iv asked to fill in a questionnaire evaluation was intended to determine how the app would be received by experts and how different aspects of participant s experience in frm influenced perception a copy of the questionnaire can be found in appendix a in the majority of questions participants were asked to specify particular levels of personal expertise or rate a particular aspect of the app on a scale of 1 non expert least to 5 expert most the raw data of which may be found in appendix b 3 results 3 1 implementation the core authoring browser activity code is available on github for download we also give a description of application components with reference to the literature to generally help with implementation reproducibility and refer the reader back to subsections 2 1 2 3 for additional detail as with general purpose ar browsers kooper and macintyre 2003 langlotz et al 2013 the presented system combines a number of technologies including environment tracking localisation data access networking visualisation and interaction e g see langlotz et al 2014 additionally a driving principle behind development was anywhere augmentation h√∂llerer et al 2007 which seeks to enable ar in unprepared environments so that users are not restricted to a finite number of specific locations tracking technology should be independent of location choice so fiducial marker tracking is not practical natural feature tracking see wagner et al 2008 and simultaneous localisation and mapping slam see e g kurz et al 2014 reitmayr et al 2010 ventura and h√∂llerer 2012 ventura et al 2014 however can achieve this goal where any site suitably rich in natural or artificial features may be tracked after comparing available ar sdk s see e g amin and govilkar 2015 we chose the vuforia sdk with nft as a compromise which gave good tracking ability in a relatively small area but with reduced implementation complexity nft is a markerless technology suited to scenes in which a homography exists between the viewpoints pirchheim and reitmayr 2011 zhou et al 2008 a tracking database automatically created by the sdk is used to track natural features present in the environment calculate pose estimation and correctly render content in perspective as a function of the tracking database and user s position projects are stored on the wesenseit server in json format content includes project name location target image tracking database geometry flood height extremities and textual sensor annotations json sensor data is retrieved via the wesenseit restful web service and includes sensor id name region longitude latitude mobility e g fixed mobile sensor measurement frequency and latest previous value creating points geometry or annotations is achieved via the retractable side menu within the main authoring activity any in situ ar authoring system requires an interaction device to register and select points of interest poi s past examples include a wearable laser wither et al 2008 a camera mouse bunnun and mayol cuevas 2008 and custom built pinch gloves piekarski and thomas 2001 in simon s 2010 approach a visual software based solution uses a central cross hair to target poi s which we also employ here for simplicity and ease of dissemination see also haynes and lange 2016a 2016b in this approach poi s are triangulated by focusing the yellow annulus in fig 4 on a poi from three different viewpoints tapping the screen at each viewpoint to register the point this technique was also adopted in bunnun and mayol cuevas 2008 and wither et al 2008 but with custom built hardware devices three dimensional model content authoring is an extremely challenging technical problem pioneering approaches such as piekarski and thomas 2001 2003 which required an ensemble of infrastructure much like that in rom√£o et al 2004 enabled construction of building geometry by physically aligning oneself with walls to mark out infinite planes the intersections of which defined building perimeters such an approach is physically demanding and could prove intractable given the presence of rivers or other obstructions another approach by langlotz et al 2012a used an adapted slam algorithm with panoramic orientation tracking in outdoor environments by assuming a static user position and allowing rotational device movements only in our approach it is necessary to occlude a virtual flood plane to create the impression of water flow around obstructing building facades haynes and lange 2016a after some experimentation the most recent effective approach attempted involved attaching the facade of a simple pre defined model to two triangulated points in some sense hanging geometry on triangulated points the benefit of this approach was population of the augmented space with perfectly geometric shapes in the required augmented positions something which seemed difficult by constructing polygon facades from triangulated points alone model parameters may be adjusted using the retractable menu e g to widen an arch or increase or decrease height or depth textual annotations can further enrich user experience by providing additional information on demand mata et al 2011 for example used fiducial marker recognition to display textual annotations in guiding tourists around a museum our approach to in situ annotations requires the user to select a triangulated point which displays the annotation input dialog shown in fig 5 left examples of informative annotations might include evacuation route details or historical flooding events water sensor identification tags may be entered which are replaced by live sensor readings taken from the wesenseit web service api in real time e g the sh 154 160 sensor is showing a water level of latestvalue meters would display the fishlake sensor is showing a water level of 2 meters supported sensor tags currently include latest previous sensor readings and sensor longitude and latitude once created annotations appear as rotating annotation bubbles selecting which displays the relevant information as in fig 6 where the sensor hash tags are replaced with live sensor readings 3 2 software testing on location at fishlake doncaster uk the app was opened and the main menu activity appeared an existing nearby project made earlier appeared in the automatically updated list downloaded from the server over the wireless internet connection shown at the bottom of the menu in fig 7 a this is also visible on the map in fig 7b and showed up via the search functionality in fig 7c selecting the existing location opened the location information activity shown in fig 7d as authors of this project we could enable password protected editing should we wish alternatively a browser user may proceed in browse mode only in which case authoring tools are not available we note one unavoidable caveat here is gps or network failure projects are also stored locally in case internet connection is unavailable which may be uploaded later or projects may be downloaded in advance if network availability is known to be unreliable on the other hand if gps is unavailable the user may search for a project providing there is an internet connection and when creating new project locations gps may be edited later manually these eventualities were all taken into account during development stage and worked as expected when wifi and or gps were intentionally disabled on the device instead of opening the existing project authors may also create new projects on doing so the author browser activity was opened in which a target image of the site was taken by pressing the camera icon shown in fig 8 tracking is then indicated by the rectangular white border which appears fixed from the various different device orientations as expected due to the nature of nft successful tracking works when the underlying sdk captures a good enough quality target image we found tracking to work within about 6 m of the location where the target image was originally captured but ultimately this depends on the quality of the target image measured in feature density by the vuforia sdk and tracking stability depends on the extent to which the target image is homographic the retractable side menu in fig 4 provides the necessary functions to register points triangulate delete points annotate points textual sensor edit prototype geometry add blocks arches delete geometry stretch geometry and flood the environment define flood plane set min max flood heights enable disable flood plane and prototype geometry visualisation in triangulating points we found in practice that viewpoints need only be at most a meter apart with minimal site navigation fig 9 shows triangulated points corresponding to features of stainforth bridge fishlake with pre defined model geometry hung from those points as the user moves around the site and orients the device the points remain in their expected positions cuboids and arches were hung from triangulated points and then scaled in depth and height using the menu and touch screen very similar to the approach in langlotz et al 2012b where a stylus pen was used to transform objects on the screen in real time flood level extremities were defined by enabling and sliding the virtual water plane level to visually known measured heights such as the current known water level or to coincide with known building measurements and setting the water level heights via the side menu as in fig 5 right the authoring process worked perfectly with the only possible hindrance being the weather strong winds can affect augmentation stability but this is not enough to severely disrupt performance the app most likely worked well due to the fact that modeling can be performed either outdoor in situ using a target image taken directly of the environment or indoor ex situ using the same target image on the desktop computer screen hence the app was tested extensively in the lab prior to the live test which reduced the number of problems potentially occurring in situ after exiting the authoring activity by pressing the device s back button we then opened the newly defined project as a browser in this mode no editing tools are available and the flood plane appeared automatically with transparent building geometry and the user free to slide the flood level up and down to simulate what a real flood might look like see figs 10 and 11 depths were interpolated between extremities as the flood plane moved giving an indication as to how high the water level might be in a real flooding event information bubbles were selected and successfully displayed the additional information added during the authoring stage shown in fig 6 3 3 software evaluation the raw data in appendix b is summarised statistically in table 1 box plots are shown in fig 12 with outliers statistically identified as single points in addition to observations on the centrality and spread of data we formulated meaningful and relevant questions by statistically determining how certain participant responses were correlated with others practicalities involved in gathering flood management experts into a single cohort lead to a relatively small sample size with relatively sparse scatter diagrams sometimes non linear in appearance and often containing tied data see fig 13 hence in order to identify correlations between questionnaire responses we calculated spearman s rank correlation coefficient which can deal with skewed linear and non linear relationships due to the presence of tied data and therefore duplicate ranks spearman s coefficient must be computed with full covariance and not the approximate formula as is often used table 2 shows a comparison of correlation coefficients between all possible pairs of questions 4 discussion 4 1 data analysis responses to questions are generally skewed to which degrees and nature magnitude positive or negative skew are shown in table 1 fig 12 shows a wide range of frm experience but with most participants in the expert category with a negative skew of data this is substantial since the number of experts from which one may obtain feedback is highly limited and gathering many different experts together simultaneously is logistically difficult the majority of participants were familiar using a smart phone with a median rating of 4 negative skew and a single outlier most participants were not experienced with 3d modeling as seen by a distinct positive skew and median rating of 2 which is interesting when compared to the median rating of 4 for involvement in frm which has opposite skew this may suggest that experts do not currently utilise 3d modeling software not to mention ar in frm tasks which could be interpreted to highlight the novelty of our application of ar to frm the majority of participants thought the visualisation was easy to understand with a median rating of 4 negative skew and one outlier indeed after viewing video footage relating to fig 11 right one participant who witnessed the flooding at fishlake in 2007 reported having watched build up in 2007 flood episode i am not surprised by the visualisation height almost all participants described the visualisation as plausible as evidenced by a median rating of 4 and a zero inter quartile range iqr showing nearly all responses were unanimous both visualisation stability and perceived usefulness to the emergency services were viewed in a positive light with median of 4 and iqr of 0 5 perceived usefulness of the app was negatively skewed with a single outlier and a maximum rating of 5 attained participant comments concerning perceived usefulness included i see some application for sharing flood awareness planning applications impact of building on flood risk areas and could see this being useful for householders to consider the threat of flooding to their property we interpret overall questionnaire results to show support in favor of our approach 4 2 correlation analysis table 2 shows the symmetric spearman correlation coefficient matrix between all questions all correlations were positive except a very weak negative correlation between frm and experience using a smartphone spearman s coefficient is suitable for skewed data and the possible non linearity of our data see e g figs 12 and 13 our first observations related to whether or not involvement in frm or experience with a smart phone or 3d modeling correlated with opinions concerning whether the visualisation was easy to understand looked plausible and stable and if the app was deemed useful for emergency planning our findings in table 2 show weak correlations between involvement in frm and visualisation plausibility and usefulness to emergency services but with a 97 confidence a moderate positive correlation with visualisation stability however these weak correlations do not imply a lack in support from experts as the scatter diagram in fig 13 top demonstrates rather the correlation statistic is inconclusive and more data is required fig 13 top shows the relationship between expert and app usefulness is quite complicated but is in the higher ratings suggesting that experts did find the app useful no meaningful statistically significant correlations were observed between experience with a smart phone and other responses interestingly experience with 3d modeling software showed moderate positive correlation with visualisation understanding plausibility and stability with between 93 and 99 confidence and usefulness to emergency services with approximately 90 confidence this could signal a dependence between 3d modeling experience and positive perceptions of the visualisation and app overall despite 3d modeling experience among experts being positively skewed our next observations concerned whether or not usefulness to emergency services was correlated to any of visualisation understanding plausibility or stability table 2 clearly shows high correlation between perceptions of usefulness to the emergency services and visualisation understanding and plausibility with a 98 99 confidence however no statistically significant correlation could be determined between usefulness and visualisation stability finally we note a strong positive correlation with 99 confidence between visualisation understanding and visualisation plausibility which seems natural to expect we can only speculate about the meaning behind these correlations but their identification as part of this research gives clues as to what factors effect expert opinion and how further work might proceed in a useful way to benefit the frm domain a further study with larger sample size would serve to sharpen findings and steer future research and development 4 3 limitations nft technology permits an acceptable but ultimately limited radius of site exploration which appears to depend somewhat on the homography of natural features in a scene a result of this limitation is that triangulated points tend to be more or less co planar attaching prototype geometry to co planar points is sufficient for the current application since buildings by riversides often appear co planar far in the distance from the user s location however to emulate truly realistic virtual water flow around buildings requires more convincing 3d building models one participant e g reported he could see this has a use for members of the public to visualise flood existences but not so much from a planning perspective as the modeling for fra s is more detailed detailed pre prepared 3d models could solve this problem but is somewhat removed from the principle of anywhere augmentation h√∂llerer et al 2007 in addition tracking proximity could be enlarged by using a wide area tracking capability such as bespoke slam see e g kurz et al 2014 reitmayr et al 2010 ventura and h√∂llerer 2012 ventura et al 2014 which could also facilitate an improved supervised method of triangulation where automatically triangulated points are recommended for selection another limitation concerns the current sdk version 5 which does not permit programmatic extraction of the tracking database so for future browsing the author must separately process the target image offline using the sdk s web based database manager and upload it to the project via the app at a later time a future version of the sdk may include data extraction functionality which would solve this problem on the other hand langlotz et al 2012b implemented their own solution where the target image was sent to a custom server for external processing and the database returned locally to the client once processing was complete ideally we would develop a bespoke slam system effectively removing the need for the underlying ar sdk and make available the tracking database to process store and retrieve as required without limitation 5 conclusion our app and study were intended to evaluate the potential usefulness of mar technology to frm tasks we interpret our results to be in support of the hypothesis that those involved in frm perceived the app as useful for the emergency services however from comments it was clear that greater geometric model complexity was required to be useful for serious application given that a majority of participants were involved in frm but were less experienced with 3d modeling software could suggest 3d modeling and visualisation may not feature prominently in current frm activities which could be interpreted as supporting the novelty of our approach in context of frm hence whilst we believe mar can be useful in expert frm further work must be carried out such as updating the underlying ar technology possibly using a wide area slam algorithm triangulation of natural features could also be semi automated via the slam algorithm whereby the salient points are automatically filtered to be selected by the user improvement of tools for in situ modeling are also necessary complemented with the ability to import existing complex models particularly for expert frm activities automatic loading of local content would be more in line with the full ar browser paradigm langlotz et al 2013 where geolocated geometric models and content could be automatically downloaded and displayed overall it is demonstrated that mar technology could be useful in frm and it is hoped this work provides support in this direction expanding the scope for future research mar could be linked to a national flood forecasting model such as e g the us national water model or the iowa flood information system where e g in case of an extreme rainfall event mar could demonstrate the water storage capacity of natural or built up environments in general mar has the potential for wider applications in planning design and environmental management acknowledgments this work was part of the wesenseit project funded by the european union horizon 2020 programme under grant agreement number 308429 www wesenseit eu we would like to thank doncaster city council uk for their help in the user study and all reviewers of em s for their helpful comments in revising the manuscript appendices supplementary data the following are the supplementary data related to this article multimedia component 2 multimedia component 2 appendices supplementary data supplementary data related to this article may be found at https doi org 10 1016 j envsoft 2018 05 012 
26333,mobile augmented reality for flood visualisation paul haynes sigrid hehl lange eckart lange department of landscape university of sheffield floor 13 the arts tower sheffield s10 2tn uk department of landscape university of sheffield floor 13 the arts tower sheffield s10 2tn uk corresponding author corresponding author mobile augmented reality mar for environmental planning and design has hardly been touched upon yet mobile smart devices are now capable of complex interactive and immersive real time visualisations we present a real time immersive prototype mar app for on site content authoring and flood visualisation combining available technologies to reduce implementation complexity networked access to live sensor readings provides rich real time annotations our main goal was to develop a novel mar app to complement existing flood risk management frm tools and to understand how it is judged by water experts we present app development in context of the literature and conduct a small user study going beyond the presented work the flexibility of the app permits a broad range of applications in planning design and environmental management graphical abstract image 1 keywords mobile augmented reality flood visualisation browser authoring mobile real time flood modeling 1 introduction appropriate use of tools for visualisation in flood risk management frm depends on the problem at hand in particular flood visualisation often employs inundation mapping methods similar to those reported in maidment et al 2016 systems such as the iowa flood information system ifis web platform demir and krajewski 2013 for example combine inundation maps sensor readings and other data to inform community flood risk assessors fra s these are important tools in frm providing clear orthographic views of potential risks over wide areas which help facilitate expert analysis virtual reality vr augmented reality ar and more recently mobile ar mar chatzopoulos et al 2017 and citizen science montargil and santos 2017 o grady et al 2016 degrossi et al 2017 create new opportunities to investigate alternative modes of visualisation and interaction for citizen volunteer and expert fra engagement this is important due to an increased need to communicate flood risks as a precautionary measure hagemeier klose and wagner 2009 in this direction our main goal is to firstly develop a mar app to enable the user to track an unspecified location populate it with building geometry and visualise an augmented reality flooding of the environment secondly we seek to understand how such an app is received by water experts hence we seek to apply the aforementioned technologies to frm in particular how ar may be applied and how it is received by fra s as a complementary flood visualisation tool as part of the frm process it is important to note that we do not seek to replace existing frm tools but to enhance them using immersive ar technology and to investigate the usefulness of such tools to support discussion about planning proposals previous works have identified user preference towards immersive 3d visualisation gill et al 2013 and experimental mobile applications were designed to take vr into the field see e g gill and lange 2015 unlike laboratory based 3d and vr simulations mar offers new levels of engagement linking simulations with an on site experience nowadays powerful smart phones and emerging technologies such as mar provide an opportunity to immerse the user in a visualisation whilst simultaneously experiencing the observed world environment observed and augmented realities may be perceived separately or together depending on how the user chooses to experience the ar a user for example may choose to intentionally note differences between the observed and augmented realities or engage directly with the augmented reality in place of the observed reality in general ar presents a range of benefits to the planning and design process lange 2011 such as location based information applications to support understanding of landscape futures and the environment bishop 2015 for example demonstrates a variety of potential prototype applications to urban and landscape planning including a simple prototype flood app mobile devices with 3d graphics capabilities are increasingly ubiquitous but their potential use in landscape and urban planning has hardly been touched upon which we seek to explore grainger et al 2016 emphasize the need for environmental data visualisation for non scientific contexts such as public engagement and expert application in the field morgan et al 2010 presented workshop based rapid prototyping of urban river corridors using 3d interactive real time graphics where lab based modeling and visualisation software sketchup and symmetry 3d was used to prototype models for the urban river corridors and sustainable living agendas ursula project in later work gill and lange 2015 explored on site vr visualisation of planning and design models where complex visualisations ordinarily viewed on laboratory projectors were streamed to a remote smart device and viewed in a web browser bringing mobile vr to the field via portable lightweight smart device technology traditional support and risk management systems appear predominantly desktop or lab based making use of inundation maps maidment et al 2016 with systems such as the ifis demir and krajewski 2013 mentioned earlier on the other hand amirebrahimi et al 2016 for example presented decision support for the evaluation of building risks in flood prone areas with 3d visualisations of water flow around and evaluation of damage to new builds van ackere et al 2016 showed web based flood damage visualisations of large coastal regions with the aim of encouraging people to mitigate and adapt to climate change an early ar environmental management system developed by rom√£o et al 2004 was augmented environments ants a system of technological infrastructure which augmented contextual information with physical structures and natural elements within the environment infrastructure consisted of a wearable laptop a head mounted display hmd motion tracker video camera gps system and mobile phones for communications pilot applications included monitoring water quality levels visualising temporal evolution of landscape pasts and futures and sub soil structure visualisation except for hmd s smart phones are remarkably sophisticated enough to contain all this infrastructure in a single lightweight device with huge potential for applications to environmental management planning and design bishop 2015 for example presents a variety of ar applications related to understanding landscape futures one such application is a mar flood visualisation concept app in which a terrain model of the snowy river flood plains was statically clipped above one metre manual positioning of the clipped geometry achieved a perceived alignment of terrain model and live image feed through the camera of the mobile phone with a flood visualisation one metre in height on site in situ modeling is a difficult problem and potentially important to environment planning and design applications since decisions made in the field e g the inclusion of design features might otherwise be overlooked in a laboratory setting lange 2011 in particular a major problem in ar is that of registering points in the real world with points on the device display and displaying 3d graphics correctly in perspective e g see chatzopoulos et al 2017 one solution demonstrated by demir 2014 in lab based ar used fiducial markers to augment a 3d model of pre defined scenarios in which students could control environmental parameters to learn about hydrological processes such as flooding and flood damage an hmd oculus rift option enabled users to experience the visualisation stereographically for an alternative immersive experience systems which use fiducial markers rely on known and physically placed markers to track the environment which can be problematic in open outdoor environments see kato and billinghurst 1999 fiducial markers often find use where inventories of objects may be identified such as in the museum guide by mata et al 2011 for example the novelty of our approach is in combining real time population of building models interactive flood visualisation and integration with the wesenseit citizen water observatory web platform mazumdar et al 2016 lanfranchi et al 2014 for live sensor readings such as water level humidity and soil moisture overall we aim to elucidate expert perceptions of mar technology applied to frm we first present our methodology detailing software architecture design and data flow novel algorithms testing and evaluation then show the actual implementation of the software as an app with results of testing and the evaluation plan a discussion then follows and conclusions are drawn supplementary video related to this article can be found at https doi org 10 1016 j envsoft 2018 05 012 the following is the supplementary data related to this article video video 2 methodology the presented work is based on previous work by the authors shown in fig 1 where primitive cuboids were manually transformed into position using the touch screen haynes and lange 2016a 2016b to visually align with the live image feed in much the same way bishop 2015 aligned a terrain model of the snowy river flood plains a constructive solid geometry csg difference operation applied to building geometry and flood plane simulated water flow where the building geometry could be made transparent and the flood plane translated vertically to different water levels in the presented work we add the following functionality i an improved strategy to more precisely populate a site with geometric primitives cuboids and arches ii cloud server capability for project storage retrieval iii integration with the wesenseit web service iv water height interpolation as a function of flood plane height and pre defined extremity values and v real time annotation visualisation and editing to convey historical information evacuation routes and real time sensor annotations 2 1 user experience a summary of user experience is now given to aid in the understanding of the remaining figures in this section the app is formed of three distinct activities for i main menu ii project information and options and iii authoring and browser the former two enable the user to create new projects find select and view existing project information and options whereas the latter activity is where authoring and or browsing i e visualisation occurs return to previous activities is achieved by pressing the device back button authoring browser activity interaction occurs via a retractable side menu a typical authoring use case would see the user select the triangulate menu option to triangulate a point by focusing a central annulus on a desired point and tapping the touch screen three times from three different viewpoints repeating this process to triangulate further points then selecting to add geometry from the menu allows the user to attach or hang geometry to these triangulated points model parameters may be adjusted via the menu to adapt the model to the existing natural features additionally textual annotations may be attached to triangulated points such as sensor readings which appear as spinning information cubes to be selected during browsing lastly a flood plane may be turned on see early prototype in fig 1 and the building geometry turned off revealing a flood plain obstructed by the invisible building geometry this flood plane may be moved up and down via the touch screen and low high water levels set as the user moves the flood plane up and down these flood level extremities are automatically interpolated to give the user a feel for flood depth 2 2 software architecture design and data flow a high level overview of application architecture is shown in fig 2 which was built on the android system using java hence the java virtual machine jvm and java development kit application programming interface jvm api libraries and tools form the core technology higher layers include opengl es 2 0 for rendering graphics and the vuforia software development kit sdk to provide ar support a http connection is required intermittently to communicate with the wesenseit rest server api data is represented in the json file format fig 3 shows core application design with the application at the base activity flow proceeds in the directions indicated with recourse to previous activities via the device s back button the json rest interface indicates the web service which manages database access and is accessed from all three activities detailed sequence diagrams of each activity functions and interactions between the different software architectures in fig 2 may be found in appendix c 2 3 algorithms our approach to point registration uses the well known method of triangulation see e g slabaugh et al 2001 where the coordinate of a perceived point to be triangulated is computed as the closest point to three rays r 1 r 2 and r 3 in model space the novelty however is in using the ar sdk to compute rays normal to the screen at various different viewpoints for triangulation when triangulating points a ray r in model space central and normal to the current screen orientation is continually computed using the ar sdk and recorded when the user taps the screen three such rays registered in sequence are used to triangulate a single point x in model space for visualisation purposes these triangulated model space points when transformed by the ar sdk produce points corresponding to perceived features in the environment as displayed on the device display once triangulated a point is visualised on the device display invariant of device pose this in turn enables the user to populate the environment with geometry to match perceived expectations another procedure involves the way in which building of geometric shapes in an augmented space is achieved a first attempt was to triangulate corners of whole building facades or natural features from which polygons were then constructed but it was soon realised that three points were often not in the required plane or that four or more points were not exactly co planar which led to undesirable or imprecise models of buildings or natural features and hindered flood visualisation the employed solution was to attach the top left and right corners of pre defined model facades to two triangulated points internal model parameters may be changed in real time to alter model particulars to match perceived building or natural feature details e g to widen an internal arch or stretch a model in depth or height this approach worked well and combined model positioning control with co planar model facades the pre defined models are not so specific as to hinder general application especially with the ability to change model parameters to match the surrounding environment 2 4 testing and evaluation besides the usual progressive developmental unit tests carried out functional testing of the app was performed on site at fishlake doncaster uk to ensure the app worked as expected reveal any technical problems and raise any remaining usability issues testing centered around checking the following aspects of the app 1 main menu activity including map location automatic project list and project search 2 information options activity including operation under difficult conditions such as disabled wifi or gps 3 create new project including target image capture point triangulation attaching and changing geometry parameters defining flood plane extremities and annotating points 4 open existing project browsing the project selecting information bubbles observing the flood plane software was evaluated by means of a small user study of experts in cooperation with doncaster city council in the uk the study is in a very narrow field with a very limited number of specialised experts however we were able to assemble eleven experts aged 25 to 65 plus whose professions included emergency planners flood risk engineers local government officers bridge inspectors civil engineers resilience coordinators and flood wardens see bogner et al 2009 participants were i shown a power point presentation of app operation at stainforth bridge fishlake doncaster uk ii shown video footage of the app in use on site iii given the opportunity to try the app for themselves and lastly iv asked to fill in a questionnaire evaluation was intended to determine how the app would be received by experts and how different aspects of participant s experience in frm influenced perception a copy of the questionnaire can be found in appendix a in the majority of questions participants were asked to specify particular levels of personal expertise or rate a particular aspect of the app on a scale of 1 non expert least to 5 expert most the raw data of which may be found in appendix b 3 results 3 1 implementation the core authoring browser activity code is available on github for download we also give a description of application components with reference to the literature to generally help with implementation reproducibility and refer the reader back to subsections 2 1 2 3 for additional detail as with general purpose ar browsers kooper and macintyre 2003 langlotz et al 2013 the presented system combines a number of technologies including environment tracking localisation data access networking visualisation and interaction e g see langlotz et al 2014 additionally a driving principle behind development was anywhere augmentation h√∂llerer et al 2007 which seeks to enable ar in unprepared environments so that users are not restricted to a finite number of specific locations tracking technology should be independent of location choice so fiducial marker tracking is not practical natural feature tracking see wagner et al 2008 and simultaneous localisation and mapping slam see e g kurz et al 2014 reitmayr et al 2010 ventura and h√∂llerer 2012 ventura et al 2014 however can achieve this goal where any site suitably rich in natural or artificial features may be tracked after comparing available ar sdk s see e g amin and govilkar 2015 we chose the vuforia sdk with nft as a compromise which gave good tracking ability in a relatively small area but with reduced implementation complexity nft is a markerless technology suited to scenes in which a homography exists between the viewpoints pirchheim and reitmayr 2011 zhou et al 2008 a tracking database automatically created by the sdk is used to track natural features present in the environment calculate pose estimation and correctly render content in perspective as a function of the tracking database and user s position projects are stored on the wesenseit server in json format content includes project name location target image tracking database geometry flood height extremities and textual sensor annotations json sensor data is retrieved via the wesenseit restful web service and includes sensor id name region longitude latitude mobility e g fixed mobile sensor measurement frequency and latest previous value creating points geometry or annotations is achieved via the retractable side menu within the main authoring activity any in situ ar authoring system requires an interaction device to register and select points of interest poi s past examples include a wearable laser wither et al 2008 a camera mouse bunnun and mayol cuevas 2008 and custom built pinch gloves piekarski and thomas 2001 in simon s 2010 approach a visual software based solution uses a central cross hair to target poi s which we also employ here for simplicity and ease of dissemination see also haynes and lange 2016a 2016b in this approach poi s are triangulated by focusing the yellow annulus in fig 4 on a poi from three different viewpoints tapping the screen at each viewpoint to register the point this technique was also adopted in bunnun and mayol cuevas 2008 and wither et al 2008 but with custom built hardware devices three dimensional model content authoring is an extremely challenging technical problem pioneering approaches such as piekarski and thomas 2001 2003 which required an ensemble of infrastructure much like that in rom√£o et al 2004 enabled construction of building geometry by physically aligning oneself with walls to mark out infinite planes the intersections of which defined building perimeters such an approach is physically demanding and could prove intractable given the presence of rivers or other obstructions another approach by langlotz et al 2012a used an adapted slam algorithm with panoramic orientation tracking in outdoor environments by assuming a static user position and allowing rotational device movements only in our approach it is necessary to occlude a virtual flood plane to create the impression of water flow around obstructing building facades haynes and lange 2016a after some experimentation the most recent effective approach attempted involved attaching the facade of a simple pre defined model to two triangulated points in some sense hanging geometry on triangulated points the benefit of this approach was population of the augmented space with perfectly geometric shapes in the required augmented positions something which seemed difficult by constructing polygon facades from triangulated points alone model parameters may be adjusted using the retractable menu e g to widen an arch or increase or decrease height or depth textual annotations can further enrich user experience by providing additional information on demand mata et al 2011 for example used fiducial marker recognition to display textual annotations in guiding tourists around a museum our approach to in situ annotations requires the user to select a triangulated point which displays the annotation input dialog shown in fig 5 left examples of informative annotations might include evacuation route details or historical flooding events water sensor identification tags may be entered which are replaced by live sensor readings taken from the wesenseit web service api in real time e g the sh 154 160 sensor is showing a water level of latestvalue meters would display the fishlake sensor is showing a water level of 2 meters supported sensor tags currently include latest previous sensor readings and sensor longitude and latitude once created annotations appear as rotating annotation bubbles selecting which displays the relevant information as in fig 6 where the sensor hash tags are replaced with live sensor readings 3 2 software testing on location at fishlake doncaster uk the app was opened and the main menu activity appeared an existing nearby project made earlier appeared in the automatically updated list downloaded from the server over the wireless internet connection shown at the bottom of the menu in fig 7 a this is also visible on the map in fig 7b and showed up via the search functionality in fig 7c selecting the existing location opened the location information activity shown in fig 7d as authors of this project we could enable password protected editing should we wish alternatively a browser user may proceed in browse mode only in which case authoring tools are not available we note one unavoidable caveat here is gps or network failure projects are also stored locally in case internet connection is unavailable which may be uploaded later or projects may be downloaded in advance if network availability is known to be unreliable on the other hand if gps is unavailable the user may search for a project providing there is an internet connection and when creating new project locations gps may be edited later manually these eventualities were all taken into account during development stage and worked as expected when wifi and or gps were intentionally disabled on the device instead of opening the existing project authors may also create new projects on doing so the author browser activity was opened in which a target image of the site was taken by pressing the camera icon shown in fig 8 tracking is then indicated by the rectangular white border which appears fixed from the various different device orientations as expected due to the nature of nft successful tracking works when the underlying sdk captures a good enough quality target image we found tracking to work within about 6 m of the location where the target image was originally captured but ultimately this depends on the quality of the target image measured in feature density by the vuforia sdk and tracking stability depends on the extent to which the target image is homographic the retractable side menu in fig 4 provides the necessary functions to register points triangulate delete points annotate points textual sensor edit prototype geometry add blocks arches delete geometry stretch geometry and flood the environment define flood plane set min max flood heights enable disable flood plane and prototype geometry visualisation in triangulating points we found in practice that viewpoints need only be at most a meter apart with minimal site navigation fig 9 shows triangulated points corresponding to features of stainforth bridge fishlake with pre defined model geometry hung from those points as the user moves around the site and orients the device the points remain in their expected positions cuboids and arches were hung from triangulated points and then scaled in depth and height using the menu and touch screen very similar to the approach in langlotz et al 2012b where a stylus pen was used to transform objects on the screen in real time flood level extremities were defined by enabling and sliding the virtual water plane level to visually known measured heights such as the current known water level or to coincide with known building measurements and setting the water level heights via the side menu as in fig 5 right the authoring process worked perfectly with the only possible hindrance being the weather strong winds can affect augmentation stability but this is not enough to severely disrupt performance the app most likely worked well due to the fact that modeling can be performed either outdoor in situ using a target image taken directly of the environment or indoor ex situ using the same target image on the desktop computer screen hence the app was tested extensively in the lab prior to the live test which reduced the number of problems potentially occurring in situ after exiting the authoring activity by pressing the device s back button we then opened the newly defined project as a browser in this mode no editing tools are available and the flood plane appeared automatically with transparent building geometry and the user free to slide the flood level up and down to simulate what a real flood might look like see figs 10 and 11 depths were interpolated between extremities as the flood plane moved giving an indication as to how high the water level might be in a real flooding event information bubbles were selected and successfully displayed the additional information added during the authoring stage shown in fig 6 3 3 software evaluation the raw data in appendix b is summarised statistically in table 1 box plots are shown in fig 12 with outliers statistically identified as single points in addition to observations on the centrality and spread of data we formulated meaningful and relevant questions by statistically determining how certain participant responses were correlated with others practicalities involved in gathering flood management experts into a single cohort lead to a relatively small sample size with relatively sparse scatter diagrams sometimes non linear in appearance and often containing tied data see fig 13 hence in order to identify correlations between questionnaire responses we calculated spearman s rank correlation coefficient which can deal with skewed linear and non linear relationships due to the presence of tied data and therefore duplicate ranks spearman s coefficient must be computed with full covariance and not the approximate formula as is often used table 2 shows a comparison of correlation coefficients between all possible pairs of questions 4 discussion 4 1 data analysis responses to questions are generally skewed to which degrees and nature magnitude positive or negative skew are shown in table 1 fig 12 shows a wide range of frm experience but with most participants in the expert category with a negative skew of data this is substantial since the number of experts from which one may obtain feedback is highly limited and gathering many different experts together simultaneously is logistically difficult the majority of participants were familiar using a smart phone with a median rating of 4 negative skew and a single outlier most participants were not experienced with 3d modeling as seen by a distinct positive skew and median rating of 2 which is interesting when compared to the median rating of 4 for involvement in frm which has opposite skew this may suggest that experts do not currently utilise 3d modeling software not to mention ar in frm tasks which could be interpreted to highlight the novelty of our application of ar to frm the majority of participants thought the visualisation was easy to understand with a median rating of 4 negative skew and one outlier indeed after viewing video footage relating to fig 11 right one participant who witnessed the flooding at fishlake in 2007 reported having watched build up in 2007 flood episode i am not surprised by the visualisation height almost all participants described the visualisation as plausible as evidenced by a median rating of 4 and a zero inter quartile range iqr showing nearly all responses were unanimous both visualisation stability and perceived usefulness to the emergency services were viewed in a positive light with median of 4 and iqr of 0 5 perceived usefulness of the app was negatively skewed with a single outlier and a maximum rating of 5 attained participant comments concerning perceived usefulness included i see some application for sharing flood awareness planning applications impact of building on flood risk areas and could see this being useful for householders to consider the threat of flooding to their property we interpret overall questionnaire results to show support in favor of our approach 4 2 correlation analysis table 2 shows the symmetric spearman correlation coefficient matrix between all questions all correlations were positive except a very weak negative correlation between frm and experience using a smartphone spearman s coefficient is suitable for skewed data and the possible non linearity of our data see e g figs 12 and 13 our first observations related to whether or not involvement in frm or experience with a smart phone or 3d modeling correlated with opinions concerning whether the visualisation was easy to understand looked plausible and stable and if the app was deemed useful for emergency planning our findings in table 2 show weak correlations between involvement in frm and visualisation plausibility and usefulness to emergency services but with a 97 confidence a moderate positive correlation with visualisation stability however these weak correlations do not imply a lack in support from experts as the scatter diagram in fig 13 top demonstrates rather the correlation statistic is inconclusive and more data is required fig 13 top shows the relationship between expert and app usefulness is quite complicated but is in the higher ratings suggesting that experts did find the app useful no meaningful statistically significant correlations were observed between experience with a smart phone and other responses interestingly experience with 3d modeling software showed moderate positive correlation with visualisation understanding plausibility and stability with between 93 and 99 confidence and usefulness to emergency services with approximately 90 confidence this could signal a dependence between 3d modeling experience and positive perceptions of the visualisation and app overall despite 3d modeling experience among experts being positively skewed our next observations concerned whether or not usefulness to emergency services was correlated to any of visualisation understanding plausibility or stability table 2 clearly shows high correlation between perceptions of usefulness to the emergency services and visualisation understanding and plausibility with a 98 99 confidence however no statistically significant correlation could be determined between usefulness and visualisation stability finally we note a strong positive correlation with 99 confidence between visualisation understanding and visualisation plausibility which seems natural to expect we can only speculate about the meaning behind these correlations but their identification as part of this research gives clues as to what factors effect expert opinion and how further work might proceed in a useful way to benefit the frm domain a further study with larger sample size would serve to sharpen findings and steer future research and development 4 3 limitations nft technology permits an acceptable but ultimately limited radius of site exploration which appears to depend somewhat on the homography of natural features in a scene a result of this limitation is that triangulated points tend to be more or less co planar attaching prototype geometry to co planar points is sufficient for the current application since buildings by riversides often appear co planar far in the distance from the user s location however to emulate truly realistic virtual water flow around buildings requires more convincing 3d building models one participant e g reported he could see this has a use for members of the public to visualise flood existences but not so much from a planning perspective as the modeling for fra s is more detailed detailed pre prepared 3d models could solve this problem but is somewhat removed from the principle of anywhere augmentation h√∂llerer et al 2007 in addition tracking proximity could be enlarged by using a wide area tracking capability such as bespoke slam see e g kurz et al 2014 reitmayr et al 2010 ventura and h√∂llerer 2012 ventura et al 2014 which could also facilitate an improved supervised method of triangulation where automatically triangulated points are recommended for selection another limitation concerns the current sdk version 5 which does not permit programmatic extraction of the tracking database so for future browsing the author must separately process the target image offline using the sdk s web based database manager and upload it to the project via the app at a later time a future version of the sdk may include data extraction functionality which would solve this problem on the other hand langlotz et al 2012b implemented their own solution where the target image was sent to a custom server for external processing and the database returned locally to the client once processing was complete ideally we would develop a bespoke slam system effectively removing the need for the underlying ar sdk and make available the tracking database to process store and retrieve as required without limitation 5 conclusion our app and study were intended to evaluate the potential usefulness of mar technology to frm tasks we interpret our results to be in support of the hypothesis that those involved in frm perceived the app as useful for the emergency services however from comments it was clear that greater geometric model complexity was required to be useful for serious application given that a majority of participants were involved in frm but were less experienced with 3d modeling software could suggest 3d modeling and visualisation may not feature prominently in current frm activities which could be interpreted as supporting the novelty of our approach in context of frm hence whilst we believe mar can be useful in expert frm further work must be carried out such as updating the underlying ar technology possibly using a wide area slam algorithm triangulation of natural features could also be semi automated via the slam algorithm whereby the salient points are automatically filtered to be selected by the user improvement of tools for in situ modeling are also necessary complemented with the ability to import existing complex models particularly for expert frm activities automatic loading of local content would be more in line with the full ar browser paradigm langlotz et al 2013 where geolocated geometric models and content could be automatically downloaded and displayed overall it is demonstrated that mar technology could be useful in frm and it is hoped this work provides support in this direction expanding the scope for future research mar could be linked to a national flood forecasting model such as e g the us national water model or the iowa flood information system where e g in case of an extreme rainfall event mar could demonstrate the water storage capacity of natural or built up environments in general mar has the potential for wider applications in planning design and environmental management acknowledgments this work was part of the wesenseit project funded by the european union horizon 2020 programme under grant agreement number 308429 www wesenseit eu we would like to thank doncaster city council uk for their help in the user study and all reviewers of em s for their helpful comments in revising the manuscript appendices supplementary data the following are the supplementary data related to this article multimedia component 2 multimedia component 2 appendices supplementary data supplementary data related to this article may be found at https doi org 10 1016 j envsoft 2018 05 012 
26334,sediment transport from agricultural fields to native waterways is a significant pollution vector not just for the bulk sediment but also for additional mass of pesticides traveling offsite that are sorbed to soil particles existing field scale models that track plant growth as well as the fate and transport of applied pesticides lack an integrated sediment transport component this study sought to address this lack of available modeling tools for researchers and regulators by integrating the sediment and surface flow components of groundwater loading effects of agricultural management systems gleams model into the mature root zone water quality model rzwqm to create a derivative model named rzwqm sed previous research identified rzwqm as a quick running agricultural field scale model that accurately estimated offsite transport of solutes unlike other well performing field scale agricultural models the full source code of rzwqm was available for modification and extension however rzwqm lacked a sediment component and thus could not measure all pollutants moving offsite gleams sedimentation was chosen for integration due to its well documented history compatibility with the rzwqm codebase and source code availability sensitivity analysis of the rzwqm runoff variables showed that the residual water content saturated water content and bubbling pressure from the brooks corey equation had the highest influence for rzwqm followed by the saturated hydraulic conductivity and the non brooks corey bubbling pressure analysis of gleams variables showed the most significant variables are the usle parameters cfact pfact ksoil and manning s n the latter variable only showed sensitivity at very high surface roughness while the usle parameters had a linear relationship over the entire domain the integrated model was calibrated and validated using multiple real world datasets spanning ranges of space and time the final model performed well in the primary task of predicting the mass of sorbed chemicals in the tailwater nash sutcliffe coefficient 0 3 keywords rzqwm gleams sediment modeling model development 1 introduction sediment runoff is a significant environmental problem that negatively impacts native ecosystems the parent soil column and manmade hydrologic infrastructure in addition to the physical problems resulting from the sedimentary soil particles themselves agricultural sediment runoff is more problematic due to the presence of toxic chemicals sorbed to the mobile sediment particles in order to evaluate different best management practices that seek to minimize sediment and sorbed chemical runoff from agricultural land uses it is imperative to have a model that tracks hydrologic processes plant growth kinetics bulk soil movement and solute chemistry in a unified setting existing models that operate on the spatial scale of a single field are often incomplete lacking one or more of the above processes this study seeks to alleviate this deficit by adding an erosion component to a widely used field scale model that currently lacks it the new integrated model is tested for sensitivity and run using input from multiple real world datasets to determine the optimal time and space scales for the model and the overall utility of the model sediment models like any other computational modeling of natural systems can be classified as empirical conceptual or physical the universal soil loss equation usle and its derivatives are classically empirical and are thus computationally quick examples of conceptual sediment models include agnps young and robert 1987 emss vertessy et al 2001 lascam viney and sivapalan 1999 and swrrb arnold 1990 these models tend to be perform best for large regions catchments and above over long time scales some sediment models claim to be at least partially physically based including answers beasley et al 1980 guest yu et al 1997 hspf bicknell et al 1997 lisem takken et al 1999 and wepp laflen et al 1991 most of these are not purely physical a portion of their calculations depend on empirically based values for instance wepp uses foster s equations for sediment transport calculations it sets the sediment rate per unit width of rill channel to the summation of rill and interrill detachment deposition rates and these rates must be derived from empirical equations based on soil type topography land cover and other factors guest uses the rose equation which includes factors for volumetric flux of water runoff rate rainfall rate rill density available depositional area rill to interrill transfer and the wetted perimeter but it depends on user supplied factors like the rainfall erodibilty parameter and the fraction of streamflow power effective in re entraining sediments answers uses an empirical equation to calculate soil particle detachment and the bedload transport equation to predict the transport of non cohesive grains lisem utilizes grovers govers 1990 rill transport equation which depends on two experimental coefficients that vary depending on the median texture of the soil material current sediment modeling research is focused on complex physical models built using linked partial differential equations solved over a fine 2d or 3d mesh fluid flow is usually modeled using the navier stokes equation or its shallow water 2d version most of these complex models focus on relatively deep flows in river channels li et al 2017 or estuaries lajaunie salla et al 2017 and therefore might not be as effective for the shallow overland flow found on farm fields those that do focus on shallow water flow li and duffy 2011 still result in a model that is hard to couple to a farm process model as it would be easier to convert the governing equations in the farm model to partial differential equations that are added to the sediment model then solved at its native timestep not only is this a significant undertaking the resulting model must have all new agricultural functions validated against both measured data and the results of the model that donated the governing equations lastly afan et al 2015 and thompson et al 2016 sidestepped the empirical conceptual physical categories and used an artificial neural network trained on daily sediment and flow data to predict future sediment transport given flow data while this technique produces good sediment flow results it would require large training datasets for each specific agricultural field that is studied and thus isn t as useful for modeling what if scenarios for arbitrary fields unfortunately the sediment models listed above lack the robust plant growth kinetics soil chemistry and pesticide fate and transport modules that are present in the root zone water quality model rzwqm ahuja et al 2000 and are necessary to accurately account for several processes which affect total pesticide runoff rzwqm is a mechanistic model designed to simulate plant growth and the movement of water nutrients and pesticides in an agricultural system the model has been used around the world to among other things model agricultural vadose zone water movement xian et al 2017 optimize irrigation timing kisekka et al 2017 and assess soil effects on irrigation sun et al 2016 recently it has been enhanced by improvements to the pesticide sub model which now includes detailed algorithms for simulating pesticide transport and fate in four compartments crop foliage crop residues soil surface and soil sub surface or root zone the current version of rzwqm compares quite well against other heavily used agricultural field scale models for real world applications zhang and goh 2015 while rzwqm is a well studied agricultural process model that has been heavily used for plant growth kinetics and solute transport it unfortunately lacks a sediment runoff component to alleviate this gap in sediment modeling rzwqm and gleams two models with complementary capabilities were merged to form a unified model expanding a widely used field scale agricultural model like rzwqm to include solute sorbed sediment runoff modeling will allow researchers and regulators to more accurately account for all edge of field runoff by using these with well tested easy to use quick executing models for both the agricultural processes and the sediment runoff processes the final joint model will be very approachable for a wide variety of people already familiar with rzwqm and gleams and allow for multi decade scenarios and monte carlo runs that require a large number of model executions the need for a robust but accessible and quick unified model motivated our decision to incorporate the gleams sedimentation routines into rzwqm 2 materials methods 2 1 integration of rzwqm and gleams 2 1 1 rzwqm rzwqm is a one dimensional vertical model with the ability to discretize the soil column into up to twelve different user defined uniform layers internally the model uses 1 cm thick layers for numerical modeling the major processes of plant growth soil chemistry nutrients pesticides site management and evapotranspiration operate on a daily time scale while heat transport water balance solute transport snowpack dynamics and chemical uptake operate on a sub hourly time scale infiltration is modeled using a green ampt equation heber green and ampt 1911 modified to include surface crust simulation based on the work of bouwer 1969 morel seytoux and khanji 1974 and brakensiek and onstad 1977 post infiltration movement of water through the soil column is calculated using a slightly modified brooks corey brooks and corey 1964 equation to quantify the relationship between soil water content and the matric suction when surface water application exceeds the maximum soil infiltration rate runoff is produced with a quantifiable runoff depth total runoff is calculated by multiplying the runoff depth by the field area surface water runoff volume is the most significant variable for sediment loss therefore the rzwqm parameters of most concern are those that effect infiltration and thus directly affect calculated runoff most of the variables listed in table 1 can be measured in the field or via laboratory analysis of soil samples but some like ct eps and lambda are abstract variables with no true relationship to a field or laboratory measured 2 1 2 gleams the gleams model was chosen for the sediment component because of its well documented history of successful use its minimal requirements for input variables beyond those already required by rzwqm source code availability and compatibility with rzwqm and because it requires minimal computation time per runoff event gleams leonard et al 1987 is an extension of the creams model knisel and douglas mankin 2012 and was developed during the 1980s at the u s department of agriculture agricultural research service gleams models sediment movement as a 1d horizontal set of linked reaches with the sediment loss of each reach governed by the universal soil loss equation usle wischmeier 1976 modified for storm by storm modeling the universal soil loss equation usle wischmeier 1976 is an empirical model that forms the basis of many current sediment models in this equation soil loss is calculated on an annual basis by the multiplication of six factors rainfall erosivity factor soil erodibility factor flow length slop angle crop cover management factor and conservation factor representing five physical system attributes rainfall soil erodibility slope and length of the flowline and land cover these factors are derived from a regression analysis of field research site data subsequent models like the revised universal soil loss equation rusle renard et al 1991 extended the usle to account for some seasonal variation and sub annual time steps perfect m littleboy 1992 creams knisel 1980 and creams successor gleams leonard et al 1987 also utilize a version of the usle modified for sub daily time steps erosion is calculated daily for both interrill and rill areas with transport and deposition occurring during overland flow channel flow and in an optional impoundment parameters include the slope and length of each channel and overland flow segment manning s n and usle contouring soil erodibility and cover management parameters these usle factors cannot be measured in the field ideally they can be obtained from published tables for sites with similar soil crops and management practices the gleams sediment module requires the following data for each runoff event bulk density of soil particles the field s acreage and length to width ratio average temperature total rainfall excess rain intensity of excess rain and the proportion of clay silt sand and organic matter in the soil during initialization parameters that are shared between rzwqm and the sediment modules such as soil composition and field geometry are set by rzwqm to be later used by the sediment component parameters specific to the sediment component are read from a dedicated input file the gleams sediment routine is called from rzwqm whenever a precipitation or irrigation event results in surface runoff gleams then calculates the bulk soil loss and outputs the results to five text files one file is a detailed output log shared with the parent code base in addition the sediment component writes a readily parsable table of output values with one row for each day that runoff occurred to each of four different files one for water and sediment flow and one for each of the possible pesticides to track sorbed solute flow off field a maximum of three pesticides can be tracked each row of water and sediment flow output contains the calculated surface water runoff total sediment runoff expressed in both tons per hectare and volumetric concentration and sediment loss for each class of particle size in the integrated rzwqm sed model the calculated sediment output from gleams is then used within rzwqm to estimate the mass of modeled pesticides dissolved in the tailwater as well as the mass of pesticides in different soil bound pools which are distinguished by is the mobility of the solute both base models and the unified model rely on input and output through plain text files rzwqm and gleams are both written in fortran they were compiled for this study on windows 7 using intel fortran and microsoft visual studio currently the unified model is command line only and the parameters of the sediment component can only be set using a plain text file the rzwqm portion of the integrated model can be set up using the existing gui and the sediment input text file can be added to the project directory if the sediment input file is present when the model is run then the gleams sedimentation routine is executed otherwise only the rzqwm routines are executed the next public release of rzwqm is expected to incorporate the sediment component and include a gui input menu for the gleams parameters 2 2 site descriptions three study sites were chosen to test the integrated a two year experimental alfalfa study in davis ca that focused on offsite sediment and solute transport a three year study of an olive orchard in cordoba spain that only focused on sediment flow off field and a three decade study of a corn planted watershed in treynor ia that focused on offsite sediment and water flow fig 1 2 2 1 site 1 alfalfa field experiment in davis california two alfalfa fields 0 27ha each 15 8 m wide by 198 12 m long in davis california were use for the experiments soils in the study consisted of yolo silty loam 35 40 25 sand silt clay mix with a 0 14 slope there were seven border fed cross field flood irrigation events during 2012 and four during 2013 with input and output flow measurements taken every 2min and sediment measurements taken approximately every 30min most of the irrigation events applied around 30 mm of water to the field with one event applying 110 mm rain was negligible during the months when the measurements were made along with sediment sorbed pesticides previously applied to the field were measured in the runoff one trial used chlorpyrifos the other diuron 2 2 2 site 2 watershed scale corn experiment in treynor iowa to model watershed scale effects on a time scale in the decade range this study used annual water and sediment runoff data along with sub daily weather data from the deep loess research station located near treynor iowa the silt loam soils are classified as typic haplorthents and cumulic hapludolls with fine silty mixed mesics and have moderate to moderately rapid permeability average slope is around 8 to 9 percent with a maximum slope of 18 percent the watershed area is 30 4ha corn was grown throughout the study period which spanned the years between 1964 and 1996 no irrigation was performed precipitation was left unmodified from the measured values while the model was run over sub daily time steps calibration and validation used yearly summations in order to match the format of available field data 2 2 3 site 3 olive orchard experiment in cordoba spain data used to build calibrate and validate a model of this orchard was obtained from the paper by taguas et al 2011 the study site is an olive planted microcatchment 6 1ha in size located in the south west of the province of cordoba spain 37 4 n 4 8 w with a mean elevation of 239 m and mean slope of 15 the soil is cambisol a loamy sand soil with an organic matter content of 1 6 and a bulk density of 1 61 g cmÀÜ3 olive trees were planted in 1999 with 7 m of space between each tree rainfall runoff and sediment loads were recorded from may 2005 to february 2008 at daily timesteps no irrigation was applied so all water input was from rainfall 2 3 sensitivity analysis after integrating rzwqm and gleams a sensitivity analysis was performed on the integrated rzwqm sed model to determine which variables have the greatest influence on modeled surface water flow and sedimentation in order to properly use a model it is necessary to conduct a sensitivity analysis for the input parameters a sensitivity analysis identifies factors or groups of factors most responsible for variation in model output and thus most responsible for uncertainty in the model s prediction particular attention was paid to the variables that are coefficients in the governing equation which do not correspond to a physical measurement a two stage sensitivity analysis was performed separately for the variables effecting surface water runoff and the variables effecting sediment runoff the first stage utilized a morris style one at a time analysis to identify variables with no influence following that a sobol sensitivity analysis was performed on the remaining variables to quantify their influence and determine if there were any interaction between pairs of variables that were not apparent in the single variable analysis knowledge gained from this sensitivity analysis was used to refine the integrated model during the calibration and validation so that only the variables of greatest import were calibrated while those of little import were left fixed for runoff residual and saturated water content along with brooks corey bubbling pressure had the greatest influence universal soil loss equation factors and manning s n showed the greatest influence for modeled soil loss two generalized models were built for sensitivity analysis both based on the davis alfalfa experiment data one of the sites had the simulated alfalfa while the other was bare soil and otherwise they were identical sensitivity analysis results for the two sites were similar enough that only the results from the planted site model are presented with any differences between the two noted surface water runoff is the main driver sediment loss therefore the rzwqm parameters of most concern are those that effect infiltration and thus directly affect calculated runoff all variables related to infiltration are listed in table 1 most of them can be measured in the field or by laboratory analysis of soil samples but some like ct eps and lambda are abstract variables with no true relationship to variables that can be measured in the field or laboratory the variables of interest for the gleams sedimentation routine are listed in table 2 aside from the slope profile which can be measured in the field the most interesting sedimentation variables are the usle c p and n factors and possibly the specific surface area of clay particles the latter was included primarily because it is difficult to accurately measure therefore it is imperative to know how strongly its value effects sediment flow 2 4 sensitivity analysis methods 2 4 1 one at a time morris the oldest and most widely used sensitivity analysis method is the morris one at a time method oat morris 1991 this method starts with a default value for each variable and then modifies a single variable per model run with all other variables set to their default value oat is quick to run and easy to implement unfortunately there are many problems with relying on oat alone underlying oat are several fundamental assumptions that might not be correct for complex models such as the assumptions of model linearity and total variable independence furthermore oat sensitivity analysis cannot sample the whole problem space if all variables are independent and the domain is normalized to the unit hyper cube then oat will only sample within the unit hyper sphere as a result with two variables oat can sample 78 of the domain with twelve variables oat can only sample 0 0326 of the domain 2 4 2 sobol sobol sensitivity analysis also known as the variance method samples the whole domain and quantifies the total influence of each variable singularly as well as the effect of multi variable interactions sobol 2001 domain sampling can be done either using a simple monte carlo approach latin hyper cube sampling or a sobol sequence sobol 1967 the latter approach was used in order to sample the domain as completely as possible while still maintaining pseudo randomness and requiring less model runs compared to the other methods 2 4 3 calibration the design analysis kit for optimization and terascale applications dakota adams et al 2013 package developed at sandia national labs was used for automated calibration of each model against measured data in a two stage process first surface water flow was calibrated by modifying the rzwqm variables shown by the sensitivity analysis to influence runoff then the sediment model was calibrated using the rzwqm parameter values found in step one and varying the influential sedimentation parameters identified during sensitivity analysis optimization was performed using a global gradient free genetic algorithm eddy and lewis 2001 included with the dakota package with the following parameters multipoint parameterized binary 2 crossover rate 0 8 mutation scale 0 1 and shrinkage percentage 0 9 2 4 4 validation the davis alfalfa trial was irrigated via flood irrigation the field trial included two neighboring blocks of planted alfalfa that were individually monitored for water sediment and chemical runoff over two years one block was used for calibration over the whole study period while the other block was used for validation due to the imperfect support of flood irrigation in rzwqm input water was hand calibrated to match measured output flows which isolated the sediment sub model from any errors that might arise in the rzwqm runoff calculations unlike the alfalfa trial the other two sites used for calibration and validation only had data available for a single field therefore the model was calibrated against the first half of available data from each of the two sites and validated against the remaining data the treynor site model was calibrated to the years 1964 1978 and was then validated against the remaining years the spanish olive model was calibrated to the first two years and then validated against the last two years of data both the treynor corn trial and the spanish olive trial were rain irrigated only therefore rzwqm parameters were calibrated to measured outflow for a given time period using measured precipitation then these parameters were validated against the other time period to provide an indication of the performance of the rzwqm runoff calculations 2 4 5 results and discussion previous sensitivity analyses for either rzwqm or gleams did not target the parameters of interest to this project for example a sensitivity analysis of gleams by cryer et al cryer and havens 1999 using a factorial design technique but it focused on solute pesticide transport and ignored sediment transport persicani 1996 ran a sensitivity analysis on gleams mouse tetrans and hydrus but only used the morris method wedwick et al 2001 performed both a morris and monte carlo sensitivity analysis on a irrigation extension of gleams called gleams ir but it also did not investigate sedimentation ahmed et al 2007 performed a morris sensitivity analysis then calibration and validation of rzwqm on two sites in ontario canada chinkuyu et al 2004 looked at both gleams and rzwqm with a focus on seepage zones and found that saturated hydraulic conductivity field capacity and rooting depth were the most sensitive rzwqm parameters 2 5 rzwqm sensitivity analysis results initial oat analysis of the variables associated with infiltration showed no response for either study site for the following 1 3 and 1 10 bar field capacity wilting point the second intercept on the k h curve and lateral hydraulic conductivity see fig 2 the exponent for the k h curve had a linear response while the remaining variables displayed a non linear response results from the sobol sequence runs showed no visual pattern fig 3 oat analysis showed that the residual water content saturated water content and bubbling pressure from the brooks corey equation had the highest influence for both models followed by the saturated hydraulic conductivity and the non brooks corey bubbling pressure none of the total order results show a dominant influence total order 0 8 analysis of second order effects revealed minor variable interaction effects between residual and saturated water content and between residual water content and brooks corey bubbling pressure for both sites these effects were more pronounced when the modeled site was bare soil rather than a planted field 2 6 gleams sensitivity analysis results there was no evidence that the specific surface area of clay particles sscly had any effect on sediment output the usle parameters cfact pfact and ksoil had an expected positive linear relationship with soil loss up to a ceiling where maximum output was reached and increasing the variable values no longer had an effect fig 4 this ceiling was model dependent and was only apparent on the unplanted site manning s n nfact showed the opposite response constant sediment flow from zero nfact to a model dependent threshold then a quick exponential decay to zero sediment flow no amount of surface roughness that still allows for overland flow should totally eliminate sediment transport therefore manning s n becomes a bit more complex as the variable is not sensitive for most lower values then becomes highly sensitive as the resulting sediment transport is reduced then becomes unrealistic thankfully the region where sediment transport is reduced is at very high values of manning s n which far exceed even estimates for native woodland with dense underbrush for most realistic values the nfact variable is not sensitive scatter plots from sobol runs fig 5 showed similar results the plots of usle factors filled in the area under the line formed in the oat analysis manning s n behaved similarly filling in the space below a more well defined decay curve 2 6 1 site 1 alfalfa field experiment in davis california water runoff was hand calibrated to measured data by modifying the amount of water input while keeping the rzwqm parameters set at constant conservative values this isolates the sediment routine so that the accuracy of bulk sediment runoff and mass of sorbed chemicals can be assessed in an annual field environment even with the runoff hand optimized sediment flow results were not that good with over 100 average error fig 6 and a negative nash sutcliffe coefficient there is minimal difference in sediment flow from one event to the next with all flows clustering tightly around the mean while the sensitivity analysis of the sediment model did show an expected high sensitivity to water input the differences in water input given the other parameters resulted in only minimal change to sediment output the lack of significant variation in modeled sediment output given the range of water flows might not be as problematic as it the first appear however the natural variability might depend on a process that is not or cannot be modeled for example the irrigation on 8 29 2012 had around four times as much water as any other irrigation event yet the measured sediment was one of the lowest values in the study fig 6 the next irrigation event 181 days later had the highest sediment runoff despite having only an average water input on a more positive note sediment sorbed pesticide results were visually better than the davis alfalfa results with predicted values tracking measured values rather well the 2 26 2013 diuron sample was the only one that showed an extreme spread between measured and modeled fig 7 given how large the measured mass was on this date compared to following dates it might indicate some sort of measurement error when that sample is removed the average percent error drops to 59 and the nash sutcliffe coefficient becomes a very strong 0 74 the chlorpyrifos data have no obvious outliers and a respectable nash sutcliffe coefficient of 0 39 fig 8 the average absolute error is high at 720 but drops to 152 with the removal of sample 8 28 2012 which has a 3560 error 2 6 2 site 2 watershed scale corn experiment in treynor ia predictions of water flow were poor for either the calibrated or validated dataset fig 9 with an average error of around 100 and a nash sutcliffe coefficient of 0 5 to 0 3 depending the removal of possible outliers a nash sutcliffe coefficient less than one indicates that the model is a worse predictor for the validation dataset than a simple average of the calibration dataset in this case poor model performance could stem from the fact that validation and calibration used annual measured data compared to a summation of individual rzwqm calculated events for that year care should be taken when using rzwqm for such long time periods since the lack of individual runoff events to calibrate against makes even slight errors compound over time as with the water flow results sediment flow predictions fig 10 also had a 90 100 average absolute error depending on removal of possible outliers the nash sutcliffe coefficient was around 0 indicating that the model is no better at prediction that using the raw average it is noteworthy that the range of modeled values is much narrower than the range of measured values indicating that the extremes occurring in the natural world have been muted toward the mean by the model 2 6 3 site 3 olive orchard experiment in cordoba spain the spanish olive model results show an average percent error of over 100 and validated nash sutcliffe coefficients for both water and sediment flows are less than zero figs 11 14 3 conclusions the integrated rzwqm sed model developed in this study performs best on field sized areas over time periods ranging from a single runoff event to an entire growing season modeled water runoff is highly sensitive to the residual and saturated water content of the soil along with the brooks corey bubbling pressure modeled sediment runoff is highly sensitive to the usle factors and for high values of manning s n calculated flow and sediment loads for the validation datasets are often no better than using an average of the calibration dataset this can be perfectly acceptable for some modeling problems such as looking at the impact of changing management practices so long as the overall change in the calculated average is used for broader decision making and not predictions based on individual storm events tracking sorbed chemicals off site is far more accurate than bulk sediment and water flow calculations this is likely due to the limited mass available for runoff in the top soil layer muting extreme events one caveat in the pesticide flow calculations is that rzwqm seems to have a longer tail of out flowing chemical mass compared to measured values this might be due to the governing equations themselves or an artifact of using the average mass present in the first centimeter of soil rather than a deeper surface crust concentration the integrated model generated by this study fills a previously empty niche in the agro hydrology model toolbox it is an agricultural model that tracks offsite sediment and solute flow along with standard farm processes like vadose zone hydrology plant growth kinetics crop management processes nutrient cycling and other soil chemical processes rzwqm sed compares well against other similar models for assessing field scale agricultural runoff chen et al 2017 while this collection of attributes makes the integrated rzwqm sed model fairly unique in the agricultural modeling world there is still ample room for improvement future work will include investigation into the precise effects of having a fixed surface layer of soil and more broadly detailed comparisons with other sediment models over the same datasets an agricultural field process model with support for chemically sorbed sediment is a needed tool for many classes of problems rzwqm sed works for enough problems that previously lacked a proper tool to be of interest to the wider community but there are still many improvements that must be made with respect to accuracy of sediment load predictions and utility over a range of spatial scales that additional research should be conducted into the relative performance of more complex physics based models and governing equations acknowledgements we would like to thank the california department of pesticide regulation contract 11 c0090 and the usda agricultural research service for their assistance and invaluable input appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 016 software data availability the most current version of the rzwqm model with gleams integration rzwqm sed can be downloaded for free at https www ars usda gov research software download softwareid 412 technical support contact rzwqmsupport ars usda gov operating system windows xp and later programming language fortran latest version 3 00 01 release date oct 20 2015 4 03pm a zip archive 156 mb of the source code model runs and data outputs used in this paper can be downloaded by reviewers at http purwebgis ucdavis edu rzwqm gleams zip 
26334,sediment transport from agricultural fields to native waterways is a significant pollution vector not just for the bulk sediment but also for additional mass of pesticides traveling offsite that are sorbed to soil particles existing field scale models that track plant growth as well as the fate and transport of applied pesticides lack an integrated sediment transport component this study sought to address this lack of available modeling tools for researchers and regulators by integrating the sediment and surface flow components of groundwater loading effects of agricultural management systems gleams model into the mature root zone water quality model rzwqm to create a derivative model named rzwqm sed previous research identified rzwqm as a quick running agricultural field scale model that accurately estimated offsite transport of solutes unlike other well performing field scale agricultural models the full source code of rzwqm was available for modification and extension however rzwqm lacked a sediment component and thus could not measure all pollutants moving offsite gleams sedimentation was chosen for integration due to its well documented history compatibility with the rzwqm codebase and source code availability sensitivity analysis of the rzwqm runoff variables showed that the residual water content saturated water content and bubbling pressure from the brooks corey equation had the highest influence for rzwqm followed by the saturated hydraulic conductivity and the non brooks corey bubbling pressure analysis of gleams variables showed the most significant variables are the usle parameters cfact pfact ksoil and manning s n the latter variable only showed sensitivity at very high surface roughness while the usle parameters had a linear relationship over the entire domain the integrated model was calibrated and validated using multiple real world datasets spanning ranges of space and time the final model performed well in the primary task of predicting the mass of sorbed chemicals in the tailwater nash sutcliffe coefficient 0 3 keywords rzqwm gleams sediment modeling model development 1 introduction sediment runoff is a significant environmental problem that negatively impacts native ecosystems the parent soil column and manmade hydrologic infrastructure in addition to the physical problems resulting from the sedimentary soil particles themselves agricultural sediment runoff is more problematic due to the presence of toxic chemicals sorbed to the mobile sediment particles in order to evaluate different best management practices that seek to minimize sediment and sorbed chemical runoff from agricultural land uses it is imperative to have a model that tracks hydrologic processes plant growth kinetics bulk soil movement and solute chemistry in a unified setting existing models that operate on the spatial scale of a single field are often incomplete lacking one or more of the above processes this study seeks to alleviate this deficit by adding an erosion component to a widely used field scale model that currently lacks it the new integrated model is tested for sensitivity and run using input from multiple real world datasets to determine the optimal time and space scales for the model and the overall utility of the model sediment models like any other computational modeling of natural systems can be classified as empirical conceptual or physical the universal soil loss equation usle and its derivatives are classically empirical and are thus computationally quick examples of conceptual sediment models include agnps young and robert 1987 emss vertessy et al 2001 lascam viney and sivapalan 1999 and swrrb arnold 1990 these models tend to be perform best for large regions catchments and above over long time scales some sediment models claim to be at least partially physically based including answers beasley et al 1980 guest yu et al 1997 hspf bicknell et al 1997 lisem takken et al 1999 and wepp laflen et al 1991 most of these are not purely physical a portion of their calculations depend on empirically based values for instance wepp uses foster s equations for sediment transport calculations it sets the sediment rate per unit width of rill channel to the summation of rill and interrill detachment deposition rates and these rates must be derived from empirical equations based on soil type topography land cover and other factors guest uses the rose equation which includes factors for volumetric flux of water runoff rate rainfall rate rill density available depositional area rill to interrill transfer and the wetted perimeter but it depends on user supplied factors like the rainfall erodibilty parameter and the fraction of streamflow power effective in re entraining sediments answers uses an empirical equation to calculate soil particle detachment and the bedload transport equation to predict the transport of non cohesive grains lisem utilizes grovers govers 1990 rill transport equation which depends on two experimental coefficients that vary depending on the median texture of the soil material current sediment modeling research is focused on complex physical models built using linked partial differential equations solved over a fine 2d or 3d mesh fluid flow is usually modeled using the navier stokes equation or its shallow water 2d version most of these complex models focus on relatively deep flows in river channels li et al 2017 or estuaries lajaunie salla et al 2017 and therefore might not be as effective for the shallow overland flow found on farm fields those that do focus on shallow water flow li and duffy 2011 still result in a model that is hard to couple to a farm process model as it would be easier to convert the governing equations in the farm model to partial differential equations that are added to the sediment model then solved at its native timestep not only is this a significant undertaking the resulting model must have all new agricultural functions validated against both measured data and the results of the model that donated the governing equations lastly afan et al 2015 and thompson et al 2016 sidestepped the empirical conceptual physical categories and used an artificial neural network trained on daily sediment and flow data to predict future sediment transport given flow data while this technique produces good sediment flow results it would require large training datasets for each specific agricultural field that is studied and thus isn t as useful for modeling what if scenarios for arbitrary fields unfortunately the sediment models listed above lack the robust plant growth kinetics soil chemistry and pesticide fate and transport modules that are present in the root zone water quality model rzwqm ahuja et al 2000 and are necessary to accurately account for several processes which affect total pesticide runoff rzwqm is a mechanistic model designed to simulate plant growth and the movement of water nutrients and pesticides in an agricultural system the model has been used around the world to among other things model agricultural vadose zone water movement xian et al 2017 optimize irrigation timing kisekka et al 2017 and assess soil effects on irrigation sun et al 2016 recently it has been enhanced by improvements to the pesticide sub model which now includes detailed algorithms for simulating pesticide transport and fate in four compartments crop foliage crop residues soil surface and soil sub surface or root zone the current version of rzwqm compares quite well against other heavily used agricultural field scale models for real world applications zhang and goh 2015 while rzwqm is a well studied agricultural process model that has been heavily used for plant growth kinetics and solute transport it unfortunately lacks a sediment runoff component to alleviate this gap in sediment modeling rzwqm and gleams two models with complementary capabilities were merged to form a unified model expanding a widely used field scale agricultural model like rzwqm to include solute sorbed sediment runoff modeling will allow researchers and regulators to more accurately account for all edge of field runoff by using these with well tested easy to use quick executing models for both the agricultural processes and the sediment runoff processes the final joint model will be very approachable for a wide variety of people already familiar with rzwqm and gleams and allow for multi decade scenarios and monte carlo runs that require a large number of model executions the need for a robust but accessible and quick unified model motivated our decision to incorporate the gleams sedimentation routines into rzwqm 2 materials methods 2 1 integration of rzwqm and gleams 2 1 1 rzwqm rzwqm is a one dimensional vertical model with the ability to discretize the soil column into up to twelve different user defined uniform layers internally the model uses 1 cm thick layers for numerical modeling the major processes of plant growth soil chemistry nutrients pesticides site management and evapotranspiration operate on a daily time scale while heat transport water balance solute transport snowpack dynamics and chemical uptake operate on a sub hourly time scale infiltration is modeled using a green ampt equation heber green and ampt 1911 modified to include surface crust simulation based on the work of bouwer 1969 morel seytoux and khanji 1974 and brakensiek and onstad 1977 post infiltration movement of water through the soil column is calculated using a slightly modified brooks corey brooks and corey 1964 equation to quantify the relationship between soil water content and the matric suction when surface water application exceeds the maximum soil infiltration rate runoff is produced with a quantifiable runoff depth total runoff is calculated by multiplying the runoff depth by the field area surface water runoff volume is the most significant variable for sediment loss therefore the rzwqm parameters of most concern are those that effect infiltration and thus directly affect calculated runoff most of the variables listed in table 1 can be measured in the field or via laboratory analysis of soil samples but some like ct eps and lambda are abstract variables with no true relationship to a field or laboratory measured 2 1 2 gleams the gleams model was chosen for the sediment component because of its well documented history of successful use its minimal requirements for input variables beyond those already required by rzwqm source code availability and compatibility with rzwqm and because it requires minimal computation time per runoff event gleams leonard et al 1987 is an extension of the creams model knisel and douglas mankin 2012 and was developed during the 1980s at the u s department of agriculture agricultural research service gleams models sediment movement as a 1d horizontal set of linked reaches with the sediment loss of each reach governed by the universal soil loss equation usle wischmeier 1976 modified for storm by storm modeling the universal soil loss equation usle wischmeier 1976 is an empirical model that forms the basis of many current sediment models in this equation soil loss is calculated on an annual basis by the multiplication of six factors rainfall erosivity factor soil erodibility factor flow length slop angle crop cover management factor and conservation factor representing five physical system attributes rainfall soil erodibility slope and length of the flowline and land cover these factors are derived from a regression analysis of field research site data subsequent models like the revised universal soil loss equation rusle renard et al 1991 extended the usle to account for some seasonal variation and sub annual time steps perfect m littleboy 1992 creams knisel 1980 and creams successor gleams leonard et al 1987 also utilize a version of the usle modified for sub daily time steps erosion is calculated daily for both interrill and rill areas with transport and deposition occurring during overland flow channel flow and in an optional impoundment parameters include the slope and length of each channel and overland flow segment manning s n and usle contouring soil erodibility and cover management parameters these usle factors cannot be measured in the field ideally they can be obtained from published tables for sites with similar soil crops and management practices the gleams sediment module requires the following data for each runoff event bulk density of soil particles the field s acreage and length to width ratio average temperature total rainfall excess rain intensity of excess rain and the proportion of clay silt sand and organic matter in the soil during initialization parameters that are shared between rzwqm and the sediment modules such as soil composition and field geometry are set by rzwqm to be later used by the sediment component parameters specific to the sediment component are read from a dedicated input file the gleams sediment routine is called from rzwqm whenever a precipitation or irrigation event results in surface runoff gleams then calculates the bulk soil loss and outputs the results to five text files one file is a detailed output log shared with the parent code base in addition the sediment component writes a readily parsable table of output values with one row for each day that runoff occurred to each of four different files one for water and sediment flow and one for each of the possible pesticides to track sorbed solute flow off field a maximum of three pesticides can be tracked each row of water and sediment flow output contains the calculated surface water runoff total sediment runoff expressed in both tons per hectare and volumetric concentration and sediment loss for each class of particle size in the integrated rzwqm sed model the calculated sediment output from gleams is then used within rzwqm to estimate the mass of modeled pesticides dissolved in the tailwater as well as the mass of pesticides in different soil bound pools which are distinguished by is the mobility of the solute both base models and the unified model rely on input and output through plain text files rzwqm and gleams are both written in fortran they were compiled for this study on windows 7 using intel fortran and microsoft visual studio currently the unified model is command line only and the parameters of the sediment component can only be set using a plain text file the rzwqm portion of the integrated model can be set up using the existing gui and the sediment input text file can be added to the project directory if the sediment input file is present when the model is run then the gleams sedimentation routine is executed otherwise only the rzqwm routines are executed the next public release of rzwqm is expected to incorporate the sediment component and include a gui input menu for the gleams parameters 2 2 site descriptions three study sites were chosen to test the integrated a two year experimental alfalfa study in davis ca that focused on offsite sediment and solute transport a three year study of an olive orchard in cordoba spain that only focused on sediment flow off field and a three decade study of a corn planted watershed in treynor ia that focused on offsite sediment and water flow fig 1 2 2 1 site 1 alfalfa field experiment in davis california two alfalfa fields 0 27ha each 15 8 m wide by 198 12 m long in davis california were use for the experiments soils in the study consisted of yolo silty loam 35 40 25 sand silt clay mix with a 0 14 slope there were seven border fed cross field flood irrigation events during 2012 and four during 2013 with input and output flow measurements taken every 2min and sediment measurements taken approximately every 30min most of the irrigation events applied around 30 mm of water to the field with one event applying 110 mm rain was negligible during the months when the measurements were made along with sediment sorbed pesticides previously applied to the field were measured in the runoff one trial used chlorpyrifos the other diuron 2 2 2 site 2 watershed scale corn experiment in treynor iowa to model watershed scale effects on a time scale in the decade range this study used annual water and sediment runoff data along with sub daily weather data from the deep loess research station located near treynor iowa the silt loam soils are classified as typic haplorthents and cumulic hapludolls with fine silty mixed mesics and have moderate to moderately rapid permeability average slope is around 8 to 9 percent with a maximum slope of 18 percent the watershed area is 30 4ha corn was grown throughout the study period which spanned the years between 1964 and 1996 no irrigation was performed precipitation was left unmodified from the measured values while the model was run over sub daily time steps calibration and validation used yearly summations in order to match the format of available field data 2 2 3 site 3 olive orchard experiment in cordoba spain data used to build calibrate and validate a model of this orchard was obtained from the paper by taguas et al 2011 the study site is an olive planted microcatchment 6 1ha in size located in the south west of the province of cordoba spain 37 4 n 4 8 w with a mean elevation of 239 m and mean slope of 15 the soil is cambisol a loamy sand soil with an organic matter content of 1 6 and a bulk density of 1 61 g cmÀÜ3 olive trees were planted in 1999 with 7 m of space between each tree rainfall runoff and sediment loads were recorded from may 2005 to february 2008 at daily timesteps no irrigation was applied so all water input was from rainfall 2 3 sensitivity analysis after integrating rzwqm and gleams a sensitivity analysis was performed on the integrated rzwqm sed model to determine which variables have the greatest influence on modeled surface water flow and sedimentation in order to properly use a model it is necessary to conduct a sensitivity analysis for the input parameters a sensitivity analysis identifies factors or groups of factors most responsible for variation in model output and thus most responsible for uncertainty in the model s prediction particular attention was paid to the variables that are coefficients in the governing equation which do not correspond to a physical measurement a two stage sensitivity analysis was performed separately for the variables effecting surface water runoff and the variables effecting sediment runoff the first stage utilized a morris style one at a time analysis to identify variables with no influence following that a sobol sensitivity analysis was performed on the remaining variables to quantify their influence and determine if there were any interaction between pairs of variables that were not apparent in the single variable analysis knowledge gained from this sensitivity analysis was used to refine the integrated model during the calibration and validation so that only the variables of greatest import were calibrated while those of little import were left fixed for runoff residual and saturated water content along with brooks corey bubbling pressure had the greatest influence universal soil loss equation factors and manning s n showed the greatest influence for modeled soil loss two generalized models were built for sensitivity analysis both based on the davis alfalfa experiment data one of the sites had the simulated alfalfa while the other was bare soil and otherwise they were identical sensitivity analysis results for the two sites were similar enough that only the results from the planted site model are presented with any differences between the two noted surface water runoff is the main driver sediment loss therefore the rzwqm parameters of most concern are those that effect infiltration and thus directly affect calculated runoff all variables related to infiltration are listed in table 1 most of them can be measured in the field or by laboratory analysis of soil samples but some like ct eps and lambda are abstract variables with no true relationship to variables that can be measured in the field or laboratory the variables of interest for the gleams sedimentation routine are listed in table 2 aside from the slope profile which can be measured in the field the most interesting sedimentation variables are the usle c p and n factors and possibly the specific surface area of clay particles the latter was included primarily because it is difficult to accurately measure therefore it is imperative to know how strongly its value effects sediment flow 2 4 sensitivity analysis methods 2 4 1 one at a time morris the oldest and most widely used sensitivity analysis method is the morris one at a time method oat morris 1991 this method starts with a default value for each variable and then modifies a single variable per model run with all other variables set to their default value oat is quick to run and easy to implement unfortunately there are many problems with relying on oat alone underlying oat are several fundamental assumptions that might not be correct for complex models such as the assumptions of model linearity and total variable independence furthermore oat sensitivity analysis cannot sample the whole problem space if all variables are independent and the domain is normalized to the unit hyper cube then oat will only sample within the unit hyper sphere as a result with two variables oat can sample 78 of the domain with twelve variables oat can only sample 0 0326 of the domain 2 4 2 sobol sobol sensitivity analysis also known as the variance method samples the whole domain and quantifies the total influence of each variable singularly as well as the effect of multi variable interactions sobol 2001 domain sampling can be done either using a simple monte carlo approach latin hyper cube sampling or a sobol sequence sobol 1967 the latter approach was used in order to sample the domain as completely as possible while still maintaining pseudo randomness and requiring less model runs compared to the other methods 2 4 3 calibration the design analysis kit for optimization and terascale applications dakota adams et al 2013 package developed at sandia national labs was used for automated calibration of each model against measured data in a two stage process first surface water flow was calibrated by modifying the rzwqm variables shown by the sensitivity analysis to influence runoff then the sediment model was calibrated using the rzwqm parameter values found in step one and varying the influential sedimentation parameters identified during sensitivity analysis optimization was performed using a global gradient free genetic algorithm eddy and lewis 2001 included with the dakota package with the following parameters multipoint parameterized binary 2 crossover rate 0 8 mutation scale 0 1 and shrinkage percentage 0 9 2 4 4 validation the davis alfalfa trial was irrigated via flood irrigation the field trial included two neighboring blocks of planted alfalfa that were individually monitored for water sediment and chemical runoff over two years one block was used for calibration over the whole study period while the other block was used for validation due to the imperfect support of flood irrigation in rzwqm input water was hand calibrated to match measured output flows which isolated the sediment sub model from any errors that might arise in the rzwqm runoff calculations unlike the alfalfa trial the other two sites used for calibration and validation only had data available for a single field therefore the model was calibrated against the first half of available data from each of the two sites and validated against the remaining data the treynor site model was calibrated to the years 1964 1978 and was then validated against the remaining years the spanish olive model was calibrated to the first two years and then validated against the last two years of data both the treynor corn trial and the spanish olive trial were rain irrigated only therefore rzwqm parameters were calibrated to measured outflow for a given time period using measured precipitation then these parameters were validated against the other time period to provide an indication of the performance of the rzwqm runoff calculations 2 4 5 results and discussion previous sensitivity analyses for either rzwqm or gleams did not target the parameters of interest to this project for example a sensitivity analysis of gleams by cryer et al cryer and havens 1999 using a factorial design technique but it focused on solute pesticide transport and ignored sediment transport persicani 1996 ran a sensitivity analysis on gleams mouse tetrans and hydrus but only used the morris method wedwick et al 2001 performed both a morris and monte carlo sensitivity analysis on a irrigation extension of gleams called gleams ir but it also did not investigate sedimentation ahmed et al 2007 performed a morris sensitivity analysis then calibration and validation of rzwqm on two sites in ontario canada chinkuyu et al 2004 looked at both gleams and rzwqm with a focus on seepage zones and found that saturated hydraulic conductivity field capacity and rooting depth were the most sensitive rzwqm parameters 2 5 rzwqm sensitivity analysis results initial oat analysis of the variables associated with infiltration showed no response for either study site for the following 1 3 and 1 10 bar field capacity wilting point the second intercept on the k h curve and lateral hydraulic conductivity see fig 2 the exponent for the k h curve had a linear response while the remaining variables displayed a non linear response results from the sobol sequence runs showed no visual pattern fig 3 oat analysis showed that the residual water content saturated water content and bubbling pressure from the brooks corey equation had the highest influence for both models followed by the saturated hydraulic conductivity and the non brooks corey bubbling pressure none of the total order results show a dominant influence total order 0 8 analysis of second order effects revealed minor variable interaction effects between residual and saturated water content and between residual water content and brooks corey bubbling pressure for both sites these effects were more pronounced when the modeled site was bare soil rather than a planted field 2 6 gleams sensitivity analysis results there was no evidence that the specific surface area of clay particles sscly had any effect on sediment output the usle parameters cfact pfact and ksoil had an expected positive linear relationship with soil loss up to a ceiling where maximum output was reached and increasing the variable values no longer had an effect fig 4 this ceiling was model dependent and was only apparent on the unplanted site manning s n nfact showed the opposite response constant sediment flow from zero nfact to a model dependent threshold then a quick exponential decay to zero sediment flow no amount of surface roughness that still allows for overland flow should totally eliminate sediment transport therefore manning s n becomes a bit more complex as the variable is not sensitive for most lower values then becomes highly sensitive as the resulting sediment transport is reduced then becomes unrealistic thankfully the region where sediment transport is reduced is at very high values of manning s n which far exceed even estimates for native woodland with dense underbrush for most realistic values the nfact variable is not sensitive scatter plots from sobol runs fig 5 showed similar results the plots of usle factors filled in the area under the line formed in the oat analysis manning s n behaved similarly filling in the space below a more well defined decay curve 2 6 1 site 1 alfalfa field experiment in davis california water runoff was hand calibrated to measured data by modifying the amount of water input while keeping the rzwqm parameters set at constant conservative values this isolates the sediment routine so that the accuracy of bulk sediment runoff and mass of sorbed chemicals can be assessed in an annual field environment even with the runoff hand optimized sediment flow results were not that good with over 100 average error fig 6 and a negative nash sutcliffe coefficient there is minimal difference in sediment flow from one event to the next with all flows clustering tightly around the mean while the sensitivity analysis of the sediment model did show an expected high sensitivity to water input the differences in water input given the other parameters resulted in only minimal change to sediment output the lack of significant variation in modeled sediment output given the range of water flows might not be as problematic as it the first appear however the natural variability might depend on a process that is not or cannot be modeled for example the irrigation on 8 29 2012 had around four times as much water as any other irrigation event yet the measured sediment was one of the lowest values in the study fig 6 the next irrigation event 181 days later had the highest sediment runoff despite having only an average water input on a more positive note sediment sorbed pesticide results were visually better than the davis alfalfa results with predicted values tracking measured values rather well the 2 26 2013 diuron sample was the only one that showed an extreme spread between measured and modeled fig 7 given how large the measured mass was on this date compared to following dates it might indicate some sort of measurement error when that sample is removed the average percent error drops to 59 and the nash sutcliffe coefficient becomes a very strong 0 74 the chlorpyrifos data have no obvious outliers and a respectable nash sutcliffe coefficient of 0 39 fig 8 the average absolute error is high at 720 but drops to 152 with the removal of sample 8 28 2012 which has a 3560 error 2 6 2 site 2 watershed scale corn experiment in treynor ia predictions of water flow were poor for either the calibrated or validated dataset fig 9 with an average error of around 100 and a nash sutcliffe coefficient of 0 5 to 0 3 depending the removal of possible outliers a nash sutcliffe coefficient less than one indicates that the model is a worse predictor for the validation dataset than a simple average of the calibration dataset in this case poor model performance could stem from the fact that validation and calibration used annual measured data compared to a summation of individual rzwqm calculated events for that year care should be taken when using rzwqm for such long time periods since the lack of individual runoff events to calibrate against makes even slight errors compound over time as with the water flow results sediment flow predictions fig 10 also had a 90 100 average absolute error depending on removal of possible outliers the nash sutcliffe coefficient was around 0 indicating that the model is no better at prediction that using the raw average it is noteworthy that the range of modeled values is much narrower than the range of measured values indicating that the extremes occurring in the natural world have been muted toward the mean by the model 2 6 3 site 3 olive orchard experiment in cordoba spain the spanish olive model results show an average percent error of over 100 and validated nash sutcliffe coefficients for both water and sediment flows are less than zero figs 11 14 3 conclusions the integrated rzwqm sed model developed in this study performs best on field sized areas over time periods ranging from a single runoff event to an entire growing season modeled water runoff is highly sensitive to the residual and saturated water content of the soil along with the brooks corey bubbling pressure modeled sediment runoff is highly sensitive to the usle factors and for high values of manning s n calculated flow and sediment loads for the validation datasets are often no better than using an average of the calibration dataset this can be perfectly acceptable for some modeling problems such as looking at the impact of changing management practices so long as the overall change in the calculated average is used for broader decision making and not predictions based on individual storm events tracking sorbed chemicals off site is far more accurate than bulk sediment and water flow calculations this is likely due to the limited mass available for runoff in the top soil layer muting extreme events one caveat in the pesticide flow calculations is that rzwqm seems to have a longer tail of out flowing chemical mass compared to measured values this might be due to the governing equations themselves or an artifact of using the average mass present in the first centimeter of soil rather than a deeper surface crust concentration the integrated model generated by this study fills a previously empty niche in the agro hydrology model toolbox it is an agricultural model that tracks offsite sediment and solute flow along with standard farm processes like vadose zone hydrology plant growth kinetics crop management processes nutrient cycling and other soil chemical processes rzwqm sed compares well against other similar models for assessing field scale agricultural runoff chen et al 2017 while this collection of attributes makes the integrated rzwqm sed model fairly unique in the agricultural modeling world there is still ample room for improvement future work will include investigation into the precise effects of having a fixed surface layer of soil and more broadly detailed comparisons with other sediment models over the same datasets an agricultural field process model with support for chemically sorbed sediment is a needed tool for many classes of problems rzwqm sed works for enough problems that previously lacked a proper tool to be of interest to the wider community but there are still many improvements that must be made with respect to accuracy of sediment load predictions and utility over a range of spatial scales that additional research should be conducted into the relative performance of more complex physics based models and governing equations acknowledgements we would like to thank the california department of pesticide regulation contract 11 c0090 and the usda agricultural research service for their assistance and invaluable input appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 08 016 software data availability the most current version of the rzwqm model with gleams integration rzwqm sed can be downloaded for free at https www ars usda gov research software download softwareid 412 technical support contact rzwqmsupport ars usda gov operating system windows xp and later programming language fortran latest version 3 00 01 release date oct 20 2015 4 03pm a zip archive 156 mb of the source code model runs and data outputs used in this paper can be downloaded by reviewers at http purwebgis ucdavis edu rzwqm gleams zip 
