index,text
5915,excess nitrogen n poses a risk of aquatic eutrophication and ecosystem degradation to downstream areas however it is poorly investigated in lowland artificial watersheds polders due to their complex hydrological processes this study investigated the n export and retention at all 2539 polders in lake taihu basin china using a nitrogen dynamic model ndp specially developed for polders the response of n export to global climate change air temperature and precipitation and human activities n fertilization in the future 2014 2049 were quantified through scenario simulations the simulation results revealed that these polders have a larger n export coefficient a spatially averaged value of 15 3 kg n ha yr than that of non polder areas 6 7 kg n ha yr mainly due to their intensive agricultural activities and high population density however these polders also showed considerable n retention with estimated retention rates of 52 7 54 6 in model results from the future 2014 2049 human activities n fertilization determined the magnitude of polder n export while global climate change determined the fluctuation of polder n export the estimation of polder n sources sinks and retention capacity at a watershed scale can be used to identify the hotspot of n loss and thus guide decision making to control n loss keywords polder global climate change nitrogen taihu 1 introduction lowland artificial watersheds polders are unique hydrological units with artificial control of runoff and water levels using pumping systems widely located around the aquatic ecosystems seas lakes and rivers worldwide lindenschmidt et al 2009 van der grift et al 2016 although a global map of polder distribution is so far unavailable previous publications revealed a wide distribution of polders in the middle and lower reaches of several large rivers such as the yangtze and mekong rivers in asia the rhine and danube rivers in europe mississippi river in north america etc fig s2 in supporting information excess nutrient export from these polders with intensive agriculture is a major contributor to the severe eutrophication of receiving water bodies huang et al 2017 considering that eutrophication due to excess nutrient loading is a worldwide challenge vinçon leite and casenave 2019 quantifying the contribution of polder nutrient export at a watershed scale would help water managers pinpoint the major nutrient sources of aquatic ecosystems and thus guide management decisions to achieve best management practices in minimizing nutrient loading abouali et al 2017 dudula and randhir 2016 qiu et al 2019 nutrient export from watersheds has been widely investigated using non point source models ouyang et al 2017 such as the soil and water assessment tool swat arnold et al 2012 liu et al 2017 yang et al 2016 the integrated nitrogen in catchments model inca lu et al 2017 wade et al 2002 and the annualized agricultural non point source pollution annagnps model li et al 2015 these studies revealed a consensus on the significant impact of weather conditions e g air temperature and precipitation and human activities e g agricultural fertilization and wastewater treatment on nutrient export hale et al 2015 qu and kroeze 2010 sinha et al 2017 swaney et al 2012 zhang et al 2016 many previous studies further investigated watershed nutrient export in the context of global climate change based on the advances of global climate models gcms on predicting future climate variables in the changing environment kharin et al 2013 marshall and randhir 2008 xu and xu 2012 it was found that future climate change had considerable impacts on watershed nutrient export sinha et al 2017 and was thus a major concern in management practice marshall and randhir 2008 however there have been very few quantitative studies investigating nutrient export from lowland artificial watersheds polders in the context of global climate change and human activities this is mainly because the widely used watershed models e g swat and inca were not well suited in simulating hydrological processes in lowland areas due to the following two facts first none of these models is structurally equipped to determine the flow direction in lowland polders they have a fundamental assumption that the watershed is spatially divided into hydrologic response units hrus or grid cells whereby flow direction is determined based on elevation differences among these hrus cells however lowland polders have flat topography e g nearly identical elevation therefore their flow direction is generally determined by water level rather than elevation differences there is frequent water exchange between surface water and farmlands fig s1 in supporting information second these models do not describe the unique process of artificial drainage e g culvert and flood drainage in polders however there is ample evidence in the literature that they can play a significant role in n transport within polders brauer et al 2014 huang et al 2018 in this context this study aimed to 1 quantify the nitrogen n sources sinks and retention capacity of polders and 2 investigate their future 2014 2049 changes in the context of global climate change air temperature and precipitation and human activities n fertilization lake taihu basin the most developed area in china with a total of 2539 polders was selected as the study area due to its wide distributed polders and severe eutrophication of rivers and lakes a nitrogen dynamic model ndp specifically developed for polders by huang et al 2018 was used to simulate n dynamics for all polders in lake taihu basin the spatial and temporal patterns of n export and retention were investigated the roles of global climate change and human activities on polder n export were identified by comparing scenario simulations based on the scenario simulation results potential strategies to control n export in nutrient management practice were proposed to the best of our knowledge this is the first attempt to investigate n export and retention for polders at a watershed scale under the context of global climate change and human activities 2 materials and methods 2 1 study area and data lake taihu basin 36 895 km2 30 12 32 22 119 03 121 91 is located in the lower reaches of the yangtze river china fig 1 with an annual precipitation of approximately 1 177 mm a total of 28 8 10 627 km2 of the basin is covered by 2539 polders located in the lowland areas the land uses of the polders include paddy land 62 6 dry land 5 0 surface water 7 3 and residential areas 25 1 in water management practice the basin was divided into eight hydraulic zones based on the hydraulic gradient and administrative division implemented by the taihu basin authority of ministry of water resources http www tba gov cn english the lowland areas have a frequent reciprocating flow with their primary water flow direction shown in fig 1 huxi zhexi and taihu were the upstream areas of lake taihu wuchengxiyu yangchengdianmao hangjiahu puxi and pudong were the downstream areas of lake taihu lake taihu basin is one of the most developed and urbanized areas in china many large cities such as shanghai suzhou wuxi and changzhou with millions of population are located within the basin nutrient loading from lake taihu basin has caused severe eutrophication and harmful cyanobacterial blooms of aquatic systems especially lake taihu china s third largest freshwater lake qin et al 2019 a dataset land use population meteorological and water quality data was collected to investigate the n balance within 2539 polders in lake taihu basin the land use data were derived from satellite images in 2010 the population data were obtained from china s sixth national population census in 2010 the meteorological data were collected from seven national weather stations inside near the basin in 2013 and included seven variables of daily precipitation mm daily maximum minimum and average air temperature c daily average humidity and daily average wind speed m s daily sunshine hours h water quality data total nitrogen concentration were collected by water sampling at 99 sites in lake taihu basin in 2013 as the boundary conditions of the model ndp fig 1 2 2 model description polders n dynamics in the context of global climate change were simulated using the ndp model that was specifically developed for polder systems huang et al 2018 the model is a semi distributed model with four spatial units land use types of surface water residential areas dry and paddy lands unlike existing watershed models e g swat ndp describes the polder s unique hydrological processes including water exchange between surface water and farmlands flood and culvert drainage huang et al 2018 the critical processes related to water and n dynamics within between these four spatial units were described at a daily time scale all the processes in ndp can be found in fig s3 supporting information with their corresponding equations provided in table s2 the model was evaluated using a dataset collected from polder jian and achieved a model fit with nash sutcliffe efficiency ranging from 0 43 to 0 48 for total nitrogen concentration fig s5 in supporting information this model performance was acceptable for lowland watersheds with strong human activities when compared with previous case studies on watershed n modeling wellen et al 2015 our field survey in lake taihu basin found that polder jian is a typical lowland polder enclosed by dikes with artificial drainage and a complex ditch pond network therefore it was justified to apply ndp to other polders in this area further details of the ndp model including the conceptual model model implementation main equations and the model evaluation results are provided in the supporting information 2 3 estimating polder nitrogen export and retention 2 3 1 global climate change and human activities in the future to investigate polder n export and retention in the context of global climate change and human activities future changes in three factors were obtained including air temperature precipitation and fertilization amount these three factors were selected because they were widely demonstrated to have significant impacts on n dynamics in lowland areas hale et al 2015 huang et al 2018 air temperature significantly affected n transformation processes such as volatilization denitrification and mineralization precipitation significantly affected n discharge and deposition within the polder system hale et al 2015 human activities affected polder n export through multiple pathways such as agricultural fertilization population change and wastewater treatment among these pathways n fertilization exhibited a dominant contribution 73 3 to the total n sources in a typical polder huang et al 2018 climate change is often the consequence of the combined effects of anthropogenic influences and complex interactions among the atmosphere hydrosphere lithosphere cryosphere and biosphere of the earth system climate system models are effective tools for simulating future climate change in the context of natural and human influences wu et al 2019 from 20 years ago the coupled model intercomparison project cmip combined a handful of global coupled climate models to generate climate information and make it available for scientific research meehl et al 1997 the beijing climate center bcc of the china meteorological administration effectively contributed to cmip5 by running most of the mandatory and optional simulations wu et al 2019 therefore future air temperature and precipitation 2014 2049 in this case study were obtained from the beijing climate center climate system model version 1 bcc csm1 1 xu and xu 2012 the model as a fully coupled global climate carbon model including interactive vegetation and the global carbon cycle wu et al 2013 and has been widely used to investigate china s future climate change xu and xu 2012 two representative concentration pathway scenarios rcp i e rcp2 6 and rcp8 5 were selected to represent possible emission scenarios in the context of economic development technological development energy use population change and land use change rcp8 5 represented a higher emission scenario with a continuously increasing radiative forcing pathway and a high greenhouse gas concentration level rcp2 6 represented a lower emission scenario with a controlled radiative forcing pathway and a low greenhouse gas concentration level temporal dynamics of annual precipitation and daily average air temperature from rcp2 6 and rcp8 5 can be found in the supporting information future fertilization targets were obtained from previous studies on optimizing the n fertilizer application rate in lake taihu basin hofmeier et al 2015 based on the field experiments and investigations in lake taihu basin the recommended n fertilizers for summer rice and winter wheat were 200 230 and 170 180 kg n ha yr respectively without any decline in grain yield hofmeier et al 2015 therefore future n fertilizers for summer rice and winter wheat was reduced to 200 and 170 kg n ha yr compared to 250 and 200 kg n ha yr under conventional n fertilization practices huang et al 2018 2 3 2 scenario simulations to quantify polder nitrogen export and retention based on the developed model ndp four simulations sim present sim rcp2 6 sim rcp8 5 and sim nreduction with different model configurations table 1 were carried out to estimate n export and retention for all 2539 polders in lake taihu basin fig 1 sim present was used to simulate the present n export and retention in 2013 sim rcp2 6 and sim rcp8 5 were used to simulate polder n export and retention in the future 2014 2049 under the emission scenarios of rcp2 6 and rcp8 5 respectively sim nreduction was used to simulate polder n export and retention in the future 2014 2049 in the context of fertilization reduction the fertilization rate had an approximate value of 450 kg n ha yr for agricultural farmlands from local farmers in lake taihu basin huang et al 2018 our survey from local farmers revealed that this fertilization rate can be reduced to approximately 370 kg n ha yr without a significant reduction of agricultural production therefore this fertilization rate 370 kg n ha yr was utilized in the sim nreduction simulation polder n export was quantified using the n export coefficient nec kg n ha yr nec represents the annual n export amount t per unit ha in the study area therefore for polders in lake taihu basin nec can be calculated by dividing the sum of three n export components n export through seepage flood and culvert drainage to the polder area polder n retention was quantified using the n retention rate nrr with a value of 0 100 compared with that of free drainage watersheds polders have larger n retention mainly due to their large surface water area e g ponds and ditches for n retention therefore nrr was calculated in this study using the equation of 1 nout nin 100 where nin t is the annual n amount flowing into the surface water area and nout t is the annual n amount flowing out of the surface water area 3 results 3 1 polder nitrogen export 3 1 1 temporal dynamics the simulation results from present 2013 table 1 showed that the polders in lake taihu basin had an annual n export of 16296 t yr with a spatially averaged nec of 15 3 kg n ha yr this nec 15 3 kg n ha yr for polders was lower than that for the upstream areas of lake taihu basin including both polders and non polder areas 20 4 21 0 kg n ha yr and that for the agricultural watershed kielstau catchment in north germany 50 3 kg n ha yr however this nec value was higher than that in the zhongtian river watershed 6 7 kg n ha yr and that 6 36 kg n ha yr at 60 sites in the us table 2 of the n export in 2013 16296 t 58 7 9561 t of the n export occurred in the rice cropping season jun oct while 41 3 6735 t of the n export occurred in the wheat cropping season nov may seepage flood and culvert drainage contributed an n export amount of 2106 7474 and 6716 t yr respectively n export through culvert drainage had a peak value in february all culverts were manually closed without any culvert drainage during the rice cropping season n export through flood drainage mostly occurred during the rice cropping season and had an extreme peak value in june with high precipitation n export through seepage mostly occurred in the rice cropping season fig 2 in the future the annual n export showed a large fluctuation varying from 6867 to 23074 t yr without a significant increasing or decreasing trend fig 3 a the annual n export under the climate scenario of rcp8 5 showed larger fluctuations a standard deviation of 3584 t yr than that under the climate scenario of rcp2 6 with a standard deviation of 3362 t yr n reduction resulted in a decrease of annually averaged n export from 12876 t yr sim rcp2 6 to 11135 t yr sim nreduction annual n export was positively related to annual precipitation fig s7 in the supporting information 3 1 2 spatial pattern in 2013 pudong had the largest nec 24 0 kg n ha yr among these eight hydraulic zones due to its high population density hangjiahu had the largest annual n export 5743 0 t yr due to its large polder area polders from three upstream zones huxi zhexi and taihu of lake taihu contributed 4270 9 t n yr into the lake which was 11 3 of the lake s external n sources 37815 t yr taihu basin authority 2014 other downstream zones of lake taihu contributed 12024 9 t n yr into the yangtze river the nec values from all four simulations sim present sim rcp2 6 sim rcp8 5 and sim nreduction showed high spatial heterogeneity fig 5 most polders had an nec value of 0 20 kg n ha yr the polders near within several large cities e g shanghai suzhou wuxi and changzhou had a large nec value 30 kg n ha yr mainly due to the large population under the future climate scenario of rcp2 6 and rcp8 5 zhexi z2 and pudong z8 showed relatively high n export with an annually averaged nec higher than 15 kg n ha yr respectively other hydraulic zones had annually averaged nec values between 10 and 15 kg n ha yr however the spatial patterns of the nec values from sim rcp2 6 fig 5 b and sim rcp8 5 fig 5 c were similar indicating the limited impact of global climate change on n export fertilization reduction led to a considerable decrease of nec in all eight hydraulic zones by 0 7 1 7 kg n ha yr although fertilization reduction was applied across all polders the response of polder nec to fertilization reduction varied spatially it is not surprising that fertilization reduction led to a significant decrease of nec in agricultural polders e g polders in zhexi due to the large area of agricultural farmlands however it did not lead to a significant decrease of nec in the polders near within large cities see fig 5 b and d 3 2 polder nitrogen retention 3 2 1 temporal dynamics in the future the annual nrr values from three scenario simulations were higher than 50 implying that n export from these lowland areas could be significantly higher without artificial control of the surface water areas the annually averaged nrr showed a slight decrease from 54 6 to 52 7 due to fertilization reduction fig 3 b there was no significant difference among the annually averaged nrr values from sim rcp2 6 and sim rcp8 5 additionally the nrr was positively related to annual n export fig s7 in the supporting information 3 2 2 spatial pattern in 2013 nrr values among the eight hydraulic zones showed a large difference varying from 53 4 taihu to 64 9 pudong and zhexi both zhexi z2 and pudong z8 showed a relatively high nrr 64 9 compared with that of the other hydraulic zones fig 4 a probably due to the large population density in these two areas it is clear that the spatial pattern of polder nrr fig 6 was similar to that of nec fig 5 implying that polders with a higher nec had a higher nrr fig s7 c 4 discussion 4 1 polders nitrogen sources or sinks it is clear that polders in lake taihu basin were n sources for their surrounding rivers and lakes with a spatially averaged nec value of 15 3 kg n ha yr and had a large contribution 11 3 see section 3 1 2 to the eutrophication of the large lake lake taihu compared with non polder areas in lake taihu basin the polders showed larger n exports as shown in table 2 probably due to their high population density and intensive farming this spatially averaged n export intensity nec 15 3 kg n ha yr for polders in lake taihu basin was also higher compared with that in many watersheds worldwide such as us and baltic sea watersheds with an nec value less than 10 kg n ha yr swaney et al 2012 white et al 2015 polder n export showed large annual variation in the future fig 3 a mainly attributed to the change in precipitation rather than air temperature fig s7 in the supporting information the main n sources included fertilization irrigation precipitation and domestic wastewater estimated based on population number for polders with large agricultural areas fertilization can be the dominant source of n huang et al 2018 however for polders with large residential areas the dominant n source may be domestic wastewater due to their large residential population considering the relatively high n concentration of polders surrounding rivers irrigation has some contribution as a n source for agricultural polders huang et al 2018 the main n sinks included crop harvesting volatilization and denitrification crop harvesting was the most critical n sink within polders its amount was generally smaller than that of n fertilization volatilization and denitrification were important n transformation processes within the polders and were strongly affected by air temperature and water content in the agricultural farmlands 4 2 what is the contribution of polders to nitrogen retention although polders in lake taihu basin were n sources for their surrounding rivers and lakes they had a large n retention rate fig 3 b in lowland polders there are three major pathways for n retention including particulate n settling oxidized n denitrification and n uptake by aquatic plants see ndp s conceptual diagram in the supporting information this study evaluated the polders n retention capacity based on the n retention in the surface water area section 2 3 2 and revealed a large potential in n retention with an nrr value as high as 52 7 54 6 fig 4 b this n retention capacity was slightly higher compared with several reported n removal retention rates 40 50 of wetlands land et al 2013 this is probably due to the following advantages of polders regarding n retention 1 compared with wetlands with water flowing through them lowland polders have extremely stable water flow in surface water e g ponds that can potentially enhance particulate n settling 2 during rainfall events runoff water may be manually retained in ditches or ponds rather than exported into its surrounding rivers such water retention would thus enhance n retention through the processes of particulate n settling denitrification and n uptake by aquatic plants 4 3 implications for water management this case study quantified n export and retention at 2539 polders in lake taihu basin under the context of global climate change and human activities the results and findings from our case study can potentially support decision making in controlling polder n export 1 polder n export can be efficiently decreased by reducing agricultural n fertilization the significant 13 5 decrease in annual n export from 12876 t yr to 11135 t yr fig 3 due to fertilization reduction revealed that polder n export was very sensitive to n fertilization fig 3 a in contrast global climate change had a limited impact on n export see fig 5 b c therefore we suggest paying more attention to fertilization reduction rather than global climate change this conclusion is different from that of a large scale study claiming that future the 21st century changes in precipitation are likely to increase watershed n loading especially in eastern china sinha et al 2017 therefore to better control n export it is helpful to identify a minimal n fertilization amount without any risk of decline in grain yield and farmer income this n fertilization amount is not constant under the context of global climate change or human activities however is particularly important for intensive farming areas such as lake taihu basin because excess use of n fertilizer has been a common practice hofmeier et al 2015 zhao et al 2012 2 regionalized management was critical to control polder n export the simulation results revealed that the nec and nrr had large spatial heterogeneity figs 5 6 and different annual fluctuations among eight hydraulic zones fig 4 a an additional analysis in section 4 supporting information revealed that polder n export was sensitive to precipitation and surface water area but was not sensitive to residential area and population parameters this result implied that both agricultural activities and domestic wastewater have comparable impacts on polder n export therefore the n reduction strategy for each polder should be investigated based on their characteristics including land use population etc in our study area polders can be mainly classified into two types i e agricultural polders and urban polders for agricultural polders with large areas of farmlands proper fertilization strategies would be a primary strategy to reduce n export due to the large contribution of fertilization to n export for urban polders with large populations wastewater was the main source of n export therefore enhancing n removal from wastewater was recommended to reduce n export 3 surface water areas e g ponds and ditches within lowland polders can serve as n retention spots in n management practice n was exported into surrounding rivers mainly through three pathways seepage culvert and flood drainage all these pathways occurred in the surface water area implying that reducing the n concentration in the surface water area can significantly reduce polder n exports to enhance polder n retention several strategies can be implemented such as developing constructed wetlands by increasing macrophyte cover in surface water areas within polders wetlands showed potentials for nutrient retention such as increasing n uptake and enhancing particulate n settling due to the improved stability of hydrodynamic conditions land et al 2013 mitsch et al 2005 vymazal 2007 however it is important to note that n retention in wetlands is not a perfect solution because continuous n retention in wetlands would result in n enrichment and could thus be a potential n source for downstream rivers and lakes through specific pathways such as re suspension and plant decay therefore certain strategies e g plant harvest for the constructed wetlands were suggested to avoid n release to water 4 4 uncertainty analysis modeling nutrient dynamics within lowland watersheds under the context of global climate change is a worldwide challenge a thorough uncertainty analysis was not among the scope of this study however some uncertainty sources in this case study were briefly mentioned for its proper transfer to other case studies the major uncertainties were from the ndp model and the global climate change data that were utilized as model inputs the uncertainties from the ndp model included model structure parameters and input data with further descriptions in huang et al 2018 according to the global climate change data from cmip5 there are 20 models that generate daily climate conditions in the future kharin et al 2013 in this case we chose only one model bcc csm1 1 due to the intensive computation for a single run of 2539 watersheds however it will be helpful to compare the model results n export and nitrogen with those obtained using other model input data in the case of computational advances future studies should investigate and reduce model uncertainty with more available data and advanced methods such as the bayesian modeling framework which is able to combine multi source uncertainties together kelly et al 2019 5 conclusions n export and retention of all 2539 polders in lake taihu basin china were investigated by simulating n dynamics using the ndp model the investigation results revealed that n fertilization determined the amount of n export while global climate change determined the fluctuation of n export polder n retention was positively related to the n export amount to control polder n export fertilization reduction regionalized management and the development of n retention plants in surface water area were recommended this study demonstrated the use of a numerical model ndp in investigating n export and retention for polders at a watershed scale although this study used lake taihu basin as an example the modeling framework and the scenario analysis method can potentially be used in other lowland polders with similar hydrological management worldwide declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the project was financially supported by youth innovation promotion association cas 2019313 national natural science foundation of china 41971138 china postdoctoral science foundation 2019 m651891 and major science and technology program for water pollution control and treatment of china 2017zx07301 001 02 the authors would like to thank china meteorological data sharing service system for providing the measured data for model development appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124428 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5915,excess nitrogen n poses a risk of aquatic eutrophication and ecosystem degradation to downstream areas however it is poorly investigated in lowland artificial watersheds polders due to their complex hydrological processes this study investigated the n export and retention at all 2539 polders in lake taihu basin china using a nitrogen dynamic model ndp specially developed for polders the response of n export to global climate change air temperature and precipitation and human activities n fertilization in the future 2014 2049 were quantified through scenario simulations the simulation results revealed that these polders have a larger n export coefficient a spatially averaged value of 15 3 kg n ha yr than that of non polder areas 6 7 kg n ha yr mainly due to their intensive agricultural activities and high population density however these polders also showed considerable n retention with estimated retention rates of 52 7 54 6 in model results from the future 2014 2049 human activities n fertilization determined the magnitude of polder n export while global climate change determined the fluctuation of polder n export the estimation of polder n sources sinks and retention capacity at a watershed scale can be used to identify the hotspot of n loss and thus guide decision making to control n loss keywords polder global climate change nitrogen taihu 1 introduction lowland artificial watersheds polders are unique hydrological units with artificial control of runoff and water levels using pumping systems widely located around the aquatic ecosystems seas lakes and rivers worldwide lindenschmidt et al 2009 van der grift et al 2016 although a global map of polder distribution is so far unavailable previous publications revealed a wide distribution of polders in the middle and lower reaches of several large rivers such as the yangtze and mekong rivers in asia the rhine and danube rivers in europe mississippi river in north america etc fig s2 in supporting information excess nutrient export from these polders with intensive agriculture is a major contributor to the severe eutrophication of receiving water bodies huang et al 2017 considering that eutrophication due to excess nutrient loading is a worldwide challenge vinçon leite and casenave 2019 quantifying the contribution of polder nutrient export at a watershed scale would help water managers pinpoint the major nutrient sources of aquatic ecosystems and thus guide management decisions to achieve best management practices in minimizing nutrient loading abouali et al 2017 dudula and randhir 2016 qiu et al 2019 nutrient export from watersheds has been widely investigated using non point source models ouyang et al 2017 such as the soil and water assessment tool swat arnold et al 2012 liu et al 2017 yang et al 2016 the integrated nitrogen in catchments model inca lu et al 2017 wade et al 2002 and the annualized agricultural non point source pollution annagnps model li et al 2015 these studies revealed a consensus on the significant impact of weather conditions e g air temperature and precipitation and human activities e g agricultural fertilization and wastewater treatment on nutrient export hale et al 2015 qu and kroeze 2010 sinha et al 2017 swaney et al 2012 zhang et al 2016 many previous studies further investigated watershed nutrient export in the context of global climate change based on the advances of global climate models gcms on predicting future climate variables in the changing environment kharin et al 2013 marshall and randhir 2008 xu and xu 2012 it was found that future climate change had considerable impacts on watershed nutrient export sinha et al 2017 and was thus a major concern in management practice marshall and randhir 2008 however there have been very few quantitative studies investigating nutrient export from lowland artificial watersheds polders in the context of global climate change and human activities this is mainly because the widely used watershed models e g swat and inca were not well suited in simulating hydrological processes in lowland areas due to the following two facts first none of these models is structurally equipped to determine the flow direction in lowland polders they have a fundamental assumption that the watershed is spatially divided into hydrologic response units hrus or grid cells whereby flow direction is determined based on elevation differences among these hrus cells however lowland polders have flat topography e g nearly identical elevation therefore their flow direction is generally determined by water level rather than elevation differences there is frequent water exchange between surface water and farmlands fig s1 in supporting information second these models do not describe the unique process of artificial drainage e g culvert and flood drainage in polders however there is ample evidence in the literature that they can play a significant role in n transport within polders brauer et al 2014 huang et al 2018 in this context this study aimed to 1 quantify the nitrogen n sources sinks and retention capacity of polders and 2 investigate their future 2014 2049 changes in the context of global climate change air temperature and precipitation and human activities n fertilization lake taihu basin the most developed area in china with a total of 2539 polders was selected as the study area due to its wide distributed polders and severe eutrophication of rivers and lakes a nitrogen dynamic model ndp specifically developed for polders by huang et al 2018 was used to simulate n dynamics for all polders in lake taihu basin the spatial and temporal patterns of n export and retention were investigated the roles of global climate change and human activities on polder n export were identified by comparing scenario simulations based on the scenario simulation results potential strategies to control n export in nutrient management practice were proposed to the best of our knowledge this is the first attempt to investigate n export and retention for polders at a watershed scale under the context of global climate change and human activities 2 materials and methods 2 1 study area and data lake taihu basin 36 895 km2 30 12 32 22 119 03 121 91 is located in the lower reaches of the yangtze river china fig 1 with an annual precipitation of approximately 1 177 mm a total of 28 8 10 627 km2 of the basin is covered by 2539 polders located in the lowland areas the land uses of the polders include paddy land 62 6 dry land 5 0 surface water 7 3 and residential areas 25 1 in water management practice the basin was divided into eight hydraulic zones based on the hydraulic gradient and administrative division implemented by the taihu basin authority of ministry of water resources http www tba gov cn english the lowland areas have a frequent reciprocating flow with their primary water flow direction shown in fig 1 huxi zhexi and taihu were the upstream areas of lake taihu wuchengxiyu yangchengdianmao hangjiahu puxi and pudong were the downstream areas of lake taihu lake taihu basin is one of the most developed and urbanized areas in china many large cities such as shanghai suzhou wuxi and changzhou with millions of population are located within the basin nutrient loading from lake taihu basin has caused severe eutrophication and harmful cyanobacterial blooms of aquatic systems especially lake taihu china s third largest freshwater lake qin et al 2019 a dataset land use population meteorological and water quality data was collected to investigate the n balance within 2539 polders in lake taihu basin the land use data were derived from satellite images in 2010 the population data were obtained from china s sixth national population census in 2010 the meteorological data were collected from seven national weather stations inside near the basin in 2013 and included seven variables of daily precipitation mm daily maximum minimum and average air temperature c daily average humidity and daily average wind speed m s daily sunshine hours h water quality data total nitrogen concentration were collected by water sampling at 99 sites in lake taihu basin in 2013 as the boundary conditions of the model ndp fig 1 2 2 model description polders n dynamics in the context of global climate change were simulated using the ndp model that was specifically developed for polder systems huang et al 2018 the model is a semi distributed model with four spatial units land use types of surface water residential areas dry and paddy lands unlike existing watershed models e g swat ndp describes the polder s unique hydrological processes including water exchange between surface water and farmlands flood and culvert drainage huang et al 2018 the critical processes related to water and n dynamics within between these four spatial units were described at a daily time scale all the processes in ndp can be found in fig s3 supporting information with their corresponding equations provided in table s2 the model was evaluated using a dataset collected from polder jian and achieved a model fit with nash sutcliffe efficiency ranging from 0 43 to 0 48 for total nitrogen concentration fig s5 in supporting information this model performance was acceptable for lowland watersheds with strong human activities when compared with previous case studies on watershed n modeling wellen et al 2015 our field survey in lake taihu basin found that polder jian is a typical lowland polder enclosed by dikes with artificial drainage and a complex ditch pond network therefore it was justified to apply ndp to other polders in this area further details of the ndp model including the conceptual model model implementation main equations and the model evaluation results are provided in the supporting information 2 3 estimating polder nitrogen export and retention 2 3 1 global climate change and human activities in the future to investigate polder n export and retention in the context of global climate change and human activities future changes in three factors were obtained including air temperature precipitation and fertilization amount these three factors were selected because they were widely demonstrated to have significant impacts on n dynamics in lowland areas hale et al 2015 huang et al 2018 air temperature significantly affected n transformation processes such as volatilization denitrification and mineralization precipitation significantly affected n discharge and deposition within the polder system hale et al 2015 human activities affected polder n export through multiple pathways such as agricultural fertilization population change and wastewater treatment among these pathways n fertilization exhibited a dominant contribution 73 3 to the total n sources in a typical polder huang et al 2018 climate change is often the consequence of the combined effects of anthropogenic influences and complex interactions among the atmosphere hydrosphere lithosphere cryosphere and biosphere of the earth system climate system models are effective tools for simulating future climate change in the context of natural and human influences wu et al 2019 from 20 years ago the coupled model intercomparison project cmip combined a handful of global coupled climate models to generate climate information and make it available for scientific research meehl et al 1997 the beijing climate center bcc of the china meteorological administration effectively contributed to cmip5 by running most of the mandatory and optional simulations wu et al 2019 therefore future air temperature and precipitation 2014 2049 in this case study were obtained from the beijing climate center climate system model version 1 bcc csm1 1 xu and xu 2012 the model as a fully coupled global climate carbon model including interactive vegetation and the global carbon cycle wu et al 2013 and has been widely used to investigate china s future climate change xu and xu 2012 two representative concentration pathway scenarios rcp i e rcp2 6 and rcp8 5 were selected to represent possible emission scenarios in the context of economic development technological development energy use population change and land use change rcp8 5 represented a higher emission scenario with a continuously increasing radiative forcing pathway and a high greenhouse gas concentration level rcp2 6 represented a lower emission scenario with a controlled radiative forcing pathway and a low greenhouse gas concentration level temporal dynamics of annual precipitation and daily average air temperature from rcp2 6 and rcp8 5 can be found in the supporting information future fertilization targets were obtained from previous studies on optimizing the n fertilizer application rate in lake taihu basin hofmeier et al 2015 based on the field experiments and investigations in lake taihu basin the recommended n fertilizers for summer rice and winter wheat were 200 230 and 170 180 kg n ha yr respectively without any decline in grain yield hofmeier et al 2015 therefore future n fertilizers for summer rice and winter wheat was reduced to 200 and 170 kg n ha yr compared to 250 and 200 kg n ha yr under conventional n fertilization practices huang et al 2018 2 3 2 scenario simulations to quantify polder nitrogen export and retention based on the developed model ndp four simulations sim present sim rcp2 6 sim rcp8 5 and sim nreduction with different model configurations table 1 were carried out to estimate n export and retention for all 2539 polders in lake taihu basin fig 1 sim present was used to simulate the present n export and retention in 2013 sim rcp2 6 and sim rcp8 5 were used to simulate polder n export and retention in the future 2014 2049 under the emission scenarios of rcp2 6 and rcp8 5 respectively sim nreduction was used to simulate polder n export and retention in the future 2014 2049 in the context of fertilization reduction the fertilization rate had an approximate value of 450 kg n ha yr for agricultural farmlands from local farmers in lake taihu basin huang et al 2018 our survey from local farmers revealed that this fertilization rate can be reduced to approximately 370 kg n ha yr without a significant reduction of agricultural production therefore this fertilization rate 370 kg n ha yr was utilized in the sim nreduction simulation polder n export was quantified using the n export coefficient nec kg n ha yr nec represents the annual n export amount t per unit ha in the study area therefore for polders in lake taihu basin nec can be calculated by dividing the sum of three n export components n export through seepage flood and culvert drainage to the polder area polder n retention was quantified using the n retention rate nrr with a value of 0 100 compared with that of free drainage watersheds polders have larger n retention mainly due to their large surface water area e g ponds and ditches for n retention therefore nrr was calculated in this study using the equation of 1 nout nin 100 where nin t is the annual n amount flowing into the surface water area and nout t is the annual n amount flowing out of the surface water area 3 results 3 1 polder nitrogen export 3 1 1 temporal dynamics the simulation results from present 2013 table 1 showed that the polders in lake taihu basin had an annual n export of 16296 t yr with a spatially averaged nec of 15 3 kg n ha yr this nec 15 3 kg n ha yr for polders was lower than that for the upstream areas of lake taihu basin including both polders and non polder areas 20 4 21 0 kg n ha yr and that for the agricultural watershed kielstau catchment in north germany 50 3 kg n ha yr however this nec value was higher than that in the zhongtian river watershed 6 7 kg n ha yr and that 6 36 kg n ha yr at 60 sites in the us table 2 of the n export in 2013 16296 t 58 7 9561 t of the n export occurred in the rice cropping season jun oct while 41 3 6735 t of the n export occurred in the wheat cropping season nov may seepage flood and culvert drainage contributed an n export amount of 2106 7474 and 6716 t yr respectively n export through culvert drainage had a peak value in february all culverts were manually closed without any culvert drainage during the rice cropping season n export through flood drainage mostly occurred during the rice cropping season and had an extreme peak value in june with high precipitation n export through seepage mostly occurred in the rice cropping season fig 2 in the future the annual n export showed a large fluctuation varying from 6867 to 23074 t yr without a significant increasing or decreasing trend fig 3 a the annual n export under the climate scenario of rcp8 5 showed larger fluctuations a standard deviation of 3584 t yr than that under the climate scenario of rcp2 6 with a standard deviation of 3362 t yr n reduction resulted in a decrease of annually averaged n export from 12876 t yr sim rcp2 6 to 11135 t yr sim nreduction annual n export was positively related to annual precipitation fig s7 in the supporting information 3 1 2 spatial pattern in 2013 pudong had the largest nec 24 0 kg n ha yr among these eight hydraulic zones due to its high population density hangjiahu had the largest annual n export 5743 0 t yr due to its large polder area polders from three upstream zones huxi zhexi and taihu of lake taihu contributed 4270 9 t n yr into the lake which was 11 3 of the lake s external n sources 37815 t yr taihu basin authority 2014 other downstream zones of lake taihu contributed 12024 9 t n yr into the yangtze river the nec values from all four simulations sim present sim rcp2 6 sim rcp8 5 and sim nreduction showed high spatial heterogeneity fig 5 most polders had an nec value of 0 20 kg n ha yr the polders near within several large cities e g shanghai suzhou wuxi and changzhou had a large nec value 30 kg n ha yr mainly due to the large population under the future climate scenario of rcp2 6 and rcp8 5 zhexi z2 and pudong z8 showed relatively high n export with an annually averaged nec higher than 15 kg n ha yr respectively other hydraulic zones had annually averaged nec values between 10 and 15 kg n ha yr however the spatial patterns of the nec values from sim rcp2 6 fig 5 b and sim rcp8 5 fig 5 c were similar indicating the limited impact of global climate change on n export fertilization reduction led to a considerable decrease of nec in all eight hydraulic zones by 0 7 1 7 kg n ha yr although fertilization reduction was applied across all polders the response of polder nec to fertilization reduction varied spatially it is not surprising that fertilization reduction led to a significant decrease of nec in agricultural polders e g polders in zhexi due to the large area of agricultural farmlands however it did not lead to a significant decrease of nec in the polders near within large cities see fig 5 b and d 3 2 polder nitrogen retention 3 2 1 temporal dynamics in the future the annual nrr values from three scenario simulations were higher than 50 implying that n export from these lowland areas could be significantly higher without artificial control of the surface water areas the annually averaged nrr showed a slight decrease from 54 6 to 52 7 due to fertilization reduction fig 3 b there was no significant difference among the annually averaged nrr values from sim rcp2 6 and sim rcp8 5 additionally the nrr was positively related to annual n export fig s7 in the supporting information 3 2 2 spatial pattern in 2013 nrr values among the eight hydraulic zones showed a large difference varying from 53 4 taihu to 64 9 pudong and zhexi both zhexi z2 and pudong z8 showed a relatively high nrr 64 9 compared with that of the other hydraulic zones fig 4 a probably due to the large population density in these two areas it is clear that the spatial pattern of polder nrr fig 6 was similar to that of nec fig 5 implying that polders with a higher nec had a higher nrr fig s7 c 4 discussion 4 1 polders nitrogen sources or sinks it is clear that polders in lake taihu basin were n sources for their surrounding rivers and lakes with a spatially averaged nec value of 15 3 kg n ha yr and had a large contribution 11 3 see section 3 1 2 to the eutrophication of the large lake lake taihu compared with non polder areas in lake taihu basin the polders showed larger n exports as shown in table 2 probably due to their high population density and intensive farming this spatially averaged n export intensity nec 15 3 kg n ha yr for polders in lake taihu basin was also higher compared with that in many watersheds worldwide such as us and baltic sea watersheds with an nec value less than 10 kg n ha yr swaney et al 2012 white et al 2015 polder n export showed large annual variation in the future fig 3 a mainly attributed to the change in precipitation rather than air temperature fig s7 in the supporting information the main n sources included fertilization irrigation precipitation and domestic wastewater estimated based on population number for polders with large agricultural areas fertilization can be the dominant source of n huang et al 2018 however for polders with large residential areas the dominant n source may be domestic wastewater due to their large residential population considering the relatively high n concentration of polders surrounding rivers irrigation has some contribution as a n source for agricultural polders huang et al 2018 the main n sinks included crop harvesting volatilization and denitrification crop harvesting was the most critical n sink within polders its amount was generally smaller than that of n fertilization volatilization and denitrification were important n transformation processes within the polders and were strongly affected by air temperature and water content in the agricultural farmlands 4 2 what is the contribution of polders to nitrogen retention although polders in lake taihu basin were n sources for their surrounding rivers and lakes they had a large n retention rate fig 3 b in lowland polders there are three major pathways for n retention including particulate n settling oxidized n denitrification and n uptake by aquatic plants see ndp s conceptual diagram in the supporting information this study evaluated the polders n retention capacity based on the n retention in the surface water area section 2 3 2 and revealed a large potential in n retention with an nrr value as high as 52 7 54 6 fig 4 b this n retention capacity was slightly higher compared with several reported n removal retention rates 40 50 of wetlands land et al 2013 this is probably due to the following advantages of polders regarding n retention 1 compared with wetlands with water flowing through them lowland polders have extremely stable water flow in surface water e g ponds that can potentially enhance particulate n settling 2 during rainfall events runoff water may be manually retained in ditches or ponds rather than exported into its surrounding rivers such water retention would thus enhance n retention through the processes of particulate n settling denitrification and n uptake by aquatic plants 4 3 implications for water management this case study quantified n export and retention at 2539 polders in lake taihu basin under the context of global climate change and human activities the results and findings from our case study can potentially support decision making in controlling polder n export 1 polder n export can be efficiently decreased by reducing agricultural n fertilization the significant 13 5 decrease in annual n export from 12876 t yr to 11135 t yr fig 3 due to fertilization reduction revealed that polder n export was very sensitive to n fertilization fig 3 a in contrast global climate change had a limited impact on n export see fig 5 b c therefore we suggest paying more attention to fertilization reduction rather than global climate change this conclusion is different from that of a large scale study claiming that future the 21st century changes in precipitation are likely to increase watershed n loading especially in eastern china sinha et al 2017 therefore to better control n export it is helpful to identify a minimal n fertilization amount without any risk of decline in grain yield and farmer income this n fertilization amount is not constant under the context of global climate change or human activities however is particularly important for intensive farming areas such as lake taihu basin because excess use of n fertilizer has been a common practice hofmeier et al 2015 zhao et al 2012 2 regionalized management was critical to control polder n export the simulation results revealed that the nec and nrr had large spatial heterogeneity figs 5 6 and different annual fluctuations among eight hydraulic zones fig 4 a an additional analysis in section 4 supporting information revealed that polder n export was sensitive to precipitation and surface water area but was not sensitive to residential area and population parameters this result implied that both agricultural activities and domestic wastewater have comparable impacts on polder n export therefore the n reduction strategy for each polder should be investigated based on their characteristics including land use population etc in our study area polders can be mainly classified into two types i e agricultural polders and urban polders for agricultural polders with large areas of farmlands proper fertilization strategies would be a primary strategy to reduce n export due to the large contribution of fertilization to n export for urban polders with large populations wastewater was the main source of n export therefore enhancing n removal from wastewater was recommended to reduce n export 3 surface water areas e g ponds and ditches within lowland polders can serve as n retention spots in n management practice n was exported into surrounding rivers mainly through three pathways seepage culvert and flood drainage all these pathways occurred in the surface water area implying that reducing the n concentration in the surface water area can significantly reduce polder n exports to enhance polder n retention several strategies can be implemented such as developing constructed wetlands by increasing macrophyte cover in surface water areas within polders wetlands showed potentials for nutrient retention such as increasing n uptake and enhancing particulate n settling due to the improved stability of hydrodynamic conditions land et al 2013 mitsch et al 2005 vymazal 2007 however it is important to note that n retention in wetlands is not a perfect solution because continuous n retention in wetlands would result in n enrichment and could thus be a potential n source for downstream rivers and lakes through specific pathways such as re suspension and plant decay therefore certain strategies e g plant harvest for the constructed wetlands were suggested to avoid n release to water 4 4 uncertainty analysis modeling nutrient dynamics within lowland watersheds under the context of global climate change is a worldwide challenge a thorough uncertainty analysis was not among the scope of this study however some uncertainty sources in this case study were briefly mentioned for its proper transfer to other case studies the major uncertainties were from the ndp model and the global climate change data that were utilized as model inputs the uncertainties from the ndp model included model structure parameters and input data with further descriptions in huang et al 2018 according to the global climate change data from cmip5 there are 20 models that generate daily climate conditions in the future kharin et al 2013 in this case we chose only one model bcc csm1 1 due to the intensive computation for a single run of 2539 watersheds however it will be helpful to compare the model results n export and nitrogen with those obtained using other model input data in the case of computational advances future studies should investigate and reduce model uncertainty with more available data and advanced methods such as the bayesian modeling framework which is able to combine multi source uncertainties together kelly et al 2019 5 conclusions n export and retention of all 2539 polders in lake taihu basin china were investigated by simulating n dynamics using the ndp model the investigation results revealed that n fertilization determined the amount of n export while global climate change determined the fluctuation of n export polder n retention was positively related to the n export amount to control polder n export fertilization reduction regionalized management and the development of n retention plants in surface water area were recommended this study demonstrated the use of a numerical model ndp in investigating n export and retention for polders at a watershed scale although this study used lake taihu basin as an example the modeling framework and the scenario analysis method can potentially be used in other lowland polders with similar hydrological management worldwide declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the project was financially supported by youth innovation promotion association cas 2019313 national natural science foundation of china 41971138 china postdoctoral science foundation 2019 m651891 and major science and technology program for water pollution control and treatment of china 2017zx07301 001 02 the authors would like to thank china meteorological data sharing service system for providing the measured data for model development appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124428 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5916,cutoff walls are widely used to alter groundwater flow and mitigate seawater intrusion in coastal areas while their behavior and performance in aquifers under static oceanic conditions are well established how do they combine with tides to affect groundwater flow and salinity distribution in coastal aquifers remains unclear here we addressed this research question based on physical experiments and numerical simulations cutoff walls were showed to regulate the inland freshwater flow and thus form a sharp waterlevel change in the landside of the cutoff wall as such inland groundwater flow was concentrated in the lower aquifer that inhibited seawater intrusion in the unconfined aquifer subjected to a static sea level under the non tidal condition this modification was enhanced as the cutoff wall went deeper or seaward however the tide pushed the saltwater wedge seaward in comparison with the case under the non tidal condition under this tidal condition the modification of the cutoff wall on saltwater intrusion was no longer evident in both cases under non tidal and tidal conditions the cutoff wall was found to alter the path and travel time of the inland fresh groundwater and seawater and total freshwater storage in the aquifer these results offer significant implications for designing engineering measures to mitigate seawater intrusion and managing groundwater resources in coastal zones keywords cutoff wall tide groundwater flow seawater intrusion unconfined aquifer 1 introduction seawater intrusion swi the movement of seawater into coastal freshwater aquifers commonly occurs in coastal aquifers worldwide bear et al 1999 this is often caused by excessive groundwater extraction in inland areas and sea level rise that decrease seaward hydraulic gradient werner et al 2013 with sea level rise due to global warming swi could be more intensive and thus threaten further coastal fresh groundwater resources luyun et al 2009 to mitigate swi and protect groundwater resources in coastal areas it needs to reduce groundwater extraction increase aquifer recharge and or inhibit the inflow of intruding saltwater construction of subsurface barriers is a technically feasible and effective solution to the swi problem in coastal aquifers therefore subsurface barriers are widely used in coastal areas around the world allow 2011 hasan basri 2001 sugio et al 1987 for example subsurface barriers were used historically in sardinia during the era of the roman empire hanson and nilsson 1986 the u s army crops of engineers designed temporary subsurface barriers to control upstream swi caused by low flow in the mississippi river in 1988 mcanally and pritchard 1997 japan had built about 15 submarine barriers by 2004 and seven of them were adopted to mitigate swi luyun et al 2009 it is approved that subsurface barriers can not only slow down the encroachment of seawater but also behave as subsurface dams to increase the freshwater storage in the coastal areas ishida et al 2011 luyun et al 2009 so far three types of barriers have been proposed kaleris and ziogas 2013 1 the semi pervious subsurface barrier extending from the top to impervious base of an aquifer 2 subsurface dam which has very low permeability and rests on the impervious base of an aquifer blocking only the lower part of the aquifer cross section and 3 cutoff wall which has very low permeability and penetrates into an aquifer to a certain depth blocking only the upper part of the aquifer in comparison with the former two types cutoff walls are more practical and of low cost kaleris and ziogas 2013 experimental and numerical studies have been conducted to examine the effect of cutoff walls on groundwater flow and salinity distribution in coastal aquifers abdoulhalik and ahmed 2017 kaleris and ziogas 2013 luyun et al 2011 kaleris and ziogas 2013 and luyun et al 2011 found that in absence of groundwater extractions effectiveness of a cutoff wall is determined by the wall depth its distance from the coast the groundwater velocity the intensity of freshwater and seawater mixing the conductivity anisotropy and the hydraulic conductivity of the wall luyun et al 2011 conducted laboratory scale investigations and showed that when a cutoff wall is located in an area of swi its protective effect increases with decreasing distance from the coast and increasing penetration depth abdoulhalik and ahmed 2017 examined the performance of cutoff walls in controlling swi in stratified coastal aquifers and the results showed that the soil stratification could reduce the effectiveness of the cutoff wall on mitigation of swi in comparison to homogeneous aquifers while these studies have proved the effectiveness of cutoff walls they predominantly adopted static sea boundary conditions and overlooked oceanic watertable oscillations caused by tides tides are a primary forcing factor that typically exist in coastal environments ataie ashtiani et al 1999 robinson et al 2018 werner et al 2013 it is now well established that the periodic tidal fluctuations can lead to dynamic and complicated groundwater flow and salinity distribution in coastal aquifers 1 tide can induce the fluctuation of inland watertable and enhance mixing of seawater and freshwater brovelli et al 2007 maji and smith 2009 robinson et al 2007a werner et al 2013 yu et al 2019b and 2 tides can induce an seawater circulation termed as upper saline plume usp in the seaward shallow aquifer and affect the saltwater wedge location li et al 2008 mao et al 2006 prieto and destouni 2005 robinson et al 2007b yu et al 2019a although previous studies have uncovered the effect of cutoff walls and tides individually to our best knowledge the combined effect of them on the groundwater flow and salinity distribution in coastal unconfined aquifers remains unclear to fill up this research gap we conducted both laboratory experiments and numerical simulations to address the following key questions 1 how do cutoff walls and tides jointly affect the salinity distribution in coastal unconfined aquifers 2 how groundwater flow and circulation are altered and 3 how important are the penetration depth and location of cutoff walls 2 methodology 2 1 laboratory experiments experiments were conducted in a 7 7 m long 1 2 m high 0 16 m wide flume fig 1 this flume has been successfully used by xin et al 2018 and yu et al 2019a for examining respectively surface water groundwater interactions and swi the flume included three compartments the middle compartment was packed with 1 m height quartz sand to simulate an unconfined coastal aquifer bounded by a sloping beach surface slope 1 2 the aquifer domain is given in fig 1a the two side compartments of the flume were linked to two water tanks respectively containing freshwater landward and saltwater seaward the landside of the aquifer was supplied with freshwater and with a fixed watertable 0 74 m note that the coordinate origin is set at the impervious base and the seaside aquifer as shown in fig 1a at the seaside of the aquifer a tide generator was used to control static or time varying tidal levels under the non tidal condition saltwater was pumped from a seawater reservoir under the flume fig 1b and discharged through an overflow outlet to maintain a constant water level at 0 70 m i e mean sea level msl under the tidal condition a programmable logic controller adjusted automatically the height of the overflow outlet and generated the preset tidal levels in this study we considered a simple sinusoidal tide as follows 1 h t msl a sin 2 π t t where h l is the tidal level at the time t t a l is the tidal amplitude set to 0 075 m and t t is the tidal period set to 240 s during the experiments both the salinity distribution and watertables in the two compartments at the land and sea sides were monitored as the flume was relatively narrow the experimental setup was essentially two dimensional focusing on flow and salinity distribution in the vertical and cross shore section of an unconfined aquifer the used quartz sand was relatively uniform with d 50 median diameter 0 5 mm and d 90 d 10 2 6 d 90 and d 10 are the sizes of sieve pores that 90 and 10 of sands can pass respectively the measured saturated hydraulic conductivity using freshwater and the darcy column test was 3 10 3 m s the porosity of the sand was 0 4 using the imbibition method collins 1961 four base experiments were conducted as follows 1 case 1 without cutoff wall and without tide 2 case 2 with cutoff wall and without tide 3 case 3 without cutoff wall and with tide 4 case 4 with cutoff wall and with tide for cases 2 and 4 the cutoff wall was inserted at the location with x 1 7 m and the penetration depth i e the distance from the cutoff wall bottom to the aquifer surface was 0 9 m the cutoff wall was set up using a polystyrene hard sheet 2 cm in thickness being inserted into the sand to the certain level the gaps between the sheet and two flume s back walls were well sealed to prevent water from seeping through the joint areas during the experiments the saltwater salinity was set to 35 ppt parts per thousand mass fraction with the associated density at 1025 kg m3 to visualize the swi process the seawater was prepared by dissolving 34 g of sodium chloride and 1 g of red food dye in a liter of freshwater density at 1000 kg m3 and salinity at 0 a camera was used to take images to record salinity distributions in the sand flume 2 2 numerical simulations as suggested by previous studies chang and clement 2012 kuan et al 2012 morgan et al 2013 the dye tracking method can only capture a sharp interface between freshwater and seawater to extend the finding from the experiments we also conducted numerical simulations to delineate a freshwater seawater mixing zone and calculate groundwater flow and associated travel time sutra voss and provost 2008 a numerical model was used to simulate the groundwater flow and salinity distribution in the aquifer with different penetration depths and positions of cutoff walls under tidal or non tidal conditions in sutra variably saturated and variable density pore flow is governed by the richards equation and this is further coupled with the convection diffusion equation for solute transport voss and provost 2008 the van genuchten 1980 functions were adopted to describe the relationship between the hydraulic conductivity soil saturation and capillary pressure head in the numerical model the model setup was consistent with the experiments regarding to saturated hydraulic conductivity soil porosity and boundary conditions in particular a constant non tidal cases or time dependent tidal cases and head specified boundary according to the seawater level was set to the seaward boundary a seepage face was allowed to develop along the beach for brevity readers are referred to xin et al 2010 to see details e g governing equations and setup of boundary conditions the mesh sizes were around 0 02 m in length and 0 01 in height note that a refined mesh was used for the area under the beach according to xin et al s 2018 measurement on the same sand the residual water saturation of the sand was set to 0 05 while the van genuchten 1980 soil water retention parameters α and n were set to 11 m 1 and 6 respectively the diffusivity longitudinal and transversal dispersivity coefficients were respectively set to 1 10 9 m2 s 0 006 m and 0 0006 m hunt et al 2011 for the 2 cm thickness cutoff wall the saturated hydraulic conductivity was set to 3 10 6 m s three orders of magnitude less than that for the sand our tests showed that given such a low saturated hydraulic conductivity groundwater cannot flow through the cutoff wall results given in section 3 based on numerical simulations we also tested the importance of penetration depths and locations of cutoff walls under both non tidal and tidal conditions for the former series of sensitivity analysis the penetration depths of cutoff walls were respectively set to 0 1 0 3 0 5 0 7 and 0 9 m while as for the latter the locations of cutoff walls were set at x 1 7 1 6 1 5 1 4 and 1 3 m respectively therefore twenty simulation cases were considered in total 3 results and analysis in this section the results for the four base cases are first presented with respect to salinity distribution section 3 1 and groundwater flow and circulation section 3 2 after the underlying mechanisms are well discussed results from the sensitivity analysis on penetration depths and locations of cutoff walls are given in sections 3 3 and 3 4 respectively finally a dimensional analysis and results under large scale conditions are discussed in section 3 5 3 1 salinity distribution the color images taken from the experiments and the simulated salinity distribution under the non tidal and tidal conditions are shown in figs 2 and 3 overall the experimental and numerical results were in good agreement this served as model validation under both the non tidal and tidal conditions the color imagines described a sharp interface between freshwater and seawater white for freshwater and red for seawater this was consistent with previous studies chang and clement 2012 kuan et al 2012 morgan et al 2013 suggesting that the dye tracking method failed to capture a freshwater seawater mixing zone the mixing zone was as expected demonstrated in the numerical simulations under the non tidal condition fig 2b and d the thickness of the mixing zone was quite small around 0 05 m but under the tidal condition the mixing was evident i e around 0 3 m in the thickness fig 3b and d this suggests that the tidal fluctuation enhanced the freshwater seawater mixing in consistent with previous studies robinson et al 2007a yu et al 2019b despite the above mentioned difference between the experimental and numerical results they consistently demonstrated the effect of cutoff wall and tides on salinity distribution in the aquifer under the non tidal condition the experimental results showed that the cutoff wall led to a saltwater wedge significantly seaward with respect to the distance from the saltwater wedge toe to the aquifer seaside termed as swi distance hereinafter it changed from 2 38 to 1 65 m being retreated by 30 7 fig 2a in comparison with fig 2c it was clear that seawater can no long go through the section at which the cutoff was set x 1 7 m suggesting that the intruding seawater was blocked by the cutoff wall these results were in consistent with the previous studies abdoulhalik and ahmed 2017 kaleris and ziogas 2013 luyun et al 2011 demonstrating that the cutoff wall was effective in mitigating swi in aquifers under static conditions with the tide in presence the salinity distribution changed dramatically the tidal fluctuation induced an usp in both the experimental and numerical results fig 3 this usp appeared between the low and high tidal marks and changed the freshwater path at the seaside a freshwater tube developed between the usp and the lower saltwater wedge this modification in the shallow aquifer also affected the salinity distribution in the lower part i e the saltwater wedge retreated seaward fig 2a in comparison with fig 3a without the cutoff wall the experimental result showed that the swi distance changed from 2 38 to 1 65 m a reduction of 30 7 under this tidal condition modification of the cutoff wall on salinity distribution became weakened i e the swi distance further retreated from 1 65 to 1 60 m only a 3 reduction by the cutoff wall fig 3a in comparison with fig 3c based on the numerical simulations we calculated the watertables and the freshwater storage salinity less than 1 ppt in the per unit width aquifer the simulated watertables pore water pressure 0 for the four base cases are shown in fig 4 the simulated watertables note that the averaged values over the tidal cycle were used for the tidal cases at the seaside for the four base cases were all around 0 7 m x 1 0 m as those at the landside were fixed at 0 74 m x 7 7 m either the cutoff wall or the tide modified the overall boundary watertables obviously however the watertables in the aquifer were diverse particularly around the cutoff wall fig 4 under the non tidal condition the cutoff wall raised the watertable at the landside of the cutoff wall but lowered down that at the seaside as such the freshwater storage in the per unit width aquifer increased from 2 057 to 2 115 m3 m by 2 82 in increase it was interesting that the tide without the cutoff wall increased the freshwater storage to a similar level 2 126 m3 m as done as the cutoff wall under the non tidal condition in comparison with the non tidal case without cutoff wall the tide increased the watertable in the whole aquifer a phenomena called watertable overheight which is caused by the non linear groundwater table fluctuation nielsen 1990 these results suggested that either cutoff wall or tide can increase the freshwater storage however with the two considered together the freshwater storage only increased to 2 137 m3 m only 0 5 increase in comparison with the tidal case without cutoff wall this demonstrates that the interaction between the cutoff wall and tide was non linear in other words the effect of the cutoff wall on the freshwater storage was no longer effective with the tide in presence 3 2 groundwater flow and circulation to elucidate the groundwater flow and seawater circulation we calculated the traces and travel times of particles moving through the aquifer the trace tracks the particle s movement driven by the pore water flow in the aquifer note that the phase averaged velocity field was used for the tidal cases as done in xin et al 2010 we released four particles to both the inland boundary x 7 7 m and the beach surface i e eight particles in total the travel time measures the duration of the particle movement from the release point to the exit from which a particle moves out these results not only illustrate the pore water flow patterns but also provide information about how fast the freshwater and seawater are turned over in the aquifer affected by the combined cutoff walls and tides under the non tidal condition the particles released from the inland moved horizontally first and went up along the saltwater wedge in the aquifer without cutoff wall fig 2b the deeper particle took longer time e g the one starting from x 7 7 m and z 0 1 m took 50 1 h while that from x 7 7 m and z 0 7 m took 48 6 h table 1 the time difference among the four particles varied slightly at the seaside particles released to deeper beach moved further landward and took longer paths in this way the associated travel time was larger the one starting from x 0 m and z 0 2 m took 348 h while as that from x 0 6 m and z 0 5 m took 84 1 h with the cutoff wall set in the aquifer under the non tidal condition both the particle movement and travel time were significantly modified fig 2d in comparison with fig 2b in the freshwater zone for x from 7 7 to 1 7 m the particles released from the shallow aquifer started to bypass the cutoff wall by moving down and moving up respectively in the landside and the seaside of the cutoff wall in this way the particle path was prolonged and the associated travel time increased table 1 for example the one starting from x 7 7 m and z 0 7 m took 76 1 h much longer than that in the case without cutoff wall 48 6 h as the saltwater wedge was pushed seaward by the cutoff wall and changed steeper the path and travel time for the deeper particles were also altered e g the particle starting from x 7 7 m and z 0 1 m took 66 4 h also longer than that in the case without cutoff wall 50 1 h as the saltwater wedge retreated both the path and travel time for the particles moving through the seawater area reduced table 1 this was more evident for the deeper ones e g that for the particle starting from x 0 m and z 0 2 m decreased from 348 to 257 h a relative 26 reduction with the tide in presence a usp developed in the intertidal zone fig 3b this usp behaved similar to the cutoff wall blocking the movement of particles in the freshwater zone fig 3b in comparison with fig 2b the shallow particles bypassed the usp prior to discharging to the sea the associated travel time increased e g the particle starting from x 7 7 m and z 0 7 m took 56 3 h in contrast to 48 6 h in the aquifer under the non tidal condition tables 1 and 2 as the tide pushed the saltwater wedge seaward the travel time for the particles moving through the seawater area reduced as done by the cutoff wall fig 3b in comparison with fig 2d however the tidal modification was much more remarkable than the cutoff wall using the particle starting from x 0 m and z 0 2 m as an example it took 89 8 h to go through the tidally affected aquifer without the cutoff wall tables 1 and 2 this time scale was one order magnitude less than those under the non tidal condition and without 348 h and with 257 h cutoff wall clearly the tidal enhanced the freshwater and saltwater mixing and speeded up the seawater circulation consistent with previous studies robinson et al 2007a xin et al 2010 while the cutoff wall didn t modify significantly the salinity distribution in the tidally affected aquifer fig 3d in comparison with fig 3b it s impact on the particle movement was evident particularly in the freshwater area being blocked by the cutoff wall the particles also bypassed the cutoff wall and thus took longer paths and travel times table 2 around the cutoff wall the fresh groundwater flow was concentrated in the lower aquifer these results suggest that cutoff walls and tides jointly affect the groundwater flow and circulation in the unconfined aquifer in detail the path and time scale of freshwater discharge is more regulated by the cutoff wall while the seawater circulation is significantly enhanced by the tide 3 3 sensitivity analysis on the penetration depth of cutoff wall with the cutoff wall set at x 1 7 m we conducted simulations and tested the importance of the penetration depth figs 5 and 6 to quantify the difference we calculated the swi distance fig 7 the total salt mass stored in the per unit width aquifer fig 7 and freshwater storage in the aquifer fig 8 the first two indicators give the extent of swi while the latter indicates the freshwater resource overall the results were consistent with those discussed above the cutoff wall blocked the inland freshwater flow and mitigated the swi under the non tidal condition fig 5 this was more evident as the cutoff wall penetrated deeper in contrast the modification on the tidally affected aquifer was not evident fig 6 under the non tidal condition both the swi distance and the total salt mass decreased as the wall depth increased fig 7 it can be seen from the slopes of the trends the swi distance decreased more quickly in detail as the wall depth increased from 0 5 to 0 7 m the swi distance decreased from 2 31 to 1 95 m a relative 15 6 reduction while as a relative 7 2 decrease in the total salt mass as the saltwater wedge retreated the freshwater storage increased e g it increased from 2 059 to 2 108 m3 m as the cutoff wall went deeper from 0 3 to 0 7 m in the non tidal aquifer this was consistent with previous studies suggesting that cutoff walls can not only mitigate swi but also has the function of storing fresh groundwater ishida et al 2011 luyun et al 2009 in the tidally affected aquifer the modifications of cutoff wall on three indicators were no longer considerable figs 7 and 8 while the swi distance decreased as the cutoff wall went deeper the total salt mass almost kept unchanged fig 7 in this way the freshwater storage increased slightly with the cutoff wall depth increasing fig 8 this demonstrates again that the interaction between the cutoff wall and tide is non linear and their effects on salinity distribution could be canceled out by each other 3 4 sensitivity analysis on the location of cutoff wall under both the non tidal and tidal conditions the salinity distribution changed similarly as the cutoff wall moved seaward figs 9 and 10 the penetration depth of the cutoff wall was set to 0 9 m the travel times for the particles released from the inland increased while those for the particles released from the beach decreased the saltwater wedge retreated leading to decreased swi distance and total salt mass stored in the aquifer fig 11 similar to the sensitivity analysis on the penetration depth of cutoff wall the importance of wall location was more evident in the non tidal aquifer i e the slopes of the variation of the swi distance and the total salt mass were both larger than those under the tidal condition under the tidal condition the freshwater storage increased apparently as the cutoff wall moved seaward fig 12 as the cutoff wall moved from x 1 7 m to x 1 6 m the freshwater storage almost unchanged under the tidal condition while that increased from 2 115 to 2 132 m3 m under the non tidal condition this suggests that an effective cutoff wall could be set further seaward in the tidal aquifer in comparison with the non tidal aquifer with the cutoff wall moved further from x 1 6 m to x 1 3 m the freshwater storage under both the non tidal and tidal conditions increased interestingly those with the cutoff wall at x 1 5 m 1 4 m and 1 3 m were similar under the non tidal and tidal conditions e g all were around 2 15 and 2 19 m3 m respectively with the cutoff wall at x 1 5 and 1 3 m this suggests that the tidal modification on the freshwater storage kept almost unchanged as the cutoff wall moved seaward in other words the location of cutoff wall played a key role in affecting the freshwater storage 3 5 dimensional analysis the aquifer considered in this paper was isotropic and homogeneous effect of molecular diffusion on water flow and salinity distribution was expected to be negligible robinson et al 2018 werner et al 2013 if considering saturated flow only as done in robinson et al 2007a 17 independent parameters in three unit dimensions length l time t and mass m were involved in this study 6 for the model geometry ll ls b β hin and haq as marked in fig 1a 3 for the tidal condition h a and ω 6 for the fluid and aquifer property k ne αl αt ρs and ρf note that the effective porosity ne is the difference between saturated water content and residual water content and 2 for the cutoff wall lw and dw listed in table 3 according to smith 2004 and robinson et al 2007b the system s behavior can be characterized using 14 non dimensional groups listed in table 4 based on these non dimensional groups our results are expected to be applicable to a large scale aquifer parameters listed in table 3 to confirm this we conducted further simulations fig 13 note that only the four base cases were tested overall the results were consistent with those at the laboratory scale the cutoff wall and tides jointly affected the groundwater flow and salinity distribution in coastal unconfined aquifers the cutoff wall altered the path and travel time of the inland fresh groundwater and seawater furthermore the modification of cutoff wall on salinity distribution was not evident in the tidally influenced aquifer 4 discussions under the consideration of a static oceanic condition our results demonstrated that cutoff walls can moderate salinity distribution and thus mitigate swi in unconfined aquifers consistent with previous studies kaleris and ziogas 2013 luyun et al 2011 this modification was related to the local hydraulic gradient i e a jump on the groundwater table occurred around the cutoff wall the mitigation of cutoff walls on swi was more evident as it went deeper and seaward design of cutoff walls should consider carefully the location and depth and thus balance the effectiveness and engineering cost tides occur in most of the global coastlines they can induce seawater circulations in shallow and seaward aquifers robinson et al 2007a xin et al 2010 this not only moderates the salinity distribution in the shallow aquifer but also that in the lower the lower saltwater wedge can be pushed back to the sea under this condition the effect of cutoff wall on salinity distribution was demonstrated to be no longer evident in comparison of that under the static oceanic condition the extent of tidal modification is expected to depend on the tidal conditions amplitudes and periods and aquifer property e g thickness of aquifer and hydraulic conductivity in a real system robinson et al 2018 werner et al 2013 based on our results the importance of tidal fluctuations should be taken into account for future design of cutoff walls coastal aquifers are natural water stores providing an important freshwater resource for the population living in coastal zones our results demonstrated that either cutoff wall or tide can increase the freshwater stored in the aquifer in detail the freshwater storage increased as the cutoff wall went deeper and seaward in this way building cutoff walls remains an effective solution to store coastal water resources under tidal conditions however tidal fluctuations like to enhance freshwater and seawater mixing e g a thick mixing zone was caused by the tide in this study in comparison with that under the static oceanic condition based on taste considerations drinking water requires a small salinity level e g less than 1 ppt in who guidelines for drinking water quality gorchev and ozolins 1984 the enhanced mixing would make a large area of groundwater saline falling short of the drinking water standard this suggests again that tidal fluctuations should be carefully considered in the coastal water resource management e g excluding tidal fluctuations likely over predicts the extent of swi coastal aquifers are a critical connection between land and ocean in coastal aquifers lateral and seaward hydraulic gradients drive not only inland groundwater but also land sourced chemicals e g nutrient metal and organic contaminant to discharge to the sea robinson et al 2018 nowadays submarine groundwater discharge and seawater intrusion are recognized as two complementary processes in coastal aquifers our results demonstrate that cutoff walls can alter both the freshwater and seawater path and associated travel time in particular the path and travel time for the deeper freshwater was prolonged significantly chemicals in the inland freshwater might be more modified by reactions with aquifer sediments before discharging into the sea chemical movement and reaction are expected to affect the groundwater quality and the utilization of water resources in aquifers 5 conclusions we have examined the combined effect of cutoff wall and tides on groundwater flow and salinity distribution in unconfined aquifers from this study the following conclusions can be drawn i cutoff wall and tides jointly affect the flow and salinity distribution in coastal unconfined aquifers either of them can inhibit swi and increase the freshwater storage individually however with the two in presence the individual influences are canceled out to some extent ii tide significantly alter the seawater circulation in the aquifer and thus decreased the pore water travel time in the lower saltwater wedge in comparison with the aquifer under non tidal conditions iii as the inland freshwater need to bypass cutoff wall prior to discharge to the sea its path is prolonged and the associated travel time increases under both the non tidal and tidal conditions this was more evident with a deeper or seaward cutoff wall iv the modification of cutoff wall on salinity distribution depended on its depth and location a deeper or seaward cutoff wall leads to a further retreated saltwater wedge these effects are not evident in a tidally influenced aquifer it should be pointed out that these results were based on the homogeneous and isotropic aquifer the inland boundary condition was head specified while as a synthetic and sinusoidal tide was considered at the seaside aquifer aquifer heterogeneity real tidal conditions including multi components and inland watertable variations should be carefully considered in practical applications here we focused on cutoff walls effects of the other two subsurface barriers semi pervious subsurface barrier and subsurface dam on tidally influenced aquifers remain unclear and need future studies nevertheless this study has shed light on groundwater flow and salinity distribution in unconfined aquifers subjected to cutoff wall and tides which provides guidance for future designs of subsurface cutoff wall and management of coastal freshwater resource credit authorship contribution statement yiqian shen methodology formal analysis data curation writing original draft pei xin conceptualization writing review editing supervision xiayang yu methodology formal analysis validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the national natural science foundation of china 51579077 
5916,cutoff walls are widely used to alter groundwater flow and mitigate seawater intrusion in coastal areas while their behavior and performance in aquifers under static oceanic conditions are well established how do they combine with tides to affect groundwater flow and salinity distribution in coastal aquifers remains unclear here we addressed this research question based on physical experiments and numerical simulations cutoff walls were showed to regulate the inland freshwater flow and thus form a sharp waterlevel change in the landside of the cutoff wall as such inland groundwater flow was concentrated in the lower aquifer that inhibited seawater intrusion in the unconfined aquifer subjected to a static sea level under the non tidal condition this modification was enhanced as the cutoff wall went deeper or seaward however the tide pushed the saltwater wedge seaward in comparison with the case under the non tidal condition under this tidal condition the modification of the cutoff wall on saltwater intrusion was no longer evident in both cases under non tidal and tidal conditions the cutoff wall was found to alter the path and travel time of the inland fresh groundwater and seawater and total freshwater storage in the aquifer these results offer significant implications for designing engineering measures to mitigate seawater intrusion and managing groundwater resources in coastal zones keywords cutoff wall tide groundwater flow seawater intrusion unconfined aquifer 1 introduction seawater intrusion swi the movement of seawater into coastal freshwater aquifers commonly occurs in coastal aquifers worldwide bear et al 1999 this is often caused by excessive groundwater extraction in inland areas and sea level rise that decrease seaward hydraulic gradient werner et al 2013 with sea level rise due to global warming swi could be more intensive and thus threaten further coastal fresh groundwater resources luyun et al 2009 to mitigate swi and protect groundwater resources in coastal areas it needs to reduce groundwater extraction increase aquifer recharge and or inhibit the inflow of intruding saltwater construction of subsurface barriers is a technically feasible and effective solution to the swi problem in coastal aquifers therefore subsurface barriers are widely used in coastal areas around the world allow 2011 hasan basri 2001 sugio et al 1987 for example subsurface barriers were used historically in sardinia during the era of the roman empire hanson and nilsson 1986 the u s army crops of engineers designed temporary subsurface barriers to control upstream swi caused by low flow in the mississippi river in 1988 mcanally and pritchard 1997 japan had built about 15 submarine barriers by 2004 and seven of them were adopted to mitigate swi luyun et al 2009 it is approved that subsurface barriers can not only slow down the encroachment of seawater but also behave as subsurface dams to increase the freshwater storage in the coastal areas ishida et al 2011 luyun et al 2009 so far three types of barriers have been proposed kaleris and ziogas 2013 1 the semi pervious subsurface barrier extending from the top to impervious base of an aquifer 2 subsurface dam which has very low permeability and rests on the impervious base of an aquifer blocking only the lower part of the aquifer cross section and 3 cutoff wall which has very low permeability and penetrates into an aquifer to a certain depth blocking only the upper part of the aquifer in comparison with the former two types cutoff walls are more practical and of low cost kaleris and ziogas 2013 experimental and numerical studies have been conducted to examine the effect of cutoff walls on groundwater flow and salinity distribution in coastal aquifers abdoulhalik and ahmed 2017 kaleris and ziogas 2013 luyun et al 2011 kaleris and ziogas 2013 and luyun et al 2011 found that in absence of groundwater extractions effectiveness of a cutoff wall is determined by the wall depth its distance from the coast the groundwater velocity the intensity of freshwater and seawater mixing the conductivity anisotropy and the hydraulic conductivity of the wall luyun et al 2011 conducted laboratory scale investigations and showed that when a cutoff wall is located in an area of swi its protective effect increases with decreasing distance from the coast and increasing penetration depth abdoulhalik and ahmed 2017 examined the performance of cutoff walls in controlling swi in stratified coastal aquifers and the results showed that the soil stratification could reduce the effectiveness of the cutoff wall on mitigation of swi in comparison to homogeneous aquifers while these studies have proved the effectiveness of cutoff walls they predominantly adopted static sea boundary conditions and overlooked oceanic watertable oscillations caused by tides tides are a primary forcing factor that typically exist in coastal environments ataie ashtiani et al 1999 robinson et al 2018 werner et al 2013 it is now well established that the periodic tidal fluctuations can lead to dynamic and complicated groundwater flow and salinity distribution in coastal aquifers 1 tide can induce the fluctuation of inland watertable and enhance mixing of seawater and freshwater brovelli et al 2007 maji and smith 2009 robinson et al 2007a werner et al 2013 yu et al 2019b and 2 tides can induce an seawater circulation termed as upper saline plume usp in the seaward shallow aquifer and affect the saltwater wedge location li et al 2008 mao et al 2006 prieto and destouni 2005 robinson et al 2007b yu et al 2019a although previous studies have uncovered the effect of cutoff walls and tides individually to our best knowledge the combined effect of them on the groundwater flow and salinity distribution in coastal unconfined aquifers remains unclear to fill up this research gap we conducted both laboratory experiments and numerical simulations to address the following key questions 1 how do cutoff walls and tides jointly affect the salinity distribution in coastal unconfined aquifers 2 how groundwater flow and circulation are altered and 3 how important are the penetration depth and location of cutoff walls 2 methodology 2 1 laboratory experiments experiments were conducted in a 7 7 m long 1 2 m high 0 16 m wide flume fig 1 this flume has been successfully used by xin et al 2018 and yu et al 2019a for examining respectively surface water groundwater interactions and swi the flume included three compartments the middle compartment was packed with 1 m height quartz sand to simulate an unconfined coastal aquifer bounded by a sloping beach surface slope 1 2 the aquifer domain is given in fig 1a the two side compartments of the flume were linked to two water tanks respectively containing freshwater landward and saltwater seaward the landside of the aquifer was supplied with freshwater and with a fixed watertable 0 74 m note that the coordinate origin is set at the impervious base and the seaside aquifer as shown in fig 1a at the seaside of the aquifer a tide generator was used to control static or time varying tidal levels under the non tidal condition saltwater was pumped from a seawater reservoir under the flume fig 1b and discharged through an overflow outlet to maintain a constant water level at 0 70 m i e mean sea level msl under the tidal condition a programmable logic controller adjusted automatically the height of the overflow outlet and generated the preset tidal levels in this study we considered a simple sinusoidal tide as follows 1 h t msl a sin 2 π t t where h l is the tidal level at the time t t a l is the tidal amplitude set to 0 075 m and t t is the tidal period set to 240 s during the experiments both the salinity distribution and watertables in the two compartments at the land and sea sides were monitored as the flume was relatively narrow the experimental setup was essentially two dimensional focusing on flow and salinity distribution in the vertical and cross shore section of an unconfined aquifer the used quartz sand was relatively uniform with d 50 median diameter 0 5 mm and d 90 d 10 2 6 d 90 and d 10 are the sizes of sieve pores that 90 and 10 of sands can pass respectively the measured saturated hydraulic conductivity using freshwater and the darcy column test was 3 10 3 m s the porosity of the sand was 0 4 using the imbibition method collins 1961 four base experiments were conducted as follows 1 case 1 without cutoff wall and without tide 2 case 2 with cutoff wall and without tide 3 case 3 without cutoff wall and with tide 4 case 4 with cutoff wall and with tide for cases 2 and 4 the cutoff wall was inserted at the location with x 1 7 m and the penetration depth i e the distance from the cutoff wall bottom to the aquifer surface was 0 9 m the cutoff wall was set up using a polystyrene hard sheet 2 cm in thickness being inserted into the sand to the certain level the gaps between the sheet and two flume s back walls were well sealed to prevent water from seeping through the joint areas during the experiments the saltwater salinity was set to 35 ppt parts per thousand mass fraction with the associated density at 1025 kg m3 to visualize the swi process the seawater was prepared by dissolving 34 g of sodium chloride and 1 g of red food dye in a liter of freshwater density at 1000 kg m3 and salinity at 0 a camera was used to take images to record salinity distributions in the sand flume 2 2 numerical simulations as suggested by previous studies chang and clement 2012 kuan et al 2012 morgan et al 2013 the dye tracking method can only capture a sharp interface between freshwater and seawater to extend the finding from the experiments we also conducted numerical simulations to delineate a freshwater seawater mixing zone and calculate groundwater flow and associated travel time sutra voss and provost 2008 a numerical model was used to simulate the groundwater flow and salinity distribution in the aquifer with different penetration depths and positions of cutoff walls under tidal or non tidal conditions in sutra variably saturated and variable density pore flow is governed by the richards equation and this is further coupled with the convection diffusion equation for solute transport voss and provost 2008 the van genuchten 1980 functions were adopted to describe the relationship between the hydraulic conductivity soil saturation and capillary pressure head in the numerical model the model setup was consistent with the experiments regarding to saturated hydraulic conductivity soil porosity and boundary conditions in particular a constant non tidal cases or time dependent tidal cases and head specified boundary according to the seawater level was set to the seaward boundary a seepage face was allowed to develop along the beach for brevity readers are referred to xin et al 2010 to see details e g governing equations and setup of boundary conditions the mesh sizes were around 0 02 m in length and 0 01 in height note that a refined mesh was used for the area under the beach according to xin et al s 2018 measurement on the same sand the residual water saturation of the sand was set to 0 05 while the van genuchten 1980 soil water retention parameters α and n were set to 11 m 1 and 6 respectively the diffusivity longitudinal and transversal dispersivity coefficients were respectively set to 1 10 9 m2 s 0 006 m and 0 0006 m hunt et al 2011 for the 2 cm thickness cutoff wall the saturated hydraulic conductivity was set to 3 10 6 m s three orders of magnitude less than that for the sand our tests showed that given such a low saturated hydraulic conductivity groundwater cannot flow through the cutoff wall results given in section 3 based on numerical simulations we also tested the importance of penetration depths and locations of cutoff walls under both non tidal and tidal conditions for the former series of sensitivity analysis the penetration depths of cutoff walls were respectively set to 0 1 0 3 0 5 0 7 and 0 9 m while as for the latter the locations of cutoff walls were set at x 1 7 1 6 1 5 1 4 and 1 3 m respectively therefore twenty simulation cases were considered in total 3 results and analysis in this section the results for the four base cases are first presented with respect to salinity distribution section 3 1 and groundwater flow and circulation section 3 2 after the underlying mechanisms are well discussed results from the sensitivity analysis on penetration depths and locations of cutoff walls are given in sections 3 3 and 3 4 respectively finally a dimensional analysis and results under large scale conditions are discussed in section 3 5 3 1 salinity distribution the color images taken from the experiments and the simulated salinity distribution under the non tidal and tidal conditions are shown in figs 2 and 3 overall the experimental and numerical results were in good agreement this served as model validation under both the non tidal and tidal conditions the color imagines described a sharp interface between freshwater and seawater white for freshwater and red for seawater this was consistent with previous studies chang and clement 2012 kuan et al 2012 morgan et al 2013 suggesting that the dye tracking method failed to capture a freshwater seawater mixing zone the mixing zone was as expected demonstrated in the numerical simulations under the non tidal condition fig 2b and d the thickness of the mixing zone was quite small around 0 05 m but under the tidal condition the mixing was evident i e around 0 3 m in the thickness fig 3b and d this suggests that the tidal fluctuation enhanced the freshwater seawater mixing in consistent with previous studies robinson et al 2007a yu et al 2019b despite the above mentioned difference between the experimental and numerical results they consistently demonstrated the effect of cutoff wall and tides on salinity distribution in the aquifer under the non tidal condition the experimental results showed that the cutoff wall led to a saltwater wedge significantly seaward with respect to the distance from the saltwater wedge toe to the aquifer seaside termed as swi distance hereinafter it changed from 2 38 to 1 65 m being retreated by 30 7 fig 2a in comparison with fig 2c it was clear that seawater can no long go through the section at which the cutoff was set x 1 7 m suggesting that the intruding seawater was blocked by the cutoff wall these results were in consistent with the previous studies abdoulhalik and ahmed 2017 kaleris and ziogas 2013 luyun et al 2011 demonstrating that the cutoff wall was effective in mitigating swi in aquifers under static conditions with the tide in presence the salinity distribution changed dramatically the tidal fluctuation induced an usp in both the experimental and numerical results fig 3 this usp appeared between the low and high tidal marks and changed the freshwater path at the seaside a freshwater tube developed between the usp and the lower saltwater wedge this modification in the shallow aquifer also affected the salinity distribution in the lower part i e the saltwater wedge retreated seaward fig 2a in comparison with fig 3a without the cutoff wall the experimental result showed that the swi distance changed from 2 38 to 1 65 m a reduction of 30 7 under this tidal condition modification of the cutoff wall on salinity distribution became weakened i e the swi distance further retreated from 1 65 to 1 60 m only a 3 reduction by the cutoff wall fig 3a in comparison with fig 3c based on the numerical simulations we calculated the watertables and the freshwater storage salinity less than 1 ppt in the per unit width aquifer the simulated watertables pore water pressure 0 for the four base cases are shown in fig 4 the simulated watertables note that the averaged values over the tidal cycle were used for the tidal cases at the seaside for the four base cases were all around 0 7 m x 1 0 m as those at the landside were fixed at 0 74 m x 7 7 m either the cutoff wall or the tide modified the overall boundary watertables obviously however the watertables in the aquifer were diverse particularly around the cutoff wall fig 4 under the non tidal condition the cutoff wall raised the watertable at the landside of the cutoff wall but lowered down that at the seaside as such the freshwater storage in the per unit width aquifer increased from 2 057 to 2 115 m3 m by 2 82 in increase it was interesting that the tide without the cutoff wall increased the freshwater storage to a similar level 2 126 m3 m as done as the cutoff wall under the non tidal condition in comparison with the non tidal case without cutoff wall the tide increased the watertable in the whole aquifer a phenomena called watertable overheight which is caused by the non linear groundwater table fluctuation nielsen 1990 these results suggested that either cutoff wall or tide can increase the freshwater storage however with the two considered together the freshwater storage only increased to 2 137 m3 m only 0 5 increase in comparison with the tidal case without cutoff wall this demonstrates that the interaction between the cutoff wall and tide was non linear in other words the effect of the cutoff wall on the freshwater storage was no longer effective with the tide in presence 3 2 groundwater flow and circulation to elucidate the groundwater flow and seawater circulation we calculated the traces and travel times of particles moving through the aquifer the trace tracks the particle s movement driven by the pore water flow in the aquifer note that the phase averaged velocity field was used for the tidal cases as done in xin et al 2010 we released four particles to both the inland boundary x 7 7 m and the beach surface i e eight particles in total the travel time measures the duration of the particle movement from the release point to the exit from which a particle moves out these results not only illustrate the pore water flow patterns but also provide information about how fast the freshwater and seawater are turned over in the aquifer affected by the combined cutoff walls and tides under the non tidal condition the particles released from the inland moved horizontally first and went up along the saltwater wedge in the aquifer without cutoff wall fig 2b the deeper particle took longer time e g the one starting from x 7 7 m and z 0 1 m took 50 1 h while that from x 7 7 m and z 0 7 m took 48 6 h table 1 the time difference among the four particles varied slightly at the seaside particles released to deeper beach moved further landward and took longer paths in this way the associated travel time was larger the one starting from x 0 m and z 0 2 m took 348 h while as that from x 0 6 m and z 0 5 m took 84 1 h with the cutoff wall set in the aquifer under the non tidal condition both the particle movement and travel time were significantly modified fig 2d in comparison with fig 2b in the freshwater zone for x from 7 7 to 1 7 m the particles released from the shallow aquifer started to bypass the cutoff wall by moving down and moving up respectively in the landside and the seaside of the cutoff wall in this way the particle path was prolonged and the associated travel time increased table 1 for example the one starting from x 7 7 m and z 0 7 m took 76 1 h much longer than that in the case without cutoff wall 48 6 h as the saltwater wedge was pushed seaward by the cutoff wall and changed steeper the path and travel time for the deeper particles were also altered e g the particle starting from x 7 7 m and z 0 1 m took 66 4 h also longer than that in the case without cutoff wall 50 1 h as the saltwater wedge retreated both the path and travel time for the particles moving through the seawater area reduced table 1 this was more evident for the deeper ones e g that for the particle starting from x 0 m and z 0 2 m decreased from 348 to 257 h a relative 26 reduction with the tide in presence a usp developed in the intertidal zone fig 3b this usp behaved similar to the cutoff wall blocking the movement of particles in the freshwater zone fig 3b in comparison with fig 2b the shallow particles bypassed the usp prior to discharging to the sea the associated travel time increased e g the particle starting from x 7 7 m and z 0 7 m took 56 3 h in contrast to 48 6 h in the aquifer under the non tidal condition tables 1 and 2 as the tide pushed the saltwater wedge seaward the travel time for the particles moving through the seawater area reduced as done by the cutoff wall fig 3b in comparison with fig 2d however the tidal modification was much more remarkable than the cutoff wall using the particle starting from x 0 m and z 0 2 m as an example it took 89 8 h to go through the tidally affected aquifer without the cutoff wall tables 1 and 2 this time scale was one order magnitude less than those under the non tidal condition and without 348 h and with 257 h cutoff wall clearly the tidal enhanced the freshwater and saltwater mixing and speeded up the seawater circulation consistent with previous studies robinson et al 2007a xin et al 2010 while the cutoff wall didn t modify significantly the salinity distribution in the tidally affected aquifer fig 3d in comparison with fig 3b it s impact on the particle movement was evident particularly in the freshwater area being blocked by the cutoff wall the particles also bypassed the cutoff wall and thus took longer paths and travel times table 2 around the cutoff wall the fresh groundwater flow was concentrated in the lower aquifer these results suggest that cutoff walls and tides jointly affect the groundwater flow and circulation in the unconfined aquifer in detail the path and time scale of freshwater discharge is more regulated by the cutoff wall while the seawater circulation is significantly enhanced by the tide 3 3 sensitivity analysis on the penetration depth of cutoff wall with the cutoff wall set at x 1 7 m we conducted simulations and tested the importance of the penetration depth figs 5 and 6 to quantify the difference we calculated the swi distance fig 7 the total salt mass stored in the per unit width aquifer fig 7 and freshwater storage in the aquifer fig 8 the first two indicators give the extent of swi while the latter indicates the freshwater resource overall the results were consistent with those discussed above the cutoff wall blocked the inland freshwater flow and mitigated the swi under the non tidal condition fig 5 this was more evident as the cutoff wall penetrated deeper in contrast the modification on the tidally affected aquifer was not evident fig 6 under the non tidal condition both the swi distance and the total salt mass decreased as the wall depth increased fig 7 it can be seen from the slopes of the trends the swi distance decreased more quickly in detail as the wall depth increased from 0 5 to 0 7 m the swi distance decreased from 2 31 to 1 95 m a relative 15 6 reduction while as a relative 7 2 decrease in the total salt mass as the saltwater wedge retreated the freshwater storage increased e g it increased from 2 059 to 2 108 m3 m as the cutoff wall went deeper from 0 3 to 0 7 m in the non tidal aquifer this was consistent with previous studies suggesting that cutoff walls can not only mitigate swi but also has the function of storing fresh groundwater ishida et al 2011 luyun et al 2009 in the tidally affected aquifer the modifications of cutoff wall on three indicators were no longer considerable figs 7 and 8 while the swi distance decreased as the cutoff wall went deeper the total salt mass almost kept unchanged fig 7 in this way the freshwater storage increased slightly with the cutoff wall depth increasing fig 8 this demonstrates again that the interaction between the cutoff wall and tide is non linear and their effects on salinity distribution could be canceled out by each other 3 4 sensitivity analysis on the location of cutoff wall under both the non tidal and tidal conditions the salinity distribution changed similarly as the cutoff wall moved seaward figs 9 and 10 the penetration depth of the cutoff wall was set to 0 9 m the travel times for the particles released from the inland increased while those for the particles released from the beach decreased the saltwater wedge retreated leading to decreased swi distance and total salt mass stored in the aquifer fig 11 similar to the sensitivity analysis on the penetration depth of cutoff wall the importance of wall location was more evident in the non tidal aquifer i e the slopes of the variation of the swi distance and the total salt mass were both larger than those under the tidal condition under the tidal condition the freshwater storage increased apparently as the cutoff wall moved seaward fig 12 as the cutoff wall moved from x 1 7 m to x 1 6 m the freshwater storage almost unchanged under the tidal condition while that increased from 2 115 to 2 132 m3 m under the non tidal condition this suggests that an effective cutoff wall could be set further seaward in the tidal aquifer in comparison with the non tidal aquifer with the cutoff wall moved further from x 1 6 m to x 1 3 m the freshwater storage under both the non tidal and tidal conditions increased interestingly those with the cutoff wall at x 1 5 m 1 4 m and 1 3 m were similar under the non tidal and tidal conditions e g all were around 2 15 and 2 19 m3 m respectively with the cutoff wall at x 1 5 and 1 3 m this suggests that the tidal modification on the freshwater storage kept almost unchanged as the cutoff wall moved seaward in other words the location of cutoff wall played a key role in affecting the freshwater storage 3 5 dimensional analysis the aquifer considered in this paper was isotropic and homogeneous effect of molecular diffusion on water flow and salinity distribution was expected to be negligible robinson et al 2018 werner et al 2013 if considering saturated flow only as done in robinson et al 2007a 17 independent parameters in three unit dimensions length l time t and mass m were involved in this study 6 for the model geometry ll ls b β hin and haq as marked in fig 1a 3 for the tidal condition h a and ω 6 for the fluid and aquifer property k ne αl αt ρs and ρf note that the effective porosity ne is the difference between saturated water content and residual water content and 2 for the cutoff wall lw and dw listed in table 3 according to smith 2004 and robinson et al 2007b the system s behavior can be characterized using 14 non dimensional groups listed in table 4 based on these non dimensional groups our results are expected to be applicable to a large scale aquifer parameters listed in table 3 to confirm this we conducted further simulations fig 13 note that only the four base cases were tested overall the results were consistent with those at the laboratory scale the cutoff wall and tides jointly affected the groundwater flow and salinity distribution in coastal unconfined aquifers the cutoff wall altered the path and travel time of the inland fresh groundwater and seawater furthermore the modification of cutoff wall on salinity distribution was not evident in the tidally influenced aquifer 4 discussions under the consideration of a static oceanic condition our results demonstrated that cutoff walls can moderate salinity distribution and thus mitigate swi in unconfined aquifers consistent with previous studies kaleris and ziogas 2013 luyun et al 2011 this modification was related to the local hydraulic gradient i e a jump on the groundwater table occurred around the cutoff wall the mitigation of cutoff walls on swi was more evident as it went deeper and seaward design of cutoff walls should consider carefully the location and depth and thus balance the effectiveness and engineering cost tides occur in most of the global coastlines they can induce seawater circulations in shallow and seaward aquifers robinson et al 2007a xin et al 2010 this not only moderates the salinity distribution in the shallow aquifer but also that in the lower the lower saltwater wedge can be pushed back to the sea under this condition the effect of cutoff wall on salinity distribution was demonstrated to be no longer evident in comparison of that under the static oceanic condition the extent of tidal modification is expected to depend on the tidal conditions amplitudes and periods and aquifer property e g thickness of aquifer and hydraulic conductivity in a real system robinson et al 2018 werner et al 2013 based on our results the importance of tidal fluctuations should be taken into account for future design of cutoff walls coastal aquifers are natural water stores providing an important freshwater resource for the population living in coastal zones our results demonstrated that either cutoff wall or tide can increase the freshwater stored in the aquifer in detail the freshwater storage increased as the cutoff wall went deeper and seaward in this way building cutoff walls remains an effective solution to store coastal water resources under tidal conditions however tidal fluctuations like to enhance freshwater and seawater mixing e g a thick mixing zone was caused by the tide in this study in comparison with that under the static oceanic condition based on taste considerations drinking water requires a small salinity level e g less than 1 ppt in who guidelines for drinking water quality gorchev and ozolins 1984 the enhanced mixing would make a large area of groundwater saline falling short of the drinking water standard this suggests again that tidal fluctuations should be carefully considered in the coastal water resource management e g excluding tidal fluctuations likely over predicts the extent of swi coastal aquifers are a critical connection between land and ocean in coastal aquifers lateral and seaward hydraulic gradients drive not only inland groundwater but also land sourced chemicals e g nutrient metal and organic contaminant to discharge to the sea robinson et al 2018 nowadays submarine groundwater discharge and seawater intrusion are recognized as two complementary processes in coastal aquifers our results demonstrate that cutoff walls can alter both the freshwater and seawater path and associated travel time in particular the path and travel time for the deeper freshwater was prolonged significantly chemicals in the inland freshwater might be more modified by reactions with aquifer sediments before discharging into the sea chemical movement and reaction are expected to affect the groundwater quality and the utilization of water resources in aquifers 5 conclusions we have examined the combined effect of cutoff wall and tides on groundwater flow and salinity distribution in unconfined aquifers from this study the following conclusions can be drawn i cutoff wall and tides jointly affect the flow and salinity distribution in coastal unconfined aquifers either of them can inhibit swi and increase the freshwater storage individually however with the two in presence the individual influences are canceled out to some extent ii tide significantly alter the seawater circulation in the aquifer and thus decreased the pore water travel time in the lower saltwater wedge in comparison with the aquifer under non tidal conditions iii as the inland freshwater need to bypass cutoff wall prior to discharge to the sea its path is prolonged and the associated travel time increases under both the non tidal and tidal conditions this was more evident with a deeper or seaward cutoff wall iv the modification of cutoff wall on salinity distribution depended on its depth and location a deeper or seaward cutoff wall leads to a further retreated saltwater wedge these effects are not evident in a tidally influenced aquifer it should be pointed out that these results were based on the homogeneous and isotropic aquifer the inland boundary condition was head specified while as a synthetic and sinusoidal tide was considered at the seaside aquifer aquifer heterogeneity real tidal conditions including multi components and inland watertable variations should be carefully considered in practical applications here we focused on cutoff walls effects of the other two subsurface barriers semi pervious subsurface barrier and subsurface dam on tidally influenced aquifers remain unclear and need future studies nevertheless this study has shed light on groundwater flow and salinity distribution in unconfined aquifers subjected to cutoff wall and tides which provides guidance for future designs of subsurface cutoff wall and management of coastal freshwater resource credit authorship contribution statement yiqian shen methodology formal analysis data curation writing original draft pei xin conceptualization writing review editing supervision xiayang yu methodology formal analysis validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the national natural science foundation of china 51579077 
5917,euclidean distance based spatial interpolation methods that are conceptually simple are commonly used for the imputation of missing precipitation and other hydroclimatic variable datasets improved variants of these methods are essential as euclidean distance will not always serve as an appropriate surrogate that can quantify the inter gauge relationships in all hydroclimatic and topographical settings probability space based error measure linear error in probability space leps and three distribution similarity hypothesis test statistic values are proposed as surrogates for distances in weighting methods to address this limitation a k fold cross validation exercise of the imputation of precipitation data at 22 rain gauges in a temperate climatic region is used for the evaluation of methods improved imputation of missing data was noted from proposed methods compared to that from a distance based method and is confirmed with statistical inference testing of multiple error and performance measures also the leps based method provided performance measures that are as good as those from a nonlinear optimization method a local spatial interpolation approach that uses leps and two sample kolmogorov smirnov hypothesis test results quantified as binary outcomes for objective selection of rain gauges are also evaluated better estimates of missing data are obtained using this approach compared to those from a euclidean distance based global interpolation method the proposed new probability space based distances are conceptually superior alternatives to euclidean distances when used in weighting methods for spatial interpolation keywords missing precipitation spatial interpolation distance weighting method linear error in probability space leps hypothesis test statistic kentucky 1 introduction availability of serially complete continuous precipitation data from rain gauge measurements is not always possible due to malfunctions of instruments systematic random and transcription errors and extreme weather events that disrupt the measurement process itself serially complete precipitation data is needed for climate variability and change studies environmental assessments and hydrological frequency analyses goly and teegavarapu 2014 serrano notivoli et al 2017 aissia et al 2017 therefore interpolation spatial or temporal becomes essential to fill any existing gaps missing data estimation at a rain gauge is a point estimation process as opposed to a surface generation i e gridded data exercise chen and liu 2012 yeggina et al 2019 temporal interpolation for the imputation of missing precipitation data is possible only if high autocorrelation is evident at low temporal resolutions e g 15 min or one hour rainfall observations often show strong persistence allowing for the use of the last observation carry forward locf procedure or baseline observation carry forward bocf or single imputation approach buuren 2012 imputation of missing precipitation at a rain gauge using spatial interpolation is the focus of this study deterministic and stochastic spatial interpolation methods using different weighting schemes employing euclidean simanton and osborn 1980 and angular shepard 1968 yeggina et al 2019 distances have been used in the past for estimation of missing precipitation data precipitation data imputation was addressed by many studies using euclidean distance based weighting method e g inverse distance weighting method idwm wei and mcguinness 1973 simanton and osborn 1980 asce 1996 garcia et al 2008 several variants of idwm were also developed to improve the interpolation by including a learned search approach hodgson 1989 that reduces the number of distance calculations and topographical information shepard 1968 and anisotropic inverse distance weighting tomczack 2008 quadrant method teegavarapu and chandramouli 2005 uses the closest gauge by euclidean distance to the base gauge i e gauge at which precipitation data is missing or assumed to be missing in each quadrant whereas normal ratio method paulhus and kohler 1952 tung 1983 uses nearest gauges with similar magnitudes of average annual precipitation totals variants of inverse distance and normal ratio methods are introduced by suhaila et al 2008 with the incorporation of the strength of correlation between any two sites and improvements were noted for precipitation imputation compared to the original versions a recent survey of spatial and temporal interpolation methods for estimation of missing precipitation data by teegavarapu 2016 serves as a good reference for understanding the limitations and advantages of these methods variants of kriging have been used to impute missing precipitation records ly et al 2011 teegavarapu and chandramouli 2005 teegavarapu 2007 several drawbacks of the kriging method include difficulty in the selection of the appropriate semi variogram uncertainty associated with the assignment of sill and nugget parameters and the computational effort required to obtain a missing precipitation value at a site imputations of precipitation data using artificial neural networks anns were reported by multiple studies kajornrit et al 2012 teegavarapu and chandramouli 2005 teegavarapu et al 2017 the semi variogram modeled using ann in a kriging approach to estimate missing precipitation data by teegavarapu 2007 is another example use of anns kim and pachepsky 2010 documented the use of two step method for constructing daily precipitation data using regression trees and anns spatially interpolated precipitation estimates were corrected with the help of association rule mining technique by teegavarapu 2009 bardossy and pegram 2014 evaluated several methods regression kriging multiple linear regression and copula based methods they noted that copula based methods performed better than all others a copula based method with support vector machines svm for filling missing precipitation data was reported by landot et al 2008 however teegavarapu et al 2017 reported that this method did not provide better estimates of missing precipitation compared to those from linear optimization and ann based methods simple substitution linear and polynomial regression and ranked regression approaches were evaluated by presti et al 2010 for the imputation of precipitation data and they concluded that the polynomial regression and simple substitution method provided better estimates of missing data than other methods a linear programming method using topographical information was reported by yoo 2013 pappas et al 2014 presented a method that uses nearest neighbors in a temporal interpolation approach for the estimation of missing data simolo et al 2010 developed a probability density function preserving approach to improve the estimation of missing daily precipitation data according to teegavarapu 2016 and brimicombe 2003 most of the spatial interpolation methods lack 1 a procedure for objective selection of an optimal number of neighbors or gauges and neighborhood size in reference to local or global interpolation 2 optimal weights in spatial interpolation schemes variants of idwm with the help of optimization formulations were developed by teegavarapu 2012 which provided mechanisms to select an optimal number of gauges identify spatial clusters to group rain gauges and use them in interpolation and use the best available gauge in each quadrant for interpolation previous studies using spatial interpolation for missing data imputation have proposed and evaluated different conceptually superior alternatives or surrogates for geographical or euclidean distances ahrens 2006 adopted a semi mean squared difference in non zero precipitation values between any two rain gauges as a replacement for geographical distance teegavarapu and chandramouli 2005 used the pearson correlation coefficient cc as a replacement for the distance that led to improvements in estimates multiple studies marteau et al 2011 westerberg et al 2009 kim et al 2008 have reported better estimates of missing precipitation data using this method compared to those from other deterministic methods ten real and binary metrics used in numerical taxonomy were adopted as substitutes for euclidean distances by teegavarapu 2014a for imputing missing data the study documented substantial improvements in multiple error measures compared to those obtained from over a dozen spatial interpolation methods a modification of idwm using elevation information of base and other rain gauges by barrios et al 2018 provided improved estimates of missing monthly precipitation records in chile compared to ann and multiple regression based methods evaluation of variants of euclidean distance based method suggests that by use of proper weighting schemes and selection of neighborhood with rain gauges surrounding a base gauge conceptually superior and simple interpolation methods that are competitive to computationally complex methods can be developed exploring parameters that characterize the inter gauge data relationships better than previously evaluated ones is attempted in this study for developing new variants of distance based or weighting methods the contents of this paper are structured as follows first the methodology adopted using probability space and hypothesis test statistic based measures is described use of these measures as substitutes for euclidean distances weighting method development and description of the optimization method objective selection of rain gauges for spatial interpolation are elaborated next applications of methods for imputation of missing data evaluation of methods and general remarks are presented next finally conclusions from the study are presented 2 methodology the methodology adopted for the development of different weighting methods for missing precipitation data estimation is shown in fig 1 a series of steps illustrated in fig 1 will show the division of available precipitation data n days at all available rain gauges in a region into calibration data n m days and validation data m days and estimation of surrogates for euclidean distances to be later used in a spatial interpolation method any surrogate for euclidean distance should 1 have an ability to characterize the inter gauge relationships using data 2 be conceptually simple to estimate and 3 be robust in handling outliers hypothesis test statistic values from distance and area based distribution similarity tests that use cumulative distribution functions cdfs of datasets such as kolmogorov smirnov ks dodge 2010 chi square and ad tests can be ideal candidates for the surrogates of euclidean distances probability space based distance defined by a linear error in probability space leps score potts et al 1996 is another potential substitute for distance details of these surrogates are explained in the next section the hypothesis test results from the ks chi square and ad tests can also be used to help in the selection of rain gauges for spatial interpolation the calibration data is used to derive leps score values and test statistic values and also to obtain the hypothesis test results i e null and alternative hypotheses considering ns rain gauges and with n observations at each rain gauge for each site or rain gauge assumed to be having missing data a total of ns 1 values of leps score and ks test statistic are derived using the calibration data the methodology proposed is applicable for estimation of missing precipitation data at a single site i e rain gauge and data are assumed to missing completely at random mcar 2 1 surrogates for distances in weighting methods four surrogates of distances defined by leps score ks chi square χ 2 and anderson darling ad test statistic values used in this study are described and the procedures for estimation of the same and their use in weighting methods are provided in this section linear error in probability space leps score potts et al 1996 is used in this study to define the mean absolute difference between cumulative frequencies déqué 2011 of the rain gauge data at any two sites the calculation of cumulative frequencies based on precipitation data at a base gauge and any other gauge and the representation of the leps score is shown in fig 2 the score β b k in eq 1 is calculated using precipitation data at the base gauge b and those at other gauge k variable n refers to the total number of observations i is the index number for a specific observation and f b θ b i is the empirical cumulative distribution function ecdf of observations and θ b i and θ k i are the observed precipitation values at a base and another gauge k respectively 1 β b k i 1 n δ i 1 n i 1 n f b θ b i f b θ k i b k i the leps score is calculated using the ecdf of the base gauge only a low value of leps score is an indication of good agreement between observations from the base rain gauge and any other gauge reciprocal of the leps score can serve as a weight associated with a gauge when used in a weighting method another surrogate of distance a measure of distributional similarity that is used in this study is the test statistic d b k obtained from a nonparametric hypothesis test a two sample two sided kolmogorov smirnov ks test dodge 2010 the statistic d b k is also referred to as ks distance or uniform distance guidici and figini 2009 the statistic is estimated by eq 2 where the variables ef b and ef k refer to the empirical cumulative distribution functions cdfs e f b θ is the proportion of θ b values less than or equal to θ at base gauge b and ef k θ is the proportion of θ k values less than or equal to θ at any other gauge k 2 d b k max θ ef b θ ef k θ k θ an alternative to the ks test statistic as a replacement for distance is the test statistic from the chi square two sample test press et al 1992 the chi square χ 2 test statistic given by eq 3 is also used and evaluated in this study precipitation data at base gauge b and another gauge k is used to calculate the statistic the variables z and z b refer to the index for the bin i e class interval and a total number of bins respectively the number of precipitation values from base gauge b within bin z is s z b and the number of values from gauge k in the same bin z is s z k 3 χ 2 b k z 1 zb s z b s z k 2 s z b s z k b k k b the anderson darling ad test statistic mil 2002 pettitt 1976 scholz and stephens 1987 is also used as a surrogate of euclidean distance in this study notation for multiple sample ad test is provided here although the test is used only with two samples i e observations at a base gauge and any other gauge in this study the ad test statistic ad b k is given by eq 4 4 ad b k n 1 n 2 l 1 lt 1 n l m 1 l h m n g lm n l i m 2 i m n i m n h m 4 b i k b where lt is the number of groups samples lt 1 2 l t n is the total number of observations n n 1 n 2 n lt h m is the number of values in the combined samples equal to z m i m is the number of values in the combined samples less than z m plus one half the number of values in the combined samples equal to z m g lm is the number of values in the l th group which are less than z m plus one half the number of values in the combined samples equal to z m n l is the number of observations in group l z 1 z 2 z l are the distinct values in the combined data set ordered from smallest to largest the ad b k is estimated with lt 2 using observations at base gauge b and any other gauge k more details of the ad test statistic can be obtained from mil 2002 pettitt 1976 and scholz and stephens 1987 2 2 weighting method the imputed precipitation value θ b i at base gauge b in an interval i is given by eq 5 as all available rain gauges are used the interpolation is considered global variable θ k i o is the precipitation value at any other rain gauge k w b k is the weight for the gauge k when missing data is estimated at base gauge b and ns is the total number of rain gauges 5 θ b i e k 1 ns 1 w b k θ k i o k 1 ns 1 w b k b i k b the weights w b k required in eq 5 are estimated using eqs 6 and 7 the variable r b k can be the euclidean distance d b k or the surrogate of the distance β b k or d b k or χ 2 b k or ad b k with exponent φ is referred to as friction distance generally a value of 2 is used for φ however it can be varied until the best performance from interpolation is achieved or optimal value for a given dataset can be obtained by solving a mathematical programming formulation teegavarapu et al 2017 6 w b k 1 r b k φ b k k b φ 1 2 10 7 r b k β b k o r r b k d b k o r r b k d b k o r r b k χ 2 b k o r r b k ad b k b k methods using euclidean distance leps score ks chi square and anderson darling test statistic values are referred to as ed leps ks chi square and ad methods respectively in this study 2 3 objective selection of rain gauges the selection of rain gauges objectively for imputation is accomplished with the help of the binary variable s assigned to the outcome of the ks ad and hypothesis tests the chi square χ 2 two sample test with null and alternative hypotheses i e h 0 the two datasets come from a common distribution and h 1 the two datasets do not come from a common distribution can be used for the selection of rain gauges for interpolation similar to the use of the ks test also the two sample version of the ad test with null and alternative hypotheses i e h 0 the populations from which two or more groups of data were drawn are identical and h 1 the that the populations from which two or more groups of data were drawn are not identical can be used for selection of rain gauges for interpolation similar to the use of the ks test for the ks test if f b and f k represent the true but unknown cumulative distribution functions cdfs of observations at the base and other gauge k respectively then ks test statistic eq 2 can be used to determine if independent random samples data at the base and another gauge are taken from the same population the ks test examines two hypotheses the null hypothesis h 0 f b θ f k θ suggesting two samples are from the same distribution or the alternative hypothesis h 1 f b θ f k θ suggesting two samples are from different distributions testing of the hypothesis can be carried out either by comparing the test statistic d b k with a critical value d c as indicated by eq 8 or by comparing p value with a pre specified significance level α the result from ks test i e null hypothesis accepted or null hypothesis rejected at a pre specified significance level can be quantified as a binary value using a variable λ b k as indicated by inequality 8 8 if d b k d c o r p v a l u e α t h e n h 0 n u l l h y p o t h e s i s i s a c c e p t e d a n d λ b k 1 e l s e h 1 a l t e r n a t i v e h y p o t h e s i s i s a c c e p t e d a n d λ b k 0 inclusion of binary variable λ b k variable in eq 9 may exclude a subset of all rain gauges from the weighting scheme 9 θ b i e k 1 ns 1 w b k θ k i o λ b k k 1 ns 1 w b k λ b k b i k b this procedure of objective selection of gauges for interpolation is referred to as the sl approach in this study for any base site if the k 1 ns 1 λ b k 0 then imputed data value is obtained out using eq 9 with an appropriate distance the weights i e w b k values can be based on euclidean distance leps score or any test statistic discussed in the earlier sections 2 4 optimal interpolation method an optimal spatial interpolation method using non negative least squares nnls formulation is also developed in this study the formulation when solved as a constrained least squares problem will provide optimal weights required for the imputation of missing data the formulation with objective function in eq 10 provides non negative weights due to the inclusion of a constraint given by inequality 11 10 m i n i m i z e e x f 2 2 subject to 11 w b k o 0 b k k b the variables e x and f are vectors e is the m n ns 1 matrix of θ m n n s 1 values x defines the ns 1x 1 of w b k o weight values and f refers to m n 1 observed precipitation values of data at the base gauge eq 10 serves as an objective function that is minimized a constraint that enforces non negative weights is included in the formulation using inequality 11 the optimal weights obtained from the solution of nnls formulation are used in eq 11 for the imputation of precipitation data using eq 12 12 θ b i e k 1 ns 1 w b k o θ k i o b i k b this method has been used in past studies teegavarapu 2012 2014a and was proven to provide better estimates than kriging and several deterministic spatial interpolation methods this method is referred to as the opt method 3 case study application the methods described in earlier sections are used for the imputation of daily missing precipitation records at several rain gauges located in kentucky usa rain gauge locations and the topographic details of the region are shown in fig 3 the case study region i e kentucky has a temperate climate dominated by frontal precipitation the climate for the region is characterized as fully humid warm with hot summer conditions as indicated by kottek et al 2006 based on the köppen geiger classification scheme long term precipitation data from the calendar year 1971 to 2016 at 22 rain gauges in this region are used for the evaluation of proposed methods a chronologically continuous i e gap free observation set of 16 802 days of precipitation data for all gauges is obtained from the kentucky agricultural weather center kawc a holdout procedure in which data are randomly assigned to two datasets for calibration or training and validation or testing is used the lengths of calibration and validation datasets are 12 602 and 4 200 days respectively the validation dataset 4 200 days constitutes 25 of the entire available data and is randomly selected the methodology explained in fig 1 refers to these two datasets by variable notation n m and m respectively also to evaluate the robustness of the methods proposed 35 random 4200 day blocks of data at each gauge are selected and are assuming to be missing these missing data are estimated using different methods at all gauges a k fold validation procedure in which the training dataset sample of 12602 days is randomly partitioned into k unequal sized sub samples with a constant size of validation dataset i e 4200 days is adopted in the current study the sub samples are used for estimation of parameters for the methods and the validation data is used for testing 4 measures for evaluation of methods error measures derived using observed and imputed precipitation data such as mean absolute error mae root mean squared error rmse and a performance measure pearson correlation coefficient cc are used to evaluate the methods the measures are calculated based on the validation data statistically significant differences in measures between any two methods or among measures derived from multiple executions of the same method are confirmed using parametric and nonparametric hypothesis tests notations for parameters used to explain null and alternative hypotheses in these tests refer to population parameters as inferences are made about them from the available sample data 4 1 evaluation of differences in measures an unpaired two sample t test is used to confirm statistically significant differences between error and performance measures obtained from any two methods the test uses the null and alternative hypotheses h 0 μ 1 μ 2 and h 1 μ 1 μ 2 and helps to assess the differences in the mean values i e μ 1 μ 2 of the measures as normality of the samples is a requirement for the t test a goodness of fit test for the gaussian distribution the kolmogorov smirnov ks test massey 1951 sheskin 2011 is used the t test also requires evaluation of variances i e σ 1 2 σ 2 2 for which the fisher test f test sheskin 2011 with null and alternative hypotheses h 0 σ 1 2 σ 2 2 and h 1 σ 1 2 σ 2 2 respectively is used a t test that employs satterthwaite s approximation satterthwaite 1946 for the estimation of effective degrees of freedom for situations with unequal variances is also used in this study 4 2 evaluation of bi variate relationships and trends spearman s rho ρ test sheskin 2011 that uses the rank order correlation coefficient to assess the monotonic association between any two metrics or evaluate trends is used in this study the null and alternative hypotheses for the test are h 0 ρ 0 and h 1 ρ 0 respectively spearman s rho test is used to evaluate the association between leps and pearson s correlation coefficient and also trends in extreme precipitation indices in this study 4 3 evaluation of differences in multiple measures one way analysis of variance anova sheskin 2011 is used to evaluate differences in mean values of more than two performance measures derived from multiple executions of one single method or from multiple methods the null and alternative hypotheses are h 0 μ 1 μ 2 μ 3 μ np and h 1 means μ 1 μ 2 μ np are not all equal the variable np is the number of groups of performance measures homoskedasticity of variances of the measures is evaluated using bartlett s test bartlett 1937 sheskin 2011 with null and alternative hypotheses as h 0 σ 1 2 σ 2 2 σ np 2 and h 1 σ l 2 σ m 2 for at least one pair l m and l m n p a non parametric version of the one way anova test the kruskal wallis h test kruskal and wallis 1952 sheskin 2011 corder and foreman 2009 was also employed in this study the p value i e probability calculated under the null hypothesis of having an outcome as extreme as the observed value in the sample dodge 2010 for each test is also reported 4 4 nonparametric visual assessment of measures kernel density estimates kdes bowman and azzalini 1997 as nonparametric representations of the probability density functions pdfs and as replacements for histograms are used to aid comparative visual assessments of error and performance measures a gaussian kernel smoothing function with optimal bandwidth that controls the smoothness is used in the current study 5 results and analysis the possibility of using temporal interpolation for the imputation of missing values was initially evaluated in this study by checking the autocorrelation function acf of precipitation data at several temporal lags at each rain gauge fig 4 shows the autocorrelation values at several lags for data at all rain gauges the upper and lower confidence bounds 95 confidence limits 1 96 n of 0 0178 and 0 0178 respectively are also shown almost all autocorrelation values at several lags are between these bounds the acfs suggest that daily precipitation data constitutes a white noise with serially uncorrelated random values based on this observation it can be concluded that temporal interpolation is not an option for the imputation of missing data due to lack of strong autocorrelation at several temporal lags imputation of missing data is initially carried out at 22 stations using 4200 days of missing data and later with 35 ensembles of 4200 days randomly selected from the training data without replacement the friction distance parameter φ is assigned a value of 2 in this study a total of 462 leps scores 22 21 and pearson correlation coefficients ccs based on data from 22 gauges are obtained the calculations of leps scores are based on n p2 permutations 22 p2 as there are 22 gauges and two gauges are used for one leps score estimation the total number of leps scores obtained is equal to 462 it important to note that for leps score β 1 2 β 2 1 as ecdfs of gauge 1 and gauge 2 are used to calculate β 1 2 and β 2 1 respectively the joint variation of leps scores and correlation coefficients is shown in fig 5 this variation is evaluated as correlations based on observations reflect the inter gauge relationships a least squares regression line provided points to evidence of a strong linear relationship between leps and cc statistically significant correlation of 0 963 was observed and was confirmed by the alternative hypothesis i e the existence of non zero correlation from spearman s rho test with a p value less than 0 0001 error and performance measures from the applications of the ed leps and ks methods for imputation of missing data comprising of 4200 days are provided in table 1 a review of the error and performance measures suggests that leps method performs better than the ed method to confirm that the differences in the error and performance measures from two methods are statistically significant a parametric hypothesis test a t test is used the normality of rmse mae and cc values are confirmed using a goodness of fit test one sample ks test with null hypothesis accepted with p values of 0 91 0 46 0 94 0 99 and 0 86 and 0 98 and respectively the f test confirmed the equality of variances for rmse values with a p value of 0 19 inequality of variances for mae and cc values with p values of 0 015 and 0 001 respectively two types of two sample t tests were conducted for equal and unequal variances at a 5 significance level α the test results indicate the acceptance of the alternative hypothesis suggesting the mean values of rmse mae and cc from the ed and leps methods are unequal with p values close to zero the mean values of rmse mae and cc for the ed and leps methods are 7 46 mm and 6 10 mm 3 16 mm and 2 59 mm and 0 54 and 0 70 respectively error and performance measures based on ks are also provided in table 1 to confirm statistically significant differences in measures between ed and ks methods hypothesis tests i e two sample t tests are used the normality checks for rmse mae and cc values are confirmed using a goodness of fit test one sample ks test with the null hypothesis being accepted with p values of 0 91 0 93 0 94 0 53 and 0 86 and 0 91 and respectively the f test confirmed the equality of variances for rmse values with a p value of 0 10 inequality of variances for mae and cc values with p values of 0 005 and 0 003 respectively two types of unpaired two sample t tests were conducted for equal and unequal variances at a 5 significance level α the test results indicated the acceptance of the alternative hypothesis suggesting the mean values of rmse mae and cc from the ed and ks methods are unequal with p values close to zero the mean values of rmse mae and cc for the ed and ks methods are 7 46 6 18 3 16 and 2 56 mm and 0 54 and 0 69 respectively imputation of precipitation data using the chi square method obtained from training data with 9 and 15 bins and a value of 2 for the exponent φ in eq 5 is carried out results from these experiments using two different bin sizes provided in table 2 to confirm the sensitivity of the statistic to the bin size also the error and performance measures improved as the number of bins increased from 9 to 15 measures from bin size of 15 are used for further comparison performance measures using the chi square method were better than those from the ed method a two sample unpaired t test after conducting normality and fisher tests with alternative hypotheses being accepted with p values close to 0 confirmed that the performance measures from both the methods are different at a statistical significance level of 5 the error measures from chi square and leps methods are also compared using t tests the t tests results noted the null hypothesis being true with p values of 0 97 0 31 and 0 97 for rmse mae and cc measures respectively suggesting the chi square and leps methods provided similar results with no statistically significant differences results based on the ad method are also provided in table 2 the performance measures obtained from this method were inferior to those from leps method and are statistically different for rmse and cc with p values from t tests equal to 0 003 and 0 02 respectively a two sample two sided ks test is used for two specific purposes in this study 1 to obtain the test statistic d b k and 2 to obtain hypothesis test result with one of the hypotheses h 0 or h 1 being accepted the two sided test assumes that two distributions are unequal i e f b θ f k θ a significance level α of 5 is used for hypothesis testing in this study the decision to reject the null hypothesis is based on a comparative evaluation of p value and significance level α as suggested by conditional inequality 3 and not based on comparison of the test statistic with the critical value in the current study the asymptotic p value a p value that is calculated using an approximation to the true distribution is used the use of p value is mainly due to the algorithmic implementation of test available in the proprietary software used in this study since the sample size i e length of training data n 12802 days is large the asymptotic p value and exact p value a value calculated using the true distribution of the sample are similar and can provide defensible hypothesis test results the asymptotic p value used is considered accurate and valid as the condition n1 n 2 n 1 n 2 4 or n2 2n 4 if n 1 n 2 is satisfied with n value equal to the length of the training data i e n m 12802 days for any two rain gauges the ks test is also used to confirm the distribution similarity between observations at a base rain gauge and any other gauge at a significance level of 5 for each rain gauge ascertained as a base rain gauge training data is used to identify the gauges which have similar probability distribution table 3 provides the list of gauges with similar distribution as the base gauge based on the ks test the average number of gauges based on the data is 4 with a maximum of 9 and a minimum of zero no gauge data with similar distribution as that of gauge k22 was identified based on the two sample ks test the groups of gauges having similar distributions as base gauges are also clearly demarcated along with the topographic variations in the study region a k means clustering approach tan et al 2014 using a squared euclidean distance measure is used to isolate four clusters with the help of calibration data the four clusters identified by the k means approach are 1 k3 k5 k9 k17 2 k4 k8 k10 k20 k12 k16 k18 k19 3 k1 k6 k11 k13 k15 and k22 and 4 k2 k7 k14 and k21 these clusters seem to align reasonably well according to topographical variations of the region for each base gauge one or more gauges identified by distribution similarity using the ks test belong to the appropriate cluster with a base gauge fig 6 shows the common gauges identified from the ks test and cluster analysis performance measures based on ed leps and ks methods using the sl approach are provided in table 3 objective selection of gauges is also possible using chi square and ad test results in the case of the chi square test the similarities in distributions confirmed between the base and any other rain gauge observations were bin size dependent considering the arbitrariness associated with bin size specification the use of chi square test results for a selection of rain gauges is not recommended also the use of results from chi square and ad tests did not result in improved estimates of rainfall than those from the ks test in this study hence these test results are not used for rain gauge selection in this study the nnls mathematical programming formulation in the opt method is solved using a least squares methodology suggested by lawson and hanson 1974 the leps method provided estimates of missing data as good as those provided by the opt method evaluated in this study performance measures related to these two methods are provided in table 4 this was confirmed using statistical tests like those that were conducted for comparison of ed and leps methods and ed and ks methods the differences in the mean values of the error and performance measures i e rmse mae and cc are not statistically significant and were confirmed using two sample t test results different values of friction distance φ were evaluated and a value of 8 was found to be best for the leps method an optimal value of friction distance can be obtained by using a nonlinear mathematical programming formulation using the calibration data a one way anova test conducted at a 5 significance level is used to evaluate differences in mean values of performance measures at all gauges given in tables 1 and 2 from leps ks chi square and ad methods measures from 15 bin chi square test are used for this evaluation the test results point to an acceptable alternative hypothesis for measures rmse cc and null hypothesis for mae with p values of 0 0002 0 007 and 0 065 respectively the mean and median values for rmse and mae are higher and mean and median values for cc for the ad method are lower than those from other three methods also when performance measures from ad are not used the test resulted in acceptable null hypothesis with p values of 0 884 0 587 and 0 872 respectively similar results with null h 0 all samples measures come from the same distribution and alternative h 1 not all samples come from the same distribution hypotheses were also obtained with kruskal wallis tests assessments of numerical values of measures and parametric and nonparametric tests used to confirm differences in measures suggests that 1 no statistically significant differences were noted in measures obtained from methods using leps ks and chi square statistic values 2 the ks method provided almost similar performance as that of leps method and 3 the median values of performance measures of chi square and ad methods were inferior to leps and ks methods and 4 leps and ks methods provided the best measures among all the methods considering the median values of the measures the inter gauge data relationships characterized by correlations and leps scores may suggest the interpolation method using correlations as weights teegavarapu and chandramouli 2005 and a kriging approach can be used for imputation of missing data limited experiments using ordinary kriging ok for imputation with visual assessment and confirmation of semi variogram fits and with no consideration of anisotropy were conducted exponential gaussian and spherical semi variogram models for ok were evaluated results based on ccwm and ok methods for different gauges are provided in table 5 with one rain gauge chosen from each cluster shown in fig 6 in comparison with the correlation coefficient weighting method ccwm teegavarapu and chandramouli 2005 teegavarapu et al 2009 and ordinary kriging ok the leps method proposed in this study performed better when error and performance measures are evaluated after an exhaustive evaluation of different performance measures the method based on leps was found to be best among all the methods in this study the ks method was the second best method further evaluations of methods in this study and discussions in the paper are limited mostly to leps and in one case ks method improved error and performance measures based on the leps method in comparison with the ed method were also confirmed using an ensemble of 35 random missing precipitation data blocks of 4200 days at each gauge are used for the imputation of data that are assumed to be missing a total of 770 values 35 values of each measure 22 rain gauges from the ed and leps methods are compared using kernel density estimates kdes that use gaussian kernels and optimal bandwidths the kdes for rmse mae and pearson s correlation coefficient cc shown in fig 7 point to improvements in all three measures considering the mean and spread of the values shifts in probability densities towards lower magnitudes of rmse and mae and higher values for cc confirm the superiority of the leps method over the ed method similar kde based comparisons of performance measures from the ed and ks methods are shown in fig 8 the length of the historical data may affect the performance of the leps method in imputation the variability in the performances of the leps method based on length on the data used to obtain leps scores is evaluated by using different lengths of calibration data fig 9 shows the variations in rmse mae and cc values with changes in the length of the data from 10 to 100 of the training calibration data parametric one way analysis of variance anova test and nonparametric hypothesis test kruskal wallis are used to assess differences in error and performance measures initially normality of values for each measure is evaluated using one sample ks tests and the equality of variance or homogeneity of variance or homoskedasticity for a sample drawn from normally distributed population is checked using bartlett s tests and then the anova test is carried out the p values for one sample ks test obtained are 0 73 0 61 0 63 0 49 0 49 0 48 0 47 0 45 0 46 for rmse and 0 94 0 68 0 80 0 99 0 99 0 99 0 95 0 97 0 99 for mae and 0 99 0 99 0 99 0 97 0 98 0 99 0 96 0 96 0 98 for cc respectively the bartlett s test resulted in a null hypothesis being true with p values of 0 09 0 06 0 31 confirming the equality of variances for rmse mae and cc respectively levene and brown forsythe tests sheskin 2011 used also confirmed the homogeneity of variances anova p values are equal to 1 the kruskal wallis test also provided a p value equal to 1 for all the performance measures lack of any statistically significant differences in the performance measures based on different lengths of data may be attributed to 1 the representativeness of the data used for calculation of leps to the data surrounding temporal intervals in which data is assumed to be missing 2 stationarity of precipitation time series 3 time invariant inter gauge data relationships and spatial configuration of gauge network lack of any trends in wmo 2009 defined eight extreme precipitation indices viz rx1day rx5day cwd cdd r10mm r20mm sdii prcptot derived using all the available historical data at most of the rain gauge sites is also noted a non parametric spearman s rho test was used at a 5 significance level to assess the trends in these indices statistically significant trends are noted at rain gauges 4 5 15 for rx1day 5 6 and 15 for rx5day 2 and 5 for cwd 21 for cdd 15 for r20mm 5 8 13 15 and 20 for sdii the minimum and maximum p values are 0 0006 and 0 99 respectively evaluation of ed leps and ks methods based on complete observed precipitation series and gap filled series imputed time series at 22 gauges using correlation coefficients as shown in fig 10 indicates that probability space and ks statistic based methods perform better than distance based method at most of the gauges the median cc values for ep leps and ks methods obtained were 0 92 0 95 and 0 94 respectively observed and estimated values of precipitation at rain gauge k13 using three different methods for 4200 days are shown in fig 11 while all the three methods in general underestimate higher end precipitation values and overestimate lower end values the leps based model provides a lower number of under and overestimations compared to other methods in the current study approximately 25 of the complete dataset is assumed to be missing in general site specific data or distributional characteristics do not change if the threshold value i e the amount of missing data is below 5 appropriate post correction procedures i e association rule mining single best estimator and variants of quantile matching approaches reported in earlier studies by teegavarapu 2009 2014b can be adopted for improved estimates of missing precipitation values and preserve statistical properties of the imputed time series to reduce the number of overestimations of the lower end values especially zero for no rain conditions values dry day correction using the nearest neighbor gauge identified by lowest leps values derived based on observations at other gauges and the base gauge is adopted corrections for spatially interpolated estimates at any base gauge are applied using the condition specified by eq 13 13 if nk 1 nng θ nk i o 0 t h e n θ b i ec 0 e l s e θ b i ec θ b i e b i n k b the variables nng nk and θ b i ec refer to the maximum number of nearest neighbor gauges used for correction nearest neighbor gauge and the corrected spatially interpolated value in the case of rain gauge k13 the three nearest neighbors identified are k15 k1 and k6 with leps values of 0 114 0 134 and 0 136 respectively dry day corrections when applied to estimates at gauge k13 improved performance measures i e rmse mae and cc values of 4 95 mm 2 03 mm and 0 774 respectively were noted and overestimations are reduced as shown in fig 12 this correction is not without a limitation where higher end extremes are also underestimated similar performance measures i e rmse mae and cc values of 4 94 mm 2 08 mm and 0 774 respectively were obtained when gauges k1 k6 k11 k15 and k22 that belong to the same cluster as k13 are used quantile based corrections using historical data at the base gauge is recommended over these corrections even though improved measures are noted the use of proposed methods to impute missing data at different temporal resolutions is possible an experiment using leps and ed methods was conducted to estimate monthly precipitation data an improvement of 50 45 and 36 in median values of rmse mae and cc respectively for 22 stations were noted for the leps method compared to those from the ed method an exhaustive evaluation of methods proposed in this study needs to be conducted for imputation of missing data at different temporal scales before any general statements can be made about the utility of the proposed methods 6 discussion the proposed probability space based methods in this study eliminate limitations associated with the euclidean distance dependent weights in spatial interpolation methods the use of weights that are representative of the inter gauge data relationships is beneficial to any spatial interpolation method leps scores and ks chi square and ad test statistic values are sensitive to the variations in inter gauge data relationships due to climate variability and change appropriately chosen temporal windows surrounding the time intervals of missing data for calculation of these scores and statistic values will improve the imputation of data if nonstationarity in precipitation time series is suspected or confirmed leps score calculations require a chronological pairing of data between any two rain gauges whereas the other three test statistic estimations do not the latter is less restrictive than the former and is recommended when chronological pairing of data is not possible the chi square test statistic is a competitive alternative to the leps score and ks test statistic one limitation of the chi square test statistic is the subjectivity related to the number of bins used for the calculation of the statistic while the anderson darling test statistic calculation is objective it provided inferior performance compared to that of other proposed methods evaluated in this study use of probability space based methods that require leps score ks chi square and ad test statistic calculations need more computational effort than for the distance based or optimization methods the time required for leps calculations depends on the length of the historical data and the number of gauges used in interpolation the methods evaluated in this study are not immune to several limitations of any spatial interpolation approach which include 1 under and overestimation of higher end and lower end extremes respectively 2 variance inflation alteration in the first four statistical moments and autocorrelation changes in two state transition probabilities i e probabilities associated with dry or wet state transitions and extreme precipitation indices when data is imputed using any spatial interpolation method statistical characteristics of the precipitation data are altered if the imputed data record length exceeds a specific threshold value objective selection of control points for interpolation in moving from global to local interpolation scheme is an issue addressed by teegavarapu 2013 using mathematical programming models with binary variables in the current study an exercise using ks test results as criteria for objective identification of gauges as part of local interpolation has helped in the improvement of the estimates compared to distance based global interpolation conceptually simple interpolation methods of imputation such as those proposed and evaluated in this study are easy to implement with minimal computational effort and provide strong support for operational hydrology applications while the probability based methods evaluated in this study can be considered as stochastic approaches uncertainty in the precipitation estimates can only be obtained through the process of multiple imputations mis of missing data using these methods mi in this context will involve an ensemble of estimates obtained by varying the lengths of the historical data used for deriving leps scores or test statistic values i e weights or local interpolations using sub sets of all the rain gauges obtained through the evaluations of distributional similarities through two sample ks tests in a stationary climate the uncertainty in the imputed value obtained with weights derived with leps or ks statistic will be lower than that from local variants of the proposed methods the performances of probability space methods can be improved by optimizing the exponents attached to the weights also these methods when used with appropriate post imputation correction procedures for estimates will address most of the limitations of spatial interpolation methods used for imputation of missing precipitation data 7 conclusions spatial interpolation methods using four new surrogates for euclidean distances are evaluated for the imputation of precipitation records in this study the methods using leps two sample ks chi square χ 2 and anderson darling ad test statistic values as replacements for distances provided better estimates of missing precipitation records than those from a distance based method the leps based method with an appropriate exponent performed as good as an optimal interpolation method when multiple error and performance measures are assessed in this study this method also outperformed all other three methods that use different test statistic values exhaustive assessments using parametric and non parametric hypothesis tests confirm the superiority of all the proposed methods over inverse distance method and other deterministic and stochastic interpolation methods with substantial improvements noted in multiple error and performance measures objective selection of control points i e rain gauges for interpolation evaluated using a binary transformation of hypothesis test results from the ks test in one of the methods provided better estimates compared to those from a distance based method the proposed data dependent imputation methods provide alternatives to computationally intensive stochastic interpolation methods credit authorship contribution statement ramesh s v teegavarapu conceptualization data curation formal analysis investigation methodology validation visualization writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the data used for analysis in this study is available in the public domain from the kentucky agricultural weather center kawc university of kentucky the author thanks the two anonymous reviewers for their objective criticism of the paper 
5917,euclidean distance based spatial interpolation methods that are conceptually simple are commonly used for the imputation of missing precipitation and other hydroclimatic variable datasets improved variants of these methods are essential as euclidean distance will not always serve as an appropriate surrogate that can quantify the inter gauge relationships in all hydroclimatic and topographical settings probability space based error measure linear error in probability space leps and three distribution similarity hypothesis test statistic values are proposed as surrogates for distances in weighting methods to address this limitation a k fold cross validation exercise of the imputation of precipitation data at 22 rain gauges in a temperate climatic region is used for the evaluation of methods improved imputation of missing data was noted from proposed methods compared to that from a distance based method and is confirmed with statistical inference testing of multiple error and performance measures also the leps based method provided performance measures that are as good as those from a nonlinear optimization method a local spatial interpolation approach that uses leps and two sample kolmogorov smirnov hypothesis test results quantified as binary outcomes for objective selection of rain gauges are also evaluated better estimates of missing data are obtained using this approach compared to those from a euclidean distance based global interpolation method the proposed new probability space based distances are conceptually superior alternatives to euclidean distances when used in weighting methods for spatial interpolation keywords missing precipitation spatial interpolation distance weighting method linear error in probability space leps hypothesis test statistic kentucky 1 introduction availability of serially complete continuous precipitation data from rain gauge measurements is not always possible due to malfunctions of instruments systematic random and transcription errors and extreme weather events that disrupt the measurement process itself serially complete precipitation data is needed for climate variability and change studies environmental assessments and hydrological frequency analyses goly and teegavarapu 2014 serrano notivoli et al 2017 aissia et al 2017 therefore interpolation spatial or temporal becomes essential to fill any existing gaps missing data estimation at a rain gauge is a point estimation process as opposed to a surface generation i e gridded data exercise chen and liu 2012 yeggina et al 2019 temporal interpolation for the imputation of missing precipitation data is possible only if high autocorrelation is evident at low temporal resolutions e g 15 min or one hour rainfall observations often show strong persistence allowing for the use of the last observation carry forward locf procedure or baseline observation carry forward bocf or single imputation approach buuren 2012 imputation of missing precipitation at a rain gauge using spatial interpolation is the focus of this study deterministic and stochastic spatial interpolation methods using different weighting schemes employing euclidean simanton and osborn 1980 and angular shepard 1968 yeggina et al 2019 distances have been used in the past for estimation of missing precipitation data precipitation data imputation was addressed by many studies using euclidean distance based weighting method e g inverse distance weighting method idwm wei and mcguinness 1973 simanton and osborn 1980 asce 1996 garcia et al 2008 several variants of idwm were also developed to improve the interpolation by including a learned search approach hodgson 1989 that reduces the number of distance calculations and topographical information shepard 1968 and anisotropic inverse distance weighting tomczack 2008 quadrant method teegavarapu and chandramouli 2005 uses the closest gauge by euclidean distance to the base gauge i e gauge at which precipitation data is missing or assumed to be missing in each quadrant whereas normal ratio method paulhus and kohler 1952 tung 1983 uses nearest gauges with similar magnitudes of average annual precipitation totals variants of inverse distance and normal ratio methods are introduced by suhaila et al 2008 with the incorporation of the strength of correlation between any two sites and improvements were noted for precipitation imputation compared to the original versions a recent survey of spatial and temporal interpolation methods for estimation of missing precipitation data by teegavarapu 2016 serves as a good reference for understanding the limitations and advantages of these methods variants of kriging have been used to impute missing precipitation records ly et al 2011 teegavarapu and chandramouli 2005 teegavarapu 2007 several drawbacks of the kriging method include difficulty in the selection of the appropriate semi variogram uncertainty associated with the assignment of sill and nugget parameters and the computational effort required to obtain a missing precipitation value at a site imputations of precipitation data using artificial neural networks anns were reported by multiple studies kajornrit et al 2012 teegavarapu and chandramouli 2005 teegavarapu et al 2017 the semi variogram modeled using ann in a kriging approach to estimate missing precipitation data by teegavarapu 2007 is another example use of anns kim and pachepsky 2010 documented the use of two step method for constructing daily precipitation data using regression trees and anns spatially interpolated precipitation estimates were corrected with the help of association rule mining technique by teegavarapu 2009 bardossy and pegram 2014 evaluated several methods regression kriging multiple linear regression and copula based methods they noted that copula based methods performed better than all others a copula based method with support vector machines svm for filling missing precipitation data was reported by landot et al 2008 however teegavarapu et al 2017 reported that this method did not provide better estimates of missing precipitation compared to those from linear optimization and ann based methods simple substitution linear and polynomial regression and ranked regression approaches were evaluated by presti et al 2010 for the imputation of precipitation data and they concluded that the polynomial regression and simple substitution method provided better estimates of missing data than other methods a linear programming method using topographical information was reported by yoo 2013 pappas et al 2014 presented a method that uses nearest neighbors in a temporal interpolation approach for the estimation of missing data simolo et al 2010 developed a probability density function preserving approach to improve the estimation of missing daily precipitation data according to teegavarapu 2016 and brimicombe 2003 most of the spatial interpolation methods lack 1 a procedure for objective selection of an optimal number of neighbors or gauges and neighborhood size in reference to local or global interpolation 2 optimal weights in spatial interpolation schemes variants of idwm with the help of optimization formulations were developed by teegavarapu 2012 which provided mechanisms to select an optimal number of gauges identify spatial clusters to group rain gauges and use them in interpolation and use the best available gauge in each quadrant for interpolation previous studies using spatial interpolation for missing data imputation have proposed and evaluated different conceptually superior alternatives or surrogates for geographical or euclidean distances ahrens 2006 adopted a semi mean squared difference in non zero precipitation values between any two rain gauges as a replacement for geographical distance teegavarapu and chandramouli 2005 used the pearson correlation coefficient cc as a replacement for the distance that led to improvements in estimates multiple studies marteau et al 2011 westerberg et al 2009 kim et al 2008 have reported better estimates of missing precipitation data using this method compared to those from other deterministic methods ten real and binary metrics used in numerical taxonomy were adopted as substitutes for euclidean distances by teegavarapu 2014a for imputing missing data the study documented substantial improvements in multiple error measures compared to those obtained from over a dozen spatial interpolation methods a modification of idwm using elevation information of base and other rain gauges by barrios et al 2018 provided improved estimates of missing monthly precipitation records in chile compared to ann and multiple regression based methods evaluation of variants of euclidean distance based method suggests that by use of proper weighting schemes and selection of neighborhood with rain gauges surrounding a base gauge conceptually superior and simple interpolation methods that are competitive to computationally complex methods can be developed exploring parameters that characterize the inter gauge data relationships better than previously evaluated ones is attempted in this study for developing new variants of distance based or weighting methods the contents of this paper are structured as follows first the methodology adopted using probability space and hypothesis test statistic based measures is described use of these measures as substitutes for euclidean distances weighting method development and description of the optimization method objective selection of rain gauges for spatial interpolation are elaborated next applications of methods for imputation of missing data evaluation of methods and general remarks are presented next finally conclusions from the study are presented 2 methodology the methodology adopted for the development of different weighting methods for missing precipitation data estimation is shown in fig 1 a series of steps illustrated in fig 1 will show the division of available precipitation data n days at all available rain gauges in a region into calibration data n m days and validation data m days and estimation of surrogates for euclidean distances to be later used in a spatial interpolation method any surrogate for euclidean distance should 1 have an ability to characterize the inter gauge relationships using data 2 be conceptually simple to estimate and 3 be robust in handling outliers hypothesis test statistic values from distance and area based distribution similarity tests that use cumulative distribution functions cdfs of datasets such as kolmogorov smirnov ks dodge 2010 chi square and ad tests can be ideal candidates for the surrogates of euclidean distances probability space based distance defined by a linear error in probability space leps score potts et al 1996 is another potential substitute for distance details of these surrogates are explained in the next section the hypothesis test results from the ks chi square and ad tests can also be used to help in the selection of rain gauges for spatial interpolation the calibration data is used to derive leps score values and test statistic values and also to obtain the hypothesis test results i e null and alternative hypotheses considering ns rain gauges and with n observations at each rain gauge for each site or rain gauge assumed to be having missing data a total of ns 1 values of leps score and ks test statistic are derived using the calibration data the methodology proposed is applicable for estimation of missing precipitation data at a single site i e rain gauge and data are assumed to missing completely at random mcar 2 1 surrogates for distances in weighting methods four surrogates of distances defined by leps score ks chi square χ 2 and anderson darling ad test statistic values used in this study are described and the procedures for estimation of the same and their use in weighting methods are provided in this section linear error in probability space leps score potts et al 1996 is used in this study to define the mean absolute difference between cumulative frequencies déqué 2011 of the rain gauge data at any two sites the calculation of cumulative frequencies based on precipitation data at a base gauge and any other gauge and the representation of the leps score is shown in fig 2 the score β b k in eq 1 is calculated using precipitation data at the base gauge b and those at other gauge k variable n refers to the total number of observations i is the index number for a specific observation and f b θ b i is the empirical cumulative distribution function ecdf of observations and θ b i and θ k i are the observed precipitation values at a base and another gauge k respectively 1 β b k i 1 n δ i 1 n i 1 n f b θ b i f b θ k i b k i the leps score is calculated using the ecdf of the base gauge only a low value of leps score is an indication of good agreement between observations from the base rain gauge and any other gauge reciprocal of the leps score can serve as a weight associated with a gauge when used in a weighting method another surrogate of distance a measure of distributional similarity that is used in this study is the test statistic d b k obtained from a nonparametric hypothesis test a two sample two sided kolmogorov smirnov ks test dodge 2010 the statistic d b k is also referred to as ks distance or uniform distance guidici and figini 2009 the statistic is estimated by eq 2 where the variables ef b and ef k refer to the empirical cumulative distribution functions cdfs e f b θ is the proportion of θ b values less than or equal to θ at base gauge b and ef k θ is the proportion of θ k values less than or equal to θ at any other gauge k 2 d b k max θ ef b θ ef k θ k θ an alternative to the ks test statistic as a replacement for distance is the test statistic from the chi square two sample test press et al 1992 the chi square χ 2 test statistic given by eq 3 is also used and evaluated in this study precipitation data at base gauge b and another gauge k is used to calculate the statistic the variables z and z b refer to the index for the bin i e class interval and a total number of bins respectively the number of precipitation values from base gauge b within bin z is s z b and the number of values from gauge k in the same bin z is s z k 3 χ 2 b k z 1 zb s z b s z k 2 s z b s z k b k k b the anderson darling ad test statistic mil 2002 pettitt 1976 scholz and stephens 1987 is also used as a surrogate of euclidean distance in this study notation for multiple sample ad test is provided here although the test is used only with two samples i e observations at a base gauge and any other gauge in this study the ad test statistic ad b k is given by eq 4 4 ad b k n 1 n 2 l 1 lt 1 n l m 1 l h m n g lm n l i m 2 i m n i m n h m 4 b i k b where lt is the number of groups samples lt 1 2 l t n is the total number of observations n n 1 n 2 n lt h m is the number of values in the combined samples equal to z m i m is the number of values in the combined samples less than z m plus one half the number of values in the combined samples equal to z m g lm is the number of values in the l th group which are less than z m plus one half the number of values in the combined samples equal to z m n l is the number of observations in group l z 1 z 2 z l are the distinct values in the combined data set ordered from smallest to largest the ad b k is estimated with lt 2 using observations at base gauge b and any other gauge k more details of the ad test statistic can be obtained from mil 2002 pettitt 1976 and scholz and stephens 1987 2 2 weighting method the imputed precipitation value θ b i at base gauge b in an interval i is given by eq 5 as all available rain gauges are used the interpolation is considered global variable θ k i o is the precipitation value at any other rain gauge k w b k is the weight for the gauge k when missing data is estimated at base gauge b and ns is the total number of rain gauges 5 θ b i e k 1 ns 1 w b k θ k i o k 1 ns 1 w b k b i k b the weights w b k required in eq 5 are estimated using eqs 6 and 7 the variable r b k can be the euclidean distance d b k or the surrogate of the distance β b k or d b k or χ 2 b k or ad b k with exponent φ is referred to as friction distance generally a value of 2 is used for φ however it can be varied until the best performance from interpolation is achieved or optimal value for a given dataset can be obtained by solving a mathematical programming formulation teegavarapu et al 2017 6 w b k 1 r b k φ b k k b φ 1 2 10 7 r b k β b k o r r b k d b k o r r b k d b k o r r b k χ 2 b k o r r b k ad b k b k methods using euclidean distance leps score ks chi square and anderson darling test statistic values are referred to as ed leps ks chi square and ad methods respectively in this study 2 3 objective selection of rain gauges the selection of rain gauges objectively for imputation is accomplished with the help of the binary variable s assigned to the outcome of the ks ad and hypothesis tests the chi square χ 2 two sample test with null and alternative hypotheses i e h 0 the two datasets come from a common distribution and h 1 the two datasets do not come from a common distribution can be used for the selection of rain gauges for interpolation similar to the use of the ks test also the two sample version of the ad test with null and alternative hypotheses i e h 0 the populations from which two or more groups of data were drawn are identical and h 1 the that the populations from which two or more groups of data were drawn are not identical can be used for selection of rain gauges for interpolation similar to the use of the ks test for the ks test if f b and f k represent the true but unknown cumulative distribution functions cdfs of observations at the base and other gauge k respectively then ks test statistic eq 2 can be used to determine if independent random samples data at the base and another gauge are taken from the same population the ks test examines two hypotheses the null hypothesis h 0 f b θ f k θ suggesting two samples are from the same distribution or the alternative hypothesis h 1 f b θ f k θ suggesting two samples are from different distributions testing of the hypothesis can be carried out either by comparing the test statistic d b k with a critical value d c as indicated by eq 8 or by comparing p value with a pre specified significance level α the result from ks test i e null hypothesis accepted or null hypothesis rejected at a pre specified significance level can be quantified as a binary value using a variable λ b k as indicated by inequality 8 8 if d b k d c o r p v a l u e α t h e n h 0 n u l l h y p o t h e s i s i s a c c e p t e d a n d λ b k 1 e l s e h 1 a l t e r n a t i v e h y p o t h e s i s i s a c c e p t e d a n d λ b k 0 inclusion of binary variable λ b k variable in eq 9 may exclude a subset of all rain gauges from the weighting scheme 9 θ b i e k 1 ns 1 w b k θ k i o λ b k k 1 ns 1 w b k λ b k b i k b this procedure of objective selection of gauges for interpolation is referred to as the sl approach in this study for any base site if the k 1 ns 1 λ b k 0 then imputed data value is obtained out using eq 9 with an appropriate distance the weights i e w b k values can be based on euclidean distance leps score or any test statistic discussed in the earlier sections 2 4 optimal interpolation method an optimal spatial interpolation method using non negative least squares nnls formulation is also developed in this study the formulation when solved as a constrained least squares problem will provide optimal weights required for the imputation of missing data the formulation with objective function in eq 10 provides non negative weights due to the inclusion of a constraint given by inequality 11 10 m i n i m i z e e x f 2 2 subject to 11 w b k o 0 b k k b the variables e x and f are vectors e is the m n ns 1 matrix of θ m n n s 1 values x defines the ns 1x 1 of w b k o weight values and f refers to m n 1 observed precipitation values of data at the base gauge eq 10 serves as an objective function that is minimized a constraint that enforces non negative weights is included in the formulation using inequality 11 the optimal weights obtained from the solution of nnls formulation are used in eq 11 for the imputation of precipitation data using eq 12 12 θ b i e k 1 ns 1 w b k o θ k i o b i k b this method has been used in past studies teegavarapu 2012 2014a and was proven to provide better estimates than kriging and several deterministic spatial interpolation methods this method is referred to as the opt method 3 case study application the methods described in earlier sections are used for the imputation of daily missing precipitation records at several rain gauges located in kentucky usa rain gauge locations and the topographic details of the region are shown in fig 3 the case study region i e kentucky has a temperate climate dominated by frontal precipitation the climate for the region is characterized as fully humid warm with hot summer conditions as indicated by kottek et al 2006 based on the köppen geiger classification scheme long term precipitation data from the calendar year 1971 to 2016 at 22 rain gauges in this region are used for the evaluation of proposed methods a chronologically continuous i e gap free observation set of 16 802 days of precipitation data for all gauges is obtained from the kentucky agricultural weather center kawc a holdout procedure in which data are randomly assigned to two datasets for calibration or training and validation or testing is used the lengths of calibration and validation datasets are 12 602 and 4 200 days respectively the validation dataset 4 200 days constitutes 25 of the entire available data and is randomly selected the methodology explained in fig 1 refers to these two datasets by variable notation n m and m respectively also to evaluate the robustness of the methods proposed 35 random 4200 day blocks of data at each gauge are selected and are assuming to be missing these missing data are estimated using different methods at all gauges a k fold validation procedure in which the training dataset sample of 12602 days is randomly partitioned into k unequal sized sub samples with a constant size of validation dataset i e 4200 days is adopted in the current study the sub samples are used for estimation of parameters for the methods and the validation data is used for testing 4 measures for evaluation of methods error measures derived using observed and imputed precipitation data such as mean absolute error mae root mean squared error rmse and a performance measure pearson correlation coefficient cc are used to evaluate the methods the measures are calculated based on the validation data statistically significant differences in measures between any two methods or among measures derived from multiple executions of the same method are confirmed using parametric and nonparametric hypothesis tests notations for parameters used to explain null and alternative hypotheses in these tests refer to population parameters as inferences are made about them from the available sample data 4 1 evaluation of differences in measures an unpaired two sample t test is used to confirm statistically significant differences between error and performance measures obtained from any two methods the test uses the null and alternative hypotheses h 0 μ 1 μ 2 and h 1 μ 1 μ 2 and helps to assess the differences in the mean values i e μ 1 μ 2 of the measures as normality of the samples is a requirement for the t test a goodness of fit test for the gaussian distribution the kolmogorov smirnov ks test massey 1951 sheskin 2011 is used the t test also requires evaluation of variances i e σ 1 2 σ 2 2 for which the fisher test f test sheskin 2011 with null and alternative hypotheses h 0 σ 1 2 σ 2 2 and h 1 σ 1 2 σ 2 2 respectively is used a t test that employs satterthwaite s approximation satterthwaite 1946 for the estimation of effective degrees of freedom for situations with unequal variances is also used in this study 4 2 evaluation of bi variate relationships and trends spearman s rho ρ test sheskin 2011 that uses the rank order correlation coefficient to assess the monotonic association between any two metrics or evaluate trends is used in this study the null and alternative hypotheses for the test are h 0 ρ 0 and h 1 ρ 0 respectively spearman s rho test is used to evaluate the association between leps and pearson s correlation coefficient and also trends in extreme precipitation indices in this study 4 3 evaluation of differences in multiple measures one way analysis of variance anova sheskin 2011 is used to evaluate differences in mean values of more than two performance measures derived from multiple executions of one single method or from multiple methods the null and alternative hypotheses are h 0 μ 1 μ 2 μ 3 μ np and h 1 means μ 1 μ 2 μ np are not all equal the variable np is the number of groups of performance measures homoskedasticity of variances of the measures is evaluated using bartlett s test bartlett 1937 sheskin 2011 with null and alternative hypotheses as h 0 σ 1 2 σ 2 2 σ np 2 and h 1 σ l 2 σ m 2 for at least one pair l m and l m n p a non parametric version of the one way anova test the kruskal wallis h test kruskal and wallis 1952 sheskin 2011 corder and foreman 2009 was also employed in this study the p value i e probability calculated under the null hypothesis of having an outcome as extreme as the observed value in the sample dodge 2010 for each test is also reported 4 4 nonparametric visual assessment of measures kernel density estimates kdes bowman and azzalini 1997 as nonparametric representations of the probability density functions pdfs and as replacements for histograms are used to aid comparative visual assessments of error and performance measures a gaussian kernel smoothing function with optimal bandwidth that controls the smoothness is used in the current study 5 results and analysis the possibility of using temporal interpolation for the imputation of missing values was initially evaluated in this study by checking the autocorrelation function acf of precipitation data at several temporal lags at each rain gauge fig 4 shows the autocorrelation values at several lags for data at all rain gauges the upper and lower confidence bounds 95 confidence limits 1 96 n of 0 0178 and 0 0178 respectively are also shown almost all autocorrelation values at several lags are between these bounds the acfs suggest that daily precipitation data constitutes a white noise with serially uncorrelated random values based on this observation it can be concluded that temporal interpolation is not an option for the imputation of missing data due to lack of strong autocorrelation at several temporal lags imputation of missing data is initially carried out at 22 stations using 4200 days of missing data and later with 35 ensembles of 4200 days randomly selected from the training data without replacement the friction distance parameter φ is assigned a value of 2 in this study a total of 462 leps scores 22 21 and pearson correlation coefficients ccs based on data from 22 gauges are obtained the calculations of leps scores are based on n p2 permutations 22 p2 as there are 22 gauges and two gauges are used for one leps score estimation the total number of leps scores obtained is equal to 462 it important to note that for leps score β 1 2 β 2 1 as ecdfs of gauge 1 and gauge 2 are used to calculate β 1 2 and β 2 1 respectively the joint variation of leps scores and correlation coefficients is shown in fig 5 this variation is evaluated as correlations based on observations reflect the inter gauge relationships a least squares regression line provided points to evidence of a strong linear relationship between leps and cc statistically significant correlation of 0 963 was observed and was confirmed by the alternative hypothesis i e the existence of non zero correlation from spearman s rho test with a p value less than 0 0001 error and performance measures from the applications of the ed leps and ks methods for imputation of missing data comprising of 4200 days are provided in table 1 a review of the error and performance measures suggests that leps method performs better than the ed method to confirm that the differences in the error and performance measures from two methods are statistically significant a parametric hypothesis test a t test is used the normality of rmse mae and cc values are confirmed using a goodness of fit test one sample ks test with null hypothesis accepted with p values of 0 91 0 46 0 94 0 99 and 0 86 and 0 98 and respectively the f test confirmed the equality of variances for rmse values with a p value of 0 19 inequality of variances for mae and cc values with p values of 0 015 and 0 001 respectively two types of two sample t tests were conducted for equal and unequal variances at a 5 significance level α the test results indicate the acceptance of the alternative hypothesis suggesting the mean values of rmse mae and cc from the ed and leps methods are unequal with p values close to zero the mean values of rmse mae and cc for the ed and leps methods are 7 46 mm and 6 10 mm 3 16 mm and 2 59 mm and 0 54 and 0 70 respectively error and performance measures based on ks are also provided in table 1 to confirm statistically significant differences in measures between ed and ks methods hypothesis tests i e two sample t tests are used the normality checks for rmse mae and cc values are confirmed using a goodness of fit test one sample ks test with the null hypothesis being accepted with p values of 0 91 0 93 0 94 0 53 and 0 86 and 0 91 and respectively the f test confirmed the equality of variances for rmse values with a p value of 0 10 inequality of variances for mae and cc values with p values of 0 005 and 0 003 respectively two types of unpaired two sample t tests were conducted for equal and unequal variances at a 5 significance level α the test results indicated the acceptance of the alternative hypothesis suggesting the mean values of rmse mae and cc from the ed and ks methods are unequal with p values close to zero the mean values of rmse mae and cc for the ed and ks methods are 7 46 6 18 3 16 and 2 56 mm and 0 54 and 0 69 respectively imputation of precipitation data using the chi square method obtained from training data with 9 and 15 bins and a value of 2 for the exponent φ in eq 5 is carried out results from these experiments using two different bin sizes provided in table 2 to confirm the sensitivity of the statistic to the bin size also the error and performance measures improved as the number of bins increased from 9 to 15 measures from bin size of 15 are used for further comparison performance measures using the chi square method were better than those from the ed method a two sample unpaired t test after conducting normality and fisher tests with alternative hypotheses being accepted with p values close to 0 confirmed that the performance measures from both the methods are different at a statistical significance level of 5 the error measures from chi square and leps methods are also compared using t tests the t tests results noted the null hypothesis being true with p values of 0 97 0 31 and 0 97 for rmse mae and cc measures respectively suggesting the chi square and leps methods provided similar results with no statistically significant differences results based on the ad method are also provided in table 2 the performance measures obtained from this method were inferior to those from leps method and are statistically different for rmse and cc with p values from t tests equal to 0 003 and 0 02 respectively a two sample two sided ks test is used for two specific purposes in this study 1 to obtain the test statistic d b k and 2 to obtain hypothesis test result with one of the hypotheses h 0 or h 1 being accepted the two sided test assumes that two distributions are unequal i e f b θ f k θ a significance level α of 5 is used for hypothesis testing in this study the decision to reject the null hypothesis is based on a comparative evaluation of p value and significance level α as suggested by conditional inequality 3 and not based on comparison of the test statistic with the critical value in the current study the asymptotic p value a p value that is calculated using an approximation to the true distribution is used the use of p value is mainly due to the algorithmic implementation of test available in the proprietary software used in this study since the sample size i e length of training data n 12802 days is large the asymptotic p value and exact p value a value calculated using the true distribution of the sample are similar and can provide defensible hypothesis test results the asymptotic p value used is considered accurate and valid as the condition n1 n 2 n 1 n 2 4 or n2 2n 4 if n 1 n 2 is satisfied with n value equal to the length of the training data i e n m 12802 days for any two rain gauges the ks test is also used to confirm the distribution similarity between observations at a base rain gauge and any other gauge at a significance level of 5 for each rain gauge ascertained as a base rain gauge training data is used to identify the gauges which have similar probability distribution table 3 provides the list of gauges with similar distribution as the base gauge based on the ks test the average number of gauges based on the data is 4 with a maximum of 9 and a minimum of zero no gauge data with similar distribution as that of gauge k22 was identified based on the two sample ks test the groups of gauges having similar distributions as base gauges are also clearly demarcated along with the topographic variations in the study region a k means clustering approach tan et al 2014 using a squared euclidean distance measure is used to isolate four clusters with the help of calibration data the four clusters identified by the k means approach are 1 k3 k5 k9 k17 2 k4 k8 k10 k20 k12 k16 k18 k19 3 k1 k6 k11 k13 k15 and k22 and 4 k2 k7 k14 and k21 these clusters seem to align reasonably well according to topographical variations of the region for each base gauge one or more gauges identified by distribution similarity using the ks test belong to the appropriate cluster with a base gauge fig 6 shows the common gauges identified from the ks test and cluster analysis performance measures based on ed leps and ks methods using the sl approach are provided in table 3 objective selection of gauges is also possible using chi square and ad test results in the case of the chi square test the similarities in distributions confirmed between the base and any other rain gauge observations were bin size dependent considering the arbitrariness associated with bin size specification the use of chi square test results for a selection of rain gauges is not recommended also the use of results from chi square and ad tests did not result in improved estimates of rainfall than those from the ks test in this study hence these test results are not used for rain gauge selection in this study the nnls mathematical programming formulation in the opt method is solved using a least squares methodology suggested by lawson and hanson 1974 the leps method provided estimates of missing data as good as those provided by the opt method evaluated in this study performance measures related to these two methods are provided in table 4 this was confirmed using statistical tests like those that were conducted for comparison of ed and leps methods and ed and ks methods the differences in the mean values of the error and performance measures i e rmse mae and cc are not statistically significant and were confirmed using two sample t test results different values of friction distance φ were evaluated and a value of 8 was found to be best for the leps method an optimal value of friction distance can be obtained by using a nonlinear mathematical programming formulation using the calibration data a one way anova test conducted at a 5 significance level is used to evaluate differences in mean values of performance measures at all gauges given in tables 1 and 2 from leps ks chi square and ad methods measures from 15 bin chi square test are used for this evaluation the test results point to an acceptable alternative hypothesis for measures rmse cc and null hypothesis for mae with p values of 0 0002 0 007 and 0 065 respectively the mean and median values for rmse and mae are higher and mean and median values for cc for the ad method are lower than those from other three methods also when performance measures from ad are not used the test resulted in acceptable null hypothesis with p values of 0 884 0 587 and 0 872 respectively similar results with null h 0 all samples measures come from the same distribution and alternative h 1 not all samples come from the same distribution hypotheses were also obtained with kruskal wallis tests assessments of numerical values of measures and parametric and nonparametric tests used to confirm differences in measures suggests that 1 no statistically significant differences were noted in measures obtained from methods using leps ks and chi square statistic values 2 the ks method provided almost similar performance as that of leps method and 3 the median values of performance measures of chi square and ad methods were inferior to leps and ks methods and 4 leps and ks methods provided the best measures among all the methods considering the median values of the measures the inter gauge data relationships characterized by correlations and leps scores may suggest the interpolation method using correlations as weights teegavarapu and chandramouli 2005 and a kriging approach can be used for imputation of missing data limited experiments using ordinary kriging ok for imputation with visual assessment and confirmation of semi variogram fits and with no consideration of anisotropy were conducted exponential gaussian and spherical semi variogram models for ok were evaluated results based on ccwm and ok methods for different gauges are provided in table 5 with one rain gauge chosen from each cluster shown in fig 6 in comparison with the correlation coefficient weighting method ccwm teegavarapu and chandramouli 2005 teegavarapu et al 2009 and ordinary kriging ok the leps method proposed in this study performed better when error and performance measures are evaluated after an exhaustive evaluation of different performance measures the method based on leps was found to be best among all the methods in this study the ks method was the second best method further evaluations of methods in this study and discussions in the paper are limited mostly to leps and in one case ks method improved error and performance measures based on the leps method in comparison with the ed method were also confirmed using an ensemble of 35 random missing precipitation data blocks of 4200 days at each gauge are used for the imputation of data that are assumed to be missing a total of 770 values 35 values of each measure 22 rain gauges from the ed and leps methods are compared using kernel density estimates kdes that use gaussian kernels and optimal bandwidths the kdes for rmse mae and pearson s correlation coefficient cc shown in fig 7 point to improvements in all three measures considering the mean and spread of the values shifts in probability densities towards lower magnitudes of rmse and mae and higher values for cc confirm the superiority of the leps method over the ed method similar kde based comparisons of performance measures from the ed and ks methods are shown in fig 8 the length of the historical data may affect the performance of the leps method in imputation the variability in the performances of the leps method based on length on the data used to obtain leps scores is evaluated by using different lengths of calibration data fig 9 shows the variations in rmse mae and cc values with changes in the length of the data from 10 to 100 of the training calibration data parametric one way analysis of variance anova test and nonparametric hypothesis test kruskal wallis are used to assess differences in error and performance measures initially normality of values for each measure is evaluated using one sample ks tests and the equality of variance or homogeneity of variance or homoskedasticity for a sample drawn from normally distributed population is checked using bartlett s tests and then the anova test is carried out the p values for one sample ks test obtained are 0 73 0 61 0 63 0 49 0 49 0 48 0 47 0 45 0 46 for rmse and 0 94 0 68 0 80 0 99 0 99 0 99 0 95 0 97 0 99 for mae and 0 99 0 99 0 99 0 97 0 98 0 99 0 96 0 96 0 98 for cc respectively the bartlett s test resulted in a null hypothesis being true with p values of 0 09 0 06 0 31 confirming the equality of variances for rmse mae and cc respectively levene and brown forsythe tests sheskin 2011 used also confirmed the homogeneity of variances anova p values are equal to 1 the kruskal wallis test also provided a p value equal to 1 for all the performance measures lack of any statistically significant differences in the performance measures based on different lengths of data may be attributed to 1 the representativeness of the data used for calculation of leps to the data surrounding temporal intervals in which data is assumed to be missing 2 stationarity of precipitation time series 3 time invariant inter gauge data relationships and spatial configuration of gauge network lack of any trends in wmo 2009 defined eight extreme precipitation indices viz rx1day rx5day cwd cdd r10mm r20mm sdii prcptot derived using all the available historical data at most of the rain gauge sites is also noted a non parametric spearman s rho test was used at a 5 significance level to assess the trends in these indices statistically significant trends are noted at rain gauges 4 5 15 for rx1day 5 6 and 15 for rx5day 2 and 5 for cwd 21 for cdd 15 for r20mm 5 8 13 15 and 20 for sdii the minimum and maximum p values are 0 0006 and 0 99 respectively evaluation of ed leps and ks methods based on complete observed precipitation series and gap filled series imputed time series at 22 gauges using correlation coefficients as shown in fig 10 indicates that probability space and ks statistic based methods perform better than distance based method at most of the gauges the median cc values for ep leps and ks methods obtained were 0 92 0 95 and 0 94 respectively observed and estimated values of precipitation at rain gauge k13 using three different methods for 4200 days are shown in fig 11 while all the three methods in general underestimate higher end precipitation values and overestimate lower end values the leps based model provides a lower number of under and overestimations compared to other methods in the current study approximately 25 of the complete dataset is assumed to be missing in general site specific data or distributional characteristics do not change if the threshold value i e the amount of missing data is below 5 appropriate post correction procedures i e association rule mining single best estimator and variants of quantile matching approaches reported in earlier studies by teegavarapu 2009 2014b can be adopted for improved estimates of missing precipitation values and preserve statistical properties of the imputed time series to reduce the number of overestimations of the lower end values especially zero for no rain conditions values dry day correction using the nearest neighbor gauge identified by lowest leps values derived based on observations at other gauges and the base gauge is adopted corrections for spatially interpolated estimates at any base gauge are applied using the condition specified by eq 13 13 if nk 1 nng θ nk i o 0 t h e n θ b i ec 0 e l s e θ b i ec θ b i e b i n k b the variables nng nk and θ b i ec refer to the maximum number of nearest neighbor gauges used for correction nearest neighbor gauge and the corrected spatially interpolated value in the case of rain gauge k13 the three nearest neighbors identified are k15 k1 and k6 with leps values of 0 114 0 134 and 0 136 respectively dry day corrections when applied to estimates at gauge k13 improved performance measures i e rmse mae and cc values of 4 95 mm 2 03 mm and 0 774 respectively were noted and overestimations are reduced as shown in fig 12 this correction is not without a limitation where higher end extremes are also underestimated similar performance measures i e rmse mae and cc values of 4 94 mm 2 08 mm and 0 774 respectively were obtained when gauges k1 k6 k11 k15 and k22 that belong to the same cluster as k13 are used quantile based corrections using historical data at the base gauge is recommended over these corrections even though improved measures are noted the use of proposed methods to impute missing data at different temporal resolutions is possible an experiment using leps and ed methods was conducted to estimate monthly precipitation data an improvement of 50 45 and 36 in median values of rmse mae and cc respectively for 22 stations were noted for the leps method compared to those from the ed method an exhaustive evaluation of methods proposed in this study needs to be conducted for imputation of missing data at different temporal scales before any general statements can be made about the utility of the proposed methods 6 discussion the proposed probability space based methods in this study eliminate limitations associated with the euclidean distance dependent weights in spatial interpolation methods the use of weights that are representative of the inter gauge data relationships is beneficial to any spatial interpolation method leps scores and ks chi square and ad test statistic values are sensitive to the variations in inter gauge data relationships due to climate variability and change appropriately chosen temporal windows surrounding the time intervals of missing data for calculation of these scores and statistic values will improve the imputation of data if nonstationarity in precipitation time series is suspected or confirmed leps score calculations require a chronological pairing of data between any two rain gauges whereas the other three test statistic estimations do not the latter is less restrictive than the former and is recommended when chronological pairing of data is not possible the chi square test statistic is a competitive alternative to the leps score and ks test statistic one limitation of the chi square test statistic is the subjectivity related to the number of bins used for the calculation of the statistic while the anderson darling test statistic calculation is objective it provided inferior performance compared to that of other proposed methods evaluated in this study use of probability space based methods that require leps score ks chi square and ad test statistic calculations need more computational effort than for the distance based or optimization methods the time required for leps calculations depends on the length of the historical data and the number of gauges used in interpolation the methods evaluated in this study are not immune to several limitations of any spatial interpolation approach which include 1 under and overestimation of higher end and lower end extremes respectively 2 variance inflation alteration in the first four statistical moments and autocorrelation changes in two state transition probabilities i e probabilities associated with dry or wet state transitions and extreme precipitation indices when data is imputed using any spatial interpolation method statistical characteristics of the precipitation data are altered if the imputed data record length exceeds a specific threshold value objective selection of control points for interpolation in moving from global to local interpolation scheme is an issue addressed by teegavarapu 2013 using mathematical programming models with binary variables in the current study an exercise using ks test results as criteria for objective identification of gauges as part of local interpolation has helped in the improvement of the estimates compared to distance based global interpolation conceptually simple interpolation methods of imputation such as those proposed and evaluated in this study are easy to implement with minimal computational effort and provide strong support for operational hydrology applications while the probability based methods evaluated in this study can be considered as stochastic approaches uncertainty in the precipitation estimates can only be obtained through the process of multiple imputations mis of missing data using these methods mi in this context will involve an ensemble of estimates obtained by varying the lengths of the historical data used for deriving leps scores or test statistic values i e weights or local interpolations using sub sets of all the rain gauges obtained through the evaluations of distributional similarities through two sample ks tests in a stationary climate the uncertainty in the imputed value obtained with weights derived with leps or ks statistic will be lower than that from local variants of the proposed methods the performances of probability space methods can be improved by optimizing the exponents attached to the weights also these methods when used with appropriate post imputation correction procedures for estimates will address most of the limitations of spatial interpolation methods used for imputation of missing precipitation data 7 conclusions spatial interpolation methods using four new surrogates for euclidean distances are evaluated for the imputation of precipitation records in this study the methods using leps two sample ks chi square χ 2 and anderson darling ad test statistic values as replacements for distances provided better estimates of missing precipitation records than those from a distance based method the leps based method with an appropriate exponent performed as good as an optimal interpolation method when multiple error and performance measures are assessed in this study this method also outperformed all other three methods that use different test statistic values exhaustive assessments using parametric and non parametric hypothesis tests confirm the superiority of all the proposed methods over inverse distance method and other deterministic and stochastic interpolation methods with substantial improvements noted in multiple error and performance measures objective selection of control points i e rain gauges for interpolation evaluated using a binary transformation of hypothesis test results from the ks test in one of the methods provided better estimates compared to those from a distance based method the proposed data dependent imputation methods provide alternatives to computationally intensive stochastic interpolation methods credit authorship contribution statement ramesh s v teegavarapu conceptualization data curation formal analysis investigation methodology validation visualization writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the data used for analysis in this study is available in the public domain from the kentucky agricultural weather center kawc university of kentucky the author thanks the two anonymous reviewers for their objective criticism of the paper 
5918,multi satellite sensing of continental water surfaces ws represents an unprecedented and increasing potential for studying ungauged hydrological and hydraulic processes from their signatures especially on complex flow zones such as anabranching rivers however the estimation of discharge from ws observations only is a very challenging ill posed inverse problem due to unknown bathymetry and friction in ungauged rivers measurements nature quality and spatio temporal resolutions regarding the flow model scales this paper proposes an effective 1d hydraulic modeling approach of sufficient complexity to describe anabranching river flows from sparse multisatellite observations using the hivdi inverse method presented in larnier et al 2019 with an augmented control vector including a spatially distributed friction law k x h depending on the flow depth h it is shown on 71 km of the xingu river anabranching amazon basin with altimetric water height timeseries that a fairly accurate upstream discharge hydrograph and effective patterns of channel bathymetry and friction can be inferred simultaneously the coherence between the sparse observation grid and the fine hydraulic model grid is ensured in the optimization process by imposing a piecewise linear bathymetry profile b x which is consistent with the hydraulic visibility ofws signatures garambois et al 2017 montazem et al 2019 the discharge hydrograph q t at observation times and effective bathymetry friction b x k x h patterns are retrieved from 8 years of satellite altimetry envisat at 6 virtual stations vs along flow next the potential of the forthcoming swot data dense in space is highlighted by inferring a discharge hydrograph and dense patterns of effective river bathymetry and friction a physically consistent scaling of friction by reaches enables to consider more dense bathymetry controls finally a numerical analysis shows i the importance of an unbiased prior information in the inference of a triplet q b x k x h from ws observations ii the clear signatures of river bottom slope break in low flows and width variations in high flows through the analysis of the friction slope term which is consistent with the findings of montazem et al 2019 from ws curvature analysis keywords anabranching river ungauged river 1d hydraulic model variational assimilation satellite altimetry swot hydraulic visibility 1 introduction fresh water is a crucial earth s resource and its journey from the clouds to the oceans passes through the hydrographic network in order to characterize hydrological fluxes an essential physical variable is river discharge cf global climate observing system w m o 2016 representing an integration of upstream hydrological processes in complement of in situ sensors networks which are declining in some regions e g fekete and vorosmarty 2002 increasingly accurate measurements of hydrological and hydraulic variables and especially river surface variabilities are now enabled by myriads of satellites for earth observation and new generations of sensors e g vorosmarty et al 1996 alsdorf and lettenmaier 2003 calmant et al 2008 schumann and domeneghetti 2016 the forthcoming surface water and ocean topography swot wide swath altimetric mission cnes nasa planned to be launched in 2021 will provide a quasi global river surfaces mapping with an unprecedented spatial and temporal resolution on water surface ws height width and slope decimetric accuracy on ws height averaged over 1 km 2 1 to 4 revisits every 21 days cycle alsdorf et al 2007 durand et al 2010 rodriguez 2012 biancamaria et al mar 2016 rodriguez et al 2018 in addition to decades of nadir altimetry e g frappart et al 2006 birkett 1998 da silva et al 2012 calmant et al 2016 and imagery e g allen and pavelsky 2018 on inland waters swot will enable an unprecedented hydraulic visibility as defined from hydraulic analysis in garambois et al 2017 montazem et al 2017 montazem et al 2019 of hydrological responses and hydraulic variabilities within river networks multi satellite observations of water surfaces from the local to the hydrographic network scale indeed represent an unprecedented observability of hydrological responses through hydraulic processes signatures especially on complex flow zones such as floodplains or anabranching rivers see river morphology classification in nanson and knighton 1996 this increased hydraulic visibility represents a great potential to learn hydrodynamic behaviors and infer hydrological fluxes the estimation of river discharge from water surface observations elevations top width remains an open and difficult question especially in case of unknown or poorly known river bathymetry friction or lateral fluxes several open channel inverse problems are studied in a relatively recent literature in a satellite data context with more or less complex flow models and inverse methods cf biancamaria et al mar 2016 for a review few studies started to highlight the benefits of assimilating synthetic swot ws observations in simplified hydraulic models with sequential methods for inferring inflow discharge assuming known river friction and bathymetry andreadis et al 2007 biancamaria et al 2011 or inferring bathymetry assuming known friction durand et al 2008 yoon et al 2012 next low complexity methods have been proposed for estimating river discharge in case of unknown bathymetry and friction based on the manning equation durand et al 2014 garambois and monnier 2015 or hydraulic geometries gleason and smith 2014 or empirical flow models durand et al 2016 see also bjerklie et al 2018 they are tested on 19 rivers with synthetic swot like daily observations in durand et al 2016 and their robustness and accuracy is found to fluctuate the importance of good prior guesses is highlighted the combined use of dynamic flow models and optimization methods enables to benefit from ws observations for solving hydraulic inverse problems as shown for flood hydrograph inference in roux and dartus 2006 from ws width time series used to optimize a 1d hydraulic model or in honnorat et al 2006 hostache et al 2010 lai and monnier 2009 by variational assimilation of flow depth time series in a 2d hydraulic model the variational data assimilation vda approach see e g cacuci et al 2013 and references therein is well suited to solve the present inverse problem see brisset et al 2018 oubanas et al 2018 larnier et al 2019 and references therein it consists in fitting the hydraulic model response to the observed ws elevations by optimizing the input parameters in a variational framework however altimetry measurements of ws are relatively sparse in time compared to local flow dynamics this important aspect of the inverse problem is investigated in brisset et al 2018 with the introduction of the identifiability maps the latter consist to represent in space time the available information ws observables hydraulic waves and an estimation of the misfit with the local equilibrium these maps enable to estimate if the sought upstream discharge information has been observed or not within the downstream river surface deformations also they help to estimate inferable hydrograph frequencies brisset et al 2018 or inferable hydrograph time windows larnier et al 2019 the inference of the hydraulic triplet inflow discharge q t effective bathymetry b x and friction coefficient k from swot like ws observations is investigated in recent studies using 1d hydraulic and variational assimilation methods e g brisset et al 2018 gejadze and malaterre 2017 oubanas et al 2018 larnier et al 2019 however the inference of the triplet from ws observations remains a very challenging inverse problem because of the correlated influence of temporal discharge and spatial bathymetry friction controls on the simulated flow lines this is especially true because of the bathymetry friction equifinality issue see the discussions in garambois and monnier 2015 and larnier et al 2019 those recently developed vda methods enable to infer accurately the inflow discharge from water surface observables considering unknown uncertain channel bathymetry friction but from accurate prior information and synthetic ws observations note that a strong prior such as a known stage discharge relationship rating curve downstream of a river domain as it is done in oubanas et al 2018 can control part of the simulated flow lines fluvial regime as a consequence the vda process may converge to the discharge hydrograph corresponding to the imposed almost exact rating curve in the present study the downstream boundary condition bc is an unknown of the inverse problem a crucial point is the sensitivity of the triplet inference to the prior value from which the inference is started and it is studied in a swot observability context in garambois and monnier 2015 yoon et al 2016 larnier et al 2019 tuozzolo et al 2019 the sensitivity of the estimated discharge in the triplet to the prior is highlighted by recent estimates performed from airswot airborne measurements on the willamette river tuozzolo et al 2019 the temporal signal is well retrieved at observation times but using a biased prior hydrograph results in a biased hydrograph inference see detailed investigations in larnier et al 2019 in view to infer worldwide river discharges from the future swot observations especially for ungauged cases a hierarchical modeling strategy hivdi hierarchical variational discharge inversion is proposed in larnier et al 2019 the hivdi approach includes low complexity flow relations under the assumption of low froude and locally steady state flows which improves the robustness of the inferences in particular if an unbiaised average value of q is provided it may be provided by a database or a regional hydrological model note that if introducing an a priori information such as a single depth measurement it enables to reconstruct an effective low flow bathymetry see gessese et al 2011 garambois and monnier 2015 larnier et al 2019 all the studies mentioned above mostly address single channel natural rivers 100 km in length without lateral inflows and using synthetic datasets except in tuozzolo et al 2019 with airswot data moreover very few studies address the modeling of effective 1d channels from real satellite data e g garambois et al 2017 schneider et al 2017 the present paper investigates the effective hydraulic modeling of anabranching river flows from real multi sensor satellite observations of ws the challenging inference of the hydraulic triplet q t b x k x h and its sensitivity to observation density in space anabranching rivers are characterized by complex hydraulic geometries relationships across flow regimes as shown in schubert et al 2015 through an analysis of a metric resolution 2d shallow water model of an anabranching portion of the platte river us the key point here is to build up a sufficiently complex model to describe anabranching river flows and in coherence with the spatio temporal scales of satellite altimetry measurements based on the inverse method presented in larnier et al 2019 and brisset et al 2018 an effective hydraulic modeling strategy is adapted for tackling anabranching river flows using i effective 1d cross sections based on real multi satellite data from low to high flows ii a spatially distributed friction law depending on modeled water depth h the inference of distributed hydraulic parameters patterns is investigated on a 71 km long reach of the xingu river amazone basin from real altimetric observations gained on a single envisat track or from synthetic swot observations low identifiability index as introduced in brisset et al 2018 and detailed in section 4 the influence of the spatial density of ws observations on the identifiability of spatial controls patterns in the unknown triplet is studied a piecewise linear bathymetry representation is introduced along with a friction power law with piecewise constant parameters to put in coherence the observations and the flow model grids their constraining effect on the inversions is studied with spatially and temporally sparse satellite observations furthermore numerical investigations are performed to test the sensitivity of hydraulic inferences to prior hydraulic values and also assess the correlated influence of bathymetry and friction on the modeled flow lines equifinality across flow regimes this study is organized as follows section 2 presents the 1d saint venant flow model and the effective modeling approach for anabranching rivers including i a spatially distributed friction law depending on the modeled flow depth ii the construction of an effective channel geometry from multi satellite observations iii an inverse method based on variational data assimilation section 3 focuses on the calibration of the effective model on 8 years of ws observations gained from envisat altimeter on a single track along this anabranching river using this model as a reference section 4 proposes detailed investigations of the hydraulic inferences from real envisat or synthetic swot observations considering this anabranching river as ungauged the discussion in section 5 presents a numerical sensitivity analysis to the hydraulic prior and some investigations on the bathymetry friction equifinality 2 modeling approach this section proposes an original 1d effective modeling approach of adequate complexity for modeling anabranching river flows across fluvial regimes and in coherence with satellite observations the approach is built on an effective channel cross section derived from multi satellite measurements and a spatially distributed friction law depending on the flow depth 2 1 the flow model river flows are classically modeled using the 1d saint venant shallow water equations involving an integration of the flow variables over the cross section see e g chow 1964 guinot 1993 for detailed assumptions in a q variables a the wetted cross section m 2 q the discharge m 3 s 1 the equations read as follows chow 1964 1 t a x q 0 t q x q 2 a ga x z gas f where g is the gravity magnitude m s 2 z is the ws elevation m z b h with b is the river bottom elevation m and h is the water depth m x is the curvilinear abscissa and t the time the friction slope s f is parameterized with the classical manning strickler law such that s f q q k 2 a 2 r h 4 3 with k the strickler friction coefficient m 1 3 s 1 r h a p h the hydraulic radius m p h the wetted perimeter the discharge q is related to the average cross sectional velocity u m s 1 such as q ua a spatially distributed strickler friction coefficient is defined as a power law in the water depth h 2 k x h x t α x h x t β x where α and β are two parameters similar approaches based on hydraulic geometry or power law resistance equations are developed in the litterature for predicting mean flow velocity for example on a wide range of in situ river flow measurements in bjerklie et al 2005 or else for gravel bed streams in ferguson 2007 the friction depends on the flow depth through the proposed power law relation eq 2 enabling a variation of the friction effect in function of the flow regime for complex flow zones for instance this spatially distributed friction law is richer than a constant uniform value as it is often set in the literature from a priori tables of frictions in function of river types for instance e g chow 1959 note that satellite altimetry mostly observes the downstream parts of river networks top width w 100 m for swot mainly in subcritical and mostly low froude flows at the observation scales cf garambois and monnier 2015 larnier et al 2019 montazem et al 2019 the discharge q in t is classically imposed upstream of the river channel with a discharge hydrograph at downstream a normal depth is imposed using the manning strickler equation depending on the unknowns a q k out it is classically integrated in the preissmann scheme equations the initial condition is set as the steady state backwater curve profile z 0 x z q in t 0 also depending on the unknowns note that these boundary and initial conditions are updated during the iterative inverse method presented in what follows this 1d saint venant model eq 1 is discretized using the classical implicit preissmann scheme see e g cunge et al 1980 on a regular grid of spacing δ x it is implemented into the computational software dassflow dassflow 2019 2 2 effective anabranching river model from multisatellite data a l 71 km long portion of the rio xingu containing anabranching reaches is considered fig 1 cf garambois et al 2017 ws observations are available at 6 virtual stations along a single envisat track 263 representing 77 samples of ws profiles between mid 2002 and mid 2010 cf da silva et al 2012 that is z s p obs s p env with s 6 corresponding to the locations of the virtual stations simultaneously observed at p 77 times see table 1 an effective hydraulic modeling strategy of this anabranching river is proposed based on cross sectional water surface widths w s 2 jers obtained from jers mosaics courtesy of grfm nasda miti in low and high flows the effective water surface width is the sum of the width of all individual river channels for anabranching reaches note that the cross section geometry of this ungauged anabranching river might be changing over a hydrological year from disconnected channels in low flows to a mono channel with forested floodplains during the flood season the available satellite images resulted in an estimation of a larger effective top width in high flow an a priori river bottom b r vs obtained from altimetric rating curves from paris et al 2016 the authors determined effective bottom elevations by adjusting the scalar parameters γ and δ of a classical stage discharge relationship q γ z b δ i 1 2 with i the water surface slope gained from altimetry at large scale they used ws elevations gained by satellite altimetry and discharges simulated with the large scale hydrological model mgb collischonn et al 2007 paiva et al 2013 pontes et al 2017 on the temporal window of interest called true discharge in what follows effective cross sections geometries are defined at the 6 virtual stations with the bathymetry b given by altimetric rating curves and from effective widths such that low flow width resp high flow is reached for the first resp ninth decile of observed ws elevations for each cross section the final model geometry is obtained by linear interpolation between these 6 effective cross sections on the model grid with δ x 50 m it is shown in fig 1 along with envisat and swot spatial samplings the friction law eq 2 introduced above and depending on the flow depth h is distributed using patches with constant values for each reach between two successive virtual stations 2 3 the computational inverse method this paper investigates the estimation of the hydraulic triplet q t b x k x h from observations of ws variabilities only on ananabranching river the employed inverse method is those presented in larnier et al 2019 see also brisset et al 2018 with an augmented composite control vector c it is detailed in appendix a c contains a spatially distributed friction coefficient enabling to model complex flow zones while it is an uniform friction law k h in larnier et al 2019 this definition of k x h enables to consider more heterogeneous bathymetry controls the principle is to estimate discrete flow controls minimizing the discrepancy between z obs the observed flow line and z the modeled one the latter depending on the unknown parameters vector c through the hydrodynamic model eq 1 this discrepancy is quantified through the cost function term 3 j obs c 1 2 z obs z c 2 2 see appendix a for details the control vector c contains the unknown input parameters of the 1d saint venant shallow water flow model eq 1 considering effective cross sections see fig 1 in the present study c reads as 4 c q in 0 q in p b 1 b r α 1 α n β 1 β n t where temporally and spatially distributed controls are the upstream discharge q in p the river bed elevation b r and the distributed friction parameters α n and β n the subscript p denotes the observation time p 0 p and r denotes the reach number r 1 r α n and β n are the parameters of the friction law depending on the model state h eq 2 for each patch n 1 n with n r the inversion consists to solve the following minimization problem c argmin j c eq 9 this minimization optimization problem is solved using a first order gradient based algorithm more precisely the classical l bfgs quasi newton algorithm the main steps of the method are illustrated in fig 2 3 model calibration this section presents the calibration of the effective hydraulic model based on the reference effective geometry defined above cf section 2 2 the observed water elevation time series z s p obs s p env at s 5 envisat virtual stations are used to calibrate the friction law of the 1d saint venant flow model eq 1 since friction has a local and upstream influence on a flow line low froude fluvial flows fig 10 the remaining envisat time series at vs 6 downstream of the river domain will be used for inferring the full control vector c in next section recall that a normal depth is used as downstream bc cf section 2 1 a reduced control vector c cal α 1 α n β 1 β n consisting in spatially distributed friction parameters only is considered here in order to avoid a spatial overparameterization regarding the 5 water height timeseries available at vs the choice is made to spatialize friction on n 5 patches on each reach downstream an altimetric vs the inverse method presented in larnier et al 2019 and described in appendix section a is used here with no regularization nor variable change for this simple calibration problem an optimal friction distribution c cal is found with the inverse method and the calibrated values of α n 1 5 and β n 1 5 are summed up in table 1 the resulting water height time series are compared to altimetric observations for each virtual station cf fig 3 the spatially distributed friction law eq 2 enables a fairly good reproduction of the observed water level variations on this anabranching river across a wide range of flows even with an effective 1d model built on multi satellite data fig 3 a constant friction in time would lead to systematical errors for a large range of flows as shown by the grey curves on fig 3 the calibrated friction exponents β n range between 0 482 and 1 133 except for the second reach sv2 3 where a small β n is found that is a barely constant friction across flow regimes for this short reach cf fig 3 the spatial pattern of α n values calibrated here corresponds to significant friction effects varying across flow regimes and necessary to effectively represent anabranching reaches using a 1d effective cross section indeed the lattest leads to an underestimation of the hydraulic radius r h a p h hence of the friction slope s f q q k 2 a 2 r h 4 3 in the 1d saint venant model see section 2 1 for anabranching reaches 4 inferences of distributed spatio temporal flow controls q t k x h b x from ws observations this section studies the challenging inference of the hydraulic triplet discharge bathymetry friction from multi satellite ws observations the anabranching xingu river morphology represents a supplementary difficulty for inversions regarding the variability of local hydraulic behaviors accross flow regimes as evidenced above by the calibrated friction laws β cal 0 the impact of spatial controls density and bathymetry representation is assessed in what follows regarding the spatial sparsity of observations first is presented the numerical experiment framework then the inferences with relatively sparse envisat measurements and finally those with swot synthetic observations 4 1 design of the numerical experiments the effective hydraulic model described in section 2 2 and calibrated in section 3 is used as a reference target in the following numerical experiments the control vector eq 4 containing discharge bathymetry and friction is sought with the inverse method described in section 2 3 see also appendix section a it is tested first with real envisat time series representing a relatively sparse spatial sampling of ws signatures with 6 vs on this 71 km long river and next with synthetic swot observations sampling the flow line at δ x 200 m riverobs product see frasson et al 2017 the xingu river is observed either by a single along stream envisat track at 6 observation points virtual stations of flow lines every 35 days or two swot tracks providing dense ws observations in space twice per 21 days repeat cycle 5 days delay cf section 2 2 note that the temporal sparsity of observations 35 days for envisat or 5 days between the two swot passes every 21 days only enables to identify low hydrograph frequencies at observation times see brisset et al 2018 for a detailed analysis and the identifiability maps indeed the hydraulic wave propagation time is around t wave 9 h which is much smaller than the lowest satellite revisit time of 5 days this propagation time is estimated using the kinematic wave velocity for rectangular channels c k 5 3 u and maximal high flow velocity u 2 17 m s from calibrated model outputs c k 2 2 m s second hydrograph peak at t 490 days see flow variables on fig 10 let i indent t wave δ t obs be the identifiability index defined in brisset et al 2018 as the ratio between flood wave propagation time and observation time step this leads to a very low temporal identifiability index for this 71 km river i ident 7 5 10 2 for swot and i ident 10 2 for envisat consequently only low temporal dynamics and discharge at observation times are inferable as shown in brisset et al 2018 swot and envisat observations are thus considered separately in the present study the starting point of the vda process in the parameter space the so called prior c prior cf section a consists in a rough hydrological prior q 0 q mgb the mean discharge estimated from the mgb hydrological model a spatially constant α 0 friction defined a priori from classical hydraulic ranges e g chow 1959 and β 0 1 the bathymetry b 0 is defined as a simple straight line over the whole domain for hydraulic analysis first note that the sensitivity of the inference to the prior definition is investigated in section 5 in a noised observation context we denote by δ the noise level such that z obs z true 2 δ for all spatial locations r with z r obs the observed and z r true the true ws elevation a common technique to avoid overfitting noisy data in the context of tykhonov s regularization of ill posed problems is morozov s discrepancy principle see e g kaltenbacher et al 2008 and references therein the regularization parameter γ see eq 7 is chosen a posteriori such that j does not decrease below the noise level in the present numerical experiments the convergence is stopped if j obs c 10 1 or if j obs is not decreased anymore for higher discrepancies 4 2 inference from spatially sparse envisat snapshots in this section the assimilation is based on ws elevations z s p env s p at s 6 virtual stations observed simultaneously by envisat during 8 years every 35 days i e p 77 in this spatially sparse observation context the impact of spatial controls density is investigated first we consider a full control vector c cf eq 4 including p 77 inflow discharges all 1d model bathymetry points r 1420 and n 5 friction patches between envisat virtual stations cf section 2 2 the inferred inflow discharge bathymetry and friction are presented in fig 4 case env a despite the satisfying value of the hydraulic controls reached at iteration 35 the descent is still possible as shown by j obs decreasing of about 20 at iteration 96 allthough it enables to fit the observations according to the a priori convergence criteria defined in section 4 1 the solution found after the vda process is not very accurate nor realistic as shown by peak flow underestimations and significant oscillations of the identified friction and bathymetry the spatial sparsity of observations prevents to infer these relatively dense bathymetry controls in this case the considered inverse problem is underconstrained in order to better constrain the inverse problem in case of sparse spatial observability a bathymetry representation is consistently introduced at the scale of the observation grid and applied to the finer flow modeling grid based on the physical analysis of the sw model eq 1 behaviour and the ws signature of bathymetry friction controls see montazem 2018 montazem et al 2017 2019 a linear bathymetry interpolation is used between the successive couples of bathymetry controls defined at observation points only the resulting bathymetry b x c 0 r x 0 l is piecewise linear and strongly constrains the bathymetry profile between the sought bathymetry points instead of using only a weak constraint j reg c 1 2 b x 2 2 in the optimization process cf appendix a as done in the next section 4 3 with spatially dense swot observations using this bathymetry constraint with r 6 bathymetry controls defined at each envisat virtual station results in 5 reaches and n 5 friction patches are consistently applied to each this leads to a more robust and accurate inference as shown in fig 5 case env b the discharge inferred for 8 years is fairly correct rmse 520 m 3 s nash 0 95 and relatively realistic bathymetry friction patterns are found with some compensations between spatial controls locally in space which is further analyzed in what follows the impact on the inferred parameters of searching a spatially uniform friction law is tested with the piecewise linear bathymetry representation used above the resulting discharge inference is fairly correct rmse 608 m 3 s nash 0 93 and interestingly the bathymetry spatial pattern is well retrieved but shifted above the reference one cf fig 6 case env c the inferred friction coefficients are α 22 621 β 0 217 which represents a lower friction effect on most flow regimes regarding the calibrated ones cf table 1 these inferred effective friction law and bathymetry patterns leading to somehow effective stage discharge relationships locally given the inferred hydrograph and its propagation enable to approximate the observed ws variations j obs 1 269 but with a less accurate fit than with spatially distributed friction j obs 0 118 note that in this case of lower model complexity an underestimation of the low flow discharges occurs recall that the observations consist in real measurements of ws elevations gained by nadir altimetry on anabranching reaches of the xingu river the complexity of the forward inverse modeling approach in coherence with the spatial sparsity of the observation grid enables to approximate satisfactorily the one of the observed anabranching flow the additionnal constraint provided by spatially dense flow lines observations is investigated in the next section with swot synthetic data 4 3 inference from spatially dense swot snapshots in this section the full hydraulic control c cf eq 4 is inferred by assimilating swot like observations those noisy data are computed using the swot hydrology simulator applied to flow lines from the effective hydraulic model calibrated above cf section 3 the swot spatio temporal pattern over the studied river is obtained by overlapping the river centerline and the expected swot orbit and swaths cf fig 1 finally the synthetic swot like observables consist in ws elevations z obs swot r p with p 1 p and p 276 generated on the fine scale model grid i e r 1 1420 the inflow discharge bathymetry and friction are inferred by assimilating swot ws observations z obs swot r p on the same spatial grid as that of the numerical hydraulic model with c prior 1 the estimates are presented on fig 7 the inferred discharge hydrograph is accurate rmse 391 m 3 s nash 0 97 and bathymetry friction patterns are relatively well retrieved using swot spatially distributed observations and piecewise constant friction enable to constrain the inference of bathymetry controls at a fine spatial resolution model grid the inverse method includes i a regularization term j reg in the cost function eq 7 ii covariance matrices acting as spatial or temporal smoothers regularizations cf eq 12 in appendix the inferred discharge and spatially distributed controls are slightly more accurate than previously in a comparable inversion scenario with sparse envisat observations in space and piecewise linear bathymetry constrain case env b cf tab 2 and fig 5 note that the friction is sought by reaches which enables to consider more dense bathymetry controls again the compensation between spatial controls appears locally in space but enables the best fit to the distributed measurements of ws elevations given the inferred discharge j obs 0 099 5 discussion and numerical investigation of the bathymetry friction equifinality this section discusses the challenging inference of spatially and temporally distributed river flow controls from water surface observations through numerical investigations indeed the considered flow controls q t b x k x h have a correlated influence and can produce undiscernable signatures in the modeled flow lines therefore leading to an ill posed inverse problem cf garambois and monnier 2015 larnier et al 2019 for investigations on this bathymetry friction equifinality in a comparable data inversion context the hydrograph is responsible for flow variability in time hence enabling to retrieve the temporal dynamics of the observed flow lines brisset et al 2018 larnier et al 2019 given altimetric measurements of ws variabilities and the first guess c prior 1 the regularized inverse method enables to infer a complex control vector composed of temporally and spatially distributed controls of the 1d sw model eq 1 in the numerical experiments above the discharge hydrograph q t is accurately inferred at observation times but because of the ill posedness of the inverse problem compensations can occur between the sought parameters and especially between the spatial controls the bathymetry b x and the distributed friction parameters α x and β x these inferred friction laws and bathymetry patterns simultaneously inferred with the discharge hydrograph correspond to effective rivers enabling to fit the observed variability of flow lines note that the spatial density of swot data enables to constrain flow controls that are relatively dense in space here on a complex anabranching flow case using the effective 1d river representation and a friction law pattern depending on water depth improving the physical segmentation parameterization and sparse representation of river networks and flow signatures e g montazem et al 2019 seems of great importance to take advantage of the forthcoming swot observations along with other data importantly as already pointed out in the vda inferences performed with the dassflow model using swot like data in brisset et al 2018 and larnier et al 2019 and airswot data in tuozzolo et al 2019 the accuracy of the inferred discharge depends on the quality of the prior in other words spatially distributed ws observations enable to depict spatio temporal signatures and eventually propagation dynamics but a quantitative biais remains regarding fluxes from the river reach to the network scale in the following subsection the influence of the prior value on the quality of the inferences with spatially distributed controls is investigated first next is proposed a numerical analysis of the sensitivity of the friction slope source term s f in the saint venant equations eq 1 to the flow controls triplet that are embeded in it manning strickler parameterization 5 1 sensitivity to the prior guess the sensitivity of the inference to the quality of the prior guess of the control vector c prior is investigated here for the most challenging inverse problem with spatially and temporally distributed controls and sparse envisat data first the inflow prior is varied of 30 around the mean true discharge the river bottom elevation and friction priors are set as previously in c prior 1 the inferred hydraulic controls are presented in fig 8 and various inference scores are summed up in table 2 for each inflow prior the temporal variations of the inflow hydrograph are very well retrieved as shown on fig 8 runs env b2 and env b3 however a biased inflow prior results in a biased hydrograph estimate with correct temporal variations at observation times which is coherent with the results of larnier et al 2019 and tuozzolo et al 2019 next the sensitivity to the prior bathymetry and friction is tested the prior bathymetry is inferred with the low complexity system proposed in the hierarchichal hivdi model chain larnier et al 2019 for ungauged rivers it consists in estimating an effective prior bathymetry from ws observables using the low froude model and prior discharge from a hydrological model q mgb here and prior friction α 0 β 0 two prior guesses c man 1 and c man 2 are considered with prior friction under over estimations compared to calibrated ones cf fig 9 as shown on fig 9 the inference in case env b31 blue results in an accurate estimation of discharge very similar to env b purple it is started from a prior guess c man 1 that underestimates river bottom elevation and overestimates the spatially averaged friction effect compared to calibrated values cf fig 9 bottom in that case fitting ws elevations enables to infer an effective river channel bathymetry and friction but also to infer a fairly realistic upstream temporal control discharge hydrograph using the prior guess c man 2 that overestimates both river bottom elevation and spatially averaged friction effect results in a comparable fit to the observed ws elevations however this correct fit stems from the compensation between an inferred effective channel of reduced conveyance capacity comparable friction effects but overestimated bed levels and consequently an inferred hydrograph with underestimated low flow discharges in yellow 5 2 spatio temporal sensitivity of the friction term the considered flow controls q t k x h b x of the 1d saint venant shallow water equations eq 1 have a complex non linear influence on the modeled flow lines and consequently on the fit to the observed ones the lattest being evaluated globally in space and time with the current inverse method given the observation cost function eq 3 the variation of momentum expressed by the second flow equation is due to a pressure source term ga x z and a dissipation term gas f the discharge and the bathymetry appear in the momentum and pressure terms while all the flow controls are embedded in the friction source term s f note that for a locally steady uniform flow s f x z and an infinity of friction and bathymetry values can correspond to a single value of discharge cf garambois and monnier 2015 larnier et al 2019 we propose a simple calculation in order to make appear the sensitivity of the friction term to a change on the controls let us express the differential of s f assuming q 0 5 d s f d 1 k 2 q 2 a 2 r h 4 3 2 k 3 q 2 a 2 r h 4 3 d k 2 a 3 q 2 k 2 r h 4 3 d a 4 3 r h 7 3 q 2 k 2 a 2 d r h 1 k 2 2 q a 2 r h 4 3 d q since d r h d a p 1 p d a a p 2 d p 1 p d a r h d p 1 p d a 0 r h d p 0 d f h with a 0 w 0 h 0 and p 0 w 0 2 h 0 respectively the unobserved low flow area and perimeter under our modeling hypothesis cf section 2 2 and fig 1 see also larnier et al 2019 for details on cross section representation it follows that f h is a function depending on the modeled water depth h and of the observed cross section variation δ a above low flow h 0 w 0 being defined from observables we get d r h 1 p 1 2 r h w 0 d a 0 d f h and finally 6 d s f 1 k 2 q a 2 r h 4 3 2 q k d k q a 2 4 3 1 2 r h w 0 d a 0 2 d q d ϕ h with ϕ h 4 3 r h 7 3 q 2 k 2 a 2 d f h a function depending on the observed geometry of a cross section above low flow and of the simulated flow a q hence h a given a channel geometry we rewrite eq 6 as d s f k s f d k a 0 s f d a 0 q s f d q d ϕ h and under our modeling hypothesis we have k s f 0 a 0 s f 0 q s f 0 x t i e opposite effects of local values of friction k low flow area a 0 and simulated local discharge q values on s f those terms are plotted on fig 10 along the xingu river on the model grid from hydraulic variables simulated forward run with calibrated parameters cf table 1 note that d ϕ h is not studied with this simple method interestingly k s f is about 100 times greater than a 0 s f or q s f at high flow and about 10 times greater at low flow this is consistent with the singular value of friction that is found 1000 times greater than the one of reach averaged discharges by garambois and monnier 2015 through a singular value decomposition of the normal equations of reach averaged manning equations applied to 70 km of the garonne river downstream of toulouse france in other words the friction term in the present 1d modeling context must be more sensitive to a change in friction than unknown low flow bathymetry or discharge remark that for low flow s f is more sensitive to discharge than unknown cross sectional area q s f a 0 s f and conversely for high flow moreover the spatial variability of the three sensitivities is more pronounced at low flow abrupt changes are highlighted at locations corresponding to changes in the bottom slope or the channel width the influences of the bottom slope break at x 30 km is clearly visible at low flow and the influence of the width contraction at x 17 km at high flow which is fully consistent with the findings of montazem et al 2019 further investigations on the sensitivity of the full saint venant equations and especially the different contributions to the friction slope in space and time could be of interest to better taylor scale and constrain methods for tackling hydraulic inverse problems 6 conclusion this paper investigates the challenging inference of the hydraulic triplet discharge bathymetry friction from real or synthetic altimetric ws observations only on an ungauged anabranching river the hivdi inverse method presented in larnier et al 2019 is adapted for reproducing an anabranching flow by introducinga spatially distributed friction law depending on modeled water depth h and by using multi satellite data the friction law coefficients are spatialized by reach to be coherent with the observation grid and with the rather large meaningful scale of these parameters in the 1d manning strickler equation see e g guinot and cappelaere 2009 this effective modeling approach enables a fairly accurate reproduction of the anabranching flows observed during 8 years by nadir altimetry envisat on this 71 km anabranching river the inference capabilities of hydraulic parameters patterns from real altimetric observations along a single envisat track or from the future spatially dense swot observations are demonstrated for the present observed anabranching river complexity the inverse method enables to infer a fairly realistic upstream discharge hydrograph along with an effective river channel the estimated bathymetry and friction patterns somehow result in local and effective stage discharge relationships in case of spatially sparse observations the coherence between the sparse observation grid and the dense model grid is ensured using a piecewise linear bathymetry representation along with a friction power law with piecewise constant parameters this constrain on the vda process provided by the above defined effective bathymetry friction representation by reach is highlighted with spatially sparse envisat observations moreover the additional constrain provided by the forthcoming swot observations to infer a discharge hydrograph and densely distributed spatial controls is assessed on this effective anabranching river representation the definition of friction by reaches enabling to consider more dense bathymetry controls swot observations would represent unprecedented measurements of hydrological and hydraulic processes signatures from the local to the hydrographic network scales including complex flow zones such as anabranching ones on going researches focus on the detection and use of various hydraulic signatures in ws as highlighted here for bottom slope resp channel width breaks in low resp high flows see ws curvature analysis and sw model behavior in montazem et al 2019 on the estimation of reliable prior guesses on the sought parameters model scaling and inverse problems at the scale of larger river network portions including complex flow zones author contributions and acknowledgments the contributions of the respective authors are as follows pierre andré garambois designed the research plan and performed the numerical investigations and analysis pierre andré garambois pascal finaud guyot kevin larnier and amanda montazem contributed to the hydraulic understanding and sensitivity analysis jérôme monnier is the principal designer of the inverse computational method and its analysis jonas verley has started the present study during the beginning of his phd this study is warmly dedicated to him the computational software dassflow1d and satellite data curation toolbox were adapted from their previous versions larnier et al 2019 by jonas verley pierre andré garambois and kevin larnier this last generated the swot synthetic data using the large scale simulator and computational ressources of cnes centre national d etudes spatiales french space agency amanda montazem processed and analyzed the swot data stéphane calmant provided the multisatelite dataset and interesting discussions related to the concept of hydraulic visibility the authors k larnier software engineer at cs corp and j verley software engineer during 10 months next phd student imt insa cls 17 18 have been co funded by cnes the four other authors have been partly supported by cnes tosca research project 14 18 the authors are indebted to adrien paris and joecilla da silva for sharing data and for fruitfull discussions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a appendix the computational inverse method as already briefly summarized in section 2 3 the computational inverse method is based on variational data assimilation vda applied to the saint venant flow model 1 the computational inverse method is those presented in brisset et al 2018 and larnier et al 2019 with an augmented composite control vector c see 4 c contains a spatially distributed friction coefficient enabling to model complex flow zones while it is an uniform friction law k h in larnier et al 2019 this definition of k x h enables to consider more heterogeneous bathymetry controls it is important to point out that the imposed downstream boundary condition is an unknown of the inverse problem it is constrained with the observed water elevations and inferred river bottom slope using a locally uniform flow hypothesis i e manning equation cf section 2 1 the cost function j c is defined as 7 j c j obs c γ j reg c where γ 0 is a weighting coefficient of the so called regularization term j reg c the term j obs c measures the misfit between observed and modeled ws elevations such that 8 j obs c 1 2 z c z obs o 2 the norm o o 1 2 2 is defined from an a priori positive definite covariance matrix o assuming uncorrelated observations o diag σ z with σ z the a priori observation error on z obs σ z 15 cm in this study the modeled ws elevations z depend on c through the hydrodynamic model 1 and the inverse problem reads as 9 c argmin c j c this optimal control problem is solved using a quasi newton descent algorithm the l bfgs algorithm version presented in gilbert and lemarechal 1989 the cost gradient j c is computed by solving the adjoint model the latter is obtained by automatic differentiation using tapenade software hascoët and pascual 2013 detailed know hows on vda may be found e g in the online courses bouttier and courtier 2002 monnier 2014 to be solved efficiently this optimization problem needs to be regularized indeed the friction and the bathymetry may trigger indiscernible surface signatures therefore leading to an ill posed inverse problem we refer e g to kaltenbacher et al 2008 for the theory of regularization of such inverse problems and to larnier et al 2019 for a discussion focused on the present inverse flow problem following larnier et al 2019 the optimization problem 9 is regularized as follows first the regularization term j reg is added to the cost function see 7 we simply set j reg c 1 2 b x 2 2 therefore this term imposes as weak constraint the inferred bathymetry profile b x to be an elastic interpolating the values of b at the control points i e a cubic spline a specificity of the present context is the inconsistency between the large observation grid altimetry points and the finer model grid between the sparse observations points equivalently the control points the bathymetry profile b x is reconstructed as a piecewise linear function it is worth to point out that the resulting reconstruction is consistent with the physical analysis presented in montazem et al 2017 montazem 2018 montazem et al 2019 this study analyses the adequation between the sw model 1 behavior and the ws signature next and following lorenc et al 2000 weaver and courtier 2001 larnier et al 2019 the following change of control variable is made 10 k b 1 2 c c prior where c is the original control vector c prior is a prior value of c and b is a covariance matrix the choice of b is crucial in the vda formulation its expression is detailed below after this change of variable the new optimization problem reads 11 min k j k with j k j c it is easy to show that this leads to the following new optimality condition b 1 2 j c 0 somehow a preconditioned optimality condition for more details and explanations we refer to haben et al 2011 haben et al 2011 and larnier et al 2019 in the present inversion context assuming uncorrelated controls b is defined as a block diagonal matrix 12 b b q 0 0 0 b b 0 0 0 b α 0 0 0 b β still following larnier et al 2019 the matrices b q and b b are set as the classical second order auto regressive correlation matrices 13 b q i j σ q 2 exp t j t i δ t q and b b i j σ b 2 exp x j x i l b the vda parameters δ t q and l b represent prior hydraulic scales and act as correlation lengths given the frequency few days and spatial resolution of observations 200 m long pixels for swot the low froude anabranching river flows of interest adequate values for those parameters are δ t q 24 h and l b 3 km we refer to brisset et al 2018 for a thorough analysis of the discharge inference in terms of frequencies and wave lengths and section 4 1 in the present river observation context in the present study the friction parameters applied to deca kilometric patches are assumed to be uncorrelated thus the matrices b α and b β are diagonal 14 b α i i σ α 2 b β i i σ β 2 the scalar values σ may be viewed as variances and constant values are used in this study σ q 3500 m 3 s σ α 10 m 1 3 s 1 σ β 0 5 σ b 1 m 
5918,multi satellite sensing of continental water surfaces ws represents an unprecedented and increasing potential for studying ungauged hydrological and hydraulic processes from their signatures especially on complex flow zones such as anabranching rivers however the estimation of discharge from ws observations only is a very challenging ill posed inverse problem due to unknown bathymetry and friction in ungauged rivers measurements nature quality and spatio temporal resolutions regarding the flow model scales this paper proposes an effective 1d hydraulic modeling approach of sufficient complexity to describe anabranching river flows from sparse multisatellite observations using the hivdi inverse method presented in larnier et al 2019 with an augmented control vector including a spatially distributed friction law k x h depending on the flow depth h it is shown on 71 km of the xingu river anabranching amazon basin with altimetric water height timeseries that a fairly accurate upstream discharge hydrograph and effective patterns of channel bathymetry and friction can be inferred simultaneously the coherence between the sparse observation grid and the fine hydraulic model grid is ensured in the optimization process by imposing a piecewise linear bathymetry profile b x which is consistent with the hydraulic visibility ofws signatures garambois et al 2017 montazem et al 2019 the discharge hydrograph q t at observation times and effective bathymetry friction b x k x h patterns are retrieved from 8 years of satellite altimetry envisat at 6 virtual stations vs along flow next the potential of the forthcoming swot data dense in space is highlighted by inferring a discharge hydrograph and dense patterns of effective river bathymetry and friction a physically consistent scaling of friction by reaches enables to consider more dense bathymetry controls finally a numerical analysis shows i the importance of an unbiased prior information in the inference of a triplet q b x k x h from ws observations ii the clear signatures of river bottom slope break in low flows and width variations in high flows through the analysis of the friction slope term which is consistent with the findings of montazem et al 2019 from ws curvature analysis keywords anabranching river ungauged river 1d hydraulic model variational assimilation satellite altimetry swot hydraulic visibility 1 introduction fresh water is a crucial earth s resource and its journey from the clouds to the oceans passes through the hydrographic network in order to characterize hydrological fluxes an essential physical variable is river discharge cf global climate observing system w m o 2016 representing an integration of upstream hydrological processes in complement of in situ sensors networks which are declining in some regions e g fekete and vorosmarty 2002 increasingly accurate measurements of hydrological and hydraulic variables and especially river surface variabilities are now enabled by myriads of satellites for earth observation and new generations of sensors e g vorosmarty et al 1996 alsdorf and lettenmaier 2003 calmant et al 2008 schumann and domeneghetti 2016 the forthcoming surface water and ocean topography swot wide swath altimetric mission cnes nasa planned to be launched in 2021 will provide a quasi global river surfaces mapping with an unprecedented spatial and temporal resolution on water surface ws height width and slope decimetric accuracy on ws height averaged over 1 km 2 1 to 4 revisits every 21 days cycle alsdorf et al 2007 durand et al 2010 rodriguez 2012 biancamaria et al mar 2016 rodriguez et al 2018 in addition to decades of nadir altimetry e g frappart et al 2006 birkett 1998 da silva et al 2012 calmant et al 2016 and imagery e g allen and pavelsky 2018 on inland waters swot will enable an unprecedented hydraulic visibility as defined from hydraulic analysis in garambois et al 2017 montazem et al 2017 montazem et al 2019 of hydrological responses and hydraulic variabilities within river networks multi satellite observations of water surfaces from the local to the hydrographic network scale indeed represent an unprecedented observability of hydrological responses through hydraulic processes signatures especially on complex flow zones such as floodplains or anabranching rivers see river morphology classification in nanson and knighton 1996 this increased hydraulic visibility represents a great potential to learn hydrodynamic behaviors and infer hydrological fluxes the estimation of river discharge from water surface observations elevations top width remains an open and difficult question especially in case of unknown or poorly known river bathymetry friction or lateral fluxes several open channel inverse problems are studied in a relatively recent literature in a satellite data context with more or less complex flow models and inverse methods cf biancamaria et al mar 2016 for a review few studies started to highlight the benefits of assimilating synthetic swot ws observations in simplified hydraulic models with sequential methods for inferring inflow discharge assuming known river friction and bathymetry andreadis et al 2007 biancamaria et al 2011 or inferring bathymetry assuming known friction durand et al 2008 yoon et al 2012 next low complexity methods have been proposed for estimating river discharge in case of unknown bathymetry and friction based on the manning equation durand et al 2014 garambois and monnier 2015 or hydraulic geometries gleason and smith 2014 or empirical flow models durand et al 2016 see also bjerklie et al 2018 they are tested on 19 rivers with synthetic swot like daily observations in durand et al 2016 and their robustness and accuracy is found to fluctuate the importance of good prior guesses is highlighted the combined use of dynamic flow models and optimization methods enables to benefit from ws observations for solving hydraulic inverse problems as shown for flood hydrograph inference in roux and dartus 2006 from ws width time series used to optimize a 1d hydraulic model or in honnorat et al 2006 hostache et al 2010 lai and monnier 2009 by variational assimilation of flow depth time series in a 2d hydraulic model the variational data assimilation vda approach see e g cacuci et al 2013 and references therein is well suited to solve the present inverse problem see brisset et al 2018 oubanas et al 2018 larnier et al 2019 and references therein it consists in fitting the hydraulic model response to the observed ws elevations by optimizing the input parameters in a variational framework however altimetry measurements of ws are relatively sparse in time compared to local flow dynamics this important aspect of the inverse problem is investigated in brisset et al 2018 with the introduction of the identifiability maps the latter consist to represent in space time the available information ws observables hydraulic waves and an estimation of the misfit with the local equilibrium these maps enable to estimate if the sought upstream discharge information has been observed or not within the downstream river surface deformations also they help to estimate inferable hydrograph frequencies brisset et al 2018 or inferable hydrograph time windows larnier et al 2019 the inference of the hydraulic triplet inflow discharge q t effective bathymetry b x and friction coefficient k from swot like ws observations is investigated in recent studies using 1d hydraulic and variational assimilation methods e g brisset et al 2018 gejadze and malaterre 2017 oubanas et al 2018 larnier et al 2019 however the inference of the triplet from ws observations remains a very challenging inverse problem because of the correlated influence of temporal discharge and spatial bathymetry friction controls on the simulated flow lines this is especially true because of the bathymetry friction equifinality issue see the discussions in garambois and monnier 2015 and larnier et al 2019 those recently developed vda methods enable to infer accurately the inflow discharge from water surface observables considering unknown uncertain channel bathymetry friction but from accurate prior information and synthetic ws observations note that a strong prior such as a known stage discharge relationship rating curve downstream of a river domain as it is done in oubanas et al 2018 can control part of the simulated flow lines fluvial regime as a consequence the vda process may converge to the discharge hydrograph corresponding to the imposed almost exact rating curve in the present study the downstream boundary condition bc is an unknown of the inverse problem a crucial point is the sensitivity of the triplet inference to the prior value from which the inference is started and it is studied in a swot observability context in garambois and monnier 2015 yoon et al 2016 larnier et al 2019 tuozzolo et al 2019 the sensitivity of the estimated discharge in the triplet to the prior is highlighted by recent estimates performed from airswot airborne measurements on the willamette river tuozzolo et al 2019 the temporal signal is well retrieved at observation times but using a biased prior hydrograph results in a biased hydrograph inference see detailed investigations in larnier et al 2019 in view to infer worldwide river discharges from the future swot observations especially for ungauged cases a hierarchical modeling strategy hivdi hierarchical variational discharge inversion is proposed in larnier et al 2019 the hivdi approach includes low complexity flow relations under the assumption of low froude and locally steady state flows which improves the robustness of the inferences in particular if an unbiaised average value of q is provided it may be provided by a database or a regional hydrological model note that if introducing an a priori information such as a single depth measurement it enables to reconstruct an effective low flow bathymetry see gessese et al 2011 garambois and monnier 2015 larnier et al 2019 all the studies mentioned above mostly address single channel natural rivers 100 km in length without lateral inflows and using synthetic datasets except in tuozzolo et al 2019 with airswot data moreover very few studies address the modeling of effective 1d channels from real satellite data e g garambois et al 2017 schneider et al 2017 the present paper investigates the effective hydraulic modeling of anabranching river flows from real multi sensor satellite observations of ws the challenging inference of the hydraulic triplet q t b x k x h and its sensitivity to observation density in space anabranching rivers are characterized by complex hydraulic geometries relationships across flow regimes as shown in schubert et al 2015 through an analysis of a metric resolution 2d shallow water model of an anabranching portion of the platte river us the key point here is to build up a sufficiently complex model to describe anabranching river flows and in coherence with the spatio temporal scales of satellite altimetry measurements based on the inverse method presented in larnier et al 2019 and brisset et al 2018 an effective hydraulic modeling strategy is adapted for tackling anabranching river flows using i effective 1d cross sections based on real multi satellite data from low to high flows ii a spatially distributed friction law depending on modeled water depth h the inference of distributed hydraulic parameters patterns is investigated on a 71 km long reach of the xingu river amazone basin from real altimetric observations gained on a single envisat track or from synthetic swot observations low identifiability index as introduced in brisset et al 2018 and detailed in section 4 the influence of the spatial density of ws observations on the identifiability of spatial controls patterns in the unknown triplet is studied a piecewise linear bathymetry representation is introduced along with a friction power law with piecewise constant parameters to put in coherence the observations and the flow model grids their constraining effect on the inversions is studied with spatially and temporally sparse satellite observations furthermore numerical investigations are performed to test the sensitivity of hydraulic inferences to prior hydraulic values and also assess the correlated influence of bathymetry and friction on the modeled flow lines equifinality across flow regimes this study is organized as follows section 2 presents the 1d saint venant flow model and the effective modeling approach for anabranching rivers including i a spatially distributed friction law depending on the modeled flow depth ii the construction of an effective channel geometry from multi satellite observations iii an inverse method based on variational data assimilation section 3 focuses on the calibration of the effective model on 8 years of ws observations gained from envisat altimeter on a single track along this anabranching river using this model as a reference section 4 proposes detailed investigations of the hydraulic inferences from real envisat or synthetic swot observations considering this anabranching river as ungauged the discussion in section 5 presents a numerical sensitivity analysis to the hydraulic prior and some investigations on the bathymetry friction equifinality 2 modeling approach this section proposes an original 1d effective modeling approach of adequate complexity for modeling anabranching river flows across fluvial regimes and in coherence with satellite observations the approach is built on an effective channel cross section derived from multi satellite measurements and a spatially distributed friction law depending on the flow depth 2 1 the flow model river flows are classically modeled using the 1d saint venant shallow water equations involving an integration of the flow variables over the cross section see e g chow 1964 guinot 1993 for detailed assumptions in a q variables a the wetted cross section m 2 q the discharge m 3 s 1 the equations read as follows chow 1964 1 t a x q 0 t q x q 2 a ga x z gas f where g is the gravity magnitude m s 2 z is the ws elevation m z b h with b is the river bottom elevation m and h is the water depth m x is the curvilinear abscissa and t the time the friction slope s f is parameterized with the classical manning strickler law such that s f q q k 2 a 2 r h 4 3 with k the strickler friction coefficient m 1 3 s 1 r h a p h the hydraulic radius m p h the wetted perimeter the discharge q is related to the average cross sectional velocity u m s 1 such as q ua a spatially distributed strickler friction coefficient is defined as a power law in the water depth h 2 k x h x t α x h x t β x where α and β are two parameters similar approaches based on hydraulic geometry or power law resistance equations are developed in the litterature for predicting mean flow velocity for example on a wide range of in situ river flow measurements in bjerklie et al 2005 or else for gravel bed streams in ferguson 2007 the friction depends on the flow depth through the proposed power law relation eq 2 enabling a variation of the friction effect in function of the flow regime for complex flow zones for instance this spatially distributed friction law is richer than a constant uniform value as it is often set in the literature from a priori tables of frictions in function of river types for instance e g chow 1959 note that satellite altimetry mostly observes the downstream parts of river networks top width w 100 m for swot mainly in subcritical and mostly low froude flows at the observation scales cf garambois and monnier 2015 larnier et al 2019 montazem et al 2019 the discharge q in t is classically imposed upstream of the river channel with a discharge hydrograph at downstream a normal depth is imposed using the manning strickler equation depending on the unknowns a q k out it is classically integrated in the preissmann scheme equations the initial condition is set as the steady state backwater curve profile z 0 x z q in t 0 also depending on the unknowns note that these boundary and initial conditions are updated during the iterative inverse method presented in what follows this 1d saint venant model eq 1 is discretized using the classical implicit preissmann scheme see e g cunge et al 1980 on a regular grid of spacing δ x it is implemented into the computational software dassflow dassflow 2019 2 2 effective anabranching river model from multisatellite data a l 71 km long portion of the rio xingu containing anabranching reaches is considered fig 1 cf garambois et al 2017 ws observations are available at 6 virtual stations along a single envisat track 263 representing 77 samples of ws profiles between mid 2002 and mid 2010 cf da silva et al 2012 that is z s p obs s p env with s 6 corresponding to the locations of the virtual stations simultaneously observed at p 77 times see table 1 an effective hydraulic modeling strategy of this anabranching river is proposed based on cross sectional water surface widths w s 2 jers obtained from jers mosaics courtesy of grfm nasda miti in low and high flows the effective water surface width is the sum of the width of all individual river channels for anabranching reaches note that the cross section geometry of this ungauged anabranching river might be changing over a hydrological year from disconnected channels in low flows to a mono channel with forested floodplains during the flood season the available satellite images resulted in an estimation of a larger effective top width in high flow an a priori river bottom b r vs obtained from altimetric rating curves from paris et al 2016 the authors determined effective bottom elevations by adjusting the scalar parameters γ and δ of a classical stage discharge relationship q γ z b δ i 1 2 with i the water surface slope gained from altimetry at large scale they used ws elevations gained by satellite altimetry and discharges simulated with the large scale hydrological model mgb collischonn et al 2007 paiva et al 2013 pontes et al 2017 on the temporal window of interest called true discharge in what follows effective cross sections geometries are defined at the 6 virtual stations with the bathymetry b given by altimetric rating curves and from effective widths such that low flow width resp high flow is reached for the first resp ninth decile of observed ws elevations for each cross section the final model geometry is obtained by linear interpolation between these 6 effective cross sections on the model grid with δ x 50 m it is shown in fig 1 along with envisat and swot spatial samplings the friction law eq 2 introduced above and depending on the flow depth h is distributed using patches with constant values for each reach between two successive virtual stations 2 3 the computational inverse method this paper investigates the estimation of the hydraulic triplet q t b x k x h from observations of ws variabilities only on ananabranching river the employed inverse method is those presented in larnier et al 2019 see also brisset et al 2018 with an augmented composite control vector c it is detailed in appendix a c contains a spatially distributed friction coefficient enabling to model complex flow zones while it is an uniform friction law k h in larnier et al 2019 this definition of k x h enables to consider more heterogeneous bathymetry controls the principle is to estimate discrete flow controls minimizing the discrepancy between z obs the observed flow line and z the modeled one the latter depending on the unknown parameters vector c through the hydrodynamic model eq 1 this discrepancy is quantified through the cost function term 3 j obs c 1 2 z obs z c 2 2 see appendix a for details the control vector c contains the unknown input parameters of the 1d saint venant shallow water flow model eq 1 considering effective cross sections see fig 1 in the present study c reads as 4 c q in 0 q in p b 1 b r α 1 α n β 1 β n t where temporally and spatially distributed controls are the upstream discharge q in p the river bed elevation b r and the distributed friction parameters α n and β n the subscript p denotes the observation time p 0 p and r denotes the reach number r 1 r α n and β n are the parameters of the friction law depending on the model state h eq 2 for each patch n 1 n with n r the inversion consists to solve the following minimization problem c argmin j c eq 9 this minimization optimization problem is solved using a first order gradient based algorithm more precisely the classical l bfgs quasi newton algorithm the main steps of the method are illustrated in fig 2 3 model calibration this section presents the calibration of the effective hydraulic model based on the reference effective geometry defined above cf section 2 2 the observed water elevation time series z s p obs s p env at s 5 envisat virtual stations are used to calibrate the friction law of the 1d saint venant flow model eq 1 since friction has a local and upstream influence on a flow line low froude fluvial flows fig 10 the remaining envisat time series at vs 6 downstream of the river domain will be used for inferring the full control vector c in next section recall that a normal depth is used as downstream bc cf section 2 1 a reduced control vector c cal α 1 α n β 1 β n consisting in spatially distributed friction parameters only is considered here in order to avoid a spatial overparameterization regarding the 5 water height timeseries available at vs the choice is made to spatialize friction on n 5 patches on each reach downstream an altimetric vs the inverse method presented in larnier et al 2019 and described in appendix section a is used here with no regularization nor variable change for this simple calibration problem an optimal friction distribution c cal is found with the inverse method and the calibrated values of α n 1 5 and β n 1 5 are summed up in table 1 the resulting water height time series are compared to altimetric observations for each virtual station cf fig 3 the spatially distributed friction law eq 2 enables a fairly good reproduction of the observed water level variations on this anabranching river across a wide range of flows even with an effective 1d model built on multi satellite data fig 3 a constant friction in time would lead to systematical errors for a large range of flows as shown by the grey curves on fig 3 the calibrated friction exponents β n range between 0 482 and 1 133 except for the second reach sv2 3 where a small β n is found that is a barely constant friction across flow regimes for this short reach cf fig 3 the spatial pattern of α n values calibrated here corresponds to significant friction effects varying across flow regimes and necessary to effectively represent anabranching reaches using a 1d effective cross section indeed the lattest leads to an underestimation of the hydraulic radius r h a p h hence of the friction slope s f q q k 2 a 2 r h 4 3 in the 1d saint venant model see section 2 1 for anabranching reaches 4 inferences of distributed spatio temporal flow controls q t k x h b x from ws observations this section studies the challenging inference of the hydraulic triplet discharge bathymetry friction from multi satellite ws observations the anabranching xingu river morphology represents a supplementary difficulty for inversions regarding the variability of local hydraulic behaviors accross flow regimes as evidenced above by the calibrated friction laws β cal 0 the impact of spatial controls density and bathymetry representation is assessed in what follows regarding the spatial sparsity of observations first is presented the numerical experiment framework then the inferences with relatively sparse envisat measurements and finally those with swot synthetic observations 4 1 design of the numerical experiments the effective hydraulic model described in section 2 2 and calibrated in section 3 is used as a reference target in the following numerical experiments the control vector eq 4 containing discharge bathymetry and friction is sought with the inverse method described in section 2 3 see also appendix section a it is tested first with real envisat time series representing a relatively sparse spatial sampling of ws signatures with 6 vs on this 71 km long river and next with synthetic swot observations sampling the flow line at δ x 200 m riverobs product see frasson et al 2017 the xingu river is observed either by a single along stream envisat track at 6 observation points virtual stations of flow lines every 35 days or two swot tracks providing dense ws observations in space twice per 21 days repeat cycle 5 days delay cf section 2 2 note that the temporal sparsity of observations 35 days for envisat or 5 days between the two swot passes every 21 days only enables to identify low hydrograph frequencies at observation times see brisset et al 2018 for a detailed analysis and the identifiability maps indeed the hydraulic wave propagation time is around t wave 9 h which is much smaller than the lowest satellite revisit time of 5 days this propagation time is estimated using the kinematic wave velocity for rectangular channels c k 5 3 u and maximal high flow velocity u 2 17 m s from calibrated model outputs c k 2 2 m s second hydrograph peak at t 490 days see flow variables on fig 10 let i indent t wave δ t obs be the identifiability index defined in brisset et al 2018 as the ratio between flood wave propagation time and observation time step this leads to a very low temporal identifiability index for this 71 km river i ident 7 5 10 2 for swot and i ident 10 2 for envisat consequently only low temporal dynamics and discharge at observation times are inferable as shown in brisset et al 2018 swot and envisat observations are thus considered separately in the present study the starting point of the vda process in the parameter space the so called prior c prior cf section a consists in a rough hydrological prior q 0 q mgb the mean discharge estimated from the mgb hydrological model a spatially constant α 0 friction defined a priori from classical hydraulic ranges e g chow 1959 and β 0 1 the bathymetry b 0 is defined as a simple straight line over the whole domain for hydraulic analysis first note that the sensitivity of the inference to the prior definition is investigated in section 5 in a noised observation context we denote by δ the noise level such that z obs z true 2 δ for all spatial locations r with z r obs the observed and z r true the true ws elevation a common technique to avoid overfitting noisy data in the context of tykhonov s regularization of ill posed problems is morozov s discrepancy principle see e g kaltenbacher et al 2008 and references therein the regularization parameter γ see eq 7 is chosen a posteriori such that j does not decrease below the noise level in the present numerical experiments the convergence is stopped if j obs c 10 1 or if j obs is not decreased anymore for higher discrepancies 4 2 inference from spatially sparse envisat snapshots in this section the assimilation is based on ws elevations z s p env s p at s 6 virtual stations observed simultaneously by envisat during 8 years every 35 days i e p 77 in this spatially sparse observation context the impact of spatial controls density is investigated first we consider a full control vector c cf eq 4 including p 77 inflow discharges all 1d model bathymetry points r 1420 and n 5 friction patches between envisat virtual stations cf section 2 2 the inferred inflow discharge bathymetry and friction are presented in fig 4 case env a despite the satisfying value of the hydraulic controls reached at iteration 35 the descent is still possible as shown by j obs decreasing of about 20 at iteration 96 allthough it enables to fit the observations according to the a priori convergence criteria defined in section 4 1 the solution found after the vda process is not very accurate nor realistic as shown by peak flow underestimations and significant oscillations of the identified friction and bathymetry the spatial sparsity of observations prevents to infer these relatively dense bathymetry controls in this case the considered inverse problem is underconstrained in order to better constrain the inverse problem in case of sparse spatial observability a bathymetry representation is consistently introduced at the scale of the observation grid and applied to the finer flow modeling grid based on the physical analysis of the sw model eq 1 behaviour and the ws signature of bathymetry friction controls see montazem 2018 montazem et al 2017 2019 a linear bathymetry interpolation is used between the successive couples of bathymetry controls defined at observation points only the resulting bathymetry b x c 0 r x 0 l is piecewise linear and strongly constrains the bathymetry profile between the sought bathymetry points instead of using only a weak constraint j reg c 1 2 b x 2 2 in the optimization process cf appendix a as done in the next section 4 3 with spatially dense swot observations using this bathymetry constraint with r 6 bathymetry controls defined at each envisat virtual station results in 5 reaches and n 5 friction patches are consistently applied to each this leads to a more robust and accurate inference as shown in fig 5 case env b the discharge inferred for 8 years is fairly correct rmse 520 m 3 s nash 0 95 and relatively realistic bathymetry friction patterns are found with some compensations between spatial controls locally in space which is further analyzed in what follows the impact on the inferred parameters of searching a spatially uniform friction law is tested with the piecewise linear bathymetry representation used above the resulting discharge inference is fairly correct rmse 608 m 3 s nash 0 93 and interestingly the bathymetry spatial pattern is well retrieved but shifted above the reference one cf fig 6 case env c the inferred friction coefficients are α 22 621 β 0 217 which represents a lower friction effect on most flow regimes regarding the calibrated ones cf table 1 these inferred effective friction law and bathymetry patterns leading to somehow effective stage discharge relationships locally given the inferred hydrograph and its propagation enable to approximate the observed ws variations j obs 1 269 but with a less accurate fit than with spatially distributed friction j obs 0 118 note that in this case of lower model complexity an underestimation of the low flow discharges occurs recall that the observations consist in real measurements of ws elevations gained by nadir altimetry on anabranching reaches of the xingu river the complexity of the forward inverse modeling approach in coherence with the spatial sparsity of the observation grid enables to approximate satisfactorily the one of the observed anabranching flow the additionnal constraint provided by spatially dense flow lines observations is investigated in the next section with swot synthetic data 4 3 inference from spatially dense swot snapshots in this section the full hydraulic control c cf eq 4 is inferred by assimilating swot like observations those noisy data are computed using the swot hydrology simulator applied to flow lines from the effective hydraulic model calibrated above cf section 3 the swot spatio temporal pattern over the studied river is obtained by overlapping the river centerline and the expected swot orbit and swaths cf fig 1 finally the synthetic swot like observables consist in ws elevations z obs swot r p with p 1 p and p 276 generated on the fine scale model grid i e r 1 1420 the inflow discharge bathymetry and friction are inferred by assimilating swot ws observations z obs swot r p on the same spatial grid as that of the numerical hydraulic model with c prior 1 the estimates are presented on fig 7 the inferred discharge hydrograph is accurate rmse 391 m 3 s nash 0 97 and bathymetry friction patterns are relatively well retrieved using swot spatially distributed observations and piecewise constant friction enable to constrain the inference of bathymetry controls at a fine spatial resolution model grid the inverse method includes i a regularization term j reg in the cost function eq 7 ii covariance matrices acting as spatial or temporal smoothers regularizations cf eq 12 in appendix the inferred discharge and spatially distributed controls are slightly more accurate than previously in a comparable inversion scenario with sparse envisat observations in space and piecewise linear bathymetry constrain case env b cf tab 2 and fig 5 note that the friction is sought by reaches which enables to consider more dense bathymetry controls again the compensation between spatial controls appears locally in space but enables the best fit to the distributed measurements of ws elevations given the inferred discharge j obs 0 099 5 discussion and numerical investigation of the bathymetry friction equifinality this section discusses the challenging inference of spatially and temporally distributed river flow controls from water surface observations through numerical investigations indeed the considered flow controls q t b x k x h have a correlated influence and can produce undiscernable signatures in the modeled flow lines therefore leading to an ill posed inverse problem cf garambois and monnier 2015 larnier et al 2019 for investigations on this bathymetry friction equifinality in a comparable data inversion context the hydrograph is responsible for flow variability in time hence enabling to retrieve the temporal dynamics of the observed flow lines brisset et al 2018 larnier et al 2019 given altimetric measurements of ws variabilities and the first guess c prior 1 the regularized inverse method enables to infer a complex control vector composed of temporally and spatially distributed controls of the 1d sw model eq 1 in the numerical experiments above the discharge hydrograph q t is accurately inferred at observation times but because of the ill posedness of the inverse problem compensations can occur between the sought parameters and especially between the spatial controls the bathymetry b x and the distributed friction parameters α x and β x these inferred friction laws and bathymetry patterns simultaneously inferred with the discharge hydrograph correspond to effective rivers enabling to fit the observed variability of flow lines note that the spatial density of swot data enables to constrain flow controls that are relatively dense in space here on a complex anabranching flow case using the effective 1d river representation and a friction law pattern depending on water depth improving the physical segmentation parameterization and sparse representation of river networks and flow signatures e g montazem et al 2019 seems of great importance to take advantage of the forthcoming swot observations along with other data importantly as already pointed out in the vda inferences performed with the dassflow model using swot like data in brisset et al 2018 and larnier et al 2019 and airswot data in tuozzolo et al 2019 the accuracy of the inferred discharge depends on the quality of the prior in other words spatially distributed ws observations enable to depict spatio temporal signatures and eventually propagation dynamics but a quantitative biais remains regarding fluxes from the river reach to the network scale in the following subsection the influence of the prior value on the quality of the inferences with spatially distributed controls is investigated first next is proposed a numerical analysis of the sensitivity of the friction slope source term s f in the saint venant equations eq 1 to the flow controls triplet that are embeded in it manning strickler parameterization 5 1 sensitivity to the prior guess the sensitivity of the inference to the quality of the prior guess of the control vector c prior is investigated here for the most challenging inverse problem with spatially and temporally distributed controls and sparse envisat data first the inflow prior is varied of 30 around the mean true discharge the river bottom elevation and friction priors are set as previously in c prior 1 the inferred hydraulic controls are presented in fig 8 and various inference scores are summed up in table 2 for each inflow prior the temporal variations of the inflow hydrograph are very well retrieved as shown on fig 8 runs env b2 and env b3 however a biased inflow prior results in a biased hydrograph estimate with correct temporal variations at observation times which is coherent with the results of larnier et al 2019 and tuozzolo et al 2019 next the sensitivity to the prior bathymetry and friction is tested the prior bathymetry is inferred with the low complexity system proposed in the hierarchichal hivdi model chain larnier et al 2019 for ungauged rivers it consists in estimating an effective prior bathymetry from ws observables using the low froude model and prior discharge from a hydrological model q mgb here and prior friction α 0 β 0 two prior guesses c man 1 and c man 2 are considered with prior friction under over estimations compared to calibrated ones cf fig 9 as shown on fig 9 the inference in case env b31 blue results in an accurate estimation of discharge very similar to env b purple it is started from a prior guess c man 1 that underestimates river bottom elevation and overestimates the spatially averaged friction effect compared to calibrated values cf fig 9 bottom in that case fitting ws elevations enables to infer an effective river channel bathymetry and friction but also to infer a fairly realistic upstream temporal control discharge hydrograph using the prior guess c man 2 that overestimates both river bottom elevation and spatially averaged friction effect results in a comparable fit to the observed ws elevations however this correct fit stems from the compensation between an inferred effective channel of reduced conveyance capacity comparable friction effects but overestimated bed levels and consequently an inferred hydrograph with underestimated low flow discharges in yellow 5 2 spatio temporal sensitivity of the friction term the considered flow controls q t k x h b x of the 1d saint venant shallow water equations eq 1 have a complex non linear influence on the modeled flow lines and consequently on the fit to the observed ones the lattest being evaluated globally in space and time with the current inverse method given the observation cost function eq 3 the variation of momentum expressed by the second flow equation is due to a pressure source term ga x z and a dissipation term gas f the discharge and the bathymetry appear in the momentum and pressure terms while all the flow controls are embedded in the friction source term s f note that for a locally steady uniform flow s f x z and an infinity of friction and bathymetry values can correspond to a single value of discharge cf garambois and monnier 2015 larnier et al 2019 we propose a simple calculation in order to make appear the sensitivity of the friction term to a change on the controls let us express the differential of s f assuming q 0 5 d s f d 1 k 2 q 2 a 2 r h 4 3 2 k 3 q 2 a 2 r h 4 3 d k 2 a 3 q 2 k 2 r h 4 3 d a 4 3 r h 7 3 q 2 k 2 a 2 d r h 1 k 2 2 q a 2 r h 4 3 d q since d r h d a p 1 p d a a p 2 d p 1 p d a r h d p 1 p d a 0 r h d p 0 d f h with a 0 w 0 h 0 and p 0 w 0 2 h 0 respectively the unobserved low flow area and perimeter under our modeling hypothesis cf section 2 2 and fig 1 see also larnier et al 2019 for details on cross section representation it follows that f h is a function depending on the modeled water depth h and of the observed cross section variation δ a above low flow h 0 w 0 being defined from observables we get d r h 1 p 1 2 r h w 0 d a 0 d f h and finally 6 d s f 1 k 2 q a 2 r h 4 3 2 q k d k q a 2 4 3 1 2 r h w 0 d a 0 2 d q d ϕ h with ϕ h 4 3 r h 7 3 q 2 k 2 a 2 d f h a function depending on the observed geometry of a cross section above low flow and of the simulated flow a q hence h a given a channel geometry we rewrite eq 6 as d s f k s f d k a 0 s f d a 0 q s f d q d ϕ h and under our modeling hypothesis we have k s f 0 a 0 s f 0 q s f 0 x t i e opposite effects of local values of friction k low flow area a 0 and simulated local discharge q values on s f those terms are plotted on fig 10 along the xingu river on the model grid from hydraulic variables simulated forward run with calibrated parameters cf table 1 note that d ϕ h is not studied with this simple method interestingly k s f is about 100 times greater than a 0 s f or q s f at high flow and about 10 times greater at low flow this is consistent with the singular value of friction that is found 1000 times greater than the one of reach averaged discharges by garambois and monnier 2015 through a singular value decomposition of the normal equations of reach averaged manning equations applied to 70 km of the garonne river downstream of toulouse france in other words the friction term in the present 1d modeling context must be more sensitive to a change in friction than unknown low flow bathymetry or discharge remark that for low flow s f is more sensitive to discharge than unknown cross sectional area q s f a 0 s f and conversely for high flow moreover the spatial variability of the three sensitivities is more pronounced at low flow abrupt changes are highlighted at locations corresponding to changes in the bottom slope or the channel width the influences of the bottom slope break at x 30 km is clearly visible at low flow and the influence of the width contraction at x 17 km at high flow which is fully consistent with the findings of montazem et al 2019 further investigations on the sensitivity of the full saint venant equations and especially the different contributions to the friction slope in space and time could be of interest to better taylor scale and constrain methods for tackling hydraulic inverse problems 6 conclusion this paper investigates the challenging inference of the hydraulic triplet discharge bathymetry friction from real or synthetic altimetric ws observations only on an ungauged anabranching river the hivdi inverse method presented in larnier et al 2019 is adapted for reproducing an anabranching flow by introducinga spatially distributed friction law depending on modeled water depth h and by using multi satellite data the friction law coefficients are spatialized by reach to be coherent with the observation grid and with the rather large meaningful scale of these parameters in the 1d manning strickler equation see e g guinot and cappelaere 2009 this effective modeling approach enables a fairly accurate reproduction of the anabranching flows observed during 8 years by nadir altimetry envisat on this 71 km anabranching river the inference capabilities of hydraulic parameters patterns from real altimetric observations along a single envisat track or from the future spatially dense swot observations are demonstrated for the present observed anabranching river complexity the inverse method enables to infer a fairly realistic upstream discharge hydrograph along with an effective river channel the estimated bathymetry and friction patterns somehow result in local and effective stage discharge relationships in case of spatially sparse observations the coherence between the sparse observation grid and the dense model grid is ensured using a piecewise linear bathymetry representation along with a friction power law with piecewise constant parameters this constrain on the vda process provided by the above defined effective bathymetry friction representation by reach is highlighted with spatially sparse envisat observations moreover the additional constrain provided by the forthcoming swot observations to infer a discharge hydrograph and densely distributed spatial controls is assessed on this effective anabranching river representation the definition of friction by reaches enabling to consider more dense bathymetry controls swot observations would represent unprecedented measurements of hydrological and hydraulic processes signatures from the local to the hydrographic network scales including complex flow zones such as anabranching ones on going researches focus on the detection and use of various hydraulic signatures in ws as highlighted here for bottom slope resp channel width breaks in low resp high flows see ws curvature analysis and sw model behavior in montazem et al 2019 on the estimation of reliable prior guesses on the sought parameters model scaling and inverse problems at the scale of larger river network portions including complex flow zones author contributions and acknowledgments the contributions of the respective authors are as follows pierre andré garambois designed the research plan and performed the numerical investigations and analysis pierre andré garambois pascal finaud guyot kevin larnier and amanda montazem contributed to the hydraulic understanding and sensitivity analysis jérôme monnier is the principal designer of the inverse computational method and its analysis jonas verley has started the present study during the beginning of his phd this study is warmly dedicated to him the computational software dassflow1d and satellite data curation toolbox were adapted from their previous versions larnier et al 2019 by jonas verley pierre andré garambois and kevin larnier this last generated the swot synthetic data using the large scale simulator and computational ressources of cnes centre national d etudes spatiales french space agency amanda montazem processed and analyzed the swot data stéphane calmant provided the multisatelite dataset and interesting discussions related to the concept of hydraulic visibility the authors k larnier software engineer at cs corp and j verley software engineer during 10 months next phd student imt insa cls 17 18 have been co funded by cnes the four other authors have been partly supported by cnes tosca research project 14 18 the authors are indebted to adrien paris and joecilla da silva for sharing data and for fruitfull discussions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a appendix the computational inverse method as already briefly summarized in section 2 3 the computational inverse method is based on variational data assimilation vda applied to the saint venant flow model 1 the computational inverse method is those presented in brisset et al 2018 and larnier et al 2019 with an augmented composite control vector c see 4 c contains a spatially distributed friction coefficient enabling to model complex flow zones while it is an uniform friction law k h in larnier et al 2019 this definition of k x h enables to consider more heterogeneous bathymetry controls it is important to point out that the imposed downstream boundary condition is an unknown of the inverse problem it is constrained with the observed water elevations and inferred river bottom slope using a locally uniform flow hypothesis i e manning equation cf section 2 1 the cost function j c is defined as 7 j c j obs c γ j reg c where γ 0 is a weighting coefficient of the so called regularization term j reg c the term j obs c measures the misfit between observed and modeled ws elevations such that 8 j obs c 1 2 z c z obs o 2 the norm o o 1 2 2 is defined from an a priori positive definite covariance matrix o assuming uncorrelated observations o diag σ z with σ z the a priori observation error on z obs σ z 15 cm in this study the modeled ws elevations z depend on c through the hydrodynamic model 1 and the inverse problem reads as 9 c argmin c j c this optimal control problem is solved using a quasi newton descent algorithm the l bfgs algorithm version presented in gilbert and lemarechal 1989 the cost gradient j c is computed by solving the adjoint model the latter is obtained by automatic differentiation using tapenade software hascoët and pascual 2013 detailed know hows on vda may be found e g in the online courses bouttier and courtier 2002 monnier 2014 to be solved efficiently this optimization problem needs to be regularized indeed the friction and the bathymetry may trigger indiscernible surface signatures therefore leading to an ill posed inverse problem we refer e g to kaltenbacher et al 2008 for the theory of regularization of such inverse problems and to larnier et al 2019 for a discussion focused on the present inverse flow problem following larnier et al 2019 the optimization problem 9 is regularized as follows first the regularization term j reg is added to the cost function see 7 we simply set j reg c 1 2 b x 2 2 therefore this term imposes as weak constraint the inferred bathymetry profile b x to be an elastic interpolating the values of b at the control points i e a cubic spline a specificity of the present context is the inconsistency between the large observation grid altimetry points and the finer model grid between the sparse observations points equivalently the control points the bathymetry profile b x is reconstructed as a piecewise linear function it is worth to point out that the resulting reconstruction is consistent with the physical analysis presented in montazem et al 2017 montazem 2018 montazem et al 2019 this study analyses the adequation between the sw model 1 behavior and the ws signature next and following lorenc et al 2000 weaver and courtier 2001 larnier et al 2019 the following change of control variable is made 10 k b 1 2 c c prior where c is the original control vector c prior is a prior value of c and b is a covariance matrix the choice of b is crucial in the vda formulation its expression is detailed below after this change of variable the new optimization problem reads 11 min k j k with j k j c it is easy to show that this leads to the following new optimality condition b 1 2 j c 0 somehow a preconditioned optimality condition for more details and explanations we refer to haben et al 2011 haben et al 2011 and larnier et al 2019 in the present inversion context assuming uncorrelated controls b is defined as a block diagonal matrix 12 b b q 0 0 0 b b 0 0 0 b α 0 0 0 b β still following larnier et al 2019 the matrices b q and b b are set as the classical second order auto regressive correlation matrices 13 b q i j σ q 2 exp t j t i δ t q and b b i j σ b 2 exp x j x i l b the vda parameters δ t q and l b represent prior hydraulic scales and act as correlation lengths given the frequency few days and spatial resolution of observations 200 m long pixels for swot the low froude anabranching river flows of interest adequate values for those parameters are δ t q 24 h and l b 3 km we refer to brisset et al 2018 for a thorough analysis of the discharge inference in terms of frequencies and wave lengths and section 4 1 in the present river observation context in the present study the friction parameters applied to deca kilometric patches are assumed to be uncorrelated thus the matrices b α and b β are diagonal 14 b α i i σ α 2 b β i i σ β 2 the scalar values σ may be viewed as variances and constant values are used in this study σ q 3500 m 3 s σ α 10 m 1 3 s 1 σ β 0 5 σ b 1 m 
5919,the response of aquifers to earth s solid tides earth tides has increasingly been used as a tool for monitoring the hydraulic properties of groundwater systems recent studies of the tidal response of the arbuckle aquifer opened to a usgs deep well in oklahoma wang et al 2018 barbour et al 2019 which has been injected with an enormous amount of toxic wastewater showed evidence that this aquifer may be leaking quantitative interpretation of the tidal response of this aquifer was made with a one dimensional analytical solution wang et al 2018 that showed that substantial leakage is occurring however the analytical model has inherent simplifications such as conductivity isotropy small aquifer thickness absence of aquitard storage and no basement leakage in this study we revisit the tidal response of leaky aquifers with a finite element multi layered model where such simplifications are removed we found that the simplifications in the analytical model lead to overly conservative estimates of leakage we revisit the tidal response of the arbuckle aquifer in oklahoma with the numerical simulation and estimate an average vertical hydraulic conductivity of 2 10 6 t o 7 10 5 m s for the aquitard overlying the arbuckle thus the aquitard above the arbuckle is not confining at this location but is as conductive as the aquifer itself given the fast rise of fluid level in many arbuckle wells in response to the injection of hundreds of millions of barrels of wastewater into this aquifer across oklahoma and kansas the present result calls for vigilant monitoring of leakage of wastewater from the arbuckle aquifer into the overlying freshwater reservoirs and the surface environment plain language summary earthquakes can damage the confinement of groundwater aquifers and thus can cause seismic hazard by letting freshwater in some aquifers to be contaminated or stored toxic wastewater in other aquifers to leak out into the environment thus it is important to monitor possible leakage of aquifers in earthquake countries analysis of the aquifer response to earth s solid tides in a usgs deep well in oklahoma wang et al 2018 barbour et al 2019 which has been used as the repository of an enormous amount of injected toxic wastewater shows that the aquifer may be leaking an analytical solution wang et al 2018 that contains several simplifications was used to quantify the aquifer leakage from the tidal response here we use a two dimensional multilayered numerical simulation without these simplifications to explore the limitations of the analytical model we find that aquitard storage and basement leakage have important effects on the tidal response of aquifers and the omission of these factors in the analytical solution may have caused underestimation of the aquifer leakage we then apply the numerical model to interpret the tidal response of water level documented in a usgs deep monitoring well installed in the arbuckle aquifer in oklahoma where an enormous amount of toxic wastewater has been stored with reasonable estimates of the aquitard storage our simulations yield an estimate of 2 10 6 t o 7 10 5 m s for the vertical hydraulic conductivity of the aquitard thus the aquitard is not at all confining but is as conductive as the aquifer itself given the fast rise of fluid level in many arbuckle wells in response to the injection of hundreds of millions of barrels of wastewater into this aquifer across oklahoma and kansas the present result calls for vigilant monitoring of leakage of wastewater from the arbuckle aquifer into the overlying freshwater reservoirs and the surface environment keywords groundwater response to the earth tides leaky aquifer numerical model 1 introduction the storage of toxic wastewaters in underground repositories is often based upon the assumption that the repository aquifer is tightly confined by impervious strata recent studies e g elkhoury et al 2006 wang et al 2016 2018 barbour et al 2019 zhang h et al 2019 zhang y et al 2019 showed however that permeability of groundwater systems may be a dynamic property and can change with earthquakes or anthropogenic disturbances thus continuous monitoring of the confinement of groundwater systems may be desirable to detect any possible leakage to the groundwater reservoir or from the underground waste repository the conventional method for studying groundwater leakage is by using the pumping injection method analytical solutions for pumping and injection in leaky aquifer have been developed since last century hantush and jacob 1955 hantush 1960 neuman and witherspoon 1969 hemker 1985 maas 1987a 1987b cheng and morohunfola 1993 hemker and maas 1994 veling and maas 2009 and used to investigate pressure change in response to fluid injection or extraction in wells cihan et al 2011 cardiff et al 2013 sun et al 2015 the method can be time consuming and expensive the response of groundwater to solid tides has been increasingly used as an economical tool for continuous monitoring of permeability bredehoeft 1967 hsieh et al 1987 roeloffs 1996 doan et al 2006 liao et al 2015 wang et al 2018 barbour et al 2019 allègre et al 2016 compared the tidal method and the conventional pumping tests at the same sites for a range of site specific permeability and found consistent results between the two methods elkhoury et al 2006 demonstrated the effectiveness of this method for continuous monitoring of the changes of aquifer properties in response to multiple earthquakes in southern california for twenty years wang et al 2018 proposed that the tidal response of a groundwater system may be used to examine the confinement of a groundwater system affected by earthquakes or anthropogenic disturbances and developed an analytical solution for the tidal response of a leaky aquifer to quantitatively evaluate the aquifer leakage from the tidal response in this model as in hantush 1967 leakage is treated as a volumetric sink in a 1d groundwater flow equation 1 t 2 h r 2 1 r h r k b h s h t b k u ρ g ε t where h m is the hydraulic head in the aquifer above a common reference r m is the radial distance from the studied well t m2 s and s respectively are the transmissivity and storativity of the aquifer ε is the tidal oscillating volumetric strain of the aquifer compression is taken to be positive b and k u pa respectively are the skempton s coefficient and the undrained bulk modulus of the aquifer and the aquifer leakage is implemented by a volumetric sink k h b in the aquifer where k m s and b m respectively are the vertical hydraulic conductivity and the thickness of the assumed aquitard in reality the leaky aquifer is part of a multiple aquifer system where leakage occurs across the boundary between the aquifer and the overlying aquitard instead of within the aquifer the tidal response of such a system depends on the hydrogeological behaviors of all the layers hantush 1967 sun and zhan 2006 hunt 2005 another simplification in the above model is that the aquitard storage was neglected the absence of the storage means the aquitard is assumed to go immediately into a steady state which is valid if leakage occurs through fine fractures and the time constant for the hydraulic equilibrium across the aquitard is short in comparison with the period of the tidal forcing this assumption however may fail for aquitards with relatively low conductivity and large thickness neuman and witherspoon 1969 witherspoon and freeze 1972 feng and zhan 2015 lastly the analytical leaky aquifer model assumes that the basement leakage is negligible however most induced earthquakes occur in the basement e g schoenball and ellsworth 2017 suggesting that some injected fluids must have leaked into the basement zhang et al 2013 barbour et al 2017 thus it is desirable to understand how basement leakage would affect the tidal response of an aquifer in the present study we revisit the response of a leaky aquifer with a 2d finite element numerical model where the simplifications in the analytic models are removed we first briefly describe the multi layered groundwater system and the numerical approach to study the system s response to earth tides we then verify the numerical method with existing analytical solutions hsieh et al 1987 for a perfectly confined aquifer and roeloffs 1996 for an idealized unconfined aquifer after the method is verified we apply it to simulate the tidal response of leaky aquifers to explore the limitations of the analytic model wang et al 2018 finally we apply the numerical model to re visit the tidal response of the arbuckle aquifer in a usgs deep monitoring well in oklahoma 2 numerical approach we use an axially symmetrical multi layered finite element model fig 1 of a groundwater system that consists of an aquifer confined below by a potentially leaky basement and above by a semi confining aquitard that in turn is overlain by an unconfined aquifer a vertical well centered along its axis completely penetrates and is open to the aquifer in the classical hantush leaky model hantush and jacob 1955 lee 1999 groundwater flow is assumed horizontal in the aquifers and vertical in the aquitard here we relax these restrictions by allowing groundwater in the aquifer to flow in both the horizontal and the vertical directions the semi confining aquitard and the basement are variably assumed to have finite transmissivity and storativity the topmost aquifer is unconfined and is bounded on the well side by the casing it is assumed to have high vertical hydraulic conductivity and is thus characterized by a hydrostatic head groundwater flow in such a system driven by earth tide may be evaluated by solving the following differential equations 2 k ri 2 h i r 2 1 r h i r k zi 2 h i z 2 s si h i t b i k ui ρ g t where h i m is the hydraulic head in the ith layer r m the radial distance from the axis of the well k ri m s and k zi m s respectively the hydraulic conductivities in the radial and vertical directions of the ith layer s si m 1 the specific storage of the ith layer the tidal volumetric strain bi and k ui p a respectively the skempton s coefficient and the undrained bulk modulus of the ith layer and ρ k g m 3 and g m s 2 respectively the density of water and the gravitational acceleration k ri and k zi respectively are related to the horizontal and vertical permeabilities k ri and k zi of the ith layer by k ri k ri ρ g μ and k zi k zi ρ g μ respectively μ the viscosity of water and b i the thickness of the ith layer the basement is assumed to be a semi infinite half space since this study aims at exploring the effect of ki and ssi on the tidal response of leaky aquifers we assume for simplicity that the skempton coefficient bi and the undrained bulk modulus k ui are uniform in all layers the basement beneath the aquifer is assumed to be impervious in most simulations except those in section 4 4 where the effect of basement leakage is examined continuity of the hydraulic head is enforced on the boundaries between all layers comparing 1 and 2 we see that our numerical approach has eliminated the assumption in the analytical model of using a volumetric sink in the aquifer to represent leakage in the aquitard we assume a boundary condition of p 0 1 atm on the ground surface z 0 and assign a mixed boundary condition at the opened section of the borehole fig 1 which is dependent on the solution 3 2 π r b t 1 h 1 r t r π r c 2 h 1 r t t 0 where r b is the radius of the opened section of the well and r c is the radius of the cased section of the well in our simulations we assume r b r c 0 1 m for simplicity finally we assign no flow conditions on the cased section of the well on the right boundary r of the model and at the base z of the model we use comsol a commercially available finite element software package to solve the system of equations 2 constrained by the boundary conditions described above and material properties to be prescribed later small element size 0 5 m and time steps 500 s are used to ensure accuracy and numerical stability finally we focus on the response to the m2 tide because it is the most widely used response on account of its relatively large signal to noise ratio and that it is minimally affected by the changes in the barometric pressure 3 verification of the numerical model we first compare the simulated results for a confined aquifer against the analytical solution provided by hsieh et al 1987 see also doan et al 2006 the simulations were carried out with both a one dimensional 1d and an axially symmetrical multilayered model with the assumption that the aquitard is impervious and has zero storativity fig 2 shows that the simulated phase shift and amplitude ratio from the 1d model matches perfectly with the analytical solutions of hsieh et al 1987 see also doan et al 2006 small differences in the phase shift occur between the 2d simulation and the analytical solution when the aquifer transmissivity is less than 10 6 m 2 s which may reflect the fact that when the horizontal transmissivity is low flow in the 2d simulation deviates from that in the 1d model supplementary information we next compare the simulated results for an unconfined aquifer against the analytical solution provided by roeloffs 1996 see also wang 2000a 2000b doan et al 2006 here t zi and s i are assigned the same value in all layers to simulate a half space unconfined aquifer we choose t zi 10 4 m 2 s and s i 10 4 same as in doan et al 2006 the simulated phase shift and amplitude ratio are plotted against z δ fig 3 a and 3b where δ 2 d ω z is the depth of the screening interval of a cased well d t s is the hydraulic diffusivity and ω the angular frequency of the m2 tide also plotted are the analytical solution for an unconfined aquifer roeloffs 1996 wang 2000a 2000b doan et al 2006 the figures show that the simulated results closely match the analytical solution summarizing the above results we have verified the numerical code against the available analytical solutions for the tidal responses of perfectly confined aquifers and idealized unconfined aquifers we may thus use the code to explore the tidal response of aquifers under more general conditions and to examine the limitations of the analytical solution for a leaky aquifer as shown below 4 revisit the tidal response of a leaky aquifer with numerical simulation in this section we use the 2d numerical model verified above to revisit the response of a leaky aquifer to earth tides and to investigate the limitations of the analytic solution in wang et al 2018 in particular we investigate the following three specific effects in sequence aquifer thickness and conductivity aquitard storage and basement leakage 4 1 effect of aquifer thickness and conductivity in the analytic models of hantush and jacob 1955 and wang et al 2018 the effect of aquifer leakage on groundwater flow is implemented as a volumetric sink in the aquifer hantush 1967 pointed out that this assumption is valid if the aquifer is relatively thin and its vertical hydraulic conductivity is relatively large compared with that of the aquitard we examine the effect of this assumption on the tidal response to the m2 tide by introducing the parameter α k z 1 b 1 k z 2 b 2 and conducting a series of simulations for different values of α with specific horizontal conductivity k r 1 and storativity s 1 of the aquifer results fig 4 shows that good agreement between the simulated results and the analytic solution wang et al 2018 occurs when α 5 across the whole ranges of studied aquitard leakage factor k z 2 b 2 k r 1 and s 1 at α 5 however the simulated results deviate progressively from the analytic solutions in the transition zone with the simulated phase shift increasing and amplitude ratio decreasing with increasing α at a given k z 2 b 2 it thus appears that when α 5 the aquifer is thin enough and its vertical hydraulic conductivity is large enough compared with that of the aquitard that the use of a volumetric sink to represent aquifer leakage in the analytical model may be acceptable hantush 1967 proposed a criterion b t k b 0 1 for testing the utility of the analytical model to interpret the results of pumping test where t and b refer to the transmissivity and thickness of the aquifer and k and b refer to the hydraulic conductivity and thickness of the aquitard here we examine if this criterion may be used for the utility of the analytical tidal model using the present notations and recalling that hantush s aquifer model is isotropic i e k z 1 k r 1 t 1 b 1 we may recast hantush s criterion with the present notations as b 1 t 1 k z 2 b 2 1 k z 1 b 1 k z 2 b 2 1 α 0 1 or α 100 as shown earlier however good agreement between the analytic tidal solutions and the numerical simulations occurs when α 5 thus it appears that hantush s criterion would be overly conservative when applied to test the utility of the analytic tidal model 4 2 effect of aquitard storativity another assumption in the analytical leaky aquifer model hantush and jacob 1955 wang et al 2018 is that the semi confining aquitard has negligible storativity as noted earlier this assumption is equivalent to assuming that the aquitard goes immediately into a steady state which is valid only if the time constant for the hydraulic equilibrium across the aquitard is short in comparison with the period of the tidal forcing the occurrence of aquitard storage significantly increases the time constant for the hydraulic equilibrium across the aquitard and renders the assumption invalid if the aquitard has relatively low conductivity and large thickness neuman and witherspoon 1969 witherspoon and freeze 1972 feng and zhan 2015 here we explore the effect of aquitard storage on tidal response of the system with our numerical simulation in the simulation we assume s 2 s 1 0 1 10 and 100 respectively with specific values of k r 1 10 5 m s and α 10 fig 5 shows good agreement between the simulated results and the analytical solution when s 2 0 but when s 2 is greater than 0 aquitard storativity has important effects on the tidal response of the system and the simulated results depart significantly from the analytical solution at a given aquitard leakage factor k z 2 b 2 increasing aquitard storativity causes significant decreases in phase shift and increases in amplitude ratio another interesting feature is that the simulated amplitude ratio exceeds 1 fig 5 and the magnitude of this excess becomes greater with increasing aquitard storativity similar increases of the amplitude ratio were reported before and interpreted to be due to the poroelastic coupling between pore pressure and deformation detournay and cheng 1993 hsieh and cooley 1995 wang 2000a 2000b 4 3 effect of basement leakage most studies interpret the positive phase shift in the observed tidal response of water level to represent leakage above the studied aquifer e g xue et al 2016 allègre et al 2016 wang et al 2018 barbour et al 2019 on the other hand many induced earthquakes occur in the basement e g schoenball and ellsworth 2017 suggesting that some injected fluids must have leaked into the basement zhang et al 2013 barbour et al 2017 some studies require basement diffusivity as high as 1 m2 s to explain the induced seismicity barbour et al 2017 the occurrence of basement leakage on the response to earth tides has not been investigated could some observed positive phase shifts be the result of basement leakage we devote this sub section to answer this question basement leakage alone will not cause positive phase shift because the tidal response in this case would be similar to that of a confined aquifer and thus negative see simulated results in supplementary information thus we discuss here the effect of basement leakage on the tidal response of a leaky aquifer the simulated result fig 6 shows that if the basement conductivity is below 10 7 m s the effect of basement leakage on the aquifer tidal response is insignificant at greater conductivity however basement leakage may cause significant decrease in phase shift and increase in amplitude ratio at the same k z 2 b 2 fig 6 and the interpretation of the tidal response may significantly underestimate aquifer leakage if basement leakage is not considered 5 revisit the tidal response of the arbuckle aquifer with numerical simulation the sharp increase of seismicity in the mid continental u s since 2005 has been linked to the injection of massive amount of wastewater co produced from hydrocarbon exploration into deep aquifers e g ellsworth 2013 langenbruch and zoback 2016 a basic assumption for the disposal of wastewater into the deep aquifers is that such aquifers for example the arbuckle aquifer in oklahoma and kansas are confined by aquitards however it is known that aquitards can be disrupted by earthquakes wang et al 2016 following the occurrences of three large mw 5 earthquakes in 2016 in oklahoma the u s geological survey installed a pressure gauge in 2017 in a deep monitoring well in the arbuckle aquifer in northeastern oklahoma logs from this well wang et al 2018 barbour et al 2019 show that the aquifer is overlain by an aquitard containing a shale layer consistent with the assumption that the aquifer is confined analysis of the water level data in this well however showed a positive phase shift of 12 5 of the water level response to the m2 tide wang et al 2018 barbour et al 2019 suggesting that the aquitard is leaking at this site an important question is how bad is the aquitard leaking wang et al 2018 interpret the positive phase shift with an analytical solution here we revisit this interpretation with the 2d numerical simulation for the 2d numerical simulation of the tidal response of the arbuckle aquifer we use the same hydraulic properties for the aquifer from existing studies as used in wang et al 2018 table 1 lists the data and the thickness of the arbuckle aquifer for completeness the aquitard above the arbuckle aquifer at this location consists of layered rocks with a total thickness of 277 m since few experimental measurements exist for the hydraulic properties of these layers we use the tidal response in this well to invert for the average aquitard conductivity in this well and assume a range of values for s 2 for the average aquitard storativity to examine how the uncertainty in s 2 may affect the result of the inversion fig 7 a shows plots of the simulated phase shift versus l o g k z 2 b 2 at three different aquitard storativity s 2 s 1 0 1 10 respectively the horizontal line representing the phase shift of 12 5 for the tidal response of the arbuckle aquifer to the m2 tide in the usgs well wang et al 2018 barbour et al 2019 intersects the model curves at k z 2 b 2 10 8 1 10 7 5 and 10 6 6 s 1 respectively given the thickness of the aquitard of 277 m the corresponding average vertical conductivity of the aquitard ranges from k z 2 2 10 6 9 10 6 and 7 10 5 m s respectively these estimates of the aquitard conductivity are as high as those of the aquifer in order to explore tidal response of the arbuckle aquifer in oklahoma further we take the basement leakage into consideration no direct measurement of the basement conductivity is available in oklahoma as far as we know through their simulations of the induced seismicity in oklahoma langenbruch et al 2018 estimated a basement permeability of 2x10 15 m2 and barbour et al 2017 suggested a basement diffusivity that decreases from 1 m2 s at the top of the basement to 0 002 m2 s at a depth of 8 km thus a wide range of basement conductivity is possible at this point here we assume for our simulations uniform basement conductivity between the top of the basement and a depth of 8 km with each of the two end member values of 10 8 and 10 4 m s the simulated results are plotted against the aquitard leakage factor k z 2 b 2 in fig 7b the intersections of these curves with the horizontal black line fig 7b which represents the phase shift of 12 5 for the tidal response of the arbuckle aquifer to the m2 tide in the usgs well wang et al 2018 yield an estimate of the leakage factor k z 2 b 2 of 10 8 1 to 10 7 75 s 1 together with the thickness of the aquitard of 277 m these values lead to an estimate of the average vertical conductivity of the aquitard as k z 2 2 10 6 and 5 4 10 6 m s respectively these estimated aquitard conductivities are also as high as those of the arbuckle aquifer summarizing the results of the numerical simulation for the tidal response of the arbuckle aquifer at the usgs deep well site oklahoma we find that the inclusion of aquitard storativity and basement conductivity in the interpretation of the observed phase shift leads to increased estimates of the aquifer leakage over that estimated from the analytical model represented by the curves with s 2 0 with reasonable estimates of aquitard storativity and basement conductivity our numerical simulation constrained by the tidal response at the usgs monitoring well and the available laboratory and field data leads to an estimate of the aquitard conductivity as high as that of the aquifer itself 6 concluding remarks in this study we demonstrate that the simplifications assumed in the existing analytical model significant affect the solutions of the tidal response of leaky aquifers and thus on the evaluation of aquifer leakage from the observed tidal response in particular we examine the limitations of the analytic model due to its assumptions that 1 the aquifer is relatively thin and its vertical hydraulic conductivity is relatively large compared with that of the aquitard 2 the aquitard storage is negligible and 3 the basement leakage is negligible we find that each of these assumptions leads to an overly conservative estimate of aquifer leakage we revisit the tidal response of the arbuckle aquifer in oklahoma with the numerical model and show that it may leak at an average vertical aquitard conductivity of 2 10 6 to 7 10 5 m s for aquitard storage of zero to ten times the aquifer storage thus the aquitard above the arbuckle is not confining at this location but is as conductive as the aquifer itself given the fast rise of fluid level in many arbuckle wells anarsi et al 2019 in response to the injection of hundreds of millions of barrels of wastewater into this aquifer across oklahoma and kansas the present result calls for vigilant monitoring of any leakage of wastewater into the overlying freshwater reservoirs and the surface environment credit authorship contribution statement ai yu zhu methodology data curation writing original draft software visualization validation chi yuen wang conceptualization supervision writing review editing resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements work was partly supported by national key r d program of china no 2018yfc1503200 and the china scholarship council to a y z and partly supported by national science foundation grant ear1344424 to c y w additionally the authors would like to thank the valuable comments from the reviewers and the editor which led to significant improvement of this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124458 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5919,the response of aquifers to earth s solid tides earth tides has increasingly been used as a tool for monitoring the hydraulic properties of groundwater systems recent studies of the tidal response of the arbuckle aquifer opened to a usgs deep well in oklahoma wang et al 2018 barbour et al 2019 which has been injected with an enormous amount of toxic wastewater showed evidence that this aquifer may be leaking quantitative interpretation of the tidal response of this aquifer was made with a one dimensional analytical solution wang et al 2018 that showed that substantial leakage is occurring however the analytical model has inherent simplifications such as conductivity isotropy small aquifer thickness absence of aquitard storage and no basement leakage in this study we revisit the tidal response of leaky aquifers with a finite element multi layered model where such simplifications are removed we found that the simplifications in the analytical model lead to overly conservative estimates of leakage we revisit the tidal response of the arbuckle aquifer in oklahoma with the numerical simulation and estimate an average vertical hydraulic conductivity of 2 10 6 t o 7 10 5 m s for the aquitard overlying the arbuckle thus the aquitard above the arbuckle is not confining at this location but is as conductive as the aquifer itself given the fast rise of fluid level in many arbuckle wells in response to the injection of hundreds of millions of barrels of wastewater into this aquifer across oklahoma and kansas the present result calls for vigilant monitoring of leakage of wastewater from the arbuckle aquifer into the overlying freshwater reservoirs and the surface environment plain language summary earthquakes can damage the confinement of groundwater aquifers and thus can cause seismic hazard by letting freshwater in some aquifers to be contaminated or stored toxic wastewater in other aquifers to leak out into the environment thus it is important to monitor possible leakage of aquifers in earthquake countries analysis of the aquifer response to earth s solid tides in a usgs deep well in oklahoma wang et al 2018 barbour et al 2019 which has been used as the repository of an enormous amount of injected toxic wastewater shows that the aquifer may be leaking an analytical solution wang et al 2018 that contains several simplifications was used to quantify the aquifer leakage from the tidal response here we use a two dimensional multilayered numerical simulation without these simplifications to explore the limitations of the analytical model we find that aquitard storage and basement leakage have important effects on the tidal response of aquifers and the omission of these factors in the analytical solution may have caused underestimation of the aquifer leakage we then apply the numerical model to interpret the tidal response of water level documented in a usgs deep monitoring well installed in the arbuckle aquifer in oklahoma where an enormous amount of toxic wastewater has been stored with reasonable estimates of the aquitard storage our simulations yield an estimate of 2 10 6 t o 7 10 5 m s for the vertical hydraulic conductivity of the aquitard thus the aquitard is not at all confining but is as conductive as the aquifer itself given the fast rise of fluid level in many arbuckle wells in response to the injection of hundreds of millions of barrels of wastewater into this aquifer across oklahoma and kansas the present result calls for vigilant monitoring of leakage of wastewater from the arbuckle aquifer into the overlying freshwater reservoirs and the surface environment keywords groundwater response to the earth tides leaky aquifer numerical model 1 introduction the storage of toxic wastewaters in underground repositories is often based upon the assumption that the repository aquifer is tightly confined by impervious strata recent studies e g elkhoury et al 2006 wang et al 2016 2018 barbour et al 2019 zhang h et al 2019 zhang y et al 2019 showed however that permeability of groundwater systems may be a dynamic property and can change with earthquakes or anthropogenic disturbances thus continuous monitoring of the confinement of groundwater systems may be desirable to detect any possible leakage to the groundwater reservoir or from the underground waste repository the conventional method for studying groundwater leakage is by using the pumping injection method analytical solutions for pumping and injection in leaky aquifer have been developed since last century hantush and jacob 1955 hantush 1960 neuman and witherspoon 1969 hemker 1985 maas 1987a 1987b cheng and morohunfola 1993 hemker and maas 1994 veling and maas 2009 and used to investigate pressure change in response to fluid injection or extraction in wells cihan et al 2011 cardiff et al 2013 sun et al 2015 the method can be time consuming and expensive the response of groundwater to solid tides has been increasingly used as an economical tool for continuous monitoring of permeability bredehoeft 1967 hsieh et al 1987 roeloffs 1996 doan et al 2006 liao et al 2015 wang et al 2018 barbour et al 2019 allègre et al 2016 compared the tidal method and the conventional pumping tests at the same sites for a range of site specific permeability and found consistent results between the two methods elkhoury et al 2006 demonstrated the effectiveness of this method for continuous monitoring of the changes of aquifer properties in response to multiple earthquakes in southern california for twenty years wang et al 2018 proposed that the tidal response of a groundwater system may be used to examine the confinement of a groundwater system affected by earthquakes or anthropogenic disturbances and developed an analytical solution for the tidal response of a leaky aquifer to quantitatively evaluate the aquifer leakage from the tidal response in this model as in hantush 1967 leakage is treated as a volumetric sink in a 1d groundwater flow equation 1 t 2 h r 2 1 r h r k b h s h t b k u ρ g ε t where h m is the hydraulic head in the aquifer above a common reference r m is the radial distance from the studied well t m2 s and s respectively are the transmissivity and storativity of the aquifer ε is the tidal oscillating volumetric strain of the aquifer compression is taken to be positive b and k u pa respectively are the skempton s coefficient and the undrained bulk modulus of the aquifer and the aquifer leakage is implemented by a volumetric sink k h b in the aquifer where k m s and b m respectively are the vertical hydraulic conductivity and the thickness of the assumed aquitard in reality the leaky aquifer is part of a multiple aquifer system where leakage occurs across the boundary between the aquifer and the overlying aquitard instead of within the aquifer the tidal response of such a system depends on the hydrogeological behaviors of all the layers hantush 1967 sun and zhan 2006 hunt 2005 another simplification in the above model is that the aquitard storage was neglected the absence of the storage means the aquitard is assumed to go immediately into a steady state which is valid if leakage occurs through fine fractures and the time constant for the hydraulic equilibrium across the aquitard is short in comparison with the period of the tidal forcing this assumption however may fail for aquitards with relatively low conductivity and large thickness neuman and witherspoon 1969 witherspoon and freeze 1972 feng and zhan 2015 lastly the analytical leaky aquifer model assumes that the basement leakage is negligible however most induced earthquakes occur in the basement e g schoenball and ellsworth 2017 suggesting that some injected fluids must have leaked into the basement zhang et al 2013 barbour et al 2017 thus it is desirable to understand how basement leakage would affect the tidal response of an aquifer in the present study we revisit the response of a leaky aquifer with a 2d finite element numerical model where the simplifications in the analytic models are removed we first briefly describe the multi layered groundwater system and the numerical approach to study the system s response to earth tides we then verify the numerical method with existing analytical solutions hsieh et al 1987 for a perfectly confined aquifer and roeloffs 1996 for an idealized unconfined aquifer after the method is verified we apply it to simulate the tidal response of leaky aquifers to explore the limitations of the analytic model wang et al 2018 finally we apply the numerical model to re visit the tidal response of the arbuckle aquifer in a usgs deep monitoring well in oklahoma 2 numerical approach we use an axially symmetrical multi layered finite element model fig 1 of a groundwater system that consists of an aquifer confined below by a potentially leaky basement and above by a semi confining aquitard that in turn is overlain by an unconfined aquifer a vertical well centered along its axis completely penetrates and is open to the aquifer in the classical hantush leaky model hantush and jacob 1955 lee 1999 groundwater flow is assumed horizontal in the aquifers and vertical in the aquitard here we relax these restrictions by allowing groundwater in the aquifer to flow in both the horizontal and the vertical directions the semi confining aquitard and the basement are variably assumed to have finite transmissivity and storativity the topmost aquifer is unconfined and is bounded on the well side by the casing it is assumed to have high vertical hydraulic conductivity and is thus characterized by a hydrostatic head groundwater flow in such a system driven by earth tide may be evaluated by solving the following differential equations 2 k ri 2 h i r 2 1 r h i r k zi 2 h i z 2 s si h i t b i k ui ρ g t where h i m is the hydraulic head in the ith layer r m the radial distance from the axis of the well k ri m s and k zi m s respectively the hydraulic conductivities in the radial and vertical directions of the ith layer s si m 1 the specific storage of the ith layer the tidal volumetric strain bi and k ui p a respectively the skempton s coefficient and the undrained bulk modulus of the ith layer and ρ k g m 3 and g m s 2 respectively the density of water and the gravitational acceleration k ri and k zi respectively are related to the horizontal and vertical permeabilities k ri and k zi of the ith layer by k ri k ri ρ g μ and k zi k zi ρ g μ respectively μ the viscosity of water and b i the thickness of the ith layer the basement is assumed to be a semi infinite half space since this study aims at exploring the effect of ki and ssi on the tidal response of leaky aquifers we assume for simplicity that the skempton coefficient bi and the undrained bulk modulus k ui are uniform in all layers the basement beneath the aquifer is assumed to be impervious in most simulations except those in section 4 4 where the effect of basement leakage is examined continuity of the hydraulic head is enforced on the boundaries between all layers comparing 1 and 2 we see that our numerical approach has eliminated the assumption in the analytical model of using a volumetric sink in the aquifer to represent leakage in the aquitard we assume a boundary condition of p 0 1 atm on the ground surface z 0 and assign a mixed boundary condition at the opened section of the borehole fig 1 which is dependent on the solution 3 2 π r b t 1 h 1 r t r π r c 2 h 1 r t t 0 where r b is the radius of the opened section of the well and r c is the radius of the cased section of the well in our simulations we assume r b r c 0 1 m for simplicity finally we assign no flow conditions on the cased section of the well on the right boundary r of the model and at the base z of the model we use comsol a commercially available finite element software package to solve the system of equations 2 constrained by the boundary conditions described above and material properties to be prescribed later small element size 0 5 m and time steps 500 s are used to ensure accuracy and numerical stability finally we focus on the response to the m2 tide because it is the most widely used response on account of its relatively large signal to noise ratio and that it is minimally affected by the changes in the barometric pressure 3 verification of the numerical model we first compare the simulated results for a confined aquifer against the analytical solution provided by hsieh et al 1987 see also doan et al 2006 the simulations were carried out with both a one dimensional 1d and an axially symmetrical multilayered model with the assumption that the aquitard is impervious and has zero storativity fig 2 shows that the simulated phase shift and amplitude ratio from the 1d model matches perfectly with the analytical solutions of hsieh et al 1987 see also doan et al 2006 small differences in the phase shift occur between the 2d simulation and the analytical solution when the aquifer transmissivity is less than 10 6 m 2 s which may reflect the fact that when the horizontal transmissivity is low flow in the 2d simulation deviates from that in the 1d model supplementary information we next compare the simulated results for an unconfined aquifer against the analytical solution provided by roeloffs 1996 see also wang 2000a 2000b doan et al 2006 here t zi and s i are assigned the same value in all layers to simulate a half space unconfined aquifer we choose t zi 10 4 m 2 s and s i 10 4 same as in doan et al 2006 the simulated phase shift and amplitude ratio are plotted against z δ fig 3 a and 3b where δ 2 d ω z is the depth of the screening interval of a cased well d t s is the hydraulic diffusivity and ω the angular frequency of the m2 tide also plotted are the analytical solution for an unconfined aquifer roeloffs 1996 wang 2000a 2000b doan et al 2006 the figures show that the simulated results closely match the analytical solution summarizing the above results we have verified the numerical code against the available analytical solutions for the tidal responses of perfectly confined aquifers and idealized unconfined aquifers we may thus use the code to explore the tidal response of aquifers under more general conditions and to examine the limitations of the analytical solution for a leaky aquifer as shown below 4 revisit the tidal response of a leaky aquifer with numerical simulation in this section we use the 2d numerical model verified above to revisit the response of a leaky aquifer to earth tides and to investigate the limitations of the analytic solution in wang et al 2018 in particular we investigate the following three specific effects in sequence aquifer thickness and conductivity aquitard storage and basement leakage 4 1 effect of aquifer thickness and conductivity in the analytic models of hantush and jacob 1955 and wang et al 2018 the effect of aquifer leakage on groundwater flow is implemented as a volumetric sink in the aquifer hantush 1967 pointed out that this assumption is valid if the aquifer is relatively thin and its vertical hydraulic conductivity is relatively large compared with that of the aquitard we examine the effect of this assumption on the tidal response to the m2 tide by introducing the parameter α k z 1 b 1 k z 2 b 2 and conducting a series of simulations for different values of α with specific horizontal conductivity k r 1 and storativity s 1 of the aquifer results fig 4 shows that good agreement between the simulated results and the analytic solution wang et al 2018 occurs when α 5 across the whole ranges of studied aquitard leakage factor k z 2 b 2 k r 1 and s 1 at α 5 however the simulated results deviate progressively from the analytic solutions in the transition zone with the simulated phase shift increasing and amplitude ratio decreasing with increasing α at a given k z 2 b 2 it thus appears that when α 5 the aquifer is thin enough and its vertical hydraulic conductivity is large enough compared with that of the aquitard that the use of a volumetric sink to represent aquifer leakage in the analytical model may be acceptable hantush 1967 proposed a criterion b t k b 0 1 for testing the utility of the analytical model to interpret the results of pumping test where t and b refer to the transmissivity and thickness of the aquifer and k and b refer to the hydraulic conductivity and thickness of the aquitard here we examine if this criterion may be used for the utility of the analytical tidal model using the present notations and recalling that hantush s aquifer model is isotropic i e k z 1 k r 1 t 1 b 1 we may recast hantush s criterion with the present notations as b 1 t 1 k z 2 b 2 1 k z 1 b 1 k z 2 b 2 1 α 0 1 or α 100 as shown earlier however good agreement between the analytic tidal solutions and the numerical simulations occurs when α 5 thus it appears that hantush s criterion would be overly conservative when applied to test the utility of the analytic tidal model 4 2 effect of aquitard storativity another assumption in the analytical leaky aquifer model hantush and jacob 1955 wang et al 2018 is that the semi confining aquitard has negligible storativity as noted earlier this assumption is equivalent to assuming that the aquitard goes immediately into a steady state which is valid only if the time constant for the hydraulic equilibrium across the aquitard is short in comparison with the period of the tidal forcing the occurrence of aquitard storage significantly increases the time constant for the hydraulic equilibrium across the aquitard and renders the assumption invalid if the aquitard has relatively low conductivity and large thickness neuman and witherspoon 1969 witherspoon and freeze 1972 feng and zhan 2015 here we explore the effect of aquitard storage on tidal response of the system with our numerical simulation in the simulation we assume s 2 s 1 0 1 10 and 100 respectively with specific values of k r 1 10 5 m s and α 10 fig 5 shows good agreement between the simulated results and the analytical solution when s 2 0 but when s 2 is greater than 0 aquitard storativity has important effects on the tidal response of the system and the simulated results depart significantly from the analytical solution at a given aquitard leakage factor k z 2 b 2 increasing aquitard storativity causes significant decreases in phase shift and increases in amplitude ratio another interesting feature is that the simulated amplitude ratio exceeds 1 fig 5 and the magnitude of this excess becomes greater with increasing aquitard storativity similar increases of the amplitude ratio were reported before and interpreted to be due to the poroelastic coupling between pore pressure and deformation detournay and cheng 1993 hsieh and cooley 1995 wang 2000a 2000b 4 3 effect of basement leakage most studies interpret the positive phase shift in the observed tidal response of water level to represent leakage above the studied aquifer e g xue et al 2016 allègre et al 2016 wang et al 2018 barbour et al 2019 on the other hand many induced earthquakes occur in the basement e g schoenball and ellsworth 2017 suggesting that some injected fluids must have leaked into the basement zhang et al 2013 barbour et al 2017 some studies require basement diffusivity as high as 1 m2 s to explain the induced seismicity barbour et al 2017 the occurrence of basement leakage on the response to earth tides has not been investigated could some observed positive phase shifts be the result of basement leakage we devote this sub section to answer this question basement leakage alone will not cause positive phase shift because the tidal response in this case would be similar to that of a confined aquifer and thus negative see simulated results in supplementary information thus we discuss here the effect of basement leakage on the tidal response of a leaky aquifer the simulated result fig 6 shows that if the basement conductivity is below 10 7 m s the effect of basement leakage on the aquifer tidal response is insignificant at greater conductivity however basement leakage may cause significant decrease in phase shift and increase in amplitude ratio at the same k z 2 b 2 fig 6 and the interpretation of the tidal response may significantly underestimate aquifer leakage if basement leakage is not considered 5 revisit the tidal response of the arbuckle aquifer with numerical simulation the sharp increase of seismicity in the mid continental u s since 2005 has been linked to the injection of massive amount of wastewater co produced from hydrocarbon exploration into deep aquifers e g ellsworth 2013 langenbruch and zoback 2016 a basic assumption for the disposal of wastewater into the deep aquifers is that such aquifers for example the arbuckle aquifer in oklahoma and kansas are confined by aquitards however it is known that aquitards can be disrupted by earthquakes wang et al 2016 following the occurrences of three large mw 5 earthquakes in 2016 in oklahoma the u s geological survey installed a pressure gauge in 2017 in a deep monitoring well in the arbuckle aquifer in northeastern oklahoma logs from this well wang et al 2018 barbour et al 2019 show that the aquifer is overlain by an aquitard containing a shale layer consistent with the assumption that the aquifer is confined analysis of the water level data in this well however showed a positive phase shift of 12 5 of the water level response to the m2 tide wang et al 2018 barbour et al 2019 suggesting that the aquitard is leaking at this site an important question is how bad is the aquitard leaking wang et al 2018 interpret the positive phase shift with an analytical solution here we revisit this interpretation with the 2d numerical simulation for the 2d numerical simulation of the tidal response of the arbuckle aquifer we use the same hydraulic properties for the aquifer from existing studies as used in wang et al 2018 table 1 lists the data and the thickness of the arbuckle aquifer for completeness the aquitard above the arbuckle aquifer at this location consists of layered rocks with a total thickness of 277 m since few experimental measurements exist for the hydraulic properties of these layers we use the tidal response in this well to invert for the average aquitard conductivity in this well and assume a range of values for s 2 for the average aquitard storativity to examine how the uncertainty in s 2 may affect the result of the inversion fig 7 a shows plots of the simulated phase shift versus l o g k z 2 b 2 at three different aquitard storativity s 2 s 1 0 1 10 respectively the horizontal line representing the phase shift of 12 5 for the tidal response of the arbuckle aquifer to the m2 tide in the usgs well wang et al 2018 barbour et al 2019 intersects the model curves at k z 2 b 2 10 8 1 10 7 5 and 10 6 6 s 1 respectively given the thickness of the aquitard of 277 m the corresponding average vertical conductivity of the aquitard ranges from k z 2 2 10 6 9 10 6 and 7 10 5 m s respectively these estimates of the aquitard conductivity are as high as those of the aquifer in order to explore tidal response of the arbuckle aquifer in oklahoma further we take the basement leakage into consideration no direct measurement of the basement conductivity is available in oklahoma as far as we know through their simulations of the induced seismicity in oklahoma langenbruch et al 2018 estimated a basement permeability of 2x10 15 m2 and barbour et al 2017 suggested a basement diffusivity that decreases from 1 m2 s at the top of the basement to 0 002 m2 s at a depth of 8 km thus a wide range of basement conductivity is possible at this point here we assume for our simulations uniform basement conductivity between the top of the basement and a depth of 8 km with each of the two end member values of 10 8 and 10 4 m s the simulated results are plotted against the aquitard leakage factor k z 2 b 2 in fig 7b the intersections of these curves with the horizontal black line fig 7b which represents the phase shift of 12 5 for the tidal response of the arbuckle aquifer to the m2 tide in the usgs well wang et al 2018 yield an estimate of the leakage factor k z 2 b 2 of 10 8 1 to 10 7 75 s 1 together with the thickness of the aquitard of 277 m these values lead to an estimate of the average vertical conductivity of the aquitard as k z 2 2 10 6 and 5 4 10 6 m s respectively these estimated aquitard conductivities are also as high as those of the arbuckle aquifer summarizing the results of the numerical simulation for the tidal response of the arbuckle aquifer at the usgs deep well site oklahoma we find that the inclusion of aquitard storativity and basement conductivity in the interpretation of the observed phase shift leads to increased estimates of the aquifer leakage over that estimated from the analytical model represented by the curves with s 2 0 with reasonable estimates of aquitard storativity and basement conductivity our numerical simulation constrained by the tidal response at the usgs monitoring well and the available laboratory and field data leads to an estimate of the aquitard conductivity as high as that of the aquifer itself 6 concluding remarks in this study we demonstrate that the simplifications assumed in the existing analytical model significant affect the solutions of the tidal response of leaky aquifers and thus on the evaluation of aquifer leakage from the observed tidal response in particular we examine the limitations of the analytic model due to its assumptions that 1 the aquifer is relatively thin and its vertical hydraulic conductivity is relatively large compared with that of the aquitard 2 the aquitard storage is negligible and 3 the basement leakage is negligible we find that each of these assumptions leads to an overly conservative estimate of aquifer leakage we revisit the tidal response of the arbuckle aquifer in oklahoma with the numerical model and show that it may leak at an average vertical aquitard conductivity of 2 10 6 to 7 10 5 m s for aquitard storage of zero to ten times the aquifer storage thus the aquitard above the arbuckle is not confining at this location but is as conductive as the aquifer itself given the fast rise of fluid level in many arbuckle wells anarsi et al 2019 in response to the injection of hundreds of millions of barrels of wastewater into this aquifer across oklahoma and kansas the present result calls for vigilant monitoring of any leakage of wastewater into the overlying freshwater reservoirs and the surface environment credit authorship contribution statement ai yu zhu methodology data curation writing original draft software visualization validation chi yuen wang conceptualization supervision writing review editing resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements work was partly supported by national key r d program of china no 2018yfc1503200 and the china scholarship council to a y z and partly supported by national science foundation grant ear1344424 to c y w additionally the authors would like to thank the valuable comments from the reviewers and the editor which led to significant improvement of this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124458 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
