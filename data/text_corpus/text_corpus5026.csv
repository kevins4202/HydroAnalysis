index,text
25130,a dissolved oxygen do mass balance was developed for a 5 9 km reach of the heavily eutrophied and macrophyte rich wastewater effluent dominated silver bow creek mt usa to assess water quality changes following an upgrade to the municipal wastewater facility surveys of diurnal do were completed in 2015 and 2016 and various mass transfer rates were quantified including macrophyte photosynthesis and respiration macrophyte density sediment oxygen demand and reaeration a do mass balance model was then developed in qual2k where oxygen equivalents of macrophytes were incorporated as closely spaced diurnally varying point sources sinusoids overall diurnal do swings and longitudinal oxygen profiles were reasonably replicated in the pre and post upgrade synoptic surveys and models and the facility upgrade greatly enhanced do concentrations in the stream improvements however were not enough to meet the minimum do criterion for the waterbody the results above have important implications for assessing do responses and impairment status in macrophyte rich streams moreover they suggest wastewater treatment upgrades may not always achieve desired results and that modeling should be conducted a priori to understand receiving water responses keywords dissolved oxygen model macrophytes wastewater silver bow creek qual2k 1 introduction effluent dominated streams have undergone limited literature study brooks et al 2006 gücker et al 2006 nonetheless offer a unique laboratory for which to observe pollution related environmental responses while numerous aquatic concerns can be linked to wastewater effluent including increases in temperature or turbidity do deficit or ph or the addition of toxic substances mackenthun 1969 daniel et al 2002 aristi et al 2015 the do concentration in the receiving water is a fundamental water quality indicator of the health and well being of a waterbody hynes 1960 dodds 2002 given its overall importance to fish and aquatic life gaining an understanding of the sources and sinks of do relative to deficit generated from human activity along with simulating instream responses from management actions such as wastewater treatment upgrades is a worthwhile endeavor impacts of wastewater treatment plants wwtps on the do balance of a receiving water are widely noted haggard et al 2001 2005 marti et al 2004 gücker et al 2006 aristi et al 2015 in both raw and treated wastewater nitrogenous or carbonaceous forms of biochemical oxygen demand bod cause deoxygenation when the rate of do consumption from ammonium nh4 oxidation or degradation of labile and refractory forms of carbon exceeds reaeration an oxygen sag occurs the most widely publicized of these is documented in the seminal work of streeter and phelps 1925 on the ohio river based on an elegant analytical model relating the physics chemistry and biology to saturation deficit downstream of a point source the do sag minimum can be computed which occurs at the location where the rate of bod decomposition and reaeration are equivalent chapra 2008 oxygen deficits can also be associated with secondary enrichment effects or eutrophication smith et al 1999 usepa 2016 excess nutrient concentrations increase the productivity of receiving waters and result in variety of undesirable water quality changes including excessive aquatic plant or algal growth diminished aquatic communities or development of hypoxia or oxygen dead zones hynes 1969 dodds and welch 2000 loss of recreational amenities reduced property values and increased drinking water treatment costs also occur dodds et al 2009 in certain instances expansive growths may reach nuisance levels and impair recreation fish and aquatic life and water quality uses gammons et al 2011 he et al 2011 in this regard both primary and secondary effects of wastewater can be far reaching moreover despite advances in treatment technologies nutrient loadings from wwtps continue to be widespread and pervasive carey and migliaccio 2009 impacts on stream ecology can persist for tens of kilometers haggard et al 2005 affecting benthic flora bacteria and biota mackenthun 1969 drury et al 2013 many investigators note that effluent impacted or effluent dominated waterbodies are prone to luxuriant macrophyte growth cole 1973 madsen and adams 1988 1989 chambers and prepas 1994 gücker et al 2006 taube et al 2016 excessive growth of aquatic plants or nuisance macrophyte biomasses cause large diurnal swings in aqueous gases like do and carbon dioxide co2 chambers and prepas 1994 macrophyte photosynthesis during the daytime elevates do beyond what can be expelled through reaeration super saturation while at night macrophyte beds consume oxygen through respiration causing hypoxic conditions alkalinity and ph likewise are affected during daytime photosynthesis co2 is consumed raising the ph of the stream at night macrophytes respire driving the bicarbonate system back towards the reactants finally carbon that is temporarily sequestered as macrophyte growth can become a temporal oxygen sink as macrophytes senesce and decompose at the end of the growing season in this regard quantifying and simulating macrophyte influences on stream do is an active area of research in the 1970s a number of efforts were made to develop models that simulate macrophytes in lakes e g clean cleaner etc park 1974 bowie et al 1985 citing others however efforts on rivers started later park et al 2003 developed macriv a mechanistic computer model to incorporate macrophytes as oxygen equivalents varying oxygen production diurnally park et al 2008 developed aquatox macrophyte routines based on previous work on lakes robinson et al 2009 modified the water quality analysis and simulation program wasp usepa 2018 to incorporate periphyton and macrophytes and simulate do concentrations in the bow river alberta canada ce qual w2 cole and wells 2017 was recently modified to include macrophytes for application to the columbia slough in oregon berger and wells 2008 the klamath river upstream of keno dam in oregon sullivan et al 2013 and lake ogallala nebraska stansbury et al 2008 qual2kw also has basic functionality for simulating macrophytes using the benthic algae submodel pelletier and chapra 2008 finally data driven models as opposed to process based models have also been used to model do in a number of instances he et al 2011 khan and valeo 2015 and 2017 these models use abiotic factors commonly water temperature nutrient concentration flow rate and solar radiation to predict do concentrations using artificial neural networks khan and valeo 2017 in this paper we investigate the do mass balance on a small urbanized stream where municipal wastewater is a large component of the available streamflow specifically we document dissolved oxygen changes both before and after a tertiary wwtp upgrade conduct modeling to simulate macrophyte effects using oxygen equivalents in the mechanistic model qual2k and address field methods to quantify the oxygen mass balance and oxygen cycling in streams results have important implications for modeling do in macrophyte rich effluent dominated streams as well as for evaluating the potential outcomes of water quality improvements from wwtp upgrades 2 materials and methods 2 1 study area silver bow creek sbc is a small urbanized stream in western montana fig 1 that flows westerly through butte mt to form the headwaters to the clark fork of the columbia river it is identified on the 2016 state of montana 303 d list as impaired for nitrate total nitrogen and total phosphorus and is currently not supporting aquatic life and primary contact recreation uses montana deq 2016 notably sbc is effluent dominated with the butte municipal metro wastewater treatment plant wwtp contributing 0 16 m3 s of the annual discharge to the stream mean annual streamflow immediately downstream of the wwtp at usgs 12323250 silver bow creek below blacktail creek at butte mt is 0 6 m3 s peak flow is 2 m3 s and annual 7 day low flow 0 4 m3 s fig 2 in this regard the low flow contribution of the wwtp is approximately 40 the climate of the study area is cold and arid wrs 1955 with a mean annual temperature of 4 5 c and valley precipitation averaging 322 mm annually wrcc western regional climate center 2017 a majority of the surface water in sbc comes from snowmelt runoff in blacktail creek during the spring and early summer months outside of this tributary inflow the remaining headwaters of upper silver bow creek are cutoff by an active mining operation berkley pit therefore contributing minimally to streamflow the occurrence of monthly mean low flow is in december although the months of july through december all have similar critical low flow conditions mccarthy 2016 eutrophication downstream of the butte metro wwtp is well documented gammons et al 2011 before the wwtp upgrades discussed in this work anaerobic conditions historically existed downstream of the plant from nbod and large masses of aquatic plants macrophytes have been observed between butte and rocker mt such conditions are accompanied by a notable amount of diurnal water quality changes gammons et al 2011 while few long term nutrient monitoring campaigns have been performed in the area recent data published by usgs indicates nitrate concentrations are high at the usgs gage immediately downstream of the wwtp fig 3 nitrate plus nitrate exhibits an inverse relationship with discharge due to upstream dilution noting the highest concentrations are observed during the winter months presumably from cold temperatures and reduced biological activity like many effluent dominated streams sbc is dominated by several macrophyte species primarily sago pondweed potamogeton pectinatus and also white buttercup ranunculus aquatilis common duckweed lumna minor and common water moss fontinalis antipyretica mitman 2015 the macrophytes partially die off and senesce each winter due to cold temperatures poor light conditions and ice cover but grow back each year over the course of summer in the late summer macrophytes form a thick mat across the stream bottom that in most places occupies the entire volume of the wetted channel between the summers of 2015 and 2016 the butte metro wwtp underwent a significant plant upgrade moving from a secondary to a tertiary treatment process to reduce ammonia and overall nutrient contributions to silver bow creek the original treatment works consisted of an activated sludge secondary treatment system with ultraviolet uv disinfection while the new plant consists of several advanced membrane bioreactors and a nitrification step the above change provides an ideal set of conditions to evaluate pre and post wwtp upgrades on stream do and water quality 2 2 data collection synoptic surveys were conducted during the summers of 2015 and 2016 over a 6 km stretch downstream of butte mt to understand the do mass balance below the municipal wwtp and to support water quality model development the study extent begins at whiskey gulch located downstream of the i 90 overpass just downstream of butte mt and ends just upstream of the i 15 south exchange fig 1a the upstream location whiskey gulch was placed far enough downstream of the wwtp so complete mixing of the effluent discharge and sbc occurred complete mixing was verified by measurements of conductivity across the channel at the headwater of the study reach water quality data were subsequently collected at four locations in the study reach 1 whiskey gulch 5 83 km upstream of the terminus of the reach beaver pond 4 76 km rocker 3 01 km and near i 15 south 0 km similar to the approach described by hobson et al 2014 macrophyte biomasses were characterized over a slightly larger extent 6 km as described later 2 2 1 datasondes and water quality sampling the following diurnal field water quality parameters were measured at each of the four monitoring locations mentioned previously with ysi exo 2 and hydrolab sondes do temperature ph and specific conductance sc sondes were securely set in the main flow path of the stream inside of pvc housings vertically to prevent movement or damage with holes drilled to allow sufficient water flow through over time the housings would collect large masses of sticks branches and loose macrophytes that were flowing downstream when collecting data for the do mass balance model debris was removed several times during the day to prevent fouling the sondes were calibrated according to their respective manuals one day prior to sampling during the sampling event an additional sonde was used to perform side by side checks of recorded values grab samples were collected concurrently at all four locations sample bottles were cleaned with 10 hydrochloric acid before use and bottles were rinsed three times with stream water before sampling collecting from the upstream side and discharging in the downstream direction samples were obtained from the center flow of the stream at about two thirds of the depth of the water column they were taken immediately downstream of the recording sondes to ensure consistency samples were analyzed using the methods outlined in table 1 for the following constituents orthophosphate soluble reactive phosphorus srp nitrate plus nitrite ammonia total phosphorus tp total kjeldahl nitrogen tkn alkalinity inorganic suspended solids and detritus 2 2 2 reach macrophyte density estimates a subsampling procedure was used to estimate macrophyte biomass within different reaches of the study area in 2015 mass of macrophytes per unit stream length 0 3048 m in the sbc reach were visually graded on a 0 to 10 scale for biomass the overall reach was then subdivided into smaller reaches of 50 m and each sub reach was assigned a grade on a 0 to 10 scale corresponding to macrophyte density fig 1b for select grades dry mass of macrophytes were collected from the entire width of the channel transect over a longitudinal length of 0 3048 m this was achieved by marking the plan view area with two measuring tapes and then only extracting macrophytes that fell within the demarcated areal region wet weight of the extracted macrophytes was measured in the field using a rapala digital scale and a subsample was collected to measure the dry mass in the lab laboratory samples were air dried for seven days and then oven dried at 105 c for eight hours and weighed for dry mass using a mettler toldeo ae 240 analytical balance usgs 2015 using the sample dry mass the dry mass of macrophyte in the sampling volume was calculated using a wet mass to dry mass conversion which was then normalized to areal density e g gd m2 see supplemental table s1 for the macrophyte density grades where mass of macrophytes were not measured 4 of the 10 categories values were linearly interpolated between measured grades example grades are shown in fig 4 grading densities are discussed more in the results based on visual inspection it was observed that macrophyte densities were similar during the summers of 2015 and 2016 2 2 3 light dark bottle experiments light dark bottle experiments were initiated in july august and october 2016 to measure macrophyte photosynthesis and respiration rates at different temperatures thomann and mueller 1987 this was done by collecting a small amount of live macrophyte material and placing it in both a light and dark bottle and incubating it near optimal irradiance a third bottle was also incubated in the light only with site water as a control however results were such that no water column corrections were necessary the experiments were conducted several times during the afternoon hours ranging from 12 15 p m to 2 20 p m with an ending times ranging from 3 00 p m to 6 38 p m solar irradiance during this period was 1210 w m2 at 3 00 p m to 1260 w m2 at 6 38 p m measured with a handheld dbtu1300solar meter macrophytes were air dried for seven days and then oven dried at 105 c for an additional 8 h and weighed for dry mass usgs 2015 bottle rates were normalized to the dry mass of macrophytes in the glass bottle mgo2 gd d 2 2 4 oxygen produced by macrophytes during photosynthesis and respiration macrophyte photosynthetic and respiratory rates were combined with the spatial distribution of macrophytes from the reach density estimates to determine their influence on the oxygen mass balance oxygen load in mgo2 d from net macrophyte production was approximated by multiplying the graded mass of macrophytes gd m2 in each longitudinal stream reach by its respective areal extent m2 and oxygen production rate mgo2 gd d reach areas were digitized in arcgis at 1 000 scale using an arcgis basemap similarly the macrophyte respiration rate and oxygen deficit were handled in the same way source sink loadings were distributed diurnally using a sine function as outlined in chapra 2008 discussed later 2 2 5 sediment oxygen demand sediment oxygen demand sod was measured by incubating sediment cores using the procedures outlined by thomann and mueller 1987 while ideally a core sample several inches deep would be used the poorly consolidated substrate of sbc prevented the corer from collecting an intact sample instead a sample tube was filled with 6 to 8 in of sediment and covered with stream water to fill the remaining space an identical sample tube was filled with stream water to be used as a blank to determine the water column oxygen demand cores were stored on ice during transport to an incubator in the lab set to 14 c the average temperature of the water during monitoring period initial and final dissolved oxygen values were recorded for the blank tube while the core was monitored continuously over a 24 hour period the change in dissolved oxygen in the blank tube was subtracted from the change in the core tube to account for the water column oxygen demand bottom areal sod coverage of 40 was used for the study 2 2 6 reaeration reaeration rate was calculated using the delta method chapra and di toro 1991 mcbride and chapra 2005 delta method empirically relates the time of peak dissolved oxygen or deficit minimum as a function of lag from solar noon to the reaeration rate within the study reach the method produced unreliable results because of the low dissolved oxygen content and variable flows from the wwtp accordingly the reaeration rate was also calculated using a time series of sonde data further upstream in blacktail creek above the wwtp discharge this site is located less than a mile upstream of the headwater site at whiskey gulch and contains most of the flow that makes up silver bow creek it has similar substrate depth and velocity to the study reach making it a suitable surrogate to estimate the reaeration rate of silver bow creek 2 3 dissolved oxygen modeling the model qual2k chapra et al 2012 was used for oxygen accounting in the reach key processes that were simulated in the model included nitrification sediment oxygen demand macrophyte photosynthesis and respiration and reaeration qual2k is a widely used one dimensional advection dispersion river model and part of the u s environmental protection agency s water quality modeling toolbox usepa 2015 state variables are simulated on a longitudinal basis with diel water quality kinetics that enable the user to study the daily fluctuation of do over a 24 hr cycle numerical computations are programmed in fortran 90 and are implemented from the microsoft excel visual basic for applications vba environment an explicit forward time backward space scheme corrected for numerical dispersion is used to determine the concentration in each model element at each time step 2 3 1 model setup and parameterization synoptic data were collected on aug 22 2015 and july 19 2016 at critical low flow 0 391 m3 s and 0 481 m3 s and warm summer temperatures 14 8 c for model development when do is at critical conditions the modeling domain was divided into five reaches based on physical features including changes in elevation gradient macrophyte coverage flow depth and beaver dams the reach was 5 83 km long reach lengths latitude and longitude information were obtained from aerial photography whereas longitudinal elevation data were surveyed using a leica viva gnss gs 15 three small beaver dams were modeled as broad crested weirs using the measured height and width of the beaver dams the weir coefficients adam and bdam from the butts and evans 1983 formula were adopted from mccullough et al 2007 using the usgs gage station 12323250 measurements usgs available online at https waterdata usgs gov mt nwis uv site no 12323250 depth and velocity rating curves were developed for study reaches that do not contain beaver dams supplemental fig s1 qual2k requires 24 hour headwater forcing functions to account for the temporal changes in the daily cycles of inputs these are believed to be important in a stream with large diurnal cycling like sbc where the upstream headwater is heavily influenced by the metro wwtp as mentioned previously diurnal field water quality parameters were measured at this location using two ysi exo 2 and two hydrolab sondes however grab samples were also collected concurrently at 10 a m 2 p m 6 p m and 10 p m on those dates samples were analyzed as outlined previously in table 1 weather data air temperature dew point temperature wind speed and cloud cover were retrieved from bert mooney airport butte mt weather station national weather service available online at http w1 weather gov obhistory kbtm html which is approximately 8 km from the upstream whiskey gulch site flow data was obtained from usgs gage station 12323250 usgs available online at https waterdata usgs gov mt nwis uv site no 12323250 fig 1 and flow depth was also measured at six locations in the project site carbonaceous bod cbod values for wwtp effluent and upstream of the wwtp confluence were obtained from butte wwtp and were estimated using a standard mass balance equation the shade xlsx program department of ecology 2016 a tool for estimating shade from riparian vegetation written in excel vba was used to estimate the fraction of potential solar radiation blocked by topography and vegetation over the study reach it was assumed that the vegetation was medium to sparse along the length of the reach 2 3 2 macrophytes in qual2k the mass balance for do oi in a qual2k element having steady flow is chapra et al 2012 1 v i d o i d t q i 1 o i 1 q i o i e i 1 o i 1 o i e i o i 1 o i w i s i where q flow m3 s o do concentration go2 m3 v element volume m3 e bulk dispersion coefficient m3 s w external load go2 s and s sources and sinks or sinks go2 s subscripts i i 1 and i 1 represent the current upstream and downstream elements respectively qualk does not simulate dissolved oxygen from macrophyte photosynthesis or respiration explicitly please refer to the discussion about this limitation as well as the rationale behind the proposed approach it does however allow the input of oxygen point sources and also accommodates oxygen lost via fast cbod oxidation nitrification and plant respiration additionally depending on whether the water is undersaturated or oversaturated oxygen is gained or lost via reaeration we used external forcing functions to simulate the influence of macrophytes on the oxygen mass balance the macrophyte source sink of oxygen is approximated using a sinusoid chapra 2008 2 s t q m o m a c r o p h y t e s o a sin ω t θ where qm negligible flow rate added as point source m3 s omacrophytes mean oxygen concentration equivalency of macrophytes go2 m3 oa oxygen concentration amplitude go2 m3 range 2 ω angular frequency radians t assumed to be 2π t t time d and θ phase shift radians respectively oxygen equivalent inputs for the sinusoid require the mean range 2 and time of max be specified around solar noon around 1 30 pm the oxygen load is added as a point source with a very small flow rate of 0 01 l sec such that do concentration in the point source is equals the oxygen equivalents measured in the light dark bottle experiments with the caveat that calibration potentially may be required the uptake rate of ammonia and influence of nitrification on oxygen was lumped into a combined nitrification rate calibrated to longitudinal ammonia data a first order rate equation was used to fit both our data and that previously collected by gammons et al 2011 2 3 3 model calibration and confirmation the model was manually calibrated using the intensive water quality data collected on august 22 2015 and confirmed using the synoptic survey from july 19 2016 calibration was constrained by adjusting only macrophyte do sinusoid point source oxygen equivalents with the objective of minimizing the difference between measured and modeled do values other variables that influenced do were either measured or estimated from the literature review and engineering judgement rates used in parameterization of the model are shown in table 2 the same parameters that were determined during the calibration were used in model confirmation to identify whether the model can predict do values for a different data set thomann 1982 reckhow and chapra 1983 arnold et al 2012 only the headwater boundary condition and meteorological data were changed for the confirmation to reflect the july 19 2016 survey with the remaining rates and macrophyte do equivalents unchanged 3 results 3 1 field and laboratory measurements 3 1 1 datasondes and water quality during the critical low flow conditions approximately 0 32 m3 s the average depth and velocity in the study reach were 0 24 m and 0 26 m s respectively diurnal do and ph data from the sondes at the four monitoring sites are shown in fig 5 significant diel swing is noted which increases from upstream to downstream and corresponds to increasing macrophyte density on august 22 2015 model calibration pre wwtp upgrade at the upstream site whiskey gulch the minimum and maximum do were 3 79 mgo2 l and 7 68 mgo2 l respectively resulting in diel variation or delta of 3 89 mgo2 l at the downstream site i 15 the minimum do value was 1 46 mgo2 l with a maximum of 14 97 mgo2 l resulting in a diurnal variation in do of 13 5 mgo2 l hypoxic conditions do 2 mg l occurred for over half the day 12 5 h at this location hence the impact from the wwtp occurs some distance longitudinally from the point of discharge notably nighttime do minima are well below the state water quality standard of 5 mgo2 l mt deq 2017 on july 19 2016 model confirmation post wwtp upgrade the minimum and maximum do values were 3 93 mgo2 l and 15 43 mg l at the downstream i 15 site respectively with a diurnal variation of 11 50 mgo2 l the wwtp upgrade significantly reduced ammonia concentrations and certainly improved the minimum do concentration and sag a similar longitudinal effect occurs with ph daytime observations at downstream sites exceed 9 0 s u with diurnal cycling on the order of 1 5 to 2 0 s u data from 2016 showed even larger diurnal variability far outside the standard required in deq 7 mt deq 2017 the latter is likely due to changes in alkalinity on august 22 2015 the alkalinity decreased over the study reach from 133 70 mg of caco3 l at the upstream boundary to 115 85 mg of caco3 l at the downstream boundary on july 19 2016 alkalinity did not change significantly over the study reach but was much lower than 2015 range of 103 6 to 108 caco3 l while we did not measure the alkalinity of the wwtp effluent in this study it is often lower than that of the receiving water unpublished data and thus the volumetric ratio of effluent to the receiving water flow is an important consideration nutrient data from the summer of 2015 and 2016 confirm that upper sbc is highly eutrophied concentrations of nh3 n and no3 no2 n were 7 95 and 2 03 mg n l respectively in 2016 they were 0 05 and 2 05 mg n l both years the inorganic phosphorus po4 3 p concentrations at the upstream and downstream sites remained unchanged 1 24 mg p l and 1 17 mg p l in 2015 and 1 27 mg p l and 1 14 mg p l in 2016 the decline in nitrogen over the reach is presumably due to macrophyte uptake notably the ratio of soluble n p is near the redfield ratio in 2015 8 1 and shifted to 2 1 in 2016 this suggests that although nutrients are still saturated in this reach see concentrations reported above at some point inorganic nitrogen will eventually become limiting downstream although the particular location is outside of our study reach presumably the influence of the wwtp upgrade is already apparent there 3 1 2 macrophyte density estimates elevated nutrient concentrations and rich organic substrates provide favorable conditions for macrophyte growth in sbc macrophyte grades and corresponding field densities measured in 2016 are listed in table 3 biomasses at the uppermost site upstream of whiskey gulch are the lowest grade and are equivalent to 43 mgd m2 densities at the terminus of the study reach near i 15 were the highest grade and equivalent to 303 mgd m2 see fig 4 for visual correspondence as a reference robinson et al 2009 measured a macrophyte dry mass density of 241 29 gd m2 for bow river alberta canada in sbc wet mass to dry mass ratios ranged from 7 9 to 14 2 supplemental table s1 and as seen in the table 3 we had difficulty visually partitioning mid level grades of macrophyte density using results above i e diurnal do measurements and macrophyte biomass approximations it is noted that both do delta i e do maximum minus do minimum and macrophyte density increase from upstream to downstream substantially fig 6 the increase in do delta is believed to be directly attributable to increases in macrophyte density although it is unclear why there is a delayed response in primary productivity and biomass directly below the metro wwtp discharge point of discharge is at roughly 7 0 km the high do deltas in this reach far exceed typical recommendations of less than 4 to 6 mgo2 l suplee and sada de suplee 2011 heiskary et al 2013 suggested for healthy streams 3 1 3 light dark bottle experiments results from the light dark bottle experiments are shown in table 4 net primary production and respiration were comparable during two of the experiments however the experiment in august 2016 had nearly double primary productivity relative to that of the other bottle rates the range of rates is discussed later in context of our results see discussion 3 1 4 oxygen produced by macrophytes during photosynthesis and respiration estimates of diurnal oxygen produced by photosynthesis and consumed via respiration as fit to the sinusoid function described in the methods is shown in fig 7 the source and sink terms peak and trough at 1 30 p m and 1 30 a m respectively which is a constraint of using a sine function to represent oxygen equivalents rates would more realistically pattern photoperiod with near constant dark or basal respiration at night and proportional oxygen production from daytime photosynthetically active radiation this is consistent with stansbury et al 2008 who indicate photosynthetic rates greatly exceed respiration note the rates in the figure must be multiplied by graded macrophyte dry mass in each reach to obtain actual oxygen units for mass balance accounting the result in fig 7 is confirmed by independent analysis using the delta method chapra and di toro 1991 in the most productive section of the river at i 15 computed primary production was 55 1 27 8 mgo2 gd d or within one standard deviation of that shown in fig 7 assuming a macrophyte density of 303 gd m2 and mean depth of 0 24 m 3 1 5 sediment oxygen demand sod sod rates at 20 c were calculated to be 0 62 go2 m2 d for the sample taken at whiskey gulch sonde station and 0 31 go2 m2 d for the sample taken at i 15 site both measurements are indicative of low sod and less enriched sediments an average sod value of 0 48 go2 m2 d was used for the model in all reaches values are within the literature range for example sod measurements n 22 at three sites in klamath river oregon ranged from 0 3 to 2 9 go2 m2 d doyle and lynch 2005 bowie et al 1985 indicate even a wider range 0 05 to 10 go2 m2 d 3 1 6 reaeration reaeration estimates ranged from 8 62 to 39 57 d n 16 with a mean and standard deviation of 17 28 7 42 d the average reaeration rate was directly applied in the model with minor enhancement from weir flow over several beaver dams in the reach 3 2 dissolved oxygen modeling dissolved oxygen modeling in qual2k suggests macrophytes have a significant effect on do diurnal variation in sbc preliminary model runs without macrophyte oxygen equivalents suggest that while the model predicts the daily average values reasonably well diurnal variation of do is substantially underestimated fig 8 a however once oxygen equivalents for macrophytes have been added to the simulation the model shows reasonable agreement with longitudinal and diurnal variation in do as evidenced by the calibration to field data fig 8b the model confirmation shows comparable results although in this instance a substantial increase in the concentration of do in the study reach occurs presumably as a result of the wwtp upgrade while no appreciable change in do delta is noted oxygen predictions for both calibration and confirmation demonstrate the importance of macrophytes on do dynamics of macrophyte dominated streams a statistical summary of the calibration and confirmation for select constituents is shown in table 5 4 discussion as evidenced in this study rooted macrophytes or submerged aquatic vegetation can play a significant role in aquatic ecosystems beyond their direct effect on do dynamics they also provide food and cover for a wide range of species dennison et al 1993 contribute to biogeochemical cycling of autochthonous resource pools and improve water quality by filtering nutrients and polluted runoff carpenter and lodge 1986 janauer and dokulil 2006 however as observed in this study excessive macrophyte growth can become problematic and cause hypoxic do conditions reductions in biodiversity declines in ecosystem health or replacement of desired species duarte 1995 torn and martin 2012 in sbc do was the primary response indicator evaluated poorly oxygenated conditions prevailed throughout much of the reach prior to the upgrade of the wwtp due in part to both macrophyte respiration and the oxygen sag from ammonia nitrification the latter significantly impacted stream hypoxia and appears to be mitigated post wwtp upgrade while macrophytes still appear to be influencing the stream via large do delta several items are worth highlighting in review of our results 4 1 effects of macrophytes on do as noted from our modeling macrophytes greatly influence gross primary production in shallow wastewater influenced streams we were able to numerically quantify these diurnal do fluctuations using light dark bottle experiments and macrophyte density characterization while macrophyte net production and respiration rate depend on the type of macrophyte solar radiation cloud cover and vegetation cover our reported values compare reasonably with the literature for example mcgahee and davis 1971 measured net production from 77 76 to 152 64 mgo2 gd d for estuarine macrophytes while respiration rates ranged from 48 96 to 63 36 mgo2 gd d within a salinity in the range of 0 to 16 5 0 00 van et al 1976 measured light saturated photosynthetic rates of 38 to 92 mgo2 gd d over natural ph ranges assuming 100gd gchla macrophyte net production and respiration for these and other studies are compared in table 6 rates from the literature are sometimes reported using other kinetic approaches that cannot be directly compared with table 6 for example uchrin et al 2005 report macrophyte respiration rates in the range of 5 28 to 13 mgo2 l d for duhernal lake and mountain lake new jersey usa gross photosynthesis rates were in the range of 30 to 44 7 mgo2 l d in that case data were not available to normalize the rates to macrophyte biomass in developing a macrophyte sub model for eau galle reservoir wi usa first order coefficients of 0 42 and 0 05 d were used for the maximum gross production and respiration rates of macrophytes collins and wlosinski 1989 while in the klamath river ce qual w2 model maximum growth and respiration rates in the range of 0 28 to 0 31 and 0 07 to 0 09 d were used sullivan et al 2013 it should also be recognized that as macrophytes density increases the associated diurnal variation of do increases macrophyte density depends on stream velocity nutrients light and substrate mebane et al 2013 all of which add complexity to understanding macrophyte effects on streams for the sbc study reach the macrophyte density is not spatially constant and changes significantly over the study reach figs 1 and 6 any approach towards estimating oxygen equivalency produced by macrophytes or their spatial variation in biomass must address such factors the use of innovative methods like unmanned aerial vehicles flynn et al 2015 may be one such approach 4 2 retrospective evaluation of wwtp upgrades macrophyte effects and long term projections the wwtp plant upgrades documented in this work have resulted in notable improvement in downstream do concentrations due to reductions in the concentration of ammonium available for nitrification however existing macrophyte biomasses are still substantial and continue to influence stream do dynamics fig 8 to evaluate the effect of the improvements relative to desired water quality endpoints the following must be weighed in assessing the effectiveness of the proposed or implemented management actions first the use classification for sbc is currently class i mt deq 2016 which is reserved for impacted waters the goal of i class is to ultimately transition to a b 1 class so that drinking culinary and food processing purposes after conventional treatment bathing swimming and recreation growth and propagation of fishes and associated aquatic life waterfowl and furbearers and agricultural and industrial water supply uses are all supported mt deq 2016 the freshwater do standard for class i waters is 5 mg l during the late summer period when cutthroat rainbow and golden trout salmonid eggs are incubating or sac fry are in the gravels i e early life stage fwp 2018 https deq mt gov portals 112 water wqinfo documents spawningtimesfwp pdf the do criterion is a one day minimum instantaneous do concentration mt deq 2017 and the corresponding do standard for b 1 classification is 8 mg l mt deq 2017 under this context from figs 5 and 8 it can be seen that while substantial improvements to sbc have occurred including do minima increasing from suboxic conditions 2 mg l in 2015 to nearly achieving the class i instantaneous do criterion minima of 5 mg l during the post wwtp upgrade in 2016 significant strides must still be made to increase do so that water column concentrations will achieve 8 mgo2 l i e b 1 use class as noted later this will likely not be easily done since there are few known upstream impacts that can be controlled other indicators including fish macroinvertebrates and perhaps even bacteria should be examined to make a full evaluation of the current waterbody condition second the visual observations of sbc reach macrophyte density made during 2015 2016 and 2017 indicate that the wwtp upgrade did not appreciably reduce the macrophyte density in the two years following the upgrade while total nutrients and ammonia concentrations declined appreciably shift in nutrient speciation and reduction in inorganic n from 9 98 mg l to 2 10 mg l 79 concentrations are well above levels thought to saturate periphyton watson and berlind 1990 rier and stevenson 2006 chapra et al 2014 presumably aqueous nutrients also have a stimulatory impact on macrophytes submerged macrophytes assimilate mineral nutrients through both foliage and roots madsen and cedergreen 2002 under most circumstances root uptake is the primary pathway for nitrogen and phosphorus accumulation whereas foliage uptake is the primary pathway for calcium magnesium sodium potassium and sulfate madsen and cedergreen 2002 in this regard the relative importance of water column uptake and associated water quality improvements may be minimal if n and p are harvested primarily from sediments however even without roots certain macrophytes can take up the required nutritional needs from the water column nutrient uptake has been found to increase with increasing concentration of nutrient availability feijoo et al 2002 and the difference in growth rate of macrophyte shoots with and without roots has been found insignificant madsen and cedergreen 2002 future work should be conducted with the macrophytes in sbc to understand what proportion of nutrient uptake can be expected to occur from the water column relative to that of the sediments it should also be recognized that macrophytes exhibit different rates of nutrient uptake nitrate uptake is based on light intensity almost stopping uptake when it is dark while ammonia uptake is a pseudo linear rate based on the concentration of the water around the macrophytes nelson et al 1981 finally years of nutrient rich organic wwtp effluent may have artificially enriched the sediment of the streambed gücker et al 2006 because of this it is speculated that the macrophyte density will not decrease significantly over the next decade without additional restoration albeit it certainly would be worth waiting for scouring flows in sbc since macrophytes are vulnerable to such events mebane et al 2013 furthermore is should be recognized that even if macrophytes are fully removed from the system model predictions indicate sbc would still scarcely meet the b 1 classification do standard fig 8 do saturation is approximately 8 mg l and any diurnal variation would reduce the one day minimum to 8 mg l perhaps reducing stream temperature if possible could potentially increase system do 4 3 model improvements for macrophytes and limitations of the stated approach surface water quality models like the one used in this study have been historically helpful in water quality management as they link nutrient loading to attendant eutrophication responses bierman et al 2013 flynn et al 2015 consequently model based approaches are an important part of environmental decision support thomann 1998 ambrose et al 2009 chapra 2011 and provide a means to simulate stream do responses before a costly management action like a wwtp upgrade is undertaken the use of modeling therefore should be widely encouraged and herein we have incorporated a modeling approach that uses oxygen equivalents in qual2k using closely spaced point sources with diurnal variation the methodology worked reasonably for a small eutrophied urban headwater stream in montana however limitations of sine curve to simulate macrophyte dissolved oxygen equivalents likely will prevent more widespread use for example the photoperiod during the simulation was 13 81 h and a sinusoid must have an angular frequency of one day additionally at some sites do values remained low throughout the night the proposed methodology does not provide a way to adjust for low oxygen attenuation of respiration as noted in chapra et al 2012 because of these limitations it is recommended that future work be implemented to modify the qual2k model to include macrophytes as a separate state variable so that macrophyte primary production and respiration are simulated explicitly and as a function of available do it is also recommended that light bottle dark bottle experiments or benthic chamber experiments be conducted at various times of the day different light and temperature conditions to better characterize the diurnal variation of macrophyte oxygen equivalents and measurements of reaeration rate dispersion and travel time kilpatrick et al 1989 wilcock et al 1995 are certainly warranted finally the development and rigorous testing of do model outcomes before and after wwtp upgrades should be made a standard practice to establish the level of wwtp upgrade required for corresponding do improvements 5 conclusions this paper has demonstrated a successful application of the mass balance approach towards incorporating the effects of macrophytes on dissolved oxygen do in the model qual2k additionally it documents widespread improvements in stream do following a wastewater treatment plant wwtp upgrade while the calibrated model adequately predicts the macrophyte effect on dissolved oxygen and improvement from the wwtp upgrade oxygen modeling of macrophyte rich streams in qual2k could be improved by incorporating macrophyte primary production and respiration mechanisms deterministically as done in other models it must also be recognized that despite implementing large scale reductions in wastewater nutrient contributions it may still be difficult to attain desired water quality standards in certain cases we recommend a model based approach be considered as standard practice for evaluating such measures acknowledgements partial support to the primary author r n and data collection was provided by mt nsf epscor pg16 66131 04 grant we thank mike eder matt strozewski and clay thomas for field data collection we also thank dr tae soo chon and two anonymous reviewers who provided valuable feedback and suggestions for this work appendix a supplementary data supplementary material related to this article can be found in the online version at doi https doi org 10 1016 j ecolmodel 2018 12 009 appendix a supplementary data the following is supplementary data to this article 
25130,a dissolved oxygen do mass balance was developed for a 5 9 km reach of the heavily eutrophied and macrophyte rich wastewater effluent dominated silver bow creek mt usa to assess water quality changes following an upgrade to the municipal wastewater facility surveys of diurnal do were completed in 2015 and 2016 and various mass transfer rates were quantified including macrophyte photosynthesis and respiration macrophyte density sediment oxygen demand and reaeration a do mass balance model was then developed in qual2k where oxygen equivalents of macrophytes were incorporated as closely spaced diurnally varying point sources sinusoids overall diurnal do swings and longitudinal oxygen profiles were reasonably replicated in the pre and post upgrade synoptic surveys and models and the facility upgrade greatly enhanced do concentrations in the stream improvements however were not enough to meet the minimum do criterion for the waterbody the results above have important implications for assessing do responses and impairment status in macrophyte rich streams moreover they suggest wastewater treatment upgrades may not always achieve desired results and that modeling should be conducted a priori to understand receiving water responses keywords dissolved oxygen model macrophytes wastewater silver bow creek qual2k 1 introduction effluent dominated streams have undergone limited literature study brooks et al 2006 gücker et al 2006 nonetheless offer a unique laboratory for which to observe pollution related environmental responses while numerous aquatic concerns can be linked to wastewater effluent including increases in temperature or turbidity do deficit or ph or the addition of toxic substances mackenthun 1969 daniel et al 2002 aristi et al 2015 the do concentration in the receiving water is a fundamental water quality indicator of the health and well being of a waterbody hynes 1960 dodds 2002 given its overall importance to fish and aquatic life gaining an understanding of the sources and sinks of do relative to deficit generated from human activity along with simulating instream responses from management actions such as wastewater treatment upgrades is a worthwhile endeavor impacts of wastewater treatment plants wwtps on the do balance of a receiving water are widely noted haggard et al 2001 2005 marti et al 2004 gücker et al 2006 aristi et al 2015 in both raw and treated wastewater nitrogenous or carbonaceous forms of biochemical oxygen demand bod cause deoxygenation when the rate of do consumption from ammonium nh4 oxidation or degradation of labile and refractory forms of carbon exceeds reaeration an oxygen sag occurs the most widely publicized of these is documented in the seminal work of streeter and phelps 1925 on the ohio river based on an elegant analytical model relating the physics chemistry and biology to saturation deficit downstream of a point source the do sag minimum can be computed which occurs at the location where the rate of bod decomposition and reaeration are equivalent chapra 2008 oxygen deficits can also be associated with secondary enrichment effects or eutrophication smith et al 1999 usepa 2016 excess nutrient concentrations increase the productivity of receiving waters and result in variety of undesirable water quality changes including excessive aquatic plant or algal growth diminished aquatic communities or development of hypoxia or oxygen dead zones hynes 1969 dodds and welch 2000 loss of recreational amenities reduced property values and increased drinking water treatment costs also occur dodds et al 2009 in certain instances expansive growths may reach nuisance levels and impair recreation fish and aquatic life and water quality uses gammons et al 2011 he et al 2011 in this regard both primary and secondary effects of wastewater can be far reaching moreover despite advances in treatment technologies nutrient loadings from wwtps continue to be widespread and pervasive carey and migliaccio 2009 impacts on stream ecology can persist for tens of kilometers haggard et al 2005 affecting benthic flora bacteria and biota mackenthun 1969 drury et al 2013 many investigators note that effluent impacted or effluent dominated waterbodies are prone to luxuriant macrophyte growth cole 1973 madsen and adams 1988 1989 chambers and prepas 1994 gücker et al 2006 taube et al 2016 excessive growth of aquatic plants or nuisance macrophyte biomasses cause large diurnal swings in aqueous gases like do and carbon dioxide co2 chambers and prepas 1994 macrophyte photosynthesis during the daytime elevates do beyond what can be expelled through reaeration super saturation while at night macrophyte beds consume oxygen through respiration causing hypoxic conditions alkalinity and ph likewise are affected during daytime photosynthesis co2 is consumed raising the ph of the stream at night macrophytes respire driving the bicarbonate system back towards the reactants finally carbon that is temporarily sequestered as macrophyte growth can become a temporal oxygen sink as macrophytes senesce and decompose at the end of the growing season in this regard quantifying and simulating macrophyte influences on stream do is an active area of research in the 1970s a number of efforts were made to develop models that simulate macrophytes in lakes e g clean cleaner etc park 1974 bowie et al 1985 citing others however efforts on rivers started later park et al 2003 developed macriv a mechanistic computer model to incorporate macrophytes as oxygen equivalents varying oxygen production diurnally park et al 2008 developed aquatox macrophyte routines based on previous work on lakes robinson et al 2009 modified the water quality analysis and simulation program wasp usepa 2018 to incorporate periphyton and macrophytes and simulate do concentrations in the bow river alberta canada ce qual w2 cole and wells 2017 was recently modified to include macrophytes for application to the columbia slough in oregon berger and wells 2008 the klamath river upstream of keno dam in oregon sullivan et al 2013 and lake ogallala nebraska stansbury et al 2008 qual2kw also has basic functionality for simulating macrophytes using the benthic algae submodel pelletier and chapra 2008 finally data driven models as opposed to process based models have also been used to model do in a number of instances he et al 2011 khan and valeo 2015 and 2017 these models use abiotic factors commonly water temperature nutrient concentration flow rate and solar radiation to predict do concentrations using artificial neural networks khan and valeo 2017 in this paper we investigate the do mass balance on a small urbanized stream where municipal wastewater is a large component of the available streamflow specifically we document dissolved oxygen changes both before and after a tertiary wwtp upgrade conduct modeling to simulate macrophyte effects using oxygen equivalents in the mechanistic model qual2k and address field methods to quantify the oxygen mass balance and oxygen cycling in streams results have important implications for modeling do in macrophyte rich effluent dominated streams as well as for evaluating the potential outcomes of water quality improvements from wwtp upgrades 2 materials and methods 2 1 study area silver bow creek sbc is a small urbanized stream in western montana fig 1 that flows westerly through butte mt to form the headwaters to the clark fork of the columbia river it is identified on the 2016 state of montana 303 d list as impaired for nitrate total nitrogen and total phosphorus and is currently not supporting aquatic life and primary contact recreation uses montana deq 2016 notably sbc is effluent dominated with the butte municipal metro wastewater treatment plant wwtp contributing 0 16 m3 s of the annual discharge to the stream mean annual streamflow immediately downstream of the wwtp at usgs 12323250 silver bow creek below blacktail creek at butte mt is 0 6 m3 s peak flow is 2 m3 s and annual 7 day low flow 0 4 m3 s fig 2 in this regard the low flow contribution of the wwtp is approximately 40 the climate of the study area is cold and arid wrs 1955 with a mean annual temperature of 4 5 c and valley precipitation averaging 322 mm annually wrcc western regional climate center 2017 a majority of the surface water in sbc comes from snowmelt runoff in blacktail creek during the spring and early summer months outside of this tributary inflow the remaining headwaters of upper silver bow creek are cutoff by an active mining operation berkley pit therefore contributing minimally to streamflow the occurrence of monthly mean low flow is in december although the months of july through december all have similar critical low flow conditions mccarthy 2016 eutrophication downstream of the butte metro wwtp is well documented gammons et al 2011 before the wwtp upgrades discussed in this work anaerobic conditions historically existed downstream of the plant from nbod and large masses of aquatic plants macrophytes have been observed between butte and rocker mt such conditions are accompanied by a notable amount of diurnal water quality changes gammons et al 2011 while few long term nutrient monitoring campaigns have been performed in the area recent data published by usgs indicates nitrate concentrations are high at the usgs gage immediately downstream of the wwtp fig 3 nitrate plus nitrate exhibits an inverse relationship with discharge due to upstream dilution noting the highest concentrations are observed during the winter months presumably from cold temperatures and reduced biological activity like many effluent dominated streams sbc is dominated by several macrophyte species primarily sago pondweed potamogeton pectinatus and also white buttercup ranunculus aquatilis common duckweed lumna minor and common water moss fontinalis antipyretica mitman 2015 the macrophytes partially die off and senesce each winter due to cold temperatures poor light conditions and ice cover but grow back each year over the course of summer in the late summer macrophytes form a thick mat across the stream bottom that in most places occupies the entire volume of the wetted channel between the summers of 2015 and 2016 the butte metro wwtp underwent a significant plant upgrade moving from a secondary to a tertiary treatment process to reduce ammonia and overall nutrient contributions to silver bow creek the original treatment works consisted of an activated sludge secondary treatment system with ultraviolet uv disinfection while the new plant consists of several advanced membrane bioreactors and a nitrification step the above change provides an ideal set of conditions to evaluate pre and post wwtp upgrades on stream do and water quality 2 2 data collection synoptic surveys were conducted during the summers of 2015 and 2016 over a 6 km stretch downstream of butte mt to understand the do mass balance below the municipal wwtp and to support water quality model development the study extent begins at whiskey gulch located downstream of the i 90 overpass just downstream of butte mt and ends just upstream of the i 15 south exchange fig 1a the upstream location whiskey gulch was placed far enough downstream of the wwtp so complete mixing of the effluent discharge and sbc occurred complete mixing was verified by measurements of conductivity across the channel at the headwater of the study reach water quality data were subsequently collected at four locations in the study reach 1 whiskey gulch 5 83 km upstream of the terminus of the reach beaver pond 4 76 km rocker 3 01 km and near i 15 south 0 km similar to the approach described by hobson et al 2014 macrophyte biomasses were characterized over a slightly larger extent 6 km as described later 2 2 1 datasondes and water quality sampling the following diurnal field water quality parameters were measured at each of the four monitoring locations mentioned previously with ysi exo 2 and hydrolab sondes do temperature ph and specific conductance sc sondes were securely set in the main flow path of the stream inside of pvc housings vertically to prevent movement or damage with holes drilled to allow sufficient water flow through over time the housings would collect large masses of sticks branches and loose macrophytes that were flowing downstream when collecting data for the do mass balance model debris was removed several times during the day to prevent fouling the sondes were calibrated according to their respective manuals one day prior to sampling during the sampling event an additional sonde was used to perform side by side checks of recorded values grab samples were collected concurrently at all four locations sample bottles were cleaned with 10 hydrochloric acid before use and bottles were rinsed three times with stream water before sampling collecting from the upstream side and discharging in the downstream direction samples were obtained from the center flow of the stream at about two thirds of the depth of the water column they were taken immediately downstream of the recording sondes to ensure consistency samples were analyzed using the methods outlined in table 1 for the following constituents orthophosphate soluble reactive phosphorus srp nitrate plus nitrite ammonia total phosphorus tp total kjeldahl nitrogen tkn alkalinity inorganic suspended solids and detritus 2 2 2 reach macrophyte density estimates a subsampling procedure was used to estimate macrophyte biomass within different reaches of the study area in 2015 mass of macrophytes per unit stream length 0 3048 m in the sbc reach were visually graded on a 0 to 10 scale for biomass the overall reach was then subdivided into smaller reaches of 50 m and each sub reach was assigned a grade on a 0 to 10 scale corresponding to macrophyte density fig 1b for select grades dry mass of macrophytes were collected from the entire width of the channel transect over a longitudinal length of 0 3048 m this was achieved by marking the plan view area with two measuring tapes and then only extracting macrophytes that fell within the demarcated areal region wet weight of the extracted macrophytes was measured in the field using a rapala digital scale and a subsample was collected to measure the dry mass in the lab laboratory samples were air dried for seven days and then oven dried at 105 c for eight hours and weighed for dry mass using a mettler toldeo ae 240 analytical balance usgs 2015 using the sample dry mass the dry mass of macrophyte in the sampling volume was calculated using a wet mass to dry mass conversion which was then normalized to areal density e g gd m2 see supplemental table s1 for the macrophyte density grades where mass of macrophytes were not measured 4 of the 10 categories values were linearly interpolated between measured grades example grades are shown in fig 4 grading densities are discussed more in the results based on visual inspection it was observed that macrophyte densities were similar during the summers of 2015 and 2016 2 2 3 light dark bottle experiments light dark bottle experiments were initiated in july august and october 2016 to measure macrophyte photosynthesis and respiration rates at different temperatures thomann and mueller 1987 this was done by collecting a small amount of live macrophyte material and placing it in both a light and dark bottle and incubating it near optimal irradiance a third bottle was also incubated in the light only with site water as a control however results were such that no water column corrections were necessary the experiments were conducted several times during the afternoon hours ranging from 12 15 p m to 2 20 p m with an ending times ranging from 3 00 p m to 6 38 p m solar irradiance during this period was 1210 w m2 at 3 00 p m to 1260 w m2 at 6 38 p m measured with a handheld dbtu1300solar meter macrophytes were air dried for seven days and then oven dried at 105 c for an additional 8 h and weighed for dry mass usgs 2015 bottle rates were normalized to the dry mass of macrophytes in the glass bottle mgo2 gd d 2 2 4 oxygen produced by macrophytes during photosynthesis and respiration macrophyte photosynthetic and respiratory rates were combined with the spatial distribution of macrophytes from the reach density estimates to determine their influence on the oxygen mass balance oxygen load in mgo2 d from net macrophyte production was approximated by multiplying the graded mass of macrophytes gd m2 in each longitudinal stream reach by its respective areal extent m2 and oxygen production rate mgo2 gd d reach areas were digitized in arcgis at 1 000 scale using an arcgis basemap similarly the macrophyte respiration rate and oxygen deficit were handled in the same way source sink loadings were distributed diurnally using a sine function as outlined in chapra 2008 discussed later 2 2 5 sediment oxygen demand sediment oxygen demand sod was measured by incubating sediment cores using the procedures outlined by thomann and mueller 1987 while ideally a core sample several inches deep would be used the poorly consolidated substrate of sbc prevented the corer from collecting an intact sample instead a sample tube was filled with 6 to 8 in of sediment and covered with stream water to fill the remaining space an identical sample tube was filled with stream water to be used as a blank to determine the water column oxygen demand cores were stored on ice during transport to an incubator in the lab set to 14 c the average temperature of the water during monitoring period initial and final dissolved oxygen values were recorded for the blank tube while the core was monitored continuously over a 24 hour period the change in dissolved oxygen in the blank tube was subtracted from the change in the core tube to account for the water column oxygen demand bottom areal sod coverage of 40 was used for the study 2 2 6 reaeration reaeration rate was calculated using the delta method chapra and di toro 1991 mcbride and chapra 2005 delta method empirically relates the time of peak dissolved oxygen or deficit minimum as a function of lag from solar noon to the reaeration rate within the study reach the method produced unreliable results because of the low dissolved oxygen content and variable flows from the wwtp accordingly the reaeration rate was also calculated using a time series of sonde data further upstream in blacktail creek above the wwtp discharge this site is located less than a mile upstream of the headwater site at whiskey gulch and contains most of the flow that makes up silver bow creek it has similar substrate depth and velocity to the study reach making it a suitable surrogate to estimate the reaeration rate of silver bow creek 2 3 dissolved oxygen modeling the model qual2k chapra et al 2012 was used for oxygen accounting in the reach key processes that were simulated in the model included nitrification sediment oxygen demand macrophyte photosynthesis and respiration and reaeration qual2k is a widely used one dimensional advection dispersion river model and part of the u s environmental protection agency s water quality modeling toolbox usepa 2015 state variables are simulated on a longitudinal basis with diel water quality kinetics that enable the user to study the daily fluctuation of do over a 24 hr cycle numerical computations are programmed in fortran 90 and are implemented from the microsoft excel visual basic for applications vba environment an explicit forward time backward space scheme corrected for numerical dispersion is used to determine the concentration in each model element at each time step 2 3 1 model setup and parameterization synoptic data were collected on aug 22 2015 and july 19 2016 at critical low flow 0 391 m3 s and 0 481 m3 s and warm summer temperatures 14 8 c for model development when do is at critical conditions the modeling domain was divided into five reaches based on physical features including changes in elevation gradient macrophyte coverage flow depth and beaver dams the reach was 5 83 km long reach lengths latitude and longitude information were obtained from aerial photography whereas longitudinal elevation data were surveyed using a leica viva gnss gs 15 three small beaver dams were modeled as broad crested weirs using the measured height and width of the beaver dams the weir coefficients adam and bdam from the butts and evans 1983 formula were adopted from mccullough et al 2007 using the usgs gage station 12323250 measurements usgs available online at https waterdata usgs gov mt nwis uv site no 12323250 depth and velocity rating curves were developed for study reaches that do not contain beaver dams supplemental fig s1 qual2k requires 24 hour headwater forcing functions to account for the temporal changes in the daily cycles of inputs these are believed to be important in a stream with large diurnal cycling like sbc where the upstream headwater is heavily influenced by the metro wwtp as mentioned previously diurnal field water quality parameters were measured at this location using two ysi exo 2 and two hydrolab sondes however grab samples were also collected concurrently at 10 a m 2 p m 6 p m and 10 p m on those dates samples were analyzed as outlined previously in table 1 weather data air temperature dew point temperature wind speed and cloud cover were retrieved from bert mooney airport butte mt weather station national weather service available online at http w1 weather gov obhistory kbtm html which is approximately 8 km from the upstream whiskey gulch site flow data was obtained from usgs gage station 12323250 usgs available online at https waterdata usgs gov mt nwis uv site no 12323250 fig 1 and flow depth was also measured at six locations in the project site carbonaceous bod cbod values for wwtp effluent and upstream of the wwtp confluence were obtained from butte wwtp and were estimated using a standard mass balance equation the shade xlsx program department of ecology 2016 a tool for estimating shade from riparian vegetation written in excel vba was used to estimate the fraction of potential solar radiation blocked by topography and vegetation over the study reach it was assumed that the vegetation was medium to sparse along the length of the reach 2 3 2 macrophytes in qual2k the mass balance for do oi in a qual2k element having steady flow is chapra et al 2012 1 v i d o i d t q i 1 o i 1 q i o i e i 1 o i 1 o i e i o i 1 o i w i s i where q flow m3 s o do concentration go2 m3 v element volume m3 e bulk dispersion coefficient m3 s w external load go2 s and s sources and sinks or sinks go2 s subscripts i i 1 and i 1 represent the current upstream and downstream elements respectively qualk does not simulate dissolved oxygen from macrophyte photosynthesis or respiration explicitly please refer to the discussion about this limitation as well as the rationale behind the proposed approach it does however allow the input of oxygen point sources and also accommodates oxygen lost via fast cbod oxidation nitrification and plant respiration additionally depending on whether the water is undersaturated or oversaturated oxygen is gained or lost via reaeration we used external forcing functions to simulate the influence of macrophytes on the oxygen mass balance the macrophyte source sink of oxygen is approximated using a sinusoid chapra 2008 2 s t q m o m a c r o p h y t e s o a sin ω t θ where qm negligible flow rate added as point source m3 s omacrophytes mean oxygen concentration equivalency of macrophytes go2 m3 oa oxygen concentration amplitude go2 m3 range 2 ω angular frequency radians t assumed to be 2π t t time d and θ phase shift radians respectively oxygen equivalent inputs for the sinusoid require the mean range 2 and time of max be specified around solar noon around 1 30 pm the oxygen load is added as a point source with a very small flow rate of 0 01 l sec such that do concentration in the point source is equals the oxygen equivalents measured in the light dark bottle experiments with the caveat that calibration potentially may be required the uptake rate of ammonia and influence of nitrification on oxygen was lumped into a combined nitrification rate calibrated to longitudinal ammonia data a first order rate equation was used to fit both our data and that previously collected by gammons et al 2011 2 3 3 model calibration and confirmation the model was manually calibrated using the intensive water quality data collected on august 22 2015 and confirmed using the synoptic survey from july 19 2016 calibration was constrained by adjusting only macrophyte do sinusoid point source oxygen equivalents with the objective of minimizing the difference between measured and modeled do values other variables that influenced do were either measured or estimated from the literature review and engineering judgement rates used in parameterization of the model are shown in table 2 the same parameters that were determined during the calibration were used in model confirmation to identify whether the model can predict do values for a different data set thomann 1982 reckhow and chapra 1983 arnold et al 2012 only the headwater boundary condition and meteorological data were changed for the confirmation to reflect the july 19 2016 survey with the remaining rates and macrophyte do equivalents unchanged 3 results 3 1 field and laboratory measurements 3 1 1 datasondes and water quality during the critical low flow conditions approximately 0 32 m3 s the average depth and velocity in the study reach were 0 24 m and 0 26 m s respectively diurnal do and ph data from the sondes at the four monitoring sites are shown in fig 5 significant diel swing is noted which increases from upstream to downstream and corresponds to increasing macrophyte density on august 22 2015 model calibration pre wwtp upgrade at the upstream site whiskey gulch the minimum and maximum do were 3 79 mgo2 l and 7 68 mgo2 l respectively resulting in diel variation or delta of 3 89 mgo2 l at the downstream site i 15 the minimum do value was 1 46 mgo2 l with a maximum of 14 97 mgo2 l resulting in a diurnal variation in do of 13 5 mgo2 l hypoxic conditions do 2 mg l occurred for over half the day 12 5 h at this location hence the impact from the wwtp occurs some distance longitudinally from the point of discharge notably nighttime do minima are well below the state water quality standard of 5 mgo2 l mt deq 2017 on july 19 2016 model confirmation post wwtp upgrade the minimum and maximum do values were 3 93 mgo2 l and 15 43 mg l at the downstream i 15 site respectively with a diurnal variation of 11 50 mgo2 l the wwtp upgrade significantly reduced ammonia concentrations and certainly improved the minimum do concentration and sag a similar longitudinal effect occurs with ph daytime observations at downstream sites exceed 9 0 s u with diurnal cycling on the order of 1 5 to 2 0 s u data from 2016 showed even larger diurnal variability far outside the standard required in deq 7 mt deq 2017 the latter is likely due to changes in alkalinity on august 22 2015 the alkalinity decreased over the study reach from 133 70 mg of caco3 l at the upstream boundary to 115 85 mg of caco3 l at the downstream boundary on july 19 2016 alkalinity did not change significantly over the study reach but was much lower than 2015 range of 103 6 to 108 caco3 l while we did not measure the alkalinity of the wwtp effluent in this study it is often lower than that of the receiving water unpublished data and thus the volumetric ratio of effluent to the receiving water flow is an important consideration nutrient data from the summer of 2015 and 2016 confirm that upper sbc is highly eutrophied concentrations of nh3 n and no3 no2 n were 7 95 and 2 03 mg n l respectively in 2016 they were 0 05 and 2 05 mg n l both years the inorganic phosphorus po4 3 p concentrations at the upstream and downstream sites remained unchanged 1 24 mg p l and 1 17 mg p l in 2015 and 1 27 mg p l and 1 14 mg p l in 2016 the decline in nitrogen over the reach is presumably due to macrophyte uptake notably the ratio of soluble n p is near the redfield ratio in 2015 8 1 and shifted to 2 1 in 2016 this suggests that although nutrients are still saturated in this reach see concentrations reported above at some point inorganic nitrogen will eventually become limiting downstream although the particular location is outside of our study reach presumably the influence of the wwtp upgrade is already apparent there 3 1 2 macrophyte density estimates elevated nutrient concentrations and rich organic substrates provide favorable conditions for macrophyte growth in sbc macrophyte grades and corresponding field densities measured in 2016 are listed in table 3 biomasses at the uppermost site upstream of whiskey gulch are the lowest grade and are equivalent to 43 mgd m2 densities at the terminus of the study reach near i 15 were the highest grade and equivalent to 303 mgd m2 see fig 4 for visual correspondence as a reference robinson et al 2009 measured a macrophyte dry mass density of 241 29 gd m2 for bow river alberta canada in sbc wet mass to dry mass ratios ranged from 7 9 to 14 2 supplemental table s1 and as seen in the table 3 we had difficulty visually partitioning mid level grades of macrophyte density using results above i e diurnal do measurements and macrophyte biomass approximations it is noted that both do delta i e do maximum minus do minimum and macrophyte density increase from upstream to downstream substantially fig 6 the increase in do delta is believed to be directly attributable to increases in macrophyte density although it is unclear why there is a delayed response in primary productivity and biomass directly below the metro wwtp discharge point of discharge is at roughly 7 0 km the high do deltas in this reach far exceed typical recommendations of less than 4 to 6 mgo2 l suplee and sada de suplee 2011 heiskary et al 2013 suggested for healthy streams 3 1 3 light dark bottle experiments results from the light dark bottle experiments are shown in table 4 net primary production and respiration were comparable during two of the experiments however the experiment in august 2016 had nearly double primary productivity relative to that of the other bottle rates the range of rates is discussed later in context of our results see discussion 3 1 4 oxygen produced by macrophytes during photosynthesis and respiration estimates of diurnal oxygen produced by photosynthesis and consumed via respiration as fit to the sinusoid function described in the methods is shown in fig 7 the source and sink terms peak and trough at 1 30 p m and 1 30 a m respectively which is a constraint of using a sine function to represent oxygen equivalents rates would more realistically pattern photoperiod with near constant dark or basal respiration at night and proportional oxygen production from daytime photosynthetically active radiation this is consistent with stansbury et al 2008 who indicate photosynthetic rates greatly exceed respiration note the rates in the figure must be multiplied by graded macrophyte dry mass in each reach to obtain actual oxygen units for mass balance accounting the result in fig 7 is confirmed by independent analysis using the delta method chapra and di toro 1991 in the most productive section of the river at i 15 computed primary production was 55 1 27 8 mgo2 gd d or within one standard deviation of that shown in fig 7 assuming a macrophyte density of 303 gd m2 and mean depth of 0 24 m 3 1 5 sediment oxygen demand sod sod rates at 20 c were calculated to be 0 62 go2 m2 d for the sample taken at whiskey gulch sonde station and 0 31 go2 m2 d for the sample taken at i 15 site both measurements are indicative of low sod and less enriched sediments an average sod value of 0 48 go2 m2 d was used for the model in all reaches values are within the literature range for example sod measurements n 22 at three sites in klamath river oregon ranged from 0 3 to 2 9 go2 m2 d doyle and lynch 2005 bowie et al 1985 indicate even a wider range 0 05 to 10 go2 m2 d 3 1 6 reaeration reaeration estimates ranged from 8 62 to 39 57 d n 16 with a mean and standard deviation of 17 28 7 42 d the average reaeration rate was directly applied in the model with minor enhancement from weir flow over several beaver dams in the reach 3 2 dissolved oxygen modeling dissolved oxygen modeling in qual2k suggests macrophytes have a significant effect on do diurnal variation in sbc preliminary model runs without macrophyte oxygen equivalents suggest that while the model predicts the daily average values reasonably well diurnal variation of do is substantially underestimated fig 8 a however once oxygen equivalents for macrophytes have been added to the simulation the model shows reasonable agreement with longitudinal and diurnal variation in do as evidenced by the calibration to field data fig 8b the model confirmation shows comparable results although in this instance a substantial increase in the concentration of do in the study reach occurs presumably as a result of the wwtp upgrade while no appreciable change in do delta is noted oxygen predictions for both calibration and confirmation demonstrate the importance of macrophytes on do dynamics of macrophyte dominated streams a statistical summary of the calibration and confirmation for select constituents is shown in table 5 4 discussion as evidenced in this study rooted macrophytes or submerged aquatic vegetation can play a significant role in aquatic ecosystems beyond their direct effect on do dynamics they also provide food and cover for a wide range of species dennison et al 1993 contribute to biogeochemical cycling of autochthonous resource pools and improve water quality by filtering nutrients and polluted runoff carpenter and lodge 1986 janauer and dokulil 2006 however as observed in this study excessive macrophyte growth can become problematic and cause hypoxic do conditions reductions in biodiversity declines in ecosystem health or replacement of desired species duarte 1995 torn and martin 2012 in sbc do was the primary response indicator evaluated poorly oxygenated conditions prevailed throughout much of the reach prior to the upgrade of the wwtp due in part to both macrophyte respiration and the oxygen sag from ammonia nitrification the latter significantly impacted stream hypoxia and appears to be mitigated post wwtp upgrade while macrophytes still appear to be influencing the stream via large do delta several items are worth highlighting in review of our results 4 1 effects of macrophytes on do as noted from our modeling macrophytes greatly influence gross primary production in shallow wastewater influenced streams we were able to numerically quantify these diurnal do fluctuations using light dark bottle experiments and macrophyte density characterization while macrophyte net production and respiration rate depend on the type of macrophyte solar radiation cloud cover and vegetation cover our reported values compare reasonably with the literature for example mcgahee and davis 1971 measured net production from 77 76 to 152 64 mgo2 gd d for estuarine macrophytes while respiration rates ranged from 48 96 to 63 36 mgo2 gd d within a salinity in the range of 0 to 16 5 0 00 van et al 1976 measured light saturated photosynthetic rates of 38 to 92 mgo2 gd d over natural ph ranges assuming 100gd gchla macrophyte net production and respiration for these and other studies are compared in table 6 rates from the literature are sometimes reported using other kinetic approaches that cannot be directly compared with table 6 for example uchrin et al 2005 report macrophyte respiration rates in the range of 5 28 to 13 mgo2 l d for duhernal lake and mountain lake new jersey usa gross photosynthesis rates were in the range of 30 to 44 7 mgo2 l d in that case data were not available to normalize the rates to macrophyte biomass in developing a macrophyte sub model for eau galle reservoir wi usa first order coefficients of 0 42 and 0 05 d were used for the maximum gross production and respiration rates of macrophytes collins and wlosinski 1989 while in the klamath river ce qual w2 model maximum growth and respiration rates in the range of 0 28 to 0 31 and 0 07 to 0 09 d were used sullivan et al 2013 it should also be recognized that as macrophytes density increases the associated diurnal variation of do increases macrophyte density depends on stream velocity nutrients light and substrate mebane et al 2013 all of which add complexity to understanding macrophyte effects on streams for the sbc study reach the macrophyte density is not spatially constant and changes significantly over the study reach figs 1 and 6 any approach towards estimating oxygen equivalency produced by macrophytes or their spatial variation in biomass must address such factors the use of innovative methods like unmanned aerial vehicles flynn et al 2015 may be one such approach 4 2 retrospective evaluation of wwtp upgrades macrophyte effects and long term projections the wwtp plant upgrades documented in this work have resulted in notable improvement in downstream do concentrations due to reductions in the concentration of ammonium available for nitrification however existing macrophyte biomasses are still substantial and continue to influence stream do dynamics fig 8 to evaluate the effect of the improvements relative to desired water quality endpoints the following must be weighed in assessing the effectiveness of the proposed or implemented management actions first the use classification for sbc is currently class i mt deq 2016 which is reserved for impacted waters the goal of i class is to ultimately transition to a b 1 class so that drinking culinary and food processing purposes after conventional treatment bathing swimming and recreation growth and propagation of fishes and associated aquatic life waterfowl and furbearers and agricultural and industrial water supply uses are all supported mt deq 2016 the freshwater do standard for class i waters is 5 mg l during the late summer period when cutthroat rainbow and golden trout salmonid eggs are incubating or sac fry are in the gravels i e early life stage fwp 2018 https deq mt gov portals 112 water wqinfo documents spawningtimesfwp pdf the do criterion is a one day minimum instantaneous do concentration mt deq 2017 and the corresponding do standard for b 1 classification is 8 mg l mt deq 2017 under this context from figs 5 and 8 it can be seen that while substantial improvements to sbc have occurred including do minima increasing from suboxic conditions 2 mg l in 2015 to nearly achieving the class i instantaneous do criterion minima of 5 mg l during the post wwtp upgrade in 2016 significant strides must still be made to increase do so that water column concentrations will achieve 8 mgo2 l i e b 1 use class as noted later this will likely not be easily done since there are few known upstream impacts that can be controlled other indicators including fish macroinvertebrates and perhaps even bacteria should be examined to make a full evaluation of the current waterbody condition second the visual observations of sbc reach macrophyte density made during 2015 2016 and 2017 indicate that the wwtp upgrade did not appreciably reduce the macrophyte density in the two years following the upgrade while total nutrients and ammonia concentrations declined appreciably shift in nutrient speciation and reduction in inorganic n from 9 98 mg l to 2 10 mg l 79 concentrations are well above levels thought to saturate periphyton watson and berlind 1990 rier and stevenson 2006 chapra et al 2014 presumably aqueous nutrients also have a stimulatory impact on macrophytes submerged macrophytes assimilate mineral nutrients through both foliage and roots madsen and cedergreen 2002 under most circumstances root uptake is the primary pathway for nitrogen and phosphorus accumulation whereas foliage uptake is the primary pathway for calcium magnesium sodium potassium and sulfate madsen and cedergreen 2002 in this regard the relative importance of water column uptake and associated water quality improvements may be minimal if n and p are harvested primarily from sediments however even without roots certain macrophytes can take up the required nutritional needs from the water column nutrient uptake has been found to increase with increasing concentration of nutrient availability feijoo et al 2002 and the difference in growth rate of macrophyte shoots with and without roots has been found insignificant madsen and cedergreen 2002 future work should be conducted with the macrophytes in sbc to understand what proportion of nutrient uptake can be expected to occur from the water column relative to that of the sediments it should also be recognized that macrophytes exhibit different rates of nutrient uptake nitrate uptake is based on light intensity almost stopping uptake when it is dark while ammonia uptake is a pseudo linear rate based on the concentration of the water around the macrophytes nelson et al 1981 finally years of nutrient rich organic wwtp effluent may have artificially enriched the sediment of the streambed gücker et al 2006 because of this it is speculated that the macrophyte density will not decrease significantly over the next decade without additional restoration albeit it certainly would be worth waiting for scouring flows in sbc since macrophytes are vulnerable to such events mebane et al 2013 furthermore is should be recognized that even if macrophytes are fully removed from the system model predictions indicate sbc would still scarcely meet the b 1 classification do standard fig 8 do saturation is approximately 8 mg l and any diurnal variation would reduce the one day minimum to 8 mg l perhaps reducing stream temperature if possible could potentially increase system do 4 3 model improvements for macrophytes and limitations of the stated approach surface water quality models like the one used in this study have been historically helpful in water quality management as they link nutrient loading to attendant eutrophication responses bierman et al 2013 flynn et al 2015 consequently model based approaches are an important part of environmental decision support thomann 1998 ambrose et al 2009 chapra 2011 and provide a means to simulate stream do responses before a costly management action like a wwtp upgrade is undertaken the use of modeling therefore should be widely encouraged and herein we have incorporated a modeling approach that uses oxygen equivalents in qual2k using closely spaced point sources with diurnal variation the methodology worked reasonably for a small eutrophied urban headwater stream in montana however limitations of sine curve to simulate macrophyte dissolved oxygen equivalents likely will prevent more widespread use for example the photoperiod during the simulation was 13 81 h and a sinusoid must have an angular frequency of one day additionally at some sites do values remained low throughout the night the proposed methodology does not provide a way to adjust for low oxygen attenuation of respiration as noted in chapra et al 2012 because of these limitations it is recommended that future work be implemented to modify the qual2k model to include macrophytes as a separate state variable so that macrophyte primary production and respiration are simulated explicitly and as a function of available do it is also recommended that light bottle dark bottle experiments or benthic chamber experiments be conducted at various times of the day different light and temperature conditions to better characterize the diurnal variation of macrophyte oxygen equivalents and measurements of reaeration rate dispersion and travel time kilpatrick et al 1989 wilcock et al 1995 are certainly warranted finally the development and rigorous testing of do model outcomes before and after wwtp upgrades should be made a standard practice to establish the level of wwtp upgrade required for corresponding do improvements 5 conclusions this paper has demonstrated a successful application of the mass balance approach towards incorporating the effects of macrophytes on dissolved oxygen do in the model qual2k additionally it documents widespread improvements in stream do following a wastewater treatment plant wwtp upgrade while the calibrated model adequately predicts the macrophyte effect on dissolved oxygen and improvement from the wwtp upgrade oxygen modeling of macrophyte rich streams in qual2k could be improved by incorporating macrophyte primary production and respiration mechanisms deterministically as done in other models it must also be recognized that despite implementing large scale reductions in wastewater nutrient contributions it may still be difficult to attain desired water quality standards in certain cases we recommend a model based approach be considered as standard practice for evaluating such measures acknowledgements partial support to the primary author r n and data collection was provided by mt nsf epscor pg16 66131 04 grant we thank mike eder matt strozewski and clay thomas for field data collection we also thank dr tae soo chon and two anonymous reviewers who provided valuable feedback and suggestions for this work appendix a supplementary data supplementary material related to this article can be found in the online version at doi https doi org 10 1016 j ecolmodel 2018 12 009 appendix a supplementary data the following is supplementary data to this article 
25131,the process of decision making is a complex task that can become more challenging if the information provided by indicators is contradictory emergy accounting is an environmental accounting methodology that has been used to guide environmental decision making in this paper we propose a comprehensive tool to support decision making in emergy accounting paraconsistent logic is a non classic logic which can aid in decision making when the investigator is confronted with contradictory results paraconsistent tri annotated logic pl3v is proposed as a decision tool to compare different systems and allow selection of those alternatives with the best performance from the standpoint of sustainability defined in emergy terms the rationale behind our selection of a set of emergy indicators to assess sustainability included such factors as increased efficiency setting a priority for local resource use and minimization of the use of non renewable resources two actual examples from the literature that resulted in contradictory evidence of system sustainability were compared within the framework of pl3v emergy indicators that correspond to positive evidence of sustainability i e those that show increased efficiency and greater local resource use were assigned as two favorable logic measures of sustainability the pl3v analysis is completed with the identification of evidence that is unfavorable to sustainability which is given by a third indicator negatively correlated with sustainability i e non renewable resource use operationally the methodology proposed the normalization of the indicator values between 0 1 to fit to the pl3v annotation framework comparison of the systems examined is presented through the paraconsistent logic approach with the aid of a graphical representation and the calculation of the degree of certainty related to the truthfulness of the sustainability proposition keywords emergy paraconsistent annotated logic decision making hydropower sustainability index 1 introduction environmental accounting using emergy odum 1996 is an evaluation method suitable for the appraisal of the long term sustainability of various systems brown and ulgiati 1999 emergy evaluation takes into account the behavior of whole systems and their dynamics in exploiting resources pulselli et al 2004 it has been used to assess the environmental sustainability of a diversity of systems such as crop production brandt williams 2002 biomass production bonilla et al 2010 pulp and paper production corcelli et al 2018 livestock castellini et al 2006 energy production systems ulgiati and brown 2002 biofuels bastianoni and marchettini 1996 cities ascione et al 2009 basins chen and chen 2009 campbell and garmestani 2012 states campbell 1998 and countries ulgiati et al 1994 emergy accounts for all the natural and economic resources of a system expressing them on an equal basis and using a common unit the solar emjoule sej in short emergy is defined as the sum of all inputs of available energy directly or indirectly used by a process to provide a given product when the inputs are expressed in the same form or type of energy usually solar energy ulgiati et al 1995 every input of a system is not only quantified but also classified as renewable non renewable or purchased r n and f respectively according to its renewability and origin traditionally odum 1996 defined a set of emergy indicators in order to evaluate environmental performance the emergy yield ratio eyr is the ratio of the flow of emergy exported in the form of goods and services to the outside market y divided by the emergy of the purchased inputs f the emergy investment ratio eir is the ratio of purchased inputs f to the emergy fluxes derived from the total local free resources r n the environmental loading ratio elr is the ratio of the total non renewable inputs local and purchased n f to renewable emergy flows brown and ulgiati 1997 extend the previous emergy indices and introduce the emergy sustainability index esi that aggregates the measure of yield and environmental loading indices esi eyr elr and most of the emergy literature published afterwards refers to the latter when assessing sustainability several approaches have been used to assess sustainability within the emergy framework among them the renewable support area which is calculated based on the renewable empower density of the region it can be considered as a predictor of long term sustainability assuming that all the environmental requirements for an enterprise are derived from renewable resources brown and ulgiati 2001 on the other hand the support area required to balance the effects of a development as measured with the elr of the region can be considered as a predictor of short term sustainability brown and ulgiati 2001 bastianoni et al 2009 explore unsustainability by means of accounting for the use of n and f resources thereby emphasizing the necessity of considering extensive parameters to assess the distance of a system from what is considered to be a sustainable state lei et al 2012 borrow the genuine savings indicator from the world bank and recalculates it in emergy terms to address the real capital storage of a system namely the sustainability of that system in addition they complement the longterm sustainability assessment by addressing how the change of real wealth impacts the inhabitants emergy consumption a modification of the esi the emergy sustainable use index esui considers the benefits gained by the larger system compared to the potential for local environmental damage it was proposed by campbell and garmestani 2012 in order to preserve the real meaning of the index when examining regional systems since according to winfrey and tilley 2016 existing emergy indices don t capture the sustainability of waste treatments they propose the tsi treatment sustainability index which accounts for the free renewable inputs relative to purchased inputs and downstream requirement for further treatment for sustainability evaluation of technical systems hay et al 2017 considered a matrix that includes among other indicators of diverse origin an emergy set composed of the sum of renewable resources the elr and the sum of local non renewable resources nevertheless the use of the esi is the most general approach used as a criterion for evaluating sustainability in emergy terms the ternary diagram giannetti et al 2006 is a graphical tool that allows the categorization of systems almeida et al 2007 giannetti et al 2007 agostinho et al 2008 li et al 2014 within sustainability regions as a function of the esi criteria of sustainability in the short and long term as proposed by brown and ulgiati 1997 the main characteristic of the esi is that it assesses the emergy yield per unit of environmental stress and in this sense the concept of sustainability it reflects is not directly concerned with the efficiency of the convergence of global resources to support the system the emergy necessary to produce a joule of a certain product or a process the solar transformity expressed in sej j is an indicator of the reciprocal of the efficiency when comparing processes with the same output the lower its value the higher the efficiency of production the same can be said when other physical units are used for expressing the efficiency of product generation thus an attempt to take a more integrated approach to the assessment of sustainability was carried out by plotting the inverse of transformity and the esi on the x axis and y axis respectively the points define geometrical areas in the cartesian plane which represent a measure of the relative sustainability of the systems under study bonilla et al 2010 except for the option giving the best performance where the greatest esi and efficiency values are a direct determination of the best solution the other situations all lead to contradiction or inconsistency hindering decision making thus we believe that the use of paraconsistent logic pl a non classical logic capable of dealing with uncertainty contradictory data or inconsistencies abe 1992 would be beneficial in clarifying situations where the emergy indicators lead to contradictory conclusions this type of logic can deal with reasoning that resembles human commonsense reasoning since it is based on information that is incomplete or inconsistent abe et al 2015 paraconsistent annotated logic with annotation of two values pal2v allows decision making through assigning favorable and unfavorable independent evidence i e quantifying the degree of belief and disbelief respectively to any proposition thus generating a logical state located within the four extreme logical states true false inconsistent and indeterminate abe 1992 the degree of belief on the x axis and the degree of disbelief on the y axis are placed in a cartesian plane thus generating a point that can lie in any of four possible logical states paraconsistent tri annotated logic pal3v presented by papalardo 2016 extended the attribution of two pieces of evidence one favorable and other unfavorable to a set of three independent pieces of evidence two favorable plus one unfavorable this will generate a tridimensional graphic where each system is represented by a point within a unitary cube papalardo 2016 since a system may be better in some respects and worse in others pal3v is proposed to aid in decision making when the three emergy indicators used are not simultaneously better in terms of assigning sustainability this necessary background to justify the selection and understand the applicability of pal3v will be described in section 3 the objective of the present study is to demonstrate the use of paraconsistent tri annotated logic by indicating which system when quantified by the most appropriate set of three emergy indicators presents the best performance from the view point of sustainability an example from the literature tassinari et al 2016 which showed contradictory emergy indicators in terms of sustainability according to the analysis of sustainability adopted in the present work was explored using the pal3v tool the paper is organized as follows first we start by justifying the need for a tool to handle contradictory information when it is provided by the emergy indicators second we discuss the selection of a set of emergy indicators that are consistent with the sustainability approach taken here i e higher sustainability corresponds to more efficient use of inputs relatively less use of nonrenewable inputs n and less dependence on external resources then we focus on explaining the usefulness of pal3v as a decision tool for handling contradictory information the materials and methods section first introduces the system under study and then presents the operational tools needed to carry out data analysis finally we discuss the integration of the emergy methods with the paraconsistent logic framework to improve decision making in the results and discussion section we analyze the two systems through integrating the analysis of the emergy indicators and the evaluation of sustainability premises using paraconsistent logic for decision making the last section summarizes the results of our analyses a theoretical background on paraconsistent logic is presented in appendix a 2 about the sustainability approach adopted 2 1 emergy and environmental accounting the emergy accounting methodology odum 1996 has been developed over the last five decades to evaluate the role of the quality of resources in the dynamics of complex systems and to provide guidance in implementing environmental policies a complete assessment of the methodology cannot be provided here but the reader may refer to other publications odum 1996 brown and ulgiati 1997 odum et al 2000 sciubba and ulgiati 2005 briefly solar emergy is defined as the sum of all inputs of available energy directly or indirectly required by a process to produce a given product when inputs are expressed in the form of solar energy odum 1996 the emergy flows represent three categories of resources r defined as renewable resources n defined as non renewable resources and the purchased inputs provided by the economy f all three categories are fundamental for emergy accounting and for the understanding of a system s interactions with the environment the r and n flows are locally supplied by the environment and are economically free while renewable resources can be replaced at least at the same rate as they are consumed the non renewable resources are depleted faster than their ability to recuperate the economic inputs f are provided by the market and are related to flows supplied by the economy all the emergy that converged into a system is assigned to an output flow namely the intentional product or service and it is expressed as y or the yield of the process operationally each input that enters the system has to be quantified and the raw data expressed in compatible units mass energy or monetary units with the transformation factors that will convert via multiplication the raw data flows into emergy flows the transformation factors include solar transformity solar emergy required to make one joule of a service or product in solar emjoule per joule sej j solar emergy per mass unit and solar emergy per money unit nowadays the ratio of emergy required to make a product to the energy mass or units of the respective material or energy flow of the product is called the unit emergy value uev in a attempt to unify methodology s nomenclature the identification and calculation of the emergy flows enables the calculation of emergy indices only a brief description of the indices is provided here but background information can be found elsewhere ulgiati et al 1995 odum 1996 brown and ulgiati 1997 the emergy yield ratio eyr is the ratio of the emergy of the output y divided by the emergy of purchased inputs f and shows the importance of local resources with respect to exogenous ones the investment ratio eir is the ratio of purchased inputs f to all emergy fluxes derived from local free resources r n the index measures the level of economic development and the degree of dependence of a system on the environment the environmental loading ratio elr is the ratio of non renewable local n and purchased f to renewable emergy flows r and represents the potential pressure on the natural environment the emergy sustainability index esi aggregates the measure of yield and environmental loading esi eyr elr 2 2 outlining the sustainability approach and selection of the indicators to be analyzed by pal3v according to bastianoni et al 2009 sustainability is an ideal state and it is only possible to quantify the distance from the ideal point of sustainability throughout the text we refer to sustainability in the sense of quantifying the contribution towards the sustainable state or the actions to achieve sustainability targets that is the contributions to decrease the distance from that ideal state so although the term sustainability is used throughout the text its real meaning even without making it explicit is related to the concept of degree or levels of proximity from the ideal state additionally the concept of sustainability is linked with extensive properties since it depends on the availability of limited resources within the biosphere in this way bastianoni et al 2009 argued that it is not possible to assess sustainability by using intensive parameters because the problem is strongly correlated with the size of the system taking into account that we are not proposing any extensive emergy indicators for assessing sustainability the indicators here adopted are useful only for comparing processes that generate the same products bastianoni et al 2007 also states that emergy evaluation can only show the relative level of sustainability enabling the choice of the better arrangement according to the characteristics of the viewpoint based on the latter considerations we adopt the concept of relative sustainability since it properly evidences the extent and limitations of the approach explored here after having explained the sustainability approach used here it seems necessary to justify the selection of the indicators capable of reflecting the degree or level of relative sustainability without disregarding the contribution that the esi index brought to the emergy assessment of sustainability its contributions are not related to the conversion efficiency of the solar energy that drives a process thus the incorporation of transformity to account for the total resources directly or indirectly used even though it is a relative indicator it can quantify the efficiency of resource convergence needed to deliver a unit of a given product transformity is not concerned with the distribution among types of resources but since it quantifies the total quantity of resources used per unit of product it is related to efficiency in this way the higher the transformity the greater the environmental activity required for product processing in agreement with brown and ulgiati 1997 transformity or another measure of the emergy per unit product is an indicator of past environmental contributions to a resource and the future load on environmental systems the combination of the indicators transformity and esi can be used to evaluate the relative goodness of systems in terms of their environmental performance and it can be considered a preliminary attempt to measure the degree of relative sustainability of the systems which was explored by bonilla et al 2010 with this purpose the inverse of transformity or product per unit of emergy which represents an emergy productivity measure was plotted in the same graphic with esi the areas defined by the points show a way to evaluate the goodness of the systems under a sustainability point of view the points represent the values of esi and the inverse of transformity for bamboo production in brazil and china respectively fig 1 adapted from bonilla et al 2010 this figure combines information about the efficiency of solar emergy supplied in the production of a unit of product and the performance of that process in terms of the emergy yield obtained per unit of environmental loading the best performance will correspond to the system that defines the larger area in the figure with the simultaneous maximization of esi and the inverse of transformity in this way points located at the high right extreme of the graphic indicated by the ascendant arrow correspond to those privileged positions where both the indicators are maximized on the other hand the worst situation corresponds to points located on the left bottom side of the graphic shown by the descendant arrow when the points lie in positions other than the extreme ones as shown in fig 1 a direct conclusion about the selection of the system with the best performance is not possible without prioritizing one indicator or goal over the other even though the areas delimited by the points are graphically equal the values of esi and the inverse of transformity are extreme for both situations in this case the two indicators selected to compare systems performance generate contradictory information and decision making is not straightforward this means that when comparing two different events by using the two indicators it is only possible to affirm that a is more sustainable than b if all indicators show better performance in a than in b to conclude that one is more sustainable than the other in other situations will be possible if one indicator is prioritized over the other although when these combinations occur decision making will imply the need to select an indicator weighting procedure or prioritize the desired outcomes according to the definition of esi brown and ulgiati 1997 sustainability is shown to be a function of the net yield and the load on the environment even so it was shown that esi is maximized by combinations of inequalities involving r n and f that are not related to maximizing renewable use or minimizing the use of n giannetti et al 2012 in this way the eyr and elr generated by those r n and f combinations do not individually contribute to improve sustainability even though they result in large values of the index as argued by lei et al 2012 the advantage of integrating metrics offered by esi conceals the impact of the individual indices thereby providing unclear indications of a system s true sustainability to address this we prioritized the adoption of the individual components of the index to assess sustainability instead of the index as a whole the transformity or uev corresponds to the consumption of solar emergy required to create a unit of a product or service thus it represents the environmental value based on the effective resource consumption that occurs during the production process and therefore it can provide significant information on the environmental basis of an item from a comparison of the reciprocals of the uevs pulselli et al 2004 the inverse of the transformity represents the efficiency of total resources use in a production process and we will adopt the term emergy productivity ep for this ratio the term productivity reflects the concept of the ratio of an output to inputs in this case the units of products in energy or mass units generated by a unit of resources invested in sej the measures chosen to assess sustainability are eyr which captures the productivity of local resources with respect to exogenous ones the elr which represents the potential pressure on the environment caused by non renewable and purchased resource use and the transformity which assesses the efficiency in the use of solar energy and is also the inverse of the ep 3 paraconsistent tri annotated logic as a decision tool for contradictory information classical logic is restricted to handle binary information that is situations when the favorable evidence is total or the inverse condition when the unfavorable evidence is total the first case allows concluding that the proposition is true and the second that the proposition is false however classical logic due to its premise of binary conditions is unable to deal with real world situations where indetermination uncertainty ambiguity and contradiction frequently occur da silva filho 2006 when a proposition is simultaneously described by favorable and unfavorable pieces of evidence paraconsistent logic allows reaching conclusions without trivialization and thus it enables decision making without the necessity of disregarding or discarding data da silva filho et al 2010 only the background necessary to justify the selection of the pal3v to handle contradictory information will be addressed in this section the theoretical basis for pl and pal that enables the understanding of the framework within which pal3v is comprised is presented in appendix a the proposition to be analyzed in the present work is concerned with the sustainability of two hydropower plants that have been evaluated through the emergy indicators described in detail in the previous section the indicators correspond to three attributes that can be associated with the proposition of sustainability as pieces of favorable or unfavorable evidence the analysis can be accomplished within the framework of paraconsistent tri annotated logic presented by papalardo 2016 within this framework the proposition porto primavera hydropower plant is environmentally sustainable is annotated by using the expression p μ λ ω and can be graphically represented as a point within a unitary cube papalardo 2016 the point is determined by the values μ ω λ and will belong to the orthogonal plane α depicted in fig 2 as a green shadow the geometrical distance from the vertex c which corresponds to the true logical state to the plane α which contains the point μ ω λ is related to the logical distance between the proposition and the true state thus our proposal is to associate the pal3v in such a way to assign to each indicator a degree of evidence projected into the real interval 0 1 the evidence could be favorable or unfavorable to the proposition under analysis since the geometrical distance from c is an indicator of proposition consistency it will be introduced as the degree of certainty defined as h which mathematically expresses this distance the calculation of h assessed through the pal3v perspective is beyond the scope of this work and can be found in papalardo 2016 the degree of certainty h is defined by the expression papalardo 2016 h μ ω λ μ ω λ 1 the degree of certainty is used when it is necessary to know the proximity to the true state h will vary between 1 and 2 2 h 1 the closer to the value of 1 the greater the degree of certainty of the proposition the closer the point is to the true state the closer to 1 the h value will be in addition a criterion should be established to consider if the situation represented by the point μ ω λ is acceptable or not acceptable a requirement value or confidence level k see table b1 in the interval 2 1 can be established for h above which the proposition can be considered true in fact the plane through points x y and z represents the limit considered acceptable and therefore divides the unit cube into two volumes see fig 3 as the plane through points x y and z approaches the extreme c the true state the volume delimited between the points decreases and the probability of the proposition being 100 true increases therefore the requirement level or confidence level k can also be expressed as the probability that a proposition belonging to the true state the probability represents the ratio of the volume limited by the points c x y z shaded in beige in fig 3 to the volume of the unitary cube the values of k and the correspondent probability are shown in table b1 4 materials and methods 4 1 systems selected for evaluation of the premise that they are sustainable the results from two hydropower plants from tassinari et al 2016 are applicable since the indicators set proposed in this work as a sustainability criterion resulted in contradictory information the two hydropower plants are located along the paraná river within brazil the eng souza dias plant known as the jupiá plant can supply 1550 2 mw with a reservoir of 330 km2 the eng sergio motta plant known as porto primavera pp a typical impoundment plant has a reservoir of 2250 km2 and can provide 1540 mw table 1 displays the values of the emergy indicators and the evidence that eyr suggests a better performance in sustainability terms for the pp plant whereas elr and ep indicators show the opposite trend 4 2 the integration between emergy accounting and paraconsistent tri annotated logic section 2 2 explained the rationale behind the selection of the set of emergy indicators used to assess sustainability this set of indicators characterizes sustainability from the viewpoint of increasing efficiency in the use of resources prioritizing the use of local resources with respect to exogenous ones and the minimization of non renewable resources with respect to renewable ones therefore the pal3v assigns three degrees of evidence to the indicators within the real interval 0 1 the degrees of evidence can be favorable or unfavorable contrary to the proposition under analysis for the present case the proposition that is being analyzed is related to the sustainability of the systems considering the results provided by the indicators within the frame of pl3v the attribution of two favorable pieces of evidence corresponds to eyr and the emergy productivity indicators whereas the unfavorable evidence corresponds to the elr in this way the degree of belief provided by eyr and ep will be indicated by μ and ω respectively while the degree of disbelief provided by elr will generate the λ value since the pl3v methodology establishes that μ ω and λ values belong to the real unitary interval 0 1 it is necessary to normalize the indicator values to integrate both methodologies consequently each system studied through the emergy approach and which delivers a set of contradictory indicators eyr elr vs ep can be converted to a pl3v premise and handled in a way to promote better decision making each premise will determine a point within the cartesian volume and the degree of certainty h can be calculated to compare the systems and to allow better informed decision making the reason for normalizing indicators was to allow each of them to vary between zero and one thus allowing them to be analyzed through the pl3v approach the indicators were normalized by assigning upper and lower bounds thus 1 eyrn eyr eyrmin eyrmax eyrmin eyrn being the normalized value eyr the value for the system under study and eyrmin and eyrmax the upper and lower bounds normalization is carried out in an analogous way for elr and ep the upper and lower values are set from the maxima and minima respectively extracted from systems with comparable characteristics found in the literature in this way upper and lower values are restricted to an interval of observed values found for similar systems as real systems can improve their performance over time for any of the criteria adopted here the normalization intervals may be modified in the future literature research on hydropower plants with comparable characteristics provided the threshold values depicted in table 2 since the value of these indicators strongly depends on the hydropower installed capacity this is the characteristic used to restrict the search for threshold values that restriction is taken from zhang et al 2014 who show differences in the emergy indicators according to the installed capacity interval considered based on this evidence the indicators corresponding to small hydropower plants were disregarded having normalized the indicator values it is possible to set values for μ ω λ and to place the point generated for each system under study i e the jupiá and pp plants within the unitary cube the degree of certainty h is calculated to know the proximity with the true state of the premise defined by each set of values μ ω λ the degree of relative sustainability will be greater the closer the point gets to the true state represented by c the true state corresponds to 1 1 0 and represents here a hypothetical state that combines the best three values for eyr ep and elr extracted from the literature and these values will be assigned to the better degree of relative sustainability as defined in section 2 2 for a fixed k that is the minimum value the degree of certainty h should allow us to accept the proposition it is possible to affirm that if h k the point p μ ω λ belongs to the region of the unitary cube where the premise is considered true 5 results and discussion as shown in table 1 the set of emergy indicators adopted to assess sustainability for two hydroelectricity generation plants tassinari et al 2016 provides contradictory information about which system has better performance in terms of sustainability the best performance will correspond to the system that combines the greater eyr and ep with the smaller elr values none of the systems under study show these characteristics since the pp plant has the best performance in terms of eyr but it is worse than jupiá when elr and ep are considered the interpretation of the contradictory information through the point of view of pal3v allows the attribution of the degree of belief and disbelief related to each emergy indicator the attribution of the degree of belief and disbelief is accomplished through the normalization of the emergy indicators and results in the values shown in table 3 for the jupiá and pp plants in this way the contradictory information provided by the emergy indicators can be treated without the necessity of adopting any type of weighting procedure in order to prioritize one indicator over the others normalization allows the translation of the emergy indicators into a unified decision variable within the pal3v framework the proposition on sustainability evaluated is related to the favorable and contrary evidence assumed for the hydropower plants performance each state has the form μ ω λ where μ and λ represent the favorable evidence and ω the contrary evidence comparison of the two plants can be accomplished through the states 0 51 1 0 and 0 67 0 58 0 13 for the jupiá and pp plants respectively which result from translations of the emergy indicators into pal3v as already explained the graphical representation of the states within the unitary cube is depicted in fig 4 we can calculate the degree of certainty as determined by papalardo 2016 for the two plants as follows hjupiá 0 51 1 0 0 1 0 51 and hpp 0 67 0 58 0 13 1 0 12 which represents the proximity to the true logical state the right side of fig 4 shows the localization of both points within the unitary cube through a diagonal viewpoint if k 0 1 is adopted as the level of requirement it is possible to say that both plants are located into the region of acceptable sustainability that is both are viable with 87 85 probability or confidence according to table b1 however if a level of requirement equal to 0 5 is adopted the jupiá sustainability is acceptable whereas the pp sustainability is not acceptable with 97 92 confidence when translating the pal3v results into the emergy framework it is possible to state that the jupiá plant has better performance in sustainability terms the integrating tool proposed in this work allows the selection of the best system that is one that balances the efficient use of resources with a relatively low elr and a relatively high eyr the degree of certainty h can be proposed as a sustainability indicator since it quantifies the degree of adherence of a system to the chosen sustainability criteria of maximizing efficiency of global resource use and eyr while minimizing elr 6 final commentaries when the information extracted from the emergy indicators selected to assess sustainability is contradictory the need to handle decision making using a tool that can deal with contradictory results arises the pal3v proposed by papalardo 2016 offered the possibility of handling three emergy indicators thus allowing comparison of systems and the selection of the one with the best performance based on sustainability or another point of view the degree of certainty h may be seen as a logically supported sustainability composite indicator since it can show which choice is better through evaluating the integration of the efficiency of global resource use the use of relatively less non renewable inputs and less dependence on external resources the usefulness of the proposed procedure can be extended to propositions involving other systems when environmental sustainability is addressed with the same set of emergy indicators discussed here accurate decision making is needed to evaluate future management plans as well as to direct strategic choices for development comparing alternatives or analyzing policy scenarios can be a complex task that gets harder if the information provided by indicators is contradictory or uncertain the integration of pal3v logic as a decision tool with the already successful environmental emergy accounting methods adds transparency ease of reporting and will result in a comprehensive tool that can support decision making when dealing with assessments that contain contradictory results acknowledgments the vice reitoria de pós graduação e pesquisa of paulista university unip is fully acknowledged the authors want to thank prof dr j m abe for the revision of the text concerning paraconsistent logic we are deeply grateful to the anonymous reviewers for the helpful comments and suggestions that have served to improve the work appendix a paraconsistent logic is a non classical logic whose main feature is the revocation of the non contradiction principle of classical logic it emerged from the necessity of handling logically contradictory situations without trivialization of the result da silva filho et al 2010 an introduction to paraconsistent logic is given here to permit the reader to understand the usefulness of this logic and the framework within which the pal3v is composed more information can be obtained elsewhere da costa et al 1991 abe 1992 da silva filho et al 2010 de carvalho and abe 2011 within the pl family paraconsistent annotated logic pal offers the language and structure to properly express the concepts involved in this study pal provides a language to capture the nuances of reality in a more complete way than is possible in classical logic da silva filho et al 2010 it is comprised of atomic propositions each of which is accompanied by an annotation composed of the degree of belief or favorable evidence de carvalho and abe 2011 pal can be represented through a lattice of four vertices that correspond to the extreme logical states true false inconsistent and indeterminate referring to the proposition that will be analyzed da silva filho et al 2010 the annotation can also be composed by a pair being the first element of the pair the favorable evidence and the second element the contrary evidence which negates the proposition de carvalho and abe 2011 so it is possible to achieve a better representation of how much the evidence can express the knowledge about a proposition through paraconsistent annotated logic with two values pal2v if a pair μ λ is used with favorable degree of evidence μ and unfavorable degree of evidence λ de carvalho and abe 2011 the atomic formulas of the language of the logic are of the type p μ λ where p denotes a propositional variable and μ favorable evidence and λ unfavorable or contrary evidence with μ λ belonging to the real cartesian product 0 1 x 0 1 abe 2014 the proposition p μ λ can be intuitively read it is assumed that p s favorable evidence is μ and contrary evidence is λ depending on the applications other terms can be considered instead of evidence such as probability belief etc abe 2014 the values of μ and λ that vary in the interval 0 1 can be plotted in a unitary square on the cartesian plane the four vertices are the points 0 0 0 1 1 0 and 1 1 which correspond to the paracomplete or indeterminate false true and inconsistent or contradictory logical states respectively similarly if there are three attributes each associated to pieces of favorable or unfavorable evidence the analysis will be able to work within the framework of paraconsistent tri annotated logic pal3v presented by papalardo 2016 in this way any proposition p will be expressed as p μ λ ω representing a point within the unitary cube papalardo 2016 four of the eight vertexes of the unitary cube correspond to the priority logical states a b c and d as depicted in fig a1 point c expressed by 1 1 0 is defined as the true state on the contrary point d expressed by 0 0 1 is defined as the false logical state point a expressed by 0 0 0 corresponds to the extreme state of indeterminancy or paracompleteness and point b 1 1 1 represents the extreme state of inconsistency contradiction since the points e f g and h don t represent relevant logic states they will not be analyzed here in this way any proposition p will be expressed with a triple annotation p μ λ ω appendix b 
25131,the process of decision making is a complex task that can become more challenging if the information provided by indicators is contradictory emergy accounting is an environmental accounting methodology that has been used to guide environmental decision making in this paper we propose a comprehensive tool to support decision making in emergy accounting paraconsistent logic is a non classic logic which can aid in decision making when the investigator is confronted with contradictory results paraconsistent tri annotated logic pl3v is proposed as a decision tool to compare different systems and allow selection of those alternatives with the best performance from the standpoint of sustainability defined in emergy terms the rationale behind our selection of a set of emergy indicators to assess sustainability included such factors as increased efficiency setting a priority for local resource use and minimization of the use of non renewable resources two actual examples from the literature that resulted in contradictory evidence of system sustainability were compared within the framework of pl3v emergy indicators that correspond to positive evidence of sustainability i e those that show increased efficiency and greater local resource use were assigned as two favorable logic measures of sustainability the pl3v analysis is completed with the identification of evidence that is unfavorable to sustainability which is given by a third indicator negatively correlated with sustainability i e non renewable resource use operationally the methodology proposed the normalization of the indicator values between 0 1 to fit to the pl3v annotation framework comparison of the systems examined is presented through the paraconsistent logic approach with the aid of a graphical representation and the calculation of the degree of certainty related to the truthfulness of the sustainability proposition keywords emergy paraconsistent annotated logic decision making hydropower sustainability index 1 introduction environmental accounting using emergy odum 1996 is an evaluation method suitable for the appraisal of the long term sustainability of various systems brown and ulgiati 1999 emergy evaluation takes into account the behavior of whole systems and their dynamics in exploiting resources pulselli et al 2004 it has been used to assess the environmental sustainability of a diversity of systems such as crop production brandt williams 2002 biomass production bonilla et al 2010 pulp and paper production corcelli et al 2018 livestock castellini et al 2006 energy production systems ulgiati and brown 2002 biofuels bastianoni and marchettini 1996 cities ascione et al 2009 basins chen and chen 2009 campbell and garmestani 2012 states campbell 1998 and countries ulgiati et al 1994 emergy accounts for all the natural and economic resources of a system expressing them on an equal basis and using a common unit the solar emjoule sej in short emergy is defined as the sum of all inputs of available energy directly or indirectly used by a process to provide a given product when the inputs are expressed in the same form or type of energy usually solar energy ulgiati et al 1995 every input of a system is not only quantified but also classified as renewable non renewable or purchased r n and f respectively according to its renewability and origin traditionally odum 1996 defined a set of emergy indicators in order to evaluate environmental performance the emergy yield ratio eyr is the ratio of the flow of emergy exported in the form of goods and services to the outside market y divided by the emergy of the purchased inputs f the emergy investment ratio eir is the ratio of purchased inputs f to the emergy fluxes derived from the total local free resources r n the environmental loading ratio elr is the ratio of the total non renewable inputs local and purchased n f to renewable emergy flows brown and ulgiati 1997 extend the previous emergy indices and introduce the emergy sustainability index esi that aggregates the measure of yield and environmental loading indices esi eyr elr and most of the emergy literature published afterwards refers to the latter when assessing sustainability several approaches have been used to assess sustainability within the emergy framework among them the renewable support area which is calculated based on the renewable empower density of the region it can be considered as a predictor of long term sustainability assuming that all the environmental requirements for an enterprise are derived from renewable resources brown and ulgiati 2001 on the other hand the support area required to balance the effects of a development as measured with the elr of the region can be considered as a predictor of short term sustainability brown and ulgiati 2001 bastianoni et al 2009 explore unsustainability by means of accounting for the use of n and f resources thereby emphasizing the necessity of considering extensive parameters to assess the distance of a system from what is considered to be a sustainable state lei et al 2012 borrow the genuine savings indicator from the world bank and recalculates it in emergy terms to address the real capital storage of a system namely the sustainability of that system in addition they complement the longterm sustainability assessment by addressing how the change of real wealth impacts the inhabitants emergy consumption a modification of the esi the emergy sustainable use index esui considers the benefits gained by the larger system compared to the potential for local environmental damage it was proposed by campbell and garmestani 2012 in order to preserve the real meaning of the index when examining regional systems since according to winfrey and tilley 2016 existing emergy indices don t capture the sustainability of waste treatments they propose the tsi treatment sustainability index which accounts for the free renewable inputs relative to purchased inputs and downstream requirement for further treatment for sustainability evaluation of technical systems hay et al 2017 considered a matrix that includes among other indicators of diverse origin an emergy set composed of the sum of renewable resources the elr and the sum of local non renewable resources nevertheless the use of the esi is the most general approach used as a criterion for evaluating sustainability in emergy terms the ternary diagram giannetti et al 2006 is a graphical tool that allows the categorization of systems almeida et al 2007 giannetti et al 2007 agostinho et al 2008 li et al 2014 within sustainability regions as a function of the esi criteria of sustainability in the short and long term as proposed by brown and ulgiati 1997 the main characteristic of the esi is that it assesses the emergy yield per unit of environmental stress and in this sense the concept of sustainability it reflects is not directly concerned with the efficiency of the convergence of global resources to support the system the emergy necessary to produce a joule of a certain product or a process the solar transformity expressed in sej j is an indicator of the reciprocal of the efficiency when comparing processes with the same output the lower its value the higher the efficiency of production the same can be said when other physical units are used for expressing the efficiency of product generation thus an attempt to take a more integrated approach to the assessment of sustainability was carried out by plotting the inverse of transformity and the esi on the x axis and y axis respectively the points define geometrical areas in the cartesian plane which represent a measure of the relative sustainability of the systems under study bonilla et al 2010 except for the option giving the best performance where the greatest esi and efficiency values are a direct determination of the best solution the other situations all lead to contradiction or inconsistency hindering decision making thus we believe that the use of paraconsistent logic pl a non classical logic capable of dealing with uncertainty contradictory data or inconsistencies abe 1992 would be beneficial in clarifying situations where the emergy indicators lead to contradictory conclusions this type of logic can deal with reasoning that resembles human commonsense reasoning since it is based on information that is incomplete or inconsistent abe et al 2015 paraconsistent annotated logic with annotation of two values pal2v allows decision making through assigning favorable and unfavorable independent evidence i e quantifying the degree of belief and disbelief respectively to any proposition thus generating a logical state located within the four extreme logical states true false inconsistent and indeterminate abe 1992 the degree of belief on the x axis and the degree of disbelief on the y axis are placed in a cartesian plane thus generating a point that can lie in any of four possible logical states paraconsistent tri annotated logic pal3v presented by papalardo 2016 extended the attribution of two pieces of evidence one favorable and other unfavorable to a set of three independent pieces of evidence two favorable plus one unfavorable this will generate a tridimensional graphic where each system is represented by a point within a unitary cube papalardo 2016 since a system may be better in some respects and worse in others pal3v is proposed to aid in decision making when the three emergy indicators used are not simultaneously better in terms of assigning sustainability this necessary background to justify the selection and understand the applicability of pal3v will be described in section 3 the objective of the present study is to demonstrate the use of paraconsistent tri annotated logic by indicating which system when quantified by the most appropriate set of three emergy indicators presents the best performance from the view point of sustainability an example from the literature tassinari et al 2016 which showed contradictory emergy indicators in terms of sustainability according to the analysis of sustainability adopted in the present work was explored using the pal3v tool the paper is organized as follows first we start by justifying the need for a tool to handle contradictory information when it is provided by the emergy indicators second we discuss the selection of a set of emergy indicators that are consistent with the sustainability approach taken here i e higher sustainability corresponds to more efficient use of inputs relatively less use of nonrenewable inputs n and less dependence on external resources then we focus on explaining the usefulness of pal3v as a decision tool for handling contradictory information the materials and methods section first introduces the system under study and then presents the operational tools needed to carry out data analysis finally we discuss the integration of the emergy methods with the paraconsistent logic framework to improve decision making in the results and discussion section we analyze the two systems through integrating the analysis of the emergy indicators and the evaluation of sustainability premises using paraconsistent logic for decision making the last section summarizes the results of our analyses a theoretical background on paraconsistent logic is presented in appendix a 2 about the sustainability approach adopted 2 1 emergy and environmental accounting the emergy accounting methodology odum 1996 has been developed over the last five decades to evaluate the role of the quality of resources in the dynamics of complex systems and to provide guidance in implementing environmental policies a complete assessment of the methodology cannot be provided here but the reader may refer to other publications odum 1996 brown and ulgiati 1997 odum et al 2000 sciubba and ulgiati 2005 briefly solar emergy is defined as the sum of all inputs of available energy directly or indirectly required by a process to produce a given product when inputs are expressed in the form of solar energy odum 1996 the emergy flows represent three categories of resources r defined as renewable resources n defined as non renewable resources and the purchased inputs provided by the economy f all three categories are fundamental for emergy accounting and for the understanding of a system s interactions with the environment the r and n flows are locally supplied by the environment and are economically free while renewable resources can be replaced at least at the same rate as they are consumed the non renewable resources are depleted faster than their ability to recuperate the economic inputs f are provided by the market and are related to flows supplied by the economy all the emergy that converged into a system is assigned to an output flow namely the intentional product or service and it is expressed as y or the yield of the process operationally each input that enters the system has to be quantified and the raw data expressed in compatible units mass energy or monetary units with the transformation factors that will convert via multiplication the raw data flows into emergy flows the transformation factors include solar transformity solar emergy required to make one joule of a service or product in solar emjoule per joule sej j solar emergy per mass unit and solar emergy per money unit nowadays the ratio of emergy required to make a product to the energy mass or units of the respective material or energy flow of the product is called the unit emergy value uev in a attempt to unify methodology s nomenclature the identification and calculation of the emergy flows enables the calculation of emergy indices only a brief description of the indices is provided here but background information can be found elsewhere ulgiati et al 1995 odum 1996 brown and ulgiati 1997 the emergy yield ratio eyr is the ratio of the emergy of the output y divided by the emergy of purchased inputs f and shows the importance of local resources with respect to exogenous ones the investment ratio eir is the ratio of purchased inputs f to all emergy fluxes derived from local free resources r n the index measures the level of economic development and the degree of dependence of a system on the environment the environmental loading ratio elr is the ratio of non renewable local n and purchased f to renewable emergy flows r and represents the potential pressure on the natural environment the emergy sustainability index esi aggregates the measure of yield and environmental loading esi eyr elr 2 2 outlining the sustainability approach and selection of the indicators to be analyzed by pal3v according to bastianoni et al 2009 sustainability is an ideal state and it is only possible to quantify the distance from the ideal point of sustainability throughout the text we refer to sustainability in the sense of quantifying the contribution towards the sustainable state or the actions to achieve sustainability targets that is the contributions to decrease the distance from that ideal state so although the term sustainability is used throughout the text its real meaning even without making it explicit is related to the concept of degree or levels of proximity from the ideal state additionally the concept of sustainability is linked with extensive properties since it depends on the availability of limited resources within the biosphere in this way bastianoni et al 2009 argued that it is not possible to assess sustainability by using intensive parameters because the problem is strongly correlated with the size of the system taking into account that we are not proposing any extensive emergy indicators for assessing sustainability the indicators here adopted are useful only for comparing processes that generate the same products bastianoni et al 2007 also states that emergy evaluation can only show the relative level of sustainability enabling the choice of the better arrangement according to the characteristics of the viewpoint based on the latter considerations we adopt the concept of relative sustainability since it properly evidences the extent and limitations of the approach explored here after having explained the sustainability approach used here it seems necessary to justify the selection of the indicators capable of reflecting the degree or level of relative sustainability without disregarding the contribution that the esi index brought to the emergy assessment of sustainability its contributions are not related to the conversion efficiency of the solar energy that drives a process thus the incorporation of transformity to account for the total resources directly or indirectly used even though it is a relative indicator it can quantify the efficiency of resource convergence needed to deliver a unit of a given product transformity is not concerned with the distribution among types of resources but since it quantifies the total quantity of resources used per unit of product it is related to efficiency in this way the higher the transformity the greater the environmental activity required for product processing in agreement with brown and ulgiati 1997 transformity or another measure of the emergy per unit product is an indicator of past environmental contributions to a resource and the future load on environmental systems the combination of the indicators transformity and esi can be used to evaluate the relative goodness of systems in terms of their environmental performance and it can be considered a preliminary attempt to measure the degree of relative sustainability of the systems which was explored by bonilla et al 2010 with this purpose the inverse of transformity or product per unit of emergy which represents an emergy productivity measure was plotted in the same graphic with esi the areas defined by the points show a way to evaluate the goodness of the systems under a sustainability point of view the points represent the values of esi and the inverse of transformity for bamboo production in brazil and china respectively fig 1 adapted from bonilla et al 2010 this figure combines information about the efficiency of solar emergy supplied in the production of a unit of product and the performance of that process in terms of the emergy yield obtained per unit of environmental loading the best performance will correspond to the system that defines the larger area in the figure with the simultaneous maximization of esi and the inverse of transformity in this way points located at the high right extreme of the graphic indicated by the ascendant arrow correspond to those privileged positions where both the indicators are maximized on the other hand the worst situation corresponds to points located on the left bottom side of the graphic shown by the descendant arrow when the points lie in positions other than the extreme ones as shown in fig 1 a direct conclusion about the selection of the system with the best performance is not possible without prioritizing one indicator or goal over the other even though the areas delimited by the points are graphically equal the values of esi and the inverse of transformity are extreme for both situations in this case the two indicators selected to compare systems performance generate contradictory information and decision making is not straightforward this means that when comparing two different events by using the two indicators it is only possible to affirm that a is more sustainable than b if all indicators show better performance in a than in b to conclude that one is more sustainable than the other in other situations will be possible if one indicator is prioritized over the other although when these combinations occur decision making will imply the need to select an indicator weighting procedure or prioritize the desired outcomes according to the definition of esi brown and ulgiati 1997 sustainability is shown to be a function of the net yield and the load on the environment even so it was shown that esi is maximized by combinations of inequalities involving r n and f that are not related to maximizing renewable use or minimizing the use of n giannetti et al 2012 in this way the eyr and elr generated by those r n and f combinations do not individually contribute to improve sustainability even though they result in large values of the index as argued by lei et al 2012 the advantage of integrating metrics offered by esi conceals the impact of the individual indices thereby providing unclear indications of a system s true sustainability to address this we prioritized the adoption of the individual components of the index to assess sustainability instead of the index as a whole the transformity or uev corresponds to the consumption of solar emergy required to create a unit of a product or service thus it represents the environmental value based on the effective resource consumption that occurs during the production process and therefore it can provide significant information on the environmental basis of an item from a comparison of the reciprocals of the uevs pulselli et al 2004 the inverse of the transformity represents the efficiency of total resources use in a production process and we will adopt the term emergy productivity ep for this ratio the term productivity reflects the concept of the ratio of an output to inputs in this case the units of products in energy or mass units generated by a unit of resources invested in sej the measures chosen to assess sustainability are eyr which captures the productivity of local resources with respect to exogenous ones the elr which represents the potential pressure on the environment caused by non renewable and purchased resource use and the transformity which assesses the efficiency in the use of solar energy and is also the inverse of the ep 3 paraconsistent tri annotated logic as a decision tool for contradictory information classical logic is restricted to handle binary information that is situations when the favorable evidence is total or the inverse condition when the unfavorable evidence is total the first case allows concluding that the proposition is true and the second that the proposition is false however classical logic due to its premise of binary conditions is unable to deal with real world situations where indetermination uncertainty ambiguity and contradiction frequently occur da silva filho 2006 when a proposition is simultaneously described by favorable and unfavorable pieces of evidence paraconsistent logic allows reaching conclusions without trivialization and thus it enables decision making without the necessity of disregarding or discarding data da silva filho et al 2010 only the background necessary to justify the selection of the pal3v to handle contradictory information will be addressed in this section the theoretical basis for pl and pal that enables the understanding of the framework within which pal3v is comprised is presented in appendix a the proposition to be analyzed in the present work is concerned with the sustainability of two hydropower plants that have been evaluated through the emergy indicators described in detail in the previous section the indicators correspond to three attributes that can be associated with the proposition of sustainability as pieces of favorable or unfavorable evidence the analysis can be accomplished within the framework of paraconsistent tri annotated logic presented by papalardo 2016 within this framework the proposition porto primavera hydropower plant is environmentally sustainable is annotated by using the expression p μ λ ω and can be graphically represented as a point within a unitary cube papalardo 2016 the point is determined by the values μ ω λ and will belong to the orthogonal plane α depicted in fig 2 as a green shadow the geometrical distance from the vertex c which corresponds to the true logical state to the plane α which contains the point μ ω λ is related to the logical distance between the proposition and the true state thus our proposal is to associate the pal3v in such a way to assign to each indicator a degree of evidence projected into the real interval 0 1 the evidence could be favorable or unfavorable to the proposition under analysis since the geometrical distance from c is an indicator of proposition consistency it will be introduced as the degree of certainty defined as h which mathematically expresses this distance the calculation of h assessed through the pal3v perspective is beyond the scope of this work and can be found in papalardo 2016 the degree of certainty h is defined by the expression papalardo 2016 h μ ω λ μ ω λ 1 the degree of certainty is used when it is necessary to know the proximity to the true state h will vary between 1 and 2 2 h 1 the closer to the value of 1 the greater the degree of certainty of the proposition the closer the point is to the true state the closer to 1 the h value will be in addition a criterion should be established to consider if the situation represented by the point μ ω λ is acceptable or not acceptable a requirement value or confidence level k see table b1 in the interval 2 1 can be established for h above which the proposition can be considered true in fact the plane through points x y and z represents the limit considered acceptable and therefore divides the unit cube into two volumes see fig 3 as the plane through points x y and z approaches the extreme c the true state the volume delimited between the points decreases and the probability of the proposition being 100 true increases therefore the requirement level or confidence level k can also be expressed as the probability that a proposition belonging to the true state the probability represents the ratio of the volume limited by the points c x y z shaded in beige in fig 3 to the volume of the unitary cube the values of k and the correspondent probability are shown in table b1 4 materials and methods 4 1 systems selected for evaluation of the premise that they are sustainable the results from two hydropower plants from tassinari et al 2016 are applicable since the indicators set proposed in this work as a sustainability criterion resulted in contradictory information the two hydropower plants are located along the paraná river within brazil the eng souza dias plant known as the jupiá plant can supply 1550 2 mw with a reservoir of 330 km2 the eng sergio motta plant known as porto primavera pp a typical impoundment plant has a reservoir of 2250 km2 and can provide 1540 mw table 1 displays the values of the emergy indicators and the evidence that eyr suggests a better performance in sustainability terms for the pp plant whereas elr and ep indicators show the opposite trend 4 2 the integration between emergy accounting and paraconsistent tri annotated logic section 2 2 explained the rationale behind the selection of the set of emergy indicators used to assess sustainability this set of indicators characterizes sustainability from the viewpoint of increasing efficiency in the use of resources prioritizing the use of local resources with respect to exogenous ones and the minimization of non renewable resources with respect to renewable ones therefore the pal3v assigns three degrees of evidence to the indicators within the real interval 0 1 the degrees of evidence can be favorable or unfavorable contrary to the proposition under analysis for the present case the proposition that is being analyzed is related to the sustainability of the systems considering the results provided by the indicators within the frame of pl3v the attribution of two favorable pieces of evidence corresponds to eyr and the emergy productivity indicators whereas the unfavorable evidence corresponds to the elr in this way the degree of belief provided by eyr and ep will be indicated by μ and ω respectively while the degree of disbelief provided by elr will generate the λ value since the pl3v methodology establishes that μ ω and λ values belong to the real unitary interval 0 1 it is necessary to normalize the indicator values to integrate both methodologies consequently each system studied through the emergy approach and which delivers a set of contradictory indicators eyr elr vs ep can be converted to a pl3v premise and handled in a way to promote better decision making each premise will determine a point within the cartesian volume and the degree of certainty h can be calculated to compare the systems and to allow better informed decision making the reason for normalizing indicators was to allow each of them to vary between zero and one thus allowing them to be analyzed through the pl3v approach the indicators were normalized by assigning upper and lower bounds thus 1 eyrn eyr eyrmin eyrmax eyrmin eyrn being the normalized value eyr the value for the system under study and eyrmin and eyrmax the upper and lower bounds normalization is carried out in an analogous way for elr and ep the upper and lower values are set from the maxima and minima respectively extracted from systems with comparable characteristics found in the literature in this way upper and lower values are restricted to an interval of observed values found for similar systems as real systems can improve their performance over time for any of the criteria adopted here the normalization intervals may be modified in the future literature research on hydropower plants with comparable characteristics provided the threshold values depicted in table 2 since the value of these indicators strongly depends on the hydropower installed capacity this is the characteristic used to restrict the search for threshold values that restriction is taken from zhang et al 2014 who show differences in the emergy indicators according to the installed capacity interval considered based on this evidence the indicators corresponding to small hydropower plants were disregarded having normalized the indicator values it is possible to set values for μ ω λ and to place the point generated for each system under study i e the jupiá and pp plants within the unitary cube the degree of certainty h is calculated to know the proximity with the true state of the premise defined by each set of values μ ω λ the degree of relative sustainability will be greater the closer the point gets to the true state represented by c the true state corresponds to 1 1 0 and represents here a hypothetical state that combines the best three values for eyr ep and elr extracted from the literature and these values will be assigned to the better degree of relative sustainability as defined in section 2 2 for a fixed k that is the minimum value the degree of certainty h should allow us to accept the proposition it is possible to affirm that if h k the point p μ ω λ belongs to the region of the unitary cube where the premise is considered true 5 results and discussion as shown in table 1 the set of emergy indicators adopted to assess sustainability for two hydroelectricity generation plants tassinari et al 2016 provides contradictory information about which system has better performance in terms of sustainability the best performance will correspond to the system that combines the greater eyr and ep with the smaller elr values none of the systems under study show these characteristics since the pp plant has the best performance in terms of eyr but it is worse than jupiá when elr and ep are considered the interpretation of the contradictory information through the point of view of pal3v allows the attribution of the degree of belief and disbelief related to each emergy indicator the attribution of the degree of belief and disbelief is accomplished through the normalization of the emergy indicators and results in the values shown in table 3 for the jupiá and pp plants in this way the contradictory information provided by the emergy indicators can be treated without the necessity of adopting any type of weighting procedure in order to prioritize one indicator over the others normalization allows the translation of the emergy indicators into a unified decision variable within the pal3v framework the proposition on sustainability evaluated is related to the favorable and contrary evidence assumed for the hydropower plants performance each state has the form μ ω λ where μ and λ represent the favorable evidence and ω the contrary evidence comparison of the two plants can be accomplished through the states 0 51 1 0 and 0 67 0 58 0 13 for the jupiá and pp plants respectively which result from translations of the emergy indicators into pal3v as already explained the graphical representation of the states within the unitary cube is depicted in fig 4 we can calculate the degree of certainty as determined by papalardo 2016 for the two plants as follows hjupiá 0 51 1 0 0 1 0 51 and hpp 0 67 0 58 0 13 1 0 12 which represents the proximity to the true logical state the right side of fig 4 shows the localization of both points within the unitary cube through a diagonal viewpoint if k 0 1 is adopted as the level of requirement it is possible to say that both plants are located into the region of acceptable sustainability that is both are viable with 87 85 probability or confidence according to table b1 however if a level of requirement equal to 0 5 is adopted the jupiá sustainability is acceptable whereas the pp sustainability is not acceptable with 97 92 confidence when translating the pal3v results into the emergy framework it is possible to state that the jupiá plant has better performance in sustainability terms the integrating tool proposed in this work allows the selection of the best system that is one that balances the efficient use of resources with a relatively low elr and a relatively high eyr the degree of certainty h can be proposed as a sustainability indicator since it quantifies the degree of adherence of a system to the chosen sustainability criteria of maximizing efficiency of global resource use and eyr while minimizing elr 6 final commentaries when the information extracted from the emergy indicators selected to assess sustainability is contradictory the need to handle decision making using a tool that can deal with contradictory results arises the pal3v proposed by papalardo 2016 offered the possibility of handling three emergy indicators thus allowing comparison of systems and the selection of the one with the best performance based on sustainability or another point of view the degree of certainty h may be seen as a logically supported sustainability composite indicator since it can show which choice is better through evaluating the integration of the efficiency of global resource use the use of relatively less non renewable inputs and less dependence on external resources the usefulness of the proposed procedure can be extended to propositions involving other systems when environmental sustainability is addressed with the same set of emergy indicators discussed here accurate decision making is needed to evaluate future management plans as well as to direct strategic choices for development comparing alternatives or analyzing policy scenarios can be a complex task that gets harder if the information provided by indicators is contradictory or uncertain the integration of pal3v logic as a decision tool with the already successful environmental emergy accounting methods adds transparency ease of reporting and will result in a comprehensive tool that can support decision making when dealing with assessments that contain contradictory results acknowledgments the vice reitoria de pós graduação e pesquisa of paulista university unip is fully acknowledged the authors want to thank prof dr j m abe for the revision of the text concerning paraconsistent logic we are deeply grateful to the anonymous reviewers for the helpful comments and suggestions that have served to improve the work appendix a paraconsistent logic is a non classical logic whose main feature is the revocation of the non contradiction principle of classical logic it emerged from the necessity of handling logically contradictory situations without trivialization of the result da silva filho et al 2010 an introduction to paraconsistent logic is given here to permit the reader to understand the usefulness of this logic and the framework within which the pal3v is composed more information can be obtained elsewhere da costa et al 1991 abe 1992 da silva filho et al 2010 de carvalho and abe 2011 within the pl family paraconsistent annotated logic pal offers the language and structure to properly express the concepts involved in this study pal provides a language to capture the nuances of reality in a more complete way than is possible in classical logic da silva filho et al 2010 it is comprised of atomic propositions each of which is accompanied by an annotation composed of the degree of belief or favorable evidence de carvalho and abe 2011 pal can be represented through a lattice of four vertices that correspond to the extreme logical states true false inconsistent and indeterminate referring to the proposition that will be analyzed da silva filho et al 2010 the annotation can also be composed by a pair being the first element of the pair the favorable evidence and the second element the contrary evidence which negates the proposition de carvalho and abe 2011 so it is possible to achieve a better representation of how much the evidence can express the knowledge about a proposition through paraconsistent annotated logic with two values pal2v if a pair μ λ is used with favorable degree of evidence μ and unfavorable degree of evidence λ de carvalho and abe 2011 the atomic formulas of the language of the logic are of the type p μ λ where p denotes a propositional variable and μ favorable evidence and λ unfavorable or contrary evidence with μ λ belonging to the real cartesian product 0 1 x 0 1 abe 2014 the proposition p μ λ can be intuitively read it is assumed that p s favorable evidence is μ and contrary evidence is λ depending on the applications other terms can be considered instead of evidence such as probability belief etc abe 2014 the values of μ and λ that vary in the interval 0 1 can be plotted in a unitary square on the cartesian plane the four vertices are the points 0 0 0 1 1 0 and 1 1 which correspond to the paracomplete or indeterminate false true and inconsistent or contradictory logical states respectively similarly if there are three attributes each associated to pieces of favorable or unfavorable evidence the analysis will be able to work within the framework of paraconsistent tri annotated logic pal3v presented by papalardo 2016 in this way any proposition p will be expressed as p μ λ ω representing a point within the unitary cube papalardo 2016 four of the eight vertexes of the unitary cube correspond to the priority logical states a b c and d as depicted in fig a1 point c expressed by 1 1 0 is defined as the true state on the contrary point d expressed by 0 0 1 is defined as the false logical state point a expressed by 0 0 0 corresponds to the extreme state of indeterminancy or paracompleteness and point b 1 1 1 represents the extreme state of inconsistency contradiction since the points e f g and h don t represent relevant logic states they will not be analyzed here in this way any proposition p will be expressed with a triple annotation p μ λ ω appendix b 
25132,possibility of shifting nutrients phytoplankton relationship in lakes requires methods with the ability to testify abrupt relationship change to facilitate efficient management bayesian change point model bcpm can handle multiple shifts in coefficients and or in residual errors and therefore suits this requirement we employed bcpms to enhance understanding of the shifting nutrients chlorophyll a chla relationship in yilong lake which has undergone a regime shift from clear state to turbid state we developed four candidate models to simulate nutrients chla relationship model selection results showed the relationship has changed and only one change point exists further research based on the selected model showed that 1 the change point was around the 96th observation 2 nutrients increase did not drive the relationship change 3 total phosphorus tp plays a more important role than total nitrogen on chla increase and 4 nutrients reduction is a better strategy than ecosystem recovery to effectively reduce chla concentration therefore tp reduction should have the priority in yilong lake bcpm is convenient for model selection posterior distribution acquisition and relationship change quantification it could provide critical information for causality deduction these characters make it useful and extendable to explore shifting relationships in ecological field keywords eutrophication regime shift ecosystem recovery nutrient reduction model selection yilong lake 1 introduction eutrophication has become the primary concern for freshwater and marine ecosystems sinha et al 2017 smith and schindler 2009 it leads to the deterioration of water quality changes of ecosystem structure harmful algae blooms and thereby huge economic losses mcdowell and hamilton 2013 paerl and otten 2013 excessive nutrients including phosphorus and nitrogen input is the main driver of eutrophication conley et al 2009 sondergaard et al 2017 to effectively control the eutrophication quantitative nutrients phytoplankton relationship is essential while biomass data is scarce chlorophyll a chla is always treated as a useful indicator of phytoplankton biomass oliver et al 2017 the nutrients chla relationship has been widely used to provide the basis for eutrophication control carneiro et al 2014 stow and cha 2013 xu et al 2017 e g setting nutrients criteria freeman et al 2009 huo et al 2013 lake eutrophication control is a challenging work mccrackin et al 2017 nevertheless unexpected regime shifts from clear state dominated by macrophytes to turbid state with phytoplankton dominance make it more complicated jeppesen et al 2007 scheffer and carpenter 2003 the regime shift impacts on water quality indicators such as the nutrients concentration increase or vegetation disappearance scheffer and nes 2007 are always apparent based on timeseries of monitoring data however whether the nutrients chla relationship has changed or not cannot be determined by visual theoretically the hysteresis of driver response relationship indicates that the relationship changes along with the regime shift andersen et al 2009 however the hysteretic relationship is unfounded in many cases with a regime shift bestelmeyer et al 2011 janssen et al 2017 kong et al 2015 litzow and hunsicker 2016 we need to confirm whether the nutrients chla relationship has changed therefore method capable of testifying the abrupt change of nutrients chla relationship is critical a typical and large class of methods such as iterative methods gröger et al 2011 the regime shift index rodionov and overland 2005 and markov switching vector auto regression models gal and anderson 2010 is to explore the temporal change point of water quality indicator unfortunately the magnitude change of water quality indicator will not lead to relationship change when the driver and the response vary simultaneously following a specific relationship cahill et al 2015 litzow and hunsicker 2016 these methods are thereby unable to reveal the relationship change methods that could give information on relationship change are limited one method is the piecewise regression it is used to identify driver s threshold at which the relationship changes in the ecological field boys et al 2016 ficetola and denoel 2009 another alternative is the bayesian change point model bcpm beckage et al 2007 the bcpm is able to detect the time at which the relationship changes via treating time as an independent variable alameddine et al 2011 while many analyses seek a single change point a more generalized model should allow for multiple shifts in the mean value variance or rate of change capon et al 2015 compared with the piecewise method the bcpm has flexible model structures to detect changes of regression coefficients and or residual variance and to analyze multiple change points beckage et al 2007 chen et al 2011 the bcpm also handles uncertainties of parameters conveniently henneken et al 2013 therefore the bcpm is more suitable for exploring the nutrients chla relationship change previous studies recommended the usage of bcpm in the water resources management hannart and naveau 2009 jo et al 2016 rasmussen 2001 but the application is rare in ecological research in this study we employed the bcpm to enhance understanding of the shifting nutrients chla relationship and took yilong lake as a case as one of the most eutrophic lakes in china yilong lake has undergone a regime shift from clear state to turbid state in 2008 li et al 2015 zhao et al 2013 while the disappearance of vegetation and the increase of total nitrogen tn total phosphorus tp and chla concentrations are apparent it remains unknown whether the nutrients chla relationship has changed as a result of the regime shift we explored the existence of nutrients chla relationship change and tried to give management suggestions we hypothesize that the nutrients chla relationship has changed the hypothesis was supported by the model selection process 1 we built five candidate models including one non change point model and four bcpms to simulate the relationship and 2 the model with one change point performed best indicating the existence of relationship change based on the best model we further analyzed 1 when the relationship change happened 2 whether the nutrients increase drove the relationship change or not and 3 what changes are in the relationship 2 materials and methods the process of using bcpm to enhance our understanding of abrupt nutrients chla relationship is summarized in fig 1 the details of the four steps for model development will be introduced in this part and the results and deductions based on models will be showed in the next part 2 1 study area and data yilong lake 102 30 102 38 e 23 39 23 42 n is located in yun gui plateau southwestern china fig s1 with the average elevation of 1414 m the surface area of 28 4 km2 the maximum volume of 114 9 million m3 the mean depth of 3 9 m and the maximum depth of 5 7 m the lake never freezes with an average water temperature of around 20 c due to the shallow depth and the wind perturbation the waterbody is completely mixed over 133 000 residents live in the watershed and the main industry is agriculture the lake is faced with a severe eutrophication problem the average tn tp and chla concentrations are approximately 3340 μg l 90 μg l and 80 μg l respectively table s1 the lake underwent a rapid regime shift from clear state to turbid state in 2008 the regime shift happened after the ecological fish culture action launched in march 2008 by the local government after the regime shift nutrients and chla concentrations increased a lot fig s2 previous studies have revealed more load release from internal sources is the main cause of the nutrient concentration increase li et al 2015 however whether the nutrients chla relationship has changed or not remains unknown since the eutrophication is the primary water quality problem in yilong lake exploring the nutrients chla relationship change is critical to provide scientific information for the eutrophication control data of tn tp and chla from 1998 to 2013 was collected by the shiping county environmental monitoring center who operated a routine monitoring program of water quality in yilong lake the data can be divided into two parts according to the annual sampling frequency from 1998 to 2003 there are six groups of data every year collected in march april august september november and december from march 2003 to december 2013 monthly data is available 2 2 candidate models both the log log linear liang et al 2018 malve and qian 2006 and sigmoidal relationship filstrup et al 2014 have been used to simulate the nutrients chla relationships in the yilong lake the scatter plots show apparent linear relationships between the log transformed nutrients and chla concentrations fig s3 the log log linear relationship was thereby used to simulate the nutrients chla relationship in this study when there is more than one independent variable we should use the partial correlation analysis to identify the correlation between a certain independent variable and the dependent variable because it can eliminate the effect of the other independent variables and reflects the relationship veritably morrissey et al 2014 a t statistic was established to test the significance of partial correlation coefficients kim 2015 both the partial correlation coefficient of tn and chla and that of tp and chla were significant p 0 001 therefore both nutrients were selected as independent variables to make sure that the model we choose reflects the reality as it is and test the hypothesis we conducted a model selection process the bcpm could identify a change point even if the change point does not actually exist qian 2014 the comparison of the model without any change point and bcpms is required to avoid over confidence in the existence of change points besides we also compared bcpms with different numbers of change point and with interaction item of tn and tp therefore in total five candidate models with different assumptions were developed table 1 for the first candidate model we assumed the regime shift did not lead to the nutrients chla relationship change the nutrients chla relationship is thereby simulated by a linear regression model without any change point cp0 model eq 1 1 ln chl a i n α ln t n i β ln t p i γ σ 2 where the subscript i i 1 2 160 represents the order of observations ln chla ln tn and ln tp are log transformed variables α β γ and σ are the slope of ln tn the slope of ln tp the intercept and the standard deviation of residuals respectively the rest four candidate models were developed by adding change points of nutrients chla relationship under different assumptions first we assumed that the regime shift leads to the relationship change we built a bcpm with one change point cp1 model eqs 2 3 2 ln chl a i n α l i ln t n i β l i ln t p i γ l i σ l i 2 3 l i 1 i f i t 2 i f i t where l i is a categorical variable the value is 1 for pre change point observations and is 2 for post change point observations and t is the change point of time when the nutrients chla relationship changes the change point divides all the parameters into two groups namely before the change point and after the change point the cp1 model can be used to detect any possible change in coefficients and or in residual errors for the cp1 model the interaction between tn and tp were excluded however it is possible that tn and tp could have a certain influence on each other due to their coupling processes cottingham et al 2015 malve and qian 2006 therefore we built a bcpm model with tn and tp interaction item cp1i model eqs 4 3 4 ln chl a i n a l i ln t n i β l i ln t p i δ l i ln t n i ln t p i γ l i σ l i 2 where δ is the regression parameter of interaction item we also assumed that the regime shift and some other event led to the nutrients chla relationship change at different points of time and built a bcpm with two change points cp2 model eqs 2 5 5 l i 1 i f i t 1 2 i f t 1 i t 2 3 i f i t 2 where t 1 and t 2 are change points of time when the nutrients chla relationship changes we also included the two change points model with interaction item as cp2i model eqs 4 5 2 3 parameters estimation we used the markov chain monte carlo mcmc procedure to obtain posterior distributions of parameters including change points regression slope intercept and the standard deviation of residuals for all candidate models the mcmc procedure in winbugs version 1 4 3 lunn et al 2000 was called by r software version 3 2 3 using the r2winbugs package version 2 1 21 sturtz et al 2005 prior distributions were uniform distributions for the change point s following cahill et al 2015 and were non informative distributions for the rest parameters we built three chains with different initial values and ran 200 000 iterations for each chain the first half of iterations were used for the burn in process from the rest 100 000 iterations 1 000 samples were taken as the posterior distribution to reduce the autocorrelation the convergence was assured by the r hat statistic 1 1 gelman and hill 2007 2 4 model selection a reliable criterion for model performance assessment is important to the model selection process piironen and vehtari 2017 for bayesian models deviance information criterion dic is an effective measure based on the deviance penalized by the model complexity which can be expressed as follows spiegelhalter et al 2002 6 dic μ d 2 p d where μ d is the mean deviance over a number of simulations and p d is the effective number of parameters reflecting the fitness and the model complexity respectively dic is a useful criterion for the bayesian model selection hooten and hobbs 2015 and has been used in the comparison of bcpms achcar et al 2010 cha et al 2016 qian and cuffney 2012 therefore we used the dic for model comparison a smaller dic value indicates a better model besides the coefficient of determination r2 was also calculated to estimate the classical goodness of fit of the model bennett et al 2013 the r2 was defined as 1 ssr sst where ssr and sst represent the residual sum of squares and the total sum of squares respectively the purposes of dic and r2 were different the dic values were calculated for model selection while r2 were calculated to ensure the performance of selected model the r2 value generally increases with the increase of the model complexity which is common when comparing candidate models cha et al 2016 however models with higher complexities are susceptible to over fitting therefore r2 is inadequate for model comparison in this case bennett et al 2013 the dic helps avoid the selection of an over fitting model spiegelhalter et al 2002 and thereby avoid the over confidence on the bcpm after that the r2 becomes a good statistic to indicate the goodness of fit of the selected model 3 results and discussion 3 1 has the relationship changed the dic values of candidate models were easily extracted from the model results for the model comparison the cp1 model had the lowest dic value table 2 and was thereby determined as the best model among the candidate models to simulate the nutrients chla relationship in yilong lake while two models have similar dic values the simpler model should be chosen coblentz et al 2017 moreover the interaction terms are very small and their 95 credible intervals covers zero indicating the interactive effect could be neglected table s2 therefore although only a small fraction 4 7 out of 167 5 is different regarding dic between the cp1 model and cp1i model the cp1 model should be chosen this result advocates the adding of one change point but rejects the adding of interaction term or more than one change point we can conclude that the nutrients chla relationship has changed and only one change point exists from the model selection result moreover the high r2 value of the cp1 model 0 857 indicated this model aligned with the reality this sets a solid ground for our further analysis on the time point of the relationship change and the quantification of the relationship change 3 2 when did the relationship change benefitting from the convenience of bayesian parameter estimation ellison 2004 the bcpm allows the uncertainty analysis on the change point the posterior distribution of the change point of the nutrients chla relationship is easily obtained fig 2 the distribution of the change point is well concentrated around the 96th observation the probability of the 96th observation being the change point of the nutrients chla relationship is 71 7 the probability that the change point located at the 95th or 96th observation is as high as 95 0 therefore the change point of the nutrients chla relationship is around the 96th observation with a very high confidence the time of the 96th observation is september 2008 in accordance with the period when the regime shift was observed the vegetation disappearance was also observed around september 2008 zhang et al 2016 besides the fish culture action was launched in march and subsequently triggered the regime shift li et al 2015 the time of the relationship change we identified was shortly after the fish culture action considering the simultaneous occurrence of the relationship change and the regime shift the regime shift is very likely to result in the relationship change 3 3 did the nutrients increase drive the relationship change the increase of nutrients is the most common driver for regime shift in lakes capon et al 2015 scheffer and carpenter 2003 but whether nutrients increase drove the relationship change in yilong lake remained unknown we explored this by comparing the time points of relationship change and nutrients increase we identified the change points for nutrients increase following a similar process as that of exploring relationship change 1 first we built candidate models for tn and tp concentrations and 2 through a model selection process we confirmed the change points for tn and tp concentrations please refer to appendix a in the supplementary materials for details we detected two points of abrupt increase for tp concentration and one for tn concentration the first abrupt increase of tp concentration happened around the 64th observation fig 3 a and the second one happened around the 106th observation fig 3b the increase of tn happened around the 104th observation fig 3c all the three change points were well concentrated with small variation the first abrupt increase in tp concentration happened 32 months ahead of the relationship change located around the 96th observations obviously it could not drive the shifting of nutrients chla relationship the second change point for tp concentration and the change point for tn concentration lagged behind the change point of nutrients chla relationship by about 9 months fig 3b c we can thereby conclude that they were not the driver for this shifting relationship as well the top down process might provide an explanation on the relationship change the effects of fish culture such as the sharp zooplanktons reduce wei and tang 2014 and the vegetation disappeared zhao et al 2013 are favorable for the phytoplankton growth more data is required to confirm it which is out of the scope of this study we generally hold the belief that statistical methods could only reveal correlation but not the underlying causal mechanism filatova et al 2016 however by identifying the sequence of different events we could give certain evidence on determining whether one event drives another therefore the bcpm may help determine causality by providing information on change point sequences of different events 3 4 what are changes in the relationship exploring changes in the relationship is important to understand the regime shift impacts on the nutrients chla relationship parameters estimation results of the cp1 model were summarized in table s2 in the cp1 model possible changes of four parameters are allowed namely the slope of ln tn the slope of ln tp the intercept and the residual deviation as the log log linear regression model is used both before and after the change point interpretations of parameters are the same that is α and β are the percent change in chla concentration with per 1 change in tn and tp concentration qian 2016 the slope of ln tn decreases a lot fig 4 a the average is 1 00 every 1 increase in tn would lead to a 1 00 increase in chla before the change point and is 0 41 after the change point for the slope of ln tp the average increases from 0 67 to 0 79 fig 4b these changes suggest a decreased effect of tn on chla and a reversal effect change for tp the intercept γ representing the baseline chla concentration the average ln chla when tp and tn concentrations are both 1 μg l increases a lot after the change point fig 4c the standard deviation of residuals decreases from 0 45 to 0 33 fig 4d indicating the prediction accuracy improves after the change point while estimated parameters of the cp1 model can reveal the change of a certain nutrient effect they cannot directly reflect the relative importance of tn and tp due to their variance difference fortunately the slopes are comparable after dividing the input variables by their sample standard deviations and these slopes are called as standardized slopes schielzeth 2010 in the bcpm case the sample standard deviations might be different before and after the change point therefore we used the estimated average slopes of the cp1 model multiple by corresponding sample standard deviations of input variables to obtain standardized slopes the results showed that before the change point standardized slopes of ln tn and ln tp had a small difference table 3 indicating the two nutrients had similar effects on chla however the standardized slope of ln tp is much larger than that of ln tn after the change point table 3 therefore tp has a relative higher effect than tn in the current turbid state the contour map fig s4 of nutrients chla also supported this results please refer to appendix a in the supplementary materials for details according to the parameters estimation results of the cp1 model we can obtain the predicted chla concentrations before and after the change point under the corresponding average tn and tp concentrations the average chla concentrations are 30 μg l and 157 μg l point a and c in fig 5 before and after the change point respectively because the regime shift happened when the nutrients concentrations were low the path a c could be decomposed into two parts the first part was the relationship change under low nutrients concentrations a b and the chla concentration increased from 30 μg l to 54 μg l the second part was the nutrients increase after the change point b c with the chla concentration increased to 157 μg l obviously the relationship change contributes smaller than the nutrients increase to the chla concentration increase since the yilong lake is under turbid state and is facing severe eutrophication problem a proper strategy to control the eutrophication is critical generally eutrophication control actions could be categorized into two kinds one is the ecosystem recovery such as biomanipulation lindegren et al 2010 triest et al 2016 the other one is nutrients concentration reduction such as reducing internal nutrients loadings zamparas and zacharias 2014 they take effect in two different ways one tries to alter the nutrients phytoplankton relationship while the other one reduces nutrients concentration elmgren et al 2015 hagerthey et al 2014 the bcpm helps us to select a better strategy in the current state of yilong lake if the ecosystem recovery actions are conducted successfully the chla would decrease to 122 μg l point d in fig 5 if the nutrients concentrations are reduced to the average level before the change point the chla would be 54 μg l point b in fig 5 therefore the nutrients reduction is a better strategy than ecosystem recovery since we have deduced that tp plays a more important role we recommend tp reduction should be considered in priority to effectively reduce the chla concentration 4 conclusions 1 the usage of bcpm has enhanced our understanding of the shifting nutrients chla relationship in yilong lake the model selection result supported our hypothesis that the nutrients chla relationship has changed this change happened around september 2008 although nutrients concentration increases are apparent they are not drivers of the relationship change in the current state nutrients reduction is a better strategy than ecosystem recovery moreover tp reduction will result in more decrease in chla concentration compared to tn reduction therefore tp reduction should be considered in priority for eutrophication control in yilong lake 2 our case study in yilong lake advocates further applications of the bcpm for several advantages the model selection which could be used to testify the abrupt change of the relationship is easy to conduct the bcpm can also give useful information on posterior distribution of the change point the location and uncertainty of this time point is thereby easily obtained the bcpm allows any possible changes in coefficients and or in residual errors the quantitative comparison of the relationship before and after the shift is convenient to conduct besides the bcpm may help causality deduction by providing information on change point sequences of different events in conclusion we argue that the bcpm is extremely useful and extendable to enhance understanding of shifting relationship in the ecological field note that in our case the change point obtained based on bcpm only describes a crossing point of the hysteresis trace in the future novel methods are required to draw complete phase diagram for predictive purpose acknowledgments we thank two reviewers the associate editor and the editor for their kind reviews and comments that improved the final manuscript this paper was supported by the national basic research program 973 of china no 2015cb458900 the national natural science foundation of china no 51779002 and high performance computing platform of peking university appendix a supplementary data supplementary material related to this article can be found in the online version at doi https doi org 10 1016 j ecolmodel 2018 12 008 appendix a supplementary data the following is supplementary data to this article 
25132,possibility of shifting nutrients phytoplankton relationship in lakes requires methods with the ability to testify abrupt relationship change to facilitate efficient management bayesian change point model bcpm can handle multiple shifts in coefficients and or in residual errors and therefore suits this requirement we employed bcpms to enhance understanding of the shifting nutrients chlorophyll a chla relationship in yilong lake which has undergone a regime shift from clear state to turbid state we developed four candidate models to simulate nutrients chla relationship model selection results showed the relationship has changed and only one change point exists further research based on the selected model showed that 1 the change point was around the 96th observation 2 nutrients increase did not drive the relationship change 3 total phosphorus tp plays a more important role than total nitrogen on chla increase and 4 nutrients reduction is a better strategy than ecosystem recovery to effectively reduce chla concentration therefore tp reduction should have the priority in yilong lake bcpm is convenient for model selection posterior distribution acquisition and relationship change quantification it could provide critical information for causality deduction these characters make it useful and extendable to explore shifting relationships in ecological field keywords eutrophication regime shift ecosystem recovery nutrient reduction model selection yilong lake 1 introduction eutrophication has become the primary concern for freshwater and marine ecosystems sinha et al 2017 smith and schindler 2009 it leads to the deterioration of water quality changes of ecosystem structure harmful algae blooms and thereby huge economic losses mcdowell and hamilton 2013 paerl and otten 2013 excessive nutrients including phosphorus and nitrogen input is the main driver of eutrophication conley et al 2009 sondergaard et al 2017 to effectively control the eutrophication quantitative nutrients phytoplankton relationship is essential while biomass data is scarce chlorophyll a chla is always treated as a useful indicator of phytoplankton biomass oliver et al 2017 the nutrients chla relationship has been widely used to provide the basis for eutrophication control carneiro et al 2014 stow and cha 2013 xu et al 2017 e g setting nutrients criteria freeman et al 2009 huo et al 2013 lake eutrophication control is a challenging work mccrackin et al 2017 nevertheless unexpected regime shifts from clear state dominated by macrophytes to turbid state with phytoplankton dominance make it more complicated jeppesen et al 2007 scheffer and carpenter 2003 the regime shift impacts on water quality indicators such as the nutrients concentration increase or vegetation disappearance scheffer and nes 2007 are always apparent based on timeseries of monitoring data however whether the nutrients chla relationship has changed or not cannot be determined by visual theoretically the hysteresis of driver response relationship indicates that the relationship changes along with the regime shift andersen et al 2009 however the hysteretic relationship is unfounded in many cases with a regime shift bestelmeyer et al 2011 janssen et al 2017 kong et al 2015 litzow and hunsicker 2016 we need to confirm whether the nutrients chla relationship has changed therefore method capable of testifying the abrupt change of nutrients chla relationship is critical a typical and large class of methods such as iterative methods gröger et al 2011 the regime shift index rodionov and overland 2005 and markov switching vector auto regression models gal and anderson 2010 is to explore the temporal change point of water quality indicator unfortunately the magnitude change of water quality indicator will not lead to relationship change when the driver and the response vary simultaneously following a specific relationship cahill et al 2015 litzow and hunsicker 2016 these methods are thereby unable to reveal the relationship change methods that could give information on relationship change are limited one method is the piecewise regression it is used to identify driver s threshold at which the relationship changes in the ecological field boys et al 2016 ficetola and denoel 2009 another alternative is the bayesian change point model bcpm beckage et al 2007 the bcpm is able to detect the time at which the relationship changes via treating time as an independent variable alameddine et al 2011 while many analyses seek a single change point a more generalized model should allow for multiple shifts in the mean value variance or rate of change capon et al 2015 compared with the piecewise method the bcpm has flexible model structures to detect changes of regression coefficients and or residual variance and to analyze multiple change points beckage et al 2007 chen et al 2011 the bcpm also handles uncertainties of parameters conveniently henneken et al 2013 therefore the bcpm is more suitable for exploring the nutrients chla relationship change previous studies recommended the usage of bcpm in the water resources management hannart and naveau 2009 jo et al 2016 rasmussen 2001 but the application is rare in ecological research in this study we employed the bcpm to enhance understanding of the shifting nutrients chla relationship and took yilong lake as a case as one of the most eutrophic lakes in china yilong lake has undergone a regime shift from clear state to turbid state in 2008 li et al 2015 zhao et al 2013 while the disappearance of vegetation and the increase of total nitrogen tn total phosphorus tp and chla concentrations are apparent it remains unknown whether the nutrients chla relationship has changed as a result of the regime shift we explored the existence of nutrients chla relationship change and tried to give management suggestions we hypothesize that the nutrients chla relationship has changed the hypothesis was supported by the model selection process 1 we built five candidate models including one non change point model and four bcpms to simulate the relationship and 2 the model with one change point performed best indicating the existence of relationship change based on the best model we further analyzed 1 when the relationship change happened 2 whether the nutrients increase drove the relationship change or not and 3 what changes are in the relationship 2 materials and methods the process of using bcpm to enhance our understanding of abrupt nutrients chla relationship is summarized in fig 1 the details of the four steps for model development will be introduced in this part and the results and deductions based on models will be showed in the next part 2 1 study area and data yilong lake 102 30 102 38 e 23 39 23 42 n is located in yun gui plateau southwestern china fig s1 with the average elevation of 1414 m the surface area of 28 4 km2 the maximum volume of 114 9 million m3 the mean depth of 3 9 m and the maximum depth of 5 7 m the lake never freezes with an average water temperature of around 20 c due to the shallow depth and the wind perturbation the waterbody is completely mixed over 133 000 residents live in the watershed and the main industry is agriculture the lake is faced with a severe eutrophication problem the average tn tp and chla concentrations are approximately 3340 μg l 90 μg l and 80 μg l respectively table s1 the lake underwent a rapid regime shift from clear state to turbid state in 2008 the regime shift happened after the ecological fish culture action launched in march 2008 by the local government after the regime shift nutrients and chla concentrations increased a lot fig s2 previous studies have revealed more load release from internal sources is the main cause of the nutrient concentration increase li et al 2015 however whether the nutrients chla relationship has changed or not remains unknown since the eutrophication is the primary water quality problem in yilong lake exploring the nutrients chla relationship change is critical to provide scientific information for the eutrophication control data of tn tp and chla from 1998 to 2013 was collected by the shiping county environmental monitoring center who operated a routine monitoring program of water quality in yilong lake the data can be divided into two parts according to the annual sampling frequency from 1998 to 2003 there are six groups of data every year collected in march april august september november and december from march 2003 to december 2013 monthly data is available 2 2 candidate models both the log log linear liang et al 2018 malve and qian 2006 and sigmoidal relationship filstrup et al 2014 have been used to simulate the nutrients chla relationships in the yilong lake the scatter plots show apparent linear relationships between the log transformed nutrients and chla concentrations fig s3 the log log linear relationship was thereby used to simulate the nutrients chla relationship in this study when there is more than one independent variable we should use the partial correlation analysis to identify the correlation between a certain independent variable and the dependent variable because it can eliminate the effect of the other independent variables and reflects the relationship veritably morrissey et al 2014 a t statistic was established to test the significance of partial correlation coefficients kim 2015 both the partial correlation coefficient of tn and chla and that of tp and chla were significant p 0 001 therefore both nutrients were selected as independent variables to make sure that the model we choose reflects the reality as it is and test the hypothesis we conducted a model selection process the bcpm could identify a change point even if the change point does not actually exist qian 2014 the comparison of the model without any change point and bcpms is required to avoid over confidence in the existence of change points besides we also compared bcpms with different numbers of change point and with interaction item of tn and tp therefore in total five candidate models with different assumptions were developed table 1 for the first candidate model we assumed the regime shift did not lead to the nutrients chla relationship change the nutrients chla relationship is thereby simulated by a linear regression model without any change point cp0 model eq 1 1 ln chl a i n α ln t n i β ln t p i γ σ 2 where the subscript i i 1 2 160 represents the order of observations ln chla ln tn and ln tp are log transformed variables α β γ and σ are the slope of ln tn the slope of ln tp the intercept and the standard deviation of residuals respectively the rest four candidate models were developed by adding change points of nutrients chla relationship under different assumptions first we assumed that the regime shift leads to the relationship change we built a bcpm with one change point cp1 model eqs 2 3 2 ln chl a i n α l i ln t n i β l i ln t p i γ l i σ l i 2 3 l i 1 i f i t 2 i f i t where l i is a categorical variable the value is 1 for pre change point observations and is 2 for post change point observations and t is the change point of time when the nutrients chla relationship changes the change point divides all the parameters into two groups namely before the change point and after the change point the cp1 model can be used to detect any possible change in coefficients and or in residual errors for the cp1 model the interaction between tn and tp were excluded however it is possible that tn and tp could have a certain influence on each other due to their coupling processes cottingham et al 2015 malve and qian 2006 therefore we built a bcpm model with tn and tp interaction item cp1i model eqs 4 3 4 ln chl a i n a l i ln t n i β l i ln t p i δ l i ln t n i ln t p i γ l i σ l i 2 where δ is the regression parameter of interaction item we also assumed that the regime shift and some other event led to the nutrients chla relationship change at different points of time and built a bcpm with two change points cp2 model eqs 2 5 5 l i 1 i f i t 1 2 i f t 1 i t 2 3 i f i t 2 where t 1 and t 2 are change points of time when the nutrients chla relationship changes we also included the two change points model with interaction item as cp2i model eqs 4 5 2 3 parameters estimation we used the markov chain monte carlo mcmc procedure to obtain posterior distributions of parameters including change points regression slope intercept and the standard deviation of residuals for all candidate models the mcmc procedure in winbugs version 1 4 3 lunn et al 2000 was called by r software version 3 2 3 using the r2winbugs package version 2 1 21 sturtz et al 2005 prior distributions were uniform distributions for the change point s following cahill et al 2015 and were non informative distributions for the rest parameters we built three chains with different initial values and ran 200 000 iterations for each chain the first half of iterations were used for the burn in process from the rest 100 000 iterations 1 000 samples were taken as the posterior distribution to reduce the autocorrelation the convergence was assured by the r hat statistic 1 1 gelman and hill 2007 2 4 model selection a reliable criterion for model performance assessment is important to the model selection process piironen and vehtari 2017 for bayesian models deviance information criterion dic is an effective measure based on the deviance penalized by the model complexity which can be expressed as follows spiegelhalter et al 2002 6 dic μ d 2 p d where μ d is the mean deviance over a number of simulations and p d is the effective number of parameters reflecting the fitness and the model complexity respectively dic is a useful criterion for the bayesian model selection hooten and hobbs 2015 and has been used in the comparison of bcpms achcar et al 2010 cha et al 2016 qian and cuffney 2012 therefore we used the dic for model comparison a smaller dic value indicates a better model besides the coefficient of determination r2 was also calculated to estimate the classical goodness of fit of the model bennett et al 2013 the r2 was defined as 1 ssr sst where ssr and sst represent the residual sum of squares and the total sum of squares respectively the purposes of dic and r2 were different the dic values were calculated for model selection while r2 were calculated to ensure the performance of selected model the r2 value generally increases with the increase of the model complexity which is common when comparing candidate models cha et al 2016 however models with higher complexities are susceptible to over fitting therefore r2 is inadequate for model comparison in this case bennett et al 2013 the dic helps avoid the selection of an over fitting model spiegelhalter et al 2002 and thereby avoid the over confidence on the bcpm after that the r2 becomes a good statistic to indicate the goodness of fit of the selected model 3 results and discussion 3 1 has the relationship changed the dic values of candidate models were easily extracted from the model results for the model comparison the cp1 model had the lowest dic value table 2 and was thereby determined as the best model among the candidate models to simulate the nutrients chla relationship in yilong lake while two models have similar dic values the simpler model should be chosen coblentz et al 2017 moreover the interaction terms are very small and their 95 credible intervals covers zero indicating the interactive effect could be neglected table s2 therefore although only a small fraction 4 7 out of 167 5 is different regarding dic between the cp1 model and cp1i model the cp1 model should be chosen this result advocates the adding of one change point but rejects the adding of interaction term or more than one change point we can conclude that the nutrients chla relationship has changed and only one change point exists from the model selection result moreover the high r2 value of the cp1 model 0 857 indicated this model aligned with the reality this sets a solid ground for our further analysis on the time point of the relationship change and the quantification of the relationship change 3 2 when did the relationship change benefitting from the convenience of bayesian parameter estimation ellison 2004 the bcpm allows the uncertainty analysis on the change point the posterior distribution of the change point of the nutrients chla relationship is easily obtained fig 2 the distribution of the change point is well concentrated around the 96th observation the probability of the 96th observation being the change point of the nutrients chla relationship is 71 7 the probability that the change point located at the 95th or 96th observation is as high as 95 0 therefore the change point of the nutrients chla relationship is around the 96th observation with a very high confidence the time of the 96th observation is september 2008 in accordance with the period when the regime shift was observed the vegetation disappearance was also observed around september 2008 zhang et al 2016 besides the fish culture action was launched in march and subsequently triggered the regime shift li et al 2015 the time of the relationship change we identified was shortly after the fish culture action considering the simultaneous occurrence of the relationship change and the regime shift the regime shift is very likely to result in the relationship change 3 3 did the nutrients increase drive the relationship change the increase of nutrients is the most common driver for regime shift in lakes capon et al 2015 scheffer and carpenter 2003 but whether nutrients increase drove the relationship change in yilong lake remained unknown we explored this by comparing the time points of relationship change and nutrients increase we identified the change points for nutrients increase following a similar process as that of exploring relationship change 1 first we built candidate models for tn and tp concentrations and 2 through a model selection process we confirmed the change points for tn and tp concentrations please refer to appendix a in the supplementary materials for details we detected two points of abrupt increase for tp concentration and one for tn concentration the first abrupt increase of tp concentration happened around the 64th observation fig 3 a and the second one happened around the 106th observation fig 3b the increase of tn happened around the 104th observation fig 3c all the three change points were well concentrated with small variation the first abrupt increase in tp concentration happened 32 months ahead of the relationship change located around the 96th observations obviously it could not drive the shifting of nutrients chla relationship the second change point for tp concentration and the change point for tn concentration lagged behind the change point of nutrients chla relationship by about 9 months fig 3b c we can thereby conclude that they were not the driver for this shifting relationship as well the top down process might provide an explanation on the relationship change the effects of fish culture such as the sharp zooplanktons reduce wei and tang 2014 and the vegetation disappeared zhao et al 2013 are favorable for the phytoplankton growth more data is required to confirm it which is out of the scope of this study we generally hold the belief that statistical methods could only reveal correlation but not the underlying causal mechanism filatova et al 2016 however by identifying the sequence of different events we could give certain evidence on determining whether one event drives another therefore the bcpm may help determine causality by providing information on change point sequences of different events 3 4 what are changes in the relationship exploring changes in the relationship is important to understand the regime shift impacts on the nutrients chla relationship parameters estimation results of the cp1 model were summarized in table s2 in the cp1 model possible changes of four parameters are allowed namely the slope of ln tn the slope of ln tp the intercept and the residual deviation as the log log linear regression model is used both before and after the change point interpretations of parameters are the same that is α and β are the percent change in chla concentration with per 1 change in tn and tp concentration qian 2016 the slope of ln tn decreases a lot fig 4 a the average is 1 00 every 1 increase in tn would lead to a 1 00 increase in chla before the change point and is 0 41 after the change point for the slope of ln tp the average increases from 0 67 to 0 79 fig 4b these changes suggest a decreased effect of tn on chla and a reversal effect change for tp the intercept γ representing the baseline chla concentration the average ln chla when tp and tn concentrations are both 1 μg l increases a lot after the change point fig 4c the standard deviation of residuals decreases from 0 45 to 0 33 fig 4d indicating the prediction accuracy improves after the change point while estimated parameters of the cp1 model can reveal the change of a certain nutrient effect they cannot directly reflect the relative importance of tn and tp due to their variance difference fortunately the slopes are comparable after dividing the input variables by their sample standard deviations and these slopes are called as standardized slopes schielzeth 2010 in the bcpm case the sample standard deviations might be different before and after the change point therefore we used the estimated average slopes of the cp1 model multiple by corresponding sample standard deviations of input variables to obtain standardized slopes the results showed that before the change point standardized slopes of ln tn and ln tp had a small difference table 3 indicating the two nutrients had similar effects on chla however the standardized slope of ln tp is much larger than that of ln tn after the change point table 3 therefore tp has a relative higher effect than tn in the current turbid state the contour map fig s4 of nutrients chla also supported this results please refer to appendix a in the supplementary materials for details according to the parameters estimation results of the cp1 model we can obtain the predicted chla concentrations before and after the change point under the corresponding average tn and tp concentrations the average chla concentrations are 30 μg l and 157 μg l point a and c in fig 5 before and after the change point respectively because the regime shift happened when the nutrients concentrations were low the path a c could be decomposed into two parts the first part was the relationship change under low nutrients concentrations a b and the chla concentration increased from 30 μg l to 54 μg l the second part was the nutrients increase after the change point b c with the chla concentration increased to 157 μg l obviously the relationship change contributes smaller than the nutrients increase to the chla concentration increase since the yilong lake is under turbid state and is facing severe eutrophication problem a proper strategy to control the eutrophication is critical generally eutrophication control actions could be categorized into two kinds one is the ecosystem recovery such as biomanipulation lindegren et al 2010 triest et al 2016 the other one is nutrients concentration reduction such as reducing internal nutrients loadings zamparas and zacharias 2014 they take effect in two different ways one tries to alter the nutrients phytoplankton relationship while the other one reduces nutrients concentration elmgren et al 2015 hagerthey et al 2014 the bcpm helps us to select a better strategy in the current state of yilong lake if the ecosystem recovery actions are conducted successfully the chla would decrease to 122 μg l point d in fig 5 if the nutrients concentrations are reduced to the average level before the change point the chla would be 54 μg l point b in fig 5 therefore the nutrients reduction is a better strategy than ecosystem recovery since we have deduced that tp plays a more important role we recommend tp reduction should be considered in priority to effectively reduce the chla concentration 4 conclusions 1 the usage of bcpm has enhanced our understanding of the shifting nutrients chla relationship in yilong lake the model selection result supported our hypothesis that the nutrients chla relationship has changed this change happened around september 2008 although nutrients concentration increases are apparent they are not drivers of the relationship change in the current state nutrients reduction is a better strategy than ecosystem recovery moreover tp reduction will result in more decrease in chla concentration compared to tn reduction therefore tp reduction should be considered in priority for eutrophication control in yilong lake 2 our case study in yilong lake advocates further applications of the bcpm for several advantages the model selection which could be used to testify the abrupt change of the relationship is easy to conduct the bcpm can also give useful information on posterior distribution of the change point the location and uncertainty of this time point is thereby easily obtained the bcpm allows any possible changes in coefficients and or in residual errors the quantitative comparison of the relationship before and after the shift is convenient to conduct besides the bcpm may help causality deduction by providing information on change point sequences of different events in conclusion we argue that the bcpm is extremely useful and extendable to enhance understanding of shifting relationship in the ecological field note that in our case the change point obtained based on bcpm only describes a crossing point of the hysteresis trace in the future novel methods are required to draw complete phase diagram for predictive purpose acknowledgments we thank two reviewers the associate editor and the editor for their kind reviews and comments that improved the final manuscript this paper was supported by the national basic research program 973 of china no 2015cb458900 the national natural science foundation of china no 51779002 and high performance computing platform of peking university appendix a supplementary data supplementary material related to this article can be found in the online version at doi https doi org 10 1016 j ecolmodel 2018 12 008 appendix a supplementary data the following is supplementary data to this article 
25133,there is an increasing need for an assessment of the impacts of land use and land use change lucc in this context simulation models are valuable tools for investigating the impacts of stakeholder actions or policy decisions agricultural landscape generators algs which systematically and automatically generate realistic but simplified representations of land cover in agricultural landscapes can provide the input for lucc models we reviewed existing algs in terms of their objectives design and scope we found eight algs that met our definition they were based either on generic mathematical algorithms pattern based or on representations of ecological or land use processes process based most algs integrate only a few landscape metrics which limits the design of the landscape pattern and thus the range of applications for example only a few specific farming systems have been implemented we conclude that existing algs contain useful approaches that can be used for specific purposes but ideally generic modular algs are developed that can be used for a wide range of scenarios regions and model types we have compiled features of such generic algs and propose a possible software architecture considerable joint efforts are required to develop such generic algs but the benefits in terms of a better understanding and development of more efficient agricultural policies would be high keywords agricultural landscape field pattern agricultural landscape generator landscape simulator neutral landscape model process based model 1 introduction in response to climate change a growing human population and globalisation land use and land cover are changing at unprecedented rates understanding and predicting these changes and their consequences for biodiversity and ecosystem services are among the grand challenges of ecological and environmental research for intensively used agricultural landscapes for example in europe key questions include how spatio temporal patterns in land cover are affected by national and eu policies or by the global market and how in turn they are affecting ecosystem services and biodiversity empirical approaches to meeting these challenges are limited because of the scale dependency and the multitude of factors involved simulation models on land use and land cover change lucc are therefore widely and increasingly developed to back and forecast landscape changes lambin et al 2000 agarwal et al 2002 parker et al 2003 heistermann et al 2006 such simulation models if they are sufficiently realistic allow us to generate scenarios and to rigorously explore by using mathematics and computer logics the consequences of stakeholder actions or political decisions e g johst et al 2015 however when using spatially explicit simulation models for this purpose there is a dilemma when it comes to representing land cover in agricultural landscapes on the one hand such land cover maps can be taken from maps from geographical information systems gis while such input implies high realism and significance for regional case studies e g wätzold et al 2016 general insights and transferability to other regions or questions are limited a single map does not allow us to systematically vary the features of a landscape even if we contrast different real landscapes we only obtain snapshots of possible relationships which are likely to be nonlinear moreover the creation of such detailed maps is time consuming as it often requires manual data processing parameterisation and calibration on the other hand an unlimited number of virtual landscapes can be generated using algorithms that systematically and automatically vary landscape metrics such as percentage cover fragmentation or spatial autocorrelation gardner et al 1987 gardner 1999 saura and martínez millán 2000 hiebeler 2007 cambui et al 2014 using these virtual landscapes as input models can provide insights into the consequences of changing landscape features and help to formulate test and validate hypotheses gardner and urban 2007 however such landscapes are usually difficult to relate to real landscapes such that it remains unclear what we have learned about the real world the alternative to these abstract landscapes is landscape generators which generate virtual but structurally realistic maps of land cover by trying to combine both realism and the option to vary landscape features the generators create variations of artificial agricultural land cover mosaics at the spatial resolution of individual fields for a given set of parameters to be classified as a generator we here require that they allow for varying features of the generated landscapes in a systematic and automated way changes in agricultural landscapes and their ecological consequences occur at small scales houet et al 2010 e g the variation of the field mosaic and the implementation of crop rotations or policy measures at the farm level there is thus a need for high resolution spatial simulation models and corresponding tools that are capable of generating artificial land cover maps at high resolution under a predefined parameter set still limited research has been done in the field and few such landscape generators have been developed so far these generators define agricultural landscapes as a mosaic of land use patches fields and landscape elements e g hedges landscape features that are typically varied are composition type and proportion of land cover and landscape configuration spatial arrangement of the land covers the distributions of these features can be taken from distributions observed in real landscapes such that insights gained from the model are relevant for e g analysing ecological processes or exploring the consequences of eu policy instruments such as the greening of farming e g langhammer et al 2017 or agri environment schemes e g sturm et al 2018 so far no common term has been established for this type of landscape generator therefore we here suggest referring to them as agricultural landscape generators algs and use it in the following as a generic term algs are computer programs that generate structurally realistic but simplified artificial representations of agricultural landscapes i e maps of land cover both the landscape configuration field mosaic and the landscape composition land cover are variable we nevertheless refer to them as generators to emphasise that they are not used for simulations by themselves and do not display temporal and spatial dynamics the output of algs is a map that can be used as input for lucc models or other model types algs can still represent change over time by producing a series of consecutive maps algs are either implemented as stand alone programs or as sub models within lucc models the approaches to generating landscapes can be distinguished into two main categories pattern based and process based pattern based generators also known as neutral landscape models are based on generic algorithms and produce virtual landscapes regardless of the underlying ecological or social processes gardner et al 1987 with and king 1997 they work with one or more characteristics of composition and configuration of a landscape regarding complexity they range from pure neutral models to more realistic models in terms of landscape structure johnson et al 1999 gaucherel et al 2014 the resulting landscapes are mostly pixel matrices with each pixel representing a spatial unit assigned to a certain land cover class so far neutral landscape models have been used primarily in the research field of forest and landscape ecology but rarely for agricultural landscapes the coupling of neutral landscapes with population models allows species perceptions of landscape configuration e g habitat fragmentation and landscape connectivity to be addressed with 1997 process based generators also known as mechanistic models produce landscape patterns as a result of ecological or socio economic processes that are explicitly integrated into the model jackson et al 2000 cuddington et al 2013 the result of these generators is also a static map to be used as input for dynamic simulation models process based in this context means that the mechanisms leading to a certain landscape pattern can be explicitly addressed an example is dinamica filho et al 2002 such generators are based on a theoretical understanding or hypotheses of the relevant processes that cause landscape patterns and they are helpful in determining how real agricultural landscapes and their dynamics emerge the resulting landscapes allow more explicitly stated hypotheses and can be used as the basis for addressing specific questions e g pattern process interaction schröder and seppelt 2006 land use change prediction the fate of specific species or of biodiversity in general and effects on ecosystem functioning and resilience in this review we examine existing algs that are able to automatically generate an agricultural landscape with given features our two main motivations are as follows 1 there is an increasing need to evaluate the driving forces behind and the extent and consequences of land use and land cover change recent eu policies for example aim at increasing biodiversity by requiring environmentally friendly farming practices the so called greening of farming european commission regulation eu no 1307 2013 whether or not such policies will in fact increase biodiversity is an open question pe er et al 2014 the usefulness of such policies requieres two things a realistic simulation model and realistic landscape where both different eco regions and policies can be represented in the case of honeybees the model beehave becher et al 2014 is such a model and so far only the software tool nepofarm horn 2017 exists that takes the structure of a given landscape important from gis implements different crop diversity and rotation scenarios and then explores how different greening measures such as flower strips affect the resilience and persistence of honeybee colonies with a kind of generic alg one could also vary the structure of the landscape for example regions with mostly small or large fields or landscapes with and without semi natural habitat or hedges the same landscapes could then also be used for exploring the performance of bumblebees becher et al 2018 wild bees everaars et al 2018 or completely different taxa where other landscape features might be important 2 our second interest is in finding the main features and criteria of generic software tools that could generate agricultural landscapes with more comprehensive and variable configuration and composition by using a modular design the landscapes generated by such generic alg could be used as input for any specific lucc model addressing specific questions this would generate coherence and synergies across individual studies that currently do not exist 2 methods because there is no consistent term for agricultural landscape generators so far in our literature search we used the following search terms ecological model and crop and landscape landscape model and crop landscape model and neutral landscape generat and crop landscape generat and neutral landscape simulat and crop and finally landscape simulat and neutral using these terms in web of science clarivate analytics led to 186 publications that cover a broad range of approaches aspects of agricultural landscape simulations and fields of application the most important selection criterion for including an alg approach in our review was the user defined automatic generation of agricultural land cover patterns which can serve as a input for dynamic simulation models we excluded landscape generators that do not encompass any characteristics of agricultural landscapes or did not include the land use type agriculture we also did not include geographical information system gis models remote sensing land use and land cover change lucc models and agent based land use models abms lambin et al 2000 agarwal et al 2002 schulze et al 2017 although they too allow landscape maps to be altered firstly these models usually work with real landscapes and data and secondly landscape changes in composition and configuration are mostly based on the outcome of decision models and not on automated procedures which were mandatory according to our definition of a landscape generator we examined the following features of the algs the specific aims the method of landscape generation in terms of configuration and composition the validation the application regarding policy measures and the software availability regarding landscape composition we analysed which method for crop generation and allocation of crops to the fields has been applied the more complex an alg is the more compositional details can be varied such as crop types fringe structures and other land use types we explored which of them have been implemented so far in the context of specific case studies we also compiled a brief overview of existing additional software tools that allow crop rotation to be implemented for a given landscape configuration moreover because it is important for allowing the exploration of ecological questions in agricultural landscapes we examined whether natural and semi natural habitats were included the same applies to the coupling with ecological population models to allow the analysis of landscape effects on species because enormous potential of agricultural landscape simulations lies in the evaluation of management and policy measures we investigated whether and how such scenario analyses were carried out finally programming language software application documentation and availability of the models were determined based on these findings we finally derived and outlined the requirements for generic algs in particular we wanted to identify which landscape features are essential or optional for user friendly agricultural landscape generation and which conclusions can be drawn for the model and software architecture 3 results 3 1 existing algs the list of publications containing solutions for generating such agricultural landscapes was short fig 1 we identified ten relevant peer reviewed articles published between 2006 and 2017 these ten publications relate to a total of seven alg approaches as several landscape generators were described or applied in more than one publication we added four more relevant publications describing one of the selected alg approaches more precisely to display even more possibilities we added the non isi listed scottish natural heritage commissioned report no 692 begg and dye 2015 describing another alg approach altogether we found eight alg approaches an overview of the reviewed alg approaches is given in table 1 and fig 2 the approaches differ widely in their method of landscape generation and agricultural details therefore it was difficult to give an integrated and structured overview and to derive general concepts to emphasise and better compare the range of existing approaches for each feature we present our results feature by feature not model by model nevertheless table 2 provides an overview of the reviewed algs the algs presented here have mainly been published within the last 10 years table a1 this makes it a young field of research with few approaches so far and most of them are described and or applied in a small number of publications only for each alg we show one example output map to get an impression of the application possibilities even if there may be many more output options available 3 2 aims aim here refers to the purpose of an alg there are various motivations for developing and applying computer generated agricultural landscapes however there are two general objectives which are not exclusive but lead to different foci and hence different designs of an alg fig 3 a first general objective in algs is to gather theoretical understanding and foster theory development for example the software platform dypal dynamic patchy landscape by gaucherel et al 2006a gaucherel et al 2006b was designed to analyse processes that drive changes in landscape patterns and ecological functioning e g field aggregation and land use allocation this not only allows investigating the relationships between landscape shaping processes and the resultant landscape pattern but also how agricultural landscapes affect ecological processes the generated landscapes of g raffe pe er et al 2013 which mimics the processes in which roads penetrate into natural habitats serve as templates for theoretical analyses and the testing of hypotheses in the same context neutral models of agricultural landscapes for example the vector based model genexp landsites le ber et al 2009 are used for studying agro ecological processes within a certain variability of landscape patterns a second objective of algs is the application of computer generated agricultural landscapes for spatial simulation models in order to predict the ecological consequences of landscape dynamics or to give policy advice the landscape generator by slager and de vries 2013 and it s updated version van strien et al 2016 for example was developed to investigate the influence of landscape patterns on spatial ecological processes the landscapes generated are used to analyse the effects of changes in the landscape configuration and composition on biodiversity and conservation issues at the landscape scale therefore they are usually coupled with models of specific species to investigate habitat suitability and population dynamics table 2 the aim of the agbioscape modelling framework begg and dye 2015 is to explore options of managing arable landscapes and their ability to enhance functional biodiversity and devise conservation recommendations the landscape generator of engel et al 2012 and its updated version everaars et al 2014 were developed to simulate changes in land use mosaics caused by bioenergy scenarios such as the thinning and spatial agglomeration of crops and to analyse their effects on the abundance of different farmland bird species the modelling framework ddal disease dynamics in agricultural landscapes aims at exploring the effects of landscape configuration and composition on the development of an epidemic papaöx et al 2014 the structure generator sg4giscame inkoom et al 2017a b aims at giving inputs for spatial ecosystem service assessment in data scarce areas the range of aims shows that the purpose of the approaches presented here is different thus some algs are a simulation model by themselves that can be used as a stand alone tool to investigate certain questions or processes e g on the drivers producing a landscape pattern the result however is a computer generated landscape pattern that can be used further for analysing respective consequences 3 3 configuration configuration refers to the size shape and spatial arrangement of structural elements of agricultural landscapes such as fields semi natural habitats or hedgerows algs generate landscape configurations that are either pattern based i e provide heuristic design rules and algorithms for reproducing typical structural characteristics of agricultural landscapes without addressing the pattern forming driving forces or are process based by explicitly including underlying ecological or land use processes overall there are more pattern based approaches 6 than process based approaches 2 in the remainder of this section we first give a general overview of the different features of the algs and then present each alg in detail table 2 3 3 1 pattern based approaches the landscape mosaic generator of the agbioscape model platform generates a pattern of rectangular fields and narrow fringe structures such as hedges whereby the size shape and clustering of the fields can be controlled fig 4 the generator from engel et al 2012 everaars et al 2014 also generates rectangular fields of variable size which are distributed irregularly and randomly in the landscape fig 5 other landscape structures cannot be displayed the landscape generator described by van strien et al 2016 is more complex than the two previous approaches as the user can set target values of landscape metrics that quantify landscape configurations e g the maximum perimeter or shape of the bounding box of a patch fig 6 therewith the linear shape of hedgerows can be depicted and the configuration in general becomes more realistic in contrast to these grid based approaches there are also pattern based models that work on the basis of vectors raster grid based and vector landscapes differ fundamentally in terms of their spatial composition raster landscapes with one grid cell being the smallest unit are particularly suitable for gradual landscape dynamics and continuous processes in vectorial landscapes patches typically polygons of varying sizes are described by the exact coordinates of their bounding vertices since landscapes especially agricultural landscapes are strongly characterised by patches and corridors forman and godron 1981 turner 1989 the vector based approach is very well suited for this type of landscape nevertheless it is much less used because the geometry and algorithms are more complex the vectorial approaches of le ber et al 2009 inkoom et al 2017a inkoom et al 2017b and papaïx et al 2014 are based on tessellation methods that are used to manage sets of polygons tessellation starts from a point pattern and determines polygons based on distances to the closest neighbour points without overlapping or holes the spatial distribution is determined by the distribution of the tessellation seeds point pattern if a landscape mosaic is based on the seed distribution of a real landscape the spatial pattern will be similar to the real landscape le ber et al 2009 by controlling the size shape and clustering of the polygons a landscape mosaic develops and different land uses can be assigned to each patch or field 3 3 2 landscape mosaic generator begg and dye 2015 the agbioscape modelling framework begg and dye 2015 integrates a landscape mosaic generator and a population module to simulate interactions between a range of species and cropping systems management and landscape characteristics the landscapes consist of fields and the boundaries between them fig 4 fringe structures such as grass margins and hedgerows can be depicted by specifying the height width and total number of fields the size shape and clustering of the fields can be controlled the generator continually subdivides a two dimensional space to produce a mosaic of rectangular fields the algorithms for generating the landscape structure contain stochastic elements leading to a spatial variation of landscape patterns 3 3 3 landscape generator engel et al 2012 everaars et al 2014 a given mean field size is used by this generator to create landscapes that consist of an irregular and randomly distributed mosaic of agricultural fields with varying shapes sizes and edge lengths fig 5 the landscapes are 9 km² in size and are divided into grid cells with a 4 m grain size 750 by 750 grid cells in a first step fields of a predefined size are placed randomly on the main grid until the whole space is occupied afterwards a correction algorithm replaces all fields that are too small by merging them with neighbouring fields field margins and in field strips can be implemented 3 3 4 landscape generator van strien et al 2016 this generator integrates different landscape metrics quantifying the landscape configuration and composition the distribution and clustering of land use classes as well as the proportion of adjacent landscape components can be determined e g hedgerows around fields the required input of the generator is configuration files with target values for the landscape metrics and an initial input raster in the ascii format that can either be a random percolation map or an existing landscape in random percolation maps each raster cell is randomly assigned to a predefined land use class with a certain probability gardner et al 1987 it can be created with several gis and programming languages e g r python the following landscape metrics can be varied on the class level or patch level number of patches for a certain land use class area of a certain patch maximum perimeter contact with another land use class shape of the bounding box of a patch total area within a bounding box occupied by a certain patch and the rectangular criterion the generator uses an optimisation algorithm to find landscapes of which the composition and configuration correspond to the target values of the landscape metrics it does so by iteratively swapping raster cells and determining whether the new landscape is an improvement with regard to the target values the algorithm contains stochastic components so the generation of two identical landscapes with the same input settings is not possible in return it is feasible to generate landscape series in which single landscape metrics are varied fig 6 3 3 5 genexp landsites software le ber et al 2009 le ber and mari 2013 this software simulates neutral agricultural landscapes to explore the variability of landscape characteristics and the variation in the geometry of fields fig 7 an irregular patchy landscape mosaic without fringe structures develops the field patterns are obtained by using two different tessellation methods the voronoi tessellation and a rectangular tessellation which make it possible to control the size number and the shape of fields the user can choose the kind of seed distribution original simulated or random the tessellation type voronoi or rectangular and the cropping pattern distribution random or stochastic the model provides a library to calculate basic landscape descriptors field area perimeter number of vertices centroid and shape file export is possible in raster or vector format and with shape files 3 3 6 sg4giscame structure generator inkoom et al 2017a b the sg4giscame structure generator which is a module within the giscame software uses voronoi tessellation and different algorithms to produce realistic landscape patterns fig 8 first the landscape is separated into a number of triangles from a regular midpoint triangulation the edge shape and size of the polygons can be altered through initial split and tolerance levels and spatial resolution as a second step the irregular triangles are merged to form more realistic polygons on the basis of a user designed or random process merging finally users can alter or refine the output geometry of the landscapes using either a manual distribution option or a cellular automaton algorithm refinement the resulting vector data are transformed into raster data and the output is an ascii text file a set of landscape pattern metrics is implemented to assess variations in landscape configuration and composition patch cohesion average patch shape contagion area weighted mean shape index and landscape patch index 3 3 7 landscape simulator papaïx et al 2014 the simple landscape simulator within the ddal framework generates a landscape mosaic based on the t tessellation simulation algorithm developed by kiêu et al 2013 fig 9 the input parameters number of fields field surface average field surface variability and the square like form of fields can be determined as a result it is possible to influence the degree of fragmentation of the landscape and to prevent triangular fields the simulator is coupled with a pathogen population dynamics model process based approaches the following two approaches work with explicit spatial locations determining the process being modelled by using the modelling platform dypal many different processes can be investigated at the landscape level e g the spatial aggregation and distribution of fields and hedges land use allocation and land use rotations the landscape processes are applied to landscape units by using one or more algorithms even though most of the previous applications of dypal are based on real landscape patterns gaucherel et al 2006a b have implemented neutral models patchy landscape neutral models in the software platform in contrast to the complex modelling platform dypal the g raffe model pe er et al 2013 generates landscapes based on a single process forest fragmentation by roads and the generation of agricultural fields 3 3 8 dypal gaucherel et al 2006a b dypal formerly known as l1 gaucherel et al 2006a b is a modelling platform for generic landscape modelling on various scales and landscape types field farm and region landscape processes such as hedgerow planting and removal when applied to landscape units lead to evolution in the composition and configuration of the landscape the alg can simulate the patch dynamics of fields as well as dynamic fringe structures such as hedgerows fig 10 the patches are defined as polygons but a pixel definition of the polygons was kept to be able to simulate continuous processes the required input parameters depend on the process being modelled the platform was designed around a kernel that provides an organisational data structure and a generic landscape structure several libraries provide specific algorithms permitting the handling of sets of points linear networks or a mosaic of adjacent polygons the user can freely choose the data structures the driving decisions and processes the simulation steps the level of detail of the description and the chosen scales several further developments of the software platform and a number of applications have been made so far gaucherel et al 2010 and gaucherel et al 2012 implemented additional mathematical models formal grammar equations into the platform to mechanistically simulate landscape dynamics bonhomme et al 2017 implemented further configurationally changes of patches that enable all possible operations and combine them into a coherent mathematical framework 3 3 9 g raffe pe er et al 2013 the simple process based simulator g raffe is able to generate the spatial patterns of agricultural fields embedded in a natural habitat esp forest that emerge from forest fragmentation by roads fig 11 three main parameters determine the generated landscapes the habitat cover the number of roads crossing the landscape and the field size an additional parameter maximum field disconnection specifies whether and to what distance agricultural fields can be detached from roads or other fields the model starts with a 100 forest landscape and then creates roads that lead straight through the landscape converting the forest into non forest roads are generated until the number of roads reaches the desired number unless the forest cover reaches the target value specified by the user once all roads have been generated agricultural fields are separated from them by a random movement of simulated farmers all fields have a square shape same length and height the size of which is derived from a uniform distribution between one and the maximum length specified by the user field expansion is a per step process that can stop when the potentially converted cells are beyond the map extent or when the desired forest cover is reached efforts lgraf dislich et al 2018 is an extended version of g raffe which additionally includes two different land uses and households fig 11 households can own several fields of different sizes with different land uses 3 4 composition composition here refers to the assignment of landscape elements configuration to different land cover types or structures however not all of the generators reviewed allow a finer differentiation in this respect table 2 the generated landscapes of g raffe consist only of forest and agricultural fields in which agricultural field is not further specified however agricultural fields can be covered with oil palm or rubber plantations in the extended version efforts lgraf the composition of the generated landscape described by van strien et al 2016 is defined by various land use categories regarding agricultural landscapes one case study on maize farmland with hedgerows has been carried out so far slager and de vries 2013 genexp landsites and presumably ddal can be coupled with external crop rotation models such as carrotage le ber et al 2006 whereby a wide range of crops can be taken into account the data mining software carrotage is based on high order hidden markov models for analysing spatio temporal cropping patterns many crop rotation approaches work with markov models to achieve a change in landscape configuration or composition markov models provide matrices with transition probabilities between different crop types similar matrices have been widely used for representing succession in forests horn et al 1975 these models are descriptive not mechanistic but they can be a starting point for realistic depictions of existing composition dynamics different policies can be implemented by manipulating the transition probabilities in ddal papaïx et al 2014 no explicit crop types have been implemented so far the number of land use types host types the proportions they cover and their level of spatial aggregation can be varied by applying a stochastic algorithm the other four generators work with pre defined crop types or land use classes which are distributed to the fields mostly according to stochastic rules of crop successions the landscape mosaic generator described by begg and dye 2015 describes crop rotations as first order markov chains usher 1992 only four crop types have been implemented so far but different land use types such as hedgerows flowering margins and conservation headlands can be chosen the number and type of 15 different crops can be varied in the landscape generator of everaars et al 2014 to build different cropping scenarios crops are allocated randomly or with a probability that equals the relative proportion to the agricultural fields for multiple subsequent scenarios in addition fields can be allocated with integrated biodiversity area iba defined as semi natural habitat dypal simulates deterministic or stochastic crop successions within farms while other landscape elements such as hedgerows forests and rivers can be depicted in gaucherel et al 2006 land use types are assigned to patches using the gibbs process which is derived from statistical physics caldiera and presutti 1974 and describes the local interactions between landscape units it is also possible to apply the gibbs process to landscape configurations gaucherel 2008 this can be achieved by editing the shape or size of the landscape patches or by selecting a gibbs pair function to constrain the relative positions of the seeds in sg4giscame inkoom et al 2017a b a large number of land use classes can be specified as well as their relative amount the distribution is based on transition probabilities and tolerable or intolerable neighbourhood settings in addition to crop types five of the algs can depict semi natural habitats such conservation headlands begg and dye 2015 integrated biodiversity areas everaars et al 2014 and forest gaucherel et al 2006a b pe er et al 2013 begg and dye 2015 inkoom et al 2017a b four of the algs were coupled with population modules pe er et al 2011 everaars et al 2014 papaïx et al 2014 begg and dye 2015 3 4 1 additional crop rotation tools as alternatives to carrotage a range of other crop rotation tools exist that can be used as a supplement to a landscape generator some useful examples are presented as follows landsfacts landscape scale functional allocation of crops temporally and spatially allocates a crop to each field for each simulation year in a gis shape file castellazzi et al 2008 2010 fields are represented as polygons in vector format with fixed boundaries the model is based on a stochastic process using the probabilities of crop to crop transitions markov chains and rule based constraints the linear optimisation model croprota schönhart et al 2009 2011 integrates agronomic criteria and observed land use data at field farm or regional scales in order to generate typical crop rotations for the particular scale rotat dogliotti et al 2003 is a computer program that combines crops from a predefined list to generate all possible different rotations a number of filters or rules based on explicit agronomic criteria and expert knowledge can be controlled by the user rotor bachinger and zander 2007 is a static rule based model for generating and evaluating site specific and agronomically sustainable crop rotations for organic farming systems in central europe rotor requires as input data field specific soil data mean annual precipitation and mean precipitation during the winter half year nepofarm horn 2017 is a landscape generator that creates farmland scenarios as input files for the honeybee model beehave becher et al 2014 field patches are allocated randomly in two british template landscapes and are characterised by crop type identity and crop diversity crop type number and relative abundance nepofarm is based on gis maps and is implemented in the freely available programming language r 3 5 validation validation here refers to testing whether landscapes generated by an alg reproduce realistic landscape features to validate the generated landscapes five of the reviewed approaches compared certain landscape metrics with real landscapes gaucherel et al 2006a b le ber et al 2009 pe er et al 2013 van strien et al 2016 inkoom et al 2017a b three of them pe er et al 2013 van strien et al 2016 inkoom et al 2017a b calculated the relevant landscape metrics of the real and computer generated landscapes by using fragstats mcgarigal et al 2012 the calculated landscape metrics can also be used as input parameters for the alg to approximate the computer generated landscape to the real one as a result the generated landscapes preserve the main characteristics of the original landscape while being configurationally different inkoom et al 2017a b used a turing test to explore expert visual judgement in comparing neutral landscapes to real landscapes the publications of the other approaches did not contain any evidence of validation 3 6 evaluation of policy measures here we summarise to what extent and how algs were used to evaluate existing or prospective policy measures addressing agricultural landscapes everaars et al 2014 simulated future scenarios of different land use changes due to policy making and economic aspects of bioenergy production the effectiveness of different mitigation strategies on farmland birds was analysed on the basis of the generated landscapes dypal has been developed inter alia to assess the environmental consequences of agricultural policies affecting processes that drive changes in landscape patterns and ecological functioning it was used to evaluate simplified common agricultural policy cap and cap reform decisions such as changing maize and cereals to fallow and temporary grassland gaucherel et al 2006a b houet et al 2010 used dypal to simulate plausible future states of landscape features such as hedgerows riparian wetlands and agricultural land covers based on hypotheses about future land management related to european policies the agbioscape modelling approach has the intention to develop an impact assessment and decision support tool for land management options including agri environmental schemes aess the potential of such a tool is to assist land managers and policy makers in identifying effective management options the landscape generator by slager 2011 was initially developed to generate plausible landscape configurations for participatory spatial plan making the study focuses on the construction of so called policy plan scenarios as a fundamental activity in spatial plan making 3 7 availability of the algs algs that have an executable version are mostly openly available on the internet table 3 however only dypal has open source code almost none of the algs are documented in detail instead only summary descriptions of the algorithms and data used are provided which also limits the level of detail by which we could characterise the algs above 3 8 other tools for generating neutral landscapes our definition of algs is rather restrictive as we require the potential to systematically vary landscape features in an automated way such generators have many advantages but there are also software tools or generators that are not algs according to our definition but are still certainly useful for more specific purposes here we give a brief overview of such tools that we found in our survey of the literature they have in common that they do not explicitly address agricultural landscapes or land use types rule is a software package for the generation of neutral landscape models and the analysis of landscape patterns gardner et al 1987 gardner 1999 gardner and walters 2002 landscape patterns are generated either as simple random processes random maps or as a result of spatially correlated processes using algorithms derived from fractal geometry multifractal maps qrule is a further development of rule retaining the essential features but providing statistical summaries based on area rather than pixel counts improving the formats of ancillary data sets and adding the potential for developing and analysing alternative neutral models gardner and urban 2007 the fractal realizer fr developed by hargrove et al 2002 generates multiple category synthetic landscape maps according to user specifications the synthetic landscapes show statistical properties similar to those of a particular empirical landscape and can be used to generate replicated input to spatial simulation models it generates fractal landscape patterns based on the midpoint displacement algorithm by saupe 1988 gradientland cambui et al 2014 is a free software program for generating a wide range of habitat cover gradients as random and fractal neutral landscapes in the fractal mode varying the aggregation and land cover is realised by using the midpoint displacement algorithm completely random patterns are produced by using a uniform probability distribution nlmpy etherington et al 2015 is a python software package for the creation of neutral landscapes within a general numerical framework it integrates a range of nlm algorithms that differ in the spatial autocorrelation of the element values in a two dimensional array it is open source can be used on any computer system and is easily combined with geographic information system gis data nlmr and landscapetools sciaini et al 2018 are r packages for simulating and modifying neutral landscape models in a single environment nlmr is a comprehensive collection of algorithms for creating neutral landscapes and landscapetools provides a utility toolbox which facilitates an easy workflow with neutral landscapes and other raster data hiebeler 2000 describes a simple algorithm for generating landscapes with spatially structured habitat heterogeneities the landscapes consist of rectangular lattices of sites or patches each characterised by a value indicating its habitat type hiebeler 2007 improved the landscape generation algorithm by using stratified sampling of sites rather than simple random sampling remmel and fortin 2013 utilize a stationary random field simulator remmel and csillag 2003 to produce large numbers of binary landscapes with identical parameters clearly defined descriptors of spatial pattern composition and configuration can be parameterized within the r statistical computing environment 4 outline of a future generic alg our review shows that currently no generic commonly used or useable alg exists but isolated solutions have been developed in specific contexts with specific purposes it seems impossible to design a single unifying alg that is able to cover all past and future applications and questions a generic alg would have to perform the balancing act of being both versatile and adaptable for case specific application in order to solve this dilemma in the following we would like to suggest a modular design for generic algs 4 1 specific requirements our idea behind generic algs is the development of a software tool in modular design the activation and deactivation of modules should be controllable with regard to the final result because the design of the landscapes can vary considerably depending on the final use likewise defined interfaces should exist for adding own specific modules the design depends above all on the simulation models to which the landscapes produced by the algs serve as an input these can be different types of dynamic models for example lucc models spatial ecological models that analyse the effects of landscapes on certain ecological aspects e g animal species or agent based land use models which analyse farmer s decisions under the influence of institutional markets policies and natural e g soil type framework conditions basically the generic algs create and systematically vary hypothetical agricultural landscapes spatial configuration and composition of field mosaics the following requirements should be fulfilled 1 pattern and or process based generation 2 the generation of a large number of random landscape maps in order to make general statements as well as the generation of specific landscapes 3 random and targeted distribution of landscape elements table 4 presents a tentative list of features that such a generic alg should have this list is our subjective merger of features that we based on our review consider essential all features should be separately testable and controllable essential elements are required to adapt the landscapes to a wide range of target model types optional elements allow tailoring the landscape to specific purposes the size and number of fields and the assignment of crop types are obligatory inputs regarding crop types coupling with a software program that generates crop types or rotations dogliotti et al 2003 bachinger and zander 2007 schönhart et al 2009 castellazzi et al 2010 can be useful additional landscape elements e g semi natural landscape elements and hedges are optional but can be decisive as in the case of pollinators even the addition of abiotic e g soil runoff relief and socio economic factors should be possible a gradient from very simple to very complex landscapes should be possible landscape complexity can successively be increased by adding certain features or modules the resulting landscape must have an adequate degree of complexity which is not just a technical or methodological question but a practice oriented one seppelt et al 2009 because scale grid type resolution and the degree of complexity have to be compatible with the simulation model to which the landscapes serve as input this also has an effect on the design of the landscape since some landscape elements are not visible at a particular resolution e g fine fringe structures 4 2 model and software architecture the optimal generic alg framework is open source fully documented and easy to use with regard to an integrative approach other open source models can be integrated quickly and easily according to agarwal et al 2002 initiating such an open source modelling effort will require several components 1 a web site to support modelling collaboration e g data and interactions among individuals such as bulletin boards and faqs 2 the establishment of one or more modelling kernels core components of models using various technologies that are designed in a modular fashion and allow participants to make enhancements with relative ease and 3 the development of mechanisms for sharing model enhancements that encourage participation and provide incentives that are comparable experience with the generic forest succession model landis ii scheller et al 2007 shows that it is crucial to employ modern software engineering techniques for software that is intended to be generic and used by many people scheller et al 2010 a modular model architecture meets the requirements for generic algs it enables the integration of building blocks of existing algs that have proven to be useful in the form of modules all modules can be easily revised such that the latest expert knowledge can always be integrated furthermore new modules can be added with little effort the algs should be operated via an intuitive graphical user interface that consists of different toolboxes with open source code for model development ideally the package concept of r would be adopted but this would require the existence of a core architecture and scheduler the algorithms and rationale of the algs have to be fully documented and a user manual and guided tour provided the algs should not only be a stand alone program but should also be usable as a library i e it can be started from every simulation model and generate landscapes during the simulation process on the fly such coupling is important particularly for optimisation models an interface to gis should exist to be able to alter real imported maps automatically using the algs various software platforms or programming languages could be envisaged for developing generic algs however no single language will be accepted and used by all potential users still if a certain widely used language is chosen such as c java or python programming interfaces should be provided that allow links to other languages if possible an alternative is to try to build on existing gis software one option is to use the arcgis modelbuilder but this might be suboptimal because this software is proprietary and still might not offer the full flexibility required a suitable solution might be based on a domain specific visual dataflow programming approach visual dataflow programming vdp is a programming paradigm that represents a program as a directed graph of data flows between operations wikipedia 2018 in visual dataflow programming users can assemble a program by placing operations nodes and connecting their data inputs and outputs in a graphical user interface fig 12 the appeal of vdp is that it combines high flexibility and extensibility with ease of use and program readability without programming knowledge in the context of an alg framework operations i e nodes would include basic gis operations such as a raster calculator buffer filters or voronoi diagram calculation as well as generators such as perlin noise or random points finally it would include output operations for different file formats and visualisation for debugging every operation can have input and output slots for defined data types e g floating point number integer raster vector layer the framework would be easily extensible through the addition of operations although some programming knowledge in the framework s implementation language would be necessary for the creation of new operations their mutual independence would greatly benefit flexibility and facilitate the exchange of operations between users or a central repository for official and community based extensions operations or bundles thereof one important advantage of this approach would be that it combines ease of use without having to learn a specific programming language with modularity and extensibility based on a widely used language in the supplementary material an example vdp program implemented in a prototype framework in scala is explained in detail to further illustrate the concept of vdp another generic approach to implementing modular generic algs are the so called pattern grammars gaucherel et al 2012 where landscape features are described using a certain syntax this approach has been widely used for functional structural plant modelling fspm using l systems grammar e g godin and sinoquet 2005 wang et al 2018 the alg dypal gaucherel et al 2006a b is based on such a grammar and is one of the most flexible existing algs 5 discussion the computer aided generation of agricultural landscapes can provide a framework for understanding and evaluating how land use and land cover changes will take place and affect the environment being input to simulation models the landscapes can serve as a basis for decision making for policy makers or as support for discussion and negotiation this especially concerns insights into the adequate scale of policies national or more regionalised but also into the relative importance of landscape structural elements for achieving societal goals with implications for the priorisation of conservation activities the results are useful for communicating policies and the corresponding landscape changes and environmental effects to local actors and to the public computer generated landscapes offer a number of advantages 1 they can fill the gap when real data are not available or are not at a suitable resolution and they allow us 2 to test new landscape configurations 3 to carry out systematic analyses of environmental gradients and 4 to perform spatial sensitivity analyses as a basis for the regional transferability of the results for these reasons we believe that the future lies in the computational evolution of landscape patterns not limited to random change the aim of each alg should be to design a plausible landscape with appropriate input parameters and algorithms this means that the generated landscape should not be more complex than necessary to serve as input for a simulation model or to answer the scientific or policy question still most existing algs represent rather simple agricultural landscapes via a few regularly shaped patches configurational changes are often realised by transition probabilities important questions though exist that would require more complex landscapes by for example adding semi natural habitats or applying advanced design rules which acknowledge the relationship between abiotic site conditions e g soil runoff relief and crop choice in this way all processes that lead to significant changes in configuration and use can be included 5 1 process based approaches the landscapes of process based algs are the result of the implemented process and are therefore strongly dependent on the input parameters users thus need to know and fully understand the effect of each input parameter to design specific landscapes an advantage of process based or mechanistic algs is that the underlying processes can be explicitly adressed so these landscapes are more likely to be relevant for the study of policy measures the disadvantage is that it can be difficult to quantify all the necessary parameters we found only two process based algs developed so far dypal is the most complex and most advanced one it integrates numerous algorithms as a basis for various processes while neutral models are already implemented for the composition landscape configuration is currently based on real landscapes that s the reason why this approach does not fully meet our selection criteria and cannot be compared very well with the other approaches nevertheless we have included it because it shows the possibilities of a process based generator the possibility to generate landscape configurations in a systematic and automated way would make the application of dypal much more versatile and flexible g raffe simulates the highly significant process by which primary forest is transformed into arable land the conversion is performed by simulated farm establishment subsequent to the generation of roads unfortunately agricultural fields cannot be assigned to different crops so this generator can only be used for the investigation of landscape dynamics rather than for agricultural questions 5 2 pattern based approaches pattern based algs usually require fewer parameters and less computing time than process based ones there are a variety of landscape metrics that can be used as input parameters e g the number and size of fields or the proportion of landscape elements most algs integrate only a few landscape metrics which limits the design of the landscape pattern and thus the range of possible applications to generate realistic agricultural landscapes a set of different landscape metrics is needed however one should consider that more input parameters as well as a larger grid size lead to more complicated algorithms and longer computing time to solve this problem efficient algorithms become important the strength of the agbioscape landscape mosaic generator is that it is already coupled with four population modules a conservation species an agricultural pest and two functionally distinct natural enemies to investigate the influence of management and land use patterns the generator can be used to generate simple field patterns from rectangular fields with fringe structures and to assign four different crop types to the fields the landscape generator of engel et al 2012 everaars et al 2014 also designs simple field patterns which can be assigned to 15 different crop types the focus is on the variation of crop proportions and the mean field size however it cannot vary the range of field sizes leading to quite artificial landscapes composed of square fields using the alg developed by van strien et al 2016 a differentiated landscape can be generated by integrating different landscape metrics that can be applied at either the field or class level the number of different land use classes can be defined but no specific crop types have been implemented so far with the tessellation methods applied in genexp landsites sg4giscame and the landscape simulator by papaöx et al 2014 irregular geometric field patterns are generated without fringe structures tessellations have the advantage that the general geometrical character as well as the spatial distribution of the agricultural landscape can be preserved the difficulty is in controlling important landscape features such as field sizes and shapes or distances between tessellation seeds while the tessellation methods allow one to simulate numbers of fields and average field sizes that are similar to those of real landscapes they do not correctly depict the shapes of the fields or the variability of these shapes within the landscape le ber et al 2009 genexp landsites produces slightly too compact fields with little variability while the rectangular tessellation produces over elongated fields with too high variability as a result this alg generates landscapes with configurations of limited realism and landscape dynamics cannot be investigated very well in contrast sg4giscame provides a better representation of field shapes through higher flexibility and refinement algorithms 5 3 simulating crops in most existing algs crop types are defined only marginally le ber et al 2009 papaïx et al 2014 begg and dye 2015 van strien et al 2016 dislich et al 2018 or not at all pe er et al 2013 this means that although there are various land use patterns from agricultural fields there are few specific farming systems however representing land cover in more detail is essential to answer many questions regarding agricultural landscapes the tessellation method for example offers little possibility for handling attributes of landscape composition but it can be combined with crop rotation models statistical modelling of crop rotations in general and markov models in particular are suitable tools for predicting crop types however markov models per se are empirical based on observed transitions of land use types or are fully hypothetical therefore they should be constrained by conditional rules based on expert knowledge 5 4 evaluating policy measures by using computer generated landscapes in simulation models agricultural policies can be evaluated quickly and effectively at the local or regional scale this is an advantage over field observations and long term field experiments which are more time consuming but obtain higher precision and validity both methods have their pros and cons and should be used and supplemented according to their capabilities the rapid evaluation and prediction of environmental effects related to policies are a great strength of simulation models and are essential to propose and implement sustainable and efficient environmental policies however since the so far generated landscapes are often rather simple the application as a tool for evaluating policy measures is still limited because the results are only partially transferable to reality validation not only of the simulation models used but also of the alg is crucial in this context here validation means providing evidence that alg generated landscapes are able to capture essential features of existing and planned landscapes 5 5 challenges limitations we have tried to describe existing alg approaches in the same depth and with regard to the same criteria unfortunately not only are the approaches themselves very different in terms of methodology but they are also often incomplete in their description which makes them difficult to compare the approaches are not des cribed in the same way terminologies differ and much of the information we have been looking for is not available this leads to incompleteness in the description of some approaches and possibly to biases alg descriptions following a standardised protocol would be extremely helpful and a desirable standard for publications in the future for example the odd protocol which is a standard format for describing individual or agent based models grimm et al 2006 2010 could be adopted for this purpose the algs presented here have mostly only been used within the research group that developed them thus they were not designed for general application and availability nor were they designed with user friendliness in mind generic algs will require well designed software and detailed documentation so that the user can quickly become familiar with the alg s functionality and understand exactly which application possibilities are available in our opinion the generator developed by van strien et al 2016 comes closest to meeting these demands a well documented open source code can be further developed and enriched by the scientific community and it can be used for other models until now most algs have been developed in isolation because no consistent terminology regarding landscape generators exists and because we had to focus on isi listed publications we might have overlooked further relevant algs although we could not find references to any further algs in the publications we reviewed our review shows that the development of computer generated agricultural landscapes is still in its infancy most generators generate simple landscapes which limits the range of application in most cases the main focus is on either the spatial configuration or the composition not on both in a balanced way all approaches still have great potential for further development towards broader applicability to address the multi functionality of landscapes generic algs should include other land use types such as forests or settlements pattern oriented modelling can be used for example to identify relevant landscape metrics the alignment of computer generated landscapes with real landscapes still has much potential for improvement this can be made possible by the further development of specific algorithms and calibration or validation with high resolution data on cultivation systems and abiotic factors an important data input for future algs will be remote sensing data e g pettorelli et al 2016 which open up new approaches for identifying land use types e g joshi et al 2016 5 6 outlook as a result of our review we derived requirements for generic future algs that have the potential to be widely used in landscape science environmental questions can be examined on certain spatial scales and transferred to other scales that are not feasible to explore in reality however the difficulty of computer generated landscapes is that they represent few landscape features well simultaneously each extension leads to a more complicated algorithm and longer calculation time this leads to the classical modeller s dilemma of when functionality falls victim to complexity therefore the complexity of the model has to be carefully considered as well as how versatile the alg can and should be it is important to give the user the possibility of prioritising e g which landscape features should be exact and which can be approximate generic algs thus needs to have a modular and preferably open architecture in the supplement we outline one possible solution but other solutions certainly exist in any case although the architecture of generic algs might be set up by individual groups of researcher e g the approach that we outline above and in the supplement or approaches based on pattern grammar gaucherel et al 2006a b gaucherel et al 2012 establishing a modular framework would have to be a community activity ideally national or european funding agencies would initiate such joint projects similar to the eu initiative to standardize models of the fate of pesticides in surface waters focus 2001 6 conclusion systematically generating variable virtual landscapes as a basis for spatially explicit assessment opens up new ways of exploring environmental issues there is an enormous field of application particularly with regard to the evaluation of policy measures critical threshold values of environmental effects can be identified at an early stage and suitable mitigation measures can be developed due to the enormous application potential the significance of landscape generators as a basis for spatial simulation models will continue to grow in the future and they will be a useful complement to real landscapes and long term field studies however considerable development work is still needed to improve and generalise the generators which would be feasible in a joint project in the open source context we expect that 5 10 years are needed to develop successively such a generic alg framework and that considerable manpower and data sources are needed in europe this would ideally be the scope of eu funded projects hot topics such as the decline of pollinators such as honeybees potts et al 2010 horn 2017 evaluating and improving the effectiveness of the cap reform pe er et al 2014 or the safe provisioning of the full bundle of ecosystem services raudsepp hearne et al 2010 emphasise that investing in developing a generic modular alg would not only pay off well but might actually by crucial acknowledgements m l acknowledges funding of this project from the heinrich böll foundation germany appendix a appendix b supplementary data supplementary material related to this article can be found in the online version at doi https doi org 10 1016 j ecolmodel 2018 12 010 appendix b supplementary data the following is supplementary data to this article 
25133,there is an increasing need for an assessment of the impacts of land use and land use change lucc in this context simulation models are valuable tools for investigating the impacts of stakeholder actions or policy decisions agricultural landscape generators algs which systematically and automatically generate realistic but simplified representations of land cover in agricultural landscapes can provide the input for lucc models we reviewed existing algs in terms of their objectives design and scope we found eight algs that met our definition they were based either on generic mathematical algorithms pattern based or on representations of ecological or land use processes process based most algs integrate only a few landscape metrics which limits the design of the landscape pattern and thus the range of applications for example only a few specific farming systems have been implemented we conclude that existing algs contain useful approaches that can be used for specific purposes but ideally generic modular algs are developed that can be used for a wide range of scenarios regions and model types we have compiled features of such generic algs and propose a possible software architecture considerable joint efforts are required to develop such generic algs but the benefits in terms of a better understanding and development of more efficient agricultural policies would be high keywords agricultural landscape field pattern agricultural landscape generator landscape simulator neutral landscape model process based model 1 introduction in response to climate change a growing human population and globalisation land use and land cover are changing at unprecedented rates understanding and predicting these changes and their consequences for biodiversity and ecosystem services are among the grand challenges of ecological and environmental research for intensively used agricultural landscapes for example in europe key questions include how spatio temporal patterns in land cover are affected by national and eu policies or by the global market and how in turn they are affecting ecosystem services and biodiversity empirical approaches to meeting these challenges are limited because of the scale dependency and the multitude of factors involved simulation models on land use and land cover change lucc are therefore widely and increasingly developed to back and forecast landscape changes lambin et al 2000 agarwal et al 2002 parker et al 2003 heistermann et al 2006 such simulation models if they are sufficiently realistic allow us to generate scenarios and to rigorously explore by using mathematics and computer logics the consequences of stakeholder actions or political decisions e g johst et al 2015 however when using spatially explicit simulation models for this purpose there is a dilemma when it comes to representing land cover in agricultural landscapes on the one hand such land cover maps can be taken from maps from geographical information systems gis while such input implies high realism and significance for regional case studies e g wätzold et al 2016 general insights and transferability to other regions or questions are limited a single map does not allow us to systematically vary the features of a landscape even if we contrast different real landscapes we only obtain snapshots of possible relationships which are likely to be nonlinear moreover the creation of such detailed maps is time consuming as it often requires manual data processing parameterisation and calibration on the other hand an unlimited number of virtual landscapes can be generated using algorithms that systematically and automatically vary landscape metrics such as percentage cover fragmentation or spatial autocorrelation gardner et al 1987 gardner 1999 saura and martínez millán 2000 hiebeler 2007 cambui et al 2014 using these virtual landscapes as input models can provide insights into the consequences of changing landscape features and help to formulate test and validate hypotheses gardner and urban 2007 however such landscapes are usually difficult to relate to real landscapes such that it remains unclear what we have learned about the real world the alternative to these abstract landscapes is landscape generators which generate virtual but structurally realistic maps of land cover by trying to combine both realism and the option to vary landscape features the generators create variations of artificial agricultural land cover mosaics at the spatial resolution of individual fields for a given set of parameters to be classified as a generator we here require that they allow for varying features of the generated landscapes in a systematic and automated way changes in agricultural landscapes and their ecological consequences occur at small scales houet et al 2010 e g the variation of the field mosaic and the implementation of crop rotations or policy measures at the farm level there is thus a need for high resolution spatial simulation models and corresponding tools that are capable of generating artificial land cover maps at high resolution under a predefined parameter set still limited research has been done in the field and few such landscape generators have been developed so far these generators define agricultural landscapes as a mosaic of land use patches fields and landscape elements e g hedges landscape features that are typically varied are composition type and proportion of land cover and landscape configuration spatial arrangement of the land covers the distributions of these features can be taken from distributions observed in real landscapes such that insights gained from the model are relevant for e g analysing ecological processes or exploring the consequences of eu policy instruments such as the greening of farming e g langhammer et al 2017 or agri environment schemes e g sturm et al 2018 so far no common term has been established for this type of landscape generator therefore we here suggest referring to them as agricultural landscape generators algs and use it in the following as a generic term algs are computer programs that generate structurally realistic but simplified artificial representations of agricultural landscapes i e maps of land cover both the landscape configuration field mosaic and the landscape composition land cover are variable we nevertheless refer to them as generators to emphasise that they are not used for simulations by themselves and do not display temporal and spatial dynamics the output of algs is a map that can be used as input for lucc models or other model types algs can still represent change over time by producing a series of consecutive maps algs are either implemented as stand alone programs or as sub models within lucc models the approaches to generating landscapes can be distinguished into two main categories pattern based and process based pattern based generators also known as neutral landscape models are based on generic algorithms and produce virtual landscapes regardless of the underlying ecological or social processes gardner et al 1987 with and king 1997 they work with one or more characteristics of composition and configuration of a landscape regarding complexity they range from pure neutral models to more realistic models in terms of landscape structure johnson et al 1999 gaucherel et al 2014 the resulting landscapes are mostly pixel matrices with each pixel representing a spatial unit assigned to a certain land cover class so far neutral landscape models have been used primarily in the research field of forest and landscape ecology but rarely for agricultural landscapes the coupling of neutral landscapes with population models allows species perceptions of landscape configuration e g habitat fragmentation and landscape connectivity to be addressed with 1997 process based generators also known as mechanistic models produce landscape patterns as a result of ecological or socio economic processes that are explicitly integrated into the model jackson et al 2000 cuddington et al 2013 the result of these generators is also a static map to be used as input for dynamic simulation models process based in this context means that the mechanisms leading to a certain landscape pattern can be explicitly addressed an example is dinamica filho et al 2002 such generators are based on a theoretical understanding or hypotheses of the relevant processes that cause landscape patterns and they are helpful in determining how real agricultural landscapes and their dynamics emerge the resulting landscapes allow more explicitly stated hypotheses and can be used as the basis for addressing specific questions e g pattern process interaction schröder and seppelt 2006 land use change prediction the fate of specific species or of biodiversity in general and effects on ecosystem functioning and resilience in this review we examine existing algs that are able to automatically generate an agricultural landscape with given features our two main motivations are as follows 1 there is an increasing need to evaluate the driving forces behind and the extent and consequences of land use and land cover change recent eu policies for example aim at increasing biodiversity by requiring environmentally friendly farming practices the so called greening of farming european commission regulation eu no 1307 2013 whether or not such policies will in fact increase biodiversity is an open question pe er et al 2014 the usefulness of such policies requieres two things a realistic simulation model and realistic landscape where both different eco regions and policies can be represented in the case of honeybees the model beehave becher et al 2014 is such a model and so far only the software tool nepofarm horn 2017 exists that takes the structure of a given landscape important from gis implements different crop diversity and rotation scenarios and then explores how different greening measures such as flower strips affect the resilience and persistence of honeybee colonies with a kind of generic alg one could also vary the structure of the landscape for example regions with mostly small or large fields or landscapes with and without semi natural habitat or hedges the same landscapes could then also be used for exploring the performance of bumblebees becher et al 2018 wild bees everaars et al 2018 or completely different taxa where other landscape features might be important 2 our second interest is in finding the main features and criteria of generic software tools that could generate agricultural landscapes with more comprehensive and variable configuration and composition by using a modular design the landscapes generated by such generic alg could be used as input for any specific lucc model addressing specific questions this would generate coherence and synergies across individual studies that currently do not exist 2 methods because there is no consistent term for agricultural landscape generators so far in our literature search we used the following search terms ecological model and crop and landscape landscape model and crop landscape model and neutral landscape generat and crop landscape generat and neutral landscape simulat and crop and finally landscape simulat and neutral using these terms in web of science clarivate analytics led to 186 publications that cover a broad range of approaches aspects of agricultural landscape simulations and fields of application the most important selection criterion for including an alg approach in our review was the user defined automatic generation of agricultural land cover patterns which can serve as a input for dynamic simulation models we excluded landscape generators that do not encompass any characteristics of agricultural landscapes or did not include the land use type agriculture we also did not include geographical information system gis models remote sensing land use and land cover change lucc models and agent based land use models abms lambin et al 2000 agarwal et al 2002 schulze et al 2017 although they too allow landscape maps to be altered firstly these models usually work with real landscapes and data and secondly landscape changes in composition and configuration are mostly based on the outcome of decision models and not on automated procedures which were mandatory according to our definition of a landscape generator we examined the following features of the algs the specific aims the method of landscape generation in terms of configuration and composition the validation the application regarding policy measures and the software availability regarding landscape composition we analysed which method for crop generation and allocation of crops to the fields has been applied the more complex an alg is the more compositional details can be varied such as crop types fringe structures and other land use types we explored which of them have been implemented so far in the context of specific case studies we also compiled a brief overview of existing additional software tools that allow crop rotation to be implemented for a given landscape configuration moreover because it is important for allowing the exploration of ecological questions in agricultural landscapes we examined whether natural and semi natural habitats were included the same applies to the coupling with ecological population models to allow the analysis of landscape effects on species because enormous potential of agricultural landscape simulations lies in the evaluation of management and policy measures we investigated whether and how such scenario analyses were carried out finally programming language software application documentation and availability of the models were determined based on these findings we finally derived and outlined the requirements for generic algs in particular we wanted to identify which landscape features are essential or optional for user friendly agricultural landscape generation and which conclusions can be drawn for the model and software architecture 3 results 3 1 existing algs the list of publications containing solutions for generating such agricultural landscapes was short fig 1 we identified ten relevant peer reviewed articles published between 2006 and 2017 these ten publications relate to a total of seven alg approaches as several landscape generators were described or applied in more than one publication we added four more relevant publications describing one of the selected alg approaches more precisely to display even more possibilities we added the non isi listed scottish natural heritage commissioned report no 692 begg and dye 2015 describing another alg approach altogether we found eight alg approaches an overview of the reviewed alg approaches is given in table 1 and fig 2 the approaches differ widely in their method of landscape generation and agricultural details therefore it was difficult to give an integrated and structured overview and to derive general concepts to emphasise and better compare the range of existing approaches for each feature we present our results feature by feature not model by model nevertheless table 2 provides an overview of the reviewed algs the algs presented here have mainly been published within the last 10 years table a1 this makes it a young field of research with few approaches so far and most of them are described and or applied in a small number of publications only for each alg we show one example output map to get an impression of the application possibilities even if there may be many more output options available 3 2 aims aim here refers to the purpose of an alg there are various motivations for developing and applying computer generated agricultural landscapes however there are two general objectives which are not exclusive but lead to different foci and hence different designs of an alg fig 3 a first general objective in algs is to gather theoretical understanding and foster theory development for example the software platform dypal dynamic patchy landscape by gaucherel et al 2006a gaucherel et al 2006b was designed to analyse processes that drive changes in landscape patterns and ecological functioning e g field aggregation and land use allocation this not only allows investigating the relationships between landscape shaping processes and the resultant landscape pattern but also how agricultural landscapes affect ecological processes the generated landscapes of g raffe pe er et al 2013 which mimics the processes in which roads penetrate into natural habitats serve as templates for theoretical analyses and the testing of hypotheses in the same context neutral models of agricultural landscapes for example the vector based model genexp landsites le ber et al 2009 are used for studying agro ecological processes within a certain variability of landscape patterns a second objective of algs is the application of computer generated agricultural landscapes for spatial simulation models in order to predict the ecological consequences of landscape dynamics or to give policy advice the landscape generator by slager and de vries 2013 and it s updated version van strien et al 2016 for example was developed to investigate the influence of landscape patterns on spatial ecological processes the landscapes generated are used to analyse the effects of changes in the landscape configuration and composition on biodiversity and conservation issues at the landscape scale therefore they are usually coupled with models of specific species to investigate habitat suitability and population dynamics table 2 the aim of the agbioscape modelling framework begg and dye 2015 is to explore options of managing arable landscapes and their ability to enhance functional biodiversity and devise conservation recommendations the landscape generator of engel et al 2012 and its updated version everaars et al 2014 were developed to simulate changes in land use mosaics caused by bioenergy scenarios such as the thinning and spatial agglomeration of crops and to analyse their effects on the abundance of different farmland bird species the modelling framework ddal disease dynamics in agricultural landscapes aims at exploring the effects of landscape configuration and composition on the development of an epidemic papaöx et al 2014 the structure generator sg4giscame inkoom et al 2017a b aims at giving inputs for spatial ecosystem service assessment in data scarce areas the range of aims shows that the purpose of the approaches presented here is different thus some algs are a simulation model by themselves that can be used as a stand alone tool to investigate certain questions or processes e g on the drivers producing a landscape pattern the result however is a computer generated landscape pattern that can be used further for analysing respective consequences 3 3 configuration configuration refers to the size shape and spatial arrangement of structural elements of agricultural landscapes such as fields semi natural habitats or hedgerows algs generate landscape configurations that are either pattern based i e provide heuristic design rules and algorithms for reproducing typical structural characteristics of agricultural landscapes without addressing the pattern forming driving forces or are process based by explicitly including underlying ecological or land use processes overall there are more pattern based approaches 6 than process based approaches 2 in the remainder of this section we first give a general overview of the different features of the algs and then present each alg in detail table 2 3 3 1 pattern based approaches the landscape mosaic generator of the agbioscape model platform generates a pattern of rectangular fields and narrow fringe structures such as hedges whereby the size shape and clustering of the fields can be controlled fig 4 the generator from engel et al 2012 everaars et al 2014 also generates rectangular fields of variable size which are distributed irregularly and randomly in the landscape fig 5 other landscape structures cannot be displayed the landscape generator described by van strien et al 2016 is more complex than the two previous approaches as the user can set target values of landscape metrics that quantify landscape configurations e g the maximum perimeter or shape of the bounding box of a patch fig 6 therewith the linear shape of hedgerows can be depicted and the configuration in general becomes more realistic in contrast to these grid based approaches there are also pattern based models that work on the basis of vectors raster grid based and vector landscapes differ fundamentally in terms of their spatial composition raster landscapes with one grid cell being the smallest unit are particularly suitable for gradual landscape dynamics and continuous processes in vectorial landscapes patches typically polygons of varying sizes are described by the exact coordinates of their bounding vertices since landscapes especially agricultural landscapes are strongly characterised by patches and corridors forman and godron 1981 turner 1989 the vector based approach is very well suited for this type of landscape nevertheless it is much less used because the geometry and algorithms are more complex the vectorial approaches of le ber et al 2009 inkoom et al 2017a inkoom et al 2017b and papaïx et al 2014 are based on tessellation methods that are used to manage sets of polygons tessellation starts from a point pattern and determines polygons based on distances to the closest neighbour points without overlapping or holes the spatial distribution is determined by the distribution of the tessellation seeds point pattern if a landscape mosaic is based on the seed distribution of a real landscape the spatial pattern will be similar to the real landscape le ber et al 2009 by controlling the size shape and clustering of the polygons a landscape mosaic develops and different land uses can be assigned to each patch or field 3 3 2 landscape mosaic generator begg and dye 2015 the agbioscape modelling framework begg and dye 2015 integrates a landscape mosaic generator and a population module to simulate interactions between a range of species and cropping systems management and landscape characteristics the landscapes consist of fields and the boundaries between them fig 4 fringe structures such as grass margins and hedgerows can be depicted by specifying the height width and total number of fields the size shape and clustering of the fields can be controlled the generator continually subdivides a two dimensional space to produce a mosaic of rectangular fields the algorithms for generating the landscape structure contain stochastic elements leading to a spatial variation of landscape patterns 3 3 3 landscape generator engel et al 2012 everaars et al 2014 a given mean field size is used by this generator to create landscapes that consist of an irregular and randomly distributed mosaic of agricultural fields with varying shapes sizes and edge lengths fig 5 the landscapes are 9 km² in size and are divided into grid cells with a 4 m grain size 750 by 750 grid cells in a first step fields of a predefined size are placed randomly on the main grid until the whole space is occupied afterwards a correction algorithm replaces all fields that are too small by merging them with neighbouring fields field margins and in field strips can be implemented 3 3 4 landscape generator van strien et al 2016 this generator integrates different landscape metrics quantifying the landscape configuration and composition the distribution and clustering of land use classes as well as the proportion of adjacent landscape components can be determined e g hedgerows around fields the required input of the generator is configuration files with target values for the landscape metrics and an initial input raster in the ascii format that can either be a random percolation map or an existing landscape in random percolation maps each raster cell is randomly assigned to a predefined land use class with a certain probability gardner et al 1987 it can be created with several gis and programming languages e g r python the following landscape metrics can be varied on the class level or patch level number of patches for a certain land use class area of a certain patch maximum perimeter contact with another land use class shape of the bounding box of a patch total area within a bounding box occupied by a certain patch and the rectangular criterion the generator uses an optimisation algorithm to find landscapes of which the composition and configuration correspond to the target values of the landscape metrics it does so by iteratively swapping raster cells and determining whether the new landscape is an improvement with regard to the target values the algorithm contains stochastic components so the generation of two identical landscapes with the same input settings is not possible in return it is feasible to generate landscape series in which single landscape metrics are varied fig 6 3 3 5 genexp landsites software le ber et al 2009 le ber and mari 2013 this software simulates neutral agricultural landscapes to explore the variability of landscape characteristics and the variation in the geometry of fields fig 7 an irregular patchy landscape mosaic without fringe structures develops the field patterns are obtained by using two different tessellation methods the voronoi tessellation and a rectangular tessellation which make it possible to control the size number and the shape of fields the user can choose the kind of seed distribution original simulated or random the tessellation type voronoi or rectangular and the cropping pattern distribution random or stochastic the model provides a library to calculate basic landscape descriptors field area perimeter number of vertices centroid and shape file export is possible in raster or vector format and with shape files 3 3 6 sg4giscame structure generator inkoom et al 2017a b the sg4giscame structure generator which is a module within the giscame software uses voronoi tessellation and different algorithms to produce realistic landscape patterns fig 8 first the landscape is separated into a number of triangles from a regular midpoint triangulation the edge shape and size of the polygons can be altered through initial split and tolerance levels and spatial resolution as a second step the irregular triangles are merged to form more realistic polygons on the basis of a user designed or random process merging finally users can alter or refine the output geometry of the landscapes using either a manual distribution option or a cellular automaton algorithm refinement the resulting vector data are transformed into raster data and the output is an ascii text file a set of landscape pattern metrics is implemented to assess variations in landscape configuration and composition patch cohesion average patch shape contagion area weighted mean shape index and landscape patch index 3 3 7 landscape simulator papaïx et al 2014 the simple landscape simulator within the ddal framework generates a landscape mosaic based on the t tessellation simulation algorithm developed by kiêu et al 2013 fig 9 the input parameters number of fields field surface average field surface variability and the square like form of fields can be determined as a result it is possible to influence the degree of fragmentation of the landscape and to prevent triangular fields the simulator is coupled with a pathogen population dynamics model process based approaches the following two approaches work with explicit spatial locations determining the process being modelled by using the modelling platform dypal many different processes can be investigated at the landscape level e g the spatial aggregation and distribution of fields and hedges land use allocation and land use rotations the landscape processes are applied to landscape units by using one or more algorithms even though most of the previous applications of dypal are based on real landscape patterns gaucherel et al 2006a b have implemented neutral models patchy landscape neutral models in the software platform in contrast to the complex modelling platform dypal the g raffe model pe er et al 2013 generates landscapes based on a single process forest fragmentation by roads and the generation of agricultural fields 3 3 8 dypal gaucherel et al 2006a b dypal formerly known as l1 gaucherel et al 2006a b is a modelling platform for generic landscape modelling on various scales and landscape types field farm and region landscape processes such as hedgerow planting and removal when applied to landscape units lead to evolution in the composition and configuration of the landscape the alg can simulate the patch dynamics of fields as well as dynamic fringe structures such as hedgerows fig 10 the patches are defined as polygons but a pixel definition of the polygons was kept to be able to simulate continuous processes the required input parameters depend on the process being modelled the platform was designed around a kernel that provides an organisational data structure and a generic landscape structure several libraries provide specific algorithms permitting the handling of sets of points linear networks or a mosaic of adjacent polygons the user can freely choose the data structures the driving decisions and processes the simulation steps the level of detail of the description and the chosen scales several further developments of the software platform and a number of applications have been made so far gaucherel et al 2010 and gaucherel et al 2012 implemented additional mathematical models formal grammar equations into the platform to mechanistically simulate landscape dynamics bonhomme et al 2017 implemented further configurationally changes of patches that enable all possible operations and combine them into a coherent mathematical framework 3 3 9 g raffe pe er et al 2013 the simple process based simulator g raffe is able to generate the spatial patterns of agricultural fields embedded in a natural habitat esp forest that emerge from forest fragmentation by roads fig 11 three main parameters determine the generated landscapes the habitat cover the number of roads crossing the landscape and the field size an additional parameter maximum field disconnection specifies whether and to what distance agricultural fields can be detached from roads or other fields the model starts with a 100 forest landscape and then creates roads that lead straight through the landscape converting the forest into non forest roads are generated until the number of roads reaches the desired number unless the forest cover reaches the target value specified by the user once all roads have been generated agricultural fields are separated from them by a random movement of simulated farmers all fields have a square shape same length and height the size of which is derived from a uniform distribution between one and the maximum length specified by the user field expansion is a per step process that can stop when the potentially converted cells are beyond the map extent or when the desired forest cover is reached efforts lgraf dislich et al 2018 is an extended version of g raffe which additionally includes two different land uses and households fig 11 households can own several fields of different sizes with different land uses 3 4 composition composition here refers to the assignment of landscape elements configuration to different land cover types or structures however not all of the generators reviewed allow a finer differentiation in this respect table 2 the generated landscapes of g raffe consist only of forest and agricultural fields in which agricultural field is not further specified however agricultural fields can be covered with oil palm or rubber plantations in the extended version efforts lgraf the composition of the generated landscape described by van strien et al 2016 is defined by various land use categories regarding agricultural landscapes one case study on maize farmland with hedgerows has been carried out so far slager and de vries 2013 genexp landsites and presumably ddal can be coupled with external crop rotation models such as carrotage le ber et al 2006 whereby a wide range of crops can be taken into account the data mining software carrotage is based on high order hidden markov models for analysing spatio temporal cropping patterns many crop rotation approaches work with markov models to achieve a change in landscape configuration or composition markov models provide matrices with transition probabilities between different crop types similar matrices have been widely used for representing succession in forests horn et al 1975 these models are descriptive not mechanistic but they can be a starting point for realistic depictions of existing composition dynamics different policies can be implemented by manipulating the transition probabilities in ddal papaïx et al 2014 no explicit crop types have been implemented so far the number of land use types host types the proportions they cover and their level of spatial aggregation can be varied by applying a stochastic algorithm the other four generators work with pre defined crop types or land use classes which are distributed to the fields mostly according to stochastic rules of crop successions the landscape mosaic generator described by begg and dye 2015 describes crop rotations as first order markov chains usher 1992 only four crop types have been implemented so far but different land use types such as hedgerows flowering margins and conservation headlands can be chosen the number and type of 15 different crops can be varied in the landscape generator of everaars et al 2014 to build different cropping scenarios crops are allocated randomly or with a probability that equals the relative proportion to the agricultural fields for multiple subsequent scenarios in addition fields can be allocated with integrated biodiversity area iba defined as semi natural habitat dypal simulates deterministic or stochastic crop successions within farms while other landscape elements such as hedgerows forests and rivers can be depicted in gaucherel et al 2006 land use types are assigned to patches using the gibbs process which is derived from statistical physics caldiera and presutti 1974 and describes the local interactions between landscape units it is also possible to apply the gibbs process to landscape configurations gaucherel 2008 this can be achieved by editing the shape or size of the landscape patches or by selecting a gibbs pair function to constrain the relative positions of the seeds in sg4giscame inkoom et al 2017a b a large number of land use classes can be specified as well as their relative amount the distribution is based on transition probabilities and tolerable or intolerable neighbourhood settings in addition to crop types five of the algs can depict semi natural habitats such conservation headlands begg and dye 2015 integrated biodiversity areas everaars et al 2014 and forest gaucherel et al 2006a b pe er et al 2013 begg and dye 2015 inkoom et al 2017a b four of the algs were coupled with population modules pe er et al 2011 everaars et al 2014 papaïx et al 2014 begg and dye 2015 3 4 1 additional crop rotation tools as alternatives to carrotage a range of other crop rotation tools exist that can be used as a supplement to a landscape generator some useful examples are presented as follows landsfacts landscape scale functional allocation of crops temporally and spatially allocates a crop to each field for each simulation year in a gis shape file castellazzi et al 2008 2010 fields are represented as polygons in vector format with fixed boundaries the model is based on a stochastic process using the probabilities of crop to crop transitions markov chains and rule based constraints the linear optimisation model croprota schönhart et al 2009 2011 integrates agronomic criteria and observed land use data at field farm or regional scales in order to generate typical crop rotations for the particular scale rotat dogliotti et al 2003 is a computer program that combines crops from a predefined list to generate all possible different rotations a number of filters or rules based on explicit agronomic criteria and expert knowledge can be controlled by the user rotor bachinger and zander 2007 is a static rule based model for generating and evaluating site specific and agronomically sustainable crop rotations for organic farming systems in central europe rotor requires as input data field specific soil data mean annual precipitation and mean precipitation during the winter half year nepofarm horn 2017 is a landscape generator that creates farmland scenarios as input files for the honeybee model beehave becher et al 2014 field patches are allocated randomly in two british template landscapes and are characterised by crop type identity and crop diversity crop type number and relative abundance nepofarm is based on gis maps and is implemented in the freely available programming language r 3 5 validation validation here refers to testing whether landscapes generated by an alg reproduce realistic landscape features to validate the generated landscapes five of the reviewed approaches compared certain landscape metrics with real landscapes gaucherel et al 2006a b le ber et al 2009 pe er et al 2013 van strien et al 2016 inkoom et al 2017a b three of them pe er et al 2013 van strien et al 2016 inkoom et al 2017a b calculated the relevant landscape metrics of the real and computer generated landscapes by using fragstats mcgarigal et al 2012 the calculated landscape metrics can also be used as input parameters for the alg to approximate the computer generated landscape to the real one as a result the generated landscapes preserve the main characteristics of the original landscape while being configurationally different inkoom et al 2017a b used a turing test to explore expert visual judgement in comparing neutral landscapes to real landscapes the publications of the other approaches did not contain any evidence of validation 3 6 evaluation of policy measures here we summarise to what extent and how algs were used to evaluate existing or prospective policy measures addressing agricultural landscapes everaars et al 2014 simulated future scenarios of different land use changes due to policy making and economic aspects of bioenergy production the effectiveness of different mitigation strategies on farmland birds was analysed on the basis of the generated landscapes dypal has been developed inter alia to assess the environmental consequences of agricultural policies affecting processes that drive changes in landscape patterns and ecological functioning it was used to evaluate simplified common agricultural policy cap and cap reform decisions such as changing maize and cereals to fallow and temporary grassland gaucherel et al 2006a b houet et al 2010 used dypal to simulate plausible future states of landscape features such as hedgerows riparian wetlands and agricultural land covers based on hypotheses about future land management related to european policies the agbioscape modelling approach has the intention to develop an impact assessment and decision support tool for land management options including agri environmental schemes aess the potential of such a tool is to assist land managers and policy makers in identifying effective management options the landscape generator by slager 2011 was initially developed to generate plausible landscape configurations for participatory spatial plan making the study focuses on the construction of so called policy plan scenarios as a fundamental activity in spatial plan making 3 7 availability of the algs algs that have an executable version are mostly openly available on the internet table 3 however only dypal has open source code almost none of the algs are documented in detail instead only summary descriptions of the algorithms and data used are provided which also limits the level of detail by which we could characterise the algs above 3 8 other tools for generating neutral landscapes our definition of algs is rather restrictive as we require the potential to systematically vary landscape features in an automated way such generators have many advantages but there are also software tools or generators that are not algs according to our definition but are still certainly useful for more specific purposes here we give a brief overview of such tools that we found in our survey of the literature they have in common that they do not explicitly address agricultural landscapes or land use types rule is a software package for the generation of neutral landscape models and the analysis of landscape patterns gardner et al 1987 gardner 1999 gardner and walters 2002 landscape patterns are generated either as simple random processes random maps or as a result of spatially correlated processes using algorithms derived from fractal geometry multifractal maps qrule is a further development of rule retaining the essential features but providing statistical summaries based on area rather than pixel counts improving the formats of ancillary data sets and adding the potential for developing and analysing alternative neutral models gardner and urban 2007 the fractal realizer fr developed by hargrove et al 2002 generates multiple category synthetic landscape maps according to user specifications the synthetic landscapes show statistical properties similar to those of a particular empirical landscape and can be used to generate replicated input to spatial simulation models it generates fractal landscape patterns based on the midpoint displacement algorithm by saupe 1988 gradientland cambui et al 2014 is a free software program for generating a wide range of habitat cover gradients as random and fractal neutral landscapes in the fractal mode varying the aggregation and land cover is realised by using the midpoint displacement algorithm completely random patterns are produced by using a uniform probability distribution nlmpy etherington et al 2015 is a python software package for the creation of neutral landscapes within a general numerical framework it integrates a range of nlm algorithms that differ in the spatial autocorrelation of the element values in a two dimensional array it is open source can be used on any computer system and is easily combined with geographic information system gis data nlmr and landscapetools sciaini et al 2018 are r packages for simulating and modifying neutral landscape models in a single environment nlmr is a comprehensive collection of algorithms for creating neutral landscapes and landscapetools provides a utility toolbox which facilitates an easy workflow with neutral landscapes and other raster data hiebeler 2000 describes a simple algorithm for generating landscapes with spatially structured habitat heterogeneities the landscapes consist of rectangular lattices of sites or patches each characterised by a value indicating its habitat type hiebeler 2007 improved the landscape generation algorithm by using stratified sampling of sites rather than simple random sampling remmel and fortin 2013 utilize a stationary random field simulator remmel and csillag 2003 to produce large numbers of binary landscapes with identical parameters clearly defined descriptors of spatial pattern composition and configuration can be parameterized within the r statistical computing environment 4 outline of a future generic alg our review shows that currently no generic commonly used or useable alg exists but isolated solutions have been developed in specific contexts with specific purposes it seems impossible to design a single unifying alg that is able to cover all past and future applications and questions a generic alg would have to perform the balancing act of being both versatile and adaptable for case specific application in order to solve this dilemma in the following we would like to suggest a modular design for generic algs 4 1 specific requirements our idea behind generic algs is the development of a software tool in modular design the activation and deactivation of modules should be controllable with regard to the final result because the design of the landscapes can vary considerably depending on the final use likewise defined interfaces should exist for adding own specific modules the design depends above all on the simulation models to which the landscapes produced by the algs serve as an input these can be different types of dynamic models for example lucc models spatial ecological models that analyse the effects of landscapes on certain ecological aspects e g animal species or agent based land use models which analyse farmer s decisions under the influence of institutional markets policies and natural e g soil type framework conditions basically the generic algs create and systematically vary hypothetical agricultural landscapes spatial configuration and composition of field mosaics the following requirements should be fulfilled 1 pattern and or process based generation 2 the generation of a large number of random landscape maps in order to make general statements as well as the generation of specific landscapes 3 random and targeted distribution of landscape elements table 4 presents a tentative list of features that such a generic alg should have this list is our subjective merger of features that we based on our review consider essential all features should be separately testable and controllable essential elements are required to adapt the landscapes to a wide range of target model types optional elements allow tailoring the landscape to specific purposes the size and number of fields and the assignment of crop types are obligatory inputs regarding crop types coupling with a software program that generates crop types or rotations dogliotti et al 2003 bachinger and zander 2007 schönhart et al 2009 castellazzi et al 2010 can be useful additional landscape elements e g semi natural landscape elements and hedges are optional but can be decisive as in the case of pollinators even the addition of abiotic e g soil runoff relief and socio economic factors should be possible a gradient from very simple to very complex landscapes should be possible landscape complexity can successively be increased by adding certain features or modules the resulting landscape must have an adequate degree of complexity which is not just a technical or methodological question but a practice oriented one seppelt et al 2009 because scale grid type resolution and the degree of complexity have to be compatible with the simulation model to which the landscapes serve as input this also has an effect on the design of the landscape since some landscape elements are not visible at a particular resolution e g fine fringe structures 4 2 model and software architecture the optimal generic alg framework is open source fully documented and easy to use with regard to an integrative approach other open source models can be integrated quickly and easily according to agarwal et al 2002 initiating such an open source modelling effort will require several components 1 a web site to support modelling collaboration e g data and interactions among individuals such as bulletin boards and faqs 2 the establishment of one or more modelling kernels core components of models using various technologies that are designed in a modular fashion and allow participants to make enhancements with relative ease and 3 the development of mechanisms for sharing model enhancements that encourage participation and provide incentives that are comparable experience with the generic forest succession model landis ii scheller et al 2007 shows that it is crucial to employ modern software engineering techniques for software that is intended to be generic and used by many people scheller et al 2010 a modular model architecture meets the requirements for generic algs it enables the integration of building blocks of existing algs that have proven to be useful in the form of modules all modules can be easily revised such that the latest expert knowledge can always be integrated furthermore new modules can be added with little effort the algs should be operated via an intuitive graphical user interface that consists of different toolboxes with open source code for model development ideally the package concept of r would be adopted but this would require the existence of a core architecture and scheduler the algorithms and rationale of the algs have to be fully documented and a user manual and guided tour provided the algs should not only be a stand alone program but should also be usable as a library i e it can be started from every simulation model and generate landscapes during the simulation process on the fly such coupling is important particularly for optimisation models an interface to gis should exist to be able to alter real imported maps automatically using the algs various software platforms or programming languages could be envisaged for developing generic algs however no single language will be accepted and used by all potential users still if a certain widely used language is chosen such as c java or python programming interfaces should be provided that allow links to other languages if possible an alternative is to try to build on existing gis software one option is to use the arcgis modelbuilder but this might be suboptimal because this software is proprietary and still might not offer the full flexibility required a suitable solution might be based on a domain specific visual dataflow programming approach visual dataflow programming vdp is a programming paradigm that represents a program as a directed graph of data flows between operations wikipedia 2018 in visual dataflow programming users can assemble a program by placing operations nodes and connecting their data inputs and outputs in a graphical user interface fig 12 the appeal of vdp is that it combines high flexibility and extensibility with ease of use and program readability without programming knowledge in the context of an alg framework operations i e nodes would include basic gis operations such as a raster calculator buffer filters or voronoi diagram calculation as well as generators such as perlin noise or random points finally it would include output operations for different file formats and visualisation for debugging every operation can have input and output slots for defined data types e g floating point number integer raster vector layer the framework would be easily extensible through the addition of operations although some programming knowledge in the framework s implementation language would be necessary for the creation of new operations their mutual independence would greatly benefit flexibility and facilitate the exchange of operations between users or a central repository for official and community based extensions operations or bundles thereof one important advantage of this approach would be that it combines ease of use without having to learn a specific programming language with modularity and extensibility based on a widely used language in the supplementary material an example vdp program implemented in a prototype framework in scala is explained in detail to further illustrate the concept of vdp another generic approach to implementing modular generic algs are the so called pattern grammars gaucherel et al 2012 where landscape features are described using a certain syntax this approach has been widely used for functional structural plant modelling fspm using l systems grammar e g godin and sinoquet 2005 wang et al 2018 the alg dypal gaucherel et al 2006a b is based on such a grammar and is one of the most flexible existing algs 5 discussion the computer aided generation of agricultural landscapes can provide a framework for understanding and evaluating how land use and land cover changes will take place and affect the environment being input to simulation models the landscapes can serve as a basis for decision making for policy makers or as support for discussion and negotiation this especially concerns insights into the adequate scale of policies national or more regionalised but also into the relative importance of landscape structural elements for achieving societal goals with implications for the priorisation of conservation activities the results are useful for communicating policies and the corresponding landscape changes and environmental effects to local actors and to the public computer generated landscapes offer a number of advantages 1 they can fill the gap when real data are not available or are not at a suitable resolution and they allow us 2 to test new landscape configurations 3 to carry out systematic analyses of environmental gradients and 4 to perform spatial sensitivity analyses as a basis for the regional transferability of the results for these reasons we believe that the future lies in the computational evolution of landscape patterns not limited to random change the aim of each alg should be to design a plausible landscape with appropriate input parameters and algorithms this means that the generated landscape should not be more complex than necessary to serve as input for a simulation model or to answer the scientific or policy question still most existing algs represent rather simple agricultural landscapes via a few regularly shaped patches configurational changes are often realised by transition probabilities important questions though exist that would require more complex landscapes by for example adding semi natural habitats or applying advanced design rules which acknowledge the relationship between abiotic site conditions e g soil runoff relief and crop choice in this way all processes that lead to significant changes in configuration and use can be included 5 1 process based approaches the landscapes of process based algs are the result of the implemented process and are therefore strongly dependent on the input parameters users thus need to know and fully understand the effect of each input parameter to design specific landscapes an advantage of process based or mechanistic algs is that the underlying processes can be explicitly adressed so these landscapes are more likely to be relevant for the study of policy measures the disadvantage is that it can be difficult to quantify all the necessary parameters we found only two process based algs developed so far dypal is the most complex and most advanced one it integrates numerous algorithms as a basis for various processes while neutral models are already implemented for the composition landscape configuration is currently based on real landscapes that s the reason why this approach does not fully meet our selection criteria and cannot be compared very well with the other approaches nevertheless we have included it because it shows the possibilities of a process based generator the possibility to generate landscape configurations in a systematic and automated way would make the application of dypal much more versatile and flexible g raffe simulates the highly significant process by which primary forest is transformed into arable land the conversion is performed by simulated farm establishment subsequent to the generation of roads unfortunately agricultural fields cannot be assigned to different crops so this generator can only be used for the investigation of landscape dynamics rather than for agricultural questions 5 2 pattern based approaches pattern based algs usually require fewer parameters and less computing time than process based ones there are a variety of landscape metrics that can be used as input parameters e g the number and size of fields or the proportion of landscape elements most algs integrate only a few landscape metrics which limits the design of the landscape pattern and thus the range of possible applications to generate realistic agricultural landscapes a set of different landscape metrics is needed however one should consider that more input parameters as well as a larger grid size lead to more complicated algorithms and longer computing time to solve this problem efficient algorithms become important the strength of the agbioscape landscape mosaic generator is that it is already coupled with four population modules a conservation species an agricultural pest and two functionally distinct natural enemies to investigate the influence of management and land use patterns the generator can be used to generate simple field patterns from rectangular fields with fringe structures and to assign four different crop types to the fields the landscape generator of engel et al 2012 everaars et al 2014 also designs simple field patterns which can be assigned to 15 different crop types the focus is on the variation of crop proportions and the mean field size however it cannot vary the range of field sizes leading to quite artificial landscapes composed of square fields using the alg developed by van strien et al 2016 a differentiated landscape can be generated by integrating different landscape metrics that can be applied at either the field or class level the number of different land use classes can be defined but no specific crop types have been implemented so far with the tessellation methods applied in genexp landsites sg4giscame and the landscape simulator by papaöx et al 2014 irregular geometric field patterns are generated without fringe structures tessellations have the advantage that the general geometrical character as well as the spatial distribution of the agricultural landscape can be preserved the difficulty is in controlling important landscape features such as field sizes and shapes or distances between tessellation seeds while the tessellation methods allow one to simulate numbers of fields and average field sizes that are similar to those of real landscapes they do not correctly depict the shapes of the fields or the variability of these shapes within the landscape le ber et al 2009 genexp landsites produces slightly too compact fields with little variability while the rectangular tessellation produces over elongated fields with too high variability as a result this alg generates landscapes with configurations of limited realism and landscape dynamics cannot be investigated very well in contrast sg4giscame provides a better representation of field shapes through higher flexibility and refinement algorithms 5 3 simulating crops in most existing algs crop types are defined only marginally le ber et al 2009 papaïx et al 2014 begg and dye 2015 van strien et al 2016 dislich et al 2018 or not at all pe er et al 2013 this means that although there are various land use patterns from agricultural fields there are few specific farming systems however representing land cover in more detail is essential to answer many questions regarding agricultural landscapes the tessellation method for example offers little possibility for handling attributes of landscape composition but it can be combined with crop rotation models statistical modelling of crop rotations in general and markov models in particular are suitable tools for predicting crop types however markov models per se are empirical based on observed transitions of land use types or are fully hypothetical therefore they should be constrained by conditional rules based on expert knowledge 5 4 evaluating policy measures by using computer generated landscapes in simulation models agricultural policies can be evaluated quickly and effectively at the local or regional scale this is an advantage over field observations and long term field experiments which are more time consuming but obtain higher precision and validity both methods have their pros and cons and should be used and supplemented according to their capabilities the rapid evaluation and prediction of environmental effects related to policies are a great strength of simulation models and are essential to propose and implement sustainable and efficient environmental policies however since the so far generated landscapes are often rather simple the application as a tool for evaluating policy measures is still limited because the results are only partially transferable to reality validation not only of the simulation models used but also of the alg is crucial in this context here validation means providing evidence that alg generated landscapes are able to capture essential features of existing and planned landscapes 5 5 challenges limitations we have tried to describe existing alg approaches in the same depth and with regard to the same criteria unfortunately not only are the approaches themselves very different in terms of methodology but they are also often incomplete in their description which makes them difficult to compare the approaches are not des cribed in the same way terminologies differ and much of the information we have been looking for is not available this leads to incompleteness in the description of some approaches and possibly to biases alg descriptions following a standardised protocol would be extremely helpful and a desirable standard for publications in the future for example the odd protocol which is a standard format for describing individual or agent based models grimm et al 2006 2010 could be adopted for this purpose the algs presented here have mostly only been used within the research group that developed them thus they were not designed for general application and availability nor were they designed with user friendliness in mind generic algs will require well designed software and detailed documentation so that the user can quickly become familiar with the alg s functionality and understand exactly which application possibilities are available in our opinion the generator developed by van strien et al 2016 comes closest to meeting these demands a well documented open source code can be further developed and enriched by the scientific community and it can be used for other models until now most algs have been developed in isolation because no consistent terminology regarding landscape generators exists and because we had to focus on isi listed publications we might have overlooked further relevant algs although we could not find references to any further algs in the publications we reviewed our review shows that the development of computer generated agricultural landscapes is still in its infancy most generators generate simple landscapes which limits the range of application in most cases the main focus is on either the spatial configuration or the composition not on both in a balanced way all approaches still have great potential for further development towards broader applicability to address the multi functionality of landscapes generic algs should include other land use types such as forests or settlements pattern oriented modelling can be used for example to identify relevant landscape metrics the alignment of computer generated landscapes with real landscapes still has much potential for improvement this can be made possible by the further development of specific algorithms and calibration or validation with high resolution data on cultivation systems and abiotic factors an important data input for future algs will be remote sensing data e g pettorelli et al 2016 which open up new approaches for identifying land use types e g joshi et al 2016 5 6 outlook as a result of our review we derived requirements for generic future algs that have the potential to be widely used in landscape science environmental questions can be examined on certain spatial scales and transferred to other scales that are not feasible to explore in reality however the difficulty of computer generated landscapes is that they represent few landscape features well simultaneously each extension leads to a more complicated algorithm and longer calculation time this leads to the classical modeller s dilemma of when functionality falls victim to complexity therefore the complexity of the model has to be carefully considered as well as how versatile the alg can and should be it is important to give the user the possibility of prioritising e g which landscape features should be exact and which can be approximate generic algs thus needs to have a modular and preferably open architecture in the supplement we outline one possible solution but other solutions certainly exist in any case although the architecture of generic algs might be set up by individual groups of researcher e g the approach that we outline above and in the supplement or approaches based on pattern grammar gaucherel et al 2006a b gaucherel et al 2012 establishing a modular framework would have to be a community activity ideally national or european funding agencies would initiate such joint projects similar to the eu initiative to standardize models of the fate of pesticides in surface waters focus 2001 6 conclusion systematically generating variable virtual landscapes as a basis for spatially explicit assessment opens up new ways of exploring environmental issues there is an enormous field of application particularly with regard to the evaluation of policy measures critical threshold values of environmental effects can be identified at an early stage and suitable mitigation measures can be developed due to the enormous application potential the significance of landscape generators as a basis for spatial simulation models will continue to grow in the future and they will be a useful complement to real landscapes and long term field studies however considerable development work is still needed to improve and generalise the generators which would be feasible in a joint project in the open source context we expect that 5 10 years are needed to develop successively such a generic alg framework and that considerable manpower and data sources are needed in europe this would ideally be the scope of eu funded projects hot topics such as the decline of pollinators such as honeybees potts et al 2010 horn 2017 evaluating and improving the effectiveness of the cap reform pe er et al 2014 or the safe provisioning of the full bundle of ecosystem services raudsepp hearne et al 2010 emphasise that investing in developing a generic modular alg would not only pay off well but might actually by crucial acknowledgements m l acknowledges funding of this project from the heinrich böll foundation germany appendix a appendix b supplementary data supplementary material related to this article can be found in the online version at doi https doi org 10 1016 j ecolmodel 2018 12 010 appendix b supplementary data the following is supplementary data to this article 
25134,virtually all current major social and environmental challenges such as financial crises migration the erosion of democratic institutions and the loss of biodiversity involve complex systems comprising decision making interacting adaptive agents to understand how such agent based complex systems function and respond to change and disturbances agent based modeling abm is increasingly recognized as the main way forward many motivating examples of agent based models exist that are realistic enough to successfully support the management of complex systems but these solutions are case specific and contribute few general insights into the functioning of systems general theory though is highly needed because we cannot model each system and question still across disciplines a critical mass of expertise has accumulated that could transform abm into a more coherent and efficient approach to discover the functioning of complex social economic ecological systems to this end we need a cross disciplinary discussion among researchers and a goal oriented synthesis to identify the general principles and theories essential to improve our understanding and management of complex systems keywords individual based modeling theory development epistemological perspectives 1 motivation we live in networks lazer et al 2009 where individual actions and institutional policies may have unintended consequences that are hard to oversee or even predict digitalization and information technology link different areas so that systems that used to be separate are now interconnected and interdependent sargut and mcgrath 2011 p 70 analyzing understanding predicting and managing the dynamics of these agent based complex systems acss are some of the most urgent issues these days sargut and mcgrath 2011 to understand how such systems function and respond to environmental changes and disturbances agent based modeling abm also called individual based modeling ibm is increasingly recognized as the main way forward macal 2016 law 2015 the approach captures dynamics that arise from the behavior and interactions of individual agents such as bird flocking behavior and the s shaped diffusion process of innovations in markets resulting from individual consumer adoption decisions schubring et al 2016 garcia and jager 2011 abm allows for a holistic view by linking different levels of an organization gräbner 2016 p 245 for example agent based models describing the complex socioeconomic dynamics of land use at multiple levels are suitable to explore the particular impacts of environmental settings on the mitigation and adaptation strategies of humans or organizations to climate change balbi and giupponi 2009 by performing simulation experiments explanations of complex developments can be found that are too complex to oversee otherwise this may also include the consideration of rare or improbable events to be better prepared for the future consequently abm is of increasing relevance and we find applications in virtually all research fields where adaptive agents matter such as socio ecology balbi and giupponi 2009 deangelis and mooij 2005a tesfatsion 2002 economics tesfatsion 2002 management kiesling et al 2012 geography heppenstall et al 2011 crooks and heppenstall 2012 and ecology railsback and johnson 2011 notwithstanding the relevance of understanding acss and the value of abm for accomplishing this goal the method seems stuck in a stage of ad hoc model development and exploration besides all the merits of abm applications scientific progress in abm has been slower than expected which was poignantly described by nobel laureate paul krugman as follows i was one of the people who got all excited about the possibility of getting somewhere with very detailed agent based models but that was 20 years ago and after all this time it s all still manifestos and promises of great things one of these days krugman 2010 the majority of existing agent based models focus on specific systems which limits their generality the scientific community recognizes this more and more and the current situation has been described recently as the yet another model syndrome o sullivan et al 2016 presenting model after model without accumulating general theoretical insights into systems and their dynamics as a consequence there is a call for theoretical engagement o sullivan et al 2016 p 184 and it is the aim of this paper to open a dialog on theory development through abm we claim that to cope with the challenges of modern complex and highly interconnected acss we have to complement the current focus on single cases with a second perspective regarding the identification of more general principles at the system level we need to identify and understand the general principles such as acss self organization their ability to cope with change and stress resilience and their propensity toward catastrophic sudden changes regime shifts egli et al 2018 similarly there is a need to more systematically accumulate knowledge at the level of individual behaviors in the form of say reusable generic submodules of agents for this purpose we need tested well understood and modular building blocks that are ready to implement in the agent based models of specific acss this would increase credibility and allow for systematic learning beyond the respective case which in the end improves the predictive capabilities of our models 2 reasons for the current situation we see at least three possible reasons why this has not been achieved so far first it might paradoxically result from a key benefit of abm namely its flexibility and ability to embrace complexity this involves many degrees of freedom in the modeling process keeping such agent based models at a generic level for example by trying to model pastoralist systems in general would leave room for so many possible outcomes that the model would be of little use for practical purposes such generic agent based models exist for example on opinion dynamics cultural dissemination and segregation but it remains unclear how well they capture the organization of real systems to avoid this abm developers that strive for inferences about the real world relate their modeling efforts to specific empirical cases which is reflected in an increasing number of empirically validated and calibrated models stillman et al 2015 this research strategy narrows the degrees of freedom in model parameters and structure which leads to testable predictions and management recommendations for the modeled system the price for this is a loss of generality both because a specific system is modeled and because the focus on this system and robust predictions seem to prevent most abm developers from thinking about general principles or theories that go beyond their specific case second abm is a sophisticated research tool which comes with its methodological challenges due to the inherent complexity of many agent based models there are concerns about their internal validity lehtinen and kuorikoski 2007 p 323 and our ability to understand these models this skepticism has been expressed by roughgarden 2012 p 8 with simulation it may be impossible to drill down to what assumptions are responsible for conclusions to discern the causal connections between initial conditions and results and simulation invites unsophisticated and sloppy research together with naive hocus pocus about the magic of emergence in many disciplines an exclusive link between the analytical tractability of models and theory is taken for granted evans et al 2013 in particular economics endorses analytical solutions as a necessary precondition for contributions to theory lehtinen and kuorikoski 2007 although it often requires an oversimplification of the described processes hindering its suitability to tackle most problems of complex systems abm provides a new avenue to model interdependencies and processes in algorithmic structures which gives the theory generating process a new appearance the specifics of the method and the new methodological challenges that follow from this however have slowed theory development so far third it might take time for a complex approach such as abm to mature calculus or statistics were not developed in just a few decades in ecology which has the longest history of using agent based models vincenot 2018 such models are now accepted as a tool for tackling applied problems but not for identifying general principles or developing a general theory evans et al 2013 there are indeed indicators of the methodological maturation of abm including topics such as standardized communication validation and sensitivity analysis grimm and berger 2016b hauke et al 2017 schulze et al 2017 these tentative explanations of the current situation are not exclusive and have to be explored further if we want to make abm suitable for much needed theory development 3 theory development through abm there is still little awareness of the need for a more general theory in abm or such a theory is considered to be impossible to achieve with this approach theories explain reoccurring patterns also referred to as stylized facts signals or regularities and describe how the system in question is internally organized computational modeling is the next level of theory development that allows for the formalization of interactions and adaptation processes further abm can combine multiple approaches and go side by side with mathematical models by including probability functions or logical rules in submodels in particular we seek two kinds of theories theories addressing the system and theories addressing the behavior of agents the first perspective aims to identify patterns at the system level to understand the underlying organization of acss from the second perspective we include alternative submodels of agent behavior to analyze the macro response at the system level ultimately these two kinds of theories need to be matched to each other because the behavior of agents and system level features are inseparably linked agent based theory development is thus cross level this is in contrast to theory in many other fields for example theory in community ecology ignores behavior whereas theory in classical behavioral ecology ignores feedback at higher organizational levels for some systems cross level theory development through abm has already worked well e g models explaining the emergence of fish schools and bird flocks the latter started by assuming that fixed distances determine behavior before realizing that real birds in fact take six to eight neighbors into account finally they managed to reproduce observed patterns by also including the basic principles of flight physics e g hemelrijk and hildenbrandt 2015 similarly theory development should also be the aim of abm linking behavior to the observed patterns of systems where the behavioral context is more complex than in bird flocks another good example of theory development through abm is the study by martin et al 2013 this simulation study shows how one generic theory namely dynamic energy budget theory can be used to extrapolate the effect of toxicants measured at the individual level to effects on population dynamics this study reproduces the population density by one food level beyond this the results showed the density and size distribution of multiple food levels and toxicant exposure which was not seen before this study also provides a good example of how circularity can be avoided as it produces new predictions empirical knowledge is an important source of patterns and candidate submodels of behavior experts can also be the first to formulate a hypothesis on why certain things happen likewise the stakeholders perspective helps asking relevant questions about a system and thereby developing theory that is related to real world problems within the limits of the formalized system we may using abm and theory development achieve a deep understanding of interdependencies and process trajectories that would be hard to obtain otherwise the theory supports a coherent understanding of complex systems thus explicating their relevant features in a systematic way alternative approaches based on highly stylized representations are less likely to lead to testable theories because they rather demonstrate certain concepts or ideas than real systems models based on opinion dynamics in social sciences and lotka volterra models in ecology are prominent examples abm has some challenges that are similar to those of other modeling approaches acss are not always self defined but we have to define their boundaries which is not often easy we think that the formalization of a defined system by one valid model may produce hypotheses of patterns suitable to represent a particular system this can be done for example by robustness analyses grimm and berger 2016a and even extended sensitivity analyses to achieve generality however we would ideally focus on generic patterns that define classes of systems not only specific ones for example tree grass coexistence in savannas it is important though to go beyond single patterns and try to reproduce entire sets of patterns pattern oriented modeling grimm and railsback 2012 theory development with agent based models also needs to consider the algorithmic nature of acss these systems are driven by context dependent and stochastic events such as natural selection and the life history of individuals dennett and mittwoch 1996 although aspects of acss may be captured by mathematical models that are analytically tractable algorithmic representations provided by abm might be more adequate for many purposes in ecology this already leads to standard algorithms in certain ecological settings see for example the zone of influence approach for the description of local interactions among plants weiner et al 2001 berger et al 2008 moreover to represent home range behavior or territorial dynamics we do not need a new approach in every single model rather we can build on existing models which are based either on maps of habitat quality e g wang and grimm 2007 carter et al 2014 or on tracking data and the assumption that animals remember good places e g nabe nielsen et al 2018 taking such an algorithmic perspective involves further challenges which have to be handled first it requires a more intensive cultivation of the skill of computational thinking such as the algorithmic problem solving and abstraction techniques developed by computer scientists wing 2006 second as already indicated above it might also change the role of mathematics and simulation with respect to theory development theories about acss that cannot be expressed mathematically can be represented algorithmically to allow for generalizations a possible contribution of mathematics could be then to formulate a theory of algorithms in terms of culture this could affect the different traditions in ecology economics and the other social sciences e g how mathematics and computer simulations are applied and relate to each other answers to these challenges emerge but are distributed among many disciplines and have to be incorporated 4 next steps how to move forward first each agent based modeler can contribute more to theory development by referring as required in the odd overview design concepts details protocol s design concept of basic principles grimm et al 2010 2006 to the general theories and concepts that guide the design of the model and by explicitly discussing the model s results in terms of these theories did they work were they useful did they need to be refined within the agent based model why also the fact that systems often depict stable patterns also referred to as stylized facts could be a possible way forward first there could be some general mechanism creating them if these patterns are similar for different systems even among classes of systems this might provide further possible avenues for theory development second these patterns might contain information that can provide insights into the general working of the system or the process under investigation in addition we need methods and approaches that support the theory development process in abm some approaches already exist that may improve the specification and analysis of models in this regard to focus on both theory and application we need to force cloudy areas to be addressed in clear specification harrison et al 2007 p 1233 the odd protocol for model specification supports this process grimm et al 2010 2006 systematic designs of experiments support the analysis of simulation models to draw valid and reliable conclusions from simulation results lorscheid et al 2012 lorscheid and meyer 2016 all these approaches can contribute to improving the rigor of agent based models and offer systematic ways for valid theory development by abm in addition various ways of theory development have been suggested including pattern oriented theory development grimm and railsback 2012 railsback and harvey 2013 breaking models thiele and grimm 2015 and robustness analysis grimm and berger 2016a management research and sociology have developed strategies on how to derive theory from single or multiple case studies the principles of pattern oriented modeling and stylized facts for example can be of added value to focus on and evaluate the core mechanics of a model grimm et al 2005 meyer 2019 heine et al 2005 unfortunately these methods have never been sufficiently considered or discussed across the disciplinary boundaries nor combined in an overall systematic research strategy this discussion however is necessary abm researchers need to develop concrete roadmaps and practical guidelines to open ways for more coherent and rigorous research that in the long run also leads to a better acceptance of agent based theory this quest for theory also poses the question of how to organize our collective learning and gather best practices how can we accumulate knowledge more systematically from our model based analyses of acss systematic reviews of existing agent based models with respect to their core mechanisms would allow us to identify similarities and differences in the investigated cases a set of the typical patterns stylized facts of different classes of acss might also be used as a coordinating device for modeling efforts meyer 2011 heine et al 2005 as hilbert s problems set a challenge for mathematics explaining the patterns observed regularly for certain acss may set the path for a community of modelers in a domain both efforts might lead to better knowledge of the underlying organization of acss given the general character of these questions the epistemological perspective is also critical but often ignored by the community of abm developers it is important to keep in mind that theory has multiple meanings ranging from the colloquial interpretation as speculative guess or conjecture to its interpretation in physics as an explanation of observed phenomena that have been well confirmed by testing the theory s predictions what kinds of predictions can we expect or should we aim for with agent based models should we seek theory rather at the level of the agent s behavior or is it also possible at the entire system level 5 conclusion this paper cannot depict a fully developed solution but wants to open the dialog concerning the posed problem and possible ways out without such a general quest for theory development abm will continue delivering patchwork results which is insufficient to meet the grand societal and environmental challenges in our interconnected and fast changing world instead of developing agent based models for each question and system we need to identify robust principles that allow both individuals and policymakers to make the right decisions this is a call towards a general cross level and cross disciplinary theoretical engagement concerning acss following the call for theoretical engagement o sullivan et al 2016 p 184 the modeling community needs 1 to gain a better understanding of how to use abm to derive the general principles of the complex systems we live in for this we need a cross disciplinary discussion and a goal oriented synthesis to transform abm into a more coherent efficient approach to identify general principles and theories 2 a compilation and critical reflection of existing methods and best practice in abm research fostering the development and dissemination of standards this also requires a discussion of the existing gaps and obstacles for successful theory development through abm including a philosophical discussion on whether abm extends classical theory to more complex situations or represents a radically new research program deangelis and mooij 2005b 3 to formulate a roadmap to overcome current obstacles to use the potential of abm as a powerful and much needed approach for theory development the main purpose of this call is to create awareness of these challenges we invite peers in all disciplines using abm to relate their more or less case specific work to theory and consider theory development to be an integral part of even the most applied abm if we all force ourselves to include in all our abm publications at least one paragraph in the discussion addressing the question what have we learned in terms or general theory we would already contribute to this first important step we invite complementary or opposing views to those expressed by us and we hope to instigate a much needed discussion on theory development among agent based modelers which hopefully will result in explicit articles special issues and projects we ourselves are organizing a series of three workshops entitled from cases to general principles theory development through agent based modeling 1 1 the events will take place in hanover germany in 2018 2020 for the website on this initiative see www abm theory org these symposia will provide a platform to connect modelers from different disciplines and epistemologists for critical reflections and the collection of best practices 
25134,virtually all current major social and environmental challenges such as financial crises migration the erosion of democratic institutions and the loss of biodiversity involve complex systems comprising decision making interacting adaptive agents to understand how such agent based complex systems function and respond to change and disturbances agent based modeling abm is increasingly recognized as the main way forward many motivating examples of agent based models exist that are realistic enough to successfully support the management of complex systems but these solutions are case specific and contribute few general insights into the functioning of systems general theory though is highly needed because we cannot model each system and question still across disciplines a critical mass of expertise has accumulated that could transform abm into a more coherent and efficient approach to discover the functioning of complex social economic ecological systems to this end we need a cross disciplinary discussion among researchers and a goal oriented synthesis to identify the general principles and theories essential to improve our understanding and management of complex systems keywords individual based modeling theory development epistemological perspectives 1 motivation we live in networks lazer et al 2009 where individual actions and institutional policies may have unintended consequences that are hard to oversee or even predict digitalization and information technology link different areas so that systems that used to be separate are now interconnected and interdependent sargut and mcgrath 2011 p 70 analyzing understanding predicting and managing the dynamics of these agent based complex systems acss are some of the most urgent issues these days sargut and mcgrath 2011 to understand how such systems function and respond to environmental changes and disturbances agent based modeling abm also called individual based modeling ibm is increasingly recognized as the main way forward macal 2016 law 2015 the approach captures dynamics that arise from the behavior and interactions of individual agents such as bird flocking behavior and the s shaped diffusion process of innovations in markets resulting from individual consumer adoption decisions schubring et al 2016 garcia and jager 2011 abm allows for a holistic view by linking different levels of an organization gräbner 2016 p 245 for example agent based models describing the complex socioeconomic dynamics of land use at multiple levels are suitable to explore the particular impacts of environmental settings on the mitigation and adaptation strategies of humans or organizations to climate change balbi and giupponi 2009 by performing simulation experiments explanations of complex developments can be found that are too complex to oversee otherwise this may also include the consideration of rare or improbable events to be better prepared for the future consequently abm is of increasing relevance and we find applications in virtually all research fields where adaptive agents matter such as socio ecology balbi and giupponi 2009 deangelis and mooij 2005a tesfatsion 2002 economics tesfatsion 2002 management kiesling et al 2012 geography heppenstall et al 2011 crooks and heppenstall 2012 and ecology railsback and johnson 2011 notwithstanding the relevance of understanding acss and the value of abm for accomplishing this goal the method seems stuck in a stage of ad hoc model development and exploration besides all the merits of abm applications scientific progress in abm has been slower than expected which was poignantly described by nobel laureate paul krugman as follows i was one of the people who got all excited about the possibility of getting somewhere with very detailed agent based models but that was 20 years ago and after all this time it s all still manifestos and promises of great things one of these days krugman 2010 the majority of existing agent based models focus on specific systems which limits their generality the scientific community recognizes this more and more and the current situation has been described recently as the yet another model syndrome o sullivan et al 2016 presenting model after model without accumulating general theoretical insights into systems and their dynamics as a consequence there is a call for theoretical engagement o sullivan et al 2016 p 184 and it is the aim of this paper to open a dialog on theory development through abm we claim that to cope with the challenges of modern complex and highly interconnected acss we have to complement the current focus on single cases with a second perspective regarding the identification of more general principles at the system level we need to identify and understand the general principles such as acss self organization their ability to cope with change and stress resilience and their propensity toward catastrophic sudden changes regime shifts egli et al 2018 similarly there is a need to more systematically accumulate knowledge at the level of individual behaviors in the form of say reusable generic submodules of agents for this purpose we need tested well understood and modular building blocks that are ready to implement in the agent based models of specific acss this would increase credibility and allow for systematic learning beyond the respective case which in the end improves the predictive capabilities of our models 2 reasons for the current situation we see at least three possible reasons why this has not been achieved so far first it might paradoxically result from a key benefit of abm namely its flexibility and ability to embrace complexity this involves many degrees of freedom in the modeling process keeping such agent based models at a generic level for example by trying to model pastoralist systems in general would leave room for so many possible outcomes that the model would be of little use for practical purposes such generic agent based models exist for example on opinion dynamics cultural dissemination and segregation but it remains unclear how well they capture the organization of real systems to avoid this abm developers that strive for inferences about the real world relate their modeling efforts to specific empirical cases which is reflected in an increasing number of empirically validated and calibrated models stillman et al 2015 this research strategy narrows the degrees of freedom in model parameters and structure which leads to testable predictions and management recommendations for the modeled system the price for this is a loss of generality both because a specific system is modeled and because the focus on this system and robust predictions seem to prevent most abm developers from thinking about general principles or theories that go beyond their specific case second abm is a sophisticated research tool which comes with its methodological challenges due to the inherent complexity of many agent based models there are concerns about their internal validity lehtinen and kuorikoski 2007 p 323 and our ability to understand these models this skepticism has been expressed by roughgarden 2012 p 8 with simulation it may be impossible to drill down to what assumptions are responsible for conclusions to discern the causal connections between initial conditions and results and simulation invites unsophisticated and sloppy research together with naive hocus pocus about the magic of emergence in many disciplines an exclusive link between the analytical tractability of models and theory is taken for granted evans et al 2013 in particular economics endorses analytical solutions as a necessary precondition for contributions to theory lehtinen and kuorikoski 2007 although it often requires an oversimplification of the described processes hindering its suitability to tackle most problems of complex systems abm provides a new avenue to model interdependencies and processes in algorithmic structures which gives the theory generating process a new appearance the specifics of the method and the new methodological challenges that follow from this however have slowed theory development so far third it might take time for a complex approach such as abm to mature calculus or statistics were not developed in just a few decades in ecology which has the longest history of using agent based models vincenot 2018 such models are now accepted as a tool for tackling applied problems but not for identifying general principles or developing a general theory evans et al 2013 there are indeed indicators of the methodological maturation of abm including topics such as standardized communication validation and sensitivity analysis grimm and berger 2016b hauke et al 2017 schulze et al 2017 these tentative explanations of the current situation are not exclusive and have to be explored further if we want to make abm suitable for much needed theory development 3 theory development through abm there is still little awareness of the need for a more general theory in abm or such a theory is considered to be impossible to achieve with this approach theories explain reoccurring patterns also referred to as stylized facts signals or regularities and describe how the system in question is internally organized computational modeling is the next level of theory development that allows for the formalization of interactions and adaptation processes further abm can combine multiple approaches and go side by side with mathematical models by including probability functions or logical rules in submodels in particular we seek two kinds of theories theories addressing the system and theories addressing the behavior of agents the first perspective aims to identify patterns at the system level to understand the underlying organization of acss from the second perspective we include alternative submodels of agent behavior to analyze the macro response at the system level ultimately these two kinds of theories need to be matched to each other because the behavior of agents and system level features are inseparably linked agent based theory development is thus cross level this is in contrast to theory in many other fields for example theory in community ecology ignores behavior whereas theory in classical behavioral ecology ignores feedback at higher organizational levels for some systems cross level theory development through abm has already worked well e g models explaining the emergence of fish schools and bird flocks the latter started by assuming that fixed distances determine behavior before realizing that real birds in fact take six to eight neighbors into account finally they managed to reproduce observed patterns by also including the basic principles of flight physics e g hemelrijk and hildenbrandt 2015 similarly theory development should also be the aim of abm linking behavior to the observed patterns of systems where the behavioral context is more complex than in bird flocks another good example of theory development through abm is the study by martin et al 2013 this simulation study shows how one generic theory namely dynamic energy budget theory can be used to extrapolate the effect of toxicants measured at the individual level to effects on population dynamics this study reproduces the population density by one food level beyond this the results showed the density and size distribution of multiple food levels and toxicant exposure which was not seen before this study also provides a good example of how circularity can be avoided as it produces new predictions empirical knowledge is an important source of patterns and candidate submodels of behavior experts can also be the first to formulate a hypothesis on why certain things happen likewise the stakeholders perspective helps asking relevant questions about a system and thereby developing theory that is related to real world problems within the limits of the formalized system we may using abm and theory development achieve a deep understanding of interdependencies and process trajectories that would be hard to obtain otherwise the theory supports a coherent understanding of complex systems thus explicating their relevant features in a systematic way alternative approaches based on highly stylized representations are less likely to lead to testable theories because they rather demonstrate certain concepts or ideas than real systems models based on opinion dynamics in social sciences and lotka volterra models in ecology are prominent examples abm has some challenges that are similar to those of other modeling approaches acss are not always self defined but we have to define their boundaries which is not often easy we think that the formalization of a defined system by one valid model may produce hypotheses of patterns suitable to represent a particular system this can be done for example by robustness analyses grimm and berger 2016a and even extended sensitivity analyses to achieve generality however we would ideally focus on generic patterns that define classes of systems not only specific ones for example tree grass coexistence in savannas it is important though to go beyond single patterns and try to reproduce entire sets of patterns pattern oriented modeling grimm and railsback 2012 theory development with agent based models also needs to consider the algorithmic nature of acss these systems are driven by context dependent and stochastic events such as natural selection and the life history of individuals dennett and mittwoch 1996 although aspects of acss may be captured by mathematical models that are analytically tractable algorithmic representations provided by abm might be more adequate for many purposes in ecology this already leads to standard algorithms in certain ecological settings see for example the zone of influence approach for the description of local interactions among plants weiner et al 2001 berger et al 2008 moreover to represent home range behavior or territorial dynamics we do not need a new approach in every single model rather we can build on existing models which are based either on maps of habitat quality e g wang and grimm 2007 carter et al 2014 or on tracking data and the assumption that animals remember good places e g nabe nielsen et al 2018 taking such an algorithmic perspective involves further challenges which have to be handled first it requires a more intensive cultivation of the skill of computational thinking such as the algorithmic problem solving and abstraction techniques developed by computer scientists wing 2006 second as already indicated above it might also change the role of mathematics and simulation with respect to theory development theories about acss that cannot be expressed mathematically can be represented algorithmically to allow for generalizations a possible contribution of mathematics could be then to formulate a theory of algorithms in terms of culture this could affect the different traditions in ecology economics and the other social sciences e g how mathematics and computer simulations are applied and relate to each other answers to these challenges emerge but are distributed among many disciplines and have to be incorporated 4 next steps how to move forward first each agent based modeler can contribute more to theory development by referring as required in the odd overview design concepts details protocol s design concept of basic principles grimm et al 2010 2006 to the general theories and concepts that guide the design of the model and by explicitly discussing the model s results in terms of these theories did they work were they useful did they need to be refined within the agent based model why also the fact that systems often depict stable patterns also referred to as stylized facts could be a possible way forward first there could be some general mechanism creating them if these patterns are similar for different systems even among classes of systems this might provide further possible avenues for theory development second these patterns might contain information that can provide insights into the general working of the system or the process under investigation in addition we need methods and approaches that support the theory development process in abm some approaches already exist that may improve the specification and analysis of models in this regard to focus on both theory and application we need to force cloudy areas to be addressed in clear specification harrison et al 2007 p 1233 the odd protocol for model specification supports this process grimm et al 2010 2006 systematic designs of experiments support the analysis of simulation models to draw valid and reliable conclusions from simulation results lorscheid et al 2012 lorscheid and meyer 2016 all these approaches can contribute to improving the rigor of agent based models and offer systematic ways for valid theory development by abm in addition various ways of theory development have been suggested including pattern oriented theory development grimm and railsback 2012 railsback and harvey 2013 breaking models thiele and grimm 2015 and robustness analysis grimm and berger 2016a management research and sociology have developed strategies on how to derive theory from single or multiple case studies the principles of pattern oriented modeling and stylized facts for example can be of added value to focus on and evaluate the core mechanics of a model grimm et al 2005 meyer 2019 heine et al 2005 unfortunately these methods have never been sufficiently considered or discussed across the disciplinary boundaries nor combined in an overall systematic research strategy this discussion however is necessary abm researchers need to develop concrete roadmaps and practical guidelines to open ways for more coherent and rigorous research that in the long run also leads to a better acceptance of agent based theory this quest for theory also poses the question of how to organize our collective learning and gather best practices how can we accumulate knowledge more systematically from our model based analyses of acss systematic reviews of existing agent based models with respect to their core mechanisms would allow us to identify similarities and differences in the investigated cases a set of the typical patterns stylized facts of different classes of acss might also be used as a coordinating device for modeling efforts meyer 2011 heine et al 2005 as hilbert s problems set a challenge for mathematics explaining the patterns observed regularly for certain acss may set the path for a community of modelers in a domain both efforts might lead to better knowledge of the underlying organization of acss given the general character of these questions the epistemological perspective is also critical but often ignored by the community of abm developers it is important to keep in mind that theory has multiple meanings ranging from the colloquial interpretation as speculative guess or conjecture to its interpretation in physics as an explanation of observed phenomena that have been well confirmed by testing the theory s predictions what kinds of predictions can we expect or should we aim for with agent based models should we seek theory rather at the level of the agent s behavior or is it also possible at the entire system level 5 conclusion this paper cannot depict a fully developed solution but wants to open the dialog concerning the posed problem and possible ways out without such a general quest for theory development abm will continue delivering patchwork results which is insufficient to meet the grand societal and environmental challenges in our interconnected and fast changing world instead of developing agent based models for each question and system we need to identify robust principles that allow both individuals and policymakers to make the right decisions this is a call towards a general cross level and cross disciplinary theoretical engagement concerning acss following the call for theoretical engagement o sullivan et al 2016 p 184 the modeling community needs 1 to gain a better understanding of how to use abm to derive the general principles of the complex systems we live in for this we need a cross disciplinary discussion and a goal oriented synthesis to transform abm into a more coherent efficient approach to identify general principles and theories 2 a compilation and critical reflection of existing methods and best practice in abm research fostering the development and dissemination of standards this also requires a discussion of the existing gaps and obstacles for successful theory development through abm including a philosophical discussion on whether abm extends classical theory to more complex situations or represents a radically new research program deangelis and mooij 2005b 3 to formulate a roadmap to overcome current obstacles to use the potential of abm as a powerful and much needed approach for theory development the main purpose of this call is to create awareness of these challenges we invite peers in all disciplines using abm to relate their more or less case specific work to theory and consider theory development to be an integral part of even the most applied abm if we all force ourselves to include in all our abm publications at least one paragraph in the discussion addressing the question what have we learned in terms or general theory we would already contribute to this first important step we invite complementary or opposing views to those expressed by us and we hope to instigate a much needed discussion on theory development among agent based modelers which hopefully will result in explicit articles special issues and projects we ourselves are organizing a series of three workshops entitled from cases to general principles theory development through agent based modeling 1 1 the events will take place in hanover germany in 2018 2020 for the website on this initiative see www abm theory org these symposia will provide a platform to connect modelers from different disciplines and epistemologists for critical reflections and the collection of best practices 
