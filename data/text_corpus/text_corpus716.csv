index,text
3580,covering the soil surface with mulch is a cropland management practice that can provide several benefits to the soil environment especially in rainfed systems soil mulching tends to enhance plant growth by reducing soil evaporation and potentially increasing transpiration but its effectiveness vary widely across rainfall regimes and mulching materials here we investigate this variability using a process based modeling framework coupling the dynamics of soil and mulching moisture and of crop growth supported by field observations under different mulching materials we study the effectiveness of soil mulching in increasing transpiration and growth under different rainfall regimes and mulching layer thickness the analysis suggests that in most rainfall scenarios soil mulching can increase plant transpiration by up to 100 and reduce soil evaporation by up to 40 however there exist rainfall conditions low frequency and high intensity under which soil mulching may cause lower transpiration we also show that soil mulching is particularly beneficial during a dry spell a phenomenon that is projected to occur more frequently in many climatic zones in the event of a dry spell during the growing season soil mulching helps maintain moist conditions for longer hence limiting the negative effects on plant transpiration and growth the analysis helps better understand the role of soil mulching on transpiration and crop growth and provides important information for improving soil mulching depending on mulching material and the site specific rainfall regime keywords soil moisture evapotranspiration conservation agriculture rainfed agriculture dry spells 1 introduction soil mulching which consists in covering the soil surface with crop residues gravel plastic film or other similar materials wander and gourley 1937 is an important conservation practice with several potential benefits such as temperature regulation kader et al 2017 reduction in evaporation rate reduced risk of salinization bezborodov et al 2010 enhanced microorganism richness dong et al 2017 and weed control murungu et al 2011 all of which may result in an increase in crop productivity yu et al 2018 soil mulching plays an important role especially in water controlled ecosystems since these ecosystems are typically subject to higher rainfall variability and unpredictability that threaten crop yields nevertheless the mechanisms controlling the soil water balance in the presence of mulch are complex thus it is difficult to quantify the effectiveness of soil mulching in buffering rainfall variability and to plan a proper application rate the benefits of soil mulching are generally more evident in rainfed agriculture which occupying 80 of the agricultural land worldwide bhattacharya 2019 contribute the most to the global food production in fact although the productivity per unit area is on average half that of irrigated areas jaramillo et al 2020 rainfed systems still contribute 60 to food production globally unesco 2009 e g 70 of the population in india relies on rainfed agriculture according to reddy and syme 2015 and have the potential to supply more than 75 of the food demand by 2025 siderius et al 2016 however crop production in rainfed systems requires nearly perfect synchronization between rain events and crop water demand and given the predicted increase in rainfall variability due to climate change sivakumar et al 2005 rockström et al 2010 ndehedehe et al 2021 the risks of yield and revenue losses are still high improving the effectiveness of soil mulching for example by identifying how application rates should vary across climates is an important strategy for increasing the resilience of rainfed systems and their productivity globally soil mulching is particularly important in the initial crop growth stages when the leaf area index is low and most of the soil surface is exposed to the atmosphere the mulching layer can reduce soil evaporation leaving more water for plant transpiration and growth in later stages li et al 2018 zheng et al 2021 however results on the effects of soil mulching from experimental studies have been somewhat inconsistent likely due to different experimental conditions for example evapotranspiration has been reported either to increase tuure et al 2021 or to remain the same zheng et al 2021 after applying mulch how soil mulching affects evapotranspiration may in fact be regulated by the climate regime and the specific rainfall variability during the growing season and by the characteristics of the mulching layer which can vary widely depending on the material size granulometry and amount or thickness of the layer chakraborty et al 2008 as a result of this limited understanding of the role of climate and mulching properties on the effectiveness of soil mulching there is minimal guidance on mulching application rates depending on site specific conditions hence creating a gap between potential and actual benefits of soil mulching to understand more quantitatively how mulch affects the soil water balance and regulates evapotranspiration so as to make optimal use of it it is important that these factors are studied jointly with climate change and increased rainfall variability the frequency and duration of dry spells is also increasing as it has already been reported in several regions cunningham 2020 makondo and thomas 2020 yaduvanshi et al 2021 this represents an important threat to rainfed agriculture since dry spells occurring during critical crop growth stages may lead to soil moisture depletion plant water stress and in turn reduction in crop productivity in this regard soil mulching may buffer small droughts or dry spells by reducing soil evaporation and limiting the decline in soil moisture the thickness of the mulching layer could also be adapted to the expected occurrence and intensity of dry spells of a specific climate region this however requires an in depth understanding of the factors controlling the soil mulching effectiveness in reducing soil evaporation and buffering the effects of dry periods experimentally capturing how soil mulching regulates the soil water balance has been challenging especially due to the difficulty in exploring all possible combinations of climate scenarios and mulching materials and in attributing changes in plant transpiration to a particular factor gusev and dzhogan 2000 rusinamhodzi et al 2011 given the increasing need imposed by climate change and water scarcity to understand soil mulching more holistically here we use a coupled soil water balance laio et al 2001 crop growth model pelak et al 2017 and a novel mulching water balance in combination with experiments across different mulching materials to quantify the benefits of soil mulching during a growing season in particular we study the effects on soil evaporation and crop transpiration across rainfall regimes mulching layer thickness and under the occurrence of a dry spell the analysis shows and explains how the benefits of soil mulching vary with climate and how the mulching layer thickness can be adjusted accordingly to increase effectiveness 2 materials and methods 2 1 modeling framework we consider the dynamics of soil moisture and mulching moisture spatially integrated over the root zone and mulching layers respectively fig 1 following the approach of laio et al 2001 root zone and mulching layers are thus considered as two buckets whose water storage depends on the porosity and the layer s depth i e rooting depth and mulching depth respectively unlike bare soil that is directly exposed to the atmosphere soil covered in mulch receives most of the water from the mulching layer leakage which depends on the temporal dynamics of the mulching moisture the mulching layer thus affects the dynamics of soil moisture in the root zone by redistributing the input of rainfall temporally and by regulating the partitioning of evapotranspiration into its individual components of evaporation and transpiration in the following sections we describe the water balance models for both root zone and mulching layer to quantify the effects of mulching on the root zone moisture dynamics and water flux partitioning depending on the mulching material and mulching layer thickness our notation including the units is summarized in table 1 2 1 1 mulch water balance mulch affects the soil water balance by serving as an intermediate layer between the soil and the atmosphere which buffers rainfall variability and limits the soil water exposure to the atmospheric evaporative demand we assume that the mulching material acts as a coarse soil that receives water directly from rainfall and is subject to water losses similar to an actual soil accordingly in the mulching layer the water balance can be expressed as 1 ϕ z m d ϑ dt r t c i r c q ϑ r l m ϑ e m ϑ c where ϕ and z m are the mulching layer porosity and thickness respectively ϑ is the mulching moisture 0 ϑ 1 r is the rainfall rate c i is the rainfall interception by the canopy q is the runoff here considered as the surplus of water with respect to mulching water storage capacity ϕ z m l m is the leakage from the mulching layer that infiltrates the soil underneath and e m is the evaporation from the mulching layer part of rainfall may be intercepted by plant canopy that covers the soil depending on the crop growth stage rainfall interception c i was computed considering the capacity of the canopy to store part of rainfall if the rainfall depth exceeds the canopy storage the excess rain reaches the soil as throughfall accordingly 2 c i r c r c t r r r c t r r where c is the crop cover fraction that represents the area covered by the plants described in section 2 1 3 and r is a threshold representing the interception storage capacity per unit crop cover which of course depends on the plant type being exposed to the atmosphere the mulching layer will lose part of the water via evaporation which can be computed similarly to soil evaporation as 3 e m ϑ c f m ϑ e max 1 c t where f m is a factor of mulching moisture c is the crop cover fraction i e 1 c being fraction of soil exposed to the atmosphere and e max is the maximum evaporation rate which as we show below is proportional to et 0 and a baseline evaporation coefficient k ec the mulching moisture factor accounts for the approximately linear dependence of stage ii evaporation on moisture brutsaert 2013 and is computed as follows 4 f m ϑ 0 ϑ ϑ h ϑ ϑ h 1 ϑ h ϑ ϑ h where ϑ h is a hygroscopic point below which evaporation stops similarly to the hygroscopic point in soils in addition to evaporation the mulching layer also loses water by percolation that infiltrates into the soil since we considered the mulching layer as a coarse soil the leakage from this layer can be computed from the hydraulic conductivity of the mulching material based on hillel 1998 5 l m ϑ k m ϑ c where k m is saturated hydraulic conductivity and c is an empirical exponent that depends on the properties of the mulching layer 2 1 2 soil water balance the soil water balance in the presence of soil mulching differs from a typical balance in that it receives water from the water percolating from the mulching while the evaporation is partly inhibited by the fact that the mulching layer introduces a resistance to evaporation the soil water balance reads 6 nz r ds dt l m ϑ t s c e s ϑ l s where n is the soil porosity z r is the active soil or root depth s t is the relative soil water content at time t 0 s 1 averaged over the rooting depth equal to the soil volumetric water content over the soil porosity the soil loses water by evaporation e plant transpiration t and leakage l transpiration and evaporation are computed as proportional to the cover fraction and maximum transpiration and evaporation rates respectively as discussed in pelak et al 2017 accordingly the transpiration rate is expressed as 7 t s c f s s t max c t where t max is the maximum transpiration rate which can be computed proportional to the reference evapotranspiration et 0 and f s s is a coefficient reducing transpiration depending on crop water stress 8 f s s 0 s s w s s w s s w s w s s 1 s s 1 where s w is the soil moisture at wilting point s is a threshold of soil moisture below which t decreases linearly with s due to water stress et 0 is usually computed for a reference crop pelak et al 2017 and it can be adjusted for other crops by multiplying it by the corresponding crop transpiration coefficient k cb from eqs 7 and 8 we can also distinguish between transpiration under stressed t s and non stressed conditions t ns depending on whether s s or s s respectively t ns will be considered later in the analysis the soil evaporative flux in the presence of mulch is subject to an additional resistance which reduces the potential evaporation rate e max depending on the mulching layer thickness jalota and prihar 1990 fuchs and hadas 2011 shumova 2018 the mulching layer contributes to reduce soil evaporation also by meeting part of the atmospheric evaporative demand e m the soil evaporation can then be computed as follows 9 e s ϑ c g s s e max 1 c t e m ϑ c where e max is the maximum evaporation rate reduced by the mulching resistance g s s is a soil moisture controlling factor of the evaporation and e 0 when e m is larger than or equal to the first term to compute e max we considered the additional resistance due to mulching r m fuchs and hadas 2011 which affects the maximum evaporation rate as 10 e max e m a x r a r a r m where r a is the aerodynamic resistance which can be computed as a function of wind speed e g r a 208 u allen et al 2005 while the mulching resistance r m has been shown experimentally to be a function of the mulching layer thickness jalota and prihar 1990 fuchs and hadas 2011 11 r m z m d eff r x 1 exp z m z x where d eff is the effective diffusivity of water vapor in the porous medium and r x and z x are adjusted parameters the soil moisture factor for soil evaporation can be computed as 12 g s s 0 s s h s s h 1 s h s s h where s h is soil moisture at the soil hygroscopic point similar to the mulching layer leakage losses are modeled as gravity drainage at the lower boundary of the soil layer i e 13 l s k s s β where k s is the soil saturated hydraulic conductivity cm day 1 and β is a power law coefficient β 2 b 3 where b is the exponent of the soil retention curve ψ ψ s s b ψ s being the saturation suction clapp and hornberger 1978 2 1 3 crop growth to model the growth of the crop during the growing season we study the temporal evolution of the crop cover fraction c defined as the fraction of the field area covered by the crop canopy as proposed in the aquacrop model see steduto et al 2009 the crop cover fraction represents the area covered by plants and varies between 0 for entirely bare soil and 1 for completely covered soil following pelak et al 2017 and steduto et al 2009 we computed the temporal dynamics of the cover fraction as a balance between growth and senescence 14 dc dt rtc t 1 c t c max γ t t sen θ t t sen c t 2 where r is an empirical coefficient related to the canopy growth rate per unit of water nutrient uptake t is the plant transpiration c max is the maximum cover fraction γ is the slope of increase of senescence after t sen and θ is heaviside step function which triggers senescence when t t sen the canopy cover c thus varies depending on plant type and stage as well as on field management e g crop line spacing which determine the maximum cover fraction c max the canopy cover c then affects canopy interception and the partitioning of evapotranspiration into transpiration and evaporation 2 2 rainfall scenarios to explore the effects of within season rainfall fluctuations rainfall was simulated using a marked poisson process rodriguez iturbe and porporato 2005 accordingly the rainfall interarrival time is a random variable described by an exponential distribution with mean 1 λ 15 f t τ λ e λ τ for τ 0 where λ is the rainfall frequency the depth of rain events is also a random variable which is described by an exponential distribution with mean depth α 16 f h h 1 α e 1 α h for h 0 from the rainfall characteristics λ and α the total rainfall is given by the product of α λ and the length of the growth season t season we simulated the stochastic rainfall 10 000 times and solved the model numerically at a 5 min timescale after which the results were integrated into the daily timescale 2 3 data collection and analysis our analysis is supported by data collected from field experiments in which crops were cultivated both with and without organic mulching we focused on experiments that provided rainfall and soil moisture at a daily timescale in order to calibrate the soil and mulching layer parameters we analyzed data from experiments by kader et al 2017 which compared soybean cultivations with no mulch and with straw grass and paper mulches and by zheng et al 2021 which studied the effect of straw mulch on a maize cultivation kader et al 2017 and zheng et al 2021 provide the amount of mulch applied in kg ha 1 though not the mulching layer depth rainfall and soil moisture and other important soil and climate information e g bulk density soil moisture at field capacity et 0 which were used to constrain the model crop growth parameters were taken from pelak et al 2017 and hsiao et al 2009 for maize and from setiyono et al 2008 for soybean since the experimental plots have a similar soil we first calibrated the soil parameters using the soil moisture data from the control plots no mulching treatment to approximate the soil parameters and then calibrated the parameters for the mulching layer allowing small variations in the soil parameters to best fit the soil moisture variability the calibration was performed using the nelder mead method through the lmfit package in python programming language python software foundation 2020 while the stochastic simulations were performed using julia programming language bezanson et al 2017 3 results we began by testing whether the model captures the variability in soil moisture across the soil mulching experiments fig 2 shows the dynamics of soil moisture observed and modeled during the growth of soybeans the correlations between observed and modeled soil moisture and the effects of soil mulching on the soil water balance for the experiments conducted by kader et al 2017 the total rainfall during the length of the experiment was about 71 cm distributed over 77 days fig 2a while soil moisture fluctuations fig 2b are largely driven by rainfall pulses soil mulching tends to smooth soil moisture variability depending on the specific mulching material following a rain event the largest jumps in soil moisture observed and modeled were found with paper mulch followed by straw and grass mulches a fact related to the characteristics of the material however after a prolonged period with low rainfall days 43 to 64 the soil moisture under paper mulch experienced a more significant decay while straw mulch was the best material in retaining soil moisture overall the model captures well the soil moisture dynamics and the differences among the mulching materials the coefficient of correlation r 2 between observed and modeled soil moisture was on average 0 88 for all the materials fig 2d all the parameters values used in the model are included in tables s 1 s 3 and the model performance is represented in a taylor diagram in fig s 1 supplementary material the water partitioning leakage evaporation and transpiration represented by the percentage of rainfall for each mulch treatment compared with their corresponding no mulching condition same soil parameters with and without mulch is shown in fig 2d f due to the occurrence of large rainfall events leakage was the main water balance component followed by transpiration and evaporation in all mulching conditions plant transpiration was lower than 40 of rainfall whereas evaporation varied between 10 and 15 of rainfall although there was no considerable difference between the straw or grass mulch compared with no mulching treatments the mulch promoted a marginal increase in both leakage and transpiration and a decrease in evaporation in addition mulching increases the time with s s resulting in higher transpiration under non stressed conditions which is important for better crop growth and higher yield the differences in the water fluxes for different mulching materials and different parameters highlight that the benefits of soil mulching depend on the material characteristics the parameters used for each mulching material are shown in table s 3 supplementary material this variability in the mulching parameters is to be expected given the number of factors that affect the hydraulic characteristics of the material such as particle size layer compaction and the type of crop residue kader et al 2017 pavlu et al 2021 3 1 effects of rainfall regime the rainfall regime can vary significantly among different regions and similar climatic zones e g rainfall in the semi arid region varies between 20 and 80 cm year 1 in era5 land data hersbach et al 2020 affecting the efficacy of soil mulching to explore the interaction between the rainfall regime and the soil mulching controls on evaporation and transpiration we simulated rainfall as a poisson process varying α and λ to generate different rainfall regimes rodriguez iturbe and porporato 2005 as detailed in section 2 2 in particular we considered a growing season of 120 days varied the rainfall frequency λ between 0 2 and 0 8 d 1 and the mean rainfall depth α between 0 5 and 1 5 cm this resulted in total rainfall amounts over the growing season from 20 cm e g arid regions in ethiopia africa to 144 cm e g humid regions in eastern india we then compared the ratios between the evapotranspiration evaporation and transpiration under mulching sm and no mulching nm conditions considering typical parameters of a straw or grass mulch table s 1 the effect of soil mulching is highly dependent on rainfall depth and frequency and interestingly is not always beneficial for crop growth fig 3 generally the total evapotranspiration is not particularly affected as shown by the ratio et sm et nm varying only between 0 85 and 1 05 with values greater than 1 only when rainfall is below 40 cm fig 3a by contrast the individual evaporation and transpiration fluxes can be considerably affected by soil mulching the total evaporation over a growing season for sm is lower than in nm condition regardless of the rainfall regime with the evaporation ratio sm nm e sm e nm varying between 0 60 and 0 76 fig 3b suggesting that mulching effectively limits evaporation by at least 24 within the rainfall scenarios considered differently from evaporation the transpiration ratio t sm t nm varies between 1 00 and 2 20 showing a substantial increase for drier conditions fig 3b in fact when rainfall is higher than 40 cm during the growing season 120 days the increase in transpiration due to mulch is relatively low only up to 15 but for drier scenarios with rainfall lower than 30 cm t sm t nm rapidly increases the positive effect of soil mulching is particularly visible in the transpiration under non stressed conditions the ratio t sm ns t nm ns shows the highest variability fig 3c with higher values up to 6 8 for very dry climates α 0 70 cm and λ 0 3 d 1 and low values down to 0 86 for α 0 70 cm and λ 0 90 d 1 for which sm has a negative effect see fig s 2 in supplementary material this is explained by the fact that in drier climates where soil moisture is generally low soil mulching helps increase soil moisture but not to a level that produces percolation or runoff therefore the increased soil moisture only increases transpiration by contrast in wetter climates an increase in soil moisture which may already be close to the value at field capacity due to soil mulching promotes percolation and runoff at the expense of transpiration an example of the hydrologic dynamics for a condition in which transpiration reduces with mulching is shown in fig s 2 in supplementary material 3 2 effects of mulching layer thickness as presented in section 3 1 soil mulching can impact positively or negatively plant transpiration total or under non stressed conditions depending on the rainfall regime an important management decision that can control the effectiveness of soil mulching is related to the thickness of the mulching layer to explore the role of mulching thickness on transpiration we simulated the soil water balance considering different mulching layer thicknesses and rainfall regimes and computed the mulching layer efficiency in increasing plant transpiration as t sm t nm t nm fig 4 a in addition the ratios of the water balance components transpiration evaporation leakage and runoff to rainfall are shown in fig 4b e for different mulching layers thickness and rainfall regimes in fig 4 we show 4 rainfall regimes total rainfall of 24 and 40 cm with α equal to 0 5 and 1 0 cm but for completeness we present other rainfall regimes in fig s 3 in supplementary material the transpiration efficiency of mulching increases with mulching layer thickness regardless of rainfall scenario and tends to plateau for z m 6 fig 4a the mean rain depth plays an important role for the thin mulching layers as evident from the fact that for low mean rain depth α 0 5 cm mulching increases transpiration t sm t nm while for α 1 0 cm mulching reduces it t sm t nm t sm t nm t nm 0 as z m increases the role of total rainfall becomes more important with mulch being more effective for lower total rainfall as expected from the previous analysis on the effects of the rainfall regime the mean rainfall depth α can still improve although only slightly the effectiveness for thicker layers z m 5 6 cm to understand more in depth how the mulching thickness affects the soil water balance we also show how all the water fluxes vary with mulching thickness in the four rainfall regimes fig 4 evaporation and runoff in particular are two main mechanisms affecting the water balance based on the mulching layer thickness z m a thicker layer increases the resistance for the soil evaporation which as a consequence decreases as z m increases fig 4c evaporation is dependent mostly on rainfall total while the effect of rainfall depth is negligible the soil only receives water from the mulching layer which redistribute the input of rainfall as percolation the water storage capacity of the mulching increases as z m increases and this reduces runoff fig 4e runoff is more affected by mean rainfall depth than rainfall total as it is the more intense events typically to produce runoff thus the reduction in runoff and soil evaporation results in an increase in soil moisture that favors both plant transpiration and in particular in wetter climates e g blue lines leakage 3 3 soil mulching buffering of dry spells dry spells in rainfed systems may compromise plant growth and yield especially based on its timing and duration to explore the capacity of soil mulching to buffer the impact of dry spells we analyzed the soil moisture dynamics and plant transpiration for a long dry spell occurring from day 40 to day 70 of the growing season the rainfall was simulated using the poisson process and all events during the dry spell window were set to zero we used a fix mulching layer thickness of 5 cm the soil moisture plant transpiration and crop cover fraction ensemble averages and samples of single realizations as well as the probabilistic density function of soil moisture during the dry spell and total t are presented in fig 5 the probabilistic density function of s at the beginning middle and the end of the dry spell highlight the effect of mulching on soil moisture dynamics fig 5 generally the soil moisture is higher in sm than in nm for most of the growing season until the end of the dry spell while it shows a similar behavior after the dry spell day 61 and until plant senescence when the transpiration drops to zero moreover the mulching layer suppressed evaporation resulting in increased soil moisture in sm for the rainfall regime that we simulated at the beginning of the dry spell there is a high likelihood of s s in both sm and nm leading to low or no crop water stress however the probability of s s is higher in sm reflecting the benefit of soil mulching in reducing the risk of water stress this also favors higher t see bottom panel in fig 5 and consequently a higher crop growth in the middle of the dry spell day 55 the pdf of soil moisture has a similar shape but the probability of larger s values is still higher in sm than in nm although we can observe that the effect of mulching in buffering the soil moisturedecreases as the dry spell continues even in the last day of the dry spell day 70 the soil moisture under sm is still higher than in nm but in that condition the transpiration reduces significantly in both conditions since s approaches the wilting point s w the benefit of having soil mulching during a dry spell is evident from the differences in transpiration fig 5b since the crop cover fraction is low at the beginning of the growing season fig 5c t is similar for sm and nm up to approximately day 30 when the dry spell starts higher moisture levels promote faster crop cover growth in sm resulting in larger transpiration this is a function of c and in turn in even faster crop cover growth this is proportional to transpiration consequently there is an almost twice as high transpiration in sm as in nm during the dry spell fig 5b even after the dry spell t in sm remains higher than in nm until about the time of senescence as a result of soil mulching the average total transpiration was about 17 1 cm in sm and 13 2 cm in nm representing respectively 57 and 41 of the total rainfall r 29 8 cm we also analyzed the effects of different dry spell lengths on total transpiration over the growing season the soil water balance was simulated as described above with the dry spell starting at the day 40 and lasting from 5 to 30 days the total transpiration was computed throughout the season and t r with respect to the dry spell length is shown in fig 6 prolonged dry spells result in reduced t r as the evaporation increases and less water is available for crop growth and transpiration however t r is always substantially higher in sm than in nm varying between 0 64 and 0 57 for sm and between 0 56 and 0 44 for nm for dry spells ranging from 5 to 30 days long according to these results under sm the crop can withstand a 30 day longer dry spell and still have higher t r value than under nm we emphasize that this mulching buffering capacity depends on several controlling factors including mulching layer thickness et 0 soil properties plant stage and rainfall regime which here were kept constant 4 discussion despite the potential benefits of soil mulching as a conservation practice its effectiveness in increasing transpiration and crop growth varies widely between different studies kader et al 2019 qin et al 2015 here we applied a modeling approach to directly quantify how soil mulching affects the soil water balance and crop growth and explain observed differences across rainfall regimes and mulching properties the model was calibrated using experimental data provided by kader et al 2017 kader et al 2019 and zheng et al 2021 and it performed well when comparing the observed and modeled temporal evolution of soil moisture the coefficient of determination was actually slightly higher here than those found in kader et al 2019 which used a vertically explicit model based on richards equation the analysis showed that soil mulching tends to increase plant transpiration for most rainfall scenarios but particularly under drier conditions when rainfall is under 30 cm considering a crop growing season of 120 days as shown in fig 3 such dry conditions include for example ethiopia or kenya in eastern africa with rainfall around 25 cm yr 1 and single cropping rainfed systems for which soil mulching may be particularly effective van velthuizen et al 2007 however it is a combination of rainfall distribution and layer thickness that determines the effectiveness of soil mulching and depending on the combination of these factors soil mulching might even result in a reduction of transpiration long inter arrival times between rain events combined with high rainfall depths may in fact cause a reduction of transpiration in particular the transpiration under non stressed conditions fig 3 in this condition the model shows that the mulching layer saturates and loses large amounts of water by runoff fig s 2 in supplementary material the differences between results reported across soil mulching experiments e g zhu et al 2015 li et al 2018 kader et al 2019 tuure et al 2021 zhang et al 2021 may be due not only to the different rainfall regimes in the experimental sites 27 cm in northwest china to 87 4 cm in japan but also to the specific properties of the mulching material adopted here we found that the hydraulic properties of the different mulching materials across the experiments were very similar while the property affecting the functioning of soil mulching was its thickness currently there is no clear guidance on the amount of mulch to apply under a specific climate and cropping system as there are only a few experiments that explored the role of mulching furthermore it is difficult to retrieve this information from the literature as different studies report application rates in different units for instance as percentage of the soil covered abrantes et al 2018 in mass per hectare jalota and prihar 1990 or layer thickness gusev et al 2018 making it difficult to combine or compare their results as shown in fig 4 the effect of mulching is controlled by both its thickness and rainfall characteristics regions with high rainfall intensity may require a mulching layer thickness of at least 3 to 4 cm to increase plant transpiration while for low rainfall intensity a layer thickness of 3 cm or less can be enough to reduce water losses and increase transpiration overall a thicker mulching layer has a higher water storage capacity which reduces the runoff and increases the resistance to water vapor fuchs and hadas 2011 these results are in line with previous findings exploring the effect of the application rate for instance flower et al 2021 found a mulching rate 2 t ha 1 a thickness of about 2 5 cm assuming a typical mulching density of 8 12 kg m 3 based on dietrich et al 2019 and chen et al 2020 can effectively reduce soil evaporation in semi arid environments while a more noticeable effect was found when increasing the mulching layer thickness to 4 5 cm in eastern european steppes gusev et al 2018 gusev and dzhogan 2019 an important threat to food production in arid regions is the occurrence of dry spells which may expose plants to severe water stress zhu et al 2015 soil mulching helps increase the soil moisture resilience to dry spells by reducing soil evaporation tuure et al 2021 hence maintaining the productivity for longer kiboi et al 2017 as shown in fig 5 the soil moisture in the mulching treatment is higher than in the no mulching treatment until at least the middle of the dry spell for about 15 days although the difference in soil moisture may not be substantial between treatments this additional moisture supports an almost constant difference in t r between the no mulching and mulching treatments for dry spells of at least up to 30 days fig 6 this may result in reaching or not the maximum yield at the end of the season the difference between the two conditions can be considered as a measure of the mulching capacity to buffer dry spells for the simulated scenario the soil mulching condition would take about 30 extra days without rain to reach the same t r of no mulching condition this mulching capacity to buffer dry spells has also been observed experimentally in dry land smallholder systems in east africa tuure et al 2021 where soil mulching contributed to maintaining soil moisture above the critical stress level for at least 19 days since the beginning of the dry spell and longer for thicker mulching layers overall our work suggests that analyzing rainfall depth and frequency is key to determine a mulching layer thickness that effectively reduces runoff and soil evaporation and maximizes the water available for transpiration hence reducing the risks for the yield a positive finding is that soil mulching is particularly effective in drier climates right where soil evaporation tends to be higher due to high atmospheric evaporative demand soil mulching can thus be a valuable strategy to increase yield of rainfed systems especially in arid and semi arid regions where irrigation is often not a valuable option due to water scarcity pereira et al 2002 passioura 2006 we also highlight that this study was focused on the short term effect of organic mulch on the hydrology of rainfed systems during the crop cycles despite a negative effect on transpiration for certain combinations of rainfall and mulching thickness soil mulching brings about other important benefits such as increased carbon sequestration and improved soil bio physical properties kahlon et al 2013 for the sake of generality in our analysis we kept the potential evapotranspiration constant during the growing season and among rainfall regimes daily fluctuations in potential evapotranspiration have limited impact on the soil water balance especially when compared to the effects of rainfall fluctuations rodriguez iturbe and porporato 2005 daly and porporato 2006 variability in potential evapotranspiration across ecosystems does not affect particularly water limited ecosystems fu 1981 wang and tang 2014 daly et al 2019 daly et al 2019 such as arid and semi arid regions where soil mulching is needed and is effective therefore while the assumption of constant potential evapotranspiration may certainly affect some of our results especially in terms of detailed estimates we do not expect the assumption to alter our key conclusions such as the patterns in figs 3 and 4 there is also a need for experimental exploration of the hydraulic properties of different mulching materials level of grinding and compactness mulching and soil properties here kept constant jointly regulate the soil water balance and hence are important factors that need to be further assessed these further investigations will help estimate optimal application rates i e and layer thickness based not only on on site climatic and edaphic factors but also on the availability of mulching materials and associated equipment 5 conclusions there is still limited understanding of how the mulch layer modulates the hydrologic cycle and impacts crop growth here we studied the effectiveness of soil mulching in increasing crop transpiration across rainfall regimes and mulching layer thickness and showed that mulching can increase transpiration twofold but can also reduce it in climates with high rainfall intensity we also demonstrate that the mulching layer thickness is an important property that along with rainfall intensity and distribution regulates the efficacy of soil mulching suggesting that the thickness should be carefully selected depending on the site specific climate under drier rainfall regimes with moderate rainfall events a mulching layer thickness of 3 cm or lower would suffice to increase plant transpiration while wetter climates with low rainfall frequency require thicker layers especially for those regions where the ongoing climate changes are increasing rainfall variability the soil mulching can also buffer the effects of dry spells that might occur during the growing season by retaining soil moisture for longer and promoting an increase in transpiration future work will explore the link between the dynamics of mulching moisture and the decomposition of the organic mulching material to investigate how in addition to increasing water retention mulching can positively affect soil biophysical properties declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank the three anonymous reviewers for the constructive comments this work was supported by the department of biological and agricultural engineering and agrilife research at texas a m university and the usda national institute of food and agriculture hatch project 1023954 the full model code is available as the julia package soilmulch and is archived at the github repository https github com calabresehydrologylab soilmulch jl fig 1 was created with biorender com appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2022 127523 supplementary data the following are the supplementary data to this article supplementary data 
3580,covering the soil surface with mulch is a cropland management practice that can provide several benefits to the soil environment especially in rainfed systems soil mulching tends to enhance plant growth by reducing soil evaporation and potentially increasing transpiration but its effectiveness vary widely across rainfall regimes and mulching materials here we investigate this variability using a process based modeling framework coupling the dynamics of soil and mulching moisture and of crop growth supported by field observations under different mulching materials we study the effectiveness of soil mulching in increasing transpiration and growth under different rainfall regimes and mulching layer thickness the analysis suggests that in most rainfall scenarios soil mulching can increase plant transpiration by up to 100 and reduce soil evaporation by up to 40 however there exist rainfall conditions low frequency and high intensity under which soil mulching may cause lower transpiration we also show that soil mulching is particularly beneficial during a dry spell a phenomenon that is projected to occur more frequently in many climatic zones in the event of a dry spell during the growing season soil mulching helps maintain moist conditions for longer hence limiting the negative effects on plant transpiration and growth the analysis helps better understand the role of soil mulching on transpiration and crop growth and provides important information for improving soil mulching depending on mulching material and the site specific rainfall regime keywords soil moisture evapotranspiration conservation agriculture rainfed agriculture dry spells 1 introduction soil mulching which consists in covering the soil surface with crop residues gravel plastic film or other similar materials wander and gourley 1937 is an important conservation practice with several potential benefits such as temperature regulation kader et al 2017 reduction in evaporation rate reduced risk of salinization bezborodov et al 2010 enhanced microorganism richness dong et al 2017 and weed control murungu et al 2011 all of which may result in an increase in crop productivity yu et al 2018 soil mulching plays an important role especially in water controlled ecosystems since these ecosystems are typically subject to higher rainfall variability and unpredictability that threaten crop yields nevertheless the mechanisms controlling the soil water balance in the presence of mulch are complex thus it is difficult to quantify the effectiveness of soil mulching in buffering rainfall variability and to plan a proper application rate the benefits of soil mulching are generally more evident in rainfed agriculture which occupying 80 of the agricultural land worldwide bhattacharya 2019 contribute the most to the global food production in fact although the productivity per unit area is on average half that of irrigated areas jaramillo et al 2020 rainfed systems still contribute 60 to food production globally unesco 2009 e g 70 of the population in india relies on rainfed agriculture according to reddy and syme 2015 and have the potential to supply more than 75 of the food demand by 2025 siderius et al 2016 however crop production in rainfed systems requires nearly perfect synchronization between rain events and crop water demand and given the predicted increase in rainfall variability due to climate change sivakumar et al 2005 rockström et al 2010 ndehedehe et al 2021 the risks of yield and revenue losses are still high improving the effectiveness of soil mulching for example by identifying how application rates should vary across climates is an important strategy for increasing the resilience of rainfed systems and their productivity globally soil mulching is particularly important in the initial crop growth stages when the leaf area index is low and most of the soil surface is exposed to the atmosphere the mulching layer can reduce soil evaporation leaving more water for plant transpiration and growth in later stages li et al 2018 zheng et al 2021 however results on the effects of soil mulching from experimental studies have been somewhat inconsistent likely due to different experimental conditions for example evapotranspiration has been reported either to increase tuure et al 2021 or to remain the same zheng et al 2021 after applying mulch how soil mulching affects evapotranspiration may in fact be regulated by the climate regime and the specific rainfall variability during the growing season and by the characteristics of the mulching layer which can vary widely depending on the material size granulometry and amount or thickness of the layer chakraborty et al 2008 as a result of this limited understanding of the role of climate and mulching properties on the effectiveness of soil mulching there is minimal guidance on mulching application rates depending on site specific conditions hence creating a gap between potential and actual benefits of soil mulching to understand more quantitatively how mulch affects the soil water balance and regulates evapotranspiration so as to make optimal use of it it is important that these factors are studied jointly with climate change and increased rainfall variability the frequency and duration of dry spells is also increasing as it has already been reported in several regions cunningham 2020 makondo and thomas 2020 yaduvanshi et al 2021 this represents an important threat to rainfed agriculture since dry spells occurring during critical crop growth stages may lead to soil moisture depletion plant water stress and in turn reduction in crop productivity in this regard soil mulching may buffer small droughts or dry spells by reducing soil evaporation and limiting the decline in soil moisture the thickness of the mulching layer could also be adapted to the expected occurrence and intensity of dry spells of a specific climate region this however requires an in depth understanding of the factors controlling the soil mulching effectiveness in reducing soil evaporation and buffering the effects of dry periods experimentally capturing how soil mulching regulates the soil water balance has been challenging especially due to the difficulty in exploring all possible combinations of climate scenarios and mulching materials and in attributing changes in plant transpiration to a particular factor gusev and dzhogan 2000 rusinamhodzi et al 2011 given the increasing need imposed by climate change and water scarcity to understand soil mulching more holistically here we use a coupled soil water balance laio et al 2001 crop growth model pelak et al 2017 and a novel mulching water balance in combination with experiments across different mulching materials to quantify the benefits of soil mulching during a growing season in particular we study the effects on soil evaporation and crop transpiration across rainfall regimes mulching layer thickness and under the occurrence of a dry spell the analysis shows and explains how the benefits of soil mulching vary with climate and how the mulching layer thickness can be adjusted accordingly to increase effectiveness 2 materials and methods 2 1 modeling framework we consider the dynamics of soil moisture and mulching moisture spatially integrated over the root zone and mulching layers respectively fig 1 following the approach of laio et al 2001 root zone and mulching layers are thus considered as two buckets whose water storage depends on the porosity and the layer s depth i e rooting depth and mulching depth respectively unlike bare soil that is directly exposed to the atmosphere soil covered in mulch receives most of the water from the mulching layer leakage which depends on the temporal dynamics of the mulching moisture the mulching layer thus affects the dynamics of soil moisture in the root zone by redistributing the input of rainfall temporally and by regulating the partitioning of evapotranspiration into its individual components of evaporation and transpiration in the following sections we describe the water balance models for both root zone and mulching layer to quantify the effects of mulching on the root zone moisture dynamics and water flux partitioning depending on the mulching material and mulching layer thickness our notation including the units is summarized in table 1 2 1 1 mulch water balance mulch affects the soil water balance by serving as an intermediate layer between the soil and the atmosphere which buffers rainfall variability and limits the soil water exposure to the atmospheric evaporative demand we assume that the mulching material acts as a coarse soil that receives water directly from rainfall and is subject to water losses similar to an actual soil accordingly in the mulching layer the water balance can be expressed as 1 ϕ z m d ϑ dt r t c i r c q ϑ r l m ϑ e m ϑ c where ϕ and z m are the mulching layer porosity and thickness respectively ϑ is the mulching moisture 0 ϑ 1 r is the rainfall rate c i is the rainfall interception by the canopy q is the runoff here considered as the surplus of water with respect to mulching water storage capacity ϕ z m l m is the leakage from the mulching layer that infiltrates the soil underneath and e m is the evaporation from the mulching layer part of rainfall may be intercepted by plant canopy that covers the soil depending on the crop growth stage rainfall interception c i was computed considering the capacity of the canopy to store part of rainfall if the rainfall depth exceeds the canopy storage the excess rain reaches the soil as throughfall accordingly 2 c i r c r c t r r r c t r r where c is the crop cover fraction that represents the area covered by the plants described in section 2 1 3 and r is a threshold representing the interception storage capacity per unit crop cover which of course depends on the plant type being exposed to the atmosphere the mulching layer will lose part of the water via evaporation which can be computed similarly to soil evaporation as 3 e m ϑ c f m ϑ e max 1 c t where f m is a factor of mulching moisture c is the crop cover fraction i e 1 c being fraction of soil exposed to the atmosphere and e max is the maximum evaporation rate which as we show below is proportional to et 0 and a baseline evaporation coefficient k ec the mulching moisture factor accounts for the approximately linear dependence of stage ii evaporation on moisture brutsaert 2013 and is computed as follows 4 f m ϑ 0 ϑ ϑ h ϑ ϑ h 1 ϑ h ϑ ϑ h where ϑ h is a hygroscopic point below which evaporation stops similarly to the hygroscopic point in soils in addition to evaporation the mulching layer also loses water by percolation that infiltrates into the soil since we considered the mulching layer as a coarse soil the leakage from this layer can be computed from the hydraulic conductivity of the mulching material based on hillel 1998 5 l m ϑ k m ϑ c where k m is saturated hydraulic conductivity and c is an empirical exponent that depends on the properties of the mulching layer 2 1 2 soil water balance the soil water balance in the presence of soil mulching differs from a typical balance in that it receives water from the water percolating from the mulching while the evaporation is partly inhibited by the fact that the mulching layer introduces a resistance to evaporation the soil water balance reads 6 nz r ds dt l m ϑ t s c e s ϑ l s where n is the soil porosity z r is the active soil or root depth s t is the relative soil water content at time t 0 s 1 averaged over the rooting depth equal to the soil volumetric water content over the soil porosity the soil loses water by evaporation e plant transpiration t and leakage l transpiration and evaporation are computed as proportional to the cover fraction and maximum transpiration and evaporation rates respectively as discussed in pelak et al 2017 accordingly the transpiration rate is expressed as 7 t s c f s s t max c t where t max is the maximum transpiration rate which can be computed proportional to the reference evapotranspiration et 0 and f s s is a coefficient reducing transpiration depending on crop water stress 8 f s s 0 s s w s s w s s w s w s s 1 s s 1 where s w is the soil moisture at wilting point s is a threshold of soil moisture below which t decreases linearly with s due to water stress et 0 is usually computed for a reference crop pelak et al 2017 and it can be adjusted for other crops by multiplying it by the corresponding crop transpiration coefficient k cb from eqs 7 and 8 we can also distinguish between transpiration under stressed t s and non stressed conditions t ns depending on whether s s or s s respectively t ns will be considered later in the analysis the soil evaporative flux in the presence of mulch is subject to an additional resistance which reduces the potential evaporation rate e max depending on the mulching layer thickness jalota and prihar 1990 fuchs and hadas 2011 shumova 2018 the mulching layer contributes to reduce soil evaporation also by meeting part of the atmospheric evaporative demand e m the soil evaporation can then be computed as follows 9 e s ϑ c g s s e max 1 c t e m ϑ c where e max is the maximum evaporation rate reduced by the mulching resistance g s s is a soil moisture controlling factor of the evaporation and e 0 when e m is larger than or equal to the first term to compute e max we considered the additional resistance due to mulching r m fuchs and hadas 2011 which affects the maximum evaporation rate as 10 e max e m a x r a r a r m where r a is the aerodynamic resistance which can be computed as a function of wind speed e g r a 208 u allen et al 2005 while the mulching resistance r m has been shown experimentally to be a function of the mulching layer thickness jalota and prihar 1990 fuchs and hadas 2011 11 r m z m d eff r x 1 exp z m z x where d eff is the effective diffusivity of water vapor in the porous medium and r x and z x are adjusted parameters the soil moisture factor for soil evaporation can be computed as 12 g s s 0 s s h s s h 1 s h s s h where s h is soil moisture at the soil hygroscopic point similar to the mulching layer leakage losses are modeled as gravity drainage at the lower boundary of the soil layer i e 13 l s k s s β where k s is the soil saturated hydraulic conductivity cm day 1 and β is a power law coefficient β 2 b 3 where b is the exponent of the soil retention curve ψ ψ s s b ψ s being the saturation suction clapp and hornberger 1978 2 1 3 crop growth to model the growth of the crop during the growing season we study the temporal evolution of the crop cover fraction c defined as the fraction of the field area covered by the crop canopy as proposed in the aquacrop model see steduto et al 2009 the crop cover fraction represents the area covered by plants and varies between 0 for entirely bare soil and 1 for completely covered soil following pelak et al 2017 and steduto et al 2009 we computed the temporal dynamics of the cover fraction as a balance between growth and senescence 14 dc dt rtc t 1 c t c max γ t t sen θ t t sen c t 2 where r is an empirical coefficient related to the canopy growth rate per unit of water nutrient uptake t is the plant transpiration c max is the maximum cover fraction γ is the slope of increase of senescence after t sen and θ is heaviside step function which triggers senescence when t t sen the canopy cover c thus varies depending on plant type and stage as well as on field management e g crop line spacing which determine the maximum cover fraction c max the canopy cover c then affects canopy interception and the partitioning of evapotranspiration into transpiration and evaporation 2 2 rainfall scenarios to explore the effects of within season rainfall fluctuations rainfall was simulated using a marked poisson process rodriguez iturbe and porporato 2005 accordingly the rainfall interarrival time is a random variable described by an exponential distribution with mean 1 λ 15 f t τ λ e λ τ for τ 0 where λ is the rainfall frequency the depth of rain events is also a random variable which is described by an exponential distribution with mean depth α 16 f h h 1 α e 1 α h for h 0 from the rainfall characteristics λ and α the total rainfall is given by the product of α λ and the length of the growth season t season we simulated the stochastic rainfall 10 000 times and solved the model numerically at a 5 min timescale after which the results were integrated into the daily timescale 2 3 data collection and analysis our analysis is supported by data collected from field experiments in which crops were cultivated both with and without organic mulching we focused on experiments that provided rainfall and soil moisture at a daily timescale in order to calibrate the soil and mulching layer parameters we analyzed data from experiments by kader et al 2017 which compared soybean cultivations with no mulch and with straw grass and paper mulches and by zheng et al 2021 which studied the effect of straw mulch on a maize cultivation kader et al 2017 and zheng et al 2021 provide the amount of mulch applied in kg ha 1 though not the mulching layer depth rainfall and soil moisture and other important soil and climate information e g bulk density soil moisture at field capacity et 0 which were used to constrain the model crop growth parameters were taken from pelak et al 2017 and hsiao et al 2009 for maize and from setiyono et al 2008 for soybean since the experimental plots have a similar soil we first calibrated the soil parameters using the soil moisture data from the control plots no mulching treatment to approximate the soil parameters and then calibrated the parameters for the mulching layer allowing small variations in the soil parameters to best fit the soil moisture variability the calibration was performed using the nelder mead method through the lmfit package in python programming language python software foundation 2020 while the stochastic simulations were performed using julia programming language bezanson et al 2017 3 results we began by testing whether the model captures the variability in soil moisture across the soil mulching experiments fig 2 shows the dynamics of soil moisture observed and modeled during the growth of soybeans the correlations between observed and modeled soil moisture and the effects of soil mulching on the soil water balance for the experiments conducted by kader et al 2017 the total rainfall during the length of the experiment was about 71 cm distributed over 77 days fig 2a while soil moisture fluctuations fig 2b are largely driven by rainfall pulses soil mulching tends to smooth soil moisture variability depending on the specific mulching material following a rain event the largest jumps in soil moisture observed and modeled were found with paper mulch followed by straw and grass mulches a fact related to the characteristics of the material however after a prolonged period with low rainfall days 43 to 64 the soil moisture under paper mulch experienced a more significant decay while straw mulch was the best material in retaining soil moisture overall the model captures well the soil moisture dynamics and the differences among the mulching materials the coefficient of correlation r 2 between observed and modeled soil moisture was on average 0 88 for all the materials fig 2d all the parameters values used in the model are included in tables s 1 s 3 and the model performance is represented in a taylor diagram in fig s 1 supplementary material the water partitioning leakage evaporation and transpiration represented by the percentage of rainfall for each mulch treatment compared with their corresponding no mulching condition same soil parameters with and without mulch is shown in fig 2d f due to the occurrence of large rainfall events leakage was the main water balance component followed by transpiration and evaporation in all mulching conditions plant transpiration was lower than 40 of rainfall whereas evaporation varied between 10 and 15 of rainfall although there was no considerable difference between the straw or grass mulch compared with no mulching treatments the mulch promoted a marginal increase in both leakage and transpiration and a decrease in evaporation in addition mulching increases the time with s s resulting in higher transpiration under non stressed conditions which is important for better crop growth and higher yield the differences in the water fluxes for different mulching materials and different parameters highlight that the benefits of soil mulching depend on the material characteristics the parameters used for each mulching material are shown in table s 3 supplementary material this variability in the mulching parameters is to be expected given the number of factors that affect the hydraulic characteristics of the material such as particle size layer compaction and the type of crop residue kader et al 2017 pavlu et al 2021 3 1 effects of rainfall regime the rainfall regime can vary significantly among different regions and similar climatic zones e g rainfall in the semi arid region varies between 20 and 80 cm year 1 in era5 land data hersbach et al 2020 affecting the efficacy of soil mulching to explore the interaction between the rainfall regime and the soil mulching controls on evaporation and transpiration we simulated rainfall as a poisson process varying α and λ to generate different rainfall regimes rodriguez iturbe and porporato 2005 as detailed in section 2 2 in particular we considered a growing season of 120 days varied the rainfall frequency λ between 0 2 and 0 8 d 1 and the mean rainfall depth α between 0 5 and 1 5 cm this resulted in total rainfall amounts over the growing season from 20 cm e g arid regions in ethiopia africa to 144 cm e g humid regions in eastern india we then compared the ratios between the evapotranspiration evaporation and transpiration under mulching sm and no mulching nm conditions considering typical parameters of a straw or grass mulch table s 1 the effect of soil mulching is highly dependent on rainfall depth and frequency and interestingly is not always beneficial for crop growth fig 3 generally the total evapotranspiration is not particularly affected as shown by the ratio et sm et nm varying only between 0 85 and 1 05 with values greater than 1 only when rainfall is below 40 cm fig 3a by contrast the individual evaporation and transpiration fluxes can be considerably affected by soil mulching the total evaporation over a growing season for sm is lower than in nm condition regardless of the rainfall regime with the evaporation ratio sm nm e sm e nm varying between 0 60 and 0 76 fig 3b suggesting that mulching effectively limits evaporation by at least 24 within the rainfall scenarios considered differently from evaporation the transpiration ratio t sm t nm varies between 1 00 and 2 20 showing a substantial increase for drier conditions fig 3b in fact when rainfall is higher than 40 cm during the growing season 120 days the increase in transpiration due to mulch is relatively low only up to 15 but for drier scenarios with rainfall lower than 30 cm t sm t nm rapidly increases the positive effect of soil mulching is particularly visible in the transpiration under non stressed conditions the ratio t sm ns t nm ns shows the highest variability fig 3c with higher values up to 6 8 for very dry climates α 0 70 cm and λ 0 3 d 1 and low values down to 0 86 for α 0 70 cm and λ 0 90 d 1 for which sm has a negative effect see fig s 2 in supplementary material this is explained by the fact that in drier climates where soil moisture is generally low soil mulching helps increase soil moisture but not to a level that produces percolation or runoff therefore the increased soil moisture only increases transpiration by contrast in wetter climates an increase in soil moisture which may already be close to the value at field capacity due to soil mulching promotes percolation and runoff at the expense of transpiration an example of the hydrologic dynamics for a condition in which transpiration reduces with mulching is shown in fig s 2 in supplementary material 3 2 effects of mulching layer thickness as presented in section 3 1 soil mulching can impact positively or negatively plant transpiration total or under non stressed conditions depending on the rainfall regime an important management decision that can control the effectiveness of soil mulching is related to the thickness of the mulching layer to explore the role of mulching thickness on transpiration we simulated the soil water balance considering different mulching layer thicknesses and rainfall regimes and computed the mulching layer efficiency in increasing plant transpiration as t sm t nm t nm fig 4 a in addition the ratios of the water balance components transpiration evaporation leakage and runoff to rainfall are shown in fig 4b e for different mulching layers thickness and rainfall regimes in fig 4 we show 4 rainfall regimes total rainfall of 24 and 40 cm with α equal to 0 5 and 1 0 cm but for completeness we present other rainfall regimes in fig s 3 in supplementary material the transpiration efficiency of mulching increases with mulching layer thickness regardless of rainfall scenario and tends to plateau for z m 6 fig 4a the mean rain depth plays an important role for the thin mulching layers as evident from the fact that for low mean rain depth α 0 5 cm mulching increases transpiration t sm t nm while for α 1 0 cm mulching reduces it t sm t nm t sm t nm t nm 0 as z m increases the role of total rainfall becomes more important with mulch being more effective for lower total rainfall as expected from the previous analysis on the effects of the rainfall regime the mean rainfall depth α can still improve although only slightly the effectiveness for thicker layers z m 5 6 cm to understand more in depth how the mulching thickness affects the soil water balance we also show how all the water fluxes vary with mulching thickness in the four rainfall regimes fig 4 evaporation and runoff in particular are two main mechanisms affecting the water balance based on the mulching layer thickness z m a thicker layer increases the resistance for the soil evaporation which as a consequence decreases as z m increases fig 4c evaporation is dependent mostly on rainfall total while the effect of rainfall depth is negligible the soil only receives water from the mulching layer which redistribute the input of rainfall as percolation the water storage capacity of the mulching increases as z m increases and this reduces runoff fig 4e runoff is more affected by mean rainfall depth than rainfall total as it is the more intense events typically to produce runoff thus the reduction in runoff and soil evaporation results in an increase in soil moisture that favors both plant transpiration and in particular in wetter climates e g blue lines leakage 3 3 soil mulching buffering of dry spells dry spells in rainfed systems may compromise plant growth and yield especially based on its timing and duration to explore the capacity of soil mulching to buffer the impact of dry spells we analyzed the soil moisture dynamics and plant transpiration for a long dry spell occurring from day 40 to day 70 of the growing season the rainfall was simulated using the poisson process and all events during the dry spell window were set to zero we used a fix mulching layer thickness of 5 cm the soil moisture plant transpiration and crop cover fraction ensemble averages and samples of single realizations as well as the probabilistic density function of soil moisture during the dry spell and total t are presented in fig 5 the probabilistic density function of s at the beginning middle and the end of the dry spell highlight the effect of mulching on soil moisture dynamics fig 5 generally the soil moisture is higher in sm than in nm for most of the growing season until the end of the dry spell while it shows a similar behavior after the dry spell day 61 and until plant senescence when the transpiration drops to zero moreover the mulching layer suppressed evaporation resulting in increased soil moisture in sm for the rainfall regime that we simulated at the beginning of the dry spell there is a high likelihood of s s in both sm and nm leading to low or no crop water stress however the probability of s s is higher in sm reflecting the benefit of soil mulching in reducing the risk of water stress this also favors higher t see bottom panel in fig 5 and consequently a higher crop growth in the middle of the dry spell day 55 the pdf of soil moisture has a similar shape but the probability of larger s values is still higher in sm than in nm although we can observe that the effect of mulching in buffering the soil moisturedecreases as the dry spell continues even in the last day of the dry spell day 70 the soil moisture under sm is still higher than in nm but in that condition the transpiration reduces significantly in both conditions since s approaches the wilting point s w the benefit of having soil mulching during a dry spell is evident from the differences in transpiration fig 5b since the crop cover fraction is low at the beginning of the growing season fig 5c t is similar for sm and nm up to approximately day 30 when the dry spell starts higher moisture levels promote faster crop cover growth in sm resulting in larger transpiration this is a function of c and in turn in even faster crop cover growth this is proportional to transpiration consequently there is an almost twice as high transpiration in sm as in nm during the dry spell fig 5b even after the dry spell t in sm remains higher than in nm until about the time of senescence as a result of soil mulching the average total transpiration was about 17 1 cm in sm and 13 2 cm in nm representing respectively 57 and 41 of the total rainfall r 29 8 cm we also analyzed the effects of different dry spell lengths on total transpiration over the growing season the soil water balance was simulated as described above with the dry spell starting at the day 40 and lasting from 5 to 30 days the total transpiration was computed throughout the season and t r with respect to the dry spell length is shown in fig 6 prolonged dry spells result in reduced t r as the evaporation increases and less water is available for crop growth and transpiration however t r is always substantially higher in sm than in nm varying between 0 64 and 0 57 for sm and between 0 56 and 0 44 for nm for dry spells ranging from 5 to 30 days long according to these results under sm the crop can withstand a 30 day longer dry spell and still have higher t r value than under nm we emphasize that this mulching buffering capacity depends on several controlling factors including mulching layer thickness et 0 soil properties plant stage and rainfall regime which here were kept constant 4 discussion despite the potential benefits of soil mulching as a conservation practice its effectiveness in increasing transpiration and crop growth varies widely between different studies kader et al 2019 qin et al 2015 here we applied a modeling approach to directly quantify how soil mulching affects the soil water balance and crop growth and explain observed differences across rainfall regimes and mulching properties the model was calibrated using experimental data provided by kader et al 2017 kader et al 2019 and zheng et al 2021 and it performed well when comparing the observed and modeled temporal evolution of soil moisture the coefficient of determination was actually slightly higher here than those found in kader et al 2019 which used a vertically explicit model based on richards equation the analysis showed that soil mulching tends to increase plant transpiration for most rainfall scenarios but particularly under drier conditions when rainfall is under 30 cm considering a crop growing season of 120 days as shown in fig 3 such dry conditions include for example ethiopia or kenya in eastern africa with rainfall around 25 cm yr 1 and single cropping rainfed systems for which soil mulching may be particularly effective van velthuizen et al 2007 however it is a combination of rainfall distribution and layer thickness that determines the effectiveness of soil mulching and depending on the combination of these factors soil mulching might even result in a reduction of transpiration long inter arrival times between rain events combined with high rainfall depths may in fact cause a reduction of transpiration in particular the transpiration under non stressed conditions fig 3 in this condition the model shows that the mulching layer saturates and loses large amounts of water by runoff fig s 2 in supplementary material the differences between results reported across soil mulching experiments e g zhu et al 2015 li et al 2018 kader et al 2019 tuure et al 2021 zhang et al 2021 may be due not only to the different rainfall regimes in the experimental sites 27 cm in northwest china to 87 4 cm in japan but also to the specific properties of the mulching material adopted here we found that the hydraulic properties of the different mulching materials across the experiments were very similar while the property affecting the functioning of soil mulching was its thickness currently there is no clear guidance on the amount of mulch to apply under a specific climate and cropping system as there are only a few experiments that explored the role of mulching furthermore it is difficult to retrieve this information from the literature as different studies report application rates in different units for instance as percentage of the soil covered abrantes et al 2018 in mass per hectare jalota and prihar 1990 or layer thickness gusev et al 2018 making it difficult to combine or compare their results as shown in fig 4 the effect of mulching is controlled by both its thickness and rainfall characteristics regions with high rainfall intensity may require a mulching layer thickness of at least 3 to 4 cm to increase plant transpiration while for low rainfall intensity a layer thickness of 3 cm or less can be enough to reduce water losses and increase transpiration overall a thicker mulching layer has a higher water storage capacity which reduces the runoff and increases the resistance to water vapor fuchs and hadas 2011 these results are in line with previous findings exploring the effect of the application rate for instance flower et al 2021 found a mulching rate 2 t ha 1 a thickness of about 2 5 cm assuming a typical mulching density of 8 12 kg m 3 based on dietrich et al 2019 and chen et al 2020 can effectively reduce soil evaporation in semi arid environments while a more noticeable effect was found when increasing the mulching layer thickness to 4 5 cm in eastern european steppes gusev et al 2018 gusev and dzhogan 2019 an important threat to food production in arid regions is the occurrence of dry spells which may expose plants to severe water stress zhu et al 2015 soil mulching helps increase the soil moisture resilience to dry spells by reducing soil evaporation tuure et al 2021 hence maintaining the productivity for longer kiboi et al 2017 as shown in fig 5 the soil moisture in the mulching treatment is higher than in the no mulching treatment until at least the middle of the dry spell for about 15 days although the difference in soil moisture may not be substantial between treatments this additional moisture supports an almost constant difference in t r between the no mulching and mulching treatments for dry spells of at least up to 30 days fig 6 this may result in reaching or not the maximum yield at the end of the season the difference between the two conditions can be considered as a measure of the mulching capacity to buffer dry spells for the simulated scenario the soil mulching condition would take about 30 extra days without rain to reach the same t r of no mulching condition this mulching capacity to buffer dry spells has also been observed experimentally in dry land smallholder systems in east africa tuure et al 2021 where soil mulching contributed to maintaining soil moisture above the critical stress level for at least 19 days since the beginning of the dry spell and longer for thicker mulching layers overall our work suggests that analyzing rainfall depth and frequency is key to determine a mulching layer thickness that effectively reduces runoff and soil evaporation and maximizes the water available for transpiration hence reducing the risks for the yield a positive finding is that soil mulching is particularly effective in drier climates right where soil evaporation tends to be higher due to high atmospheric evaporative demand soil mulching can thus be a valuable strategy to increase yield of rainfed systems especially in arid and semi arid regions where irrigation is often not a valuable option due to water scarcity pereira et al 2002 passioura 2006 we also highlight that this study was focused on the short term effect of organic mulch on the hydrology of rainfed systems during the crop cycles despite a negative effect on transpiration for certain combinations of rainfall and mulching thickness soil mulching brings about other important benefits such as increased carbon sequestration and improved soil bio physical properties kahlon et al 2013 for the sake of generality in our analysis we kept the potential evapotranspiration constant during the growing season and among rainfall regimes daily fluctuations in potential evapotranspiration have limited impact on the soil water balance especially when compared to the effects of rainfall fluctuations rodriguez iturbe and porporato 2005 daly and porporato 2006 variability in potential evapotranspiration across ecosystems does not affect particularly water limited ecosystems fu 1981 wang and tang 2014 daly et al 2019 daly et al 2019 such as arid and semi arid regions where soil mulching is needed and is effective therefore while the assumption of constant potential evapotranspiration may certainly affect some of our results especially in terms of detailed estimates we do not expect the assumption to alter our key conclusions such as the patterns in figs 3 and 4 there is also a need for experimental exploration of the hydraulic properties of different mulching materials level of grinding and compactness mulching and soil properties here kept constant jointly regulate the soil water balance and hence are important factors that need to be further assessed these further investigations will help estimate optimal application rates i e and layer thickness based not only on on site climatic and edaphic factors but also on the availability of mulching materials and associated equipment 5 conclusions there is still limited understanding of how the mulch layer modulates the hydrologic cycle and impacts crop growth here we studied the effectiveness of soil mulching in increasing crop transpiration across rainfall regimes and mulching layer thickness and showed that mulching can increase transpiration twofold but can also reduce it in climates with high rainfall intensity we also demonstrate that the mulching layer thickness is an important property that along with rainfall intensity and distribution regulates the efficacy of soil mulching suggesting that the thickness should be carefully selected depending on the site specific climate under drier rainfall regimes with moderate rainfall events a mulching layer thickness of 3 cm or lower would suffice to increase plant transpiration while wetter climates with low rainfall frequency require thicker layers especially for those regions where the ongoing climate changes are increasing rainfall variability the soil mulching can also buffer the effects of dry spells that might occur during the growing season by retaining soil moisture for longer and promoting an increase in transpiration future work will explore the link between the dynamics of mulching moisture and the decomposition of the organic mulching material to investigate how in addition to increasing water retention mulching can positively affect soil biophysical properties declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank the three anonymous reviewers for the constructive comments this work was supported by the department of biological and agricultural engineering and agrilife research at texas a m university and the usda national institute of food and agriculture hatch project 1023954 the full model code is available as the julia package soilmulch and is archived at the github repository https github com calabresehydrologylab soilmulch jl fig 1 was created with biorender com appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2022 127523 supplementary data the following are the supplementary data to this article supplementary data 
3581,evaporation as a core process within the global hydrological cycle requires reliable methods to monitor its variation for decision making in agriculture irrigation systems and dam operations also in other areas of hydrology and water resource management accurate monitoring of pan evaporation e p is one the most popular approaches to understand the evaporative process this work aims to construct a hybrid long short term memory lstm predictive model that is coupled with neighbourhood component analysis for feature selection to predict e p in drought prone regions in queensland australia amberley gatton oakey townsville utilizing the daily scale dataset 31 august 2002 to 22 september 2020 the performance of the proposed deep learning dl hybrid model denoted as nca lstm is compared with competitive benchmark models i e standalone lstm other types of dl single hidden layer neuronal architecture and decision tree based method the testing results reveal the lowest relative root mean square error 20 absolute percentage bias 14 5 and the highest kling gupta efficiency 87 attained by the nca lstm hybrid model relative to benchmark models tested for amberley gatton and oakey sites in respect to the predictive efficiency the proposed nca lstm hybrid model improved with feature selection outperforms all benchmark models indicating its future utility in the prediction of daily ep in practical sense the predictive model developed for ep estimation provides an accurate estimation of evaporative water loss in hydrological cycle and therefore can be implemented in areas of irrigation management planning of irrigation based agriculture and mitigation of financial losses to agricultural and related sectors where regular monitoring and forecasting of water resources are a vital part of sustainable livelihood and business keywords prediction of pan evaporation long short term memory networks neighbourhood component analysis deep learning hybrid models evaporative water loss 1 introduction evaporation is a key element in the hydrological cycle where water in the liquid phase from the earth s surface transforms into atmospheric water vapour usqs 2021 it is a major cause of water loss in both arid and semi arid regions koohafkan and stewart 2008 precise measurement and calculation of water loss due to evaporation is extremely useful in efficient water resource management abtew and melesse 2012 the more popular approaches for measuring and calculating evaporation relate to the data from evaporation pan method water balance and energy balance methods including the penman equations that aim to integrate both mass and energy balance methods ghorbani et al 2017 the most popular method is the evaporation pan method as it is relatively simpler and less expensive keshtegar et al 2016 kahler and brutsaert 2006 showed that the evaporation pan method gives an accurate value of the actual changes in evaporation hence the present study aims to predict pan evaporation ep as a close approximation of the actual evaporation the methods related to empirical evaporation equation water budget and energy budget based on meteorological datasets have been utilized for e p prediction dewes et al 2017 antonopoulos and antonopoulos 2017 however the predictive errors in these methods can be relatively large due to the complex nonlinear behaviour of the evaporative process which is not captured adequately by the linear modelling approach singh and xu 1997 kişi 2006 further empirical models need recalibration of model coefficients before implementing in different agroclimatic zones as they are not performing similarly in distinct situations to minimize these constraints many researchers are now locating their efforts in data driven machine learning techniques to predict evaporative losses these works use various climatic parameters as predictor variables abghari et al 2012 ghaemi et al 2019 ghorbani et al 2017 guven and kisi 2013 malik and kumar 2015 shirsath and singh 2010 wu et al 2020 the study of keskin and terzi 2006 used an artificial neural network ann model to predict e p in a lake in turkey and showing that the performance of ann was superior to the penman approach research conducted by deo et al 2016 revealed that relevance vector machine rvm outperformed in estimating monthly evaporative losses using meteorological parameters as predictor variables over the extreme learning machine elm and multivariate adaptive regression spline mars wang et al 2017 in another study to estimate daily e p using fuzzy genetic fg least square support vector regression lssvr mars m5 model tree m5tree and multiple linear regression mlr for eight stations around dongting lake basin in china has shown that fg and lssvr outperform over other machine learning techniques malik et al 2017 in their study to estimate monthly e p in the indian central himalayas region has utilized multi layer perceptron neural network mlpnn co active neuro fuzzy inference system canfis radial basis neural network rbnn and self organizing map neural network somnn while using gamma test for the selection of appropriate input combination has revealed superiority of canfis over other techniques the potentials of decision tree based machine learning methods such as chi square automatic interaction detector chaid and classification and regression tree cart for daily e p estimation in turkey were examined in research carried out by kisi et al 2016 and compared that with the neural network model this study revealed that neural networks performed better compared to the decision tree based machine learning models goyal et al 2014 have tested ann lssvr fuzzy logic fl and anfis techniques in estimating daily e p and the results are evaluated against empirical methods proposed by hargreaves and samani hgs and the stephens stewart ss findings of this study has shown that fl and lssvr techniques are superior to the traditional approaches in daily evaporation estimations deep learning dl methodologies consist of advanced multi layered neural networks provide a new gateway for e p predictions as they are now becoming popular categories of artificial intelligence approaches used in both scientific and industrial research due to their improved accuracy emmert streib et al 2020 the utilization of dl is appealing for time series prediction given its success in many fields literature proves that among dl methodologies long short term memory lstm network is widely used in prediction of hydro meteorological and other variables due to its remarkable performances for example ghimire et al 2019c developed a solar radiation forecast model using lstm network coupled with convolutional neural network cnn and it has shown superior performances compared to the benchmark models cnn lstm gated recurrent unit gru recurrent neural network rnn deep neural network dnn multi layer perceptron mlp and decision tree dt the study carried out by zhang et al 2018 to forecast daily land surface temperature using deep hybrid lstm network coupled with ensemble empirical mode decomposition eemd shown that this target eemd lstm model outperformed over recurrent neural network rnn lstm rnn coupled with empirical mode decomposition emd lstm coupled with emd and rnn coupled with eemd poornima and pushpalatha 2019 built up a lstm model for drought predictions based on standardized precipitation index spi and standardized precipitation and evapotranspiration index spei for 1 6 and 12 month time scale and compared its performances with arima statistical model for all given time scales in this study target lstm model was shown better performance than all other comparison models further ferreira and da cunha 2020 have developed multi step cnn lstm model to forecast daily reference evapotranspiration for 53 weather stations located in minas gerais brazil this model has exhibited better performance than traditional machine learning ann and rf models however studies on employing lstm network to predict ep is lack in literature the study carried out by majhi et al 2020 to predict evaporative loss is a recent example for employing lstm for ep prediction this study appears to be the only one study employing the lstm model for evaporative loss prediction in this study the lstm model was compared with multilayer artificial neural networks and empirical methods like hargreaves and blaney criddle showing its superior capability to predict daily evaporative losses against selected benchmark models however literature is not providing any evidence of employing more advanced hybrid lstm for evaporative loss predictions therefore the present study aims to construct hybrid ep forecasting model utilizing lstm network coupled with neighbourhood component analysis nca feature selection technique we have not come across any work applying nca algorithm integrated with deep learning to predict daily ep or using the deep learning nca lstm hybrid model for any other purposes feature selection is a primary step in advanced data driven models which reduces the high dimensional or redundant inputs to a set of low dimensional or selects most relevant datasets prior to constructing a predictive model nca is a good feature selection technique use for selecting features to maximize prediction accuracy of regression and classification algorithms mathworks 2021 wei yang 2012 showed experimentally that the nca is highly sensitive to such irrelevant features and therefore can perform well in reducing high dimensional data to determine the most relevant input features in this respect the nca method has been used extensively in many disciplines to identify the most relevant features and eliminate the irrelevant variables to improve the performance of a model jin and deng 2018 explored a new ensemble decision tree classifier to predict different stages of alzheimer s disease showing that the nca based model was more effective than its standalone counterparts ghimire et al 2019a compared global solar radiation forecasting accuracy with an ann model that has the nca feature selection method with standalone models support vector regression gaussian process machine learning and genetic programming evidently the ann model integrated with nca appeared to be an elite tool considering its merits and significant capabilities that are likely to increase the overall forecasting skill of a predictive model nca is selected as the feature selection technique in this study this study is a novel experience in data science field as it is found to be the first time that lstm is being hybridized with nca and employed in daily ep predictions using satellite and ground based data 2 study case and data materials 2 1 study region hence it is not practically possible to consider the entire globe the present study is centred in queensland australia where 84 of its land resources are used for agricultural purposes doawe 2020 the queensland government declared 67 4 of the land area drought affected in the year 2020 queensland 2020 according to craig et al 2005 annual water loss due to evaporation and the underlying water storage in irrigated agricultural areas particularly in the present study area can be up to 40 of total storage volumes therefore developing an accurate estimation model to predict the water deficits is a strategic approach to devise hydrology and water resource management frameworks in this drought prone region in this study four sites located within the arid and semi arid areas in queensland were selected amberley 152 71 e 27 63 s gatton 152 34 e 27 54 s oakey 151 74 e 27 40 s and townsville 146 77 e 19 25 s see fig 1 the land resources in these selected study sites are mainly utilized for farm operations particularly in producing a wide range of agricultural products therefore this study aiming to build deep learning models for the prediction of evaporation is of great significance particularly in management of water resources for sustainable agriculture 2 2 data daily climatic data for 22 predictive and target variables for 31 august 2002 to 22 september 2020 period were extracted for all the study sites from the databases of nasa s goddard online interactive visualization and analysis infrastructure giovanni atmospheric infrared sounder airs spectrometer satellite and the ground based scientific information for landowners silo the giovanni provides easy and user friendly access to visualize and analyse the vast amount of earth science related remote sensing data teng et al 2014 that inform the pattern in hydrological changes and the evaporative loss in addition the giovanni data can be extracted easily without prior knowledge of downloading the more complex remote sensing datasets and can be sourced from several platforms instruments namely the atmospheric infrared sounder airs the tropical rainfall measuring mission trmm ozone measuring instrument omi the moderate resolution imaging spectroradiometer modis the modern era retrospective analysis for research and applications merra project and both the north american land data assimilation system nldas and the global land data assimilation system gldas with various spatial and temporal resolutions in this study we have selected the airs platform with 1 x 1 spatial resolution within the giovanni archives used to extract the most correlated atmospheric and hydrological variables in relation to e p in addition the ground based data for predictor variables were extracted from silo source for the same period to further improve the model s performance this database is operationally managed by the queensland government morshed et al 2013 class a pan evaporation data for the target variable e p were extracted from silo data base table 1a shows a summary of data sources and predictor variables with their respective acronyms used in this research paper 3 methodology 3 1 time sequential predictive algorithm long short term memory lstm network the lstm is a special recurrent neural network rnn cho et al 2014 related to conventional artificial neural networks that is mainly used to identify patterns in sequences of data such as text video speech language genomes and time series variables manaswi 2018 the rnn model has been associated with the problem of vanishing or exploding gradients with long data sequences swamynathan 2019 this has led to an unnecessary increase in training time and is one of the main reasons that rnn is not used for deep sequence contexts manaswi 2018 due to these limitations rnn has been further modified to build lstm as noted in the work of hochreiter and schmidhuber 1997 lstm networks are able to capture higher order nonlinear features in predictor datasets majhi et al 2020 lstm also can explore the inherent features within time series predictors and target considering the persistent patterns over historical periods of time to generate improved performances moreover the lstms operate with special units denoted as memory blocks that consist of input output and forget gates and these memory blocks continuously update and control the information flow chen et al 2018 these gates also receive input data from the previous time step t 1 and the new time step t and help to eliminate the vanishing gradient issues working efficiently with large time series datasets such as those in the present study considering all merits past records of outstanding performances and its high suitability in analysing nonlinear time series data lstm network with general input hidden output layers framework is selected as the forecasting algorithm in the hybrid ep prediction model proposed in the current study a brief explanation on theoretical overview of lstm architecture is given in the appendix 3 2 feature extraction algorithm neighbourhood component analysis this study uses neighbourhood component analysis şenkal and kuleli 2009 which is a non parametric feature selection method that can increase the predictive accuracy mathworks 2020 in this study data of high dimensional predictor variables from satellite sources i e the atmospheric infrared sounder airs and ground based sources silo which are non linearly related to ground based evaporation data is used for proposed model training nca has shown success in previous works in nominating corelated predictor variables to the target variable to be considered for model training this helps in dimensionality reduction of data and consequently leads to increase the prediction accuracy of models further it is not being used for ep prediction works before considering above facts it is selected as the feature selection algorithm in the current study the list of the selected predictor variables by nca feature selection process is shown in table 1b further fig 2 is showing the correlation metrics of extracted predictor variables by the nca algorithm and target variable e p for all study sites the meanings of all acronyms used in table 1b and fig 2 are as per table 1a according to fig 2 radiation and maximum temperature are the most highly correlated predictive variables with e p for all sites theoretical overview of nca algorithm is briefly described in appendix 3 3 deep learning hybrid model long short term memory network integrated with neighbourhood component analysis nca lstm many research works have evidently shown that dl hybrid models are very successful than other standalone machine learning models in terms of prediction accuracy however literature is not providing any evidence of employing hybrid dl model for evaporative loss predictions and also current study uses relatively big volume of high dimensional data from two distinctive data sources thus data processing prior to the model training can favourably influence the final outcome of prediction model above facts directed the current study to develop hybrid dl model by combining nca feature selection algorithm and lstm neural network for ep prediction in this hybrid nca is employed to extract the most correlated predictor variables related to the target variable e p and the lstm network is employed to build a precise ep forecasting model using data of those corelated input variables fig 3 illustrates the topological structure of nca lstm hybrid model proposed in this study before applying nca input data was normalized as they are in different scale data of different scales will produce weights in different scales in the nca feature selection process and therefore not meaningful as nca feature selection is a dimensional reduction process z score standardization is used in this normalization step mathworks 2020 after normalizing daily interval data set were sent through the nca algorithm embedded in machine learning toolbox function fsrnca on matlab platform data of selected predictor variables by nca feature selection is used for ep prediction model development and training in the next step data of selected predictor variables by above feature selection process were normalized between 0 1 to remove the variance before starting the model development and training garcía et al 2016 as this is a regression and prediction process max min scaling approach is used in this step and the equation is given below 1 x n x actual x min x max x min where xn x actual x max and x min represent the normalized actual maximum and minimum values of predictor variable data respectively the normalized data for all predictor variables and target variable were then partitioned into the training and testing sets as there is no rule of thumb for data division 80 of data is allocated for the training data set while 20 of data is allocated for the testing data set and 10 of the training data set is used for the model validation process in this study to construct the best architectures of the target hybrid model nca lstm and comparative standalone models lstm dnn rf ann and dt hyperparameter optimization is employed using the hyperopt algorithm in python model architectures were designed based on optimal hyperparameters given by hyperparameter optimization process table 2 shows the list of hyperparameters and trainable number of model parameters for nca lstm and the comparative standalone predictive models with optimal parameters for all models boldfaced in blue for gatton site following the results shown in table 2 optimum architecture for nca lstm is designed embedding six lstm layers consisting of 150 50 100 50 50 and 10 neurons prior to the output layer dropout layers were added after each lstm layer with 0 3 dropout ratio the batch size selected was 10 while activation function weight initializer and recurrent activation function selected were relu he uniform and sigmoid respectively after designing model architectures model training process was carried out followed by model validation process using training data set in the next step prediction skills of models were tested using unseen testing data set and predicted values of ep in this step were denormalized for the visualization purpose and compared with observed ep note that high computational cost due to the longer time taken for the training process is a significant issue experienced in the development of a machine learning model ghimire et al 2019c one of the main factors which lengthens the time for the training process is the algorithm used for hyperparameter optimization yu et al 2019 the performance of the hyperopt algorithm in the hyperparameter optimization process is better than the grid search and random search algorithms as it ensures comparatively less time in the model training process while increasing the accuracy of the model putatunda and rama 2018 the time taken for the hyperopt algorithm optimization process is about 1 5 h in this study however this optimization process helps to bring the model training and testing time down to less than 20 min overfitting is also another common issue that can be experienced in the process of dl model training this occurs when the model identifies specific patterns of training data and thereby achieves good fit with those training data overfitted models are failing to generalize on new unseen data as the specific patterns recognized by them in training data sets cannot be seen in new data sets zech et al 2018 there are several ways that can be used to reduce overfitting problem in dl model training process the best option is to get more training data however it was not practicable in current study due to time and data availability constraints so that in this study early stopping es which is one of the hyperparameters in keras dl library chollet 2015 zeng 2019 is used as a major strategy to avoid the overfitting problem it does this by stopping the training process when validation loss stops thus decreasing in the specified epochs further dropout layers are added after each deep learning neural layers to reduce the overfitting problem ferreira and da cunha 2020 in addition hyperparameter optimization step done here which tunes different architectures via hyperopt until a suitable number of nodes layers epochs activation function weight initializer dropout ratio and or batch size is found is also assisting to reduce the overfitting problem the proposed hybrid model i e nca lstm and all other comparative standalone models i e deep learning and conventional models are developed using an intel core i7 3 3 ghz and 16 gb memory computer built using freely available dl libraries keras ketkar 2017 and tensorflow abadi et al 2016 in python sanner 1999 3 4 benchmark models used for performances evaluation of the proposed nca lstm hybrid model in this study other than the standalone lstm artificial neural network ann deep neural network dnn decision tree dt and random forest rf are selected as benchmark models for performance comparison with proposed hybrid nca lstm model all these benchmark models are having diverse architectures and belonging to different generations in the machine learning family ann is a widely used algorithm and has shown high performances in previous research studies for example shirsath and singh 2010 developed ann and multiple linear regression mlr models along with penman priestley taylor and stephens and stewart models to estimate ep and that were compared statistically with observed ep comparison showed that ann model performs better than other models another study caried out by bruton et al 2000 revealed that ep estimated with ann models was more accurate than multiple linear regression model and the priestley taylor equation ann is a single neural layer machine learning model and its theoretical overview is discussed in previous studies carried out by deo et al 2018 deo and şahin 2017 dnn algorithm a further advancement of ann and having multiple neural layer network architecture and belongs to the dl subset in machine learning family is also increasingly deployed in real world applications for example yi et al 2017 developed dnn model to analyse and estimate traffic conditions using big data of real time transportation and it has shown 99 estimation accuracy however literature does not provide any evidence for use of dnn in ep prediction studies the theoretical background and mathematical formulae of dnn algorithm is described in a previous study carried out by ghimire et al 2019b rf is a tree based regression algorithm consisting of many decision trees theoretical background is described in detail in previous literature chen et al 2019 lin et al 2017 rf also has been widely employed in many research works for instance althoff et al 2020 employed rf along with penman equation cubist regression cb bayesian regularized neural network brnn and svm models to estimate small reservoir evaporation in brazilian savanna and in this study rf shown the best performance a pan evaporation prediction model was developed by singh et al 2021 using rf model along with feature selection for karnal district india and performances were compared with ann back propagation algorithm proposed rf model has shown best performances in this study instead of high performance of rf model it generally requires less adjustment in hyperparameters ferreira and da cunha 2020 dt is an extensively used early stage tree based machine learning regression algorithm and the theoretical concepts are described in detail by song and ying 2015 for instance tso and yau 2007 employed traditional regression analysis methods dt and neural network models to predict electricity energy consumption in this study dt and neural network models has exhibited the best performances showing their usefulness in understanding and predicting energy consumption patterns dt has also been widely used as a classification method for example hamsa et al 2016 developed a student s academic performance prediction model for the bachelor and master degree students in computer science and electronics and communication streams using dt and fuzzy genetic algorithms results has shown that dt model can be used to identify student s performance for each subject successfully than the fuzzy genetic algorithms the main reason to select above benchmark models is to increase the validity and the precision of the performance evaluation testing thus they were selected based on their architectural diversity and high performances they have shown in previous research works the performances of the target hybrid model can be evaluated in broader sense as these benchmark models are architecturally distinctive to each other and representing machine learning model categories in wide range in this study empirical methods are not used as the benchmark models as it is more suitable to select advanced machine learning benchmark models which have shown superiority over those empirical methods in previous research works furthermore use of such lower performing empirical methods instead of better alternative machine learning options may show big performance gap consequently leading to over estimate the proposed hybrid model 3 5 model performance evaluation model performances evaluation in terms of prediction accuracy and errors is essential part of machine learning model development such evaluation supports in determining the appropriateness of a model for specific applications facilitates comparative assessment against rival models and modelling techniques and detects aspects of a model most in need of improvement pearce and ferrier 2000 thus following statistical score metrics are used to evaluate the performance of the nca lstm hybrid model against benchmark models pearson s correlation coefficient r the value of r eq 2 describes the degree of collinearity between forecasted e p for and observed e p obs values moriasi et al 2007 in general the r value always lies between 1 to 1 including 1 and 1 the r value is equal to 1 when correlation between two variables e g forecasted and observed e p is strongly and positively correlated it becomes equal to 1 when the correlation between two variables is perfectly strong and negative if no correlation exists between two variables the r value will be equal to 0 however in this case the values forecasted by the forecasting models should be strongly and positively correlated with observed values therefore r value should be either equal to 1 or very close to 1 van vuren 2020 2 r i 1 n e p obs i e p obs e p for i e p for i 1 n e p obs i e p obs 2 i 1 n e p for i e p for 2 1 r 1 root mean square error r m s e m m d a y 1 the rmse eq 3 is commonly used for the performance evaluation of regression models the rmse measures the average model performance error between predicted value e p for and observed value e p obs willmott and matsuura 2005 the rmse value can range from 0 to whereas the value of rmse becomes zero for the best predictive models 3 rmse 1 n i 1 n e p for i e p obs i 2 0 r m s e mean absolute error m a e m m d a y 1 this error value eq 4 provides an assessment of the actual forecasting errors concerning the total number of observations prasad et al 2019 mae can range from 0 to whereas the value of mae becomes zero for best predictive models the mae gives a more robust measure of average model error than the rmse since it is not influenced by extreme outliers legates and mccabe 1999 4 mae 1 n i 1 n e p for i e p obs i 0 m a e willmott s index w i the wi eq 5 is more rationally related to model accuracy than other existing indices and quite flexible making it applicable to a wide range of model performance problems willmott et al 2012 the value for wi ranges from 0 to 1 whereas this value equals 1 for best predictive models 5 wi 1 i 1 n e p obs i e p for i 2 i 1 n e p for i e p for e p obs i e p obs 2 0 w i 1 nash sutcliffe index n s the ns eq 6 nash and sutcliffe 1970 reflects how well the plotted line between observed data and simulated data fits into 1 1 the ns will be equal to 1 if the model forecasted data is perfectly matched to the observed data the ns 1 indicates that the model predictions are as accurate as of the mean of the observed data while inf ns less than 0 indicates that the observed mean is a better predictor than the model agrimetsoft 2019 6 ns 1 i 1 n e p obs i e p for i 2 i 1 n e p obs i e p obs 2 n s 1 legate and mccabe index lm the lm eq 7 is an advanced assessment metric based on wi and ns values this index can be used to assess the goodness of fit of a hydrologic or hydro climatic model and is more effective than correlation and correlation based measures e g the coefficient of determination r 2 wi and ns legates and mccabe 1999 the value for lm ranges from to 1 whereas this value equals one for best predictive models 7 lm 1 i 1 n e p for i e p obs i i 1 n e p for e p for e p for e p obs 2 l m 1 relative root mean square error rrmse the rrmse eq 8 is used to evaluate and compare the model performances it provides an overall forecasting accuracy of the respective models and always gives positive values prasad et al 2019 if the value for rrmse is less than 10 r r m s e 10 model performance is considered to be outstanding while model performance is considered to be good if it is lying between 10 and 20 10 r r m s e 20 if the value for rrmse error lies between 20 and 30 20 r r m s e 30 model performance is considered as fair if the value for rrmse error is higher than 30 rrmse 30 model performance is considered to be poor ertekin and yaldiz 2000 8 rrmse 1 n i 1 n e p for i e p obs i 2 1 n i 1 n e p obs i 100 0 r r m s e absolute percentage bias a p b the apb eq 9 gives the error of forecasted values as a percentage concerning the observed values the optimal value for apb is zero and lower magnitude values closer to zero reflect good accuracy of the model ghimire et al 2019b 9 apb i 1 n e p obs i e p for i 100 i 1 n e p obs i kling gupta efficiency kge the kge eq 10 measures the goodness of fit of the model it was developed by gupta et al 2009 this metric can be decomposed into the contribution of mean variance and correlation on the model performance kling and gupta 2009 perfect models will give value one for the kge index ghimire et al 2019b 10 kge 1 r 1 2 cv for cv obs 2 e p for e p obs 1 2 where cv coefficient of variation e p obs e p for e p obs and e p for are observed ep forecasted ep average of observed ep and the average of forecasted ep respectively n is the total number of data points of the test dataset 4 results and discussion 4 1 result to establish the robustness of the proposed hybrid nca lstm ep forecasting model this section provides detailed analysis of empirical results derived from this modelling experiment and comparative assessment of model performances in this experiment total of six models including the proposed model i e nca lstm and benchmark models standalone lstm multi hidden layer dnn single hidden layer ann ensemble rf regression and dt were employed in ep prediction task in four sites namely amberley 152 71 e 27 63 s gatton 152 34 e 27 54 s oakey 151 74 e 27 40 s and townsville 146 77 e 19 25 s in queensland australia assessment of all models including the proposed model was done based on the results of performance evaluation metrics r rmse mae rrmse w i ns lm a p b and kge in the testing phase for all study sites the r value is used to assess the performances of all models experimented in the current study in terms of degree of collinearity between forecasted e p for and observed e p obs values the r values given for the nca lstm hybrid model tested at amberley gatton oakey and townsville are found to be 0 9142 0 9208 0 9221 and 0 8080 respectively the values of r produced by all other benchmark models are lower than the r values of the nca lstm hybrid model for all sites see table 3 so that nca lstm model is showing the highest degree of collinearity between forecasted e p for and observed e p obs values furthermore r values generated by the proposed hybrid nca lstm model for amberley gatton and oakey sites are quite close to 1 it should be noted that the pearson s correlation coefficient r value reaches 1 when the model performance is perfect hence it appears that the nca lstm hybrid model shows a better performance than its comparative counterpart models in terms of the r value computed between observed and forecasted e p and also this results further affirms the improvement of dl lstm modal performances via hybridization with nca feature selection technique comparing the different sites the present results show that when the model performance is higher the values of the root mean square error r m s e m m d a y 1 and mean absolute error m a e m m d a y 1 are lower for example the rmse values generated by the nca lstm hybrid model for the amberley gatton oakey and townsville study sites are 0 9129 0 9126 0 9890 and 1 3982 while the mae values are 0 6687 0 6684 0 7033 and 1 0555 respectively importantly the rmse and mae values produced by all other benchmark models are higher than the r m s e a n d m a e values registered by the nca lstm hybrid model for all study sites as evident in table 3 for instance rmse and mae values are 0 9363 and 0 6827 for lstm 1 0233 and 0 7570 for dnn 0 9923 and 0 7169 for ann 1 1494 and 0 8795 for rf and 1 0818 and 0 7963 for dt respectively in amberley site which all values are higher than the rmse 0 9129 and mae 0 6687 values for nca lstm model these evaluation metrics assess the models with respect to prediction errors thus lower values are expected from forecasting models according to the rmse and mae values the nca lstm hybrid model appears to exhibit a better performance relative to all other counterpart models as it has shown lower prediction errors to enable a comparison of the nca lstm hybrid model tested at geographically diverse sites where absolute errors do not make sense the relative root mean square error rrmse is used and this metric appears to be lower for the objective model as another measure of model accuracy the radar plots shown in fig 4 clearly illustrate that the nca lstm hybrid model has the lowest rrmse for all study sites furthermore the rrmse values generated by the nca lstm hybrid model for the amberley gatton and oakey study sites are about 19 381 19 08 and 19 92 respectively and these values are less than the 20 required for a good predictive model the rrmse value generated by this proposed hybrid model for the townsville study site is about 21 23 however this rrmse value scored by the proposed nca lstm hybrid model for townsville is still lower than the values of the other benchmark models since rrmse values are less than 20 for three sites amberley gatton and oakey out of four sites the nca lstm hybrid model can be considered as a well performed model to estimate daily ep in this study we adopt the values for willmott s index wi nash sutcliffe coefficient ns and legates mccabe s index lm to measure the accuracy of the nca lstm hybrid model note that for a perfect model these metrics should register a value of unity it is noted that the values of these performance metrics registered by the nca lstm hybrid model are closer to unity compared with any of the other benchmark models employed in this research study according to the results shown in table 4 the highest wi values belong to the nca lstm hybrid model for all study sites that is we obtained a value of wi 0 9544 0 9534 0 9562 and 0 8948 for amberley gatton oakey and townsville respectively a similar trend is shown by the nca lstm hybrid model if we use the ns values to evaluate its performance against the other benchmark model for example the highest magnitude of ns 0 8460 has been registered for the oakey study site for the nca lstm hybrid model while the lowest value of ns 0 5517 has been registered at the townsville study site for the dt based model although relatively low values of the lm metric for the nca lstm hybrid model are between 0 4400 and 0 6600 for all study sites these values are still higher than the values compared to the other benchmark models since the highest wi ns and lm values are demonstrated for all the study sites by the nca lstm hybrid model we aver that the proposed deep learning model has strong potential to forecast daily e p in terms of the absolute percentage bias apb error calculated in the testing phase fig 5 shows that the nca lstm hybrid model generates a lower percentage value of apb compared to the other benchmark models and this is comparatively closer to zero for all study sites for instance the lowest value of apb 13 88 is produced by the nca lstm hybrid model while the highest value of apb 17 53 is produced by the ann model for the gatton study site furthermore the value of the kling gupta efficiency kge another metric used to test the efficacy of the proposed deep learning model appears to be closer to a value of unity for all study sites relative to all the other benchmark models to highlight this metric for the nca lstm hybrid model for example we note that kge 0 87 for the study sites amberley gatton and oakey while kge 0 80 for the townsville study site importantly these values are higher than those of the comparative models for all the study sites as illustrated in fig 5 overall the present analysis provides compelling evidence that the nca lstm hybrid model has a significant potential to predict daily e p and this performance exceeds that of the comparative models for all the study sites in queensland we further evaluate the efficacy of the newly proposed nca lstm hybrid model by using the spread of the prediction error p e o b s e r v e d v a l u e p r e d i c t e d v a l u e including those of the other benchmark models for all the selected study sites these are depicted as bar plots in fig 6 it is noteworthy that predictive error is lower for the case of the nca lstm hybrid model for all the study sites compared to the other models used in the testing phase fig 7 shows the scatter plots of the observed vs the predicted daily e p for the nca lstm hybrid model and all the benchmark models in the testing phase the coefficient of determination r 2 resulting from these scatter plots can advise a reader how well the variance in modelled e p compares with the variance in observed e p with this value being bounded by 0 and 1 if the model is fitted well and the relative covariance between the forecasted and observed e p resonates well the r 2 is closer to value unity according to fig 7 all of the models appear to register high r 2 values which are closer to unity except for townsville however the nca lstm hybrid model yields the highest r 2 value compared with the other models for all study sites the r 2 values scored by the proposed nca lstm hybrid model for the amberley gatton oakey and townsville study sites are approximately 0 8353 0 8501 0 8502 and 0 6528 all of which exceed the values of 0 8295 0 8478 0 8389 and 0 6324 generated by the lstm model this deduction shows that the nca lstm hybrid model can produce more accurate e p compared to the other benchmark models and shows that the proposed deep learning hybrid model can be considered as a significant forecasting tool to predict e p in queensland according to the results it is noticed that proposed hybrid nca lstm model outperform over all benchmark models including the standalone lstm in all sites reflecting the positive influence of nca feature selection algorithm on increasing the prediction accuracy 4 2 discussion pan evaporation is affected by periodic meteorological parameters such as air temperature humidity radiation and wind speed trends and irregularities of meteorological variables clarify the effect of those variables on pan evaporation singh et al 2021 several researchers have explained the pan evaporation paradox which suggests the relationship of reduction in pan evaporation with increase in air temperature jaswal et al 2008 jhajharia et al 2009 investigated the effect of meteorological parameters such as air temperature relative humidity sunshine duration vapour pressure wet bulb temperature number of rainy days and wind speed on evaporation at agartala using linear and exponential methods and discovered that the wind speed and mean temperature had positive and significant impact on pan evaporation another study carried out by liu and xia 2012 in haihe river basin china has shown that evaporation was most sensitive to net radiation many research works in addition to the above proves that influence of such meteorological parameters on pan evaporation is site specific in our study we have extracted data for 21 meteorological predictor variables listed in table 1a and selected more correlated variables to e p using nca feature selection process see table 1b correlation metrics see fig 2 were used to analyse and visualize the selected predictor variables according to the results of nca feature selection process in our study maximum temperature max temp solar radiation radiation minimum temperature min temp are positively correlated with e p while relative humidity at time of maximum temperature rh tmax relative humidity at time of minimum temperature rh tmin and air temperature at surface daytime atsd mean sea level pressure mslp relative humidity night time rhn and surface temperature sth are negatively correlated with e p among of them maximum temperature and radiation are highly influenced on evaporation loss in our study proposed nca lstm model has shown leading performances in ep prediction in all four sites selected while all the other benchmark models get ranked in different positions in terms of ep prediction performances in different sites consistency shown by the proposed nca lstm model in ep prediction performances by securing its position as the best ep prediction model in all study sites affirms the synergetic effect of hybridizing lstm with nca in this study nca feature selection algorithm has shown its capability in improving the performance of dl predictive model in terms of the limitations of this study it is acknowledged that data were extracted and modelled for only four study sites within queensland as a case study to achieve the objectives while this pioneer study has no doubt produced a new modelling framework for ep prediction albeit within a limited scope future studies can select more sites representing the whole drought affected region in australia or elsewhere while this was useful research and does indicate a scope for future studies the geographic dependence of nca lstm hybrid model accuracy should be considered in any future research nonetheless the deep learning has significant implications in managing irrigations and other water resource systems through monitoring the changes in daily e p the practical implication of this study is that the e p predictive model which can yield a very close estimation of the actual water loss due to evaporation and its relationship to the management of water resources can used as a scientific strategy for irrigation and other agricultural purposes it should be noted that by multiplying the e p values with the surface area of the irrigation water resources the volume of water losses due to evaporation which is a major cause of water loss from the available water resource volume can be calculated therefore the total volume of available water for irrigation purposes can be easily estimated and accordingly a suite of smart irrigation schedules can be planned or implemented these schedules can avoid unnecessary water losses due to more relaxed irrigation practices therefore the present deep learning hybrid model used for predicting e p is expected to yield significant financial benefits to the farmers in arid and semi arid regions where agricultural practices are constrained by water resources drought and other forms of hydrological imbalances also this study provides a significant guideline for hydrologists in analysing non linear and non stationary behaviour in hydrological cycles using soft computing 5 conclusions and recommendation for future work this study has focused on designing a deep learning hybrid lstm model as a practical utility to predict e p and has further incorporated the neighbourhood component analysis şenkal and kuleli 2009 feature selection method to screen the most potent predictors using satellite and ground based variables the daily input data 31 august 2002 to 22 september 2020 were extracted from giovanni airs satellites including reliable silo data generated by the queensland government the test sites included amberley gatton and oakey and townsville within the drought prone region in queensland australia the integration of lstm with nca led to a deep learning nca lstm hybrid model whose performance was evaluated using statistical score metrics and compared with the other benchmark models namely the lstm dnn rf ann and dt based approaches the nca lstm hybrid model yielded improved performance in predicting daily e p relative to the other benchmark models and this was especially evident for the amberley gatton and oakey study sites however the performance of the proposed objective model as seen by the statistical metrics for the townsville study site was lower compared to the other study sites for example the results showed wi 0 95 n s 0 83 and lm 0 63 for the case of amberley gatton and oakey study sites whereas wi 0 8946 n s 0 6352 and lm 0 4426 for the townsville study site despite this discrepancy in the model performance that has a site specific signature the proposed nca lstm hybrid model still performed remarkably better than the other benchmark models for this study site this reaffirmed that the nca lstm hybrid model can be used efficaciously in predicting daily e p data series the efficiency of the proposed deep learning model can be improved by signal decomposition techniques such as but not limited to the ensemble empirical mode decomposition eemd complete ensemble empirical mode decomposition with adaptive noise ceemdan and etc signal decomposition process can divide the original data sequences into several intrinsic mode functions that will reveal the features within the input variables examples of their use are evident for example chen et al 2021 designed a short term wind speed lstm predicting framework based on eemd and genetic algorithm feature selection method and its accuracy was higher than the benchmark models so future researchers can blend proposed hybrid nca lstm model in this study with appropriate signal decomposition technique and it will be promising predictive tool in field of hydrology credit authorship contribution statement w j m lakmini prarthana jayasinghe writing original draft conceptualization methodology software writing review editing investigation ravinesh c deo conceptualization writing review editing supervision afshin ghahramani conceptualization writing review editing sujan ghimire conceptualization writing review editing investigation supervision nawin raj writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the data were acquired from nasa s goddard online interactive visualization and analysis infrastructure giovanni atmospheric infrared sounder airs spectrometer satellite and queensland government s scientific information for landowners silo database which are duly acknowledged the authors are also grateful to university of southern queensland usq for awarding the international phd tuition fee scholarship 2020 2023 australia and wayamba university of sri lanka for study leave funding over 2020 2023 to conduct this research we thank all reviewers associate editor and the editor in chief for their critical insights to improve this paper appendix theoretical overview of nca feature selection algorithm in nca feature selection process the best feature weights w is recognized corresponding to the feature vector x i by minimizing regression loss using training data malan and sharma 2019 yang et al 2012a a reference sample point x j is selected from the sample x i from all samples then the probability p ij of x j is chosen as a reference for x i from all samples it depends on the weighted distance d w x i x j 11 d w x i x j m 1 r w m 2 x im x jm where w m is the weight of the m th feature the probability p ij can be defined by using d w and kernel function k 12 p ij k d w x i x j j 1 j i n k d w x i x j where kernel function k is k z e x p z σ parameter σ is the kernel width which involves the probability that a sample x j will be selected as a reference point now the probability of x i p i 13 p i j 1 j i n p ij y ij where y ij is one only if y i y j the objective function a can be obtained by the summation of p i over all the trials divided by the total number of trials because this objective function is prone to overfitting a term regularization parameter λ is introduced to a in the nca model yang et al 2012b 14 a i 1 n p i λ m 1 r w m 2 this objective function a is known as the regularized nca that can be solved using the conjugate gradient approach and if it is limited to being a diagonal matrix then its diagonal values provide the weight of each feature malan and sharma 2019 finally based on weight outcomes the best features are selected theoretical overview of the lstm network the architecture of the lstm network is illustrated in fig 8 and it is described in 4 steps zhang et al 2018 the first step in lstm is to decide which information should be forgotten or remembered based on the last hidden layer output h t 1 and the new input x t by using forget gate f t 15 f t σ w f h t 1 x t b f where w f is the weight matrices b f is the bias vector and σ is the logistic sigmoid function the second step is to decide what information needs to be stored in the new cell state c t that is represented by new candidate cell state c t after updating information by using input gate i t 16 c t t a n h w c h t 1 x t b c 17 i t σ w i h t 1 x t b i where tanh is the hyperbolic tangent function the third step is to update the old cell state c t 1 to c t by the forget gate f t to remove unnecessary information and the input gate i t to get a new candidate cell state c t 18 c t f t c t 1 i t c t the final step is to decide the output h t of the predictive model the output process is divided into two steps the new gate called output gate o t is built to determine what parts of the cell state are to be outputted the cell state c t is activated by the tanh function and then multiplied by the output gate o t to get the desired output h t 19 o t σ w o h t 1 x t b o 20 h t o t t a n h c t 
3581,evaporation as a core process within the global hydrological cycle requires reliable methods to monitor its variation for decision making in agriculture irrigation systems and dam operations also in other areas of hydrology and water resource management accurate monitoring of pan evaporation e p is one the most popular approaches to understand the evaporative process this work aims to construct a hybrid long short term memory lstm predictive model that is coupled with neighbourhood component analysis for feature selection to predict e p in drought prone regions in queensland australia amberley gatton oakey townsville utilizing the daily scale dataset 31 august 2002 to 22 september 2020 the performance of the proposed deep learning dl hybrid model denoted as nca lstm is compared with competitive benchmark models i e standalone lstm other types of dl single hidden layer neuronal architecture and decision tree based method the testing results reveal the lowest relative root mean square error 20 absolute percentage bias 14 5 and the highest kling gupta efficiency 87 attained by the nca lstm hybrid model relative to benchmark models tested for amberley gatton and oakey sites in respect to the predictive efficiency the proposed nca lstm hybrid model improved with feature selection outperforms all benchmark models indicating its future utility in the prediction of daily ep in practical sense the predictive model developed for ep estimation provides an accurate estimation of evaporative water loss in hydrological cycle and therefore can be implemented in areas of irrigation management planning of irrigation based agriculture and mitigation of financial losses to agricultural and related sectors where regular monitoring and forecasting of water resources are a vital part of sustainable livelihood and business keywords prediction of pan evaporation long short term memory networks neighbourhood component analysis deep learning hybrid models evaporative water loss 1 introduction evaporation is a key element in the hydrological cycle where water in the liquid phase from the earth s surface transforms into atmospheric water vapour usqs 2021 it is a major cause of water loss in both arid and semi arid regions koohafkan and stewart 2008 precise measurement and calculation of water loss due to evaporation is extremely useful in efficient water resource management abtew and melesse 2012 the more popular approaches for measuring and calculating evaporation relate to the data from evaporation pan method water balance and energy balance methods including the penman equations that aim to integrate both mass and energy balance methods ghorbani et al 2017 the most popular method is the evaporation pan method as it is relatively simpler and less expensive keshtegar et al 2016 kahler and brutsaert 2006 showed that the evaporation pan method gives an accurate value of the actual changes in evaporation hence the present study aims to predict pan evaporation ep as a close approximation of the actual evaporation the methods related to empirical evaporation equation water budget and energy budget based on meteorological datasets have been utilized for e p prediction dewes et al 2017 antonopoulos and antonopoulos 2017 however the predictive errors in these methods can be relatively large due to the complex nonlinear behaviour of the evaporative process which is not captured adequately by the linear modelling approach singh and xu 1997 kişi 2006 further empirical models need recalibration of model coefficients before implementing in different agroclimatic zones as they are not performing similarly in distinct situations to minimize these constraints many researchers are now locating their efforts in data driven machine learning techniques to predict evaporative losses these works use various climatic parameters as predictor variables abghari et al 2012 ghaemi et al 2019 ghorbani et al 2017 guven and kisi 2013 malik and kumar 2015 shirsath and singh 2010 wu et al 2020 the study of keskin and terzi 2006 used an artificial neural network ann model to predict e p in a lake in turkey and showing that the performance of ann was superior to the penman approach research conducted by deo et al 2016 revealed that relevance vector machine rvm outperformed in estimating monthly evaporative losses using meteorological parameters as predictor variables over the extreme learning machine elm and multivariate adaptive regression spline mars wang et al 2017 in another study to estimate daily e p using fuzzy genetic fg least square support vector regression lssvr mars m5 model tree m5tree and multiple linear regression mlr for eight stations around dongting lake basin in china has shown that fg and lssvr outperform over other machine learning techniques malik et al 2017 in their study to estimate monthly e p in the indian central himalayas region has utilized multi layer perceptron neural network mlpnn co active neuro fuzzy inference system canfis radial basis neural network rbnn and self organizing map neural network somnn while using gamma test for the selection of appropriate input combination has revealed superiority of canfis over other techniques the potentials of decision tree based machine learning methods such as chi square automatic interaction detector chaid and classification and regression tree cart for daily e p estimation in turkey were examined in research carried out by kisi et al 2016 and compared that with the neural network model this study revealed that neural networks performed better compared to the decision tree based machine learning models goyal et al 2014 have tested ann lssvr fuzzy logic fl and anfis techniques in estimating daily e p and the results are evaluated against empirical methods proposed by hargreaves and samani hgs and the stephens stewart ss findings of this study has shown that fl and lssvr techniques are superior to the traditional approaches in daily evaporation estimations deep learning dl methodologies consist of advanced multi layered neural networks provide a new gateway for e p predictions as they are now becoming popular categories of artificial intelligence approaches used in both scientific and industrial research due to their improved accuracy emmert streib et al 2020 the utilization of dl is appealing for time series prediction given its success in many fields literature proves that among dl methodologies long short term memory lstm network is widely used in prediction of hydro meteorological and other variables due to its remarkable performances for example ghimire et al 2019c developed a solar radiation forecast model using lstm network coupled with convolutional neural network cnn and it has shown superior performances compared to the benchmark models cnn lstm gated recurrent unit gru recurrent neural network rnn deep neural network dnn multi layer perceptron mlp and decision tree dt the study carried out by zhang et al 2018 to forecast daily land surface temperature using deep hybrid lstm network coupled with ensemble empirical mode decomposition eemd shown that this target eemd lstm model outperformed over recurrent neural network rnn lstm rnn coupled with empirical mode decomposition emd lstm coupled with emd and rnn coupled with eemd poornima and pushpalatha 2019 built up a lstm model for drought predictions based on standardized precipitation index spi and standardized precipitation and evapotranspiration index spei for 1 6 and 12 month time scale and compared its performances with arima statistical model for all given time scales in this study target lstm model was shown better performance than all other comparison models further ferreira and da cunha 2020 have developed multi step cnn lstm model to forecast daily reference evapotranspiration for 53 weather stations located in minas gerais brazil this model has exhibited better performance than traditional machine learning ann and rf models however studies on employing lstm network to predict ep is lack in literature the study carried out by majhi et al 2020 to predict evaporative loss is a recent example for employing lstm for ep prediction this study appears to be the only one study employing the lstm model for evaporative loss prediction in this study the lstm model was compared with multilayer artificial neural networks and empirical methods like hargreaves and blaney criddle showing its superior capability to predict daily evaporative losses against selected benchmark models however literature is not providing any evidence of employing more advanced hybrid lstm for evaporative loss predictions therefore the present study aims to construct hybrid ep forecasting model utilizing lstm network coupled with neighbourhood component analysis nca feature selection technique we have not come across any work applying nca algorithm integrated with deep learning to predict daily ep or using the deep learning nca lstm hybrid model for any other purposes feature selection is a primary step in advanced data driven models which reduces the high dimensional or redundant inputs to a set of low dimensional or selects most relevant datasets prior to constructing a predictive model nca is a good feature selection technique use for selecting features to maximize prediction accuracy of regression and classification algorithms mathworks 2021 wei yang 2012 showed experimentally that the nca is highly sensitive to such irrelevant features and therefore can perform well in reducing high dimensional data to determine the most relevant input features in this respect the nca method has been used extensively in many disciplines to identify the most relevant features and eliminate the irrelevant variables to improve the performance of a model jin and deng 2018 explored a new ensemble decision tree classifier to predict different stages of alzheimer s disease showing that the nca based model was more effective than its standalone counterparts ghimire et al 2019a compared global solar radiation forecasting accuracy with an ann model that has the nca feature selection method with standalone models support vector regression gaussian process machine learning and genetic programming evidently the ann model integrated with nca appeared to be an elite tool considering its merits and significant capabilities that are likely to increase the overall forecasting skill of a predictive model nca is selected as the feature selection technique in this study this study is a novel experience in data science field as it is found to be the first time that lstm is being hybridized with nca and employed in daily ep predictions using satellite and ground based data 2 study case and data materials 2 1 study region hence it is not practically possible to consider the entire globe the present study is centred in queensland australia where 84 of its land resources are used for agricultural purposes doawe 2020 the queensland government declared 67 4 of the land area drought affected in the year 2020 queensland 2020 according to craig et al 2005 annual water loss due to evaporation and the underlying water storage in irrigated agricultural areas particularly in the present study area can be up to 40 of total storage volumes therefore developing an accurate estimation model to predict the water deficits is a strategic approach to devise hydrology and water resource management frameworks in this drought prone region in this study four sites located within the arid and semi arid areas in queensland were selected amberley 152 71 e 27 63 s gatton 152 34 e 27 54 s oakey 151 74 e 27 40 s and townsville 146 77 e 19 25 s see fig 1 the land resources in these selected study sites are mainly utilized for farm operations particularly in producing a wide range of agricultural products therefore this study aiming to build deep learning models for the prediction of evaporation is of great significance particularly in management of water resources for sustainable agriculture 2 2 data daily climatic data for 22 predictive and target variables for 31 august 2002 to 22 september 2020 period were extracted for all the study sites from the databases of nasa s goddard online interactive visualization and analysis infrastructure giovanni atmospheric infrared sounder airs spectrometer satellite and the ground based scientific information for landowners silo the giovanni provides easy and user friendly access to visualize and analyse the vast amount of earth science related remote sensing data teng et al 2014 that inform the pattern in hydrological changes and the evaporative loss in addition the giovanni data can be extracted easily without prior knowledge of downloading the more complex remote sensing datasets and can be sourced from several platforms instruments namely the atmospheric infrared sounder airs the tropical rainfall measuring mission trmm ozone measuring instrument omi the moderate resolution imaging spectroradiometer modis the modern era retrospective analysis for research and applications merra project and both the north american land data assimilation system nldas and the global land data assimilation system gldas with various spatial and temporal resolutions in this study we have selected the airs platform with 1 x 1 spatial resolution within the giovanni archives used to extract the most correlated atmospheric and hydrological variables in relation to e p in addition the ground based data for predictor variables were extracted from silo source for the same period to further improve the model s performance this database is operationally managed by the queensland government morshed et al 2013 class a pan evaporation data for the target variable e p were extracted from silo data base table 1a shows a summary of data sources and predictor variables with their respective acronyms used in this research paper 3 methodology 3 1 time sequential predictive algorithm long short term memory lstm network the lstm is a special recurrent neural network rnn cho et al 2014 related to conventional artificial neural networks that is mainly used to identify patterns in sequences of data such as text video speech language genomes and time series variables manaswi 2018 the rnn model has been associated with the problem of vanishing or exploding gradients with long data sequences swamynathan 2019 this has led to an unnecessary increase in training time and is one of the main reasons that rnn is not used for deep sequence contexts manaswi 2018 due to these limitations rnn has been further modified to build lstm as noted in the work of hochreiter and schmidhuber 1997 lstm networks are able to capture higher order nonlinear features in predictor datasets majhi et al 2020 lstm also can explore the inherent features within time series predictors and target considering the persistent patterns over historical periods of time to generate improved performances moreover the lstms operate with special units denoted as memory blocks that consist of input output and forget gates and these memory blocks continuously update and control the information flow chen et al 2018 these gates also receive input data from the previous time step t 1 and the new time step t and help to eliminate the vanishing gradient issues working efficiently with large time series datasets such as those in the present study considering all merits past records of outstanding performances and its high suitability in analysing nonlinear time series data lstm network with general input hidden output layers framework is selected as the forecasting algorithm in the hybrid ep prediction model proposed in the current study a brief explanation on theoretical overview of lstm architecture is given in the appendix 3 2 feature extraction algorithm neighbourhood component analysis this study uses neighbourhood component analysis şenkal and kuleli 2009 which is a non parametric feature selection method that can increase the predictive accuracy mathworks 2020 in this study data of high dimensional predictor variables from satellite sources i e the atmospheric infrared sounder airs and ground based sources silo which are non linearly related to ground based evaporation data is used for proposed model training nca has shown success in previous works in nominating corelated predictor variables to the target variable to be considered for model training this helps in dimensionality reduction of data and consequently leads to increase the prediction accuracy of models further it is not being used for ep prediction works before considering above facts it is selected as the feature selection algorithm in the current study the list of the selected predictor variables by nca feature selection process is shown in table 1b further fig 2 is showing the correlation metrics of extracted predictor variables by the nca algorithm and target variable e p for all study sites the meanings of all acronyms used in table 1b and fig 2 are as per table 1a according to fig 2 radiation and maximum temperature are the most highly correlated predictive variables with e p for all sites theoretical overview of nca algorithm is briefly described in appendix 3 3 deep learning hybrid model long short term memory network integrated with neighbourhood component analysis nca lstm many research works have evidently shown that dl hybrid models are very successful than other standalone machine learning models in terms of prediction accuracy however literature is not providing any evidence of employing hybrid dl model for evaporative loss predictions and also current study uses relatively big volume of high dimensional data from two distinctive data sources thus data processing prior to the model training can favourably influence the final outcome of prediction model above facts directed the current study to develop hybrid dl model by combining nca feature selection algorithm and lstm neural network for ep prediction in this hybrid nca is employed to extract the most correlated predictor variables related to the target variable e p and the lstm network is employed to build a precise ep forecasting model using data of those corelated input variables fig 3 illustrates the topological structure of nca lstm hybrid model proposed in this study before applying nca input data was normalized as they are in different scale data of different scales will produce weights in different scales in the nca feature selection process and therefore not meaningful as nca feature selection is a dimensional reduction process z score standardization is used in this normalization step mathworks 2020 after normalizing daily interval data set were sent through the nca algorithm embedded in machine learning toolbox function fsrnca on matlab platform data of selected predictor variables by nca feature selection is used for ep prediction model development and training in the next step data of selected predictor variables by above feature selection process were normalized between 0 1 to remove the variance before starting the model development and training garcía et al 2016 as this is a regression and prediction process max min scaling approach is used in this step and the equation is given below 1 x n x actual x min x max x min where xn x actual x max and x min represent the normalized actual maximum and minimum values of predictor variable data respectively the normalized data for all predictor variables and target variable were then partitioned into the training and testing sets as there is no rule of thumb for data division 80 of data is allocated for the training data set while 20 of data is allocated for the testing data set and 10 of the training data set is used for the model validation process in this study to construct the best architectures of the target hybrid model nca lstm and comparative standalone models lstm dnn rf ann and dt hyperparameter optimization is employed using the hyperopt algorithm in python model architectures were designed based on optimal hyperparameters given by hyperparameter optimization process table 2 shows the list of hyperparameters and trainable number of model parameters for nca lstm and the comparative standalone predictive models with optimal parameters for all models boldfaced in blue for gatton site following the results shown in table 2 optimum architecture for nca lstm is designed embedding six lstm layers consisting of 150 50 100 50 50 and 10 neurons prior to the output layer dropout layers were added after each lstm layer with 0 3 dropout ratio the batch size selected was 10 while activation function weight initializer and recurrent activation function selected were relu he uniform and sigmoid respectively after designing model architectures model training process was carried out followed by model validation process using training data set in the next step prediction skills of models were tested using unseen testing data set and predicted values of ep in this step were denormalized for the visualization purpose and compared with observed ep note that high computational cost due to the longer time taken for the training process is a significant issue experienced in the development of a machine learning model ghimire et al 2019c one of the main factors which lengthens the time for the training process is the algorithm used for hyperparameter optimization yu et al 2019 the performance of the hyperopt algorithm in the hyperparameter optimization process is better than the grid search and random search algorithms as it ensures comparatively less time in the model training process while increasing the accuracy of the model putatunda and rama 2018 the time taken for the hyperopt algorithm optimization process is about 1 5 h in this study however this optimization process helps to bring the model training and testing time down to less than 20 min overfitting is also another common issue that can be experienced in the process of dl model training this occurs when the model identifies specific patterns of training data and thereby achieves good fit with those training data overfitted models are failing to generalize on new unseen data as the specific patterns recognized by them in training data sets cannot be seen in new data sets zech et al 2018 there are several ways that can be used to reduce overfitting problem in dl model training process the best option is to get more training data however it was not practicable in current study due to time and data availability constraints so that in this study early stopping es which is one of the hyperparameters in keras dl library chollet 2015 zeng 2019 is used as a major strategy to avoid the overfitting problem it does this by stopping the training process when validation loss stops thus decreasing in the specified epochs further dropout layers are added after each deep learning neural layers to reduce the overfitting problem ferreira and da cunha 2020 in addition hyperparameter optimization step done here which tunes different architectures via hyperopt until a suitable number of nodes layers epochs activation function weight initializer dropout ratio and or batch size is found is also assisting to reduce the overfitting problem the proposed hybrid model i e nca lstm and all other comparative standalone models i e deep learning and conventional models are developed using an intel core i7 3 3 ghz and 16 gb memory computer built using freely available dl libraries keras ketkar 2017 and tensorflow abadi et al 2016 in python sanner 1999 3 4 benchmark models used for performances evaluation of the proposed nca lstm hybrid model in this study other than the standalone lstm artificial neural network ann deep neural network dnn decision tree dt and random forest rf are selected as benchmark models for performance comparison with proposed hybrid nca lstm model all these benchmark models are having diverse architectures and belonging to different generations in the machine learning family ann is a widely used algorithm and has shown high performances in previous research studies for example shirsath and singh 2010 developed ann and multiple linear regression mlr models along with penman priestley taylor and stephens and stewart models to estimate ep and that were compared statistically with observed ep comparison showed that ann model performs better than other models another study caried out by bruton et al 2000 revealed that ep estimated with ann models was more accurate than multiple linear regression model and the priestley taylor equation ann is a single neural layer machine learning model and its theoretical overview is discussed in previous studies carried out by deo et al 2018 deo and şahin 2017 dnn algorithm a further advancement of ann and having multiple neural layer network architecture and belongs to the dl subset in machine learning family is also increasingly deployed in real world applications for example yi et al 2017 developed dnn model to analyse and estimate traffic conditions using big data of real time transportation and it has shown 99 estimation accuracy however literature does not provide any evidence for use of dnn in ep prediction studies the theoretical background and mathematical formulae of dnn algorithm is described in a previous study carried out by ghimire et al 2019b rf is a tree based regression algorithm consisting of many decision trees theoretical background is described in detail in previous literature chen et al 2019 lin et al 2017 rf also has been widely employed in many research works for instance althoff et al 2020 employed rf along with penman equation cubist regression cb bayesian regularized neural network brnn and svm models to estimate small reservoir evaporation in brazilian savanna and in this study rf shown the best performance a pan evaporation prediction model was developed by singh et al 2021 using rf model along with feature selection for karnal district india and performances were compared with ann back propagation algorithm proposed rf model has shown best performances in this study instead of high performance of rf model it generally requires less adjustment in hyperparameters ferreira and da cunha 2020 dt is an extensively used early stage tree based machine learning regression algorithm and the theoretical concepts are described in detail by song and ying 2015 for instance tso and yau 2007 employed traditional regression analysis methods dt and neural network models to predict electricity energy consumption in this study dt and neural network models has exhibited the best performances showing their usefulness in understanding and predicting energy consumption patterns dt has also been widely used as a classification method for example hamsa et al 2016 developed a student s academic performance prediction model for the bachelor and master degree students in computer science and electronics and communication streams using dt and fuzzy genetic algorithms results has shown that dt model can be used to identify student s performance for each subject successfully than the fuzzy genetic algorithms the main reason to select above benchmark models is to increase the validity and the precision of the performance evaluation testing thus they were selected based on their architectural diversity and high performances they have shown in previous research works the performances of the target hybrid model can be evaluated in broader sense as these benchmark models are architecturally distinctive to each other and representing machine learning model categories in wide range in this study empirical methods are not used as the benchmark models as it is more suitable to select advanced machine learning benchmark models which have shown superiority over those empirical methods in previous research works furthermore use of such lower performing empirical methods instead of better alternative machine learning options may show big performance gap consequently leading to over estimate the proposed hybrid model 3 5 model performance evaluation model performances evaluation in terms of prediction accuracy and errors is essential part of machine learning model development such evaluation supports in determining the appropriateness of a model for specific applications facilitates comparative assessment against rival models and modelling techniques and detects aspects of a model most in need of improvement pearce and ferrier 2000 thus following statistical score metrics are used to evaluate the performance of the nca lstm hybrid model against benchmark models pearson s correlation coefficient r the value of r eq 2 describes the degree of collinearity between forecasted e p for and observed e p obs values moriasi et al 2007 in general the r value always lies between 1 to 1 including 1 and 1 the r value is equal to 1 when correlation between two variables e g forecasted and observed e p is strongly and positively correlated it becomes equal to 1 when the correlation between two variables is perfectly strong and negative if no correlation exists between two variables the r value will be equal to 0 however in this case the values forecasted by the forecasting models should be strongly and positively correlated with observed values therefore r value should be either equal to 1 or very close to 1 van vuren 2020 2 r i 1 n e p obs i e p obs e p for i e p for i 1 n e p obs i e p obs 2 i 1 n e p for i e p for 2 1 r 1 root mean square error r m s e m m d a y 1 the rmse eq 3 is commonly used for the performance evaluation of regression models the rmse measures the average model performance error between predicted value e p for and observed value e p obs willmott and matsuura 2005 the rmse value can range from 0 to whereas the value of rmse becomes zero for the best predictive models 3 rmse 1 n i 1 n e p for i e p obs i 2 0 r m s e mean absolute error m a e m m d a y 1 this error value eq 4 provides an assessment of the actual forecasting errors concerning the total number of observations prasad et al 2019 mae can range from 0 to whereas the value of mae becomes zero for best predictive models the mae gives a more robust measure of average model error than the rmse since it is not influenced by extreme outliers legates and mccabe 1999 4 mae 1 n i 1 n e p for i e p obs i 0 m a e willmott s index w i the wi eq 5 is more rationally related to model accuracy than other existing indices and quite flexible making it applicable to a wide range of model performance problems willmott et al 2012 the value for wi ranges from 0 to 1 whereas this value equals 1 for best predictive models 5 wi 1 i 1 n e p obs i e p for i 2 i 1 n e p for i e p for e p obs i e p obs 2 0 w i 1 nash sutcliffe index n s the ns eq 6 nash and sutcliffe 1970 reflects how well the plotted line between observed data and simulated data fits into 1 1 the ns will be equal to 1 if the model forecasted data is perfectly matched to the observed data the ns 1 indicates that the model predictions are as accurate as of the mean of the observed data while inf ns less than 0 indicates that the observed mean is a better predictor than the model agrimetsoft 2019 6 ns 1 i 1 n e p obs i e p for i 2 i 1 n e p obs i e p obs 2 n s 1 legate and mccabe index lm the lm eq 7 is an advanced assessment metric based on wi and ns values this index can be used to assess the goodness of fit of a hydrologic or hydro climatic model and is more effective than correlation and correlation based measures e g the coefficient of determination r 2 wi and ns legates and mccabe 1999 the value for lm ranges from to 1 whereas this value equals one for best predictive models 7 lm 1 i 1 n e p for i e p obs i i 1 n e p for e p for e p for e p obs 2 l m 1 relative root mean square error rrmse the rrmse eq 8 is used to evaluate and compare the model performances it provides an overall forecasting accuracy of the respective models and always gives positive values prasad et al 2019 if the value for rrmse is less than 10 r r m s e 10 model performance is considered to be outstanding while model performance is considered to be good if it is lying between 10 and 20 10 r r m s e 20 if the value for rrmse error lies between 20 and 30 20 r r m s e 30 model performance is considered as fair if the value for rrmse error is higher than 30 rrmse 30 model performance is considered to be poor ertekin and yaldiz 2000 8 rrmse 1 n i 1 n e p for i e p obs i 2 1 n i 1 n e p obs i 100 0 r r m s e absolute percentage bias a p b the apb eq 9 gives the error of forecasted values as a percentage concerning the observed values the optimal value for apb is zero and lower magnitude values closer to zero reflect good accuracy of the model ghimire et al 2019b 9 apb i 1 n e p obs i e p for i 100 i 1 n e p obs i kling gupta efficiency kge the kge eq 10 measures the goodness of fit of the model it was developed by gupta et al 2009 this metric can be decomposed into the contribution of mean variance and correlation on the model performance kling and gupta 2009 perfect models will give value one for the kge index ghimire et al 2019b 10 kge 1 r 1 2 cv for cv obs 2 e p for e p obs 1 2 where cv coefficient of variation e p obs e p for e p obs and e p for are observed ep forecasted ep average of observed ep and the average of forecasted ep respectively n is the total number of data points of the test dataset 4 results and discussion 4 1 result to establish the robustness of the proposed hybrid nca lstm ep forecasting model this section provides detailed analysis of empirical results derived from this modelling experiment and comparative assessment of model performances in this experiment total of six models including the proposed model i e nca lstm and benchmark models standalone lstm multi hidden layer dnn single hidden layer ann ensemble rf regression and dt were employed in ep prediction task in four sites namely amberley 152 71 e 27 63 s gatton 152 34 e 27 54 s oakey 151 74 e 27 40 s and townsville 146 77 e 19 25 s in queensland australia assessment of all models including the proposed model was done based on the results of performance evaluation metrics r rmse mae rrmse w i ns lm a p b and kge in the testing phase for all study sites the r value is used to assess the performances of all models experimented in the current study in terms of degree of collinearity between forecasted e p for and observed e p obs values the r values given for the nca lstm hybrid model tested at amberley gatton oakey and townsville are found to be 0 9142 0 9208 0 9221 and 0 8080 respectively the values of r produced by all other benchmark models are lower than the r values of the nca lstm hybrid model for all sites see table 3 so that nca lstm model is showing the highest degree of collinearity between forecasted e p for and observed e p obs values furthermore r values generated by the proposed hybrid nca lstm model for amberley gatton and oakey sites are quite close to 1 it should be noted that the pearson s correlation coefficient r value reaches 1 when the model performance is perfect hence it appears that the nca lstm hybrid model shows a better performance than its comparative counterpart models in terms of the r value computed between observed and forecasted e p and also this results further affirms the improvement of dl lstm modal performances via hybridization with nca feature selection technique comparing the different sites the present results show that when the model performance is higher the values of the root mean square error r m s e m m d a y 1 and mean absolute error m a e m m d a y 1 are lower for example the rmse values generated by the nca lstm hybrid model for the amberley gatton oakey and townsville study sites are 0 9129 0 9126 0 9890 and 1 3982 while the mae values are 0 6687 0 6684 0 7033 and 1 0555 respectively importantly the rmse and mae values produced by all other benchmark models are higher than the r m s e a n d m a e values registered by the nca lstm hybrid model for all study sites as evident in table 3 for instance rmse and mae values are 0 9363 and 0 6827 for lstm 1 0233 and 0 7570 for dnn 0 9923 and 0 7169 for ann 1 1494 and 0 8795 for rf and 1 0818 and 0 7963 for dt respectively in amberley site which all values are higher than the rmse 0 9129 and mae 0 6687 values for nca lstm model these evaluation metrics assess the models with respect to prediction errors thus lower values are expected from forecasting models according to the rmse and mae values the nca lstm hybrid model appears to exhibit a better performance relative to all other counterpart models as it has shown lower prediction errors to enable a comparison of the nca lstm hybrid model tested at geographically diverse sites where absolute errors do not make sense the relative root mean square error rrmse is used and this metric appears to be lower for the objective model as another measure of model accuracy the radar plots shown in fig 4 clearly illustrate that the nca lstm hybrid model has the lowest rrmse for all study sites furthermore the rrmse values generated by the nca lstm hybrid model for the amberley gatton and oakey study sites are about 19 381 19 08 and 19 92 respectively and these values are less than the 20 required for a good predictive model the rrmse value generated by this proposed hybrid model for the townsville study site is about 21 23 however this rrmse value scored by the proposed nca lstm hybrid model for townsville is still lower than the values of the other benchmark models since rrmse values are less than 20 for three sites amberley gatton and oakey out of four sites the nca lstm hybrid model can be considered as a well performed model to estimate daily ep in this study we adopt the values for willmott s index wi nash sutcliffe coefficient ns and legates mccabe s index lm to measure the accuracy of the nca lstm hybrid model note that for a perfect model these metrics should register a value of unity it is noted that the values of these performance metrics registered by the nca lstm hybrid model are closer to unity compared with any of the other benchmark models employed in this research study according to the results shown in table 4 the highest wi values belong to the nca lstm hybrid model for all study sites that is we obtained a value of wi 0 9544 0 9534 0 9562 and 0 8948 for amberley gatton oakey and townsville respectively a similar trend is shown by the nca lstm hybrid model if we use the ns values to evaluate its performance against the other benchmark model for example the highest magnitude of ns 0 8460 has been registered for the oakey study site for the nca lstm hybrid model while the lowest value of ns 0 5517 has been registered at the townsville study site for the dt based model although relatively low values of the lm metric for the nca lstm hybrid model are between 0 4400 and 0 6600 for all study sites these values are still higher than the values compared to the other benchmark models since the highest wi ns and lm values are demonstrated for all the study sites by the nca lstm hybrid model we aver that the proposed deep learning model has strong potential to forecast daily e p in terms of the absolute percentage bias apb error calculated in the testing phase fig 5 shows that the nca lstm hybrid model generates a lower percentage value of apb compared to the other benchmark models and this is comparatively closer to zero for all study sites for instance the lowest value of apb 13 88 is produced by the nca lstm hybrid model while the highest value of apb 17 53 is produced by the ann model for the gatton study site furthermore the value of the kling gupta efficiency kge another metric used to test the efficacy of the proposed deep learning model appears to be closer to a value of unity for all study sites relative to all the other benchmark models to highlight this metric for the nca lstm hybrid model for example we note that kge 0 87 for the study sites amberley gatton and oakey while kge 0 80 for the townsville study site importantly these values are higher than those of the comparative models for all the study sites as illustrated in fig 5 overall the present analysis provides compelling evidence that the nca lstm hybrid model has a significant potential to predict daily e p and this performance exceeds that of the comparative models for all the study sites in queensland we further evaluate the efficacy of the newly proposed nca lstm hybrid model by using the spread of the prediction error p e o b s e r v e d v a l u e p r e d i c t e d v a l u e including those of the other benchmark models for all the selected study sites these are depicted as bar plots in fig 6 it is noteworthy that predictive error is lower for the case of the nca lstm hybrid model for all the study sites compared to the other models used in the testing phase fig 7 shows the scatter plots of the observed vs the predicted daily e p for the nca lstm hybrid model and all the benchmark models in the testing phase the coefficient of determination r 2 resulting from these scatter plots can advise a reader how well the variance in modelled e p compares with the variance in observed e p with this value being bounded by 0 and 1 if the model is fitted well and the relative covariance between the forecasted and observed e p resonates well the r 2 is closer to value unity according to fig 7 all of the models appear to register high r 2 values which are closer to unity except for townsville however the nca lstm hybrid model yields the highest r 2 value compared with the other models for all study sites the r 2 values scored by the proposed nca lstm hybrid model for the amberley gatton oakey and townsville study sites are approximately 0 8353 0 8501 0 8502 and 0 6528 all of which exceed the values of 0 8295 0 8478 0 8389 and 0 6324 generated by the lstm model this deduction shows that the nca lstm hybrid model can produce more accurate e p compared to the other benchmark models and shows that the proposed deep learning hybrid model can be considered as a significant forecasting tool to predict e p in queensland according to the results it is noticed that proposed hybrid nca lstm model outperform over all benchmark models including the standalone lstm in all sites reflecting the positive influence of nca feature selection algorithm on increasing the prediction accuracy 4 2 discussion pan evaporation is affected by periodic meteorological parameters such as air temperature humidity radiation and wind speed trends and irregularities of meteorological variables clarify the effect of those variables on pan evaporation singh et al 2021 several researchers have explained the pan evaporation paradox which suggests the relationship of reduction in pan evaporation with increase in air temperature jaswal et al 2008 jhajharia et al 2009 investigated the effect of meteorological parameters such as air temperature relative humidity sunshine duration vapour pressure wet bulb temperature number of rainy days and wind speed on evaporation at agartala using linear and exponential methods and discovered that the wind speed and mean temperature had positive and significant impact on pan evaporation another study carried out by liu and xia 2012 in haihe river basin china has shown that evaporation was most sensitive to net radiation many research works in addition to the above proves that influence of such meteorological parameters on pan evaporation is site specific in our study we have extracted data for 21 meteorological predictor variables listed in table 1a and selected more correlated variables to e p using nca feature selection process see table 1b correlation metrics see fig 2 were used to analyse and visualize the selected predictor variables according to the results of nca feature selection process in our study maximum temperature max temp solar radiation radiation minimum temperature min temp are positively correlated with e p while relative humidity at time of maximum temperature rh tmax relative humidity at time of minimum temperature rh tmin and air temperature at surface daytime atsd mean sea level pressure mslp relative humidity night time rhn and surface temperature sth are negatively correlated with e p among of them maximum temperature and radiation are highly influenced on evaporation loss in our study proposed nca lstm model has shown leading performances in ep prediction in all four sites selected while all the other benchmark models get ranked in different positions in terms of ep prediction performances in different sites consistency shown by the proposed nca lstm model in ep prediction performances by securing its position as the best ep prediction model in all study sites affirms the synergetic effect of hybridizing lstm with nca in this study nca feature selection algorithm has shown its capability in improving the performance of dl predictive model in terms of the limitations of this study it is acknowledged that data were extracted and modelled for only four study sites within queensland as a case study to achieve the objectives while this pioneer study has no doubt produced a new modelling framework for ep prediction albeit within a limited scope future studies can select more sites representing the whole drought affected region in australia or elsewhere while this was useful research and does indicate a scope for future studies the geographic dependence of nca lstm hybrid model accuracy should be considered in any future research nonetheless the deep learning has significant implications in managing irrigations and other water resource systems through monitoring the changes in daily e p the practical implication of this study is that the e p predictive model which can yield a very close estimation of the actual water loss due to evaporation and its relationship to the management of water resources can used as a scientific strategy for irrigation and other agricultural purposes it should be noted that by multiplying the e p values with the surface area of the irrigation water resources the volume of water losses due to evaporation which is a major cause of water loss from the available water resource volume can be calculated therefore the total volume of available water for irrigation purposes can be easily estimated and accordingly a suite of smart irrigation schedules can be planned or implemented these schedules can avoid unnecessary water losses due to more relaxed irrigation practices therefore the present deep learning hybrid model used for predicting e p is expected to yield significant financial benefits to the farmers in arid and semi arid regions where agricultural practices are constrained by water resources drought and other forms of hydrological imbalances also this study provides a significant guideline for hydrologists in analysing non linear and non stationary behaviour in hydrological cycles using soft computing 5 conclusions and recommendation for future work this study has focused on designing a deep learning hybrid lstm model as a practical utility to predict e p and has further incorporated the neighbourhood component analysis şenkal and kuleli 2009 feature selection method to screen the most potent predictors using satellite and ground based variables the daily input data 31 august 2002 to 22 september 2020 were extracted from giovanni airs satellites including reliable silo data generated by the queensland government the test sites included amberley gatton and oakey and townsville within the drought prone region in queensland australia the integration of lstm with nca led to a deep learning nca lstm hybrid model whose performance was evaluated using statistical score metrics and compared with the other benchmark models namely the lstm dnn rf ann and dt based approaches the nca lstm hybrid model yielded improved performance in predicting daily e p relative to the other benchmark models and this was especially evident for the amberley gatton and oakey study sites however the performance of the proposed objective model as seen by the statistical metrics for the townsville study site was lower compared to the other study sites for example the results showed wi 0 95 n s 0 83 and lm 0 63 for the case of amberley gatton and oakey study sites whereas wi 0 8946 n s 0 6352 and lm 0 4426 for the townsville study site despite this discrepancy in the model performance that has a site specific signature the proposed nca lstm hybrid model still performed remarkably better than the other benchmark models for this study site this reaffirmed that the nca lstm hybrid model can be used efficaciously in predicting daily e p data series the efficiency of the proposed deep learning model can be improved by signal decomposition techniques such as but not limited to the ensemble empirical mode decomposition eemd complete ensemble empirical mode decomposition with adaptive noise ceemdan and etc signal decomposition process can divide the original data sequences into several intrinsic mode functions that will reveal the features within the input variables examples of their use are evident for example chen et al 2021 designed a short term wind speed lstm predicting framework based on eemd and genetic algorithm feature selection method and its accuracy was higher than the benchmark models so future researchers can blend proposed hybrid nca lstm model in this study with appropriate signal decomposition technique and it will be promising predictive tool in field of hydrology credit authorship contribution statement w j m lakmini prarthana jayasinghe writing original draft conceptualization methodology software writing review editing investigation ravinesh c deo conceptualization writing review editing supervision afshin ghahramani conceptualization writing review editing sujan ghimire conceptualization writing review editing investigation supervision nawin raj writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the data were acquired from nasa s goddard online interactive visualization and analysis infrastructure giovanni atmospheric infrared sounder airs spectrometer satellite and queensland government s scientific information for landowners silo database which are duly acknowledged the authors are also grateful to university of southern queensland usq for awarding the international phd tuition fee scholarship 2020 2023 australia and wayamba university of sri lanka for study leave funding over 2020 2023 to conduct this research we thank all reviewers associate editor and the editor in chief for their critical insights to improve this paper appendix theoretical overview of nca feature selection algorithm in nca feature selection process the best feature weights w is recognized corresponding to the feature vector x i by minimizing regression loss using training data malan and sharma 2019 yang et al 2012a a reference sample point x j is selected from the sample x i from all samples then the probability p ij of x j is chosen as a reference for x i from all samples it depends on the weighted distance d w x i x j 11 d w x i x j m 1 r w m 2 x im x jm where w m is the weight of the m th feature the probability p ij can be defined by using d w and kernel function k 12 p ij k d w x i x j j 1 j i n k d w x i x j where kernel function k is k z e x p z σ parameter σ is the kernel width which involves the probability that a sample x j will be selected as a reference point now the probability of x i p i 13 p i j 1 j i n p ij y ij where y ij is one only if y i y j the objective function a can be obtained by the summation of p i over all the trials divided by the total number of trials because this objective function is prone to overfitting a term regularization parameter λ is introduced to a in the nca model yang et al 2012b 14 a i 1 n p i λ m 1 r w m 2 this objective function a is known as the regularized nca that can be solved using the conjugate gradient approach and if it is limited to being a diagonal matrix then its diagonal values provide the weight of each feature malan and sharma 2019 finally based on weight outcomes the best features are selected theoretical overview of the lstm network the architecture of the lstm network is illustrated in fig 8 and it is described in 4 steps zhang et al 2018 the first step in lstm is to decide which information should be forgotten or remembered based on the last hidden layer output h t 1 and the new input x t by using forget gate f t 15 f t σ w f h t 1 x t b f where w f is the weight matrices b f is the bias vector and σ is the logistic sigmoid function the second step is to decide what information needs to be stored in the new cell state c t that is represented by new candidate cell state c t after updating information by using input gate i t 16 c t t a n h w c h t 1 x t b c 17 i t σ w i h t 1 x t b i where tanh is the hyperbolic tangent function the third step is to update the old cell state c t 1 to c t by the forget gate f t to remove unnecessary information and the input gate i t to get a new candidate cell state c t 18 c t f t c t 1 i t c t the final step is to decide the output h t of the predictive model the output process is divided into two steps the new gate called output gate o t is built to determine what parts of the cell state are to be outputted the cell state c t is activated by the tanh function and then multiplied by the output gate o t to get the desired output h t 19 o t σ w o h t 1 x t b o 20 h t o t t a n h c t 
3582,generally reliable simulation results are obtained by calibrating and validating the parameters of a hydrological model through a split sample test to obtain adequate and stable calibration and validation results of a hydrological model calibration data with sufficient length should be used therefore a study on the estimation of appropriate calibration data length is required in this study the appropriate calibration data length was estimated for three hydrological models gr4j ihacres and sacramento models with varying complexities using the sobol global sensitivity analysis method as a result of analyzing the appropriate calibration data length in three hydrological models for three dam catchments in korea a relatively stable simulation result could be derived using more than eight years of calibration data length in addition it was confirmed that the appropriate length of the calibration data increased as the size of the catchment decreased in the case of the sacramento model with the largest number of parameters the variability of the optimum parameter values was high even if the calibration period increased therefore the variability size of the optimum parameter values is an improper scale for estimating the appropriate calibration data length when many parameter uncertainties exist however as a result of analyzing the parameter sensitivity of the sacramento model the variability of the parameter sensitivity decreased as the calibration period increased the variability of model performance was also related to the variability of parameter sensitivity rather than to the variability of optimal parameter values therefore parameter sensitivity analysis can be used to estimate the calibration data length for various hydrological models including hydrological models with high uncertainty keywords global sensitivity analysis calibration data length estimation conceptual hydrological model hydrological model uncertainty split sample test 1 introduction a hydrological model is useful when the observed flow data can be simulated properly in general calibrating and validating the parameters of a hydrological model using a split sample test klemeš 1986 provides reliable simulation results to obtain meaningful calibration and validation results for a hydrological model the calibration period should be sufficiently long klemeš 1986 arsenault et al 2018 if it is too short a simulation result may have problems of overfitting or low agreement with the observed data harlin 1991 in addition if an overly short data period is used for model calibration the model performance variability over the course of the calibration and validation may become large and unstable e g kim et al 2011 razavi and tolson 2013 the data used to calibrate the parameters should contain as much hydrological information as possible related to the target catchment therefore several studies have been conducted on data length considering sufficient hydrological information for parameter calibration and validation first some studies have shown that even if hydrological data from a short period e g one or two years are used for parameter calibration appropriate simulation results can be obtained sorooshian et al 1983 studied the appropriate length of the calibration data for the sacramento conceptual hydrological model appropriate parameter values and prediction results can be obtained with a calibration period of only one year they emphasized that data quality was more important than data length harlin 1991 argued that it is appropriate to use a calibration period between two and six years to estimate the optimal parameter values for the hydrologiska byråns vattenbalansavdelning hbv model the optimal calibration period was four years for model performance in some cases the result of the short calibration period of one or two years was equivalent to the result of the 10 year calibration period therefore the hydrological information of the short period was also useful refsgaard and knudsen 1996 determined that a data period of more than one year was suitable for the parameter calibration of three hydrological models with different structures nam watbal and mike she yew gan et al 1997 analyzed the performance of five hydrological models pitman sacramento nam xinanjiang and smar using data from three african and american catchments in their study the structure of the hydrological models calibration objective function and quality of the calibration data were more important than the length of the calibration data perrin et al 2007 calibrated the parameters of two hydrological models gr4j and topmo using randomly extracted data from 39 years and validated the parameters using the entire data period they found that 350 daily data could be used to calibrate the models and estimate appropriate parameter values the above studies argued that optimal parameter values can be properly estimated using high quality short term data therefore it will be most efficient if only the period with high quality data containing a lot of information can be accurately extracted and used for model calibration however in practice it is not easy to investigate select and use high quality data from the entire period therefore for practical use it is necessary to estimate the average length of the calibration data with good quality some studies suggest a longer period for the calibration process yapo et al 1996 estimated the appropriate data length with good calibration results while being relatively insensitive to the selection of a specific period of data they applied the data from the us leaf river catchment 1944 km2 to the sacramento model with 13 parameters and confirmed that the eight year calibration period was appropriate anctil et al 2004 studied the appropriate calibration data length for the gr4j model with four parameters for the serein river catchment 1120 km2 in france they confirmed that stable simulation results were obtained when using a calibration period of five years or more vaze et al 2010 estimated the calibration data length suitable for climate change studies using four conceptual models simhyd sacramento smarg and ihacres with different numbers of parameters 6 14 for 61 catchments of varying sizes 50 2000 km2 in southeast australia consequently a 20 year calibration period was found to be optimal for the different models kim et al 2011 investigated the appropriate calibration data length using the ihacres model with five parameters for five catchments of various sizes 90 506 km2 in australia the model performance and parameter values were stabilized when the eight year period was used motavita et al 2019 explored the influence of the selection of calibration and validation data on the predictive ability of the model using the hbv model and comprehensive differential split sample test for the deggendorf kollbach catchment 36 6 km2 in germany as the calibration period of the data increased the parameter values stabilized however if the calibration period exceeded eight years the predictive ability of the model for the validation period decreased as shown in the previous studies described above the appropriate length of the calibration data varied significantly from study to study the difference in the appropriate calibration data length for each study may be caused by differences in the size of the target catchments hydrogeological characteristics of catchments meteorological characteristics structure of hydrological models and data quality there are no suitable answers of the appropriate calibration data length for various conditions and data quality therefore a method for determining the appropriate calibration period length is needed in particular hydrological models with numerous parameters have high uncertainty shin et al 2013 2015 therefore parameter values may not be stabilized owing to uncertainty for hydrological models with large uncertainties it may be difficult to estimate the appropriate calibration data length depending on the hydrological characteristics of the target catchment hence research on this is necessary the purpose of this study is to estimate the appropriate calibration data length for hydrological models using the sobol method 1993 a global sensitivity analysis method for practical use this study estimates the average length of the calibration data with proper calibration and validation results while being relatively unaffected by the selection of a specific data period as in the study by yapo et al 1996 in particular this study analyzes how the sensitivity analysis method is applicable for estimating the appropriate calibration data length for hydrological models with high uncertainty previous studies have analyzed the variability of optimal model performances and or parameter values to estimate the appropriate calibration data length the difference between this study and the previous ones is that this one estimates the appropriate calibration data length by analyzing the parameter sensitivity index variability in addition this study analyzes the correlation between catchment size and the appropriate calibration data length for hydrological models for this analysis three hydrological models and three catchments in korea with diverse hydrological characteristics over 40 years of observed hydrological data were used 2 materials 2 1 catchments and data the study areas were the soyanggang andong and seomjingang dam catchments in korea fig 1 to obtain stable calibration and validation results for a hydrological model it is necessary to select a catchment with sufficiently long hydrological data which is required to estimate the appropriate calibration data length by testing a hydrological model for various calibration periods these three dam catchments are suitable for this study because they have the longest hydrological data in korea these three catchments are located in different major basins the soyanggang 2703 km2 andong 1584 km2 and seomjingang 763 km2 catchments are located in the han river basin to the north the nakdong river basin to the southeast and the seomjin river basin to the southwest there are no artificial structures in these three catchments and the flow rates in the catchments have natural flows with no synthetic distortions these three catchments have various meteorological conditions and runoff characteristics because they are located in various regions of korea therefore they are representative of the hydrological characteristics of korea the data used for hydrological modeling were daily areal rainfall potential evapotranspiration and observed runoff data for the calibration and validation of the parameters areal rainfall data were generated using the thiessen polygon method observed runoff and areal rainfall data were provided by the water resources management information system http www wamis go kr of korea the period of data used in this study was 41 years from january 1 1978 to december 31 2018 potential evapotranspiration data were generated using the penman monteith method provided by the spei package beguería and vicente serrano 2015 for the generation of potential evapotranspiration data the daily maximum and minimum temperature wind speed and sunshine hours data of the meteorological stations were provided by the korea meteorological administration http www kma go kr 2 2 hydrological models three models with very different complexities gr4j ihacres and sacramento have been used to demonstrate the procedure for estimating the appropriate calibration data length table 1 these conceptual hydrological models have been used in various studies until recently moussu et al 2011 petheram et al 2012 shin et al 2016 heřmanovský et al 2017 guo et al 2018 sezen et al 2019 the gr4j model perrin et al 2003 uses four parameters and simulates daily runoff using two stores production and routing and two unit hydrographs the production store controls the storage of rainfall evapotranspiration and infiltration processes at the surface in the routing store slow and quick flows are simulated using the effective rainfall generated in the production store the slow flow is generated using 90 effective rainfall and the first unit hydrograph the quick flow uses the remaining amount of effective rainfall 10 and the second unit hydrograph finally the total runoff is generated as the sum of slow and quick flows le moine et al 2008 the ranges of the gr4j model parameters follow those of shin et al 2013 the ihacres model was developed in the early 1990 s jakeman et al 1990 jakeman and hornberger 1993 this model has been modified in several versions considering the hydrological characteristics of catchment and application this study uses the catchment moisture deficit cmd version of ihacres model croke and jakeman 2004 that uses a total of six parameters in this study a total of five parameters were used table 1 because the potential evapotranspiration data was used instead of the temperature data which fixes the parameter e as one the ihacres model simulates runoff by considering the changes in soil moisture in the catchment this model calculates the effective rainfall by combining the catchment moisture deficit calculated using the accounting equation and the conversion result of the raw rainfall calculated using the nonlinear function the calculated effective rainfall is converted into quick and slow flows through two unit hydrographs finally the total runoff was calculated by adding the quick and slow flows the sacramento model burnash et al 1973 uses 16 parameters three parameters side rserv and riva were fixed by referring to the study by peck 1976 table 1 therefore 13 parameters were used in this study and the parameter ranges were the same as those used by shin et al 2013 this model simulates a direct runoff for an impervious area surface runoff interflow and two types of base runoff some of the excess rainfall is converted to runoff through a unit hydrograph and the remainder is stored in soil moisture stores some of the water stored in the soil moisture store is lost by evapotranspiration and the rest becomes interflow and groundwater finally this model calculates the total runoff by summing the direct runoff surface runoff and interflow in this study the hydrological model assessment and development hydromad andrews et al 2011 modeling package including these three hydrological models was used hydromad is an r based open source software package that can be downloaded and used for free from http hydromad catchment org 3 method 3 1 parameter calibration the shuffled complex evolution sce duan et al 1992 1993 algorithm was used to calibrate the parameters of the three hydrological models sce is a global optimization algorithm widely used to calibrate hydrological model parameters nicklow et al 2010 and has been used in various studies qi et al 2016 tigkas et al 2016 shin and kim 2017 kan et al 2018 shin and choi 2018 the sce algorithm combines the advantages of the simplex procedure nelder and mead 1965 competitive evolution holland 1975 controlled random search price 1987 and complex shuffling duan et al 1992 in brief this algorithm creates an initial random population in a feasible parameter space and divides this population into complexes the complexes refer to communities with parents who produce offspring each complex then evolves independently using a competitive complex evolution strategy the evolved complexes are gathered and mixed into a population for information exchange finally these optimization processes are repeated until the convergence condition of the previously selected objective function is satisfied the objective function used for parameter calibration is the nash sutcliffe efficiency nse nash and sutcliffe 1970 and is defined as follows 1 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 where q obs i and q sim i are the observed and simulated flow rates at time step i daily here respectively q obs is the average of the observed flow rates and n is the number of time steps the range of nse is to 1 where unity means that the simulated flow rate is the same as the observed flow rate and zero means that the simulated flow rate is the same as the average value of the observed flow rate 3 2 sensitivity analysis the sobol method sobol 1993 a global sensitivity analysis method was used to analyze the sensitivity of the parameters this method has been used in various studies houle et al 2017 jepsen et al 2018 zhang et al 2019 this sensitivity analysis method decomposes the variance in the simulation results finally it estimates the relative effect of each parameter and the interaction between the parameters on the variance of the results this method computes two sensitivity indices the first is the first order sensitivity index fsi which calculates the effect of each parameter on the model s results and the second is the total sensitivity index tsi which has the function of the fsi including the interactions between each parameter and the rest of the parameters on the results of the model saltelli et al 2008 the tsi provides more reliable results than the fsi in investigating the overall effect of each parameter on the model s results saltelli et al 2008 therefore in this study the sensitivity of each parameter was analyzed using tsi the tsi values range from 0 to 1 tsi values closer to 1 indicate that the parameter further affects the results of the model the tsi is defined as follows saltelli annoni 2010 2 tsi e x ĩ v x i y x ĩ v y where x i is the i th parameter and x ĩ is the vector of all parameters except for x i the inner variance of the numerator means that the variance of y the value of the objective function in a scalar form is considered for all possible values of x i while x ĩ is fixed the outer expectation operator is considered for all possible values of x ĩ the variance v y in the denominator is the total unconditioned variance the tsi numerator is the expected variance that would be left if all parameters are fixed except for x i saltelli annoni 2010 an r based sensitivity package pujol et al 2012 was used to apply the sobol method in addition saltelli s scheme saltelli 2002 was used to efficiently calculate tsi with a smaller number of samples by using n k 2 instead of n 2 k 2 here n is the size of the initial sample and 10 000 samples were used in this study moreover k denotes the number of parameters in the hydrological model therefore the total number of samples for sensitivity analysis was 60 000 for the gr4j model with four parameters 70 000 for the ihacres model with five parameters and 150 000 for the sacramento model with 13 parameters the target function of the sensitivity analysis was the modified nse nse mathevet et al 2006 and is defined as follows 3 n se 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 the nse is nse divided by nse with a plus sign and the range of the nse is 1 1 the nse has a range of negative values that is significantly smaller than the range of the nse 1 which has the advantage of reducing the effect of very large negative numbers on the sensitivity analysis without changing the interpretation of the nse value shin et al 2013 3 3 estimation of stable calibration data length first for a 30 year period from 1979 to 2008 the parameters were calibrated by increasing the parameter calibration period from three to 10 years in one year increments e g 3 4 or 10 the total number of calibration periods for each calibration period was created using a one year moving window method then the predictive performance of the model was evaluated by validating each calibrated parameter value for a period of 10 years from 2009 to 2018 for example in the case of a three year parameter calibration period a total of 28 calibration periods were created by shifting the three year period such as from 1979 to 1981 from 1980 to 1982 and finally from 2006 to 2008 by moving one year as shown in fig 2 subsequently the estimated parameter values for each three year calibration period were applied to the 10 year validation period from 2009 to 2018 to simulate the runoff and investigate the distribution of the objective function values for the calibration and validation periods fig 2 the period one year before each calibration period was used as the warm up period e g 1978 is the warm up period of the 1979 1981 calibration period note that there is no certainty on the selection of the calibration period by researchers to obtain appropriate calibration and validation results no matter which calibration period researchers select all possible calibration periods should be considered as the subject of calibration to reflect this purpose all possible calibration periods were selected and each experiment was performed in each experiment as shown in fig 2 the calibration and validation periods are independent without any overlaps based on this independence the calibration and validation process is appropriate in the usage of the split sample test klemeš 1986 when all experiments are considered together overlapped periods between experiments have no substantial interdependence on the results except the size of the ranges of boxplots not shown here for example in the case of the three year calibration period described above the calibration periods of experiment 1 1979 1981 and 2 1980 1982 have a 2 year overlap fig 2 a boxplot using non overlapped calibration periods e g 1979 1981 1982 1984 etc has a smaller range compared to a boxplot using all possible calibration periods due to the smaller number of experiments although the overlap of calibration periods slightly affects the range of the boxplot all possible calibration periods should be used to estimate an appropriate calibration length in this study for the three dam catchments and three hydrological models the stabilized distribution of the objective function values for the calibration and validation periods was determined as the optimal length of the calibration data the total number of models for the three catchments and three hydrological models was 1764 196 calibrations for the three to 10 year calibration period three catchments three hydrological models boxplots and coefficients of variation cvs were used to investigate the distribution of the objective function values for each calibration period the cv is defined as follows 4 cv σ μ where σ and μ denote the standard deviation and the mean of the objective function values for each calibration period respectively in addition the obtained calibration period using the distribution of the objective function values was compared with the period in which the distribution of the calibrated parameter values was stabilized finally for each calibration period the tsi of the parameters was calculated 1764 calculations and the distribution and stabilization period of the parameter sensitivity index were explored when investigating the distribution of optimal parameter values and parameter sensitivity indices a boxplot and normalized standard deviation for each calibration period were used as in shin et al 2015 when the average value of the optimal parameter values or that of the sensitivity indices approaches zero the value of the cv becomes very large and therefore it becomes difficult to properly analyze the variability to solve this problem the normalized standard deviation is used and the equation is as follows 5 nor s t d e v σ δ p where δ p is the range the difference between the maximum and minimum values of each parameter or sensitivity index we examined whether the optimal length of the calibration data based on the distribution of parameter sensitivity indices was different from that of the distribution of objective function values and parameter values in addition we analyzed how the results of the sensitivity analysis of parameters can help in the selection of the optimal calibration data length finally the correlation between the size of the study catchments and the optimal length of the conceptual hydrological model calibration data was analyzed 4 results 4 1 estimation of the calibration data length using the model performance variability fig 3 shows boxplots representing the distribution of the nse values obtained for the calibration periods of the gr4j ihacres and sacramento models for the soyanggang andong and seomjingang catchments in fig 3 the numbers on the horizontal axis from 3 to 10 in the calibration column refer to the length of the data number of years used for parameter calibration moreover the numbers on the horizontal axis from 3 to 10 in the validation column are validation results for each calibration period for example the result of validation 3 was obtained when the estimated parameter value for the three year calibration period was applied to the validation period 2009 2018 for the gr4j model using four parameters the distribution of nse values for the three year calibration data for the seomjingang catchment was very wide and ranged from approximately 0 5 to 0 9 in addition the distribution of the nse values during the validation period also showed a very wide distribution from approximately 0 4 to 0 9 this means that even if the simulated hydrograph for a specific calibration period e g three year has a high degree of agreement with the observed hydrograph with a high nse value the validation period could have a low nse value due to overfitting for the calibration period namely the runoff during the validation period cannot be properly predicted therefore it is necessary to increase the length of the calibration data so that sufficient information necessary for validation is included in the calibration period hence the length of the calibration data should be increased until the distribution of the nse values for both the calibration and validation periods is as narrow as possible as shown in fig 3 the distribution of the nse values for calibration and validation continued to narrow when the calibration period was increased because this study aims to estimate the minimum calibration period length with adequate model performance nse value of 0 6 or more the calibration period was estimated by the cv of the nse value for each calibration period shown in fig 4 with concise expression of nse variances consequently the number of years in the calibration period in which the cv decreased rapidly and then became gently steady was six years in the soyanggang catchment six years in the andong catchment and seven years in the seomjingang catchment fig 4 the nse values for all catchments were greater than 0 6 as shown in fig 3 therefore in the case of the gr4j model an appropriate simulation result can be obtained only when the calibration period is more than six seven years for the ihacres model using five parameters the number of years for the calibration period based on the rapidly decreased and moderated cv was six years for the soyanggang and andong catchments and eight years for the seomjingang catchment fig 4 with eligible nse values greater than0 6 fig 3 moreover the results of the sacramento model with the highest number of parameters showed relatively large variability compared to the gr4j or ihacres models fig 4 the sudden decrease in the cv with moderation for the sacramento model was six years in the soyanggang catchment seven years in the andong catchment and eight years in the seomjingang catchment with sufficiently high nse values therefore the ihacres and sacramento models should use a calibration period of six eight years or longer to obtain appropriate simulation results in particular the distribution of the nse values for calibration and validation decreased as the calibration period was increased in the sacramento model but the variability was relatively greater than that of the other two models namely as the length of the calibration data increased there was a period in which the cv of the nse value repeatedly decreased and increased especially in the case of validation fig 4 the instability of the distribution of the nse values over this validation period may be related to the uncertainty of the parameters of the sacramento model shin et al 2015 therefore in section 4 2 the variability of the optimal parameter values of the hydrological models according to the increase in the calibration period is analyzed 4 2 estimation of the calibration data length using the distribution of optimal parameter values figs a1 a5 in appendix a show the distribution of optimal parameter values for each calibration period of the gr4j ihacres and sacramento models for the three catchments fig 5 shows the variability of the optimal parameter values for each calibration period for the gr4j and ihacres models the distributions of optimal parameter values narrowed as the length of the calibration data increased figs a1 and a2 in appendix a the variabilities of the optimal parameter values by calibration period for the gr4j model were stabilized at six year in the soyanggang catchment six year in the andong catchment and approximately seven year in the seomjingang catchment fig 5 for the ihacres model the variability of the parameter values stabilized for six year in the soyanggang catchment six year in the andong catchment and approximately eight year in the seomjingang catchment fig 5 therefore the periods of calibration data when the variabilities of the optimal parameter values of these two models stabilized supports the results of section 4 1 this means that the distributions of the optimal parameter values for the two hydrological models with relatively few parameters affect the distributions of the nse values representing model performance however the distributions of the optimal parameter values of the sacramento model did not narrow down in most cases even when the calibration periods were increased for all three catchments these distributions repeatedly decreased and expanded figs a3 a5 in appendix a therefore it is difficult to estimate the appropriate length of the calibration data using the distributions of the optimal parameter values because of the instability of the distributions with larger variability fig 5 in addition these unstable distributions of optimal parameter values may cause variations in the distributions of the nse values in the validation period analyzed in section 4 1 the sacramento model uses a relatively large number of parameters compared to the gr4j and ihacres models the parameters have large uncertainties owing to the interaction between many parameters shin et al 2013 2015 shin and kim 2019 therefore the uncertainties caused by the interactions between these parameters can result in a relatively unstable distribution of the optimal parameter values for each calibration period therefore as an alternative method for estimating the appropriate calibration period of the sacramento model the sensitivity analysis of the parameters was used as shown in section 4 3 4 3 estimation of the calibration data length using the parameter sensitivity distribution figs a6 a10 in appendix a show the distribution of the tsi of the parameters for each calibration period of the gr4j ihacres and sacramento models in fig 6 the tsi variability for each calibration period is shown as expected the tsi distribution for the gr4j and ihacres models narrowed as the calibration period increased figs a6 and a7 in appendix a for the sacramento model surprisingly the tsi distributions of the parameters also narrowed down as the calibration period increased unlike the distributions of the optimal parameter values figs a8 a10 in appendix a the tsi variabilities for the gr4j model rapidly decreased and then stabilized at six year in the soyanggang catchment six year in the andong catchment and seven year in the seomjingang catchment fig 6 the ihacres model has similar stabilizing points of the tsi variabilities at six year in the soyanggang catchment six year in the andong catchment and eight year in the seomjingang catchment fig 6 therefore the gr4j and ihacres models using relatively few parameters have adequate calibration data length similar to those shown in the variabilities of the nse values and the variabilities of the optimal parameter values according to the tsi variability analysis for the sacramento model the variabilities of the tsi values stabilized at six year in the soyanggang catchment seven year in the andong catchment and eight year in the seomjingang catchment fig 6 these numbers of years are the same as those corresponding to the stabilized cv of the nse values as shown in section 4 1 therefore the distributions of the sensitivity index of the sacramento model parameters for the calibration period were distinctively related to the distributions of model performance the parameter sensitivities indicate the degree of influence of the parameters on the model simulation results therefore for a model with large parameter uncertainties such as the sacramento model the distributions of parameter sensitivities are better indicators of model performance characteristics during the calibration period than the distributions of optimal parameter values 5 discussion regarding catchment size used in this study all hydrological models with decreased catchment sizes had a greater appropriate calibration data length this is because smaller catchments have shorter concentration times in addition runoff at the catchment outlet is greatly affected by the amount of rainfall the hydrographs at the smaller catchment outlets react more sensitively to rainfall which shows greater variability of the hydrographs for smaller catchments this can be confirmed from the fact that the cvs increased from the larger catchment i e soyanggang to the smaller catchment i e seomjingang in fig 4 for smaller catchments more rainfall and runoff information should be included in the calibration period to adequately simulate the variability of the hydrograph during the calibration and validation periods therefore smaller catchments require longer calibration data lengths for all three hydrological models as the length of the calibration data increased the variability of the nse and tsi values decreased therefore the longer the calibration data length used the more stable the calibration and validation results however not all catchments always have long hydrological data so it is necessary to present the appropriate minimum length of calibration data for this study in the case of the catchments covered in this study six to eight years of data were required for parameter calibration to obtain stable results therefore to be applied to three catchments and three hydrological models in common hydrological data of more than eight years were required for parameter calibration this result is the same as the length of the eight year calibration data presented in the studies of yapo et al 1996 and kim et al 2011 however this study is different from the previous two studies because the sensitivity index of the parameter was used to estimate the appropriate calibration data length most previous studies have estimated the appropriate length of calibration data using the variabilities of the model performance and or the optimal parameter values e g harlin 1991 yapo et al 1996 anctil et al 2004 vaze et al 2010 kim et al 2011 arsenault et al 2018 motavita et al 2019 however as shown in the results of this study the method considering the variabilities of optimal parameter values does not apply to all hydrological models namely the distributions of the optimum parameter values of the sacramento model shown in section 4 2 showed great variability even when the length of the calibration data increased thus the previous method could not be used to estimate the appropriate calibration data length for this model the large variability of the sacramento model parameters was also confirmed by yapo et al 1996 vrugt et al 2006 also analyzed the effects of calibration data length on model performance and parameter uncertainties of the sacramento model for the leaf river watershed in the united states the model performance improved as the length of the calibration data increased but the parameter uncertainties were not reduced in addition the strong interaction between parameters with lower identifiability for each parameter may induce uncertainties in the sacramento model shin et al 2013 2015 shin and kim 2019 in the case of physically based distributed hydrological models with relatively many parameters e g soil and water assessment tool arnold et al 1998 there may be more parameter uncertainties e g abbaspour et al 2015 therefore for a hydrological model using many parameters the appropriate calibration data length can be estimated by using the normalized standard deviation of the parameter sensitivity tsi based on the sobol method as described in section 4 3 the sensitivity analysis method based on the sobol method can help in the selection of an appropriate calibration period not only for the sacramento model with many parameters but also for the remaining hydrological models with few parameters for example in fig 5 showing the normalized standard deviation of optimal parameter values the appropriate calibration period for the x2 and x4 parameters of the gr4j model for the soyanggang catchment is relatively unclear the appropriate calibration period for these parameters was clearly shown in fig 6 which shows the normalized standard deviation of the parameter sensitivity tsi as six years therefore the sensitivity analysis method provides a lot of information to select an appropriate calibration period for a hydrological model 6 conclusions in this study the appropriate calibration data length of the hydrological model was estimated using the sobol global sensitivity analysis method as a result of analyzing the appropriate calibration data length for three conceptual hydrological models with different complexities for three dam catchments in korea a calibration period of six to eight years was required therefore when considering the three catchments and the three hydrological models in common an appropriate simulation result can be obtained if more than eight years of data are used for model calibration in addition it was confirmed that as the size of the catchment decreases an increased length of hydrological data is required for calibration of the hydrological model overall in the case of the sacramento model which has relatively many parameters with plenty of uncertainties the variability of the optimal parameter values was large even if the calibration period was increased therefore the distribution of the optimal parameter values could not be used to estimate the appropriate calibration data length however as a result of analyzing the sensitivity of the parameters of the sacramento model the variability of the parameter sensitivity decreased as the calibration period increased therefore the sensitivity analysis of parameters can be used to estimate the length of the calibration data for various hydrological models including a model with large parameter uncertainties the methods and results used in this study can be usefully applied to estimate the appropriate calibration data length for other hydrological models in the future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was conducted without external funding appendix 
3582,generally reliable simulation results are obtained by calibrating and validating the parameters of a hydrological model through a split sample test to obtain adequate and stable calibration and validation results of a hydrological model calibration data with sufficient length should be used therefore a study on the estimation of appropriate calibration data length is required in this study the appropriate calibration data length was estimated for three hydrological models gr4j ihacres and sacramento models with varying complexities using the sobol global sensitivity analysis method as a result of analyzing the appropriate calibration data length in three hydrological models for three dam catchments in korea a relatively stable simulation result could be derived using more than eight years of calibration data length in addition it was confirmed that the appropriate length of the calibration data increased as the size of the catchment decreased in the case of the sacramento model with the largest number of parameters the variability of the optimum parameter values was high even if the calibration period increased therefore the variability size of the optimum parameter values is an improper scale for estimating the appropriate calibration data length when many parameter uncertainties exist however as a result of analyzing the parameter sensitivity of the sacramento model the variability of the parameter sensitivity decreased as the calibration period increased the variability of model performance was also related to the variability of parameter sensitivity rather than to the variability of optimal parameter values therefore parameter sensitivity analysis can be used to estimate the calibration data length for various hydrological models including hydrological models with high uncertainty keywords global sensitivity analysis calibration data length estimation conceptual hydrological model hydrological model uncertainty split sample test 1 introduction a hydrological model is useful when the observed flow data can be simulated properly in general calibrating and validating the parameters of a hydrological model using a split sample test klemeš 1986 provides reliable simulation results to obtain meaningful calibration and validation results for a hydrological model the calibration period should be sufficiently long klemeš 1986 arsenault et al 2018 if it is too short a simulation result may have problems of overfitting or low agreement with the observed data harlin 1991 in addition if an overly short data period is used for model calibration the model performance variability over the course of the calibration and validation may become large and unstable e g kim et al 2011 razavi and tolson 2013 the data used to calibrate the parameters should contain as much hydrological information as possible related to the target catchment therefore several studies have been conducted on data length considering sufficient hydrological information for parameter calibration and validation first some studies have shown that even if hydrological data from a short period e g one or two years are used for parameter calibration appropriate simulation results can be obtained sorooshian et al 1983 studied the appropriate length of the calibration data for the sacramento conceptual hydrological model appropriate parameter values and prediction results can be obtained with a calibration period of only one year they emphasized that data quality was more important than data length harlin 1991 argued that it is appropriate to use a calibration period between two and six years to estimate the optimal parameter values for the hydrologiska byråns vattenbalansavdelning hbv model the optimal calibration period was four years for model performance in some cases the result of the short calibration period of one or two years was equivalent to the result of the 10 year calibration period therefore the hydrological information of the short period was also useful refsgaard and knudsen 1996 determined that a data period of more than one year was suitable for the parameter calibration of three hydrological models with different structures nam watbal and mike she yew gan et al 1997 analyzed the performance of five hydrological models pitman sacramento nam xinanjiang and smar using data from three african and american catchments in their study the structure of the hydrological models calibration objective function and quality of the calibration data were more important than the length of the calibration data perrin et al 2007 calibrated the parameters of two hydrological models gr4j and topmo using randomly extracted data from 39 years and validated the parameters using the entire data period they found that 350 daily data could be used to calibrate the models and estimate appropriate parameter values the above studies argued that optimal parameter values can be properly estimated using high quality short term data therefore it will be most efficient if only the period with high quality data containing a lot of information can be accurately extracted and used for model calibration however in practice it is not easy to investigate select and use high quality data from the entire period therefore for practical use it is necessary to estimate the average length of the calibration data with good quality some studies suggest a longer period for the calibration process yapo et al 1996 estimated the appropriate data length with good calibration results while being relatively insensitive to the selection of a specific period of data they applied the data from the us leaf river catchment 1944 km2 to the sacramento model with 13 parameters and confirmed that the eight year calibration period was appropriate anctil et al 2004 studied the appropriate calibration data length for the gr4j model with four parameters for the serein river catchment 1120 km2 in france they confirmed that stable simulation results were obtained when using a calibration period of five years or more vaze et al 2010 estimated the calibration data length suitable for climate change studies using four conceptual models simhyd sacramento smarg and ihacres with different numbers of parameters 6 14 for 61 catchments of varying sizes 50 2000 km2 in southeast australia consequently a 20 year calibration period was found to be optimal for the different models kim et al 2011 investigated the appropriate calibration data length using the ihacres model with five parameters for five catchments of various sizes 90 506 km2 in australia the model performance and parameter values were stabilized when the eight year period was used motavita et al 2019 explored the influence of the selection of calibration and validation data on the predictive ability of the model using the hbv model and comprehensive differential split sample test for the deggendorf kollbach catchment 36 6 km2 in germany as the calibration period of the data increased the parameter values stabilized however if the calibration period exceeded eight years the predictive ability of the model for the validation period decreased as shown in the previous studies described above the appropriate length of the calibration data varied significantly from study to study the difference in the appropriate calibration data length for each study may be caused by differences in the size of the target catchments hydrogeological characteristics of catchments meteorological characteristics structure of hydrological models and data quality there are no suitable answers of the appropriate calibration data length for various conditions and data quality therefore a method for determining the appropriate calibration period length is needed in particular hydrological models with numerous parameters have high uncertainty shin et al 2013 2015 therefore parameter values may not be stabilized owing to uncertainty for hydrological models with large uncertainties it may be difficult to estimate the appropriate calibration data length depending on the hydrological characteristics of the target catchment hence research on this is necessary the purpose of this study is to estimate the appropriate calibration data length for hydrological models using the sobol method 1993 a global sensitivity analysis method for practical use this study estimates the average length of the calibration data with proper calibration and validation results while being relatively unaffected by the selection of a specific data period as in the study by yapo et al 1996 in particular this study analyzes how the sensitivity analysis method is applicable for estimating the appropriate calibration data length for hydrological models with high uncertainty previous studies have analyzed the variability of optimal model performances and or parameter values to estimate the appropriate calibration data length the difference between this study and the previous ones is that this one estimates the appropriate calibration data length by analyzing the parameter sensitivity index variability in addition this study analyzes the correlation between catchment size and the appropriate calibration data length for hydrological models for this analysis three hydrological models and three catchments in korea with diverse hydrological characteristics over 40 years of observed hydrological data were used 2 materials 2 1 catchments and data the study areas were the soyanggang andong and seomjingang dam catchments in korea fig 1 to obtain stable calibration and validation results for a hydrological model it is necessary to select a catchment with sufficiently long hydrological data which is required to estimate the appropriate calibration data length by testing a hydrological model for various calibration periods these three dam catchments are suitable for this study because they have the longest hydrological data in korea these three catchments are located in different major basins the soyanggang 2703 km2 andong 1584 km2 and seomjingang 763 km2 catchments are located in the han river basin to the north the nakdong river basin to the southeast and the seomjin river basin to the southwest there are no artificial structures in these three catchments and the flow rates in the catchments have natural flows with no synthetic distortions these three catchments have various meteorological conditions and runoff characteristics because they are located in various regions of korea therefore they are representative of the hydrological characteristics of korea the data used for hydrological modeling were daily areal rainfall potential evapotranspiration and observed runoff data for the calibration and validation of the parameters areal rainfall data were generated using the thiessen polygon method observed runoff and areal rainfall data were provided by the water resources management information system http www wamis go kr of korea the period of data used in this study was 41 years from january 1 1978 to december 31 2018 potential evapotranspiration data were generated using the penman monteith method provided by the spei package beguería and vicente serrano 2015 for the generation of potential evapotranspiration data the daily maximum and minimum temperature wind speed and sunshine hours data of the meteorological stations were provided by the korea meteorological administration http www kma go kr 2 2 hydrological models three models with very different complexities gr4j ihacres and sacramento have been used to demonstrate the procedure for estimating the appropriate calibration data length table 1 these conceptual hydrological models have been used in various studies until recently moussu et al 2011 petheram et al 2012 shin et al 2016 heřmanovský et al 2017 guo et al 2018 sezen et al 2019 the gr4j model perrin et al 2003 uses four parameters and simulates daily runoff using two stores production and routing and two unit hydrographs the production store controls the storage of rainfall evapotranspiration and infiltration processes at the surface in the routing store slow and quick flows are simulated using the effective rainfall generated in the production store the slow flow is generated using 90 effective rainfall and the first unit hydrograph the quick flow uses the remaining amount of effective rainfall 10 and the second unit hydrograph finally the total runoff is generated as the sum of slow and quick flows le moine et al 2008 the ranges of the gr4j model parameters follow those of shin et al 2013 the ihacres model was developed in the early 1990 s jakeman et al 1990 jakeman and hornberger 1993 this model has been modified in several versions considering the hydrological characteristics of catchment and application this study uses the catchment moisture deficit cmd version of ihacres model croke and jakeman 2004 that uses a total of six parameters in this study a total of five parameters were used table 1 because the potential evapotranspiration data was used instead of the temperature data which fixes the parameter e as one the ihacres model simulates runoff by considering the changes in soil moisture in the catchment this model calculates the effective rainfall by combining the catchment moisture deficit calculated using the accounting equation and the conversion result of the raw rainfall calculated using the nonlinear function the calculated effective rainfall is converted into quick and slow flows through two unit hydrographs finally the total runoff was calculated by adding the quick and slow flows the sacramento model burnash et al 1973 uses 16 parameters three parameters side rserv and riva were fixed by referring to the study by peck 1976 table 1 therefore 13 parameters were used in this study and the parameter ranges were the same as those used by shin et al 2013 this model simulates a direct runoff for an impervious area surface runoff interflow and two types of base runoff some of the excess rainfall is converted to runoff through a unit hydrograph and the remainder is stored in soil moisture stores some of the water stored in the soil moisture store is lost by evapotranspiration and the rest becomes interflow and groundwater finally this model calculates the total runoff by summing the direct runoff surface runoff and interflow in this study the hydrological model assessment and development hydromad andrews et al 2011 modeling package including these three hydrological models was used hydromad is an r based open source software package that can be downloaded and used for free from http hydromad catchment org 3 method 3 1 parameter calibration the shuffled complex evolution sce duan et al 1992 1993 algorithm was used to calibrate the parameters of the three hydrological models sce is a global optimization algorithm widely used to calibrate hydrological model parameters nicklow et al 2010 and has been used in various studies qi et al 2016 tigkas et al 2016 shin and kim 2017 kan et al 2018 shin and choi 2018 the sce algorithm combines the advantages of the simplex procedure nelder and mead 1965 competitive evolution holland 1975 controlled random search price 1987 and complex shuffling duan et al 1992 in brief this algorithm creates an initial random population in a feasible parameter space and divides this population into complexes the complexes refer to communities with parents who produce offspring each complex then evolves independently using a competitive complex evolution strategy the evolved complexes are gathered and mixed into a population for information exchange finally these optimization processes are repeated until the convergence condition of the previously selected objective function is satisfied the objective function used for parameter calibration is the nash sutcliffe efficiency nse nash and sutcliffe 1970 and is defined as follows 1 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 where q obs i and q sim i are the observed and simulated flow rates at time step i daily here respectively q obs is the average of the observed flow rates and n is the number of time steps the range of nse is to 1 where unity means that the simulated flow rate is the same as the observed flow rate and zero means that the simulated flow rate is the same as the average value of the observed flow rate 3 2 sensitivity analysis the sobol method sobol 1993 a global sensitivity analysis method was used to analyze the sensitivity of the parameters this method has been used in various studies houle et al 2017 jepsen et al 2018 zhang et al 2019 this sensitivity analysis method decomposes the variance in the simulation results finally it estimates the relative effect of each parameter and the interaction between the parameters on the variance of the results this method computes two sensitivity indices the first is the first order sensitivity index fsi which calculates the effect of each parameter on the model s results and the second is the total sensitivity index tsi which has the function of the fsi including the interactions between each parameter and the rest of the parameters on the results of the model saltelli et al 2008 the tsi provides more reliable results than the fsi in investigating the overall effect of each parameter on the model s results saltelli et al 2008 therefore in this study the sensitivity of each parameter was analyzed using tsi the tsi values range from 0 to 1 tsi values closer to 1 indicate that the parameter further affects the results of the model the tsi is defined as follows saltelli annoni 2010 2 tsi e x ĩ v x i y x ĩ v y where x i is the i th parameter and x ĩ is the vector of all parameters except for x i the inner variance of the numerator means that the variance of y the value of the objective function in a scalar form is considered for all possible values of x i while x ĩ is fixed the outer expectation operator is considered for all possible values of x ĩ the variance v y in the denominator is the total unconditioned variance the tsi numerator is the expected variance that would be left if all parameters are fixed except for x i saltelli annoni 2010 an r based sensitivity package pujol et al 2012 was used to apply the sobol method in addition saltelli s scheme saltelli 2002 was used to efficiently calculate tsi with a smaller number of samples by using n k 2 instead of n 2 k 2 here n is the size of the initial sample and 10 000 samples were used in this study moreover k denotes the number of parameters in the hydrological model therefore the total number of samples for sensitivity analysis was 60 000 for the gr4j model with four parameters 70 000 for the ihacres model with five parameters and 150 000 for the sacramento model with 13 parameters the target function of the sensitivity analysis was the modified nse nse mathevet et al 2006 and is defined as follows 3 n se 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 the nse is nse divided by nse with a plus sign and the range of the nse is 1 1 the nse has a range of negative values that is significantly smaller than the range of the nse 1 which has the advantage of reducing the effect of very large negative numbers on the sensitivity analysis without changing the interpretation of the nse value shin et al 2013 3 3 estimation of stable calibration data length first for a 30 year period from 1979 to 2008 the parameters were calibrated by increasing the parameter calibration period from three to 10 years in one year increments e g 3 4 or 10 the total number of calibration periods for each calibration period was created using a one year moving window method then the predictive performance of the model was evaluated by validating each calibrated parameter value for a period of 10 years from 2009 to 2018 for example in the case of a three year parameter calibration period a total of 28 calibration periods were created by shifting the three year period such as from 1979 to 1981 from 1980 to 1982 and finally from 2006 to 2008 by moving one year as shown in fig 2 subsequently the estimated parameter values for each three year calibration period were applied to the 10 year validation period from 2009 to 2018 to simulate the runoff and investigate the distribution of the objective function values for the calibration and validation periods fig 2 the period one year before each calibration period was used as the warm up period e g 1978 is the warm up period of the 1979 1981 calibration period note that there is no certainty on the selection of the calibration period by researchers to obtain appropriate calibration and validation results no matter which calibration period researchers select all possible calibration periods should be considered as the subject of calibration to reflect this purpose all possible calibration periods were selected and each experiment was performed in each experiment as shown in fig 2 the calibration and validation periods are independent without any overlaps based on this independence the calibration and validation process is appropriate in the usage of the split sample test klemeš 1986 when all experiments are considered together overlapped periods between experiments have no substantial interdependence on the results except the size of the ranges of boxplots not shown here for example in the case of the three year calibration period described above the calibration periods of experiment 1 1979 1981 and 2 1980 1982 have a 2 year overlap fig 2 a boxplot using non overlapped calibration periods e g 1979 1981 1982 1984 etc has a smaller range compared to a boxplot using all possible calibration periods due to the smaller number of experiments although the overlap of calibration periods slightly affects the range of the boxplot all possible calibration periods should be used to estimate an appropriate calibration length in this study for the three dam catchments and three hydrological models the stabilized distribution of the objective function values for the calibration and validation periods was determined as the optimal length of the calibration data the total number of models for the three catchments and three hydrological models was 1764 196 calibrations for the three to 10 year calibration period three catchments three hydrological models boxplots and coefficients of variation cvs were used to investigate the distribution of the objective function values for each calibration period the cv is defined as follows 4 cv σ μ where σ and μ denote the standard deviation and the mean of the objective function values for each calibration period respectively in addition the obtained calibration period using the distribution of the objective function values was compared with the period in which the distribution of the calibrated parameter values was stabilized finally for each calibration period the tsi of the parameters was calculated 1764 calculations and the distribution and stabilization period of the parameter sensitivity index were explored when investigating the distribution of optimal parameter values and parameter sensitivity indices a boxplot and normalized standard deviation for each calibration period were used as in shin et al 2015 when the average value of the optimal parameter values or that of the sensitivity indices approaches zero the value of the cv becomes very large and therefore it becomes difficult to properly analyze the variability to solve this problem the normalized standard deviation is used and the equation is as follows 5 nor s t d e v σ δ p where δ p is the range the difference between the maximum and minimum values of each parameter or sensitivity index we examined whether the optimal length of the calibration data based on the distribution of parameter sensitivity indices was different from that of the distribution of objective function values and parameter values in addition we analyzed how the results of the sensitivity analysis of parameters can help in the selection of the optimal calibration data length finally the correlation between the size of the study catchments and the optimal length of the conceptual hydrological model calibration data was analyzed 4 results 4 1 estimation of the calibration data length using the model performance variability fig 3 shows boxplots representing the distribution of the nse values obtained for the calibration periods of the gr4j ihacres and sacramento models for the soyanggang andong and seomjingang catchments in fig 3 the numbers on the horizontal axis from 3 to 10 in the calibration column refer to the length of the data number of years used for parameter calibration moreover the numbers on the horizontal axis from 3 to 10 in the validation column are validation results for each calibration period for example the result of validation 3 was obtained when the estimated parameter value for the three year calibration period was applied to the validation period 2009 2018 for the gr4j model using four parameters the distribution of nse values for the three year calibration data for the seomjingang catchment was very wide and ranged from approximately 0 5 to 0 9 in addition the distribution of the nse values during the validation period also showed a very wide distribution from approximately 0 4 to 0 9 this means that even if the simulated hydrograph for a specific calibration period e g three year has a high degree of agreement with the observed hydrograph with a high nse value the validation period could have a low nse value due to overfitting for the calibration period namely the runoff during the validation period cannot be properly predicted therefore it is necessary to increase the length of the calibration data so that sufficient information necessary for validation is included in the calibration period hence the length of the calibration data should be increased until the distribution of the nse values for both the calibration and validation periods is as narrow as possible as shown in fig 3 the distribution of the nse values for calibration and validation continued to narrow when the calibration period was increased because this study aims to estimate the minimum calibration period length with adequate model performance nse value of 0 6 or more the calibration period was estimated by the cv of the nse value for each calibration period shown in fig 4 with concise expression of nse variances consequently the number of years in the calibration period in which the cv decreased rapidly and then became gently steady was six years in the soyanggang catchment six years in the andong catchment and seven years in the seomjingang catchment fig 4 the nse values for all catchments were greater than 0 6 as shown in fig 3 therefore in the case of the gr4j model an appropriate simulation result can be obtained only when the calibration period is more than six seven years for the ihacres model using five parameters the number of years for the calibration period based on the rapidly decreased and moderated cv was six years for the soyanggang and andong catchments and eight years for the seomjingang catchment fig 4 with eligible nse values greater than0 6 fig 3 moreover the results of the sacramento model with the highest number of parameters showed relatively large variability compared to the gr4j or ihacres models fig 4 the sudden decrease in the cv with moderation for the sacramento model was six years in the soyanggang catchment seven years in the andong catchment and eight years in the seomjingang catchment with sufficiently high nse values therefore the ihacres and sacramento models should use a calibration period of six eight years or longer to obtain appropriate simulation results in particular the distribution of the nse values for calibration and validation decreased as the calibration period was increased in the sacramento model but the variability was relatively greater than that of the other two models namely as the length of the calibration data increased there was a period in which the cv of the nse value repeatedly decreased and increased especially in the case of validation fig 4 the instability of the distribution of the nse values over this validation period may be related to the uncertainty of the parameters of the sacramento model shin et al 2015 therefore in section 4 2 the variability of the optimal parameter values of the hydrological models according to the increase in the calibration period is analyzed 4 2 estimation of the calibration data length using the distribution of optimal parameter values figs a1 a5 in appendix a show the distribution of optimal parameter values for each calibration period of the gr4j ihacres and sacramento models for the three catchments fig 5 shows the variability of the optimal parameter values for each calibration period for the gr4j and ihacres models the distributions of optimal parameter values narrowed as the length of the calibration data increased figs a1 and a2 in appendix a the variabilities of the optimal parameter values by calibration period for the gr4j model were stabilized at six year in the soyanggang catchment six year in the andong catchment and approximately seven year in the seomjingang catchment fig 5 for the ihacres model the variability of the parameter values stabilized for six year in the soyanggang catchment six year in the andong catchment and approximately eight year in the seomjingang catchment fig 5 therefore the periods of calibration data when the variabilities of the optimal parameter values of these two models stabilized supports the results of section 4 1 this means that the distributions of the optimal parameter values for the two hydrological models with relatively few parameters affect the distributions of the nse values representing model performance however the distributions of the optimal parameter values of the sacramento model did not narrow down in most cases even when the calibration periods were increased for all three catchments these distributions repeatedly decreased and expanded figs a3 a5 in appendix a therefore it is difficult to estimate the appropriate length of the calibration data using the distributions of the optimal parameter values because of the instability of the distributions with larger variability fig 5 in addition these unstable distributions of optimal parameter values may cause variations in the distributions of the nse values in the validation period analyzed in section 4 1 the sacramento model uses a relatively large number of parameters compared to the gr4j and ihacres models the parameters have large uncertainties owing to the interaction between many parameters shin et al 2013 2015 shin and kim 2019 therefore the uncertainties caused by the interactions between these parameters can result in a relatively unstable distribution of the optimal parameter values for each calibration period therefore as an alternative method for estimating the appropriate calibration period of the sacramento model the sensitivity analysis of the parameters was used as shown in section 4 3 4 3 estimation of the calibration data length using the parameter sensitivity distribution figs a6 a10 in appendix a show the distribution of the tsi of the parameters for each calibration period of the gr4j ihacres and sacramento models in fig 6 the tsi variability for each calibration period is shown as expected the tsi distribution for the gr4j and ihacres models narrowed as the calibration period increased figs a6 and a7 in appendix a for the sacramento model surprisingly the tsi distributions of the parameters also narrowed down as the calibration period increased unlike the distributions of the optimal parameter values figs a8 a10 in appendix a the tsi variabilities for the gr4j model rapidly decreased and then stabilized at six year in the soyanggang catchment six year in the andong catchment and seven year in the seomjingang catchment fig 6 the ihacres model has similar stabilizing points of the tsi variabilities at six year in the soyanggang catchment six year in the andong catchment and eight year in the seomjingang catchment fig 6 therefore the gr4j and ihacres models using relatively few parameters have adequate calibration data length similar to those shown in the variabilities of the nse values and the variabilities of the optimal parameter values according to the tsi variability analysis for the sacramento model the variabilities of the tsi values stabilized at six year in the soyanggang catchment seven year in the andong catchment and eight year in the seomjingang catchment fig 6 these numbers of years are the same as those corresponding to the stabilized cv of the nse values as shown in section 4 1 therefore the distributions of the sensitivity index of the sacramento model parameters for the calibration period were distinctively related to the distributions of model performance the parameter sensitivities indicate the degree of influence of the parameters on the model simulation results therefore for a model with large parameter uncertainties such as the sacramento model the distributions of parameter sensitivities are better indicators of model performance characteristics during the calibration period than the distributions of optimal parameter values 5 discussion regarding catchment size used in this study all hydrological models with decreased catchment sizes had a greater appropriate calibration data length this is because smaller catchments have shorter concentration times in addition runoff at the catchment outlet is greatly affected by the amount of rainfall the hydrographs at the smaller catchment outlets react more sensitively to rainfall which shows greater variability of the hydrographs for smaller catchments this can be confirmed from the fact that the cvs increased from the larger catchment i e soyanggang to the smaller catchment i e seomjingang in fig 4 for smaller catchments more rainfall and runoff information should be included in the calibration period to adequately simulate the variability of the hydrograph during the calibration and validation periods therefore smaller catchments require longer calibration data lengths for all three hydrological models as the length of the calibration data increased the variability of the nse and tsi values decreased therefore the longer the calibration data length used the more stable the calibration and validation results however not all catchments always have long hydrological data so it is necessary to present the appropriate minimum length of calibration data for this study in the case of the catchments covered in this study six to eight years of data were required for parameter calibration to obtain stable results therefore to be applied to three catchments and three hydrological models in common hydrological data of more than eight years were required for parameter calibration this result is the same as the length of the eight year calibration data presented in the studies of yapo et al 1996 and kim et al 2011 however this study is different from the previous two studies because the sensitivity index of the parameter was used to estimate the appropriate calibration data length most previous studies have estimated the appropriate length of calibration data using the variabilities of the model performance and or the optimal parameter values e g harlin 1991 yapo et al 1996 anctil et al 2004 vaze et al 2010 kim et al 2011 arsenault et al 2018 motavita et al 2019 however as shown in the results of this study the method considering the variabilities of optimal parameter values does not apply to all hydrological models namely the distributions of the optimum parameter values of the sacramento model shown in section 4 2 showed great variability even when the length of the calibration data increased thus the previous method could not be used to estimate the appropriate calibration data length for this model the large variability of the sacramento model parameters was also confirmed by yapo et al 1996 vrugt et al 2006 also analyzed the effects of calibration data length on model performance and parameter uncertainties of the sacramento model for the leaf river watershed in the united states the model performance improved as the length of the calibration data increased but the parameter uncertainties were not reduced in addition the strong interaction between parameters with lower identifiability for each parameter may induce uncertainties in the sacramento model shin et al 2013 2015 shin and kim 2019 in the case of physically based distributed hydrological models with relatively many parameters e g soil and water assessment tool arnold et al 1998 there may be more parameter uncertainties e g abbaspour et al 2015 therefore for a hydrological model using many parameters the appropriate calibration data length can be estimated by using the normalized standard deviation of the parameter sensitivity tsi based on the sobol method as described in section 4 3 the sensitivity analysis method based on the sobol method can help in the selection of an appropriate calibration period not only for the sacramento model with many parameters but also for the remaining hydrological models with few parameters for example in fig 5 showing the normalized standard deviation of optimal parameter values the appropriate calibration period for the x2 and x4 parameters of the gr4j model for the soyanggang catchment is relatively unclear the appropriate calibration period for these parameters was clearly shown in fig 6 which shows the normalized standard deviation of the parameter sensitivity tsi as six years therefore the sensitivity analysis method provides a lot of information to select an appropriate calibration period for a hydrological model 6 conclusions in this study the appropriate calibration data length of the hydrological model was estimated using the sobol global sensitivity analysis method as a result of analyzing the appropriate calibration data length for three conceptual hydrological models with different complexities for three dam catchments in korea a calibration period of six to eight years was required therefore when considering the three catchments and the three hydrological models in common an appropriate simulation result can be obtained if more than eight years of data are used for model calibration in addition it was confirmed that as the size of the catchment decreases an increased length of hydrological data is required for calibration of the hydrological model overall in the case of the sacramento model which has relatively many parameters with plenty of uncertainties the variability of the optimal parameter values was large even if the calibration period was increased therefore the distribution of the optimal parameter values could not be used to estimate the appropriate calibration data length however as a result of analyzing the sensitivity of the parameters of the sacramento model the variability of the parameter sensitivity decreased as the calibration period increased therefore the sensitivity analysis of parameters can be used to estimate the length of the calibration data for various hydrological models including a model with large parameter uncertainties the methods and results used in this study can be usefully applied to estimate the appropriate calibration data length for other hydrological models in the future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was conducted without external funding appendix 
3583,the extent of coastal flooding is influenced by many factors such as the topography of the low lying land tidal level rainfall pattern inflow discharge collected from the upstream drainage area etc this study establishes a new methodology of effectively predicting the flooding process in coastal areas and which is achieved by combining the recurrent neural network rnn model with the detailed analysis of different hydrological and geomorphological factors the novelty of this study is to apply the topographic wetness index twi of each grid to classify all inputs into multiple classes for separative training to improve the overall accuracy of flooding simulations a numerical inundation model based on hydrodynamic equations was applied to investigate the behavior of coastal flooding in the temporal and spatial domain under a variety of model settings with different hydrologic conditions and it was utilized to generate the target inundation depths for the training of the rnn model the relevance between the downstream topography tidal level rainfall intensity and the spatial distribution of flooding in coastal areas is explored via the use of machine learning ml techniques the focus of this study is to evaluate the proposed alternative method that allows for improving the efficiency and stability of forecasting coastal floods caused by rains and storm surges due to the approaching tropical cyclones the method developed in this study is promising to replace the numerical inundation model to reinforce the model s stability and computational efficiency keywords floodplain inundation coastal flooding storm surge topographic wetness index geomorphological characteristics recurrent neural network model 1 introduction flooding in coastal areas normally occurs when dry and low lying land is submerged by seawater or overland flow resulting from heavy rainfall ramsay and bell 2008 coastal flooding whose extent is controlled by the topography of the coastal land kulp and strauss 2019 and the difference in water surface elevation among adjacent regions is caused by floodwater from the sea and rivers inundating the inland most of the available methodologies for coastal flooding simulations rely on hydrodynamic models and require digital elevation models dems previous studies have indicated that the accuracy of coastal floodplain simulation is sensitive to the dem resolution adopted in the hydrodynamic model thus high resolution topographic data is demanded to capture the more realistic landform and analyze the flooding in low lying land in detail bates et al 2003 gallegos et al 2009 however computing efficiency would be compromised especially when numerical models in which the computational time interval is restrained by the stability condition are applied for simulating inundation on the coastal floodplain area hunter et al 2005 bates et al 2010 huang and lee 2013 2017 the primary motivation of this study is to seek other alternatives to replace the use of numerical algorithms on the other hand the need for a better understanding of the spatial and temporal dynamics of floodwater is more urgent considering the impacts of climate change which has been indicated to induce the global sea level rise and population growth in many countries intensifying flood damages and calling for a global interest in founding out different flood assessment and management approaches vankoningsveld et al 2008 nerem et al 2018 nevertheless related studies have reported that most existing floodplains were analyzed by merely using rainfall as an input in hydrological models but not considering the impact of cyclone induced storm surge on the coastal area ray et al 2011 budiyono et al 2016 hamman et al 2016 eccles et al 2021 in that case flooding simulations would be limited to regional scale and such an approach lacks the overall considerations for the floodwater occurring in the whole basin previous articles also revealed that the timing of both rainfall and the storm surge play a significant role in the extent of inland flooding ray et al 2011 this finding therefore motivates this study to devise a new analysis method which can more comprehensively take into account multiple factors such as boundary conditions and geomorphological characteristics that may influence the results of flooding simulations to come up with a more robust flood forecasting method associated studies about the simulation of floodplains or coastal flooding have been continuously discussed in the recent two decades bilskie et al 2014 utilized numerical models to analyze the mississippi and alabama coast and simulate the response of hurricane storm surge to changes in sea level land use and land surface elevation they indicated that the storm surge response to sea level rise is dynamic and sensitive to changes in the landscape poulter and halpin 2008 applied lidar elevation data in the coastal area to investigate the effects of horizontal resolution and connectivity on the extent and timing of flooding resulting from sea level rise they found that the rate and extent of inundation were dependent on horizontal resolution and assumptions made on hydrological connectivity ray et al 2011 adopted one dimensional dynamic hydraulic modeling to analyze the combined effects of storm surge and inland rainfall on the floodplain of a coastal bayou in the houston area olbert et al 2017 applied an integrated flood modeling system comprising of an ocean model and a coastal flood model to investigate mechanisms of flooding resulting from multiple process drivers and evaluate flood risk to human safety such an approach gave a better understating of the dynamics of complex coastal urban flooding and would therefore facilitate coastal management in addition to applying hydrodynamic numerical models researchers have also developed other alternatives to simulate floodplain dynamics narayan et al 2012 proposed a holistic graphical model for coastal flooding by using system diagrams and the source pathway receptor spr concept to structure the understanding of large and complex floodplains in recent years machine learning ml methods have been widely applied to facilitate flood prediction bass and bedient 2018 developed an artificial intelligence ai based surrogate model to rapidly represent peak inundation due to the joint occurrence and interaction between rainfall runoff and storm surge from tropical cyclones bermúdez et al 2019 built a non parametric regression model based on least squares support vector machines ls svms as a computationally efficient surrogate of two dimensional shallow water equations for flood inundation mapping zahura et al 2020 advocated training a surrogate model to relate topographic and environmental features to hourly water depths simulated by a physics based model at road segments in the coastal city of the usa in their method the topographic wetness index twi was directly adopted as model input compared with the methodology proposed by zahura et al 2020 this study further considers the impact of storm surge on flood inundation and the twi is jointly applied to classify the input data into multiple classes for separative training of the surrogate model to enhance the overall accuracy of 2d inundation prediction the objective of this study is to develop an alternative method for coastal flooding predictions based on the application of geomorphological characteristics and the improvement of the training process for an artificial intelligence tool to avoid any forms of numerical problems such as calculation instability or inefficiency we first investigate the influence of all the factors i e the downstream topography tidal level rainfall intensity on the spatial distribution of flooding in the coastal floodplain area a variety of geomorphological factors extracted from the original topographic data are explored thoroughly and then adopted as the important indexes to estimate the flooding depths during rainstorms it has been pointed out that the application of the digital terrain model and set of terrain analysis procedures is capable of identifying floodplain boundaries and this approach obtained consistent results with floodplain delineations derived by flood hazard models nardi et al 2019 grimaldi et al 2013 applied detailed topographic information to establish a fully continuous hydrologic hydraulic modeling framework for flood mapping to avoid the use of the design hyetograph and the design hydrograph that constitute the main source of subjective analysis and uncertainty manfreda et al 2014 utilized three different geomorphic approaches to identify flood prone areas through a comparative analysis of the input parameters and the range of applicability in this study a machine learning ml tool called recurrent neural network rnn is applied to construct the optimal connections between all possible influencing factors and the flooding depth at any location within the studied watershed although ml methods have been widely used for hydrological applications or associated simulations of the flow field the novelty of this article is to propose a new training procedure by considering more geomorphological factors such as the local upslope contributing area the length of the flow path from the furthest point to a selected location and the length of the flow path from a selected location to the coastline these factors are considered to have physical significance to explain the influence of coastal landform on the inundation depth to effectively and accurately describe the temporal and spatial behavior of floodwater on the land surface a classification method according to the terrain characteristics is devised to facilitate the establishment of an ml based prediction model for coastal floodplain simulations in which the complicated numerical algorithms can be exempted 2 study area the applicability of the proposed ml based prediction model to simulate flooding in coastal floodplain areas was investigated considering two adjacent river basins namely the touqian and fengshan river basins located in north western taiwan as shown in fig 1 the two river basins are adjacent both of their mainstreams originate from the xueshan mountain range and merge westward into the same estuary the nanliao harbor of hsinchu city which belongs to the taiwan strait the total drainage area of the touqian river basin is about 544 km2 and the mainstream of this watershed has a total length of 63 km the network of mainstreams in this watershed consists of two upstream branches yulo river and shangping river and a downstream channel touqian river the total drainage area of the fengshan river basin is approximately 250 km2 and the total length of the mainstream in this watershed is about 45 km the major land covers in the two river basins are forests shrubs and cultivated fields according to the information reported by the water resources department ministry of economic affairs in taiwan there are currently 4 rain gauges and 5 flow gauges installed in the touqian river basin and 2 rain gauges and 2 flow gauges in the fengshan river basin the average annual rainfall of this river basin measured at the hsinchu station is 1747 mm affected by the periodic southwest monsoon and typhoon the annual precipitation is unevenly distributed in time and space the rainy season usually occurs from june to september during summer and autumn typhoons often invade taiwan island and usually bring torrential rains which lead to severe floods or associated natural hazards and even threaten the lives of inland residents the peak discharge of the 20 year return period at the downstream main channel has reached 4810 m3 s which approximates to the extent of the 200 year return period analyzed from the data before 1993 therefore it is conceivable that the flood hazard is more destructive as reported by the water resources department of taiwan the low lying lands in the coastal floodplain areas of the two river basins are prone to flooding due to the changes in tidal level induced by the tropical cyclone and the local terrain condition inherent in the two jointed river basins 3 methodology although the objective of this study is not to explore the applicability of hydrologic and hydraulic models for coastal flooding simulations associated numerical algorithms and well developed models are utilized to generate different flooding scenarios showing the temporal and spatial variations of inundated depth under various hydrologic conditions these data are collected and provided for the training of the ml based prediction model since the available inundation records in the studied areas are lacking in the following content the theoretical governing equations of the hydrodynamic models the proposed topography based prediction model for coastal flooding simulations and the details of the model settings about the initial and boundary conditions are sequentially explained 3 1 hydrologic and hydraulic modeling based on numerical algorithms for the current study a storm surge model and a hydrologic inundation model were integrated to perform the flooding simulations which are simultaneously affected by the inland rainfall and the abnormal rise in seawater level during a typhoon these two types of numerical models are respectively explained in the following sub sections 3 1 1 storm surge model the advanced circulation adcirc coastal circulation and storm surge model developed by luettich et al 1992 and westerink et al 1994 is used to estimate water surface elevations and currents the two dimensional depth integrated version often named adcirc 2ddi was selected in this study to solve generalized wave continuity equations on an unstructured triangular mesh with a continuous galerkin finite element method fem the governing equations in spherical coordinates are as follows 2 ζ t 1 r e cos φ uh λ vh cos φ φ 0 u t u r e cos φ u λ v r e u φ tan φ r e u f v 1 r e cos φ λ p s ρ 0 g ζ α η υ t h λ uh λ vh φ τ s λ ρ 0 h τ u 3 v t u r e cos φ v λ v r e v φ tan φ r e u f u 1 r e φ p s ρ 0 g ζ α η υ t h φ vh λ vh φ τ s φ ρ 0 h τ v where t is time λ and φ are respectively longitude and latitude ζ is the free surface elevation relative to the geoid u and v are depth integrated velocity components in west east and south north directions respectively h is the total water depth r e is the radius of the earth f is the coriolis parameter p s is the atmospheric pressure at the free surface ρ s is the reference density of water g is gravitational acceleration α is the effective earth elasticity factor η is the newtonian equilibrium tide potential υ t is the depth averaged horizontal eddy viscosity coefficient τ s λ and τ s φ are the surface wind stresses in longitudinal and latitudinal directions respectively which can be computed by a standard quadratic air sea drag law τ is the bottom friction term 3 1 2 hydrological inundation model a distributed rainfall runoff model was applied to perform inundation simulations in the coastal floodplain area it calculates the discharge and flooding depth at every grid based on the inputs of precipitation boundary conditions and topographic data of the watershed saint venant shallow water equations have been widely adopted to describe the transmission of surface runoff and they can be expressed as 4 a t q x i e δ x 5 q t x q 2 a g a h z x g n o 2 q 2 r 4 3 a 0 where q is the discharge a is the flow cross section area ie is the excessive rainfall intensity δ x is the grid size of the raster elevation data h is the water depth z is the bed elevation r is the hydraulic radius no is the manning roughness coefficient in this study the determination of flow direction for each grid follows the steepest gradient of the water surface elevation among eight adjacent grids wang and hjelmfelt 1998 kuiry et al 2010 huang and lee 2013 2017 previous studies advocated using an inertial momentum equation in which the convective acceleration term in the saint venant equations is omitted to effectively alleviate numerical oscillation and maintain the simulated accuracy simultaneously hunter et al 2008 bates et al 2010 according to this simplification bates et al 2010 reformulated the momentum equation as follows 6 q t δ t q t g h t δ t δ t h t z x 1 g h t δ t δ t n o 2 q t h t δ t 10 3 where q is the discharge per unit width this approach has been confirmed to have the utility of improving the stability of 2d floodplain inundation simulations bates et al 2010 huang and lee 2017 thus this hydrological model for analyzing the unsteady overland flow was utilized to consider the time dependent inland rainfall and the boundary conditions affected by the storm surge during a typhoon to derive excessive rainfall from the original precipitation data the green and ampt method 1911 was adopted to estimate the infiltration rate which can be expressed as 7 f t k s k s ψ f θ s θ i f f o r t t p 8 f t i o f o r t t p where k s is the saturated hydraulic conductivity cm h ψ f is the suction head at the wetting front cm θ s is the saturated moisture content θ i is the initial moisture content f is the cumulative amount of infiltrated water cm t p is the time of ponding i o is the observed rainfall rate cm h in this method a sharp wetting front is assumed to form when water penetrates a relatively dry soil layer from the land surface and its physical mechanism of infiltration depends on the soil characteristics 3 2 topography based prediction model for coastal flooding simulations in the following sub sections the fundamental structure of the machine learning algorithm the influential factors considered in this study and a novel training procedure according to the topographic feature are separately elaborated 3 2 1 structure of machine learning tools an artificial intelligence algorithm the recurrent neural network rnn was applied in this study to set up the relationship between the influential factors and the single output namely the time series of inundation depth at each grid the rnn algorithm is a kind of dynamic neural network method devised to take into account the temporal behavior of input data so it has been indicated to be suitable for predicting a time series fig 2 shows the architecture of rnn which consists of three layers with internal time delay feedback loops in both hidden and output layers the output of neuron j in the hidden layer following the architecture of rnn can be expressed as 9 y j t δ t f i 1 i w ini x i t m 1 m w unm y m t where i is equal to the total number of neurons influential factors assigned in the input layer m j which is equal to the total number of neurons assigned in the hidden layer f denotes the activation function x i t denotes the input of neuron i at time t y j t denotes the output of the hidden neuron j at time t w ini denotes the connection weight from the neuron i of the input layer to the neuron j of the hidden layer w unm denotes the feedback weight from the time delay unit m to the neuron j of the hidden layer the network output of neuron k in the output layer at time t δ t is given by 10 o k t δ t f j 1 j w hdj y j t δ t p 1 p w uop o p t where p k 1 which is equal to the number of predicted variables at each time step w hdj denotes the connection weight from the neuron j of the hidden layer to the output neuron k w uop denotes the feedback weight from the time delay unit p to the output neuron k hence the output of predicted inundation depth at time t δ t can be derived by 11 h t δ t o 1 t δ t where h represents the predicted inundation depth in the structure of the rnn the feedback links added in the static neural network are used to allow signals to propagate in both forward and backward directions the time delay units can provide the hidden dynamic memories for the training of neural networks hence they are regarded as additional inputs to retain the previous output information of each neuron from the hidden and output layers in this study the sigmoid activation function was adopted in the neural network algorithm to perform the nonlinear transformation the first order iterative optimization algorithm named gradient descent was chosen to seek the minimum of predicted error 3 2 2 influential factors and data inputs to emphasize the physical meaning of the proposed neural network model for predicting the floodplain inundation the extraction of geomorphological parameters from the topographic data and the use of hydrological factors represent a significant step in this study that facilitate the training work and build the prediction model in particular the parameters associated with topographic characteristics are considered important information to evaluate the hydrological response at a designated grid in the watershed under study as shown in fig 3 a total of 10 influential factors was adopted as the inputs of the rnn model including 3 hydrological factors and 7 geomorphological factors the three hydrological factors are respectively the rainfall intensities ir over the past tp hours the free surface elevation of the tide et on the coastline which varies with the periodic tide and storm surge the discharge at the inflow section of the main channel qin it should be noted that the value of tp is related to the time of concentration of the watershed the seven geomorphological factors are explained accordingly as follows the surface roughness coefficient of an overland grid no which depends on the vegetation and land cover patterns the land surface elevation el the local terrain slope of the ground surface so the local upslope contributing area of an overland grid ad which indicates the ability to collect water from its upstream area and can be derived by utilizing the flow accumulation value that is defined in the digital elevation model the longest length ld from the furthest point on the boundary of ad to a selected location along the flow path assigned by the digital elevation model this parameter has been denoted to be relevant to the time to peak flow huang and lee 2016 the length of the flow path from a selected location to the first channel grid encountered lc as shown by the schematic diagram in fig 4 and the length of the flow path from a selected location to the estuary or coastline ls the aforementioned geomorphological factors can easily be extracted in advance from the topographic data derived from the dem 3 2 3 regional classification and training procedure to describe the behavior of inundation depth changes in more detail a classification method according to the topographic wetness index twi of each grid was employed in this study to divide the studied watershed into multiple regions the topographic wetness index developed by beven and kirkby 1979 is defined as 12 twi ln a d s o where ad is the local upslope contributing area per unit contour length twi is a steady state wetness indicator devised to quantify topographic control on hydrological processes sørensen et al 2006 since the magnitude of inundation depth is simultaneously affected by the upstream contributing area ad and the local slope so twi was considered as an indicator to denote the ability to accumulate water depth by using this way to classify the watershed into multiple regions the grids with similar scales of depth can be trained together the spatial distribution of the twi in the study area is depicted in the upper graph of fig 5 the study area is further partitioned according to the intrinsic distribution of twi extracted from the elevation dataset of the river basin by applying the k means clustering analysis hartigan and wong 1979 and 5 was found to be the optimal number of clusters in this case therefore all grids in the study area are divided into 5 classes as shown in the lower graph of fig 5 the optimal number of classes needs to be investigated before the model training and it depends on the watershed topography on the other hand the area belonging to the main channel as shown by the red zone in the lower graph of fig 5 was additionally categorized as the 6th class for individual arrangement it should be noted that both the spatial distribution of twi and the main channel grids can be extracted by applying the digital elevation model although twi is a function of the upstream contributing area ad and the local slope so it is not suggested to replace the two variables ad and so and merge them as a single input factor since the impacts of the upstream contributing area and the local slope on the inundation depth can change during a flood event these two variables are separately assigned as influential factors of the ai model as shown in fig 3 as shown in fig 6 a series of preparation works were required before training the proposed rnn model the numerical storm surge model was applied to produce tidal levels along the coastal line as the boundary conditions for implementing the numerical inundation model the numerical inundation model was then used to generate numerous flood maps as the target inundation depths for the training of the proposed rnn model the digital elevation model was utilized to extract all the required geomorphological factors as the inputs of the proposed rnn model and the topographic wetness index twi of each grid as shown by the flow chart of fig 6 the whole simulation domain was first partitioned and classified according to the twi of each grid and then the input factors belonging to the same class were assigned to the same rnn model in this study the training of the rnn model was separately executed for each twi class to manipulate the spatial and temporal variation of inundation depth more preciously therefore in this study case a total of six rnn models was required to be established for generating flood maps that show inundation depths of all girds within the simulation area the respective training of the rnn model can be carried out by assigning the corresponding inputs and target outputs it should be noted that the factor qin is only adopted to train the rnn model for the grids belonging to the main channel since it represents the discharge at the inflow section the holdout cross validation cv method was adopted in this study to verify the rnn model by randomly selecting 25 of the dataset as the testing data and training the model with the remaining data to highlight the ability of the proposed training method in enhancing the accuracy of the flood prediction model simulation results of three models are provided for performance evaluation the models considered are the hydrologic inundation model the rnn model obtained from the proposed procedure which applies the data classification according to the twi of each grid and the rnn model executed without data classification in advance 3 3 model settings and training setups as informed by the associated reports only the downstream coastal floodplain areas of the touqian and fengshan river basins are flood prone regions therefore the area marked by green as shown in fig 7 was adopted as the inundation simulation domain and analyzed in this research the horizontal resolution of topographic data applied to implement the hydrologic model and the prediction model is 20 m and the total number of grids contained in the computational domain is 3 922 686 the discharge records measured at the jing guo and the xin pu stations were adopted as the inflow boundary conditions and this volume flow rate was collected from their respective upstream contributing area marked by red and blue the initial condition of the overland area grids was assumed as a dry surface and the steady discharge was assigned in the hydraulic model to provide the initial depths for the grids of the main channel marked by light blue the free surface elevations along the coastline yielded by the adcirc model were adopted as the downstream boundary conditions since the soil type in the study area is sandy loam the saturated hydraulic conductivity was set as 1 14 cm h the suction head at the wetting front was set as 9 cm and the saturated moisture content was set as 0 48 to estimate the infiltration rate and derive the excessive rainfall by applying the greem and ampt method in this study a total of 80 storm events in which 20 events were testing data were collected for cross validation of the rnn model all the storm events adopted in this study were brought by typhoons hydrological data were observed between 1974 and 2020 3 4 performance metrics to further quantify the precited accuracy of the rnn models three metrics including the pearson correlation coefficient pc mean relative error mre and the coefficient of determination r2 are applied to evaluate the performance of the predicted inundation depths they are calculated by the following equations 13 pc n p h pi h ti h pi h ti n p h pi 2 h pi 2 n p h ti 2 h ti 2 14 mre 1 n p i 1 n p h pi h ti h ti 15 r 2 1 i 1 n p h ti h pi 2 i 1 n p h ti h t 2 where h p is the predicted inundation depth yielded by the neural network model h t is the target inundation depth yielded by the numerical model n p is the total number of predicted values the value of pc normally ranges from 1 to 1 and it is used to measure the similarity between two lists of numbers when an absolute value of pc equals 1 the data objects are recognized as perfectly correlated r2 is a statistical measure ranging from 0 to 1 and it explains the strength of the relationship between two arrays of variables additionally an indicator denoted as rs is applied to calculate the rate of similarity between the predicted flood map and the flood map generated by the numerical model as follows 16 r s 1 n t t 1 n t n st n g 100 where n g is the total number of grids in the simulation area n st is the total number of grids possessing the same scale of inundation depth between the two flood maps at time t n t is the total number of time points of the flood event assigned in the neural network model this indicator also represents the correct rate to predict the level of inundation depth by applying the rnn model 4 results in the following sub sections verifications for the two hydrodynamic models are first provided and elaborated subsequently the performance of the proposed model for predicting the spatial distribution of inundation depth in the coastal floodplain area is overall evaluated 4 1 validation of the hydrodynamic models since the simulation results of the hydrodynamic models based on the governing equations were provided for the training of the rnn model developed in this study the numerical solutions separately yielded by the hydrologic inundation model and the storm surge model were needed to be confirmed beforehand by comparing them with the available records data of 12 rainstorm events was taken to calibrate the values of all parameters required in the models and 6 events were then adopted to verify the applicability of the numerical models fig 8 shows the simulated free surface elevations of two storm events and the observed tide levels induced by storm surges at the two sea level measuring stations as marked in fig 7 the results show that the changes in tidal level caused by the approaching of the tropical cyclone can be well described by the adcirc model the mean relative error mre of the six storm events can be less than 0 067 fig 9 shows the observed discharges and the simulated hydrographs of two storm events yielded by the hydrologic inundation model at two inland measuring stations as marked in fig 7 the results show that this hydrologic inundation model is capable of providing satisfactory and reliable simulation in comparison to the observed data the mre of the six storm events can be controlled within 0 049 4 2 assessment of flood inundation prediction in the coastal floodplain area fig 10 shows the comparisons of inundation depths between the numerical solutions target values and the predicted values of two rnn models for various regional classes as illustrated in fig 5 in fig 10 proposed represents the points obtained from the rnn model which applies the proposed data classification method according to the twi of each grid conventional represents the points obtained from the rnn model which is executed without data classification in advance in other words only one rnn model was trained with all the data without classification in the conventional approach six separate rnns were trained with classified data based on twi in the proposed method and the six separate predictions were then merged to get the final output inundation map in this study the hyperparameters such as the number of neurons in the hidden layer and the activation function were only tuned for the conventional approach to seeking the most satisfactory results subsequently the same settings of hyperparameters were assigned for the proposed approach since superior predictions were found by applying the proposed training approach no further adjustments were made to the hyperparameters as shown in fig 10 these data points representing the inundation depths at different grids were extracted from flooding maps separately generated by the three types of models in which the inputs of testing events were assigned data points of 20 testing events with a 3 hour time interval were selected and plotted in fig 10 the results show that the proposed training procedure can provide significantly superior performance as shown by the yellow purple and blue points for different regional classes which means more accurate predictions of inundation depth than the conventional procedure as shown by the black points the behavior of water depth distribution can be captured more precisely by separately training the model with the data in each class than training the model collectively fig 11 shows the charts of the three performance indicators for different data classes by analyzing the simulated results of all testing events separately executed by the two types of rnn models these values of indicators were calculated by comparing the numerical solutions which were adopted as the target values with the predicted results both rnn models produced satisfactory results in terms of pc which was consistently larger than 0 906 in addition the proposed training procedure can offer a significantly superior effect of reducing the value of mre with respect to the conventional training procedure indeed the mre decreased from 0 338 to 0 055 on average as shown in fig 11 the performance of the proposed rnn model in mre could be revealed obviously when the model was applied in the zones with lower twi such as the 1st 2nd and 3rd classes the value of r2 was consistently larger than 0 991 in executing the proposed training method which implies that approximately 99 1 of the variation of the target values can be explained by the proposed model such a result confirms the improved performance of the model the predicted results of the spatial distribution of inundation depth extracted at different time points of a testing event typhoon amber in 1997 are depicted in fig 12 together with the maps obtained from the numerical simulation and the conventional rnn method for comparison purposes the figure reports the observed rainfall pattern of typhoon amber the tidal level near the estuary and the spatial distributions of inundation depth at the 26th hour and 38th hour the magnitude of water depth shown in these maps is divided into 7 intervals from 0 m to more than 3 m the flooding maps yielded by the proposed rnn model are similar to those produced by the hydrologic inundation model based on saint venant equations at different times the similarity rate rs between the two maps namely the correct rate of predicting the scale of inundation depth over the whole studied area can reach an average of 97 8 among different times when the water depth is classified as the 7 intervals whereas the similarity rate between the maps obtained from the hydrologic inundation model and the conventional rnn model is only 64 4 on average as shown in table 1 the evaluation of computational costs by implementing the numerical inundation model and the proposed rnn model is also provided to show the efficiency of the ai based model compared to the numerical model for coastal floodplain simulation the size of the calculation time step is usually limited to maintain the numerical stability during flood simulations therefore the time step assigned in the numerical model is between 0 01 s and 30 s for the five testing events listed in table 1 whereas the ai based prediction model can be free of the restriction of the calculation time step in this study the proposed rnn model is executed to predict the flood map for the next hour it can be found in table 1 that the computational costs of the five flood events can be significantly reduced by applying the proposed rnn model to replace the numerical inundation model the calculation speed of the proposed rnn model is at least 322 times faster than that of the numerical model if the time step of the proposed rnn model is set as 1 h all the above results demonstrate that by integrating the rnn model with a variety of geomorphological parameters and training data separately on the basis of twi classes the proposed methodology can provide reliable information for flood inundation predictions in the coastal area during rainstorms its performance is comparable to the numerical solutions yielded by the hydrologic inundation model 5 discussion and conclusions this study aimed at developing a topography based prediction model for flooding simulation in the coastal floodplain area without using any type of numerical algorithm a dynamic neural network model was utilized to seek the optimal description of floodwater moving in the river basin by comprehensively deliberating the possible impact factors including upstream and downstream boundary conditions and various geomorphological characteristics the inflow condition that was collected from the upstream drainage area tide changes at the estuary and along the coastline induced by the storm surge and the rainfall distribution brought by typhoons were jointly considered to estimate inundation depths in the watershed moreover the new focus of this study was to further investigate the influence of all kinds of topographic indicators on coastal floodings such as local slope drainage area traveling length and the distances from a selected location to the main channel and the estuary along the flow path the topographic wetness index twi of each grid was advocated to classify the study area into multiple classes for the separative training of the neural network model results showed that the proposed rnn prediction model performed by this novel training procedure could effectively enhance the accuracy of predicted inundation depths the main outcomes of this study in different aspects of evaluation are elaborated in the following items in terms of the concise of model structure this study effectively applied the topographic data to extract useful geomorphological factors for the model training hence a complicated architecture of neural network algorithm was not necessarily to be utilized only a classic recurrent neural network method was able to yield satisfactory results of flood maps in terms of simulation accuracy the predicted flood maps which applied the proposed rnn model were found to be comparable to those generated by the hydrological numerical model the proposed training procedure can offer a significant effect to reduce the value of mre with respect to the conventional training procedure from 0 338 to 0 055 on average additionally the correct rate in predicting the scale of inundation depth which was divided into 7 intervals was able to enhance from 64 4 to 97 8 on average over the whole river basin in terms of computational stability any type of numerical instability or oscillation that may encounter in executing numerical algorithms can be erased by using the proposed ai based flood prediction model in terms of physical meanings different hydrological and geomorphological features were extracted and adopted as model inputs to emphasize their influences on the spatial and temporal distribution of floods moreover to accurately describe the flow responses in different regions various scales of inundation depth among grids were classified by using the topographic wetness index for respective training in terms of computational efficiency to maintain the numerical stability during flood simulations the calculation time step is usually restricted when the numerical model is applied to the topographic data with a higher horizontal resolution the proposed ai based prediction model can be an alternative method to overcome the limitation of the calculation time step and to reduce the computational cost results of five flood events applied in this study showed that the calculation speed of the proposed rnn model can be at least 322 times faster than that of the numerical inundation model if the time step of the proposed rnn model is set as 1 h the above research findings revealed that the proposed prediction model could be a promising way to replace the complicated numerical models for the real time flooding simulation in the coastal area credit authorship contribution statement pin chun huang conceptualization methodology software validation formal analysis investigation writing original draft writing review editing visualization data curation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments financial support provided by the ministry of science and technology taiwan under grant most 110 2625 m 019 001 is sincerely acknowledged 
3583,the extent of coastal flooding is influenced by many factors such as the topography of the low lying land tidal level rainfall pattern inflow discharge collected from the upstream drainage area etc this study establishes a new methodology of effectively predicting the flooding process in coastal areas and which is achieved by combining the recurrent neural network rnn model with the detailed analysis of different hydrological and geomorphological factors the novelty of this study is to apply the topographic wetness index twi of each grid to classify all inputs into multiple classes for separative training to improve the overall accuracy of flooding simulations a numerical inundation model based on hydrodynamic equations was applied to investigate the behavior of coastal flooding in the temporal and spatial domain under a variety of model settings with different hydrologic conditions and it was utilized to generate the target inundation depths for the training of the rnn model the relevance between the downstream topography tidal level rainfall intensity and the spatial distribution of flooding in coastal areas is explored via the use of machine learning ml techniques the focus of this study is to evaluate the proposed alternative method that allows for improving the efficiency and stability of forecasting coastal floods caused by rains and storm surges due to the approaching tropical cyclones the method developed in this study is promising to replace the numerical inundation model to reinforce the model s stability and computational efficiency keywords floodplain inundation coastal flooding storm surge topographic wetness index geomorphological characteristics recurrent neural network model 1 introduction flooding in coastal areas normally occurs when dry and low lying land is submerged by seawater or overland flow resulting from heavy rainfall ramsay and bell 2008 coastal flooding whose extent is controlled by the topography of the coastal land kulp and strauss 2019 and the difference in water surface elevation among adjacent regions is caused by floodwater from the sea and rivers inundating the inland most of the available methodologies for coastal flooding simulations rely on hydrodynamic models and require digital elevation models dems previous studies have indicated that the accuracy of coastal floodplain simulation is sensitive to the dem resolution adopted in the hydrodynamic model thus high resolution topographic data is demanded to capture the more realistic landform and analyze the flooding in low lying land in detail bates et al 2003 gallegos et al 2009 however computing efficiency would be compromised especially when numerical models in which the computational time interval is restrained by the stability condition are applied for simulating inundation on the coastal floodplain area hunter et al 2005 bates et al 2010 huang and lee 2013 2017 the primary motivation of this study is to seek other alternatives to replace the use of numerical algorithms on the other hand the need for a better understanding of the spatial and temporal dynamics of floodwater is more urgent considering the impacts of climate change which has been indicated to induce the global sea level rise and population growth in many countries intensifying flood damages and calling for a global interest in founding out different flood assessment and management approaches vankoningsveld et al 2008 nerem et al 2018 nevertheless related studies have reported that most existing floodplains were analyzed by merely using rainfall as an input in hydrological models but not considering the impact of cyclone induced storm surge on the coastal area ray et al 2011 budiyono et al 2016 hamman et al 2016 eccles et al 2021 in that case flooding simulations would be limited to regional scale and such an approach lacks the overall considerations for the floodwater occurring in the whole basin previous articles also revealed that the timing of both rainfall and the storm surge play a significant role in the extent of inland flooding ray et al 2011 this finding therefore motivates this study to devise a new analysis method which can more comprehensively take into account multiple factors such as boundary conditions and geomorphological characteristics that may influence the results of flooding simulations to come up with a more robust flood forecasting method associated studies about the simulation of floodplains or coastal flooding have been continuously discussed in the recent two decades bilskie et al 2014 utilized numerical models to analyze the mississippi and alabama coast and simulate the response of hurricane storm surge to changes in sea level land use and land surface elevation they indicated that the storm surge response to sea level rise is dynamic and sensitive to changes in the landscape poulter and halpin 2008 applied lidar elevation data in the coastal area to investigate the effects of horizontal resolution and connectivity on the extent and timing of flooding resulting from sea level rise they found that the rate and extent of inundation were dependent on horizontal resolution and assumptions made on hydrological connectivity ray et al 2011 adopted one dimensional dynamic hydraulic modeling to analyze the combined effects of storm surge and inland rainfall on the floodplain of a coastal bayou in the houston area olbert et al 2017 applied an integrated flood modeling system comprising of an ocean model and a coastal flood model to investigate mechanisms of flooding resulting from multiple process drivers and evaluate flood risk to human safety such an approach gave a better understating of the dynamics of complex coastal urban flooding and would therefore facilitate coastal management in addition to applying hydrodynamic numerical models researchers have also developed other alternatives to simulate floodplain dynamics narayan et al 2012 proposed a holistic graphical model for coastal flooding by using system diagrams and the source pathway receptor spr concept to structure the understanding of large and complex floodplains in recent years machine learning ml methods have been widely applied to facilitate flood prediction bass and bedient 2018 developed an artificial intelligence ai based surrogate model to rapidly represent peak inundation due to the joint occurrence and interaction between rainfall runoff and storm surge from tropical cyclones bermúdez et al 2019 built a non parametric regression model based on least squares support vector machines ls svms as a computationally efficient surrogate of two dimensional shallow water equations for flood inundation mapping zahura et al 2020 advocated training a surrogate model to relate topographic and environmental features to hourly water depths simulated by a physics based model at road segments in the coastal city of the usa in their method the topographic wetness index twi was directly adopted as model input compared with the methodology proposed by zahura et al 2020 this study further considers the impact of storm surge on flood inundation and the twi is jointly applied to classify the input data into multiple classes for separative training of the surrogate model to enhance the overall accuracy of 2d inundation prediction the objective of this study is to develop an alternative method for coastal flooding predictions based on the application of geomorphological characteristics and the improvement of the training process for an artificial intelligence tool to avoid any forms of numerical problems such as calculation instability or inefficiency we first investigate the influence of all the factors i e the downstream topography tidal level rainfall intensity on the spatial distribution of flooding in the coastal floodplain area a variety of geomorphological factors extracted from the original topographic data are explored thoroughly and then adopted as the important indexes to estimate the flooding depths during rainstorms it has been pointed out that the application of the digital terrain model and set of terrain analysis procedures is capable of identifying floodplain boundaries and this approach obtained consistent results with floodplain delineations derived by flood hazard models nardi et al 2019 grimaldi et al 2013 applied detailed topographic information to establish a fully continuous hydrologic hydraulic modeling framework for flood mapping to avoid the use of the design hyetograph and the design hydrograph that constitute the main source of subjective analysis and uncertainty manfreda et al 2014 utilized three different geomorphic approaches to identify flood prone areas through a comparative analysis of the input parameters and the range of applicability in this study a machine learning ml tool called recurrent neural network rnn is applied to construct the optimal connections between all possible influencing factors and the flooding depth at any location within the studied watershed although ml methods have been widely used for hydrological applications or associated simulations of the flow field the novelty of this article is to propose a new training procedure by considering more geomorphological factors such as the local upslope contributing area the length of the flow path from the furthest point to a selected location and the length of the flow path from a selected location to the coastline these factors are considered to have physical significance to explain the influence of coastal landform on the inundation depth to effectively and accurately describe the temporal and spatial behavior of floodwater on the land surface a classification method according to the terrain characteristics is devised to facilitate the establishment of an ml based prediction model for coastal floodplain simulations in which the complicated numerical algorithms can be exempted 2 study area the applicability of the proposed ml based prediction model to simulate flooding in coastal floodplain areas was investigated considering two adjacent river basins namely the touqian and fengshan river basins located in north western taiwan as shown in fig 1 the two river basins are adjacent both of their mainstreams originate from the xueshan mountain range and merge westward into the same estuary the nanliao harbor of hsinchu city which belongs to the taiwan strait the total drainage area of the touqian river basin is about 544 km2 and the mainstream of this watershed has a total length of 63 km the network of mainstreams in this watershed consists of two upstream branches yulo river and shangping river and a downstream channel touqian river the total drainage area of the fengshan river basin is approximately 250 km2 and the total length of the mainstream in this watershed is about 45 km the major land covers in the two river basins are forests shrubs and cultivated fields according to the information reported by the water resources department ministry of economic affairs in taiwan there are currently 4 rain gauges and 5 flow gauges installed in the touqian river basin and 2 rain gauges and 2 flow gauges in the fengshan river basin the average annual rainfall of this river basin measured at the hsinchu station is 1747 mm affected by the periodic southwest monsoon and typhoon the annual precipitation is unevenly distributed in time and space the rainy season usually occurs from june to september during summer and autumn typhoons often invade taiwan island and usually bring torrential rains which lead to severe floods or associated natural hazards and even threaten the lives of inland residents the peak discharge of the 20 year return period at the downstream main channel has reached 4810 m3 s which approximates to the extent of the 200 year return period analyzed from the data before 1993 therefore it is conceivable that the flood hazard is more destructive as reported by the water resources department of taiwan the low lying lands in the coastal floodplain areas of the two river basins are prone to flooding due to the changes in tidal level induced by the tropical cyclone and the local terrain condition inherent in the two jointed river basins 3 methodology although the objective of this study is not to explore the applicability of hydrologic and hydraulic models for coastal flooding simulations associated numerical algorithms and well developed models are utilized to generate different flooding scenarios showing the temporal and spatial variations of inundated depth under various hydrologic conditions these data are collected and provided for the training of the ml based prediction model since the available inundation records in the studied areas are lacking in the following content the theoretical governing equations of the hydrodynamic models the proposed topography based prediction model for coastal flooding simulations and the details of the model settings about the initial and boundary conditions are sequentially explained 3 1 hydrologic and hydraulic modeling based on numerical algorithms for the current study a storm surge model and a hydrologic inundation model were integrated to perform the flooding simulations which are simultaneously affected by the inland rainfall and the abnormal rise in seawater level during a typhoon these two types of numerical models are respectively explained in the following sub sections 3 1 1 storm surge model the advanced circulation adcirc coastal circulation and storm surge model developed by luettich et al 1992 and westerink et al 1994 is used to estimate water surface elevations and currents the two dimensional depth integrated version often named adcirc 2ddi was selected in this study to solve generalized wave continuity equations on an unstructured triangular mesh with a continuous galerkin finite element method fem the governing equations in spherical coordinates are as follows 2 ζ t 1 r e cos φ uh λ vh cos φ φ 0 u t u r e cos φ u λ v r e u φ tan φ r e u f v 1 r e cos φ λ p s ρ 0 g ζ α η υ t h λ uh λ vh φ τ s λ ρ 0 h τ u 3 v t u r e cos φ v λ v r e v φ tan φ r e u f u 1 r e φ p s ρ 0 g ζ α η υ t h φ vh λ vh φ τ s φ ρ 0 h τ v where t is time λ and φ are respectively longitude and latitude ζ is the free surface elevation relative to the geoid u and v are depth integrated velocity components in west east and south north directions respectively h is the total water depth r e is the radius of the earth f is the coriolis parameter p s is the atmospheric pressure at the free surface ρ s is the reference density of water g is gravitational acceleration α is the effective earth elasticity factor η is the newtonian equilibrium tide potential υ t is the depth averaged horizontal eddy viscosity coefficient τ s λ and τ s φ are the surface wind stresses in longitudinal and latitudinal directions respectively which can be computed by a standard quadratic air sea drag law τ is the bottom friction term 3 1 2 hydrological inundation model a distributed rainfall runoff model was applied to perform inundation simulations in the coastal floodplain area it calculates the discharge and flooding depth at every grid based on the inputs of precipitation boundary conditions and topographic data of the watershed saint venant shallow water equations have been widely adopted to describe the transmission of surface runoff and they can be expressed as 4 a t q x i e δ x 5 q t x q 2 a g a h z x g n o 2 q 2 r 4 3 a 0 where q is the discharge a is the flow cross section area ie is the excessive rainfall intensity δ x is the grid size of the raster elevation data h is the water depth z is the bed elevation r is the hydraulic radius no is the manning roughness coefficient in this study the determination of flow direction for each grid follows the steepest gradient of the water surface elevation among eight adjacent grids wang and hjelmfelt 1998 kuiry et al 2010 huang and lee 2013 2017 previous studies advocated using an inertial momentum equation in which the convective acceleration term in the saint venant equations is omitted to effectively alleviate numerical oscillation and maintain the simulated accuracy simultaneously hunter et al 2008 bates et al 2010 according to this simplification bates et al 2010 reformulated the momentum equation as follows 6 q t δ t q t g h t δ t δ t h t z x 1 g h t δ t δ t n o 2 q t h t δ t 10 3 where q is the discharge per unit width this approach has been confirmed to have the utility of improving the stability of 2d floodplain inundation simulations bates et al 2010 huang and lee 2017 thus this hydrological model for analyzing the unsteady overland flow was utilized to consider the time dependent inland rainfall and the boundary conditions affected by the storm surge during a typhoon to derive excessive rainfall from the original precipitation data the green and ampt method 1911 was adopted to estimate the infiltration rate which can be expressed as 7 f t k s k s ψ f θ s θ i f f o r t t p 8 f t i o f o r t t p where k s is the saturated hydraulic conductivity cm h ψ f is the suction head at the wetting front cm θ s is the saturated moisture content θ i is the initial moisture content f is the cumulative amount of infiltrated water cm t p is the time of ponding i o is the observed rainfall rate cm h in this method a sharp wetting front is assumed to form when water penetrates a relatively dry soil layer from the land surface and its physical mechanism of infiltration depends on the soil characteristics 3 2 topography based prediction model for coastal flooding simulations in the following sub sections the fundamental structure of the machine learning algorithm the influential factors considered in this study and a novel training procedure according to the topographic feature are separately elaborated 3 2 1 structure of machine learning tools an artificial intelligence algorithm the recurrent neural network rnn was applied in this study to set up the relationship between the influential factors and the single output namely the time series of inundation depth at each grid the rnn algorithm is a kind of dynamic neural network method devised to take into account the temporal behavior of input data so it has been indicated to be suitable for predicting a time series fig 2 shows the architecture of rnn which consists of three layers with internal time delay feedback loops in both hidden and output layers the output of neuron j in the hidden layer following the architecture of rnn can be expressed as 9 y j t δ t f i 1 i w ini x i t m 1 m w unm y m t where i is equal to the total number of neurons influential factors assigned in the input layer m j which is equal to the total number of neurons assigned in the hidden layer f denotes the activation function x i t denotes the input of neuron i at time t y j t denotes the output of the hidden neuron j at time t w ini denotes the connection weight from the neuron i of the input layer to the neuron j of the hidden layer w unm denotes the feedback weight from the time delay unit m to the neuron j of the hidden layer the network output of neuron k in the output layer at time t δ t is given by 10 o k t δ t f j 1 j w hdj y j t δ t p 1 p w uop o p t where p k 1 which is equal to the number of predicted variables at each time step w hdj denotes the connection weight from the neuron j of the hidden layer to the output neuron k w uop denotes the feedback weight from the time delay unit p to the output neuron k hence the output of predicted inundation depth at time t δ t can be derived by 11 h t δ t o 1 t δ t where h represents the predicted inundation depth in the structure of the rnn the feedback links added in the static neural network are used to allow signals to propagate in both forward and backward directions the time delay units can provide the hidden dynamic memories for the training of neural networks hence they are regarded as additional inputs to retain the previous output information of each neuron from the hidden and output layers in this study the sigmoid activation function was adopted in the neural network algorithm to perform the nonlinear transformation the first order iterative optimization algorithm named gradient descent was chosen to seek the minimum of predicted error 3 2 2 influential factors and data inputs to emphasize the physical meaning of the proposed neural network model for predicting the floodplain inundation the extraction of geomorphological parameters from the topographic data and the use of hydrological factors represent a significant step in this study that facilitate the training work and build the prediction model in particular the parameters associated with topographic characteristics are considered important information to evaluate the hydrological response at a designated grid in the watershed under study as shown in fig 3 a total of 10 influential factors was adopted as the inputs of the rnn model including 3 hydrological factors and 7 geomorphological factors the three hydrological factors are respectively the rainfall intensities ir over the past tp hours the free surface elevation of the tide et on the coastline which varies with the periodic tide and storm surge the discharge at the inflow section of the main channel qin it should be noted that the value of tp is related to the time of concentration of the watershed the seven geomorphological factors are explained accordingly as follows the surface roughness coefficient of an overland grid no which depends on the vegetation and land cover patterns the land surface elevation el the local terrain slope of the ground surface so the local upslope contributing area of an overland grid ad which indicates the ability to collect water from its upstream area and can be derived by utilizing the flow accumulation value that is defined in the digital elevation model the longest length ld from the furthest point on the boundary of ad to a selected location along the flow path assigned by the digital elevation model this parameter has been denoted to be relevant to the time to peak flow huang and lee 2016 the length of the flow path from a selected location to the first channel grid encountered lc as shown by the schematic diagram in fig 4 and the length of the flow path from a selected location to the estuary or coastline ls the aforementioned geomorphological factors can easily be extracted in advance from the topographic data derived from the dem 3 2 3 regional classification and training procedure to describe the behavior of inundation depth changes in more detail a classification method according to the topographic wetness index twi of each grid was employed in this study to divide the studied watershed into multiple regions the topographic wetness index developed by beven and kirkby 1979 is defined as 12 twi ln a d s o where ad is the local upslope contributing area per unit contour length twi is a steady state wetness indicator devised to quantify topographic control on hydrological processes sørensen et al 2006 since the magnitude of inundation depth is simultaneously affected by the upstream contributing area ad and the local slope so twi was considered as an indicator to denote the ability to accumulate water depth by using this way to classify the watershed into multiple regions the grids with similar scales of depth can be trained together the spatial distribution of the twi in the study area is depicted in the upper graph of fig 5 the study area is further partitioned according to the intrinsic distribution of twi extracted from the elevation dataset of the river basin by applying the k means clustering analysis hartigan and wong 1979 and 5 was found to be the optimal number of clusters in this case therefore all grids in the study area are divided into 5 classes as shown in the lower graph of fig 5 the optimal number of classes needs to be investigated before the model training and it depends on the watershed topography on the other hand the area belonging to the main channel as shown by the red zone in the lower graph of fig 5 was additionally categorized as the 6th class for individual arrangement it should be noted that both the spatial distribution of twi and the main channel grids can be extracted by applying the digital elevation model although twi is a function of the upstream contributing area ad and the local slope so it is not suggested to replace the two variables ad and so and merge them as a single input factor since the impacts of the upstream contributing area and the local slope on the inundation depth can change during a flood event these two variables are separately assigned as influential factors of the ai model as shown in fig 3 as shown in fig 6 a series of preparation works were required before training the proposed rnn model the numerical storm surge model was applied to produce tidal levels along the coastal line as the boundary conditions for implementing the numerical inundation model the numerical inundation model was then used to generate numerous flood maps as the target inundation depths for the training of the proposed rnn model the digital elevation model was utilized to extract all the required geomorphological factors as the inputs of the proposed rnn model and the topographic wetness index twi of each grid as shown by the flow chart of fig 6 the whole simulation domain was first partitioned and classified according to the twi of each grid and then the input factors belonging to the same class were assigned to the same rnn model in this study the training of the rnn model was separately executed for each twi class to manipulate the spatial and temporal variation of inundation depth more preciously therefore in this study case a total of six rnn models was required to be established for generating flood maps that show inundation depths of all girds within the simulation area the respective training of the rnn model can be carried out by assigning the corresponding inputs and target outputs it should be noted that the factor qin is only adopted to train the rnn model for the grids belonging to the main channel since it represents the discharge at the inflow section the holdout cross validation cv method was adopted in this study to verify the rnn model by randomly selecting 25 of the dataset as the testing data and training the model with the remaining data to highlight the ability of the proposed training method in enhancing the accuracy of the flood prediction model simulation results of three models are provided for performance evaluation the models considered are the hydrologic inundation model the rnn model obtained from the proposed procedure which applies the data classification according to the twi of each grid and the rnn model executed without data classification in advance 3 3 model settings and training setups as informed by the associated reports only the downstream coastal floodplain areas of the touqian and fengshan river basins are flood prone regions therefore the area marked by green as shown in fig 7 was adopted as the inundation simulation domain and analyzed in this research the horizontal resolution of topographic data applied to implement the hydrologic model and the prediction model is 20 m and the total number of grids contained in the computational domain is 3 922 686 the discharge records measured at the jing guo and the xin pu stations were adopted as the inflow boundary conditions and this volume flow rate was collected from their respective upstream contributing area marked by red and blue the initial condition of the overland area grids was assumed as a dry surface and the steady discharge was assigned in the hydraulic model to provide the initial depths for the grids of the main channel marked by light blue the free surface elevations along the coastline yielded by the adcirc model were adopted as the downstream boundary conditions since the soil type in the study area is sandy loam the saturated hydraulic conductivity was set as 1 14 cm h the suction head at the wetting front was set as 9 cm and the saturated moisture content was set as 0 48 to estimate the infiltration rate and derive the excessive rainfall by applying the greem and ampt method in this study a total of 80 storm events in which 20 events were testing data were collected for cross validation of the rnn model all the storm events adopted in this study were brought by typhoons hydrological data were observed between 1974 and 2020 3 4 performance metrics to further quantify the precited accuracy of the rnn models three metrics including the pearson correlation coefficient pc mean relative error mre and the coefficient of determination r2 are applied to evaluate the performance of the predicted inundation depths they are calculated by the following equations 13 pc n p h pi h ti h pi h ti n p h pi 2 h pi 2 n p h ti 2 h ti 2 14 mre 1 n p i 1 n p h pi h ti h ti 15 r 2 1 i 1 n p h ti h pi 2 i 1 n p h ti h t 2 where h p is the predicted inundation depth yielded by the neural network model h t is the target inundation depth yielded by the numerical model n p is the total number of predicted values the value of pc normally ranges from 1 to 1 and it is used to measure the similarity between two lists of numbers when an absolute value of pc equals 1 the data objects are recognized as perfectly correlated r2 is a statistical measure ranging from 0 to 1 and it explains the strength of the relationship between two arrays of variables additionally an indicator denoted as rs is applied to calculate the rate of similarity between the predicted flood map and the flood map generated by the numerical model as follows 16 r s 1 n t t 1 n t n st n g 100 where n g is the total number of grids in the simulation area n st is the total number of grids possessing the same scale of inundation depth between the two flood maps at time t n t is the total number of time points of the flood event assigned in the neural network model this indicator also represents the correct rate to predict the level of inundation depth by applying the rnn model 4 results in the following sub sections verifications for the two hydrodynamic models are first provided and elaborated subsequently the performance of the proposed model for predicting the spatial distribution of inundation depth in the coastal floodplain area is overall evaluated 4 1 validation of the hydrodynamic models since the simulation results of the hydrodynamic models based on the governing equations were provided for the training of the rnn model developed in this study the numerical solutions separately yielded by the hydrologic inundation model and the storm surge model were needed to be confirmed beforehand by comparing them with the available records data of 12 rainstorm events was taken to calibrate the values of all parameters required in the models and 6 events were then adopted to verify the applicability of the numerical models fig 8 shows the simulated free surface elevations of two storm events and the observed tide levels induced by storm surges at the two sea level measuring stations as marked in fig 7 the results show that the changes in tidal level caused by the approaching of the tropical cyclone can be well described by the adcirc model the mean relative error mre of the six storm events can be less than 0 067 fig 9 shows the observed discharges and the simulated hydrographs of two storm events yielded by the hydrologic inundation model at two inland measuring stations as marked in fig 7 the results show that this hydrologic inundation model is capable of providing satisfactory and reliable simulation in comparison to the observed data the mre of the six storm events can be controlled within 0 049 4 2 assessment of flood inundation prediction in the coastal floodplain area fig 10 shows the comparisons of inundation depths between the numerical solutions target values and the predicted values of two rnn models for various regional classes as illustrated in fig 5 in fig 10 proposed represents the points obtained from the rnn model which applies the proposed data classification method according to the twi of each grid conventional represents the points obtained from the rnn model which is executed without data classification in advance in other words only one rnn model was trained with all the data without classification in the conventional approach six separate rnns were trained with classified data based on twi in the proposed method and the six separate predictions were then merged to get the final output inundation map in this study the hyperparameters such as the number of neurons in the hidden layer and the activation function were only tuned for the conventional approach to seeking the most satisfactory results subsequently the same settings of hyperparameters were assigned for the proposed approach since superior predictions were found by applying the proposed training approach no further adjustments were made to the hyperparameters as shown in fig 10 these data points representing the inundation depths at different grids were extracted from flooding maps separately generated by the three types of models in which the inputs of testing events were assigned data points of 20 testing events with a 3 hour time interval were selected and plotted in fig 10 the results show that the proposed training procedure can provide significantly superior performance as shown by the yellow purple and blue points for different regional classes which means more accurate predictions of inundation depth than the conventional procedure as shown by the black points the behavior of water depth distribution can be captured more precisely by separately training the model with the data in each class than training the model collectively fig 11 shows the charts of the three performance indicators for different data classes by analyzing the simulated results of all testing events separately executed by the two types of rnn models these values of indicators were calculated by comparing the numerical solutions which were adopted as the target values with the predicted results both rnn models produced satisfactory results in terms of pc which was consistently larger than 0 906 in addition the proposed training procedure can offer a significantly superior effect of reducing the value of mre with respect to the conventional training procedure indeed the mre decreased from 0 338 to 0 055 on average as shown in fig 11 the performance of the proposed rnn model in mre could be revealed obviously when the model was applied in the zones with lower twi such as the 1st 2nd and 3rd classes the value of r2 was consistently larger than 0 991 in executing the proposed training method which implies that approximately 99 1 of the variation of the target values can be explained by the proposed model such a result confirms the improved performance of the model the predicted results of the spatial distribution of inundation depth extracted at different time points of a testing event typhoon amber in 1997 are depicted in fig 12 together with the maps obtained from the numerical simulation and the conventional rnn method for comparison purposes the figure reports the observed rainfall pattern of typhoon amber the tidal level near the estuary and the spatial distributions of inundation depth at the 26th hour and 38th hour the magnitude of water depth shown in these maps is divided into 7 intervals from 0 m to more than 3 m the flooding maps yielded by the proposed rnn model are similar to those produced by the hydrologic inundation model based on saint venant equations at different times the similarity rate rs between the two maps namely the correct rate of predicting the scale of inundation depth over the whole studied area can reach an average of 97 8 among different times when the water depth is classified as the 7 intervals whereas the similarity rate between the maps obtained from the hydrologic inundation model and the conventional rnn model is only 64 4 on average as shown in table 1 the evaluation of computational costs by implementing the numerical inundation model and the proposed rnn model is also provided to show the efficiency of the ai based model compared to the numerical model for coastal floodplain simulation the size of the calculation time step is usually limited to maintain the numerical stability during flood simulations therefore the time step assigned in the numerical model is between 0 01 s and 30 s for the five testing events listed in table 1 whereas the ai based prediction model can be free of the restriction of the calculation time step in this study the proposed rnn model is executed to predict the flood map for the next hour it can be found in table 1 that the computational costs of the five flood events can be significantly reduced by applying the proposed rnn model to replace the numerical inundation model the calculation speed of the proposed rnn model is at least 322 times faster than that of the numerical model if the time step of the proposed rnn model is set as 1 h all the above results demonstrate that by integrating the rnn model with a variety of geomorphological parameters and training data separately on the basis of twi classes the proposed methodology can provide reliable information for flood inundation predictions in the coastal area during rainstorms its performance is comparable to the numerical solutions yielded by the hydrologic inundation model 5 discussion and conclusions this study aimed at developing a topography based prediction model for flooding simulation in the coastal floodplain area without using any type of numerical algorithm a dynamic neural network model was utilized to seek the optimal description of floodwater moving in the river basin by comprehensively deliberating the possible impact factors including upstream and downstream boundary conditions and various geomorphological characteristics the inflow condition that was collected from the upstream drainage area tide changes at the estuary and along the coastline induced by the storm surge and the rainfall distribution brought by typhoons were jointly considered to estimate inundation depths in the watershed moreover the new focus of this study was to further investigate the influence of all kinds of topographic indicators on coastal floodings such as local slope drainage area traveling length and the distances from a selected location to the main channel and the estuary along the flow path the topographic wetness index twi of each grid was advocated to classify the study area into multiple classes for the separative training of the neural network model results showed that the proposed rnn prediction model performed by this novel training procedure could effectively enhance the accuracy of predicted inundation depths the main outcomes of this study in different aspects of evaluation are elaborated in the following items in terms of the concise of model structure this study effectively applied the topographic data to extract useful geomorphological factors for the model training hence a complicated architecture of neural network algorithm was not necessarily to be utilized only a classic recurrent neural network method was able to yield satisfactory results of flood maps in terms of simulation accuracy the predicted flood maps which applied the proposed rnn model were found to be comparable to those generated by the hydrological numerical model the proposed training procedure can offer a significant effect to reduce the value of mre with respect to the conventional training procedure from 0 338 to 0 055 on average additionally the correct rate in predicting the scale of inundation depth which was divided into 7 intervals was able to enhance from 64 4 to 97 8 on average over the whole river basin in terms of computational stability any type of numerical instability or oscillation that may encounter in executing numerical algorithms can be erased by using the proposed ai based flood prediction model in terms of physical meanings different hydrological and geomorphological features were extracted and adopted as model inputs to emphasize their influences on the spatial and temporal distribution of floods moreover to accurately describe the flow responses in different regions various scales of inundation depth among grids were classified by using the topographic wetness index for respective training in terms of computational efficiency to maintain the numerical stability during flood simulations the calculation time step is usually restricted when the numerical model is applied to the topographic data with a higher horizontal resolution the proposed ai based prediction model can be an alternative method to overcome the limitation of the calculation time step and to reduce the computational cost results of five flood events applied in this study showed that the calculation speed of the proposed rnn model can be at least 322 times faster than that of the numerical inundation model if the time step of the proposed rnn model is set as 1 h the above research findings revealed that the proposed prediction model could be a promising way to replace the complicated numerical models for the real time flooding simulation in the coastal area credit authorship contribution statement pin chun huang conceptualization methodology software validation formal analysis investigation writing original draft writing review editing visualization data curation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments financial support provided by the ministry of science and technology taiwan under grant most 110 2625 m 019 001 is sincerely acknowledged 
3584,mid winter breakups mwbs consisting of the early breakup of the winter river ice cover before the typical spring breakup season are becoming increasingly common events in cold region rivers these events can lead to potentially severe flooding while also altering the expected spring flow regime yet data on these events is limited in this study a newly released canadian river ice database crid containing river ice data from 196 rivers across canada obtained from time series analysis was used to analyse these mwbs on a previously impossible national scale the crid data was combined with the natural resources canada nrcan gridded daily climate dataset to identify a list of potential hydrologic and climatic drivers for mwb events techniques such as correlation analysis least absolute selection shrinkage operator lasso regression and input omission were combined to select 20 key drivers of the severity of mwb events a random forest model that was trained with these drivers using data driven modelling techniques successfully classified the mwbs as either low medium or high severity achieving an overall accuracy of 80 a new threshold for the prediction of mwb initiation based on climatic conditions was subsequently proposed through the use of optimization via an exhaustive grid search and its accuracy in identifying mwbs exceeded those proposed by previous studies the new threshold used in conjunction with the random forest model provide valuable tools for both the prediction of mwbs and the assessment of their potential severity keywords river ice breakup flooding prediction data driven modelling time series analysis 1 introduction river ice formation and breakups are a yearly phenomena on many canadian rivers and are often source of the highest annual flows in recent years there has been an increasing risk of mid winter breakups mwbs which are the early breakup of a river ice cover before winter ends beltaos et al 2003 these typically result from unseasonably high temperatures and are followed by temperatures returning to typical seasonal values and the reformation of an ice cover in addition to exposing the river to higher than usual flows more than once per season they also carry the risk of producing ice jams where broken river ice becomes restricted in the channel leading to a damming effect on flows massie et al 2002 beltaos 2002 rokaya et al 2018 there is the potential for these jams to freeze in place when temperatures return to seasonal levels creating a semi permanent dam on the river beltaos 2003 further these events alter the subsequent spring breakup on the river greatly affecting the expected flow regime by reducing expected flows which can have impacts on the hydrology and ecosystem of downstream basins beltaos et al 2006 many studies have noted the increasing frequency of these events throughout north america prowse et al 2002 huntington et al 2003 carr and vuyovich 2014 because of this it is of great interest to develop a better understanding of the key factors both at the start of the ice season and before melt occurs that can trigger a mwb and their effect on the severity of the resulting mwb several past studies have applied large scale data analysis techniques to the spring breakup of river ice cover for example de rham et al 2008a investigated annual high water events in the mackenzie river basin investigating the spatial distribution of open water and breakup dominated high flows they concluded that high water events in the southern portion of the basin were dominated by open water flows while those in the north were dominated by spring breakup flows this was further investigated through a spatiotemporal analysis of the last ice affected dates of 29 water survey of canada wsc gauges in the basin de rham et al 2008b through the extraction of the breakup and peak water levels and subsequent trend analysis it was found that the timing of breakup is trending earlier throughout the basin with longer breakup periods expected goulding et al 2009a examined the drivers of breakup and ice jamming in the mackenzie delta through time series inspection trend analysis using mann kendall and sen s slope revealed that the peak stage in the delta was most influenced by upstream discharge while timing of breakup was most influenced by ice conditions such as thickness and the speed of melt and that breakups in the delta were trending towards longer melts lower peaks and earlier timing further research incorporating spatial mapping and analysis of both ice driven and open water driven peak flows reinforced these conclusions goulding et al 2009b while these papers investigated the drivers and trends in breakup they were focussed largely on single regions within the country and investigated only spring breakup and open water events past studies on the phenomena of mwbs have looked at these events in a generalized sense emphasizing their increasing frequency but due to the lack of readily available data were unable to do any detailed modeling beltaos 1999 provided an overview of the effects of climate change on the saint john rivers ice breakup regime it was noted that there was an increase in mild winter days over the past 80 years with a trend of spring breakup occurring earlier that was tied to an increase of mid winter breakup events carrying a risk of ice jams freezing in place and flooding beltaos and prowse 2009 investigated the impacts of climate change on the timing and severity of ice events including breakup and ice jamming their findings indicated a trend towards shorter ice seasons and earlier breakups with the potential for mid winter ice jams increasing as a result further it was found that the changes to breakups occurring both in mid winter and in spring would be driven by changes in warming rates and snowpack depths with potentially severe environmental impacts both to habitats and hydrology research has also been conducted on mwb severity and drivers with varying levels of success prowse et al 2002 investigated the drivers of mwbs focussing on the effects of temperature in triggering these events they defined a climatic threshold of 25 melting degree days mdd the sum of temperatures over 0 over 7 days as a major trigger for breakups similarly carr and vuyovich 2014 also defined a threshold for the trigger of an mwb their threshold considered temperature as well as precipitation with values of 8 mdd or 2 8 mm of rain over a period of 5 days both of these thresholds were investigated by newton et al 2017 in their study of the hydro climatic drivers of mwbs in western canada in this study a database compiled from gauges on 90 unregulated rivers was used to study the influence of daily temperature and precipitation on mwbs in 5 different climate regions with a larger temperate region defined as the area where solid sufficiently thick ice cover is expected to form while still being susceptible to mid winter warm spells in total 52 mwbs were identified from 21 rivers in the considered region the climate conditions preceding these mwbs were then compared to the thresholds proposed by prowse et al 2002 and carr and vuyovich 2014 finding that the first threshold was inaccurate only accurately predicting 11 of the mwbs while the second was more accurate predicting 60 of all mwbs while the results of this research were promising it was limited both by the quantity of data s and in the scale of the considered region only including the western coast of the country machine learning techniques have been previously applied to model and predict a variety of river ice phenomena white 1996 massie et al 2002 and mahabir et al 2006 utilised logistic regression artificial neural networks and hybrid neuro fuzzy systems for the prediction of ice jam timing on rivers however they encountered issues related to the availability of data spring breakup has also been modeled using techniques such as artificial neural networks guo et al 2018 yang et al 2021 zhao et al 2012 adaptive neuro fuzzy inference systems balogun et al 2020 sun and trevor 2018 wang et al 2012 sun and trevor 2015 stacking ensembles sun 2018 and support vector machines wang et al 2010 barzegar et al 2019 these studies often focus on predicting the water levels or ice thicknesses associated with these events however some have focused on the specific timing of spring breakup with data availability often being a limiting factor in the results this study focuses on the application of return period analysis statistical and spatial analysis and machine learning techniques to investigate the primary drivers of mwbs and predict the severity of mwbs on a national scale the study was facilitated through the use of a newly developed river ice dataset containing data on 458 mwbs occurring throughout the country through this investigation a generalised set of key indicators of mwb occurrence are identified and their linkages to mwb severity are examined a data driven model capable of accurate prediction of mwb severity and a new threshold providing highly accurate indication of mwb occurrence were both developed outperforming results of past studies with similar goals this is the first attempt to assess and predict the severity of mwbs in canada at a national scale it allowed a greater understanding of drivers of mwbs and a clearer relationship between the drivers and severity of the mwb events 2 data 2 1 the canadian river ice database crid one of the primary data sources for this study the canadian river ice database crid contains an extensive amount of data on river ice throughout the country extracted from wsc gauge records by de rham et al 2020 using time series analysis the extraction process involved visual inspection of water level time series records according to a process laid out by beltaos 1990 requiring detailed criteria for each river ice event to be identified before the timeline of each river ice season could be constructed the definition of each event was primarily based on the time series of water levels with peaks and lows occurring throughout the winter season acting as indicators of distinct events the crid contains data from 196 gauges in canada with 46 on regulated rivers and 150 on unregulated rivers for each season up to 15 river ice related events are identified and the corresponding water levels discharges and event timings are recorded one of the key events recorded is the occurrence of mwbs identified as peaks in the flow record associated with higher than average winter temperatures at nearby climate stations historically a difficult task beltaosv 1990 the instantaneous mwb water level represents the onset of ice cover movement at a site during the winter season and is identified as a spike on the rising limb of the water level record de rham et al 2020 for each mwb event the event date and associated discharge are recorded along with the water level additioznal water level flow and ice thickness data were also recorded for each event if available to demonstrate potential applications of the data an initial trend analysis was conducted for the calculated interval representing ice cover duration the span between the date of freeze up and the date of break up their primary findings through this analysis were that ice duration was decreasing and breakups were occurring earlier throughout the country with only some gauges in the southwest experiencing longer seasons de rham et al 2019 the 196 gauges of the crid are shown in fig 1 with the gauges containing historical mwbs highlighted with the number of mwb events there are a total of 52 gauges with mwb events mainly concentrated in two major regions of the country the southwest in bc and alberta and the southeast in ontario quebec new brunswick and newfoundland and labrador the locations of these gauges are largely outside of the colder northern portions of the country and are more frequently affected by mid winter thaws temporal coverage varies from gauge to gauge depending on period of operation with the earliest mwb occurring in 1955 and 301 of the mwb station years occurring after 1990 38 of the gauges are located on unregulated rivers while 14 are on regulated rivers containing structures altering the flow regime in the rivers data on 452 mwb events are contained in the crid amongst the 52 stations where they have been observed outliers in the time water level or discharge time series stemming from gauge repositioning or measurement error were identified and corrected after consultation with environment and climate change canada historical notes were used to identify the dates of gauge datum changes and the corresponding datum measurements allowing corrections to be made in total 7 gauges had portions of their record adjusted including 28 station years with mwbs the crid data that was utilised in this study for the prediction of mwbs is listed in table 1 this data consists of all ice cover related variables preceding the occurrence of mwb events 2 2 nrcan gridded climate data the primary source of climate data for this research was the natural resources canada nrcan daily gridded climate set providing 0 1 degree gridded data across the country spanning 1950 2010 variables included in the initial data are daily minimum temperature daily maximum temperature and daily precipitation this data was derived from quality controlled but unadjusted without homogenization or procedural changes station data from the national climate data archive ncda of environment and climate change canada data hutchinson et al 2009 and interpolated onto a high resolution grid using thin plate splines mckenney et al 2011 hopkinson et al 2011 geographic information system mapping was used to extract daily minimum and maximum air temperature and daily precipitation data from the nearest nrcan grid point at each of the gauges in the crid where mwbs have occurred the minimum and maximum temperature values were used to calculate a single daily mean temperature value for each day in the time series mcmaster and wilhelm 1997 these values were used to compile a series of climate variables for attribution analysis of mwbs temperature values were also used to calculate a daily value for accumulated freezing degree days afdd the sum of temperatures below 0 beginning from a reference date in this case october 1st the beginning of the canadian water year boyd 1979 over the course of the winter these values would represent the magnitude of how cold the season had been the daily total seasonal precipitation cumulatively summed from the beginning of freeze up was also calculated to account for the depth of snowpack over the winter 3 methodology 3 1 trend analysis trend analysis of mwbs was conducted using the mann kendall mk trend test for time series data based on it s previous successes in applications related to river flooding du et al 2015 goulding et al 2009a hamed and ramachandra rao 1998 mk has been widely used for trend analysis in hydrological studies as it does not require the data it s applied to to be normally distributed while also not being affected by missing data points for a time series x x 1 x 2 xn a statistic s is calculated using eq 1 1 s i 1 n 1 j i 1 n s i g n x j x i where s is the mk trend statistic the values of xi are the data being analysed for trends and n is the number of observations in the time series under the null hypothesis that no trend is present the statistic s tends towards normality with variance given by eq 2 2 v a r s 1 18 n n 1 2 n 5 the test statistic z for the mk test is described by eq 3 3 z s 1 se s 0 0 s 0 s 1 se s 0 where se is the square root of var the p value derived from the area under a normal distribution curve at the value of z will be assessed against a 95 confidence interval for this mk test where a value less than 0 05 for the p value would indicate the presence of a trend allowing the null hypothesis of no trend to be rejected 3 2 return period analysis the return period of each mwb was calculated at each of the gauges independently at each gauge ice affected flows and water levels were first normalised through the subtraction of the means a weibull distribution traditionally used in the assessment of flood return periods on rivers apel et al 2006 vervuren et al 2003 was then fitted to each of the water level and flow curves using maximum likelihood estimation to fit parameters de rham et al 2008a the probability density function pdf of the weibull distribution is presented in eq 4 4 f x c c 2 x c 1 e x p x c where c is the shape parameter fitted for the distribution and is greater than 0 eq 5 is used to calculate the plotting position of return periods of the historic mwbs 5 r n 1 m where r is the return period of the event in years n is the number of years of water level records and m is the magnitude ranking of the event stations with less than 30 years of ice season data including both years with and without mwbs were excluded from this analysis in total 50 of the 52 stations with mwbs had sufficient data to be included in this analysis 3 3 driver identification a series of potential drivers were identified for early indication of mwbs based on the nrcan climate data and the crid data to determine the drivers best suited to provide early indications of mwb occurrence a multi step variable selection process was employed consisting of correlation analysis regression analysis and input omission hall and miller 2009 meinshausen and buhlmann 2006 galelli et al 2014 while there are various other techniques that can be employed including analysis of variable distributions or principal component analysis this process ensures that each of the possible drivers are considered in the selection process to prevent the risk of excluding vital features while also ensuring that redundant or detrimental drivers are excluded this combination of multiple selection methods considers each driver individually while also employing a combination of a typical forward selection approach and a modified backward elimination process employing shrinkage avoiding biased regression coefficients typical of a standard backwards approach tibshirani 1996 potential issues stemming from non linear relationships between drivers are also addressed through the selection of a regression algorithm capable of functioning in non linear problems in the second step the first step of this process involved correlation analysis of the candidate drivers against the three variables representing mwb severity water level discharge and return period corresponding to the maximum mwb water level hmwm pearson s correlation was used as the primary metric for this analysis described by equation 6 benesty et al 2009 6 ρ x y c o v x y σ x σ y where ρ x y is the pearson correlation between variables x and y c o v x y is the covariance between variables x and y and σ x and σ y are the standard deviations of variables x and y a pearson s correlation value approaching 1 would represent an increasingly strong positive correlation a value approaching 1 would represent an increasingly strong negative correlation and a value of 0 would represent no correlation between the variables by conducting this analysis for all drivers to the three mwb severity metrics early indications of potentially redundant drivers could be identified while drivers with stronger correlations indicate stronger potential as predictors the second step of this process involved initial driver selection using least absolute selection shrinkage operator lasso regression regressing the full input set against the three variables representing mwb severity a lasso model fits a regression with an l1 penalty on non intercept coefficients in the regression equation tibshirani 1996 this allows the regression to perform initial variable selection through using a shrinkage factor detailed in eq 7 7 β 0 argmax β l β y it a λ q 1 p β q where β the coefficient or weight for a particular variable is estimated through maximizing the likelihood function β y it a with y it representing the observed value of the predictand a representing the pool of potential predictors λ the tuning parameter and l the l1 regularization penalty which focuses on reducing the weights of each variable often driving small weights to zero the tuning parameter λ was selected through 5 fold cross validation on the data subdividing the data into five portions and building a model based on four then testing the model against the fifth each of the five possible data combinations is tested with each of the possible λ values and the value producing the best performance is selected the final equation developed resembles that of a multiple linear regression shown in eq 8 where the b parameters would be replaced by β through this the drivers selected by the lasso algorithm from the full input set those with a non zero β value for regressing each of the three targets were able to be ranked based on the order in which the regression included them and the value of their final coefficient providing an indication of their importance sermpinis et al 2018 drivers not selected for inclusion in the fitted lasso regressions could be excluded from subsequent analysis following this the remaining ranked drivers selected from the lasso analysis were tested using an input omission io process against a multiple linear regression mlr to the three targets detailed in eq 8 8 y a b 1 x 1 b 2 x 2 b n x n where a is the intercept and bi are the coefficients for each of the predictor variables xi predicting the response y goswami and brahma 2019 an mlr equation was constructed using all drivers and an additional equation was developed for each variable where it was omitted from the predictor variables changes in mean squared error were calculated and drivers whose omission either decreased the value or resulted in no change were removed from the driver pool to develop a final driver selection snieder et al 2020 this two step process of lasso and io functions to reduce the initial candidate driver pool to those that showed the strongest link to the predictand variables the final driver selection could conceptually be used to identify a new threshold for the initiation of mwbs by identifying the ideal climatic variables to base a threshold around identified climatic variables would be run through a grid search process to identify the values that maximize the prediction of mwbs from the full dataset 3 4 classification algorithm following the final selection of drivers a data driven modelling algorithm random forest was used to test the effectiveness of the drivers in classifying the severity of mwb return periods the amount of events in the severity classes would be uneven to ensure the model is capable of capturing the uneven distribution of rare events while also ensuring each severity class was distinct a random forest model develops an ensemble of classification trees through bootstrap samples of the dataset as shown in fig 2 stampoulis et al 2020 zhou et al 2019a b each bootstrap sample set is used to develop an independent classification tree and a separate prediction and the predictions of all bootstrap sample sets are used to output a final prediction liaw and wiener 2002 this process is represented in equation 9 9 f 0 x 1 m m 1 m f m x where f x is the overall prediction of the random forest m is the number of bootstrap ensembles and f m x is the prediction trained on the m th bootstrap sample overfitting of random forest models is a concern particularly with smaller datasets thus in some cases it is recommended to use stopping criterion to limit tree growth to account for this problem as this model was built for classification which seldom encounters the overfitting effect as a result of the ensemble structure which also limits error increases due to bias segal 2003 wu and zhang 2016 javeed et al 2019 a default stopping criterion of zero with no pruning was used producing fully grown trees as recommended by hastie et al 2009 as a results with no stopping criteria to meet full trees will be grown for each member of the random forest according to the values selected for the model hyperparameters these values would be selected using 5 fold cross validation with a grid search being used to try each possible combination of the considered hyperparameters one at a time probst et al 2018 albers et al 2016 the hyperparameters included in model tuning were the number of estimators number of trees included in the forest maximum features the number of features considered when determining the best split maximum depth maximum levels of the tree minimum samples per split number of samples needed to split a node and minimum samples per leaf number of samples needed at a leaf node a minimized gini impurity the measure of an incorrect classification s likelihood was used as the target value to split each node a default learning rate of 0 1 and step size of 10 hastie et al 2009 the final model would be subsequently trained and tested on a stratified and randomized 90 10 data split with variables normalized the variables of test data would be run through the trained model to obtain a set of predicted severity classes which would then be compared to the actual classes those observations belonged to model accuracy can be assessed using metrics based around the class by class rate of true positives tpi the number of correctly classified members of the class true negatives tni the number of correctly classified non members of the class false positives fpi the number of non members of the class incorrectly classified into the class and false negatives fni the number of members of the class incorrectly classified as non members with these values the metrics overall accuracy average effectiveness of the classifier per class average precision agreement of the classifier s labels with the true class labels per class and average recall effectiveness of the classifier in identifying class labels can be calculated using eqs 10 12 additionally the rate of true negatives or average specificity can be calculated using eq 13 10 overallaccuracy i 1 k tp i tn i tp i tn i fp i tn i k 11 precision i 1 k tp i tp i fp i k 12 recall i 1 k tp i tp i fn i k 13 specificity i 1 k tn i tn i fp i k where k is the total number of classes sokolova and lapalme 2009 these metrics are commonly used in the assessment of multi class models abbaszadeh shahri et al 2020 shahri et al 2021 by plotting the relationship between the recall or true positive rate and 1 specificity or the false positive rate a receiver operating characteristic roc curve can be developed this curve plots the ability of the model to classify each target class with a curve produced for each of the considered classes by looking at the accuracy of their predictions the area under the curve auc is a useful indication of model skill producing a value between 0 and 1 0 with values of 0 5 representing no discriminatory ability 0 7 0 8 being acceptable 0 8 0 9 considered excellent and anything above 0 9 demonstrating outstanding ability mandrekar 2010 the trained model can also provide an indication of variable selection accuracy through the output of variable importance values the value of a variables importance in a random forest model indicates the level of contribution it provides in lowering the gini impurity of the model predictions based around overall classification rate this allows an indication of whether any selected variables are further redundant and could potentially be excluded or if each variable provides an even contribution to the model results while non stationarity can be a concern as a result of climate change in these modelling applications the developed model will be built on a combination of hydrologic and climatic variables which addresses this potential issue li et al 2016 ghaith et al 2020 random forest models have historically been successful in classifying flood hazard risks wang et al 2015 sadler et al 2018 this final model will be valuable in demonstrating the strength of the selected drivers in predicting the severity of a subsequent mwb in combination with the techniques applied in driver selection the predictions of the model are based on the assumption that there are relationships present in the data specifically between the variables and the severity which are demonstrated through the variable selection process though not necessarily described in detail while random forest models have historically encountered issues related to computational time especially in real time predictions these issues are not a concern in this application due to the size of the data the rareness of mwb events limits the amount of data needed for initial model training while the variable selection process reduces the amounts of data needed for real time monitoring preventing issues stemming from computation time and model complexity 3 5 algorithm implementation analysis in this study was completed using python version 3 7 van rossum and drake 2009 additional packages implemented in these applications included numpy oliphant 2006 pandas mckinney et al 2010 scikit learn pedregosa et al 2011 scipy virtanen et al 2020 and seaborn waskom and the seaborn development team 2020 4 results and discussion 4 1 mwb trend analysis the annual number of mwbs throughout canada was compiled from the crid and plotted as a time series in fig 3 this time series was used as the basis of the mk trend test on the annual number of mwbs in the country this analysis produced an s value of 1061 which provides an indication of an increasing trend an se value of 15 9 a z value of 6 63 and a p value of 3 47 10 11 which indicates a statistically significant trend at a 95 confidence interval it can be concluded based on both this analysis and the visible trend in fig 3 that there is an increasing trend in the frequency of mwbs in canada emphasizing the importance of their analysis a trend analysis of the mwbs at the individual gauges within the crid was further conducted mk testing of the water levels and timing of the events at individual gauges was less conclusive displaying no statistically significant trend at all but one of the rivers the exception of which had an increasing trend in water level thus while the frequency of these events is clearly increasing there is no clear increase or decrease in their severity on a regional scale 4 2 return period analysis at each of the gauges with mwb events and sufficient ice season data a weibull distribution was fitted to the maximum ice affected water level of each year the fitted distribution was used to calculate the return period of each maximum ice affected water level for each ice season including the maximum mwb water levels it was found that a significant portion of the high return period ice affected water levels in the crid were caused by mwbs fig 4 a shows the number of mwb water levels with return periods over 5 years plotted at each gauge location with the average return period being 3 47 years it was found that more southern locations had a higher number of such events and that every gauge where a mwb had occurred produced at least one with a return period exceeding 5 years fig 4b plots the percentage of water levels with a return period of over 5 years caused by mwbs in the southern portions of bc and alberta as well as southern ontario and quebec the percentage is notably higher approaching 85 at some gauges while the mk tests on the water level and flows related to these mwbs indicated that the severity of these events has no significant increasing trend on average these events are typically much more severe than the regular ice season flows because of this the increasing trend in frequency that was found for these events indicates an increasing likelihood of high water level events related to mwbs on these rivers which can be much more severe than typical spring breakups 4 3 driver identification an initial selection of 130 potential indicator variables was assembled for each of the 452 mwbs in the crid each mwb would be treated as a discrete event with the goal of using a selection of the 130 indicator variables to predict the level of mwb severity via classification table 2 details these variables consisting of ice related events preceding mwbs from the crid and climatic indicators derived from the nrcan climate time series all of which could provide early indication of ice snow or climatic conditions preceding mwbs occurrence each variable includes the name they were coded as in analysis the events included the first ice affected day and the freeze up date which describe the initial traits of the ice cover and the dates of the first winter low flow and low water level providing an indication of the development of both the ice cover and the flow regime in the river preceding an mwb dates used in the analysis were calculated as the number of days since the beginning of the reference period october 1st water levels and flows were normalised at each station to prevent any inconsistencies being present in modelling the afdd was used as a measure of how cold the ice season had been preceding an mwb with values included from each of the 30 days preceding the event the change in afdd between each of these 30 days and the value measured on the day an mwb occurred were also included providing an indication of how quickly the warming occurred during the thaw preceding the mwb similarly the total precipitation from the start of the winter season was calculated up to each of the 30 days preceding the mwbs providing an early indication of how much snow was present before thaw occurred the change in total precipitation between each of the 30 days preceding the mwb and the date of the mwb was also calculated providing an indication of the amount of precipitation that fell directly preceding the mwb potentially as liquid initial analysis of pearson correlation was conducted between each of the 130 candidate variables and the three severity variables fig 5 a e shows heatmap results of this analysis stronger correlations were found between ice event variables and precipitation variables to the three severity targets while the variables related to temperature largely had a weaker correlation to these same targets though these values varied lasso models were constructed as the next step of variable selection from the 130 initial variables fig 6 shows an example of the variable implementation of the lasso regressing a selection of variables to the return period models were developed regressing the entire driver pool to the water level flow and return period of each mwb by removing those variables that were not included in the final regression equations having a β of 0 in eq 7 the initial variable selection was able to be reduced to 76 variables these remaining variables were ranked based on the order of their implementation in the lasso regressions and the value of their β coefficient in the final regression equation inspection of the rankings allowed an additional 35 variables to be rejected on the basis of their overall low contributions to the regression equations the final 41 variables were then analysed through an io process regressing them against the mwb return period using mlr equations each variable was removed from the equation in turn allowing the changes in mean squared error with their absence to be calculated variables whose removal resulted in either no change or a decrease in mean squared error would be removed from consideration based on the change to mean squared error a further 21 variables were removed resulting in the final 20 variables listed in table 3 4 4 classification algorithm using the final selection of 20 variables a random forest model was next trained and tested to classify the severity of mwb event return periods the return periods of the mwbs considered in the dataset were divided into three categories low severity return period less than 2 years medium severity return period between 2 and 15 years and high severity return period greater than 15 years fig 7 maps the dominant category at each of the gauges in the crid included in mwb analysis after completing a 5 fold cross validation to select model hyperparameters via a grid search with a selected value of 100 estimators from a range of 100 1000 maximum features of 5 maximum depth of 30 from a range of 10 to 100 minimum samples per split of 2 from a range of 2 to 5 minimum samples per leaf of 3 from a range of 1 to 5 and bootstrap selection producing the highest accuracy on the training set the random forest was trained and tested using the 20 variables the variables of a testing set with 40 events was classified by the model and compared to the actual classes of the data with the resulting confusion matrix shown in table 4 the trained model produced an 80 overall accuracy a precision of 87 and a recall of 71 on the testing data the roc curve for the testing data is shown in fig 8 an auc of 0 8 was obtained for low severity 0 735 for medium severity and 0 824 for high severity indicating overall good ability of the model to capture the mwb severity many of the events were classified correctly with the majority of incorrect classifications being the prediction of a low severity event as a medium severity event fig 9 shows the variable importance plot for this model while the date variables obtained slightly higher values than the others it can be seen that all of the selected variables provided a roughly equal contribution to the reduction of gini impurity in the model classification these results successfully demonstrate the strength of the selected variables in classifying mwbs and their use as early indicators for mwb severity the classification accuracy of the trained model applied to the whole dataset is mapped by gauge in fig 10 the overall accuracy was 96 with a precision of 97 and a recall of 88 an auc of 0 99 was obtained for low severity 0 99 for medium severity and 0 936 for low severity nearly all gauges had high classification accuracies with the exception of one gauge in northern alberta which had a 0 classification accuracy further analysis of this gauge shows that there was only one mwb in its record which was considered a high severity event by the criteria described above based on the overall results the high severity events are the hardest to classify due to the small number of them contained in the dataset to investigate the structural uncertainty of the final model and the driver selection process additional models were developed for comparison the first of these models was constructed using all 130 of the variables considered in table 2 the constructed model was a random forest classifying the return period in the same manner as the curated model detailed above with training and testing being conducted in the same manner the resulting model had a 63 overall accuracy a recall of 46 a precision of 67 5 and an average auc of 0 65 a decrease in comparison to the curated model this indicates that the reduced variable set provides a much greater indication of mwb severity through the removal of redundant variables whose linkages to the severity are less significant less relevant and misleading or potentially correlated non linearly with other variables while also increasing computational efficiency through the removal of unneeded data a second model was developed using an alternative method of afdd calculation from the method described in section 3 1 in this method afdd was calculated from the first day of below 0 temperatures rather than the generalized start date of october 1st as the only afdd variable present in the final curated dataset was afdd1 the afdd up to the day of an mwb this was the only factor that would change in the final model dafddi variables would remain the same as they are the day to day difference in afdd directly preceding the mwb event by replacing the afdd1 variable and retraining the model an overall accuracy of 72 recall of 65 precision of 81 and an average auc of 0 72 were obtained indicating that the generalized method of calculating the afdd provides a better indicator of mwb severity 4 5 comparison with previous studies investigation of the use of thresholds to predict the occurrence of mwbs was also conducted previously two thresholds for predicting the initiation of mwbs were proposed prowse et al 2002 carr and vuyovich 2014 the accuracy of each of these thresholds was evaluated against the data collected for this research followed by the construction of a random forest model classifying mwb severity based solely on the threshold variables the threshold proposed by prowse et al 2002 of a value of 25 mdd over the 7 days preceding an mwb was accurate for only 0 22 of the mwbs in the crid as shown in fig 11 a using only the single variable of this threshold in a random forest classifying mwb severity an overall accuracy of 26 was obtained the threshold from carr and vuyovich 2014 8 mdd or 2 8 mm of precipitation over the 5 days preceding an mwb was accurate for 12 in the case of the mdd and 80 in the case of the precipitation of the mwbs in the crid as shown in fig 11b a random forest model using these two variables obtained an overall accuracy of 48 with these results in mind a new threshold was proposed through analysis of the values of mdd and precipitation for the 30 days preceding all mwbs contained in the crid an optimization process focused on maximization of the percentage of mwbs correctly predicted by threshold values was developed with each possible combination of mdd ranging from 0 to 25 in increments of 1 and precipitation ranging from 0 mm to 10 mm in increments of 0 1 mm a threshold of 4 mdd and 8 mm of precipitation in the 20 days preceding an mwb was selected with an overall accuracy of 96 shown in fig 11c the newly proposed threshold was also tested for use as classification variables obtaining an overall accuracy for mwb severity of 64 this new threshold exceeds both the accuracy in predicting mwbs and the classification accuracy of the previous thresholds when measured against the crid data however it does not outperform the final input set developed above in classifying mwb severity this indicates that while these thresholds have some use in predicting mwb occurrence predictions of the mwb severity are a much more complicated process requiring additional variables to be considered beyond the values presented by the thresholds additionally while these thresholds may provide some early indication of the occurrence of mwbs due to their simplicity they cannot be solely relied on for accurate prediction of mwb timing and additional research would be necessary to develop a more dependable method of predicting the timing of mwbs 4 6 discussion in this study a combination of lasso correlation analysis and input omission was used to select input variables from the initial selection of 130 potential variables using this multi step approach some of the shortcomings of each method were overcome while ensuring that multiple facets of input relationships were considered the variable selection methods have had past successes in previous research and were successful in this application in determining a set of drivers with a strong ability to predict mwb severity but they still have shortcomings for example care must be taken when restricting variables to avoid excluding their potential effects in the classification model and variable distribution should be considered when determining which variables to exclude chowdhury and turin 2020 other methods for input selection exist with their own advantages and shortcomings including methods such as bayesian variable selection best subset regression stepwise selection and principal component analysis george and mcculloch 1997 abdi and williams 2010 zhang 2016 although it is worth noting that there is no universally accepted method these concerns also extend to the model construction where steps were taken in choosing hyperparameters division of testing and training data and model structure to avoid overfitting issues common in machine learning applications for example although random forest is known for its ability to limit overfitting without substantially increasing error yet the risk remains for this model type also though the 90 10 data split is commonly used in the literature for training and testing ahmad et al 2018 you et al 2020 there is no consensus on the optimal split and other ratios e g 80 20 and 70 30 can be found in many other studies garcia and muga 2016 wahid et al 2017 future work to account for this can include the use of different proportions of training and testing data or different algorithms and training techniques uncertainties remain present in the results both in terms of the used data and methods though the data has been quality controlled uncertainties are still present stemming from the numerous sources and quantity of data which increases risk of error some of these issues were encountered in this study and corrections were provided but the risk remains present further uncertainties exist in both the application of variable selection and the random forest algorithm mentch and hooker 2016 and rahmati et al 2019 detailed analysis of these inherent uncertainties may form the basis of future work additionally though the algorithm is successful for the utilised data which includes all possible data for mwbs in crid the algorithm may have issues when encountering data which falls outside of the range of the data used hengl et al 2018 it is recommended to continue refining both the model and thresholds as new data is acquired this is especially important as climate change brings about more extreme and more frequent events which may easily fall outside of the considered ranges closely related to this concern are issues potentially stemming from spatial distribution with a common consequence of models working accurately within the spatial regions for which they were developed but struggling when extended beyond the training region meyer et al 2019 the current model includes data from many rivers across the country however the climate regions they inhabit are quite similar particularly in their capacity for mwbs as climate change continues to alter the expected temperatures in winter the distribution of these events can be expected to shift throughout the country thus the current approach may no longer be applicable with this in mind revisions to the spatial distribution of data when training the model or training separate regional models may be necessary to account for spatial and climatic variability 5 conclusions this study focussed on the analysis of the severity and causes of mwbs which have become increasingly common in canada as a result of climate change this study utilised a newly released dataset the crid to gain insight on mwb events occurring throughout the country the extensive data contained in the crid allowed this study to conduct mwbs analysis on a scale not possible before providing the opportunity for a greater understanding of the main drivers of these events a combination of trend analysis return period analysis attribution analysis and machine learning techniques were employed to gain a better understanding of the early indicators of mwb severity a clear increasing trend in the frequency of mwbs in canada was identified while return period analysis found that these events are consistently more severe than the average ice events on the affected rivers combining traits of the river ice cover in the early parts of the ice season and climate conditions directly preceding the mwb events 130 initial candidate variables were identified the initial variable set was reduced through the application of correlation analysis lasso regression and input omission through this analysis 20 variables that have high link to the traits defining mwb severity were selected these variables include the initial date of freeze up the low flow water levels and flow rate and several variables representing the warming rate and quantities of liquid precipitation occurring during the warming preceding and mwb these variables can be easily monitored in advance of a potential mwb providing the opportunity for detailed forecasting to be developed the strength of these selected variables connection to mwb severity was demonstrated through the construction of a random forest model classifying the return period of the mwbs based on the identified variables this model achieved a high level of accuracy indicating a strong connection between the variables and the severity of the mwb events further this model was compared to previously developed threshold values for the triggering of mwbs as well as a new set of threshold values developed from the extensive data contained in the crid the new threshold 4 mdd and 8 mm of precipitation in the 20 days preceding an mwb consistently outperformed the previous thresholds and coupled with the results of the random forest model provides a new method through which both the occurrence and severity of mwbs throughout the country can be predicted through this major indicators of mwb severity have been identified and their utility in the prediction of mwbs can continue to be researched future studies of these drivers may investigate alternative methods for selection of drivers or model variables such as global sensitivity analysis or principal component analysis ashegi et al 2020 ciriello et al 2019 the study of multiple periodicities present in the time series data as well as data non stationarity is also recommended credit authorship contribution statement michael de coste conceptualization methodology software validation formal analysis visualization writing original draft writing review editing zhong li conceptualization supervision writing review editing funding acquisition yonas dibike resources data curation methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by natural sciences and engineering research council of canada nserc data used is available from environment canada https open canada ca data en dataset c5b58ccd 0011 4a80 8f24 034c86cbc14d and natural resources canada https cfs nrcan gc ca projects 3 4 
3584,mid winter breakups mwbs consisting of the early breakup of the winter river ice cover before the typical spring breakup season are becoming increasingly common events in cold region rivers these events can lead to potentially severe flooding while also altering the expected spring flow regime yet data on these events is limited in this study a newly released canadian river ice database crid containing river ice data from 196 rivers across canada obtained from time series analysis was used to analyse these mwbs on a previously impossible national scale the crid data was combined with the natural resources canada nrcan gridded daily climate dataset to identify a list of potential hydrologic and climatic drivers for mwb events techniques such as correlation analysis least absolute selection shrinkage operator lasso regression and input omission were combined to select 20 key drivers of the severity of mwb events a random forest model that was trained with these drivers using data driven modelling techniques successfully classified the mwbs as either low medium or high severity achieving an overall accuracy of 80 a new threshold for the prediction of mwb initiation based on climatic conditions was subsequently proposed through the use of optimization via an exhaustive grid search and its accuracy in identifying mwbs exceeded those proposed by previous studies the new threshold used in conjunction with the random forest model provide valuable tools for both the prediction of mwbs and the assessment of their potential severity keywords river ice breakup flooding prediction data driven modelling time series analysis 1 introduction river ice formation and breakups are a yearly phenomena on many canadian rivers and are often source of the highest annual flows in recent years there has been an increasing risk of mid winter breakups mwbs which are the early breakup of a river ice cover before winter ends beltaos et al 2003 these typically result from unseasonably high temperatures and are followed by temperatures returning to typical seasonal values and the reformation of an ice cover in addition to exposing the river to higher than usual flows more than once per season they also carry the risk of producing ice jams where broken river ice becomes restricted in the channel leading to a damming effect on flows massie et al 2002 beltaos 2002 rokaya et al 2018 there is the potential for these jams to freeze in place when temperatures return to seasonal levels creating a semi permanent dam on the river beltaos 2003 further these events alter the subsequent spring breakup on the river greatly affecting the expected flow regime by reducing expected flows which can have impacts on the hydrology and ecosystem of downstream basins beltaos et al 2006 many studies have noted the increasing frequency of these events throughout north america prowse et al 2002 huntington et al 2003 carr and vuyovich 2014 because of this it is of great interest to develop a better understanding of the key factors both at the start of the ice season and before melt occurs that can trigger a mwb and their effect on the severity of the resulting mwb several past studies have applied large scale data analysis techniques to the spring breakup of river ice cover for example de rham et al 2008a investigated annual high water events in the mackenzie river basin investigating the spatial distribution of open water and breakup dominated high flows they concluded that high water events in the southern portion of the basin were dominated by open water flows while those in the north were dominated by spring breakup flows this was further investigated through a spatiotemporal analysis of the last ice affected dates of 29 water survey of canada wsc gauges in the basin de rham et al 2008b through the extraction of the breakup and peak water levels and subsequent trend analysis it was found that the timing of breakup is trending earlier throughout the basin with longer breakup periods expected goulding et al 2009a examined the drivers of breakup and ice jamming in the mackenzie delta through time series inspection trend analysis using mann kendall and sen s slope revealed that the peak stage in the delta was most influenced by upstream discharge while timing of breakup was most influenced by ice conditions such as thickness and the speed of melt and that breakups in the delta were trending towards longer melts lower peaks and earlier timing further research incorporating spatial mapping and analysis of both ice driven and open water driven peak flows reinforced these conclusions goulding et al 2009b while these papers investigated the drivers and trends in breakup they were focussed largely on single regions within the country and investigated only spring breakup and open water events past studies on the phenomena of mwbs have looked at these events in a generalized sense emphasizing their increasing frequency but due to the lack of readily available data were unable to do any detailed modeling beltaos 1999 provided an overview of the effects of climate change on the saint john rivers ice breakup regime it was noted that there was an increase in mild winter days over the past 80 years with a trend of spring breakup occurring earlier that was tied to an increase of mid winter breakup events carrying a risk of ice jams freezing in place and flooding beltaos and prowse 2009 investigated the impacts of climate change on the timing and severity of ice events including breakup and ice jamming their findings indicated a trend towards shorter ice seasons and earlier breakups with the potential for mid winter ice jams increasing as a result further it was found that the changes to breakups occurring both in mid winter and in spring would be driven by changes in warming rates and snowpack depths with potentially severe environmental impacts both to habitats and hydrology research has also been conducted on mwb severity and drivers with varying levels of success prowse et al 2002 investigated the drivers of mwbs focussing on the effects of temperature in triggering these events they defined a climatic threshold of 25 melting degree days mdd the sum of temperatures over 0 over 7 days as a major trigger for breakups similarly carr and vuyovich 2014 also defined a threshold for the trigger of an mwb their threshold considered temperature as well as precipitation with values of 8 mdd or 2 8 mm of rain over a period of 5 days both of these thresholds were investigated by newton et al 2017 in their study of the hydro climatic drivers of mwbs in western canada in this study a database compiled from gauges on 90 unregulated rivers was used to study the influence of daily temperature and precipitation on mwbs in 5 different climate regions with a larger temperate region defined as the area where solid sufficiently thick ice cover is expected to form while still being susceptible to mid winter warm spells in total 52 mwbs were identified from 21 rivers in the considered region the climate conditions preceding these mwbs were then compared to the thresholds proposed by prowse et al 2002 and carr and vuyovich 2014 finding that the first threshold was inaccurate only accurately predicting 11 of the mwbs while the second was more accurate predicting 60 of all mwbs while the results of this research were promising it was limited both by the quantity of data s and in the scale of the considered region only including the western coast of the country machine learning techniques have been previously applied to model and predict a variety of river ice phenomena white 1996 massie et al 2002 and mahabir et al 2006 utilised logistic regression artificial neural networks and hybrid neuro fuzzy systems for the prediction of ice jam timing on rivers however they encountered issues related to the availability of data spring breakup has also been modeled using techniques such as artificial neural networks guo et al 2018 yang et al 2021 zhao et al 2012 adaptive neuro fuzzy inference systems balogun et al 2020 sun and trevor 2018 wang et al 2012 sun and trevor 2015 stacking ensembles sun 2018 and support vector machines wang et al 2010 barzegar et al 2019 these studies often focus on predicting the water levels or ice thicknesses associated with these events however some have focused on the specific timing of spring breakup with data availability often being a limiting factor in the results this study focuses on the application of return period analysis statistical and spatial analysis and machine learning techniques to investigate the primary drivers of mwbs and predict the severity of mwbs on a national scale the study was facilitated through the use of a newly developed river ice dataset containing data on 458 mwbs occurring throughout the country through this investigation a generalised set of key indicators of mwb occurrence are identified and their linkages to mwb severity are examined a data driven model capable of accurate prediction of mwb severity and a new threshold providing highly accurate indication of mwb occurrence were both developed outperforming results of past studies with similar goals this is the first attempt to assess and predict the severity of mwbs in canada at a national scale it allowed a greater understanding of drivers of mwbs and a clearer relationship between the drivers and severity of the mwb events 2 data 2 1 the canadian river ice database crid one of the primary data sources for this study the canadian river ice database crid contains an extensive amount of data on river ice throughout the country extracted from wsc gauge records by de rham et al 2020 using time series analysis the extraction process involved visual inspection of water level time series records according to a process laid out by beltaos 1990 requiring detailed criteria for each river ice event to be identified before the timeline of each river ice season could be constructed the definition of each event was primarily based on the time series of water levels with peaks and lows occurring throughout the winter season acting as indicators of distinct events the crid contains data from 196 gauges in canada with 46 on regulated rivers and 150 on unregulated rivers for each season up to 15 river ice related events are identified and the corresponding water levels discharges and event timings are recorded one of the key events recorded is the occurrence of mwbs identified as peaks in the flow record associated with higher than average winter temperatures at nearby climate stations historically a difficult task beltaosv 1990 the instantaneous mwb water level represents the onset of ice cover movement at a site during the winter season and is identified as a spike on the rising limb of the water level record de rham et al 2020 for each mwb event the event date and associated discharge are recorded along with the water level additioznal water level flow and ice thickness data were also recorded for each event if available to demonstrate potential applications of the data an initial trend analysis was conducted for the calculated interval representing ice cover duration the span between the date of freeze up and the date of break up their primary findings through this analysis were that ice duration was decreasing and breakups were occurring earlier throughout the country with only some gauges in the southwest experiencing longer seasons de rham et al 2019 the 196 gauges of the crid are shown in fig 1 with the gauges containing historical mwbs highlighted with the number of mwb events there are a total of 52 gauges with mwb events mainly concentrated in two major regions of the country the southwest in bc and alberta and the southeast in ontario quebec new brunswick and newfoundland and labrador the locations of these gauges are largely outside of the colder northern portions of the country and are more frequently affected by mid winter thaws temporal coverage varies from gauge to gauge depending on period of operation with the earliest mwb occurring in 1955 and 301 of the mwb station years occurring after 1990 38 of the gauges are located on unregulated rivers while 14 are on regulated rivers containing structures altering the flow regime in the rivers data on 452 mwb events are contained in the crid amongst the 52 stations where they have been observed outliers in the time water level or discharge time series stemming from gauge repositioning or measurement error were identified and corrected after consultation with environment and climate change canada historical notes were used to identify the dates of gauge datum changes and the corresponding datum measurements allowing corrections to be made in total 7 gauges had portions of their record adjusted including 28 station years with mwbs the crid data that was utilised in this study for the prediction of mwbs is listed in table 1 this data consists of all ice cover related variables preceding the occurrence of mwb events 2 2 nrcan gridded climate data the primary source of climate data for this research was the natural resources canada nrcan daily gridded climate set providing 0 1 degree gridded data across the country spanning 1950 2010 variables included in the initial data are daily minimum temperature daily maximum temperature and daily precipitation this data was derived from quality controlled but unadjusted without homogenization or procedural changes station data from the national climate data archive ncda of environment and climate change canada data hutchinson et al 2009 and interpolated onto a high resolution grid using thin plate splines mckenney et al 2011 hopkinson et al 2011 geographic information system mapping was used to extract daily minimum and maximum air temperature and daily precipitation data from the nearest nrcan grid point at each of the gauges in the crid where mwbs have occurred the minimum and maximum temperature values were used to calculate a single daily mean temperature value for each day in the time series mcmaster and wilhelm 1997 these values were used to compile a series of climate variables for attribution analysis of mwbs temperature values were also used to calculate a daily value for accumulated freezing degree days afdd the sum of temperatures below 0 beginning from a reference date in this case october 1st the beginning of the canadian water year boyd 1979 over the course of the winter these values would represent the magnitude of how cold the season had been the daily total seasonal precipitation cumulatively summed from the beginning of freeze up was also calculated to account for the depth of snowpack over the winter 3 methodology 3 1 trend analysis trend analysis of mwbs was conducted using the mann kendall mk trend test for time series data based on it s previous successes in applications related to river flooding du et al 2015 goulding et al 2009a hamed and ramachandra rao 1998 mk has been widely used for trend analysis in hydrological studies as it does not require the data it s applied to to be normally distributed while also not being affected by missing data points for a time series x x 1 x 2 xn a statistic s is calculated using eq 1 1 s i 1 n 1 j i 1 n s i g n x j x i where s is the mk trend statistic the values of xi are the data being analysed for trends and n is the number of observations in the time series under the null hypothesis that no trend is present the statistic s tends towards normality with variance given by eq 2 2 v a r s 1 18 n n 1 2 n 5 the test statistic z for the mk test is described by eq 3 3 z s 1 se s 0 0 s 0 s 1 se s 0 where se is the square root of var the p value derived from the area under a normal distribution curve at the value of z will be assessed against a 95 confidence interval for this mk test where a value less than 0 05 for the p value would indicate the presence of a trend allowing the null hypothesis of no trend to be rejected 3 2 return period analysis the return period of each mwb was calculated at each of the gauges independently at each gauge ice affected flows and water levels were first normalised through the subtraction of the means a weibull distribution traditionally used in the assessment of flood return periods on rivers apel et al 2006 vervuren et al 2003 was then fitted to each of the water level and flow curves using maximum likelihood estimation to fit parameters de rham et al 2008a the probability density function pdf of the weibull distribution is presented in eq 4 4 f x c c 2 x c 1 e x p x c where c is the shape parameter fitted for the distribution and is greater than 0 eq 5 is used to calculate the plotting position of return periods of the historic mwbs 5 r n 1 m where r is the return period of the event in years n is the number of years of water level records and m is the magnitude ranking of the event stations with less than 30 years of ice season data including both years with and without mwbs were excluded from this analysis in total 50 of the 52 stations with mwbs had sufficient data to be included in this analysis 3 3 driver identification a series of potential drivers were identified for early indication of mwbs based on the nrcan climate data and the crid data to determine the drivers best suited to provide early indications of mwb occurrence a multi step variable selection process was employed consisting of correlation analysis regression analysis and input omission hall and miller 2009 meinshausen and buhlmann 2006 galelli et al 2014 while there are various other techniques that can be employed including analysis of variable distributions or principal component analysis this process ensures that each of the possible drivers are considered in the selection process to prevent the risk of excluding vital features while also ensuring that redundant or detrimental drivers are excluded this combination of multiple selection methods considers each driver individually while also employing a combination of a typical forward selection approach and a modified backward elimination process employing shrinkage avoiding biased regression coefficients typical of a standard backwards approach tibshirani 1996 potential issues stemming from non linear relationships between drivers are also addressed through the selection of a regression algorithm capable of functioning in non linear problems in the second step the first step of this process involved correlation analysis of the candidate drivers against the three variables representing mwb severity water level discharge and return period corresponding to the maximum mwb water level hmwm pearson s correlation was used as the primary metric for this analysis described by equation 6 benesty et al 2009 6 ρ x y c o v x y σ x σ y where ρ x y is the pearson correlation between variables x and y c o v x y is the covariance between variables x and y and σ x and σ y are the standard deviations of variables x and y a pearson s correlation value approaching 1 would represent an increasingly strong positive correlation a value approaching 1 would represent an increasingly strong negative correlation and a value of 0 would represent no correlation between the variables by conducting this analysis for all drivers to the three mwb severity metrics early indications of potentially redundant drivers could be identified while drivers with stronger correlations indicate stronger potential as predictors the second step of this process involved initial driver selection using least absolute selection shrinkage operator lasso regression regressing the full input set against the three variables representing mwb severity a lasso model fits a regression with an l1 penalty on non intercept coefficients in the regression equation tibshirani 1996 this allows the regression to perform initial variable selection through using a shrinkage factor detailed in eq 7 7 β 0 argmax β l β y it a λ q 1 p β q where β the coefficient or weight for a particular variable is estimated through maximizing the likelihood function β y it a with y it representing the observed value of the predictand a representing the pool of potential predictors λ the tuning parameter and l the l1 regularization penalty which focuses on reducing the weights of each variable often driving small weights to zero the tuning parameter λ was selected through 5 fold cross validation on the data subdividing the data into five portions and building a model based on four then testing the model against the fifth each of the five possible data combinations is tested with each of the possible λ values and the value producing the best performance is selected the final equation developed resembles that of a multiple linear regression shown in eq 8 where the b parameters would be replaced by β through this the drivers selected by the lasso algorithm from the full input set those with a non zero β value for regressing each of the three targets were able to be ranked based on the order in which the regression included them and the value of their final coefficient providing an indication of their importance sermpinis et al 2018 drivers not selected for inclusion in the fitted lasso regressions could be excluded from subsequent analysis following this the remaining ranked drivers selected from the lasso analysis were tested using an input omission io process against a multiple linear regression mlr to the three targets detailed in eq 8 8 y a b 1 x 1 b 2 x 2 b n x n where a is the intercept and bi are the coefficients for each of the predictor variables xi predicting the response y goswami and brahma 2019 an mlr equation was constructed using all drivers and an additional equation was developed for each variable where it was omitted from the predictor variables changes in mean squared error were calculated and drivers whose omission either decreased the value or resulted in no change were removed from the driver pool to develop a final driver selection snieder et al 2020 this two step process of lasso and io functions to reduce the initial candidate driver pool to those that showed the strongest link to the predictand variables the final driver selection could conceptually be used to identify a new threshold for the initiation of mwbs by identifying the ideal climatic variables to base a threshold around identified climatic variables would be run through a grid search process to identify the values that maximize the prediction of mwbs from the full dataset 3 4 classification algorithm following the final selection of drivers a data driven modelling algorithm random forest was used to test the effectiveness of the drivers in classifying the severity of mwb return periods the amount of events in the severity classes would be uneven to ensure the model is capable of capturing the uneven distribution of rare events while also ensuring each severity class was distinct a random forest model develops an ensemble of classification trees through bootstrap samples of the dataset as shown in fig 2 stampoulis et al 2020 zhou et al 2019a b each bootstrap sample set is used to develop an independent classification tree and a separate prediction and the predictions of all bootstrap sample sets are used to output a final prediction liaw and wiener 2002 this process is represented in equation 9 9 f 0 x 1 m m 1 m f m x where f x is the overall prediction of the random forest m is the number of bootstrap ensembles and f m x is the prediction trained on the m th bootstrap sample overfitting of random forest models is a concern particularly with smaller datasets thus in some cases it is recommended to use stopping criterion to limit tree growth to account for this problem as this model was built for classification which seldom encounters the overfitting effect as a result of the ensemble structure which also limits error increases due to bias segal 2003 wu and zhang 2016 javeed et al 2019 a default stopping criterion of zero with no pruning was used producing fully grown trees as recommended by hastie et al 2009 as a results with no stopping criteria to meet full trees will be grown for each member of the random forest according to the values selected for the model hyperparameters these values would be selected using 5 fold cross validation with a grid search being used to try each possible combination of the considered hyperparameters one at a time probst et al 2018 albers et al 2016 the hyperparameters included in model tuning were the number of estimators number of trees included in the forest maximum features the number of features considered when determining the best split maximum depth maximum levels of the tree minimum samples per split number of samples needed to split a node and minimum samples per leaf number of samples needed at a leaf node a minimized gini impurity the measure of an incorrect classification s likelihood was used as the target value to split each node a default learning rate of 0 1 and step size of 10 hastie et al 2009 the final model would be subsequently trained and tested on a stratified and randomized 90 10 data split with variables normalized the variables of test data would be run through the trained model to obtain a set of predicted severity classes which would then be compared to the actual classes those observations belonged to model accuracy can be assessed using metrics based around the class by class rate of true positives tpi the number of correctly classified members of the class true negatives tni the number of correctly classified non members of the class false positives fpi the number of non members of the class incorrectly classified into the class and false negatives fni the number of members of the class incorrectly classified as non members with these values the metrics overall accuracy average effectiveness of the classifier per class average precision agreement of the classifier s labels with the true class labels per class and average recall effectiveness of the classifier in identifying class labels can be calculated using eqs 10 12 additionally the rate of true negatives or average specificity can be calculated using eq 13 10 overallaccuracy i 1 k tp i tn i tp i tn i fp i tn i k 11 precision i 1 k tp i tp i fp i k 12 recall i 1 k tp i tp i fn i k 13 specificity i 1 k tn i tn i fp i k where k is the total number of classes sokolova and lapalme 2009 these metrics are commonly used in the assessment of multi class models abbaszadeh shahri et al 2020 shahri et al 2021 by plotting the relationship between the recall or true positive rate and 1 specificity or the false positive rate a receiver operating characteristic roc curve can be developed this curve plots the ability of the model to classify each target class with a curve produced for each of the considered classes by looking at the accuracy of their predictions the area under the curve auc is a useful indication of model skill producing a value between 0 and 1 0 with values of 0 5 representing no discriminatory ability 0 7 0 8 being acceptable 0 8 0 9 considered excellent and anything above 0 9 demonstrating outstanding ability mandrekar 2010 the trained model can also provide an indication of variable selection accuracy through the output of variable importance values the value of a variables importance in a random forest model indicates the level of contribution it provides in lowering the gini impurity of the model predictions based around overall classification rate this allows an indication of whether any selected variables are further redundant and could potentially be excluded or if each variable provides an even contribution to the model results while non stationarity can be a concern as a result of climate change in these modelling applications the developed model will be built on a combination of hydrologic and climatic variables which addresses this potential issue li et al 2016 ghaith et al 2020 random forest models have historically been successful in classifying flood hazard risks wang et al 2015 sadler et al 2018 this final model will be valuable in demonstrating the strength of the selected drivers in predicting the severity of a subsequent mwb in combination with the techniques applied in driver selection the predictions of the model are based on the assumption that there are relationships present in the data specifically between the variables and the severity which are demonstrated through the variable selection process though not necessarily described in detail while random forest models have historically encountered issues related to computational time especially in real time predictions these issues are not a concern in this application due to the size of the data the rareness of mwb events limits the amount of data needed for initial model training while the variable selection process reduces the amounts of data needed for real time monitoring preventing issues stemming from computation time and model complexity 3 5 algorithm implementation analysis in this study was completed using python version 3 7 van rossum and drake 2009 additional packages implemented in these applications included numpy oliphant 2006 pandas mckinney et al 2010 scikit learn pedregosa et al 2011 scipy virtanen et al 2020 and seaborn waskom and the seaborn development team 2020 4 results and discussion 4 1 mwb trend analysis the annual number of mwbs throughout canada was compiled from the crid and plotted as a time series in fig 3 this time series was used as the basis of the mk trend test on the annual number of mwbs in the country this analysis produced an s value of 1061 which provides an indication of an increasing trend an se value of 15 9 a z value of 6 63 and a p value of 3 47 10 11 which indicates a statistically significant trend at a 95 confidence interval it can be concluded based on both this analysis and the visible trend in fig 3 that there is an increasing trend in the frequency of mwbs in canada emphasizing the importance of their analysis a trend analysis of the mwbs at the individual gauges within the crid was further conducted mk testing of the water levels and timing of the events at individual gauges was less conclusive displaying no statistically significant trend at all but one of the rivers the exception of which had an increasing trend in water level thus while the frequency of these events is clearly increasing there is no clear increase or decrease in their severity on a regional scale 4 2 return period analysis at each of the gauges with mwb events and sufficient ice season data a weibull distribution was fitted to the maximum ice affected water level of each year the fitted distribution was used to calculate the return period of each maximum ice affected water level for each ice season including the maximum mwb water levels it was found that a significant portion of the high return period ice affected water levels in the crid were caused by mwbs fig 4 a shows the number of mwb water levels with return periods over 5 years plotted at each gauge location with the average return period being 3 47 years it was found that more southern locations had a higher number of such events and that every gauge where a mwb had occurred produced at least one with a return period exceeding 5 years fig 4b plots the percentage of water levels with a return period of over 5 years caused by mwbs in the southern portions of bc and alberta as well as southern ontario and quebec the percentage is notably higher approaching 85 at some gauges while the mk tests on the water level and flows related to these mwbs indicated that the severity of these events has no significant increasing trend on average these events are typically much more severe than the regular ice season flows because of this the increasing trend in frequency that was found for these events indicates an increasing likelihood of high water level events related to mwbs on these rivers which can be much more severe than typical spring breakups 4 3 driver identification an initial selection of 130 potential indicator variables was assembled for each of the 452 mwbs in the crid each mwb would be treated as a discrete event with the goal of using a selection of the 130 indicator variables to predict the level of mwb severity via classification table 2 details these variables consisting of ice related events preceding mwbs from the crid and climatic indicators derived from the nrcan climate time series all of which could provide early indication of ice snow or climatic conditions preceding mwbs occurrence each variable includes the name they were coded as in analysis the events included the first ice affected day and the freeze up date which describe the initial traits of the ice cover and the dates of the first winter low flow and low water level providing an indication of the development of both the ice cover and the flow regime in the river preceding an mwb dates used in the analysis were calculated as the number of days since the beginning of the reference period october 1st water levels and flows were normalised at each station to prevent any inconsistencies being present in modelling the afdd was used as a measure of how cold the ice season had been preceding an mwb with values included from each of the 30 days preceding the event the change in afdd between each of these 30 days and the value measured on the day an mwb occurred were also included providing an indication of how quickly the warming occurred during the thaw preceding the mwb similarly the total precipitation from the start of the winter season was calculated up to each of the 30 days preceding the mwbs providing an early indication of how much snow was present before thaw occurred the change in total precipitation between each of the 30 days preceding the mwb and the date of the mwb was also calculated providing an indication of the amount of precipitation that fell directly preceding the mwb potentially as liquid initial analysis of pearson correlation was conducted between each of the 130 candidate variables and the three severity variables fig 5 a e shows heatmap results of this analysis stronger correlations were found between ice event variables and precipitation variables to the three severity targets while the variables related to temperature largely had a weaker correlation to these same targets though these values varied lasso models were constructed as the next step of variable selection from the 130 initial variables fig 6 shows an example of the variable implementation of the lasso regressing a selection of variables to the return period models were developed regressing the entire driver pool to the water level flow and return period of each mwb by removing those variables that were not included in the final regression equations having a β of 0 in eq 7 the initial variable selection was able to be reduced to 76 variables these remaining variables were ranked based on the order of their implementation in the lasso regressions and the value of their β coefficient in the final regression equation inspection of the rankings allowed an additional 35 variables to be rejected on the basis of their overall low contributions to the regression equations the final 41 variables were then analysed through an io process regressing them against the mwb return period using mlr equations each variable was removed from the equation in turn allowing the changes in mean squared error with their absence to be calculated variables whose removal resulted in either no change or a decrease in mean squared error would be removed from consideration based on the change to mean squared error a further 21 variables were removed resulting in the final 20 variables listed in table 3 4 4 classification algorithm using the final selection of 20 variables a random forest model was next trained and tested to classify the severity of mwb event return periods the return periods of the mwbs considered in the dataset were divided into three categories low severity return period less than 2 years medium severity return period between 2 and 15 years and high severity return period greater than 15 years fig 7 maps the dominant category at each of the gauges in the crid included in mwb analysis after completing a 5 fold cross validation to select model hyperparameters via a grid search with a selected value of 100 estimators from a range of 100 1000 maximum features of 5 maximum depth of 30 from a range of 10 to 100 minimum samples per split of 2 from a range of 2 to 5 minimum samples per leaf of 3 from a range of 1 to 5 and bootstrap selection producing the highest accuracy on the training set the random forest was trained and tested using the 20 variables the variables of a testing set with 40 events was classified by the model and compared to the actual classes of the data with the resulting confusion matrix shown in table 4 the trained model produced an 80 overall accuracy a precision of 87 and a recall of 71 on the testing data the roc curve for the testing data is shown in fig 8 an auc of 0 8 was obtained for low severity 0 735 for medium severity and 0 824 for high severity indicating overall good ability of the model to capture the mwb severity many of the events were classified correctly with the majority of incorrect classifications being the prediction of a low severity event as a medium severity event fig 9 shows the variable importance plot for this model while the date variables obtained slightly higher values than the others it can be seen that all of the selected variables provided a roughly equal contribution to the reduction of gini impurity in the model classification these results successfully demonstrate the strength of the selected variables in classifying mwbs and their use as early indicators for mwb severity the classification accuracy of the trained model applied to the whole dataset is mapped by gauge in fig 10 the overall accuracy was 96 with a precision of 97 and a recall of 88 an auc of 0 99 was obtained for low severity 0 99 for medium severity and 0 936 for low severity nearly all gauges had high classification accuracies with the exception of one gauge in northern alberta which had a 0 classification accuracy further analysis of this gauge shows that there was only one mwb in its record which was considered a high severity event by the criteria described above based on the overall results the high severity events are the hardest to classify due to the small number of them contained in the dataset to investigate the structural uncertainty of the final model and the driver selection process additional models were developed for comparison the first of these models was constructed using all 130 of the variables considered in table 2 the constructed model was a random forest classifying the return period in the same manner as the curated model detailed above with training and testing being conducted in the same manner the resulting model had a 63 overall accuracy a recall of 46 a precision of 67 5 and an average auc of 0 65 a decrease in comparison to the curated model this indicates that the reduced variable set provides a much greater indication of mwb severity through the removal of redundant variables whose linkages to the severity are less significant less relevant and misleading or potentially correlated non linearly with other variables while also increasing computational efficiency through the removal of unneeded data a second model was developed using an alternative method of afdd calculation from the method described in section 3 1 in this method afdd was calculated from the first day of below 0 temperatures rather than the generalized start date of october 1st as the only afdd variable present in the final curated dataset was afdd1 the afdd up to the day of an mwb this was the only factor that would change in the final model dafddi variables would remain the same as they are the day to day difference in afdd directly preceding the mwb event by replacing the afdd1 variable and retraining the model an overall accuracy of 72 recall of 65 precision of 81 and an average auc of 0 72 were obtained indicating that the generalized method of calculating the afdd provides a better indicator of mwb severity 4 5 comparison with previous studies investigation of the use of thresholds to predict the occurrence of mwbs was also conducted previously two thresholds for predicting the initiation of mwbs were proposed prowse et al 2002 carr and vuyovich 2014 the accuracy of each of these thresholds was evaluated against the data collected for this research followed by the construction of a random forest model classifying mwb severity based solely on the threshold variables the threshold proposed by prowse et al 2002 of a value of 25 mdd over the 7 days preceding an mwb was accurate for only 0 22 of the mwbs in the crid as shown in fig 11 a using only the single variable of this threshold in a random forest classifying mwb severity an overall accuracy of 26 was obtained the threshold from carr and vuyovich 2014 8 mdd or 2 8 mm of precipitation over the 5 days preceding an mwb was accurate for 12 in the case of the mdd and 80 in the case of the precipitation of the mwbs in the crid as shown in fig 11b a random forest model using these two variables obtained an overall accuracy of 48 with these results in mind a new threshold was proposed through analysis of the values of mdd and precipitation for the 30 days preceding all mwbs contained in the crid an optimization process focused on maximization of the percentage of mwbs correctly predicted by threshold values was developed with each possible combination of mdd ranging from 0 to 25 in increments of 1 and precipitation ranging from 0 mm to 10 mm in increments of 0 1 mm a threshold of 4 mdd and 8 mm of precipitation in the 20 days preceding an mwb was selected with an overall accuracy of 96 shown in fig 11c the newly proposed threshold was also tested for use as classification variables obtaining an overall accuracy for mwb severity of 64 this new threshold exceeds both the accuracy in predicting mwbs and the classification accuracy of the previous thresholds when measured against the crid data however it does not outperform the final input set developed above in classifying mwb severity this indicates that while these thresholds have some use in predicting mwb occurrence predictions of the mwb severity are a much more complicated process requiring additional variables to be considered beyond the values presented by the thresholds additionally while these thresholds may provide some early indication of the occurrence of mwbs due to their simplicity they cannot be solely relied on for accurate prediction of mwb timing and additional research would be necessary to develop a more dependable method of predicting the timing of mwbs 4 6 discussion in this study a combination of lasso correlation analysis and input omission was used to select input variables from the initial selection of 130 potential variables using this multi step approach some of the shortcomings of each method were overcome while ensuring that multiple facets of input relationships were considered the variable selection methods have had past successes in previous research and were successful in this application in determining a set of drivers with a strong ability to predict mwb severity but they still have shortcomings for example care must be taken when restricting variables to avoid excluding their potential effects in the classification model and variable distribution should be considered when determining which variables to exclude chowdhury and turin 2020 other methods for input selection exist with their own advantages and shortcomings including methods such as bayesian variable selection best subset regression stepwise selection and principal component analysis george and mcculloch 1997 abdi and williams 2010 zhang 2016 although it is worth noting that there is no universally accepted method these concerns also extend to the model construction where steps were taken in choosing hyperparameters division of testing and training data and model structure to avoid overfitting issues common in machine learning applications for example although random forest is known for its ability to limit overfitting without substantially increasing error yet the risk remains for this model type also though the 90 10 data split is commonly used in the literature for training and testing ahmad et al 2018 you et al 2020 there is no consensus on the optimal split and other ratios e g 80 20 and 70 30 can be found in many other studies garcia and muga 2016 wahid et al 2017 future work to account for this can include the use of different proportions of training and testing data or different algorithms and training techniques uncertainties remain present in the results both in terms of the used data and methods though the data has been quality controlled uncertainties are still present stemming from the numerous sources and quantity of data which increases risk of error some of these issues were encountered in this study and corrections were provided but the risk remains present further uncertainties exist in both the application of variable selection and the random forest algorithm mentch and hooker 2016 and rahmati et al 2019 detailed analysis of these inherent uncertainties may form the basis of future work additionally though the algorithm is successful for the utilised data which includes all possible data for mwbs in crid the algorithm may have issues when encountering data which falls outside of the range of the data used hengl et al 2018 it is recommended to continue refining both the model and thresholds as new data is acquired this is especially important as climate change brings about more extreme and more frequent events which may easily fall outside of the considered ranges closely related to this concern are issues potentially stemming from spatial distribution with a common consequence of models working accurately within the spatial regions for which they were developed but struggling when extended beyond the training region meyer et al 2019 the current model includes data from many rivers across the country however the climate regions they inhabit are quite similar particularly in their capacity for mwbs as climate change continues to alter the expected temperatures in winter the distribution of these events can be expected to shift throughout the country thus the current approach may no longer be applicable with this in mind revisions to the spatial distribution of data when training the model or training separate regional models may be necessary to account for spatial and climatic variability 5 conclusions this study focussed on the analysis of the severity and causes of mwbs which have become increasingly common in canada as a result of climate change this study utilised a newly released dataset the crid to gain insight on mwb events occurring throughout the country the extensive data contained in the crid allowed this study to conduct mwbs analysis on a scale not possible before providing the opportunity for a greater understanding of the main drivers of these events a combination of trend analysis return period analysis attribution analysis and machine learning techniques were employed to gain a better understanding of the early indicators of mwb severity a clear increasing trend in the frequency of mwbs in canada was identified while return period analysis found that these events are consistently more severe than the average ice events on the affected rivers combining traits of the river ice cover in the early parts of the ice season and climate conditions directly preceding the mwb events 130 initial candidate variables were identified the initial variable set was reduced through the application of correlation analysis lasso regression and input omission through this analysis 20 variables that have high link to the traits defining mwb severity were selected these variables include the initial date of freeze up the low flow water levels and flow rate and several variables representing the warming rate and quantities of liquid precipitation occurring during the warming preceding and mwb these variables can be easily monitored in advance of a potential mwb providing the opportunity for detailed forecasting to be developed the strength of these selected variables connection to mwb severity was demonstrated through the construction of a random forest model classifying the return period of the mwbs based on the identified variables this model achieved a high level of accuracy indicating a strong connection between the variables and the severity of the mwb events further this model was compared to previously developed threshold values for the triggering of mwbs as well as a new set of threshold values developed from the extensive data contained in the crid the new threshold 4 mdd and 8 mm of precipitation in the 20 days preceding an mwb consistently outperformed the previous thresholds and coupled with the results of the random forest model provides a new method through which both the occurrence and severity of mwbs throughout the country can be predicted through this major indicators of mwb severity have been identified and their utility in the prediction of mwbs can continue to be researched future studies of these drivers may investigate alternative methods for selection of drivers or model variables such as global sensitivity analysis or principal component analysis ashegi et al 2020 ciriello et al 2019 the study of multiple periodicities present in the time series data as well as data non stationarity is also recommended credit authorship contribution statement michael de coste conceptualization methodology software validation formal analysis visualization writing original draft writing review editing zhong li conceptualization supervision writing review editing funding acquisition yonas dibike resources data curation methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by natural sciences and engineering research council of canada nserc data used is available from environment canada https open canada ca data en dataset c5b58ccd 0011 4a80 8f24 034c86cbc14d and natural resources canada https cfs nrcan gc ca projects 3 4 
