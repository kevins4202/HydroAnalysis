index,text
5080,waterlogging is one of the most important agricultural disasters affecting rice in this study we developed a waterlogging analysis system for paddy fields in irrigation districts with 7 modules including pretreatment hydrological computations and waterlogging computations the newly developed system can consider the effects of both landform features and human interventions in irrigation districts observational data from the gaoyou irrigation district during 2014 and 2015 were applied to calibrate and validate a waterlogging analysis system respectively the results indicated that the waterlogging analysis system could accurately predict the water levels in both the calibration r2 0 97 and validation r2 0 92 periods sensitivity and uncertainty analyses of the yield reduction rate indicated that saturated soil moisture and shape parameters Î± and n were the dominant soil hydrodynamic parameters affecting the simulated yield reduction rates the weighted mean yield reduction rate of field areas decreased with increasing shape parameters and increased with increasing soil moisture saturation however further analysis showed that the maximum yield reduction rate exhibited a trend similar to that of saturated soil moisture which indicated that the backwater effects of the river and ditch water level changes had a greater influence than the soil hydrodynamic parameters on the yield reduction rate especially in low elevation fields in addition the relationship between the yield reduction rate and field elevation could be fitted by an exponential function r2 0 83 and the field pond depth decreased linearly with a reduction in field elevation in both 2014 r2 0 36 p 0 01 and 2015 r2 0 64 p 0 01 the proposed waterlogging analysis system could be a useful tool for evaluating the effects of waterlogging on rice production in the studied irrigation district or in other regions with similar climatic conditions keywords spatial distribution flow direction yield reduction waterlogging modelling 1 introduction 1 1 impact of waterlogging on agriculture waterlogging is the main agricultural disaster that occurs in humid and semi humid regions previous studies have shown that soil o2 is rapidly depleted during waterlogging konnerup et al 2018 luan et al 2018 and that the soil may become hypoxic or anoxic within a few hours moreover some waterlogged soils become devoid of no3 and so4 2 and anaerobic microbial metabolites may accumulate todero et al 2018 malik et al 2002 also noted that even short term waterlogging can have considerable effects on the growth of dryland crops statistical analyses have indicated that more than 22 million hectares of cropland are suffering from waterlogging singh 2017 in china one of the countries with the most frequent waterlogging in the world waterlogging has had great adverse effects on agricultural production li et al 2016 xie et al 2017 rice is one of the most important food crops worldwide and a staple food for more than 60 of china s population studies have shown that waterlogging can reduce rice yields by more than 10 sun et al 2020 zhen et al 2019 in china rice losses due to waterlogging account for 25 of all natural disasters each year shao et al 2019 therefore waterlogging could affect farmers income and cause a series of socio economic problems sarkar et al 2019b ullah and sarkar 2020 in recent decades due to climate change the spatial and temporal distributions of water resources have become increasingly uneven leading to increasingly unexpected and abnormal waterlogging alam and rabbani 2007 liu et al 2011 in addition field drainage water produced during waterlogging generally contains pesticides and chemical fertilizers which increase the risk of water pollution and secondary soil salinization kaur et al 2017 martin 2017 neha et al 2020 si et al 2018 singh 2015 drainage experiments are important for studying waterlogging redelstein et al 2018 tandy et al 2018 however due to the complex distributions of ditches ponds and different crops the achievements gained during field scale experiments are usually difficult to implement in an irrigation district ird moreover regional experiments are always time consuming and costly therefore it is necessary and urgent to conduct modelling studies of waterlogging in an ird 1 2 modelling study of waterlogging simulations of regional waterlogging usually require many physical processes such as evaporation transpiration soil water movement groundwater movement runoff yield and runoff routing of surfaces and rivers shi et al 2010 wang et al 2019a b previous studies usually combined hydrological models with river hydraulic models e g hec hms hec hrs mike she mike 11 and swmm to simulate waterlogging however these combined models were mainly developed for natural basins in an ird the landform features e g remoulded canals and ditches and human intervention e g gates and pump stations are both different from those in natural basins which affect waterlogging modelling 1 2 1 impact of landform features in waterlogging modelling in an ird canals ditches ponds and field ridges are relatively concentrated which could change the water gradient for example canals and ditches affect water movement and enhance the response of runoff routing to precipitation buchanan et al 2012 and ponds affect runoff processes by intercepting and storing precipitation wan and yang 2007 moreover irrigated fields have many entrances and exits and a complicated flow direction considering the above characteristics in an ird researchers improved the original hydrological models for a basin to simulate waterlogging by adding drainage items performing a flow advance calculation in irrigation and drainage ditches improving surface convergence dividing the sub basin or hydrological response units and refining the soil water movement processes as well as the groundwater soil water and river water exchange modules for example carluer and marsily 2004 developed the anthropog model by considering the impact of artificial canals jang et al 2010 proposed tr 20 rice by adding simulations of the water cycle in paddy fields based on the tr 20 model and they found that more precise water circulation results were acquired in a variety of land use regions by the modified model simulation although these modifications improved the simulations of hydrological models in irrigation areas most of the models employ digital elevation models dems to determine the water flow path the river network and sub basin or simulation units however due to the limited resolution of dems the models can distinguish the areas in large river water systems but cannot meticulously describe ditch systems which might distort the drainage network and might not reflect the multi stage canal composition of the irrigation area to overcome this issue previous studies usually inputted a vector of real drainage canals into the model e g swat and corrected the elevation and flow direction by force getirana et al 2009 turcotte et al 2001 however the above solution requires very fine grids to be defined resulting in an extremely large number of parameter values which leads to over parameterization and calculation time problems lagacherie et al 2010 1 2 2 impact of human intervention in waterlogging modelling the occurrence of waterlogging is affected by human interventions such as crop growth gate and pumping station control drainage methods and field ridge blocks wang et al 2019b therefore the effects of human interventions on processes such as runoff soil water movement and groundwater movement must be considered in waterlogging simulations taking runoff as an example different land use conditions e g farmland and urban residential construction sites should be treated differently moreover the backwater effects of field ridges and downstream rivers crop evapotranspiration and constructions such as sluices culverts and pumping stations all need to be considered in terms of soil water and groundwater movement infiltration root water absorption water exchange between saturated and unsaturated soils and lateral flow should also be considered similar to considering landform features previous studies also tried to improve large scale hydrological models to fit the waterlogging simulations in irds by considering human interventions for example zheng et al 2010 improved the production and convergence processes of irrigation ditches the division of distributed irrigation sub basins and hydrological response units and the method used to calculate the actual evapotranspiration of crops simulating the natural artificial mixing of the irrigation basin hydrological cycle in the swat model xie and cui 2011 combined irrigation and drainage processes evapotranspiration calculation modifications and the joint paddy crop model in the swat model which improved the effects of crop yield simulation and drainage management application in paddy fields in addition another feasible method is to expand a field based small scale soil water groundwater model and apply it to an ird barthel and banzhaf 2016 glendenning et al 2012 the field scale model represented by the drainmod field drainage model skaggs et al 2012 which has detailed descriptions of processes such as soil water and groundwater movement surface runoff and crop growth among others but lacks calculations of the surface confluence surface water advance of the canal and regulation by various types of buildings also needs to address the problem of parameter matching at the field and ird scales therefore the expansion of field scale models to ird scale models requires the specialization and scale enhancement of input data and parameters the addition of surface manifold modules and the addition of river and canal manifold modules meanwhile both methods can consider only one or a few parts of the human interventions in irds in waterlogging modelling 1 3 study objectives therefore the objective of this study was to develop a novel waterlogging analysis system was for rice that closely reflects the real characteristics of landform features and human interventions in irds especially in terms of the spatial distribution of canals recognition of flow direction and prediction of yield reduction moreover the newly developed system was calibrated and validated based on precipitation events over a period of two years and sensitivity and uncertainty analyses were also performed to evaluate the availability and reliability of the was 2 materials and methods 2 1 framework of the system the was contains 7 modules for pretreatment 1 module hydrological computations 5 modules and waterlogging computations 1 module fig 1 all these modules were developed based on the openfluid platform version 2 1 0 fabre et al 2010 the openfluid platform was established by the laboratory for the study of soil agrosystem hydrosystem interactions in france lisah for flexibly connecting and managing modules with different functions the modules were first edited encapsulated and compiled with c cmake and qt respectively then all the compiled modules could be flexibly coupled in openfluid as plug ins to constitute the was 2 2 components of the system 2 2 1 spatial distribution and flow direction based on open source geographic information lisah has developed 15 functions for spatial analysis table 1 the was combines these functions to develop the spatial distribution and flow direction module sfm the sfm contains four steps for pretreatment the first step is the spatial treatment of the imported spatial data e g dem soil distributions land use and river and ditch distributions the spatial treatment includes verifying the spatial network relationships and updating the general spatial data second the sfm overlays spatial data to generate a modelling unit mu and separates linear mus lmus and planar mus pmus to determine the flow directions for mus with different properties third the sfm can determine the flow direction for each mu based on the dem or user experience in addition the sfm provides different options to calculate the distance and slope between adjacent mus for further modelling for example to calculate surface elevation the sfm can use the grid in the geometric centre of the mus the geometric centre grid with 8 neighbouring grids or all of grids of the mus fig 2 in the last step the sfm outputs the spatial distribution and flow direction results for further calculations more precisely the linear mu results contain serial numbers upstream and downstream nodes distance slope and flow grades the planar mu results contain the serial number area slope for downstream mus distance to the centre of the downstream mus and flow level 2 2 2 precipitation and evapotranspiration the precipitation module pcm directly uses climate data user input moreover linear interpolation is used if some climate information is missing during the simulation period based on the climate data the evapotranspiration module etm first uses the penman monteith method to calculate the daily reference crop evapotranspiration etref the potential crop evapotranspiration etp is obtained by multiplying the crop coefficient kc by etref water surface evaporation ew is calculated from daily pan records soil evaporation es is obtained by multiplying the conversion factor by ew moreover etp ew and es are converted from daily to hourly data to fit the modelling time step considering different land use types 2 2 3 runoff and soil water movement the runoff and soil water movement module rsm uses water balance theory to describe the change in the surface aquifer eq 1 1 h p t p e i r in eq 1 hp is the ponding depth of the soil surface cm which is the ridge depth for fields and 0 for residential construction sites p is precipitation cm e is soil or water evaporation es or ew cm i is infiltration cm r is surface runoff and t is time in units of days or hours soil water movement is determined by richard s equation eq 2 and the van genuchten vg model van genuchten 1980 is applied for soil water retention characteristics eq 3 2 c Ï Ï t z k Ï Ï z k Ï z t Î³ 3 s Î¸ Î¸ s Î¸ s Î¸ r 1 Î± Ï n m Ï 0 1 Ï 0 in eq 2 Ï is soil matric potential cm c is specific water capacity cm 1 k is hydraulic conductivity cm d 1 Î³ is seepage cm and t is crop transpiration cm in eq 3 Î¸ is soil volumetric content cm3 cm 3 Î¸s is saturated soil moisture cm3 cm 3 Î¸r is residual soil moisture cm3 cm 3 s is soil saturation and Î± cm 1 m and n are empirical shape parameters in the soil water retention function the value of k in eq 2 is calculated using the mualem model mualem 1976 eq 4 and c is the derivative of Ï in eq 3 in addition r and i in eq 1 are calculated by eqs 5 6 4 k Ï k s s l 1 1 s 1 m m 2 Ï 0 k s Ï 0 5 i k Ï Ï t k Ï 6 r max h p max h p max h r b s 0 in eqs 4 6 ks is the saturated hydraulic conductivity cm d 1 l is the shape coefficient 0 5 hp max is the maximum water storage depth cm hr is the water level in the downstream ditch cm and bs is the elevation of the planar mu cm if there is no ponding on the soil surface the seepage is calculated as described by hooghoudt 1940 eqs 7 9 otherwise the equation by qu 1980 is used eqs 10 12 in eqs 7 9 khs is the saturated horizontal permeability coefficient cm d 1 l is the space of the drainage ditch cm hd is the depth of the drainage ditch cm ht is the water depth in the drainage ditch cm hg is the groundwater depth cm pe is the wetted perimeter of the drainage ditch cm and de is the distance between the bottom of the drainage ditch and the impermeable layer cm 7 Î³ 8 k hs d q h d h t h g 4 k hs h d h t h g 2 l 2 h d h t h g 0 0 h d h t h g 0 8 d q Ï l 8 ln l Ï p e f x 9 f x Ï l 8 d e ln d e l 2 Ï d e l 0 5 i 1 4 e 4 i Ï d e l i 1 e 4 i Ï d e l 2 Ï d e l 0 5 10 Î³ k hs h d h t h p Ï 11 Ï 1 Ï a r t h 1 t n 2 Ï b 4 d e k m t n 2 Ï a 0 4 d e k m 12 b 8 Ï b 0 h t m 0 h t 2 in eqs 10 12 b is the equivalent water surface depth cm a0 is the width of the water free zone of the drainage ditch cm and b0 and m0 are the bottom width cm and slope of the drainage ditch respectively here km is the factor of the complete elliptic integral of the first kind the rsm first calculates the infiltration rate and surface runoff based on the surface water potential and ponding depth of the last time step then the ponding depth of the next time step is determined by calculating the water balance the ponding depth of the next time step will be used as the top boundary condition of soil water movement eq 2 and the infiltration rate surface runoff and ponding depth will be updated in each calculation circle until iterative convergence is obtained 2 2 4 field and ditch routing the field routing module frm assumes that surface runoff is from the centre of each planar mu and uses diffusion wave theory to describe the movement of surface runoff from the centre of each planar mu to the boundary eq 13 the ditch routing is calculated by one dimensional saint venant functions strelkoff 1970 in the ditch routing module drm eqs 14 15 13 q su t c 0 q su x d 2 q su x 2 14 a t q x q l 15 q t u q x g a z x g n 0 2 q q a r 4 3 0 in eq 13 qsu is the surface runoff of the entry of the planar mu cm3 h 1 c0 is the wave velocity cm h 1 d is the diffusion coefficient and x is the distance of the diffusion direction cm in eqs 14 15 a is the area of the flow section cm2 q is the flux of the flow section cm3 h 1 ql is the flux per unit width of lateral inflow cm2 h 1 u is the mean velocity of the flow section cm h 1 g is gravitational acceleration m s 2 z is the water level m n0 is the roughness coefficient and r is the hydraulic radius cm in addition the frm can consider constructed field objects such as gates pump stations and culvert pipes using hydraulic equations altunin and chernykh 2016 cozzolino et al 2015 izquierdo et al 1996 2 2 5 waterlogging the crop waterlogging production function wpf can reveal the relationship between crop yield and waterlogging characteristics such as waterlogging time or waterlogging depth at different crop growth stages because rice is the crop most commonly grown in areas with waterlogging suralta and yamauchi 2008 the present study uses rice as the indicator crop the waterlogging module wlm uses the wpf of xiong et al 2018 to quantify the rice yield reduction resulting from waterlogging eqs 16 18 16 y h t 0 h h c a h w h r b t c h h c 17 y t 1 y t Î´ y t 18 Î´ y t y h t t 1 y h t t y h t 1 t 1 y h t 1 t 2 19 h r 0 0059 d a s 2 1 4518 d a s 15 09 100 in eqs 16 18 y is the yield reduction rate hw is the waterlogging depth m t is the accumulated waterlogging time d and hc is the critical waterlogging depth m according to huang 2007 the hc values of rice at the returning green tillering jointing and head sprouting stages are 0 03 m 0 06 m 0 2 m and 0 3 m respectively hr is the rice height m which is a function of the day after sowing das of rice eq 19 here a b and c are empirical parameters determined by xiong et al 2018 table 2 2 2 6 internal relationships the internal relationships between different modules in the was are shown in fig 1 sfm is the basis of the was the discrete mu the flow direction between mus and the spatial properties of each mu determined by sfm will be invoked to initialize other modules the outputs of etm and pcm are the inputs of the rsm the surface ponding depth and the start and end times of the waterlogging will be transferred to the wpf to identify whether the crop is under waterlogging stress seepage is directly entered into the drm as inflow from upstream areas surface runoff is first input into the frm to determine surface drainage and the surface drainage is allocated to the frm or rsm based on the connection between the fields and ditches more precisely if the downstream fields are ditches the surface drainage is allocated to the frm otherwise the surface drainage is allocated to the rsm to calculate the soil water movement in the downstream fields the intermediate water depth of the drm is fed backward into the rsm to consider the backwater effects of ditches on the runoff of fields 2 3 inputs and outputs 2 3 1 inputs the was input includes foundational maps module related parameters and spatial properties table 3 2 3 2 outputs the outputs of planar mus include precipitation rate evapotranspiration rate accumulated rice yield reduction rate ponding depth of the surface seepage surface runoff and surface drainage the outputs of linear mus include the flux and depth of the discharge outlet 2 4 sensitivity and uncertainty analyses few parameters are needed for the was section 2 5 1 and the main parameters are from the vg model therefore 5 parameters of the vg model Î¸r Î¸s Î± n and ks and the ratio of the horizontal and vertical permeability coefficients rhvp were applied for the sensitivity analysis more precisely the base value of the vg model was first determined using a soil transfer function schaap et al 2001 and the average soil texture of the study site section 2 5 1 the base values of Î¸r Î¸s Î± n and ks were 0 0505 cm3 cm 3 0 431 cm3 cm 3 0 0087 1 5496 and 2 79 cm h 1 respectively the base value of rhvp was 30 based on local expert experience the was was operated with 5 10 15 5 10 and 15 of the base values the yield reduction rate for each run was calculated to evaluate the uncertainty of the was in addition the weather scenario for the sensitivity and uncertainty analyses was the occurrence of a storm with a recurrence interval of 50 years at the study site 2 5 model application 2 5 1 demonstrational area and data in this section the developed was model is applied in a sub basin of the gaoyou ird gid located in jiangsu province china fig 3 the selected area covers 2027 ha of which the soil texture 0 30 cm is mainly loam the southern eastern and western boundaries of the area are the nanguan main canal and its two sub canals and the northern boundary is the north chengzi river all drainages of the area flow into the north chengzi river first and then flow out of the area from west to east fig 3 moreover the study area is sloping with elevations ranging from 4 3 m above sea level in the southwest to 2 2 m above sea level in the northeast this area has a typical subtropical climate with an annual mean temperature of 15 c and the average annual rainfall is 1025 mm in addition there are four drainage pumping stations in the study area to control the ponding level fig 3 six water level observation points and one precipitation observation point were selected in the study area fig 3 precipitation was measured by a rain gauge hobo onset rg3 m which provided hourly data six water level observation hobo u20 points were established in the zhongshi river and jiangma river more precisely 2 hobo u20 units were installed in the middle of the zhongshi and jiangma rivers and 4 hobo u20 units were installed before and after the gates at the end of the zhongshi and jiangma rivers the resolution of the hobo u20 is 1 cm and the hobo u20 can provide hourly measurements automatically basic meteorological data including maximum and minimum temperature relative humidity wind speed sunshine duration and atmospheric pressure were obtained from the gaoyou meteorological station which is located 6 km from the study area information about the soils rivers and drains e g distribution transverse section size slope and pumping stations was collected from the gaoyou water supplies bureau rice was selected as the indicator crop for testing the system and the characteristics of rice such as its crop coefficient 1 488 and crop height were acquired from previous studies gao et al 2016 shi et al 2013 2 5 2 system configuration the initial pmu was the overlay area of the lateral controlling ditch and its land use while the initial minimum lmu was the river and the lateral ditch the sfm first determined the flow direction automatically based on the spatially adjacent relations and elevations of each pmu and lmu then an artificial check was applied to guarantee the accuracy of the flow direction the study region in the gid was divided into 368 lmus and 1073 pmus including 566 paddy fields 365 small reservoirs and 142 places of residence furthermore the pmu was separated into 10 layers vertically and the deepest soil depth was 1 5 m moreover each lmu was divided into several transverse sections along the river specifically for the lengths of the river in the ranges of 15 m 50 m 50 m 200 m and 200 m 500 m the transverse sections were 15 20 and 25 respectively when the river length was longer than 500 m it was separated into 30 transverse sections therefore 8921 transverse sections were determined for 368 lmus the upper boundary was hourly precipitation and evapotranspiration the soil depth in the present simulation was 1 5 m and the soil at this depth was saturated during the entire rice growth stage therefore the vertical water exchange was neglected and the lower boundary was set as an impermeable boundary the horizontal boundary was the measured water level in the north chengzi river the initial conditions included the initial ponding depth river water level and soil moisture distribution in the soil profile specifically the initial ponding depths for the field and places of residence were 0 and 1 5 m respectively for a small reservoir and the observed value was used to initialize the river water level and the soil moisture content a dynamic time step was used for the rsm and frm more precisely the minimum and maximum time steps for the rsm were 36 s and 180 s respectively and the maximum number of iterations for each time step was 100 the maximum time step of the hayami kernel function moussa 1996 in the frm was 100 s and the time step of the drm was 0 1 s the time of data exchange among the different modules was 60 s furthermore the hourly pcm and etm data were first interpolated into a minute scale and then exchanged with the other modules last the surface ponding depths were converted into daily average values and transferred to the wlm to determine the yield reduction rate 2 5 3 calibration and validation the river water levels observed from august 13 to august 17 2014 were used to calibrate the was this period was usually the critical stage flowering stage of rice which was also the period with concentrated precipitation in the study area gao et al 2016 the accumulated precipitation in the calibration period was 133 8 mm the maximum precipitation in 24 h was 108 8 mm and the maximum rainfall intensity was 18 4 mm h fig 4 a during the calibration period all of the drainage gates were open while all of the pump stations were closed the validation period was august 9 to august 19 2015 the accumulated precipitation in the validation period was 327 6 mm the maximum precipitation in 24 h was 269 2 mm and the maximum rainfall intensity was 47 4 mm h fig 4b because the precipitation process in the validation period was intensive only a portion of the pump stations worked during the validation period table 4 2 5 4 evaluation five statistical indicators namely the coefficient of determination r2 relative error re eq 20 nash sutcliffe coefficient nsc eq 21 mean residual ratio mrr eq 22 and dispersed root mean square ratio drmse eq 23 were used to evaluate the simulation accuracy for both the calibration and validation periods 20 re i 1 n s i o i i 1 n o i 100 21 nsc 1 i 1 n s i o i 2 i 1 n o i o mean 2 22 mrr i 1 n s i o i n Î´ o 23 drmse i 1 n s i o i 2 n Î´ o 3 results 3 1 sensitivity and uncertainty analyses 3 1 1 maximum yield reduction rate the maximum yield reduction rate myrr increased with the change in Î¸s compared with the base value fig 5 a specifically as Î¸s increased at rates of 5 10 and 15 the myrr increased by 9 92 4 65 and 2 71 respectively furthermore the myrr increased by 6 45 8 39 and 9 92 as Î¸s decreased at rates of 5 10 and 15 respectively in contrast to Î¸s the change in Î¸r from 15 to 15 had little effect on the myrr 0 06 0 35 moreover the myrr increased at rates of 0 63 1 18 and 1 32 and ks increased from 5 to 15 moreover with a decrease in ks at rates of 5 and 10 the myrr increased by 1 46 and 2 57 respectively however the myrr decreased by 1 03 with a 15 reduction in ks in addition the myrr showed an opposite trend compared with those of Î± and n for example the myrr increased by 5 76 and 6 59 with a 15 decrease in Î± and n and a 15 increase in Î± and n decreased the myrr by 3 67 and 1 45 respectively the sensitivity of the rhvp was similar to that of ks and the myrr decreased by only 2 28 when the reduction in rhvp was as large as 15 while the myrr had increasing rates of 0 08 to 2 57 with other variations in rhvp 3 1 2 weighted mean yield reduction rate the effects of the six selected parameters on the weighted mean yield reduction rates wyrrs of the field area are shown in fig 5b only Î¸s and Î± had relatively strong effects on the wyrr taking Î¸s as an example with Î¸s increasing at rates of 5 10 and 15 the wyrr decreased by 0 2 25 and 5 62 respectively the wyrr increased by 2 25 3 37 and 5 62 as Î¸s decreased at rates of 5 10 and 15 respectively moreover a decrease in parameter n had a slight effect on the wyrr more precisely the wyrr increased by 1 12 2 25 and 3 37 as n decreased at rates of 5 10 and 15 respectively 3 1 3 uncertainty analysis the uncertainties for both the myrr and wyrr were mainly caused by Î¸s Î± and n for example the ranges of the variation in the myrr were 7 41 7 93 6 95 7 63 and 7 11 7 69 for Î¸s Î± and n rates of 5 10 and 15 respectively for the wyrr the ranges of the variation were 0 84 0 94 0 86 0 92 and 0 88 0 92 respectively fig 6 in contrast the uncertainties for the myrr caused by ks and rhvp were low and the changes were 0 26 and 0 35 respectively moreover the change in the myrr caused by the change in Î¸r was only 0 04 similar to those for the myrr the uncertainties for the wyrr caused by Î¸r ks and rhvp were low and the changes were all smaller than 0 01 fig 6 3 2 calibration and validation the simulated water levels in the calibration process are shown in fig 7 with the calibrated parameters table 5 the simulated and observed water levels in the middle and at the end of the zhongshi river and jiangma river had similar trends the r2 and nsc at the four locations were all greater than 0 9 table 6 furthermore the re values in the middle and at the end of the zhongshi river were 2 62 and 2 47 respectively and those of the jiangma river were 2 48 and 1 31 respectively the mrr and drmse in the zhongshi river and in the middle of the jiangma river ranged from 7 32 to 8 82 respectively moreover the mrr and drmse at the end of the jiangma river were 4 32 and 5 13 respectively based on the validation results the model also had very high accuracy in the middle of the zhongshi river and the jiangma river and at the end of the jiangma river the nscs of the above three locations were all approximately 0 94 and the mrrs were 4 30 5 06 and 5 90 respectively fig 8 furthermore the drmses at these three locations were smaller than 8 however the model overestimated the water level at the end of the zhongshi river during the validation process fig 8c more precisely the re nsc mrr and drmse values at the end of the zhongshi river were 5 84 0 78 11 07 and 14 77 respectively 3 3 yield reduction due to waterlogging no yield reduction was found in the calibration period 2014 in the validation period 2015 approximately 53 of fields accounting for 60 of the studied areas had different levels of yield reduction fig 9 moreover fields in the east had a higher rice yield reduction rate than other locations furthermore the reduction rates in 99 12 of the fields were smaller than 4 and only 1 field had a reduction rate larger than 9 fig 9b in regard to the considered area only 19 5 ha of the field area approximately 1 2 of the total field area suffered from yield reductions that were greater than 4 fig 9c 4 discussion 4 1 sensitivity and uncertainty analyses the sensitivity and uncertainty analyses indicated that Î¸s Î± and n were the three parameters with the greatest effects on the simulated yield reduction rates figs 5 and 6 the variation trend of the wyrr was opposite to that of Î¸s because the soil water holding capacity increased with Î¸s in addition both the wyrr and myrr had opposite variation trends with the soil properties Î± and n the curves in fig 10 show the relationships between the pressure head and soil moisture with different Î± and n values the curves moved up as Î± or n decreased furthermore larger Î± or n values indicated that the soil texture was similar to that of sand which has a poor soil water holding capacity hwang et al 2002 minasny et al 1999 wÃ¶sten et al 2001 however our study found that the myrr increased with increasing Î¸s one possible reason was that the yield reductions in our model were determined not only by the soil properties such as Î¸s but also by the boundary conditions such as the geography and water levels in the drainage ditches wesseling and feddes 2006 xu et al 2013 the myrr mainly occurred in fields with low elevation fig 10 in these fields the interactions between precipitation surface and sub surface drainages and soil properties were very complex causing the backwater effects of the water levels in the ditches to be larger than the effects of soil properties e g Î¸s on the myrr boem et al 1996 matson et al 1997 abbas et al 2018 and sharma et al 2003 also reported that soil hydrodynamic properties could affect crop yield reductions under waterlogging 4 2 yield reduction field ponding and backwater effects no yield reductions were found in the calibration period because the precipitation in the calibration period was relatively low 133 8 mm and the ponding depth was almost smaller than the field ridge depth 10 cm in the validation period high precipitation 327 6 mm caused yield reductions in many fields mainly due to the backwater effects of the high drainage ditch level le et al 2007 which was in accordance with the sensitivity and uncertainty analyses in addition our study showed that the yield reduction was exponentially reduced with increasing field elevation r2 0 8 fig 11 field elevation also affected the ponding processes and backwater effects the elevations of fields 178 946 and 812 were 2 9 m 2 6 m and 2 3 m respectively fig 12 a in field 178 due to the high topography the maximum ponding depth was the field ridge depth 10 cm and drains had no backwater effects on surface runoff yields therefore the ponding process curve decreased at a relatively constant rate after precipitation and no yield reduction occurred in field 178 fig 12b in fields 946 and 812 because of the low elevations the maximum ponding depths were 16 69 cm and 18 29 cm and the yield reduction rates were 0 87 and 3 32 respectively fig 12a in contrast to that in field 812 the ponding depth decreased rapidly close the first precipitation event august 11 2015 during the validation period in field 946 fig 12b this rapid decrease potentially resulted from the large amount of precipitation that accumulated above the field ridge that could not be discharged due to the backwater effects of the drains once the water levels in the drains were lower than the height of the field ridge ponding on the field surface quickly ceased fig 12b furthermore fig 13 b indicates that the slope of the ponding process curve in field 946 gradually decreased after the ponding depth decreased to less than that of the field ridge more precisely the slope from august 12 to august 13 was smaller than that from august 13 to august 16 this phenomenon could also be explained by the backwater effect specifically as the drainage route changed from the surface to the sub surface when the ponding depth was smaller than the height of the field ridge the water level in the drains and the ponding depth decreased which weakened the backwater effects of the drains hussein et al 2007 however due to the low elevation of field 812 the water level of the drain was higher than that of the field ridge between the first precipitation event and august 15 causing the slope of the ponding depth curve to decrease at a lower rate than that observed for fields 178 and 946 therefore the backwater effects of the drains decreased with field elevation similar observations were also made by metcalfe et al 2017 chang et al 2018 hatton et al 2002 and akter et al 2017 in addition we found that the maximum ponding depth could be determined from field elevation fig 13 one possible reason for this result could be the backwater effects of the drains fields at lower elevations could experience more obvious backwater effects than those at higher elevations which would reduce the drainage rate and increase the ponding depth schmitt et al 2004 moreover the r2 between the field ponding depth and elevation in 2015 r2 0 64 was higher than that in 2014 r2 0 36 indicating that higher precipitation also promoted backwater effects 4 3 merits and limitations compared with other models such as swat or its modified versions wang and cui 2011 xie and cui 2011 and mike wang et al 2019a the was merged the dem and spatial topological relationships with customized definitions to establish hydraulic connections among different mus therefore the was does not require a very high resolution dem to reflect different ditch levels in the gid furthermore the was was used for the river around the gid as a boundary to consider the interactive effects among the outside of the river the end level of the ditch and the ancillary buildings including the water gate and pump stations on the agricultural drainage processes although some distributed drainage models such as drainmod gis could also be extended to the outside boundary fernandez et al 2006 the was described soil water movement accurately eqs 2 3 and considered the effects of the ditch water level on surface drainage e g backwater effects in addition the was could consider the effects of ridge depth and backwater on the pond depth calculations which might be more appropriate for the gid than the majority of hydrological models kan et al 2017 ma et al 2018 yang et al 2004 moreover the was has a user friendly interface and the transparency and modularity of the was structure can help users better understand and use the system these features could be very attractive to potential users who are mainly managers of irds ahmed and sarkar 2019 sarkar et al 2019a umakanta et al 2020 therefore the extension and application of the was can aid in waterlogging management in irds and increase rice yield and farmers income in addition the modular programming ideas of the was can also be applied to develop systems for other fields of study such as the management of energy socio economic and policy decisions khan et al 2019 sarkar et al 2020 tiwari et al 2019 however there are still some limitations in the present was first serial computing is used in the was which requires more time for calculation than parallel computing second the present was could consider only rice and more crops should be added to the was in the future third the yield reduction rate of rice is determined based on the dynamics of the simulated ponding depth and the crop wpf however this method is essentially empirical and does not consider the crop growth mechanism 5 conclusions in this study we developed a novel was that could consider the effects of both landform features and human interventions in irds the water level and rice yield data observed in the gid in 2014 and 2015 were used to calibrate and validate the was respectively the calibration and validation indicated that was could provide very accurate predictions for water levels in the gid and yield reduction rates for rice crops sensitivity and uncertainty analyses indicated that Î¸s Î± and n were the three soil hydrodynamic parameters with the greatest impacts on the simulated yield reduction rates furthermore field elevation exhibited good relationships with the yield reduction rate and field pond depth boundary conditions such as the river and ditch water levels had greater impacts than the soil hydrodynamic parameters on yield reduction in the was especially for low elevation fields in addition the was has a friendly interface and the transparency and modularity of the was structure can help the managers of irds better understand waterlogging and decrease the risk of rice yield reduction future studies should focus more on the mechanisms of the interactions between crop growth soil hydrodynamic parameters boundary conditions weather and regional geography to accurately evaluate waterlogging credit authorship contribution statement haorui chen methodology writing original draft wenzhi zeng supervision conceptualization writing original draft yinlong jin visualization investigation writing review editing yuanyuan zha writing original draft boyu mi data curation software validation shaohui zhang writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national key research and development program of china 2017yfc0403302 2017yfc0403205 2016yfc0501301 2019yfc049203 the open research fund of the state key laboratory of simulation and regulation of water cycle in river basin china institute of water resources and hydropower research grant no iwhr skl kf201814 the crsri open research program program sn ckwv2017528 ky the national natural science foundation of china grant no 51779273 51609175 51879196 and 51790533 and the basic research fund of china s institute of water resources and hydropower research gg0145b502017 mk2019j03 
5080,waterlogging is one of the most important agricultural disasters affecting rice in this study we developed a waterlogging analysis system for paddy fields in irrigation districts with 7 modules including pretreatment hydrological computations and waterlogging computations the newly developed system can consider the effects of both landform features and human interventions in irrigation districts observational data from the gaoyou irrigation district during 2014 and 2015 were applied to calibrate and validate a waterlogging analysis system respectively the results indicated that the waterlogging analysis system could accurately predict the water levels in both the calibration r2 0 97 and validation r2 0 92 periods sensitivity and uncertainty analyses of the yield reduction rate indicated that saturated soil moisture and shape parameters Î± and n were the dominant soil hydrodynamic parameters affecting the simulated yield reduction rates the weighted mean yield reduction rate of field areas decreased with increasing shape parameters and increased with increasing soil moisture saturation however further analysis showed that the maximum yield reduction rate exhibited a trend similar to that of saturated soil moisture which indicated that the backwater effects of the river and ditch water level changes had a greater influence than the soil hydrodynamic parameters on the yield reduction rate especially in low elevation fields in addition the relationship between the yield reduction rate and field elevation could be fitted by an exponential function r2 0 83 and the field pond depth decreased linearly with a reduction in field elevation in both 2014 r2 0 36 p 0 01 and 2015 r2 0 64 p 0 01 the proposed waterlogging analysis system could be a useful tool for evaluating the effects of waterlogging on rice production in the studied irrigation district or in other regions with similar climatic conditions keywords spatial distribution flow direction yield reduction waterlogging modelling 1 introduction 1 1 impact of waterlogging on agriculture waterlogging is the main agricultural disaster that occurs in humid and semi humid regions previous studies have shown that soil o2 is rapidly depleted during waterlogging konnerup et al 2018 luan et al 2018 and that the soil may become hypoxic or anoxic within a few hours moreover some waterlogged soils become devoid of no3 and so4 2 and anaerobic microbial metabolites may accumulate todero et al 2018 malik et al 2002 also noted that even short term waterlogging can have considerable effects on the growth of dryland crops statistical analyses have indicated that more than 22 million hectares of cropland are suffering from waterlogging singh 2017 in china one of the countries with the most frequent waterlogging in the world waterlogging has had great adverse effects on agricultural production li et al 2016 xie et al 2017 rice is one of the most important food crops worldwide and a staple food for more than 60 of china s population studies have shown that waterlogging can reduce rice yields by more than 10 sun et al 2020 zhen et al 2019 in china rice losses due to waterlogging account for 25 of all natural disasters each year shao et al 2019 therefore waterlogging could affect farmers income and cause a series of socio economic problems sarkar et al 2019b ullah and sarkar 2020 in recent decades due to climate change the spatial and temporal distributions of water resources have become increasingly uneven leading to increasingly unexpected and abnormal waterlogging alam and rabbani 2007 liu et al 2011 in addition field drainage water produced during waterlogging generally contains pesticides and chemical fertilizers which increase the risk of water pollution and secondary soil salinization kaur et al 2017 martin 2017 neha et al 2020 si et al 2018 singh 2015 drainage experiments are important for studying waterlogging redelstein et al 2018 tandy et al 2018 however due to the complex distributions of ditches ponds and different crops the achievements gained during field scale experiments are usually difficult to implement in an irrigation district ird moreover regional experiments are always time consuming and costly therefore it is necessary and urgent to conduct modelling studies of waterlogging in an ird 1 2 modelling study of waterlogging simulations of regional waterlogging usually require many physical processes such as evaporation transpiration soil water movement groundwater movement runoff yield and runoff routing of surfaces and rivers shi et al 2010 wang et al 2019a b previous studies usually combined hydrological models with river hydraulic models e g hec hms hec hrs mike she mike 11 and swmm to simulate waterlogging however these combined models were mainly developed for natural basins in an ird the landform features e g remoulded canals and ditches and human intervention e g gates and pump stations are both different from those in natural basins which affect waterlogging modelling 1 2 1 impact of landform features in waterlogging modelling in an ird canals ditches ponds and field ridges are relatively concentrated which could change the water gradient for example canals and ditches affect water movement and enhance the response of runoff routing to precipitation buchanan et al 2012 and ponds affect runoff processes by intercepting and storing precipitation wan and yang 2007 moreover irrigated fields have many entrances and exits and a complicated flow direction considering the above characteristics in an ird researchers improved the original hydrological models for a basin to simulate waterlogging by adding drainage items performing a flow advance calculation in irrigation and drainage ditches improving surface convergence dividing the sub basin or hydrological response units and refining the soil water movement processes as well as the groundwater soil water and river water exchange modules for example carluer and marsily 2004 developed the anthropog model by considering the impact of artificial canals jang et al 2010 proposed tr 20 rice by adding simulations of the water cycle in paddy fields based on the tr 20 model and they found that more precise water circulation results were acquired in a variety of land use regions by the modified model simulation although these modifications improved the simulations of hydrological models in irrigation areas most of the models employ digital elevation models dems to determine the water flow path the river network and sub basin or simulation units however due to the limited resolution of dems the models can distinguish the areas in large river water systems but cannot meticulously describe ditch systems which might distort the drainage network and might not reflect the multi stage canal composition of the irrigation area to overcome this issue previous studies usually inputted a vector of real drainage canals into the model e g swat and corrected the elevation and flow direction by force getirana et al 2009 turcotte et al 2001 however the above solution requires very fine grids to be defined resulting in an extremely large number of parameter values which leads to over parameterization and calculation time problems lagacherie et al 2010 1 2 2 impact of human intervention in waterlogging modelling the occurrence of waterlogging is affected by human interventions such as crop growth gate and pumping station control drainage methods and field ridge blocks wang et al 2019b therefore the effects of human interventions on processes such as runoff soil water movement and groundwater movement must be considered in waterlogging simulations taking runoff as an example different land use conditions e g farmland and urban residential construction sites should be treated differently moreover the backwater effects of field ridges and downstream rivers crop evapotranspiration and constructions such as sluices culverts and pumping stations all need to be considered in terms of soil water and groundwater movement infiltration root water absorption water exchange between saturated and unsaturated soils and lateral flow should also be considered similar to considering landform features previous studies also tried to improve large scale hydrological models to fit the waterlogging simulations in irds by considering human interventions for example zheng et al 2010 improved the production and convergence processes of irrigation ditches the division of distributed irrigation sub basins and hydrological response units and the method used to calculate the actual evapotranspiration of crops simulating the natural artificial mixing of the irrigation basin hydrological cycle in the swat model xie and cui 2011 combined irrigation and drainage processes evapotranspiration calculation modifications and the joint paddy crop model in the swat model which improved the effects of crop yield simulation and drainage management application in paddy fields in addition another feasible method is to expand a field based small scale soil water groundwater model and apply it to an ird barthel and banzhaf 2016 glendenning et al 2012 the field scale model represented by the drainmod field drainage model skaggs et al 2012 which has detailed descriptions of processes such as soil water and groundwater movement surface runoff and crop growth among others but lacks calculations of the surface confluence surface water advance of the canal and regulation by various types of buildings also needs to address the problem of parameter matching at the field and ird scales therefore the expansion of field scale models to ird scale models requires the specialization and scale enhancement of input data and parameters the addition of surface manifold modules and the addition of river and canal manifold modules meanwhile both methods can consider only one or a few parts of the human interventions in irds in waterlogging modelling 1 3 study objectives therefore the objective of this study was to develop a novel waterlogging analysis system was for rice that closely reflects the real characteristics of landform features and human interventions in irds especially in terms of the spatial distribution of canals recognition of flow direction and prediction of yield reduction moreover the newly developed system was calibrated and validated based on precipitation events over a period of two years and sensitivity and uncertainty analyses were also performed to evaluate the availability and reliability of the was 2 materials and methods 2 1 framework of the system the was contains 7 modules for pretreatment 1 module hydrological computations 5 modules and waterlogging computations 1 module fig 1 all these modules were developed based on the openfluid platform version 2 1 0 fabre et al 2010 the openfluid platform was established by the laboratory for the study of soil agrosystem hydrosystem interactions in france lisah for flexibly connecting and managing modules with different functions the modules were first edited encapsulated and compiled with c cmake and qt respectively then all the compiled modules could be flexibly coupled in openfluid as plug ins to constitute the was 2 2 components of the system 2 2 1 spatial distribution and flow direction based on open source geographic information lisah has developed 15 functions for spatial analysis table 1 the was combines these functions to develop the spatial distribution and flow direction module sfm the sfm contains four steps for pretreatment the first step is the spatial treatment of the imported spatial data e g dem soil distributions land use and river and ditch distributions the spatial treatment includes verifying the spatial network relationships and updating the general spatial data second the sfm overlays spatial data to generate a modelling unit mu and separates linear mus lmus and planar mus pmus to determine the flow directions for mus with different properties third the sfm can determine the flow direction for each mu based on the dem or user experience in addition the sfm provides different options to calculate the distance and slope between adjacent mus for further modelling for example to calculate surface elevation the sfm can use the grid in the geometric centre of the mus the geometric centre grid with 8 neighbouring grids or all of grids of the mus fig 2 in the last step the sfm outputs the spatial distribution and flow direction results for further calculations more precisely the linear mu results contain serial numbers upstream and downstream nodes distance slope and flow grades the planar mu results contain the serial number area slope for downstream mus distance to the centre of the downstream mus and flow level 2 2 2 precipitation and evapotranspiration the precipitation module pcm directly uses climate data user input moreover linear interpolation is used if some climate information is missing during the simulation period based on the climate data the evapotranspiration module etm first uses the penman monteith method to calculate the daily reference crop evapotranspiration etref the potential crop evapotranspiration etp is obtained by multiplying the crop coefficient kc by etref water surface evaporation ew is calculated from daily pan records soil evaporation es is obtained by multiplying the conversion factor by ew moreover etp ew and es are converted from daily to hourly data to fit the modelling time step considering different land use types 2 2 3 runoff and soil water movement the runoff and soil water movement module rsm uses water balance theory to describe the change in the surface aquifer eq 1 1 h p t p e i r in eq 1 hp is the ponding depth of the soil surface cm which is the ridge depth for fields and 0 for residential construction sites p is precipitation cm e is soil or water evaporation es or ew cm i is infiltration cm r is surface runoff and t is time in units of days or hours soil water movement is determined by richard s equation eq 2 and the van genuchten vg model van genuchten 1980 is applied for soil water retention characteristics eq 3 2 c Ï Ï t z k Ï Ï z k Ï z t Î³ 3 s Î¸ Î¸ s Î¸ s Î¸ r 1 Î± Ï n m Ï 0 1 Ï 0 in eq 2 Ï is soil matric potential cm c is specific water capacity cm 1 k is hydraulic conductivity cm d 1 Î³ is seepage cm and t is crop transpiration cm in eq 3 Î¸ is soil volumetric content cm3 cm 3 Î¸s is saturated soil moisture cm3 cm 3 Î¸r is residual soil moisture cm3 cm 3 s is soil saturation and Î± cm 1 m and n are empirical shape parameters in the soil water retention function the value of k in eq 2 is calculated using the mualem model mualem 1976 eq 4 and c is the derivative of Ï in eq 3 in addition r and i in eq 1 are calculated by eqs 5 6 4 k Ï k s s l 1 1 s 1 m m 2 Ï 0 k s Ï 0 5 i k Ï Ï t k Ï 6 r max h p max h p max h r b s 0 in eqs 4 6 ks is the saturated hydraulic conductivity cm d 1 l is the shape coefficient 0 5 hp max is the maximum water storage depth cm hr is the water level in the downstream ditch cm and bs is the elevation of the planar mu cm if there is no ponding on the soil surface the seepage is calculated as described by hooghoudt 1940 eqs 7 9 otherwise the equation by qu 1980 is used eqs 10 12 in eqs 7 9 khs is the saturated horizontal permeability coefficient cm d 1 l is the space of the drainage ditch cm hd is the depth of the drainage ditch cm ht is the water depth in the drainage ditch cm hg is the groundwater depth cm pe is the wetted perimeter of the drainage ditch cm and de is the distance between the bottom of the drainage ditch and the impermeable layer cm 7 Î³ 8 k hs d q h d h t h g 4 k hs h d h t h g 2 l 2 h d h t h g 0 0 h d h t h g 0 8 d q Ï l 8 ln l Ï p e f x 9 f x Ï l 8 d e ln d e l 2 Ï d e l 0 5 i 1 4 e 4 i Ï d e l i 1 e 4 i Ï d e l 2 Ï d e l 0 5 10 Î³ k hs h d h t h p Ï 11 Ï 1 Ï a r t h 1 t n 2 Ï b 4 d e k m t n 2 Ï a 0 4 d e k m 12 b 8 Ï b 0 h t m 0 h t 2 in eqs 10 12 b is the equivalent water surface depth cm a0 is the width of the water free zone of the drainage ditch cm and b0 and m0 are the bottom width cm and slope of the drainage ditch respectively here km is the factor of the complete elliptic integral of the first kind the rsm first calculates the infiltration rate and surface runoff based on the surface water potential and ponding depth of the last time step then the ponding depth of the next time step is determined by calculating the water balance the ponding depth of the next time step will be used as the top boundary condition of soil water movement eq 2 and the infiltration rate surface runoff and ponding depth will be updated in each calculation circle until iterative convergence is obtained 2 2 4 field and ditch routing the field routing module frm assumes that surface runoff is from the centre of each planar mu and uses diffusion wave theory to describe the movement of surface runoff from the centre of each planar mu to the boundary eq 13 the ditch routing is calculated by one dimensional saint venant functions strelkoff 1970 in the ditch routing module drm eqs 14 15 13 q su t c 0 q su x d 2 q su x 2 14 a t q x q l 15 q t u q x g a z x g n 0 2 q q a r 4 3 0 in eq 13 qsu is the surface runoff of the entry of the planar mu cm3 h 1 c0 is the wave velocity cm h 1 d is the diffusion coefficient and x is the distance of the diffusion direction cm in eqs 14 15 a is the area of the flow section cm2 q is the flux of the flow section cm3 h 1 ql is the flux per unit width of lateral inflow cm2 h 1 u is the mean velocity of the flow section cm h 1 g is gravitational acceleration m s 2 z is the water level m n0 is the roughness coefficient and r is the hydraulic radius cm in addition the frm can consider constructed field objects such as gates pump stations and culvert pipes using hydraulic equations altunin and chernykh 2016 cozzolino et al 2015 izquierdo et al 1996 2 2 5 waterlogging the crop waterlogging production function wpf can reveal the relationship between crop yield and waterlogging characteristics such as waterlogging time or waterlogging depth at different crop growth stages because rice is the crop most commonly grown in areas with waterlogging suralta and yamauchi 2008 the present study uses rice as the indicator crop the waterlogging module wlm uses the wpf of xiong et al 2018 to quantify the rice yield reduction resulting from waterlogging eqs 16 18 16 y h t 0 h h c a h w h r b t c h h c 17 y t 1 y t Î´ y t 18 Î´ y t y h t t 1 y h t t y h t 1 t 1 y h t 1 t 2 19 h r 0 0059 d a s 2 1 4518 d a s 15 09 100 in eqs 16 18 y is the yield reduction rate hw is the waterlogging depth m t is the accumulated waterlogging time d and hc is the critical waterlogging depth m according to huang 2007 the hc values of rice at the returning green tillering jointing and head sprouting stages are 0 03 m 0 06 m 0 2 m and 0 3 m respectively hr is the rice height m which is a function of the day after sowing das of rice eq 19 here a b and c are empirical parameters determined by xiong et al 2018 table 2 2 2 6 internal relationships the internal relationships between different modules in the was are shown in fig 1 sfm is the basis of the was the discrete mu the flow direction between mus and the spatial properties of each mu determined by sfm will be invoked to initialize other modules the outputs of etm and pcm are the inputs of the rsm the surface ponding depth and the start and end times of the waterlogging will be transferred to the wpf to identify whether the crop is under waterlogging stress seepage is directly entered into the drm as inflow from upstream areas surface runoff is first input into the frm to determine surface drainage and the surface drainage is allocated to the frm or rsm based on the connection between the fields and ditches more precisely if the downstream fields are ditches the surface drainage is allocated to the frm otherwise the surface drainage is allocated to the rsm to calculate the soil water movement in the downstream fields the intermediate water depth of the drm is fed backward into the rsm to consider the backwater effects of ditches on the runoff of fields 2 3 inputs and outputs 2 3 1 inputs the was input includes foundational maps module related parameters and spatial properties table 3 2 3 2 outputs the outputs of planar mus include precipitation rate evapotranspiration rate accumulated rice yield reduction rate ponding depth of the surface seepage surface runoff and surface drainage the outputs of linear mus include the flux and depth of the discharge outlet 2 4 sensitivity and uncertainty analyses few parameters are needed for the was section 2 5 1 and the main parameters are from the vg model therefore 5 parameters of the vg model Î¸r Î¸s Î± n and ks and the ratio of the horizontal and vertical permeability coefficients rhvp were applied for the sensitivity analysis more precisely the base value of the vg model was first determined using a soil transfer function schaap et al 2001 and the average soil texture of the study site section 2 5 1 the base values of Î¸r Î¸s Î± n and ks were 0 0505 cm3 cm 3 0 431 cm3 cm 3 0 0087 1 5496 and 2 79 cm h 1 respectively the base value of rhvp was 30 based on local expert experience the was was operated with 5 10 15 5 10 and 15 of the base values the yield reduction rate for each run was calculated to evaluate the uncertainty of the was in addition the weather scenario for the sensitivity and uncertainty analyses was the occurrence of a storm with a recurrence interval of 50 years at the study site 2 5 model application 2 5 1 demonstrational area and data in this section the developed was model is applied in a sub basin of the gaoyou ird gid located in jiangsu province china fig 3 the selected area covers 2027 ha of which the soil texture 0 30 cm is mainly loam the southern eastern and western boundaries of the area are the nanguan main canal and its two sub canals and the northern boundary is the north chengzi river all drainages of the area flow into the north chengzi river first and then flow out of the area from west to east fig 3 moreover the study area is sloping with elevations ranging from 4 3 m above sea level in the southwest to 2 2 m above sea level in the northeast this area has a typical subtropical climate with an annual mean temperature of 15 c and the average annual rainfall is 1025 mm in addition there are four drainage pumping stations in the study area to control the ponding level fig 3 six water level observation points and one precipitation observation point were selected in the study area fig 3 precipitation was measured by a rain gauge hobo onset rg3 m which provided hourly data six water level observation hobo u20 points were established in the zhongshi river and jiangma river more precisely 2 hobo u20 units were installed in the middle of the zhongshi and jiangma rivers and 4 hobo u20 units were installed before and after the gates at the end of the zhongshi and jiangma rivers the resolution of the hobo u20 is 1 cm and the hobo u20 can provide hourly measurements automatically basic meteorological data including maximum and minimum temperature relative humidity wind speed sunshine duration and atmospheric pressure were obtained from the gaoyou meteorological station which is located 6 km from the study area information about the soils rivers and drains e g distribution transverse section size slope and pumping stations was collected from the gaoyou water supplies bureau rice was selected as the indicator crop for testing the system and the characteristics of rice such as its crop coefficient 1 488 and crop height were acquired from previous studies gao et al 2016 shi et al 2013 2 5 2 system configuration the initial pmu was the overlay area of the lateral controlling ditch and its land use while the initial minimum lmu was the river and the lateral ditch the sfm first determined the flow direction automatically based on the spatially adjacent relations and elevations of each pmu and lmu then an artificial check was applied to guarantee the accuracy of the flow direction the study region in the gid was divided into 368 lmus and 1073 pmus including 566 paddy fields 365 small reservoirs and 142 places of residence furthermore the pmu was separated into 10 layers vertically and the deepest soil depth was 1 5 m moreover each lmu was divided into several transverse sections along the river specifically for the lengths of the river in the ranges of 15 m 50 m 50 m 200 m and 200 m 500 m the transverse sections were 15 20 and 25 respectively when the river length was longer than 500 m it was separated into 30 transverse sections therefore 8921 transverse sections were determined for 368 lmus the upper boundary was hourly precipitation and evapotranspiration the soil depth in the present simulation was 1 5 m and the soil at this depth was saturated during the entire rice growth stage therefore the vertical water exchange was neglected and the lower boundary was set as an impermeable boundary the horizontal boundary was the measured water level in the north chengzi river the initial conditions included the initial ponding depth river water level and soil moisture distribution in the soil profile specifically the initial ponding depths for the field and places of residence were 0 and 1 5 m respectively for a small reservoir and the observed value was used to initialize the river water level and the soil moisture content a dynamic time step was used for the rsm and frm more precisely the minimum and maximum time steps for the rsm were 36 s and 180 s respectively and the maximum number of iterations for each time step was 100 the maximum time step of the hayami kernel function moussa 1996 in the frm was 100 s and the time step of the drm was 0 1 s the time of data exchange among the different modules was 60 s furthermore the hourly pcm and etm data were first interpolated into a minute scale and then exchanged with the other modules last the surface ponding depths were converted into daily average values and transferred to the wlm to determine the yield reduction rate 2 5 3 calibration and validation the river water levels observed from august 13 to august 17 2014 were used to calibrate the was this period was usually the critical stage flowering stage of rice which was also the period with concentrated precipitation in the study area gao et al 2016 the accumulated precipitation in the calibration period was 133 8 mm the maximum precipitation in 24 h was 108 8 mm and the maximum rainfall intensity was 18 4 mm h fig 4 a during the calibration period all of the drainage gates were open while all of the pump stations were closed the validation period was august 9 to august 19 2015 the accumulated precipitation in the validation period was 327 6 mm the maximum precipitation in 24 h was 269 2 mm and the maximum rainfall intensity was 47 4 mm h fig 4b because the precipitation process in the validation period was intensive only a portion of the pump stations worked during the validation period table 4 2 5 4 evaluation five statistical indicators namely the coefficient of determination r2 relative error re eq 20 nash sutcliffe coefficient nsc eq 21 mean residual ratio mrr eq 22 and dispersed root mean square ratio drmse eq 23 were used to evaluate the simulation accuracy for both the calibration and validation periods 20 re i 1 n s i o i i 1 n o i 100 21 nsc 1 i 1 n s i o i 2 i 1 n o i o mean 2 22 mrr i 1 n s i o i n Î´ o 23 drmse i 1 n s i o i 2 n Î´ o 3 results 3 1 sensitivity and uncertainty analyses 3 1 1 maximum yield reduction rate the maximum yield reduction rate myrr increased with the change in Î¸s compared with the base value fig 5 a specifically as Î¸s increased at rates of 5 10 and 15 the myrr increased by 9 92 4 65 and 2 71 respectively furthermore the myrr increased by 6 45 8 39 and 9 92 as Î¸s decreased at rates of 5 10 and 15 respectively in contrast to Î¸s the change in Î¸r from 15 to 15 had little effect on the myrr 0 06 0 35 moreover the myrr increased at rates of 0 63 1 18 and 1 32 and ks increased from 5 to 15 moreover with a decrease in ks at rates of 5 and 10 the myrr increased by 1 46 and 2 57 respectively however the myrr decreased by 1 03 with a 15 reduction in ks in addition the myrr showed an opposite trend compared with those of Î± and n for example the myrr increased by 5 76 and 6 59 with a 15 decrease in Î± and n and a 15 increase in Î± and n decreased the myrr by 3 67 and 1 45 respectively the sensitivity of the rhvp was similar to that of ks and the myrr decreased by only 2 28 when the reduction in rhvp was as large as 15 while the myrr had increasing rates of 0 08 to 2 57 with other variations in rhvp 3 1 2 weighted mean yield reduction rate the effects of the six selected parameters on the weighted mean yield reduction rates wyrrs of the field area are shown in fig 5b only Î¸s and Î± had relatively strong effects on the wyrr taking Î¸s as an example with Î¸s increasing at rates of 5 10 and 15 the wyrr decreased by 0 2 25 and 5 62 respectively the wyrr increased by 2 25 3 37 and 5 62 as Î¸s decreased at rates of 5 10 and 15 respectively moreover a decrease in parameter n had a slight effect on the wyrr more precisely the wyrr increased by 1 12 2 25 and 3 37 as n decreased at rates of 5 10 and 15 respectively 3 1 3 uncertainty analysis the uncertainties for both the myrr and wyrr were mainly caused by Î¸s Î± and n for example the ranges of the variation in the myrr were 7 41 7 93 6 95 7 63 and 7 11 7 69 for Î¸s Î± and n rates of 5 10 and 15 respectively for the wyrr the ranges of the variation were 0 84 0 94 0 86 0 92 and 0 88 0 92 respectively fig 6 in contrast the uncertainties for the myrr caused by ks and rhvp were low and the changes were 0 26 and 0 35 respectively moreover the change in the myrr caused by the change in Î¸r was only 0 04 similar to those for the myrr the uncertainties for the wyrr caused by Î¸r ks and rhvp were low and the changes were all smaller than 0 01 fig 6 3 2 calibration and validation the simulated water levels in the calibration process are shown in fig 7 with the calibrated parameters table 5 the simulated and observed water levels in the middle and at the end of the zhongshi river and jiangma river had similar trends the r2 and nsc at the four locations were all greater than 0 9 table 6 furthermore the re values in the middle and at the end of the zhongshi river were 2 62 and 2 47 respectively and those of the jiangma river were 2 48 and 1 31 respectively the mrr and drmse in the zhongshi river and in the middle of the jiangma river ranged from 7 32 to 8 82 respectively moreover the mrr and drmse at the end of the jiangma river were 4 32 and 5 13 respectively based on the validation results the model also had very high accuracy in the middle of the zhongshi river and the jiangma river and at the end of the jiangma river the nscs of the above three locations were all approximately 0 94 and the mrrs were 4 30 5 06 and 5 90 respectively fig 8 furthermore the drmses at these three locations were smaller than 8 however the model overestimated the water level at the end of the zhongshi river during the validation process fig 8c more precisely the re nsc mrr and drmse values at the end of the zhongshi river were 5 84 0 78 11 07 and 14 77 respectively 3 3 yield reduction due to waterlogging no yield reduction was found in the calibration period 2014 in the validation period 2015 approximately 53 of fields accounting for 60 of the studied areas had different levels of yield reduction fig 9 moreover fields in the east had a higher rice yield reduction rate than other locations furthermore the reduction rates in 99 12 of the fields were smaller than 4 and only 1 field had a reduction rate larger than 9 fig 9b in regard to the considered area only 19 5 ha of the field area approximately 1 2 of the total field area suffered from yield reductions that were greater than 4 fig 9c 4 discussion 4 1 sensitivity and uncertainty analyses the sensitivity and uncertainty analyses indicated that Î¸s Î± and n were the three parameters with the greatest effects on the simulated yield reduction rates figs 5 and 6 the variation trend of the wyrr was opposite to that of Î¸s because the soil water holding capacity increased with Î¸s in addition both the wyrr and myrr had opposite variation trends with the soil properties Î± and n the curves in fig 10 show the relationships between the pressure head and soil moisture with different Î± and n values the curves moved up as Î± or n decreased furthermore larger Î± or n values indicated that the soil texture was similar to that of sand which has a poor soil water holding capacity hwang et al 2002 minasny et al 1999 wÃ¶sten et al 2001 however our study found that the myrr increased with increasing Î¸s one possible reason was that the yield reductions in our model were determined not only by the soil properties such as Î¸s but also by the boundary conditions such as the geography and water levels in the drainage ditches wesseling and feddes 2006 xu et al 2013 the myrr mainly occurred in fields with low elevation fig 10 in these fields the interactions between precipitation surface and sub surface drainages and soil properties were very complex causing the backwater effects of the water levels in the ditches to be larger than the effects of soil properties e g Î¸s on the myrr boem et al 1996 matson et al 1997 abbas et al 2018 and sharma et al 2003 also reported that soil hydrodynamic properties could affect crop yield reductions under waterlogging 4 2 yield reduction field ponding and backwater effects no yield reductions were found in the calibration period because the precipitation in the calibration period was relatively low 133 8 mm and the ponding depth was almost smaller than the field ridge depth 10 cm in the validation period high precipitation 327 6 mm caused yield reductions in many fields mainly due to the backwater effects of the high drainage ditch level le et al 2007 which was in accordance with the sensitivity and uncertainty analyses in addition our study showed that the yield reduction was exponentially reduced with increasing field elevation r2 0 8 fig 11 field elevation also affected the ponding processes and backwater effects the elevations of fields 178 946 and 812 were 2 9 m 2 6 m and 2 3 m respectively fig 12 a in field 178 due to the high topography the maximum ponding depth was the field ridge depth 10 cm and drains had no backwater effects on surface runoff yields therefore the ponding process curve decreased at a relatively constant rate after precipitation and no yield reduction occurred in field 178 fig 12b in fields 946 and 812 because of the low elevations the maximum ponding depths were 16 69 cm and 18 29 cm and the yield reduction rates were 0 87 and 3 32 respectively fig 12a in contrast to that in field 812 the ponding depth decreased rapidly close the first precipitation event august 11 2015 during the validation period in field 946 fig 12b this rapid decrease potentially resulted from the large amount of precipitation that accumulated above the field ridge that could not be discharged due to the backwater effects of the drains once the water levels in the drains were lower than the height of the field ridge ponding on the field surface quickly ceased fig 12b furthermore fig 13 b indicates that the slope of the ponding process curve in field 946 gradually decreased after the ponding depth decreased to less than that of the field ridge more precisely the slope from august 12 to august 13 was smaller than that from august 13 to august 16 this phenomenon could also be explained by the backwater effect specifically as the drainage route changed from the surface to the sub surface when the ponding depth was smaller than the height of the field ridge the water level in the drains and the ponding depth decreased which weakened the backwater effects of the drains hussein et al 2007 however due to the low elevation of field 812 the water level of the drain was higher than that of the field ridge between the first precipitation event and august 15 causing the slope of the ponding depth curve to decrease at a lower rate than that observed for fields 178 and 946 therefore the backwater effects of the drains decreased with field elevation similar observations were also made by metcalfe et al 2017 chang et al 2018 hatton et al 2002 and akter et al 2017 in addition we found that the maximum ponding depth could be determined from field elevation fig 13 one possible reason for this result could be the backwater effects of the drains fields at lower elevations could experience more obvious backwater effects than those at higher elevations which would reduce the drainage rate and increase the ponding depth schmitt et al 2004 moreover the r2 between the field ponding depth and elevation in 2015 r2 0 64 was higher than that in 2014 r2 0 36 indicating that higher precipitation also promoted backwater effects 4 3 merits and limitations compared with other models such as swat or its modified versions wang and cui 2011 xie and cui 2011 and mike wang et al 2019a the was merged the dem and spatial topological relationships with customized definitions to establish hydraulic connections among different mus therefore the was does not require a very high resolution dem to reflect different ditch levels in the gid furthermore the was was used for the river around the gid as a boundary to consider the interactive effects among the outside of the river the end level of the ditch and the ancillary buildings including the water gate and pump stations on the agricultural drainage processes although some distributed drainage models such as drainmod gis could also be extended to the outside boundary fernandez et al 2006 the was described soil water movement accurately eqs 2 3 and considered the effects of the ditch water level on surface drainage e g backwater effects in addition the was could consider the effects of ridge depth and backwater on the pond depth calculations which might be more appropriate for the gid than the majority of hydrological models kan et al 2017 ma et al 2018 yang et al 2004 moreover the was has a user friendly interface and the transparency and modularity of the was structure can help users better understand and use the system these features could be very attractive to potential users who are mainly managers of irds ahmed and sarkar 2019 sarkar et al 2019a umakanta et al 2020 therefore the extension and application of the was can aid in waterlogging management in irds and increase rice yield and farmers income in addition the modular programming ideas of the was can also be applied to develop systems for other fields of study such as the management of energy socio economic and policy decisions khan et al 2019 sarkar et al 2020 tiwari et al 2019 however there are still some limitations in the present was first serial computing is used in the was which requires more time for calculation than parallel computing second the present was could consider only rice and more crops should be added to the was in the future third the yield reduction rate of rice is determined based on the dynamics of the simulated ponding depth and the crop wpf however this method is essentially empirical and does not consider the crop growth mechanism 5 conclusions in this study we developed a novel was that could consider the effects of both landform features and human interventions in irds the water level and rice yield data observed in the gid in 2014 and 2015 were used to calibrate and validate the was respectively the calibration and validation indicated that was could provide very accurate predictions for water levels in the gid and yield reduction rates for rice crops sensitivity and uncertainty analyses indicated that Î¸s Î± and n were the three soil hydrodynamic parameters with the greatest impacts on the simulated yield reduction rates furthermore field elevation exhibited good relationships with the yield reduction rate and field pond depth boundary conditions such as the river and ditch water levels had greater impacts than the soil hydrodynamic parameters on yield reduction in the was especially for low elevation fields in addition the was has a friendly interface and the transparency and modularity of the was structure can help the managers of irds better understand waterlogging and decrease the risk of rice yield reduction future studies should focus more on the mechanisms of the interactions between crop growth soil hydrodynamic parameters boundary conditions weather and regional geography to accurately evaluate waterlogging credit authorship contribution statement haorui chen methodology writing original draft wenzhi zeng supervision conceptualization writing original draft yinlong jin visualization investigation writing review editing yuanyuan zha writing original draft boyu mi data curation software validation shaohui zhang writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national key research and development program of china 2017yfc0403302 2017yfc0403205 2016yfc0501301 2019yfc049203 the open research fund of the state key laboratory of simulation and regulation of water cycle in river basin china institute of water resources and hydropower research grant no iwhr skl kf201814 the crsri open research program program sn ckwv2017528 ky the national natural science foundation of china grant no 51779273 51609175 51879196 and 51790533 and the basic research fund of china s institute of water resources and hydropower research gg0145b502017 mk2019j03 
5081,global climate change and increasing pressure of water shortage reinforce the necessity of optimal water management in this study a type 2 fuzzy mixed integer bi level programming t2fmbp approach is developed for the identification of reasonable water allocation policies by incorporating type 2 fuzzy sets mixed integer linear programming bi level programming and stewart model into a general optimization framework the t2fmbp model improves upon conventional bi level programming for handling tradeoffs between two level decision makers considering multiple water allocation processes it is capable of addressing parameter uncertainties caused by natural conditions and human activities and supporting in depth analysis of water allocation schemes associated with future climate change in this study group opinion aggregation method for fuzzy number construction critical value method for type 2 fuzzy number defuzzification and fuzzy coordination method for solving bi level programming are adopted then the model was demonstrated for a real world case study in the zhanghe irrigation district for multi source multi user water resources planning the results show that the proposed model can tackle tradeoffs among hierarchical decision makers conflicting concerns under uncertainties characterized as type 2 fuzzy numbers besides the results can help generate water allocation schemes among different water sectors as well as different crop growth stages effectively under three hydrological years wet year normal year and dry year and three representative concentration pathway rcp scenarios rcp 2 6 rcp 4 5 and rcp 8 5 furthermore comparison was made between t2fmbp model and four single level models with same constraints the comparison reveals that t2fmnp model considers all the targets and makes excellent balance between two level decision makers a comparison between current situation and rcp scenarios will help make policies for foresight the formulated framework is applicable for similar regions to determine water strategies in a changing environment thus promote sustainable development of socio economic and water resources system keywords type 2 fuzzy sets bi level programming future climate change uncertainty water allocation 1 introduction livelihood security and socio economic development are heavily dependent on natural resources especially water resources owing to burgeoning global population and urbanization rising water demands greatly outweigh natural water resources availability resulting in wide range water shortage chen et al 2013 wang et al 2019a cheng et al 2019 unreasonable water planning strategies have exacerbated the problem of water resources deficiency li et al 2017 ren et al 2019 moreover climate change undoubtedly one of the most severe environmental problems confirmed in the fifth assessment report ar5 of the intergovernmental panel on climate change ipcc climate change 2013 will further challenge sustainable socio economic development thus the approach to planning water resources as well as the weight given to climate change consideration is essential to be concerned worldwide water researchers have devoted themselves to healthy and effective water resource allocation over long periods of time Ã¶zerol et al 2018 yao et al 2019 mathematical modelling confirmed as a predominant tool has been widely employed which allocates multi water resources i e different sources of water resources among multi agent various water users li et al 2019 han et al 2011 zhang et al 2018a for example song et al 2016 developed a rule based water resource allocation model to balance water allocation among sub areas and users chen et al 2017 formulated an interval multistage water classified allocation model to optimally allocate water resources to municipality industry hydropower and agriculture fu et al 2018 optimized multi water source allocation to different crops using an optimization model in all the above researches verified the applicability and effectiveness of optimization model in water allocation system however three major concerns remained to be further explored in multi source multi user water allocation system first of all the sequential order and strategic interaction among multiple hierarchical decision makers should be analyzed deeply in practice district administrator has priority to allocate water to each sector in each sub area and sub area farmers execute their decision power based on given amount of water resources safari et al 2014 since each decision maker puts emphasis on different targets the feedback and coordination between different decision makers are of great significance second a compensatory demand for external water due to water shortage of seasonal inflows is apparently needed to be taken into account third in terms of agricultural water how field condition and allocated water in each growth period affect crop production is needed to be figured out generally the production loss caused by water deficit in key period can be hardly compensated through more irrigation in other period guo et al 2014a yet there are no studies available optimizing multi source multi user water planning strategies with all aforementioned issues taken into consideration in response to the above mentioned concerns a bi level programming blp framework is formulated to gain insight into the whole water allocation process with two groups of decision makers district administrator and sub area farmers objectives in two hierarchical levels are performed from the upper level to the lower level zhang and vesselinov 2016 jin et al 2018 and then the decision of upper level may be affected by the reaction of the lower level decision makers arora and gupta 2009 baky 2009 in this way blp provides an effective means to prioritize the more important target and balance different decision making levels baky and abo sinna 2013 additionally mixed integer linear programming mlp where integer variable is equal to 1 or 0 should be adopted to indicate whether external water transferring should be done and how much external water is consequently needed to be transferred furthermore stewart model stewart et al 1976 can not only reflect the relationship between crop production and allocated water in each grow stage but also represent the difference when the same amount of water is allocated following different schedules chen et al 2017 besides field water balance equation can support effectively quantification of field condition which help enhance feasibility and applicability of optimization model accordingly the integration of mlp stewart model field water balance equation and blp is a potential approach to address complex difficulties associated with water resources management however the method will encounter difficulties addressing multiple uncertainties in water allocation system specifically uncertain factors which mainly arise from the randomness of natural events the vagueness of the objectives and constraints and the parameter estimation errors regulwar and gurav 2011 lead to the uncertainty and complexity of the water allocation process therefore uncertainty techniques including interval parameter programming ipp stochastic mathematical programming smp and fuzzy mathematical programming fmp are widely used to address different kinds of uncertainties related to water resources management problems maqsood et al 2005 dai and li 2013 tong and guo 2013 jin et al 2012 zhang and guo 2017 guo et al 2014b zhang et al 2019 in comparison fmp is proved more convenient in practical applications because it not only is more informative than ipp but also has less computational burden than smp li et al 2017 xie et al 2018 zhang et al 2018b in fmp uncertain parameters are expressed as fuzzy sets fs with membership function for example a traditional triangular fuzzy number a is composed of the least possible value a1 the middle value a2 and the highest possible value a3 which can be represented by a a 1 a 2 a 3 each possible value in a 1 a 2 a 3 corresponds to a certain membership in 0 1 which forms the triangular membership function in reality it is badly hard to deduce a crisp membership function of fs in circumstances where exist multi fold uncertainty and instinctive imprecision jana et al 2017 type 2 fuzzy sets t2fs originally introduced by zadeh 1975 has enhanced the ability to handle uncertain information and overcome the limitations of simplified type 1 fuzzy sets t1fs consequently it has quickly attracted widespread attention and been adopted to a variety of fields rapidly for example site selection problem Ã§ebi and otay 2015 energy systems planning suo et al 2017 municipal solid waste management jin et al 2019 transportation problem liu et al 2014 and so on however few researches have been reported considering t2fs in water resources planning system where hydrological parameters has strong variability and highly uncertainty besides many studies reveal that climate change will lead to the spatial and temporal redistribution of water resources gosling and arnell 2016 liu and xu 2015 palutikof 2007 and arise severe influence on water supply demand structure by altering the hydrological cycle jang et al 2007 kirby et al 2016 wang et al 2014 previous studies showed that the impacts of climate change are particularly sensitive to changes in precipitation and temperature frederick and major 1997 it is believed that climate change will take the world into a new phase of water stress and uncertainty in the future rowshon et al 2019 ausseil et al 2019 although the significance of this issue there are limited studies available which analysis how to optimally plan water allocation strategies in a changing environment due to future climate change summarily one potential approach for better accounting for all above concerns is incorporating t2fs mlp stewart model field water balance equation within general blp framework under climate change scenarios formulating a type 2 fuzzy mixed integer bi level programming t2fmbp model nevertheless there are few applications of the t2fmbp model to water resources planning therefore the primary objective of this study is to develop a novel approach namely t2fmbp for allocating multi source water resources to multiple water use sectors in future changing environment the developed approach makes contributions mainly on 1 balancing the conflicting concerns of hierarchical decision makers in a multi source multi user water allocation system 2 improving the accuracy of characterizing highly uncertain parameters concurrently occurring in both objective functions and constraints 3 detailing the interrelationship among water demand water supply and climate change to demonstrate its validity the t2fmbp approach will be applied to the zhanghe irrigation district zid for planning water resources under uncertainty flexible optimization solutions under different scenarios can provide prospective guidance for efficient water management and climate change adaptation 2 development of methodology in a real world water allocation system characterized by multiple hierarchies and intricate water supply demand structure management authority is tasked with allocating water resources to multiple sectors in multiple subareas the tradeoffs between water demand and water availability often make decision makers in a dilemma which calls for sustainable water management different hierarchies where each decision maker independently control over their own objective and decision making process make it far more difficult for appropriate water allocation strategy in general there are two decision making levels consist of district administrator and subarea farmers different decision makers have different and perhaps conflicting preferences a higher decision level occupies the priority to make decisions and the lower decision level must follow the decisions of higher level besides the higher level decisions are affected by the feedback from the lower level to the higher level the different concerns from bi level decision makers should be fully considered moreover uncertainties associated with environmental factors exist in water allocation system and strengthen the complexity water allocation system furthermore climate change has exacerbated the instability of the hydro meteorological system caused temporal spatial redistribution of water resources and affected local livelihood security wang et al 2019b wang et al 2019c it s crucial to find out how climate change affect the water resources as well as the description of consequent uncertainties resulting from climate projections accordingly for sustainable water resources management following issues should be taken seriously as 1 how to effectively allocate limited available water from different sources to conflicting sectors in different subareas 2 how to balance the different targets associated with bi level decision makers 3 how to quantify the uncertain factors associated with water allocation process and future climate change in order to effectively address above complexities and interactions it is essential to propose an integrated approach for gaining proper water allocation policy therefore a t2fmbp approach integrating t2fs with mlp into general blp framework is formulated for water resources planning under future climate change scenarios the model will be solved by the typical fuzzy coordination algorithm and preferred schemes will be identified allowing water allocation decisions to be made by managers accordingly fig 1 shows the framework of the study system with details being explained in the following sections 2 1 type 2 triangular fuzzy sets the concept of t2fs was first introduced by zadeh in 1975 as an extension of the traditional t1fs to effectively describe uncertainties unlike a t1fs where the membership function is a deterministic number in 0 1 a t2fs has a secondary grades of membership resulting a three dimensional membership function as fig 2 shown in this study type 2 fuzzy triangular sets t2tfs was used because it is computationally simper in solving mathematical programming problems according to liu and liu 2010 a t2tfs can be written as Î¾ r 1 r 2 r 3 Î¸ r Î¸ l where r 1 r 2 r 3 are real values and Î¸ r Î¸ l 0 1 are two parameters characterizing the spreads of primary membership grades of t2tfs then for x r 1 r 3 the secondary membership function Î¼ Î¾ x of Î¾ is defined in the form 1a Î¼ Î¾ x x r 1 r 2 r 1 Î¸ l x r 1 r 2 r 1 x r 1 r 2 r 1 x r 1 r 2 r 1 Î¸ r x r 1 r 2 r 1 i f x r 1 r 1 r 2 2 x r 1 r 2 r 1 Î¸ l r 2 x r 2 r 1 x r 1 r 2 r 1 x r 1 r 2 r 1 Î¸ r r 2 x r 2 r 1 i f x r 1 r 2 2 r 2 r 3 x r 3 r 2 Î¸ l x r 2 r 3 r 2 r 3 x r 3 r 2 r 3 x r 3 r 2 Î¸ r x r 2 r 3 r 2 i f x r 2 r 2 r 3 2 r 3 x r 3 r 2 Î¸ l r 3 x r 3 r 2 r 3 x r 3 r 2 r 3 x r 3 r 2 Î¸ r r 3 x r 3 r 2 i f x r 2 r 3 2 r 3 as shown in fig 2 each membership degree corresponds to a series of unfixed numbers posing a considerable obstacle to practical application therefore an extra type reduction is required to convert t2fs into conventional t1fs so that they can be defuzzified to give crisp outputs qin et al 2011 developed a reduction method for t2fs based on critical value cv method supposed that Î¾ is a t2tfs with secondary possibility distribution function Î¼ Î¾ x the method introduces the cvs as representing values of the regular fuzzy variable Î¼ Î¾ x i e c v Î¼ Î¾ x optimistic cv c v Î¼ Î¾ x pessimistic cv c v Î¼ Î¾ x neutral cv these cvs are defined as follows 1b c v Î¼ Î¾ x sup Î± 0 1 Î± p o s Î¾ Î± 1c c v Î¼ Î¾ x sup Î± 0 1 Î± n e c Î¾ Î± 1d c v Î¼ Î¾ x sup Î± 0 1 Î± c r Î¾ Î± for t2tfs following theorems qin et al 2011 dutta and jana 2017 are available for acquiring the expected value of these cvs consequently the t2tfs could be defuzzified to give crisp outputs in real world applications theorem 1 assume Î¾ 1 to be the reduction of the t2fs Î¾ r 1 r 2 r 3 Î¸ r Î¸ l obtained by the optimistic cv reduction method then 1e e o Î¾ 1 r 1 r 3 2 r 1 2 r 2 r 3 ln 1 Î¸ l 2 2 Î¸ l theorem 2 assume Î¾ 2 to be the reduction of the t2fs Î¾ r 1 r 2 r 3 Î¸ r Î¸ l obtained by the pessimistic cv reduction method then 1f e p Î¾ 2 r 2 r 1 2 r 2 r 3 ln 1 Î¸ r 2 2 Î¸ r theorem 3 assume Î¾ 3 to be the reduction of the t2fs Î¾ r 1 r 2 r 3 Î¸ r Î¸ l obtained by the neutral cv reduction method then 1g e n Î¾ 3 r 1 2 r 2 r 3 4 r 1 2 r 2 r 3 8 1 Î¸ l 1 Î¸ r 1 Î¸ l ln 1 Î¸ l Î¸ l 2 1 Î¸ r ln 1 Î¸ r Î¸ r 2 2 2 modelling a t2fmbp model is developed involving two basic decision making levels district administrator and farmers in each subarea in the upper level mlp is required to indicate whether or not external water should be transferred to satisfy total water demand in the lower level stewart model is considered to accurately reflect the impact of water supply on crop production during different periods therefore it is the demand of different sectors coupled with the desire of district administrator to maximize profits and the desire of farmers to maximize their incomes which together determine how water resources shall be allocated in the decision making process decisions are made sequentially from the upper level to the lower level and then modified with consideration of bi level concerns additionally complex data characteristics existed in water allocation system calls for detailed description in a changing environment in this study precipitation and available water are described by t2tfs with type 2 fuzzy membership function to present the model a list of notations is shown in table 1 upper level maximum system benefit 2a max f 1 i i c i x i j 1 j t 1 t a c j a j t w jt Î´ c e w e lower level maximum agricultural profit for each subarea 2b max f 2 j a j y m p 1 t 1 t b t e t mt t w jt e t mt u j a j t 1 t a j d 1 r w jt Î· j 1 d 2 s w jt i w jt Î· 2 j with 2c t w jt min p w jt r w jt s w jt i w jt e t mt j t 2d p w jt min e t mt Î± p r t j t 1 paddy field water balance constraint paddy field water balance constraint is required to deeply explore the relationship between water recharge water discharge and water storage during a certain period for paddy field the water depth drops with evapotranspiration drainage and percolation and it grows with precipitation and irrigation chen et al 2016 depth of water layer in period t can be calculated as follows 2e h jt h j t 1 p r t r w jt s w jt i w jt e t mt d w jt s jt j t to guarantee the crop growth the water depth should be within the scope of minimum and maximum field water depth this constraint can be expressed as 2f h min t h jt h max t j t 2 the key reservoir water supply constraint the key reservoir water allocated to all the non agricultural sectors and agricultural subareas should not be larger than the total available water that comes from the zhanghe reservoir this constraint can be presented as 2g i 1 4 x i Î· 11 j 1 3 t 1 4 a j r w jt Î· j 1 rq Î´ w e 3 general reservoir water supply constraint the general reservoir water allocated to each agricultural division must not exceed the available water supply the general reservoir water availability can be calculated by the method reported by pandey et al 2011 this constraint can be expressed as 2h t 1 4 a j s w jt p r t s a j Î· 2 j 4 pond water supply constraint similar to the general reservoir water pond water allocated to each agricultural division must not exceed the available water supply this constraint can be expressed as 2i t 1 4 a j i w jt p r t i a j Î· 2 j 5 non agricultural water demand constraint the water allocation amount for each non agricultural sectors should be within the scope of minimum and maximum water demand this constraint can be expressed as 2j x i min x i x i max i 6 binary constraints for external water 2k Î´ 0 if external water is not transferred 1 if external water is transferred 7 nonnegative constraint the allocated irrigation amount of multiple water sources and drainage in various crop growth stages in each subarea should be negative this constraint can be expressed as 2l r w jt 0 s w jt 0 i w jt 0 d w jt j t 2 3 model solution the core to solve the developed t2fmbp model is to transform the uncertain and bi level model into a deterministic and single level model hence two steps are needed the first step is to convert the t2tfs of the developed optimization model into deterministic numbers based on the type reduction method the second step is to transform the bi level programming model into a single level programming model using fuzzy coordination method step 1 formulate the model with t2tfs step 2 convert t2tfs into a chosen deterministic type via defuzzification based on the cv method step 3 calculate the upper level model firstly to obtain f 1 u f 1 l x i u t w jt u and w e u step 4 conduct membership functions for xi twjt and we with maximum tolerance t1 t2 and t3 as follows 3a Î¼ x i x i x i u t 1 t 1 x i u t 1 x i x i u x i u t 1 x i t 1 x i u x i x i u t 1 3b Î¼ t w jt t w jt t w jt u t 2 t 2 t w jt u t 2 t w jt t w jt u t w jt u t 2 t w jt t 2 t w jt u t w jt t w jt u t 2 3c Î¼ w e w e w e u t 3 t 3 w e u t 3 w e w e u w e u t 3 w e t 3 w e u w e w e u t 3 step 5 conduct the membership function for upper level objective f1 and lower level objective f2j with the acceptable satisfaction degree as follows 3d Î¼ f 1 x i t w jt w e 1 i f f 1 x i t w jt w e f 1 u f 1 x i t w jt w e f 1 l f 1 u f 1 l i f f 1 l f 1 x i t w jt w e f 1 u 0 i f f 1 x i t w jt w e f 1 l 3e Î¼ j f 2 j s w jt r w jt i w jt 1 i f f 2 j s w jt r w jt i w jt d w jt f 2 j u f 2 j s w jt r w jt i w jt d w jt f 2 j l f 2 j u f 2 j l i f f 2 j l f 2 j s w jt r w jt i w jt d w jt f 2 j u 0 i f f 2 j s w jt r w jt i w jt d w jt f 2 j l step 6 obtain a single level single objective optimization model with the objective of maximizing satisfactory degree consequently the programming problem can be solved as 4a max Î» 4b Î¼ x i Î» i 4c Î¼ t w jt Î» i 4d Î¼ w e Î» i 4e Î¼ f 1 x i t w jt w e Î» 4f Î¼ j f 2 j s w jt r w jt i w jt d w jt Î» 4g Î» 0 1 4h x i t w jt w e s w jt r w jt i w jt d w jt m where Î» is overall satisfactory degree of upper level and lower level model m is the constraint set in initial model step 7 calculate the t2fmbp model under different scenarios and generate flexible water allocation solutions 3 model application 3 1 study area the proposed model was applied to a real case study in the zid fig 3 zid is located north of the yangtze river basin in central china which across three cities of jingmen jm jingzhou jz and dangyang dy zid is one of the most important production bases of commodity grain in hubei province accompanying the complicated water allocation to competitive users cities industry irrigation and hydropower salient features of zid in addition to the multiple water users include its relative abundance of water supply especially the precipitation this area receives an average annual rainfall of 901 3 mm 1963 2018 although the annual rainfall is high drought frequently occurs due to significant rainfall variability both within and among years roost et al 2008a roost et al 2008b approximately 82 6 of the yearly rainfall occurs between april and october furthermore the zhanghe reservoir is a main water supply source for multiple users including irrigation domestic industry ecology and hydropower of jm city irrigation of jz city and irrigation of dy city with the total storage capacity of 2 113 billion cubic meters besides there are 314 general reservoirs 81 595 ponds and 34 pumping stations in the district the general reservoirs and ponds are operated independently from the zhanghe reservoir to allocate irrigation water resources agricultural users in each subarea could benefit from flexible supplies generally allowing farmers to gain water on demand nevertheless due to the water supply shortage occurred in dry year a compensatory demand for external water is apparent for sustainable regional development in zid winter rape and rice rotation is the main farming pattern however winter rape is no need to be irrigated due to the low water requirement thus rice is the only agricultural water consumer on the one hand it is significant to optimally manage water resources with multiple water supply sources and multiple water users in different subarea on the other hand with continuous increase of population and rapid development of economy how to satisfy the increasing water requirement with limited water resources is an urgent issue additionally various uncertain parameters existed in the water allocation system make it more complicated to obtain appropriate schemes furthermore climate change will probably have interacting effects on the environment and represent a major challenge to water management therefore in response to above issues inexact optimization models are desirable to support sustainable water resources management under future climate change 3 2 parameter determination data for the t2fmbp model mainly includes hydrological data crop water production function paddy field condition socio economic data and so on bcc csm1 1 m was adopted to generate climate change scenarios consisting of daily precipitation and the maximum and minimum air temperature from 2021 to 2050 by driving the statistical downscaling model sdsm in three representative concentration pathway rcp scenarios rcp2 6 rcp4 5 and rcp8 5 the elaborated projection methods can be found in wang et al 2019b after that future inflow of the zhanghe reservoir from 2021 to 2050 can be predicted using swat soil and water assessment tool model under above climate change scenarios to better quantify the stochastic characteristics frequency analysis method was used to classify different hydrological years namely wet year p 25 normal year 25 p 75 and dry year p 75 where p denotes the frequency li et al 2016 for each hydrological year the effective precipitation can be obtained by multiplying precipitation by corresponding effective coefficient moreover precipitation and water availability subjected to human judgments xu and qin 2010 rarely has the accurate characteristics resulting in a higher uncertainty t2tfs as a dual uncertainty could be a potential expression for these environmental factors these t2tfs can be constructed by the fuzzification method reported by cheng 2004 as shown in appendix 1 all these hydrological parameters can be seen in table 2 future daily reference crop evapotranspiration mm was calculated by hargreaves model hargreaves and samani 1982 nonlinear regression method was used to modify the model input parameters and then the daily potential evapotranspiration was calculated by the crop coefficient approach accordingly the total crop water requirement in each growth stage can be calculated by the sum of daily value during each growth stage the crop potential yield and water sensitivity index were obtained from previous researches the water loss of paddy field can be estimated by the rate of 1 mm day the maximum and minimum water layer depth were obtained from field experiment provided by the hubei irrigation experiment center station detailed information are given in table 3 socio economic parameters including crop price cultivation area area of general reservoirs and ponds water use coefficient benefit coefficient planting cost and water requirement of non agricultural water users were obtained mainly from statistical yearbook filed survey report and previous researches these socio economic parameters have shorter time series and less uncertainty than hydrological parameters accordingly can be expressed as determinate parameters benefit coefficients of non agricultural sectors were calculated by contribution coefficient method referred to li 2017 quota method is used to acquire the maximum water requirement of non agricultural water users in the planning year of 2030 the minimum water requirement is obtained by multiplying the maximum water requirement by proper coefficient that is 0 9 for domestic 0 8 for industry and 0 8 for ecology in addition the minimum water demand of hydropower equals to the ecological water demand in downstream rivers crop price planting cost cultivation area area of general reservoirs and ponds and water use coefficient were provided by the hubei zhanghe project administration bureau detailed information can be seen in tables 4 and 5 4 results analysis and discussion 4 1 results of future climate change scenarios fig 4 shows the maximum air temperature tmax minimum air temperature tmin precipitation crop potential evapotranspiration and annual inflow of the zhanghe reservoir during 1989 2018 historical period and 2021 2050 future period under the three rcp scenarios rcp2 6 rcp4 5 and rcp8 5 these variables play significant roles in determining water resources environment in a changing climate both tmax and tmin over the next 30 years show increasing trends under three rcp scenarios compared with historical period the temperature raises along with increasing rcp which is rcp 8 5 rcp 4 5 rcp 2 6 specifically the maximum temperature increases by 1 18 1 43 and 1 57 as well as the minimum temperature increases by 1 47 1 65 and 1 85 in three rcp scenarios as fig 4 c shown the precipitation during crop growth stages in rcp 2 6 exhibits a noticeable increasing tendency while the increase in other rcps is slight due to apparent warming conditions and associated precipitation change crop evapotranspiration as well as annual inflow is influenced correspondingly crop potential evapotranspiration during the whole growth periods tend to increase from historical period to future period and the ranks from high to low are rcp 2 6 465 4 mm rcp 4 5 454 4 mm rcp 8 5 454 2 mm and history 440 7 mm in terms of annual inflow it denotes obvious uptrend in rcp 2 6 and downtrend in rcp 4 5 and rcp 8 5 from historical period to future period finally the future climate change scenarios can be accordingly generated consisting of above main elements overall three rcp scenarios rcp 2 6 seems like less negative for local socio economy development considering environmental changes the scenarios generated could be adopted to further explore optimal water resources allocation in the future 4 2 results of optimal water allocation by solving developed t2fmbp model in the optimization software optimal water allocation results among different water use sectors in different subareas during different period under different hydrological years and climate scenarios are obtained fig 5 depicts the proportion of total water resources from each source i e precipitation the key reservoir general reservoirs ponds and external water to the whole water distribution the graph presents not only the overall trend of water allocation amount but also the characteristics of each water source specifically the total water allocation has a downward trend from wet year to normal year as a result of shrinking natural inflow after that the total distributed water amount reaches a peak in dry year attributed by considerable external water transferring in terms of multiple water sources both the key reservoir and external water supply for agriculture and non agricultural sectors while other sources provide available water resources for agriculture only that can explain why the key reservoir water allocated amounts accounted for approximately 45 55 to the total water supply no matter in which scenarios in wet year zid is basically a rain fed agricultural region and the proportion which rainfall accounts for is up to 50 under rcp 4 5 however the rate of rainfall drops rapidly to 3 in dry year irrigation will play a more significant role on sustainable agriculture along with the decreasing natural water availability water from general reservoirs and ponds is prioritized for irrigation due to its features of flexibility simplicity and meeting water demand on time the ratio of general reservoirs and ponds water supply reaches the peak at 32 in normal year and then experiences a fall to 11 in dry year under rcp 8 5 when low inflow occurs the maximum proportion of external water occupies 38 under rcp 8 5 those above parameters and water allocation schemes are affected to different extent by changing environmental elements the results indicate that it makes sense to tackle this water management problem under different scenarios considering great natural resources variability taking normal year as an example fig 6 presents the optimal agricultural water allocation of each water source in each subarea the water supply in each subarea under the same scenario is nonidentical because of the differences of nature water availability and water requirement among subareas jm city has the biggest water demand followed by dy city and jz city while the available water supply rank from high to low is jm dy and jz in reality water from general reservoirs and ponds is allocated firstly when those parts of water is exhausted the key reservoir water is needed to meet the agricultural water demand specifically in dy city the water demand can be satisfied in rcp 2 6 and rcp 8 5 while supplement from key reservoir is allocated in rcp 4 5 in addition the proportion of key reservoir water in jz city varying from 5 to 34 is always higher than that in jm city in other word jz city is much more desirable for conjunctive allocation of multiple water sources the conjunctive operation of the key reservoir general reservoirs and ponds can ensure supplementary irrigation during water scarcity the results help managers better understand how the water supply condition is and how to manage agricultural water resources effectively the above analysis focus on total agricultural water allocation schemes with multiple water sources however it is also of interest to decision makers on how to allocate these amount of water among different crop growth stages fig 7 shows the detailed water distribution among different growth stages in different subareas under different scenarios in normal year the results show that when water demand cannot be well met across four periods water supply priority is given to heading stage followed by booting stage tillering stage and milky stage these results are related to water scarcity sensitivity water requirement and precipitation in each period specifically the production loss in heading stage which have stronger sensitivity to water scarcity is difficult to make up through more irrigation in other stages even though tillering stage has the highest water demand it can be satisfied because of high precipitation within the period although rainfall has variability among different rcp scenarios it is the main source of water supply under all rcps in normal year to reflect the water recharge discharge results comprehensively dynamic water layer depth during growth periods is expressed in fig 8 it is able to present how much water volume are remained in a certain period apparently the paddy field was drier when hydrological inflow was lower despite the change regularity of water depth among rcp scenarios was unavailable it is all controlled within the safe range the optimal results can offer a guidance for decision makers to allocate water in a reasonable way fig 9 presents the optimal solutions of non agricultural sectors among different scenarios the amount of water allocated to the same sector varies among different rcp scenarios determined by different environmental elements which mainly include precipitation and annual inflow the results demonstrate that the optimal water allocation results completely follows natural laws which is larger water availability for example in wet year and rcp 2 6 corresponds to more amount of water distribution overall for each scenarios water allocated to domestic and ecology reaches the maximum water requirements that is because the optimization model tends to satisfy water demand of high benefit industries to achieve higher system total profit but this brings about larger water shortage risks existed in industry and hydropower which are low benefit industries the satisfaction degree defined by the water supply demand ratio is shown in fig 9 b lower satisfaction degree means graver contradiction between water supply and water demand in terms of industry the percentage varies from 100 to 80 which is within a safe and acceptable range however the value of hydropower is extremely low even 13 in some certain conditions this occurs because of two main reasons one is that hydropower has a smaller impact on the objective than other sectors due to the lower per unit benefit the other one is that hydropower has the highest water requirement target among all users it can be indicated that the proposed optimization model can optimally allocate water to achieve maximum system benefit obeying the benefit oriented mechanism optimal solutions for different scenarios corresponding to the combinations of hydrological levels and rcp scenarios were different resulting in varying system benefits the objective function of t2fmbp model is to maximize the total system economic benefit from the system benefit under different given scenarios illustrated in fig 10 the system benefit varies mainly in accordance with the trend of the total water allocation and is up to 4 14 billion yuan however when external water is transferred the system benefit would be seriously affected marked in red because the price of external water is much higher than internal water those benefits are lower than the expected value associated with water allocation nevertheless the external water is essential for sustainable agricultural and socio economic development considering large inter annual environmental variability meanwhile the model always obtains the higher profit in rcp 2 6 thus previous speculation which believe rcp 2 6 is better for optimal water allocation is verified thereby the results help decision makers better understand water allocation conditions under each possible scenario and hence make appropriate decisions 4 3 discussion the real world case study showed that the t2fmbp model under uncertainty was an effective tool for sustainable water allocation in zid the model presented its own distinctiveness mainly on three points firstly the model can tackle the complexity of hierarchical decision making among multiple processes of water allocation within blp framework making more practical and reasonable decisions to better reflect the performance of t2fmbp model upper level model model 1 and lower level models model 2 model 3 and model 4 were calculated separately for contrasting with developed model model 5 as shown in fig 11 the system benefit results of t2fmbp model were within the range of other single level models and closer to the upper level model the results reflected the tradeoff between district administrator and subarea farmers and the priority of upper level decision maker secondly the model addressed dual uncertainties expressed as type 2 fuzzy numbers of water resources supply aspect for the accuracy characterization of vagueness in order to validate the results we obtained a sensitivity analysis with different spreads Î¸l Î¸r the type 2 fuzzy numbers can be transformed into different deterministic ones with different given spreads via critical value method the optimum results were given in table 6 it is observed that the profits had a downtrend when the right spreads increased and the left spreads decreased respectively however the changes among different results are below 2 5 which means the spreads had little effect on optimal targets in addition the critical value method adopted in this paper helped more indicative schemes provided rather than a series of alternatives under different Î± cut levels thirdly the model provided managerial insights for water resources allocation considering changing climate and corresponding influence on water supply demand structure in the future fig 12 displayed the total water shortage among current year 2020 and future rcp scenarios in 2030 it indicated that the water scarcity problem would be aggravated in the future owing to negative impact caused by global climate change there would be huge volumes of water shortage even in normal year mainly attributed to burgeoning increase of water demand overall the developed t2fmbp model would be helpful for managers to cope with difficulties in water allocation system and thus guide local water resources planning to explore the impacts of input parameters the following scenarios were assumed a three precipitation levels with high h level 1 2 pr middle m level pr and low l level 0 8 pr where pr represent the actual precipitation b three reservoir water availability levels with h level 1 2 rq m level rq and l level 0 8 rq where rq represent the actual reservoir water availability c nine combination levels with h h level 1 2 pr 1 2 rq h m level 1 2 pr rq h l level 1 2 pr 0 8 rq m h level pr 1 2 rq m m level pr rq m l level pr 0 8 rq l h level 0 8 pr 1 2 rq l m level 0 8 pr rq l l level 0 8 pr 0 8 rq the above 15 cases were optimized in normal year under rcp 2 6 scenarios the optimal results are displayed in fig 13 including the effects of individual parameters and interactive parameter pairs on system benefit it illustrates that all parameters have effect on system net benefit benefit increases slightly with precipitation while it climbs rapidly with reservoir water availability this indicates that net benefit is more sensitive to reservoir water availability the main reason is that the actual water availability is much larger than precipitation the results demonstrate that identifying water allocation strategies under different scenarios is of great significant 5 conclusions aimed at water resources planning problems an integrated model called t2fmbp was proposed under uncertainty and future climate change three advantages which make the developed model idiographic for water resources management are 1 balancing the competing targets for hierarchical decision makers in a multi source multi user water resources system 2 addressing parameter uncertainties associated with the fluctuation of natural resources and vagueness of human judgement 3 analyzing the response of water allocation to the water supply availability and climate change which will help generate proper water management policies in a changing environment the t2fmbp model was applied to identify the optimal water resources allocation policies with five water resources to five water users in three subareas in the zhanghe irrigation district central china optimal results had significant differences among different scenarios especially in different hydrological years which demonstrated that water allocation was sensitive to water availability massive external water up to 8 82 108 m3 would help to reach the targets of maximizing system benefit in dry year the model follow the benefit oriented mechanism which lead to higher satisfactory degree in high benefit sectors as well as large water shortage of hydropower in the process of agricultural water allocation the results of each period coincided with the expectations associated with the water scarcity sensitivity distribution according to comparison between developed model and four single level models t2fmbp performed well on balancing conflicting goals of two level decision makers furthermore global climate change would aggravate the contradiction of water supply and demand but rcp 2 6 was validated little negative for water resources management the developed approach was portable to other similar regions encountering water scarcity problems moreover the spatial variability associated with natural resources and field conditions deserves further study to enhance the accuracy of the model framework credit authorship contribution statement qiong yue conceptualization methodology software writing original draft youzhi wang validation methodology software liu liu resources formal analysis jun niu resources formal analysis ping guo supervision writing review editing funding acquisition peng li investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was supported by the national key r d program of china no 2017yfc0403201 appendix assume that g 1 g n are the values assigned by n different experts when grading an object in addition let g i g j for at least one pair of i j these values can be considered to represent the possibility distribution of the grading process step 1 calculate the distance between each g i and presented in the relative distance matrix d d ij n n where d ij g i g j step 2 calculate the average of the relative distance for each g i by d i j 1 n d ij n 1 step 3 conduct the pair wise comparison matrix p p ij n n where p ij represents the relative importance of g i compared to g j given by p ij d j d i step 4 calculate the true degree of importance w i of g i where w i 1 i 1 n p ij step 5 estimate the mode m of the fuzzy number by m i 1 n w i g i step 6 define the average deviation s to approximate the unknown mean deviation Ï where s i 1 n w i g i m step 7 define the ratio of the left spread to the right spread Î· to approximate the unknown ration Î· calculate Î· m g l g r m where g l i a w i g i i a w i g r i b w i g i i b w i a i g i m i i b i g i m i i and i 1 n step 8 obtain a m 3 1 Î· Î· Ï 1 Î· 2 b m 3 1 Î· Ï 1 Î· 2 then acquire the conventional triangular fuzzy number f a m b 
5081,global climate change and increasing pressure of water shortage reinforce the necessity of optimal water management in this study a type 2 fuzzy mixed integer bi level programming t2fmbp approach is developed for the identification of reasonable water allocation policies by incorporating type 2 fuzzy sets mixed integer linear programming bi level programming and stewart model into a general optimization framework the t2fmbp model improves upon conventional bi level programming for handling tradeoffs between two level decision makers considering multiple water allocation processes it is capable of addressing parameter uncertainties caused by natural conditions and human activities and supporting in depth analysis of water allocation schemes associated with future climate change in this study group opinion aggregation method for fuzzy number construction critical value method for type 2 fuzzy number defuzzification and fuzzy coordination method for solving bi level programming are adopted then the model was demonstrated for a real world case study in the zhanghe irrigation district for multi source multi user water resources planning the results show that the proposed model can tackle tradeoffs among hierarchical decision makers conflicting concerns under uncertainties characterized as type 2 fuzzy numbers besides the results can help generate water allocation schemes among different water sectors as well as different crop growth stages effectively under three hydrological years wet year normal year and dry year and three representative concentration pathway rcp scenarios rcp 2 6 rcp 4 5 and rcp 8 5 furthermore comparison was made between t2fmbp model and four single level models with same constraints the comparison reveals that t2fmnp model considers all the targets and makes excellent balance between two level decision makers a comparison between current situation and rcp scenarios will help make policies for foresight the formulated framework is applicable for similar regions to determine water strategies in a changing environment thus promote sustainable development of socio economic and water resources system keywords type 2 fuzzy sets bi level programming future climate change uncertainty water allocation 1 introduction livelihood security and socio economic development are heavily dependent on natural resources especially water resources owing to burgeoning global population and urbanization rising water demands greatly outweigh natural water resources availability resulting in wide range water shortage chen et al 2013 wang et al 2019a cheng et al 2019 unreasonable water planning strategies have exacerbated the problem of water resources deficiency li et al 2017 ren et al 2019 moreover climate change undoubtedly one of the most severe environmental problems confirmed in the fifth assessment report ar5 of the intergovernmental panel on climate change ipcc climate change 2013 will further challenge sustainable socio economic development thus the approach to planning water resources as well as the weight given to climate change consideration is essential to be concerned worldwide water researchers have devoted themselves to healthy and effective water resource allocation over long periods of time Ã¶zerol et al 2018 yao et al 2019 mathematical modelling confirmed as a predominant tool has been widely employed which allocates multi water resources i e different sources of water resources among multi agent various water users li et al 2019 han et al 2011 zhang et al 2018a for example song et al 2016 developed a rule based water resource allocation model to balance water allocation among sub areas and users chen et al 2017 formulated an interval multistage water classified allocation model to optimally allocate water resources to municipality industry hydropower and agriculture fu et al 2018 optimized multi water source allocation to different crops using an optimization model in all the above researches verified the applicability and effectiveness of optimization model in water allocation system however three major concerns remained to be further explored in multi source multi user water allocation system first of all the sequential order and strategic interaction among multiple hierarchical decision makers should be analyzed deeply in practice district administrator has priority to allocate water to each sector in each sub area and sub area farmers execute their decision power based on given amount of water resources safari et al 2014 since each decision maker puts emphasis on different targets the feedback and coordination between different decision makers are of great significance second a compensatory demand for external water due to water shortage of seasonal inflows is apparently needed to be taken into account third in terms of agricultural water how field condition and allocated water in each growth period affect crop production is needed to be figured out generally the production loss caused by water deficit in key period can be hardly compensated through more irrigation in other period guo et al 2014a yet there are no studies available optimizing multi source multi user water planning strategies with all aforementioned issues taken into consideration in response to the above mentioned concerns a bi level programming blp framework is formulated to gain insight into the whole water allocation process with two groups of decision makers district administrator and sub area farmers objectives in two hierarchical levels are performed from the upper level to the lower level zhang and vesselinov 2016 jin et al 2018 and then the decision of upper level may be affected by the reaction of the lower level decision makers arora and gupta 2009 baky 2009 in this way blp provides an effective means to prioritize the more important target and balance different decision making levels baky and abo sinna 2013 additionally mixed integer linear programming mlp where integer variable is equal to 1 or 0 should be adopted to indicate whether external water transferring should be done and how much external water is consequently needed to be transferred furthermore stewart model stewart et al 1976 can not only reflect the relationship between crop production and allocated water in each grow stage but also represent the difference when the same amount of water is allocated following different schedules chen et al 2017 besides field water balance equation can support effectively quantification of field condition which help enhance feasibility and applicability of optimization model accordingly the integration of mlp stewart model field water balance equation and blp is a potential approach to address complex difficulties associated with water resources management however the method will encounter difficulties addressing multiple uncertainties in water allocation system specifically uncertain factors which mainly arise from the randomness of natural events the vagueness of the objectives and constraints and the parameter estimation errors regulwar and gurav 2011 lead to the uncertainty and complexity of the water allocation process therefore uncertainty techniques including interval parameter programming ipp stochastic mathematical programming smp and fuzzy mathematical programming fmp are widely used to address different kinds of uncertainties related to water resources management problems maqsood et al 2005 dai and li 2013 tong and guo 2013 jin et al 2012 zhang and guo 2017 guo et al 2014b zhang et al 2019 in comparison fmp is proved more convenient in practical applications because it not only is more informative than ipp but also has less computational burden than smp li et al 2017 xie et al 2018 zhang et al 2018b in fmp uncertain parameters are expressed as fuzzy sets fs with membership function for example a traditional triangular fuzzy number a is composed of the least possible value a1 the middle value a2 and the highest possible value a3 which can be represented by a a 1 a 2 a 3 each possible value in a 1 a 2 a 3 corresponds to a certain membership in 0 1 which forms the triangular membership function in reality it is badly hard to deduce a crisp membership function of fs in circumstances where exist multi fold uncertainty and instinctive imprecision jana et al 2017 type 2 fuzzy sets t2fs originally introduced by zadeh 1975 has enhanced the ability to handle uncertain information and overcome the limitations of simplified type 1 fuzzy sets t1fs consequently it has quickly attracted widespread attention and been adopted to a variety of fields rapidly for example site selection problem Ã§ebi and otay 2015 energy systems planning suo et al 2017 municipal solid waste management jin et al 2019 transportation problem liu et al 2014 and so on however few researches have been reported considering t2fs in water resources planning system where hydrological parameters has strong variability and highly uncertainty besides many studies reveal that climate change will lead to the spatial and temporal redistribution of water resources gosling and arnell 2016 liu and xu 2015 palutikof 2007 and arise severe influence on water supply demand structure by altering the hydrological cycle jang et al 2007 kirby et al 2016 wang et al 2014 previous studies showed that the impacts of climate change are particularly sensitive to changes in precipitation and temperature frederick and major 1997 it is believed that climate change will take the world into a new phase of water stress and uncertainty in the future rowshon et al 2019 ausseil et al 2019 although the significance of this issue there are limited studies available which analysis how to optimally plan water allocation strategies in a changing environment due to future climate change summarily one potential approach for better accounting for all above concerns is incorporating t2fs mlp stewart model field water balance equation within general blp framework under climate change scenarios formulating a type 2 fuzzy mixed integer bi level programming t2fmbp model nevertheless there are few applications of the t2fmbp model to water resources planning therefore the primary objective of this study is to develop a novel approach namely t2fmbp for allocating multi source water resources to multiple water use sectors in future changing environment the developed approach makes contributions mainly on 1 balancing the conflicting concerns of hierarchical decision makers in a multi source multi user water allocation system 2 improving the accuracy of characterizing highly uncertain parameters concurrently occurring in both objective functions and constraints 3 detailing the interrelationship among water demand water supply and climate change to demonstrate its validity the t2fmbp approach will be applied to the zhanghe irrigation district zid for planning water resources under uncertainty flexible optimization solutions under different scenarios can provide prospective guidance for efficient water management and climate change adaptation 2 development of methodology in a real world water allocation system characterized by multiple hierarchies and intricate water supply demand structure management authority is tasked with allocating water resources to multiple sectors in multiple subareas the tradeoffs between water demand and water availability often make decision makers in a dilemma which calls for sustainable water management different hierarchies where each decision maker independently control over their own objective and decision making process make it far more difficult for appropriate water allocation strategy in general there are two decision making levels consist of district administrator and subarea farmers different decision makers have different and perhaps conflicting preferences a higher decision level occupies the priority to make decisions and the lower decision level must follow the decisions of higher level besides the higher level decisions are affected by the feedback from the lower level to the higher level the different concerns from bi level decision makers should be fully considered moreover uncertainties associated with environmental factors exist in water allocation system and strengthen the complexity water allocation system furthermore climate change has exacerbated the instability of the hydro meteorological system caused temporal spatial redistribution of water resources and affected local livelihood security wang et al 2019b wang et al 2019c it s crucial to find out how climate change affect the water resources as well as the description of consequent uncertainties resulting from climate projections accordingly for sustainable water resources management following issues should be taken seriously as 1 how to effectively allocate limited available water from different sources to conflicting sectors in different subareas 2 how to balance the different targets associated with bi level decision makers 3 how to quantify the uncertain factors associated with water allocation process and future climate change in order to effectively address above complexities and interactions it is essential to propose an integrated approach for gaining proper water allocation policy therefore a t2fmbp approach integrating t2fs with mlp into general blp framework is formulated for water resources planning under future climate change scenarios the model will be solved by the typical fuzzy coordination algorithm and preferred schemes will be identified allowing water allocation decisions to be made by managers accordingly fig 1 shows the framework of the study system with details being explained in the following sections 2 1 type 2 triangular fuzzy sets the concept of t2fs was first introduced by zadeh in 1975 as an extension of the traditional t1fs to effectively describe uncertainties unlike a t1fs where the membership function is a deterministic number in 0 1 a t2fs has a secondary grades of membership resulting a three dimensional membership function as fig 2 shown in this study type 2 fuzzy triangular sets t2tfs was used because it is computationally simper in solving mathematical programming problems according to liu and liu 2010 a t2tfs can be written as Î¾ r 1 r 2 r 3 Î¸ r Î¸ l where r 1 r 2 r 3 are real values and Î¸ r Î¸ l 0 1 are two parameters characterizing the spreads of primary membership grades of t2tfs then for x r 1 r 3 the secondary membership function Î¼ Î¾ x of Î¾ is defined in the form 1a Î¼ Î¾ x x r 1 r 2 r 1 Î¸ l x r 1 r 2 r 1 x r 1 r 2 r 1 x r 1 r 2 r 1 Î¸ r x r 1 r 2 r 1 i f x r 1 r 1 r 2 2 x r 1 r 2 r 1 Î¸ l r 2 x r 2 r 1 x r 1 r 2 r 1 x r 1 r 2 r 1 Î¸ r r 2 x r 2 r 1 i f x r 1 r 2 2 r 2 r 3 x r 3 r 2 Î¸ l x r 2 r 3 r 2 r 3 x r 3 r 2 r 3 x r 3 r 2 Î¸ r x r 2 r 3 r 2 i f x r 2 r 2 r 3 2 r 3 x r 3 r 2 Î¸ l r 3 x r 3 r 2 r 3 x r 3 r 2 r 3 x r 3 r 2 Î¸ r r 3 x r 3 r 2 i f x r 2 r 3 2 r 3 as shown in fig 2 each membership degree corresponds to a series of unfixed numbers posing a considerable obstacle to practical application therefore an extra type reduction is required to convert t2fs into conventional t1fs so that they can be defuzzified to give crisp outputs qin et al 2011 developed a reduction method for t2fs based on critical value cv method supposed that Î¾ is a t2tfs with secondary possibility distribution function Î¼ Î¾ x the method introduces the cvs as representing values of the regular fuzzy variable Î¼ Î¾ x i e c v Î¼ Î¾ x optimistic cv c v Î¼ Î¾ x pessimistic cv c v Î¼ Î¾ x neutral cv these cvs are defined as follows 1b c v Î¼ Î¾ x sup Î± 0 1 Î± p o s Î¾ Î± 1c c v Î¼ Î¾ x sup Î± 0 1 Î± n e c Î¾ Î± 1d c v Î¼ Î¾ x sup Î± 0 1 Î± c r Î¾ Î± for t2tfs following theorems qin et al 2011 dutta and jana 2017 are available for acquiring the expected value of these cvs consequently the t2tfs could be defuzzified to give crisp outputs in real world applications theorem 1 assume Î¾ 1 to be the reduction of the t2fs Î¾ r 1 r 2 r 3 Î¸ r Î¸ l obtained by the optimistic cv reduction method then 1e e o Î¾ 1 r 1 r 3 2 r 1 2 r 2 r 3 ln 1 Î¸ l 2 2 Î¸ l theorem 2 assume Î¾ 2 to be the reduction of the t2fs Î¾ r 1 r 2 r 3 Î¸ r Î¸ l obtained by the pessimistic cv reduction method then 1f e p Î¾ 2 r 2 r 1 2 r 2 r 3 ln 1 Î¸ r 2 2 Î¸ r theorem 3 assume Î¾ 3 to be the reduction of the t2fs Î¾ r 1 r 2 r 3 Î¸ r Î¸ l obtained by the neutral cv reduction method then 1g e n Î¾ 3 r 1 2 r 2 r 3 4 r 1 2 r 2 r 3 8 1 Î¸ l 1 Î¸ r 1 Î¸ l ln 1 Î¸ l Î¸ l 2 1 Î¸ r ln 1 Î¸ r Î¸ r 2 2 2 modelling a t2fmbp model is developed involving two basic decision making levels district administrator and farmers in each subarea in the upper level mlp is required to indicate whether or not external water should be transferred to satisfy total water demand in the lower level stewart model is considered to accurately reflect the impact of water supply on crop production during different periods therefore it is the demand of different sectors coupled with the desire of district administrator to maximize profits and the desire of farmers to maximize their incomes which together determine how water resources shall be allocated in the decision making process decisions are made sequentially from the upper level to the lower level and then modified with consideration of bi level concerns additionally complex data characteristics existed in water allocation system calls for detailed description in a changing environment in this study precipitation and available water are described by t2tfs with type 2 fuzzy membership function to present the model a list of notations is shown in table 1 upper level maximum system benefit 2a max f 1 i i c i x i j 1 j t 1 t a c j a j t w jt Î´ c e w e lower level maximum agricultural profit for each subarea 2b max f 2 j a j y m p 1 t 1 t b t e t mt t w jt e t mt u j a j t 1 t a j d 1 r w jt Î· j 1 d 2 s w jt i w jt Î· 2 j with 2c t w jt min p w jt r w jt s w jt i w jt e t mt j t 2d p w jt min e t mt Î± p r t j t 1 paddy field water balance constraint paddy field water balance constraint is required to deeply explore the relationship between water recharge water discharge and water storage during a certain period for paddy field the water depth drops with evapotranspiration drainage and percolation and it grows with precipitation and irrigation chen et al 2016 depth of water layer in period t can be calculated as follows 2e h jt h j t 1 p r t r w jt s w jt i w jt e t mt d w jt s jt j t to guarantee the crop growth the water depth should be within the scope of minimum and maximum field water depth this constraint can be expressed as 2f h min t h jt h max t j t 2 the key reservoir water supply constraint the key reservoir water allocated to all the non agricultural sectors and agricultural subareas should not be larger than the total available water that comes from the zhanghe reservoir this constraint can be presented as 2g i 1 4 x i Î· 11 j 1 3 t 1 4 a j r w jt Î· j 1 rq Î´ w e 3 general reservoir water supply constraint the general reservoir water allocated to each agricultural division must not exceed the available water supply the general reservoir water availability can be calculated by the method reported by pandey et al 2011 this constraint can be expressed as 2h t 1 4 a j s w jt p r t s a j Î· 2 j 4 pond water supply constraint similar to the general reservoir water pond water allocated to each agricultural division must not exceed the available water supply this constraint can be expressed as 2i t 1 4 a j i w jt p r t i a j Î· 2 j 5 non agricultural water demand constraint the water allocation amount for each non agricultural sectors should be within the scope of minimum and maximum water demand this constraint can be expressed as 2j x i min x i x i max i 6 binary constraints for external water 2k Î´ 0 if external water is not transferred 1 if external water is transferred 7 nonnegative constraint the allocated irrigation amount of multiple water sources and drainage in various crop growth stages in each subarea should be negative this constraint can be expressed as 2l r w jt 0 s w jt 0 i w jt 0 d w jt j t 2 3 model solution the core to solve the developed t2fmbp model is to transform the uncertain and bi level model into a deterministic and single level model hence two steps are needed the first step is to convert the t2tfs of the developed optimization model into deterministic numbers based on the type reduction method the second step is to transform the bi level programming model into a single level programming model using fuzzy coordination method step 1 formulate the model with t2tfs step 2 convert t2tfs into a chosen deterministic type via defuzzification based on the cv method step 3 calculate the upper level model firstly to obtain f 1 u f 1 l x i u t w jt u and w e u step 4 conduct membership functions for xi twjt and we with maximum tolerance t1 t2 and t3 as follows 3a Î¼ x i x i x i u t 1 t 1 x i u t 1 x i x i u x i u t 1 x i t 1 x i u x i x i u t 1 3b Î¼ t w jt t w jt t w jt u t 2 t 2 t w jt u t 2 t w jt t w jt u t w jt u t 2 t w jt t 2 t w jt u t w jt t w jt u t 2 3c Î¼ w e w e w e u t 3 t 3 w e u t 3 w e w e u w e u t 3 w e t 3 w e u w e w e u t 3 step 5 conduct the membership function for upper level objective f1 and lower level objective f2j with the acceptable satisfaction degree as follows 3d Î¼ f 1 x i t w jt w e 1 i f f 1 x i t w jt w e f 1 u f 1 x i t w jt w e f 1 l f 1 u f 1 l i f f 1 l f 1 x i t w jt w e f 1 u 0 i f f 1 x i t w jt w e f 1 l 3e Î¼ j f 2 j s w jt r w jt i w jt 1 i f f 2 j s w jt r w jt i w jt d w jt f 2 j u f 2 j s w jt r w jt i w jt d w jt f 2 j l f 2 j u f 2 j l i f f 2 j l f 2 j s w jt r w jt i w jt d w jt f 2 j u 0 i f f 2 j s w jt r w jt i w jt d w jt f 2 j l step 6 obtain a single level single objective optimization model with the objective of maximizing satisfactory degree consequently the programming problem can be solved as 4a max Î» 4b Î¼ x i Î» i 4c Î¼ t w jt Î» i 4d Î¼ w e Î» i 4e Î¼ f 1 x i t w jt w e Î» 4f Î¼ j f 2 j s w jt r w jt i w jt d w jt Î» 4g Î» 0 1 4h x i t w jt w e s w jt r w jt i w jt d w jt m where Î» is overall satisfactory degree of upper level and lower level model m is the constraint set in initial model step 7 calculate the t2fmbp model under different scenarios and generate flexible water allocation solutions 3 model application 3 1 study area the proposed model was applied to a real case study in the zid fig 3 zid is located north of the yangtze river basin in central china which across three cities of jingmen jm jingzhou jz and dangyang dy zid is one of the most important production bases of commodity grain in hubei province accompanying the complicated water allocation to competitive users cities industry irrigation and hydropower salient features of zid in addition to the multiple water users include its relative abundance of water supply especially the precipitation this area receives an average annual rainfall of 901 3 mm 1963 2018 although the annual rainfall is high drought frequently occurs due to significant rainfall variability both within and among years roost et al 2008a roost et al 2008b approximately 82 6 of the yearly rainfall occurs between april and october furthermore the zhanghe reservoir is a main water supply source for multiple users including irrigation domestic industry ecology and hydropower of jm city irrigation of jz city and irrigation of dy city with the total storage capacity of 2 113 billion cubic meters besides there are 314 general reservoirs 81 595 ponds and 34 pumping stations in the district the general reservoirs and ponds are operated independently from the zhanghe reservoir to allocate irrigation water resources agricultural users in each subarea could benefit from flexible supplies generally allowing farmers to gain water on demand nevertheless due to the water supply shortage occurred in dry year a compensatory demand for external water is apparent for sustainable regional development in zid winter rape and rice rotation is the main farming pattern however winter rape is no need to be irrigated due to the low water requirement thus rice is the only agricultural water consumer on the one hand it is significant to optimally manage water resources with multiple water supply sources and multiple water users in different subarea on the other hand with continuous increase of population and rapid development of economy how to satisfy the increasing water requirement with limited water resources is an urgent issue additionally various uncertain parameters existed in the water allocation system make it more complicated to obtain appropriate schemes furthermore climate change will probably have interacting effects on the environment and represent a major challenge to water management therefore in response to above issues inexact optimization models are desirable to support sustainable water resources management under future climate change 3 2 parameter determination data for the t2fmbp model mainly includes hydrological data crop water production function paddy field condition socio economic data and so on bcc csm1 1 m was adopted to generate climate change scenarios consisting of daily precipitation and the maximum and minimum air temperature from 2021 to 2050 by driving the statistical downscaling model sdsm in three representative concentration pathway rcp scenarios rcp2 6 rcp4 5 and rcp8 5 the elaborated projection methods can be found in wang et al 2019b after that future inflow of the zhanghe reservoir from 2021 to 2050 can be predicted using swat soil and water assessment tool model under above climate change scenarios to better quantify the stochastic characteristics frequency analysis method was used to classify different hydrological years namely wet year p 25 normal year 25 p 75 and dry year p 75 where p denotes the frequency li et al 2016 for each hydrological year the effective precipitation can be obtained by multiplying precipitation by corresponding effective coefficient moreover precipitation and water availability subjected to human judgments xu and qin 2010 rarely has the accurate characteristics resulting in a higher uncertainty t2tfs as a dual uncertainty could be a potential expression for these environmental factors these t2tfs can be constructed by the fuzzification method reported by cheng 2004 as shown in appendix 1 all these hydrological parameters can be seen in table 2 future daily reference crop evapotranspiration mm was calculated by hargreaves model hargreaves and samani 1982 nonlinear regression method was used to modify the model input parameters and then the daily potential evapotranspiration was calculated by the crop coefficient approach accordingly the total crop water requirement in each growth stage can be calculated by the sum of daily value during each growth stage the crop potential yield and water sensitivity index were obtained from previous researches the water loss of paddy field can be estimated by the rate of 1 mm day the maximum and minimum water layer depth were obtained from field experiment provided by the hubei irrigation experiment center station detailed information are given in table 3 socio economic parameters including crop price cultivation area area of general reservoirs and ponds water use coefficient benefit coefficient planting cost and water requirement of non agricultural water users were obtained mainly from statistical yearbook filed survey report and previous researches these socio economic parameters have shorter time series and less uncertainty than hydrological parameters accordingly can be expressed as determinate parameters benefit coefficients of non agricultural sectors were calculated by contribution coefficient method referred to li 2017 quota method is used to acquire the maximum water requirement of non agricultural water users in the planning year of 2030 the minimum water requirement is obtained by multiplying the maximum water requirement by proper coefficient that is 0 9 for domestic 0 8 for industry and 0 8 for ecology in addition the minimum water demand of hydropower equals to the ecological water demand in downstream rivers crop price planting cost cultivation area area of general reservoirs and ponds and water use coefficient were provided by the hubei zhanghe project administration bureau detailed information can be seen in tables 4 and 5 4 results analysis and discussion 4 1 results of future climate change scenarios fig 4 shows the maximum air temperature tmax minimum air temperature tmin precipitation crop potential evapotranspiration and annual inflow of the zhanghe reservoir during 1989 2018 historical period and 2021 2050 future period under the three rcp scenarios rcp2 6 rcp4 5 and rcp8 5 these variables play significant roles in determining water resources environment in a changing climate both tmax and tmin over the next 30 years show increasing trends under three rcp scenarios compared with historical period the temperature raises along with increasing rcp which is rcp 8 5 rcp 4 5 rcp 2 6 specifically the maximum temperature increases by 1 18 1 43 and 1 57 as well as the minimum temperature increases by 1 47 1 65 and 1 85 in three rcp scenarios as fig 4 c shown the precipitation during crop growth stages in rcp 2 6 exhibits a noticeable increasing tendency while the increase in other rcps is slight due to apparent warming conditions and associated precipitation change crop evapotranspiration as well as annual inflow is influenced correspondingly crop potential evapotranspiration during the whole growth periods tend to increase from historical period to future period and the ranks from high to low are rcp 2 6 465 4 mm rcp 4 5 454 4 mm rcp 8 5 454 2 mm and history 440 7 mm in terms of annual inflow it denotes obvious uptrend in rcp 2 6 and downtrend in rcp 4 5 and rcp 8 5 from historical period to future period finally the future climate change scenarios can be accordingly generated consisting of above main elements overall three rcp scenarios rcp 2 6 seems like less negative for local socio economy development considering environmental changes the scenarios generated could be adopted to further explore optimal water resources allocation in the future 4 2 results of optimal water allocation by solving developed t2fmbp model in the optimization software optimal water allocation results among different water use sectors in different subareas during different period under different hydrological years and climate scenarios are obtained fig 5 depicts the proportion of total water resources from each source i e precipitation the key reservoir general reservoirs ponds and external water to the whole water distribution the graph presents not only the overall trend of water allocation amount but also the characteristics of each water source specifically the total water allocation has a downward trend from wet year to normal year as a result of shrinking natural inflow after that the total distributed water amount reaches a peak in dry year attributed by considerable external water transferring in terms of multiple water sources both the key reservoir and external water supply for agriculture and non agricultural sectors while other sources provide available water resources for agriculture only that can explain why the key reservoir water allocated amounts accounted for approximately 45 55 to the total water supply no matter in which scenarios in wet year zid is basically a rain fed agricultural region and the proportion which rainfall accounts for is up to 50 under rcp 4 5 however the rate of rainfall drops rapidly to 3 in dry year irrigation will play a more significant role on sustainable agriculture along with the decreasing natural water availability water from general reservoirs and ponds is prioritized for irrigation due to its features of flexibility simplicity and meeting water demand on time the ratio of general reservoirs and ponds water supply reaches the peak at 32 in normal year and then experiences a fall to 11 in dry year under rcp 8 5 when low inflow occurs the maximum proportion of external water occupies 38 under rcp 8 5 those above parameters and water allocation schemes are affected to different extent by changing environmental elements the results indicate that it makes sense to tackle this water management problem under different scenarios considering great natural resources variability taking normal year as an example fig 6 presents the optimal agricultural water allocation of each water source in each subarea the water supply in each subarea under the same scenario is nonidentical because of the differences of nature water availability and water requirement among subareas jm city has the biggest water demand followed by dy city and jz city while the available water supply rank from high to low is jm dy and jz in reality water from general reservoirs and ponds is allocated firstly when those parts of water is exhausted the key reservoir water is needed to meet the agricultural water demand specifically in dy city the water demand can be satisfied in rcp 2 6 and rcp 8 5 while supplement from key reservoir is allocated in rcp 4 5 in addition the proportion of key reservoir water in jz city varying from 5 to 34 is always higher than that in jm city in other word jz city is much more desirable for conjunctive allocation of multiple water sources the conjunctive operation of the key reservoir general reservoirs and ponds can ensure supplementary irrigation during water scarcity the results help managers better understand how the water supply condition is and how to manage agricultural water resources effectively the above analysis focus on total agricultural water allocation schemes with multiple water sources however it is also of interest to decision makers on how to allocate these amount of water among different crop growth stages fig 7 shows the detailed water distribution among different growth stages in different subareas under different scenarios in normal year the results show that when water demand cannot be well met across four periods water supply priority is given to heading stage followed by booting stage tillering stage and milky stage these results are related to water scarcity sensitivity water requirement and precipitation in each period specifically the production loss in heading stage which have stronger sensitivity to water scarcity is difficult to make up through more irrigation in other stages even though tillering stage has the highest water demand it can be satisfied because of high precipitation within the period although rainfall has variability among different rcp scenarios it is the main source of water supply under all rcps in normal year to reflect the water recharge discharge results comprehensively dynamic water layer depth during growth periods is expressed in fig 8 it is able to present how much water volume are remained in a certain period apparently the paddy field was drier when hydrological inflow was lower despite the change regularity of water depth among rcp scenarios was unavailable it is all controlled within the safe range the optimal results can offer a guidance for decision makers to allocate water in a reasonable way fig 9 presents the optimal solutions of non agricultural sectors among different scenarios the amount of water allocated to the same sector varies among different rcp scenarios determined by different environmental elements which mainly include precipitation and annual inflow the results demonstrate that the optimal water allocation results completely follows natural laws which is larger water availability for example in wet year and rcp 2 6 corresponds to more amount of water distribution overall for each scenarios water allocated to domestic and ecology reaches the maximum water requirements that is because the optimization model tends to satisfy water demand of high benefit industries to achieve higher system total profit but this brings about larger water shortage risks existed in industry and hydropower which are low benefit industries the satisfaction degree defined by the water supply demand ratio is shown in fig 9 b lower satisfaction degree means graver contradiction between water supply and water demand in terms of industry the percentage varies from 100 to 80 which is within a safe and acceptable range however the value of hydropower is extremely low even 13 in some certain conditions this occurs because of two main reasons one is that hydropower has a smaller impact on the objective than other sectors due to the lower per unit benefit the other one is that hydropower has the highest water requirement target among all users it can be indicated that the proposed optimization model can optimally allocate water to achieve maximum system benefit obeying the benefit oriented mechanism optimal solutions for different scenarios corresponding to the combinations of hydrological levels and rcp scenarios were different resulting in varying system benefits the objective function of t2fmbp model is to maximize the total system economic benefit from the system benefit under different given scenarios illustrated in fig 10 the system benefit varies mainly in accordance with the trend of the total water allocation and is up to 4 14 billion yuan however when external water is transferred the system benefit would be seriously affected marked in red because the price of external water is much higher than internal water those benefits are lower than the expected value associated with water allocation nevertheless the external water is essential for sustainable agricultural and socio economic development considering large inter annual environmental variability meanwhile the model always obtains the higher profit in rcp 2 6 thus previous speculation which believe rcp 2 6 is better for optimal water allocation is verified thereby the results help decision makers better understand water allocation conditions under each possible scenario and hence make appropriate decisions 4 3 discussion the real world case study showed that the t2fmbp model under uncertainty was an effective tool for sustainable water allocation in zid the model presented its own distinctiveness mainly on three points firstly the model can tackle the complexity of hierarchical decision making among multiple processes of water allocation within blp framework making more practical and reasonable decisions to better reflect the performance of t2fmbp model upper level model model 1 and lower level models model 2 model 3 and model 4 were calculated separately for contrasting with developed model model 5 as shown in fig 11 the system benefit results of t2fmbp model were within the range of other single level models and closer to the upper level model the results reflected the tradeoff between district administrator and subarea farmers and the priority of upper level decision maker secondly the model addressed dual uncertainties expressed as type 2 fuzzy numbers of water resources supply aspect for the accuracy characterization of vagueness in order to validate the results we obtained a sensitivity analysis with different spreads Î¸l Î¸r the type 2 fuzzy numbers can be transformed into different deterministic ones with different given spreads via critical value method the optimum results were given in table 6 it is observed that the profits had a downtrend when the right spreads increased and the left spreads decreased respectively however the changes among different results are below 2 5 which means the spreads had little effect on optimal targets in addition the critical value method adopted in this paper helped more indicative schemes provided rather than a series of alternatives under different Î± cut levels thirdly the model provided managerial insights for water resources allocation considering changing climate and corresponding influence on water supply demand structure in the future fig 12 displayed the total water shortage among current year 2020 and future rcp scenarios in 2030 it indicated that the water scarcity problem would be aggravated in the future owing to negative impact caused by global climate change there would be huge volumes of water shortage even in normal year mainly attributed to burgeoning increase of water demand overall the developed t2fmbp model would be helpful for managers to cope with difficulties in water allocation system and thus guide local water resources planning to explore the impacts of input parameters the following scenarios were assumed a three precipitation levels with high h level 1 2 pr middle m level pr and low l level 0 8 pr where pr represent the actual precipitation b three reservoir water availability levels with h level 1 2 rq m level rq and l level 0 8 rq where rq represent the actual reservoir water availability c nine combination levels with h h level 1 2 pr 1 2 rq h m level 1 2 pr rq h l level 1 2 pr 0 8 rq m h level pr 1 2 rq m m level pr rq m l level pr 0 8 rq l h level 0 8 pr 1 2 rq l m level 0 8 pr rq l l level 0 8 pr 0 8 rq the above 15 cases were optimized in normal year under rcp 2 6 scenarios the optimal results are displayed in fig 13 including the effects of individual parameters and interactive parameter pairs on system benefit it illustrates that all parameters have effect on system net benefit benefit increases slightly with precipitation while it climbs rapidly with reservoir water availability this indicates that net benefit is more sensitive to reservoir water availability the main reason is that the actual water availability is much larger than precipitation the results demonstrate that identifying water allocation strategies under different scenarios is of great significant 5 conclusions aimed at water resources planning problems an integrated model called t2fmbp was proposed under uncertainty and future climate change three advantages which make the developed model idiographic for water resources management are 1 balancing the competing targets for hierarchical decision makers in a multi source multi user water resources system 2 addressing parameter uncertainties associated with the fluctuation of natural resources and vagueness of human judgement 3 analyzing the response of water allocation to the water supply availability and climate change which will help generate proper water management policies in a changing environment the t2fmbp model was applied to identify the optimal water resources allocation policies with five water resources to five water users in three subareas in the zhanghe irrigation district central china optimal results had significant differences among different scenarios especially in different hydrological years which demonstrated that water allocation was sensitive to water availability massive external water up to 8 82 108 m3 would help to reach the targets of maximizing system benefit in dry year the model follow the benefit oriented mechanism which lead to higher satisfactory degree in high benefit sectors as well as large water shortage of hydropower in the process of agricultural water allocation the results of each period coincided with the expectations associated with the water scarcity sensitivity distribution according to comparison between developed model and four single level models t2fmbp performed well on balancing conflicting goals of two level decision makers furthermore global climate change would aggravate the contradiction of water supply and demand but rcp 2 6 was validated little negative for water resources management the developed approach was portable to other similar regions encountering water scarcity problems moreover the spatial variability associated with natural resources and field conditions deserves further study to enhance the accuracy of the model framework credit authorship contribution statement qiong yue conceptualization methodology software writing original draft youzhi wang validation methodology software liu liu resources formal analysis jun niu resources formal analysis ping guo supervision writing review editing funding acquisition peng li investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was supported by the national key r d program of china no 2017yfc0403201 appendix assume that g 1 g n are the values assigned by n different experts when grading an object in addition let g i g j for at least one pair of i j these values can be considered to represent the possibility distribution of the grading process step 1 calculate the distance between each g i and presented in the relative distance matrix d d ij n n where d ij g i g j step 2 calculate the average of the relative distance for each g i by d i j 1 n d ij n 1 step 3 conduct the pair wise comparison matrix p p ij n n where p ij represents the relative importance of g i compared to g j given by p ij d j d i step 4 calculate the true degree of importance w i of g i where w i 1 i 1 n p ij step 5 estimate the mode m of the fuzzy number by m i 1 n w i g i step 6 define the average deviation s to approximate the unknown mean deviation Ï where s i 1 n w i g i m step 7 define the ratio of the left spread to the right spread Î· to approximate the unknown ration Î· calculate Î· m g l g r m where g l i a w i g i i a w i g r i b w i g i i b w i a i g i m i i b i g i m i i and i 1 n step 8 obtain a m 3 1 Î· Î· Ï 1 Î· 2 b m 3 1 Î· Ï 1 Î· 2 then acquire the conventional triangular fuzzy number f a m b 
5082,water level fluctuation wlf forecast plays an essential role in the regulations and management of the yangtze river s navigable rivers traditional methods for navigable rivers forecasts are often time consuming and cost inefficient often requiring constant updates and are univariate in nature this study utilized one of the yangtze river s navigable rivers nanjing navigable river to perform forecasts employing deep learning techniques for the first time nanjing navigable river s wlf data was exploited to make multi step univariate and multivariate time series forecasts employing a deep learning technique multilayer perceptron mlp the data consisted of 3545 days worth of wlf measurements from ten different navigable rivers and was allocated properly without data leakage into training and testing mlp was built to take time series sequence inputs from up to ten navigable rivers on a daily basis and output fast accurate stable and reliable short term forecasts and undeviating trends for long term forecasts the models were also constructed in an adaptive way so they can self update daily based on the daily measurements the naive model was constructed as a baseline model to measure the improvement and the validity of mlp models univariate and multivariate adaptive models were then constructed based on the augmented data by a popular data augmentation method rolling windows hyperparameters of mlp models were optimized based on relevant testing and large scale grid search both short term and long term forecasts showed promises of mlp model in time series forecast for navigable river water level problems and they achieved at least 27 6 percent lower in root mean square error rmse compared to the baseline since the total time required for the trained models to produce forecasts and self update is at most 15 min on a local quad core intel core i5 10th generation 2 0 ghz and because of the nonnegotiable performance of the models it was concluded that mlp is a fast cost efficient and accurate alternative technique for navigable rivers wlf forecasts keywords navigable river water level fluctuation deep learning multilayer perceptrons time series 1 introduction note that a list of abbreviations and symbols used are in the appendices yangtze river is one of the largest rivers in the world with a drainage area of 1 8 million square kilometers which contributes to one fifth of china inland area chen and gu 2010 wlf of yangtze navigable rivers are crucial to national transportation king and webber 2008 ecosystem coops et al 2003 irrigation schuurmans et al 1999 fishery cohen and radomski 1993 flood planning alsdorf et al 2000 hydropower li and he 2008 etc making navigable river wlf forecast extremely valuable until today worldwide wlf forecasting focuses on large lakes for their significance in globalization for instance lake van altunkaynak et al 2003 however forecasting wlf of artificial non artificial local navigable rivers may have tremendous economic benefits for local governments traditional approaches of wlf forecast can be divided into theoretical methods numerical simulations and experimental physics they have some major power as well as major drawbacks theoretical methods aksoy et al 2013 based on statistics are accurate and reliable in an ideal scenario but unable to handle multivariate wlf forecasts with high complexities in a realistic setting numerical simulations work by solving complex hydrodynamic equations kebede et al 2006 requiring a large number of parameters air temperature wind level precipitation and etc this approach has developed rapidly in the past twenty years yet it is still inapplicable for areas with limited measurements other limitations of numerical simulations are computational complexities and accuracy experimental physics fischer and Ã¶hl 2005 is the most costly approach and can only be applied to a locality for mechanism discoveries these limitations led to the development of neural networks that rely on completely different assumptions and possess the capability to accurately predict wlf with limited resources neural networks can also take other variables other cities navigable rivers wlf into account and build multivariate models as other variables might have strong interactions with the studied city in the last decades artificial neural networks or anns have shown promises of time series forecast in diverse fields surface water level forecasting piasecki et al 2017 short term traffic forecasting zhao et al 2017 energy consumption forecasting berriel et al 2017 environmental consumption lee et al 2017 airport availability forecasting zhu et al 2017 etc these studies not only proved the validity of anns but also demonstrated the power of anns in terms of time complexities and accuracy in very recent years the developments of various neural networks frameworks especially recurrent neural networks have grown even more rapidly and were popularized among different types of steamflow forecasts flood forecasting using a encoder decoder long short term memory kao et al 2020 and recurrent anfis zhou et al 2019 and temperate lakes water level forecasting using lstms and anns zhu et al 2020 these studies have further demonstrated the power of neural network frameworks and how they can be utilized as cheap alternatives or even mainstream methodologies due to their cost efficiency and effectiveness due to all the merits of neural networks in this study we will be investigating the problem of navigable rivers wlf using a basic fully connected and self adaptive neural network framework or more specifically the development of adaptive mlps in nanjing navigable river being adaptive means the nn model will be re built by quickly adjusting its weights from the feedback of the new data generating adapted forecasts resulting in more accuracy es experimented in this study this adaptive nature of the model is indispensable and highly valuable in real life as its ability to deal with the unpredictables for instance if there are some factors heavily influencing today s water level an adaptive model can quickly gain information and adapt to this change reconstructing the model for future accurate predictions furthermore the novelty of this study will be the application of mlps in a navigable river wlf forecast which has never been done before 2 methodology 2 1 study area nanjing fig 1 is the capital city of jiangsu province located along the bank of yangtze river s downstream it is a major city in yangtze delta contributing largely to the economy politics culture and information of jiangsu province it is a humid subtropical region characterized by disparities between long hot summers and cold cloudy winters nanjing navigable river is one of the most significant yangtze river s navigable rivers both geographically and economically from the investigation of the nanjing navigable river we can gain insights of how yangtze river s navigable rivers wlf change providing later investigations of other yangtze river s navigable rivers with ideas and methods in this study we are interested in discovering the long term trends and accurate short term forecasts for wlf in nanjing navigable river nanjing navigable river s water level fluctuation shows vague trend and seasonality and they oscillate tremendously between no pattern or very complex patterns the challenge here is to learn the complex mappings between water level fluctuation measured at different time stamps a reasonable branching of the problem can be 1 univariate multi step forecast for water level of nanjing navigable river i e using merely nanjing s navigable river s water level measurements 2 multivariate multi step forecast for water level of nanjing navigable river i e using the water level measurements of the navigable rivers in ten cities around nanjing city along the yangtze river a general workflow fig 2 of our study can be structured based on this division ranging from problem definition to final deliverable model the former model investigates nanjing s own temporal dependencies whereas the latter model investigates the interactions between navigable rivers with other navigable rivers which are upstream or downstream to nanjing navigable river heatmap is a useful visualization tool invented by cormac kinney in 1991 to visualize the correlations between each variable the heatmap was constructed using seaborn library waskom et al 2017 in python in fig 3 and the coloring represents the strength of correlations the lighter the color the higher the correlation from the heatmap we can see that changsha s water level is less correlated with other navigable rivers which makes sense as changsha s precipitation is much higher than other cities on the other hand other cities have shown a close correlation to the city of interest nanjing all ten navigable rivers measurements were plotted in fig 4 2 2 mlp multilayer perceptrons mlp colloquially referred to as the vanilla neural network hastie et al 2009 is a branch of feed forward networks svozil et al 1997 and is one of the first created anns as the name suggests mlp usually contains multiple layers it mainly consists of three layers the input layer the hidden layer and the output layer rosenblatt 1961 the number of neurons fig 5 in each layer and the number of layers are often hyper parameters and can be tuned later on to improve performance in this study in the output layer the number of neurons in an output layer is equal to the number of dependent variables after the window method each neuron contains bias b input x and weight w as three main components and it also has a non linear activation function that produces a cumulative output of the preceding neurons each output of a single neuron can be written as 1 y i Ï i w i x i b i whereas Ï is an activation function in this study rectified linear unit function relu 2 relu Ï z max 0 z was tested and selected over sigmoid and hyperbolic tangent functions as it has the ability to deal with the vanishing gradient problem making it one of the most popular activation functions ramachandran et al 2017 mlp is a gradient descent based learning method common selection such as hyperbolic tangent functions have gradients between 1 1 as gradient descent goes on the slope and gradients of function decrease exponentially resulting in slow learning and costly computation goodfellow et al 2016 mlp utilizes a supervised learning technique called backpropagation hecht nielsen 1992 for training fig 6 back propagation allows the information cost function to flow back to the network in order to compute gradients which is a fairly simple and inexpensive procedure goodfellow et al 2016 its learning occurs between perceptrons by updating connecting weights w the error of each output node can be expressed as 3 e i y i y i where y i is the predicted value from the neural network and root mean squared error rmse will be used as the metric to measure the overall performance of the model 4 e j w i 1 n y i y i 2 n where w is the weight between nodes that contributes to the predicted value y i and j w is the loss function to minimize j w gradient descent is applied to update the parameters Î¸ 5 w ij n 1 w ij n Î· w ij n j w where w ij is the parameter between the node i and node j and Î· is the learning rate which is to ensure the quick converge to a good model haykin 1994 mlp has advantages and disadvantages in different settings an issue that mlp encounters is as the number of input features increases the algorithm will become inefficient due to its fully connected nature driss et al 2017 other neural network structures were then developed because of the issue using shared weights between neurons in nanjing s navigable river data because the input size is fairly small it s reasonable to construct an mlp model because of the small number of total parameters the initial dataset was cleaned by imputing miss labeled points and divided into training 3215 days and testing 330 days sets by its time steps i e using the oldest 3215 days or less to train the model and the latest 330 days or less to test the model next the data needs to be prepared for the model constructions 2 3 data preparation window method the use of previous time steps to predict the next time steps is called the rolling window method li et al 2014 in short the window method or lag method which is a common method in statistics and time series analysis the number of previous time steps is called window width or lag size bontempi et al 2012 window method is the foundation of turning time series problems into supervised learning problems we will apply the window method to re frame our data for univariate and multivariate mlp models suppose we have a week of data and each day observation has one corresponding value and we want to construct a model that has the ability to predict the next two days i e day8 and day9 to do that re framing the data using previous three days i e window size of 3 to predict the next two days meaning using the values from day 1 2 3 as xs and values from day 4 5 as corresponding ys using the values from day 2 3 4 as xs and values from day 5 6 as corresponding ys and etc fig 7 the resulting matrix will have one row that contains only one y as our data is relatively abundant we can delete this row as it will not impair our models performance for multivariate data the window method can be analogously applied treat each value s i as a set of values tsay 2013 applying this technique on the real dataset with shape 3545 10 i e water level measurements of 3545 days in 10 cities in china is straightforward for brevity we will illustrate this process fig 8 for a seven day short time forecast i e n output 7 first of all split the data into training set and testing set by time steps resulting in two data frames with shape 3213 10 and 329 10 the values 3213 days and 329 days are chosen because they are divisible by 7 this is required for rolling window method then restructure the both the training set and the testing set into windows of size 7 resulting in two 3 d data frames with shape 459 7 10 and 47 7 10 additionally use the rolling window method to transform the restructured 3 d training set into a data frame for supervised learning the window size i e the number of previous time steps to predict the next time steps is a parameter that can be tuned later on for now we will call it n input if only using nanjing s water level data i e univariate forecasting the independent variables xs will be shaped as Ï n input n output n input 1 where Ï is a value varies with n input and n output 7 in this case whereas the dependent variables ys will be shaped as Ï n input n output n output 7 1 Ï n input n output can be easily derived as 6 Ï n input n output 3214 n input n output where 3214 length of the training set 3213 1 for instance if n input 7 Ï n input n output 3214 7 7 3200 from the window method on the other hand if using all 10 cities to predict nanjing s water level i e multivariate forecasting the independent variables xs will be shaped as Ï n input n output n input 10 whereas the dependent variables ys will be shaped as Ï n input n output 7 10 2 4 test harness a baseline persistence forecast now the data is prepared and the following procedure is to build a baseline model to measure the validity performance and improvements of our mlp models if our models achieve performance below the baseline the model needs to be fixed or simply abandoned a persistence forecast or naive forecast is a simple fast and repeatable method that assumes little about the nature of the forecast hyndman and athanasopoulos 2018 it can be generalized to testing possible offsets of the historical data for instance persisting last week s measurements persisting last year s measurements and etc three models were constructed using different offsets the daily persistence uses exact measurement from one day before our forecasting period and applies this value to all forecasting period as predictions the weekly persistence uses the measurements one week prior to our forecasting period as predictions to the forecasting period the weekly one year ago persistence uses one year ago measurements and taking one week s measurements prior to the identical week as our forecasting period an example of 7 day forecast persistence models are demonstrated in fig 9 2 5 model construction building skillful mlp models after constructing the baseline persistence models skillful mlp models are built a skillful model is a model that performs better than the baseline model brownlee 2018 the reason to build a skillful model first instead of tuning parameters is to confirm the validation of the model we don t expect the models to be the best possible but we are expecting to deliver a model that s around 80 of what can be possibly achieved as stated in the problem definition we will build two main kinds of models namely univariate and multivariate for both long term and short term forecasts fig 10 for the univariate case only nanjing water s water level data will be used i e we did not use any other cities measurements the mechanics used for long term forecasts and short term forecasts are quite disparate in terms of long term forecast we started by applying the window method on our training set and obtain the restructured dataframes namely train x and train y then utilized these two dataframes to fit our mlp univariate model and expect a one day forecast when feeding the neural network with historical values in the train x as inputs additionally adding this one day forecast to the original dataset to retrain our model and then feeding it historical values to make another one day forecast the process was repeated until sufficient forecasts have been obtained i e the same number of observations as the testing set lastly we can compare our forecasts with the actual measures point by point and calculate the error in metrics of rmse on the other hand for short term forecasts the main difference is that forecasts are not added to the training set but actual measurements are added in order to update the model resulting in an adaptive model that changes dynamically based on the actual inputs for the multivariate case the ten cities water levels will be used these models are expected to outperform the univariate models as neural networks have the ability to distinguish complex mappings and the relationships upstream and downstream relations between other cities and nanjing the procedure is slightly adjusted from the univariate case but still adopting the idea for long term forecasts repeating one step forecasts and updating the model using nanjing s one day forecast along with actual measurements from other cities for short term forecasts we are now updating the model with actual measurements from all the cities including nanjing also resulting in an adaptive model that changes dynamically based on the actual inputs one other thing to notice is that after applying the rolling window method to the training set with multiple variables the resulting dataframe will be 3 d instead of 2 d as these variables occupy a dimension 2 6 hyperparameter tuning building a grid search network after determining the skillfulness of the models constructed earlier we may think about ways to improve the performance or achieve the best performance of the models by tuning hyperparameters a good set of hyperparameters is an important component of model construction in this study the hyperparameters selections are n input n nodes n epochs n batch n hidden for example if we would like to create a univariate mlp model for a 7 day forecast fig 11 we start by setting n input in order to prepare the data using the window method after that the inputs and outputs of the neural network are now defined we then decide how many hidden layers we are using i e n hidden and for each hidden layer how many nodes neurons to use i e n nodes now the structure of mlp is established we can start training the model picking the number of times we want to repeat this process back and forth i e n epochs and decide how many samples are thrown into one mini batch i e n batch hyperparameter tuning is lengthy and computationally costly with the assistance of high performance computing clusters hpccs the time complexity issue is resolved moreover the set of hyperparameters doesn t need to be tuned regularly the same set of hyperparameters can be used without any adjustments and only the weights connecting each neuron need to be adjusted adjusting weights only took about 15 min on a local quad core i5 tenth generation which is fast and cost efficient hence we built a grid search network that takes into all combinations of the hyperparameters into account after each run of the hyperparameters we will re run with the same set of hyperparameters 5 times to ensure it is not just luck due to the stochastic nature of neural networks rmses of the testing set and training set from all runs were measured and were divided by the number of runs 5 as the metrics of the model performance 3 results all the models with different hyperparameters were constructed and updated using keras chollet et al 2015 an api with tensorflow abadi et al 2015 back end the inputs and outputs of each model were obtained using the rolling window method the hyperparameters of each model were selected from hyperparameter tuning using hpccs in the manner of optimizing rmse 3 1 short term forecasts the short term forecasts consist of 3 5 and 7 days forecasting the overall comparisons were shown in figs 12 14 showing the top three hyperparameters of each model after parameter tuning and the error in rmse for three day forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 0 297 0 193 and 0 161 respectively for five day forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 0 362 0 253 and 0 203 respectively for a seven day forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 0 442 0 320 and 0 229 respectively additionally the best model prediction vs actual plots were also generated and zoomed in figs 15 17 for better comparison each scenario consisted of the baseline persistence model univariate mlp and multivariate mlp for univariate mlp and multivariate mlp their model hyperparameters were selected by the grid search network constructed earlier to simplify the presentation only the top three sets of hyperparameters of each model will be reported and the best hyperparameters predicted values v s actual values was plotted we used 3213 days as the training set and predicted with a model created with the training set for the next 3 5 7 days then added the actual 3 5 7 days measurements to the training set and updated the model repeated this process and recorded each prediction cumulatively until the predictions reached the length of the testing set each combination of hyperparameters was repeatedly evaluated five times and each time s measurement of error rmse was collected and a mean was taken as the final rmse of the model in all cases 3 5 and 7 days forecasts multivariate mlp outperformed the other models by a lot as we expected fig 18 given the non negligible relationships between different cities for 3 day forecasts univariate mlp and multivariate mlp produced predictions 35 0 and 45 8 lower in terms of rmse for 5 day forecasts univariate mlp and multivariate mlp produced predictions 30 1 and 43 9 lower in terms of rmse for 7 day forecasts univariate mlp and multivariate mlp produced predictions 27 6 and 48 2 lower in terms of rmse multiplayer perceptrons or mlp models have shown great performance in short term time series forecasts for navigable rivers wlf 3 2 long term forecast the long term forecast is a forecast with the length of the testing set in other words we are predicting the full sequence of time series whose length is identical to the testing set s length in this study we predicted a full sequence of time series of length 330 the yearly persistence model i e using last year s same 330 days measurements constructed as the baseline model to evaluate the performance of the mlp models to summarize for long term forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 2 063 1 797 and 0 659 respectively the comparison of three models was shown in fig 19 with the top three hyperparameters rmse and plots of results of best hyperparameters from fig 19 we can see that long term forecasts were far from being accurate but they did exhibit the trend accurately which can be valuable in real life settings the mechanics used in univariate mlp and multivariate mlp are analogous in univariate mlp we obtain one forecast from the constructed model and add this one forecast to the training set to construct a new model then obtain another forecast the process is repeated until we obtain enough forecasts whose length matches the test set s length in multivariate mlp we obtain ten forecasts for ten cities from the constructed model and add these ten forecasts to the training set to construct a new model then obtain another ten forecasts repeat this process until we obtain enough forecasts whose length matches the test set s length upon gaining all the forecasts we measure the performance of the model by calculating the rmse and repeat the whole process five times due to the stochastic nature of neural networks the final rmse is calculated by the mean of cumulative rmse by each trial for brevity we will only include the top three hyperparameters a zoomed in comparison of the three models is shown in fig 20 from the plot we can see that multivariate mlp performed so much better than univariate mlp and the baseline model for long term forecast consequently multivariate mlp again outperformed all the other models as we expected fig 21 univariate mlp showed a 12 9 decrease in rmse and multivariate mlp showed a 68 1 decrease in rmse compared to the baseline model unlike traditional approaches the large scale parameter tuning was done in less than twenty four hours on hpccs also the univariate model and multivariate model with the selected hyperparameters only took at most 89 s and 143 s respectively to train and produce forecasts on a local machine with a processor of 2 0 ghz quad core intel core i5 10th generation 4 discussion overall the utility of mlp for time series forecasting has been perfectly demonstrated multivariate mlp provided a valuable full sequence forecast of 330 days with only an rmse of 0 659 and short term forecasts with rmses of 0 161 0 203 and 0 229 3 5 7 days respectively resulting in a final deliverable model that can be utilized in governmental navigable river regulations both for short term and long term forecasts hence we can confidently say that it is a success of experimenting with nns on navigable rivers wlf for the first time the results exhibited great applicability of mlp and once again proved the power of neural networks in time series problems for short term forecasts univariate mlp models have shown significant improvements when compared to the baseline model giving fairly accurate forecasts for 3 5 7 days forecasting additionally multivariate mlp models provided even more improvements than univariate mlp models for long term forecasts the performance of univariate mlp models are poor perhaps due to the lack of variables only being a little better than the baseline model however the general trend and seasonality can be somehow observed on the other hand multivariate mlp models performed outstandingly as each neighboring individual river has an undeniable effect on nanjing navigable river s wlf since mlp is the very basic nn and it lacks the ability to perform feature learning which is a key attribute of cnns and rnns and the ability to learn temporal dependence as rnns brownlee 2018 do it cannot generalize well in all time series problems although it performed well in this study additionally due to the fully connected nature of mlp goodfellow et al 2016 as the network gets larger the number of parameters grows exponentially resulting in overfitting to resolve these issues we can construct cnns rnns especially lstm and their mixtures which are more complex in terms of embedding and neurons and have better ability to prevent overfitting and perform well for time series problems 5 conclusions mlp models are extremely cost efficient reusable quickly implemented and can be easily developed to a web application or software with embedded model updating mechanisms for extremely simple usage for anyone only requiring updated measurements as inputs though the results are promising and validating for nanjing navigable river further improvements and generalization can be made using convolutional neural networks cnns recurrent neural networks rnns and their mixtures due to the limitations of mlp brownlee 2018 mlp is by all means the cheap alternative or maybe a replacement for expensive traditional methodologies for navigable river wlf forecasts declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this project is sponsored by the national natural science foundation of china grant no 51879058 and qing lan project special thanks to victor palacios for editing and polishing appendix a description of abbreviations the following descriptions of abbreviations are provided in alphabetical order to clarify the meaning 2 d two dimensional 3 d three dimensional anns artificial neural networks cnns convolutional neural networks lstm long short term memories mlp multilayor perceptron relu rectified linear unit rmse root mean square error rnns recurrent neural networks testx testing set features testy testing set labels trainx training set features trainy training set labels wlf water level fluctuation appendix b notation list the following symbols are used in this paper h n is the n t h layer of a neural network n output is the number of next time steps to be predicted n input is the number of previous time steps to predict the next time steps this will affect the shape of train x and train y fig 8 it is an essential part for window method for instance n input 7 means using the previous seven days as inputs to make forecasts on the next day s n nodes is the number of nodes or neurons in the hidden layer also called the size of the hidden layer the choice of many of nodes in the hidden layer to choose is empirical empirically speaking the optimal size of the hidden layer is usually between input size and output size heaton 2008 n epochs is the number of training epochs an epoch is a process of putting the entire training set into the neural network once both forward and backward the number of epochs usually determines the fitness of the model if the number of epochs is too low it will likely underfit if the number of epochs is too high it will likely overfit so we are aiming for the middle ground for the optimum n batch is the number of training samples in each batch or batch size due to the large size of one entire training set the dataset is often divided into small batches batch size is smaller than the number of training samples n hidden is the number of hidden layers in the neural network in most cases one hidden layer will solve most of the problems but we will try adding another layer s i is the observed measurement on i th day b i is the i th bias term associated with x i e i is the i th error term which is the difference between the true output and predicted output e is the total error which is the sum of each e i w i is the i th weight term associated with x i x i is the i th input y i is the i th output after the transformation of Ï y i is the i th predicted output from the model z l is the l t h output before the transformation of Ï Î· is the learning rate in gradient descent Ï is an activation function it transforms the inputs in the neurons to outputs Ï is a value that varies with n input and n output in the window method appendix c data availability statement some or all data models or code that support the findings of this study are available from the corresponding author upon reasonable request the original dataset the pre processed dataset 
5082,water level fluctuation wlf forecast plays an essential role in the regulations and management of the yangtze river s navigable rivers traditional methods for navigable rivers forecasts are often time consuming and cost inefficient often requiring constant updates and are univariate in nature this study utilized one of the yangtze river s navigable rivers nanjing navigable river to perform forecasts employing deep learning techniques for the first time nanjing navigable river s wlf data was exploited to make multi step univariate and multivariate time series forecasts employing a deep learning technique multilayer perceptron mlp the data consisted of 3545 days worth of wlf measurements from ten different navigable rivers and was allocated properly without data leakage into training and testing mlp was built to take time series sequence inputs from up to ten navigable rivers on a daily basis and output fast accurate stable and reliable short term forecasts and undeviating trends for long term forecasts the models were also constructed in an adaptive way so they can self update daily based on the daily measurements the naive model was constructed as a baseline model to measure the improvement and the validity of mlp models univariate and multivariate adaptive models were then constructed based on the augmented data by a popular data augmentation method rolling windows hyperparameters of mlp models were optimized based on relevant testing and large scale grid search both short term and long term forecasts showed promises of mlp model in time series forecast for navigable river water level problems and they achieved at least 27 6 percent lower in root mean square error rmse compared to the baseline since the total time required for the trained models to produce forecasts and self update is at most 15 min on a local quad core intel core i5 10th generation 2 0 ghz and because of the nonnegotiable performance of the models it was concluded that mlp is a fast cost efficient and accurate alternative technique for navigable rivers wlf forecasts keywords navigable river water level fluctuation deep learning multilayer perceptrons time series 1 introduction note that a list of abbreviations and symbols used are in the appendices yangtze river is one of the largest rivers in the world with a drainage area of 1 8 million square kilometers which contributes to one fifth of china inland area chen and gu 2010 wlf of yangtze navigable rivers are crucial to national transportation king and webber 2008 ecosystem coops et al 2003 irrigation schuurmans et al 1999 fishery cohen and radomski 1993 flood planning alsdorf et al 2000 hydropower li and he 2008 etc making navigable river wlf forecast extremely valuable until today worldwide wlf forecasting focuses on large lakes for their significance in globalization for instance lake van altunkaynak et al 2003 however forecasting wlf of artificial non artificial local navigable rivers may have tremendous economic benefits for local governments traditional approaches of wlf forecast can be divided into theoretical methods numerical simulations and experimental physics they have some major power as well as major drawbacks theoretical methods aksoy et al 2013 based on statistics are accurate and reliable in an ideal scenario but unable to handle multivariate wlf forecasts with high complexities in a realistic setting numerical simulations work by solving complex hydrodynamic equations kebede et al 2006 requiring a large number of parameters air temperature wind level precipitation and etc this approach has developed rapidly in the past twenty years yet it is still inapplicable for areas with limited measurements other limitations of numerical simulations are computational complexities and accuracy experimental physics fischer and Ã¶hl 2005 is the most costly approach and can only be applied to a locality for mechanism discoveries these limitations led to the development of neural networks that rely on completely different assumptions and possess the capability to accurately predict wlf with limited resources neural networks can also take other variables other cities navigable rivers wlf into account and build multivariate models as other variables might have strong interactions with the studied city in the last decades artificial neural networks or anns have shown promises of time series forecast in diverse fields surface water level forecasting piasecki et al 2017 short term traffic forecasting zhao et al 2017 energy consumption forecasting berriel et al 2017 environmental consumption lee et al 2017 airport availability forecasting zhu et al 2017 etc these studies not only proved the validity of anns but also demonstrated the power of anns in terms of time complexities and accuracy in very recent years the developments of various neural networks frameworks especially recurrent neural networks have grown even more rapidly and were popularized among different types of steamflow forecasts flood forecasting using a encoder decoder long short term memory kao et al 2020 and recurrent anfis zhou et al 2019 and temperate lakes water level forecasting using lstms and anns zhu et al 2020 these studies have further demonstrated the power of neural network frameworks and how they can be utilized as cheap alternatives or even mainstream methodologies due to their cost efficiency and effectiveness due to all the merits of neural networks in this study we will be investigating the problem of navigable rivers wlf using a basic fully connected and self adaptive neural network framework or more specifically the development of adaptive mlps in nanjing navigable river being adaptive means the nn model will be re built by quickly adjusting its weights from the feedback of the new data generating adapted forecasts resulting in more accuracy es experimented in this study this adaptive nature of the model is indispensable and highly valuable in real life as its ability to deal with the unpredictables for instance if there are some factors heavily influencing today s water level an adaptive model can quickly gain information and adapt to this change reconstructing the model for future accurate predictions furthermore the novelty of this study will be the application of mlps in a navigable river wlf forecast which has never been done before 2 methodology 2 1 study area nanjing fig 1 is the capital city of jiangsu province located along the bank of yangtze river s downstream it is a major city in yangtze delta contributing largely to the economy politics culture and information of jiangsu province it is a humid subtropical region characterized by disparities between long hot summers and cold cloudy winters nanjing navigable river is one of the most significant yangtze river s navigable rivers both geographically and economically from the investigation of the nanjing navigable river we can gain insights of how yangtze river s navigable rivers wlf change providing later investigations of other yangtze river s navigable rivers with ideas and methods in this study we are interested in discovering the long term trends and accurate short term forecasts for wlf in nanjing navigable river nanjing navigable river s water level fluctuation shows vague trend and seasonality and they oscillate tremendously between no pattern or very complex patterns the challenge here is to learn the complex mappings between water level fluctuation measured at different time stamps a reasonable branching of the problem can be 1 univariate multi step forecast for water level of nanjing navigable river i e using merely nanjing s navigable river s water level measurements 2 multivariate multi step forecast for water level of nanjing navigable river i e using the water level measurements of the navigable rivers in ten cities around nanjing city along the yangtze river a general workflow fig 2 of our study can be structured based on this division ranging from problem definition to final deliverable model the former model investigates nanjing s own temporal dependencies whereas the latter model investigates the interactions between navigable rivers with other navigable rivers which are upstream or downstream to nanjing navigable river heatmap is a useful visualization tool invented by cormac kinney in 1991 to visualize the correlations between each variable the heatmap was constructed using seaborn library waskom et al 2017 in python in fig 3 and the coloring represents the strength of correlations the lighter the color the higher the correlation from the heatmap we can see that changsha s water level is less correlated with other navigable rivers which makes sense as changsha s precipitation is much higher than other cities on the other hand other cities have shown a close correlation to the city of interest nanjing all ten navigable rivers measurements were plotted in fig 4 2 2 mlp multilayer perceptrons mlp colloquially referred to as the vanilla neural network hastie et al 2009 is a branch of feed forward networks svozil et al 1997 and is one of the first created anns as the name suggests mlp usually contains multiple layers it mainly consists of three layers the input layer the hidden layer and the output layer rosenblatt 1961 the number of neurons fig 5 in each layer and the number of layers are often hyper parameters and can be tuned later on to improve performance in this study in the output layer the number of neurons in an output layer is equal to the number of dependent variables after the window method each neuron contains bias b input x and weight w as three main components and it also has a non linear activation function that produces a cumulative output of the preceding neurons each output of a single neuron can be written as 1 y i Ï i w i x i b i whereas Ï is an activation function in this study rectified linear unit function relu 2 relu Ï z max 0 z was tested and selected over sigmoid and hyperbolic tangent functions as it has the ability to deal with the vanishing gradient problem making it one of the most popular activation functions ramachandran et al 2017 mlp is a gradient descent based learning method common selection such as hyperbolic tangent functions have gradients between 1 1 as gradient descent goes on the slope and gradients of function decrease exponentially resulting in slow learning and costly computation goodfellow et al 2016 mlp utilizes a supervised learning technique called backpropagation hecht nielsen 1992 for training fig 6 back propagation allows the information cost function to flow back to the network in order to compute gradients which is a fairly simple and inexpensive procedure goodfellow et al 2016 its learning occurs between perceptrons by updating connecting weights w the error of each output node can be expressed as 3 e i y i y i where y i is the predicted value from the neural network and root mean squared error rmse will be used as the metric to measure the overall performance of the model 4 e j w i 1 n y i y i 2 n where w is the weight between nodes that contributes to the predicted value y i and j w is the loss function to minimize j w gradient descent is applied to update the parameters Î¸ 5 w ij n 1 w ij n Î· w ij n j w where w ij is the parameter between the node i and node j and Î· is the learning rate which is to ensure the quick converge to a good model haykin 1994 mlp has advantages and disadvantages in different settings an issue that mlp encounters is as the number of input features increases the algorithm will become inefficient due to its fully connected nature driss et al 2017 other neural network structures were then developed because of the issue using shared weights between neurons in nanjing s navigable river data because the input size is fairly small it s reasonable to construct an mlp model because of the small number of total parameters the initial dataset was cleaned by imputing miss labeled points and divided into training 3215 days and testing 330 days sets by its time steps i e using the oldest 3215 days or less to train the model and the latest 330 days or less to test the model next the data needs to be prepared for the model constructions 2 3 data preparation window method the use of previous time steps to predict the next time steps is called the rolling window method li et al 2014 in short the window method or lag method which is a common method in statistics and time series analysis the number of previous time steps is called window width or lag size bontempi et al 2012 window method is the foundation of turning time series problems into supervised learning problems we will apply the window method to re frame our data for univariate and multivariate mlp models suppose we have a week of data and each day observation has one corresponding value and we want to construct a model that has the ability to predict the next two days i e day8 and day9 to do that re framing the data using previous three days i e window size of 3 to predict the next two days meaning using the values from day 1 2 3 as xs and values from day 4 5 as corresponding ys using the values from day 2 3 4 as xs and values from day 5 6 as corresponding ys and etc fig 7 the resulting matrix will have one row that contains only one y as our data is relatively abundant we can delete this row as it will not impair our models performance for multivariate data the window method can be analogously applied treat each value s i as a set of values tsay 2013 applying this technique on the real dataset with shape 3545 10 i e water level measurements of 3545 days in 10 cities in china is straightforward for brevity we will illustrate this process fig 8 for a seven day short time forecast i e n output 7 first of all split the data into training set and testing set by time steps resulting in two data frames with shape 3213 10 and 329 10 the values 3213 days and 329 days are chosen because they are divisible by 7 this is required for rolling window method then restructure the both the training set and the testing set into windows of size 7 resulting in two 3 d data frames with shape 459 7 10 and 47 7 10 additionally use the rolling window method to transform the restructured 3 d training set into a data frame for supervised learning the window size i e the number of previous time steps to predict the next time steps is a parameter that can be tuned later on for now we will call it n input if only using nanjing s water level data i e univariate forecasting the independent variables xs will be shaped as Ï n input n output n input 1 where Ï is a value varies with n input and n output 7 in this case whereas the dependent variables ys will be shaped as Ï n input n output n output 7 1 Ï n input n output can be easily derived as 6 Ï n input n output 3214 n input n output where 3214 length of the training set 3213 1 for instance if n input 7 Ï n input n output 3214 7 7 3200 from the window method on the other hand if using all 10 cities to predict nanjing s water level i e multivariate forecasting the independent variables xs will be shaped as Ï n input n output n input 10 whereas the dependent variables ys will be shaped as Ï n input n output 7 10 2 4 test harness a baseline persistence forecast now the data is prepared and the following procedure is to build a baseline model to measure the validity performance and improvements of our mlp models if our models achieve performance below the baseline the model needs to be fixed or simply abandoned a persistence forecast or naive forecast is a simple fast and repeatable method that assumes little about the nature of the forecast hyndman and athanasopoulos 2018 it can be generalized to testing possible offsets of the historical data for instance persisting last week s measurements persisting last year s measurements and etc three models were constructed using different offsets the daily persistence uses exact measurement from one day before our forecasting period and applies this value to all forecasting period as predictions the weekly persistence uses the measurements one week prior to our forecasting period as predictions to the forecasting period the weekly one year ago persistence uses one year ago measurements and taking one week s measurements prior to the identical week as our forecasting period an example of 7 day forecast persistence models are demonstrated in fig 9 2 5 model construction building skillful mlp models after constructing the baseline persistence models skillful mlp models are built a skillful model is a model that performs better than the baseline model brownlee 2018 the reason to build a skillful model first instead of tuning parameters is to confirm the validation of the model we don t expect the models to be the best possible but we are expecting to deliver a model that s around 80 of what can be possibly achieved as stated in the problem definition we will build two main kinds of models namely univariate and multivariate for both long term and short term forecasts fig 10 for the univariate case only nanjing water s water level data will be used i e we did not use any other cities measurements the mechanics used for long term forecasts and short term forecasts are quite disparate in terms of long term forecast we started by applying the window method on our training set and obtain the restructured dataframes namely train x and train y then utilized these two dataframes to fit our mlp univariate model and expect a one day forecast when feeding the neural network with historical values in the train x as inputs additionally adding this one day forecast to the original dataset to retrain our model and then feeding it historical values to make another one day forecast the process was repeated until sufficient forecasts have been obtained i e the same number of observations as the testing set lastly we can compare our forecasts with the actual measures point by point and calculate the error in metrics of rmse on the other hand for short term forecasts the main difference is that forecasts are not added to the training set but actual measurements are added in order to update the model resulting in an adaptive model that changes dynamically based on the actual inputs for the multivariate case the ten cities water levels will be used these models are expected to outperform the univariate models as neural networks have the ability to distinguish complex mappings and the relationships upstream and downstream relations between other cities and nanjing the procedure is slightly adjusted from the univariate case but still adopting the idea for long term forecasts repeating one step forecasts and updating the model using nanjing s one day forecast along with actual measurements from other cities for short term forecasts we are now updating the model with actual measurements from all the cities including nanjing also resulting in an adaptive model that changes dynamically based on the actual inputs one other thing to notice is that after applying the rolling window method to the training set with multiple variables the resulting dataframe will be 3 d instead of 2 d as these variables occupy a dimension 2 6 hyperparameter tuning building a grid search network after determining the skillfulness of the models constructed earlier we may think about ways to improve the performance or achieve the best performance of the models by tuning hyperparameters a good set of hyperparameters is an important component of model construction in this study the hyperparameters selections are n input n nodes n epochs n batch n hidden for example if we would like to create a univariate mlp model for a 7 day forecast fig 11 we start by setting n input in order to prepare the data using the window method after that the inputs and outputs of the neural network are now defined we then decide how many hidden layers we are using i e n hidden and for each hidden layer how many nodes neurons to use i e n nodes now the structure of mlp is established we can start training the model picking the number of times we want to repeat this process back and forth i e n epochs and decide how many samples are thrown into one mini batch i e n batch hyperparameter tuning is lengthy and computationally costly with the assistance of high performance computing clusters hpccs the time complexity issue is resolved moreover the set of hyperparameters doesn t need to be tuned regularly the same set of hyperparameters can be used without any adjustments and only the weights connecting each neuron need to be adjusted adjusting weights only took about 15 min on a local quad core i5 tenth generation which is fast and cost efficient hence we built a grid search network that takes into all combinations of the hyperparameters into account after each run of the hyperparameters we will re run with the same set of hyperparameters 5 times to ensure it is not just luck due to the stochastic nature of neural networks rmses of the testing set and training set from all runs were measured and were divided by the number of runs 5 as the metrics of the model performance 3 results all the models with different hyperparameters were constructed and updated using keras chollet et al 2015 an api with tensorflow abadi et al 2015 back end the inputs and outputs of each model were obtained using the rolling window method the hyperparameters of each model were selected from hyperparameter tuning using hpccs in the manner of optimizing rmse 3 1 short term forecasts the short term forecasts consist of 3 5 and 7 days forecasting the overall comparisons were shown in figs 12 14 showing the top three hyperparameters of each model after parameter tuning and the error in rmse for three day forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 0 297 0 193 and 0 161 respectively for five day forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 0 362 0 253 and 0 203 respectively for a seven day forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 0 442 0 320 and 0 229 respectively additionally the best model prediction vs actual plots were also generated and zoomed in figs 15 17 for better comparison each scenario consisted of the baseline persistence model univariate mlp and multivariate mlp for univariate mlp and multivariate mlp their model hyperparameters were selected by the grid search network constructed earlier to simplify the presentation only the top three sets of hyperparameters of each model will be reported and the best hyperparameters predicted values v s actual values was plotted we used 3213 days as the training set and predicted with a model created with the training set for the next 3 5 7 days then added the actual 3 5 7 days measurements to the training set and updated the model repeated this process and recorded each prediction cumulatively until the predictions reached the length of the testing set each combination of hyperparameters was repeatedly evaluated five times and each time s measurement of error rmse was collected and a mean was taken as the final rmse of the model in all cases 3 5 and 7 days forecasts multivariate mlp outperformed the other models by a lot as we expected fig 18 given the non negligible relationships between different cities for 3 day forecasts univariate mlp and multivariate mlp produced predictions 35 0 and 45 8 lower in terms of rmse for 5 day forecasts univariate mlp and multivariate mlp produced predictions 30 1 and 43 9 lower in terms of rmse for 7 day forecasts univariate mlp and multivariate mlp produced predictions 27 6 and 48 2 lower in terms of rmse multiplayer perceptrons or mlp models have shown great performance in short term time series forecasts for navigable rivers wlf 3 2 long term forecast the long term forecast is a forecast with the length of the testing set in other words we are predicting the full sequence of time series whose length is identical to the testing set s length in this study we predicted a full sequence of time series of length 330 the yearly persistence model i e using last year s same 330 days measurements constructed as the baseline model to evaluate the performance of the mlp models to summarize for long term forecast the baseline model the univariate mlp and multivariate mlp achieved best rmse of 2 063 1 797 and 0 659 respectively the comparison of three models was shown in fig 19 with the top three hyperparameters rmse and plots of results of best hyperparameters from fig 19 we can see that long term forecasts were far from being accurate but they did exhibit the trend accurately which can be valuable in real life settings the mechanics used in univariate mlp and multivariate mlp are analogous in univariate mlp we obtain one forecast from the constructed model and add this one forecast to the training set to construct a new model then obtain another forecast the process is repeated until we obtain enough forecasts whose length matches the test set s length in multivariate mlp we obtain ten forecasts for ten cities from the constructed model and add these ten forecasts to the training set to construct a new model then obtain another ten forecasts repeat this process until we obtain enough forecasts whose length matches the test set s length upon gaining all the forecasts we measure the performance of the model by calculating the rmse and repeat the whole process five times due to the stochastic nature of neural networks the final rmse is calculated by the mean of cumulative rmse by each trial for brevity we will only include the top three hyperparameters a zoomed in comparison of the three models is shown in fig 20 from the plot we can see that multivariate mlp performed so much better than univariate mlp and the baseline model for long term forecast consequently multivariate mlp again outperformed all the other models as we expected fig 21 univariate mlp showed a 12 9 decrease in rmse and multivariate mlp showed a 68 1 decrease in rmse compared to the baseline model unlike traditional approaches the large scale parameter tuning was done in less than twenty four hours on hpccs also the univariate model and multivariate model with the selected hyperparameters only took at most 89 s and 143 s respectively to train and produce forecasts on a local machine with a processor of 2 0 ghz quad core intel core i5 10th generation 4 discussion overall the utility of mlp for time series forecasting has been perfectly demonstrated multivariate mlp provided a valuable full sequence forecast of 330 days with only an rmse of 0 659 and short term forecasts with rmses of 0 161 0 203 and 0 229 3 5 7 days respectively resulting in a final deliverable model that can be utilized in governmental navigable river regulations both for short term and long term forecasts hence we can confidently say that it is a success of experimenting with nns on navigable rivers wlf for the first time the results exhibited great applicability of mlp and once again proved the power of neural networks in time series problems for short term forecasts univariate mlp models have shown significant improvements when compared to the baseline model giving fairly accurate forecasts for 3 5 7 days forecasting additionally multivariate mlp models provided even more improvements than univariate mlp models for long term forecasts the performance of univariate mlp models are poor perhaps due to the lack of variables only being a little better than the baseline model however the general trend and seasonality can be somehow observed on the other hand multivariate mlp models performed outstandingly as each neighboring individual river has an undeniable effect on nanjing navigable river s wlf since mlp is the very basic nn and it lacks the ability to perform feature learning which is a key attribute of cnns and rnns and the ability to learn temporal dependence as rnns brownlee 2018 do it cannot generalize well in all time series problems although it performed well in this study additionally due to the fully connected nature of mlp goodfellow et al 2016 as the network gets larger the number of parameters grows exponentially resulting in overfitting to resolve these issues we can construct cnns rnns especially lstm and their mixtures which are more complex in terms of embedding and neurons and have better ability to prevent overfitting and perform well for time series problems 5 conclusions mlp models are extremely cost efficient reusable quickly implemented and can be easily developed to a web application or software with embedded model updating mechanisms for extremely simple usage for anyone only requiring updated measurements as inputs though the results are promising and validating for nanjing navigable river further improvements and generalization can be made using convolutional neural networks cnns recurrent neural networks rnns and their mixtures due to the limitations of mlp brownlee 2018 mlp is by all means the cheap alternative or maybe a replacement for expensive traditional methodologies for navigable river wlf forecasts declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this project is sponsored by the national natural science foundation of china grant no 51879058 and qing lan project special thanks to victor palacios for editing and polishing appendix a description of abbreviations the following descriptions of abbreviations are provided in alphabetical order to clarify the meaning 2 d two dimensional 3 d three dimensional anns artificial neural networks cnns convolutional neural networks lstm long short term memories mlp multilayor perceptron relu rectified linear unit rmse root mean square error rnns recurrent neural networks testx testing set features testy testing set labels trainx training set features trainy training set labels wlf water level fluctuation appendix b notation list the following symbols are used in this paper h n is the n t h layer of a neural network n output is the number of next time steps to be predicted n input is the number of previous time steps to predict the next time steps this will affect the shape of train x and train y fig 8 it is an essential part for window method for instance n input 7 means using the previous seven days as inputs to make forecasts on the next day s n nodes is the number of nodes or neurons in the hidden layer also called the size of the hidden layer the choice of many of nodes in the hidden layer to choose is empirical empirically speaking the optimal size of the hidden layer is usually between input size and output size heaton 2008 n epochs is the number of training epochs an epoch is a process of putting the entire training set into the neural network once both forward and backward the number of epochs usually determines the fitness of the model if the number of epochs is too low it will likely underfit if the number of epochs is too high it will likely overfit so we are aiming for the middle ground for the optimum n batch is the number of training samples in each batch or batch size due to the large size of one entire training set the dataset is often divided into small batches batch size is smaller than the number of training samples n hidden is the number of hidden layers in the neural network in most cases one hidden layer will solve most of the problems but we will try adding another layer s i is the observed measurement on i th day b i is the i th bias term associated with x i e i is the i th error term which is the difference between the true output and predicted output e is the total error which is the sum of each e i w i is the i th weight term associated with x i x i is the i th input y i is the i th output after the transformation of Ï y i is the i th predicted output from the model z l is the l t h output before the transformation of Ï Î· is the learning rate in gradient descent Ï is an activation function it transforms the inputs in the neurons to outputs Ï is a value that varies with n input and n output in the window method appendix c data availability statement some or all data models or code that support the findings of this study are available from the corresponding author upon reasonable request the original dataset the pre processed dataset 
5083,the last twenty years have brought significant advances in hydrology and hydrogeology especially in the area of data availability and predictive modeling capabilities remote sensing imaging technology and in situ continuous monitoring devices have allowed the collection of large and complex datasets at the same time the computational power efficiency and parallelization capabilities of numerical models have been constantly increasing making possible simulations at larger scales and finer resolutions harnessing these new capabilities can result in better characterization of complex heterogeneous systems through inverse modeling and better accuracy in predicting the behavior of dynamic systems through data assimilation keeping up with developments in data collection and simulation capabilities significant research has been conducted on developing computationally efficient inverse modeling and data assimilation algorithms these new algorithms need to be able to handle expensive linear algebra computations excessive data storage needs and large numbers of repeated numerical simulations the algorithms that have been developed aim to achieve a reasonable trade off between computational cost and estimation accuracy two of the most common techniques used to handle this trade off are ensemble based methods and eigenspectrum based compression of covariances both of these approaches can be combined with fast linear algebra techniques further improving their computational efficiency this focused review discusses computationally efficient inverse modeling and data assimilation methods developed in the past two decades in the context of their predecessor algorithms outlining their similarities and differences and the applications they have been used for by presenting a conceptual map of approaches that have been used to reduce inverse modeling and data assimilation costs we hope to increase the visibility and understanding of these computational tools as they are becoming more available to the broader scientific community and a bigger part of data driven decision making in hydrological and hydrogeological applications 1 overview 1 1 inverse modeling in hydrology the purpose of stochastic inverse modeling and data assimilation methods is to estimate the unknown parameters of a system and to predict the behavior of that system as well as quantify the uncertainty of the estimated quantities this is achieved by representing unknowns and data as random variables with their associated probability distributions in all stochastic methods and their algorithmic variants two sources of data are combined observed data that are affected by one or more sources of noise e g analyst error instrument variability interferences with predicted data obtained using physics based numerical simulations that employ a number of simplifying assumptions e g model structure parameters boundary conditions from an uncertainty quantification point of view observed data help reduce the uncertainty of imperfect model predictions like other estimation methods stochastic methods seek a best estimate of system parameters and states this best estimate and its associated uncertainty factor in a the physical laws governing the observed processes as represented by physics based distributed models b a reasonable spatial structure of the unknown quantities represented by spatial covariances determined by data and or expert knowledge and c observed data from various sources directly or indirectly related to estimated quantities using observed data to refine our understanding of complex earth systems has expanded the ways in which we can understand their individual elements e g identification of hydrogeological features using geophysical techniques as well as their cumulative behavior e g prediction uncertainty in contaminant transport the general framework of inverse modeling applies to a wide variety of such systems as reflected in the applications published both historically and in recent years weather prediction carbon emission estimation monitoring terrestrial hydrological processes like snow cover precipitation and drought and characterization of aquifers geological formations and the ocean floor miyoshi and kunii 2012 wang et al 2009 ginn and cushman 1990 michalak et al 2004 zhang et al 2017 park and xu 2018 a classic application of inverse modeling and data assimilation can be found in the field of hydrogeology where inverse modeling techniques seek to estimate spatially variable hydraulic properties of aquifers e g carrera and neuman 1986 kitanidis 1996 lee et al 2016 in the same field data assimilation techniques seek to track spatially and temporally variable states of the system like pressure temperature or concentration examples include tracking non aqueous fluids e g li et al 2015 kang et al 2018 or solutes e g gharamti et al 2016 cui et al 2017 the two estimation problems i e estimation of static parameters and estimation of dynamic variables can also be conducted simultaneously e g franssen et al 2008 li et al 2017 or sequentially e g moradkhani et al 2005 nowak 2009 in all cases the quantities to be estimated are discretized in space and time the discretization is guided by the desired resolution in estimated quantities but also depends on the resolution of the data available finer discretization of the modeled system results in higher resolution of the estimation but also in a larger number of quantities to be estimated and therefore a more significant computational cost constrained by the computational capabilities of the time when the original algorithms were developed early applications of inverse modeling and data assimilation in hydrology were limited in size e g kitanidis and bras 1980 kitanidis and vomvoris 1983 geer and kloet 1985 yeh 1986 katul et al 1993 entekhabi et al march 1994 with domains discretized such that the number of unknowns would range from just a few lumped parameters to a few hundreds spatially discretized parameters coarse discretizations together with the lack of data significantly limited the resolution of estimated spatial fields since then developments in instrumentation have been increasing the quantity and quality of monitoring data new in situ sensors provide continuous monitoring data and modern observatories and image capture technologies allow large scale data collection remote sensing and satellite data are currently used for high resolution mapping of terrestrial hydrological and groundwater processes moradkhani et al 2005 becker 2006 flores et al 2012 meng et al 2017 bertino et al 2003 clark et al 2017 with this increase in available data the potential for accurate high resolution multi parameter multi domain characterization of hydrological systems has become attainable however inverse modeling and data assimilation algorithms in their original textbook versions kitanidis 1997 fletcher 2017 are not applicable for large scale problems because they require a number of computations that increase quadratically with the number of unknowns as an example consider the permeability matrix of a coarsely discretized three dimensional domain of size 100 100 10 resulting in 10 5 unknowns for this problem traditional inversion algorithms require computations in the order of 10 10 operations which is the size of the covariance matrix and at least 10 5 simulations of expensive forward models for sensitivity calculations such computations are prohibitive for most computers a problem that was recognized early on eigbe et al 1998 new algorithms strive to achieve linear scaling such that for the problem above operations and storage requirements is of order 10 5 and the number of simulations to be run is in the order of 10 2 tasks that are computationally tractable even by ordinary computers with parallel computing these computations are possible even for much bigger systems with millions of unknowns since multiple simulations can be run in parallel instead of sequentially the objective of this focused review is to present computationally efficient inverse modeling and data assimilation methods that are able to achieve the linear scaling described above while we focus on hydrological applications many of the computational tools we describe have applications beyond hydrology and even beyond inverse modeling e g fast linear algebra methods we classify methods based on the technique used to reduce the computational cost of state and parameter estimation and uncertainty quantification since computational cost is closely related to estimation accuracy we include it in our discussion where appropriate we do not describe all variants of inverse modeling and data assimilation methods presented in the literature for other excellent reviews approaching inverse modeling from different angles see yeh 1986 mclaughlin and townley 1996 montzka et al 2012 zhou et al 2014 scholze et al 2017 rajabi et al 2018 1 2 methods in stochastic inverse modeling in this section we discuss the family of inverse modeling methods that we focus on and explain where these methods fit in the broader inverse modeling and data assimilation field fig 1 inverse modeling algorithms are generally divided in deterministic and stochastic inversion methods deterministic inversion methods also referred to as parameter estimation or model calibration use gradient based techniques to obtain estimates that minimize the misfit between observations and model predictions in this paper we focus on stochastic or bayesian methods stochastic methods also obtain estimates that minimize the misfit between observations and model predictions but conceptualize the unknowns and data as random variables with probability distributions that represent their uncertainty probability distributions are used to describe variability in space for spatial random variables or variability due to random errors stochastic methods can be used to estimate a large number of unknowns with a comparatively small number of measurements with regularization provided by the assumed prior covariance of the unknowns while also providing uncertainty estimates in the form of posterior covariances among stochastic methods we focus on methods that apply the following assumptions a gaussian errors in measurements and unknowns and b linear or weakly nonlinear relationships between data and unknowns fig 2 these assumptions allow the analytical derivation of the first two moments of the posterior probability density function namely the posterior mean best estimate and posterior covariance uncertainty estimate the linearity assumption refers to a linear or weakly nonlinear relationship between measurements and estimated parameters for geostatistical inversion e g pressure distribution dependency on hydraulic conductivity and for data assimilation a linear or weakly nonlinear relationship between consecutive states of a dynamic system noted as f and h in fig 2 systems for which these assumptions can be made include many slow gradually evolving earth processes we do not review methods that estimate higher order moments of the unknown distributions i e particle filters because of the currently impractical computational cost associated with these methods finally methods for strongly nonlinear non gaussian systems are beyond the scope of this review readers are referred to bocquet et al 2010 and morzfeld and hodyss 2019 even though the methods covered in this review constitute only a subset of the complete inverse modeling data assimilation tree shown in fig 1 they still are the most tractable option for solving a wide range of inverse problems in earth and hydrologic sciences including inversion of large noisy datasets e g remote sensing of hydrological processes problems where high spatial resolution is needed e g subsurface characterization and bathymetry or large domains that even with a coarse resolution result in a large number of unknowns e g watershed characterization efficient and generally applicable inverse modeling methods that can solve such large problems have the following characteristics a computational scalability as the number of unknowns grows and b compatibility with any number of finely discretized multiphysics forward simulators that model the relationships between the unknowns and available data without requiring modification of the forward solvers being able to use forward solvers as black boxes allows the combination of varied datasets without intrusive code changes or additional storage requirements lee and kitanidis 2014 this latter requirement precludes from our review inverse modeling approaches that rely on adjoint state methods even though such methods can drastically reduce computational costs when they are applicable e g carrera and neuman 1986 inverse modeling methods that satisfy both the scalability and the black box forward solver requirement can be used for a wide range of estimation problems at large scales and can jointly invert diverse datasets and processes modeled with existing efficient stable and highly optimized forward solvers we approach both single step also termed batch geostatistical inversion and data assimilation using kalman filtering also known as recursive estimation under the lense of their computational costs at a fundamental level both methods are based on the same problem formulation using a statistical representation of spatiotemporal systems though covariance matrices in addition both methods involve two steps prediction by a forward solver and a bayesian update as shown in fig 2 for data assimilation this sequence is repeated recursively to estimate unknown states at multiple times or steps k of the system s evolution theoretical similarities between geostatistical inversion and data assimilation are discussed in detail in oliver et al 2008 from a practical point of view the similarities between geostatistical inversion and data assimilation mean that the computational bottlenecks are the same for both problems first the large dimension of the covariance matrix translates to high storage costs and expensive matrix matrix operations in the bayesian update step and second the calculation of the jacobian matrix or an approximation of it translates to a large number of forward model runs these computational challenges can be addressed by the same approaches whether within an inverse modeling algorithm that estimates a system s parameters or a data assimilation approach that estimates states and or parameters of a dynamic system there are three main categories of methods that can be employed to reduce the computational cost associated with the large storage and matrix operations related to the covariance matrices bottom level of fig 1 in the first two of these methods the reduction in computational cost is achieved by the compression of the large dense error covariance matrix either by representing it with a number of random realizations generated from an appropriate distribution ensemble based methods or with projection of the covariance matrix to a lower dimensional subspace obtained by eigenspectrum decomposition eigenspectrum based methods in both approaches the compression effectively reduces both sources of computational costs mentioned above a third method to reduce computational costs in both eigenspectrum and ensemble based compression methods is to employ fast linear algebra methods to accelerate individual components of the inversion workflow without changing the inversion method itself examples of fast linear algebra methods include methods for the generation of realizations matrix vector multiplications or direct inverse matrix preconditioner construction combinations of eigenspectrum based compression and fast linear algebra methods have been most common for single step geostatistical inverse modeling whereas both eigenspectrum and ensemble based compression methods have been combined with fast linear algebra in data assimilation applications the following sections will review these methods for reducing the overall inversion computational cost first for geostatistical inversion section 2 and then for kalman filtering section 3 2 geostatistical inverse modeling 2 1 the original algorithm stochastic batch optimization based inversion also known as variational inversion is a long standing area of research in hydrology and hydrogeology yeh 1986 mclaughlin and townley 1996 snodgrass and kitanidis 1997 ines and droogers 2002 carrera et al 2005 oliver et al 2008 linde et al 2017 park and xu 2018 in these methods referred to here as geostatistical inverse modeling indirect noisy measurements such as pressure heads and contaminant concentrations are used to estimate unknown hydraulic parameters that are expensive to measure directly over large scales such as hydraulic conductivity most engineering applications such as contaminant identification and remediation lee and kitanidis 1991 yeh and zhu 2007 real time monitoring of co2 sequestration ghorbanidehno et al 2015 li et al 2015 and river flooding management wilson and ozkan haller 2012 require accurate prediction of unknown hydraulic parameters at a high resolution requiring a fine discretization of the domain this leads to inverse problems with a large number of unknowns that are estimated with a smaller number of measurements finer domain discretization amplifies the non uniqueness of the estimation the generalized covariance serves the need for regularization and provides the means for quantifying the uncertainty associated with the non unique best estimate the bayesian geostatistical approach ga kitanidis and vomvoris 1983 kitanidis 1996 is such a method that has been widely used for parameter estimation in hydrogeology the ga characterizes the structure of the unknown parameters by an a priori probability density function which is parameterized through a generalized covariance function then the method combines noisy measurements with this statistical model and provides the best estimate that minimizes the objective function quantifying the discrepancy between measured and observed data several iterations are usually required until convergence is reached the major computational bottleneck of ga similar to other estimation methods is that it becomes computationally expensive as the number of unknowns n and the number of observations m grows the bottleneck arises due to the fact that 1 storage and matrix operations involving large dense covariance matrices scale quadratically with the number of unknowns and 2 for nonlinear problems the method requires the computation of the jacobian matrix for each parameter estimated and its product with the covariance matrix at each iteration these computations require o min n m calls to the forward model at each iteration using the finite difference o n or the adjoint state method o m while in hydrogeology adjoint methods can be used for several applications e g carrera and neuman 1986 adjoint state equations may not exist for other estimation problems to avoid the need for a large number of expensive simulations especially associated with the number of observations m one may use a nonlinear least squares method combined with a newton conjugate gradient type method haber and ascher 2001 that avoids full hessian products by forming hessian vector products in the inner conjugate gradient iterations followed by outer gauss newton iterations still this method requires additional intrusive adjoint state code development and the entire inversion may require a large number of sequential inner and outer iterations to converge unless a good preconditioner is constructed 2 2 scalable geostatistical approach several fast linear algebra approaches have been used to reduce computational costs associated with matrix operations in geostatistical inversion for example liu et al 2007 fritz et al 2009 and nowak et al 2003 utilize the fast fourier transform fft to accelerate matrix vector multiplications in inverse problems on a regular grid if the covariance matrix is separable meaning that the covariance function can be written as products of independent functions for each dimension kronecker product methods can accelerate the matrix vector computation combined with fft e g yadav and michalak 2013 nowak et al may 2013 because the extension of fft based methods to unstructured grids is nontrivial several other methods have been proposed to deal with fast matrix vector multiplication with a minimum storage requirement li and cirpka 2006 propose an algorithm that parameterizes the spatial random field by the karhunen loÃ¨ve kl expansion liu and kitanidis 2011 utilize a sparse formulation for the generalized inverse of the covariance matrix i e the precision matrix to avoid using the large dense covariance matrix ambikasaran et al 2013 and saibaba and kitanidis 2012 exploit the hierarchical structure of the covariance matrices and use h 2 matrices and fast multiple methods fmm beatson and greengard 1997 darve 2000 cheng et al 1999 to reduce the matrix vector multiplication and storage costs these approaches are exceptionally beneficial in the context of inverse modeling because they can be applied to general covariance matrices constructed on unstructured grids achieve linear scalability fig 3 and can be implemented within the inversion algorithms as black boxes with minimal code modifications alternatively ensemble based approaches e g wilson and ozkan haller 2012 have been applied to accelerate the computation associated with covariance matrix products although such methods are more commonly used in sequential data assimilation applications described later in section 3 2 for nonlinear problems another computational bottleneck is the need to compute jacobian matrices at each iteration which is computationally expensive for large problems with the number of forward model runs and storage costs of o min m n and o mn respectively to overcome this computational challenge liu et al 2013 propose the geostatistical reduced order approach where the large unknown parameter state is represented in a small dimensional space in another method kitanidis and lee 2014 and lee and kitanidis 2014 present the principal component geostatistical approach pcga which utilizes a matrix free approach for jacobian calculation and a low rank representation of the covariance matrix based on its principal components or eigenvectors this eigenspectrum approach to matrix compression reduces the number of forward model calls and avoids the direct computation of jacobian matrices at each iteration with a controlled reduction in accuracy based on the number of principal components considered the computational benefit is significant since the number of principal components n is significantly smaller than the number of unknowns n lee et al 2016 extend pcga to handle data intensive problems through generalized eigen decomposition of the posterior data update space and applies the proposed method to a three dimensional laboratory scale sand box characterization using around seven million tracer data points from mri with modflow mt3dms for groundwater flow and transport simulation lin et al 2017 extend pcga with a randomized approach to reduce the dimension of data and run a 10 million data point synthetic problem in lee et al 2018 a detailed comparison is made between eigenspectrum based and ensemble based approaches showing superior performance of pcga in batch data inversion applications 3 kalman filtering techniques 3 1 the original kalman filter algorithm the kalman filter kf kalman et al 1960 harvey 1990 is the most widely used data assimilation method for sequential state and parameter estimation this method was originally developed for least squares or gaussian distribution state updating for linear systems sorenson 1985 simon 2006 but has been extended to systems where these requirements are only approximately met the algorithm works in a two step process as shown in fig 2 first in the prediction step the forward model is used to produce estimates of the current state variables second the bayesian update step is executed every time a set of measurements is collected during which the kalman filter produces an estimate of the state of the system as a weighted average of the system s predicted state and of the new measurements with weights representing the relative uncertainty of model predictions and assimilated data as represented by the associated covariance matrices the result of the weighted average lies between the predicted and measured state and has lower uncertainty than either alone the algorithm is recursive meaning that the same procedure is performed at every time new observations are assimilated it can run in real time using only the present input measurements and the previously calculated state and its uncertainty i e the posterior covariance matrix no additional past information is required this is in contrast to history matching techniques that use the entire past observed data at each estimation step oliver and chen 2011 tahmasebi et al 2018 for nonlinear dynamic models the extended kalman filter ekf the nonlinear kf variant provides reasonably accurate solutions using a linearization scheme the ekf has found many applications in hydrology katul et al 1993 eigbe et al 1998 de rosnay et al 2013 the ekf algorithm utilizes taylor series expansion to linearize the model around the estimate of the current mean values one of the major limitations of both kf and ekf for hydrology problems is the inherent high dimensionality that arises when dynamical systems for large scale domains are discretized for modeling for such systems the original implementation of kf and ekf is extremely expensive because it requires to update and store a large covariance matrix of size n 2 every time new data are assimilated this computation is normally performed at a computational cost of o mn 2 and storage cost of o n 2 also for nonlinear problems it requires computing the jacobian matrices which are expensive to compute and store this problem has given rise to techniques such as ensemble based kalman filters and low rank kalman filters 3 2 ensemble based kalman filters ensemble kalman filter enkf is a computationally efficient kalman filter method that avoids explicit calculation of full n n covariance matrices and jacobian matrices enkf uses an ensemble of realizations to create a low rank approximation of the state covariance matrix evensen 2009 this approximation makes the number of forward model calls scale linearly with the ensemble size n with ensemble sizes usually in the order of 100 and generally orders of magnitude smaller than the number of unknowns n thus reducing the storage cost of enkf and achieving overall linear scaling of the method with the number of unknowns enkf s ensemble based formulation allows the algorithm to use forward solvers as black boxes and the code to be highly parallelizable these attributes have led to the wide adoption of enkf for data assimilation in a range of disciplines for both linear and nonlinear problems evensen 2003 pathiraja et al 2016 wang et al 2009 in hydrology enkf has been widely used to estimate the state and parameters of hydrologic models moradkhani et al 2005 vrugt et al 2005 clark et al 2008 chen and zhang 2006 pathiraja et al 2016 rafieeinasab et al 2014 weerts and el serafy 2006 use enkf in flood forecasting to reduce the uncertainty in the rainfall runoff update and model state estimation pathiraja et al 2016 investigate the potential for enkf to estimate hyper parameters of the temporal structure from streamflow observations gu et al 2005 apply enkf for automatic history matching for a reservoir problem and conclude that enkf provides accurate history matching results while requiring less computation work than traditional history matching methods the extensive use of enkf in different fields has resulted in several improvements of the basic algorithm these improvements are often viewed as tuning of the basic enkf algorithm and while they do not change its overall computational cost they are necessary to improve its accuracy and to provide a fair basis for comparison with other approaches in the basic enkf implementation observation perturbation is necessary to prevent excessive reduction of the prediction error estimation also known as filter inbreeding houtekamer and mitchell 1998 lorenc 2003 or ensemble collapse bengtsson et al 2008 however this may introduce sampling errors which could in turn result in the sample covariance matrix being suboptimal lee et al 2018 and losing its positive definiteness furrer and bengtsson 2007 aanonsen et al 2009 one way in which this is manifested is the deterioration of the forecast covariance which results in spurious correlations ghorbanidehno et al 2015 li et al 2015 this is especially a problem when the rank of the state covariance matrix is much larger than the ensemble size these problems can be addressed using covariance inflation whitaker 2002 which does not have an impact on computational cost but improves stability of the filter and ultimately its accuracy the sampling error issue can also be resolved by using a larger number of ensemble members albeit at a higher computational cost an efficient alternative is to use square root filters whitaker 2002 tippett et al 2003 which by construction avoid the loss of positive definiteness of error covariance matrices examples of square root filters include the ensemble square root kalman filter ensrf chen et al 2013 tong and xue 2008 the ensemble transform kalman filter etkf bishop et al 2001 wei et al 2006 and the local ensemble transform kalman filter letkf hunt et al 2007 which combines ensrf with etkf these methods consider model error in the updates without perturbing the observations and thereby avoid sampling errors the differences between ensrf etkf and letkf are in the computational cost of matrix operations during the update step of the filter tippett et al 2003 however in cases where the assumptions of the kalman filter are not strictly satisfied as for example in cases with significant nonlinearities systematic errors and non gaussian error statistics enkf and ensrf methods may lead to unstable results and ultimately to filter divergence resulting in estimated values with large estimation errors in such cases the update step of data assimilation may compute model parameters or state variables that are not physically realistic to avoid filter divergence ott et al 2004 and szunyogh et al 2005 propose to apply localization on enkf a method that employs an effective cut off radius observations beyond this radius are not considered for updating state variables for each region however the discontinuity added in the measurement space results in noise in the update step in order to overcome this problem houtekamer and mitchell 2001 and ott et al 2004 utilize a schur product which applies a smooth function to the covariance matrices to reduce the effect of observation points at larger distances implications of nonlinearities are even more pronounced if the a priori information on model parameters and state variables structure is poor and the initial guess is far from the true values to improve enkf s performance for strongly nonlinear problems with poor initial guesses iterative enkf ienkf schemes allow improving the initial ensemble and hence the resulting estimated model parameters and state variables for each data assimilation step ienkf methods employ iterative optimization for maximizing the posterior probability of the estimations conditional to its forecast value and the measurements adding to the computational cost of the method the ensemble randomized maximum likelihood enrml is an example of ienkfs that iterates on the parameters using quasi newton optimization techniques gu et al 2007 li et al 2007 krymskaya et al 2009 for a review of several types of ienkf methods readers are referred to reynolds et al 2006 and aanonsen et al 2009 ultimately all enkf variants improve upon the basic enkf implementation by increasing its accuracy for a given computational cost however the convergence of the filter i e how many ensemble members are needed to achieve a low and stable estimation error may still be slow especially for high dimensional hydrological problems determining the appropriate number of ensemble realizations for accurate state and uncertainty estimation is a key question for ensemble based methods it is well understood that convergence strongly depends on initial ensemble design and specifically on how well the initial ensemble captures the characteristics of the true field especially in situations where the assumptions of gaussianity are not met jafarpour and mclaughlin 2009 to improve convergence and thereby estimation accuracy for a given computational cost methods that improve the initial ensemble or sampling include applying an orthogonal decomposition to the ensemble in order to determine the dominant directions in the state space and use those rather than a random sample to represent the error covariance matrix li et al 2015 3 3 projection based low rank methods orthogonal decomposition can be applied directly on the prior covariance matrix to reduce the dimensionality of the data assimilation problem this approach has given rise to a different class of efficient methods in data assimilation termed here projection based low rank methods similarly to projection based approaches in geostatistical inversion section 2 2 matrix factorization is used to compute dominant directions of the prior error covariance and thus more effectively parameterize the error covariance at the initial step of data assimilation by projecting the initial covariance matrix into the smaller subspace all subsequent kalman filter equations are solved in that subspace significantly reducing the computational cost of matrix operations practically this can be achieved by performing eigen decomposition of the prior covariance matrix and selecting the n eigenvectors that correspond to the n largest eigenvalues these eigenvectors represent dominant and independent features of the prior covariance the selection of n depends on the desired resolution if only large scale features are of interest 10 50 eigenvectors may suffice to delineate the underlying structure smaller scale features can be resolved by increasing the number of eigenvectors used at an increased computational cost flath et al 2011 lee et al 2016 this selection process can be used to optimize the computational cost for the desired accuracy but also improves the filter stability by avoiding making corrections in directions for which the error is the most attenuated by the system pham et al 1998 propose such a low rank method called singular evolutive extended kalman filter seek for data assimilation in oceanography the approach uses eigendecomposition of the covariance matrix that retains a few important and dominant modes the initial eigenvectors are then propagated through the state transition equations and the decomposition is renewed to maintain orthogonality in follow up work pham 1996 present the singular evolutive interpolated kalman seik filter which is similar to seek but uses linear interpolation instead of linearization and provides better performance for nonlinear systems seek and seik filters have found applications in oceanography with accurate estimation results pham 1996 pham et al 1998 carmillet et al 2001 brasseur et al 1999 and approaches have been developed to further reduce their computational cost hoteit et al 2002 kitanidis 2015 introduces the compressed state kalman filter cskf that uses an eigendecomposition basis selected based on the characteristics of the problem such as the transition model and the system noise covariance matrix unlike seek the basis is pre selected and fixed reducing the computational cost associated with evaluating it at every step and improving overall performance li et al 2015 show that cskf provides more accurate results than enkf for a nonlinear reservoir monitoring problem in follow up work li et al 2017 introduce the smoothing based compressed state kalman filter scskf that combines cskf with a one step ahead smoothing scheme to tackle problems with stronger nonlinearities in the unknowns such as sharp interfaces observed in multiphase flow systems in another variant of cskf ghorbanidehno et al 2019 improve cskf to be applicable for problems with both a large number of unknowns and a large number of measurements a comparison between the workflow of enkf cskf and seek type methods is shown in fig 4 similar to ensemble based methods projection based methods are approximate methods and strive to achieve a balance between estimation accuracy and computational cost the optimal trade off depends on the characteristics of the estimation problem the desired resolution for the unknown field the information content of the data and the computational resources available for projection based methods a convergence analysis similar to ensemble based methods can be performed to identify the optimal number of components needed however the choice of the number of components is guided by the structure of the covariance and the required resolution with larger eigenvalues of the covariance corresponding to estimation of larger scale features and such that the more eigenvalues are considered the larger the n the more finely resolved the estimate is in contrast in ensemble based methods the efficiency of the compression depends on the sampling method used to generate the ensembles and the ensemble size asymptotically i e for large ensemble sizes ensemble based compression and projection based compression can provide the same accuracy 3 4 fast linear algebra and special cases finally there are special cases where the characteristics of the data assimilation problem allow for simplifications in the kf algorithm significantly improving its computational efficiency at little additional cost to the estimation accuracy for example li et al 2014 develop hikf for applications where the data is acquired at a much faster rate than the rate of the evolution of the system i e quasi continuous data assimilation such that the forward model operator can be assumed to be equal to the identify matrix by simplifying the kalman filter recursion and using the bbfmm method ambikasaran et al 2013 for matrix vector multiplications hikf achieves higher accuracy than enkf for the same computational cost savings compared to kf hikf can be also viewed as a dynamic spatiotemporal modeling method with markov assumption along the same lines ghorbanidehno et al 2015 propose the spectral kalman filter speckf that extends hikf for general problems by using a forward model approximation combined with a low rank approximation for the prior covariance the computational benefits of speckf are significant given that the forward model computation is avoided this concept was further extended by ghorbanidehno et al 2017 who combine speckf with linear gaussian control for optimization of groundwater pumping 4 summary and conclusions in this focused review we approached stochastic inverse modeling and data assimilation from the common perspective of computational efficiency in the context of large scale estimation problems in hydrology and hydrogeology and more generally earth sciences the size of these estimation problems is a result of the physical size of the systems modeled as well as the complex physical processes and heterogeneities of such systems many of which we need to characterize at a fine scale large scale estimation problems result in expensive matrix operations storage requirements and indirectly in a large number of forward model runs for sensitivity evaluations these costs are summarized in table 1 categorized by type of method and main source of computational cost a more detailed breakdown of computational costs can be found in the original papers e g ambikasaran et al 2013 li et al 2014 li et al 2015 to reduce all these computational costs one can approximate the large n n prior covariance matrix with a compressed n n covariance matrix where n is the number of the unknowns to be estimated and n is a number significantly smaller than n usually in the hundreds the compressed covariance matrix can be obtained a statistically by propagating an ensemble of n realizations or b analytically by performing eigenspectrum decomposition of the prior covariance and neglecting the smallest n n eigenvalues in both of these approaches the resulting compressed rank n covariance is an approximation of the full covariance the closer the n is to n the lower the estimation error and the higher the computational cost this reduction in dimensionality of the covariance matrix by both ensemble and eigenspectrum based methods not only reduces the cost of matrix storage and operations but also reduces the number of forward model runs required to obtain the jacobian matrix that gives the sensitivities of the unknowns to the measurements table 1 unavoidably compression introduces estimation errors compared to methods that utilize the entire covariance matrix the trade offs between the desired resolution estimation accuracy and computational cost are at the center of choosing between inversion methods and are strongly dependent on the characteristics of each application this is especially so as inverse modeling and data assimilation methods have been pushed more and more outside the boundaries of their original implementations and theoretical assumptions of gaussianity and linearity morzfeld and hodyss 2019 while the methods described in this review have advantages and disadvantages from either a computational cost or an accuracy point of view they all apply the general principles of compression of information through a low rank representation of the covariance matrix and they all benefit from fast linear algebra techniques ensemble based methods have been used extensively and have many advantages they are easy to implement in their basic form they do not involve matrix matrix multiplications or jacobian calculations and there are proven techniques available to tackle common problems like ensemble collapse and filter divergence on the other hand eigenspectrum based compression has also been used extensively in inverse modeling while these methods involve more complex matrix algebra they allow customizable compression based on characteristics of the problem and the resolution desired e g scale of plume features or geologic structures of interest and there are proven techniques available to reduce the cost of matrix matrix multiplications and matrix free jacobian estimation for both ensemble based and eigenspectrum based compression the reduction in computational cost is significant compared to traditional methods and the scaling in both cases is comparable table 1 when it comes to specific applications for the same computational cost neither approach guarantees higher accuracy differences in the estimation may also vary depending on the metric used to evaluate accuracy e g rmse based metrics versus low level noise in estimated field non physical hot spots etc it should be noted that the computational cost of inversion is always dependent on the cost of each individual forward run even with a reduced number of forward runs the computational cost will be significant for inversions where individual runs are expensive e g large domains multiphase forward simulators parallelizable inverse modeling methods like for example pcga and enkf that allow individual runs to run in parallel can significantly reduce the overall inversion cost allowing higher accuracy for high dimensional systems when combined with parallelizable forward solvers further cost reductions are possible kurtz et al 2016 reducing the cost of individual forward model runs is also possible through the use of surrogate or reduced order models e g mo et al 2019 while such methods appear promising they are strongly case dependent and require code development and training data processing in a way that limits their general utility more research is needed in this field as continued advancements in efficiency of individual forward solvers will allow the speedup of methods presented in this review as well as of higher order estimation methods like particle filters and mcmc approaches the plethora of inverse modeling and data assimilation acronyms and the continuous evolution and combination of approaches is an indication of the expansion of the field to more diverse applications within and beyond hydrology with newer and more complex datasets and a strong focus on reliable uncertainty quantification as new methods are developed and existing methods are improved effective sharing of these algorithms in the public domain using a common framework will facilitate not only reproducible and reliable research but also better benchmarking and more widespread use in real world applications integrated and modularized platforms that allow the use and comparison of various inversion approaches like the terrestrial data assimilation framework terrsysmp pdaf kurtz et al 2016 will be instrumental in making progress in the inversion field at the same time while algorithm development is crucial equally important is progress in the area of data collection and sharing increasing the resolution and sensitivity of instruments as well as developing automatic sensors that can collect the most information dense measurements is another frontier last but not least public domain open source databases for data dissemination can help in the validation and comparison of new algorithms in the coming years the need for fast algorithms that can process big data from multiple sources and that can run large physics based simulations will only continue to increase in all scientific fields these developments will be especially consequential for the field of hydrology in which physical processes occur at large interconnected scales but resource management is urgently needed at scales ranging from the local continuum scale to the watershed scale and ultimately up to the global scale declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the three anonymous reviewers for their valuable feedback on this focused review this work is supported by an appointment to the faculty and postdoctoral fellow research participation program at the u s engineer research and development center coastal and hydraulics laboratory administered by the oak ridge institute for science and education through an interagency agreement between the u s department of energy and erdc jonghyun lee was supported by hawaii experimental program to stimulate competitive research epscor provided by the national science foundation research infrastructure improvement rii track 1 ike wai securing hawaii s water future award oia 1557349 
5083,the last twenty years have brought significant advances in hydrology and hydrogeology especially in the area of data availability and predictive modeling capabilities remote sensing imaging technology and in situ continuous monitoring devices have allowed the collection of large and complex datasets at the same time the computational power efficiency and parallelization capabilities of numerical models have been constantly increasing making possible simulations at larger scales and finer resolutions harnessing these new capabilities can result in better characterization of complex heterogeneous systems through inverse modeling and better accuracy in predicting the behavior of dynamic systems through data assimilation keeping up with developments in data collection and simulation capabilities significant research has been conducted on developing computationally efficient inverse modeling and data assimilation algorithms these new algorithms need to be able to handle expensive linear algebra computations excessive data storage needs and large numbers of repeated numerical simulations the algorithms that have been developed aim to achieve a reasonable trade off between computational cost and estimation accuracy two of the most common techniques used to handle this trade off are ensemble based methods and eigenspectrum based compression of covariances both of these approaches can be combined with fast linear algebra techniques further improving their computational efficiency this focused review discusses computationally efficient inverse modeling and data assimilation methods developed in the past two decades in the context of their predecessor algorithms outlining their similarities and differences and the applications they have been used for by presenting a conceptual map of approaches that have been used to reduce inverse modeling and data assimilation costs we hope to increase the visibility and understanding of these computational tools as they are becoming more available to the broader scientific community and a bigger part of data driven decision making in hydrological and hydrogeological applications 1 overview 1 1 inverse modeling in hydrology the purpose of stochastic inverse modeling and data assimilation methods is to estimate the unknown parameters of a system and to predict the behavior of that system as well as quantify the uncertainty of the estimated quantities this is achieved by representing unknowns and data as random variables with their associated probability distributions in all stochastic methods and their algorithmic variants two sources of data are combined observed data that are affected by one or more sources of noise e g analyst error instrument variability interferences with predicted data obtained using physics based numerical simulations that employ a number of simplifying assumptions e g model structure parameters boundary conditions from an uncertainty quantification point of view observed data help reduce the uncertainty of imperfect model predictions like other estimation methods stochastic methods seek a best estimate of system parameters and states this best estimate and its associated uncertainty factor in a the physical laws governing the observed processes as represented by physics based distributed models b a reasonable spatial structure of the unknown quantities represented by spatial covariances determined by data and or expert knowledge and c observed data from various sources directly or indirectly related to estimated quantities using observed data to refine our understanding of complex earth systems has expanded the ways in which we can understand their individual elements e g identification of hydrogeological features using geophysical techniques as well as their cumulative behavior e g prediction uncertainty in contaminant transport the general framework of inverse modeling applies to a wide variety of such systems as reflected in the applications published both historically and in recent years weather prediction carbon emission estimation monitoring terrestrial hydrological processes like snow cover precipitation and drought and characterization of aquifers geological formations and the ocean floor miyoshi and kunii 2012 wang et al 2009 ginn and cushman 1990 michalak et al 2004 zhang et al 2017 park and xu 2018 a classic application of inverse modeling and data assimilation can be found in the field of hydrogeology where inverse modeling techniques seek to estimate spatially variable hydraulic properties of aquifers e g carrera and neuman 1986 kitanidis 1996 lee et al 2016 in the same field data assimilation techniques seek to track spatially and temporally variable states of the system like pressure temperature or concentration examples include tracking non aqueous fluids e g li et al 2015 kang et al 2018 or solutes e g gharamti et al 2016 cui et al 2017 the two estimation problems i e estimation of static parameters and estimation of dynamic variables can also be conducted simultaneously e g franssen et al 2008 li et al 2017 or sequentially e g moradkhani et al 2005 nowak 2009 in all cases the quantities to be estimated are discretized in space and time the discretization is guided by the desired resolution in estimated quantities but also depends on the resolution of the data available finer discretization of the modeled system results in higher resolution of the estimation but also in a larger number of quantities to be estimated and therefore a more significant computational cost constrained by the computational capabilities of the time when the original algorithms were developed early applications of inverse modeling and data assimilation in hydrology were limited in size e g kitanidis and bras 1980 kitanidis and vomvoris 1983 geer and kloet 1985 yeh 1986 katul et al 1993 entekhabi et al march 1994 with domains discretized such that the number of unknowns would range from just a few lumped parameters to a few hundreds spatially discretized parameters coarse discretizations together with the lack of data significantly limited the resolution of estimated spatial fields since then developments in instrumentation have been increasing the quantity and quality of monitoring data new in situ sensors provide continuous monitoring data and modern observatories and image capture technologies allow large scale data collection remote sensing and satellite data are currently used for high resolution mapping of terrestrial hydrological and groundwater processes moradkhani et al 2005 becker 2006 flores et al 2012 meng et al 2017 bertino et al 2003 clark et al 2017 with this increase in available data the potential for accurate high resolution multi parameter multi domain characterization of hydrological systems has become attainable however inverse modeling and data assimilation algorithms in their original textbook versions kitanidis 1997 fletcher 2017 are not applicable for large scale problems because they require a number of computations that increase quadratically with the number of unknowns as an example consider the permeability matrix of a coarsely discretized three dimensional domain of size 100 100 10 resulting in 10 5 unknowns for this problem traditional inversion algorithms require computations in the order of 10 10 operations which is the size of the covariance matrix and at least 10 5 simulations of expensive forward models for sensitivity calculations such computations are prohibitive for most computers a problem that was recognized early on eigbe et al 1998 new algorithms strive to achieve linear scaling such that for the problem above operations and storage requirements is of order 10 5 and the number of simulations to be run is in the order of 10 2 tasks that are computationally tractable even by ordinary computers with parallel computing these computations are possible even for much bigger systems with millions of unknowns since multiple simulations can be run in parallel instead of sequentially the objective of this focused review is to present computationally efficient inverse modeling and data assimilation methods that are able to achieve the linear scaling described above while we focus on hydrological applications many of the computational tools we describe have applications beyond hydrology and even beyond inverse modeling e g fast linear algebra methods we classify methods based on the technique used to reduce the computational cost of state and parameter estimation and uncertainty quantification since computational cost is closely related to estimation accuracy we include it in our discussion where appropriate we do not describe all variants of inverse modeling and data assimilation methods presented in the literature for other excellent reviews approaching inverse modeling from different angles see yeh 1986 mclaughlin and townley 1996 montzka et al 2012 zhou et al 2014 scholze et al 2017 rajabi et al 2018 1 2 methods in stochastic inverse modeling in this section we discuss the family of inverse modeling methods that we focus on and explain where these methods fit in the broader inverse modeling and data assimilation field fig 1 inverse modeling algorithms are generally divided in deterministic and stochastic inversion methods deterministic inversion methods also referred to as parameter estimation or model calibration use gradient based techniques to obtain estimates that minimize the misfit between observations and model predictions in this paper we focus on stochastic or bayesian methods stochastic methods also obtain estimates that minimize the misfit between observations and model predictions but conceptualize the unknowns and data as random variables with probability distributions that represent their uncertainty probability distributions are used to describe variability in space for spatial random variables or variability due to random errors stochastic methods can be used to estimate a large number of unknowns with a comparatively small number of measurements with regularization provided by the assumed prior covariance of the unknowns while also providing uncertainty estimates in the form of posterior covariances among stochastic methods we focus on methods that apply the following assumptions a gaussian errors in measurements and unknowns and b linear or weakly nonlinear relationships between data and unknowns fig 2 these assumptions allow the analytical derivation of the first two moments of the posterior probability density function namely the posterior mean best estimate and posterior covariance uncertainty estimate the linearity assumption refers to a linear or weakly nonlinear relationship between measurements and estimated parameters for geostatistical inversion e g pressure distribution dependency on hydraulic conductivity and for data assimilation a linear or weakly nonlinear relationship between consecutive states of a dynamic system noted as f and h in fig 2 systems for which these assumptions can be made include many slow gradually evolving earth processes we do not review methods that estimate higher order moments of the unknown distributions i e particle filters because of the currently impractical computational cost associated with these methods finally methods for strongly nonlinear non gaussian systems are beyond the scope of this review readers are referred to bocquet et al 2010 and morzfeld and hodyss 2019 even though the methods covered in this review constitute only a subset of the complete inverse modeling data assimilation tree shown in fig 1 they still are the most tractable option for solving a wide range of inverse problems in earth and hydrologic sciences including inversion of large noisy datasets e g remote sensing of hydrological processes problems where high spatial resolution is needed e g subsurface characterization and bathymetry or large domains that even with a coarse resolution result in a large number of unknowns e g watershed characterization efficient and generally applicable inverse modeling methods that can solve such large problems have the following characteristics a computational scalability as the number of unknowns grows and b compatibility with any number of finely discretized multiphysics forward simulators that model the relationships between the unknowns and available data without requiring modification of the forward solvers being able to use forward solvers as black boxes allows the combination of varied datasets without intrusive code changes or additional storage requirements lee and kitanidis 2014 this latter requirement precludes from our review inverse modeling approaches that rely on adjoint state methods even though such methods can drastically reduce computational costs when they are applicable e g carrera and neuman 1986 inverse modeling methods that satisfy both the scalability and the black box forward solver requirement can be used for a wide range of estimation problems at large scales and can jointly invert diverse datasets and processes modeled with existing efficient stable and highly optimized forward solvers we approach both single step also termed batch geostatistical inversion and data assimilation using kalman filtering also known as recursive estimation under the lense of their computational costs at a fundamental level both methods are based on the same problem formulation using a statistical representation of spatiotemporal systems though covariance matrices in addition both methods involve two steps prediction by a forward solver and a bayesian update as shown in fig 2 for data assimilation this sequence is repeated recursively to estimate unknown states at multiple times or steps k of the system s evolution theoretical similarities between geostatistical inversion and data assimilation are discussed in detail in oliver et al 2008 from a practical point of view the similarities between geostatistical inversion and data assimilation mean that the computational bottlenecks are the same for both problems first the large dimension of the covariance matrix translates to high storage costs and expensive matrix matrix operations in the bayesian update step and second the calculation of the jacobian matrix or an approximation of it translates to a large number of forward model runs these computational challenges can be addressed by the same approaches whether within an inverse modeling algorithm that estimates a system s parameters or a data assimilation approach that estimates states and or parameters of a dynamic system there are three main categories of methods that can be employed to reduce the computational cost associated with the large storage and matrix operations related to the covariance matrices bottom level of fig 1 in the first two of these methods the reduction in computational cost is achieved by the compression of the large dense error covariance matrix either by representing it with a number of random realizations generated from an appropriate distribution ensemble based methods or with projection of the covariance matrix to a lower dimensional subspace obtained by eigenspectrum decomposition eigenspectrum based methods in both approaches the compression effectively reduces both sources of computational costs mentioned above a third method to reduce computational costs in both eigenspectrum and ensemble based compression methods is to employ fast linear algebra methods to accelerate individual components of the inversion workflow without changing the inversion method itself examples of fast linear algebra methods include methods for the generation of realizations matrix vector multiplications or direct inverse matrix preconditioner construction combinations of eigenspectrum based compression and fast linear algebra methods have been most common for single step geostatistical inverse modeling whereas both eigenspectrum and ensemble based compression methods have been combined with fast linear algebra in data assimilation applications the following sections will review these methods for reducing the overall inversion computational cost first for geostatistical inversion section 2 and then for kalman filtering section 3 2 geostatistical inverse modeling 2 1 the original algorithm stochastic batch optimization based inversion also known as variational inversion is a long standing area of research in hydrology and hydrogeology yeh 1986 mclaughlin and townley 1996 snodgrass and kitanidis 1997 ines and droogers 2002 carrera et al 2005 oliver et al 2008 linde et al 2017 park and xu 2018 in these methods referred to here as geostatistical inverse modeling indirect noisy measurements such as pressure heads and contaminant concentrations are used to estimate unknown hydraulic parameters that are expensive to measure directly over large scales such as hydraulic conductivity most engineering applications such as contaminant identification and remediation lee and kitanidis 1991 yeh and zhu 2007 real time monitoring of co2 sequestration ghorbanidehno et al 2015 li et al 2015 and river flooding management wilson and ozkan haller 2012 require accurate prediction of unknown hydraulic parameters at a high resolution requiring a fine discretization of the domain this leads to inverse problems with a large number of unknowns that are estimated with a smaller number of measurements finer domain discretization amplifies the non uniqueness of the estimation the generalized covariance serves the need for regularization and provides the means for quantifying the uncertainty associated with the non unique best estimate the bayesian geostatistical approach ga kitanidis and vomvoris 1983 kitanidis 1996 is such a method that has been widely used for parameter estimation in hydrogeology the ga characterizes the structure of the unknown parameters by an a priori probability density function which is parameterized through a generalized covariance function then the method combines noisy measurements with this statistical model and provides the best estimate that minimizes the objective function quantifying the discrepancy between measured and observed data several iterations are usually required until convergence is reached the major computational bottleneck of ga similar to other estimation methods is that it becomes computationally expensive as the number of unknowns n and the number of observations m grows the bottleneck arises due to the fact that 1 storage and matrix operations involving large dense covariance matrices scale quadratically with the number of unknowns and 2 for nonlinear problems the method requires the computation of the jacobian matrix for each parameter estimated and its product with the covariance matrix at each iteration these computations require o min n m calls to the forward model at each iteration using the finite difference o n or the adjoint state method o m while in hydrogeology adjoint methods can be used for several applications e g carrera and neuman 1986 adjoint state equations may not exist for other estimation problems to avoid the need for a large number of expensive simulations especially associated with the number of observations m one may use a nonlinear least squares method combined with a newton conjugate gradient type method haber and ascher 2001 that avoids full hessian products by forming hessian vector products in the inner conjugate gradient iterations followed by outer gauss newton iterations still this method requires additional intrusive adjoint state code development and the entire inversion may require a large number of sequential inner and outer iterations to converge unless a good preconditioner is constructed 2 2 scalable geostatistical approach several fast linear algebra approaches have been used to reduce computational costs associated with matrix operations in geostatistical inversion for example liu et al 2007 fritz et al 2009 and nowak et al 2003 utilize the fast fourier transform fft to accelerate matrix vector multiplications in inverse problems on a regular grid if the covariance matrix is separable meaning that the covariance function can be written as products of independent functions for each dimension kronecker product methods can accelerate the matrix vector computation combined with fft e g yadav and michalak 2013 nowak et al may 2013 because the extension of fft based methods to unstructured grids is nontrivial several other methods have been proposed to deal with fast matrix vector multiplication with a minimum storage requirement li and cirpka 2006 propose an algorithm that parameterizes the spatial random field by the karhunen loÃ¨ve kl expansion liu and kitanidis 2011 utilize a sparse formulation for the generalized inverse of the covariance matrix i e the precision matrix to avoid using the large dense covariance matrix ambikasaran et al 2013 and saibaba and kitanidis 2012 exploit the hierarchical structure of the covariance matrices and use h 2 matrices and fast multiple methods fmm beatson and greengard 1997 darve 2000 cheng et al 1999 to reduce the matrix vector multiplication and storage costs these approaches are exceptionally beneficial in the context of inverse modeling because they can be applied to general covariance matrices constructed on unstructured grids achieve linear scalability fig 3 and can be implemented within the inversion algorithms as black boxes with minimal code modifications alternatively ensemble based approaches e g wilson and ozkan haller 2012 have been applied to accelerate the computation associated with covariance matrix products although such methods are more commonly used in sequential data assimilation applications described later in section 3 2 for nonlinear problems another computational bottleneck is the need to compute jacobian matrices at each iteration which is computationally expensive for large problems with the number of forward model runs and storage costs of o min m n and o mn respectively to overcome this computational challenge liu et al 2013 propose the geostatistical reduced order approach where the large unknown parameter state is represented in a small dimensional space in another method kitanidis and lee 2014 and lee and kitanidis 2014 present the principal component geostatistical approach pcga which utilizes a matrix free approach for jacobian calculation and a low rank representation of the covariance matrix based on its principal components or eigenvectors this eigenspectrum approach to matrix compression reduces the number of forward model calls and avoids the direct computation of jacobian matrices at each iteration with a controlled reduction in accuracy based on the number of principal components considered the computational benefit is significant since the number of principal components n is significantly smaller than the number of unknowns n lee et al 2016 extend pcga to handle data intensive problems through generalized eigen decomposition of the posterior data update space and applies the proposed method to a three dimensional laboratory scale sand box characterization using around seven million tracer data points from mri with modflow mt3dms for groundwater flow and transport simulation lin et al 2017 extend pcga with a randomized approach to reduce the dimension of data and run a 10 million data point synthetic problem in lee et al 2018 a detailed comparison is made between eigenspectrum based and ensemble based approaches showing superior performance of pcga in batch data inversion applications 3 kalman filtering techniques 3 1 the original kalman filter algorithm the kalman filter kf kalman et al 1960 harvey 1990 is the most widely used data assimilation method for sequential state and parameter estimation this method was originally developed for least squares or gaussian distribution state updating for linear systems sorenson 1985 simon 2006 but has been extended to systems where these requirements are only approximately met the algorithm works in a two step process as shown in fig 2 first in the prediction step the forward model is used to produce estimates of the current state variables second the bayesian update step is executed every time a set of measurements is collected during which the kalman filter produces an estimate of the state of the system as a weighted average of the system s predicted state and of the new measurements with weights representing the relative uncertainty of model predictions and assimilated data as represented by the associated covariance matrices the result of the weighted average lies between the predicted and measured state and has lower uncertainty than either alone the algorithm is recursive meaning that the same procedure is performed at every time new observations are assimilated it can run in real time using only the present input measurements and the previously calculated state and its uncertainty i e the posterior covariance matrix no additional past information is required this is in contrast to history matching techniques that use the entire past observed data at each estimation step oliver and chen 2011 tahmasebi et al 2018 for nonlinear dynamic models the extended kalman filter ekf the nonlinear kf variant provides reasonably accurate solutions using a linearization scheme the ekf has found many applications in hydrology katul et al 1993 eigbe et al 1998 de rosnay et al 2013 the ekf algorithm utilizes taylor series expansion to linearize the model around the estimate of the current mean values one of the major limitations of both kf and ekf for hydrology problems is the inherent high dimensionality that arises when dynamical systems for large scale domains are discretized for modeling for such systems the original implementation of kf and ekf is extremely expensive because it requires to update and store a large covariance matrix of size n 2 every time new data are assimilated this computation is normally performed at a computational cost of o mn 2 and storage cost of o n 2 also for nonlinear problems it requires computing the jacobian matrices which are expensive to compute and store this problem has given rise to techniques such as ensemble based kalman filters and low rank kalman filters 3 2 ensemble based kalman filters ensemble kalman filter enkf is a computationally efficient kalman filter method that avoids explicit calculation of full n n covariance matrices and jacobian matrices enkf uses an ensemble of realizations to create a low rank approximation of the state covariance matrix evensen 2009 this approximation makes the number of forward model calls scale linearly with the ensemble size n with ensemble sizes usually in the order of 100 and generally orders of magnitude smaller than the number of unknowns n thus reducing the storage cost of enkf and achieving overall linear scaling of the method with the number of unknowns enkf s ensemble based formulation allows the algorithm to use forward solvers as black boxes and the code to be highly parallelizable these attributes have led to the wide adoption of enkf for data assimilation in a range of disciplines for both linear and nonlinear problems evensen 2003 pathiraja et al 2016 wang et al 2009 in hydrology enkf has been widely used to estimate the state and parameters of hydrologic models moradkhani et al 2005 vrugt et al 2005 clark et al 2008 chen and zhang 2006 pathiraja et al 2016 rafieeinasab et al 2014 weerts and el serafy 2006 use enkf in flood forecasting to reduce the uncertainty in the rainfall runoff update and model state estimation pathiraja et al 2016 investigate the potential for enkf to estimate hyper parameters of the temporal structure from streamflow observations gu et al 2005 apply enkf for automatic history matching for a reservoir problem and conclude that enkf provides accurate history matching results while requiring less computation work than traditional history matching methods the extensive use of enkf in different fields has resulted in several improvements of the basic algorithm these improvements are often viewed as tuning of the basic enkf algorithm and while they do not change its overall computational cost they are necessary to improve its accuracy and to provide a fair basis for comparison with other approaches in the basic enkf implementation observation perturbation is necessary to prevent excessive reduction of the prediction error estimation also known as filter inbreeding houtekamer and mitchell 1998 lorenc 2003 or ensemble collapse bengtsson et al 2008 however this may introduce sampling errors which could in turn result in the sample covariance matrix being suboptimal lee et al 2018 and losing its positive definiteness furrer and bengtsson 2007 aanonsen et al 2009 one way in which this is manifested is the deterioration of the forecast covariance which results in spurious correlations ghorbanidehno et al 2015 li et al 2015 this is especially a problem when the rank of the state covariance matrix is much larger than the ensemble size these problems can be addressed using covariance inflation whitaker 2002 which does not have an impact on computational cost but improves stability of the filter and ultimately its accuracy the sampling error issue can also be resolved by using a larger number of ensemble members albeit at a higher computational cost an efficient alternative is to use square root filters whitaker 2002 tippett et al 2003 which by construction avoid the loss of positive definiteness of error covariance matrices examples of square root filters include the ensemble square root kalman filter ensrf chen et al 2013 tong and xue 2008 the ensemble transform kalman filter etkf bishop et al 2001 wei et al 2006 and the local ensemble transform kalman filter letkf hunt et al 2007 which combines ensrf with etkf these methods consider model error in the updates without perturbing the observations and thereby avoid sampling errors the differences between ensrf etkf and letkf are in the computational cost of matrix operations during the update step of the filter tippett et al 2003 however in cases where the assumptions of the kalman filter are not strictly satisfied as for example in cases with significant nonlinearities systematic errors and non gaussian error statistics enkf and ensrf methods may lead to unstable results and ultimately to filter divergence resulting in estimated values with large estimation errors in such cases the update step of data assimilation may compute model parameters or state variables that are not physically realistic to avoid filter divergence ott et al 2004 and szunyogh et al 2005 propose to apply localization on enkf a method that employs an effective cut off radius observations beyond this radius are not considered for updating state variables for each region however the discontinuity added in the measurement space results in noise in the update step in order to overcome this problem houtekamer and mitchell 2001 and ott et al 2004 utilize a schur product which applies a smooth function to the covariance matrices to reduce the effect of observation points at larger distances implications of nonlinearities are even more pronounced if the a priori information on model parameters and state variables structure is poor and the initial guess is far from the true values to improve enkf s performance for strongly nonlinear problems with poor initial guesses iterative enkf ienkf schemes allow improving the initial ensemble and hence the resulting estimated model parameters and state variables for each data assimilation step ienkf methods employ iterative optimization for maximizing the posterior probability of the estimations conditional to its forecast value and the measurements adding to the computational cost of the method the ensemble randomized maximum likelihood enrml is an example of ienkfs that iterates on the parameters using quasi newton optimization techniques gu et al 2007 li et al 2007 krymskaya et al 2009 for a review of several types of ienkf methods readers are referred to reynolds et al 2006 and aanonsen et al 2009 ultimately all enkf variants improve upon the basic enkf implementation by increasing its accuracy for a given computational cost however the convergence of the filter i e how many ensemble members are needed to achieve a low and stable estimation error may still be slow especially for high dimensional hydrological problems determining the appropriate number of ensemble realizations for accurate state and uncertainty estimation is a key question for ensemble based methods it is well understood that convergence strongly depends on initial ensemble design and specifically on how well the initial ensemble captures the characteristics of the true field especially in situations where the assumptions of gaussianity are not met jafarpour and mclaughlin 2009 to improve convergence and thereby estimation accuracy for a given computational cost methods that improve the initial ensemble or sampling include applying an orthogonal decomposition to the ensemble in order to determine the dominant directions in the state space and use those rather than a random sample to represent the error covariance matrix li et al 2015 3 3 projection based low rank methods orthogonal decomposition can be applied directly on the prior covariance matrix to reduce the dimensionality of the data assimilation problem this approach has given rise to a different class of efficient methods in data assimilation termed here projection based low rank methods similarly to projection based approaches in geostatistical inversion section 2 2 matrix factorization is used to compute dominant directions of the prior error covariance and thus more effectively parameterize the error covariance at the initial step of data assimilation by projecting the initial covariance matrix into the smaller subspace all subsequent kalman filter equations are solved in that subspace significantly reducing the computational cost of matrix operations practically this can be achieved by performing eigen decomposition of the prior covariance matrix and selecting the n eigenvectors that correspond to the n largest eigenvalues these eigenvectors represent dominant and independent features of the prior covariance the selection of n depends on the desired resolution if only large scale features are of interest 10 50 eigenvectors may suffice to delineate the underlying structure smaller scale features can be resolved by increasing the number of eigenvectors used at an increased computational cost flath et al 2011 lee et al 2016 this selection process can be used to optimize the computational cost for the desired accuracy but also improves the filter stability by avoiding making corrections in directions for which the error is the most attenuated by the system pham et al 1998 propose such a low rank method called singular evolutive extended kalman filter seek for data assimilation in oceanography the approach uses eigendecomposition of the covariance matrix that retains a few important and dominant modes the initial eigenvectors are then propagated through the state transition equations and the decomposition is renewed to maintain orthogonality in follow up work pham 1996 present the singular evolutive interpolated kalman seik filter which is similar to seek but uses linear interpolation instead of linearization and provides better performance for nonlinear systems seek and seik filters have found applications in oceanography with accurate estimation results pham 1996 pham et al 1998 carmillet et al 2001 brasseur et al 1999 and approaches have been developed to further reduce their computational cost hoteit et al 2002 kitanidis 2015 introduces the compressed state kalman filter cskf that uses an eigendecomposition basis selected based on the characteristics of the problem such as the transition model and the system noise covariance matrix unlike seek the basis is pre selected and fixed reducing the computational cost associated with evaluating it at every step and improving overall performance li et al 2015 show that cskf provides more accurate results than enkf for a nonlinear reservoir monitoring problem in follow up work li et al 2017 introduce the smoothing based compressed state kalman filter scskf that combines cskf with a one step ahead smoothing scheme to tackle problems with stronger nonlinearities in the unknowns such as sharp interfaces observed in multiphase flow systems in another variant of cskf ghorbanidehno et al 2019 improve cskf to be applicable for problems with both a large number of unknowns and a large number of measurements a comparison between the workflow of enkf cskf and seek type methods is shown in fig 4 similar to ensemble based methods projection based methods are approximate methods and strive to achieve a balance between estimation accuracy and computational cost the optimal trade off depends on the characteristics of the estimation problem the desired resolution for the unknown field the information content of the data and the computational resources available for projection based methods a convergence analysis similar to ensemble based methods can be performed to identify the optimal number of components needed however the choice of the number of components is guided by the structure of the covariance and the required resolution with larger eigenvalues of the covariance corresponding to estimation of larger scale features and such that the more eigenvalues are considered the larger the n the more finely resolved the estimate is in contrast in ensemble based methods the efficiency of the compression depends on the sampling method used to generate the ensembles and the ensemble size asymptotically i e for large ensemble sizes ensemble based compression and projection based compression can provide the same accuracy 3 4 fast linear algebra and special cases finally there are special cases where the characteristics of the data assimilation problem allow for simplifications in the kf algorithm significantly improving its computational efficiency at little additional cost to the estimation accuracy for example li et al 2014 develop hikf for applications where the data is acquired at a much faster rate than the rate of the evolution of the system i e quasi continuous data assimilation such that the forward model operator can be assumed to be equal to the identify matrix by simplifying the kalman filter recursion and using the bbfmm method ambikasaran et al 2013 for matrix vector multiplications hikf achieves higher accuracy than enkf for the same computational cost savings compared to kf hikf can be also viewed as a dynamic spatiotemporal modeling method with markov assumption along the same lines ghorbanidehno et al 2015 propose the spectral kalman filter speckf that extends hikf for general problems by using a forward model approximation combined with a low rank approximation for the prior covariance the computational benefits of speckf are significant given that the forward model computation is avoided this concept was further extended by ghorbanidehno et al 2017 who combine speckf with linear gaussian control for optimization of groundwater pumping 4 summary and conclusions in this focused review we approached stochastic inverse modeling and data assimilation from the common perspective of computational efficiency in the context of large scale estimation problems in hydrology and hydrogeology and more generally earth sciences the size of these estimation problems is a result of the physical size of the systems modeled as well as the complex physical processes and heterogeneities of such systems many of which we need to characterize at a fine scale large scale estimation problems result in expensive matrix operations storage requirements and indirectly in a large number of forward model runs for sensitivity evaluations these costs are summarized in table 1 categorized by type of method and main source of computational cost a more detailed breakdown of computational costs can be found in the original papers e g ambikasaran et al 2013 li et al 2014 li et al 2015 to reduce all these computational costs one can approximate the large n n prior covariance matrix with a compressed n n covariance matrix where n is the number of the unknowns to be estimated and n is a number significantly smaller than n usually in the hundreds the compressed covariance matrix can be obtained a statistically by propagating an ensemble of n realizations or b analytically by performing eigenspectrum decomposition of the prior covariance and neglecting the smallest n n eigenvalues in both of these approaches the resulting compressed rank n covariance is an approximation of the full covariance the closer the n is to n the lower the estimation error and the higher the computational cost this reduction in dimensionality of the covariance matrix by both ensemble and eigenspectrum based methods not only reduces the cost of matrix storage and operations but also reduces the number of forward model runs required to obtain the jacobian matrix that gives the sensitivities of the unknowns to the measurements table 1 unavoidably compression introduces estimation errors compared to methods that utilize the entire covariance matrix the trade offs between the desired resolution estimation accuracy and computational cost are at the center of choosing between inversion methods and are strongly dependent on the characteristics of each application this is especially so as inverse modeling and data assimilation methods have been pushed more and more outside the boundaries of their original implementations and theoretical assumptions of gaussianity and linearity morzfeld and hodyss 2019 while the methods described in this review have advantages and disadvantages from either a computational cost or an accuracy point of view they all apply the general principles of compression of information through a low rank representation of the covariance matrix and they all benefit from fast linear algebra techniques ensemble based methods have been used extensively and have many advantages they are easy to implement in their basic form they do not involve matrix matrix multiplications or jacobian calculations and there are proven techniques available to tackle common problems like ensemble collapse and filter divergence on the other hand eigenspectrum based compression has also been used extensively in inverse modeling while these methods involve more complex matrix algebra they allow customizable compression based on characteristics of the problem and the resolution desired e g scale of plume features or geologic structures of interest and there are proven techniques available to reduce the cost of matrix matrix multiplications and matrix free jacobian estimation for both ensemble based and eigenspectrum based compression the reduction in computational cost is significant compared to traditional methods and the scaling in both cases is comparable table 1 when it comes to specific applications for the same computational cost neither approach guarantees higher accuracy differences in the estimation may also vary depending on the metric used to evaluate accuracy e g rmse based metrics versus low level noise in estimated field non physical hot spots etc it should be noted that the computational cost of inversion is always dependent on the cost of each individual forward run even with a reduced number of forward runs the computational cost will be significant for inversions where individual runs are expensive e g large domains multiphase forward simulators parallelizable inverse modeling methods like for example pcga and enkf that allow individual runs to run in parallel can significantly reduce the overall inversion cost allowing higher accuracy for high dimensional systems when combined with parallelizable forward solvers further cost reductions are possible kurtz et al 2016 reducing the cost of individual forward model runs is also possible through the use of surrogate or reduced order models e g mo et al 2019 while such methods appear promising they are strongly case dependent and require code development and training data processing in a way that limits their general utility more research is needed in this field as continued advancements in efficiency of individual forward solvers will allow the speedup of methods presented in this review as well as of higher order estimation methods like particle filters and mcmc approaches the plethora of inverse modeling and data assimilation acronyms and the continuous evolution and combination of approaches is an indication of the expansion of the field to more diverse applications within and beyond hydrology with newer and more complex datasets and a strong focus on reliable uncertainty quantification as new methods are developed and existing methods are improved effective sharing of these algorithms in the public domain using a common framework will facilitate not only reproducible and reliable research but also better benchmarking and more widespread use in real world applications integrated and modularized platforms that allow the use and comparison of various inversion approaches like the terrestrial data assimilation framework terrsysmp pdaf kurtz et al 2016 will be instrumental in making progress in the inversion field at the same time while algorithm development is crucial equally important is progress in the area of data collection and sharing increasing the resolution and sensitivity of instruments as well as developing automatic sensors that can collect the most information dense measurements is another frontier last but not least public domain open source databases for data dissemination can help in the validation and comparison of new algorithms in the coming years the need for fast algorithms that can process big data from multiple sources and that can run large physics based simulations will only continue to increase in all scientific fields these developments will be especially consequential for the field of hydrology in which physical processes occur at large interconnected scales but resource management is urgently needed at scales ranging from the local continuum scale to the watershed scale and ultimately up to the global scale declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the three anonymous reviewers for their valuable feedback on this focused review this work is supported by an appointment to the faculty and postdoctoral fellow research participation program at the u s engineer research and development center coastal and hydraulics laboratory administered by the oak ridge institute for science and education through an interagency agreement between the u s department of energy and erdc jonghyun lee was supported by hawaii experimental program to stimulate competitive research epscor provided by the national science foundation research infrastructure improvement rii track 1 ike wai securing hawaii s water future award oia 1557349 
5084,urban rivers are important sources of greenhouse gases ghgs to the atmosphere however these high dissolved ghgs are not well studied we report the first detailed investigation on an urban river influenced by wastewater treatment plant wwtp dam and aeration device with a focus on the concentration of ghgs and their underlying microbial processes basing on isotope approaches the result revealed that these infrastructures influenced carbon and or nitrogen input and redox condition of the river system leading to impaction of ghgs concentrations and spatiotemporal pattern the wwtp effluent was the point source of n2o loading to rivers and also contained high no3 and dissolved organic carbon creating favorable conditions for denitrification by microbes we measured isotopic compositions Î´15n n2o and Î´18o n2o and site preference sp of dissolved n2o to differentiate the relative contribution of n2o production processes and calculate the degree of n2o reduction fr the relative contribution of denitrification increased at downstream and fr suggested that n2o was produced and consumed by heterotrophic denitrification resulting in a sink of n2o downstream the closure of dam increased water residence time trapped the sediment accelerated oxygen consumption and development of anoxic conditions that stimulating the production of co2 and ch4 as well as consumption of n2o aeration devices maintained oxic condition that slowing the development of the anoxic stage and eliminating the methanic stage at downstream as a result co2 concentrations increased along the river due to production of co2 via anaerobic and aerobic respiration of aqueous organic matter ch4 concentrations increased at downstream from organic matter biodegradation under anoxic conditions the measured dissolved ghgs especially the upper ranges correspond to a large oversaturation of surface water with respect to atmospheric equilibrium leading high fluxes to the atmosphere our values are on the high end of estimates reported in the literature among different climate regions indicating that urban river influenced by various of infrastructures are comparable to those in wetlands and intensively agricultural rivers in terms of ghgs emissions urban river should be urgently included in the determination of global carbon and nitrogen budgets from rivers keywords urban river stable isotope greenhouse gases microbial process treated wastewater 1 introduction carbon oxide co2 methane ch4 and nitrous oxide n2o are important greenhouse gases ghgs contributing to global climate change ipcc 2013 rivers are important ghgs emission sources because receive water from sewage discharge agricultural soil wetland and groundwater which contain ghgs and its precursors the sources of these potent ghgs are poorly constrained and quantified sutton et al 2007 especially those related to release from rivers and streams marzadri et al 2017 the co2 emissions from rivers and streams have been updated to 1 8 pg c y raymond et al 2013 while other recent work has provided an even lower estimate of 0 65 pg c y from global rivers and streams lauerwald et al 2013 there is also a lack of consensus on both the magnitude of the anthropogenic contribution and the general importance of lotic systems to n2o emissions the united states environmental protection agency epa anderson et al 2010 estimates that the natural nitrous oxide emissions from rivers are 0 1 tg n n2o yr 1 while a recent large scale tracer study suggests that rivers account for at least 0 68 tg n n2o yr 1 representing up to 10 of global anthropogenic n2o emissions hu et al 2016 beaulieu et al 2010 annual ch4 evasion from fluvial environments is estimated to be 26 8 tg ch4 which is comparable to the values for both lakes and wetlands stanley et al 2015 methane dynamics have been well documented in inland water such as lakes and reservoirs however less is known about riverine ch4 dynamics atkins et al 2017 the prevailing large uncertainty involved in ghg flux estimates for rivers is essentially due to two reasons this first reason is the paucity of available data particularly that related to low order rivers although small rivers are individually trivial ghg sources they are likely to be more supersaturated in ghgs than large rivers zeng and masiello 2010 li et al 2018 the second reason is an incomplete understanding of the underlying processes leading to these emissions quick et al 2019 riverine n2o production and consumption processes include nitrification the oxidation of nh3 to no3 release n2o as a by product nitrifier denitrification the reduction of no2 to n2o and heterotrophic denitrification the reduction of no3 to n2 can either produce n2o and reduce n2o to n2 toyoda et al 2015 li et al 2019 production processes of riverine co2 include biodegradation of either from terrestrial organic matter om and aqueous om as well as respiration of phytoplankton while riverine co2 can be deceased by processes of evasion to atmosphere and uptake by phytoplankton hosen et al 2014 crawford et al 2016 borges et al 2019 riverine ch4 is produced by methanogenesis that via reduction of co2 or decomposition of acetate under anaerobic condition while is consumed by oxidation the oxidation of ch4 to co2 atkins et al 2017 thereby ghgs concentrations are supposed to related with environmental factors such as temperature organic matter dissolved oxygen do nitrate ammonia and salinity which can be attempted with a correlation analysis with underlying process borges et al 2015 however the relation between ghgs and those factors are not always simple thus underlying processes of the ghgs were generally identified by incubating sediment and water in laboratory conditions despite that do not truly reflect ghgs production in the field setting of rivers thuan et al 2017 stable isotopic technique have been recommended as a powerful tool for addressing this difficult issue li et al 2019 nitrogen and oxygen isotopic ratios Î´15n n2o and Î´18o n2o and site preference sp the difference in 15n abundance between central and outer n position of n2o have been adopted to differentiate n2o production mechanism in agricultural soils partial nitrification reactors and wastewater treatment plants wwtp koba et al 2009 lewicka szczebak et al 2017 zou et al 2014 in particular sp value is only determined by production processes and not dependent on Î´15n the substrate no3 or nh4 isotopic composition which makes it universally applicable sutka et al 2006 generally for nh2oh oxidation nitrification the sp value is expected to be positive 33 4 because 14n binds preferentially to hydroxylamine oxidoreductase toyoda et al 2015 for no reduction denitrification and nitrifier denitrification the sp is expected to be close to zero because two no molecules simultaneously bond to the fe centers of nitric oxide reductase denk et al 2017 additionally Î´15nbulk n2o Î´18o n2o and sp will be enriched during the process of n2o reduction by complete denitrification which can be described by rayleigh fractionation model wunderlin et al 2013 ishii et al 2014 thuan et al 2017 the sable isotopic ratio also can provide insight into origin of co2 through the determination of Î´13c in dissolved inorganic carbon dic polsenaere and abril 2012 the Î´13c of atmospheric co2 is about 7 5 whereas co2 produced by respiration has a Î´13c value close to terrestrial and aqueous om i e 27 in case of c3 plants and 13 in case of c4 plants miyajima et al 2009 hco3 is another major component of dic and the Î´13c of hco3 is controlled by type of weathering rock carbonate and silicate and origin of the co2 involved in rock dissolution polsenaere and abril 2012 since hco3 is isotopically enrichment relative to co2 from om respiration the change of Î´13c dic is supposed to follow the relative abundance of co2 to hco3 which through the processes including physical gas exchange with atmosphere weathering ice cover and biological respiration and photosynthesis roach et al 2016 ch4 from biogenic methanogenesis usually has Î´13c values lower than 50 whereas oxidation extends from about 50 to 20 because of enrichment of oxidation process teodoru et al 2015 mackensen and schmiedl 2019 andreas et al 2019 the fraction of ch4 removed by methane oxidation can be calculated with a closed system rayleigh fractionation model instead of open system models liptay et al 1998 identification of these underlying processes will illuminate potential role of river on nutrient cycling water quality and ghgs budgets smith et al 2017 urban river is highly human activities modified system with various of in river structures i e dam aeration device wwtp wetland and sanitary sewer the closure of dam can increase water residence time trap the sediment accelerate oxygen consumption and development of anoxic conditions which can affect the production and consumption of ghgs maeck et al 2013 maavara et al 2018 wwtp is known to be a source of n2o ch4 and co2 in urban areas and contribute point source ghgs loading to rivers strokal and kroeze 2014 alshboul et al 2016 it is believed that do can be increased significantly by aeration device resulting decrease of nitrogen phosphorus and chlorophyll Î± wu et al 2016 the overall result suggested that these in river structures influenced carbon and or nitrogen input and redox condition of the river system leading to change of ghgs concentrations and spatiotemporal pattern maeck et al 2013 smith et al 2017 jin et al 2018 in addition dissolved ghgs were supersaturated in urban rivers which were significantly higher than those in the natural waters creating ghgs emission hot spot alshboul et al 2016 smith et al 2017 hu et al 2018 abril and borges 2019 therefore further research is required to quantified the ghgs concentrations identified the underlying processes related with ghgs and the controlling factors which responsible for the observed patterns of urban river 2 methods 2 1 sampling sites and sample collection the xixiang river is a river mainly replenished by wwtp effluent locating at shenzhen city in china fig 1 which is dominated by an urbanized land use regime this region has a southern subtropical monsoon climate with an annual mean temperature of 22 4 c and an annual rainfall of 1769 mm huang et al 2012 the headwater is a reservoir at upstream which only discharge to downstream in flood season due to the shortage of drinking water in shenzhen city the river flows 6 21 km to the pearl river estuary creating a watershed spanning 17 78 km2 the depth of the river increases gradually from 0 3 m s1 to 3 m s10 the flow rate tends to decrease due to interception by the dam built at the estuary the reclaimed water from the wwtps is widely used to supply the urban rivers to reconstruct the urban water ecological environment in china the xixiang river receives little water from the reservoir because of increasing water demand and is predominantly charged by wwtp effluents at s1 the wwtp aside this river utilizes anaerobic anoxic oxic a2o process that is commonly used process in domestic wastewater treatment in china making the river representative sun et al 2013 in order to prevent seawater intrusion a dam is settled at the mouth of the estuary aeration devices were settled at the downstream of the river from s7 to s9 which is supposed to improve water quality and eliminate odor of the river the river water was mainly supplied by the wwtp effluents at s1 in february may and december and was sourced from the reservoir upstream in august the aeration devices at down steam of the river were opened in may and december black odor season and closed in february and august we selected 10 sampling stations between the xixiang river estuary and 5 km upstream of the estuary water was collected on 1 february 30 may 31 august and 30 december in 2018 the water temperature dissolved oxygen do concentration electrical conductivity ec and ph were measured in site using portable sensors hq40d hach co usa surface water was collected from the river by a water sampler samples for dissolved inorganic nitrogen nitrite and nitrate analysis were collected in 100 ml plastic bottles while samples for total dissolved fe mn and nh4 were filtered with a 0 45 Î¼m hydrophilic polypropylene membrane and adjusted to a ph of 2 with 1 m h2so4 samples for dissolved organic carbon doc were filtered through a 0 7 Î¼m glass fiber membrane samples for greenhouse gas concentration analysis were collected in three gas serum vials 20 ml without headspace preserved with hgcl2 to stop microbial activity and sealed with butyl rubber stoppers samples for greenhouse gas stable isotope composition analysis were collected in three 100 ml vials in the same way all the water samples were sent back to laboratory in 24 h and store in 4 c 2 2 laboratory analysis the no3 and nh4 concentrations in water samples were measured by flow injection analyzer aa3 seal german total dissolved fe and mn were determined by inductively coupled plasma mass spectrometry icap qc thermo fisher scientific usa the dissolved n2o co2 and ch4 concentrations were measured using a gas chromatograph equipped with an electron capture detector ecd a thermal conductivity detector tcd and a flame ionization detector fid gc2014 shimadzu co japan based on the headspace method and calculated by henry s law as described by smith et al 2017 instrument detection limits were 100 ppb for n2o 10 ppm for co2 and 0 1 ppm for ch4 samples for isotopic composition measurements of dissolved ghgs were extracted by purging the water sample with ultra high purity helium gas using liquid n2 to trap ghgs and then were released from the trap by purging with helium gas which descried by baulch 2011 the gas samples were injected into air bags and were introduced into an isotope ratio monitoring mass spectrometer irms isprime100 isoprime cheadle uk in environmentally stable isotope lab at the chinese academy of agricultural science calibration was conducted by measuring the standards usgs32 usgs34 nbs19 and nbs22 the typical analytical precision was 0 5 0 9 and 0 6 for Î´15nbulk Î´15nÎ± and Î´18o respectively Î´13c dic and Î´13c ch4 was analyzed using an isotope ratio mass spectrometer thermo fisher delta v advantage usa and were calibrated using iaea co 8 and an internal standard nahco3 Î´13c of 15 53 and the analytical precision was better than 0 2 Î´15nÎ± and Î´15nÎ² represent the 15n 14n ratios at the center and end of n atoms respectively in n2o n n o Î´15nbulk and Î´18o indicate the average isotope ratios of 15n 14n and 18o 16o respectively in n2o sp value is calculated as follows 1 sp Î´ 15 n Î± Î´ 15 n Î² 2 3 calculations 2 3 1 greenhouse gas saturation saturation of ghgs in the river water is the ratio of in situ measured concentration of ghgs and calculated saturated ghgs concentration in ambient air s is the greenhouse gases saturation cw is the measured ghgs concentration in the river water ca is the atmospheric concentration of sampling sites Î± is the bunsen coefficient wanninkhof 1992 2 s c w Î± c a 100 2 3 2 production and consumption analysis using sp and Î´18o of n2o isotopic ratios of n2o reflect production and consumption process lewicka szczebak et al 2017 proposed a mapping approach based on the sp and Î´18o n2o to calculate the relative contribution ratio of nitrification and denitrification as well as the ratio of n2o reduction to n2 fig 2 the calculation is based on the assumption that n2o is from two sources is first mixed and then the mixed n2o is reduced by complete denitrification the relative contribution of nitrification x to n2o production is calculated according to equation 3 3 x sp sample sp intercept sp nit sp intercept 100 where spsample and spintercept represent the sp value measured from the sample and the calculated intercept in fig 2 sp value would change by n2o reduction which can be described using rayleigh fractionation 4 sp sp 0 Îµ s p red l n c c o 5 fr 1 c c 0 where sp and sp0 equal to spintercept in fig 2 stand for the sp value of n2o during and before n2o reduction respectively c and c0 stand for the concentration of n2o during and before n2o reduction respectively the degree of n2o reduction fr is calculated according to eqs 4 and 5 the variation in the sp values of n2o during and before n2o reduction is described by an enrichment factor Îµ sp red which have a range from 7 7 to 2 3 with an average value of 5 was used in this study lewicka szczebak et al 2017 therefore in order to calculate x and fr it s critical to obtain the initial sp value before reduction spintercept the mixing line in fig 2 is determined by two end members including nitrification and denitrification the common end member of sp value of 3 9 for bacterial denitrification and 34 8 for nitrification while the common end member of Î´18o n2o value of 21 for bacterial denitrification and 43 6 for nitrification are used which obtained from previous studies toyoda et al 2005 frame and casciotti 2010 lewicka szczebak et al 2017 the equation of reduction line is determined by the sp value and Î´18o n2o from each sample as well as the slope Îµ spred Îµ 18o of this line Îµ 18o is the enrichment factor of Î´18o n2o during n2o reduction with a common mean value of 15 ostrom et al 2007 we applied average value of Îµ spred Îµ 18o 0 35 instead of an independent Îµ spred and Îµ 18o since the ratio of Îµ has been found to be more robust than Îµ finally spintercept is calculated by solving two equations of mixing line and reduction line 2 3 3 methane oxidation the fraction of ch4 removed by methane oxidation fox was calculated with a closed system rayleigh fractionation described by borges et al 2019 as follow 6 ln 1 f ox ln Î´ 13 c c h 4 i n i t i a l 1000 ln Î´ 13 c c h 4 1000 Î± 1 where Î´13c ch4 initial an average value of 60 is the isotopic ratio of ch4 produced by methanogenesis in sediments and or water column borges et al 2019 Î´13c ch4 is the isotopic ratio of measured water samples and Î± 1 02 is the fractionation factor during oxidation process morana et al 2015 3 results 3 1 general water chemistry the range of the main environmental variables in this study including ph temperature ec doc and hco3 are listed in table 1 the temperature of the surface water followed a seasonal dynamic with the highest values in may and the lowest in february at s1 the ec values were significantly higher when receiving wwtp effluents than when receiving reservoir water the ec values changed in a narrow range from s1 to s5 then increased significantly from s5 which was affected by seawater intrusion in february and december the ph of the river water varied between 6 9 and 8 4 in february may and december which shows a weakly alkaline environment while the ph changed between 6 4 and 6 8 in august indicated a weakly acidic environment the doc values ranged from 3 3 to 10 5 mg l among the four sampling seasons the concentrations of no3 nh4 and no2 showed prominent temporal changes fig 3 the no3 n concentrations were extremely low in august when the river was recharged by the reservoir wwtp effluent discharge to the river led to higher no3 n concentrations upstream the nh4 n concentrations increased downstream in february and august while the do concentrations decreased to low levels no2 n was only detected at low do dissolved fe was detected in all sampling periods fig 3 the dissolved fe and mn concentrations were also higher when do were low 3 2 concentrations dissolved dic and isotopic ratios of Î´13c dic the concentration of hco3 in august was approximately 2 times higher in than that in february and may while it was approximately 3 times higher than that in december which might be due to higher dissolved co2 in august the co2 concentrations increased while the dissolved do concentrations decreased along the river fig 4 the saturation of co2 ranged from 282 to 33 846 fig 6 the Î´13c dic varied from 20 1 to 7 6 most of the Î´13c dic values in may were higher than those values in other sampling periods Î´13c dic values in august were between those in february and in may corresponded to high concentrations of dissolved co2 fig 4 3 3 concentrations dissolved ch4 and isotopic ratios of Î´13c ch4 the dissolved ch4 increased along the river and exhibited seasonal variability fig 4 with a range of 0 04 76 Î¼mol l for concentration and 64 137801 for saturation fig 6 at s1 the dissolved ch4 concentrations were low in february may and december which suggested that the wwtp effluent was not the main source of ch4 to the river water the concentrations of dissolved ch4 in surface water during the four sampling periods increased along the river which indicated that ch4 was derived from in situ production in the water column or sediments the dissolved ch4 concentrations were much higher in february and august than in may and december downstream possibly due to hypoxia the Î´13c ch4 values first decreased and then increased quickly upstream in may and december while they first decreased and then remained stable downstream in february and august the fraction of ch4 removed by methane oxidation had a range of 28 78 fig 8 3 4 concentrations and isotopic compositions of dissolved n2o dissolved n2o also showed obvious temporal and spatial variability fig 5 dissolved n2o originated from wwtp at s1 had high variability in february and may the concentrations of dissolved n2o were as high as 1426 18 nmol l and 405 87 nmol l decreasing quickly along the river the dissolved n2o concentration was 75 24 nmol l in december at s1 and increased along the river when the river received water from the reservoir in august the concentration of dissolved n2o was relatively low in the upper stream reached a maximum midstream and then decreased almost all of the measured values were higher than that corresponding to equilibrium with the atmosphere fig 6 suggesting that the river was a source of n2o emission to the atmosphere the values of Î´15nbulk n2o and Î´18o n2o were both enriched along the river ranging from 19 34 to 16 03 and from 50 17 to 82 54 respectively while the sp value decreased when reclaimed water replenished the river fig 5 in august the value of Î´15n n2o had minor change along the river but the sp and Î´18o n2o values showed obvious temporal variation the spatial variation patterns of isotope compositions were quite similar when the river received reclaimed water and were different from those in reservoir water the contribution of nitrification x increased along the river as did the degree of n2o reduction fr when the river received reclaimed water fig 7 however x and fr exhibited large fluctuations when the river received reservoir water the values of x suggested that n2o derived from nitrification dominated in the wwtp in february and may while n2o produced from denitrification were responsible for the remaining n2o surface water along the river n2o was mainly produced from denitrification nitrifier denitrification at the mouth of the estuary in august the high dissolved n2o was mainly produced by nitrification at downstream with unexpectedly elevated nh4 concentrations even under anoxic conditions in the absence of nitrate moreover the large amount of n2o produced in situ could be from entirely different pathways nitrification at s6 in august and denitrification at s9 in december 4 discussion 4 1 dissolved ghg concentrations the dissolved ghg concentrations of global rivers are shown in table 2 our values are on the high end of estimates reported in the literature among different climate regions indicating that urban rivers replenished by reclaimed water are a significant source of ghgs the large contribution of wwtp effluents to the observed high concentrations of n2o and co2 might be surprising the treatment employed in the wwtp reduces the high levels of biological oxygen demand bod nh4 and no3 fulfilling the water quality standards imposed by the government these processes including om respiration combined nitrification denitrification can release large amounts of n2o and co2 to the river via effluent however the effluent that discharge into the urban river did not contribute significantly to the river ch4 levels which is consistent with a previous report sturm et al 2016 due to uncertainties in the gas transfer velocity ghg concentrations were used rather than ghg emissions to compare spatial and temporal patterns across sites the measured dissolved ghgs especially the upper ranges correspond to a large oversaturation of surface water with respect to atmospheric equilibrium leading high fluxes to the atmosphere our observations of n2o concentrations and saturations are comparable with a river that strong influenced by agriculture borges et al 2018a ch4 concentrations are close to the values that reported in a tributary of congo river that is bordered by extensive wetland borges et al 2019 co2 concentrations 355 1 1133 2 Î¼mol l in february may and december are close to tropical rivers i e congo river and urban river i e huangpujiang river borges et al 2019 he et al 2013 but unexpected high in august while the do was extremely low these results indicated that urban river influenced by with various of in river structures are comparable to those in wetlands and intensively agricultural rivers in terms of ghgs emissions 4 2 redox conditions change by in river structures production and consumption processes of ghgs are redox reactions and are often assumed to occur in sediment thus the redox conditions of a system will influence the likely biogeochemical pathway each pathway is regulated differently by environmental factors assuming that the electron donor is organic carbon there is an ideal sequence of redox reactions based on the available energy as put forward from a thermodynamic point of view champ et al 1979 in this sequence organic carbon is decomposed by electron acceptors in the following order o2 nitrate manganese oxide iron oxide sulfate and co2 puckett and cowdery 2002 this sequence coupled with knowledge of the spatial distribution of electron donors may allow the determination of the redox state of a water body and the evaluation of the extent of pollution accordingly many studies have been conducted on the gradient characteristics of biogeochemical processes in groundwater and vertical systems in hyporheic zone bardini et al 2012 reeder et al 2018 there is less research on this redox sequence in water column along rivers presumably as surface water is generally characterized in oxic condition however surface water and suspended sediment could account for biogeochemical processes including respiration and denitrification liu et al 2013 reisinger et al 2016 therefore redox condition of surface water is supposed be more successful in describing spatial variation pattern of ghgs concentration compare to sediment urban rivers are highly altered systems with a variety of forms of infrastructures that change the redox conditions of surface water the influence of dam and aeration device on redox condition of surface water can be examined by variation of doc and electron acceptors in february the do no3 and dissolved co2 concentrations had little change from s1 to s4 suggesting this reach was in the oxic stage from s4 to s8 the do and no3 decreased due to consumption as electron acceptors resulting in an increase of dissolved co2 manganese oxide and iron oxide can be used as electron acceptors to oxidize organic compounds and then release mn and fe into river water therefore their concentrations showed the highest values at s5 and s7 respectively from s8 to s10 the do concentrations were lower than 2 mg l the dissolved co2 decreased and the dissolved ch4 showed a peak at s9 indicating that a methanic stage was formed in august do progressively decreased and the absence of no3 accelerated the development of the methanic stage from s4 to s10 the result suggested that the anoxic condition downstream was caused by the dam at the mouth of the estuary in february and august with aeration device closed in may similar redox conditions were observed to those in february at upstream from s1 to s4 which were characterized by oxic stage however aeration downstream preserved the higher do and no3 inhibited concentration of mn fe nh4 and ch4 in december aeration downstream resulted in a similar spatial distribution of electron acceptors to those in may the result addressed that aeration can maintain oxic condition that slowing the development of the anoxic stage and eliminating the methanic stage at downstream 4 3 identification of the underlying processes of dissolved n2o n2o production and consumption are both strongly microbially mediated microbiological nitrification heterotrophic denitrification and nitrifier denitrification are considered to be three predominant production pathways in rivers thuan et al 2017 quick et al 2019 different n2o production pathways often occur simultaneously and thus it is necessary to distinguish their relative contributions to total n2o for n2o heterotrophic denitrification is favored by elevated nitrate concentrations and sufficient organic carbon under anoxic condition and is commonly regarded as the dominant n2o production pathway liu et al 2013 reisinger et al 2016 nitrification and nitrifier denitrification are favored by higher concentrations of ammonia under oxic and hypoxic condition respectively beaulieu et al 2010 toyoda et al 2017 n2o consumption was more likely occur under condition of low do no3 and high doc nh4 soued et al 2016 borges et al 2019 assumed values of the n2o yield due to nitrification may actually be values corresponding to the n2o yield from nitrifier denitrification because both processes are favored by similar environmental conditions and biological communities nitrifiers beaulieu et al 2011 thus determining which pathway produces the observed n2o would likely require the application of isotopic approaches a decrease of x values along the river showed that denitrification was the dominant process leading to production of dissolved n2o in both oxic and anoxic conditions fig 7 which is consistent with the results of earlier studies lansdown et al 2015 thuan et al 2017 the reclaimed water contains high no3 and doc creating favorable conditions for denitrification by microbes he et al 2013 the reduction of n2o to n2 during heterotrophic denitrification is the only known biological pathway of n2o consumption pauleta et al 2019 the increased of fr values with distance downstream suggested that n2o was consumed by heterotrophic denitrification resulting in a sink of n2o downstream the negative correlation between doc and n2o concentration indicated heterotrophic denitrification not nitrifier denitrification may dominated the denitrification process in this study sp values and Î´18o n2o were used for the quantifying the relative contribution of nitrification and denitrification however this model does not allow the separation of nitrifier denitrification and heterotrophic denitrification because the two processes have very similar isotopic signature values and because mass balance equations would not give a unique solution for three unknowns simultaneously duan et al 2017 the sequence analysis of denitrification functional gene cnorb encoding cytochrome containing nitric oxide no reductase transcripts is therefore recommended to distinguish the relative contributions of nitrifier denitrification and heterotrophic denitrification to n2o production ishii et al 2014 4 4 identification of the underlying processes of dissolved ch4 and co2 ch4 is produced during anaerobic om biodegradation and high ch4 concentrations and fluxes have been found in aquatic ecosystems and water saturated terrestrial ecosystems with anaerobic conditions atkins et al 2017 yu et al 2017 although ch4 should be scarce in streams and rivers because these ecosystems are usually well aerated and thus lack anoxic conditions which required for ch4 production and persistence dam reduce flow velocity trap the sediments and develop anoxic condition to create habitat for methanogenesis maeck et al 2013 stanley et al 2016 ch4 oxidation is the key factor controlling dissolved ch4 concentrations in surface water the ch4 oxidation process can be inhibited by low do and nh4 oxidizing bacteria compete with ch4 oxidizing bacteria for o2 resulting in the accumulation of dissolved ch4 in sediments and water column hu et al 2018 therefore a negative correlation was found between ch4 and do while a positive correlation was found between ch4 and nh4 in this study table 3 thus we observed dissolved ch4 concentration increased significantly at downstream in february and august when the aeration devices were closed the isotopic signature indicated that om biodegradation in sediments or water column contributed to riverine ch4 in anoxic conditions and the elative depletion of Î´13c in ch4 at downstream indicated less of an effect of bacterial oxidation fig 8a aeration changed the redox condition of downstream and enriched the Î´13c ch4 values and enhanced the bacterial oxidation of ch4 which resulting in a limited concentration of ch4 in may and december when aeration devices were open in addition dissolved ch4 concentration ranged from 0 04 to 0 39 Î¼mol l at s1 in february may and december when wwtp effluent charged to the river which is consistent with a previous report of nine wwtp effluent alshboul et al 2016 most of the samples collected from downstream had a higher ch4 value than those at upstream s1 suggested that wwtp effluent was not likely the dominant source of riverine dissolved ch4 co2 supersaturation has been reported for large rivers in boreal temperate and tropical areas bouillon et al 2009 richey et al 2002 aqueous co2 in river systems generally comes from three sources one source is allochthonous i e soil co2 derived from the biodegradation of terrestrial organic matter om or from soil respiration on land the second source is autochthonous and includes co2 produced from the in situ respiration of aqueous om li et al 2018 the third source is the wetland that adjacent to river abril and borges 2019 recently anthropogenic effects such as the discharge of untreated and treated sewage effluent have been identified as major factors that affect both dissolved co2 and dic as well as om in urban rivers hu et al 2018 in this study wwtp effluent contributed large amount dissolved co2 into the urban river at s1 in february may and december Î´13c in dic ranged from 11 0 to 12 89 this value is very close to that found in wwtp effluent in brazil 12 yang et al 2018 and in china 12 2 cotovicz et al 2019 the increase of concentration of dissolved co2 along the river indicated that the autochthonous production of co2 via in situ respiration of aqueous om occurred in the sediments and or water column at downstream due to the dam trapped the sediments that increase the available of om thus the dominant process of respiration could plausibly increase the co2 concentration lowering do and ph as well as depleting Î´13c in dic resulting in the negative correlation between co2 and do and between co2 and ph table 3 although the variation pattern of concentrations of dissolved co2 were similar in february may and however aeration increased co2 degassing from surface water which decreased the co2 concentration and enriched the Î´13c dic values in may fig 8b in august the river water was mainly from upstream reservoir the relative lower do and higher co2 and hco3 concentrations to other sampling periods that indicated the more intense autochthonous production of co2 via in situ respiration of aqueous om however the much higher dissolved co2 that compare to values in other sampling periods at s1 implied that allochthonous co2 from terrestrial inputs transferred by upstream reservoir 5 conclusion various forms of infrastructures influenced the underlying microbial processes by changing the redox conditions of the river resulting in spatiotemporal variations in dissolved ghgs the closure of dam can increase water residence time trap the sediment accelerate oxygen consumption and development of anoxic conditions which can stimulate the production of co2 and ch4 and consumption of n2o aeration device can maintain oxic condition that slowing the development of the anoxic stage and eliminating the methanic stage at downstream the wwtp effluent contribute the river wih high no3 and doc creating favorable conditions for denitrification by microbes isotopic ratio analysis indicated that the dissolved n2o and co2 were derived not only from the wwtp but also from in situ om biodegradation terrestrial inputs can also influence riverine co2 however wwtp effluent was not likely the dominant source of riverine ch4 while the isotopic signature demonstrated that autochthonous om biodegradation in the sediments or water column contributed to riverine ch4 in anoxic conditions the key results demonstrate that the dissolved ghg concentrations in this urban river are at the high end of estimates currently reported in the literature and should be urgently included in the determination of global carbon and nitrogen budgets from rivers these results indicated that urban river influenced by various of in river structures are comparable to those in wetlands and intensively agricultural rivers in terms of dissolved ghgs concentrations credit authorship contribution statement xing li conceptualization methodology software validation investigation formal analysis data curation writing original draft writing review editing huaiying yao resources writing review editing visualization yongxiang yu yingjie cao investigation validation changyuan tang validation writing review editing visualization supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was funded by the natural science foundation of guangdong province china grant no 2017a030310563 
5084,urban rivers are important sources of greenhouse gases ghgs to the atmosphere however these high dissolved ghgs are not well studied we report the first detailed investigation on an urban river influenced by wastewater treatment plant wwtp dam and aeration device with a focus on the concentration of ghgs and their underlying microbial processes basing on isotope approaches the result revealed that these infrastructures influenced carbon and or nitrogen input and redox condition of the river system leading to impaction of ghgs concentrations and spatiotemporal pattern the wwtp effluent was the point source of n2o loading to rivers and also contained high no3 and dissolved organic carbon creating favorable conditions for denitrification by microbes we measured isotopic compositions Î´15n n2o and Î´18o n2o and site preference sp of dissolved n2o to differentiate the relative contribution of n2o production processes and calculate the degree of n2o reduction fr the relative contribution of denitrification increased at downstream and fr suggested that n2o was produced and consumed by heterotrophic denitrification resulting in a sink of n2o downstream the closure of dam increased water residence time trapped the sediment accelerated oxygen consumption and development of anoxic conditions that stimulating the production of co2 and ch4 as well as consumption of n2o aeration devices maintained oxic condition that slowing the development of the anoxic stage and eliminating the methanic stage at downstream as a result co2 concentrations increased along the river due to production of co2 via anaerobic and aerobic respiration of aqueous organic matter ch4 concentrations increased at downstream from organic matter biodegradation under anoxic conditions the measured dissolved ghgs especially the upper ranges correspond to a large oversaturation of surface water with respect to atmospheric equilibrium leading high fluxes to the atmosphere our values are on the high end of estimates reported in the literature among different climate regions indicating that urban river influenced by various of infrastructures are comparable to those in wetlands and intensively agricultural rivers in terms of ghgs emissions urban river should be urgently included in the determination of global carbon and nitrogen budgets from rivers keywords urban river stable isotope greenhouse gases microbial process treated wastewater 1 introduction carbon oxide co2 methane ch4 and nitrous oxide n2o are important greenhouse gases ghgs contributing to global climate change ipcc 2013 rivers are important ghgs emission sources because receive water from sewage discharge agricultural soil wetland and groundwater which contain ghgs and its precursors the sources of these potent ghgs are poorly constrained and quantified sutton et al 2007 especially those related to release from rivers and streams marzadri et al 2017 the co2 emissions from rivers and streams have been updated to 1 8 pg c y raymond et al 2013 while other recent work has provided an even lower estimate of 0 65 pg c y from global rivers and streams lauerwald et al 2013 there is also a lack of consensus on both the magnitude of the anthropogenic contribution and the general importance of lotic systems to n2o emissions the united states environmental protection agency epa anderson et al 2010 estimates that the natural nitrous oxide emissions from rivers are 0 1 tg n n2o yr 1 while a recent large scale tracer study suggests that rivers account for at least 0 68 tg n n2o yr 1 representing up to 10 of global anthropogenic n2o emissions hu et al 2016 beaulieu et al 2010 annual ch4 evasion from fluvial environments is estimated to be 26 8 tg ch4 which is comparable to the values for both lakes and wetlands stanley et al 2015 methane dynamics have been well documented in inland water such as lakes and reservoirs however less is known about riverine ch4 dynamics atkins et al 2017 the prevailing large uncertainty involved in ghg flux estimates for rivers is essentially due to two reasons this first reason is the paucity of available data particularly that related to low order rivers although small rivers are individually trivial ghg sources they are likely to be more supersaturated in ghgs than large rivers zeng and masiello 2010 li et al 2018 the second reason is an incomplete understanding of the underlying processes leading to these emissions quick et al 2019 riverine n2o production and consumption processes include nitrification the oxidation of nh3 to no3 release n2o as a by product nitrifier denitrification the reduction of no2 to n2o and heterotrophic denitrification the reduction of no3 to n2 can either produce n2o and reduce n2o to n2 toyoda et al 2015 li et al 2019 production processes of riverine co2 include biodegradation of either from terrestrial organic matter om and aqueous om as well as respiration of phytoplankton while riverine co2 can be deceased by processes of evasion to atmosphere and uptake by phytoplankton hosen et al 2014 crawford et al 2016 borges et al 2019 riverine ch4 is produced by methanogenesis that via reduction of co2 or decomposition of acetate under anaerobic condition while is consumed by oxidation the oxidation of ch4 to co2 atkins et al 2017 thereby ghgs concentrations are supposed to related with environmental factors such as temperature organic matter dissolved oxygen do nitrate ammonia and salinity which can be attempted with a correlation analysis with underlying process borges et al 2015 however the relation between ghgs and those factors are not always simple thus underlying processes of the ghgs were generally identified by incubating sediment and water in laboratory conditions despite that do not truly reflect ghgs production in the field setting of rivers thuan et al 2017 stable isotopic technique have been recommended as a powerful tool for addressing this difficult issue li et al 2019 nitrogen and oxygen isotopic ratios Î´15n n2o and Î´18o n2o and site preference sp the difference in 15n abundance between central and outer n position of n2o have been adopted to differentiate n2o production mechanism in agricultural soils partial nitrification reactors and wastewater treatment plants wwtp koba et al 2009 lewicka szczebak et al 2017 zou et al 2014 in particular sp value is only determined by production processes and not dependent on Î´15n the substrate no3 or nh4 isotopic composition which makes it universally applicable sutka et al 2006 generally for nh2oh oxidation nitrification the sp value is expected to be positive 33 4 because 14n binds preferentially to hydroxylamine oxidoreductase toyoda et al 2015 for no reduction denitrification and nitrifier denitrification the sp is expected to be close to zero because two no molecules simultaneously bond to the fe centers of nitric oxide reductase denk et al 2017 additionally Î´15nbulk n2o Î´18o n2o and sp will be enriched during the process of n2o reduction by complete denitrification which can be described by rayleigh fractionation model wunderlin et al 2013 ishii et al 2014 thuan et al 2017 the sable isotopic ratio also can provide insight into origin of co2 through the determination of Î´13c in dissolved inorganic carbon dic polsenaere and abril 2012 the Î´13c of atmospheric co2 is about 7 5 whereas co2 produced by respiration has a Î´13c value close to terrestrial and aqueous om i e 27 in case of c3 plants and 13 in case of c4 plants miyajima et al 2009 hco3 is another major component of dic and the Î´13c of hco3 is controlled by type of weathering rock carbonate and silicate and origin of the co2 involved in rock dissolution polsenaere and abril 2012 since hco3 is isotopically enrichment relative to co2 from om respiration the change of Î´13c dic is supposed to follow the relative abundance of co2 to hco3 which through the processes including physical gas exchange with atmosphere weathering ice cover and biological respiration and photosynthesis roach et al 2016 ch4 from biogenic methanogenesis usually has Î´13c values lower than 50 whereas oxidation extends from about 50 to 20 because of enrichment of oxidation process teodoru et al 2015 mackensen and schmiedl 2019 andreas et al 2019 the fraction of ch4 removed by methane oxidation can be calculated with a closed system rayleigh fractionation model instead of open system models liptay et al 1998 identification of these underlying processes will illuminate potential role of river on nutrient cycling water quality and ghgs budgets smith et al 2017 urban river is highly human activities modified system with various of in river structures i e dam aeration device wwtp wetland and sanitary sewer the closure of dam can increase water residence time trap the sediment accelerate oxygen consumption and development of anoxic conditions which can affect the production and consumption of ghgs maeck et al 2013 maavara et al 2018 wwtp is known to be a source of n2o ch4 and co2 in urban areas and contribute point source ghgs loading to rivers strokal and kroeze 2014 alshboul et al 2016 it is believed that do can be increased significantly by aeration device resulting decrease of nitrogen phosphorus and chlorophyll Î± wu et al 2016 the overall result suggested that these in river structures influenced carbon and or nitrogen input and redox condition of the river system leading to change of ghgs concentrations and spatiotemporal pattern maeck et al 2013 smith et al 2017 jin et al 2018 in addition dissolved ghgs were supersaturated in urban rivers which were significantly higher than those in the natural waters creating ghgs emission hot spot alshboul et al 2016 smith et al 2017 hu et al 2018 abril and borges 2019 therefore further research is required to quantified the ghgs concentrations identified the underlying processes related with ghgs and the controlling factors which responsible for the observed patterns of urban river 2 methods 2 1 sampling sites and sample collection the xixiang river is a river mainly replenished by wwtp effluent locating at shenzhen city in china fig 1 which is dominated by an urbanized land use regime this region has a southern subtropical monsoon climate with an annual mean temperature of 22 4 c and an annual rainfall of 1769 mm huang et al 2012 the headwater is a reservoir at upstream which only discharge to downstream in flood season due to the shortage of drinking water in shenzhen city the river flows 6 21 km to the pearl river estuary creating a watershed spanning 17 78 km2 the depth of the river increases gradually from 0 3 m s1 to 3 m s10 the flow rate tends to decrease due to interception by the dam built at the estuary the reclaimed water from the wwtps is widely used to supply the urban rivers to reconstruct the urban water ecological environment in china the xixiang river receives little water from the reservoir because of increasing water demand and is predominantly charged by wwtp effluents at s1 the wwtp aside this river utilizes anaerobic anoxic oxic a2o process that is commonly used process in domestic wastewater treatment in china making the river representative sun et al 2013 in order to prevent seawater intrusion a dam is settled at the mouth of the estuary aeration devices were settled at the downstream of the river from s7 to s9 which is supposed to improve water quality and eliminate odor of the river the river water was mainly supplied by the wwtp effluents at s1 in february may and december and was sourced from the reservoir upstream in august the aeration devices at down steam of the river were opened in may and december black odor season and closed in february and august we selected 10 sampling stations between the xixiang river estuary and 5 km upstream of the estuary water was collected on 1 february 30 may 31 august and 30 december in 2018 the water temperature dissolved oxygen do concentration electrical conductivity ec and ph were measured in site using portable sensors hq40d hach co usa surface water was collected from the river by a water sampler samples for dissolved inorganic nitrogen nitrite and nitrate analysis were collected in 100 ml plastic bottles while samples for total dissolved fe mn and nh4 were filtered with a 0 45 Î¼m hydrophilic polypropylene membrane and adjusted to a ph of 2 with 1 m h2so4 samples for dissolved organic carbon doc were filtered through a 0 7 Î¼m glass fiber membrane samples for greenhouse gas concentration analysis were collected in three gas serum vials 20 ml without headspace preserved with hgcl2 to stop microbial activity and sealed with butyl rubber stoppers samples for greenhouse gas stable isotope composition analysis were collected in three 100 ml vials in the same way all the water samples were sent back to laboratory in 24 h and store in 4 c 2 2 laboratory analysis the no3 and nh4 concentrations in water samples were measured by flow injection analyzer aa3 seal german total dissolved fe and mn were determined by inductively coupled plasma mass spectrometry icap qc thermo fisher scientific usa the dissolved n2o co2 and ch4 concentrations were measured using a gas chromatograph equipped with an electron capture detector ecd a thermal conductivity detector tcd and a flame ionization detector fid gc2014 shimadzu co japan based on the headspace method and calculated by henry s law as described by smith et al 2017 instrument detection limits were 100 ppb for n2o 10 ppm for co2 and 0 1 ppm for ch4 samples for isotopic composition measurements of dissolved ghgs were extracted by purging the water sample with ultra high purity helium gas using liquid n2 to trap ghgs and then were released from the trap by purging with helium gas which descried by baulch 2011 the gas samples were injected into air bags and were introduced into an isotope ratio monitoring mass spectrometer irms isprime100 isoprime cheadle uk in environmentally stable isotope lab at the chinese academy of agricultural science calibration was conducted by measuring the standards usgs32 usgs34 nbs19 and nbs22 the typical analytical precision was 0 5 0 9 and 0 6 for Î´15nbulk Î´15nÎ± and Î´18o respectively Î´13c dic and Î´13c ch4 was analyzed using an isotope ratio mass spectrometer thermo fisher delta v advantage usa and were calibrated using iaea co 8 and an internal standard nahco3 Î´13c of 15 53 and the analytical precision was better than 0 2 Î´15nÎ± and Î´15nÎ² represent the 15n 14n ratios at the center and end of n atoms respectively in n2o n n o Î´15nbulk and Î´18o indicate the average isotope ratios of 15n 14n and 18o 16o respectively in n2o sp value is calculated as follows 1 sp Î´ 15 n Î± Î´ 15 n Î² 2 3 calculations 2 3 1 greenhouse gas saturation saturation of ghgs in the river water is the ratio of in situ measured concentration of ghgs and calculated saturated ghgs concentration in ambient air s is the greenhouse gases saturation cw is the measured ghgs concentration in the river water ca is the atmospheric concentration of sampling sites Î± is the bunsen coefficient wanninkhof 1992 2 s c w Î± c a 100 2 3 2 production and consumption analysis using sp and Î´18o of n2o isotopic ratios of n2o reflect production and consumption process lewicka szczebak et al 2017 proposed a mapping approach based on the sp and Î´18o n2o to calculate the relative contribution ratio of nitrification and denitrification as well as the ratio of n2o reduction to n2 fig 2 the calculation is based on the assumption that n2o is from two sources is first mixed and then the mixed n2o is reduced by complete denitrification the relative contribution of nitrification x to n2o production is calculated according to equation 3 3 x sp sample sp intercept sp nit sp intercept 100 where spsample and spintercept represent the sp value measured from the sample and the calculated intercept in fig 2 sp value would change by n2o reduction which can be described using rayleigh fractionation 4 sp sp 0 Îµ s p red l n c c o 5 fr 1 c c 0 where sp and sp0 equal to spintercept in fig 2 stand for the sp value of n2o during and before n2o reduction respectively c and c0 stand for the concentration of n2o during and before n2o reduction respectively the degree of n2o reduction fr is calculated according to eqs 4 and 5 the variation in the sp values of n2o during and before n2o reduction is described by an enrichment factor Îµ sp red which have a range from 7 7 to 2 3 with an average value of 5 was used in this study lewicka szczebak et al 2017 therefore in order to calculate x and fr it s critical to obtain the initial sp value before reduction spintercept the mixing line in fig 2 is determined by two end members including nitrification and denitrification the common end member of sp value of 3 9 for bacterial denitrification and 34 8 for nitrification while the common end member of Î´18o n2o value of 21 for bacterial denitrification and 43 6 for nitrification are used which obtained from previous studies toyoda et al 2005 frame and casciotti 2010 lewicka szczebak et al 2017 the equation of reduction line is determined by the sp value and Î´18o n2o from each sample as well as the slope Îµ spred Îµ 18o of this line Îµ 18o is the enrichment factor of Î´18o n2o during n2o reduction with a common mean value of 15 ostrom et al 2007 we applied average value of Îµ spred Îµ 18o 0 35 instead of an independent Îµ spred and Îµ 18o since the ratio of Îµ has been found to be more robust than Îµ finally spintercept is calculated by solving two equations of mixing line and reduction line 2 3 3 methane oxidation the fraction of ch4 removed by methane oxidation fox was calculated with a closed system rayleigh fractionation described by borges et al 2019 as follow 6 ln 1 f ox ln Î´ 13 c c h 4 i n i t i a l 1000 ln Î´ 13 c c h 4 1000 Î± 1 where Î´13c ch4 initial an average value of 60 is the isotopic ratio of ch4 produced by methanogenesis in sediments and or water column borges et al 2019 Î´13c ch4 is the isotopic ratio of measured water samples and Î± 1 02 is the fractionation factor during oxidation process morana et al 2015 3 results 3 1 general water chemistry the range of the main environmental variables in this study including ph temperature ec doc and hco3 are listed in table 1 the temperature of the surface water followed a seasonal dynamic with the highest values in may and the lowest in february at s1 the ec values were significantly higher when receiving wwtp effluents than when receiving reservoir water the ec values changed in a narrow range from s1 to s5 then increased significantly from s5 which was affected by seawater intrusion in february and december the ph of the river water varied between 6 9 and 8 4 in february may and december which shows a weakly alkaline environment while the ph changed between 6 4 and 6 8 in august indicated a weakly acidic environment the doc values ranged from 3 3 to 10 5 mg l among the four sampling seasons the concentrations of no3 nh4 and no2 showed prominent temporal changes fig 3 the no3 n concentrations were extremely low in august when the river was recharged by the reservoir wwtp effluent discharge to the river led to higher no3 n concentrations upstream the nh4 n concentrations increased downstream in february and august while the do concentrations decreased to low levels no2 n was only detected at low do dissolved fe was detected in all sampling periods fig 3 the dissolved fe and mn concentrations were also higher when do were low 3 2 concentrations dissolved dic and isotopic ratios of Î´13c dic the concentration of hco3 in august was approximately 2 times higher in than that in february and may while it was approximately 3 times higher than that in december which might be due to higher dissolved co2 in august the co2 concentrations increased while the dissolved do concentrations decreased along the river fig 4 the saturation of co2 ranged from 282 to 33 846 fig 6 the Î´13c dic varied from 20 1 to 7 6 most of the Î´13c dic values in may were higher than those values in other sampling periods Î´13c dic values in august were between those in february and in may corresponded to high concentrations of dissolved co2 fig 4 3 3 concentrations dissolved ch4 and isotopic ratios of Î´13c ch4 the dissolved ch4 increased along the river and exhibited seasonal variability fig 4 with a range of 0 04 76 Î¼mol l for concentration and 64 137801 for saturation fig 6 at s1 the dissolved ch4 concentrations were low in february may and december which suggested that the wwtp effluent was not the main source of ch4 to the river water the concentrations of dissolved ch4 in surface water during the four sampling periods increased along the river which indicated that ch4 was derived from in situ production in the water column or sediments the dissolved ch4 concentrations were much higher in february and august than in may and december downstream possibly due to hypoxia the Î´13c ch4 values first decreased and then increased quickly upstream in may and december while they first decreased and then remained stable downstream in february and august the fraction of ch4 removed by methane oxidation had a range of 28 78 fig 8 3 4 concentrations and isotopic compositions of dissolved n2o dissolved n2o also showed obvious temporal and spatial variability fig 5 dissolved n2o originated from wwtp at s1 had high variability in february and may the concentrations of dissolved n2o were as high as 1426 18 nmol l and 405 87 nmol l decreasing quickly along the river the dissolved n2o concentration was 75 24 nmol l in december at s1 and increased along the river when the river received water from the reservoir in august the concentration of dissolved n2o was relatively low in the upper stream reached a maximum midstream and then decreased almost all of the measured values were higher than that corresponding to equilibrium with the atmosphere fig 6 suggesting that the river was a source of n2o emission to the atmosphere the values of Î´15nbulk n2o and Î´18o n2o were both enriched along the river ranging from 19 34 to 16 03 and from 50 17 to 82 54 respectively while the sp value decreased when reclaimed water replenished the river fig 5 in august the value of Î´15n n2o had minor change along the river but the sp and Î´18o n2o values showed obvious temporal variation the spatial variation patterns of isotope compositions were quite similar when the river received reclaimed water and were different from those in reservoir water the contribution of nitrification x increased along the river as did the degree of n2o reduction fr when the river received reclaimed water fig 7 however x and fr exhibited large fluctuations when the river received reservoir water the values of x suggested that n2o derived from nitrification dominated in the wwtp in february and may while n2o produced from denitrification were responsible for the remaining n2o surface water along the river n2o was mainly produced from denitrification nitrifier denitrification at the mouth of the estuary in august the high dissolved n2o was mainly produced by nitrification at downstream with unexpectedly elevated nh4 concentrations even under anoxic conditions in the absence of nitrate moreover the large amount of n2o produced in situ could be from entirely different pathways nitrification at s6 in august and denitrification at s9 in december 4 discussion 4 1 dissolved ghg concentrations the dissolved ghg concentrations of global rivers are shown in table 2 our values are on the high end of estimates reported in the literature among different climate regions indicating that urban rivers replenished by reclaimed water are a significant source of ghgs the large contribution of wwtp effluents to the observed high concentrations of n2o and co2 might be surprising the treatment employed in the wwtp reduces the high levels of biological oxygen demand bod nh4 and no3 fulfilling the water quality standards imposed by the government these processes including om respiration combined nitrification denitrification can release large amounts of n2o and co2 to the river via effluent however the effluent that discharge into the urban river did not contribute significantly to the river ch4 levels which is consistent with a previous report sturm et al 2016 due to uncertainties in the gas transfer velocity ghg concentrations were used rather than ghg emissions to compare spatial and temporal patterns across sites the measured dissolved ghgs especially the upper ranges correspond to a large oversaturation of surface water with respect to atmospheric equilibrium leading high fluxes to the atmosphere our observations of n2o concentrations and saturations are comparable with a river that strong influenced by agriculture borges et al 2018a ch4 concentrations are close to the values that reported in a tributary of congo river that is bordered by extensive wetland borges et al 2019 co2 concentrations 355 1 1133 2 Î¼mol l in february may and december are close to tropical rivers i e congo river and urban river i e huangpujiang river borges et al 2019 he et al 2013 but unexpected high in august while the do was extremely low these results indicated that urban river influenced by with various of in river structures are comparable to those in wetlands and intensively agricultural rivers in terms of ghgs emissions 4 2 redox conditions change by in river structures production and consumption processes of ghgs are redox reactions and are often assumed to occur in sediment thus the redox conditions of a system will influence the likely biogeochemical pathway each pathway is regulated differently by environmental factors assuming that the electron donor is organic carbon there is an ideal sequence of redox reactions based on the available energy as put forward from a thermodynamic point of view champ et al 1979 in this sequence organic carbon is decomposed by electron acceptors in the following order o2 nitrate manganese oxide iron oxide sulfate and co2 puckett and cowdery 2002 this sequence coupled with knowledge of the spatial distribution of electron donors may allow the determination of the redox state of a water body and the evaluation of the extent of pollution accordingly many studies have been conducted on the gradient characteristics of biogeochemical processes in groundwater and vertical systems in hyporheic zone bardini et al 2012 reeder et al 2018 there is less research on this redox sequence in water column along rivers presumably as surface water is generally characterized in oxic condition however surface water and suspended sediment could account for biogeochemical processes including respiration and denitrification liu et al 2013 reisinger et al 2016 therefore redox condition of surface water is supposed be more successful in describing spatial variation pattern of ghgs concentration compare to sediment urban rivers are highly altered systems with a variety of forms of infrastructures that change the redox conditions of surface water the influence of dam and aeration device on redox condition of surface water can be examined by variation of doc and electron acceptors in february the do no3 and dissolved co2 concentrations had little change from s1 to s4 suggesting this reach was in the oxic stage from s4 to s8 the do and no3 decreased due to consumption as electron acceptors resulting in an increase of dissolved co2 manganese oxide and iron oxide can be used as electron acceptors to oxidize organic compounds and then release mn and fe into river water therefore their concentrations showed the highest values at s5 and s7 respectively from s8 to s10 the do concentrations were lower than 2 mg l the dissolved co2 decreased and the dissolved ch4 showed a peak at s9 indicating that a methanic stage was formed in august do progressively decreased and the absence of no3 accelerated the development of the methanic stage from s4 to s10 the result suggested that the anoxic condition downstream was caused by the dam at the mouth of the estuary in february and august with aeration device closed in may similar redox conditions were observed to those in february at upstream from s1 to s4 which were characterized by oxic stage however aeration downstream preserved the higher do and no3 inhibited concentration of mn fe nh4 and ch4 in december aeration downstream resulted in a similar spatial distribution of electron acceptors to those in may the result addressed that aeration can maintain oxic condition that slowing the development of the anoxic stage and eliminating the methanic stage at downstream 4 3 identification of the underlying processes of dissolved n2o n2o production and consumption are both strongly microbially mediated microbiological nitrification heterotrophic denitrification and nitrifier denitrification are considered to be three predominant production pathways in rivers thuan et al 2017 quick et al 2019 different n2o production pathways often occur simultaneously and thus it is necessary to distinguish their relative contributions to total n2o for n2o heterotrophic denitrification is favored by elevated nitrate concentrations and sufficient organic carbon under anoxic condition and is commonly regarded as the dominant n2o production pathway liu et al 2013 reisinger et al 2016 nitrification and nitrifier denitrification are favored by higher concentrations of ammonia under oxic and hypoxic condition respectively beaulieu et al 2010 toyoda et al 2017 n2o consumption was more likely occur under condition of low do no3 and high doc nh4 soued et al 2016 borges et al 2019 assumed values of the n2o yield due to nitrification may actually be values corresponding to the n2o yield from nitrifier denitrification because both processes are favored by similar environmental conditions and biological communities nitrifiers beaulieu et al 2011 thus determining which pathway produces the observed n2o would likely require the application of isotopic approaches a decrease of x values along the river showed that denitrification was the dominant process leading to production of dissolved n2o in both oxic and anoxic conditions fig 7 which is consistent with the results of earlier studies lansdown et al 2015 thuan et al 2017 the reclaimed water contains high no3 and doc creating favorable conditions for denitrification by microbes he et al 2013 the reduction of n2o to n2 during heterotrophic denitrification is the only known biological pathway of n2o consumption pauleta et al 2019 the increased of fr values with distance downstream suggested that n2o was consumed by heterotrophic denitrification resulting in a sink of n2o downstream the negative correlation between doc and n2o concentration indicated heterotrophic denitrification not nitrifier denitrification may dominated the denitrification process in this study sp values and Î´18o n2o were used for the quantifying the relative contribution of nitrification and denitrification however this model does not allow the separation of nitrifier denitrification and heterotrophic denitrification because the two processes have very similar isotopic signature values and because mass balance equations would not give a unique solution for three unknowns simultaneously duan et al 2017 the sequence analysis of denitrification functional gene cnorb encoding cytochrome containing nitric oxide no reductase transcripts is therefore recommended to distinguish the relative contributions of nitrifier denitrification and heterotrophic denitrification to n2o production ishii et al 2014 4 4 identification of the underlying processes of dissolved ch4 and co2 ch4 is produced during anaerobic om biodegradation and high ch4 concentrations and fluxes have been found in aquatic ecosystems and water saturated terrestrial ecosystems with anaerobic conditions atkins et al 2017 yu et al 2017 although ch4 should be scarce in streams and rivers because these ecosystems are usually well aerated and thus lack anoxic conditions which required for ch4 production and persistence dam reduce flow velocity trap the sediments and develop anoxic condition to create habitat for methanogenesis maeck et al 2013 stanley et al 2016 ch4 oxidation is the key factor controlling dissolved ch4 concentrations in surface water the ch4 oxidation process can be inhibited by low do and nh4 oxidizing bacteria compete with ch4 oxidizing bacteria for o2 resulting in the accumulation of dissolved ch4 in sediments and water column hu et al 2018 therefore a negative correlation was found between ch4 and do while a positive correlation was found between ch4 and nh4 in this study table 3 thus we observed dissolved ch4 concentration increased significantly at downstream in february and august when the aeration devices were closed the isotopic signature indicated that om biodegradation in sediments or water column contributed to riverine ch4 in anoxic conditions and the elative depletion of Î´13c in ch4 at downstream indicated less of an effect of bacterial oxidation fig 8a aeration changed the redox condition of downstream and enriched the Î´13c ch4 values and enhanced the bacterial oxidation of ch4 which resulting in a limited concentration of ch4 in may and december when aeration devices were open in addition dissolved ch4 concentration ranged from 0 04 to 0 39 Î¼mol l at s1 in february may and december when wwtp effluent charged to the river which is consistent with a previous report of nine wwtp effluent alshboul et al 2016 most of the samples collected from downstream had a higher ch4 value than those at upstream s1 suggested that wwtp effluent was not likely the dominant source of riverine dissolved ch4 co2 supersaturation has been reported for large rivers in boreal temperate and tropical areas bouillon et al 2009 richey et al 2002 aqueous co2 in river systems generally comes from three sources one source is allochthonous i e soil co2 derived from the biodegradation of terrestrial organic matter om or from soil respiration on land the second source is autochthonous and includes co2 produced from the in situ respiration of aqueous om li et al 2018 the third source is the wetland that adjacent to river abril and borges 2019 recently anthropogenic effects such as the discharge of untreated and treated sewage effluent have been identified as major factors that affect both dissolved co2 and dic as well as om in urban rivers hu et al 2018 in this study wwtp effluent contributed large amount dissolved co2 into the urban river at s1 in february may and december Î´13c in dic ranged from 11 0 to 12 89 this value is very close to that found in wwtp effluent in brazil 12 yang et al 2018 and in china 12 2 cotovicz et al 2019 the increase of concentration of dissolved co2 along the river indicated that the autochthonous production of co2 via in situ respiration of aqueous om occurred in the sediments and or water column at downstream due to the dam trapped the sediments that increase the available of om thus the dominant process of respiration could plausibly increase the co2 concentration lowering do and ph as well as depleting Î´13c in dic resulting in the negative correlation between co2 and do and between co2 and ph table 3 although the variation pattern of concentrations of dissolved co2 were similar in february may and however aeration increased co2 degassing from surface water which decreased the co2 concentration and enriched the Î´13c dic values in may fig 8b in august the river water was mainly from upstream reservoir the relative lower do and higher co2 and hco3 concentrations to other sampling periods that indicated the more intense autochthonous production of co2 via in situ respiration of aqueous om however the much higher dissolved co2 that compare to values in other sampling periods at s1 implied that allochthonous co2 from terrestrial inputs transferred by upstream reservoir 5 conclusion various forms of infrastructures influenced the underlying microbial processes by changing the redox conditions of the river resulting in spatiotemporal variations in dissolved ghgs the closure of dam can increase water residence time trap the sediment accelerate oxygen consumption and development of anoxic conditions which can stimulate the production of co2 and ch4 and consumption of n2o aeration device can maintain oxic condition that slowing the development of the anoxic stage and eliminating the methanic stage at downstream the wwtp effluent contribute the river wih high no3 and doc creating favorable conditions for denitrification by microbes isotopic ratio analysis indicated that the dissolved n2o and co2 were derived not only from the wwtp but also from in situ om biodegradation terrestrial inputs can also influence riverine co2 however wwtp effluent was not likely the dominant source of riverine ch4 while the isotopic signature demonstrated that autochthonous om biodegradation in the sediments or water column contributed to riverine ch4 in anoxic conditions the key results demonstrate that the dissolved ghg concentrations in this urban river are at the high end of estimates currently reported in the literature and should be urgently included in the determination of global carbon and nitrogen budgets from rivers these results indicated that urban river influenced by various of in river structures are comparable to those in wetlands and intensively agricultural rivers in terms of dissolved ghgs concentrations credit authorship contribution statement xing li conceptualization methodology software validation investigation formal analysis data curation writing original draft writing review editing huaiying yao resources writing review editing visualization yongxiang yu yingjie cao investigation validation changyuan tang validation writing review editing visualization supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was funded by the natural science foundation of guangdong province china grant no 2017a030310563 
