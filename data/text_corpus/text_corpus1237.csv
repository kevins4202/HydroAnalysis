index,text
6185,depending on the concept of optimality the decision makers responsible for the planning and management of water resources seek to maximize the optimization performance however the optimized solutions are vulnerable to failure because decision making in water resources management usually involves factors with deep uncertainties e g runoff conditions water demand growth climatic forces etc in this study we further contribute to the many objective robust decision making framework for defining the robust operating rules of a water supply system of interest the multi objective optimization and uncertainty analysis tools were used to reveal the trade offs between the competing objectives and discover the sensitive factors for the plausible states of the system respectively the robust operating rules are demonstrated for the han to wei inter basin water transfer project which is the most important water diversion project in shaanxi province china results show that although the current operating rules are optimized for the water supply system over the long term these operating rules cannot deal with the problem of performance degradation under deep uncertainties associated with runoff conditions and water demand growth the two uncertain factors are the sensitive factors responsible for the failure or success of the system and robustness of the system may be achieved by reducing the effect of key uncertainties e g reduced water demand growth furthermore there are obvious differences in the robust operating rules across different months with the key or sensitive months providing the uncertain ranges to likely sustain the success of the system finally the successful frequency of the system derived from the most robust operating rules is 18 higher than that obtained from the current operating rules for alternative states of the world the robust operating rules offer critical insights into the challenges posed by deep uncertainties and provide a management template for decision making on climate change and complex human activities keywords operating rule curve uncertainty analysis sensitivity analysis water supply 1 introduction over the past century a large number of reservoirs and dams have been built for providing water resources flood control and power generation these hydraulic projects establish the water resource base for the development and progress of human society in developed countries the social and ecological costs of dam construction are no longer acceptable since the best reservoirs and dams have already been developed and the degradation in river ecosystems caused by dams has received increasing attention vörösmarty et al 2010 ansar et al 2014 moran et al 2018 zhao et al 2019 as a result the construction of large dams in such countries is largely absent and has been replaced by the question how can the existing reservoirs and dams be managed more effectively for balancing the competing objectives and mitigating the risks associated with uncertainties kasprzyk et al 2012 borgomeo et al 2016 wild et al 2018 in developing countries especially those in south america south asia and africa the development and construction of reservoirs and dams for the future is still at its peak and managing the existing reservoirs and dams while providing a management strategy for future reservoirs and dams is a key concern for the decision makers winemiller et al 2016 sabo et al 2017 latrubesse et al 2017 in water resources system analysis the uncertainties derive from the inability of decision makers to adequately describe the possible states of the world for quantifying the possible risks in the system kasprzyk et al 2012 huang et al 2016 furthermore water resources management which is affected by the increase in the uncertainty as a result of climate change and human activities has become a risk based decision making process morgan and mellon 2011 brown et al 2015 guo et al 2019 such management has become necessary for sustainable development of human society optimal operation of reservoirs provides a feasible way to reduce the cost and risk associated with reservoir management and balance the beneficial relationship between the competing objectives fayaed et al 2013 giuliani et al 2014 despite the progress in the use of system engineering theory and complex non linear optimization algorithms in reservoir operation most of these methods remain theoretical and are rarely used in practical application maier et al 2014 the gap between theoretical research and practical application of reservoir optimization operation is obvious which is why it is difficult for decision makers to use the results of optimization as a guide in practical operation labadie 2004 brown et al 2015 on the one hand because the complexity of the optimization operation model makes it hard for decision makers to understand deeply its principle and usage conditions it is difficult to devise a reasonable management strategy in practice which is directly employable on the other hand the root cause of the gap is that most of the optimal operation processes are modelled with deterministic runoff sequences which indicate that all the information observed historical information is known beforehand during the operation period however in practical reservoir operation the future runoff information is completely unknown and cannot be accurately predicted herman et al 2015 borgomeo et al 2018 as a result an operation strategy based on historical information is not available owing to the uncertainty in runoff and other factors e g water demand growth and precipitation variability furthermore in the context of climate change the stationarity of runoff series has been destroyed which has led to more severe challenges in devising operation strategies based on historical information milly et al 2015 at present most reservoirs are operated according to the operation rule curves as part of actual management you and cai 2008 the traditional operation rule curves can be identified according to the basic storage relationship of a reservoir in recent years the parameter simulation optimization approach has offered the possibility of better guidance of reservoir operation dariane and momtahen 2009 the most representative of the parameter simulation optimization methods is the evolutionary multi objective direct policy search emodps which combines direct policy search nonlinear approximating network and multi objective evolutionary algorithm to define pareto approximate operating rules for multi purpose reservoir operation giuliani et al 2015a b emodps is used to improve water reservoir operation through direct use of the hydro meteorological data e g snow water equivalent cumulative inflow and enso state denaro et al 2017 libisch lehner et al 2019 to mitigate the gap between the theoretical research and practical application of reservoir optimization operation the parameter simulation optimization approach will become the focus of future research although the methods based on making the most of data can better determine the reservoir operation strategy they are still affected by the uncertainties in decision making process giuliani et al 2015b in the context of uncertainty decision makers are aiming at realizing multiple performance objectives in water resources management along with ensuring that the differences between the expected and actual performances are minimized in the possible future states kasprzyk et al 2012 bhave et al 2018 based on these goals robustness is most widely defined as the insensitivity of the system design to errors random or otherwise in the estimates of those parameters affecting design choice matalas and fiering 1977 although the specific approach is different when applying this concept decision makers seek alternative strategies for water resources systems to minimize the possibility of an undesirable outcome across future states these alternatives have been advocated by frameworks recently developed for decision making under uncertainties including decision scaling brown et al 2012 robust decision making lempert 2002 information gap ben haim 2004 and many objective robust decision making morod kasprzyk et al 2013 these frameworks should be applied to reservoir operation to assess whether the existing operation rules are suitable for uncertain scenarios and to clarify whether they are robust in the expected future states of the world herman et al 2015 furthermore existing water projects often involve multiple tasks e g flood control water supply power generation etc and the performances objectives of multistakeholder in reservoir management are different according to their preference labadie 2004 reed et al 2013 jiang et al 2019 to use the existing water related infrastructures more efficiently and equitably multi objective decision making should be employed to coordinate the conflicting relationships between multiple stakeholders this coordination is reflected in the achievement of a pareto trade off solution across multiple water utilities therefore this study focuses on the gap between the reservoir optimal operation and practical application and analyzes the multi objective characteristic of reservoir operation to mitigate the performance conflicts based on above mentioned considerations we further contribute to the morod framework and define the robust operation rule for multi purpose water reservoir under deep uncertainties for achieving these objectives this study evaluated a water supply system and explored the ability of the robust operating rule to deal with deep uncertainties of the water resources system for future planning 2020 2030 the han to wei inter basin water transfer ibwt project which is a water supply system located in shaanxi province of china was selected for a case study to reveal the drawback of the current operating rule under deep uncertainties the pre optimized operating rules derived by ming et al 2017 were evaluated through inputting the uncertainty factors into the simulation model a multi objective reservoir optimization model based on the mordm approach was established to identify the robust operating rule of the water reservoir of interest moreover the scenario and the sensitivity of the solutions of the operation model were analyzed by patient rule induction method prim finally the robust operating rule of the water supply reservoir was defined by combined analysis of the tradeoffs and sensitivity in multi objective space this study establishes the robust operating rule for reservoir operation in practical application which can better address the performance degradation of water resources system under deep uncertainties 2 study area and pre optimized operating rules 2 1 the han to wei ibwt project the han river the largest tributary of the yangtze river is located in the subtropical monsoon region of southern china the han river basin covers an area of 159 000 km2 and receives an average annual precipitation of 800 1200 mm the abundant rainfall in this basin produces an average annual natural runoff of 56 billion m3 most of which occurs during the flood season from may to october the runoff also varies greatly from year to year with cv values of 0 3 0 5 and the maximum annual runoff is 4 times larger than the minimum annual runoff fig 1 c from the han river basin to the north through the qinling mountains the north south boundary of china the study area reaches the wei river basin which is located in the transitional region between a semi humid region and an arid region the wei river basin covers an area of 134 766 km2 and receives an average annual precipitation of 500 800 mm the rainfall of wei river is unevenly distributed across the year with the maximum occurring in july to october the rainfall of this basin produces an average annual natural runoff of 10 4 billion m3 which is the basis of the water resources of 76 major cities with a total population of 22 million in the guanzhong plain which are used for domestic living industry and irrigation with the increasing impact of climate change and human activities huang et al 2014 2017 the water resources of the wei river basin are not sufficient to support sustainable socio economic development of the guanzhong plain furthermore the increased water stress of the wei river basin reflects a broader difference between the north and south of china liu et al 2018 huang et al 2019 fang et al 2019 although the han river has been selected as the water source i e the danjaingkou reservoir for the south to north water transfer project a new project the han to wei ibwt project for water transfer from the southern to the northern region is planned which is expected to solve the increasingly serious problem of water shortage in the guanzhong plain fig 1a the water transfer system of the ibwt project is located in the upper reaches of the han river basin fig 1b and contains two reservoirs the hunagjinxia reservoir and the sanhekou reservoir and related water supply facilities hydropower stations pumping stations and pipelines these two reservoirs are the core components of the water transfer project and are mainly used to store water for reducing the temporal deviation in the water supply the huangjinxia reservoir a run of river reservoir is located in the upper reaches of the han river it raises the water level so that the pumping station can supply water more easily the sanhekou reservoir is a multi year regulation reservoir which is located in the tributary the ziwu river of the han river if there is excess water in the water supply process this water will be stored in the reservoir for supply during the dry period the electrical energy consumed by the pumping stations of this project during the water supply process is mainly provided by the huangjinxia and sanhekou hydropower stations the more the water diverted the more is the electricity consumed therefore the main competing objectives of the project are the reliability of water supply and the net electricity generation of the hydropower stations the project aims to reduce water shortages in the guanzhong plain and it is planned to diverted 1000 million m3 to the wei river basin in 2025 increasing to 1500 million m3 in 2030 the diverted water resources are mainly used to supply 22 users including meeting domestic and industrial demands ren et al 2019 furthermore these volumes of diverted water are not defined arbitrarily and are based on water supply and demand analysis of the benefited areas in the wei river basin over the planning horizon this analysis takes into account the growth of industrial agricultural domestic ecological and reused or discharged water to pre determine the thresholds of water supply 2 2 pre optimized operating rules of the ibwt project reservoir operation usually involves the realization of multiple objectives including flood control drought management water supply and hydropower generation for rational utilization of a reservoir reservoir operating rules are used to determine when and how to operate the reservoir for storage and release over various runoff conditions at the planning stage of a reservoir the standard operating rule curves are designed to guide the relationship between storage and release however these rule curves may not be applicable in practice especially when drought occurs and should be modified or refined herman et al 2014 considering the shortcomings of the standard operating rule curves for the ibwt project optimized operating rule curves which are based on a multi objective optimization model were developed by ming et al 2017 fig 2 for different annual water demands the optimized operating rule curves inherit the characteristic curves of the standard operating policy and contain one water transfer rule curve and two hedging rule curves as shown in fig 2 the active storage of the sanhekou reservoir is divided into different operating zones by the different rule curves in zone ⅰ when the water level of the sanhekou reservoir is above the water transfer rule curve the water demand is fully satisfied by the sanhekou reservoir and the pumping station of the hunagjinxia reservoir does not operate in zone ⅱ the huangjinxia reservoir is preferred for meeting the water demand and the available water is transported to the node fig 1b through the hunagjinxia pumping station if the water demand is greater than the amount of diverted water the deficit water will be compensated for by the sanhekou reservoir furthermore if the demand is less than the amount of diverted water the sanhekou pumping station will operate to pump the excess water into the sanhekou reservoir for storage the water supply for industry and domestic living is not hedged in this zone in zones iii and ⅳ the basic relationship between the water supply and demand is similar to that in zone ⅱ however the water supply for the industry is hedged in zone iii whereas that for both industry and domestic living is hedged in zone ⅳ the rationing factor of the water supply for industry and domestic living is 0 9 these pre optimized operating rules are based on the long term historical runoff data obtained from the changjiang water resources commission for the period 1954 to 2010 and the water demand of the recipient basin is fixed at two standards of 1000 and 1500 million m3 per year however the planning horizon of water supply for this project is 10 years 2020 2030 therefore focusing on the runoff conditions over the 10 year window period is more important to the operation of the project as shown in fig 1c the three 10 year runoffs display low middle and high conditions and the differences between these runoff conditions may be more pronounced in the future owing to the destruction of the runoff stationary as a result of climate change and human activities furthermore the regional water demand is unlikely to remain fixed in the near future therefore this optimization falls far short of the goal of practical application when decision makers deal with the deep uncertainties in the input information of the system in this study the uncertainty factors listed in table1 were considered based on rigorous uncertainty analysis of a previous work which considered 13 uncertainty factors herman et al 2014 2 3 sampling uncertainty and testing the pre optimized operating rules in this section the possible runoff conditions were sampled with historical runoff data by the latin hypercube sampling lhs method and the uncertain set of water demand growth was established through the scaling factors these uncertainties include two components the uncertainties of runoff and water demand making up the plausible future states of the world which are used to test the pre optimized operating rules 2 3 1 sampling uncertainty the deep uncertainties mainly result from the incorrect or inaccurate projection of the future states of the world therefore decision making based on the status quo or expected future states of the world may fail to account for the risks associated with these uncertainties although accurate predictions of future states of the world cannot be made alternative decision making options can be provided by tracing the probability distributions of the input parameters to the model output these input parameters of the model are the deeply uncertain exogenous factors e g future runoff conditions water demand population growth etc which can be sampled to create an uncertainty ensemble each ensemble member represents a set of exogenous factors for a state of the world in which the future condition has been determined in this current study runoff conditions and future water demand are considered as the typical uncertain exogenous factors in order to correlate the optimization model output with the planned horizon of the project the operation period is set to 10 years 2020 2030 as shown in fig 1c the runoff conditions over the 10 year windows show significant differences which indicate whether samples were taken from a specific window or from the full sequence which may not fully represent the possible runoff conditions in the future therefore the runoff uncertainty ensemble was sampled from three 10 year runoff windows including high middle and low windows through the lhs method fig 3 a b the sampled runoff sequences increased the frequency and magnitude of the extreme values however the sampling is based on a mathematical algorithm with the historical distributions of the runoffs the magnitude of the extreme value of some sampled runoff sequences may be unreasonable and can be much larger than that of the historical runoffs therefore multipliers i e the upper bound of 1 2 and the lower bound of 0 8 in table 1 are used to limit the range of extreme values and further select the sampled runoff sequences another uncertainty ensemble which needs to be sampled is the future water demand which is determined by the capacity of the ibwt project this uncertainty ensemble was sampled by setting the upper and lower scaling factors of the uncertain dimension as shown in fig 3c the blue line represents the current baseline demand projection whereas the projected uncertain range of demand growth is colored according to the values of the scaling factors 2 3 2 testing of the pre optimized operating rules although the pre optimized operating rules were proposed from an optimization model the inputs of this model were the deterministic historical runoff data and the water demand was fixed to 1000 and 1500 million m3 per year over the operation years respectively therefore when both runoff conditions and water demand are uncertain ensembles the pre optimized operating rules are tested for whether they meet the performance requirements of the stokeholds as mentioned in section 3 2 four performance metrics were considered along with the corresponding threshold values the uncertain ensembles are inputted to the simulation model and based on the pre optimized operating rules these performance metrics can be calculated if all the metrics satisfy the requirements of the stokeholds the water supply system will be in successful states otherwise it is in failed states fig 4 shows the operational consequences of the pre optimized operating rules for 1000 fig 4a and 1500 million m3 per year fig 4b the green points represent the solutions which successfully meet the requirements in the alternative states of the world whereas the magenta points represent the states of the water supply system in which the solutions fail in this regard the plotted inflow and water demand factors show a clear separation between the alternative states of the world where the consequences of the solutions are successful and failed this result indicates that both the uncertain factors are sensitive factors and the increased water demand and decreased runoffs would prompt the water supply system towards the failed states and vice versa furthermore herman et al 2014 considered a 13 dimensional uncertainty space of an urban water supply case study and revealed that the factors of inflows and demand growth are the most sensitive factors and that the other uncertain factors e g evaporation water supply allocation consumer reductions etc do not provide additional information on whether the system succeeds or fails as shown in fig 4a the successful states of the system are 40 of all the states of the world by contrast the proportion of the successful states of the system reported in fig 4b is large than 70 this result indicates that choosing different operating rules has a significant impact on the state of the system under deep uncertainties which will confuse decision makers in their decision making if the inflow conditions and water demand are specific e g inflow condition of a dry year and a water demand of 800 million m3 per year there may not be a reasonable operating rule which can be selected therefore for defining the robust operating rules a framework for robust decision making is presented in following sections 3 methodology in this section the methods for defining the robust operating rule are presented by formulating the multi objective optimization model and application furthermore the robustness measures of solutions and prim for scenario discovery and sensitivity analysis are also introduced in detail by specifying them in this study 3 1 problem formulation 3 1 1 optimization operation model as mentioned above the competing objectives of the ibwt project are the reliability of water supply and the energy generation of the two reservoirs therefore this study established a multi objective optimization operation model which aimed to minimize the water shortage index of water supply and maximize the net revenue of the hydropower generation the ecological environmental objective is considered as a constraint a fixed eco flow constraint in the optimization model the two objectives are formulated as follow objective one minimize the water shortage index 1 min w s i 1 t t 1 t max w t d w t s 0 w t d 100 where wsi is the water shortage index unitless t is the total number of operation periods tth month w t d is the total water demand of the users at the node m3 w t s is the actual water supply to the users m3 objective two maximize the net revenue 2 max n r 12 t i 1 2 t 1 t e 1 n i t e 2 p i t 10 8 δ t 3 n i t g λ i q i t h i t 4 p i t g q i t h i t η i where nr is the net revenue yuan i 1 denotes the hunagjinxia reservoir i 2 denotes the sanhekou reservoir e 1 is the feed in tariff which is set as 0 3 yuan kwh e 2 is the electricity price which is set as 0 5 yuan kwh n i t is the power generation of the hydropower plants kw p i t is the electrical consumption of the pumping stations kw δ t is the duration of the time step h λ i is the coefficient of the hydropower stations unitless q i t is the discharge for power generation m 3 s 1 h i t is the hydraulic head for the power generation m g is the gravitational acceleration 9 81 nkg 1 q i t is the rate of water supply m 3 s 1 h i t is the delivery head for water supply m η i is the coefficient of the pumping stations unitless in this study the hydraulic head of the huangjinxia hydropower station is considered as a constant over the long term operation period because the huangjinxia reservoir is a run of river reservoir the constraints of the optimization operation model are the physical and operational constraints which include mass balance water diversion capacity operating rule curves and power output capacity the details of the constraints of the optimization model can be found in the paper by ming et al 2017 3 1 2 parameterization simulation optimization approach the decision variable of the traditional reservoir optimization model is the storage capacity of the reservoir which can be iteratively optimized through optimization algorithms e g evolutionary algorithms clarkin et al 2018 in this study we consider direct optimization of the operating rule curves which should be parameterized first the parameters i e the decision variables used to represent the operating rule curves are the water levels of the reservoir in different months there are three operating rule curves which should be optimized and each curve includes 12 months covering the annual operation period in order to reduce the variability of the rule curves and the time taken for optimization the rule curves are classified into four operation periods for one year according to the hydrological conditions these operation periods are the pre flood season from january to march main flood season from april to june post flood season from july to october and dry season november and december each sub operation period is represented using the same parameter so that each operation rule curve can be optimized with four parameters therefore although there are three curves 36 parameters which need to be optimized the optimization parameters are reduced to 12 through this classification in the initial step these parameters can be randomly generated along with the search range and then decision makers operate the water supply system according to the pre parametric rule curves to simulate the results of water supply and power generation finally the optimization algorithm is used to iteratively improve the results by evaluating the two objective functions and fitness value in this study the cuckoo search cs algorithm was used to optimize these parameters the cs algorithm which is an evolutionary algorithm inspired from the obligate brood parasitic behavior of some birds was established by the yang and deb 2010 the cs algorithm further improves the search efficiency by using the lévy flight process which has been demonstrated by previous studies to solve the non linear and highly complexity optimization problems yang and deb 2013 ming et al 2017 2018 3 2 robustness measures of the solutions using the multi objective evolutionary algorithm many sets of pareto approximate non dominated solutions can be obtained under many plausible states of the world the robust solution which is a solution that provides improved performance across as many states of the world as possible will be more easily accepted by decision makers robustness measures of solutions can be used to quantify and rank which one is the most robust solution of these sets of pareto approximate solutions however a previous study has shown that selecting different robustness measures will significantly affect the selection of the robust solution giuliani and castelletti 2016 therefore for selecting the robust solution reasonably one regret based measure and two satisficing based measures were considered in this research they were identified by lempert and collins 2007 and further discussed by herman et al 2015 the regret based measure r quantifies the performance deviation d i of an objective between the current state of the world and the baseline state of the world this measure is maximized as follows 5 r max i d i 90 p d i d i 90 0 90 6 d i j f x i j f x i f x i where f x i denotes the value of objective i in the baseline state of the world f x i j denotes the value of objective i determined in the current state of the world j d i j is the performance deviation of a solution between the current state of the world and the baseline state of the world d i 90 is 90th percentile performance deviation the first satisficing based measure s1 is defined as the fraction of n states of the world in which the performance requirements of decision makers are satisfied by a solution in one or more objectives 7 s 1 1 n j 1 n λ s j where if solution s meets the requirements in the state of the world j λ s j 1 and λ s j 0 otherwise the most important feature of this measure is that it incorporates the performance requirements of multiple stakeholders in this case study although the objectives of the optimization pertain to the water shortage index of the water supply and the net benefits of the hydropower generation the reliability of the water supply hashimoto et al 1982 and minimum water supply index are also considered to strictly influence the selection of the solutions therefore the requirements of water shortage index less than 0 5 net benefits above 0 reliability above 95 and minimum water supply index above 70 are considered in this study the second satisficing based measure s2 is defined as the uncertainty horizon over which the system can withstand failures this measure is derived from the info gap approach and can be formulated as 8 s 2 α max α min j u α f x j r where α is the maximum uncertainty horizon which can be accepted without performance falling below r in this study the reliability of the water supply was used to calculate s2 and the threshold value r is 0 95 3 3 scenario discovery and sensitivity analysis with prim the main purpose of using scenario discovery in water resource system analysis is to identify the regular patterns in the system which can be used to interpret and predict its characteristics bryant and lempert 2010 kasprzyk et al 2012 generally a water resources system involves a lot of input parameters to control its output and there are differences in the contributions of different parameters to the output these differences can be identified through sensitivity analysis scenario discovery and sensitivity analysis are important for decision making in analytic applications involving water resource systems under deep uncertainties because the deterministic patterns or information can be obtained from the uncertainties this information or patterns will be useful to decision makers for reducing the complexity in decision making these two methods are based on statistical or data mining algorithms and fortunately prim can be used to accomplish both tasks at the same time the following section begins with an introduction of the several core concepts applied in this method in previous work bryant and lempert 2010 the regions of input parameters space are characterized as multi dimensional boxes through a specific algorithm an individual box which is constrained by partial input parameters is called a scenario and a set of boxes is interpreted as a set of scenarios the scenario discovery applied here is to seek a box or a set of boxes which exhibits the maximum explanatory power for input relevant cases according to previous studies bryant and lempert 2010 kasprzyk et al 2012 herman et al 2014 there are three reasonable measures of quality for the purpose of scenario discovery that is density coverage and interpretability in order to provide useful information in decision making a selected box should capture as many proportions as possible of the total number of input relevant cases high coverage capture primarily input relevant cases high density and display high interpretability for decision making coverage is the ratio of the total number of input relevant cases xi in scenario b to the total number of input relevant cases x which can be formulated as follows 9 coverage x i b y i x i x y i where y i 1 if xi b and y i 0 otherwise density is the ratio of the total number of input relevant cases xi in a scenario b to the total number of cases x in the scenario 10 density x i b y i x b 1 the measure of interpretability is highly subjective because it requires decision makers to select a specific scenario which is based on the characteristics of the problem generally these measures are conflicting therefore the ideal set of scenarios high coverage high density and high interpretability is not observed for a given dataset these three measures generally define a multi dimensional efficiency frontier therefore prim is used to generate alternative scenarios at different points of the frontier and then users choose the most reasonable scenario based on the preferences of the decision makers the prim is a bump hunting algorithm which was proposed by friedman and fisher 1999 the algorithm presents decision makers with a visualization of the peeling trajectory by plotting the density of each box against its coverage scenario discovery can be easily achieved using this method through the r toolkit which is available at http cran r project org web packages sdtoolkit index html for more details on this method the reader can refer to the report of bryant and lempert 2010 4 results and discussion our framework for defining the robust operating rule which depends on the mordm approach is shown in fig 5 sections 4 1 4 3 detail the results and demonstrate this framework by using the han to wei ibwt project test case 4 1 selecting the robust solution across the alternative states of the world each solution across the alternative states of the world can be calculated using the parameterization simulation optimization approach described in section 3 1 although the runoff uncertain ensemble has been sampled in section 2 3 1 this ensemble is only used to test the reasonability of the operating rules since the water supply system considered in this study has two water sources namely the hunagjinxia reservoir and the sanhekou reservoir the positive correlation between their monthly inflows is significant fig 6 reasonable runoff conditions of these two water sources should consider their synchronous and asynchronous encounter situations however this problem is beyond the consideration of this study the sampled runoff uncertain ensemble regenerated the relationships of magnitude and frequency between the two water sources and ignores this problem therefore this ensemble may only be used to test the operating rules rather than to identify the robust operating rules keeping these points in mind only the historical runoff combination of the two sources is reasonable for establishing the alternative runoff conditions the 57 year 1954 2010 runoff time series used to define the pre optimized operating rules was split into shorter 10 year durations for each of the two water sources two adjacent runoff durations maintained a one year lag and the total of 57 years of runoff could be divided into 47 runoff durations these established runoff conditions and the uncertain ensemble of water demand growth identified in section 2 3 1 are used to define the robust operating rules fig 7 shows the cumulative distributions of the four performance metrics across the alternative states of the world and those calculated by the parameterization simulation optimization approach each line represents a solution across the alternative states of the world the pareto approximate solutions calculated through multi objective optimization are shown as dark green lines the robust solutions which are selected through the robustness measures are indicated in blue red and green lines the performance requirements of the stakeholders are represented as black vertical lines several salient features can be observed in fig 7 first although the set of pareto approximate solutions provides options for decision makers to improve the quality of alternative decisions these solutions do not reduce the risk of performance loss when the system is across the alternative states of the world i e the deep uncertainties in the space of the deep uncertainties the proportions of the performance metrics for the system in the successful states are 50 50 42 and 30 respectively this result indicates that multiple uncertain factors exhibit a significant impact on the performance of the system and that robustness of the system may be achieved by reducing the effect of the key uncertainties herman et al 2015 see the solid circle in fig 4 second as demonstrated by herman et al 2015 different robustness measures reveal significantly different ranking for the solutions in this study although the robust solutions identified based on the robustness metrics show differences in the rankings these solutions are concentrated in the performance frontiers this result facilitates the selection of the most robust solutions fig 8 shows the parallel axis plots of the most robust solutions obtained according to the robustness measures the values of these performance metrics are normalized between their minimum and maximum values so that these metrics can be plotted on a common axis each line represents a solution at the corresponding performance values for a specific state of the world the ideal solutions are represented as red lines which correspond to the minimum water demand growth and positive runoff conditions fig 8 shows clear conflicts or trade offs especially when seeking to minimize the water shortage index or maximize the net revenue the attainment of a low water shortage for the water supply in the ibwt project is in conflict with the sustenance of a positive net revenue the net revenue is more sensitive across the alternative states of the world than over the pareto approximate sets fig 7 indicating that water demand and supply is the key factors determining the performance of the ibwt project finally the most robust solutions according to the robustness measures show similar patterns of the performances for brevity we chose the robust solution derived from regret based measure r for further analysis fig 9 shows the box plots of the robust operating rule according to the robustness measure r for clarity the water transfer rule curves and the hedging rule curves for industry and domestic living are plotted in subgraphs which are represented as high middle and low curves respectively the high curves are distributed between the upper and lower limits of the reservoir s storage capacity especially the operation rule of the wet season e g july and august which is distributed over a wider range compared to that of another season the middle and low curves are distributed over a narrow range however the rule curves of the dry season e g november and december are distributed between the upper and lower limits this result indicates that there are key months for the operating rules and the reasonability of the operating rules may determine the performance of the system over the entire operation period 4 2 scenario discovery and sensitivity analysis there are differences in the response sensitivity of the output of a system to the input parameters of the system and the purpose of identifying these differences is to find out the key factors affecting the performance of the system as shown in fig 4 both the uncertainties of inflow conditions and water demand growth are responsible for the vulnerabilities of the system however this result derived from the pre optimized operating rules was evaluated by a qualitative and visual sensitivity analysis based on the results of multi objective optimization sensitivity analysis can be strengthened by using a formal and quantitative method prim therefore this section first discovered the scenarios and analyzed the most sensitive uncertain factors and then explored the relationships between the optimized operating rule curves and the system performance first the inputs of the prim method require that each runoff condition should be represented by a value and that the magnitude of the runoff conditions should be equal to the magnitude of each performance metric however each runoff condition is a long term time series which is difficult to represent by a fixed value therefore for rationality we chose a series of characteristic values e g maximum and minimum values mean and median values standard deviation skew coefficient variation coefficient interquartile range etc which represent the overall conditions of runoff as the input variables of this method the water demand increases strictly no matter which characteristic value can represent its overall state fig 10 shows the ranges of the sensitive factors identified by prim which are likely to produce a particular outcome the x axis is normalized with the corresponding maximum and minimum values of the sensitive factors for water demand shortage the inflow of the huangjinxia reservoir and the water demand growth are identified by the method as the sensitive factors which suggests that a maximum value of the inflow greater than 1051 m 3 s 1 and an average water demand less than 111 million m3 per year will most likely ensure success of the system furthermore for the net revenue of hydropower generation the inflows of the huangjinxia and sanhekou reservoirs and the water demand growth are identified by the method as the sensitive factors maximum values of the inflows of the two reservoirs greater than 1529 and 214 m 3 s 1 respectively and an average water demand less than 67 million m3 per year will most likely ensure the success of the system second figs 11 and 12 provide the detailed results of the discovered scenarios from the optimized operating rules to the system performance fig 11 shows the overall metrics of quality of the selected scenarios as observed most of the values of density and coverage are greater than 0 9 therefore they provide high confidence levels for the selected scenarios the competitive relationships between them are well balanced especially for the high rule curves which are stronger than the middle or low rule curves however in fig 11b and c some lower values of density are observed which indicate that the discovered scenario may not accurately describe the input output relations of the system in the middle and low hedging curves furthermore scenario discovery of the middle and low operating rule curves is more difficult than that of the high operating rule curves fig 12 shows the most sensitive operation months based on the robust operating rules for the selected scenarios of fig 11 for the success of the system the key water levels of the sensitive months which need to be controlled are displayed above on green bars and the corresponding values of density and coverage are shown in the right tables for water demand shortage the sensitive operation months are the january april and july of the high rule curves the april july and november of the middle rule curves and the january of the low rule curves furthermore for the net revenue of hydropower generation the sensitive operation months are the july and november of the high rule curves the november of the middle rule curves and the july and november of the low rule curves these results indicate that when the water levels of the reservoir are above the threshold values of the high rule curves the available water resources of the sanhekou reservoir are sufficient to meet the water demand without the need for supply from the huangjinxia reservoir the high rule curves are in the higher position and the moments when water supply is hedged occur earlier this strategy ensures minimum water shortage for long term water supply the sensitive months of the middle rule curves are in the wet season and the middle rule curves are distributed over wide ranges therefore the inflows of the two reservoirs are sufficient for water supply furthermore when the water levels are below the low rule curves both the water supply for industry and domestic living are hedged which suggest that the water demand cannot be meet indefinitely finally for the net revenue of hydropower generation the lower position of the high rule curves the smaller is the power consumed in pumping water this strategy ensures that positive net revenue can be realized the sensitive months of the middle and low rule curves are in the wet season and the available water resources are sufficient therefore their reasonable operating curves should depend on the specific conditions of runoff and water demand 4 3 defining the robust operating rule in this section the key question raised in the introduction section is answered that is how can the robust operating rule be defined for a water supply reservoir under deep uncertainties first the uncertain ensembles sampled in section 2 3 were used to test the optimized operating rules which were selected according to the robustness measures of solutions section 4 1 second based on the performance requirements of the stakeholders the performance calculated from the optimized operating rules was compared with that derived from the pre optimized operating rules to choose the best performing solutions fig 13 presents the results of the best performing solutions and shows the performance space of the maximum success frequency as shown in fig 13a the positions of the operating rule curves are ranked according to the values of the successful frequency this result is consistent with the findings reported in section 4 2 that is the high rule curves are in the higher position the moments when the water supply is hedged occur earlier and the water demand is easier to meet the green line shows the water transfer rule curve of pre optimization which is located in higher positions in the dry seasons and in lower positions in the wet seasons this rule curve hedges the water supply later in the dry seasons and earlier in the wet seasons compared to the robust rule curves which indicate that the water supply during the year is not properly allocated when the system experiences the deep uncertainties fig 13b and c show the middle and low rule curves which are compared with the pre optimized operating rule curves although the positional ranks of these rule curves are not related to the successful frequency the rule curves of the maximum successful frequency are located in lower positions furthermore these results are consistent with that shown in fig 9 there are more outlier values in the middle and low curves which result to the scenarios cannot be accurately discovered in these curves compared with the pre optimized operating rule curves the robust operating rule curves delay the moments of restricted water supply and expand the operational range of the water level which are significant for ensuring the performance of the system as shown in fig 13d the successful proportion of the performance space is significantly larger than that derived from the pre optimized operating rules fig 4b the maximum frequency of success is about 0 88 which is more than the original successful frequency of roughly 0 18 finally when the runoff conditions are in the high range the system is always in the successful states indicating that this strategy is a better way of achieving the desired performance of the system than the original operating rules under deep uncertainties the robust operating rule curves highlight the important role of robustness analysis in identifying the key sources of uncertainties while providing the available operating rules for practical applications giuliani et al 2014 although precise prediction of future water demand growth and runoff conditions is lacking we demonstrate that the robust operating rule can mitigate the gap between optimization operation and actual reservoir operation this mitigation is based on the operating rule used in practical reservoir operation which is optimized by combining the optimization algorithm e g multi objective evolutionary algorithms with parameterization simulation optimization approach furthermore the framework we proposed for identifying the robust operating rule balances the competing objectives and integrates the modern analysis tools for water resource systems under deep uncertainties 5 conclusion the deep uncertainties derived from climate variability and human activities will challenge water resources management in the coming decades this requires advancing the optimization model for complex water resource systems in order to obtain the robust operating rules for an uncertain world this study contributes to the parameterization simulation optimization framework for defining the robust operating rules of water resource systems for the alternative states of the world based on the mordm framework and multi objective optimization for better capturing the uncertain factors and their interactions with the water supply system in order to evaluate the performance of the system the operating rule is parameterized according to the parameters of the operation rule curves which were simulated for the actual operation process and optimized using the evolutionary algorithms the application to the case study of the han to wei ibwt project allows evaluating the different uncertain factors to identify the robust operating rules for improving the current operating rules the current operating rule for a water resource system may not address the challenges of the deep uncertainties the hedging rule curves derived from the parameterization simulation optimization framework provide a feasible way to reduce the gap between actual operation and optimizing operation results show that the hedging rules are more robust and effective than the pre optimized operating rules the successful frequency of the case system based on the hedging rules is 18 higher than that of the pre optimized operating rules for the plausible future states of the world the hedging rules used in the actual operation process only require the input information of the current operation period therefore they are more operable for decision makers moreover according to sensitivity analysis and scenario discovery approach the inflow conditions and water demand growth are the sensitive factors governing the success or failure of the system robustness of a system may be achieved by reducing the effect of key uncertainties e g reduced the water demand growth for optimized rule curves there are differences in the sensitive months of the water transfer rule curves and the hedging rule curves the several ranges of the sensitive factors which are likely to produce a particular outcome are identified finally compared with the pre optimized operating rules the robust operating rules provide a range of operation spaces for better addressing the challenges posed by the deep uncertainty the framework proposed in this study can provide alternative management strategies for decision makers when the risk sources are broad or the performance requirements of stakeholders are different this framework is more robust in resolving risk escalation and performance degradation than the traditional operation strategies with the increasing impact of climate change and human activities on water resource systems the management of water resources will involve paying more attention to robust solutions instead of optimality under deep uncertainties herman et al 2014 the root cause of uncertainty is the inability to accurately predict the future state of the world therefore the range of alternative states of the world should be appropriately constrained for improving the credibility of decision making and reducing the computational expense the approach of making the most of data can be integrated into the parameterization simulation optimization framework to better define the robust operating rules and improve the ability to integrate the concept of deep uncertainty into optimization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we sincerely appreciate the editor and four anonymous reviewers for their helpful and constructive comments this research is jointly funded by the national natural science foundation of china 51879213 and 51709221 the national key research and development program of china 2017yfc0405900 the planning project of science and technology of water resources of shaanxi 2017slkj 16 and 2017slkj 19 the key laboratory research projects of the education department of shaanxi province 17js104 the open research fund of state key laboratory of simulation and regulation of water cycle in river basin china institute of water resources and hydropower research iwhr skl kf201803 and the belt and road special foundation of the state key laboratory of hydrology water resources and hydraulic engineering 2018490711 
6185,depending on the concept of optimality the decision makers responsible for the planning and management of water resources seek to maximize the optimization performance however the optimized solutions are vulnerable to failure because decision making in water resources management usually involves factors with deep uncertainties e g runoff conditions water demand growth climatic forces etc in this study we further contribute to the many objective robust decision making framework for defining the robust operating rules of a water supply system of interest the multi objective optimization and uncertainty analysis tools were used to reveal the trade offs between the competing objectives and discover the sensitive factors for the plausible states of the system respectively the robust operating rules are demonstrated for the han to wei inter basin water transfer project which is the most important water diversion project in shaanxi province china results show that although the current operating rules are optimized for the water supply system over the long term these operating rules cannot deal with the problem of performance degradation under deep uncertainties associated with runoff conditions and water demand growth the two uncertain factors are the sensitive factors responsible for the failure or success of the system and robustness of the system may be achieved by reducing the effect of key uncertainties e g reduced water demand growth furthermore there are obvious differences in the robust operating rules across different months with the key or sensitive months providing the uncertain ranges to likely sustain the success of the system finally the successful frequency of the system derived from the most robust operating rules is 18 higher than that obtained from the current operating rules for alternative states of the world the robust operating rules offer critical insights into the challenges posed by deep uncertainties and provide a management template for decision making on climate change and complex human activities keywords operating rule curve uncertainty analysis sensitivity analysis water supply 1 introduction over the past century a large number of reservoirs and dams have been built for providing water resources flood control and power generation these hydraulic projects establish the water resource base for the development and progress of human society in developed countries the social and ecological costs of dam construction are no longer acceptable since the best reservoirs and dams have already been developed and the degradation in river ecosystems caused by dams has received increasing attention vörösmarty et al 2010 ansar et al 2014 moran et al 2018 zhao et al 2019 as a result the construction of large dams in such countries is largely absent and has been replaced by the question how can the existing reservoirs and dams be managed more effectively for balancing the competing objectives and mitigating the risks associated with uncertainties kasprzyk et al 2012 borgomeo et al 2016 wild et al 2018 in developing countries especially those in south america south asia and africa the development and construction of reservoirs and dams for the future is still at its peak and managing the existing reservoirs and dams while providing a management strategy for future reservoirs and dams is a key concern for the decision makers winemiller et al 2016 sabo et al 2017 latrubesse et al 2017 in water resources system analysis the uncertainties derive from the inability of decision makers to adequately describe the possible states of the world for quantifying the possible risks in the system kasprzyk et al 2012 huang et al 2016 furthermore water resources management which is affected by the increase in the uncertainty as a result of climate change and human activities has become a risk based decision making process morgan and mellon 2011 brown et al 2015 guo et al 2019 such management has become necessary for sustainable development of human society optimal operation of reservoirs provides a feasible way to reduce the cost and risk associated with reservoir management and balance the beneficial relationship between the competing objectives fayaed et al 2013 giuliani et al 2014 despite the progress in the use of system engineering theory and complex non linear optimization algorithms in reservoir operation most of these methods remain theoretical and are rarely used in practical application maier et al 2014 the gap between theoretical research and practical application of reservoir optimization operation is obvious which is why it is difficult for decision makers to use the results of optimization as a guide in practical operation labadie 2004 brown et al 2015 on the one hand because the complexity of the optimization operation model makes it hard for decision makers to understand deeply its principle and usage conditions it is difficult to devise a reasonable management strategy in practice which is directly employable on the other hand the root cause of the gap is that most of the optimal operation processes are modelled with deterministic runoff sequences which indicate that all the information observed historical information is known beforehand during the operation period however in practical reservoir operation the future runoff information is completely unknown and cannot be accurately predicted herman et al 2015 borgomeo et al 2018 as a result an operation strategy based on historical information is not available owing to the uncertainty in runoff and other factors e g water demand growth and precipitation variability furthermore in the context of climate change the stationarity of runoff series has been destroyed which has led to more severe challenges in devising operation strategies based on historical information milly et al 2015 at present most reservoirs are operated according to the operation rule curves as part of actual management you and cai 2008 the traditional operation rule curves can be identified according to the basic storage relationship of a reservoir in recent years the parameter simulation optimization approach has offered the possibility of better guidance of reservoir operation dariane and momtahen 2009 the most representative of the parameter simulation optimization methods is the evolutionary multi objective direct policy search emodps which combines direct policy search nonlinear approximating network and multi objective evolutionary algorithm to define pareto approximate operating rules for multi purpose reservoir operation giuliani et al 2015a b emodps is used to improve water reservoir operation through direct use of the hydro meteorological data e g snow water equivalent cumulative inflow and enso state denaro et al 2017 libisch lehner et al 2019 to mitigate the gap between the theoretical research and practical application of reservoir optimization operation the parameter simulation optimization approach will become the focus of future research although the methods based on making the most of data can better determine the reservoir operation strategy they are still affected by the uncertainties in decision making process giuliani et al 2015b in the context of uncertainty decision makers are aiming at realizing multiple performance objectives in water resources management along with ensuring that the differences between the expected and actual performances are minimized in the possible future states kasprzyk et al 2012 bhave et al 2018 based on these goals robustness is most widely defined as the insensitivity of the system design to errors random or otherwise in the estimates of those parameters affecting design choice matalas and fiering 1977 although the specific approach is different when applying this concept decision makers seek alternative strategies for water resources systems to minimize the possibility of an undesirable outcome across future states these alternatives have been advocated by frameworks recently developed for decision making under uncertainties including decision scaling brown et al 2012 robust decision making lempert 2002 information gap ben haim 2004 and many objective robust decision making morod kasprzyk et al 2013 these frameworks should be applied to reservoir operation to assess whether the existing operation rules are suitable for uncertain scenarios and to clarify whether they are robust in the expected future states of the world herman et al 2015 furthermore existing water projects often involve multiple tasks e g flood control water supply power generation etc and the performances objectives of multistakeholder in reservoir management are different according to their preference labadie 2004 reed et al 2013 jiang et al 2019 to use the existing water related infrastructures more efficiently and equitably multi objective decision making should be employed to coordinate the conflicting relationships between multiple stakeholders this coordination is reflected in the achievement of a pareto trade off solution across multiple water utilities therefore this study focuses on the gap between the reservoir optimal operation and practical application and analyzes the multi objective characteristic of reservoir operation to mitigate the performance conflicts based on above mentioned considerations we further contribute to the morod framework and define the robust operation rule for multi purpose water reservoir under deep uncertainties for achieving these objectives this study evaluated a water supply system and explored the ability of the robust operating rule to deal with deep uncertainties of the water resources system for future planning 2020 2030 the han to wei inter basin water transfer ibwt project which is a water supply system located in shaanxi province of china was selected for a case study to reveal the drawback of the current operating rule under deep uncertainties the pre optimized operating rules derived by ming et al 2017 were evaluated through inputting the uncertainty factors into the simulation model a multi objective reservoir optimization model based on the mordm approach was established to identify the robust operating rule of the water reservoir of interest moreover the scenario and the sensitivity of the solutions of the operation model were analyzed by patient rule induction method prim finally the robust operating rule of the water supply reservoir was defined by combined analysis of the tradeoffs and sensitivity in multi objective space this study establishes the robust operating rule for reservoir operation in practical application which can better address the performance degradation of water resources system under deep uncertainties 2 study area and pre optimized operating rules 2 1 the han to wei ibwt project the han river the largest tributary of the yangtze river is located in the subtropical monsoon region of southern china the han river basin covers an area of 159 000 km2 and receives an average annual precipitation of 800 1200 mm the abundant rainfall in this basin produces an average annual natural runoff of 56 billion m3 most of which occurs during the flood season from may to october the runoff also varies greatly from year to year with cv values of 0 3 0 5 and the maximum annual runoff is 4 times larger than the minimum annual runoff fig 1 c from the han river basin to the north through the qinling mountains the north south boundary of china the study area reaches the wei river basin which is located in the transitional region between a semi humid region and an arid region the wei river basin covers an area of 134 766 km2 and receives an average annual precipitation of 500 800 mm the rainfall of wei river is unevenly distributed across the year with the maximum occurring in july to october the rainfall of this basin produces an average annual natural runoff of 10 4 billion m3 which is the basis of the water resources of 76 major cities with a total population of 22 million in the guanzhong plain which are used for domestic living industry and irrigation with the increasing impact of climate change and human activities huang et al 2014 2017 the water resources of the wei river basin are not sufficient to support sustainable socio economic development of the guanzhong plain furthermore the increased water stress of the wei river basin reflects a broader difference between the north and south of china liu et al 2018 huang et al 2019 fang et al 2019 although the han river has been selected as the water source i e the danjaingkou reservoir for the south to north water transfer project a new project the han to wei ibwt project for water transfer from the southern to the northern region is planned which is expected to solve the increasingly serious problem of water shortage in the guanzhong plain fig 1a the water transfer system of the ibwt project is located in the upper reaches of the han river basin fig 1b and contains two reservoirs the hunagjinxia reservoir and the sanhekou reservoir and related water supply facilities hydropower stations pumping stations and pipelines these two reservoirs are the core components of the water transfer project and are mainly used to store water for reducing the temporal deviation in the water supply the huangjinxia reservoir a run of river reservoir is located in the upper reaches of the han river it raises the water level so that the pumping station can supply water more easily the sanhekou reservoir is a multi year regulation reservoir which is located in the tributary the ziwu river of the han river if there is excess water in the water supply process this water will be stored in the reservoir for supply during the dry period the electrical energy consumed by the pumping stations of this project during the water supply process is mainly provided by the huangjinxia and sanhekou hydropower stations the more the water diverted the more is the electricity consumed therefore the main competing objectives of the project are the reliability of water supply and the net electricity generation of the hydropower stations the project aims to reduce water shortages in the guanzhong plain and it is planned to diverted 1000 million m3 to the wei river basin in 2025 increasing to 1500 million m3 in 2030 the diverted water resources are mainly used to supply 22 users including meeting domestic and industrial demands ren et al 2019 furthermore these volumes of diverted water are not defined arbitrarily and are based on water supply and demand analysis of the benefited areas in the wei river basin over the planning horizon this analysis takes into account the growth of industrial agricultural domestic ecological and reused or discharged water to pre determine the thresholds of water supply 2 2 pre optimized operating rules of the ibwt project reservoir operation usually involves the realization of multiple objectives including flood control drought management water supply and hydropower generation for rational utilization of a reservoir reservoir operating rules are used to determine when and how to operate the reservoir for storage and release over various runoff conditions at the planning stage of a reservoir the standard operating rule curves are designed to guide the relationship between storage and release however these rule curves may not be applicable in practice especially when drought occurs and should be modified or refined herman et al 2014 considering the shortcomings of the standard operating rule curves for the ibwt project optimized operating rule curves which are based on a multi objective optimization model were developed by ming et al 2017 fig 2 for different annual water demands the optimized operating rule curves inherit the characteristic curves of the standard operating policy and contain one water transfer rule curve and two hedging rule curves as shown in fig 2 the active storage of the sanhekou reservoir is divided into different operating zones by the different rule curves in zone ⅰ when the water level of the sanhekou reservoir is above the water transfer rule curve the water demand is fully satisfied by the sanhekou reservoir and the pumping station of the hunagjinxia reservoir does not operate in zone ⅱ the huangjinxia reservoir is preferred for meeting the water demand and the available water is transported to the node fig 1b through the hunagjinxia pumping station if the water demand is greater than the amount of diverted water the deficit water will be compensated for by the sanhekou reservoir furthermore if the demand is less than the amount of diverted water the sanhekou pumping station will operate to pump the excess water into the sanhekou reservoir for storage the water supply for industry and domestic living is not hedged in this zone in zones iii and ⅳ the basic relationship between the water supply and demand is similar to that in zone ⅱ however the water supply for the industry is hedged in zone iii whereas that for both industry and domestic living is hedged in zone ⅳ the rationing factor of the water supply for industry and domestic living is 0 9 these pre optimized operating rules are based on the long term historical runoff data obtained from the changjiang water resources commission for the period 1954 to 2010 and the water demand of the recipient basin is fixed at two standards of 1000 and 1500 million m3 per year however the planning horizon of water supply for this project is 10 years 2020 2030 therefore focusing on the runoff conditions over the 10 year window period is more important to the operation of the project as shown in fig 1c the three 10 year runoffs display low middle and high conditions and the differences between these runoff conditions may be more pronounced in the future owing to the destruction of the runoff stationary as a result of climate change and human activities furthermore the regional water demand is unlikely to remain fixed in the near future therefore this optimization falls far short of the goal of practical application when decision makers deal with the deep uncertainties in the input information of the system in this study the uncertainty factors listed in table1 were considered based on rigorous uncertainty analysis of a previous work which considered 13 uncertainty factors herman et al 2014 2 3 sampling uncertainty and testing the pre optimized operating rules in this section the possible runoff conditions were sampled with historical runoff data by the latin hypercube sampling lhs method and the uncertain set of water demand growth was established through the scaling factors these uncertainties include two components the uncertainties of runoff and water demand making up the plausible future states of the world which are used to test the pre optimized operating rules 2 3 1 sampling uncertainty the deep uncertainties mainly result from the incorrect or inaccurate projection of the future states of the world therefore decision making based on the status quo or expected future states of the world may fail to account for the risks associated with these uncertainties although accurate predictions of future states of the world cannot be made alternative decision making options can be provided by tracing the probability distributions of the input parameters to the model output these input parameters of the model are the deeply uncertain exogenous factors e g future runoff conditions water demand population growth etc which can be sampled to create an uncertainty ensemble each ensemble member represents a set of exogenous factors for a state of the world in which the future condition has been determined in this current study runoff conditions and future water demand are considered as the typical uncertain exogenous factors in order to correlate the optimization model output with the planned horizon of the project the operation period is set to 10 years 2020 2030 as shown in fig 1c the runoff conditions over the 10 year windows show significant differences which indicate whether samples were taken from a specific window or from the full sequence which may not fully represent the possible runoff conditions in the future therefore the runoff uncertainty ensemble was sampled from three 10 year runoff windows including high middle and low windows through the lhs method fig 3 a b the sampled runoff sequences increased the frequency and magnitude of the extreme values however the sampling is based on a mathematical algorithm with the historical distributions of the runoffs the magnitude of the extreme value of some sampled runoff sequences may be unreasonable and can be much larger than that of the historical runoffs therefore multipliers i e the upper bound of 1 2 and the lower bound of 0 8 in table 1 are used to limit the range of extreme values and further select the sampled runoff sequences another uncertainty ensemble which needs to be sampled is the future water demand which is determined by the capacity of the ibwt project this uncertainty ensemble was sampled by setting the upper and lower scaling factors of the uncertain dimension as shown in fig 3c the blue line represents the current baseline demand projection whereas the projected uncertain range of demand growth is colored according to the values of the scaling factors 2 3 2 testing of the pre optimized operating rules although the pre optimized operating rules were proposed from an optimization model the inputs of this model were the deterministic historical runoff data and the water demand was fixed to 1000 and 1500 million m3 per year over the operation years respectively therefore when both runoff conditions and water demand are uncertain ensembles the pre optimized operating rules are tested for whether they meet the performance requirements of the stokeholds as mentioned in section 3 2 four performance metrics were considered along with the corresponding threshold values the uncertain ensembles are inputted to the simulation model and based on the pre optimized operating rules these performance metrics can be calculated if all the metrics satisfy the requirements of the stokeholds the water supply system will be in successful states otherwise it is in failed states fig 4 shows the operational consequences of the pre optimized operating rules for 1000 fig 4a and 1500 million m3 per year fig 4b the green points represent the solutions which successfully meet the requirements in the alternative states of the world whereas the magenta points represent the states of the water supply system in which the solutions fail in this regard the plotted inflow and water demand factors show a clear separation between the alternative states of the world where the consequences of the solutions are successful and failed this result indicates that both the uncertain factors are sensitive factors and the increased water demand and decreased runoffs would prompt the water supply system towards the failed states and vice versa furthermore herman et al 2014 considered a 13 dimensional uncertainty space of an urban water supply case study and revealed that the factors of inflows and demand growth are the most sensitive factors and that the other uncertain factors e g evaporation water supply allocation consumer reductions etc do not provide additional information on whether the system succeeds or fails as shown in fig 4a the successful states of the system are 40 of all the states of the world by contrast the proportion of the successful states of the system reported in fig 4b is large than 70 this result indicates that choosing different operating rules has a significant impact on the state of the system under deep uncertainties which will confuse decision makers in their decision making if the inflow conditions and water demand are specific e g inflow condition of a dry year and a water demand of 800 million m3 per year there may not be a reasonable operating rule which can be selected therefore for defining the robust operating rules a framework for robust decision making is presented in following sections 3 methodology in this section the methods for defining the robust operating rule are presented by formulating the multi objective optimization model and application furthermore the robustness measures of solutions and prim for scenario discovery and sensitivity analysis are also introduced in detail by specifying them in this study 3 1 problem formulation 3 1 1 optimization operation model as mentioned above the competing objectives of the ibwt project are the reliability of water supply and the energy generation of the two reservoirs therefore this study established a multi objective optimization operation model which aimed to minimize the water shortage index of water supply and maximize the net revenue of the hydropower generation the ecological environmental objective is considered as a constraint a fixed eco flow constraint in the optimization model the two objectives are formulated as follow objective one minimize the water shortage index 1 min w s i 1 t t 1 t max w t d w t s 0 w t d 100 where wsi is the water shortage index unitless t is the total number of operation periods tth month w t d is the total water demand of the users at the node m3 w t s is the actual water supply to the users m3 objective two maximize the net revenue 2 max n r 12 t i 1 2 t 1 t e 1 n i t e 2 p i t 10 8 δ t 3 n i t g λ i q i t h i t 4 p i t g q i t h i t η i where nr is the net revenue yuan i 1 denotes the hunagjinxia reservoir i 2 denotes the sanhekou reservoir e 1 is the feed in tariff which is set as 0 3 yuan kwh e 2 is the electricity price which is set as 0 5 yuan kwh n i t is the power generation of the hydropower plants kw p i t is the electrical consumption of the pumping stations kw δ t is the duration of the time step h λ i is the coefficient of the hydropower stations unitless q i t is the discharge for power generation m 3 s 1 h i t is the hydraulic head for the power generation m g is the gravitational acceleration 9 81 nkg 1 q i t is the rate of water supply m 3 s 1 h i t is the delivery head for water supply m η i is the coefficient of the pumping stations unitless in this study the hydraulic head of the huangjinxia hydropower station is considered as a constant over the long term operation period because the huangjinxia reservoir is a run of river reservoir the constraints of the optimization operation model are the physical and operational constraints which include mass balance water diversion capacity operating rule curves and power output capacity the details of the constraints of the optimization model can be found in the paper by ming et al 2017 3 1 2 parameterization simulation optimization approach the decision variable of the traditional reservoir optimization model is the storage capacity of the reservoir which can be iteratively optimized through optimization algorithms e g evolutionary algorithms clarkin et al 2018 in this study we consider direct optimization of the operating rule curves which should be parameterized first the parameters i e the decision variables used to represent the operating rule curves are the water levels of the reservoir in different months there are three operating rule curves which should be optimized and each curve includes 12 months covering the annual operation period in order to reduce the variability of the rule curves and the time taken for optimization the rule curves are classified into four operation periods for one year according to the hydrological conditions these operation periods are the pre flood season from january to march main flood season from april to june post flood season from july to october and dry season november and december each sub operation period is represented using the same parameter so that each operation rule curve can be optimized with four parameters therefore although there are three curves 36 parameters which need to be optimized the optimization parameters are reduced to 12 through this classification in the initial step these parameters can be randomly generated along with the search range and then decision makers operate the water supply system according to the pre parametric rule curves to simulate the results of water supply and power generation finally the optimization algorithm is used to iteratively improve the results by evaluating the two objective functions and fitness value in this study the cuckoo search cs algorithm was used to optimize these parameters the cs algorithm which is an evolutionary algorithm inspired from the obligate brood parasitic behavior of some birds was established by the yang and deb 2010 the cs algorithm further improves the search efficiency by using the lévy flight process which has been demonstrated by previous studies to solve the non linear and highly complexity optimization problems yang and deb 2013 ming et al 2017 2018 3 2 robustness measures of the solutions using the multi objective evolutionary algorithm many sets of pareto approximate non dominated solutions can be obtained under many plausible states of the world the robust solution which is a solution that provides improved performance across as many states of the world as possible will be more easily accepted by decision makers robustness measures of solutions can be used to quantify and rank which one is the most robust solution of these sets of pareto approximate solutions however a previous study has shown that selecting different robustness measures will significantly affect the selection of the robust solution giuliani and castelletti 2016 therefore for selecting the robust solution reasonably one regret based measure and two satisficing based measures were considered in this research they were identified by lempert and collins 2007 and further discussed by herman et al 2015 the regret based measure r quantifies the performance deviation d i of an objective between the current state of the world and the baseline state of the world this measure is maximized as follows 5 r max i d i 90 p d i d i 90 0 90 6 d i j f x i j f x i f x i where f x i denotes the value of objective i in the baseline state of the world f x i j denotes the value of objective i determined in the current state of the world j d i j is the performance deviation of a solution between the current state of the world and the baseline state of the world d i 90 is 90th percentile performance deviation the first satisficing based measure s1 is defined as the fraction of n states of the world in which the performance requirements of decision makers are satisfied by a solution in one or more objectives 7 s 1 1 n j 1 n λ s j where if solution s meets the requirements in the state of the world j λ s j 1 and λ s j 0 otherwise the most important feature of this measure is that it incorporates the performance requirements of multiple stakeholders in this case study although the objectives of the optimization pertain to the water shortage index of the water supply and the net benefits of the hydropower generation the reliability of the water supply hashimoto et al 1982 and minimum water supply index are also considered to strictly influence the selection of the solutions therefore the requirements of water shortage index less than 0 5 net benefits above 0 reliability above 95 and minimum water supply index above 70 are considered in this study the second satisficing based measure s2 is defined as the uncertainty horizon over which the system can withstand failures this measure is derived from the info gap approach and can be formulated as 8 s 2 α max α min j u α f x j r where α is the maximum uncertainty horizon which can be accepted without performance falling below r in this study the reliability of the water supply was used to calculate s2 and the threshold value r is 0 95 3 3 scenario discovery and sensitivity analysis with prim the main purpose of using scenario discovery in water resource system analysis is to identify the regular patterns in the system which can be used to interpret and predict its characteristics bryant and lempert 2010 kasprzyk et al 2012 generally a water resources system involves a lot of input parameters to control its output and there are differences in the contributions of different parameters to the output these differences can be identified through sensitivity analysis scenario discovery and sensitivity analysis are important for decision making in analytic applications involving water resource systems under deep uncertainties because the deterministic patterns or information can be obtained from the uncertainties this information or patterns will be useful to decision makers for reducing the complexity in decision making these two methods are based on statistical or data mining algorithms and fortunately prim can be used to accomplish both tasks at the same time the following section begins with an introduction of the several core concepts applied in this method in previous work bryant and lempert 2010 the regions of input parameters space are characterized as multi dimensional boxes through a specific algorithm an individual box which is constrained by partial input parameters is called a scenario and a set of boxes is interpreted as a set of scenarios the scenario discovery applied here is to seek a box or a set of boxes which exhibits the maximum explanatory power for input relevant cases according to previous studies bryant and lempert 2010 kasprzyk et al 2012 herman et al 2014 there are three reasonable measures of quality for the purpose of scenario discovery that is density coverage and interpretability in order to provide useful information in decision making a selected box should capture as many proportions as possible of the total number of input relevant cases high coverage capture primarily input relevant cases high density and display high interpretability for decision making coverage is the ratio of the total number of input relevant cases xi in scenario b to the total number of input relevant cases x which can be formulated as follows 9 coverage x i b y i x i x y i where y i 1 if xi b and y i 0 otherwise density is the ratio of the total number of input relevant cases xi in a scenario b to the total number of cases x in the scenario 10 density x i b y i x b 1 the measure of interpretability is highly subjective because it requires decision makers to select a specific scenario which is based on the characteristics of the problem generally these measures are conflicting therefore the ideal set of scenarios high coverage high density and high interpretability is not observed for a given dataset these three measures generally define a multi dimensional efficiency frontier therefore prim is used to generate alternative scenarios at different points of the frontier and then users choose the most reasonable scenario based on the preferences of the decision makers the prim is a bump hunting algorithm which was proposed by friedman and fisher 1999 the algorithm presents decision makers with a visualization of the peeling trajectory by plotting the density of each box against its coverage scenario discovery can be easily achieved using this method through the r toolkit which is available at http cran r project org web packages sdtoolkit index html for more details on this method the reader can refer to the report of bryant and lempert 2010 4 results and discussion our framework for defining the robust operating rule which depends on the mordm approach is shown in fig 5 sections 4 1 4 3 detail the results and demonstrate this framework by using the han to wei ibwt project test case 4 1 selecting the robust solution across the alternative states of the world each solution across the alternative states of the world can be calculated using the parameterization simulation optimization approach described in section 3 1 although the runoff uncertain ensemble has been sampled in section 2 3 1 this ensemble is only used to test the reasonability of the operating rules since the water supply system considered in this study has two water sources namely the hunagjinxia reservoir and the sanhekou reservoir the positive correlation between their monthly inflows is significant fig 6 reasonable runoff conditions of these two water sources should consider their synchronous and asynchronous encounter situations however this problem is beyond the consideration of this study the sampled runoff uncertain ensemble regenerated the relationships of magnitude and frequency between the two water sources and ignores this problem therefore this ensemble may only be used to test the operating rules rather than to identify the robust operating rules keeping these points in mind only the historical runoff combination of the two sources is reasonable for establishing the alternative runoff conditions the 57 year 1954 2010 runoff time series used to define the pre optimized operating rules was split into shorter 10 year durations for each of the two water sources two adjacent runoff durations maintained a one year lag and the total of 57 years of runoff could be divided into 47 runoff durations these established runoff conditions and the uncertain ensemble of water demand growth identified in section 2 3 1 are used to define the robust operating rules fig 7 shows the cumulative distributions of the four performance metrics across the alternative states of the world and those calculated by the parameterization simulation optimization approach each line represents a solution across the alternative states of the world the pareto approximate solutions calculated through multi objective optimization are shown as dark green lines the robust solutions which are selected through the robustness measures are indicated in blue red and green lines the performance requirements of the stakeholders are represented as black vertical lines several salient features can be observed in fig 7 first although the set of pareto approximate solutions provides options for decision makers to improve the quality of alternative decisions these solutions do not reduce the risk of performance loss when the system is across the alternative states of the world i e the deep uncertainties in the space of the deep uncertainties the proportions of the performance metrics for the system in the successful states are 50 50 42 and 30 respectively this result indicates that multiple uncertain factors exhibit a significant impact on the performance of the system and that robustness of the system may be achieved by reducing the effect of the key uncertainties herman et al 2015 see the solid circle in fig 4 second as demonstrated by herman et al 2015 different robustness measures reveal significantly different ranking for the solutions in this study although the robust solutions identified based on the robustness metrics show differences in the rankings these solutions are concentrated in the performance frontiers this result facilitates the selection of the most robust solutions fig 8 shows the parallel axis plots of the most robust solutions obtained according to the robustness measures the values of these performance metrics are normalized between their minimum and maximum values so that these metrics can be plotted on a common axis each line represents a solution at the corresponding performance values for a specific state of the world the ideal solutions are represented as red lines which correspond to the minimum water demand growth and positive runoff conditions fig 8 shows clear conflicts or trade offs especially when seeking to minimize the water shortage index or maximize the net revenue the attainment of a low water shortage for the water supply in the ibwt project is in conflict with the sustenance of a positive net revenue the net revenue is more sensitive across the alternative states of the world than over the pareto approximate sets fig 7 indicating that water demand and supply is the key factors determining the performance of the ibwt project finally the most robust solutions according to the robustness measures show similar patterns of the performances for brevity we chose the robust solution derived from regret based measure r for further analysis fig 9 shows the box plots of the robust operating rule according to the robustness measure r for clarity the water transfer rule curves and the hedging rule curves for industry and domestic living are plotted in subgraphs which are represented as high middle and low curves respectively the high curves are distributed between the upper and lower limits of the reservoir s storage capacity especially the operation rule of the wet season e g july and august which is distributed over a wider range compared to that of another season the middle and low curves are distributed over a narrow range however the rule curves of the dry season e g november and december are distributed between the upper and lower limits this result indicates that there are key months for the operating rules and the reasonability of the operating rules may determine the performance of the system over the entire operation period 4 2 scenario discovery and sensitivity analysis there are differences in the response sensitivity of the output of a system to the input parameters of the system and the purpose of identifying these differences is to find out the key factors affecting the performance of the system as shown in fig 4 both the uncertainties of inflow conditions and water demand growth are responsible for the vulnerabilities of the system however this result derived from the pre optimized operating rules was evaluated by a qualitative and visual sensitivity analysis based on the results of multi objective optimization sensitivity analysis can be strengthened by using a formal and quantitative method prim therefore this section first discovered the scenarios and analyzed the most sensitive uncertain factors and then explored the relationships between the optimized operating rule curves and the system performance first the inputs of the prim method require that each runoff condition should be represented by a value and that the magnitude of the runoff conditions should be equal to the magnitude of each performance metric however each runoff condition is a long term time series which is difficult to represent by a fixed value therefore for rationality we chose a series of characteristic values e g maximum and minimum values mean and median values standard deviation skew coefficient variation coefficient interquartile range etc which represent the overall conditions of runoff as the input variables of this method the water demand increases strictly no matter which characteristic value can represent its overall state fig 10 shows the ranges of the sensitive factors identified by prim which are likely to produce a particular outcome the x axis is normalized with the corresponding maximum and minimum values of the sensitive factors for water demand shortage the inflow of the huangjinxia reservoir and the water demand growth are identified by the method as the sensitive factors which suggests that a maximum value of the inflow greater than 1051 m 3 s 1 and an average water demand less than 111 million m3 per year will most likely ensure success of the system furthermore for the net revenue of hydropower generation the inflows of the huangjinxia and sanhekou reservoirs and the water demand growth are identified by the method as the sensitive factors maximum values of the inflows of the two reservoirs greater than 1529 and 214 m 3 s 1 respectively and an average water demand less than 67 million m3 per year will most likely ensure the success of the system second figs 11 and 12 provide the detailed results of the discovered scenarios from the optimized operating rules to the system performance fig 11 shows the overall metrics of quality of the selected scenarios as observed most of the values of density and coverage are greater than 0 9 therefore they provide high confidence levels for the selected scenarios the competitive relationships between them are well balanced especially for the high rule curves which are stronger than the middle or low rule curves however in fig 11b and c some lower values of density are observed which indicate that the discovered scenario may not accurately describe the input output relations of the system in the middle and low hedging curves furthermore scenario discovery of the middle and low operating rule curves is more difficult than that of the high operating rule curves fig 12 shows the most sensitive operation months based on the robust operating rules for the selected scenarios of fig 11 for the success of the system the key water levels of the sensitive months which need to be controlled are displayed above on green bars and the corresponding values of density and coverage are shown in the right tables for water demand shortage the sensitive operation months are the january april and july of the high rule curves the april july and november of the middle rule curves and the january of the low rule curves furthermore for the net revenue of hydropower generation the sensitive operation months are the july and november of the high rule curves the november of the middle rule curves and the july and november of the low rule curves these results indicate that when the water levels of the reservoir are above the threshold values of the high rule curves the available water resources of the sanhekou reservoir are sufficient to meet the water demand without the need for supply from the huangjinxia reservoir the high rule curves are in the higher position and the moments when water supply is hedged occur earlier this strategy ensures minimum water shortage for long term water supply the sensitive months of the middle rule curves are in the wet season and the middle rule curves are distributed over wide ranges therefore the inflows of the two reservoirs are sufficient for water supply furthermore when the water levels are below the low rule curves both the water supply for industry and domestic living are hedged which suggest that the water demand cannot be meet indefinitely finally for the net revenue of hydropower generation the lower position of the high rule curves the smaller is the power consumed in pumping water this strategy ensures that positive net revenue can be realized the sensitive months of the middle and low rule curves are in the wet season and the available water resources are sufficient therefore their reasonable operating curves should depend on the specific conditions of runoff and water demand 4 3 defining the robust operating rule in this section the key question raised in the introduction section is answered that is how can the robust operating rule be defined for a water supply reservoir under deep uncertainties first the uncertain ensembles sampled in section 2 3 were used to test the optimized operating rules which were selected according to the robustness measures of solutions section 4 1 second based on the performance requirements of the stakeholders the performance calculated from the optimized operating rules was compared with that derived from the pre optimized operating rules to choose the best performing solutions fig 13 presents the results of the best performing solutions and shows the performance space of the maximum success frequency as shown in fig 13a the positions of the operating rule curves are ranked according to the values of the successful frequency this result is consistent with the findings reported in section 4 2 that is the high rule curves are in the higher position the moments when the water supply is hedged occur earlier and the water demand is easier to meet the green line shows the water transfer rule curve of pre optimization which is located in higher positions in the dry seasons and in lower positions in the wet seasons this rule curve hedges the water supply later in the dry seasons and earlier in the wet seasons compared to the robust rule curves which indicate that the water supply during the year is not properly allocated when the system experiences the deep uncertainties fig 13b and c show the middle and low rule curves which are compared with the pre optimized operating rule curves although the positional ranks of these rule curves are not related to the successful frequency the rule curves of the maximum successful frequency are located in lower positions furthermore these results are consistent with that shown in fig 9 there are more outlier values in the middle and low curves which result to the scenarios cannot be accurately discovered in these curves compared with the pre optimized operating rule curves the robust operating rule curves delay the moments of restricted water supply and expand the operational range of the water level which are significant for ensuring the performance of the system as shown in fig 13d the successful proportion of the performance space is significantly larger than that derived from the pre optimized operating rules fig 4b the maximum frequency of success is about 0 88 which is more than the original successful frequency of roughly 0 18 finally when the runoff conditions are in the high range the system is always in the successful states indicating that this strategy is a better way of achieving the desired performance of the system than the original operating rules under deep uncertainties the robust operating rule curves highlight the important role of robustness analysis in identifying the key sources of uncertainties while providing the available operating rules for practical applications giuliani et al 2014 although precise prediction of future water demand growth and runoff conditions is lacking we demonstrate that the robust operating rule can mitigate the gap between optimization operation and actual reservoir operation this mitigation is based on the operating rule used in practical reservoir operation which is optimized by combining the optimization algorithm e g multi objective evolutionary algorithms with parameterization simulation optimization approach furthermore the framework we proposed for identifying the robust operating rule balances the competing objectives and integrates the modern analysis tools for water resource systems under deep uncertainties 5 conclusion the deep uncertainties derived from climate variability and human activities will challenge water resources management in the coming decades this requires advancing the optimization model for complex water resource systems in order to obtain the robust operating rules for an uncertain world this study contributes to the parameterization simulation optimization framework for defining the robust operating rules of water resource systems for the alternative states of the world based on the mordm framework and multi objective optimization for better capturing the uncertain factors and their interactions with the water supply system in order to evaluate the performance of the system the operating rule is parameterized according to the parameters of the operation rule curves which were simulated for the actual operation process and optimized using the evolutionary algorithms the application to the case study of the han to wei ibwt project allows evaluating the different uncertain factors to identify the robust operating rules for improving the current operating rules the current operating rule for a water resource system may not address the challenges of the deep uncertainties the hedging rule curves derived from the parameterization simulation optimization framework provide a feasible way to reduce the gap between actual operation and optimizing operation results show that the hedging rules are more robust and effective than the pre optimized operating rules the successful frequency of the case system based on the hedging rules is 18 higher than that of the pre optimized operating rules for the plausible future states of the world the hedging rules used in the actual operation process only require the input information of the current operation period therefore they are more operable for decision makers moreover according to sensitivity analysis and scenario discovery approach the inflow conditions and water demand growth are the sensitive factors governing the success or failure of the system robustness of a system may be achieved by reducing the effect of key uncertainties e g reduced the water demand growth for optimized rule curves there are differences in the sensitive months of the water transfer rule curves and the hedging rule curves the several ranges of the sensitive factors which are likely to produce a particular outcome are identified finally compared with the pre optimized operating rules the robust operating rules provide a range of operation spaces for better addressing the challenges posed by the deep uncertainty the framework proposed in this study can provide alternative management strategies for decision makers when the risk sources are broad or the performance requirements of stakeholders are different this framework is more robust in resolving risk escalation and performance degradation than the traditional operation strategies with the increasing impact of climate change and human activities on water resource systems the management of water resources will involve paying more attention to robust solutions instead of optimality under deep uncertainties herman et al 2014 the root cause of uncertainty is the inability to accurately predict the future state of the world therefore the range of alternative states of the world should be appropriately constrained for improving the credibility of decision making and reducing the computational expense the approach of making the most of data can be integrated into the parameterization simulation optimization framework to better define the robust operating rules and improve the ability to integrate the concept of deep uncertainty into optimization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we sincerely appreciate the editor and four anonymous reviewers for their helpful and constructive comments this research is jointly funded by the national natural science foundation of china 51879213 and 51709221 the national key research and development program of china 2017yfc0405900 the planning project of science and technology of water resources of shaanxi 2017slkj 16 and 2017slkj 19 the key laboratory research projects of the education department of shaanxi province 17js104 the open research fund of state key laboratory of simulation and regulation of water cycle in river basin china institute of water resources and hydropower research iwhr skl kf201803 and the belt and road special foundation of the state key laboratory of hydrology water resources and hydraulic engineering 2018490711 
6186,although a variety of climate datasets are now available including observational and model products there remains a pressing need for the development of a unified automated and application focused approach for evaluating and comparing climate extremes within and across these datasets precipitation frequency pf estimates for extreme precipitation events are useful decision relevant quantities among water managers our objective and quantitative framework for computing pf estimates of any duration uses known techniques in a novel combination our framework consists of three steps 1 use of a regionalization based statistical method for precipitation frequency estimation at observed sites this involves hierarchical clustering here we used ward s method for delineating homogeneous regions and regional frequency analysis using l moments 2 use of kriging for spatial mapping because of its advantages over other conventional interpolation methods 3 use of z scores accounts for estimation uncertainties when comparing pf estimates between datasets the 24 h pf estimates in the kissimmee southern florida watershed flat topography and the sacramento san joaquin watershed complex topography demonstrate the applicability of this approach in regions of any geographical complexity our results are shown to be reasonably calibrated using the probability integral transform pit histogram of the best fitted distribution our results are compared with that of the noaa atlas 14 reports and show that for most of the stations the two estimates are statistically indistinguishable and the confidence intervals of our estimates are narrower than those of the noaa estimates our approach is applicable to a variety of datasets and provides a baseline for assessing performance of climate models in historical simulations a necessary first step towards analyzing future projections keywords regional frequency analysis rfa using l moments extreme precipitation intensity duration frequency idf estimates clustering analysis kriging calibration using pit histogram 1 introduction in this work we present a framework for estimating intensity duration frequency idf curves or precipitation frequency pf estimates of extreme precipitation events of different durations pf estimates are used for advance planning and management of extreme precipitation events the pf estimates provide information support for a wide variety of civil activities such as designing flood protection structures urban drainage systems and agricultural planning schaefer 1990 parrett 1997 trefry et al 2005 norbiato et al 2007 cheng and aghakouchak 2014 agilan and umamahesh 2018 our methodology involves three steps first the use of a regionalization based statistical method for precipitation frequency estimation at observed sites second the use of an interpolation method that quantifies both the estimates and their associated uncertainties between observed locations third a proposed metric that can objectively quantify differences in precipitation estimates between datasets observed vs model model vs model in the remainder of this section we present a brief literature review of available methods and approaches and demonstrate the rationale behind choosing methods that are optimal to our proposed framework the first step in our methodology is to choose a statistical method for precipitation frequency analysis precipitation frequency analysis can either be site specific or regional but reliable estimation at sites can be problematic because of short data records consequently regional frequency analysis rfa has been developed to avoid this issue rfa pools the data from nearby stations with similar characteristics to the target station this procedure is called regionalization stedinger 1993 some variants of rfa are based upon multiple regression analysis that relate regional attributes to quantiles or parameters of the probability distribution at a site riggs 1973 kroll and stedinger 1998 reis et al 2005 griffis and stedinger 2007 ahn and palmer 2016 durocher et al 2019 the detailed description of regression based methods is out of the scope of this paper an important variant of rfa is the index flood based approach which assumes that all sites inside a homogeneous region have identical frequency distribution apart from a site specific scaling factor called the index flood dalrymple 1960 hosking and wallis 1997 naghettini 2017 subjectivity involved in the formation of homogeneous regions is still a topic of current research naghettini 2017 a unified approach proposed by hosking and wallis 1997 combines the index flood procedure with the l moments based estimation method in this method l moments are not only used to estimate regional parameters and quantiles but also to build regional statistics such as formation of homogeneous regions capable of reducing subjectivity involved in the formation of homogeneous regions the method of regional frequency analysis using l moments is considered to be among the most relevant and efficient approaches bobée and rasmussen 1995 bonnin et al 2006 what makes the method of l moments preferable to others is that l moments uniquely define a distribution and l moments are less sensitive than other moments to outliers hosking 2014 we use rfa with the method of l moments as described in hosking and wallis 1997 there are several methods prevalent for regionalization here we use ward s hierarchical clustering algorithm for regionalization clustering based algorithms and other methods of regionalization are discussed further in section 3 2 2 the second step in our proposed framework is the use of a comprehensive interpolation method to provide precipitation estimates between observed locations conventional interpolation methods such as distance weighting thin plate splines etc have some shortcomings for example they use arbitrarily assigned weights do not account for clustering of data and most importantly do not quantify uncertainties associated with the interpolation a sophisticated and widely popular interpolation method in geostatistics is kriging simply speaking kriging provides the minimum variance unbiased linear estimates at unmeasured locations watkins et al 2005 the advantages of kriging are that it accounts for spatial correlation of the data being mapped accounts for clustering of data and quantifies uncertainty of interpolated estimates in terms of the standard error of the estimates pierre 1997 coburn 2000 various forms of kriging have been used previously for spatially interpolating the precipitation estimates goovaerts 2000 watkins et al 2005 szolgay et al 2009 mair and fares 2010 frazier et al 2016 das 2019 durocher et al 2019 risser et al 2019 the mathematical details of kriging used in our study are given in section 3 3 the third step in our methodology is the use of a metric to objectively compare two different precipitation estimates most of the previous studies only consider the difference in the estimates without taking the uncertainty in estimates into account we present a metric that quantifies statistical differences between the precipitation estimates by considering both the estimates and their uncertainties the method is described in section 3 4 to demonstrate the applicability of this approach in regions of any geographical complexity we compute 24 h pf estimates in the kissimmee southern florida watershed and the sacramento san joaquin watershed the two case study regions in the project the kissimmee southern florida watershed is important for water supply and maintaining important ecological services the main issues concerning civil authorities are water supply for a growing population flooding in dense urban areas sea level rise and restoration of natural ecosystems such as the everglades koebel and bousquin 2014 south florida water management district 2018 the sacramento san joaquin watershed in california provides drinking and irrigation water to the local population the watershed largely depends on the winter snowfall for supply to its reservoirs u s department of interior bureau of reclamation s 2016 secure water act report identifies that increasing temperatures may cause variable precipitation over the next century and may also result in less snowfall resulting in more rain on snow events mote et al 2005 we compute 24 h precipitation estimates for nine return periods 2 5 10 25 50 100 200 500 and 1000 years the methodology adopted here is valuable for ongoing efforts in evaluating pf estimates in observations and climate models given that many regional climate models and climate datasets are now available a unified and automated approach that can objectively evaluate and validate these datasets in light of observations is needed this study proposes such a unified framework from input data to rfa based pf estimation to kriging based spatial mapping of the estimates and finally a metric for scoring different datasets that takes estimation uncertainty into account a novelty of this study is the analysis of the probability integral transform pit histogram of the best fitted distribution to show that the pf estimates and their confidence intervals are reasonably calibrated a method common in probabilistic forecasting the homogeneous clusters obtained in the observations may also be used as reference clusters in all models using the same reference clusters in observations and across all models offers a clean approach to comparing across datasets and also allows for automation of the analysis procedure to some extent we suggest this procedure is desirable over previous studies that analyze and compare pf estimates in historical and future simulations on a station by station basis the remainder of the paper is summarized as follows section 2 outlines the sources of the data used in the study section 3 presents approaches and methods section 4 discusses results of the analysis calibration of estimates is discussed in section 5 a comparison of our results with that of the noaa estimates is presented in section 6 and lastly section 7 summarizes the results 2 data for this analysis the data is in the form of station based 24 h annual maximum precipitation amp timeseries the amp data is presently available from the noaa atlas 14 website https hdsc nws noaa gov hdsc pfds pfds map cont html we use the noaa atlas 14 data because data at each station have already passed quality assessments and checks and many possible errors in the data including unphysical outliers have been removed the amp timeseries is constructed from daily precipitation timeseries for each calendar year january 1 december 31 for the kissimmee southern florida watershed and each water year october 1 september 30 for the sacramento san joaquin watershed perica et al 2011 perica et al 2013 since the amp data for stations at the shasta reservoir in the sacramento san joaquin watershed are missing from the noaa atlas 14 the corresponding amp data is constructed from daily global historical climatological network daily ghcnd data maintained by noaa https www ncdc noaa gov ghcnd data access the quality of the ghcnd data has been tested for both the errors and outliers no outliers were found gridded precipitation data has been constructed from the daily prism data over 1981 2016 daly et al 1994 gridded precipitation data are used to construct mean daily and monthly precipitation time series both the long term mean daily and monthly precipitation time series are used as attributes for cluster analysis 3 method 3 1 statistics of l moments l moments are defined as certain linear combinations of order statistics of a random sample hosking and wallis 1993 hosking and wallis 1997 the l moments can be derived from the probability weighted moments pwms greenwood et al 1979 a pwm is defined as 1 β r 0 1 x f f r df where x f is the quantile function in terms of cumulative distribution function f for an ordered set of independent and identically distributed random variables x 1 x 2 x 2 x n an unbiased estimator of β r can be derived as 2a β r 1 n i 1 n i 1 r n 1 r x i certain linear combinations of β r give l moments of the data for example the first three l moments can be expressed as 2b λ 1 β 0 2c λ 2 2 β 1 β 0 2d λ 3 6 β 2 6 β 1 β 0 the first two l moments λ 1 and λ 2 are the measures of the sample mean and scale a dispersion measure of the distribution respectively the l moments are used to derive l moment ratios one of the l moment ratios called sample l cv is given by t λ 2 λ 1 the sample l cv is analogous to the conventional coefficient of variation the other sample l moment ratios are defined as 3 t r λ r λ 2 r 3 4 t 3 and t 4 are called sample l skewness and l kurtosis respectively as compared to the other conventional methods l moments based methods are less susceptible to the presence of outliers and are more robust to sampling variability a detailed description of l moments can be found in hosking and wallis 1997 and naghettini 2017 3 2 regional frequency analysis using l moments if q i f represents the quantile as a function of cumulative distribution function f at site i i 1 2 n then we may write 4 q i f μ i q f i 1 n where μ i is the index flood usually the mean of the at site frequency distribution here q f is a dimensionless quantile function called the regional growth curve and is the quantity estimated in regional frequency analysis once q f is estimated the site specific quantile is calculated using 4 3 2 1 screening of the data the index flood approach assumes that the observations at a site are stationary serially independent and independent of observations at other sites no cross correlation we tested the stationarity assumption by using the mann kendall trend test at the 5 significance level and removed any significant linear trend from the data while maintaining the mean of the time series the criteria of serial independence is tested by analyzing the lag 1 to lag 6 autocorrelation at the 95 significance level previous studies show that the impact of cross correlation on the pf estimates is minimal hosking and wallis 1993 perica et al 2011 therefore we did not address the issue of cross correlation in the calculation of pf estimates however cross correlation reduces the number of independent sites in a region which has been accounted for in the calculation of confidence intervals of the estimates hosking and wallis 1997 hosking and wallis 1997 suggested a discordancy measure d based upon comparison of l moment ratios for a given site with the average l moment ratios for a group of sites a site is declared discordant if d is greater than a critical discordancy value d crit typically d crit increases with the number of sites in the region and is equal to 3 for a group of 15 sites or more the discordancy measure d is capable of identifying gross errors and outliers in the data and hence is used for screening the data d has one more purpose in regional frequency analysis after a group of sites is tentatively identified as a homogeneous region d is recalculated for the proposed homogeneous region if a site is identified as discordant the possibility of moving that site out of the proposed homogeneous region is considered however hosking and wallis 1997 cautioned that a site may be discordant by a random chance or because of a localized extreme event that did not affect other sites in the proposed homogeneous region 3 2 2 review of methods of regionalization a variety of regionalization methods has been developed in the past few decades they include correlation analysis based approaches such as elementary linkage analysis and canonical correlation analysis principal component analysis the region of influence approach and cluster analysis this list of methods is only indicative and not exhaustive of all the methods in practice it is worth mentioning that all of these methods have their own advantages and disadvantages and their specific use may depend on specific applications and situations elementary linkage analysis is a variant of correlation based methods jackson 1973 adelekan 1998 in elementary linkage analysis two sites that have the strongest positive correlation are assigned the same region additional sites are added to the region based upon their significant correlations with the sites in the provisional region this process is repeated until all sites are partitioned into coherent regions the limitations of correlation based approaches are that they involve subjectivity in selecting a correlation threshold value and that they are insensitive to the magnitude of differences in correlated variables unal et al 2003 satyanarayana and srinivas 2008 irwin 2015 canonical correlation analysis cca is another variant of correlation based methods in which a linear combination of regional characteristics that has the strongest correlation with the hydrologic parameters is identified cca is a widely used method cavadias 1989 ouarda et al 2001 chokmani and ouarda 2004 leclerc and ouarda 2007 shu and ouarda 2007 khalil et al 2019 and is useful in evaluating linear relationship between two variables the problem with this method is that the pattern recognition is based on a subjective visual analysis and that there is no guarantee that a pattern will be detected bobée and rasmussen 1995 rao and srinivas 2006 also results obtained by cca are sensitive to number of sites in the region ouarda et al 2001 leclerc and ouarda 2007 principal component analysis pca is a method that decomposes data into a set of uncorrelated orthogonal components pca and its variations have been popular in regionalization for example li juan et al 2009 used simple principal component analysis for mapping precipitation regimes in china miller and goodrich 2007 used rotated pca for regionalization of winter precipitation in the north western usa darand and mansouri daneshvar 2014 and raziei 2018 employed s mode of pca for regionalization of precipitation in iran the major limitation of pca based approaches is that they are ineffective when a large number of components describe total variance of the dataset in areas with complex topography little variance is explained by the leading principal components therefore pca based approaches are not suitable in such regions srinivas 2013 irwin 2015 serra et al 1996 the region of influence roi approach burn 1990 considers each target site as a one site region the sites in the region are included based upon their distance from the target site in the geographic and other attributes space one of the main advantages of the roi method is that it results in a smooth transition in estimates across regional boundaries perica et al 2011 perica et al 2013 this approach has also been used in several previous studies zrinji and burn 1994 holmes et al 2002 gaál et al 2008 das and cunnane 2011 perica et al 2011 perica et al 2013 hailegeorgis et al 2013 das 2017 dehghan et al 2019 the roi approach has limitations imposed by subjectivity involved in the choice of attribute variables attributes weights and threshold distance in the attribute space bobée and rasmussen 1995 rao and srinivas 2006 cluster analysis is a method of grouping sites in such a way that sites in the same group cluster are more similar to each other than to those in other groups clustering algorithms can be broadly divided into two groups hierarchical clustering and partitional clustering in hierarchical clustering either individual sites are merged to form clusters agglomerative or a region is divided to form clusters divisive algorithms representative of agglomerative hierarchical clustering include single linkage complete linkage average linkage k linkage ward s algorithm etc partitional clustering divides a region into a natural set of clusters through a single partitioning examples of partitional clustering include k means k median k modes k medoids algorithms both agglomerative hierarchical and partitional clustering have been used in several previous studies periago et al 1991 guttman 1993 trefry et al 2005 satyanarayana and srinivas 2008 dikbas et al 2013 sarhadi and heydarizadeh 2014 abdi et al 2016 fathian and dehghan 2019 all of these clustering algorithms form hard clusters in a sense that each site belongs to only one cluster žalik and žalik 2011 satyanarayana and srinivas 2011 srinivas 2013 which is not valid in real world satyanarayana and srinivas 2011 srinivas 2013 this limitation is overcome by fuzzy clustering algorithm in which a site may belong to different clusters on a scale of 0 to 1 fuzzy clustering algorithms have been used in the studies of satyanarayana and srinivas 2011 srinivas 2013 goyal and gupta 2014 zhang et al 2015 gomes et al 2018 clustering algorithms gained recognition in efforts to reduce subjectivity involved in identification of spatial patterns in pca periago et al 1991 satyanarayana and srinivas 2008 satyanarayana and srinivas 2011 the clustering approach is considered the most practical approach for regional frequency analysis hosking and wallis 1997 it is recommended that clusters should preferably be formed using site characteristics such as latitude longitude elevation etc and at site statistics estimated from data be used for independent validation of homogeneity of delineated clusters hosking and wallis 1997 satyanarayana and srinivas 2008 satyanarayana and srinivas 2011 site characteristics are either deterministic quantities such as latitude longitude elevation etc or are estimated with sufficient accuracy so as to be treated as deterministic quantities e g mean daily precipitation hosking and wallis 1997 recommend the use of clustering algorithms that tend to produce clusters containing equal number of sites such algorithms yield good regions for regional frequency analysis 3 2 3 determination of homogeneous regions via clustering although many different methods are available we used ward s hierarchical clustering algorithm to form preliminary homogeneous regions as recommended by hosking and wallis 1997 ward s methods employs analysis of variance to determine the distance between sites and clusters we used a combination of site characteristics latitude longitude elevation mean daily precipitation long term mean of daily precipitation one for each site and mean monthly precipitation long term mean of monthly precipitation 12 in numbers for each site as attributes for cluster analysis 3 2 4 estimation of homogeneity for validating homogeneity of a cluster a heterogeneity measure h 1 is calculated h 1 compares the dispersion of sample l cv estimates v for a cluster with the dispersion of l cv estimates v l for a realization simulation of a homogeneous region the dispersion of sample l cv v is defined as the weighted by the record length at each station in a cluster standard deviation of sample l cv estimates v l is determined from monte carlo simulation experiments each simulation experiment consists of constructing a homogeneous region with the same number of sites as in the observed sample and each site having the same record length as in the actual sample from a large number of repeated experiments the mean μ v l and standard deviation σ v l of v l are calculated finally the heterogeneity measure h 1 is calculated as 5 h 1 v μ v l σ v l a cluster is declared homogeneous if h 1 2 and heterogeneous if h 1 2 this criterion is reasonable and used in previous studies hosking and wallis 1993 bonnin et al 2006 in deciding if a region is homogeneous or not the following approach is adopted if for a cluster h 1 2 then that cluster is accepted as homogeneous even if it has a few discordant sites for a cluster with h 1 2 the following possibilities are considered first try to merge the discordant site to a nearby cluster second divide the cluster into smaller clusters if none of these adjustments improve homogeneity the regional quantile of the cluster with and without the discordant site is calculated to ensure if there is any significant difference between quantiles if there is no appreciable difference in the quantiles the heterogeneous cluster is accepted as a homogeneous region such adjustments have been used in bonnin et al 2006 3 2 5 selection of the best fitted distribution and estimation of quantiles previous studies have found that fitting only one distribution without any thorough choice of the best fitted distribution increases the uncertainty due to choice of distributions hailegeorgis et al 2009 hailegeorgis et al 2013 zhu et al 2015 choice of distribution and underlying uncertainty in parameter estimation can lead to a large range in quantiles estimates sadegh et al 2018 therefore we chose to fit a variety of distributions to fit the data from all sites the aim is to choose a distribution that not only fits the data approximately but also gives reasonable estimates of the quantiles at each site hosking and wallis 1997 introduced a goodness of fit measure z dist that measures how well the l kurtosis of the fitted distribution matches with the regional averaged l kurtosis of the sample data the goodness of fit measure is defined as 6 z dist τ 4 dist t 4 r b 4 σ 4 where τ 4 dist is the theoretical l kurtosis of the fitted distribution t 4 r is the regional averaged l kurtosis estimated by weighting site specific l kurtosis by their sample sizes σ 4 is the estimate of the standard deviation of t 4 r and is evaluated by repeated monte carlo simulations in the same way as described in the previous section b 4 is the bias correction term added to correct the bias of sample l kurtosis t 4 and is computed from the same monte carlo simulation used to calculate σ 4 the candidate distributions are the generalized logistic glo the generalized extreme value gev the lognormal ln3 the pearson type iii pe3 and the generalized pareto gpa a distribution is considered fit if it satisfies z dist 1 64 if more than one distribution fits the criteria the distribution that has the smallest z dist is chosen once the best fitted distribution is selected the population parameters θ k k 1 k of the fitted distribution are estimated by equating the population l moments of the distribution to the sample l moments from the data hosking and wallis 1997 define the procedure as follows suppose the region has n sites with site i having record length n i sample mean l 1 i and sample l moments ratios t i t 3 i t 4 i the corresponding regional average l moment ratios t r t 3 r t 4 r are calculated as a t r i 1 n n i t i i 1 n n i b t r r i 1 n n i t r i i 1 n n i r 3 4 the regional average mean l 1 r is set equal to 1 this is done by dividing the site specific data amp in our case by their mean mean of amp at each site then the mean of the rescaled data is 1 for each site and so the regional average of these means is also 1 equating population l moments of the fitted distribution λ 1 τ τ 3 τ 4 to the regional average l moment ratios l 1 r t r t 3 r t 4 r calculated above gives the estimates θ k k 1 k of the parameters of the fitted distribution the regional quantiles q f are estimated by the inverse function of f as q f q f θ 1 θ k finally the site specific quantiles precipitation estimates for different return periods are calculated by using eq 4 3 2 6 estimation of confidence intervals hosking and wallis 1997 proposed a method for estimating confidence intervals with calibration in mind a personal communication from j r m hosking calibration of a confidence interval is an assertion that over the possible outputs of a particular data generating process with a parameter θ a 90 confidence interval will contain the true parameter value 90 of the time the estimation procedure for confidence intervals is based upon monte carlo simulations the simulations take into account the possibility of heterogeneity in the region misspecification of the frequency distribution and intersite dependence cross correlation between sites the simulations match particular characteristics of the data use the same number of sites record length at each site and regional averaged l moment ratios as the actual data the complete procedure is mentioned in section 6 4 of hosking and wallis 1997 and is not described here for the sake of brevity since we exactly followed the procedure outlined in section 6 4 of hosking and wallis 1997 we argue that the confidence intervals from our estimates are reasonably calibrated we have used r statistical package lmomrfa for regional frequency analysis hosking 2009 3 3 interpolating precipitation estimates the basic idea of kriging is to estimate the value of a spatial variable at unobserved locations by computing a weighted average of the values at nearby observed locations we use a form of kriging that assumes constant but unknown mean μ x of the variables the predicted value y x o of unknown quantity y x o at unobserved location x o is calculated as 8 y x o i 1 n ψ i y x i where y x i is the observed value at a locations x i i 1 2 n and ψ i is the kriging weight assigned to observed location x i the kriging weights are chosen such that they minimize the variance of the prediction error δ y x o y x o y x o prior to interpolation the precipitation estimates are transformed using box cox transformation box and cox 1964 to make the spatial distribution of precipitation estimates somewhat normally distributed this is done in order to conveniently interpret the standard errors of the interpolated values box cox transformation is defined by 9 p log p if ϕ 0 p ϕ 1 ϕ otherwise where p is the actual precipitation estimate p is the transformed precipitation estimate ϕ is the transformation parameter estimated using maximum likelihood method we have used r statistical package geor for kriging ribeiro et al 2001 3 4 a metric for comparing precipitation frequency estimates to test if the two precipitation estimates are statistically different we assume that the two precipitation estimates are normally distributed and therefore their differences are also normally distributed the assumption that the precipitation estimates are normally distributed is based upon the central limit theorem which states that for infinitely large sample size the sample mean of the independent and identically distributed random variables is normally distributed while this theorem is technically applicable in an asymptotic limit it holds very well for even moderately finite samples as a general rule of thumb sample mean can be assumed to be normally distributed for sample size of 30 or larger ross 2009 vos and wu 2018 the null hypothesis of the test assumes that the two estimates are the same the test statistic z is formulated as 10 z p t r p t n σ t r 2 n r σ t n 2 n n where p t r and p t n are the t year estimates from two different methods datasets σ t r and σ t n are the standard deviations of the corresponding estimates n r and n n are the number of observations used in calculating p t r and p t n respectively both the terms in the denominator can be derived from confidence intervals of the respective t year estimates for instance the 1 α confidence interval of p t r is expressed as 11 1 α ci p t r z α 2 σ t r n r where z α 2 is the 1 α quantile of the standard normal distribution for α 0 1 corresponding to a 90 confidence interval z 5 equals 1 645 if z 1 645 we say that the null hypothesis cannot be rejected at the 10 significance level or in other words the difference between the two estimates is not significant at 10 significance level similar metrics assuming normality of distribution have been used in a few previous studies nataraj and grenney 2005 madsen et al 2009 4 results 4 1 the kissimmee southern florida watershed fig 1 a shows the stations blue dots included in the analysis the polygon indicates the region of the kissimmee southern florida ksf watershed a total of 189 stations are included and the length of the station data varies between 22 and 131 years 4 1 1 screening of the data the mann kendall test identified a significant trend at 25 out of 189 stations not shown we removed the trend at those stations while maintaining the mean of the time series further we computed lag 1 to lag 6 autocorrelations for each station and found that none of the stations have significant autocorrelation confirming the serial independence of the data 4 1 2 formation of homogeneous regions based upon cluster analysis five preliminary clusters are selected as shown in fig 2 the stations marked with a cross are the discordant stations in their respective clusters as suggested by hosking and wallis 1997 discordancy of the stations is diagnosed an extreme and localized precipitation event at stations new smyrna beach 08 6210 in cluster 2 and cedar key 1 wsw 08 1432 in cluster 5 seems to be responsible for their high discordancy for other discordant stations no obvious problems with the data were found the decision on discordant sites is postponed until the homogeneity measure h 1 of the proposed clusters is calculated table 1 shows values of h 1 for all five clusters it is apparent that h 1 is less than 2 for all clusters therefore the clusters can be regarded as homogeneous regions despite having a few discordant sites 4 1 3 selection of distribution and quantile estimation the results for goodness of fit measure z dist for the candidate distributions are shown in table 1 the minimum z dist values satisfying the criteria z dist 1 64 are shown as bold the gev and gno distributions meet the criteria for clusters 2 4 and 5 the gev gno and pe3 distribution meet the criteria for cluster 3 whereas only the gev distribution meets the required criteria for cluster 1 in case more than one distribution satisfies the criteria the distribution with the least z dist is chosen as the best fitted distribution therefore the gev distribution is selected as the best fitted distribution for clusters 1 2 4 and 5 while the gno distribution is selected for cluster 3 once the best fitted distribution is chosen the parameters e g location scale and shape of the fitted distribution are obtained by the procedure described in the methods section the quantile of the fitted distribution gives q f in eq 4 finally using eq 4 the site specific quantiles are calculated we computed precipitation estimates for multiple return periods ranging from 2 years to 1000 years the results for 5 and 100 year return periods are shown in figs 3 and 4 for a 5 year return period 6 8 5 inches of precipitation is estimated around the south east coast of florida whereas 4 6 inches of precipitation is estimated in and around the watershed fig 3 the bottom right panel in fig 3 shows the average uncertainty of the precipitation estimates the average uncertainty is the average of 5 and 95 confidence intervals the maximum uncertainty of 0 3 0 4 inches is estimated along the south east coast and the least estimated uncertainty is within and around the watershed a closer examination reveals that for nearly 40 of the stations the uncertainty is around 3 5 of the estimate and for nearly 82 of all stations the uncertainty is less than 5 of the estimate the precipitation estimates for 100 year period and their uncertainties are shown in fig 4 for stations near the south east coast 14 17 inches of precipitation is estimated whereas for stations in the watershed 7 14 inches of precipitation is estimated for nearly 40 of the stations the uncertainty is around 11 12 of the estimate and for nearly 42 of the stations the uncertainty is around 15 16 of the estimate 4 1 4 mapping precipitation estimates the spatial maps and corresponding standard errors for 5 and 100 year return periods are shown in fig 5 as in figs 3 and 4 the maximum precipitation estimates for both the return periods are obtained along the south east coast the regions away from the coast have lower precipitation estimates the standard errors of the estimates quantify uncertainty in the spatial mapping 4 2 the sacramento san joaquin watershed fig 1 c shows the boundary of the watershed inside the two black polygons blue dots are the stations included in the analysis fig 1 d shows the mean daily precipitation in california it is apparent that the pattern of the mean daily precipitation mdp roughly matches with the terrain of california for instance the maximum mdp is observed along the northern coastal ranges cascade ranges and the northern sierra nevada whereas lowest mdp is observed in the central valley generally speaking precipitation increases from south to north and from lower to higher elevations in the sierra nevada windward zone for the reasons discussed in section 4 2 2 we divided california into 6 climate zones as shown in fig 1 c 4 2 1 screening of the data the data used include 153 stations in the central valley 86 in the north mountains 54 in the sierra nevada windward 39 in the sierra nevada leeward and 11 stations in the north coast zone we performed the analysis in each of the zones separately the test for stationarity using mann kendall test revealed that not more than 10 of the stations had significant trend in any of the climate zones we removed the significant trend from those stations as described in the methods section further lag 1 to lag 6 autocorrelation analysis indicated that none of the stations had significant autocorrelation 4 2 2 formation of homogeneous regions the initial clustering procedure applied the clustering algorithm over all stations shown in fig 1 c however some of the resulting clusters were highly heterogeneous and required subjective adjustments such as assigning relative importance to the site attributes choosing a combination of attributes over the other and so on dividing the stations into different climate zones as shown in fig 1 c prior to applying the clustering algorithm resulted in more homogeneous clusters with few adjustments the five climate zones are the north coast cyan the central valley red the sierra nevada windward green the sierra nevada leeward magenta and the north mountains comprising the cascade range and the northern coastal range yellow shading results of clustering applied to stations in each of the climate zones are shown in fig 6 all 11 stations in the north coast zone panel a form a single cluster with h 1 0 09 table 2 the north mountain region consists of 86 stations as shown in fig 6 b nine clusters were initially identified by cluster analysis out of which all clusters except clusters 2 and 9 satisfied the homogeneity criteria h 1 2 the h 1 value of original cluster 2 was 3 15 the stations in original cluster 2 are marked with blue squares and black squares inside blue circles our investigation suggested that a division of cluster 2 resulted in more homogeneous regions therefore we split cluster 2 such that nine stations blue squares remained in cluster 2 and the other four stations each marked with a black square enclosed in a blue circle were merged in cluster 6 the homogeneity measures h 1 of revised cluster 6 is 0 8 and of cluster 2 is 2 2 the discordant station 98 0016 in cluster 2 has the shortest record length 26 years and has the highest l kurtosis in the cluster we allowed the discordant station to remain in cluster 2 the h 1 value of cluster 9 is 2 5 the discordancy measure d of station usc00356426 in cluster 9 is 2 21 as against d crit value of 2 14 the station has 111 years of data and has the highest l cv l skewness and l kurtosis values the removal of the discordant station results in improved h 1 value of 1 93 as compared to the previous value of 2 21 the quantile estimates for the cluster after removal of the discordant station changes only by 5 for the 100 year return period therefore cluster 9 is accepted as a homogeneous region for further analysis fig 6 b shows the final homogeneous clusters and table 3 shows the corresponding h 1 values for the north mountains zone clustering analysis reveals 4 clusters for stations in the sierra nevada windward fig 6 c and 3 clusters for stations in the sierra nevada leeward fig 6 d climate zones the clusters in both climate zones satisfy the homogeneity criteria h 1 2 tables 4 and 5 stations in the central valley are divided into 8 clusters as shown in fig 6 except for cluster 6 all other clusters satisfy the homogeneity criteria h 1 2 the heterogeneity measure h 1 for cluster 1 is 1 9 the discordant station kerlinger 04 4508 in cluster 1 has 34 years of data from 1948 to 1983 whereas the discordant station mercey hot spring 04 5550 has 26 years of data from 1933 to 1965 the data records at other stations in cluster 1 are much longer and span until around year 2010 the absence of long and recent data at both of these discordant stations may be responsible for their discordancy in the absence of any physical reason we accepted cluster 1 as a homogeneous region the heterogeneity measure h 1 for cluster 6 is 2 3 the discordancy of the station ferguson rch 04 3020 in cluster 6 may be attributed to a localized and unusually high 12 inches of precipitation on dec 03 1980 we retained this high value of precipitation as the station has already been checked for any error by the data provider noaa the homogeneity of the cluster improves after the removal of the station from cluster 1 but the quantile estimates change only by 2 after the removal therefore cluster 6 is accepted as a homogeneous region table 6 shows h 1 values for clusters in the central valley 4 2 3 selection of distribution and quantile estimation the best fitted distributions for the clusters in each climate zone are given in tables 2 6 as is clear from the tables the gev distribution best fits in most of the clusters the precipitation estimates for 5 and 100 years are shown in figs 7 and 8 as indicated in fig 7 the highest 5 year precipitation is estimated along the sierra nevada ranges and the least in the central valley region the average uncertainty in the estimates is less than 16 for nearly 82 stations whereas the highest average uncertainty of 22 24 is estimated for less than 7 of total stations fig 7 gives an estimate for 100 year precipitation as for 5 year return period the maximum precipitation is estimated along the sierra nevada ranges and the least in the central valley region interestingly the maximum average uncertainty in the estimates is less than 7 at any location for nearly 86 of the stations the average uncertainty is less than 5 4 2 4 mapping precipitation estimates the spatial mapping of the station specific precipitation estimates is shown in fig 9 the station specific precipitation estimates were log transformed prior to kriging for both the 5 and 100 year return periods the lowest precipitation is estimated for the central valley and the northern regions north of 41 latitude and east of 122 longitude the highest precipitation is estimated along the sierra nevada ranges panels b and d provide uncertainties associated with the 5 and 100 year precipitation estimates 5 calibration of estimates in recognizing that the estimated quantiles pertain to rare events e g 1 in 100 year rainfall it follows that the accuracy of these estimates cannot be robustly calculated using available data cloke and pappenberger 2009 however we argue that the method adopted in this study produces estimates that can be considered reasonably calibrated as discussed in section 3 2 6 to support this claim we adopt an approach based upon calibration methods adopted in the field of probabilistic forecasting gneiting et al 2007 gneiting and katzfuss 2014 cloke and pappenberger 2009 emerton et al 2016 therein the statement is made that calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize gneiting et al 2007 in practice one way to assess calibration is via probability integral transform pit histograms pit is defined as follows if f denotes a fixed nonrandom predictive cumulative distribution function for an observation y the probability integral transform pit is the random variable z f f y if f is continuous and y f then z f is uniform the forecast f is considered to be probabilistically calibrated if its pit z f has a standard uniform distribution gneiting and katzfuss 2014 we apply this calibration assessment to the best fitted distribution for all sites in a cluster as explained in section 3 2 5 if the pit histogram of the best fitted distribution is uniform in the interval 0 1 it can be reasonably assumed that precipitation frequency estimates and their confidence intervals computed from the calibrated distributions are also calibrated fig 10 shows pit histograms computed for each cluster in the two watersheds the top five panels belong to clusters in southern florida and the rest pertain to clusters in the sacramento san joaquin watershed a visual examination of pit histograms in the figure suggests that cdfs of fitted distributions can be assumed to be reasonably calibrated pit histograms are roughly uniform in all clusters this suggests that our estimates and their confidence intervals computed from the calibrated distributions are also reasonably calibrated 6 comparison with noaa estimates we use the metric defined in section 3 4 to quantitatively compare our estimates with that of the noaa estimates figs 11 14 illustrate the qualitative and quantitative differences between the station specific precipitation estimates computed from our study here referred to as rfa and that from noaa atlas 14 report here referred to as noaa we compared the precipitation estimates and their uncertainties at all stations in the two watersheds but for the sake of convenience here we show only analyses done on a sample of 14 stations spread across the watersheds the stations have been picked arbitrarily and are representative samples of the different zones clusters in the watershed fig 11 shows the precipitation estimates for kissimmee southern florida watershed from our study and noaa atlas 14 report the curves are the precipitation estimates as a function of return periods and the shadings are the corresponding 90 confidence intervals for all the stations and for all the return periods the two estimates are close to each other and the confidence intervals overlap each other strikingly the uncertainties of the rfa estimates are much lower than that of the noaa estimates as indicated by narrower confidence intervals of rfa estimates the statistical similarity of the two curves is shown in fig 12 in the figure the blue curve is the z score computed as in eq 10 and shown as a function of the return period the red dashed lines are 5 significance levels it is clear that for all the stations and for all the return periods shown the two estimates are not different at the 10 significance level fig 13 shows the precipitation estimates for the sacramento san joaquin watershed from our study and noaa atlas 14 report it is apparent that for some stations the two estimates are essentially coincident and their confidence intervals also overlap however for station 04 0731 the two estimates including their confidence intervals are different for 10 year or longer return periods noticeably confidence intervals around our estimates are narrower than that around noaa s the statistical similarity of the two estimates is shown in the form of z score in fig 14 for station 04 0731 the two estimates are different at 10 significance level for 10 year or longer return periods for station 04 9855 for all return periods except for 2 years the two estimates are not different at the 10 significance level for station 04 3369 for 2 year return period the two estimates are statistically different at the 10 significance level in general the two estimates are not different at the 10 level for most of the stations investigated there may be multiple reasons for differences between the two estimates the two main sources of uncertainty are 1 different methods to identify homogeneous regions and 2 choice of different frequency distributions fitted to the data zhu et al 2015 hailegeorgis et al 2013 noaa used roi approach for regionalization whereas we use clustering approach it is not clear from available noaa atlas 14 reports what the additional measures were that were taken to validate the homogeneity of groups of stations formed using the roi approach the method adopted here uses an additional measure based upon homogeneity criteria h 1 to ensure homogeneity of clusters moreover though noaa tested multiple distributions for fitting to the data they eventually fit only the gev distribution arguing that for most of the stations gev distributions fit the data in contrast our estimates are based upon fitting a wide variety of candidate distributions to the data 7 summary the main objective of this study is to demonstrate a unified and automated framework for pf analysis of extreme precipitation events availability of multiple datasets and the need for decision relevant approaches necessitate the development of such a framework based upon a thorough literature search we devise a methodology that involves three steps first use of regional frequency analysis using the l moments method for computing precipitation frequency estimates for any duration over a region clustering algorithms are the preferred methods for regionalization and in this analysis we used ward s hierarchical clustering algorithm second kriging is used for interpolating values to locations between observed sites lastly a metric objectively and quantitatively compares the two different precipitation estimates the proposed metric is based upon the central limit theorem and accounts for uncertainty in the estimates the unified framework serves as a baseline for assessing climate models performances in their historical and future climate simulations to demonstrate the applicability of this approach in regions of any geographical complexity we computed 24 h precipitation frequency estimates in the kissimmee southern florida and sacramento san joaquin watersheds the two case study regions in the project these watersheds are quite different with the former being smaller and relatively flat while the latter having complex topography a novelty of this study is our analysis of the pit histogram of the best fitted distribution to show that the pf estimates and their confidence intervals are reasonably calibrated a method common in probabilistic forecasting we compared our estimates with that from noaa the comparison indicates that our estimates are statistically similar at most of the locations moreover the uncertainty in our estimates is lower than that in noaa atlas 14 reports we claim that the methodology adopted here is valuable for evaluating precipitation estimates for different durations in climate models adopting a unified approach for evaluating datasets provides a clean mechanism for inter model comparisons as in other statistical methods the method of regional frequency analysis using l moments also has some limitations one of the assumptions of the rfa is that the data are random variables however rescaling the data by the sample mean may create data that may not be random sveinsson et al 2002 also methods based upon regionalization tend to reduce the variation in pf estimates in a region considered homogeneous it may enhance discontinuities at the regional boundaries trefry et al 2005 despite these limitations the method has emerged as the dominant method in the field because of its robust quantile estimations credit authorship contribution statement abhishekh srivastava conceptualization methodology software validation formal analysis investigation writing original draft writing review editing richard grotjahn conceptualization validation resources writing review editing supervision paul a ullrich conceptualization validation resources writing review editing supervision project administration funding acquisition mark risser methodology validation software writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors sincerely thank j r m hosking for his valuable suggestions and comments on the procedures described in hosking and wallis 1997 the authors thank mike fennessy and dr j shukla of george mason university usa for providing access to the prism data the authors also thank dr timothy delsole of george mason university usa for his valuable suggestions on the statistical interpretation of the results this work is supported by the department of energy office of science award number de sc0016605 an integrated evaluation of the simulated hydroclimate system of the continental us additional support comes from the usda national institute of food and agriculture hatch project accession no 1001953 and 1010971 
6186,although a variety of climate datasets are now available including observational and model products there remains a pressing need for the development of a unified automated and application focused approach for evaluating and comparing climate extremes within and across these datasets precipitation frequency pf estimates for extreme precipitation events are useful decision relevant quantities among water managers our objective and quantitative framework for computing pf estimates of any duration uses known techniques in a novel combination our framework consists of three steps 1 use of a regionalization based statistical method for precipitation frequency estimation at observed sites this involves hierarchical clustering here we used ward s method for delineating homogeneous regions and regional frequency analysis using l moments 2 use of kriging for spatial mapping because of its advantages over other conventional interpolation methods 3 use of z scores accounts for estimation uncertainties when comparing pf estimates between datasets the 24 h pf estimates in the kissimmee southern florida watershed flat topography and the sacramento san joaquin watershed complex topography demonstrate the applicability of this approach in regions of any geographical complexity our results are shown to be reasonably calibrated using the probability integral transform pit histogram of the best fitted distribution our results are compared with that of the noaa atlas 14 reports and show that for most of the stations the two estimates are statistically indistinguishable and the confidence intervals of our estimates are narrower than those of the noaa estimates our approach is applicable to a variety of datasets and provides a baseline for assessing performance of climate models in historical simulations a necessary first step towards analyzing future projections keywords regional frequency analysis rfa using l moments extreme precipitation intensity duration frequency idf estimates clustering analysis kriging calibration using pit histogram 1 introduction in this work we present a framework for estimating intensity duration frequency idf curves or precipitation frequency pf estimates of extreme precipitation events of different durations pf estimates are used for advance planning and management of extreme precipitation events the pf estimates provide information support for a wide variety of civil activities such as designing flood protection structures urban drainage systems and agricultural planning schaefer 1990 parrett 1997 trefry et al 2005 norbiato et al 2007 cheng and aghakouchak 2014 agilan and umamahesh 2018 our methodology involves three steps first the use of a regionalization based statistical method for precipitation frequency estimation at observed sites second the use of an interpolation method that quantifies both the estimates and their associated uncertainties between observed locations third a proposed metric that can objectively quantify differences in precipitation estimates between datasets observed vs model model vs model in the remainder of this section we present a brief literature review of available methods and approaches and demonstrate the rationale behind choosing methods that are optimal to our proposed framework the first step in our methodology is to choose a statistical method for precipitation frequency analysis precipitation frequency analysis can either be site specific or regional but reliable estimation at sites can be problematic because of short data records consequently regional frequency analysis rfa has been developed to avoid this issue rfa pools the data from nearby stations with similar characteristics to the target station this procedure is called regionalization stedinger 1993 some variants of rfa are based upon multiple regression analysis that relate regional attributes to quantiles or parameters of the probability distribution at a site riggs 1973 kroll and stedinger 1998 reis et al 2005 griffis and stedinger 2007 ahn and palmer 2016 durocher et al 2019 the detailed description of regression based methods is out of the scope of this paper an important variant of rfa is the index flood based approach which assumes that all sites inside a homogeneous region have identical frequency distribution apart from a site specific scaling factor called the index flood dalrymple 1960 hosking and wallis 1997 naghettini 2017 subjectivity involved in the formation of homogeneous regions is still a topic of current research naghettini 2017 a unified approach proposed by hosking and wallis 1997 combines the index flood procedure with the l moments based estimation method in this method l moments are not only used to estimate regional parameters and quantiles but also to build regional statistics such as formation of homogeneous regions capable of reducing subjectivity involved in the formation of homogeneous regions the method of regional frequency analysis using l moments is considered to be among the most relevant and efficient approaches bobée and rasmussen 1995 bonnin et al 2006 what makes the method of l moments preferable to others is that l moments uniquely define a distribution and l moments are less sensitive than other moments to outliers hosking 2014 we use rfa with the method of l moments as described in hosking and wallis 1997 there are several methods prevalent for regionalization here we use ward s hierarchical clustering algorithm for regionalization clustering based algorithms and other methods of regionalization are discussed further in section 3 2 2 the second step in our proposed framework is the use of a comprehensive interpolation method to provide precipitation estimates between observed locations conventional interpolation methods such as distance weighting thin plate splines etc have some shortcomings for example they use arbitrarily assigned weights do not account for clustering of data and most importantly do not quantify uncertainties associated with the interpolation a sophisticated and widely popular interpolation method in geostatistics is kriging simply speaking kriging provides the minimum variance unbiased linear estimates at unmeasured locations watkins et al 2005 the advantages of kriging are that it accounts for spatial correlation of the data being mapped accounts for clustering of data and quantifies uncertainty of interpolated estimates in terms of the standard error of the estimates pierre 1997 coburn 2000 various forms of kriging have been used previously for spatially interpolating the precipitation estimates goovaerts 2000 watkins et al 2005 szolgay et al 2009 mair and fares 2010 frazier et al 2016 das 2019 durocher et al 2019 risser et al 2019 the mathematical details of kriging used in our study are given in section 3 3 the third step in our methodology is the use of a metric to objectively compare two different precipitation estimates most of the previous studies only consider the difference in the estimates without taking the uncertainty in estimates into account we present a metric that quantifies statistical differences between the precipitation estimates by considering both the estimates and their uncertainties the method is described in section 3 4 to demonstrate the applicability of this approach in regions of any geographical complexity we compute 24 h pf estimates in the kissimmee southern florida watershed and the sacramento san joaquin watershed the two case study regions in the project the kissimmee southern florida watershed is important for water supply and maintaining important ecological services the main issues concerning civil authorities are water supply for a growing population flooding in dense urban areas sea level rise and restoration of natural ecosystems such as the everglades koebel and bousquin 2014 south florida water management district 2018 the sacramento san joaquin watershed in california provides drinking and irrigation water to the local population the watershed largely depends on the winter snowfall for supply to its reservoirs u s department of interior bureau of reclamation s 2016 secure water act report identifies that increasing temperatures may cause variable precipitation over the next century and may also result in less snowfall resulting in more rain on snow events mote et al 2005 we compute 24 h precipitation estimates for nine return periods 2 5 10 25 50 100 200 500 and 1000 years the methodology adopted here is valuable for ongoing efforts in evaluating pf estimates in observations and climate models given that many regional climate models and climate datasets are now available a unified and automated approach that can objectively evaluate and validate these datasets in light of observations is needed this study proposes such a unified framework from input data to rfa based pf estimation to kriging based spatial mapping of the estimates and finally a metric for scoring different datasets that takes estimation uncertainty into account a novelty of this study is the analysis of the probability integral transform pit histogram of the best fitted distribution to show that the pf estimates and their confidence intervals are reasonably calibrated a method common in probabilistic forecasting the homogeneous clusters obtained in the observations may also be used as reference clusters in all models using the same reference clusters in observations and across all models offers a clean approach to comparing across datasets and also allows for automation of the analysis procedure to some extent we suggest this procedure is desirable over previous studies that analyze and compare pf estimates in historical and future simulations on a station by station basis the remainder of the paper is summarized as follows section 2 outlines the sources of the data used in the study section 3 presents approaches and methods section 4 discusses results of the analysis calibration of estimates is discussed in section 5 a comparison of our results with that of the noaa estimates is presented in section 6 and lastly section 7 summarizes the results 2 data for this analysis the data is in the form of station based 24 h annual maximum precipitation amp timeseries the amp data is presently available from the noaa atlas 14 website https hdsc nws noaa gov hdsc pfds pfds map cont html we use the noaa atlas 14 data because data at each station have already passed quality assessments and checks and many possible errors in the data including unphysical outliers have been removed the amp timeseries is constructed from daily precipitation timeseries for each calendar year january 1 december 31 for the kissimmee southern florida watershed and each water year october 1 september 30 for the sacramento san joaquin watershed perica et al 2011 perica et al 2013 since the amp data for stations at the shasta reservoir in the sacramento san joaquin watershed are missing from the noaa atlas 14 the corresponding amp data is constructed from daily global historical climatological network daily ghcnd data maintained by noaa https www ncdc noaa gov ghcnd data access the quality of the ghcnd data has been tested for both the errors and outliers no outliers were found gridded precipitation data has been constructed from the daily prism data over 1981 2016 daly et al 1994 gridded precipitation data are used to construct mean daily and monthly precipitation time series both the long term mean daily and monthly precipitation time series are used as attributes for cluster analysis 3 method 3 1 statistics of l moments l moments are defined as certain linear combinations of order statistics of a random sample hosking and wallis 1993 hosking and wallis 1997 the l moments can be derived from the probability weighted moments pwms greenwood et al 1979 a pwm is defined as 1 β r 0 1 x f f r df where x f is the quantile function in terms of cumulative distribution function f for an ordered set of independent and identically distributed random variables x 1 x 2 x 2 x n an unbiased estimator of β r can be derived as 2a β r 1 n i 1 n i 1 r n 1 r x i certain linear combinations of β r give l moments of the data for example the first three l moments can be expressed as 2b λ 1 β 0 2c λ 2 2 β 1 β 0 2d λ 3 6 β 2 6 β 1 β 0 the first two l moments λ 1 and λ 2 are the measures of the sample mean and scale a dispersion measure of the distribution respectively the l moments are used to derive l moment ratios one of the l moment ratios called sample l cv is given by t λ 2 λ 1 the sample l cv is analogous to the conventional coefficient of variation the other sample l moment ratios are defined as 3 t r λ r λ 2 r 3 4 t 3 and t 4 are called sample l skewness and l kurtosis respectively as compared to the other conventional methods l moments based methods are less susceptible to the presence of outliers and are more robust to sampling variability a detailed description of l moments can be found in hosking and wallis 1997 and naghettini 2017 3 2 regional frequency analysis using l moments if q i f represents the quantile as a function of cumulative distribution function f at site i i 1 2 n then we may write 4 q i f μ i q f i 1 n where μ i is the index flood usually the mean of the at site frequency distribution here q f is a dimensionless quantile function called the regional growth curve and is the quantity estimated in regional frequency analysis once q f is estimated the site specific quantile is calculated using 4 3 2 1 screening of the data the index flood approach assumes that the observations at a site are stationary serially independent and independent of observations at other sites no cross correlation we tested the stationarity assumption by using the mann kendall trend test at the 5 significance level and removed any significant linear trend from the data while maintaining the mean of the time series the criteria of serial independence is tested by analyzing the lag 1 to lag 6 autocorrelation at the 95 significance level previous studies show that the impact of cross correlation on the pf estimates is minimal hosking and wallis 1993 perica et al 2011 therefore we did not address the issue of cross correlation in the calculation of pf estimates however cross correlation reduces the number of independent sites in a region which has been accounted for in the calculation of confidence intervals of the estimates hosking and wallis 1997 hosking and wallis 1997 suggested a discordancy measure d based upon comparison of l moment ratios for a given site with the average l moment ratios for a group of sites a site is declared discordant if d is greater than a critical discordancy value d crit typically d crit increases with the number of sites in the region and is equal to 3 for a group of 15 sites or more the discordancy measure d is capable of identifying gross errors and outliers in the data and hence is used for screening the data d has one more purpose in regional frequency analysis after a group of sites is tentatively identified as a homogeneous region d is recalculated for the proposed homogeneous region if a site is identified as discordant the possibility of moving that site out of the proposed homogeneous region is considered however hosking and wallis 1997 cautioned that a site may be discordant by a random chance or because of a localized extreme event that did not affect other sites in the proposed homogeneous region 3 2 2 review of methods of regionalization a variety of regionalization methods has been developed in the past few decades they include correlation analysis based approaches such as elementary linkage analysis and canonical correlation analysis principal component analysis the region of influence approach and cluster analysis this list of methods is only indicative and not exhaustive of all the methods in practice it is worth mentioning that all of these methods have their own advantages and disadvantages and their specific use may depend on specific applications and situations elementary linkage analysis is a variant of correlation based methods jackson 1973 adelekan 1998 in elementary linkage analysis two sites that have the strongest positive correlation are assigned the same region additional sites are added to the region based upon their significant correlations with the sites in the provisional region this process is repeated until all sites are partitioned into coherent regions the limitations of correlation based approaches are that they involve subjectivity in selecting a correlation threshold value and that they are insensitive to the magnitude of differences in correlated variables unal et al 2003 satyanarayana and srinivas 2008 irwin 2015 canonical correlation analysis cca is another variant of correlation based methods in which a linear combination of regional characteristics that has the strongest correlation with the hydrologic parameters is identified cca is a widely used method cavadias 1989 ouarda et al 2001 chokmani and ouarda 2004 leclerc and ouarda 2007 shu and ouarda 2007 khalil et al 2019 and is useful in evaluating linear relationship between two variables the problem with this method is that the pattern recognition is based on a subjective visual analysis and that there is no guarantee that a pattern will be detected bobée and rasmussen 1995 rao and srinivas 2006 also results obtained by cca are sensitive to number of sites in the region ouarda et al 2001 leclerc and ouarda 2007 principal component analysis pca is a method that decomposes data into a set of uncorrelated orthogonal components pca and its variations have been popular in regionalization for example li juan et al 2009 used simple principal component analysis for mapping precipitation regimes in china miller and goodrich 2007 used rotated pca for regionalization of winter precipitation in the north western usa darand and mansouri daneshvar 2014 and raziei 2018 employed s mode of pca for regionalization of precipitation in iran the major limitation of pca based approaches is that they are ineffective when a large number of components describe total variance of the dataset in areas with complex topography little variance is explained by the leading principal components therefore pca based approaches are not suitable in such regions srinivas 2013 irwin 2015 serra et al 1996 the region of influence roi approach burn 1990 considers each target site as a one site region the sites in the region are included based upon their distance from the target site in the geographic and other attributes space one of the main advantages of the roi method is that it results in a smooth transition in estimates across regional boundaries perica et al 2011 perica et al 2013 this approach has also been used in several previous studies zrinji and burn 1994 holmes et al 2002 gaál et al 2008 das and cunnane 2011 perica et al 2011 perica et al 2013 hailegeorgis et al 2013 das 2017 dehghan et al 2019 the roi approach has limitations imposed by subjectivity involved in the choice of attribute variables attributes weights and threshold distance in the attribute space bobée and rasmussen 1995 rao and srinivas 2006 cluster analysis is a method of grouping sites in such a way that sites in the same group cluster are more similar to each other than to those in other groups clustering algorithms can be broadly divided into two groups hierarchical clustering and partitional clustering in hierarchical clustering either individual sites are merged to form clusters agglomerative or a region is divided to form clusters divisive algorithms representative of agglomerative hierarchical clustering include single linkage complete linkage average linkage k linkage ward s algorithm etc partitional clustering divides a region into a natural set of clusters through a single partitioning examples of partitional clustering include k means k median k modes k medoids algorithms both agglomerative hierarchical and partitional clustering have been used in several previous studies periago et al 1991 guttman 1993 trefry et al 2005 satyanarayana and srinivas 2008 dikbas et al 2013 sarhadi and heydarizadeh 2014 abdi et al 2016 fathian and dehghan 2019 all of these clustering algorithms form hard clusters in a sense that each site belongs to only one cluster žalik and žalik 2011 satyanarayana and srinivas 2011 srinivas 2013 which is not valid in real world satyanarayana and srinivas 2011 srinivas 2013 this limitation is overcome by fuzzy clustering algorithm in which a site may belong to different clusters on a scale of 0 to 1 fuzzy clustering algorithms have been used in the studies of satyanarayana and srinivas 2011 srinivas 2013 goyal and gupta 2014 zhang et al 2015 gomes et al 2018 clustering algorithms gained recognition in efforts to reduce subjectivity involved in identification of spatial patterns in pca periago et al 1991 satyanarayana and srinivas 2008 satyanarayana and srinivas 2011 the clustering approach is considered the most practical approach for regional frequency analysis hosking and wallis 1997 it is recommended that clusters should preferably be formed using site characteristics such as latitude longitude elevation etc and at site statistics estimated from data be used for independent validation of homogeneity of delineated clusters hosking and wallis 1997 satyanarayana and srinivas 2008 satyanarayana and srinivas 2011 site characteristics are either deterministic quantities such as latitude longitude elevation etc or are estimated with sufficient accuracy so as to be treated as deterministic quantities e g mean daily precipitation hosking and wallis 1997 recommend the use of clustering algorithms that tend to produce clusters containing equal number of sites such algorithms yield good regions for regional frequency analysis 3 2 3 determination of homogeneous regions via clustering although many different methods are available we used ward s hierarchical clustering algorithm to form preliminary homogeneous regions as recommended by hosking and wallis 1997 ward s methods employs analysis of variance to determine the distance between sites and clusters we used a combination of site characteristics latitude longitude elevation mean daily precipitation long term mean of daily precipitation one for each site and mean monthly precipitation long term mean of monthly precipitation 12 in numbers for each site as attributes for cluster analysis 3 2 4 estimation of homogeneity for validating homogeneity of a cluster a heterogeneity measure h 1 is calculated h 1 compares the dispersion of sample l cv estimates v for a cluster with the dispersion of l cv estimates v l for a realization simulation of a homogeneous region the dispersion of sample l cv v is defined as the weighted by the record length at each station in a cluster standard deviation of sample l cv estimates v l is determined from monte carlo simulation experiments each simulation experiment consists of constructing a homogeneous region with the same number of sites as in the observed sample and each site having the same record length as in the actual sample from a large number of repeated experiments the mean μ v l and standard deviation σ v l of v l are calculated finally the heterogeneity measure h 1 is calculated as 5 h 1 v μ v l σ v l a cluster is declared homogeneous if h 1 2 and heterogeneous if h 1 2 this criterion is reasonable and used in previous studies hosking and wallis 1993 bonnin et al 2006 in deciding if a region is homogeneous or not the following approach is adopted if for a cluster h 1 2 then that cluster is accepted as homogeneous even if it has a few discordant sites for a cluster with h 1 2 the following possibilities are considered first try to merge the discordant site to a nearby cluster second divide the cluster into smaller clusters if none of these adjustments improve homogeneity the regional quantile of the cluster with and without the discordant site is calculated to ensure if there is any significant difference between quantiles if there is no appreciable difference in the quantiles the heterogeneous cluster is accepted as a homogeneous region such adjustments have been used in bonnin et al 2006 3 2 5 selection of the best fitted distribution and estimation of quantiles previous studies have found that fitting only one distribution without any thorough choice of the best fitted distribution increases the uncertainty due to choice of distributions hailegeorgis et al 2009 hailegeorgis et al 2013 zhu et al 2015 choice of distribution and underlying uncertainty in parameter estimation can lead to a large range in quantiles estimates sadegh et al 2018 therefore we chose to fit a variety of distributions to fit the data from all sites the aim is to choose a distribution that not only fits the data approximately but also gives reasonable estimates of the quantiles at each site hosking and wallis 1997 introduced a goodness of fit measure z dist that measures how well the l kurtosis of the fitted distribution matches with the regional averaged l kurtosis of the sample data the goodness of fit measure is defined as 6 z dist τ 4 dist t 4 r b 4 σ 4 where τ 4 dist is the theoretical l kurtosis of the fitted distribution t 4 r is the regional averaged l kurtosis estimated by weighting site specific l kurtosis by their sample sizes σ 4 is the estimate of the standard deviation of t 4 r and is evaluated by repeated monte carlo simulations in the same way as described in the previous section b 4 is the bias correction term added to correct the bias of sample l kurtosis t 4 and is computed from the same monte carlo simulation used to calculate σ 4 the candidate distributions are the generalized logistic glo the generalized extreme value gev the lognormal ln3 the pearson type iii pe3 and the generalized pareto gpa a distribution is considered fit if it satisfies z dist 1 64 if more than one distribution fits the criteria the distribution that has the smallest z dist is chosen once the best fitted distribution is selected the population parameters θ k k 1 k of the fitted distribution are estimated by equating the population l moments of the distribution to the sample l moments from the data hosking and wallis 1997 define the procedure as follows suppose the region has n sites with site i having record length n i sample mean l 1 i and sample l moments ratios t i t 3 i t 4 i the corresponding regional average l moment ratios t r t 3 r t 4 r are calculated as a t r i 1 n n i t i i 1 n n i b t r r i 1 n n i t r i i 1 n n i r 3 4 the regional average mean l 1 r is set equal to 1 this is done by dividing the site specific data amp in our case by their mean mean of amp at each site then the mean of the rescaled data is 1 for each site and so the regional average of these means is also 1 equating population l moments of the fitted distribution λ 1 τ τ 3 τ 4 to the regional average l moment ratios l 1 r t r t 3 r t 4 r calculated above gives the estimates θ k k 1 k of the parameters of the fitted distribution the regional quantiles q f are estimated by the inverse function of f as q f q f θ 1 θ k finally the site specific quantiles precipitation estimates for different return periods are calculated by using eq 4 3 2 6 estimation of confidence intervals hosking and wallis 1997 proposed a method for estimating confidence intervals with calibration in mind a personal communication from j r m hosking calibration of a confidence interval is an assertion that over the possible outputs of a particular data generating process with a parameter θ a 90 confidence interval will contain the true parameter value 90 of the time the estimation procedure for confidence intervals is based upon monte carlo simulations the simulations take into account the possibility of heterogeneity in the region misspecification of the frequency distribution and intersite dependence cross correlation between sites the simulations match particular characteristics of the data use the same number of sites record length at each site and regional averaged l moment ratios as the actual data the complete procedure is mentioned in section 6 4 of hosking and wallis 1997 and is not described here for the sake of brevity since we exactly followed the procedure outlined in section 6 4 of hosking and wallis 1997 we argue that the confidence intervals from our estimates are reasonably calibrated we have used r statistical package lmomrfa for regional frequency analysis hosking 2009 3 3 interpolating precipitation estimates the basic idea of kriging is to estimate the value of a spatial variable at unobserved locations by computing a weighted average of the values at nearby observed locations we use a form of kriging that assumes constant but unknown mean μ x of the variables the predicted value y x o of unknown quantity y x o at unobserved location x o is calculated as 8 y x o i 1 n ψ i y x i where y x i is the observed value at a locations x i i 1 2 n and ψ i is the kriging weight assigned to observed location x i the kriging weights are chosen such that they minimize the variance of the prediction error δ y x o y x o y x o prior to interpolation the precipitation estimates are transformed using box cox transformation box and cox 1964 to make the spatial distribution of precipitation estimates somewhat normally distributed this is done in order to conveniently interpret the standard errors of the interpolated values box cox transformation is defined by 9 p log p if ϕ 0 p ϕ 1 ϕ otherwise where p is the actual precipitation estimate p is the transformed precipitation estimate ϕ is the transformation parameter estimated using maximum likelihood method we have used r statistical package geor for kriging ribeiro et al 2001 3 4 a metric for comparing precipitation frequency estimates to test if the two precipitation estimates are statistically different we assume that the two precipitation estimates are normally distributed and therefore their differences are also normally distributed the assumption that the precipitation estimates are normally distributed is based upon the central limit theorem which states that for infinitely large sample size the sample mean of the independent and identically distributed random variables is normally distributed while this theorem is technically applicable in an asymptotic limit it holds very well for even moderately finite samples as a general rule of thumb sample mean can be assumed to be normally distributed for sample size of 30 or larger ross 2009 vos and wu 2018 the null hypothesis of the test assumes that the two estimates are the same the test statistic z is formulated as 10 z p t r p t n σ t r 2 n r σ t n 2 n n where p t r and p t n are the t year estimates from two different methods datasets σ t r and σ t n are the standard deviations of the corresponding estimates n r and n n are the number of observations used in calculating p t r and p t n respectively both the terms in the denominator can be derived from confidence intervals of the respective t year estimates for instance the 1 α confidence interval of p t r is expressed as 11 1 α ci p t r z α 2 σ t r n r where z α 2 is the 1 α quantile of the standard normal distribution for α 0 1 corresponding to a 90 confidence interval z 5 equals 1 645 if z 1 645 we say that the null hypothesis cannot be rejected at the 10 significance level or in other words the difference between the two estimates is not significant at 10 significance level similar metrics assuming normality of distribution have been used in a few previous studies nataraj and grenney 2005 madsen et al 2009 4 results 4 1 the kissimmee southern florida watershed fig 1 a shows the stations blue dots included in the analysis the polygon indicates the region of the kissimmee southern florida ksf watershed a total of 189 stations are included and the length of the station data varies between 22 and 131 years 4 1 1 screening of the data the mann kendall test identified a significant trend at 25 out of 189 stations not shown we removed the trend at those stations while maintaining the mean of the time series further we computed lag 1 to lag 6 autocorrelations for each station and found that none of the stations have significant autocorrelation confirming the serial independence of the data 4 1 2 formation of homogeneous regions based upon cluster analysis five preliminary clusters are selected as shown in fig 2 the stations marked with a cross are the discordant stations in their respective clusters as suggested by hosking and wallis 1997 discordancy of the stations is diagnosed an extreme and localized precipitation event at stations new smyrna beach 08 6210 in cluster 2 and cedar key 1 wsw 08 1432 in cluster 5 seems to be responsible for their high discordancy for other discordant stations no obvious problems with the data were found the decision on discordant sites is postponed until the homogeneity measure h 1 of the proposed clusters is calculated table 1 shows values of h 1 for all five clusters it is apparent that h 1 is less than 2 for all clusters therefore the clusters can be regarded as homogeneous regions despite having a few discordant sites 4 1 3 selection of distribution and quantile estimation the results for goodness of fit measure z dist for the candidate distributions are shown in table 1 the minimum z dist values satisfying the criteria z dist 1 64 are shown as bold the gev and gno distributions meet the criteria for clusters 2 4 and 5 the gev gno and pe3 distribution meet the criteria for cluster 3 whereas only the gev distribution meets the required criteria for cluster 1 in case more than one distribution satisfies the criteria the distribution with the least z dist is chosen as the best fitted distribution therefore the gev distribution is selected as the best fitted distribution for clusters 1 2 4 and 5 while the gno distribution is selected for cluster 3 once the best fitted distribution is chosen the parameters e g location scale and shape of the fitted distribution are obtained by the procedure described in the methods section the quantile of the fitted distribution gives q f in eq 4 finally using eq 4 the site specific quantiles are calculated we computed precipitation estimates for multiple return periods ranging from 2 years to 1000 years the results for 5 and 100 year return periods are shown in figs 3 and 4 for a 5 year return period 6 8 5 inches of precipitation is estimated around the south east coast of florida whereas 4 6 inches of precipitation is estimated in and around the watershed fig 3 the bottom right panel in fig 3 shows the average uncertainty of the precipitation estimates the average uncertainty is the average of 5 and 95 confidence intervals the maximum uncertainty of 0 3 0 4 inches is estimated along the south east coast and the least estimated uncertainty is within and around the watershed a closer examination reveals that for nearly 40 of the stations the uncertainty is around 3 5 of the estimate and for nearly 82 of all stations the uncertainty is less than 5 of the estimate the precipitation estimates for 100 year period and their uncertainties are shown in fig 4 for stations near the south east coast 14 17 inches of precipitation is estimated whereas for stations in the watershed 7 14 inches of precipitation is estimated for nearly 40 of the stations the uncertainty is around 11 12 of the estimate and for nearly 42 of the stations the uncertainty is around 15 16 of the estimate 4 1 4 mapping precipitation estimates the spatial maps and corresponding standard errors for 5 and 100 year return periods are shown in fig 5 as in figs 3 and 4 the maximum precipitation estimates for both the return periods are obtained along the south east coast the regions away from the coast have lower precipitation estimates the standard errors of the estimates quantify uncertainty in the spatial mapping 4 2 the sacramento san joaquin watershed fig 1 c shows the boundary of the watershed inside the two black polygons blue dots are the stations included in the analysis fig 1 d shows the mean daily precipitation in california it is apparent that the pattern of the mean daily precipitation mdp roughly matches with the terrain of california for instance the maximum mdp is observed along the northern coastal ranges cascade ranges and the northern sierra nevada whereas lowest mdp is observed in the central valley generally speaking precipitation increases from south to north and from lower to higher elevations in the sierra nevada windward zone for the reasons discussed in section 4 2 2 we divided california into 6 climate zones as shown in fig 1 c 4 2 1 screening of the data the data used include 153 stations in the central valley 86 in the north mountains 54 in the sierra nevada windward 39 in the sierra nevada leeward and 11 stations in the north coast zone we performed the analysis in each of the zones separately the test for stationarity using mann kendall test revealed that not more than 10 of the stations had significant trend in any of the climate zones we removed the significant trend from those stations as described in the methods section further lag 1 to lag 6 autocorrelation analysis indicated that none of the stations had significant autocorrelation 4 2 2 formation of homogeneous regions the initial clustering procedure applied the clustering algorithm over all stations shown in fig 1 c however some of the resulting clusters were highly heterogeneous and required subjective adjustments such as assigning relative importance to the site attributes choosing a combination of attributes over the other and so on dividing the stations into different climate zones as shown in fig 1 c prior to applying the clustering algorithm resulted in more homogeneous clusters with few adjustments the five climate zones are the north coast cyan the central valley red the sierra nevada windward green the sierra nevada leeward magenta and the north mountains comprising the cascade range and the northern coastal range yellow shading results of clustering applied to stations in each of the climate zones are shown in fig 6 all 11 stations in the north coast zone panel a form a single cluster with h 1 0 09 table 2 the north mountain region consists of 86 stations as shown in fig 6 b nine clusters were initially identified by cluster analysis out of which all clusters except clusters 2 and 9 satisfied the homogeneity criteria h 1 2 the h 1 value of original cluster 2 was 3 15 the stations in original cluster 2 are marked with blue squares and black squares inside blue circles our investigation suggested that a division of cluster 2 resulted in more homogeneous regions therefore we split cluster 2 such that nine stations blue squares remained in cluster 2 and the other four stations each marked with a black square enclosed in a blue circle were merged in cluster 6 the homogeneity measures h 1 of revised cluster 6 is 0 8 and of cluster 2 is 2 2 the discordant station 98 0016 in cluster 2 has the shortest record length 26 years and has the highest l kurtosis in the cluster we allowed the discordant station to remain in cluster 2 the h 1 value of cluster 9 is 2 5 the discordancy measure d of station usc00356426 in cluster 9 is 2 21 as against d crit value of 2 14 the station has 111 years of data and has the highest l cv l skewness and l kurtosis values the removal of the discordant station results in improved h 1 value of 1 93 as compared to the previous value of 2 21 the quantile estimates for the cluster after removal of the discordant station changes only by 5 for the 100 year return period therefore cluster 9 is accepted as a homogeneous region for further analysis fig 6 b shows the final homogeneous clusters and table 3 shows the corresponding h 1 values for the north mountains zone clustering analysis reveals 4 clusters for stations in the sierra nevada windward fig 6 c and 3 clusters for stations in the sierra nevada leeward fig 6 d climate zones the clusters in both climate zones satisfy the homogeneity criteria h 1 2 tables 4 and 5 stations in the central valley are divided into 8 clusters as shown in fig 6 except for cluster 6 all other clusters satisfy the homogeneity criteria h 1 2 the heterogeneity measure h 1 for cluster 1 is 1 9 the discordant station kerlinger 04 4508 in cluster 1 has 34 years of data from 1948 to 1983 whereas the discordant station mercey hot spring 04 5550 has 26 years of data from 1933 to 1965 the data records at other stations in cluster 1 are much longer and span until around year 2010 the absence of long and recent data at both of these discordant stations may be responsible for their discordancy in the absence of any physical reason we accepted cluster 1 as a homogeneous region the heterogeneity measure h 1 for cluster 6 is 2 3 the discordancy of the station ferguson rch 04 3020 in cluster 6 may be attributed to a localized and unusually high 12 inches of precipitation on dec 03 1980 we retained this high value of precipitation as the station has already been checked for any error by the data provider noaa the homogeneity of the cluster improves after the removal of the station from cluster 1 but the quantile estimates change only by 2 after the removal therefore cluster 6 is accepted as a homogeneous region table 6 shows h 1 values for clusters in the central valley 4 2 3 selection of distribution and quantile estimation the best fitted distributions for the clusters in each climate zone are given in tables 2 6 as is clear from the tables the gev distribution best fits in most of the clusters the precipitation estimates for 5 and 100 years are shown in figs 7 and 8 as indicated in fig 7 the highest 5 year precipitation is estimated along the sierra nevada ranges and the least in the central valley region the average uncertainty in the estimates is less than 16 for nearly 82 stations whereas the highest average uncertainty of 22 24 is estimated for less than 7 of total stations fig 7 gives an estimate for 100 year precipitation as for 5 year return period the maximum precipitation is estimated along the sierra nevada ranges and the least in the central valley region interestingly the maximum average uncertainty in the estimates is less than 7 at any location for nearly 86 of the stations the average uncertainty is less than 5 4 2 4 mapping precipitation estimates the spatial mapping of the station specific precipitation estimates is shown in fig 9 the station specific precipitation estimates were log transformed prior to kriging for both the 5 and 100 year return periods the lowest precipitation is estimated for the central valley and the northern regions north of 41 latitude and east of 122 longitude the highest precipitation is estimated along the sierra nevada ranges panels b and d provide uncertainties associated with the 5 and 100 year precipitation estimates 5 calibration of estimates in recognizing that the estimated quantiles pertain to rare events e g 1 in 100 year rainfall it follows that the accuracy of these estimates cannot be robustly calculated using available data cloke and pappenberger 2009 however we argue that the method adopted in this study produces estimates that can be considered reasonably calibrated as discussed in section 3 2 6 to support this claim we adopt an approach based upon calibration methods adopted in the field of probabilistic forecasting gneiting et al 2007 gneiting and katzfuss 2014 cloke and pappenberger 2009 emerton et al 2016 therein the statement is made that calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize gneiting et al 2007 in practice one way to assess calibration is via probability integral transform pit histograms pit is defined as follows if f denotes a fixed nonrandom predictive cumulative distribution function for an observation y the probability integral transform pit is the random variable z f f y if f is continuous and y f then z f is uniform the forecast f is considered to be probabilistically calibrated if its pit z f has a standard uniform distribution gneiting and katzfuss 2014 we apply this calibration assessment to the best fitted distribution for all sites in a cluster as explained in section 3 2 5 if the pit histogram of the best fitted distribution is uniform in the interval 0 1 it can be reasonably assumed that precipitation frequency estimates and their confidence intervals computed from the calibrated distributions are also calibrated fig 10 shows pit histograms computed for each cluster in the two watersheds the top five panels belong to clusters in southern florida and the rest pertain to clusters in the sacramento san joaquin watershed a visual examination of pit histograms in the figure suggests that cdfs of fitted distributions can be assumed to be reasonably calibrated pit histograms are roughly uniform in all clusters this suggests that our estimates and their confidence intervals computed from the calibrated distributions are also reasonably calibrated 6 comparison with noaa estimates we use the metric defined in section 3 4 to quantitatively compare our estimates with that of the noaa estimates figs 11 14 illustrate the qualitative and quantitative differences between the station specific precipitation estimates computed from our study here referred to as rfa and that from noaa atlas 14 report here referred to as noaa we compared the precipitation estimates and their uncertainties at all stations in the two watersheds but for the sake of convenience here we show only analyses done on a sample of 14 stations spread across the watersheds the stations have been picked arbitrarily and are representative samples of the different zones clusters in the watershed fig 11 shows the precipitation estimates for kissimmee southern florida watershed from our study and noaa atlas 14 report the curves are the precipitation estimates as a function of return periods and the shadings are the corresponding 90 confidence intervals for all the stations and for all the return periods the two estimates are close to each other and the confidence intervals overlap each other strikingly the uncertainties of the rfa estimates are much lower than that of the noaa estimates as indicated by narrower confidence intervals of rfa estimates the statistical similarity of the two curves is shown in fig 12 in the figure the blue curve is the z score computed as in eq 10 and shown as a function of the return period the red dashed lines are 5 significance levels it is clear that for all the stations and for all the return periods shown the two estimates are not different at the 10 significance level fig 13 shows the precipitation estimates for the sacramento san joaquin watershed from our study and noaa atlas 14 report it is apparent that for some stations the two estimates are essentially coincident and their confidence intervals also overlap however for station 04 0731 the two estimates including their confidence intervals are different for 10 year or longer return periods noticeably confidence intervals around our estimates are narrower than that around noaa s the statistical similarity of the two estimates is shown in the form of z score in fig 14 for station 04 0731 the two estimates are different at 10 significance level for 10 year or longer return periods for station 04 9855 for all return periods except for 2 years the two estimates are not different at the 10 significance level for station 04 3369 for 2 year return period the two estimates are statistically different at the 10 significance level in general the two estimates are not different at the 10 level for most of the stations investigated there may be multiple reasons for differences between the two estimates the two main sources of uncertainty are 1 different methods to identify homogeneous regions and 2 choice of different frequency distributions fitted to the data zhu et al 2015 hailegeorgis et al 2013 noaa used roi approach for regionalization whereas we use clustering approach it is not clear from available noaa atlas 14 reports what the additional measures were that were taken to validate the homogeneity of groups of stations formed using the roi approach the method adopted here uses an additional measure based upon homogeneity criteria h 1 to ensure homogeneity of clusters moreover though noaa tested multiple distributions for fitting to the data they eventually fit only the gev distribution arguing that for most of the stations gev distributions fit the data in contrast our estimates are based upon fitting a wide variety of candidate distributions to the data 7 summary the main objective of this study is to demonstrate a unified and automated framework for pf analysis of extreme precipitation events availability of multiple datasets and the need for decision relevant approaches necessitate the development of such a framework based upon a thorough literature search we devise a methodology that involves three steps first use of regional frequency analysis using the l moments method for computing precipitation frequency estimates for any duration over a region clustering algorithms are the preferred methods for regionalization and in this analysis we used ward s hierarchical clustering algorithm second kriging is used for interpolating values to locations between observed sites lastly a metric objectively and quantitatively compares the two different precipitation estimates the proposed metric is based upon the central limit theorem and accounts for uncertainty in the estimates the unified framework serves as a baseline for assessing climate models performances in their historical and future climate simulations to demonstrate the applicability of this approach in regions of any geographical complexity we computed 24 h precipitation frequency estimates in the kissimmee southern florida and sacramento san joaquin watersheds the two case study regions in the project these watersheds are quite different with the former being smaller and relatively flat while the latter having complex topography a novelty of this study is our analysis of the pit histogram of the best fitted distribution to show that the pf estimates and their confidence intervals are reasonably calibrated a method common in probabilistic forecasting we compared our estimates with that from noaa the comparison indicates that our estimates are statistically similar at most of the locations moreover the uncertainty in our estimates is lower than that in noaa atlas 14 reports we claim that the methodology adopted here is valuable for evaluating precipitation estimates for different durations in climate models adopting a unified approach for evaluating datasets provides a clean mechanism for inter model comparisons as in other statistical methods the method of regional frequency analysis using l moments also has some limitations one of the assumptions of the rfa is that the data are random variables however rescaling the data by the sample mean may create data that may not be random sveinsson et al 2002 also methods based upon regionalization tend to reduce the variation in pf estimates in a region considered homogeneous it may enhance discontinuities at the regional boundaries trefry et al 2005 despite these limitations the method has emerged as the dominant method in the field because of its robust quantile estimations credit authorship contribution statement abhishekh srivastava conceptualization methodology software validation formal analysis investigation writing original draft writing review editing richard grotjahn conceptualization validation resources writing review editing supervision paul a ullrich conceptualization validation resources writing review editing supervision project administration funding acquisition mark risser methodology validation software writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors sincerely thank j r m hosking for his valuable suggestions and comments on the procedures described in hosking and wallis 1997 the authors thank mike fennessy and dr j shukla of george mason university usa for providing access to the prism data the authors also thank dr timothy delsole of george mason university usa for his valuable suggestions on the statistical interpretation of the results this work is supported by the department of energy office of science award number de sc0016605 an integrated evaluation of the simulated hydroclimate system of the continental us additional support comes from the usda national institute of food and agriculture hatch project accession no 1001953 and 1010971 
6187,thermal waters in the central highlands of madagascar around antsirabe were investigated using a combination of hydrogeochemical and isotopic methods geochemical speciation and inverse geochemical modeling thermal waters at antsirabe have temperatures from 35 2 to 47 7 c are highly mineralized ec up to 5 87 ms cm are of na hco3 cl type and have elevated concentrations of arsenic up to 0 597 mg l sr up to 8 05 mg l and li up to 2 83 mg l about 25 km west of antsirabe a thermal spring at betafo has a temperature of 53 6 c but its mineralization is much lower ec 0 72 ms cm and its water is of na hco3 so4 type concentrations of as sr and li at betafo are much lower only 0 006 mg l 0 72 mg l and 0 063 mg l respectively calculated reservoir temperatures using quartz and chalcedony geothermometers are up to 153 c at antsirabe and 108 c at betafo values of δ2h and δ18o are above the wmwl indicating exchange with silicates like micas values of δ13c dic are very enriched up to 0 45 in antsirabe samples but depleted with a value of 21 52 in a betafo sample values of δ34s so4 are close to 4 0 in all samples suggesting an origin of sulfate from a na sulfate mineral values of 87sr 86sr ratios in antsirabe samples suggest interactions with reservoir rocks the principal difference between both sites seems to be in the significant input of magmatic origin co2 at the antsirabe site up to 61 4 mmol l as determined by inverse geochemical modeling with resulting higher dissolution rates of as containing silicate minerals such as micas there is probably no such input at the betafo site in spite of relatively lower as concentrations compared to geothermal waters at global tectonic plate margins concentrations of as at antsirabe can represent a serious environmental problem keywords geothermal waters arsenic isotopes geochemical modeling antsirabe madagascar 1 introduction naturally high arsenic concentrations can be the result of several processes e g reductive dissolution of ferric oxyhydroxides in organic rich alluvial aquifers in countries like bangladesh india and nepal or alkaline desorption in oxidized aquifers e g in the pampean region of argentina ravenscroft et al 2009 hasan et al 2009 mueller and hug 2018 however geothermal waters can also be a very significant source of arsenic webster and nordstrom 2003 sracek et al 2004 morales arredondo et al 2018 hossein hamidian et al 2019 guo et al 2019 in mexico several geothermal wells are linked to the transmexican volcanic belt tmvb including los azufres concentrations up to 28 4 mg l and los humeros concentrations up to 73 6 mg l birkle et al 2010 in madison river in montana usa fed by the yellowstone geothermal system concentrations of as up to 0 37 mg l were reported nimick et al 1998 and close to geothermal sources they were higher than 1 mg l in new zealand high as concentrations about 5 mg l in well fluids have been observed at the taupo geothermal system webster and nordstrom 2003 long term exposure to arsenic can lead to cancer and as iii is more toxic and carcinogenic than as v smith et al 2002 sarkar and paul 2016 maximum arsenic concentrations in geothermal systems are generally observed in high temperature reservoirs of igneous and metamorphic rocks but are generally lower in sedimentary rocks such as carbonates and sandstones except black shales at cerro prieto in mexico the geothermal reservoir is located in shale and sandstone of the colorado river delta and dissolved concentrations of arsenic are less than 1 mg l birkle et al 2010 lópez et al 2012 in some cases geothermal waters can acquire high as concentrations in contact with sulphidic mineralization from geological formations overlying the as depleted reservoir e g at durkova in slovakia vranovská et al 2015 in spite of generally postulated provenance of arsenic by leaching processes in geothermal systems ellis and mahon 1967 arsenic contribution from magmatic fluids was also suggested at some sites in mexico bernard et al 2011 and tibet tong et al 2000 high concentrations of endogenous co2 can result in enhanced interactions with reservoir rocks dupalová et al 2012 sracek et al 2019 and thus in release of arsenic initially present in silicate minerals in some studies minerals like biotite and chlorite were suggested as primary sources of arsenic later released by their chemical weathering dowling et al 2002 sediqque et al 2008 masuda et al 2012 alam et al 2014 furthermore high co2 concentrations can be responsible for lower ph values and dissolution of oxyhydroxides which are natural adsorbents of dissolved arsenic zheng et al 2009 naturally high co2 reservoirs are considered analogs of carbon capture and storage sites suggested as an option to reduce co2 impact causing climate change jun et al 2013 lower ph and eh as well as high concentration of organic matter were identified as factors leading to high arsenic concentrations in mofettas which are emanating co2 mehlhorn et al 2014 environmental isotopes such as δ34s and 87sr 86sr ratios have been successfully used to determine the source of arsenic in groundwater tissserand et al 2014 wen et al 2018 the antsirabe area fig 1 a located to the south of the capital antananarivo has been a well known geothermal region since the 19th century it is a volcanic plateau dissected by river valleys which are filled with quaternary sediments initial analyses of geothermal waters were already performed by la bathie de 1915 the surface temperature of hot waters reaches more than 50 c and they are exploited in the local spa the thermal waters at the antsirabe site were studied by sarazin et al 1986 the source of heat is local volcanism and heat transport is controlled by deep fault zones here we present geochemical and isotopic data as well as arsenic concentrations in the geothermal waters at antsirabe and betafo in the central highland plateau of madagascar the principal objectives of the study were 1 to explain the origin of geothermal waters and 2 to identify factors responsible for arsenic enrichment 2 local geology and hydrogeology the geological formations of madagascar can be divided into crystalline basement rocks and sedimentary rocks jolly et al 1984 the crystalline basement covers two thirds of the island s surface extending over 400 000 km2 jolly et al 1984 which formed from numerous orogenic phases during the precambrian period due to its location in gondwana cox et al 2004 and its extensive mineralization it has been studied over many years the remaining one third of the island is covered by sedimentary rocks from the carboniferous to quaternary periods jolly et al 1984 based on geochronological dating the precambrian bedrock can be divided into six geodynamic domains tucker et al 2014 one is the antananarivo domain where the antsirabe study site is located fig 1a a geological map of the antsirabe area with its principal rocks is shown in fig 1a and a geological cross section w e including the betafo site is shown in fig 1b three geological units can be distinguished in antsirabe and its surrounding areas zebrowski and ratsimbazafy 1979 the north and west are dominated by volcanic formations of ankaratra and the granitic mountains of vavavato fig 1a b their altitude is around 2300 m for the high summit but decreases gradually toward the south and north in the middle the altitude varies between 1400 and 1500 m corresponding to the sedimentary basin of antsirabe and betafo s volcanic regions covered by volcano sedimentary formations fig 1a in the southwest the tongarivo plateau fig 1a dominates the area rising more than 1600 m but is itself dominated by the metamorphic rocks of itongafeno the western part of the study area is dominated by the ivohitra massif and the east is delimited by an escarpment resulting from the betampona fault dissecting the basement rasoanimanana et al 2012 the middle part is underlined by a parallel mandray escarpment fig 1b which divides the antsirabe basin into two sub basins separated by the horst of the mandray tilted eastwards and extending for several kilometres generally sediments in this basin present a very clear sub horizontal stratification which results from erosion acting on the ancient basement profile and is sometimes slightly deformed or tilted by tectonic displacement and differential digressions raunet 1981 rasoanimanana et al 2012 the geology of the antsirabe basin where lake andraikiba is located is mainly formed of gneiss and lake sediments raunet 1981 volcanic rocks consist of trachytes basanites basanitoides and ankaratrites fine grained rocks rich in olivine with nepheline augite and titanomagnetite these rocks are derived from the volcanic eruptions of ankaratra according to the volcanic material composition and dating three main episodes have been distinguished first volcanism began in the miocene and continued into the upper pliocene but with long interruptions in between and the last episode in the holocene they have a general direction ns to nne ssw similar to the dominant direction of faults in the crystalline basement of madagascar these volcanic eruptions were linked to the dislocation of gondwana during the separation of madagascar from this supercontinent which happened in the cretaceous period open fractures in this basin formed during the tectonic phases that began in the upper miocene have provided passage to large quantities of lavas raunet 1981 ancient recent and very recent volcanisms are linked to these three episodes the first of which formed the ankaratra mountains rising up to 2443 m volcanic rocks from the second episode occupy the western region of the antsirabe basin where their shapes are clearly noticeable and weathering is relatively shallow geothermal activity in this area is probably related to tectonic features ancient craters are often occupied by lakes and these depressions with vertical walls maars are linked to violent explosions causing ejections of slag and ash the volcanic rocks of ankaratra vakinankantra and itasy are essentially basaltic raunet 1981 the town of antsirabe is located at an altitude of 1500 m where the average precipitation is 1332 mm most falls in summer months october april the average temperature is 16 9 c and the region belongs to the af type according to the köppen geiger climate classification geothermal fields in volcanic areas of antsirabe fig 1a are linked to the volcanism and are controlled by fault zones the na hco3 water type represents water in the antsirabe spa based on the previous chalcedony and isotopic geothermometer calculation the estimated reservoir temperature at antsirabe was between 75 and 150 c gunnlaugsson et al 1981 sarazin et al 1986 the betafo site is located about 25 km west of antsirabe fig 1a where local ground water has much lower mineralization but its temperature is comparable to the antsirabe samples shallow surface groundwater at antsirabe is mainly polluted by faecal bacteria and nitrate and cannot be used for water supply benani 2004 3 material and methods ground water was sampled from springs in the antsirabe spa samples s1 s5 and one sample s6 was taken at the betafo site fig 1a b a description of the sampling points is provided in table 1 all sampling points at antsirabe are flowing artesian wells but are plugged to some degree by carbonate precipitates fig 1d and their yield has decreased compared to their initial yield the sampling point at betafo is an exception because it is a spring flowing from fractures in a lava layer fig 1e a rain sample was collected in the spa in february 2018 i e in the summer rainy period temperature ph and electrical conductivity ec were measured on site samples for cation and trace element analyses were pre filtered with 0 45 mm millipore filters acidified with hno3 suprapur and stored in 50 ml hdpe bottles cations and trace elements were analyzed with the icp ms technique at the analytical laboratories of charles university in prague the analytical error of the individual solution analyses was below 2 anions were determined by hplc dionex ics 2000 ferrous iron concentrations were determined by potassium dichromate titration alkalinity was determined by titration with hcl using the gran plot to determine the end point calculated charge balance errors cbe were between 3 81 sample s2 and 9 81 sample s3 the latter sample was probably strongly influenced by de gassing isotope values for δ2h and δ18o in water were determined at the czech geological survey in prague with a lwia 3000 laser analyzer lgr the precision was 0 4 for δ2h and 0 12 for δ18o the results were normalized to the internationally accepted v smow standard and reported in δ notation for δ13c analyses bacl2 was added to precipitate baco3 under alkaline conditions clark and fritz 1997 the precipitate was decomposed in 100 h3po4 under vacuum at 25 c the c isotope ratio in the generated co2 was determined by a thermo delta v mass spectrometer with a precision of δ13c better than 0 1 results were expressed with respect to the pdb standard strontium solution aliquot corresponding to at least 2 µg of sr was isolated from the water by exchange chromatography techniques using triskem s sr resin equivalent to sr spec pin et al 1994 míková and denková 2007 isotopic composition was analysed using the neptune plus instrument mc icp mc thermofisher scientific in static mode in the stable and radiogenic isotope research laboratory at charles university in prague analytical mass bias was corrected to 88sr 86sr 8 375209 defined as δ 88 86sr 0 relative to nist srm 987 nier 1938 the overall analytical uncertainty was given by repeated analyses of the srm 987 standard resulting in 87sr 86sr 0 7102777 0 0000099in 2 s e m n 8 the program phreeqc parkhurst and appelo 1999 with the minteq dat database was used to calculate speciation and to model mass transfer using the inverse geochemical modeling module the eh ph diagram was constructed by geochemist workbench bethke and yeakel 2016 4 results 4 1 water chemistry water chemistry data are listed in table 2 and visualized in a piper diagram shown in fig 2 a geothermal samples from antsirabe s1 s5 have temperatures from 35 2 c to 47 7 c have high mineralization ec 4 97 5 87 ms cm and they are of na hco3 cl water type concentrations of na are in the range from 940 mg l to 1087 mg l and cl concentrations range from 411 mg l to 534 mg l hco3 is the most abundant component with concentrations from 2821 s4 sample mg l to 3587 mg l s5 sample sample s6 from betafo has a different na so4 hco3 water type and much lower mineralization ec 0 72 ms cm but its temperature of 53 6 c is elevated excluding the possibility of mixing with cold shallow water notably high is its concentration of so4 187 mg l which is in the range typical for antsirabe samples rain water is of ca hco3 water type and has very low mineralization as expected 4 2 dissolved arsenic and trace element concentrations concentrations of as and trace elements are shown in table 2 arsenic concentrations in antsirabe samples s1 s5 are high in the range from 0 294 mg l to 0 597 mg l i e much higher than the who limit of 0 01 mg l for drinking water the as concentration in the betafo sample is only 0 006 mg l concentrations of li vary from 2 1 mg l to 2 44 mg l in geothermal samples and 0 063 mg l in the betafo s6 sample also rb concentrations range from 0 47 mg l to 0 524 mg l in the antsirabe samples and 0 028 mg l in the betafo sample however the concentrations of other geothermal indicator species such as sb and f were close to detection limit not shown finally sr concentrations ranged from 7 2 mg l to 8 05 mg l in the antsirabe samples and 0 079 mg l in the betafo sample regarding speciation of arsenic in the eh ph diagram fig 2b all springs fall into the haso4 field however eh values were calculated on the basis of the fe2 fe oh 3 couple see table 3 and their validity is limited nevertheless it seems that thioarsenite species are probably insignificant 4 3 isotopes analytical results for 2h and 18o are shown in table 3 and in fig 3 all samples are above the global meteoric water line gmwl in contrast there is no evaporation shift and infiltration was probably fast also there is no geothermal oxygen shift the δ18o of the betafo sample is enriched by about 0 7 compared to the antsirabe samples the only rain sample falls directly on the gmwl values of δ13c are presented in table 3 and are plotted with concentrations of hco3 in fig 4 antsirabe waters have δ13c dic values in the range from 0 70 to 0 45 and have very high hco3 concentrations on the other hand the betafo sample s6 has a δ13c dic value of 21 52 and rain water had an even more depleted value of 25 11 values of δ34s so4 are shown in table 3 and are plotted with so4 2 concentrations in fig 5 they are in the range from 3 1 to 4 3 and the betafo sample is at the upper limit of observed values the relatively narrow range indicates a common source of sulfate for all samples without an impact of sulfate reduction the isotopic ratios 87sr 86sr are shown in table 3 and are plotted vs inverse sr concentrations in fig 6 the 87sr 86sr ratios for antsirabe are in a relatively narrow range from 0 70840 to 0 70870 rain water is very different with a ratio of 0 71180 the betafo sample has an intermediate value of 0 71054 between antsirabe waters and rain water fig 6 4 4 speciation calculations selected results of speciation calculations are shown in table 4 the saturation indices for calcite in geothermal waters are positive except for one under saturated sample which is from the betafo spring s6 the same applies to saturation indices for dolomite except for sample a5 calculated values of log pco2 for the antsirabe samples are very high in the range between 0 64 and 1 20 in contrast to 2 36 for the betafo sample all saturation indices for gypsum are negative suggesting a conservative behavior of sulfate all samples are supersaturated with respect to quartz all except for the betafo sample s6 are supersaturated with respect to chalcedony strontianite srco3 values not shown and talc mg3si4o10 oh 2 total calculated c concentrations range from 51 05 mmol l to 63 52 mmol l for the antsirabe sample and 2 593 mmol l for the betafo sample i e only about 4 of the antsirabe concentrations values of eh calculated on the basis of the fe 2 fe oh 3 couple are in the range 61 110 mv indicating more than 90 of as v but results have only limited validity due to common redox disequilibrium observed for as sracek et al 2004 sengupta et al 2018 4 5 geothermometers quartz and chalcedony geothermometers were already applied at the site by sarazin et al 1986 in previous studies it has been concluded that geothermometers based on na such as the na k ca geothermometer overestimated the reservoir temperature presumably as a consequence of the na input from evaporitic minerals at the surface we also used chalcedony and quartz geothermometers as suggested by fournier 1977 with equations modified by karingithi 2008 calculation results are shown in table 5 temperatures based on the chalcedony geothermometer are in the range from 113 to 124 c for the antsirabe samples and 81 c for the betafo sample temperatures based on the quartz thermometer were consistently higher in the range from 141 to 153 c for the antsirabe samples and 108 c for the betafo sample 5 discussion 5 1 origin of thermal water chemistry in general groundwaters with high na and hco3 concentrations are formed by two processes toran and saunders 1999 sracek and hirata 2002 1 dissolution of carbonates such as calcite combined with cation exchange and 2 reaction of silicates such as plagioclases with co2 frequently of endogenic origin dupalová et al 2012 mass balance for na table 6 based on subtraction of na originating from dissolution of halite and thenardite from total na indicates large amounts of na about 60 of total na which cannot be accounted for by dissolving of evaporitic minerals at the antsirabe site presumably supplied by dissolution of na silicates in contrast the silicate contribution is insignificant less than 3 at the betafo site where na balanced by sulfate dominates based on the na mass balance the second mechanism is probably dominant at the antsirabe site highly enriched δ13c dic values up to 0 45 and calculated log pco2 values up to 0 64 are consistent with a large input of endogenic co2 of volcanic origin similar behavior was observed at the eger rift in central europe weinlich et al 1999 noseck et al 2009 and in central italy minissale at al 2002 minissale 2004 and in central namibia sracek et al 2015 environmental isotopes provide insights into mechanisms of recharge and interactions with the rock matrix values of δ2h and δ18o table 3 fig 3 suggest fast infiltration without significant evaporation effects this is similar to data from the horombe plateau located southwest of the study area rahobisoa et al 2014 depleted δ18o values at antsirabe compared to betafo probably indicate a higher recharge area of antsirabe waters at the ivohitra massive fig 1a there is no oxygen shift to the right caused by geothermal exchange with oxygen in rocks but points are above the gmwl suggesting intensive exchange of hydrogen with silicates such as micas clark and fritz 1997 clark 2015 the values of δ13c dic table 3 fig 5 in the antsirabe samples are consistent with the input of endogenic co2 but the betafo sample s6 with a δ13c dic value of 21 52 seems to be completely free of endogenic co2 values of δ34s so4 table 3 fig 5 range from 3 1 to 4 4 at all sites including betafo and sulfate concentrations are in a relatively narrow range of 166 mg l to 214 mg l at all sites sulfate cannot be of gypsum origin because 3 90 mmol l out of total 4 17 mmol l i e more than 90 of total sulfate is balanced by na and not by ca suggesting a na sulfate mineral such as thenardite na2so4 as the sulfate source ratios of 87sr 86sr at antsirabe are from 0 70840 to 0 70870 table 2 indicating extensive interactions with reservoir rocks they are consistent with values of about 0 7082 reported for antsirabe by sarazin et al 1986 the 87sr 86sr ratios at antsirabe are between about 0 703 reported for basaltic rocks and more than 0 710 reported for granitic rocks faure and mensing 2004 clark 2015 ryan et al 2018 in contrast the 0 71054 value from betafo is different and closer to rain water fig 6 this is consistent with limited interactions with rocks at the site as deduced from water chemistry inverse geochemical modeling has been performed to estimate mass transfer in reactions and results are shown in table 7 spring s5 with a maximum concentration of hco3 and as represents final highly mineralized antsirabe waters and spring s6 is betafo waters with low mineralization the initial sample was rain water concentrated 3 15 times on the basis of cl enrichment compared to rain water in low mineralization sample s6 to account for evapotranspiration the models were calibrated using δ13c dic the δ13c co2 value of endogenic co2 used in the modeling was 1 clark and fritz 1997 weinlich et al 1999 sracek et al 2019 the principal source of na was plagioclase represented by albite at the betafo site no endogenic co2 input was assumed inverse geochemical modeling of water chemistry of waters at antsirabe s5 indicated a large input of endogenic co2 equal to 61 4 mmol l which was consistent with a modeled δ13c dic value of 1 29 compared to a measured value of 1 40 the co2 input is accompanied by dissolution of large amounts of na plagioclase such as albite and with precipitation of quartz and kaolinite there is also input of cl and so4 from halite and thenardite dissolution thus contributing to the na budget but cation exchange is relatively insignificant anorthite was used as a source of ca2 because no information on plagioclases composition was available a relatively large amount of precipitated calcite 1 82 mmol i or 73 mg l is consistent with carbonate scale observed at the wellhead of s5 at antsirabe fig 1d sample s6 from betafo showed much lower mass transfers as expected where the input of co2 was only 1 89 mmol l the sample seems to be unaffected by endogenous co2 because its δ13c dic is 21 52 there is only dissolution of a small amount of albite and precipitation of similar amounts of quartz and kaolinite anorthite contributes a small amount of ca2 but there is much less precipitated calcite compared to s5 at antsirabe again amounts of dissolved halite and thenardite are fixed by cl and so4 inputs but only dissolution of thenardite is significant cation exchange in this sample is relatively insignificant 5 2 origin of arsenic samples from antsirabe have arsenic concentrations from 0 232 to 0 597 mg l the upper limit is in the highly mineralized geothermal spring s5 the minimum is in relatively lower temperature spring s4 which is probably affected by mixing with shallow water arsenic in geothermal systems seems to be mainly derived from host rock leaching there is generally a good correlation between as and cl because both elements remain in the water phase during boiling and steam separation however the as cl ratio can be altered by dilution or mixing of the geothermal waters webster and nordstrom 2003 the plots of as vs na cl li and rb are shown in fig 7 a d respective determination coefficients for as vs na cl li and rb are 0 59 0 55 0 59 and 0 51 the betafo sample at the extreme left in addition to the low as concentration of 0 006 mg l also has much lower li and rb concentrations 0 063 mg l and 0 028 mg l respectively concentrations of li and rb typically increase with increasing temperature but they can be incorporated into alteration minerals i e rb is substituted for k and li for mg kaasalainen et al 2015 mixing of thermal waters with cold waters was observed in yellowstone national park and resulted in low as concentration in the mixture nordstrom et al 2001 however based on the high temperature at the betafo site table 2 mixing with shallow cold water cannot explain the depletion in as and other geothermal species concentrations compared to the antsirabe site high as concentrations at the antsirabe site are linked to na hco3 cl waters table 2 and fig 2a with very high log pco2 and total c values table 4 high temperature and rock type alone cannot explain arsenic enrichment of hot waters at antsirabe compared to low arsenic in the hot water at betafo it seems that enhanced interaction of endogenous co2 with rock minerals in springs and wells located on or close to magmatic co2 conduits is responsible for elevated arsenic concentrations at antsirabe potential source minerals of arsenic can be micas in igneous and volcanic rocks with reported arsenic concentrations up to 4 3 ppm smedley and kinniburgh 2002 this is also consistent with isotopic exchange between geothermal waters and micas suggested by the position of samples above the gmwl in the plot of δ2h vs δ18o fig 3 micas such as biotite were suggested as a primary arsenic source in the bengal delta plain aquifer in bangladesh dowling et al 2002 sediqque et al 2008 similarly silicate minerals were suggested as a source of arsenic in newfoundland alam et al 2014 low arsenic and other geothermal species concentrations observed at the betafo site cannot be explained by water interaction with basaltic rocks which typically have a low arsenic content webster and nordstrom 2003 because value 0 71054 table 3 of 87sr 86sr ratio is too high for an extensive interaction with basaltic rocks another factor can be the relatively high ph of na hco3 water with resulting lower adsorption affinity for as oxyanions sracek et al 2004 on the other hand low ph and eh with high concentrations of organic matter suggested as arsenic mobilization factors in mofettas mehlhorn et al 2014 cannot be important at this study site a conceptual model of processes at the studied sites is shown in fig 8 thermal waters infiltrate at higher altitudes on the slopes of the ivohitra massive at an altitude of more than 2000 masl fig 1a and are heated as they flow downward in the gravity driven flow system the antsirabe waters acquire large amounts of endogenous co2 probably transmitted via a tectonic zone linked to a deep magmatic chamber there is an intense dissolution of silicate minerals in reservoir rocks with resulting release of as and other geothermal species such as li and rb at betafo there is no endogenous co2 input and mineralization and as concentrations are much lower observed as concentrations in the range from 0 232 to 0 597 mg l albeit considerable are still well below measured concentrations in na cl dominated high enthalpy geothermal systems at global tectonic plate margins like at los humeros in mexico with as concentrations of up to 73 6 mg l and el tatio in chile with concentrations of up to 30 mg l lópez et al 2012 however they may represent an environmental problem for discharge of the spa water 6 conclusions the study of thermal waters in the central highlands of madagascar around antsirabe provided geochemical evidence of arsenic enrichment thermal waters close to antsirabe have temperatures varying from 35 2 to 47 7 c are highly mineralized of na hco3 cl type and have arsenic concentrations up to 0 597 mg l high concentrations of sr up to 8 05 mg l and li up to 2 83 mg l are also found in contrast a thermal spring at betafo about 30 km west of antsirabe has a temperature of 53 6 c but its mineralization is much lower and the groundwater is of na so4 hco3 type concentrations of as sr and li at betafo are depleted with maximum values of only 0 006 mg l 0 72 mg l and 0 063 mg l respectively calculated reservoir temperatures using quartz and chalcedony geothermometers are up to 153 c for antsirabe and 108 c for betafo differences in mineralization and arsenic concentrations between both sites cannot be explained by water temperatures and rock types alone because both sites are similar from these viewpoints the principal difference seems to be in the large input of magmatic origin co2 at the antsirabe site up to 61 4 mmol l as determined by inverse geochemical modeling with resulting high dissolution rates of as containing silicate rocks in contrast to the betafo site thermal waters at the antsirabe site seem to be located in or in close proximity to co2 transmitting conduits the thermal spring at betafo seems to be unaffected by endogenic co2 and thus leaching of as from host rocks is limited in spite of lower as concentrations in antsirabe compared to geothermal waters at global tectonic plate margins an environmental problem still exists which requires monitoring of as concentrations in discharged thermal waters declaration of competing interest none acknowledgements we thank peter birkle from saudi aramco for helpful comments this study was partly supported by the center for geosphere dynamics unce sci 006 and the operational programme prague competitiveness cz 2 16 3 1 00 21516 we also thank the associate editor and two anonymous reviewers for comments which helped to improve the manuscript 
6187,thermal waters in the central highlands of madagascar around antsirabe were investigated using a combination of hydrogeochemical and isotopic methods geochemical speciation and inverse geochemical modeling thermal waters at antsirabe have temperatures from 35 2 to 47 7 c are highly mineralized ec up to 5 87 ms cm are of na hco3 cl type and have elevated concentrations of arsenic up to 0 597 mg l sr up to 8 05 mg l and li up to 2 83 mg l about 25 km west of antsirabe a thermal spring at betafo has a temperature of 53 6 c but its mineralization is much lower ec 0 72 ms cm and its water is of na hco3 so4 type concentrations of as sr and li at betafo are much lower only 0 006 mg l 0 72 mg l and 0 063 mg l respectively calculated reservoir temperatures using quartz and chalcedony geothermometers are up to 153 c at antsirabe and 108 c at betafo values of δ2h and δ18o are above the wmwl indicating exchange with silicates like micas values of δ13c dic are very enriched up to 0 45 in antsirabe samples but depleted with a value of 21 52 in a betafo sample values of δ34s so4 are close to 4 0 in all samples suggesting an origin of sulfate from a na sulfate mineral values of 87sr 86sr ratios in antsirabe samples suggest interactions with reservoir rocks the principal difference between both sites seems to be in the significant input of magmatic origin co2 at the antsirabe site up to 61 4 mmol l as determined by inverse geochemical modeling with resulting higher dissolution rates of as containing silicate minerals such as micas there is probably no such input at the betafo site in spite of relatively lower as concentrations compared to geothermal waters at global tectonic plate margins concentrations of as at antsirabe can represent a serious environmental problem keywords geothermal waters arsenic isotopes geochemical modeling antsirabe madagascar 1 introduction naturally high arsenic concentrations can be the result of several processes e g reductive dissolution of ferric oxyhydroxides in organic rich alluvial aquifers in countries like bangladesh india and nepal or alkaline desorption in oxidized aquifers e g in the pampean region of argentina ravenscroft et al 2009 hasan et al 2009 mueller and hug 2018 however geothermal waters can also be a very significant source of arsenic webster and nordstrom 2003 sracek et al 2004 morales arredondo et al 2018 hossein hamidian et al 2019 guo et al 2019 in mexico several geothermal wells are linked to the transmexican volcanic belt tmvb including los azufres concentrations up to 28 4 mg l and los humeros concentrations up to 73 6 mg l birkle et al 2010 in madison river in montana usa fed by the yellowstone geothermal system concentrations of as up to 0 37 mg l were reported nimick et al 1998 and close to geothermal sources they were higher than 1 mg l in new zealand high as concentrations about 5 mg l in well fluids have been observed at the taupo geothermal system webster and nordstrom 2003 long term exposure to arsenic can lead to cancer and as iii is more toxic and carcinogenic than as v smith et al 2002 sarkar and paul 2016 maximum arsenic concentrations in geothermal systems are generally observed in high temperature reservoirs of igneous and metamorphic rocks but are generally lower in sedimentary rocks such as carbonates and sandstones except black shales at cerro prieto in mexico the geothermal reservoir is located in shale and sandstone of the colorado river delta and dissolved concentrations of arsenic are less than 1 mg l birkle et al 2010 lópez et al 2012 in some cases geothermal waters can acquire high as concentrations in contact with sulphidic mineralization from geological formations overlying the as depleted reservoir e g at durkova in slovakia vranovská et al 2015 in spite of generally postulated provenance of arsenic by leaching processes in geothermal systems ellis and mahon 1967 arsenic contribution from magmatic fluids was also suggested at some sites in mexico bernard et al 2011 and tibet tong et al 2000 high concentrations of endogenous co2 can result in enhanced interactions with reservoir rocks dupalová et al 2012 sracek et al 2019 and thus in release of arsenic initially present in silicate minerals in some studies minerals like biotite and chlorite were suggested as primary sources of arsenic later released by their chemical weathering dowling et al 2002 sediqque et al 2008 masuda et al 2012 alam et al 2014 furthermore high co2 concentrations can be responsible for lower ph values and dissolution of oxyhydroxides which are natural adsorbents of dissolved arsenic zheng et al 2009 naturally high co2 reservoirs are considered analogs of carbon capture and storage sites suggested as an option to reduce co2 impact causing climate change jun et al 2013 lower ph and eh as well as high concentration of organic matter were identified as factors leading to high arsenic concentrations in mofettas which are emanating co2 mehlhorn et al 2014 environmental isotopes such as δ34s and 87sr 86sr ratios have been successfully used to determine the source of arsenic in groundwater tissserand et al 2014 wen et al 2018 the antsirabe area fig 1 a located to the south of the capital antananarivo has been a well known geothermal region since the 19th century it is a volcanic plateau dissected by river valleys which are filled with quaternary sediments initial analyses of geothermal waters were already performed by la bathie de 1915 the surface temperature of hot waters reaches more than 50 c and they are exploited in the local spa the thermal waters at the antsirabe site were studied by sarazin et al 1986 the source of heat is local volcanism and heat transport is controlled by deep fault zones here we present geochemical and isotopic data as well as arsenic concentrations in the geothermal waters at antsirabe and betafo in the central highland plateau of madagascar the principal objectives of the study were 1 to explain the origin of geothermal waters and 2 to identify factors responsible for arsenic enrichment 2 local geology and hydrogeology the geological formations of madagascar can be divided into crystalline basement rocks and sedimentary rocks jolly et al 1984 the crystalline basement covers two thirds of the island s surface extending over 400 000 km2 jolly et al 1984 which formed from numerous orogenic phases during the precambrian period due to its location in gondwana cox et al 2004 and its extensive mineralization it has been studied over many years the remaining one third of the island is covered by sedimentary rocks from the carboniferous to quaternary periods jolly et al 1984 based on geochronological dating the precambrian bedrock can be divided into six geodynamic domains tucker et al 2014 one is the antananarivo domain where the antsirabe study site is located fig 1a a geological map of the antsirabe area with its principal rocks is shown in fig 1a and a geological cross section w e including the betafo site is shown in fig 1b three geological units can be distinguished in antsirabe and its surrounding areas zebrowski and ratsimbazafy 1979 the north and west are dominated by volcanic formations of ankaratra and the granitic mountains of vavavato fig 1a b their altitude is around 2300 m for the high summit but decreases gradually toward the south and north in the middle the altitude varies between 1400 and 1500 m corresponding to the sedimentary basin of antsirabe and betafo s volcanic regions covered by volcano sedimentary formations fig 1a in the southwest the tongarivo plateau fig 1a dominates the area rising more than 1600 m but is itself dominated by the metamorphic rocks of itongafeno the western part of the study area is dominated by the ivohitra massif and the east is delimited by an escarpment resulting from the betampona fault dissecting the basement rasoanimanana et al 2012 the middle part is underlined by a parallel mandray escarpment fig 1b which divides the antsirabe basin into two sub basins separated by the horst of the mandray tilted eastwards and extending for several kilometres generally sediments in this basin present a very clear sub horizontal stratification which results from erosion acting on the ancient basement profile and is sometimes slightly deformed or tilted by tectonic displacement and differential digressions raunet 1981 rasoanimanana et al 2012 the geology of the antsirabe basin where lake andraikiba is located is mainly formed of gneiss and lake sediments raunet 1981 volcanic rocks consist of trachytes basanites basanitoides and ankaratrites fine grained rocks rich in olivine with nepheline augite and titanomagnetite these rocks are derived from the volcanic eruptions of ankaratra according to the volcanic material composition and dating three main episodes have been distinguished first volcanism began in the miocene and continued into the upper pliocene but with long interruptions in between and the last episode in the holocene they have a general direction ns to nne ssw similar to the dominant direction of faults in the crystalline basement of madagascar these volcanic eruptions were linked to the dislocation of gondwana during the separation of madagascar from this supercontinent which happened in the cretaceous period open fractures in this basin formed during the tectonic phases that began in the upper miocene have provided passage to large quantities of lavas raunet 1981 ancient recent and very recent volcanisms are linked to these three episodes the first of which formed the ankaratra mountains rising up to 2443 m volcanic rocks from the second episode occupy the western region of the antsirabe basin where their shapes are clearly noticeable and weathering is relatively shallow geothermal activity in this area is probably related to tectonic features ancient craters are often occupied by lakes and these depressions with vertical walls maars are linked to violent explosions causing ejections of slag and ash the volcanic rocks of ankaratra vakinankantra and itasy are essentially basaltic raunet 1981 the town of antsirabe is located at an altitude of 1500 m where the average precipitation is 1332 mm most falls in summer months october april the average temperature is 16 9 c and the region belongs to the af type according to the köppen geiger climate classification geothermal fields in volcanic areas of antsirabe fig 1a are linked to the volcanism and are controlled by fault zones the na hco3 water type represents water in the antsirabe spa based on the previous chalcedony and isotopic geothermometer calculation the estimated reservoir temperature at antsirabe was between 75 and 150 c gunnlaugsson et al 1981 sarazin et al 1986 the betafo site is located about 25 km west of antsirabe fig 1a where local ground water has much lower mineralization but its temperature is comparable to the antsirabe samples shallow surface groundwater at antsirabe is mainly polluted by faecal bacteria and nitrate and cannot be used for water supply benani 2004 3 material and methods ground water was sampled from springs in the antsirabe spa samples s1 s5 and one sample s6 was taken at the betafo site fig 1a b a description of the sampling points is provided in table 1 all sampling points at antsirabe are flowing artesian wells but are plugged to some degree by carbonate precipitates fig 1d and their yield has decreased compared to their initial yield the sampling point at betafo is an exception because it is a spring flowing from fractures in a lava layer fig 1e a rain sample was collected in the spa in february 2018 i e in the summer rainy period temperature ph and electrical conductivity ec were measured on site samples for cation and trace element analyses were pre filtered with 0 45 mm millipore filters acidified with hno3 suprapur and stored in 50 ml hdpe bottles cations and trace elements were analyzed with the icp ms technique at the analytical laboratories of charles university in prague the analytical error of the individual solution analyses was below 2 anions were determined by hplc dionex ics 2000 ferrous iron concentrations were determined by potassium dichromate titration alkalinity was determined by titration with hcl using the gran plot to determine the end point calculated charge balance errors cbe were between 3 81 sample s2 and 9 81 sample s3 the latter sample was probably strongly influenced by de gassing isotope values for δ2h and δ18o in water were determined at the czech geological survey in prague with a lwia 3000 laser analyzer lgr the precision was 0 4 for δ2h and 0 12 for δ18o the results were normalized to the internationally accepted v smow standard and reported in δ notation for δ13c analyses bacl2 was added to precipitate baco3 under alkaline conditions clark and fritz 1997 the precipitate was decomposed in 100 h3po4 under vacuum at 25 c the c isotope ratio in the generated co2 was determined by a thermo delta v mass spectrometer with a precision of δ13c better than 0 1 results were expressed with respect to the pdb standard strontium solution aliquot corresponding to at least 2 µg of sr was isolated from the water by exchange chromatography techniques using triskem s sr resin equivalent to sr spec pin et al 1994 míková and denková 2007 isotopic composition was analysed using the neptune plus instrument mc icp mc thermofisher scientific in static mode in the stable and radiogenic isotope research laboratory at charles university in prague analytical mass bias was corrected to 88sr 86sr 8 375209 defined as δ 88 86sr 0 relative to nist srm 987 nier 1938 the overall analytical uncertainty was given by repeated analyses of the srm 987 standard resulting in 87sr 86sr 0 7102777 0 0000099in 2 s e m n 8 the program phreeqc parkhurst and appelo 1999 with the minteq dat database was used to calculate speciation and to model mass transfer using the inverse geochemical modeling module the eh ph diagram was constructed by geochemist workbench bethke and yeakel 2016 4 results 4 1 water chemistry water chemistry data are listed in table 2 and visualized in a piper diagram shown in fig 2 a geothermal samples from antsirabe s1 s5 have temperatures from 35 2 c to 47 7 c have high mineralization ec 4 97 5 87 ms cm and they are of na hco3 cl water type concentrations of na are in the range from 940 mg l to 1087 mg l and cl concentrations range from 411 mg l to 534 mg l hco3 is the most abundant component with concentrations from 2821 s4 sample mg l to 3587 mg l s5 sample sample s6 from betafo has a different na so4 hco3 water type and much lower mineralization ec 0 72 ms cm but its temperature of 53 6 c is elevated excluding the possibility of mixing with cold shallow water notably high is its concentration of so4 187 mg l which is in the range typical for antsirabe samples rain water is of ca hco3 water type and has very low mineralization as expected 4 2 dissolved arsenic and trace element concentrations concentrations of as and trace elements are shown in table 2 arsenic concentrations in antsirabe samples s1 s5 are high in the range from 0 294 mg l to 0 597 mg l i e much higher than the who limit of 0 01 mg l for drinking water the as concentration in the betafo sample is only 0 006 mg l concentrations of li vary from 2 1 mg l to 2 44 mg l in geothermal samples and 0 063 mg l in the betafo s6 sample also rb concentrations range from 0 47 mg l to 0 524 mg l in the antsirabe samples and 0 028 mg l in the betafo sample however the concentrations of other geothermal indicator species such as sb and f were close to detection limit not shown finally sr concentrations ranged from 7 2 mg l to 8 05 mg l in the antsirabe samples and 0 079 mg l in the betafo sample regarding speciation of arsenic in the eh ph diagram fig 2b all springs fall into the haso4 field however eh values were calculated on the basis of the fe2 fe oh 3 couple see table 3 and their validity is limited nevertheless it seems that thioarsenite species are probably insignificant 4 3 isotopes analytical results for 2h and 18o are shown in table 3 and in fig 3 all samples are above the global meteoric water line gmwl in contrast there is no evaporation shift and infiltration was probably fast also there is no geothermal oxygen shift the δ18o of the betafo sample is enriched by about 0 7 compared to the antsirabe samples the only rain sample falls directly on the gmwl values of δ13c are presented in table 3 and are plotted with concentrations of hco3 in fig 4 antsirabe waters have δ13c dic values in the range from 0 70 to 0 45 and have very high hco3 concentrations on the other hand the betafo sample s6 has a δ13c dic value of 21 52 and rain water had an even more depleted value of 25 11 values of δ34s so4 are shown in table 3 and are plotted with so4 2 concentrations in fig 5 they are in the range from 3 1 to 4 3 and the betafo sample is at the upper limit of observed values the relatively narrow range indicates a common source of sulfate for all samples without an impact of sulfate reduction the isotopic ratios 87sr 86sr are shown in table 3 and are plotted vs inverse sr concentrations in fig 6 the 87sr 86sr ratios for antsirabe are in a relatively narrow range from 0 70840 to 0 70870 rain water is very different with a ratio of 0 71180 the betafo sample has an intermediate value of 0 71054 between antsirabe waters and rain water fig 6 4 4 speciation calculations selected results of speciation calculations are shown in table 4 the saturation indices for calcite in geothermal waters are positive except for one under saturated sample which is from the betafo spring s6 the same applies to saturation indices for dolomite except for sample a5 calculated values of log pco2 for the antsirabe samples are very high in the range between 0 64 and 1 20 in contrast to 2 36 for the betafo sample all saturation indices for gypsum are negative suggesting a conservative behavior of sulfate all samples are supersaturated with respect to quartz all except for the betafo sample s6 are supersaturated with respect to chalcedony strontianite srco3 values not shown and talc mg3si4o10 oh 2 total calculated c concentrations range from 51 05 mmol l to 63 52 mmol l for the antsirabe sample and 2 593 mmol l for the betafo sample i e only about 4 of the antsirabe concentrations values of eh calculated on the basis of the fe 2 fe oh 3 couple are in the range 61 110 mv indicating more than 90 of as v but results have only limited validity due to common redox disequilibrium observed for as sracek et al 2004 sengupta et al 2018 4 5 geothermometers quartz and chalcedony geothermometers were already applied at the site by sarazin et al 1986 in previous studies it has been concluded that geothermometers based on na such as the na k ca geothermometer overestimated the reservoir temperature presumably as a consequence of the na input from evaporitic minerals at the surface we also used chalcedony and quartz geothermometers as suggested by fournier 1977 with equations modified by karingithi 2008 calculation results are shown in table 5 temperatures based on the chalcedony geothermometer are in the range from 113 to 124 c for the antsirabe samples and 81 c for the betafo sample temperatures based on the quartz thermometer were consistently higher in the range from 141 to 153 c for the antsirabe samples and 108 c for the betafo sample 5 discussion 5 1 origin of thermal water chemistry in general groundwaters with high na and hco3 concentrations are formed by two processes toran and saunders 1999 sracek and hirata 2002 1 dissolution of carbonates such as calcite combined with cation exchange and 2 reaction of silicates such as plagioclases with co2 frequently of endogenic origin dupalová et al 2012 mass balance for na table 6 based on subtraction of na originating from dissolution of halite and thenardite from total na indicates large amounts of na about 60 of total na which cannot be accounted for by dissolving of evaporitic minerals at the antsirabe site presumably supplied by dissolution of na silicates in contrast the silicate contribution is insignificant less than 3 at the betafo site where na balanced by sulfate dominates based on the na mass balance the second mechanism is probably dominant at the antsirabe site highly enriched δ13c dic values up to 0 45 and calculated log pco2 values up to 0 64 are consistent with a large input of endogenic co2 of volcanic origin similar behavior was observed at the eger rift in central europe weinlich et al 1999 noseck et al 2009 and in central italy minissale at al 2002 minissale 2004 and in central namibia sracek et al 2015 environmental isotopes provide insights into mechanisms of recharge and interactions with the rock matrix values of δ2h and δ18o table 3 fig 3 suggest fast infiltration without significant evaporation effects this is similar to data from the horombe plateau located southwest of the study area rahobisoa et al 2014 depleted δ18o values at antsirabe compared to betafo probably indicate a higher recharge area of antsirabe waters at the ivohitra massive fig 1a there is no oxygen shift to the right caused by geothermal exchange with oxygen in rocks but points are above the gmwl suggesting intensive exchange of hydrogen with silicates such as micas clark and fritz 1997 clark 2015 the values of δ13c dic table 3 fig 5 in the antsirabe samples are consistent with the input of endogenic co2 but the betafo sample s6 with a δ13c dic value of 21 52 seems to be completely free of endogenic co2 values of δ34s so4 table 3 fig 5 range from 3 1 to 4 4 at all sites including betafo and sulfate concentrations are in a relatively narrow range of 166 mg l to 214 mg l at all sites sulfate cannot be of gypsum origin because 3 90 mmol l out of total 4 17 mmol l i e more than 90 of total sulfate is balanced by na and not by ca suggesting a na sulfate mineral such as thenardite na2so4 as the sulfate source ratios of 87sr 86sr at antsirabe are from 0 70840 to 0 70870 table 2 indicating extensive interactions with reservoir rocks they are consistent with values of about 0 7082 reported for antsirabe by sarazin et al 1986 the 87sr 86sr ratios at antsirabe are between about 0 703 reported for basaltic rocks and more than 0 710 reported for granitic rocks faure and mensing 2004 clark 2015 ryan et al 2018 in contrast the 0 71054 value from betafo is different and closer to rain water fig 6 this is consistent with limited interactions with rocks at the site as deduced from water chemistry inverse geochemical modeling has been performed to estimate mass transfer in reactions and results are shown in table 7 spring s5 with a maximum concentration of hco3 and as represents final highly mineralized antsirabe waters and spring s6 is betafo waters with low mineralization the initial sample was rain water concentrated 3 15 times on the basis of cl enrichment compared to rain water in low mineralization sample s6 to account for evapotranspiration the models were calibrated using δ13c dic the δ13c co2 value of endogenic co2 used in the modeling was 1 clark and fritz 1997 weinlich et al 1999 sracek et al 2019 the principal source of na was plagioclase represented by albite at the betafo site no endogenic co2 input was assumed inverse geochemical modeling of water chemistry of waters at antsirabe s5 indicated a large input of endogenic co2 equal to 61 4 mmol l which was consistent with a modeled δ13c dic value of 1 29 compared to a measured value of 1 40 the co2 input is accompanied by dissolution of large amounts of na plagioclase such as albite and with precipitation of quartz and kaolinite there is also input of cl and so4 from halite and thenardite dissolution thus contributing to the na budget but cation exchange is relatively insignificant anorthite was used as a source of ca2 because no information on plagioclases composition was available a relatively large amount of precipitated calcite 1 82 mmol i or 73 mg l is consistent with carbonate scale observed at the wellhead of s5 at antsirabe fig 1d sample s6 from betafo showed much lower mass transfers as expected where the input of co2 was only 1 89 mmol l the sample seems to be unaffected by endogenous co2 because its δ13c dic is 21 52 there is only dissolution of a small amount of albite and precipitation of similar amounts of quartz and kaolinite anorthite contributes a small amount of ca2 but there is much less precipitated calcite compared to s5 at antsirabe again amounts of dissolved halite and thenardite are fixed by cl and so4 inputs but only dissolution of thenardite is significant cation exchange in this sample is relatively insignificant 5 2 origin of arsenic samples from antsirabe have arsenic concentrations from 0 232 to 0 597 mg l the upper limit is in the highly mineralized geothermal spring s5 the minimum is in relatively lower temperature spring s4 which is probably affected by mixing with shallow water arsenic in geothermal systems seems to be mainly derived from host rock leaching there is generally a good correlation between as and cl because both elements remain in the water phase during boiling and steam separation however the as cl ratio can be altered by dilution or mixing of the geothermal waters webster and nordstrom 2003 the plots of as vs na cl li and rb are shown in fig 7 a d respective determination coefficients for as vs na cl li and rb are 0 59 0 55 0 59 and 0 51 the betafo sample at the extreme left in addition to the low as concentration of 0 006 mg l also has much lower li and rb concentrations 0 063 mg l and 0 028 mg l respectively concentrations of li and rb typically increase with increasing temperature but they can be incorporated into alteration minerals i e rb is substituted for k and li for mg kaasalainen et al 2015 mixing of thermal waters with cold waters was observed in yellowstone national park and resulted in low as concentration in the mixture nordstrom et al 2001 however based on the high temperature at the betafo site table 2 mixing with shallow cold water cannot explain the depletion in as and other geothermal species concentrations compared to the antsirabe site high as concentrations at the antsirabe site are linked to na hco3 cl waters table 2 and fig 2a with very high log pco2 and total c values table 4 high temperature and rock type alone cannot explain arsenic enrichment of hot waters at antsirabe compared to low arsenic in the hot water at betafo it seems that enhanced interaction of endogenous co2 with rock minerals in springs and wells located on or close to magmatic co2 conduits is responsible for elevated arsenic concentrations at antsirabe potential source minerals of arsenic can be micas in igneous and volcanic rocks with reported arsenic concentrations up to 4 3 ppm smedley and kinniburgh 2002 this is also consistent with isotopic exchange between geothermal waters and micas suggested by the position of samples above the gmwl in the plot of δ2h vs δ18o fig 3 micas such as biotite were suggested as a primary arsenic source in the bengal delta plain aquifer in bangladesh dowling et al 2002 sediqque et al 2008 similarly silicate minerals were suggested as a source of arsenic in newfoundland alam et al 2014 low arsenic and other geothermal species concentrations observed at the betafo site cannot be explained by water interaction with basaltic rocks which typically have a low arsenic content webster and nordstrom 2003 because value 0 71054 table 3 of 87sr 86sr ratio is too high for an extensive interaction with basaltic rocks another factor can be the relatively high ph of na hco3 water with resulting lower adsorption affinity for as oxyanions sracek et al 2004 on the other hand low ph and eh with high concentrations of organic matter suggested as arsenic mobilization factors in mofettas mehlhorn et al 2014 cannot be important at this study site a conceptual model of processes at the studied sites is shown in fig 8 thermal waters infiltrate at higher altitudes on the slopes of the ivohitra massive at an altitude of more than 2000 masl fig 1a and are heated as they flow downward in the gravity driven flow system the antsirabe waters acquire large amounts of endogenous co2 probably transmitted via a tectonic zone linked to a deep magmatic chamber there is an intense dissolution of silicate minerals in reservoir rocks with resulting release of as and other geothermal species such as li and rb at betafo there is no endogenous co2 input and mineralization and as concentrations are much lower observed as concentrations in the range from 0 232 to 0 597 mg l albeit considerable are still well below measured concentrations in na cl dominated high enthalpy geothermal systems at global tectonic plate margins like at los humeros in mexico with as concentrations of up to 73 6 mg l and el tatio in chile with concentrations of up to 30 mg l lópez et al 2012 however they may represent an environmental problem for discharge of the spa water 6 conclusions the study of thermal waters in the central highlands of madagascar around antsirabe provided geochemical evidence of arsenic enrichment thermal waters close to antsirabe have temperatures varying from 35 2 to 47 7 c are highly mineralized of na hco3 cl type and have arsenic concentrations up to 0 597 mg l high concentrations of sr up to 8 05 mg l and li up to 2 83 mg l are also found in contrast a thermal spring at betafo about 30 km west of antsirabe has a temperature of 53 6 c but its mineralization is much lower and the groundwater is of na so4 hco3 type concentrations of as sr and li at betafo are depleted with maximum values of only 0 006 mg l 0 72 mg l and 0 063 mg l respectively calculated reservoir temperatures using quartz and chalcedony geothermometers are up to 153 c for antsirabe and 108 c for betafo differences in mineralization and arsenic concentrations between both sites cannot be explained by water temperatures and rock types alone because both sites are similar from these viewpoints the principal difference seems to be in the large input of magmatic origin co2 at the antsirabe site up to 61 4 mmol l as determined by inverse geochemical modeling with resulting high dissolution rates of as containing silicate rocks in contrast to the betafo site thermal waters at the antsirabe site seem to be located in or in close proximity to co2 transmitting conduits the thermal spring at betafo seems to be unaffected by endogenic co2 and thus leaching of as from host rocks is limited in spite of lower as concentrations in antsirabe compared to geothermal waters at global tectonic plate margins an environmental problem still exists which requires monitoring of as concentrations in discharged thermal waters declaration of competing interest none acknowledgements we thank peter birkle from saudi aramco for helpful comments this study was partly supported by the center for geosphere dynamics unce sci 006 and the operational programme prague competitiveness cz 2 16 3 1 00 21516 we also thank the associate editor and two anonymous reviewers for comments which helped to improve the manuscript 
6188,this study introduces a novel hydrological assessment tool hat based on hybrid machine learning hml framework the hml framework combines an unsupervised clustering technique and a supervised classification technique to determine reasonable performance ratings unsatisfactory satisfactory good and very good and build a practical assessment tool hydrologically significant error indices are used to cluster the performance rating groups and train the hat the hat was applied to the national water model nwm which is operated in real time for the continental united states conus for establishing training and validating the hat data from october 2013 to february 2017 were used and a performance assessment was conducted on the nwm in the san francisco bay area as a result the hat determined the performance ratings that were reliable in terms of the statistics and hydrograph it was confirmed that the hat could perform an accurate hydrograph assessment as the concordance rate of the performance ratings was 98 the nwm was evaluated against 57 usgs streamflow gauges using the hat and was found to perform with 46 on average good and very good ratings the hml framework an integral part of the hat is expected to be useful not only in hydrological analysis but also across all geophysical fields that deal with physical processes keywords hydrological assessment hybrid machine learning national water model streamflow evaluation performance ratings 1 introduction identifying and predicting the response of hydrologic systems by using a simulation model are very important for reducing damages from natural disasters abbott et al 1986 dutta et al 2003 rozalis et al 2010 yoo et al 2012 kim et al 2018a b this is because a hydrologic model can identify in advance the potential occurrence of various water related natural disasters as it estimates and predicts the flow and volume from surface to groundwater runoff in time and space henderson and wooding 1964 moreover by virtue of advanced remote sensing techniques quantitative precipitation estimation schemes kim et al 2015 and correction methods yoo et al 2014 kim and yoo 2014 to improve accuracy of meteorological inputs e g precipitation hydrological products from models will play a role in a wide range of disciplines many types of hydrologic models have advanced from the basic lumped approach that combines characteristics across an entire watershed to provide forecast information at an outlet point to distributed hydrologic models that account for spatially varying characteristics across the watershed and can be used to simulate a local scale flood liang et al 1994 arnold et al 1998 singh and woolhiser 2002 in contrast to the evolution and improvement of hydrologic modeling general hydrological evaluation methods have remained simple most relying on a few error indices a hydrological evaluation method is not simply to determine whether there are many or few errors it should reasonably determine the reliability of outputs and present objective indices understandable to users the limitations of current hydrological evaluation methods must be overcome and a new assessment tool is required that can objectively evaluate any hydrologic model performance there are many potential and important uses for the hydrological evaluation method in hydrology its main purposes include calibrating the model evaluating its performance and communicating with stakeholders the hydrologic model which has a complex structure and various parameters requires a calibration process depending on the status of outputs and the evaluation of its results determines the necessity strategy and extent of calibration moriasi et al 2007 as the model s performance differs depending on the status of inputs arising from various meteorological forcings and geographical characteristics and the status of calibration the hydrological evaluation method is useful for evaluation of its performance beven 1993 freer et al 1996 furthermore the hydrological evaluation method serves as to provide guidance on the model s reliability to forecasters and operators who use the hydrologic model outputs for decision making flood warnings and mitigation al sabhan et al 2003 for current hydrological evaluation the graphical and statistical methods are commonly used green and stephenson 1986 legates and mccabe 1999 coffey et al 2004 the graphical method is used for a qualitative evaluation by comparing observations and simulated hydrographs and the statistical method is used for a quantitative evaluation based on statistics for various error indices asce 1993 in general the statistical method is based on an evaluation method that statistically divides the error index range and determines outputs in terms of various ratings santhi et al 2001 moriasi et al 2007 such an evaluation framework relatively straightforward process and hence its advantage is that it is readily applied nevertheless its limitation is that it cannot present standardized ratings for various error indices more importantly the evaluation framework based on a single error index cannot reflect the complementary interaction between different error indices it is also questionable how reasonably the error index range defined statistically represents the performance of a hydrologic model donigian et al 1983 ramanarayanan et al 1997 gupta et al 2009 singh et al 2005 several requirements must be satisfied in developing a robust hydrological assessment tool first a statistical meaningful index including error indices should be sought to ensure the objectivity of an evaluation framework second a combination of complementary error indices not a single error index must be considered green and stephenson 1986 coffey et al 2004 furthermore the outputs of a hydrologic model suitable for the application should be used for evaluation for example a long term complex hydrograph without separating single events should be avoided when evaluating a flood forecasting model as some period with no rain could play a role in generating noise that leads calculating inadequate error indices for the purpose of hydrological assessment in flood forecasting ramirez 2000 it is also important to consider the significance of the rising and recession limbs of a hydrograph as each limb represents a meaningful response of hydrological process the rising limb is mainly formed by concentration of direct runoff which determines peak flow and time to peak since the recession limb is formed by all types of runoff it is dominant over the rising limb in determining total runoff volume related to the water budget boyle et al 2000 machine learning could be the alternative to overcome the shortcomings of a general evaluation method described above machine learning utilizes algorithms that detect patterns and relationships inherent to inputs and outputs and is used across many areas with the development of various new algorithms and more powerful computers hong 2008 sahoo et al 2017 owing to an increase in the amount of data in hydrology the use of machine learning is becoming increasingly important more specifically it is expected to serve as a supplementary solution in physics based deterministic hydrology as many studies are being performed on physical factors such as surface runoff from rainfall groundwater and soil moisture coulibaly and anctil 1999 tokar and johnson 1999 shortridge et al 2016 machine learning that can combine two or more methods for effective data analysis is referred to as hybrid machine learning hml in general the hml uses two machine learning techniques suitable for most application and can complement the limitations of a single technique and deliver improved outcomes tsai and chen 2010 hml has been used widely in financial applications hsieh 2005 combined the k means clustering technique and the neural network technique and developed a credit scoring model based on a hybrid mining approach huysmans et al 2006 used a framework that combined an unsupervised self organizing maps technique and supervised multi layered perception technique to obtain a new credit scoring method tsai and chen 2010 reviewed various combinations of clustering machine learning techniques and classification machine learning techniques and demonstrated a high applicability of hml in developing credit rating systems tsai 2014 developed a novel hybrid financial distress model based on clustering and classification machine learning for supporting financial decisions these studies that coupled clustering and classification machine learning techniques to establish a hml framework demonstrated better results than a single machine learning technique the hml framework is considered an attractive approach for hydrological evaluation using various error indices a hml framework could secure a stable performance assessment by employing a big data and has an advantage to determine a composite rating metric this study aims to develop a novel hydrological assessment tool hat by adopting hml framework based on a combination of clustering and classification techniques and a composite of error indices national oceanic and atmospheric administration noaa national water model nwm is used to develop the hat since it has enough simulation data for over 5 years for training and testing the hat the nwm has been operated in real time since 2016 for the continental us conus han et al 2019 the performance test is conducted on rising and recession limbs in a single hydrograph as well as the total hydrograph to build train and validate the model nwm simulated streamflow from october 2013 to february 2017 is applied at selected usgs streamflow sites across the san francisco bay area the performance of the hat is then tested against the nwm simulated streamflow data the rest of this paper is organized as follows section 2 reviews the hydrological assessment framework in flood forecasting and introduces a hml framework and the hat used in this study section 3 presents data descriptions for this study the study area and the hat assessment results of simulated streamflow which is estimated by the nwm from 2013 to 2017 section 4 compares the error index based results presented by previous studies for the performance test of a hydrologic model with the results of the new hat and provides an overall discussion section 5 presents the conclusion of the study 2 materials and methods 2 1 hydrological assessment framework in flood forecasting aspect various error indices are used for hydrological assessment an error index is useful as it measures the simulated value against the reference value many cases where an error index was applied to hydrological assessment are noted in previous studies green and stephenson 1986 legates and mccabe 1999 moriasi et al 2007 yoo et al 2016 table 1 lists the error indices frequently used in hydrology error indices can be classified into two types based on their purpose the first type of index is related to hydrograph characteristic values and includes errors of peak flow peak time and total runoff volume peak flow is calculated from complex interactions between precipitation infiltration and effective rainfall resultant at the watershed outlet or measurement point it is the maximum flow during the period in which direct runoff occurs intensively peak time refers to the time at which the peak flow occurs as these error indices are determined by the rising limb of a hydrograph they are very useful in assessing the performance for flood forecasting the second type of error index quantifies hydrograph characteristics most notably it includes correlation coefficient cc nash sutcliffe efficiency coefficient nse bias and percent bias pbias and the rmse observations standard deviation ratio rsr these error indices have significance according to their development background for instance cc indicates a trend of simulated results against observations whereas bias shows only average differences in ratio as such a single error index cannot fully represent the accuracy of a simulated hydrograph furthermore even though various error indices are used together to assess a hydrograph many individual analyses are required along with a wide range of data to reach a unified conclusion owing to the different features and scales of each indices fig 1 shows poor assessment results obtained from the use of a single error index hydrological assessment should be based on an agile framework that can be applied in conditions appropriate for various purposes such as flood waves low flows and regulated flows in a river system for the purpose of flood forecasting an independent hydrograph is mainly assessed to test its performance in terms of surface runoff which determines the peak value and flood risk level evaluation results may sharply diagnose the model performance and suggest a direction for calibration moreover when a hydrological assessment is performed on a monthly or seasonal basis it can assess the overall hydrological process but its results cannot represent the outperformance of a model in terms of flood forecasting in addition as long duration simulated results contain multiple peak flows repeated rising and recession limbs and many low flows they can become noise when estimating error indices an independent hydrograph can be separated into two limbs rising and recession limbs the rising limb is a part of a hydrograph ranging from the initial point of the direct runoff flow to the peak flow conceptually the initial direct runoff flow starts when the precipitation rate exceeds initial losses in a watershed area in terms of flood forecasting the rising limb is very significant as it indicates a concentration time of discharge and as it provides the trend and magnitudes of the increasing flow and a peak flow the recession limb is the part of a hydrograph ranging from the peak flow to the point where the decreasing flow is corresponds to the discharge immediately before the initial direct runoff in terms of water management the recession limb is very important as all hydrological runoff components surface subsurface and groundwater occur during this time finally understandable terminology must be used to allow people across different disciplines to interpret assessment results 2 2 hybrid machine learning framework machine learning uses the x dataset as an independent variable and the y label as a dependent variable and is divided into supervised learning sl and unsupervised learning usl based on whether it has the y label bishop 2006 some of the most widely known sl approaches include the artificial neural network mcculloch and pitts 1943 the random forest breiman 2001 usl approaches include the self organizing map kohonen 1982 and k means clustering macqueen 1967 in the past it was difficult to utilize machine learning owing to the limitations of computer technology however machine learning is garnering significant attention with the recent advances in high performance computing many hydrological applications which generate and handle large amounts of data and information are also applying machine learning techniques shrestha and solomatine 2006 demissie et al 2009 2 2 1 unsupervised learning for clustering usl is a type of machine learning that detects complex relationships between x datasets with no determined y label usl is mostly used for clustering dimension reduction and anomaly detection clustering is the most widely used technique in usl and it aims to detect similarity between datasets and to cluster similar data points into one group in addition it can be used to identify similarity between data points in a cluster or differences with other objects in another cluster tsai and chen 2010 some of the most widely known clustering techniques include k means macqueen 1967 dbscan ester et al 1996 and hierarchical clustering johnson 1967 k means clustering proposed by macqueen 1967 is based on non hierarchical clustering and is effective in detecting clusters from extensive large data sets hartigan and wong 1979 everitt et al 2001 olden et al 2012 fig 2 shows the conceptual diagram of a k means clustering technique k means includes the number of clusters as a parameter and uses it to begin clustering initial datasets as many centroids as a set number of clusters are randomly chosen and centroids are changed repeatedly until the sum of the distances between each centroid and data points reaches the minimum finally a centroid that has the minimum sum of distances is detected to determine the set number of clusters the advantages of k means are that its algorithms are simple and fast to calculate it can obtain very reliable results and it can be applied in various applications that involve a large amount of datasets 2 2 2 supervised learning for classification sl is a type of machine learning that detects a pattern between the x dataset and the y label and expresses the relationship in a function it is used widely across disciplines that require data mining sl can establish a model that estimates and predicts the y label for a newly input x dataset by learning a training dataset consisting of an x dataset and y label pair sl is mainly used for regression and classification based on a causal relationship for datasets the supervised classification technique is one of the most widely used techniques for statistics and engineering and it classifies and predicts given x datasets into a suitable y label the dependent variable y label serves as a category and is used for learning together with the independent variable x dataset classification techniques includes random forest breiman 2001 support vector machine boser et al 1992 and artificial neural networks mcculloch and pitts 1943 among the classification techniques the random forest is highly applicable to applications that require the informed decision making based on numerous data a high speed processing and high accuracy this technique also has an advantage that is easy to link with the usl based clustering technique for hml establishment the random forest which was introduced by breiman 2001 is a type of ensemble learning based on multiple decision trees the random forest applies randomness to not only training sets but also each decision tree s variable to reduce the high probability of overfit of the traditional decision tree method da silva chagas et al 2016 fig 3 illustrates the conceptual diagram of the random forest technique first n sub training sets are randomly selected from a given total training set here a sub training set refers to a single decision tree while the sub training set processing is the same as that of traditional decision tree processing available variables are applied considering randomness the final outcome is chosen based on majority voting determined from n decision trees ließ et al 2012 da silva chagas et al 2016 as such the random forest combines prediction results from multiple trees and makes a decision by using a bootstrap of samples similar to the conventional bootstrap aggregating method i e bagging and can achieve both predictability and stability cutler et al 2007 wang et al 2015 in the random forest a weight of variables is determined through measuring of contribution of the variables to the prediction accuracy and the node impurity used in training process the descriptions of the detailed method are well documented elsewhere louppe et al 2013 2 2 3 hybrid machine learning framework hml refers to a combination of two or more machine learning techniques tsai and chen 2010 in general such techniques include a combination of 1 usl techniques 2 sl and usl techniques or 3 a combination of sl techniques different hml frameworks can be established depending on the combination sequence and type of applied techniques for a combination of sl and usl techniques the pattern and characteristics of an x dataset can be defined by usl as a y label and the hml framework that shares it with sl can be established fig 4 shows the conceptual diagram of a hml framework that combines the usl based clustering technique and the sl based classification technique first clustering creates groups i e clusters and provides them as a y label to classification the hml framework generates the y label required for training in the sl technique from unsupervised clustering and the sl technique takes charge of modeling which is difficult in the usl technique by doing so the limitations of the two techniques can be mutually complemented the y label provided from clustering is applied to classification learning along with the x dataset and the applicability of the model is confirmed through a verification process the established model estimates and predicts the y label for a new x dataset 2 3 a framework for hydrological assessment tool this study adopts a hml technique as described in section 2 2 3 and established a hat that can assess the accuracy of simulated streamflow the hml framework is configured through a combination of k means and random forest one of the key points in the applied hml framework is that the x dataset an input is clustered into multiple groups and the group is used as the y label required for classification accordingly the representation of the y label for the clustered x dataset group should be apparent in the hml framework the sl plays a role in establishing a practical model that can estimate the y label for a new x dataset the hat can evaluate rising and recession limbs for an independent hydrograph as well as the total hydrograph the evaluation results are determined by four ratings very good vg good g satisfactory s and unsatisfactory us which are determined by the unsupervised clustering technique the hat can evaluate all streamflow hydrographs estimated or predicted using various methodologies such as deterministic and stochastic approaches since this hml framework has a relatively simple structure it could be applied not only for hydrologic modeling but also more broadly for analysis of other geophysical quantities fig 5 is a schematic diagram of the structure and flow of the hat the hat consists of three modules the first module is for pre processing this module aims to separate an independent hydrograph identify rising and recession limbs and calculate error indices for the independent hydrograph and two limbs the separation process has four steps as follows 1 smoothing the hydrograph to eliminate the noise due to small fluctuation i e hydrological responses in observed hydrograph the smoothed hydrograph is used to determine the beginning and end points at a smoothing three points t 1 t and t 1 arithmetic mean is used 2 eliminating very low flows below threshold value the threshold value is defined as mean observed runoff over entire period 3 the rate of runoff increment is used to identify the rising and recession limbs of a single hydrograph the rate of increment at each time is defined as runoff t 1 runoff t runoff t parts of rising and recession limbs are defined by setting the threshold of the increment rate for each drainage area small 163 km2 medium 1010 km2 large 1010 km2 the threshold is determined by sensitivity analysis for rising limb the threshold values are 0 50 for small area 0 30 for medium area and 0 25 for large area for recession limb the threshold values are 0 50 for small area 0 40 for medium area and 0 20 for large area the beginning point at which the rising limb begins the end point at which the recession limb ends and the peak point at which the largest runoff occurs in the hydrograph in the case of recession limb the n days method is used to determine the point of the end point for complex hydrographs with two or more peak flows the largest runoff value is defined as the peak point of the hydrograph and the rising and recession limbs are defined according to the processes previously described in this study five indices to evaluate the performance of the nwm hydrologic model are used within the error indices shown in table 1 this study used three cc nse pf of them and modified two modified pbias and tp of them to build the clustering module the combination of the five error indices demonstrated better performance in the clustering module than the other combinations for example using nse and rsr together was not as good as using only nse as statistical meanings of the two error indices are similar see table 1 each error index used in this study has a different role in determining clusters pf and the modified tp were used as hydrograph characteristic values and cc nse and mod pbias which quantified the characteristics of a hydrograph from various aspects were applied as error indices the cc shows the trend of a hydrograph and nse shows the variance of simulated errors against observations mod pbias refers to modified pbias and aims to consider errors in runoff volume mod pbias considers the cancellation effect of the runoff volume error which cannot be reflected by the existing pbias and overcomes the limitations of the conventional method which estimates errors only based on the observed runoff volume eq 1 furthermore the modified tp hereinafter referred to as mod tp was used instead of the existing tp so that the peak times that have different error directions but the same scale can be clustered in the same group eq 2 these estimated error indices are used as the x dataset in the clustering and classification modules 1 m o d p b i a s a b s q obs q sim q obs q sim 100 2 m o d t p a b s t obs t sim the second is the clustering module this module determines ratings which indicate the performance level of a hydrologic model based on the error indices described above and provides the y label required for training and testing in the classification module cc nse and mod pbias are applied to rising and recession limbs and the pf and the mod tp hr are used in addition to these three indices in the total hydrograph in the clustering process it is necessary to determine the appropriate k as k i e the number of clusters of k means is an important parameter that affects the reliability of the clustering result this study implements sensitivity analysis using k values from 4 to 30 and compares the observed and simulated hydrographs to verify clustering results in the four ratings the sensitivity analysis consists of two steps to determine an initial k and final k to determine the initial k statistics e g mean and variance of error indices are used to rank in order of superiority in order to confirm the final k r square value between the simulated and observed hydrographs was used as another statistics in this study the initial k is determined to 20 when more than 20 of k is used it was difficult to distinguish clustered groups due to similar statistics of the groups conversely when smaller than 20 of k is used mean value of error indices was not representative of each group as variance of error indices was too wide final k was determined to 4 of the clustered groups referring to vg g s and us the third module is the classification this module is responsible for modeling training and testing the hat the range of the five error indices of clusters from the clustering module has a limitation to represent the relationship between the clusters and the ranges since it indicates only a degree of distance between a centroid of clusters and error indices to overcome this limitation this study employs the third module the classification the classification module aims to model the range of the error indices and to help understanding of the clusters from the clustering module the classification module identifies the algorithm between the clusters and the range of error indices and builds up the knowledge for modeling the range through training in addition the classification module provides weights of the error indices so that it is able to analyze the contribution of the indices to clustering the error indices are used as the x dataset and four ratings determined in the clustering module are used as the y label the hat training is performed using a large amount of streamflow data and the performance of the trained hat can be verified from the x dataset and y label for verification the verified hat can be implemented by using observed and simulated time series streamflow data and the four ratings can be determined for the rising and recession limbs and a total 2 4 national water model the nwm is a fully distributed hydrologic model that aims to enhance flood forecasting capability of the noaa hydrologic prediction system han et al 2019 the nwm simulates the water cycle with mathematical representations of different physical processes and their interactions this complex representation of physical processes such as rainfall rate and spatial distribution snowmelt and infiltration and movement of water through the soil layers varies significantly with the change in terrain soils vegetation types and various other variables cosgrove et al 2018 the nwm is based on the community wrf hydro modeling system which produces various hydrological analysis and prediction products including gridded fields of surface runoff soil moisture snowpack shallow groundwater levels inundated area depths and evapotranspiration as well as estimates of river flow and velocity for approximately 2 7 million river reaches defined by the seamless national hydrography dataset nhd plus v2 0 hydrography dataset the nwm ingests atmospheric forcings e g temperature humidity and precipitation rate into a noah mp land surface model lsm to simulate land surface processes at a 1 km resolution then once exfiltration from the soil column is calculated a diffusive wave overland routing scheme moves water horizontally across the landscape at 250 m catchment aggregation occurs and distributes the water into the channel network at the end of each modeling time step and flow is routed according to a modified muskingum cunge scheme along a modified version of the nhdplus where waterbodies lakes and reservoirs are encountered on the network and store release water according to a level pool routing scheme https water noaa gov about nwm 2 5 data this study is performed in the nine county regions surrounding the san francisco sf bay area california the sf is an area of diverse topography with regions near sea level juxtaposed with mountains rising in excess of 1000 m the sf bay area is a flood prone region owing to orographic rainfall occurring in steep terrain cifelli et al 2018 the orographic rainfall is often produced from moisture plumes over the pacific ocean known as atmospheric rivers ars ralph et al 2012 as an example an ar event starting on december 29 2005 brought more than 20 in of rain across the sf bay region urban areas such as the city of san francisco recorded 24 hour rainfall totals of 5 in on december 31 alone there was major flooding in the napa and russian river basins with 10 counties declaring federal disaster areas over 1000 homes were flooded in napa costing over 300 million in damages the geographic diversity and resulting flooding events in the sf bay area provides a challenging testbed to evaluate the performance of the nwm fig 6 shows the locations of the sf bay area and stream gages that are currently operated by the usgs a total of 91 usgs gages were identified across the nine counties in the sf bay area upon review on the usgs s observed data a subset of 57 usgs gages were selected in this study excluding those that observed low quality streamflow data associated with reservoir operations and diversions the watershed for these 57 gages varies from 11 5 to 3425 3 km2 this study used the nwm to conduct a retrospective streamflow simulation using nldas forcing data cosgrove et al 2003 as inputs the hat is developed and tested using long time period data from october 2013 to february 2017 the performance of hat and nwm for the sf bay area is assessed against the usgs streamflow data 3 results 3 1 clustering of rating labels the ratings of the four clustered groups were categorized into vg g s and us as a part of the statistical method the characteristics of error indices for each rating were examined fig 7 illustrates the probability distribution of error indices for each rating group and each error index the results are for individual rising and recession limbs and total hydrographs according to the overall results the trend of the probability distribution depending on rating group was obvious that all of average error index from vg to us moves toward the direction of negative meaning i e negative infinity for nse and variance increases gradually it was also found that the percentage of a higher rating level was higher as the fraction of each rating approached the ideal error index i e 1 0 for cc and nse whereas the percentage of a lower rating level was higher as it was further away these results were observed in all error indices and in rising and recession limbs and total hydrographs in addition table 2 lists statistics of error indices depending on the performance rating for the total hydrograph case from the table it confirms the range features of error indices by the clustered rating level it is found that the ranges minimum to maximum of the error indices were overlapped since the rating groups have clustered with a composite of the error indices for example a range of cc in very good rating level is from 0 74 to 1 00 and in good rating level is from 0 44 to 0 98 this result suggests that the clustered rating levels are very reasonable as there is no absolute range for performance rating however a range from q1 to q3 of the error indices was barely overlapped in the ratings the characteristics of mean and variance statistics in the table were very obvious by each rating level and it supports the results in fig 7 it was confirmed that error indices for each rating were reasonably clustered subsequently an assessment of the quality of simulated hydrologic model results for each rating was conducted fig 8 shows scatter density plots between usgs observations and simulated nwm values for each rating to remove the variability of different streamflow scales by various watershed areas and rainfall events the observed and simulated streamflow were normalized by a peak flow so that it did not exceed 1 0 the results showed that the distribution trend of the scatter plot of each rating was distinct and the observed trend was consistent each rating s meaning according to the results for the total hydrograph vg s coefficient of determination was 0 86 and was the highest and the data points tended to cluster around the x y line g showed a similar distribution trend to that of vg but its density for the x y line was relatively lower and more scattered g s coefficient of determination was 0 66 s showed a more scattered distribution trend than g and its coefficient of determination was 0 49 for us most of the data points were located around the x or y axis indicating simulated values were largely underestimated or overestimated compared with observed ones as a result us s coefficient of determination was 0 01 which was the lowest the scatter plot trend for each rating was observed to be identical in the results of rising and recession limbs in addition fig 9 shows samples of the comparison results between the observed and simulated hydrographs in the four ratings clustered groups runoff y axis and duration time x axis are normalized using a maximum value the results present a degree of quality of hydrograph in accordance with each rating the clustering module determined the ratings that were reliable both statistically and graphically the determined ratings were then used as the y label in the classification module and served as a link between two machine learning techniques 3 2 classification and verification the classification module was built based on the supervised random forest technique and aims to detect the hidden pattern between error indices x dataset and ratings y label since the random forest technique includes the sl process for modeling the evaluation tool the classification module in which all processes were completed became the hat that can perform a hydrological assessment on new x datasets the trained classification module evaluates the performance of the model through a verification process table 3 lists the verification results for the trained classification module here 80 of the training data was used for training whereas 20 was used for verification the verification was performed by comparing the ratings previously determined by the clustering module and the ratings determined through the hat according to the results the concordance rates of the hat ratings were 98 rising 99 recession and 97 total which confirms that the hat could perform an accurate hydrograph assessment the concordance rate for each rating was also observed to be similar to the above table 4 lists a weight of error indices determined in the classification module in overall mod pbias is the most important error index to assign the ratings and cc and nse are the next higher in order in the case of total hydrograph the weights of tp and pb are similar to nse it is speculated that the accuracy of baseflow played a role in determining the weight as the evaluation subject of the hat is total runoff flow consisting of baseflow and direct runoff flow not only for direct runoff flow that could describe the main reason of why mod pbias is considered as the most important weight 3 3 test to evaluate the nwm the hat tested the performance of the nwm for the sf bay area through adopting a concept of leave one out cross looc validation method efron 1983 which is widely used in machine learning technique the looc validation method leaves one set of total available data sets as a test set trains the hat using the remaining data sets except the one set and tests the nwm performance using the one set and repeat this process as many times as needed in this study the entire simulation period october 2013 february 2017 is equally divided into 10 sub periods as the data sets by sequence of date and the looc validation method is applied to each sub period the entire simulated results by the looc validation method are analyzed at various points of view table 5 shows the validation result of the looc validation method using a fraction of incorrect ratings a range of the fractions is from 1 9 to 4 4 on average which confirms that the hat is properly built and performs an accurate hydrograph assessment however overrated and underrated results did not show significant proportional differences the results by drainage size are presented in fig 10 overall the performance of the nwm for the sf bay area was rated vg or g by the hat for at least 46 of the simulated hydrographs regardless the limbs and total hydrograph the occurrence of vg and g increased with drainage area for the total hydrograph results the ratings of small areas vg and g accounted for 42 or more medium areas 50 or more and large areas 58 or more similar trends were identical across the limbs of the hydrograph in this study training of the hat was implemented for each hydrograph limb thus the distribution of the four labels could be different depending on the hydrograph limbs i e rising and recession for example a fraction of us in the rising limb is 5 on average while a fraction of us in the recession limb is 28 which is 5 times higher fig 11 shows a map representing the average ratings of total hydrograph at usgs gages and the fraction of ratings for each county from us to vg the model performance score ranges from 0 0 to 3 0 and the arithmetically averaged score is indicated on the map according to the results by county marin county scored 0 62 points on average and showed the lowest nwm performance among six other counties except three counties whose the observed data properly usable is not found vg and g accounted for less than 18 5 following marin county napa county showed the second lowest performance at 1 11 points the best performance was shown in santa clara county which scored 1 79 points on average these vg and g ratings of the county accounted for 66 7 or more in addition the overall results demonstrated that the nwm performance for the southern sf bay area san mateo santa clara and alameda was better than that for the northern sf bay area marin sonoma and napa since the accuracy of simulated streamflows varies with various characteristics of rainfall and watershed it is necessary to examine how the decision of performance ratings is affected by them fig 12 shows the contribution of four impact factors complexity of hydrograph with the numbers of peak runoff duration drainage size and whether regulated or not to performance ratings in the case of complexity of hydrograph the ratings were assigned equally regardless of the numbers of peak multiple peaks case has a large fraction of vg and it confirms that the performance of the nwm for complex storm events is reliable and comparable to simulation performance for single storm events in the case of runoff duration g s and us did not show significant proportional differences by a duration length for vg the long duration has the largest fraction in the case of drainage size the higher ratings were assigned to a large drainage area a fraction of a large drainage area was higher at the three ratings except the us and the small area tended to be the opposite trend of the large drainage area there are several reasons for that the hat assigns the performance ratings for total runoff flows consisting of baseflows and direct flows and a large drainage area is affected by the accuracy of baseflow different from small drainage areas commonly located in the upper river basin also mod pbias among the error indices is highly influenced to determine the performance rating in the case of whether regulated or not g s and us did not show significant proportional differences and a fraction of unregulated was higher at vg 4 discussion one of the most notable hydrological evaluation framework studies was conducted by moriasi et al 2007 who suggested general hydrological assessment guidelines their study determined classification criteria for an error index through the basic framework of decision trees and tested the performance of a hydrologic model based on the determined classification criteria however their evaluation method can only be used for single indices and it is difficult to draw a comprehensive conclusion from various indices fig 13 compares the results of the hat and moriasi et al 2007 nse pbias and rsr error indices were used for the results of moriasi et al 2007 the results using the moriasi et al 2007 methodology are difficult to interpret in terms of an overall performance rating result graphically the scatter plot distributions of the top three ratings vg g and s are so similar that it was difficult to distinguish them the us rating showed no trend in the scatter plot distribution these results could be reaffirmed by the coefficient of determination in particular there were few differences in the coefficient of determination between vg g and s and hence it was difficult to determine which rating shows high accuracy when pbias was applied the coefficient of determination of the three ratings ranged from 0 75 to 0 77 and the coefficient of determination for the g rating was estimated to be higher than that of the vg rating in nse and rsr the coefficient of determination for the three ratings ranged from 0 85 to 0 92 and from 0 84 to 0 92 respectively which was similar to that in pbias while the coefficient of determination of the us rating was estimated to be much lower than those of the top three ratings it was difficult to conclude that us was assessed well given that there was no trend in the scatter plot distribution the advantage of the hat is that by objectively combining the indices into an objective algorithm an overall assessment of the model performance is easier to obtain in addition table 6 shows the comparison results of ranges of error indices derived from the hat and moriasi et al 2007 it confirms that the absolute ranges of error indices used in the general evaluation may not reasonable to evaluate simulation results the hat showed a high accuracy of over 98 in the verification results to further improve the performance of the hat we believe that a model that uses more training data than those used in this study should be established for 2 the ratings were underestimated compared with the actual ratings in all cases these results may be obtained owing to the use of the random forest apart from whether the amount of data is simply large or small the random forest is a machine learning technique that supplements flexibility which decision trees do not have and determines classification criteria between the given x dataset and y label from various decision trees this technique however cannot implement perfect classification criteria without infinite training data owing to the fundamental problem of decision trees discontinuous classification criteria even if the optimized classification criteria are determined based on multiple decision trees nevertheless 98 accuracy achieved by the hat can be considered acceptable and we believe that the ratings for the hydrologic model determined via the hat established based on such a performance are reliable understanding uncertainties in the procedures needs for meaningful quantification of the results in case of this study uncertainties may arise from two parts the hydrograph separation and the four ratings assignment the hydrograph separation is the important process as it determines an independent hydrograph as well as two limbs i e rising and recession which is the source for evaluation criteria of the hydrologic model performance thus the results could be slightly varied with the separation methods especially in determining the end point of a hydrograph however it is speculated that the uncertainties from the hydrograph separation are not big enough to change the results as the error indices were barely changed depending on the lengths of a hydrograph on the other hands since the rating assignment is a key to evaluate a hydrograph whether it is good or not the parameter k in the cluster module is very important in this study k is determined by the sensitivity analysis method so that the result may include a subjective point of view 5 summary and conclusions this study describes the hat based on the hml technique the hml technique was established by a combination of clustering and classification techniques and ratings were reasonably determined from a composite of various error indices the hat was applied to retrospective simulations of the nwm in the sf bay area conclusions from this study include 1 a novel assessment tool hat has been developed four ratings determined by the hat accompanied apparent statistical and graphical characteristics and could accurately diagnose outputs for each rating accordingly it could define the status of the model for each rating objectively and the hat is expected to be applied to determine the necessity strategy and extent of calibration 2 through the training and verification processes we confirmed the reliability of the hat and showed that hat could assess a single hydrograph from three aspects the rising and recession limbs and total hydrograph moreover easy to understand terms were used to define ratings and help understand the assessment results 3 the hat assessed the performance of the nwm for the sf bay area using a limited training and verification data set the nwm was shown to perform g vg for at least 46 of the hydrographs examined during from october 2013 to february 2017 regardless of the watershed size the new evaluation framework is extensively applicable the hat is able to rate for additional performance levels e g super very good and super unsatisfactory by adding new groups as it is very flexible if sub hourly evaluation is needed like a flash flood the hat could implement that through training the hat based on sub hourly time step data also the hat can be applied to not only a flood forecasting model but also any geophysical data that are driven by physically pulsed phenomena for instance it can be applied to the indices that represent precipitation soil moisture content ground water pollution load and natural disasters acknowledgments this work was supported by the california department of water resources and the noaa physical sciences division and this research was supported by basic science research program through the national research foundation of korea declaration of competing interest none 
6188,this study introduces a novel hydrological assessment tool hat based on hybrid machine learning hml framework the hml framework combines an unsupervised clustering technique and a supervised classification technique to determine reasonable performance ratings unsatisfactory satisfactory good and very good and build a practical assessment tool hydrologically significant error indices are used to cluster the performance rating groups and train the hat the hat was applied to the national water model nwm which is operated in real time for the continental united states conus for establishing training and validating the hat data from october 2013 to february 2017 were used and a performance assessment was conducted on the nwm in the san francisco bay area as a result the hat determined the performance ratings that were reliable in terms of the statistics and hydrograph it was confirmed that the hat could perform an accurate hydrograph assessment as the concordance rate of the performance ratings was 98 the nwm was evaluated against 57 usgs streamflow gauges using the hat and was found to perform with 46 on average good and very good ratings the hml framework an integral part of the hat is expected to be useful not only in hydrological analysis but also across all geophysical fields that deal with physical processes keywords hydrological assessment hybrid machine learning national water model streamflow evaluation performance ratings 1 introduction identifying and predicting the response of hydrologic systems by using a simulation model are very important for reducing damages from natural disasters abbott et al 1986 dutta et al 2003 rozalis et al 2010 yoo et al 2012 kim et al 2018a b this is because a hydrologic model can identify in advance the potential occurrence of various water related natural disasters as it estimates and predicts the flow and volume from surface to groundwater runoff in time and space henderson and wooding 1964 moreover by virtue of advanced remote sensing techniques quantitative precipitation estimation schemes kim et al 2015 and correction methods yoo et al 2014 kim and yoo 2014 to improve accuracy of meteorological inputs e g precipitation hydrological products from models will play a role in a wide range of disciplines many types of hydrologic models have advanced from the basic lumped approach that combines characteristics across an entire watershed to provide forecast information at an outlet point to distributed hydrologic models that account for spatially varying characteristics across the watershed and can be used to simulate a local scale flood liang et al 1994 arnold et al 1998 singh and woolhiser 2002 in contrast to the evolution and improvement of hydrologic modeling general hydrological evaluation methods have remained simple most relying on a few error indices a hydrological evaluation method is not simply to determine whether there are many or few errors it should reasonably determine the reliability of outputs and present objective indices understandable to users the limitations of current hydrological evaluation methods must be overcome and a new assessment tool is required that can objectively evaluate any hydrologic model performance there are many potential and important uses for the hydrological evaluation method in hydrology its main purposes include calibrating the model evaluating its performance and communicating with stakeholders the hydrologic model which has a complex structure and various parameters requires a calibration process depending on the status of outputs and the evaluation of its results determines the necessity strategy and extent of calibration moriasi et al 2007 as the model s performance differs depending on the status of inputs arising from various meteorological forcings and geographical characteristics and the status of calibration the hydrological evaluation method is useful for evaluation of its performance beven 1993 freer et al 1996 furthermore the hydrological evaluation method serves as to provide guidance on the model s reliability to forecasters and operators who use the hydrologic model outputs for decision making flood warnings and mitigation al sabhan et al 2003 for current hydrological evaluation the graphical and statistical methods are commonly used green and stephenson 1986 legates and mccabe 1999 coffey et al 2004 the graphical method is used for a qualitative evaluation by comparing observations and simulated hydrographs and the statistical method is used for a quantitative evaluation based on statistics for various error indices asce 1993 in general the statistical method is based on an evaluation method that statistically divides the error index range and determines outputs in terms of various ratings santhi et al 2001 moriasi et al 2007 such an evaluation framework relatively straightforward process and hence its advantage is that it is readily applied nevertheless its limitation is that it cannot present standardized ratings for various error indices more importantly the evaluation framework based on a single error index cannot reflect the complementary interaction between different error indices it is also questionable how reasonably the error index range defined statistically represents the performance of a hydrologic model donigian et al 1983 ramanarayanan et al 1997 gupta et al 2009 singh et al 2005 several requirements must be satisfied in developing a robust hydrological assessment tool first a statistical meaningful index including error indices should be sought to ensure the objectivity of an evaluation framework second a combination of complementary error indices not a single error index must be considered green and stephenson 1986 coffey et al 2004 furthermore the outputs of a hydrologic model suitable for the application should be used for evaluation for example a long term complex hydrograph without separating single events should be avoided when evaluating a flood forecasting model as some period with no rain could play a role in generating noise that leads calculating inadequate error indices for the purpose of hydrological assessment in flood forecasting ramirez 2000 it is also important to consider the significance of the rising and recession limbs of a hydrograph as each limb represents a meaningful response of hydrological process the rising limb is mainly formed by concentration of direct runoff which determines peak flow and time to peak since the recession limb is formed by all types of runoff it is dominant over the rising limb in determining total runoff volume related to the water budget boyle et al 2000 machine learning could be the alternative to overcome the shortcomings of a general evaluation method described above machine learning utilizes algorithms that detect patterns and relationships inherent to inputs and outputs and is used across many areas with the development of various new algorithms and more powerful computers hong 2008 sahoo et al 2017 owing to an increase in the amount of data in hydrology the use of machine learning is becoming increasingly important more specifically it is expected to serve as a supplementary solution in physics based deterministic hydrology as many studies are being performed on physical factors such as surface runoff from rainfall groundwater and soil moisture coulibaly and anctil 1999 tokar and johnson 1999 shortridge et al 2016 machine learning that can combine two or more methods for effective data analysis is referred to as hybrid machine learning hml in general the hml uses two machine learning techniques suitable for most application and can complement the limitations of a single technique and deliver improved outcomes tsai and chen 2010 hml has been used widely in financial applications hsieh 2005 combined the k means clustering technique and the neural network technique and developed a credit scoring model based on a hybrid mining approach huysmans et al 2006 used a framework that combined an unsupervised self organizing maps technique and supervised multi layered perception technique to obtain a new credit scoring method tsai and chen 2010 reviewed various combinations of clustering machine learning techniques and classification machine learning techniques and demonstrated a high applicability of hml in developing credit rating systems tsai 2014 developed a novel hybrid financial distress model based on clustering and classification machine learning for supporting financial decisions these studies that coupled clustering and classification machine learning techniques to establish a hml framework demonstrated better results than a single machine learning technique the hml framework is considered an attractive approach for hydrological evaluation using various error indices a hml framework could secure a stable performance assessment by employing a big data and has an advantage to determine a composite rating metric this study aims to develop a novel hydrological assessment tool hat by adopting hml framework based on a combination of clustering and classification techniques and a composite of error indices national oceanic and atmospheric administration noaa national water model nwm is used to develop the hat since it has enough simulation data for over 5 years for training and testing the hat the nwm has been operated in real time since 2016 for the continental us conus han et al 2019 the performance test is conducted on rising and recession limbs in a single hydrograph as well as the total hydrograph to build train and validate the model nwm simulated streamflow from october 2013 to february 2017 is applied at selected usgs streamflow sites across the san francisco bay area the performance of the hat is then tested against the nwm simulated streamflow data the rest of this paper is organized as follows section 2 reviews the hydrological assessment framework in flood forecasting and introduces a hml framework and the hat used in this study section 3 presents data descriptions for this study the study area and the hat assessment results of simulated streamflow which is estimated by the nwm from 2013 to 2017 section 4 compares the error index based results presented by previous studies for the performance test of a hydrologic model with the results of the new hat and provides an overall discussion section 5 presents the conclusion of the study 2 materials and methods 2 1 hydrological assessment framework in flood forecasting aspect various error indices are used for hydrological assessment an error index is useful as it measures the simulated value against the reference value many cases where an error index was applied to hydrological assessment are noted in previous studies green and stephenson 1986 legates and mccabe 1999 moriasi et al 2007 yoo et al 2016 table 1 lists the error indices frequently used in hydrology error indices can be classified into two types based on their purpose the first type of index is related to hydrograph characteristic values and includes errors of peak flow peak time and total runoff volume peak flow is calculated from complex interactions between precipitation infiltration and effective rainfall resultant at the watershed outlet or measurement point it is the maximum flow during the period in which direct runoff occurs intensively peak time refers to the time at which the peak flow occurs as these error indices are determined by the rising limb of a hydrograph they are very useful in assessing the performance for flood forecasting the second type of error index quantifies hydrograph characteristics most notably it includes correlation coefficient cc nash sutcliffe efficiency coefficient nse bias and percent bias pbias and the rmse observations standard deviation ratio rsr these error indices have significance according to their development background for instance cc indicates a trend of simulated results against observations whereas bias shows only average differences in ratio as such a single error index cannot fully represent the accuracy of a simulated hydrograph furthermore even though various error indices are used together to assess a hydrograph many individual analyses are required along with a wide range of data to reach a unified conclusion owing to the different features and scales of each indices fig 1 shows poor assessment results obtained from the use of a single error index hydrological assessment should be based on an agile framework that can be applied in conditions appropriate for various purposes such as flood waves low flows and regulated flows in a river system for the purpose of flood forecasting an independent hydrograph is mainly assessed to test its performance in terms of surface runoff which determines the peak value and flood risk level evaluation results may sharply diagnose the model performance and suggest a direction for calibration moreover when a hydrological assessment is performed on a monthly or seasonal basis it can assess the overall hydrological process but its results cannot represent the outperformance of a model in terms of flood forecasting in addition as long duration simulated results contain multiple peak flows repeated rising and recession limbs and many low flows they can become noise when estimating error indices an independent hydrograph can be separated into two limbs rising and recession limbs the rising limb is a part of a hydrograph ranging from the initial point of the direct runoff flow to the peak flow conceptually the initial direct runoff flow starts when the precipitation rate exceeds initial losses in a watershed area in terms of flood forecasting the rising limb is very significant as it indicates a concentration time of discharge and as it provides the trend and magnitudes of the increasing flow and a peak flow the recession limb is the part of a hydrograph ranging from the peak flow to the point where the decreasing flow is corresponds to the discharge immediately before the initial direct runoff in terms of water management the recession limb is very important as all hydrological runoff components surface subsurface and groundwater occur during this time finally understandable terminology must be used to allow people across different disciplines to interpret assessment results 2 2 hybrid machine learning framework machine learning uses the x dataset as an independent variable and the y label as a dependent variable and is divided into supervised learning sl and unsupervised learning usl based on whether it has the y label bishop 2006 some of the most widely known sl approaches include the artificial neural network mcculloch and pitts 1943 the random forest breiman 2001 usl approaches include the self organizing map kohonen 1982 and k means clustering macqueen 1967 in the past it was difficult to utilize machine learning owing to the limitations of computer technology however machine learning is garnering significant attention with the recent advances in high performance computing many hydrological applications which generate and handle large amounts of data and information are also applying machine learning techniques shrestha and solomatine 2006 demissie et al 2009 2 2 1 unsupervised learning for clustering usl is a type of machine learning that detects complex relationships between x datasets with no determined y label usl is mostly used for clustering dimension reduction and anomaly detection clustering is the most widely used technique in usl and it aims to detect similarity between datasets and to cluster similar data points into one group in addition it can be used to identify similarity between data points in a cluster or differences with other objects in another cluster tsai and chen 2010 some of the most widely known clustering techniques include k means macqueen 1967 dbscan ester et al 1996 and hierarchical clustering johnson 1967 k means clustering proposed by macqueen 1967 is based on non hierarchical clustering and is effective in detecting clusters from extensive large data sets hartigan and wong 1979 everitt et al 2001 olden et al 2012 fig 2 shows the conceptual diagram of a k means clustering technique k means includes the number of clusters as a parameter and uses it to begin clustering initial datasets as many centroids as a set number of clusters are randomly chosen and centroids are changed repeatedly until the sum of the distances between each centroid and data points reaches the minimum finally a centroid that has the minimum sum of distances is detected to determine the set number of clusters the advantages of k means are that its algorithms are simple and fast to calculate it can obtain very reliable results and it can be applied in various applications that involve a large amount of datasets 2 2 2 supervised learning for classification sl is a type of machine learning that detects a pattern between the x dataset and the y label and expresses the relationship in a function it is used widely across disciplines that require data mining sl can establish a model that estimates and predicts the y label for a newly input x dataset by learning a training dataset consisting of an x dataset and y label pair sl is mainly used for regression and classification based on a causal relationship for datasets the supervised classification technique is one of the most widely used techniques for statistics and engineering and it classifies and predicts given x datasets into a suitable y label the dependent variable y label serves as a category and is used for learning together with the independent variable x dataset classification techniques includes random forest breiman 2001 support vector machine boser et al 1992 and artificial neural networks mcculloch and pitts 1943 among the classification techniques the random forest is highly applicable to applications that require the informed decision making based on numerous data a high speed processing and high accuracy this technique also has an advantage that is easy to link with the usl based clustering technique for hml establishment the random forest which was introduced by breiman 2001 is a type of ensemble learning based on multiple decision trees the random forest applies randomness to not only training sets but also each decision tree s variable to reduce the high probability of overfit of the traditional decision tree method da silva chagas et al 2016 fig 3 illustrates the conceptual diagram of the random forest technique first n sub training sets are randomly selected from a given total training set here a sub training set refers to a single decision tree while the sub training set processing is the same as that of traditional decision tree processing available variables are applied considering randomness the final outcome is chosen based on majority voting determined from n decision trees ließ et al 2012 da silva chagas et al 2016 as such the random forest combines prediction results from multiple trees and makes a decision by using a bootstrap of samples similar to the conventional bootstrap aggregating method i e bagging and can achieve both predictability and stability cutler et al 2007 wang et al 2015 in the random forest a weight of variables is determined through measuring of contribution of the variables to the prediction accuracy and the node impurity used in training process the descriptions of the detailed method are well documented elsewhere louppe et al 2013 2 2 3 hybrid machine learning framework hml refers to a combination of two or more machine learning techniques tsai and chen 2010 in general such techniques include a combination of 1 usl techniques 2 sl and usl techniques or 3 a combination of sl techniques different hml frameworks can be established depending on the combination sequence and type of applied techniques for a combination of sl and usl techniques the pattern and characteristics of an x dataset can be defined by usl as a y label and the hml framework that shares it with sl can be established fig 4 shows the conceptual diagram of a hml framework that combines the usl based clustering technique and the sl based classification technique first clustering creates groups i e clusters and provides them as a y label to classification the hml framework generates the y label required for training in the sl technique from unsupervised clustering and the sl technique takes charge of modeling which is difficult in the usl technique by doing so the limitations of the two techniques can be mutually complemented the y label provided from clustering is applied to classification learning along with the x dataset and the applicability of the model is confirmed through a verification process the established model estimates and predicts the y label for a new x dataset 2 3 a framework for hydrological assessment tool this study adopts a hml technique as described in section 2 2 3 and established a hat that can assess the accuracy of simulated streamflow the hml framework is configured through a combination of k means and random forest one of the key points in the applied hml framework is that the x dataset an input is clustered into multiple groups and the group is used as the y label required for classification accordingly the representation of the y label for the clustered x dataset group should be apparent in the hml framework the sl plays a role in establishing a practical model that can estimate the y label for a new x dataset the hat can evaluate rising and recession limbs for an independent hydrograph as well as the total hydrograph the evaluation results are determined by four ratings very good vg good g satisfactory s and unsatisfactory us which are determined by the unsupervised clustering technique the hat can evaluate all streamflow hydrographs estimated or predicted using various methodologies such as deterministic and stochastic approaches since this hml framework has a relatively simple structure it could be applied not only for hydrologic modeling but also more broadly for analysis of other geophysical quantities fig 5 is a schematic diagram of the structure and flow of the hat the hat consists of three modules the first module is for pre processing this module aims to separate an independent hydrograph identify rising and recession limbs and calculate error indices for the independent hydrograph and two limbs the separation process has four steps as follows 1 smoothing the hydrograph to eliminate the noise due to small fluctuation i e hydrological responses in observed hydrograph the smoothed hydrograph is used to determine the beginning and end points at a smoothing three points t 1 t and t 1 arithmetic mean is used 2 eliminating very low flows below threshold value the threshold value is defined as mean observed runoff over entire period 3 the rate of runoff increment is used to identify the rising and recession limbs of a single hydrograph the rate of increment at each time is defined as runoff t 1 runoff t runoff t parts of rising and recession limbs are defined by setting the threshold of the increment rate for each drainage area small 163 km2 medium 1010 km2 large 1010 km2 the threshold is determined by sensitivity analysis for rising limb the threshold values are 0 50 for small area 0 30 for medium area and 0 25 for large area for recession limb the threshold values are 0 50 for small area 0 40 for medium area and 0 20 for large area the beginning point at which the rising limb begins the end point at which the recession limb ends and the peak point at which the largest runoff occurs in the hydrograph in the case of recession limb the n days method is used to determine the point of the end point for complex hydrographs with two or more peak flows the largest runoff value is defined as the peak point of the hydrograph and the rising and recession limbs are defined according to the processes previously described in this study five indices to evaluate the performance of the nwm hydrologic model are used within the error indices shown in table 1 this study used three cc nse pf of them and modified two modified pbias and tp of them to build the clustering module the combination of the five error indices demonstrated better performance in the clustering module than the other combinations for example using nse and rsr together was not as good as using only nse as statistical meanings of the two error indices are similar see table 1 each error index used in this study has a different role in determining clusters pf and the modified tp were used as hydrograph characteristic values and cc nse and mod pbias which quantified the characteristics of a hydrograph from various aspects were applied as error indices the cc shows the trend of a hydrograph and nse shows the variance of simulated errors against observations mod pbias refers to modified pbias and aims to consider errors in runoff volume mod pbias considers the cancellation effect of the runoff volume error which cannot be reflected by the existing pbias and overcomes the limitations of the conventional method which estimates errors only based on the observed runoff volume eq 1 furthermore the modified tp hereinafter referred to as mod tp was used instead of the existing tp so that the peak times that have different error directions but the same scale can be clustered in the same group eq 2 these estimated error indices are used as the x dataset in the clustering and classification modules 1 m o d p b i a s a b s q obs q sim q obs q sim 100 2 m o d t p a b s t obs t sim the second is the clustering module this module determines ratings which indicate the performance level of a hydrologic model based on the error indices described above and provides the y label required for training and testing in the classification module cc nse and mod pbias are applied to rising and recession limbs and the pf and the mod tp hr are used in addition to these three indices in the total hydrograph in the clustering process it is necessary to determine the appropriate k as k i e the number of clusters of k means is an important parameter that affects the reliability of the clustering result this study implements sensitivity analysis using k values from 4 to 30 and compares the observed and simulated hydrographs to verify clustering results in the four ratings the sensitivity analysis consists of two steps to determine an initial k and final k to determine the initial k statistics e g mean and variance of error indices are used to rank in order of superiority in order to confirm the final k r square value between the simulated and observed hydrographs was used as another statistics in this study the initial k is determined to 20 when more than 20 of k is used it was difficult to distinguish clustered groups due to similar statistics of the groups conversely when smaller than 20 of k is used mean value of error indices was not representative of each group as variance of error indices was too wide final k was determined to 4 of the clustered groups referring to vg g s and us the third module is the classification this module is responsible for modeling training and testing the hat the range of the five error indices of clusters from the clustering module has a limitation to represent the relationship between the clusters and the ranges since it indicates only a degree of distance between a centroid of clusters and error indices to overcome this limitation this study employs the third module the classification the classification module aims to model the range of the error indices and to help understanding of the clusters from the clustering module the classification module identifies the algorithm between the clusters and the range of error indices and builds up the knowledge for modeling the range through training in addition the classification module provides weights of the error indices so that it is able to analyze the contribution of the indices to clustering the error indices are used as the x dataset and four ratings determined in the clustering module are used as the y label the hat training is performed using a large amount of streamflow data and the performance of the trained hat can be verified from the x dataset and y label for verification the verified hat can be implemented by using observed and simulated time series streamflow data and the four ratings can be determined for the rising and recession limbs and a total 2 4 national water model the nwm is a fully distributed hydrologic model that aims to enhance flood forecasting capability of the noaa hydrologic prediction system han et al 2019 the nwm simulates the water cycle with mathematical representations of different physical processes and their interactions this complex representation of physical processes such as rainfall rate and spatial distribution snowmelt and infiltration and movement of water through the soil layers varies significantly with the change in terrain soils vegetation types and various other variables cosgrove et al 2018 the nwm is based on the community wrf hydro modeling system which produces various hydrological analysis and prediction products including gridded fields of surface runoff soil moisture snowpack shallow groundwater levels inundated area depths and evapotranspiration as well as estimates of river flow and velocity for approximately 2 7 million river reaches defined by the seamless national hydrography dataset nhd plus v2 0 hydrography dataset the nwm ingests atmospheric forcings e g temperature humidity and precipitation rate into a noah mp land surface model lsm to simulate land surface processes at a 1 km resolution then once exfiltration from the soil column is calculated a diffusive wave overland routing scheme moves water horizontally across the landscape at 250 m catchment aggregation occurs and distributes the water into the channel network at the end of each modeling time step and flow is routed according to a modified muskingum cunge scheme along a modified version of the nhdplus where waterbodies lakes and reservoirs are encountered on the network and store release water according to a level pool routing scheme https water noaa gov about nwm 2 5 data this study is performed in the nine county regions surrounding the san francisco sf bay area california the sf is an area of diverse topography with regions near sea level juxtaposed with mountains rising in excess of 1000 m the sf bay area is a flood prone region owing to orographic rainfall occurring in steep terrain cifelli et al 2018 the orographic rainfall is often produced from moisture plumes over the pacific ocean known as atmospheric rivers ars ralph et al 2012 as an example an ar event starting on december 29 2005 brought more than 20 in of rain across the sf bay region urban areas such as the city of san francisco recorded 24 hour rainfall totals of 5 in on december 31 alone there was major flooding in the napa and russian river basins with 10 counties declaring federal disaster areas over 1000 homes were flooded in napa costing over 300 million in damages the geographic diversity and resulting flooding events in the sf bay area provides a challenging testbed to evaluate the performance of the nwm fig 6 shows the locations of the sf bay area and stream gages that are currently operated by the usgs a total of 91 usgs gages were identified across the nine counties in the sf bay area upon review on the usgs s observed data a subset of 57 usgs gages were selected in this study excluding those that observed low quality streamflow data associated with reservoir operations and diversions the watershed for these 57 gages varies from 11 5 to 3425 3 km2 this study used the nwm to conduct a retrospective streamflow simulation using nldas forcing data cosgrove et al 2003 as inputs the hat is developed and tested using long time period data from october 2013 to february 2017 the performance of hat and nwm for the sf bay area is assessed against the usgs streamflow data 3 results 3 1 clustering of rating labels the ratings of the four clustered groups were categorized into vg g s and us as a part of the statistical method the characteristics of error indices for each rating were examined fig 7 illustrates the probability distribution of error indices for each rating group and each error index the results are for individual rising and recession limbs and total hydrographs according to the overall results the trend of the probability distribution depending on rating group was obvious that all of average error index from vg to us moves toward the direction of negative meaning i e negative infinity for nse and variance increases gradually it was also found that the percentage of a higher rating level was higher as the fraction of each rating approached the ideal error index i e 1 0 for cc and nse whereas the percentage of a lower rating level was higher as it was further away these results were observed in all error indices and in rising and recession limbs and total hydrographs in addition table 2 lists statistics of error indices depending on the performance rating for the total hydrograph case from the table it confirms the range features of error indices by the clustered rating level it is found that the ranges minimum to maximum of the error indices were overlapped since the rating groups have clustered with a composite of the error indices for example a range of cc in very good rating level is from 0 74 to 1 00 and in good rating level is from 0 44 to 0 98 this result suggests that the clustered rating levels are very reasonable as there is no absolute range for performance rating however a range from q1 to q3 of the error indices was barely overlapped in the ratings the characteristics of mean and variance statistics in the table were very obvious by each rating level and it supports the results in fig 7 it was confirmed that error indices for each rating were reasonably clustered subsequently an assessment of the quality of simulated hydrologic model results for each rating was conducted fig 8 shows scatter density plots between usgs observations and simulated nwm values for each rating to remove the variability of different streamflow scales by various watershed areas and rainfall events the observed and simulated streamflow were normalized by a peak flow so that it did not exceed 1 0 the results showed that the distribution trend of the scatter plot of each rating was distinct and the observed trend was consistent each rating s meaning according to the results for the total hydrograph vg s coefficient of determination was 0 86 and was the highest and the data points tended to cluster around the x y line g showed a similar distribution trend to that of vg but its density for the x y line was relatively lower and more scattered g s coefficient of determination was 0 66 s showed a more scattered distribution trend than g and its coefficient of determination was 0 49 for us most of the data points were located around the x or y axis indicating simulated values were largely underestimated or overestimated compared with observed ones as a result us s coefficient of determination was 0 01 which was the lowest the scatter plot trend for each rating was observed to be identical in the results of rising and recession limbs in addition fig 9 shows samples of the comparison results between the observed and simulated hydrographs in the four ratings clustered groups runoff y axis and duration time x axis are normalized using a maximum value the results present a degree of quality of hydrograph in accordance with each rating the clustering module determined the ratings that were reliable both statistically and graphically the determined ratings were then used as the y label in the classification module and served as a link between two machine learning techniques 3 2 classification and verification the classification module was built based on the supervised random forest technique and aims to detect the hidden pattern between error indices x dataset and ratings y label since the random forest technique includes the sl process for modeling the evaluation tool the classification module in which all processes were completed became the hat that can perform a hydrological assessment on new x datasets the trained classification module evaluates the performance of the model through a verification process table 3 lists the verification results for the trained classification module here 80 of the training data was used for training whereas 20 was used for verification the verification was performed by comparing the ratings previously determined by the clustering module and the ratings determined through the hat according to the results the concordance rates of the hat ratings were 98 rising 99 recession and 97 total which confirms that the hat could perform an accurate hydrograph assessment the concordance rate for each rating was also observed to be similar to the above table 4 lists a weight of error indices determined in the classification module in overall mod pbias is the most important error index to assign the ratings and cc and nse are the next higher in order in the case of total hydrograph the weights of tp and pb are similar to nse it is speculated that the accuracy of baseflow played a role in determining the weight as the evaluation subject of the hat is total runoff flow consisting of baseflow and direct runoff flow not only for direct runoff flow that could describe the main reason of why mod pbias is considered as the most important weight 3 3 test to evaluate the nwm the hat tested the performance of the nwm for the sf bay area through adopting a concept of leave one out cross looc validation method efron 1983 which is widely used in machine learning technique the looc validation method leaves one set of total available data sets as a test set trains the hat using the remaining data sets except the one set and tests the nwm performance using the one set and repeat this process as many times as needed in this study the entire simulation period october 2013 february 2017 is equally divided into 10 sub periods as the data sets by sequence of date and the looc validation method is applied to each sub period the entire simulated results by the looc validation method are analyzed at various points of view table 5 shows the validation result of the looc validation method using a fraction of incorrect ratings a range of the fractions is from 1 9 to 4 4 on average which confirms that the hat is properly built and performs an accurate hydrograph assessment however overrated and underrated results did not show significant proportional differences the results by drainage size are presented in fig 10 overall the performance of the nwm for the sf bay area was rated vg or g by the hat for at least 46 of the simulated hydrographs regardless the limbs and total hydrograph the occurrence of vg and g increased with drainage area for the total hydrograph results the ratings of small areas vg and g accounted for 42 or more medium areas 50 or more and large areas 58 or more similar trends were identical across the limbs of the hydrograph in this study training of the hat was implemented for each hydrograph limb thus the distribution of the four labels could be different depending on the hydrograph limbs i e rising and recession for example a fraction of us in the rising limb is 5 on average while a fraction of us in the recession limb is 28 which is 5 times higher fig 11 shows a map representing the average ratings of total hydrograph at usgs gages and the fraction of ratings for each county from us to vg the model performance score ranges from 0 0 to 3 0 and the arithmetically averaged score is indicated on the map according to the results by county marin county scored 0 62 points on average and showed the lowest nwm performance among six other counties except three counties whose the observed data properly usable is not found vg and g accounted for less than 18 5 following marin county napa county showed the second lowest performance at 1 11 points the best performance was shown in santa clara county which scored 1 79 points on average these vg and g ratings of the county accounted for 66 7 or more in addition the overall results demonstrated that the nwm performance for the southern sf bay area san mateo santa clara and alameda was better than that for the northern sf bay area marin sonoma and napa since the accuracy of simulated streamflows varies with various characteristics of rainfall and watershed it is necessary to examine how the decision of performance ratings is affected by them fig 12 shows the contribution of four impact factors complexity of hydrograph with the numbers of peak runoff duration drainage size and whether regulated or not to performance ratings in the case of complexity of hydrograph the ratings were assigned equally regardless of the numbers of peak multiple peaks case has a large fraction of vg and it confirms that the performance of the nwm for complex storm events is reliable and comparable to simulation performance for single storm events in the case of runoff duration g s and us did not show significant proportional differences by a duration length for vg the long duration has the largest fraction in the case of drainage size the higher ratings were assigned to a large drainage area a fraction of a large drainage area was higher at the three ratings except the us and the small area tended to be the opposite trend of the large drainage area there are several reasons for that the hat assigns the performance ratings for total runoff flows consisting of baseflows and direct flows and a large drainage area is affected by the accuracy of baseflow different from small drainage areas commonly located in the upper river basin also mod pbias among the error indices is highly influenced to determine the performance rating in the case of whether regulated or not g s and us did not show significant proportional differences and a fraction of unregulated was higher at vg 4 discussion one of the most notable hydrological evaluation framework studies was conducted by moriasi et al 2007 who suggested general hydrological assessment guidelines their study determined classification criteria for an error index through the basic framework of decision trees and tested the performance of a hydrologic model based on the determined classification criteria however their evaluation method can only be used for single indices and it is difficult to draw a comprehensive conclusion from various indices fig 13 compares the results of the hat and moriasi et al 2007 nse pbias and rsr error indices were used for the results of moriasi et al 2007 the results using the moriasi et al 2007 methodology are difficult to interpret in terms of an overall performance rating result graphically the scatter plot distributions of the top three ratings vg g and s are so similar that it was difficult to distinguish them the us rating showed no trend in the scatter plot distribution these results could be reaffirmed by the coefficient of determination in particular there were few differences in the coefficient of determination between vg g and s and hence it was difficult to determine which rating shows high accuracy when pbias was applied the coefficient of determination of the three ratings ranged from 0 75 to 0 77 and the coefficient of determination for the g rating was estimated to be higher than that of the vg rating in nse and rsr the coefficient of determination for the three ratings ranged from 0 85 to 0 92 and from 0 84 to 0 92 respectively which was similar to that in pbias while the coefficient of determination of the us rating was estimated to be much lower than those of the top three ratings it was difficult to conclude that us was assessed well given that there was no trend in the scatter plot distribution the advantage of the hat is that by objectively combining the indices into an objective algorithm an overall assessment of the model performance is easier to obtain in addition table 6 shows the comparison results of ranges of error indices derived from the hat and moriasi et al 2007 it confirms that the absolute ranges of error indices used in the general evaluation may not reasonable to evaluate simulation results the hat showed a high accuracy of over 98 in the verification results to further improve the performance of the hat we believe that a model that uses more training data than those used in this study should be established for 2 the ratings were underestimated compared with the actual ratings in all cases these results may be obtained owing to the use of the random forest apart from whether the amount of data is simply large or small the random forest is a machine learning technique that supplements flexibility which decision trees do not have and determines classification criteria between the given x dataset and y label from various decision trees this technique however cannot implement perfect classification criteria without infinite training data owing to the fundamental problem of decision trees discontinuous classification criteria even if the optimized classification criteria are determined based on multiple decision trees nevertheless 98 accuracy achieved by the hat can be considered acceptable and we believe that the ratings for the hydrologic model determined via the hat established based on such a performance are reliable understanding uncertainties in the procedures needs for meaningful quantification of the results in case of this study uncertainties may arise from two parts the hydrograph separation and the four ratings assignment the hydrograph separation is the important process as it determines an independent hydrograph as well as two limbs i e rising and recession which is the source for evaluation criteria of the hydrologic model performance thus the results could be slightly varied with the separation methods especially in determining the end point of a hydrograph however it is speculated that the uncertainties from the hydrograph separation are not big enough to change the results as the error indices were barely changed depending on the lengths of a hydrograph on the other hands since the rating assignment is a key to evaluate a hydrograph whether it is good or not the parameter k in the cluster module is very important in this study k is determined by the sensitivity analysis method so that the result may include a subjective point of view 5 summary and conclusions this study describes the hat based on the hml technique the hml technique was established by a combination of clustering and classification techniques and ratings were reasonably determined from a composite of various error indices the hat was applied to retrospective simulations of the nwm in the sf bay area conclusions from this study include 1 a novel assessment tool hat has been developed four ratings determined by the hat accompanied apparent statistical and graphical characteristics and could accurately diagnose outputs for each rating accordingly it could define the status of the model for each rating objectively and the hat is expected to be applied to determine the necessity strategy and extent of calibration 2 through the training and verification processes we confirmed the reliability of the hat and showed that hat could assess a single hydrograph from three aspects the rising and recession limbs and total hydrograph moreover easy to understand terms were used to define ratings and help understand the assessment results 3 the hat assessed the performance of the nwm for the sf bay area using a limited training and verification data set the nwm was shown to perform g vg for at least 46 of the hydrographs examined during from october 2013 to february 2017 regardless of the watershed size the new evaluation framework is extensively applicable the hat is able to rate for additional performance levels e g super very good and super unsatisfactory by adding new groups as it is very flexible if sub hourly evaluation is needed like a flash flood the hat could implement that through training the hat based on sub hourly time step data also the hat can be applied to not only a flood forecasting model but also any geophysical data that are driven by physically pulsed phenomena for instance it can be applied to the indices that represent precipitation soil moisture content ground water pollution load and natural disasters acknowledgments this work was supported by the california department of water resources and the noaa physical sciences division and this research was supported by basic science research program through the national research foundation of korea declaration of competing interest none 
6189,improved spatial and temporal resolutions in quantification enable the water footprint wf in crop production to be a comprehensive indicator of water consumption in agricultural water management in general existing literature focus on the impact of water saving irrigation techniques on crop yield and water consumption during the growth period at sites or experimental units few studies yet that explicitly addresses the effect of developments in water saving irrigation techniques on large scale wf accounting and benchmarking here we fill this gap through a case study for wheat in china over 2000 2014 during which the micro irrigated wheat area expanded 14 times the green and blue wfs of china s wheat per year are estimated at a 5 arc minute resolution for irrigated wheat we distinguish three irrigation techniques furrow sprinkler and micro irrigation the wf benchmarks by irrigation type are further estimated separately for arid and humid zones irrigation accounted for 70 of annual wf in china s wheat land while furrow irrigation dominated the national total wf the occupation by wf under micro irrigation was the smallest but jumped by 14 times in quantity whereas that under sprinkler halved china s average wf per ton of wheat under sprinkler irrigation was 21 higher than that under micro irrigation in 2014 the 20th percentile wf benchmarks of wheat under micro irrigation was 13 and 31 smaller than that under furrow and sprinkler irrigation respectively in arid zones meanwhile high provincial heterogeneities in terms of wf under varied distribution of irrigation techniques were also shown the study shows possibility and importance to account for developments of water saving techniques in large scale crop wf estimations keywords irrigation techniques water footprint accounting water footprint benchmark spatial temporal variations 1 introduction water resource scarcity in crop production is one of the main drivers of the existing food crisis kang et al 2017 increasing food demand with population growth and diet structure changes continue to put pressure on the limited freshwater resources mekonnen and hoekstra 2016 veldkamp et al 2017 wada et al 2016 the water footprint wf hoekstra 2003 in crop production measures the amount of water consumption and pollution generated during the crop growth period within a geographical area for a certain time the wf of growing a crop consists of blue wf surface and groundwater consumption green wf rainwater consumption and gray wf freshwater required to assimilate water pollution hoekstra et al 2011 green and blue wfs are the consumptive wfs whereas gray wf is the degradative wf compared to traditional indicators of crop water consumption e g evapotranspiration the wf reflects not only how much the water consumed but also where the water came from i e blue or green water existing studies have been able to estimate regional wfs in crop production in high spatial and temporal resolutions using soil plant atmosphere management system models liu 2009 liu et al 2007a liu and yang 2010 hydrological models fader et al 2010 hanasaki et al 2008 rost et al 2008 or crop water productivity models chukalla et al 2015 siebert and döll 2010 ye et al 2018 zhuo and hoekstra 2017 zhuo et al 2016c d the role of remote sensing in assessing wf were also discussed romaguera et al 2010 relying on explicit data the spatial temporal evolution of regional crop wf can be demonstrated and feasible policies on sustainable local water use can be enacted various irrigation methods affect evapotranspiration at crop filed by acting on the fraction of soil surface wetted to improve irrigation performance on different crops a number of studies have been conducted to analyze the effects on irrigation water requirements crop yield and irrigation water productivity see table 1 additionally the method humicro 2000 peyremorte and tron 1995 using a microcomputer and electronic tensiometers to schedule drip irrigation or micro sprinkler systems can effectively reduce water consumption by 50 in several experiments chukalla et al 2015 indicated that sprinkler irrigation has a larger consumptive wf and the average reduction of the consumptive wf is 8 10 when changing from furrow irrigation to micro irrigation as determined by evaluating the response of the wf for crops such as wheat maize and potato in europe to different irrigation practices hoekstra 2013 2014 proposed the idea of wf benchmarks to motivate governments businesses and farmers to set wf reduction targets especially water intensive products to reasonable levels mekonnen and hoekstra 2014 established a set of global wf benchmark values for both the green blue wfs and gray wf for major crops using the global crop wf assessment for 1996 2005 at a spatial resolution of 5 5 arc minute zhuo et al 2016a systematically analyzed how different climate and soil conditions influence the consumptive wf benchmarking of winter wheat in china and confirmed that wf benchmarks are more sensitive to climate types humid vs arid above researches tended to focus on the positive impact of water saving irrigation techniques on crop yields and water consumption during the growth period at sites or fields experimental units few studies highlighted the influence of the development and popularization of water saving irrigation techniques on the spatial and temporal evolution in crop wfs in large scales obviously the difference between irrigation techniques in terms of consumptive wf intensity and temporal spatial distribution patterns cannot be neglected however the effects of applications and developments of water saving techniques across crop fields has not been considered in regional wf accounting yet previous studies assumed irrigation volume as meeting the water demand based on precipitation levels during crop growth and did not distinguish the actual variations in irrigation techniques in large spatial scales especially in developing countries the large scale application of water saving irrigation is booming for instance the micro irrigated cropping area in china has increased fourteen times since 2000 nbsc 2018 the objective of this study is to explicitly address the effect of the popularization of water saving irrigation techniques on large scale wf accounting through the case for wheat in china over 2000 2014 the green and blue wfs of both rain fed and irrigated wheat are estimated using the aquacrop model hsiao et al 2009 raes et al 2009 steduto et al 2009 at a 5 5 arc minute resolution 8 9 km 9 2 km at the latitude of china for each year for irrigated wheat we distinguish three irrigation technologies furrow sprinkler and micro irrigation the wf benchmark levels for each irrigation technology are further estimated for arid and humid zones respectively as one of the three major grain crops in china wheat accounts for a sow area of 24 million ha and annual production of 129 million ton in 2016 fig 1 contributing approximately 15 of the world total wheat production nbsc 2018 fao 2016 many scholars have studied the wf in china s wheat production table 2 highly spatial heterogeneities and temporal variations in wfs of wheat have been widely recognized in the available literatures however still without consideration of water saving instruments effects 2 material and methods 2 1 calculating green and blue water footprints in crop production the green and blue wfs m3 t 1 equal to the green and blue evapotranspiration in m3 ha 1 over the crop growing period divided by the actual crop yield in t ha 1 respectively hoekstra et al 2011 1 w f b f t 1 g p e t b t y 2 w f g f t 1 g p e t g t y in which w f b f w f g f is the blue and green wfs m3 t 1 of crops in each grid cell respectively g p day the growing period e t b t and e t g t mm the blue and green evapotranspiration on day t y t ha 1 the yield 2 1 1 dividing green and blue crop water use cwu the dynamic daily soil water balance in each grid cell in the model is estimated by keeping track of the incoming and outgoing water fluxes at the boundaries of the root zone mekonnen and hoekstra 2010 3 s t s t 1 p r t i r r t c r t e t t r o t d p t in which s t mm is the soil water content at the end of day t p r t mm the precipitation on day t i r r t mm the net irrigation depth on day t c r t mm the capillary rise of the soil horizon from groundwater which is assumed to be zero because the ground water depth is considered to be much larger than 1 m allen et al 1998 e t t mm the actual crop evapotranspiration is separated into soil evaporation e and crop transpiration tr avoids the confounding effect between non productive soil evaporation and productive crop transpiration consumptive use of water fluxes 4 e k r k e e t 0 5 t r k s k s t r k c t r e t 0 where k r is the evaporation reduction coefficient which becomes smaller than 1 the soil evaporation coefficient k e is proportional to the fraction of the soil surface not covered by canopy k s is the soil water stress coefficient which becomes smaller than 1 and k s t r is the cold stress coefficient which becomes smaller than 1 when there are not enough growing degrees in the day the crop transpiration coefficient k c t r is proportional with the green canopy cover thus aquacrop can estimate these two different types of water consumption patterns respectively r o t mm the amount of water lost by surface runoff is based on the curve number method developed by the us soil conservation service usda 1964 rallison 1980 steenhuis et al 1995 6 r o t p r t i a 2 p r t s i a where s mm refers to potential maximum soil water retention which is a function of the soil curve number i a mm the initial abstraction or the amount of water that can infiltrate before runoff occurs and d p t mm the deep percolation is defined by the drainage ability m3 m 3 day 1 from which can get the drainage ability for a particular soil water content between saturation and field capacity the drainage ability is zero when the soil water content is lower than or equal to field capacity the initial soil water content under rain fed is assumed to be equal to field capacity in contrast to statistics under irrigation following chukalla et al 2015 and zhuo et al 2016d the daily green and blue et mm were separated by tracking the daily incoming and outgoing green and blue water fluxes at the boundaries of the root zone 7 s g t s g t 1 p r t i r r t r o t p r t p r t i r r t d p t e t t s g t 1 s t 1 8 s b t s b t 1 p r t i r r t r o t i r r t p r t i r r t d p t e t t s b t 1 s t 1 in which s g t and s b t is the green and blue soil water content on day t respectively the initial soil water moisture at the start of the growing period is assumed to be green water 2 1 2 simulating the crop yield y in aquacrop the aboveground biomass b kg is derived by considering the normalized biomass water productivity w p kg m 2 the daily aboveground biomass production of the crop cycle was obtained by multiplying the wp with the ratio of crop transpiration t r to the reference evapotranspiration eto 9 b w p t r t e t 0 t the normalized w p was adjusted to consider the average atmospheric carbon dioxide co2 concentration the atmospheric evaporative demand e t 0 the crop classes c3 or c4 crops and limited soil fertility therefore the water productivity remains constant for a given crop species after normalization which explains the nature of the water driven crop water productivity model aquacrop the harvestable portion of the biomass the crop yield y t ha 1 was obtained by multiplying the aboveground biomass b with the adjusted reference harvest index h i 0 10 y f h i h i 0 b where f h i is a coefficient which takes the water deficits and temperature stresses depending on the timing and extent during the crop cycle into account that correct the harvest index from its reference value h i 0 the reference harvest index the simulated y per crop per year for each grid cell was calibrated by scaling the model outputs at provincial level to fit crop yield statistics nbsc 2018 2 1 3 considering different irrigation techniques we consider three irrigation techniques furrow 80 soil surface wetted sprinkler 100 soil surface wetted and micro irrigation 40 soil surface wetted due to the differences in the parts of the soil surface is wetted the soil evaporation varies under different irrigation types in this case the simulated value of b y e t and w p can be adjusted about the performance of the irrigation schedule for each grid cell the wfs of irrigated crop production is then weighted averaged over wfs under each type of irrigation technique and corresponding irrigated area with each irrigation technique 11 w f b f i 1 3 10 t 1 g p e t b i t w i i 1 3 y i w i 12 w f g f i 1 3 10 t 1 g p e t g i t w i i 1 3 y i w i in which w f b f w f g f is the blue and green wfs m3 kg 1 of irrigated crops in each grid cell respectively i represents the type of irrigation techniques e t b i t and e t g i t mm the blue and green evapotranspiration under the condition of i on day t g p day the growing period y i kg ha 1 the yield under the condition of i w i the irrigated area of i divided by the total area for each grid 2 2 benchmarking water footprints in wheat production the wf benchmark of wheat production is estimated following the mekonnen and hoekstra 2014 by ranking the calculated wf values in grid from the smallest to the largest against the corresponding cumulative percentage of total crop production in this study we set wf benchmarks through distinguishing different irrigation techniques and climate zones fig 2 the climate zones are classified based on unep s aridity index ai middleton and thomas 1992 1997 an indicator of dryness defined as the ratio of precipitation to reference evapotranspiration in this study we divided the geographic spread of climate zones in china into two broad zones by using the data on annual precipitation and et0 averaged during the period 2000 2014 at 30 by 30 arc min resolution harris et al 2014 zhuo et al 2016a the arid to semi arid arid zone ai 0 5 and the humid to semi humid humid zone ai 0 5 2 3 data data on monthly precipitation pr minimum tn maximum tx air temperature and reference evapotranspiration et0 were obtained from the cru ts 3 24 dataset ceda 2018 harris et al 2014 which was from monthly observations of over 4000 individual meteorological station records across the world s land areas and calculated on high resolution 0 5 0 5 degree grids the mean annual atmospheric carbon dioxide concentration was measured at mauna loa observatory in hawaii noaa 2018 in addition to the selected harvest index hi and maximum root depth zx allen et al 1998 the remaining values of parameter were obtained from raes et al 2017 soil texture data were taken from the isric soil and terrain database for china dijkshoorn et al 2008 soil water capacity data in vol on 5 by 5 arc min were obtained from isric wise batjes 2012 the irrigated and rain fed areas for wheat at a 5 by 5 arc min resolution from mirca2000 portmann et al 2010 were divided into areas with different irrigation techniques according to the proportion of different water saving irrigation techniques from statistical yearbook nbsc 2018 while the crop areas from mirca2000 and yields simulated by aquacrop were scaled to fit corresponding yearly statistics at provincial level nbsc 2018 3 results 3 1 water footprint of wheat production in m3 yr 1 during the study period of 2000 2014 the average annual total consumptive wf of wheat production in china was 132 gm3 yr 1 58 green 42 blue fig 3 shows the composition and annual decreasing trends in the total wf of wheat production over the study period the total harvested area and the irrigated area of wheat in china decreased by 10 and 9 respectively which caused a 4 4 decline in the total wf specifically the blue wf in 2014 53 gm3 yr 1 decreased by 5 7 compared with that in 2000 56 gm3 yr 1 and the green wf in 2014 74 gm3 yr 1 was 3 5 lower than that in 2000 76 gm3 yr 1 the annual average wf of irrigated wheat 86 gm3 yr 1 accounts for 70 of the total wf the contribution of the wf under different irrigation techniques towards the total wf changed from year to year due to the changes in corresponding harvested area as illustrated in fig 3 the largest wf was computed in furrow irrigation 81 gm3 yr 1 which also dominated the national wf volume fig 3 it must be pointed out that the proportion of the wf from micro irrigation is the smallest whereas the rise of its contribution is the largest the wf in micro irrigation increased substantially by 12 times from 0 4 to 4 8 gm3 yr 1 over 2000 2014 as the cultivated area of wheat with micro irrigation in china in 2014 had expanded 14 times relative to 68 kha in 2000 the wf of wheat under sprinkler irrigation 2 8 gm3 yr 1 in 2014 is approximately one half that under micro irrigation because the wheat area under sprinkler irrigation decreased by nearly 40 reaching 485 kha in 2014 during the study period fig 4 illustrates the proportions of the blue and green wf of wheat under different irrigation techniques relative to the total wf over 2000 2014 concerning the blue wf proportion with furrow and sprinkler irrigation in the total wf has been declining from 94 and 5 in 2000 to 90 and 3 respectively as a result of the sharp decrease in cultivated area at the same time with the continuous expansion of the cultivated area with micro irrigation the blue wf of wheat for micro irrigation has undergone a 17 fold increase compared to the value at the beginning of the research 0 2 gm3 yr 1 in 2000 the largest annual value on the percentage of the total green wf was for rain fed wheat 52 followed by furrow irrigation 45 while the sprinkler 2 and micro 1 irrigation were at a lower level over the study period there are provincial heterogeneities in terms of the annual developments in the total wf of wheat fig 5 a the harvested area and wf of wheat of most provinces decreased by more than 30 the exceptions were mainly in the henan shandong hubei anhui jiangsu and xinjiang provinces where the harvested area and wf of wheat increased during the study period the spatial distribution of the wf of wheat is similar to the spatial distribution of the wheat harvested area fig 5b the wf values of wheat determined by distinguishing irrigation techniques are obviously different at the provincial level table 3 in 2014 approximately 67 of the wheat planting area and 70 of the wf was clustered in the following five provinces henan 28 gm3 yr 1 shandong 21 gm3 yr 1 hebei 14 gm3 yr 1 anhui 13 gm3 yr 1 and jiangsu 11 gm3 yr 1 in addition the actual proportion of wheat planting area under various irrigation techniques has a profound impact on the value of the wf for example in 2014 the shares of wheat planting area under furrow sprinkler and micro irrigation relative to the total irrigated area in gansu were 48 47 and 5 respectively in contrast to 92 5 and 3 in shanxi however gansu 812 kha of irrigated area and 1 3 gm3 yr 1 of blue wf with more irrigated land and a drier climate has a blue wf much smaller than that of shanxi 565 kha of irrigated area and 2 3 gm3 yr 1 of blue wf 3 2 the water footprint per ton of wheat in m3 t 1 as can be seen in fig 6 the national average wf per ton of wheat decreased by 25 from 1330 m3 t 1 in 2000 to 1003 m3 t 1 in 2014 with the blue wf and green wf falling by 26 and 24 respectively this significant change was caused by the steady increase of wheat yield the yield increased by more than 40 from 3 7 t ha 1 in 2000 to 5 2 t ha 1 in 2014 fig 7 shows the distribution of the wf per ton of wheat in 2014 and its relative change from 2000 to 2014 the per unit product wf of wheat in northern china was mostly below 1200 m3 t 1 in 2014 but the relatively low yield in southern china 42 lower than the north resulted in the per unit product wf of wheat being generally higher than 2000 m3 t 1 the results shown in table 4 display great variation across provinces only less than one third of the provinces have a lower per unit product wf of wheat than the national average such as those of henan 854 m3 t 1 anhui 930 m3 t 1 shandong 948 m3 t 1 jiangsu 953 m3 t 1 and hebei 999 m3 t 1 these provinces are mainly located in the middle and eastern part of china where the wheat production accounted for 76 of the national total however except for anhui and jiangsu where the blue wf accounts for 16 the average blue wf of henan shandong and hebei account for nearly 54 of the total green blue wf the provinces with the highest wf are guangxi yunnan and jiangxi with an average wf more than 2500 m3 t 1 fig 7b this result can be explained by the rainfed dominated cultivation the rainfed land in these regions accounts for 65 of the total planting area while the national average is 36 and the mountainous geographical environment resulting in a yield 2 2 t ha 1 of just 40 of the national average in 2014 among the spatial variation in the relative change of the total wf of wheat the wf in most regions 16 provinces decreased by 20 conversely the wf in guangxi and yunnan increased by 5 and 35 respectively the wf per ton of wheat under furrow sprinkler and micro irrigation showed a downward trend in the past 15 years with a significant difference comparatively in 2014 the wf under sprinkler irrigation 1149 m3 t 1 was the highest which was 21 higher than the lowest wf of micro irrigation 948 m3 t 1 and the wf under furrow was 997 m3 t 1 moreover 30 provinces were estimated as samples to further analyze the impact of the development and evolution of different irrigation techniques on the wf calculation we found that the provincial per unit product wf was reduced upon move from furrow to micro irrigation considering xinjiang as an example the planting areas with furrow irrigation decreased by 56 whereas micro irrigated area increased by 60 during which the per unit product wf fell by 20 845 m3 t 1 far lower than the national average we further look at the sensitivity of evaporation and transpiration during the wheat growth period to different irrigation techniques fig 8 the calculated et of rain fed wheat was confirmed to be the smallest it is worth nothing that the productive t or unproductive e maintained fixed proportions 82 vs 18 of the total cwu in both rain fed and irrigated conditions an interesting result from this study is that sprinkler irrigation a traditional water saving irrigation technique had a larger et 544 mm than furrow 532 mm and micro irrigation 511 mm which agrees well with the views of chukalla et al 2015 on major crops in israel spain italy and the united kingdom the so called water saving irrigation technique reduces water withdrawal and improves water efficiency but based on the consumption during the crop growth period sprinkler irrigation is not a superior the same result is obtained in the analysis of non productive blue water e blue i e the maximum amount of blue water used for ineffective evaporation is found with sprinkler irrigation followed by furrow and micro irrigation because there is a significant difference in the soil surface moisture under different irrigation techniques fig 9 illustrates the main evaluation index for quantifying the wf under different irrigation techniques during the study period a relatively higher water consumption and low yield level fig 9a explain why the highest wf occurs with sprinkler irrigation fig 9b from the perspective of the green wf the lowest value is obtained by micro irrigation because micro irrigation is mainly used in areas where fresh water and even rainwater resources are scarce for blue water with a higher opportunity cost fig 9c the change from furrow to sprinkler irrigation reduces the yield by 8 1 and the blue et increases by 3 5 while the yield slightly reduces by 2 8 but the blue et obviously reduces by 4 7 upon changing from furrow to micro irrigation all these results indicate that the blue water conversion rate of production which is defined as the amount of food produced per unit of blue water that varies with the irrigation techniques applied fig 9d micro 1 77 kg m 1 and furrow 1 68 kg m 1 irrigation are 19 and 13 higher respectively than sprinkler irrigation 1 49 kg m 1 3 3 water footprint benchmarks of wheat by irrigation techniques we further explored how different irrigation techniques influence the benchmark levels for the wf per ton of wheat in china for different climate zones we found that the benchmark levels for wheat fluctuated within a range of 16 in long term serial averages over 2000 2014 table 5 considering irrigated and rain fed croplands together i e not distinguishing the various irrigation techniques the wf benchmarks per ton of wheat for the arid zone were 17 for the 10th production percentile to 9 for the 20th production percentile smaller than those for the humid zone the wf benchmarks of wheat in this study are contrary to those of zhuo et al 2016a for arid and humid regions i e the wf benchmarks for the arid zone are smaller than for the humid zone and could be explained by in that zhuo et al 2016a considered the wf of winter wheat from 1996 to 2008 while both winter and spring wheat are considered in this study from 2000 to 2014 the calculated wf of spring wheat distributed mostly in the humid area was confirmed to be higher than that of winter wheat which inclined the low wf towards the arid zone it can be seen from fig 7 that the per unit product wf in arid regions is distinctly lower than that in humid regions in addition the agricultural technological level at the different study periods selected also had an impact on the wf quantification by comparing the per unit product wf benchmarks in same climate region the values for different irrigation techniques differ greatly in arid regions the wf benchmarks under micro irrigation are 23 for the 10th production percentile to 31 for the 20th production percentile smaller than that under sprinkler irrigation while 7 and 13 smaller compared to furrow irrigation however we did not find a typical change of wf benchmarks in humid regions under different irrigation techniques the sample difference rate did not exceed 3 from the best 10 952 16 m3 t 1 to the best 20 993 18 m3 t 1 of wheat production including the national average 1182 38 m3 t 1 by comparing per unit product wf benchmarks for same irrigation technique the values for different climate regions vary by irrigation technique the wf benchmarks for the arid zones are 15 for the 10th production percentile to 4 for the 20th production percentile smaller than those for humid zones under furrow irrigation in contrast to 22 and 20 respectively under furrow irrigation nevertheless the wf benchmark for arid zones is 16 larger for the 20th production percentile than for humid zones under sprinkler irrigation which is due to the relatively higher wf of spring wheat with 60 of the spring wheat cultivated areas under sprinkler irrigation concentrated in arid zones as a whole benchmarks for the consumptive wf of wheat at different production percentiles show obvious distinctions within the same climate region with different irrigation techniques or in different climate regions with the same irrigation techniques therefore setting the benchmark for wf per ton of wheat by considering different irrigation techniques in different climate zones is of great practical and guiding significance for agricultural water saving 4 discussion considering different irrigation techniques the current study estimates and assesses at a high spatial resolution the temporal spatial variation in the consumptive wf of china s wheat production results show that the per unit water consumption and per unit product wf is largest under sprinkler irrigation followed by furrow and micro irrigation which is consistent with the results of chukalla et al 2015 water saving irrigation in the traditional sense essentially increases the efficiency of water use in the field and reduces the loss of water delivery for example sprinkler irrigation can effectively reduce the water demand by 46 compared with furrow irrigation xue and ren 2016 however from the perspective of the wf of crop production sprinkler irrigation is not dominant on the one hand though furrow irrigation is less efficient with higher percolation and runoff fluxes compared to sprinkler irrigation these fluxes return to the catchment and are not lost from the system and therefore are not considered to contribute to the actual water consumption hoekstra et al 2011 grafton et al 2018 on the other hand sprinkler irrigation results in a larger et due to the large surface wetting rate for an equal yield micro irrigation has been shown to be most effective for wf reduction in this study it has become a trend to grow wheat by micro irrigation on a large scale in china for which the arid and semiarid northwest regions such as xinjiang ningxia gansu and inner mongolia account for 83 of this micro irrigated crop the social and ecological benefits of growing wheat by micro irrigation will be more prominent if the problems of micro irrigation system design high equipment cost and wheat physiological mechanisms can be effectively solved in future practices a 10 of decrease is observed in the wheat harvest area whereas the yield shows an increasing trend fig 6 statistics show that china s grain output has achieved a 12 year increase in the past 15 years including wheat although the harvested area of wheat has fallen by 10 the gradual expansion of effective irrigated areas grew by 20 from 2000 has not only stabilized but also boosted wheat production it can be seen from fig 9 that the difference in yield per unit area of wheat under irrigation and rain fed conditions is much greater than that between different irrigation methods therefore the increase of effective irrigated area is the main reason to promote the increase of wheat production in addition the blue wf in m3 yr 1 fig 3 experienced little downward trend for 15 years was not obvious and even had a significant rebound in 2010 which was mainly caused by extreme climate factors the severe drought from the winter of 2009 to the spring of 2010 increased the irrigation water consumption during the winter wheat growing period which resulted in a sharp increase in the blue wf of wheat production during the year the estimated wf values in m3 t 1 were compared with those of previous studies as shown in table 6 the calculated total wf for the current study averaged for the period of 2000 2005 is relatively low in comparison with the values presented by mekonnen and hoekstra 2010 specifically the green wf of this study was 14 lower under rain fed conditions while the green and blue wf were 21 and 18 lower respectively under this irrigation mode compared to the estimations by mekonnen and hoekstra 2010 the temporal spatial scales selected and the modeling standards applied between wf studies may improve the level of uncertainties there are two reasons explaining this difference in results first the crop yield calibrated at the provincial level for the current study was more accurate than that of mekonnen and hoekstra 2010 at the national level second the modeling standard dividing the planting modes into rain fed conditions and furrow micro and sprinkler irrigation of this study was closer to reality instead of the one irrigation type furrow irrigation assumed by mekonnen and hoekstra 2010 in addition our estimated total wf was 4 higher than the assessment by liu et al 2007b for the year 2000 which simply considered winter wheat it is important to note that both spring and winter wheat were taken into account in this study and the results showed that the per unit product wf of spring wheat at the provincial scale was higher than the national average the wf in m3 t 1 and m3 yr 1 of this study were 1047 m3 t 1 and agree well with that of sun et al 2013 for the year 2009 comparing the quantified wf in m3 t 1 with the values presented by zhuo et al 2016c for the year 2008 indicates that the wf in total terms is well matched by 3 lower while the green wf 13 lower and blue wf 34 higher present obvious differences even though we used the same crop model and climate input data it thus indicates the significant effects of developments in irrigation techniques as considered in the current study the wf values in m3 yr 1were compared with those of sun et al 2013 for the year 2009 and cao et al 2014 for the year 2010 at the national scale the difference between the studies is approximately 10 due to the difference between the model used and the data input at the provincial scale the estimated green blue wfs in total terms compares to the result of cao et al 2014 the correlation is reasonably good and the order of magnitude is similar in these two studies with an r2 value of 0 96 however their total blue wf 40 gm3 yr 1 estimate is 36 lower than our estimate 63 gm3 yr 1 while their green wf 72 gm3 yr 1 is 11 higher than the current estimate 64 gm3 yr 1 this result can be explained from the perspective of the research scale either from the typical irrigation districts cao et al 2014 or from the grid scale current study the green wf plays a dominant role in quantifying the wf of wheat more importantly this comparison shows that the classification of different planting types and irrigation techniques has little impact on the wf of total items but the effect is significant on the composition of the water footprint i e the proportion of green and blue wf respectively the findings of this study indicate that micro irrigation was the most useful for consumptive wf reduction compared to furrow and sprinkler irrigation the reason was that micro irrigation produces a cooling effect on the topsoil and has a relatively low soil surface moistening rate which limits the soil evaporation however this comparison was only based on the two indicators of water consumption and yield without considering the constraints of fertilizer agronomy and other factors in the setting of irrigation schedule in fact the evaluation of an irrigation methods should consider comprehensive considerations such as resource consumption field management and economic cost and benefits this will be where we need to improve in future research it is positive that this study is the first time such a comparison has been made on a large regional scale though there are some limitations with varied climate crops and socio economic conditions across china different micro irrigation application models have been slowly and gradually formed the obstacles encountered in the promotion of micro irrigation in different geographical areas have the following common points the household contract responsibility system is based on households which restricts the development of micro irrigation scale and is difficult to meet the requirements of modern agricultural development the government focuses its investment on the construction of the backbone project in the irrigation district while farmers are the main investors of the field water saving irrigation project they are less motivated to buy micro irrigation equipment consciously micro irrigation is not only a water saving technology but also a comprehensive management of integrating irrigation technology agricultural planting technology fertilization technology and farmers operating skills in order to give full play to its economic and social benefits the government should further improve the technical extension service system and strengthen the training of grassroots farmers in addition it is necessary to increase investment and subsidies in micro irrigation projects and guide farmers to develop micro irrigation projects according to local conditions the accuracy of the aquacrop model in simulating crop water consumption and yield in different climates and soil field water and fertilizer management types has been widely demonstrated however it must be pointed out that because all studies rely on many assumptions regarding parameter values the mechanism of the model and the dataset used the current study has several limitations first although different irrigation techniques were considered in this study unified values were adopted nationwide when setting the soil surface moisture rate which ignored the difference in actual irrigation technology levels in different regions second we assumed that the proportion of different irrigation techniques in each wheat planting grid cell was equal to the statistics of the corresponding province which neglected the actual distribution of different irrigation techniques third in calculating the wf we assumed that the changes in wheat planting area occurred only in existing grids based on the 2000 database without considering the migration of the wheat harvesting zone fourth we focused more on the effect of water stress on the wheat growth period while the potential impact of temperature stress overvaluing the production was neglected hatfield et al 2011 mueller et al 2013 finally under the same planting type e g rain fed or irrigated many constant crop parameters e g cropping calendar harvest index and maximum root depth were assumed throughout the study period which may lead to over or underestimation of the yield and wf levels in different scenarios waha et al 2012 additionally the effect of the model parameters has been minimized as explained in the method section the quality of the input data determines the accuracy of the model output and all limitations from the data and methods used cause uncertainties in the results however this study core includes the relative differences and trends in the wf of per ton of wheat over different times and spaces we concentrate on how the different irrigation techniques used influence the large scale wf quantification and benchmark setting of different climate zones therefore the method proposed and the outcome obtained from this study can be a meaningful reference for similar studies regarding the potential effect of management practices on the consumptive wf using other models in the future as well finally because all available studies rely on the assumption of program algorithms parameters and input data it is extremely necessary to devote more attention to data collation and model optimization in future field scale studies 5 conclusions in order to explore the impact of distinguishing different planting types and irrigation techniques on regional wf quantification and benchmark setting here we comprehensively analyzed the spatial and temporal evolution in wf of wheat production in china over 2000 to 2014 the major findings of the current study are as follows i overall the wf in m3 yr 1related to china s wheat production decreases by 4 4 during the study period while the weight of the wf for different irrigation techniques changed significantly relative to the total wf over the years in particular there is a 14 fold increase in the wf of micro irrigation with 15 years of development though it accounted for a small proportion at the beginning of the study ii the total green blue wfs per ton of wheat in china declined at the national average the yield decreases by only 2 8 while blue water consumption is reduced by 4 7 when switching from furrow to micro irrigation both productive water consumption t and nonproductive water consumption e are kept at a fixed ratio 82 vs 18 under different irrigation techniques but the total evapotranspiration et and the ineffective blue water evaporation eb are the highest for sprinkler irrigation followed by furrow and micro irrigation iii the blue water use efficiency of production that varies with the irrigation techniques applied micro 1 77 kg m 1 and furrow 1 68 kg m 1 irrigation are 19 and 13 higher respectively than sprinkler irrigation 1 49 kg m 1 iv the wf benchmarks differ greatly under both different irrigation techniques in arid regions and different climate regions with the same irrigation technique therefore the benchmarks for the wf of wheat must be set by distinguishing the irrigation techniques especially for arid zones the current analysis suggests that it is necessary and practical to consider the impact of different field management types i e the different irrigation techniques in this paper on wf quantification and benchmark setting in future studies declaration of competing interest none acknowledgments the research falls under the umbrella of the panta rhei research initiative of the international association of hydrological sciences iahs this work was financially supported by the national key research and development plan 2018yff0215702 national natural science foundation of china grants 51809215 shaanxi natural science foundation grants 2018jq4020 the west light talent program of the chinese academy of sciences to l zhuo the technology foundation for selected overseas chinese scholars in shaanxi province 2017034 and the fundamental research funds for the central universities 2452017181 the sources of all the input data used in the current study are clearly provided in the section data sources with cited references 
6189,improved spatial and temporal resolutions in quantification enable the water footprint wf in crop production to be a comprehensive indicator of water consumption in agricultural water management in general existing literature focus on the impact of water saving irrigation techniques on crop yield and water consumption during the growth period at sites or experimental units few studies yet that explicitly addresses the effect of developments in water saving irrigation techniques on large scale wf accounting and benchmarking here we fill this gap through a case study for wheat in china over 2000 2014 during which the micro irrigated wheat area expanded 14 times the green and blue wfs of china s wheat per year are estimated at a 5 arc minute resolution for irrigated wheat we distinguish three irrigation techniques furrow sprinkler and micro irrigation the wf benchmarks by irrigation type are further estimated separately for arid and humid zones irrigation accounted for 70 of annual wf in china s wheat land while furrow irrigation dominated the national total wf the occupation by wf under micro irrigation was the smallest but jumped by 14 times in quantity whereas that under sprinkler halved china s average wf per ton of wheat under sprinkler irrigation was 21 higher than that under micro irrigation in 2014 the 20th percentile wf benchmarks of wheat under micro irrigation was 13 and 31 smaller than that under furrow and sprinkler irrigation respectively in arid zones meanwhile high provincial heterogeneities in terms of wf under varied distribution of irrigation techniques were also shown the study shows possibility and importance to account for developments of water saving techniques in large scale crop wf estimations keywords irrigation techniques water footprint accounting water footprint benchmark spatial temporal variations 1 introduction water resource scarcity in crop production is one of the main drivers of the existing food crisis kang et al 2017 increasing food demand with population growth and diet structure changes continue to put pressure on the limited freshwater resources mekonnen and hoekstra 2016 veldkamp et al 2017 wada et al 2016 the water footprint wf hoekstra 2003 in crop production measures the amount of water consumption and pollution generated during the crop growth period within a geographical area for a certain time the wf of growing a crop consists of blue wf surface and groundwater consumption green wf rainwater consumption and gray wf freshwater required to assimilate water pollution hoekstra et al 2011 green and blue wfs are the consumptive wfs whereas gray wf is the degradative wf compared to traditional indicators of crop water consumption e g evapotranspiration the wf reflects not only how much the water consumed but also where the water came from i e blue or green water existing studies have been able to estimate regional wfs in crop production in high spatial and temporal resolutions using soil plant atmosphere management system models liu 2009 liu et al 2007a liu and yang 2010 hydrological models fader et al 2010 hanasaki et al 2008 rost et al 2008 or crop water productivity models chukalla et al 2015 siebert and döll 2010 ye et al 2018 zhuo and hoekstra 2017 zhuo et al 2016c d the role of remote sensing in assessing wf were also discussed romaguera et al 2010 relying on explicit data the spatial temporal evolution of regional crop wf can be demonstrated and feasible policies on sustainable local water use can be enacted various irrigation methods affect evapotranspiration at crop filed by acting on the fraction of soil surface wetted to improve irrigation performance on different crops a number of studies have been conducted to analyze the effects on irrigation water requirements crop yield and irrigation water productivity see table 1 additionally the method humicro 2000 peyremorte and tron 1995 using a microcomputer and electronic tensiometers to schedule drip irrigation or micro sprinkler systems can effectively reduce water consumption by 50 in several experiments chukalla et al 2015 indicated that sprinkler irrigation has a larger consumptive wf and the average reduction of the consumptive wf is 8 10 when changing from furrow irrigation to micro irrigation as determined by evaluating the response of the wf for crops such as wheat maize and potato in europe to different irrigation practices hoekstra 2013 2014 proposed the idea of wf benchmarks to motivate governments businesses and farmers to set wf reduction targets especially water intensive products to reasonable levels mekonnen and hoekstra 2014 established a set of global wf benchmark values for both the green blue wfs and gray wf for major crops using the global crop wf assessment for 1996 2005 at a spatial resolution of 5 5 arc minute zhuo et al 2016a systematically analyzed how different climate and soil conditions influence the consumptive wf benchmarking of winter wheat in china and confirmed that wf benchmarks are more sensitive to climate types humid vs arid above researches tended to focus on the positive impact of water saving irrigation techniques on crop yields and water consumption during the growth period at sites or fields experimental units few studies highlighted the influence of the development and popularization of water saving irrigation techniques on the spatial and temporal evolution in crop wfs in large scales obviously the difference between irrigation techniques in terms of consumptive wf intensity and temporal spatial distribution patterns cannot be neglected however the effects of applications and developments of water saving techniques across crop fields has not been considered in regional wf accounting yet previous studies assumed irrigation volume as meeting the water demand based on precipitation levels during crop growth and did not distinguish the actual variations in irrigation techniques in large spatial scales especially in developing countries the large scale application of water saving irrigation is booming for instance the micro irrigated cropping area in china has increased fourteen times since 2000 nbsc 2018 the objective of this study is to explicitly address the effect of the popularization of water saving irrigation techniques on large scale wf accounting through the case for wheat in china over 2000 2014 the green and blue wfs of both rain fed and irrigated wheat are estimated using the aquacrop model hsiao et al 2009 raes et al 2009 steduto et al 2009 at a 5 5 arc minute resolution 8 9 km 9 2 km at the latitude of china for each year for irrigated wheat we distinguish three irrigation technologies furrow sprinkler and micro irrigation the wf benchmark levels for each irrigation technology are further estimated for arid and humid zones respectively as one of the three major grain crops in china wheat accounts for a sow area of 24 million ha and annual production of 129 million ton in 2016 fig 1 contributing approximately 15 of the world total wheat production nbsc 2018 fao 2016 many scholars have studied the wf in china s wheat production table 2 highly spatial heterogeneities and temporal variations in wfs of wheat have been widely recognized in the available literatures however still without consideration of water saving instruments effects 2 material and methods 2 1 calculating green and blue water footprints in crop production the green and blue wfs m3 t 1 equal to the green and blue evapotranspiration in m3 ha 1 over the crop growing period divided by the actual crop yield in t ha 1 respectively hoekstra et al 2011 1 w f b f t 1 g p e t b t y 2 w f g f t 1 g p e t g t y in which w f b f w f g f is the blue and green wfs m3 t 1 of crops in each grid cell respectively g p day the growing period e t b t and e t g t mm the blue and green evapotranspiration on day t y t ha 1 the yield 2 1 1 dividing green and blue crop water use cwu the dynamic daily soil water balance in each grid cell in the model is estimated by keeping track of the incoming and outgoing water fluxes at the boundaries of the root zone mekonnen and hoekstra 2010 3 s t s t 1 p r t i r r t c r t e t t r o t d p t in which s t mm is the soil water content at the end of day t p r t mm the precipitation on day t i r r t mm the net irrigation depth on day t c r t mm the capillary rise of the soil horizon from groundwater which is assumed to be zero because the ground water depth is considered to be much larger than 1 m allen et al 1998 e t t mm the actual crop evapotranspiration is separated into soil evaporation e and crop transpiration tr avoids the confounding effect between non productive soil evaporation and productive crop transpiration consumptive use of water fluxes 4 e k r k e e t 0 5 t r k s k s t r k c t r e t 0 where k r is the evaporation reduction coefficient which becomes smaller than 1 the soil evaporation coefficient k e is proportional to the fraction of the soil surface not covered by canopy k s is the soil water stress coefficient which becomes smaller than 1 and k s t r is the cold stress coefficient which becomes smaller than 1 when there are not enough growing degrees in the day the crop transpiration coefficient k c t r is proportional with the green canopy cover thus aquacrop can estimate these two different types of water consumption patterns respectively r o t mm the amount of water lost by surface runoff is based on the curve number method developed by the us soil conservation service usda 1964 rallison 1980 steenhuis et al 1995 6 r o t p r t i a 2 p r t s i a where s mm refers to potential maximum soil water retention which is a function of the soil curve number i a mm the initial abstraction or the amount of water that can infiltrate before runoff occurs and d p t mm the deep percolation is defined by the drainage ability m3 m 3 day 1 from which can get the drainage ability for a particular soil water content between saturation and field capacity the drainage ability is zero when the soil water content is lower than or equal to field capacity the initial soil water content under rain fed is assumed to be equal to field capacity in contrast to statistics under irrigation following chukalla et al 2015 and zhuo et al 2016d the daily green and blue et mm were separated by tracking the daily incoming and outgoing green and blue water fluxes at the boundaries of the root zone 7 s g t s g t 1 p r t i r r t r o t p r t p r t i r r t d p t e t t s g t 1 s t 1 8 s b t s b t 1 p r t i r r t r o t i r r t p r t i r r t d p t e t t s b t 1 s t 1 in which s g t and s b t is the green and blue soil water content on day t respectively the initial soil water moisture at the start of the growing period is assumed to be green water 2 1 2 simulating the crop yield y in aquacrop the aboveground biomass b kg is derived by considering the normalized biomass water productivity w p kg m 2 the daily aboveground biomass production of the crop cycle was obtained by multiplying the wp with the ratio of crop transpiration t r to the reference evapotranspiration eto 9 b w p t r t e t 0 t the normalized w p was adjusted to consider the average atmospheric carbon dioxide co2 concentration the atmospheric evaporative demand e t 0 the crop classes c3 or c4 crops and limited soil fertility therefore the water productivity remains constant for a given crop species after normalization which explains the nature of the water driven crop water productivity model aquacrop the harvestable portion of the biomass the crop yield y t ha 1 was obtained by multiplying the aboveground biomass b with the adjusted reference harvest index h i 0 10 y f h i h i 0 b where f h i is a coefficient which takes the water deficits and temperature stresses depending on the timing and extent during the crop cycle into account that correct the harvest index from its reference value h i 0 the reference harvest index the simulated y per crop per year for each grid cell was calibrated by scaling the model outputs at provincial level to fit crop yield statistics nbsc 2018 2 1 3 considering different irrigation techniques we consider three irrigation techniques furrow 80 soil surface wetted sprinkler 100 soil surface wetted and micro irrigation 40 soil surface wetted due to the differences in the parts of the soil surface is wetted the soil evaporation varies under different irrigation types in this case the simulated value of b y e t and w p can be adjusted about the performance of the irrigation schedule for each grid cell the wfs of irrigated crop production is then weighted averaged over wfs under each type of irrigation technique and corresponding irrigated area with each irrigation technique 11 w f b f i 1 3 10 t 1 g p e t b i t w i i 1 3 y i w i 12 w f g f i 1 3 10 t 1 g p e t g i t w i i 1 3 y i w i in which w f b f w f g f is the blue and green wfs m3 kg 1 of irrigated crops in each grid cell respectively i represents the type of irrigation techniques e t b i t and e t g i t mm the blue and green evapotranspiration under the condition of i on day t g p day the growing period y i kg ha 1 the yield under the condition of i w i the irrigated area of i divided by the total area for each grid 2 2 benchmarking water footprints in wheat production the wf benchmark of wheat production is estimated following the mekonnen and hoekstra 2014 by ranking the calculated wf values in grid from the smallest to the largest against the corresponding cumulative percentage of total crop production in this study we set wf benchmarks through distinguishing different irrigation techniques and climate zones fig 2 the climate zones are classified based on unep s aridity index ai middleton and thomas 1992 1997 an indicator of dryness defined as the ratio of precipitation to reference evapotranspiration in this study we divided the geographic spread of climate zones in china into two broad zones by using the data on annual precipitation and et0 averaged during the period 2000 2014 at 30 by 30 arc min resolution harris et al 2014 zhuo et al 2016a the arid to semi arid arid zone ai 0 5 and the humid to semi humid humid zone ai 0 5 2 3 data data on monthly precipitation pr minimum tn maximum tx air temperature and reference evapotranspiration et0 were obtained from the cru ts 3 24 dataset ceda 2018 harris et al 2014 which was from monthly observations of over 4000 individual meteorological station records across the world s land areas and calculated on high resolution 0 5 0 5 degree grids the mean annual atmospheric carbon dioxide concentration was measured at mauna loa observatory in hawaii noaa 2018 in addition to the selected harvest index hi and maximum root depth zx allen et al 1998 the remaining values of parameter were obtained from raes et al 2017 soil texture data were taken from the isric soil and terrain database for china dijkshoorn et al 2008 soil water capacity data in vol on 5 by 5 arc min were obtained from isric wise batjes 2012 the irrigated and rain fed areas for wheat at a 5 by 5 arc min resolution from mirca2000 portmann et al 2010 were divided into areas with different irrigation techniques according to the proportion of different water saving irrigation techniques from statistical yearbook nbsc 2018 while the crop areas from mirca2000 and yields simulated by aquacrop were scaled to fit corresponding yearly statistics at provincial level nbsc 2018 3 results 3 1 water footprint of wheat production in m3 yr 1 during the study period of 2000 2014 the average annual total consumptive wf of wheat production in china was 132 gm3 yr 1 58 green 42 blue fig 3 shows the composition and annual decreasing trends in the total wf of wheat production over the study period the total harvested area and the irrigated area of wheat in china decreased by 10 and 9 respectively which caused a 4 4 decline in the total wf specifically the blue wf in 2014 53 gm3 yr 1 decreased by 5 7 compared with that in 2000 56 gm3 yr 1 and the green wf in 2014 74 gm3 yr 1 was 3 5 lower than that in 2000 76 gm3 yr 1 the annual average wf of irrigated wheat 86 gm3 yr 1 accounts for 70 of the total wf the contribution of the wf under different irrigation techniques towards the total wf changed from year to year due to the changes in corresponding harvested area as illustrated in fig 3 the largest wf was computed in furrow irrigation 81 gm3 yr 1 which also dominated the national wf volume fig 3 it must be pointed out that the proportion of the wf from micro irrigation is the smallest whereas the rise of its contribution is the largest the wf in micro irrigation increased substantially by 12 times from 0 4 to 4 8 gm3 yr 1 over 2000 2014 as the cultivated area of wheat with micro irrigation in china in 2014 had expanded 14 times relative to 68 kha in 2000 the wf of wheat under sprinkler irrigation 2 8 gm3 yr 1 in 2014 is approximately one half that under micro irrigation because the wheat area under sprinkler irrigation decreased by nearly 40 reaching 485 kha in 2014 during the study period fig 4 illustrates the proportions of the blue and green wf of wheat under different irrigation techniques relative to the total wf over 2000 2014 concerning the blue wf proportion with furrow and sprinkler irrigation in the total wf has been declining from 94 and 5 in 2000 to 90 and 3 respectively as a result of the sharp decrease in cultivated area at the same time with the continuous expansion of the cultivated area with micro irrigation the blue wf of wheat for micro irrigation has undergone a 17 fold increase compared to the value at the beginning of the research 0 2 gm3 yr 1 in 2000 the largest annual value on the percentage of the total green wf was for rain fed wheat 52 followed by furrow irrigation 45 while the sprinkler 2 and micro 1 irrigation were at a lower level over the study period there are provincial heterogeneities in terms of the annual developments in the total wf of wheat fig 5 a the harvested area and wf of wheat of most provinces decreased by more than 30 the exceptions were mainly in the henan shandong hubei anhui jiangsu and xinjiang provinces where the harvested area and wf of wheat increased during the study period the spatial distribution of the wf of wheat is similar to the spatial distribution of the wheat harvested area fig 5b the wf values of wheat determined by distinguishing irrigation techniques are obviously different at the provincial level table 3 in 2014 approximately 67 of the wheat planting area and 70 of the wf was clustered in the following five provinces henan 28 gm3 yr 1 shandong 21 gm3 yr 1 hebei 14 gm3 yr 1 anhui 13 gm3 yr 1 and jiangsu 11 gm3 yr 1 in addition the actual proportion of wheat planting area under various irrigation techniques has a profound impact on the value of the wf for example in 2014 the shares of wheat planting area under furrow sprinkler and micro irrigation relative to the total irrigated area in gansu were 48 47 and 5 respectively in contrast to 92 5 and 3 in shanxi however gansu 812 kha of irrigated area and 1 3 gm3 yr 1 of blue wf with more irrigated land and a drier climate has a blue wf much smaller than that of shanxi 565 kha of irrigated area and 2 3 gm3 yr 1 of blue wf 3 2 the water footprint per ton of wheat in m3 t 1 as can be seen in fig 6 the national average wf per ton of wheat decreased by 25 from 1330 m3 t 1 in 2000 to 1003 m3 t 1 in 2014 with the blue wf and green wf falling by 26 and 24 respectively this significant change was caused by the steady increase of wheat yield the yield increased by more than 40 from 3 7 t ha 1 in 2000 to 5 2 t ha 1 in 2014 fig 7 shows the distribution of the wf per ton of wheat in 2014 and its relative change from 2000 to 2014 the per unit product wf of wheat in northern china was mostly below 1200 m3 t 1 in 2014 but the relatively low yield in southern china 42 lower than the north resulted in the per unit product wf of wheat being generally higher than 2000 m3 t 1 the results shown in table 4 display great variation across provinces only less than one third of the provinces have a lower per unit product wf of wheat than the national average such as those of henan 854 m3 t 1 anhui 930 m3 t 1 shandong 948 m3 t 1 jiangsu 953 m3 t 1 and hebei 999 m3 t 1 these provinces are mainly located in the middle and eastern part of china where the wheat production accounted for 76 of the national total however except for anhui and jiangsu where the blue wf accounts for 16 the average blue wf of henan shandong and hebei account for nearly 54 of the total green blue wf the provinces with the highest wf are guangxi yunnan and jiangxi with an average wf more than 2500 m3 t 1 fig 7b this result can be explained by the rainfed dominated cultivation the rainfed land in these regions accounts for 65 of the total planting area while the national average is 36 and the mountainous geographical environment resulting in a yield 2 2 t ha 1 of just 40 of the national average in 2014 among the spatial variation in the relative change of the total wf of wheat the wf in most regions 16 provinces decreased by 20 conversely the wf in guangxi and yunnan increased by 5 and 35 respectively the wf per ton of wheat under furrow sprinkler and micro irrigation showed a downward trend in the past 15 years with a significant difference comparatively in 2014 the wf under sprinkler irrigation 1149 m3 t 1 was the highest which was 21 higher than the lowest wf of micro irrigation 948 m3 t 1 and the wf under furrow was 997 m3 t 1 moreover 30 provinces were estimated as samples to further analyze the impact of the development and evolution of different irrigation techniques on the wf calculation we found that the provincial per unit product wf was reduced upon move from furrow to micro irrigation considering xinjiang as an example the planting areas with furrow irrigation decreased by 56 whereas micro irrigated area increased by 60 during which the per unit product wf fell by 20 845 m3 t 1 far lower than the national average we further look at the sensitivity of evaporation and transpiration during the wheat growth period to different irrigation techniques fig 8 the calculated et of rain fed wheat was confirmed to be the smallest it is worth nothing that the productive t or unproductive e maintained fixed proportions 82 vs 18 of the total cwu in both rain fed and irrigated conditions an interesting result from this study is that sprinkler irrigation a traditional water saving irrigation technique had a larger et 544 mm than furrow 532 mm and micro irrigation 511 mm which agrees well with the views of chukalla et al 2015 on major crops in israel spain italy and the united kingdom the so called water saving irrigation technique reduces water withdrawal and improves water efficiency but based on the consumption during the crop growth period sprinkler irrigation is not a superior the same result is obtained in the analysis of non productive blue water e blue i e the maximum amount of blue water used for ineffective evaporation is found with sprinkler irrigation followed by furrow and micro irrigation because there is a significant difference in the soil surface moisture under different irrigation techniques fig 9 illustrates the main evaluation index for quantifying the wf under different irrigation techniques during the study period a relatively higher water consumption and low yield level fig 9a explain why the highest wf occurs with sprinkler irrigation fig 9b from the perspective of the green wf the lowest value is obtained by micro irrigation because micro irrigation is mainly used in areas where fresh water and even rainwater resources are scarce for blue water with a higher opportunity cost fig 9c the change from furrow to sprinkler irrigation reduces the yield by 8 1 and the blue et increases by 3 5 while the yield slightly reduces by 2 8 but the blue et obviously reduces by 4 7 upon changing from furrow to micro irrigation all these results indicate that the blue water conversion rate of production which is defined as the amount of food produced per unit of blue water that varies with the irrigation techniques applied fig 9d micro 1 77 kg m 1 and furrow 1 68 kg m 1 irrigation are 19 and 13 higher respectively than sprinkler irrigation 1 49 kg m 1 3 3 water footprint benchmarks of wheat by irrigation techniques we further explored how different irrigation techniques influence the benchmark levels for the wf per ton of wheat in china for different climate zones we found that the benchmark levels for wheat fluctuated within a range of 16 in long term serial averages over 2000 2014 table 5 considering irrigated and rain fed croplands together i e not distinguishing the various irrigation techniques the wf benchmarks per ton of wheat for the arid zone were 17 for the 10th production percentile to 9 for the 20th production percentile smaller than those for the humid zone the wf benchmarks of wheat in this study are contrary to those of zhuo et al 2016a for arid and humid regions i e the wf benchmarks for the arid zone are smaller than for the humid zone and could be explained by in that zhuo et al 2016a considered the wf of winter wheat from 1996 to 2008 while both winter and spring wheat are considered in this study from 2000 to 2014 the calculated wf of spring wheat distributed mostly in the humid area was confirmed to be higher than that of winter wheat which inclined the low wf towards the arid zone it can be seen from fig 7 that the per unit product wf in arid regions is distinctly lower than that in humid regions in addition the agricultural technological level at the different study periods selected also had an impact on the wf quantification by comparing the per unit product wf benchmarks in same climate region the values for different irrigation techniques differ greatly in arid regions the wf benchmarks under micro irrigation are 23 for the 10th production percentile to 31 for the 20th production percentile smaller than that under sprinkler irrigation while 7 and 13 smaller compared to furrow irrigation however we did not find a typical change of wf benchmarks in humid regions under different irrigation techniques the sample difference rate did not exceed 3 from the best 10 952 16 m3 t 1 to the best 20 993 18 m3 t 1 of wheat production including the national average 1182 38 m3 t 1 by comparing per unit product wf benchmarks for same irrigation technique the values for different climate regions vary by irrigation technique the wf benchmarks for the arid zones are 15 for the 10th production percentile to 4 for the 20th production percentile smaller than those for humid zones under furrow irrigation in contrast to 22 and 20 respectively under furrow irrigation nevertheless the wf benchmark for arid zones is 16 larger for the 20th production percentile than for humid zones under sprinkler irrigation which is due to the relatively higher wf of spring wheat with 60 of the spring wheat cultivated areas under sprinkler irrigation concentrated in arid zones as a whole benchmarks for the consumptive wf of wheat at different production percentiles show obvious distinctions within the same climate region with different irrigation techniques or in different climate regions with the same irrigation techniques therefore setting the benchmark for wf per ton of wheat by considering different irrigation techniques in different climate zones is of great practical and guiding significance for agricultural water saving 4 discussion considering different irrigation techniques the current study estimates and assesses at a high spatial resolution the temporal spatial variation in the consumptive wf of china s wheat production results show that the per unit water consumption and per unit product wf is largest under sprinkler irrigation followed by furrow and micro irrigation which is consistent with the results of chukalla et al 2015 water saving irrigation in the traditional sense essentially increases the efficiency of water use in the field and reduces the loss of water delivery for example sprinkler irrigation can effectively reduce the water demand by 46 compared with furrow irrigation xue and ren 2016 however from the perspective of the wf of crop production sprinkler irrigation is not dominant on the one hand though furrow irrigation is less efficient with higher percolation and runoff fluxes compared to sprinkler irrigation these fluxes return to the catchment and are not lost from the system and therefore are not considered to contribute to the actual water consumption hoekstra et al 2011 grafton et al 2018 on the other hand sprinkler irrigation results in a larger et due to the large surface wetting rate for an equal yield micro irrigation has been shown to be most effective for wf reduction in this study it has become a trend to grow wheat by micro irrigation on a large scale in china for which the arid and semiarid northwest regions such as xinjiang ningxia gansu and inner mongolia account for 83 of this micro irrigated crop the social and ecological benefits of growing wheat by micro irrigation will be more prominent if the problems of micro irrigation system design high equipment cost and wheat physiological mechanisms can be effectively solved in future practices a 10 of decrease is observed in the wheat harvest area whereas the yield shows an increasing trend fig 6 statistics show that china s grain output has achieved a 12 year increase in the past 15 years including wheat although the harvested area of wheat has fallen by 10 the gradual expansion of effective irrigated areas grew by 20 from 2000 has not only stabilized but also boosted wheat production it can be seen from fig 9 that the difference in yield per unit area of wheat under irrigation and rain fed conditions is much greater than that between different irrigation methods therefore the increase of effective irrigated area is the main reason to promote the increase of wheat production in addition the blue wf in m3 yr 1 fig 3 experienced little downward trend for 15 years was not obvious and even had a significant rebound in 2010 which was mainly caused by extreme climate factors the severe drought from the winter of 2009 to the spring of 2010 increased the irrigation water consumption during the winter wheat growing period which resulted in a sharp increase in the blue wf of wheat production during the year the estimated wf values in m3 t 1 were compared with those of previous studies as shown in table 6 the calculated total wf for the current study averaged for the period of 2000 2005 is relatively low in comparison with the values presented by mekonnen and hoekstra 2010 specifically the green wf of this study was 14 lower under rain fed conditions while the green and blue wf were 21 and 18 lower respectively under this irrigation mode compared to the estimations by mekonnen and hoekstra 2010 the temporal spatial scales selected and the modeling standards applied between wf studies may improve the level of uncertainties there are two reasons explaining this difference in results first the crop yield calibrated at the provincial level for the current study was more accurate than that of mekonnen and hoekstra 2010 at the national level second the modeling standard dividing the planting modes into rain fed conditions and furrow micro and sprinkler irrigation of this study was closer to reality instead of the one irrigation type furrow irrigation assumed by mekonnen and hoekstra 2010 in addition our estimated total wf was 4 higher than the assessment by liu et al 2007b for the year 2000 which simply considered winter wheat it is important to note that both spring and winter wheat were taken into account in this study and the results showed that the per unit product wf of spring wheat at the provincial scale was higher than the national average the wf in m3 t 1 and m3 yr 1 of this study were 1047 m3 t 1 and agree well with that of sun et al 2013 for the year 2009 comparing the quantified wf in m3 t 1 with the values presented by zhuo et al 2016c for the year 2008 indicates that the wf in total terms is well matched by 3 lower while the green wf 13 lower and blue wf 34 higher present obvious differences even though we used the same crop model and climate input data it thus indicates the significant effects of developments in irrigation techniques as considered in the current study the wf values in m3 yr 1were compared with those of sun et al 2013 for the year 2009 and cao et al 2014 for the year 2010 at the national scale the difference between the studies is approximately 10 due to the difference between the model used and the data input at the provincial scale the estimated green blue wfs in total terms compares to the result of cao et al 2014 the correlation is reasonably good and the order of magnitude is similar in these two studies with an r2 value of 0 96 however their total blue wf 40 gm3 yr 1 estimate is 36 lower than our estimate 63 gm3 yr 1 while their green wf 72 gm3 yr 1 is 11 higher than the current estimate 64 gm3 yr 1 this result can be explained from the perspective of the research scale either from the typical irrigation districts cao et al 2014 or from the grid scale current study the green wf plays a dominant role in quantifying the wf of wheat more importantly this comparison shows that the classification of different planting types and irrigation techniques has little impact on the wf of total items but the effect is significant on the composition of the water footprint i e the proportion of green and blue wf respectively the findings of this study indicate that micro irrigation was the most useful for consumptive wf reduction compared to furrow and sprinkler irrigation the reason was that micro irrigation produces a cooling effect on the topsoil and has a relatively low soil surface moistening rate which limits the soil evaporation however this comparison was only based on the two indicators of water consumption and yield without considering the constraints of fertilizer agronomy and other factors in the setting of irrigation schedule in fact the evaluation of an irrigation methods should consider comprehensive considerations such as resource consumption field management and economic cost and benefits this will be where we need to improve in future research it is positive that this study is the first time such a comparison has been made on a large regional scale though there are some limitations with varied climate crops and socio economic conditions across china different micro irrigation application models have been slowly and gradually formed the obstacles encountered in the promotion of micro irrigation in different geographical areas have the following common points the household contract responsibility system is based on households which restricts the development of micro irrigation scale and is difficult to meet the requirements of modern agricultural development the government focuses its investment on the construction of the backbone project in the irrigation district while farmers are the main investors of the field water saving irrigation project they are less motivated to buy micro irrigation equipment consciously micro irrigation is not only a water saving technology but also a comprehensive management of integrating irrigation technology agricultural planting technology fertilization technology and farmers operating skills in order to give full play to its economic and social benefits the government should further improve the technical extension service system and strengthen the training of grassroots farmers in addition it is necessary to increase investment and subsidies in micro irrigation projects and guide farmers to develop micro irrigation projects according to local conditions the accuracy of the aquacrop model in simulating crop water consumption and yield in different climates and soil field water and fertilizer management types has been widely demonstrated however it must be pointed out that because all studies rely on many assumptions regarding parameter values the mechanism of the model and the dataset used the current study has several limitations first although different irrigation techniques were considered in this study unified values were adopted nationwide when setting the soil surface moisture rate which ignored the difference in actual irrigation technology levels in different regions second we assumed that the proportion of different irrigation techniques in each wheat planting grid cell was equal to the statistics of the corresponding province which neglected the actual distribution of different irrigation techniques third in calculating the wf we assumed that the changes in wheat planting area occurred only in existing grids based on the 2000 database without considering the migration of the wheat harvesting zone fourth we focused more on the effect of water stress on the wheat growth period while the potential impact of temperature stress overvaluing the production was neglected hatfield et al 2011 mueller et al 2013 finally under the same planting type e g rain fed or irrigated many constant crop parameters e g cropping calendar harvest index and maximum root depth were assumed throughout the study period which may lead to over or underestimation of the yield and wf levels in different scenarios waha et al 2012 additionally the effect of the model parameters has been minimized as explained in the method section the quality of the input data determines the accuracy of the model output and all limitations from the data and methods used cause uncertainties in the results however this study core includes the relative differences and trends in the wf of per ton of wheat over different times and spaces we concentrate on how the different irrigation techniques used influence the large scale wf quantification and benchmark setting of different climate zones therefore the method proposed and the outcome obtained from this study can be a meaningful reference for similar studies regarding the potential effect of management practices on the consumptive wf using other models in the future as well finally because all available studies rely on the assumption of program algorithms parameters and input data it is extremely necessary to devote more attention to data collation and model optimization in future field scale studies 5 conclusions in order to explore the impact of distinguishing different planting types and irrigation techniques on regional wf quantification and benchmark setting here we comprehensively analyzed the spatial and temporal evolution in wf of wheat production in china over 2000 to 2014 the major findings of the current study are as follows i overall the wf in m3 yr 1related to china s wheat production decreases by 4 4 during the study period while the weight of the wf for different irrigation techniques changed significantly relative to the total wf over the years in particular there is a 14 fold increase in the wf of micro irrigation with 15 years of development though it accounted for a small proportion at the beginning of the study ii the total green blue wfs per ton of wheat in china declined at the national average the yield decreases by only 2 8 while blue water consumption is reduced by 4 7 when switching from furrow to micro irrigation both productive water consumption t and nonproductive water consumption e are kept at a fixed ratio 82 vs 18 under different irrigation techniques but the total evapotranspiration et and the ineffective blue water evaporation eb are the highest for sprinkler irrigation followed by furrow and micro irrigation iii the blue water use efficiency of production that varies with the irrigation techniques applied micro 1 77 kg m 1 and furrow 1 68 kg m 1 irrigation are 19 and 13 higher respectively than sprinkler irrigation 1 49 kg m 1 iv the wf benchmarks differ greatly under both different irrigation techniques in arid regions and different climate regions with the same irrigation technique therefore the benchmarks for the wf of wheat must be set by distinguishing the irrigation techniques especially for arid zones the current analysis suggests that it is necessary and practical to consider the impact of different field management types i e the different irrigation techniques in this paper on wf quantification and benchmark setting in future studies declaration of competing interest none acknowledgments the research falls under the umbrella of the panta rhei research initiative of the international association of hydrological sciences iahs this work was financially supported by the national key research and development plan 2018yff0215702 national natural science foundation of china grants 51809215 shaanxi natural science foundation grants 2018jq4020 the west light talent program of the chinese academy of sciences to l zhuo the technology foundation for selected overseas chinese scholars in shaanxi province 2017034 and the fundamental research funds for the central universities 2452017181 the sources of all the input data used in the current study are clearly provided in the section data sources with cited references 
