index,text
23820,populated coastlines influenced by tropical cyclone tc prone areas call for flood risk hazard assessments including knowledge on the probability of occurrence of major tc induced significant wave heights due to the scarcity of tc historical records extreme value analyses often rely on fitting generalized extreme value distribution functions to extrapolate longer return periods this paper describes a methodology that allows to obtain deterministic estimations of the tail probability distribution using long collections of high fidelity tracks that reproduce similar historical diversity and frequency trends given the large dimensionality of the problem spatiotemporal variability of track geometry and intensity we implement a track parameterization to easily identify storms in a parametric space a hybrid approach significantly reduces computational resources by enabling to narrow the number of non stationary numerically simulated cases forced with vortex type wind fields parameterized using the holland dynamic model the proposed surrogate model hytcwaves is trained with a selected subset of maximum significant wave height mswh spatial fields to which a principal component analysis and interpolation functions are performed results show a useful approximation of spatial based regional extreme value distribution of mswh induced by tcs the proposed model is applied to the target location of majuro atoll keywords tropical cyclone hybrid downscaling surrogate model vortex type winds extreme value distribution 1 introduction tropical cyclones tcs also known as typhoons or hurricanes are among the world s most destructive natural disasters bringing strong winds heavy rainfall large waves and storm surges that devastate property and cause loss of life e g chu and wang 1998 diamond et al 2012 stephens and ramsay 2014 substantial research has been directed to assess the wide range of hazards mori and takemi 2015 puotinen et al 2016 young 2017 cagigal et al 2022 and damaging impacts emanuel 2020 ye et al 2020 sajjad and chan 2020 over increasingly populated coastlines affected by the passage of tcs including the potential catalyst effect of compound events i e with king tides leonard et al 2014 fakhruddin et al 2022 moreover policy makers responsible for flood risk management and coastal defense infrastructures generally require probabilistic analysis that provide the design wave height for standard return periods 100 year or even higher for instance the 1000 year return values used by the united kingdom for coastal flood boundary conditions environment agency 2018 the extreme value ev theory seeks to assess the probability of events that are more extreme than any previously observed return values for wind and waves are fundamental to assessing the risks associated with human activities but their computation is complicated by the paucity of observational records breivik et al 2014 particularly when dealing with tcs only short collections of historical data that span for less than five decades can be gathered at a certain target location therefore long return values can only be extrapolated well beyond the range of available data caires 2011 with the common use of generalized ev distribution fittings however long return period estimates carry a great deal of uncertainty here we aim to address this issue by using high fidelity storm tracks namely synthetic storms which allow to generate large samples of thousands of tracks while preserving historical probability distribution functions of tc parameters and temporal correlation nevertheless dealing with huge amounts of tracks would mean very intensive computational demand to characterize wave climate using numerical simulation of wave propagation processes alternatively past studies have accounted for successful applications of hybrid downscaling methods camus et al 2011 2013 antolínez et al 2018 anderson et al 2021 ricondo et al submitted that combine dynamical simulations with statistical techniques allowing to interpolate the dynamical response of a dataset based on a reduced number of simulated output cases given that such subset is selected ensuring that it is well distributed and explores the full dimensional space we incorporate the use of a surrogate predictive model trained with precomputed waves based on high fidelity simulations offering satisfactory accuracy and enhanced computational efficiency smith et al 2015 past studies have already established advancements for the application of surrogate modeling techniques for storm surge prediction jia et al 2016 although to our knowledge this is the first attempt to predict spatial distribution of maximum tc induced waves moreover principal component analysis pca is integrated as a dimension reduction technique to enhance computational efficiency the focus of the current study is to implement and evaluate the skills of the preliminary proposed methodology to assess the ev distribution of maximum significant wave height mswh due to tcs in a target domain both the study site and the data used are presented in section 2 the subsequent steps of the proposed methodology are explained in section 3 while the ev distribution and the obtained results are shown in section 4 followed by summary and discussion in section 5 2 application area and data 2 1 study site the methodology presented in this paper can be applied to coastal areas surrounded by open waters and subjected to tc activity here we have chosen the area of majuro the capital of the republic of the marshall islands to apply hytcwaves these archipelagic islands are located in the north west equatorial pacific fig 1a particularly at the east of the most active concentration of tcs in the western tropical pacific basin which is located between the philippines and guam camargo et al 2007 majuro is an atoll formed by many little low lying islands which make them extremely prone to storm surge induced flooding due to tcs the area of influence of the study site is moderately exposed to tcs with a mean annual rate of 0 6 events year for the last 60 years according to historical records knapp et al 2018 however devastating events were documented by spennemann 1996 with a storm surge that washed the entire southern part of majuro typhoons in 1905 1908 as well as severe inundations due to tc alice 1979 moreover ford et al 2018 compiled damaging impacts due to more recent tcs pamela 1982 roy 1988 axel 1992 gay 1992 paka 1997 2 2 bathymetry in this study the bathymetry resulted from a combination between the gebco general bathymetric charts of the ocean http www gebco net global bathymetric dataset and a high resolution nearshore bathymetry dataset available for majuro atoll fig 1a the gebco s gridded bathymetric dataset gebco 2019 grid is a global terrain model for ocean and land providing elevation data on a 15 arc second interval grid equivalent to 450 m spatial resolution however this global dataset lacks resolution for the low lying islands of the study site for that reason a topobathymetric digital elevation model for the majuro atoll was developed by the u s geological survey usgs https www usgs gov in collaboration with the u s department of interior doi pacific islands climate science centre pi csc in order to support the modeling of storm and tide induced flooding its grid spacing is 1 m and it includes the majuro atoll and extends offshore to a depth of at least 71 m https doi org 10 5066 f7416vxx 2 3 tropical cyclone databases the tc input data is collected from two storm track databases a historical database the ibtracs v04r00 database international best track archive for climate stewardship knapp et al 2018 compiles global available records of historical storm tracks from 1851 onwards and it combines track and intensity estimates from several observational sources knapp et al 2010 ibtracs includes the track location longitude and latitude the sea level pressure and the maximum wind speed mws at six hour intervals in this study we have used the world meteorological organization wmo dataset which provides the official pressure and wind speed data reported by the responsible agency at every location in this case the rsmc tokyo which is operated by the japanese meteorological agency jma b synthetic database for the purpose of this study high fidelity tracks generated by nakajo et al 2014 are employed to demonstrate the application of the proposed methodology however other synthetic databases e g emanuel et al 2008 bloemendaal et al 2020 nederhoff et al 2021 or a combination of several databases could be selected instead these synthetic tracks from a global stochastic model are sensitive to the joint probability distribution functions of tc parameters such as the track sea level pressure and forward speed as well as temporal correlations thereby reproducing the frequency of tcs and diversity of track geometry synthetic tracks include information of the longitude latitude time and sea level pressure in this study an area of influence to evaluate tcs induced waves is established as a 4 degrees radius circle centered in majuro atoll 450 km radius then a subset of storm tracks that enter and or cross the circle area is extracted from both historical and synthetic tc databases figs 1b and 1c respectively with 37 historical storm tracks during the period from 1951 until 2021 and 10 064 synthetic storm tracks this large subset overcomes the shortage of historical events for this particular region in order to illustrate the tcs intensity in figs 1b and 1c the track line color indicates the tc category 5 4 3 2 1 corresponding with minimum central pressures lower than 920 944 964 979 1000 mbar respectively while category 0 accounts for tropical storms with central pressures higher than 1000 mbar while the historical subset intensities range between lower categories 0 2 the synthetic subset intensities include all categories 0 5 3 methodology 3 1 overview the proposed methodology aims to estimate the wave climate ev distribution induced by tcs in the atoll of majuro and its immediate surroundings a standard approach would perform a dynamical downscaling of historical events that crossed or occurred near majuro simulated with hindcast wind fields forcing to conduct an ev analysis fitting to characterize the tail distribution of extreme significant wave heights at particular locations however this approach is very limited to the number of occurrences as tcs are scarce phenomena both in time and space moreover the available and statistically representative period of historical records is too short when the interest is to characterize the ev distribution for return periods of 100 years or more meaning that estimates must be extrapolated with a high degree of uncertainty alternatively a hybrid approach is proposed in order to overcome those limitations on one hand high fidelity tracks are employed to significantly populate the sample of historical storm tracks being accountable for thousands of years so that the tail distribution needs no extrapolation on the other hand a surrogate model is proposed to unload the number of dynamical simulations as it is impracticable to numerically simulate thousands of events moreover the hybrid approach includes the use of statistical and clustering techniques that allow to reduce the computational resources demand regarding the generation of high fidelity tracks the approach used by nakajo et al 2014 basically employs a stochastic downscaling method based on monte carlo simulations for a sequential development of tcs calculated statistically from given statistical parameters of tc data therefore artificial tracks are sensitive to the approximations of joint probability distribution functions by using principal component analysis of several tc parameters and temporal correlations fig 2 illustrates the flow chart of the hytcwaves methodology which is composed of the following steps a a stochastic sample of historical and synthetic database events is collected and extracted for a 4 degrees radius circle area of influence b storm tracks are parameterized in terms of a reduced number of variables which characterize its main attributes while reducing the dimensionality of the problem c a selection method is used to generate a subset that preserves tc diversity for a given target location d tc induced waves are obtained by running dynamic non stationary simulations forced with parameterized time varying vortex type wind fields for each storm track e the spatial wave conditions for the remaining non simulated database tracks are reconstructed using pca coupled with an interpolation technique based on radial basis functions rbfs and f calculation of the ev distribution the shaded text boxes fig 2 right column correspond to the standard dynamical downscaling approach the following sections describe in detail the methodology steps and present the results obtained for the study site as an example of its applicability 3 2 track parameterization the fundamental idea of surrogate based models is to build a predictive model that is computationally efficient and capable of approximating the value of a function goldstein et al 2019 anderson et al 2021 the standard approach includes a learning phase with training examples of past events linking the design parameters and its corresponding time varying dynamical response therefore a set of input parameters must be defined to train the surrogate model the choice of such parameters in this case is conditioned by the following criteria a parameters must be available from the storm track database and b parameters must be representative of the track geometry and intensity the tc database composed of both historical and synthetic tracks have three common variables longitude latitude location of the storm eye and central pressure besides the forward speed can be derived from successive storm coordinates the parametric space aims to explore the diversity of events and to represent each storm by a low dimensional vector for that purpose a simplification of the track geometry within the influence area of 4 degrees radius around majuro is proposed fig 3 in order to reduce its dimensionality into a small number of variables given by the following geometric kinematic and dynamic parameters which constitute the surrogate model predictor inputs a delta δ azimuth of the storm entrance point in the circle influence area b gamma γ azimuth of the mean direction within the circle using the entrance and exit coordinates c p m i n minimum central pressure along the storm track coordinates within the circle and d v m e a n mean forward speed within the circle fig 3 left column illustrates the comparison sketch of a real track geometry versus an approximated track with the ad hoc parameters the hypothesis of constraining the track morphology with a constant forward direction meaning a straight track simplifies the intrinsic complexity and it allows to represent storm events in a 4 dimensional parametric space the neglected discrepancies are generally small within the local area of influence since real and synthetic storms show seldom sinusoidal tracks fig 3 upper row however this assumption may limit its applicability in target areas where tracks may be generally more erratic recurving and convoluted as reported in past review papers terry and feng 2010 sharma et al 2020 a second hypothesis implies that storm intensity is constant along a whole event within the influence area and the minimum value is set to account for the most adverse possible events moreover the impacts over majuro will largely depend on the intensity the rmw v mean and the minimum distance from land all the extracted tcs from historical and synthetic databases for the influence area around majuro are parameterized and its results are shown in fig 3 where real versus parameterized tracks can be compared for both historical and synthetic tracks it can be noticed the straightening effect between the circle s entrance and exit coordinates and the low ratio of quasi straight and sinuous tracks here a 4 degrees radius was established as a balance between accounting for a large enough influence area and ensuring that the simplification of sinuous tracks into straight storms remains a good representation of the tc characteristics this means that the size of the influence area may be tuned for each location taking into consideration the tc characteristics i e smaller area if convoluted tracks are likely to occur or larger if tracks are generally quasi straight also a future line of research could be to perform sensitivity tests on the radius size to the ev analysis it should be noted that a limitation of this preliminary methodology does not account for potential extreme events produced by tc induced distant swells generated outside the 4 degrees influence area the current applicability of the proposed method is restricted to tc induced waves produced in the study area regional vicinity 3 3 selection the synthetic dataset extracted for the target study site is composed of 10 064 tracks and the tc track parameters can be visually analyzed with a multi scatter plot fig 4a where each dot represents a storm track when comparing the historical purple and synthetic gray dots it can be seen that synthetic tracks explore the parametric space while spanning over the historical data limits partly because recorded events are very scarce in number however some criteria need to be established to remove tc parameters that are not physically plausible or that excessively surmount historical parameters 1 the minimum central pressure lower limit is set to 860 mbar corresponding to the minimum historical record plus 1 margin 2 the mean forward speed upper limit is established by the 99 percentile of historical values plus 5 km h margin 3 the azimuth angle δ upper limit is 270 degrees since historical tracks are not statistically arriving from the north west at the target area in the north west equatorial pacific and 4 the entrance angle γ lower limit is 40 degrees to remove noticeable synthetic outliers it should be noted that establishing the filter criteria and the removal of tc parameter outliers is fully dependent on the available historical data within the influence area at the study site fig 4b illustrates the filtered database gray dots resulting from applying these criteria which renders 8773 synthetic tracks the updated storm dataset of historical and filtered synthetic tracks for the target study site is composed of 8810 events a number too large to dynamically downscale as it would be very computationally demanding instead a selection algorithm can be used to determine the subset to eventually train the surrogate model in this case the maximum dissimilarity algorithm mda as proposed by camus et al 2011 to downscale wave climate to coastal areas has been used this mathematical tool is used to obtain a reduced number of cases that cover the track variability and guarantee that all possible combinations of track characteristics are represented with a special emphasis on the boundary events of the multivariate parametric space the dataset can be defined as x i p m i n v m e a n δ γ i with i 1 n the total number of tracks the scalar and directional variables are previously normalized so that the mda algorithm is applied over a non dimensional space where the target subset of m vectors is initialized by selecting the vector for which its dissimilitude is the largest out of the sample the remaining m 1 vectors are selected iteratively by calculating at each iteration the vector which maximizes the dissimilitude in respect to the vectors added to the subset until a number of m vectors are selected this selection method has the advantage of allowing an easy iterative analysis of results with incrementing selection sample numbers as a deterministic tool that further calculates dissimilitude distances with the remaining dataset points fig 4b shows the multivariate distribution of the mda subset m 500 in the four dimensional parametric space noting that boundary data is included in the selection the colored dots depict the order in which data points are selected by applying the mda algorithm to successive badges of 100 intervals black red orange yellow green fig 4c illustrates the corresponding parameterized tracks for successive selection samples m 100 200 300 400 500 it is noted that already in the first 100 badge the selected tracks are well distributed in terms of both angles and intensities if compared with the historical parameterized tracks fig 3 lower middle the selection includes more intense events as expected due to having incorporated synthetic tracks in the dataset sample the choice on the selection number is partly subordinated to the simulation computing time camus et al 2011 analyzed the sensitivity effect of the selection number for hybrid model applied to wave propagations and observed that for higher than m 200 the decrease of the error was negligible however since the current application in this study involves a higher level of complexity as we aim to characterize a spatial based reconstruction and the multivariate problem has more degrees of freedom we have chosen m 500 it seems reasonable in terms of computation and to explore well enough the parametric space fig 4d shows the comparative histograms of probability density distribution for the four tc parameters and the historical red the synthetic filtered blue datasets and the mda yellow subset it can be noticed that the synthetic filtered dataset exhibits a certain shift of probability distribution to the lower and upper tails for the minimum central pressure and mean forward speed distributions respectively consistent with the limiting filtering criteria that was applied over synthetic tracks both synthetic angles exhibit a normal probability distribution within the bound limits of historical data these results account for a synthetic dataset that explores more intense and severe tcs than the historical event records that will likely account for extreme events the probability density distribution of the mda subset shows a general agreement with the dataset despite showing a higher frequency of lower central pressures and fast moving storms 3 4 vortex type winds parameterization once the selected sample of 500 parameterized straightened tracks has been defined the corresponding time varying wind fields need to be estimated in order to feed the wave numerical model here a wind parametric model is employed with the advantage of using a small number of input variables ruiz salcines et al 2019 evaluated and compared six well known parametric wind models and concluded that when dealing with a large number of events the choice of a particular model does not guarantee greater accuracy the dynamic holland model is based on the vortex type model developed by holland 1980 2008 to provide estimates of maximum winds using an analytic model of the sea level pressure and wind profiles however the original model was parameterized to fit the tc instantaneous gradient wind level rather than the winds at surface level of a moving and dynamically developing tc to overcome this a modified model was developed by fleming et al 2008 to account for the dynamic changes of the tc parameters along the track the dynamic holland model estimates the spatial distribution of sea surface wind fields in terms of the following variables 1 the forward speed 2 the maximum wind speed at 10 m with a 1 minute sampling interval 3 the rmw and 4 the central pressure however as it was described the synthetic storm track database does not inform either about the maximum winds or the rmw therefore these variables must be estimated on one hand the ibtracs storm data provides maximum winds and the resulting empirical relationship between central pressure and maximum winds depicts a significant correlation not shown therefore a regression model was performed to obtain 3 order polynomial fittings for every combination of oceanic basins and regional specialized meteorological centers rsmcs which will be used to estimate maximum winds as a function of the central pressure eq 1 defines the pmin wmax empirical relationship employed for the wmo center and western pacific basin with central pressures in mbar and maximum wind speeds in knots 1 minute average winds which are converted to 10 minutes average winds by a factor of 0 93 according to harper et al 2010 1 w max 2 85 1 0 7 p min 3 8 56 1 0 5 p min 2 0 1089 p min 297 97 on the other hand the rmw is a determining factor along with the decaying rate of wind speed over the distance from the storm eye to calculate the tc vortex profile that defines the extent or domain subjected to more intense winds moreover irish et al 2008 showed that storm size must be considered when estimating surge generation in coastal areas to predict flood risk even though historically the famous saffir simpson scale has only provided a classification of damaging tcs intensity in terms of the central pressure and or the maximum sustained winds these two variables are generally available whereas there are limited observational measurements of the rmw by radar flights or satellites knaff et al 2014 which has only been provided by a few rsmcs since 2001 onwards thus only spanning for the last two decades due to the importance of this relevant variable there have been several efforts aimed at obtaining empirical regression functions either global knaff et al 2015 or by oceanic basins knaff et al 2007 tan and fang 2018 despite the uncertainty and complexity involved in its determination most estimations infer the rmw in terms of the central pressure the latitude and the maximum winds although there are no robust estimates as shown in previous studies in this study the estimation of knaff et al 2015 obtained from observed flight level tc winds will be employed to calculate the rmw along the storm track both for historical and synthetic tracks it is a function of intensity and latitude in line with several studies that documented the tendency for the rmw to become smaller with increasing intensity weatherford and gray 1988 kimball and mulekar 2004 and to become larger as the tc moves poleward mueller et al 2006 evidently the rmw estimate will have an effect and add on the uncertainty of spatial wind fields and consequently of wave simulations 3 5 numerical modeling the simulating waves nearshore swan booij et al 1996 third generation model version 41 31 is used to predict the wave action evolution in time and space with non stationary runs forced with large scale time varying parametric vortex type storm wind fields over the numerical domain which covers the circle influence area and extends to the outer boundaries 163 5º 178 5º e 0 5º 13 5º n fig 1a gray dashed line to capture the storm regional scale and time evolution over periods of a few days simulations are performed for the 500 selected parameterized tracks which are elongated from the parameterization circle area until reaching the domain boundaries the extended frame area provides enough computational time to warm up the model s cold start swan was run on a 15 km regular mesh and results were stored at spatially gridded nodes and at a control point located at the north of majuro the swan time step is 15 min and frequency space ranges from 0 03 to 1 hz discretized into 34 bins on a logarithmic scale the direction space is discretized into 72 sectors 5 for each sector simulations activate default white capping komen model quadruplets and triads the wind drag coefficient is capped c d 0 0025 since swan s default bulk wind input formulation wu 1982 may overestimate wind drag coefficients in very intense wind conditions due to tcs zijlema et al 2012 and the wind source term implementation is set to st6 rogers et al 2012 compared to climate forecast system reanalysis cfsr wind fields synthetic vortex wind fields may underestimate far field winds and wave generation by neglecting to consider larger scale meteorological conditions as shown in hoeke et al 2015 a qualitative validation of tcs ofa 1990 and paka 1997 vortex type winds found an agreement with maximum wind warnings issued by the joint typhoon warning center jtwc and the japan meteorological agency jma however the scope of this study does not include a sensitivity analysis on the wave model which remains an area for future research instead the focus of this study is the development of a hybrid methodology to replicate the outputs of a numerical model therefore the present study does not include a calibration and or validation of the wave numerical model against measurements of historical tcs which remains an area for future research fig 5 shows the model s input and output corresponding to the first 100 simulated cases the tc induced maximum synthetic vortex wind fields fig 5a and the mswh fields fig 5b namely the swath maps along the track simulation period these swath maps provide a representative measure of the track wind wave footprint maximum winds reach up to 60 m s near the storm eye for most intense storms and maximum waves are generated up to 14 8 m the combination of most intense and slow motion storms usually produces larger waves also the tc forward speed is considered to be the primary factor that contributes to the tc structural asymmetry sun et al 2019 which translates to wave asymmetry due to strong winds upon the right side of the heading direction in the north hemisphere during some time dependent on the forward speed which assimilates to a cumulative energy fetch the holland asymmetric model that was transcribed and implemented takes into account wind asymmetry while obtaining parameterized vortex type wind fields in fig 5a asymmetry can be observed in some cases where it is more noticeable for instance in the third to last case in the last row pink rectangle the tc is moving westwards and the extent of the maximum wind footprint is larger on the right side from the heading direction which is translated to a similar pattern in the wave simulations shown in fig 5b the analysis of the 500 output swath maps illustrates a consistent relationship between irregular spatial distribution of footprint with corresponding tc parameters where the forward speed exceeds the maximum sustained winds the vortex parameterization calculates the maximum storm wind speed at 10 m by subtracting the storm forward speed from the maximum wind speed therefore the formulation does not support storms moving faster than the maximum winds for this reason the mda selected cases are filtered to remove the anomalous and non representative output results 3 6 reconstruction the simulated swath maps of mswh represent the aggregated variable response which will be used to train the surrogate model first the pca technique is applied to the spatial swath maps projecting the original data on a new coordinate system space while aiming to preserve the maximum variance of the data in such way that new coordinates are sorted in a decreasing order this allows to reduce the dimensionality of the spatial fields by taking the first n components that explain the most variance and obtaining the most dominant spatial variability patterns empirical orthogonal functions eofs with its corresponding temporal coefficients principal components pcs therefore the original data x x c can be explained as a linear combination of eofs spatial variability and pcs case x x c e o f 1 x p c 1 c e o f 2 x p c 2 c e o f n x p c n c with n the dimension of the data grid points to neglect the initial model warm up period results only data within the subarea 166 176 e 2 12 n is kept the pca was applied to the standardized sub area swath maps with the original data s mean and standard deviation in order to remove the effect of dimension scales the first 4 modes from the pca analysis explain 92 18 of the variance 65 63 19 3 4 7 2 55 respectively fig 6 shows the results of the first 4 eofs at the target location multiplied by the standard deviation and its corresponding standardized pcs after several tests it was found that by selecting the first 50 eofs multiplied by the corresponding pcs we are able to predict the simulated swath maps as shown in fig 6 dashed box the spatial correlation of the track footprint is preserved and the maximum values are correctly estimated the pca technique allows to decompose the wave fields simulated with the mda sample tc parameters in terms of the most significant modes of oscillation or in this case wave features the linear composition of eofs and pcs are able to reconstruct the original data employed with pca the composition example shown in fig 6 shows the mswh response due to a storm track coming from the east heading wnw with an extended fetch on the right side since in the northern hemisphere tcs winds move counter clockwise the result is consistent with the corresponding tc parameters 960 mbar 34 3 km h gamma 104 5º delta 87 9º also regarding the swh footprint intensity which describes higher maximum values for cases with lower central pressures the effect of the mean forward velocity is translated in more intense swath maps when the ratio between the maximum winds and the mean forward velocity is close to one while very fast moving storms only reach moderate values of maximum swhs in those cases the storm moves faster than the group velocity and there is not enough fetch to reach fully developed sea conditions the concept of the extended fetch and how wave trains develop and travel through the tc varying wind field was recently implemented in kudryavtsev et al 2021 next step is to train the surrogate model with the subset of filtered simulated events and to estimate the prediction of any other parameterized storm track using rbfs this is a flexible non parametric technique used for constructing an approximated function based on the m simulated responses as it was successfully applied in previous studies camus et al 2011 gouldby et al 2014 rueda et al 2019 the general form of the rbfs comes as z x r b f x p x i 1 n a i φ x x i where z x is the surrogate model output swath maps of the non stationary aggregated output x is the vector of input parameters p m i n v m e a n δ γ that determine the track intensity and geometry and p x is formed by a number of monomial equal to the data dimension and a monomial of degree zero being b the vector of coefficients of these monomials therefore b i together with a i which are the coefficients of the rbfs are obtained based on the m simulated cases the rbfs are trained with the mswh for the first 50 pcs independently as this number yielded a good agreement between real and reconstructed swath maps moreover a k fold cross validation was performed to assess the statistical model prediction ability a 4 fold validation using the filtered cases from mda is shown in fig 7 in this case 400 cases are used to train the model and the plots show a comparison of the remaining reconstructed versus simulated mswh once the rbfs are fitted they can be used to transfer tc parameters with the corresponding swath map given that the parameters are within the limits of the trained parametric space the rbf interpolation technique was previously applied for point based waves propagation camus et al 2011 from a suitable sample of sea state parameters at a buoy and the corresponding propagated sea state parameters for instance in front of a coastal infrastructure it is possible to reconstruct the sea surface of any other given sea state by interpolating in the resulting surface from interpolating at the known response values similarly the rbf application for the spatial swath maps response due to a sample of tc parameters has proven to work reasonably well with m 500 this sample feeds the rbf with information of mswh consistent with each set of tc parameters which include a wide range of values of central pressure mean forward speed angle of entrance and angle of direction the accuracy of results highly depends on the quality of input swan simulations which have shown in the previous section to be able to capture features like the extended fetch and wave asymmetry 4 extreme value distribution extreme values of wave heights govern the design of safety regulations concerning flood risk management offshore platforms coastal structures among other fields of engineering thus it is important to understand and estimate the frequency intensity and severity of natural hazards rueda et al 2016 as well as the risk of extreme events that threat exposed coastal communities in low lying coastal areas to support long term policy decision making at long term scale the ev theory aims to quantify the behavior at unusually large values and to estimate the probability of events larger than any on record coles 2001 therefore it mainly deals with the first exceedance of a high level value expected to occur within the next n years namely the n year return value that is exceeded once every n years from the multiple methods derived from the ev analysis one classical method is the annual maxima based on the approximation of the distribution of independent and identically distributed random variables by a member of the generalized extreme value gev family of distribution functions haigh et al 2010 however the level of uncertainty stems from the quality and quantity of data used statistically longer records imply smaller errors and additionally the record should be long enough to encompass the range of variability in extremes serafin and ruggiero 2014 longer time series of available historical data usually cover no more than 50 years meaning that one generally needs to extrapolate well beyond the range of the available data and thus resort to ev analysis to obtain the required return value estimates caires 2011 in the present study for the determination of long return period estimates of mswh produced by tcs at a particular site we explore the use of large amounts of virtually independent synthetic events this approach enables to obtain estimates without the application of gev functions where longer return periods than available observational records imply extrapolation estimates and consequently the tail of the distribution carries larger inherent uncertainty instead the empirical distribution of annual maxima is calculated for modeling the extremes of both the historical and synthetic databases of reconstructed parameterized tracks for this purpose the series of mswh corresponding to each historical storm track at any given control point from the simulation domain are independent and identically distributed numerical observations x x 1 x 2 x n with n observations these discrete events are grouped by years in order to calculate the spatial annual maxima z z 1 z 2 z k with k years the historical period from season 1979 1980 onwards until 2021 spanning for 42 years is selected for statistical purposes since it is considered to be the modern era when geostationary satellite coverage is more widely available than in previous years therefore a total 22 storms that entered or crossed the circle area of influence around majuro thereby computing a mean occurrence rate of λ 0 52 storm tracks per year the empirical distribution function evaluated in the k th ordered annual maxima z k is f z k k m 1 and the corresponding return period t r z k 1 1 f z k is obtained in terms of the mean number of tcs per year and the probability of exceedance of sorted annual maxima the same procedure is applied to evaluate the empirical distribution function of the synthetic database however the 8773 stochastic events lack chronological time reference and according to the mean historical rate of occurrence λ 0 52 they account for 15 671 years of high fidelity simulated tracks thus in order to generate plausible events preserving the historical occurrence probabilities a poisson distribution with λ 0 52 is used to obtain the number of events per year n 1 n 2 n 15 500 for 15 500 years fig 8a then the series of n i events is populated by randomly extracting a reconstructed swath map from the synthetic database so that the annual maxima can then be calculated meaning at each grid node the maximum value of all available event per year is taken to determine the annual maxima whether multiple one or none events in the context of using monte carlo simulations of thousands of years the peak over threshold pot method can be used with the poisson gpd generalized pareto distribution model estimating frequencies and intensities which on the other hand is a method analog for threshold exceedances of the gev distribution for annual maxima coles 2001 meaning both methods are entirely consistent with one another above the gpd threshold in order to analyze the confidence interval of the synthetic reconstructed tcs the series of years have been split in 31 portions of 500 years each fig 8b shows the probability plot comparing the empirical distribution function resulting from the historical red dots and synthetic blue line reconstructed swath maps at the control point located in the north of majuro fig 1a it can be observed that the mean synthetic distribution and the 90 confidence intervals between the 5th and 95th percentiles mostly match the historical results and also are capable to extend to longer return periods since the mswh was reconstructed over a spatial domain it is possible to obtain the 31 series of 500 year annual maxima at all grid nodes moreover return plots are obtained by computing the q th percentile of the data along the case axis corresponding to the m year return values fig 8c and 8d show the spatial variability of the 20 year return plots 95 percentile for historical and synthetic reconstructed events the most noticeable difference is the effect of the scarce number of historical data which obtains less track footprints due to less populated calibration years while the synthetic output shows less spatial variability due to the large amount of storm data in the previous section it was demonstrated that the use of pca preserves spatial correlation the presented methodology is capable of obtaining spatially return period estimates without the need of fitting analytical distributions to the empirical distribution function at each point and thereby extrapolating extreme values for high return periods as an example fig 8e illustrates the 100 year return plot 99 percentile where mswh reaches up to 10 m in the northern area of the domain and 6 9 m at the control point moreover the proposed methodology can be further applied for regional downscaling simulations with increasing resolution at smaller areas closer to the target location 5 summary and discussion in tc prone areas it is important to acquire knowledge on the probability of occurrence of major tc induced storm surge and mswh as key tools for policy management here we aim to characterize low probability extreme events of regional mswh produced by tcs the proposed methodology is based on a the use of stochastic sample of high fidelity storm tracks b parameterization of tc tracks in terms of geometric kinematic and dynamic parameters to reduce dimensionality c mda selection of a reduced and representative subset of cases d use of vortex type parameterized winds for each storm track e non stationary runs of swan forced with time varying wind fields f the application of pca over the selected output cases swath maps and rbf interpolation of the first pcs to reconstruct any tc induced swath map and g the ev distribution based on synthetic reconstructed tcs the developed surrogate model provides a preliminary methodology that allows to obtain estimations of a computationally intensive physical process model using a hybrid approach that only simulates a reduced number of cases that are used to train the model which can reconstruct any given storm within the original parametric space the surrogate model is applied to one location in majuro atoll in the equatorial north west pacific exposed to an average of one tc every two years for the last four decades the storm parameterization allows to reduce the dimensionality of complex track geometries an assumption which is acceptable in tc prone areas that exhibit seldom convoluted or sinuous tracks results are also dependent on the use of the constant minimum central pressure along the track which ensures to yield the most adverse mswh the mda selection algorithm allows for an efficient low number of cases to be simulated to train the model and the k fold cross validation demonstrates the good skill of the surrogate model however to feed the pca good quality trained outputs are required in that sense the surrogate model s ability to reproduce simulated cases from the reconstructed pcs showed an evident improvement when the velocity criteria were applied to remove storms moving at absolute speeds higher than the maximum sustained winds overall this methodology reduces significant computational resources since only a limited number of cases need to be numerically simulated and the reconstruction calculations are not demanding at last regional estimates are provided however the methodology allows to further downscale waves by simulating high resolution nested meshes at nearshore domains that correctly solve the physical processes and consider the local effect of bathymetry at intermediate water levels the numerical skill of the methodology has been assessed based on k fold validation and the ev distribution comparisons although it is out of scope of this paper the swan model validations could be addressed in the future with available altimeter data hytcwaves provides new means to gain insight on the upper tail of extreme distribution functions by using a large sample of synthetic storm tracks high fidelity tracks developed by nakajo et al 2014 have been used in this study however other synthetic databases can be used in the future or a combination of them to evaluate global differences moreover it is possible to include a disturbance factor on the storm intensity and or frequency to account for climate change scenarios mori and takemi 2015 additionally this study has focused on simplified storm track events however there is room to evaluate more complex parameterizations in the future that allow for close to real representation of tracks i e temporal variability of tc intensity distance weighted storm selection also it is recommended to further examine sensitivity analysis on several steps of the methodology a optimization of the minimum number of selection cases needed b effect on introducing a weighted distance in the mda selection algorithm to obtain more tracks near the target location less tangent tracks far away c effect on different selection algorithms d size of the influence circle area and e number of pcs trained for interpolation as described in previous sections the methodology implements certain assumptions which derive in some limitations the user should take into consideration the storm track parameterization provides a close to real representation of quasi straight tracks while convoluted tracks would be poorly represented as well as the hazards produced by such events moreover the applicability is restricted to tc induced waves produced in the regional vicinity of the study area defined by a 4 degrees radius in the present study although a sensitivity analysis of the radius size is recommended in future research additionally the present study does not include a calibration and or validation of the wave numerical model against measurements of historical tcs which still remains an area for future research instead the focus of this study was addressed towards the development of a hybrid methodology that replicates the outputs of a numerical model in summary the proposed methodology has the ability of coupling numerical modeling data mining and statistical tools to obtain a cost effective approach for producing a large database of maximum swath maps induced by tcs we expect this preliminary methodology will be useful to end users as a first approximation of regional ev distribution of mswh induced by tcs credit authorship contribution statement sara o van vloten conceptualization methodology software validation writing original draft visualization laura cagigal supervision writing review editing ana rueda supervision writing review editing nicolás ripoll software writing review editing fernando j méndez conceptualization methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work has been partially funded by the beach4cast pid2019 107053rb i00 project granted by the spanish ministry of science and innovation ar acknowledge the funding from juan de la cierva incorporación ijc2020 043907 i mcin aei 10 13039 501100011033 and nextgenerationeu prtr 
23820,populated coastlines influenced by tropical cyclone tc prone areas call for flood risk hazard assessments including knowledge on the probability of occurrence of major tc induced significant wave heights due to the scarcity of tc historical records extreme value analyses often rely on fitting generalized extreme value distribution functions to extrapolate longer return periods this paper describes a methodology that allows to obtain deterministic estimations of the tail probability distribution using long collections of high fidelity tracks that reproduce similar historical diversity and frequency trends given the large dimensionality of the problem spatiotemporal variability of track geometry and intensity we implement a track parameterization to easily identify storms in a parametric space a hybrid approach significantly reduces computational resources by enabling to narrow the number of non stationary numerically simulated cases forced with vortex type wind fields parameterized using the holland dynamic model the proposed surrogate model hytcwaves is trained with a selected subset of maximum significant wave height mswh spatial fields to which a principal component analysis and interpolation functions are performed results show a useful approximation of spatial based regional extreme value distribution of mswh induced by tcs the proposed model is applied to the target location of majuro atoll keywords tropical cyclone hybrid downscaling surrogate model vortex type winds extreme value distribution 1 introduction tropical cyclones tcs also known as typhoons or hurricanes are among the world s most destructive natural disasters bringing strong winds heavy rainfall large waves and storm surges that devastate property and cause loss of life e g chu and wang 1998 diamond et al 2012 stephens and ramsay 2014 substantial research has been directed to assess the wide range of hazards mori and takemi 2015 puotinen et al 2016 young 2017 cagigal et al 2022 and damaging impacts emanuel 2020 ye et al 2020 sajjad and chan 2020 over increasingly populated coastlines affected by the passage of tcs including the potential catalyst effect of compound events i e with king tides leonard et al 2014 fakhruddin et al 2022 moreover policy makers responsible for flood risk management and coastal defense infrastructures generally require probabilistic analysis that provide the design wave height for standard return periods 100 year or even higher for instance the 1000 year return values used by the united kingdom for coastal flood boundary conditions environment agency 2018 the extreme value ev theory seeks to assess the probability of events that are more extreme than any previously observed return values for wind and waves are fundamental to assessing the risks associated with human activities but their computation is complicated by the paucity of observational records breivik et al 2014 particularly when dealing with tcs only short collections of historical data that span for less than five decades can be gathered at a certain target location therefore long return values can only be extrapolated well beyond the range of available data caires 2011 with the common use of generalized ev distribution fittings however long return period estimates carry a great deal of uncertainty here we aim to address this issue by using high fidelity storm tracks namely synthetic storms which allow to generate large samples of thousands of tracks while preserving historical probability distribution functions of tc parameters and temporal correlation nevertheless dealing with huge amounts of tracks would mean very intensive computational demand to characterize wave climate using numerical simulation of wave propagation processes alternatively past studies have accounted for successful applications of hybrid downscaling methods camus et al 2011 2013 antolínez et al 2018 anderson et al 2021 ricondo et al submitted that combine dynamical simulations with statistical techniques allowing to interpolate the dynamical response of a dataset based on a reduced number of simulated output cases given that such subset is selected ensuring that it is well distributed and explores the full dimensional space we incorporate the use of a surrogate predictive model trained with precomputed waves based on high fidelity simulations offering satisfactory accuracy and enhanced computational efficiency smith et al 2015 past studies have already established advancements for the application of surrogate modeling techniques for storm surge prediction jia et al 2016 although to our knowledge this is the first attempt to predict spatial distribution of maximum tc induced waves moreover principal component analysis pca is integrated as a dimension reduction technique to enhance computational efficiency the focus of the current study is to implement and evaluate the skills of the preliminary proposed methodology to assess the ev distribution of maximum significant wave height mswh due to tcs in a target domain both the study site and the data used are presented in section 2 the subsequent steps of the proposed methodology are explained in section 3 while the ev distribution and the obtained results are shown in section 4 followed by summary and discussion in section 5 2 application area and data 2 1 study site the methodology presented in this paper can be applied to coastal areas surrounded by open waters and subjected to tc activity here we have chosen the area of majuro the capital of the republic of the marshall islands to apply hytcwaves these archipelagic islands are located in the north west equatorial pacific fig 1a particularly at the east of the most active concentration of tcs in the western tropical pacific basin which is located between the philippines and guam camargo et al 2007 majuro is an atoll formed by many little low lying islands which make them extremely prone to storm surge induced flooding due to tcs the area of influence of the study site is moderately exposed to tcs with a mean annual rate of 0 6 events year for the last 60 years according to historical records knapp et al 2018 however devastating events were documented by spennemann 1996 with a storm surge that washed the entire southern part of majuro typhoons in 1905 1908 as well as severe inundations due to tc alice 1979 moreover ford et al 2018 compiled damaging impacts due to more recent tcs pamela 1982 roy 1988 axel 1992 gay 1992 paka 1997 2 2 bathymetry in this study the bathymetry resulted from a combination between the gebco general bathymetric charts of the ocean http www gebco net global bathymetric dataset and a high resolution nearshore bathymetry dataset available for majuro atoll fig 1a the gebco s gridded bathymetric dataset gebco 2019 grid is a global terrain model for ocean and land providing elevation data on a 15 arc second interval grid equivalent to 450 m spatial resolution however this global dataset lacks resolution for the low lying islands of the study site for that reason a topobathymetric digital elevation model for the majuro atoll was developed by the u s geological survey usgs https www usgs gov in collaboration with the u s department of interior doi pacific islands climate science centre pi csc in order to support the modeling of storm and tide induced flooding its grid spacing is 1 m and it includes the majuro atoll and extends offshore to a depth of at least 71 m https doi org 10 5066 f7416vxx 2 3 tropical cyclone databases the tc input data is collected from two storm track databases a historical database the ibtracs v04r00 database international best track archive for climate stewardship knapp et al 2018 compiles global available records of historical storm tracks from 1851 onwards and it combines track and intensity estimates from several observational sources knapp et al 2010 ibtracs includes the track location longitude and latitude the sea level pressure and the maximum wind speed mws at six hour intervals in this study we have used the world meteorological organization wmo dataset which provides the official pressure and wind speed data reported by the responsible agency at every location in this case the rsmc tokyo which is operated by the japanese meteorological agency jma b synthetic database for the purpose of this study high fidelity tracks generated by nakajo et al 2014 are employed to demonstrate the application of the proposed methodology however other synthetic databases e g emanuel et al 2008 bloemendaal et al 2020 nederhoff et al 2021 or a combination of several databases could be selected instead these synthetic tracks from a global stochastic model are sensitive to the joint probability distribution functions of tc parameters such as the track sea level pressure and forward speed as well as temporal correlations thereby reproducing the frequency of tcs and diversity of track geometry synthetic tracks include information of the longitude latitude time and sea level pressure in this study an area of influence to evaluate tcs induced waves is established as a 4 degrees radius circle centered in majuro atoll 450 km radius then a subset of storm tracks that enter and or cross the circle area is extracted from both historical and synthetic tc databases figs 1b and 1c respectively with 37 historical storm tracks during the period from 1951 until 2021 and 10 064 synthetic storm tracks this large subset overcomes the shortage of historical events for this particular region in order to illustrate the tcs intensity in figs 1b and 1c the track line color indicates the tc category 5 4 3 2 1 corresponding with minimum central pressures lower than 920 944 964 979 1000 mbar respectively while category 0 accounts for tropical storms with central pressures higher than 1000 mbar while the historical subset intensities range between lower categories 0 2 the synthetic subset intensities include all categories 0 5 3 methodology 3 1 overview the proposed methodology aims to estimate the wave climate ev distribution induced by tcs in the atoll of majuro and its immediate surroundings a standard approach would perform a dynamical downscaling of historical events that crossed or occurred near majuro simulated with hindcast wind fields forcing to conduct an ev analysis fitting to characterize the tail distribution of extreme significant wave heights at particular locations however this approach is very limited to the number of occurrences as tcs are scarce phenomena both in time and space moreover the available and statistically representative period of historical records is too short when the interest is to characterize the ev distribution for return periods of 100 years or more meaning that estimates must be extrapolated with a high degree of uncertainty alternatively a hybrid approach is proposed in order to overcome those limitations on one hand high fidelity tracks are employed to significantly populate the sample of historical storm tracks being accountable for thousands of years so that the tail distribution needs no extrapolation on the other hand a surrogate model is proposed to unload the number of dynamical simulations as it is impracticable to numerically simulate thousands of events moreover the hybrid approach includes the use of statistical and clustering techniques that allow to reduce the computational resources demand regarding the generation of high fidelity tracks the approach used by nakajo et al 2014 basically employs a stochastic downscaling method based on monte carlo simulations for a sequential development of tcs calculated statistically from given statistical parameters of tc data therefore artificial tracks are sensitive to the approximations of joint probability distribution functions by using principal component analysis of several tc parameters and temporal correlations fig 2 illustrates the flow chart of the hytcwaves methodology which is composed of the following steps a a stochastic sample of historical and synthetic database events is collected and extracted for a 4 degrees radius circle area of influence b storm tracks are parameterized in terms of a reduced number of variables which characterize its main attributes while reducing the dimensionality of the problem c a selection method is used to generate a subset that preserves tc diversity for a given target location d tc induced waves are obtained by running dynamic non stationary simulations forced with parameterized time varying vortex type wind fields for each storm track e the spatial wave conditions for the remaining non simulated database tracks are reconstructed using pca coupled with an interpolation technique based on radial basis functions rbfs and f calculation of the ev distribution the shaded text boxes fig 2 right column correspond to the standard dynamical downscaling approach the following sections describe in detail the methodology steps and present the results obtained for the study site as an example of its applicability 3 2 track parameterization the fundamental idea of surrogate based models is to build a predictive model that is computationally efficient and capable of approximating the value of a function goldstein et al 2019 anderson et al 2021 the standard approach includes a learning phase with training examples of past events linking the design parameters and its corresponding time varying dynamical response therefore a set of input parameters must be defined to train the surrogate model the choice of such parameters in this case is conditioned by the following criteria a parameters must be available from the storm track database and b parameters must be representative of the track geometry and intensity the tc database composed of both historical and synthetic tracks have three common variables longitude latitude location of the storm eye and central pressure besides the forward speed can be derived from successive storm coordinates the parametric space aims to explore the diversity of events and to represent each storm by a low dimensional vector for that purpose a simplification of the track geometry within the influence area of 4 degrees radius around majuro is proposed fig 3 in order to reduce its dimensionality into a small number of variables given by the following geometric kinematic and dynamic parameters which constitute the surrogate model predictor inputs a delta δ azimuth of the storm entrance point in the circle influence area b gamma γ azimuth of the mean direction within the circle using the entrance and exit coordinates c p m i n minimum central pressure along the storm track coordinates within the circle and d v m e a n mean forward speed within the circle fig 3 left column illustrates the comparison sketch of a real track geometry versus an approximated track with the ad hoc parameters the hypothesis of constraining the track morphology with a constant forward direction meaning a straight track simplifies the intrinsic complexity and it allows to represent storm events in a 4 dimensional parametric space the neglected discrepancies are generally small within the local area of influence since real and synthetic storms show seldom sinusoidal tracks fig 3 upper row however this assumption may limit its applicability in target areas where tracks may be generally more erratic recurving and convoluted as reported in past review papers terry and feng 2010 sharma et al 2020 a second hypothesis implies that storm intensity is constant along a whole event within the influence area and the minimum value is set to account for the most adverse possible events moreover the impacts over majuro will largely depend on the intensity the rmw v mean and the minimum distance from land all the extracted tcs from historical and synthetic databases for the influence area around majuro are parameterized and its results are shown in fig 3 where real versus parameterized tracks can be compared for both historical and synthetic tracks it can be noticed the straightening effect between the circle s entrance and exit coordinates and the low ratio of quasi straight and sinuous tracks here a 4 degrees radius was established as a balance between accounting for a large enough influence area and ensuring that the simplification of sinuous tracks into straight storms remains a good representation of the tc characteristics this means that the size of the influence area may be tuned for each location taking into consideration the tc characteristics i e smaller area if convoluted tracks are likely to occur or larger if tracks are generally quasi straight also a future line of research could be to perform sensitivity tests on the radius size to the ev analysis it should be noted that a limitation of this preliminary methodology does not account for potential extreme events produced by tc induced distant swells generated outside the 4 degrees influence area the current applicability of the proposed method is restricted to tc induced waves produced in the study area regional vicinity 3 3 selection the synthetic dataset extracted for the target study site is composed of 10 064 tracks and the tc track parameters can be visually analyzed with a multi scatter plot fig 4a where each dot represents a storm track when comparing the historical purple and synthetic gray dots it can be seen that synthetic tracks explore the parametric space while spanning over the historical data limits partly because recorded events are very scarce in number however some criteria need to be established to remove tc parameters that are not physically plausible or that excessively surmount historical parameters 1 the minimum central pressure lower limit is set to 860 mbar corresponding to the minimum historical record plus 1 margin 2 the mean forward speed upper limit is established by the 99 percentile of historical values plus 5 km h margin 3 the azimuth angle δ upper limit is 270 degrees since historical tracks are not statistically arriving from the north west at the target area in the north west equatorial pacific and 4 the entrance angle γ lower limit is 40 degrees to remove noticeable synthetic outliers it should be noted that establishing the filter criteria and the removal of tc parameter outliers is fully dependent on the available historical data within the influence area at the study site fig 4b illustrates the filtered database gray dots resulting from applying these criteria which renders 8773 synthetic tracks the updated storm dataset of historical and filtered synthetic tracks for the target study site is composed of 8810 events a number too large to dynamically downscale as it would be very computationally demanding instead a selection algorithm can be used to determine the subset to eventually train the surrogate model in this case the maximum dissimilarity algorithm mda as proposed by camus et al 2011 to downscale wave climate to coastal areas has been used this mathematical tool is used to obtain a reduced number of cases that cover the track variability and guarantee that all possible combinations of track characteristics are represented with a special emphasis on the boundary events of the multivariate parametric space the dataset can be defined as x i p m i n v m e a n δ γ i with i 1 n the total number of tracks the scalar and directional variables are previously normalized so that the mda algorithm is applied over a non dimensional space where the target subset of m vectors is initialized by selecting the vector for which its dissimilitude is the largest out of the sample the remaining m 1 vectors are selected iteratively by calculating at each iteration the vector which maximizes the dissimilitude in respect to the vectors added to the subset until a number of m vectors are selected this selection method has the advantage of allowing an easy iterative analysis of results with incrementing selection sample numbers as a deterministic tool that further calculates dissimilitude distances with the remaining dataset points fig 4b shows the multivariate distribution of the mda subset m 500 in the four dimensional parametric space noting that boundary data is included in the selection the colored dots depict the order in which data points are selected by applying the mda algorithm to successive badges of 100 intervals black red orange yellow green fig 4c illustrates the corresponding parameterized tracks for successive selection samples m 100 200 300 400 500 it is noted that already in the first 100 badge the selected tracks are well distributed in terms of both angles and intensities if compared with the historical parameterized tracks fig 3 lower middle the selection includes more intense events as expected due to having incorporated synthetic tracks in the dataset sample the choice on the selection number is partly subordinated to the simulation computing time camus et al 2011 analyzed the sensitivity effect of the selection number for hybrid model applied to wave propagations and observed that for higher than m 200 the decrease of the error was negligible however since the current application in this study involves a higher level of complexity as we aim to characterize a spatial based reconstruction and the multivariate problem has more degrees of freedom we have chosen m 500 it seems reasonable in terms of computation and to explore well enough the parametric space fig 4d shows the comparative histograms of probability density distribution for the four tc parameters and the historical red the synthetic filtered blue datasets and the mda yellow subset it can be noticed that the synthetic filtered dataset exhibits a certain shift of probability distribution to the lower and upper tails for the minimum central pressure and mean forward speed distributions respectively consistent with the limiting filtering criteria that was applied over synthetic tracks both synthetic angles exhibit a normal probability distribution within the bound limits of historical data these results account for a synthetic dataset that explores more intense and severe tcs than the historical event records that will likely account for extreme events the probability density distribution of the mda subset shows a general agreement with the dataset despite showing a higher frequency of lower central pressures and fast moving storms 3 4 vortex type winds parameterization once the selected sample of 500 parameterized straightened tracks has been defined the corresponding time varying wind fields need to be estimated in order to feed the wave numerical model here a wind parametric model is employed with the advantage of using a small number of input variables ruiz salcines et al 2019 evaluated and compared six well known parametric wind models and concluded that when dealing with a large number of events the choice of a particular model does not guarantee greater accuracy the dynamic holland model is based on the vortex type model developed by holland 1980 2008 to provide estimates of maximum winds using an analytic model of the sea level pressure and wind profiles however the original model was parameterized to fit the tc instantaneous gradient wind level rather than the winds at surface level of a moving and dynamically developing tc to overcome this a modified model was developed by fleming et al 2008 to account for the dynamic changes of the tc parameters along the track the dynamic holland model estimates the spatial distribution of sea surface wind fields in terms of the following variables 1 the forward speed 2 the maximum wind speed at 10 m with a 1 minute sampling interval 3 the rmw and 4 the central pressure however as it was described the synthetic storm track database does not inform either about the maximum winds or the rmw therefore these variables must be estimated on one hand the ibtracs storm data provides maximum winds and the resulting empirical relationship between central pressure and maximum winds depicts a significant correlation not shown therefore a regression model was performed to obtain 3 order polynomial fittings for every combination of oceanic basins and regional specialized meteorological centers rsmcs which will be used to estimate maximum winds as a function of the central pressure eq 1 defines the pmin wmax empirical relationship employed for the wmo center and western pacific basin with central pressures in mbar and maximum wind speeds in knots 1 minute average winds which are converted to 10 minutes average winds by a factor of 0 93 according to harper et al 2010 1 w max 2 85 1 0 7 p min 3 8 56 1 0 5 p min 2 0 1089 p min 297 97 on the other hand the rmw is a determining factor along with the decaying rate of wind speed over the distance from the storm eye to calculate the tc vortex profile that defines the extent or domain subjected to more intense winds moreover irish et al 2008 showed that storm size must be considered when estimating surge generation in coastal areas to predict flood risk even though historically the famous saffir simpson scale has only provided a classification of damaging tcs intensity in terms of the central pressure and or the maximum sustained winds these two variables are generally available whereas there are limited observational measurements of the rmw by radar flights or satellites knaff et al 2014 which has only been provided by a few rsmcs since 2001 onwards thus only spanning for the last two decades due to the importance of this relevant variable there have been several efforts aimed at obtaining empirical regression functions either global knaff et al 2015 or by oceanic basins knaff et al 2007 tan and fang 2018 despite the uncertainty and complexity involved in its determination most estimations infer the rmw in terms of the central pressure the latitude and the maximum winds although there are no robust estimates as shown in previous studies in this study the estimation of knaff et al 2015 obtained from observed flight level tc winds will be employed to calculate the rmw along the storm track both for historical and synthetic tracks it is a function of intensity and latitude in line with several studies that documented the tendency for the rmw to become smaller with increasing intensity weatherford and gray 1988 kimball and mulekar 2004 and to become larger as the tc moves poleward mueller et al 2006 evidently the rmw estimate will have an effect and add on the uncertainty of spatial wind fields and consequently of wave simulations 3 5 numerical modeling the simulating waves nearshore swan booij et al 1996 third generation model version 41 31 is used to predict the wave action evolution in time and space with non stationary runs forced with large scale time varying parametric vortex type storm wind fields over the numerical domain which covers the circle influence area and extends to the outer boundaries 163 5º 178 5º e 0 5º 13 5º n fig 1a gray dashed line to capture the storm regional scale and time evolution over periods of a few days simulations are performed for the 500 selected parameterized tracks which are elongated from the parameterization circle area until reaching the domain boundaries the extended frame area provides enough computational time to warm up the model s cold start swan was run on a 15 km regular mesh and results were stored at spatially gridded nodes and at a control point located at the north of majuro the swan time step is 15 min and frequency space ranges from 0 03 to 1 hz discretized into 34 bins on a logarithmic scale the direction space is discretized into 72 sectors 5 for each sector simulations activate default white capping komen model quadruplets and triads the wind drag coefficient is capped c d 0 0025 since swan s default bulk wind input formulation wu 1982 may overestimate wind drag coefficients in very intense wind conditions due to tcs zijlema et al 2012 and the wind source term implementation is set to st6 rogers et al 2012 compared to climate forecast system reanalysis cfsr wind fields synthetic vortex wind fields may underestimate far field winds and wave generation by neglecting to consider larger scale meteorological conditions as shown in hoeke et al 2015 a qualitative validation of tcs ofa 1990 and paka 1997 vortex type winds found an agreement with maximum wind warnings issued by the joint typhoon warning center jtwc and the japan meteorological agency jma however the scope of this study does not include a sensitivity analysis on the wave model which remains an area for future research instead the focus of this study is the development of a hybrid methodology to replicate the outputs of a numerical model therefore the present study does not include a calibration and or validation of the wave numerical model against measurements of historical tcs which remains an area for future research fig 5 shows the model s input and output corresponding to the first 100 simulated cases the tc induced maximum synthetic vortex wind fields fig 5a and the mswh fields fig 5b namely the swath maps along the track simulation period these swath maps provide a representative measure of the track wind wave footprint maximum winds reach up to 60 m s near the storm eye for most intense storms and maximum waves are generated up to 14 8 m the combination of most intense and slow motion storms usually produces larger waves also the tc forward speed is considered to be the primary factor that contributes to the tc structural asymmetry sun et al 2019 which translates to wave asymmetry due to strong winds upon the right side of the heading direction in the north hemisphere during some time dependent on the forward speed which assimilates to a cumulative energy fetch the holland asymmetric model that was transcribed and implemented takes into account wind asymmetry while obtaining parameterized vortex type wind fields in fig 5a asymmetry can be observed in some cases where it is more noticeable for instance in the third to last case in the last row pink rectangle the tc is moving westwards and the extent of the maximum wind footprint is larger on the right side from the heading direction which is translated to a similar pattern in the wave simulations shown in fig 5b the analysis of the 500 output swath maps illustrates a consistent relationship between irregular spatial distribution of footprint with corresponding tc parameters where the forward speed exceeds the maximum sustained winds the vortex parameterization calculates the maximum storm wind speed at 10 m by subtracting the storm forward speed from the maximum wind speed therefore the formulation does not support storms moving faster than the maximum winds for this reason the mda selected cases are filtered to remove the anomalous and non representative output results 3 6 reconstruction the simulated swath maps of mswh represent the aggregated variable response which will be used to train the surrogate model first the pca technique is applied to the spatial swath maps projecting the original data on a new coordinate system space while aiming to preserve the maximum variance of the data in such way that new coordinates are sorted in a decreasing order this allows to reduce the dimensionality of the spatial fields by taking the first n components that explain the most variance and obtaining the most dominant spatial variability patterns empirical orthogonal functions eofs with its corresponding temporal coefficients principal components pcs therefore the original data x x c can be explained as a linear combination of eofs spatial variability and pcs case x x c e o f 1 x p c 1 c e o f 2 x p c 2 c e o f n x p c n c with n the dimension of the data grid points to neglect the initial model warm up period results only data within the subarea 166 176 e 2 12 n is kept the pca was applied to the standardized sub area swath maps with the original data s mean and standard deviation in order to remove the effect of dimension scales the first 4 modes from the pca analysis explain 92 18 of the variance 65 63 19 3 4 7 2 55 respectively fig 6 shows the results of the first 4 eofs at the target location multiplied by the standard deviation and its corresponding standardized pcs after several tests it was found that by selecting the first 50 eofs multiplied by the corresponding pcs we are able to predict the simulated swath maps as shown in fig 6 dashed box the spatial correlation of the track footprint is preserved and the maximum values are correctly estimated the pca technique allows to decompose the wave fields simulated with the mda sample tc parameters in terms of the most significant modes of oscillation or in this case wave features the linear composition of eofs and pcs are able to reconstruct the original data employed with pca the composition example shown in fig 6 shows the mswh response due to a storm track coming from the east heading wnw with an extended fetch on the right side since in the northern hemisphere tcs winds move counter clockwise the result is consistent with the corresponding tc parameters 960 mbar 34 3 km h gamma 104 5º delta 87 9º also regarding the swh footprint intensity which describes higher maximum values for cases with lower central pressures the effect of the mean forward velocity is translated in more intense swath maps when the ratio between the maximum winds and the mean forward velocity is close to one while very fast moving storms only reach moderate values of maximum swhs in those cases the storm moves faster than the group velocity and there is not enough fetch to reach fully developed sea conditions the concept of the extended fetch and how wave trains develop and travel through the tc varying wind field was recently implemented in kudryavtsev et al 2021 next step is to train the surrogate model with the subset of filtered simulated events and to estimate the prediction of any other parameterized storm track using rbfs this is a flexible non parametric technique used for constructing an approximated function based on the m simulated responses as it was successfully applied in previous studies camus et al 2011 gouldby et al 2014 rueda et al 2019 the general form of the rbfs comes as z x r b f x p x i 1 n a i φ x x i where z x is the surrogate model output swath maps of the non stationary aggregated output x is the vector of input parameters p m i n v m e a n δ γ that determine the track intensity and geometry and p x is formed by a number of monomial equal to the data dimension and a monomial of degree zero being b the vector of coefficients of these monomials therefore b i together with a i which are the coefficients of the rbfs are obtained based on the m simulated cases the rbfs are trained with the mswh for the first 50 pcs independently as this number yielded a good agreement between real and reconstructed swath maps moreover a k fold cross validation was performed to assess the statistical model prediction ability a 4 fold validation using the filtered cases from mda is shown in fig 7 in this case 400 cases are used to train the model and the plots show a comparison of the remaining reconstructed versus simulated mswh once the rbfs are fitted they can be used to transfer tc parameters with the corresponding swath map given that the parameters are within the limits of the trained parametric space the rbf interpolation technique was previously applied for point based waves propagation camus et al 2011 from a suitable sample of sea state parameters at a buoy and the corresponding propagated sea state parameters for instance in front of a coastal infrastructure it is possible to reconstruct the sea surface of any other given sea state by interpolating in the resulting surface from interpolating at the known response values similarly the rbf application for the spatial swath maps response due to a sample of tc parameters has proven to work reasonably well with m 500 this sample feeds the rbf with information of mswh consistent with each set of tc parameters which include a wide range of values of central pressure mean forward speed angle of entrance and angle of direction the accuracy of results highly depends on the quality of input swan simulations which have shown in the previous section to be able to capture features like the extended fetch and wave asymmetry 4 extreme value distribution extreme values of wave heights govern the design of safety regulations concerning flood risk management offshore platforms coastal structures among other fields of engineering thus it is important to understand and estimate the frequency intensity and severity of natural hazards rueda et al 2016 as well as the risk of extreme events that threat exposed coastal communities in low lying coastal areas to support long term policy decision making at long term scale the ev theory aims to quantify the behavior at unusually large values and to estimate the probability of events larger than any on record coles 2001 therefore it mainly deals with the first exceedance of a high level value expected to occur within the next n years namely the n year return value that is exceeded once every n years from the multiple methods derived from the ev analysis one classical method is the annual maxima based on the approximation of the distribution of independent and identically distributed random variables by a member of the generalized extreme value gev family of distribution functions haigh et al 2010 however the level of uncertainty stems from the quality and quantity of data used statistically longer records imply smaller errors and additionally the record should be long enough to encompass the range of variability in extremes serafin and ruggiero 2014 longer time series of available historical data usually cover no more than 50 years meaning that one generally needs to extrapolate well beyond the range of the available data and thus resort to ev analysis to obtain the required return value estimates caires 2011 in the present study for the determination of long return period estimates of mswh produced by tcs at a particular site we explore the use of large amounts of virtually independent synthetic events this approach enables to obtain estimates without the application of gev functions where longer return periods than available observational records imply extrapolation estimates and consequently the tail of the distribution carries larger inherent uncertainty instead the empirical distribution of annual maxima is calculated for modeling the extremes of both the historical and synthetic databases of reconstructed parameterized tracks for this purpose the series of mswh corresponding to each historical storm track at any given control point from the simulation domain are independent and identically distributed numerical observations x x 1 x 2 x n with n observations these discrete events are grouped by years in order to calculate the spatial annual maxima z z 1 z 2 z k with k years the historical period from season 1979 1980 onwards until 2021 spanning for 42 years is selected for statistical purposes since it is considered to be the modern era when geostationary satellite coverage is more widely available than in previous years therefore a total 22 storms that entered or crossed the circle area of influence around majuro thereby computing a mean occurrence rate of λ 0 52 storm tracks per year the empirical distribution function evaluated in the k th ordered annual maxima z k is f z k k m 1 and the corresponding return period t r z k 1 1 f z k is obtained in terms of the mean number of tcs per year and the probability of exceedance of sorted annual maxima the same procedure is applied to evaluate the empirical distribution function of the synthetic database however the 8773 stochastic events lack chronological time reference and according to the mean historical rate of occurrence λ 0 52 they account for 15 671 years of high fidelity simulated tracks thus in order to generate plausible events preserving the historical occurrence probabilities a poisson distribution with λ 0 52 is used to obtain the number of events per year n 1 n 2 n 15 500 for 15 500 years fig 8a then the series of n i events is populated by randomly extracting a reconstructed swath map from the synthetic database so that the annual maxima can then be calculated meaning at each grid node the maximum value of all available event per year is taken to determine the annual maxima whether multiple one or none events in the context of using monte carlo simulations of thousands of years the peak over threshold pot method can be used with the poisson gpd generalized pareto distribution model estimating frequencies and intensities which on the other hand is a method analog for threshold exceedances of the gev distribution for annual maxima coles 2001 meaning both methods are entirely consistent with one another above the gpd threshold in order to analyze the confidence interval of the synthetic reconstructed tcs the series of years have been split in 31 portions of 500 years each fig 8b shows the probability plot comparing the empirical distribution function resulting from the historical red dots and synthetic blue line reconstructed swath maps at the control point located in the north of majuro fig 1a it can be observed that the mean synthetic distribution and the 90 confidence intervals between the 5th and 95th percentiles mostly match the historical results and also are capable to extend to longer return periods since the mswh was reconstructed over a spatial domain it is possible to obtain the 31 series of 500 year annual maxima at all grid nodes moreover return plots are obtained by computing the q th percentile of the data along the case axis corresponding to the m year return values fig 8c and 8d show the spatial variability of the 20 year return plots 95 percentile for historical and synthetic reconstructed events the most noticeable difference is the effect of the scarce number of historical data which obtains less track footprints due to less populated calibration years while the synthetic output shows less spatial variability due to the large amount of storm data in the previous section it was demonstrated that the use of pca preserves spatial correlation the presented methodology is capable of obtaining spatially return period estimates without the need of fitting analytical distributions to the empirical distribution function at each point and thereby extrapolating extreme values for high return periods as an example fig 8e illustrates the 100 year return plot 99 percentile where mswh reaches up to 10 m in the northern area of the domain and 6 9 m at the control point moreover the proposed methodology can be further applied for regional downscaling simulations with increasing resolution at smaller areas closer to the target location 5 summary and discussion in tc prone areas it is important to acquire knowledge on the probability of occurrence of major tc induced storm surge and mswh as key tools for policy management here we aim to characterize low probability extreme events of regional mswh produced by tcs the proposed methodology is based on a the use of stochastic sample of high fidelity storm tracks b parameterization of tc tracks in terms of geometric kinematic and dynamic parameters to reduce dimensionality c mda selection of a reduced and representative subset of cases d use of vortex type parameterized winds for each storm track e non stationary runs of swan forced with time varying wind fields f the application of pca over the selected output cases swath maps and rbf interpolation of the first pcs to reconstruct any tc induced swath map and g the ev distribution based on synthetic reconstructed tcs the developed surrogate model provides a preliminary methodology that allows to obtain estimations of a computationally intensive physical process model using a hybrid approach that only simulates a reduced number of cases that are used to train the model which can reconstruct any given storm within the original parametric space the surrogate model is applied to one location in majuro atoll in the equatorial north west pacific exposed to an average of one tc every two years for the last four decades the storm parameterization allows to reduce the dimensionality of complex track geometries an assumption which is acceptable in tc prone areas that exhibit seldom convoluted or sinuous tracks results are also dependent on the use of the constant minimum central pressure along the track which ensures to yield the most adverse mswh the mda selection algorithm allows for an efficient low number of cases to be simulated to train the model and the k fold cross validation demonstrates the good skill of the surrogate model however to feed the pca good quality trained outputs are required in that sense the surrogate model s ability to reproduce simulated cases from the reconstructed pcs showed an evident improvement when the velocity criteria were applied to remove storms moving at absolute speeds higher than the maximum sustained winds overall this methodology reduces significant computational resources since only a limited number of cases need to be numerically simulated and the reconstruction calculations are not demanding at last regional estimates are provided however the methodology allows to further downscale waves by simulating high resolution nested meshes at nearshore domains that correctly solve the physical processes and consider the local effect of bathymetry at intermediate water levels the numerical skill of the methodology has been assessed based on k fold validation and the ev distribution comparisons although it is out of scope of this paper the swan model validations could be addressed in the future with available altimeter data hytcwaves provides new means to gain insight on the upper tail of extreme distribution functions by using a large sample of synthetic storm tracks high fidelity tracks developed by nakajo et al 2014 have been used in this study however other synthetic databases can be used in the future or a combination of them to evaluate global differences moreover it is possible to include a disturbance factor on the storm intensity and or frequency to account for climate change scenarios mori and takemi 2015 additionally this study has focused on simplified storm track events however there is room to evaluate more complex parameterizations in the future that allow for close to real representation of tracks i e temporal variability of tc intensity distance weighted storm selection also it is recommended to further examine sensitivity analysis on several steps of the methodology a optimization of the minimum number of selection cases needed b effect on introducing a weighted distance in the mda selection algorithm to obtain more tracks near the target location less tangent tracks far away c effect on different selection algorithms d size of the influence circle area and e number of pcs trained for interpolation as described in previous sections the methodology implements certain assumptions which derive in some limitations the user should take into consideration the storm track parameterization provides a close to real representation of quasi straight tracks while convoluted tracks would be poorly represented as well as the hazards produced by such events moreover the applicability is restricted to tc induced waves produced in the regional vicinity of the study area defined by a 4 degrees radius in the present study although a sensitivity analysis of the radius size is recommended in future research additionally the present study does not include a calibration and or validation of the wave numerical model against measurements of historical tcs which still remains an area for future research instead the focus of this study was addressed towards the development of a hybrid methodology that replicates the outputs of a numerical model in summary the proposed methodology has the ability of coupling numerical modeling data mining and statistical tools to obtain a cost effective approach for producing a large database of maximum swath maps induced by tcs we expect this preliminary methodology will be useful to end users as a first approximation of regional ev distribution of mswh induced by tcs credit authorship contribution statement sara o van vloten conceptualization methodology software validation writing original draft visualization laura cagigal supervision writing review editing ana rueda supervision writing review editing nicolás ripoll software writing review editing fernando j méndez conceptualization methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work has been partially funded by the beach4cast pid2019 107053rb i00 project granted by the spanish ministry of science and innovation ar acknowledge the funding from juan de la cierva incorporación ijc2020 043907 i mcin aei 10 13039 501100011033 and nextgenerationeu prtr 
23821,inability of low resolution ocean models to simulate many important aspects of the large scale general circulation is a common problem in the view of physics the main reason for this failure are the missed dynamical effects of the unresolved small scales of motion on the explicitly resolved large scale circulation complimentary to this mainstream physics based perspective we propose to address this failure from the dynamical systems point of view namely as the persistent tendency of phase space trajectories representing the low resolution solution to escape the right region of the corresponding phase space which is occupied by the reference eddy resolving solution based on this concept we propose to use methods of constrained optimization to confine the low resolution solution to remain within the correct phase space region without attempting to amend the eddy physics by introducing a process based parameterization this approach is advocated as a novel framework for data driven hyper parameterizations of mesoscale oceanic eddies in non eddy resolving models we tested the idea in the context of classical baroclinic beta plane turbulence model and showed that non eddy resolving solution can be substantially improved towards the reference eddy resolving benchmark keywords nonlinear ocean dynamics mesoscale eddies and their parameterizations dynamical systems constrained optimization 1 introduction the problem of reproducing large scale flow structures in low resolution ocean simulations is among the most challenging ones in ocean modelling and this is mostly due to the lack of information from the small unresolved scales the mainstream approach to this problem is to use parameterizations that is mathematically simple and physically justified approximations of the key unresolved and under resolved small scale processes e g gent and mcwilliams 1990 duan and nadiga 2007 frederiksen et al 2012 jansen and held 2014 mana and zanna 2014 cooper and zanna 2015 grooms et al 2015 berloff 2016 2018 danilov et al 2019 ryzhov et al 2019 juricke et al 2020a b cotter et al 2019 ryzhov et al 2020 cotter et al 2020a b c despite the decades of research effort invested in this direction the problem remains mainly unresolved for various reasons the majority of which is due to inaccurate description of small scales physics and energy transfers between scales this work takes a new angle on this long standing problem namely we propose to look at the problem from the dynamical system point of view and consider the inability of the low resolution model to reproduce the large scale flow structures as the persistent tendency of phase space trajectories representing the low resolution solution to escape the right region of the corresponding phase space which is occupied by the reference eddy resolving solution thus instead of parameterizing directly the action of unresolved scales onto the resolved ones our approach is to constrain the low resolution flow dynamics to the right region of the phase space two other methods based on this approach were developed and tested earlier the first method computes the low resolution solution as the phase space trajectory of the image point which is dynamically governed by the reference solution shevchenko and berloff 2021a the second method reconstructs a dynamical system from the reference solution and then explicitly uses this system to predict the low resolutions circulation shevchenko and berloff 2022 in this study we propose a new method the employed low resolution model which is integrated explicitly is constrained by an optimization procedure that restricts the solution to stay within the right region of phase space as defined from the reference solution for the proof of concept stage we consider first the lorenz model and then the classical baroclinic quasigeostrophic qg model of the beta plane turbulence 2 the method we run the mathematical model of the studied phenomenon here the qg model at low resolution and restrict its solution to the reference region of phase space defined by a set of constraints g a ball of radius r in our case the method is based on solving a constrained minimization problem of the form e g bertsekas 1996 1 min f x subject to g x 0 where f and g are given functions in order to inject the constraint into the minimization problem we use the barrier function ϕ 1 g x which leads to the following unconstrained minimization problem 2 min f x μ g x μ 0 where parameter μ 0 regulates accuracy for finding the minimum in our case a very accurate approximation of the minimum is not required as the problem is chaotic and the goal of constraining will be achieved anyway however we expect that a systematically wrong choice of μ over relatively long periods of time can potentially lead to a flow dynamics with different compared to the reference solution large scale features not to mention small scale ones without compromising the main message we leave further technicalities beyond the scope of our work and refer readers to bertsekas 1996 as an example we first consider the lorenz 63 system lorenz 1963 3 x t f x t f σ y x x ρ z y x y β z subject to g x x 2 y 2 z 2 r 2 0 where prime denotes a derivative with respect to time and x t x t y t z t in order to reformulate the constrained lorenz system 3 as an unconstrained minimization problem we first choose an integrator the euler method in our case and then define the objective function f x and the constraint g x as follows 4 f x 1 2 x n 1 x n δ t f x n 2 2 g x n 1 x n 1 2 y n 1 2 z n 1 2 r 2 0 where δ t is the time step and x n denotes the solution at discrete time t n n δ t n 0 the solution to the unconstrained minimization problem 2 with given functions f x and g x can be found with an optimization method we use newton s method the initial point x n 1 0 for the optimization method must be feasible i e satisfy the constraint g x n 1 0 0 otherwise the method fails to find the optimal solution in order to solve the constrained lorenz system we take σ 10 β 8 3 ρ 28 and the initial condition x t 0 4 32 6 00 18 34 is chosen close to the lorenz attractor the results are presented in fig 1 as seen in fig 1a the solution to the lorenz system remains on the attractor over the whole simulation time and there are no constraints influencing the trajectory if trajectory is to be restricted to some region of the phase space then a set of constraints needs to be introduced we chose a ball of radius r 40 centred at 0 0 0 to be the constraining phase space region and the constrained solution remains in it over the whole simulation fig 1b but the constrained solution is not the same as the original one even within the ball interior the region where the trajectory is allowed to evolve with no constraints as long as the constraints are satisfied it happens because the constraints deform the structure of the original phase space by imposing extra restrictions on the solution if we keep decreasing the radius the deformation eventually becomes so large that the constrained system completely fails to reproduce the lorenz attractor not shown this indicates that the lorenz system should be somehow modified but discussing this is beyond the scope of our study the above example shows how one can use the constrained optimization approach in more sophisticated settings for instance one can take the primitive equations or a qg ocean model compute its eddy resolving reference solution project it onto the coarse grid and find approximately a spherical region of the phase space that is occupied by this solution if the unconstrained low resolution model configuration cannot reproduce the nominally resolved reference circulation then implementation of constraint is justified and the questions are whether it works and how can it be tuned and optimized 3 multilayer quasi geostrophic equations in this section we apply the method to the two layer qg model describing evolution of the potential vorticity pv anomaly q q 1 q 2 in a domain ω pedlosky 1987 5 q 1 t u 1 q 1 ν 4 ψ 1 β ψ 1 x q 2 t u 2 q 2 ν 4 ψ 2 μ 2 ψ 2 β ψ 2 x where ψ ψ 1 ψ 2 is the velocity streamfunction in the top and bottom layers respectively β 2 1 0 11 m 1 s 1 is the planetary vorticity gradient μ 4 1 0 9 s 1 is the bottom friction parameter ν is the lateral eddy viscosity to be specified later and u u v is the flow velocity vector the ocean basin ω 0 l x 0 l y 0 h is zonally periodic flat bottom channel with horizontal dimensions l x 1800 km and l y l x 2 with the depth h h 1 h 2 and filled out by two stacked isopycnal fluid layers of depths h 1 1 0 km and h 2 3 0 km more details about the problem formulation the flow dynamics in the channel and large small scale interactions can be found in berloff and kamenkovich 2013b forcing in 5 is introduced via a vertically sheared baroclinically unstable background flow e g berloff and kamenkovich 2013a 6 ψ i u i y ψ i i 1 2 with the zonal velocities u 6 0 0 0 cm s 1 the layer wise pv anomalies and streamfunctions are related through the pair of coupled elliptic equations 7a q 1 2 ψ 1 s 1 ψ 2 ψ 1 7b q 2 2 ψ 2 s 2 ψ 1 ψ 2 with stratification parameters s 1 4 22 1 0 3 km 2 and s 2 1 41 1 0 3 km 2 chosen so that the first baroclinic rossby deformation radius is r d 1 25 km the mass and momentum constraints are imposed following mcwilliams 1977 system 5 7b is augmented by the periodic horizontal boundary conditions set at the eastern γ 2 and western γ 4 boundaries 8 ψ γ 2 ψ γ 4 ψ ψ 1 ψ 2 and no slip boundary conditions 9 u γ 1 u γ 3 0 are imposed at the northern γ 1 and southern γ 3 boundaries we use 513 257 uniform spatial grid take the eddy viscosity value ν 25 m 2 s 1 and spin up the model from the state of rest to t 0 over the time interval t s p i n 10 0 years so that the statistically equilibrated flow regime is established for the low resolution model we use the same set up except for much coarser grid 129 65 and much larger eddy viscosity value ν 250 m 2 s 1 note that dimensional units can be converted to their non dimensional analogues by using the velocity scale 0 01 m s 1 and the grid interval as the length scale in order to apply the method to the qg equations 5 one has to choose the variable or variables to constrain for this role we take the pv anomaly q that leads to the inequality g q 0 however the method is not limited to this particular choice and other constraints can be implemented for example one can constrain the velocity field or individual terms in the equations to solve the constrained optimization problem 2 for the qg model 5 we use the same algorithm as for the lorenz system 3 the only difference is the time integrator which is the leapfrog scheme for the qg equations as seen in fig 2a in each direction the reference solution has 4 well pronounced horizontal jets which the unconstrained low resolution model fails to reproduce fig 2b this is because the low resolution solution trajectory quickly escapes the right phase space region even when we start it from the right initial condition the phase space is constrained as g q q q 2 2 r 2 0 q 1 t 0 t q t d t 10 r 1 t 0 t q t q 2 d t where r 846 non dimensional units t 4 years and q denotes the constrained low resolution solution restricted to the ball of radius r constraint 10 corresponds to the ball of radius r centred at the 4 year time mean of the reference eddy resolving solution q and the radius is found as the mean distance of the 4 year long reference solution from q here the ball is the simplest approximation of the real reference solution attractor in the phase space it might seem reasonable to find a value of r such that the low resolution constrained solution q is a more accurate approximation to the reference solution q however we do not recommend this since r is an approximation to the reference phase volume i e even knowing its optimal value does not guarantee a significantly more accurate solution as the coarse grain trajectory may not visit the attractor regions populated by the reference solution a better way would be to more accurately approximate the shape of the reference phase space volume for example one could find a hyper ellipsoid that takes into account the actual spread of the attractor along different coordinate axes when the model is constrained the 4 jets in the top layer are recovered both in the instantaneous and time mean fields fig 2c the relative blurriness of the jet edges comes from the use of an order of magnitude larger viscosity perhaps the jet edges can be sharpened up by injecting noise into the advection operator as in the salt approach e g cotter et al 2019 2020a b c or simply by adding it as a forcing on the other hand the jets in the bottom layer are much weaker compared to those in the top layer but even in this case the constrained model reproduces them although these jets are less smeared compared to the reference ones we hypothesize that our approximation of the reference phase space is too rough to accurately capture the jets in the bottom layer to see how the radius of the ball influences the dynamics we took the ball of a larger radius r 923 this is the maximum radius for the 10 year long reference solution in this case the constrained solution still has the jets which are however noticeably corrupted fig 2d especially after 10 years of simulation see the jet near the southern boundary however the 10 year average of the bottom layer pv anomaly fig 2d shows relatively good agreement with the reference solution fig 2a with particular improvement over the r 846 case fig 2c this indicates that increasing the radius improves the representation of the pv anomaly mean field in the bottom layer the 10 year average this contrasts with the observed behaviour of the upper layer when increasing the radius which corrupts the pv anomaly fields in the upper layer it suggests that the ball of a fixed radius is likely not the most appropriate representation of the shape of reference phase space on the other note the separation between the two southern jets becomes less evident see the time average subplot and the standard deviation does not show as pronounced jets as those of the reference solution or the solution constrained in the smaller ball this is explained by the fact that the solution constrained by a larger ball drifts farther away from the right phase space region based on this evidence one could think that a tighter ball would yield a more accurate solution but this is not necessarily the case since an over constrained qg model can lead to significantly incorrect dynamics as an example we found the solution for r 796 this is the minimum radius for the 10 year long reference solution and obtained the results very similar to those with r 846 not shown this another suggestion that the ball is not an accurate approximation of the reference phase space when finer structures of the solution have to be modelled as an alternative one should focus on methods that can better approximate the reference phase space in order to get better insights in the low resolution dynamics in the phase space we compute the euclidean distance d t of different solutions from the reference time mean fig 3 as it follows from the results the constrained low resolution solution evolves near the boundary of the constrained region since the low resolution solution fig 2b is too crude an approximation to the reference solution fig 2a and therefore the low resolution solution always tries to escape the constrained region however even in this case the method restores the nominally resolved flow patterns that are not present in the unconstrained low resolution solution 4 conclusions and discussion in this work we have further developed alternative hyper parameterization approach for parameterizing effects of mesoscale oceanic eddies on the large scale ocean circulation complimentary to the mainstream physics based perspective we propose to deal with the eddy effects from the dynamical systems point of view and interpret the lack of them as the persistent tendency of phase space trajectories representing the low resolution solution to escape the right region of the corresponding phase space which is occupied by the reference eddy resolving solution based on this concept we propose to use methods of constrained optimization to confine the low resolution solution to remain within the correct phase space region without attempting to amend the eddy physics by introducing a process based parameterization formally speaking the constrained optimization can be thought of as being a generalization of the classical nudging approach when the solution is nudged to a reference volume in phase space with the nudging parameter tending to infinity at the boundary of the sphere in the classical nudging the solution is nudged to a reference solution not to a reference volume and the nudging parameter is supposed to be fixed it is worth mentioning that the development of such a nudging method can involve a highly sophisticated control of the nudging parameter or parameters that should probably reflect the structure of the reference phase space we used the lorenz 63 system as a simple conceptual toy model for the proof of concept then we considered the baroclinic quasigeostrophic qg model of the beta plane turbulence and showed that the low resolution solution cannot reproduce such nominally resolved flow structures as the multiple alternating zonal jets which are robustly present in the reference eddy resolving solution implementation of the proposed hyper parameterization approach significantly improves the low resolution model and recovers the top layer jets the bottom layer jets are much weaker compared to the top layer ones but even in this case the constrained model reproduces them too however the reference bottom layer jets are more defused than those of the constrained model there might be two reasons for that firstly the viscosity in the constrained model is one order of magnitude larger compared to that in the reference model it can significantly change both the dimension and structure of the attractor compared to the reference that leads to the second reason namely our approximation of the reference phase space might be too rough we used a ball with the radius found as the time mean distance of the 4 year long reference solution from its time mean and centred at the 4 year time mean of the reference solution to accurately capture the jets in the bottom layer this suggests that a more accurate approximation of the reference phase space might be needed to accurately represent the flow dynamics in the deep ocean it is worth drawing reader s attention to the fact that only 4 years of the reference solution have been used to find the centre of the ball and its radius and this turned out to be enough to reproduce the jets in the 10 year long run at low resolution this demonstrates that the proposed method gives robust results as soon as it is supplied with sufficient data on the other hand for more sophisticated models or even for different setups of the qg model longer or shorter runs might be needed to accurately estimate the centre and radius in addition we have studied how the radius of the ball influences the ability of the constrained qg model to reproduce nominally resolved structures and found that too large radius eventually lead to the solution degradation due to the detrimental drift in the phase space whereas too small radius does not allow for an accurate approximation of the shape of the reference phase space thus there is the optimal strength of the constraint the analysis of the constrained solution shows that it evolves near the boundary of the constrained region as its dynamics is governed by the low resolution qg model which is too crude an approximation to the reference solution and therefore the constrained solution always tries to escape the constrained region however even in this case the method restores the nominally resolved flow patterns that are not present in the unconstrained low resolution solution thus giving another level of reassurance that it will likely work well in more sophisticated settings the utility of the proposed method is that it does not require in depth physical knowledge of interactions between the scales of motion and it does not require any modification of the governing equations as in the case of traditional parameterizations the method falls into the category of data driven methods as it requires either observations or their substitute in terms of some eddy resolving solution data in this work we use the projection of the high resolution solution on the coarse grid which we refer to as the reference solution to compute the radius of the sphere the boundary for the constrained optimization and its centre in the reference phase space if this information can be obtained without computing the reference solution for example through physical insights or using observational data then the high resolution solution is not needed obviously the advantage of the method may turn into a possible drawback as often information presented in data is not sufficient for example characteristics of the constraining ball may be inaccurately estimated this can be mitigated by using more accurate approximations of the constraining geometry for example a hyper ellipsoid instead of the ball to take into account the spread of the solution along different coordinate axes and of the attractor reconstruction another intriguing avenue for future research extension is the so called term wise constraining which deals with individual dynamical terms rather than with the whole solution like in this study the proposed method can be implemented into the dynamic core of oceanic general circulation models by constraining solutions of different equations and terms or their combinations this is in turn the open broad research agenda on the effects of different data driven constraints of the governing equations e g shevchenko and berloff 2021c it can also be applied to comprehensive ocean atmosphere models with many dynamical variables changing external conditions and different dynamical regimes these models can be thought of as being either monostable chaotic systems chaotic systems with only one chaotic attractor or multistable chaotic systems chaotic systems with several chaotic attractors for a given set of parameters in case of monostable systems different dynamical regimes are realized in different regions of one attractor when the solution switches between different regions of the attractor it is observed as a different dynamical regime in case of multistable systems the solution switches between different attractors the method should properly approximate the reference solution for monostable systems if the coarse grid trajectory can visit the regions of the attractor corresponding to different dynamical regimes the method can also be used for multistable systems given that the chaotic attractors are present in the data provided the accuracy of the method for monostable and multistable systems can be improved if combined with parameterizations of the coarse grid model on the other note the attractor might be extremely complex in a more complicated model and it is not clear that defining a ball or ellipsoid would yield a useful constraint assuming more detailed knowledge of the structure of the attractor requires further knowledge of the reference flow dynamics potentially making it more difficult to configure the method all in all the accuracy of the method for comprehensive ocean atmosphere models remains uncharted territory worth exploring in the future credit authorship contribution statement i shevchenko conceptualization methodology software validation formal analysis writing original draft p berloff writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the leverhulme trust for the support of this work through the grant rpg 2019 024 and the anonymous referees for their constructive comments suggestions and efforts which helped us improve the paper pavel berloff was supported by the nerc grant ne t002220 1 and by the moscow centre for fundamental and applied mathematics supported by the agreement 075 15 2019 1624 with the ministry of education and science of the russian federation we thank the associate editor david marshall for all his work in managing this paper 
23821,inability of low resolution ocean models to simulate many important aspects of the large scale general circulation is a common problem in the view of physics the main reason for this failure are the missed dynamical effects of the unresolved small scales of motion on the explicitly resolved large scale circulation complimentary to this mainstream physics based perspective we propose to address this failure from the dynamical systems point of view namely as the persistent tendency of phase space trajectories representing the low resolution solution to escape the right region of the corresponding phase space which is occupied by the reference eddy resolving solution based on this concept we propose to use methods of constrained optimization to confine the low resolution solution to remain within the correct phase space region without attempting to amend the eddy physics by introducing a process based parameterization this approach is advocated as a novel framework for data driven hyper parameterizations of mesoscale oceanic eddies in non eddy resolving models we tested the idea in the context of classical baroclinic beta plane turbulence model and showed that non eddy resolving solution can be substantially improved towards the reference eddy resolving benchmark keywords nonlinear ocean dynamics mesoscale eddies and their parameterizations dynamical systems constrained optimization 1 introduction the problem of reproducing large scale flow structures in low resolution ocean simulations is among the most challenging ones in ocean modelling and this is mostly due to the lack of information from the small unresolved scales the mainstream approach to this problem is to use parameterizations that is mathematically simple and physically justified approximations of the key unresolved and under resolved small scale processes e g gent and mcwilliams 1990 duan and nadiga 2007 frederiksen et al 2012 jansen and held 2014 mana and zanna 2014 cooper and zanna 2015 grooms et al 2015 berloff 2016 2018 danilov et al 2019 ryzhov et al 2019 juricke et al 2020a b cotter et al 2019 ryzhov et al 2020 cotter et al 2020a b c despite the decades of research effort invested in this direction the problem remains mainly unresolved for various reasons the majority of which is due to inaccurate description of small scales physics and energy transfers between scales this work takes a new angle on this long standing problem namely we propose to look at the problem from the dynamical system point of view and consider the inability of the low resolution model to reproduce the large scale flow structures as the persistent tendency of phase space trajectories representing the low resolution solution to escape the right region of the corresponding phase space which is occupied by the reference eddy resolving solution thus instead of parameterizing directly the action of unresolved scales onto the resolved ones our approach is to constrain the low resolution flow dynamics to the right region of the phase space two other methods based on this approach were developed and tested earlier the first method computes the low resolution solution as the phase space trajectory of the image point which is dynamically governed by the reference solution shevchenko and berloff 2021a the second method reconstructs a dynamical system from the reference solution and then explicitly uses this system to predict the low resolutions circulation shevchenko and berloff 2022 in this study we propose a new method the employed low resolution model which is integrated explicitly is constrained by an optimization procedure that restricts the solution to stay within the right region of phase space as defined from the reference solution for the proof of concept stage we consider first the lorenz model and then the classical baroclinic quasigeostrophic qg model of the beta plane turbulence 2 the method we run the mathematical model of the studied phenomenon here the qg model at low resolution and restrict its solution to the reference region of phase space defined by a set of constraints g a ball of radius r in our case the method is based on solving a constrained minimization problem of the form e g bertsekas 1996 1 min f x subject to g x 0 where f and g are given functions in order to inject the constraint into the minimization problem we use the barrier function ϕ 1 g x which leads to the following unconstrained minimization problem 2 min f x μ g x μ 0 where parameter μ 0 regulates accuracy for finding the minimum in our case a very accurate approximation of the minimum is not required as the problem is chaotic and the goal of constraining will be achieved anyway however we expect that a systematically wrong choice of μ over relatively long periods of time can potentially lead to a flow dynamics with different compared to the reference solution large scale features not to mention small scale ones without compromising the main message we leave further technicalities beyond the scope of our work and refer readers to bertsekas 1996 as an example we first consider the lorenz 63 system lorenz 1963 3 x t f x t f σ y x x ρ z y x y β z subject to g x x 2 y 2 z 2 r 2 0 where prime denotes a derivative with respect to time and x t x t y t z t in order to reformulate the constrained lorenz system 3 as an unconstrained minimization problem we first choose an integrator the euler method in our case and then define the objective function f x and the constraint g x as follows 4 f x 1 2 x n 1 x n δ t f x n 2 2 g x n 1 x n 1 2 y n 1 2 z n 1 2 r 2 0 where δ t is the time step and x n denotes the solution at discrete time t n n δ t n 0 the solution to the unconstrained minimization problem 2 with given functions f x and g x can be found with an optimization method we use newton s method the initial point x n 1 0 for the optimization method must be feasible i e satisfy the constraint g x n 1 0 0 otherwise the method fails to find the optimal solution in order to solve the constrained lorenz system we take σ 10 β 8 3 ρ 28 and the initial condition x t 0 4 32 6 00 18 34 is chosen close to the lorenz attractor the results are presented in fig 1 as seen in fig 1a the solution to the lorenz system remains on the attractor over the whole simulation time and there are no constraints influencing the trajectory if trajectory is to be restricted to some region of the phase space then a set of constraints needs to be introduced we chose a ball of radius r 40 centred at 0 0 0 to be the constraining phase space region and the constrained solution remains in it over the whole simulation fig 1b but the constrained solution is not the same as the original one even within the ball interior the region where the trajectory is allowed to evolve with no constraints as long as the constraints are satisfied it happens because the constraints deform the structure of the original phase space by imposing extra restrictions on the solution if we keep decreasing the radius the deformation eventually becomes so large that the constrained system completely fails to reproduce the lorenz attractor not shown this indicates that the lorenz system should be somehow modified but discussing this is beyond the scope of our study the above example shows how one can use the constrained optimization approach in more sophisticated settings for instance one can take the primitive equations or a qg ocean model compute its eddy resolving reference solution project it onto the coarse grid and find approximately a spherical region of the phase space that is occupied by this solution if the unconstrained low resolution model configuration cannot reproduce the nominally resolved reference circulation then implementation of constraint is justified and the questions are whether it works and how can it be tuned and optimized 3 multilayer quasi geostrophic equations in this section we apply the method to the two layer qg model describing evolution of the potential vorticity pv anomaly q q 1 q 2 in a domain ω pedlosky 1987 5 q 1 t u 1 q 1 ν 4 ψ 1 β ψ 1 x q 2 t u 2 q 2 ν 4 ψ 2 μ 2 ψ 2 β ψ 2 x where ψ ψ 1 ψ 2 is the velocity streamfunction in the top and bottom layers respectively β 2 1 0 11 m 1 s 1 is the planetary vorticity gradient μ 4 1 0 9 s 1 is the bottom friction parameter ν is the lateral eddy viscosity to be specified later and u u v is the flow velocity vector the ocean basin ω 0 l x 0 l y 0 h is zonally periodic flat bottom channel with horizontal dimensions l x 1800 km and l y l x 2 with the depth h h 1 h 2 and filled out by two stacked isopycnal fluid layers of depths h 1 1 0 km and h 2 3 0 km more details about the problem formulation the flow dynamics in the channel and large small scale interactions can be found in berloff and kamenkovich 2013b forcing in 5 is introduced via a vertically sheared baroclinically unstable background flow e g berloff and kamenkovich 2013a 6 ψ i u i y ψ i i 1 2 with the zonal velocities u 6 0 0 0 cm s 1 the layer wise pv anomalies and streamfunctions are related through the pair of coupled elliptic equations 7a q 1 2 ψ 1 s 1 ψ 2 ψ 1 7b q 2 2 ψ 2 s 2 ψ 1 ψ 2 with stratification parameters s 1 4 22 1 0 3 km 2 and s 2 1 41 1 0 3 km 2 chosen so that the first baroclinic rossby deformation radius is r d 1 25 km the mass and momentum constraints are imposed following mcwilliams 1977 system 5 7b is augmented by the periodic horizontal boundary conditions set at the eastern γ 2 and western γ 4 boundaries 8 ψ γ 2 ψ γ 4 ψ ψ 1 ψ 2 and no slip boundary conditions 9 u γ 1 u γ 3 0 are imposed at the northern γ 1 and southern γ 3 boundaries we use 513 257 uniform spatial grid take the eddy viscosity value ν 25 m 2 s 1 and spin up the model from the state of rest to t 0 over the time interval t s p i n 10 0 years so that the statistically equilibrated flow regime is established for the low resolution model we use the same set up except for much coarser grid 129 65 and much larger eddy viscosity value ν 250 m 2 s 1 note that dimensional units can be converted to their non dimensional analogues by using the velocity scale 0 01 m s 1 and the grid interval as the length scale in order to apply the method to the qg equations 5 one has to choose the variable or variables to constrain for this role we take the pv anomaly q that leads to the inequality g q 0 however the method is not limited to this particular choice and other constraints can be implemented for example one can constrain the velocity field or individual terms in the equations to solve the constrained optimization problem 2 for the qg model 5 we use the same algorithm as for the lorenz system 3 the only difference is the time integrator which is the leapfrog scheme for the qg equations as seen in fig 2a in each direction the reference solution has 4 well pronounced horizontal jets which the unconstrained low resolution model fails to reproduce fig 2b this is because the low resolution solution trajectory quickly escapes the right phase space region even when we start it from the right initial condition the phase space is constrained as g q q q 2 2 r 2 0 q 1 t 0 t q t d t 10 r 1 t 0 t q t q 2 d t where r 846 non dimensional units t 4 years and q denotes the constrained low resolution solution restricted to the ball of radius r constraint 10 corresponds to the ball of radius r centred at the 4 year time mean of the reference eddy resolving solution q and the radius is found as the mean distance of the 4 year long reference solution from q here the ball is the simplest approximation of the real reference solution attractor in the phase space it might seem reasonable to find a value of r such that the low resolution constrained solution q is a more accurate approximation to the reference solution q however we do not recommend this since r is an approximation to the reference phase volume i e even knowing its optimal value does not guarantee a significantly more accurate solution as the coarse grain trajectory may not visit the attractor regions populated by the reference solution a better way would be to more accurately approximate the shape of the reference phase space volume for example one could find a hyper ellipsoid that takes into account the actual spread of the attractor along different coordinate axes when the model is constrained the 4 jets in the top layer are recovered both in the instantaneous and time mean fields fig 2c the relative blurriness of the jet edges comes from the use of an order of magnitude larger viscosity perhaps the jet edges can be sharpened up by injecting noise into the advection operator as in the salt approach e g cotter et al 2019 2020a b c or simply by adding it as a forcing on the other hand the jets in the bottom layer are much weaker compared to those in the top layer but even in this case the constrained model reproduces them although these jets are less smeared compared to the reference ones we hypothesize that our approximation of the reference phase space is too rough to accurately capture the jets in the bottom layer to see how the radius of the ball influences the dynamics we took the ball of a larger radius r 923 this is the maximum radius for the 10 year long reference solution in this case the constrained solution still has the jets which are however noticeably corrupted fig 2d especially after 10 years of simulation see the jet near the southern boundary however the 10 year average of the bottom layer pv anomaly fig 2d shows relatively good agreement with the reference solution fig 2a with particular improvement over the r 846 case fig 2c this indicates that increasing the radius improves the representation of the pv anomaly mean field in the bottom layer the 10 year average this contrasts with the observed behaviour of the upper layer when increasing the radius which corrupts the pv anomaly fields in the upper layer it suggests that the ball of a fixed radius is likely not the most appropriate representation of the shape of reference phase space on the other note the separation between the two southern jets becomes less evident see the time average subplot and the standard deviation does not show as pronounced jets as those of the reference solution or the solution constrained in the smaller ball this is explained by the fact that the solution constrained by a larger ball drifts farther away from the right phase space region based on this evidence one could think that a tighter ball would yield a more accurate solution but this is not necessarily the case since an over constrained qg model can lead to significantly incorrect dynamics as an example we found the solution for r 796 this is the minimum radius for the 10 year long reference solution and obtained the results very similar to those with r 846 not shown this another suggestion that the ball is not an accurate approximation of the reference phase space when finer structures of the solution have to be modelled as an alternative one should focus on methods that can better approximate the reference phase space in order to get better insights in the low resolution dynamics in the phase space we compute the euclidean distance d t of different solutions from the reference time mean fig 3 as it follows from the results the constrained low resolution solution evolves near the boundary of the constrained region since the low resolution solution fig 2b is too crude an approximation to the reference solution fig 2a and therefore the low resolution solution always tries to escape the constrained region however even in this case the method restores the nominally resolved flow patterns that are not present in the unconstrained low resolution solution 4 conclusions and discussion in this work we have further developed alternative hyper parameterization approach for parameterizing effects of mesoscale oceanic eddies on the large scale ocean circulation complimentary to the mainstream physics based perspective we propose to deal with the eddy effects from the dynamical systems point of view and interpret the lack of them as the persistent tendency of phase space trajectories representing the low resolution solution to escape the right region of the corresponding phase space which is occupied by the reference eddy resolving solution based on this concept we propose to use methods of constrained optimization to confine the low resolution solution to remain within the correct phase space region without attempting to amend the eddy physics by introducing a process based parameterization formally speaking the constrained optimization can be thought of as being a generalization of the classical nudging approach when the solution is nudged to a reference volume in phase space with the nudging parameter tending to infinity at the boundary of the sphere in the classical nudging the solution is nudged to a reference solution not to a reference volume and the nudging parameter is supposed to be fixed it is worth mentioning that the development of such a nudging method can involve a highly sophisticated control of the nudging parameter or parameters that should probably reflect the structure of the reference phase space we used the lorenz 63 system as a simple conceptual toy model for the proof of concept then we considered the baroclinic quasigeostrophic qg model of the beta plane turbulence and showed that the low resolution solution cannot reproduce such nominally resolved flow structures as the multiple alternating zonal jets which are robustly present in the reference eddy resolving solution implementation of the proposed hyper parameterization approach significantly improves the low resolution model and recovers the top layer jets the bottom layer jets are much weaker compared to the top layer ones but even in this case the constrained model reproduces them too however the reference bottom layer jets are more defused than those of the constrained model there might be two reasons for that firstly the viscosity in the constrained model is one order of magnitude larger compared to that in the reference model it can significantly change both the dimension and structure of the attractor compared to the reference that leads to the second reason namely our approximation of the reference phase space might be too rough we used a ball with the radius found as the time mean distance of the 4 year long reference solution from its time mean and centred at the 4 year time mean of the reference solution to accurately capture the jets in the bottom layer this suggests that a more accurate approximation of the reference phase space might be needed to accurately represent the flow dynamics in the deep ocean it is worth drawing reader s attention to the fact that only 4 years of the reference solution have been used to find the centre of the ball and its radius and this turned out to be enough to reproduce the jets in the 10 year long run at low resolution this demonstrates that the proposed method gives robust results as soon as it is supplied with sufficient data on the other hand for more sophisticated models or even for different setups of the qg model longer or shorter runs might be needed to accurately estimate the centre and radius in addition we have studied how the radius of the ball influences the ability of the constrained qg model to reproduce nominally resolved structures and found that too large radius eventually lead to the solution degradation due to the detrimental drift in the phase space whereas too small radius does not allow for an accurate approximation of the shape of the reference phase space thus there is the optimal strength of the constraint the analysis of the constrained solution shows that it evolves near the boundary of the constrained region as its dynamics is governed by the low resolution qg model which is too crude an approximation to the reference solution and therefore the constrained solution always tries to escape the constrained region however even in this case the method restores the nominally resolved flow patterns that are not present in the unconstrained low resolution solution thus giving another level of reassurance that it will likely work well in more sophisticated settings the utility of the proposed method is that it does not require in depth physical knowledge of interactions between the scales of motion and it does not require any modification of the governing equations as in the case of traditional parameterizations the method falls into the category of data driven methods as it requires either observations or their substitute in terms of some eddy resolving solution data in this work we use the projection of the high resolution solution on the coarse grid which we refer to as the reference solution to compute the radius of the sphere the boundary for the constrained optimization and its centre in the reference phase space if this information can be obtained without computing the reference solution for example through physical insights or using observational data then the high resolution solution is not needed obviously the advantage of the method may turn into a possible drawback as often information presented in data is not sufficient for example characteristics of the constraining ball may be inaccurately estimated this can be mitigated by using more accurate approximations of the constraining geometry for example a hyper ellipsoid instead of the ball to take into account the spread of the solution along different coordinate axes and of the attractor reconstruction another intriguing avenue for future research extension is the so called term wise constraining which deals with individual dynamical terms rather than with the whole solution like in this study the proposed method can be implemented into the dynamic core of oceanic general circulation models by constraining solutions of different equations and terms or their combinations this is in turn the open broad research agenda on the effects of different data driven constraints of the governing equations e g shevchenko and berloff 2021c it can also be applied to comprehensive ocean atmosphere models with many dynamical variables changing external conditions and different dynamical regimes these models can be thought of as being either monostable chaotic systems chaotic systems with only one chaotic attractor or multistable chaotic systems chaotic systems with several chaotic attractors for a given set of parameters in case of monostable systems different dynamical regimes are realized in different regions of one attractor when the solution switches between different regions of the attractor it is observed as a different dynamical regime in case of multistable systems the solution switches between different attractors the method should properly approximate the reference solution for monostable systems if the coarse grid trajectory can visit the regions of the attractor corresponding to different dynamical regimes the method can also be used for multistable systems given that the chaotic attractors are present in the data provided the accuracy of the method for monostable and multistable systems can be improved if combined with parameterizations of the coarse grid model on the other note the attractor might be extremely complex in a more complicated model and it is not clear that defining a ball or ellipsoid would yield a useful constraint assuming more detailed knowledge of the structure of the attractor requires further knowledge of the reference flow dynamics potentially making it more difficult to configure the method all in all the accuracy of the method for comprehensive ocean atmosphere models remains uncharted territory worth exploring in the future credit authorship contribution statement i shevchenko conceptualization methodology software validation formal analysis writing original draft p berloff writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the leverhulme trust for the support of this work through the grant rpg 2019 024 and the anonymous referees for their constructive comments suggestions and efforts which helped us improve the paper pavel berloff was supported by the nerc grant ne t002220 1 and by the moscow centre for fundamental and applied mathematics supported by the agreement 075 15 2019 1624 with the ministry of education and science of the russian federation we thank the associate editor david marshall for all his work in managing this paper 
23822,the yellow and bohai seas ybs are shallow marginal seas located at the temperate latitudes of the western north pacific the seasonal bottom water temperature variation in the ybs can be greater than 20 c and therefore generates significant seafloor heat flux which significantly changes both the sediment temperature profile and heat content of the overlying water column in this study we investigated the seafloor heat flux driven by bottom water temperature variation in the ybs using a high resolution numerical ocean model and a one dimensional sediment temperature model the results showed that seafloor heat flux in the area shallower than 50 m was on the order of 10 w m2 the seafloor heat flux was larger than the lateral heat flux driven by circulation and ranked second only to surface net heat flux accounting for the most important forcing mechanism of ocean heat content variation in the coastal ybs the accumulated seafloor heat flux during the sediment cooling warming season could warm cool the overlying water column by about 1 c in the coastal ybs where the depth is shallower than 30 m the depth of sediment affected by seafloor heat flux seasonal sediment temperature variation 0 1 c could be as deep as 10 m the complex spatial temporal distribution of seafloor heat flux generated a complex distribution of sediment temperature and sound speed which may have an important effect on acoustic wave propagation in the ybs keywords seafloor heat flux acoustic velocity conductive heat flux water temperature yellow and bohai seas 1 introduction the yellow sea ys and the bohai sea bs are shallow and semi enclosed marginal seas located at the northwest pacific it has a mean depth of about 44 m and a maximum depth greater than 100 m fig 1 the horizontal scale of the yellow and bohai seas ybs is about 600 km 900 km the water depth increases gently from the shore to the 50 m isobath then the depth gradient is much steeper in the central ybs fig 1b in the shallow coastal ybs strong tide induced mixing weakens the temperature stratification and the bottom water temperature basically varies with the sea surface temperature which reaches maximum in summer and minimum in winter lü et al 2010 in the central ybs the yellow sea warm current yswc and the yellow sea cold water mass yscwm are the two most prominent phenomena isobe 2008 lü et al 2015 xiong et al 2019 yang et al 2017 the yswc which flows northward along the western side of the ys trough is generated under the prevalent northerly winds in winter to compensate transport of southward coastal currents along the chinese and korean coasts as the yswc transports warm and saline water from the northeastern east china sea into the ybs a warm water tongue can be identified in the distribution of sea surface temperature and bottom water temperature fig 2a the yscwm which is a basin scale water mass of low temperature beneath the seasonal thermocline generates a strong thermocline and strong temperature fronts in the ybs the yscwm is generated locally during the previous winter as a result of surface cooling and strong tide induced vertical mixing and reaches its peak in summer and then decays in autumn as shown in fig 2b the boundary of the yscwm can be outlined by the bottom water temperature front the bottom water temperature in the central ys in summer is 2 3 c cooler than that in winter because both the yswc and the yscwm are constrained by topography and mainly located at the ys trough the 50 m isobath is an important transition boundary of hydrological characteristics the water temperature structure in the ybs has a significant effect on the physical oceanography lie et al 2019 the biological environment lü et al 2013 ras et al 2013 and the acoustic field yang et al 2015a for example the strong stratification in summer makes the m 2 internal tide ubiquitous in the ybs liu et al 2019 the yswc brings warm water thus allowing the tropical species of zooplankton to survive in winter in the southern ys lü et al 2013 furthermore the temperature front movement in the coastal waters can quickly change the sound speed profile of water column and thus have an important effect on acoustic field yang et al 2015b a significant number of quantitative and qualitative analyses of the heat fluxes and ocean heat content variation have been conducted wei et al 2013 suggested that the surface net heat flux which is on the order of 100 w m2 hirose et al 1999 and the lateral heat flux are the main mechanisms forcing ocean heat content variation in the ybs the numerical ocean models such as the wave tide circulation coupled model developed by the key laboratory of marine science and numerical modeling masnum qiao et al 2006 have been applied successfully in the analysis of the yswc ma et al 2006 upwelling lü et al 2006 2010 and seasonal temperature variability associated with summertime circulation in the ybs xia et al 2006 the sediment temperature variation is significant in the ybs in shallow seas because the sound wave interacts with the sea bottom frequently the sediment acoustic properties such as the temperature dependent sediment sound speed have an important effect on shallow sea acoustic field information tang et al 2019 which can be used to detect underwater target yang et al 2015a measure current speed dushaw et al 2017 and protect marine mammals jiang et al 2020 a previous model study presented by rajan and frisk 1992 suggested that the seasonal bottom water temperature variation in the gulf of mexico may significantly change the sediment temperature and thus have an important effect on sediment sound speed based on model results wood et al 2014 showed that the seasonal bottom water temperature variation also can have an important effect on seismic reflectivity by changing sediment temperature profile yang et al 2020 designed and deployed an in situ sediment measurement system to investigate the synoptic time scale variability of sediment and the observations proved that the seafloor heat flux driven by bottom water temperature variation played an important role in sediment temperature and sound speed variation the seafloor heat flux transports heat between the sediment and the overlying water column and thus have an important effect on the temperature of both water column and sediment for the water column the seafloor heat flux together with the surface heat flux and the lateral heat flux determines the water column temperature for the sediment because the geothermal heat flow is small the seafloor heat flux should play the most important role in sediment temperature variation in shallow seas the bottom water warms the sediment when the bottom water is warmer than the sediment and vice versa therefore the bottom water temperature variation is a main mechanism driving the seafloor heat flux because the ybs are located at the temperate latitudes the seasonal bottom water temperature variation is significant the seafloor heat flux driven by bottom water temperature variation in the ybs however and its effects on the heat content of the water column and sediment properties have never been evaluated in this study we first calculate the seafloor heat flux driven by bottom water temperature variation in the ybs using a high resolution numerical ocean model and a one dimensional 1 d sediment temperature model then the significance of seafloor heat flux on water column and sediment is evaluated by calculating its effect on ocean heat content and sediment sound speed section 2 introduces the two models and the seafloor heat flux calculation method and section 3 presents the model results and the spatial temporal distribution of seafloor heat flux in the ybs in section 4 we discuss the effects of the seafloor heat flux on ocean heat content and sediment properties and other potential mechanisms contributing to seafloor heat flux finally the summary is presented in section 5 unless otherwise indicated the seafloor heat flux in this paper indicates the seafloor heat flux driven by bottom water temperature variation 2 material and method 2 1 bottom water temperature simulation in this study we applied the masnum wave tide circulation coupled model hereafter referred to as the ocean model qiao et al 2006 in bottom water temperature simulation the circulation part of the ocean model was based on the princeton ocean model pom ezer et al 2002 we used the masnum wave model to simulate the wave field and to incorporate the surface wave induced mixing in the ocean model qiao et al 2004 the model domain 15 41 n 105 135 e with a horizontal scale of 2900 km 3200 km covered the entire ys the bs and the east china sea the horizontal resolution was 1 18 1 18 and we used 16 vertical sigma layers with higher resolution in the surface layer σ 0 0 00313 0 00625 0 0125 0 025 0 05 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 1 open boundary conditions were provided by a quasi global model which covered 78 s 65 n 0 360 with a horizontal resolution of 1 6 1 6 the wind field of the ncep reanalysis data 1980 1999 and the quikscat data 2000 2007 and surface heat flux of the ncep reanalysis data were used as the surface forcing conditions in the model the surface heat flux was of the haney type haney 1971 a radiation condition was used for open boundary velocity to include tidal current the m 2 tide is prevailing in the ybs and was added in the model the simulation results of the ocean model with similar configurations have been applied in analysis of seasonal water temperature variation dai et al 2006 upwelling lü et al 2008 drift characteristics of green macroalgae qiao et al 2011 and sediment transport dynamics lu et al 2011 in the ybs 2 2 sediment temperature simulation we simulated the sediment temperature using a 1 d heat conduction model hereafter referred to as the sediment temperature model rajan and frisk 1992 1 d 2 t d z 2 1 α 2 d t d t because the geothermal heat flow is small o 0 1 w m2 and to isolate the effect of the bottom water temperature variation the geothermal gradient was fixed at zero the bottom water temperature was assumed to be the same as the sediment temperature at z 0 therefore the depth time distribution of sediment temperature corresponding to a sinusoidal temperature variation t 0 exp i ω t applied at the seafloor z 0 is 2 t z t t 0 exp k z exp i ω t k z where k ω 2 α 2 α 2 k s ρ is the sediment thermal diffusivity k is the thermal conductivity s is the specific heat ρ is the density t 0 t 0 exp i φ φ is the initial phase of bottom water temperature variation the 1 d heat conduction equation is a homogeneous linear differential equation and thus it satisfies the principle of superposition that is if the sediment temperatures corresponding to sinusoidal bottom water temperature variations sbt ω1 and sbt ω2 are t ω1 and t ω2 respectively the sediment temperature corresponding to sbt ω1 sbt ω2 should be t ω1 t ω2 therefore the sediment temperature corresponding to a broadband bottom water temperature variation consisting of different frequency components can be calculated as follows jensen et al 2011 1 calculate the spectrum of broadband bottom water temperature variation t 0 t using the fast fourier transform fft to obtain the t 0 ω ω t 0 ω ω t 0 ω ω exp i φ ω the mean bottom water temperature t 0m should be removed before applying the fft 3 t 0 ω ω f f t t 0 t t 0 m 2 calculate sediment temperature corresponding to the broadband bottom water temperature variation using the fourier synthesis technique 4 t z t t 0 m 1 2 π ω max ω max t 0 ω ω e k z i k z e i ω t d ω according to the nyquist sampling theorem the ω max is half of the sample frequency of the bottom water temperature the t z t includes the response of sediment temperature to the time independent ω 0 and the time dependent ω 0 parts of the bottom water temperature variation when ω 0 the t ω 0 z t t 0 m this indicates the mean sediment temperature is depth independent and time independent and equal to the mean bottom water temperature in this study the sediment temperature model ran offline we applied a repeated 20 year daily climatology of modeled bottom water temperature as introduced in section 3 1 at the seafloor the estimated sediment temperature of the 11th year was extracted for further analysis to avoid the gibbs effect 2 3 seafloor heat flux estimation we estimated the seafloor heat flux from the sediment temperature profile as the product of the vertical sediment temperature gradient and thermal conductivity k as derived from eq 4 the vertical sediment temperature gradient is 5 t z t z 1 2 π ω max ω max t 0 ω e k z i k z e i ω t d ω z 1 2 π ω max ω max 2 k t 0 ω e k z e i ω t k z 3 π 4 d ω then the seafloor heat flux in this study can be defined as follows 6 s h f t z t z k z 0 k 2 π ω max ω max 2 k t 0 ω e i ω t 3 π 4 d ω k 2 π α ω max ω max ω t 0 ω e i ω t 3 π 4 d ω we added a minus sign to eq 6 to make the seafloor heat flux positive when the heat was transported downward from water to sediment as shown in eq 6 the seafloor heat flux is a function of sediment thermal conductivity k and sediment thermal diffusivity α 2 k ω 2 α 2 however the sediment thermal conductivity and sediment thermal diffusivity depend on sediment property which is spatially varying in the ybs zheng et al 2016 a detailed observation or estimation of sediment thermal conductivity and sediment thermal diffusivity in the ybs is scarce as listed in table 1 we collected several sediment parameters which were used in sediment temperature modeling wood et al 2014 used a representative assemblage of sediment grains consisting of 30 quartz 24 albite 6 muscovite 20 smectite and 20 calcium carbonate to model seafloor seismic reflectivity change induced by seasonal seafloor temperature variation and calculated the thermal conductivity and thermal diffusivity of the representative sediment with porosity of 40 50 and 60 case i case ii and case iii in table 1 case iv case v and case vi are sediment parameters derived from observations or estimations in the venice lagoon pivato et al 2018 the lake kinneret nishri et al 2015 and the gulf of mexico rajan and frisk 1992 it should be noted that the thermal diffusivity of case vi is close to that derived from our observations in the jiaozhou bay section 3 2 fig 3 compares the daily mean seafloor heat flux at a coastal station 121 e 36 n indicated by the white star in fig 10 simulated with different sediment parameters even though the thermal diffusivity and thermal conductivity used in simulations have a wide range of variation 0 22 0 6 10 6 m2 s and 0 8 1 8 w m c the maximum difference between the simulations and the average of the six cases is about 20 therefore in this study we arbitrarily used the sediment parameters of the case iii which is medium among the 6 cases to simulate the seafloor heat flux in the ybs in following sections 2 4 lateral heat flux estimation the lateral heat flux driven by horizontal advection can be calculated as 7 l h f z ρ 0 c p t z t d z where t t u t x v t y c p 4180 j kg c is specific heat capacity and ρ 0 1024 kg m3 is density 3 results 3 1 bottom water temperature simulation in this study we conducted a 38 year simulation 1980 2007 using the masnum wave tide circulation coupled model the 3 d temperature salinity and current were output daily fig 4 shows the comparison between the modeled and field measured bottom water temperature at six different stations as indicated by the red circles in fig 1 the results comparison covering four seasons and different water depths suggests the ocean model well captured the main pattern of seasonal bottom water temperature variation we obtained the daily and monthly climatology of water temperature by averaging the 38 year daily mean model output the climatology data were used for further analysis in this study the monthly climatology of ocean model output was compared with that of the woa18 which had a horizontal resolution of 1 4 as shown in fig 5 the comparison suggests the seasonal variation of the monthly climatology of the modeled water temperature is basically consistent with that of the woa18 at different water depths it should be noted that the water temperature observations in the woa18 are very limited in the ybs especially in the area west of 124 e in the area east of 124 e even though the water temperature observations are relatively abundant the depth difference between the water depth and the depth of the bottommost layer containing observations is relatively large 10 m at the stations with deeper water depth these suggest the bottom water temperature of the woa18 is mainly based on objectively analysis in the ybs fig 6 shows the monthly climatology of bottom water temperature of ocean model output and the woa18 in each month three main bottom water temperature characteristics can be identified in both the model result and the woa18 1 the bottom water temperature at the coastal ybs has a significant seasonal variation which reaches maximum in summer and minimum in winter 2 a warm tongue is generated along the western side of the ys trough by the yswc in winter 3 the bottom water temperature in the central ybs is dominated by the yscwm in summer the bottom water temperature derived from historical observations also suggests the ocean model can well reveal the yswc fig 5a in winter and the yscwm fig 5 m in summer in addition because the ocean model uses a terrain following sigma coordinate while the woa18 uses a z coordinate the bottom water temperature distribution of the ocean model is smoother fig 7 shows the modeled maximum seasonal bottom water temperature variation in the ybs the 10 c isothermal basically followed the 50 m isobath the seasonal variation of bottom water temperature was relatively small in the area deeper than 50 m while the maximum seasonal variation of bottom water temperature could be greater than 20 c in coastal shallow waters 3 2 sediment temperature profile simulation because the ocean model can present a reasonable bottom water temperature simulation we then simulate the sediment temperature profile with the daily climatology of the modeled 38 year bottom water temperature fig 8 compares the modeled sediment temperature and the in situ observations in the jiaozhou bay the sediment temperature profiles were measured using the long term multi parameter sediment measurement system lmsms which was equipped with a sediment temperature probe with 7 self contained sediment temperature sensors installed at depths of 0 5 0 6 0 7 0 8 0 9 1 and 1 1 m below seafloor in the summer observation and 0 3 0 4 0 5 0 6 0 7 0 8 and 0 9 m below seafloor in the winter observation the one month long summer observation was conducted from august 2 to 31 2019 the winter observation was conducted on january 3 2020 at eight adjacent stations 36 n 120 25 e as indicated by the red triangle in fig 1 detailed observation method was introduced by yang et al 2020 the sediment temperature was simulated with thermal diffusivity α 2 0 2 1 0 6 m 2 s which was calibrated with the one month long simultaneous bottom water temperature and sediment temperature observations by finding minimum root mean square error between measured and simulated sediment temperature profiles as shown in fig 8 the 1 d sediment temperature model well captured the seasonal variation of sediment temperature profile 3 3 spatial temporal distribution of seafloor heat flux in the yellow sea because the sediment temperature model can well simulate the sediment temperature profile then we can estimate the daily climatology of the seafloor heat flux with the sediment temperature driven by the modeled daily climatology of bottom water temperature fig 9 shows the monthly mean seafloor heat flux in january april july and october in warm season fig 9c the seafloor heat flux was negative in the center of the ybs because of the existence of the yscwm and was positive the sediment was warmed by water in coastal waters in cold season fig 9a the seafloor heat flux was positive in the center of the ybs because of the yswc and was negative in the coastal waters the transition boundary isoline of 0 w m2 of the seafloor heat flux changing from positive to negative basically followed the 50 m isobath the spatial distributions of the maximum absolute seafloor heat flux the seasonal variation of seafloor heat flux and the mean seafloor heat flux during the sediment warming and cooling seasons are shown in fig 10 at the coastal region with depth shallower than 50 m the maximum absolute seafloor heat flux was larger than 6 w m2 the seasonal variation of seafloor heat flux was larger than 10 w m2 and the mean seafloor heat flux during the sediment warming cooling season was larger smaller than 3 3 w m2 the black and red lines in fig 11 show the temporal variation of the seafloor heat flux at a coastal station 121 e 36 n indicated by the white star in fig 10 and a central ys station 124 e 36 n indicated by the black star in fig 10 respectively the variation of the seafloor heat flux at both stations clearly followed an annual cycle while sharing exactly the reverse phase change the seafloor heat flux at the coastal central ys station reached the maximum in august january and the minimum in january august the seafloor heat fluxes at both stations changed their signs in april and october the annual variation was about 20 w m2 at the coastal ys station whereas it was smaller than 4 w m2 at the central ys station 4 discussion 4 1 effect of seafloor heat flux on ocean heat content wei et al 2013 investigated the forcing mechanisms of heat content variations in the ybs using a numerical ocean model and suggested that the daily mean surface net heat flux and the lateral heat flux driven by the circulation contributed most to the ocean heat content variation in the ybs as the seafloor heat flux seemed to be significant in the ybs we compared the seafloor heat flux with the surface net heat flux and the lateral heat flux in this section the surface net heat flux used in comparison was the monthly climatology of the ncep reanalysis surface net heat flux data which were used in forcing the ocean model the lateral heat flux was first calculated using eq 7 with the daily climatology of the ocean model output and then averaged in each month the seafloor heat flux was also calculated using daily climatology bottom water temperature and then averaged by month the downward surface net heat flux and the seafloor heat flux were defined to be positive while the lateral heat flux flowing out of the water column was defined to be positive both the positive seafloor heat flux and the lateral heat flux contributed to cool the water column fig 12 compares the monthly climatology of the surface heat flux the lateral heat flux and the seafloor heat flux which are all averaged in the ybs north of 34 5 n the surface net heat flux varied approximately sinusoidally from about 170 w m2 in winter to about 150 w m2 in summer in an annual cycle hirose et al 1999 the annual mean of the absolute value of surface net heat flux was on the order of 100 w m2 which was about ten times larger than that of the seafloor heat flux in the coastal waters of the ybs the formation and southward extension of the yscwm generated positive lateral heat flux cooling water in the ybs from may to august the decay of the yscwm and the formation of the yswc generated a significant negative lateral heat flux warming water in the ybs from october to december the seafloor heat flux was significant in winter and summer from january to march the seafloor heat flux was larger than the lateral heat flux and should rank second only to surface net heat flux for the most important forcing mechanism of ocean heat content variation in the ybs from june to august the seafloor heat flux was about a half of the lateral heat flux and both the lateral advective heat flux and the seafloor heat flux acted to cool the water in the ybs the ratio of the magnitude of the seafloor heat flux to that of the surface net heat flux was 15 20 in february and september when the surface net heat flux was relatively small in addition to the difference in temporal variation we observed a significant difference in the spatial distributions of the seafloor heat flux and the lateral heat flux as shown in fig 10 the seafloor heat flux was significant in the coastal waters of the ybs where the depth was shallower than 50 m whereas the lateral heat flux which was forced mainly by the yscwm and the yswc was significant in the central ybs wei et al 2013 fig 13 compares the seafloor heat flux and the lateral heat flux averaged over the area shallower than 30 m and 50 m in the ybs north of 34 5 n in most months the seafloor heat flux was larger than the lateral heat flux in the area shallower than 50 m in february and september the ratio of the magnitude of the seafloor heat flux to that of the surface net heat flux was 20 30 the annual mean amplitudes of the seafloor heat flux and the lateral heat flux were 4 18 w m2 and 3 18 w m2 in the area shallower than 50 m while they were 4 87 w m2 and 1 03 w m2 in the area shallower than 30 m therefore in the shallower areas of the ybs depth 50 m the two main mechanisms forcing ocean heat content variation should be the surface heat flux and the seafloor heat flux whereas they were the surface heat flux and the lateral heat flux in the deeper region depth 50 m because the commonly used ocean models such as the pom ezer et al 2002 the fvcom chen et al 2006 and the roms shchepetkin and mcwilliams 2005 do not include the seafloor heat flux the overlook of seafloor heat flux may be a reason that we usually need assimilation technique to obtain satisfying model results the seafloor heat flux may have had different effects on the ocean heat content in different areas in the ybs because of its nonuniform spatial distribution as suggested by dai et al 2006 the role of local vertical diffusion in the subsurface water temperature variation was three to five times larger than that of the horizontal advection in the ys therefore the large amount of heat transported through the strong seafloor heat flux at the coastal waters in the ybs may have played an important role in local water temperature modulation the temperature decrease increase of the water column caused by the heat absorbed released by sediment during the sediment warming cooling period was estimated as 8 δ t t 1 t 2 s h f t d t c p ρ 0 h where h is water depth t 1 t 2 is the sediment warming or cooling period because the sediment warming cooling period is spatially varying fig 11 the t 1 and t 2 are also spatially varying as shown in fig 14 the water column within 100 km off the west coast of the ys where the water depth is shallower than 30 m could be cooled warmed by more than 1 c during the sediment warming cooling period it should be noted that this is only a rough estimate of the water temperature variation induced by neglecting the seafloor heat flux 4 2 effect of seafloor heat flux on sediment properties in addition to the ocean heat content the seafloor heat flux also affected the sediment temperature significantly by transporting heat between sediment and overlying water column fig 15 shows that the depth of sediment affected by seafloor heat flux with seasonal sediment temperature variation 0 1 c could be greater than 8 m in the area shallower than 50 m the maximum depth of sediment affected by the seafloor heat flux could be as large as 10 m fig 16 shows the sediment temperature profiles at a coastal station 121 e 36 n indicated by the white star in fig 15 on march 18 and september 24 when the bottom water temperature reached the minimum and maximum respectively the two profiles had significantly different vertical structures the sediment temperature increased with depth and possessed a positive vertical temperature gradient on march 18 whereas it decreased with depth and possessed a negative vertical gradient on september 24 as the sediment sound speed compressional wave speed increased approximately linearly with respect to temperature at a rate of 2 5 m s c rajan and frisk 1992 the maximum sediment sound speed variation was about 45 m s previous studies have shown that neglecting such a big variation in sediment sound speed may lead to a significant error in acoustic field calculation wood et al 2014 yang et al 2016 in addition the complex spatial temporal distribution of the seafloor heat flux in the ybs caused complex sediment sound speed variation fig 17a shows the sediment temperature profile along the 36 n transection indicated by the black dash line in fig 15 on march 18 and the corresponding sediment sound speed variation relative to the mean sediment sound speed of the whole transection with the assumption that the sediment was homogeneous and the sediment sound speed was only temperature dependent the sediment temperature increased with depth in the east but it decreased with depth in the west the corresponding sediment sound speed variation was larger than 15 m s as shown in fig 17b the strong and positive vertical gradient of the sediment sound speed gradually faded from west to east on september 24 the sediment temperature decreased with depth in the west and was basically depth independent in the east the corresponding sediment sound speed variation was larger than 35 m s fig 17c the vertical gradient of the sediment sound speed at the surface layer was negative in the west and gradually faded from west to east fig 17d previous studies mainly showed that the temporal variability of sediment sound speed has a significant effect on acoustic wave transmitting in water column and sediment for example yang et al 2016 showed that the sediment warming induced by bottom water temperature variation of 5 c can lead to a change of transmission loss larger than 10 db within 16 km wood et al 2014 showed that seasonal bottom water temperature variation larger than 2 c has a significant effect on seismic wave reflectivity at angles greater than 50 fig 17 suggests the temporal variability of sediment sound speed in the ybs was also significant a fixed sediment sound speed structure positive or negative vertical gradient which is usually used in marine acoustic field analysis such as the match field processing will therefore lead to failure in extraction of marine acoustic field information such as sound source depth and range estimation a model can predict spatial temporal variation of sediment temperature and sound speed will be needed for improvement of marine acoustic field analysis 4 3 other potential mechanisms contributing to seafloor heat flux in shallow seas this study mainly examined the seafloor heat flux driven by the bottom water temperature variation which were calculated according to the 1 d sediment temperature model other potential mechanisms however may have contributed to the seafloor heat flux in shallow seas first as the penetration depth of solar radiation in seawater can be over tens of meters sui et al 1998 kara et al 2005 lee et al 2005 liu et al 2018 solar radiation may have had a direct effect on the seafloor heat flux in shallow seas because the specific heat capacity of sediment is smaller than that of water the solar radiation at the sea bottom may make the top most sediment warmer than its overlying water the heat conduction process may then generate a temperature inversion at the bottom water that is the bottom most water is warmer than its overlying water the temperature inversion may further enhance turbulence mixing at the sea bottom and have an effect on water column even though the pioneering work of pivato et al 2018 suggested the effect of direct solar radiation on seafloor heat flux may be weak in the venice lagoon where the water depth is only about 1 m and the hydrological condition is simple the role of solar radiation in seafloor heat flux in the ybs may need further investigation in addition yang et al 2020 suggested that the pore water convection process which is associated with the sea bottom topography bottom currents and surface waves santos et al 2012 may significantly enhance seafloor heat transfer speed when the temperature difference of bottom water and pore water is significant therefore as illustrated in fig 18 the seafloor heat flux should be controlled by a series of complex thermal and hydrodynamic processes such as the heat conduction solar radiation currents and waves the model used in this study may be too simple in some occasions and a more complete model may be needed for a better understanding of seafloor heat flux and its effect on water column and sediment 5 summary in this study we calculated the seafloor heat flux driven by bottom water temperature variation in the ybs using a high resolution numerical ocean model and a 1 d sediment temperature model the importance of the seafloor heat flux in ocean heat content and sediment properties was evaluated in the coastal waters of the ybs depth 50 m the seafloor heat flux was larger than the lateral heat flux driven by circulation and ranked second only to surface net heat flux for the most important forcing mechanism of ocean heat content variation the accumulated heat absorbed released by sediment could cool warm the overlying water column by more than 1 c in the area within about 100 km off the west coast of the ys where the water depth is shallower than 30 m below the seafloor the complex spatial temporal distribution of the seafloor heat flux generated complex sediment sound speed distribution which may have had a significant effect on the shallow sea acoustic field furthermore because other mechanisms such as the solar radiation and pore water convection processes also may have contributed to the seafloor heat flux we suggest further observation additional modeling studies are therefore needed to gain a better understanding of seafloor heat flux in shallow seas credit authorship contribution statement guang bing yang conceptualization methodology formal analysis writing original draft writing review editing changshui xia software xue jun xiong funding acquisition supervision zhi tao feng resources zhao chen resources yang yang resources de jing ma data curation xia ju data curation quanan zheng writing review editing yeli yuan supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china nsfc grant numbers 41706038 41821004 42130406 41576027 41376038 and 40406009 the shandong provincial natural science foundation china grant number zr2017qd005 the basic scientific fund for national public research institutes of china grant number 2017q01 the nsfc shandong joint fund for marine science research centers china grant numbers u1406405 and u1606405 the international cooperation project of indo pacific ocean environment variation and air sea interaction grant number gasi 03 ipovai 05 the national programme on global change and air sea interaction grant numbers gasi 03 01 01 02 and gasi ipovai 01 05 the public science and technology research funds projects of ocean grant number 2009050240 the national key scientific instrument and equipment development projects grant number 2012yq12003908 and the national science and technology major project grant number 2016zx05057015 the observation data of sediment temperature profile and bottom water temperature can be obtained at this website https jmp sh bjkscbd the ncep reanalysis data are from http www nco ncep noaa gov pmb products gfs the woa18 data are from https www nodc noaa gov cgi bin oc5 woa18 woa18 pl the quikscat wind data are from https manati star nesdis noaa gov datasets quikscatdata php 
23822,the yellow and bohai seas ybs are shallow marginal seas located at the temperate latitudes of the western north pacific the seasonal bottom water temperature variation in the ybs can be greater than 20 c and therefore generates significant seafloor heat flux which significantly changes both the sediment temperature profile and heat content of the overlying water column in this study we investigated the seafloor heat flux driven by bottom water temperature variation in the ybs using a high resolution numerical ocean model and a one dimensional sediment temperature model the results showed that seafloor heat flux in the area shallower than 50 m was on the order of 10 w m2 the seafloor heat flux was larger than the lateral heat flux driven by circulation and ranked second only to surface net heat flux accounting for the most important forcing mechanism of ocean heat content variation in the coastal ybs the accumulated seafloor heat flux during the sediment cooling warming season could warm cool the overlying water column by about 1 c in the coastal ybs where the depth is shallower than 30 m the depth of sediment affected by seafloor heat flux seasonal sediment temperature variation 0 1 c could be as deep as 10 m the complex spatial temporal distribution of seafloor heat flux generated a complex distribution of sediment temperature and sound speed which may have an important effect on acoustic wave propagation in the ybs keywords seafloor heat flux acoustic velocity conductive heat flux water temperature yellow and bohai seas 1 introduction the yellow sea ys and the bohai sea bs are shallow and semi enclosed marginal seas located at the northwest pacific it has a mean depth of about 44 m and a maximum depth greater than 100 m fig 1 the horizontal scale of the yellow and bohai seas ybs is about 600 km 900 km the water depth increases gently from the shore to the 50 m isobath then the depth gradient is much steeper in the central ybs fig 1b in the shallow coastal ybs strong tide induced mixing weakens the temperature stratification and the bottom water temperature basically varies with the sea surface temperature which reaches maximum in summer and minimum in winter lü et al 2010 in the central ybs the yellow sea warm current yswc and the yellow sea cold water mass yscwm are the two most prominent phenomena isobe 2008 lü et al 2015 xiong et al 2019 yang et al 2017 the yswc which flows northward along the western side of the ys trough is generated under the prevalent northerly winds in winter to compensate transport of southward coastal currents along the chinese and korean coasts as the yswc transports warm and saline water from the northeastern east china sea into the ybs a warm water tongue can be identified in the distribution of sea surface temperature and bottom water temperature fig 2a the yscwm which is a basin scale water mass of low temperature beneath the seasonal thermocline generates a strong thermocline and strong temperature fronts in the ybs the yscwm is generated locally during the previous winter as a result of surface cooling and strong tide induced vertical mixing and reaches its peak in summer and then decays in autumn as shown in fig 2b the boundary of the yscwm can be outlined by the bottom water temperature front the bottom water temperature in the central ys in summer is 2 3 c cooler than that in winter because both the yswc and the yscwm are constrained by topography and mainly located at the ys trough the 50 m isobath is an important transition boundary of hydrological characteristics the water temperature structure in the ybs has a significant effect on the physical oceanography lie et al 2019 the biological environment lü et al 2013 ras et al 2013 and the acoustic field yang et al 2015a for example the strong stratification in summer makes the m 2 internal tide ubiquitous in the ybs liu et al 2019 the yswc brings warm water thus allowing the tropical species of zooplankton to survive in winter in the southern ys lü et al 2013 furthermore the temperature front movement in the coastal waters can quickly change the sound speed profile of water column and thus have an important effect on acoustic field yang et al 2015b a significant number of quantitative and qualitative analyses of the heat fluxes and ocean heat content variation have been conducted wei et al 2013 suggested that the surface net heat flux which is on the order of 100 w m2 hirose et al 1999 and the lateral heat flux are the main mechanisms forcing ocean heat content variation in the ybs the numerical ocean models such as the wave tide circulation coupled model developed by the key laboratory of marine science and numerical modeling masnum qiao et al 2006 have been applied successfully in the analysis of the yswc ma et al 2006 upwelling lü et al 2006 2010 and seasonal temperature variability associated with summertime circulation in the ybs xia et al 2006 the sediment temperature variation is significant in the ybs in shallow seas because the sound wave interacts with the sea bottom frequently the sediment acoustic properties such as the temperature dependent sediment sound speed have an important effect on shallow sea acoustic field information tang et al 2019 which can be used to detect underwater target yang et al 2015a measure current speed dushaw et al 2017 and protect marine mammals jiang et al 2020 a previous model study presented by rajan and frisk 1992 suggested that the seasonal bottom water temperature variation in the gulf of mexico may significantly change the sediment temperature and thus have an important effect on sediment sound speed based on model results wood et al 2014 showed that the seasonal bottom water temperature variation also can have an important effect on seismic reflectivity by changing sediment temperature profile yang et al 2020 designed and deployed an in situ sediment measurement system to investigate the synoptic time scale variability of sediment and the observations proved that the seafloor heat flux driven by bottom water temperature variation played an important role in sediment temperature and sound speed variation the seafloor heat flux transports heat between the sediment and the overlying water column and thus have an important effect on the temperature of both water column and sediment for the water column the seafloor heat flux together with the surface heat flux and the lateral heat flux determines the water column temperature for the sediment because the geothermal heat flow is small the seafloor heat flux should play the most important role in sediment temperature variation in shallow seas the bottom water warms the sediment when the bottom water is warmer than the sediment and vice versa therefore the bottom water temperature variation is a main mechanism driving the seafloor heat flux because the ybs are located at the temperate latitudes the seasonal bottom water temperature variation is significant the seafloor heat flux driven by bottom water temperature variation in the ybs however and its effects on the heat content of the water column and sediment properties have never been evaluated in this study we first calculate the seafloor heat flux driven by bottom water temperature variation in the ybs using a high resolution numerical ocean model and a one dimensional 1 d sediment temperature model then the significance of seafloor heat flux on water column and sediment is evaluated by calculating its effect on ocean heat content and sediment sound speed section 2 introduces the two models and the seafloor heat flux calculation method and section 3 presents the model results and the spatial temporal distribution of seafloor heat flux in the ybs in section 4 we discuss the effects of the seafloor heat flux on ocean heat content and sediment properties and other potential mechanisms contributing to seafloor heat flux finally the summary is presented in section 5 unless otherwise indicated the seafloor heat flux in this paper indicates the seafloor heat flux driven by bottom water temperature variation 2 material and method 2 1 bottom water temperature simulation in this study we applied the masnum wave tide circulation coupled model hereafter referred to as the ocean model qiao et al 2006 in bottom water temperature simulation the circulation part of the ocean model was based on the princeton ocean model pom ezer et al 2002 we used the masnum wave model to simulate the wave field and to incorporate the surface wave induced mixing in the ocean model qiao et al 2004 the model domain 15 41 n 105 135 e with a horizontal scale of 2900 km 3200 km covered the entire ys the bs and the east china sea the horizontal resolution was 1 18 1 18 and we used 16 vertical sigma layers with higher resolution in the surface layer σ 0 0 00313 0 00625 0 0125 0 025 0 05 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 1 open boundary conditions were provided by a quasi global model which covered 78 s 65 n 0 360 with a horizontal resolution of 1 6 1 6 the wind field of the ncep reanalysis data 1980 1999 and the quikscat data 2000 2007 and surface heat flux of the ncep reanalysis data were used as the surface forcing conditions in the model the surface heat flux was of the haney type haney 1971 a radiation condition was used for open boundary velocity to include tidal current the m 2 tide is prevailing in the ybs and was added in the model the simulation results of the ocean model with similar configurations have been applied in analysis of seasonal water temperature variation dai et al 2006 upwelling lü et al 2008 drift characteristics of green macroalgae qiao et al 2011 and sediment transport dynamics lu et al 2011 in the ybs 2 2 sediment temperature simulation we simulated the sediment temperature using a 1 d heat conduction model hereafter referred to as the sediment temperature model rajan and frisk 1992 1 d 2 t d z 2 1 α 2 d t d t because the geothermal heat flow is small o 0 1 w m2 and to isolate the effect of the bottom water temperature variation the geothermal gradient was fixed at zero the bottom water temperature was assumed to be the same as the sediment temperature at z 0 therefore the depth time distribution of sediment temperature corresponding to a sinusoidal temperature variation t 0 exp i ω t applied at the seafloor z 0 is 2 t z t t 0 exp k z exp i ω t k z where k ω 2 α 2 α 2 k s ρ is the sediment thermal diffusivity k is the thermal conductivity s is the specific heat ρ is the density t 0 t 0 exp i φ φ is the initial phase of bottom water temperature variation the 1 d heat conduction equation is a homogeneous linear differential equation and thus it satisfies the principle of superposition that is if the sediment temperatures corresponding to sinusoidal bottom water temperature variations sbt ω1 and sbt ω2 are t ω1 and t ω2 respectively the sediment temperature corresponding to sbt ω1 sbt ω2 should be t ω1 t ω2 therefore the sediment temperature corresponding to a broadband bottom water temperature variation consisting of different frequency components can be calculated as follows jensen et al 2011 1 calculate the spectrum of broadband bottom water temperature variation t 0 t using the fast fourier transform fft to obtain the t 0 ω ω t 0 ω ω t 0 ω ω exp i φ ω the mean bottom water temperature t 0m should be removed before applying the fft 3 t 0 ω ω f f t t 0 t t 0 m 2 calculate sediment temperature corresponding to the broadband bottom water temperature variation using the fourier synthesis technique 4 t z t t 0 m 1 2 π ω max ω max t 0 ω ω e k z i k z e i ω t d ω according to the nyquist sampling theorem the ω max is half of the sample frequency of the bottom water temperature the t z t includes the response of sediment temperature to the time independent ω 0 and the time dependent ω 0 parts of the bottom water temperature variation when ω 0 the t ω 0 z t t 0 m this indicates the mean sediment temperature is depth independent and time independent and equal to the mean bottom water temperature in this study the sediment temperature model ran offline we applied a repeated 20 year daily climatology of modeled bottom water temperature as introduced in section 3 1 at the seafloor the estimated sediment temperature of the 11th year was extracted for further analysis to avoid the gibbs effect 2 3 seafloor heat flux estimation we estimated the seafloor heat flux from the sediment temperature profile as the product of the vertical sediment temperature gradient and thermal conductivity k as derived from eq 4 the vertical sediment temperature gradient is 5 t z t z 1 2 π ω max ω max t 0 ω e k z i k z e i ω t d ω z 1 2 π ω max ω max 2 k t 0 ω e k z e i ω t k z 3 π 4 d ω then the seafloor heat flux in this study can be defined as follows 6 s h f t z t z k z 0 k 2 π ω max ω max 2 k t 0 ω e i ω t 3 π 4 d ω k 2 π α ω max ω max ω t 0 ω e i ω t 3 π 4 d ω we added a minus sign to eq 6 to make the seafloor heat flux positive when the heat was transported downward from water to sediment as shown in eq 6 the seafloor heat flux is a function of sediment thermal conductivity k and sediment thermal diffusivity α 2 k ω 2 α 2 however the sediment thermal conductivity and sediment thermal diffusivity depend on sediment property which is spatially varying in the ybs zheng et al 2016 a detailed observation or estimation of sediment thermal conductivity and sediment thermal diffusivity in the ybs is scarce as listed in table 1 we collected several sediment parameters which were used in sediment temperature modeling wood et al 2014 used a representative assemblage of sediment grains consisting of 30 quartz 24 albite 6 muscovite 20 smectite and 20 calcium carbonate to model seafloor seismic reflectivity change induced by seasonal seafloor temperature variation and calculated the thermal conductivity and thermal diffusivity of the representative sediment with porosity of 40 50 and 60 case i case ii and case iii in table 1 case iv case v and case vi are sediment parameters derived from observations or estimations in the venice lagoon pivato et al 2018 the lake kinneret nishri et al 2015 and the gulf of mexico rajan and frisk 1992 it should be noted that the thermal diffusivity of case vi is close to that derived from our observations in the jiaozhou bay section 3 2 fig 3 compares the daily mean seafloor heat flux at a coastal station 121 e 36 n indicated by the white star in fig 10 simulated with different sediment parameters even though the thermal diffusivity and thermal conductivity used in simulations have a wide range of variation 0 22 0 6 10 6 m2 s and 0 8 1 8 w m c the maximum difference between the simulations and the average of the six cases is about 20 therefore in this study we arbitrarily used the sediment parameters of the case iii which is medium among the 6 cases to simulate the seafloor heat flux in the ybs in following sections 2 4 lateral heat flux estimation the lateral heat flux driven by horizontal advection can be calculated as 7 l h f z ρ 0 c p t z t d z where t t u t x v t y c p 4180 j kg c is specific heat capacity and ρ 0 1024 kg m3 is density 3 results 3 1 bottom water temperature simulation in this study we conducted a 38 year simulation 1980 2007 using the masnum wave tide circulation coupled model the 3 d temperature salinity and current were output daily fig 4 shows the comparison between the modeled and field measured bottom water temperature at six different stations as indicated by the red circles in fig 1 the results comparison covering four seasons and different water depths suggests the ocean model well captured the main pattern of seasonal bottom water temperature variation we obtained the daily and monthly climatology of water temperature by averaging the 38 year daily mean model output the climatology data were used for further analysis in this study the monthly climatology of ocean model output was compared with that of the woa18 which had a horizontal resolution of 1 4 as shown in fig 5 the comparison suggests the seasonal variation of the monthly climatology of the modeled water temperature is basically consistent with that of the woa18 at different water depths it should be noted that the water temperature observations in the woa18 are very limited in the ybs especially in the area west of 124 e in the area east of 124 e even though the water temperature observations are relatively abundant the depth difference between the water depth and the depth of the bottommost layer containing observations is relatively large 10 m at the stations with deeper water depth these suggest the bottom water temperature of the woa18 is mainly based on objectively analysis in the ybs fig 6 shows the monthly climatology of bottom water temperature of ocean model output and the woa18 in each month three main bottom water temperature characteristics can be identified in both the model result and the woa18 1 the bottom water temperature at the coastal ybs has a significant seasonal variation which reaches maximum in summer and minimum in winter 2 a warm tongue is generated along the western side of the ys trough by the yswc in winter 3 the bottom water temperature in the central ybs is dominated by the yscwm in summer the bottom water temperature derived from historical observations also suggests the ocean model can well reveal the yswc fig 5a in winter and the yscwm fig 5 m in summer in addition because the ocean model uses a terrain following sigma coordinate while the woa18 uses a z coordinate the bottom water temperature distribution of the ocean model is smoother fig 7 shows the modeled maximum seasonal bottom water temperature variation in the ybs the 10 c isothermal basically followed the 50 m isobath the seasonal variation of bottom water temperature was relatively small in the area deeper than 50 m while the maximum seasonal variation of bottom water temperature could be greater than 20 c in coastal shallow waters 3 2 sediment temperature profile simulation because the ocean model can present a reasonable bottom water temperature simulation we then simulate the sediment temperature profile with the daily climatology of the modeled 38 year bottom water temperature fig 8 compares the modeled sediment temperature and the in situ observations in the jiaozhou bay the sediment temperature profiles were measured using the long term multi parameter sediment measurement system lmsms which was equipped with a sediment temperature probe with 7 self contained sediment temperature sensors installed at depths of 0 5 0 6 0 7 0 8 0 9 1 and 1 1 m below seafloor in the summer observation and 0 3 0 4 0 5 0 6 0 7 0 8 and 0 9 m below seafloor in the winter observation the one month long summer observation was conducted from august 2 to 31 2019 the winter observation was conducted on january 3 2020 at eight adjacent stations 36 n 120 25 e as indicated by the red triangle in fig 1 detailed observation method was introduced by yang et al 2020 the sediment temperature was simulated with thermal diffusivity α 2 0 2 1 0 6 m 2 s which was calibrated with the one month long simultaneous bottom water temperature and sediment temperature observations by finding minimum root mean square error between measured and simulated sediment temperature profiles as shown in fig 8 the 1 d sediment temperature model well captured the seasonal variation of sediment temperature profile 3 3 spatial temporal distribution of seafloor heat flux in the yellow sea because the sediment temperature model can well simulate the sediment temperature profile then we can estimate the daily climatology of the seafloor heat flux with the sediment temperature driven by the modeled daily climatology of bottom water temperature fig 9 shows the monthly mean seafloor heat flux in january april july and october in warm season fig 9c the seafloor heat flux was negative in the center of the ybs because of the existence of the yscwm and was positive the sediment was warmed by water in coastal waters in cold season fig 9a the seafloor heat flux was positive in the center of the ybs because of the yswc and was negative in the coastal waters the transition boundary isoline of 0 w m2 of the seafloor heat flux changing from positive to negative basically followed the 50 m isobath the spatial distributions of the maximum absolute seafloor heat flux the seasonal variation of seafloor heat flux and the mean seafloor heat flux during the sediment warming and cooling seasons are shown in fig 10 at the coastal region with depth shallower than 50 m the maximum absolute seafloor heat flux was larger than 6 w m2 the seasonal variation of seafloor heat flux was larger than 10 w m2 and the mean seafloor heat flux during the sediment warming cooling season was larger smaller than 3 3 w m2 the black and red lines in fig 11 show the temporal variation of the seafloor heat flux at a coastal station 121 e 36 n indicated by the white star in fig 10 and a central ys station 124 e 36 n indicated by the black star in fig 10 respectively the variation of the seafloor heat flux at both stations clearly followed an annual cycle while sharing exactly the reverse phase change the seafloor heat flux at the coastal central ys station reached the maximum in august january and the minimum in january august the seafloor heat fluxes at both stations changed their signs in april and october the annual variation was about 20 w m2 at the coastal ys station whereas it was smaller than 4 w m2 at the central ys station 4 discussion 4 1 effect of seafloor heat flux on ocean heat content wei et al 2013 investigated the forcing mechanisms of heat content variations in the ybs using a numerical ocean model and suggested that the daily mean surface net heat flux and the lateral heat flux driven by the circulation contributed most to the ocean heat content variation in the ybs as the seafloor heat flux seemed to be significant in the ybs we compared the seafloor heat flux with the surface net heat flux and the lateral heat flux in this section the surface net heat flux used in comparison was the monthly climatology of the ncep reanalysis surface net heat flux data which were used in forcing the ocean model the lateral heat flux was first calculated using eq 7 with the daily climatology of the ocean model output and then averaged in each month the seafloor heat flux was also calculated using daily climatology bottom water temperature and then averaged by month the downward surface net heat flux and the seafloor heat flux were defined to be positive while the lateral heat flux flowing out of the water column was defined to be positive both the positive seafloor heat flux and the lateral heat flux contributed to cool the water column fig 12 compares the monthly climatology of the surface heat flux the lateral heat flux and the seafloor heat flux which are all averaged in the ybs north of 34 5 n the surface net heat flux varied approximately sinusoidally from about 170 w m2 in winter to about 150 w m2 in summer in an annual cycle hirose et al 1999 the annual mean of the absolute value of surface net heat flux was on the order of 100 w m2 which was about ten times larger than that of the seafloor heat flux in the coastal waters of the ybs the formation and southward extension of the yscwm generated positive lateral heat flux cooling water in the ybs from may to august the decay of the yscwm and the formation of the yswc generated a significant negative lateral heat flux warming water in the ybs from october to december the seafloor heat flux was significant in winter and summer from january to march the seafloor heat flux was larger than the lateral heat flux and should rank second only to surface net heat flux for the most important forcing mechanism of ocean heat content variation in the ybs from june to august the seafloor heat flux was about a half of the lateral heat flux and both the lateral advective heat flux and the seafloor heat flux acted to cool the water in the ybs the ratio of the magnitude of the seafloor heat flux to that of the surface net heat flux was 15 20 in february and september when the surface net heat flux was relatively small in addition to the difference in temporal variation we observed a significant difference in the spatial distributions of the seafloor heat flux and the lateral heat flux as shown in fig 10 the seafloor heat flux was significant in the coastal waters of the ybs where the depth was shallower than 50 m whereas the lateral heat flux which was forced mainly by the yscwm and the yswc was significant in the central ybs wei et al 2013 fig 13 compares the seafloor heat flux and the lateral heat flux averaged over the area shallower than 30 m and 50 m in the ybs north of 34 5 n in most months the seafloor heat flux was larger than the lateral heat flux in the area shallower than 50 m in february and september the ratio of the magnitude of the seafloor heat flux to that of the surface net heat flux was 20 30 the annual mean amplitudes of the seafloor heat flux and the lateral heat flux were 4 18 w m2 and 3 18 w m2 in the area shallower than 50 m while they were 4 87 w m2 and 1 03 w m2 in the area shallower than 30 m therefore in the shallower areas of the ybs depth 50 m the two main mechanisms forcing ocean heat content variation should be the surface heat flux and the seafloor heat flux whereas they were the surface heat flux and the lateral heat flux in the deeper region depth 50 m because the commonly used ocean models such as the pom ezer et al 2002 the fvcom chen et al 2006 and the roms shchepetkin and mcwilliams 2005 do not include the seafloor heat flux the overlook of seafloor heat flux may be a reason that we usually need assimilation technique to obtain satisfying model results the seafloor heat flux may have had different effects on the ocean heat content in different areas in the ybs because of its nonuniform spatial distribution as suggested by dai et al 2006 the role of local vertical diffusion in the subsurface water temperature variation was three to five times larger than that of the horizontal advection in the ys therefore the large amount of heat transported through the strong seafloor heat flux at the coastal waters in the ybs may have played an important role in local water temperature modulation the temperature decrease increase of the water column caused by the heat absorbed released by sediment during the sediment warming cooling period was estimated as 8 δ t t 1 t 2 s h f t d t c p ρ 0 h where h is water depth t 1 t 2 is the sediment warming or cooling period because the sediment warming cooling period is spatially varying fig 11 the t 1 and t 2 are also spatially varying as shown in fig 14 the water column within 100 km off the west coast of the ys where the water depth is shallower than 30 m could be cooled warmed by more than 1 c during the sediment warming cooling period it should be noted that this is only a rough estimate of the water temperature variation induced by neglecting the seafloor heat flux 4 2 effect of seafloor heat flux on sediment properties in addition to the ocean heat content the seafloor heat flux also affected the sediment temperature significantly by transporting heat between sediment and overlying water column fig 15 shows that the depth of sediment affected by seafloor heat flux with seasonal sediment temperature variation 0 1 c could be greater than 8 m in the area shallower than 50 m the maximum depth of sediment affected by the seafloor heat flux could be as large as 10 m fig 16 shows the sediment temperature profiles at a coastal station 121 e 36 n indicated by the white star in fig 15 on march 18 and september 24 when the bottom water temperature reached the minimum and maximum respectively the two profiles had significantly different vertical structures the sediment temperature increased with depth and possessed a positive vertical temperature gradient on march 18 whereas it decreased with depth and possessed a negative vertical gradient on september 24 as the sediment sound speed compressional wave speed increased approximately linearly with respect to temperature at a rate of 2 5 m s c rajan and frisk 1992 the maximum sediment sound speed variation was about 45 m s previous studies have shown that neglecting such a big variation in sediment sound speed may lead to a significant error in acoustic field calculation wood et al 2014 yang et al 2016 in addition the complex spatial temporal distribution of the seafloor heat flux in the ybs caused complex sediment sound speed variation fig 17a shows the sediment temperature profile along the 36 n transection indicated by the black dash line in fig 15 on march 18 and the corresponding sediment sound speed variation relative to the mean sediment sound speed of the whole transection with the assumption that the sediment was homogeneous and the sediment sound speed was only temperature dependent the sediment temperature increased with depth in the east but it decreased with depth in the west the corresponding sediment sound speed variation was larger than 15 m s as shown in fig 17b the strong and positive vertical gradient of the sediment sound speed gradually faded from west to east on september 24 the sediment temperature decreased with depth in the west and was basically depth independent in the east the corresponding sediment sound speed variation was larger than 35 m s fig 17c the vertical gradient of the sediment sound speed at the surface layer was negative in the west and gradually faded from west to east fig 17d previous studies mainly showed that the temporal variability of sediment sound speed has a significant effect on acoustic wave transmitting in water column and sediment for example yang et al 2016 showed that the sediment warming induced by bottom water temperature variation of 5 c can lead to a change of transmission loss larger than 10 db within 16 km wood et al 2014 showed that seasonal bottom water temperature variation larger than 2 c has a significant effect on seismic wave reflectivity at angles greater than 50 fig 17 suggests the temporal variability of sediment sound speed in the ybs was also significant a fixed sediment sound speed structure positive or negative vertical gradient which is usually used in marine acoustic field analysis such as the match field processing will therefore lead to failure in extraction of marine acoustic field information such as sound source depth and range estimation a model can predict spatial temporal variation of sediment temperature and sound speed will be needed for improvement of marine acoustic field analysis 4 3 other potential mechanisms contributing to seafloor heat flux in shallow seas this study mainly examined the seafloor heat flux driven by the bottom water temperature variation which were calculated according to the 1 d sediment temperature model other potential mechanisms however may have contributed to the seafloor heat flux in shallow seas first as the penetration depth of solar radiation in seawater can be over tens of meters sui et al 1998 kara et al 2005 lee et al 2005 liu et al 2018 solar radiation may have had a direct effect on the seafloor heat flux in shallow seas because the specific heat capacity of sediment is smaller than that of water the solar radiation at the sea bottom may make the top most sediment warmer than its overlying water the heat conduction process may then generate a temperature inversion at the bottom water that is the bottom most water is warmer than its overlying water the temperature inversion may further enhance turbulence mixing at the sea bottom and have an effect on water column even though the pioneering work of pivato et al 2018 suggested the effect of direct solar radiation on seafloor heat flux may be weak in the venice lagoon where the water depth is only about 1 m and the hydrological condition is simple the role of solar radiation in seafloor heat flux in the ybs may need further investigation in addition yang et al 2020 suggested that the pore water convection process which is associated with the sea bottom topography bottom currents and surface waves santos et al 2012 may significantly enhance seafloor heat transfer speed when the temperature difference of bottom water and pore water is significant therefore as illustrated in fig 18 the seafloor heat flux should be controlled by a series of complex thermal and hydrodynamic processes such as the heat conduction solar radiation currents and waves the model used in this study may be too simple in some occasions and a more complete model may be needed for a better understanding of seafloor heat flux and its effect on water column and sediment 5 summary in this study we calculated the seafloor heat flux driven by bottom water temperature variation in the ybs using a high resolution numerical ocean model and a 1 d sediment temperature model the importance of the seafloor heat flux in ocean heat content and sediment properties was evaluated in the coastal waters of the ybs depth 50 m the seafloor heat flux was larger than the lateral heat flux driven by circulation and ranked second only to surface net heat flux for the most important forcing mechanism of ocean heat content variation the accumulated heat absorbed released by sediment could cool warm the overlying water column by more than 1 c in the area within about 100 km off the west coast of the ys where the water depth is shallower than 30 m below the seafloor the complex spatial temporal distribution of the seafloor heat flux generated complex sediment sound speed distribution which may have had a significant effect on the shallow sea acoustic field furthermore because other mechanisms such as the solar radiation and pore water convection processes also may have contributed to the seafloor heat flux we suggest further observation additional modeling studies are therefore needed to gain a better understanding of seafloor heat flux in shallow seas credit authorship contribution statement guang bing yang conceptualization methodology formal analysis writing original draft writing review editing changshui xia software xue jun xiong funding acquisition supervision zhi tao feng resources zhao chen resources yang yang resources de jing ma data curation xia ju data curation quanan zheng writing review editing yeli yuan supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china nsfc grant numbers 41706038 41821004 42130406 41576027 41376038 and 40406009 the shandong provincial natural science foundation china grant number zr2017qd005 the basic scientific fund for national public research institutes of china grant number 2017q01 the nsfc shandong joint fund for marine science research centers china grant numbers u1406405 and u1606405 the international cooperation project of indo pacific ocean environment variation and air sea interaction grant number gasi 03 ipovai 05 the national programme on global change and air sea interaction grant numbers gasi 03 01 01 02 and gasi ipovai 01 05 the public science and technology research funds projects of ocean grant number 2009050240 the national key scientific instrument and equipment development projects grant number 2012yq12003908 and the national science and technology major project grant number 2016zx05057015 the observation data of sediment temperature profile and bottom water temperature can be obtained at this website https jmp sh bjkscbd the ncep reanalysis data are from http www nco ncep noaa gov pmb products gfs the woa18 data are from https www nodc noaa gov cgi bin oc5 woa18 woa18 pl the quikscat wind data are from https manati star nesdis noaa gov datasets quikscatdata php 
23823,in the present study a newly designed radiative forcing scheme i e impulsive radiative forcing scheme irfs is applied in the one dimensional regional ocean modeling system carbon silicate nitrate ecosystem roms cosine model to reproduce under ice phytoplankton blooms uibs in the arctic ocean the model results obtained with the irfs and the traditional continuous radiative forcing scheme crfs are compared with observations of an uib north of svalbard it is found that the new irfs performs much better than the traditional crfs with lower biases lower root mean square difference rmsd and a higher correlation coefficient r especially at the near surface layer of the water column 0 15 m it is also found that in the simulations with the crfs the uib started earlier and maximum chlorophyll concentration was more than twice the observed data however the uib with the irfs is similar to observations in terms of uib timing and magnitude since the irfs allows more solar radiation to penetrate through the upper water column phytoplankton growth is supported at greater water depth 10 40 m therefore this model reproduces a deeper phytoplankton bloom and corresponding deepened subsurface chlorophyll maxima which agrees well with the observations additionally the introduction of melt ponds into the irfs model plays a vital role in accelerating spring uibs because ponded ice can transmit more light however the magnitude of integrated chlorophyll a hardly changes between the model runs with and without melt ponds this study proposes a more accurate averaging of the light field that simply changes the averaging procedure to take into account horizontal light variability at the sub grid scale and provides an approach to improve radiative forcing scheme in the pan arctic model case keywords arctic ocean under ice phytoplankton blooms radiative forcing scheme physical biogeochemical model 1 introduction in recent decades the arctic ocean has experienced rapid changes in sea ice extent and thickness with old stable multi year ice being largely replaced by young thinner first year ice maslanik et al 2011 stroeve et al 2012 king et al 2018 according to the national snow and ice data center nsidc records the sea ice extent in the arctic showed a clear downward trend from 1978 to 2020 and reached its lowest level on record in september 2012 https nsidc org arcticseaicenews recently under ice phytoplankton blooms uibs were widely observed in the arctic mundy et al 2009 2014 arrigo et al 2012 assmy et al 2017 oziel et al 2019 as a result of sea ice thinning kwok and rothrock 2009 polyakov et al 2012 horvat et al 2017 and increased melt pond fraction rösel et al 2012 clement kinney et al 2020 the thinning sea ice and increasing melt pond coverage increases light transmission to the underlying water column that initializes uibs frey et al 2011 arrigo et al 2012 palmer et al 2014 zhang et al 2015 ardyna et al 2020a b additionally sea ice melting and water column stratification in spring contribute to driving bloom dynamics lowry et al 2018 accordingly uibs have been widely observed across the arctic ocean which may challenge the previous paradigms of arctic wide production that under ice phytoplankton production can be negligible due to the strong light attenuation of sea ice and snow arrigo and van dijken 2015 ardyna et al 2020a b payne et al 2021 massive uibs can generate ecological consequences as they enhance the arctic ocean s under ice productivity arrigo et al 2014 clement kinney et al 2020 however uibs may consume nutrients and thus limit pelagic phytoplankton growth in open waters after sea ice retreating jin et al 2016 therefore changes in the total primary production in the arctic ocean may or may not be correlated directly to sea ice changes depending on nutrient availability jin et al 2016 although uibs are critical to arctic production studies are limited due to sporadic observations limited by the harsh environment at high latitudes lee et al 2016 clement kinney et al 2020 also current satellite based estimates of high latitude annual primary production are confirmed to be underestimated by an order of magnitude because satellites cannot detect phytoplankton beneath sea ice arrigo et al 2012 2014 thus to bridge this gap physical biogeochemical models are important tools for understanding the ecosystem processes in the arctic ocean and for revealing their regulating factors jin et al 2006 horvat et al 2017 it is worth mentioning that multiple numerical pelagic biogeochemical models have been used successfully to study the arctic ocean planktonic ecosystems in various spatial temporal scales e g slagstad and støle hansen 1991 walsh et al 2004 lavoie et al 2009 zhang et al 2010 2015 mortenson et al 2017 schourup kristensen et al 2018 the significance of under ice productivity has been confirmed by many model studies in which the under ice production contributes about one third of the arctic total production popova et al 2010 jin et al 2016 schourup kristensen et al 2018 based on the three dimensional 3d biology ice ocean modeling and assimilation system biomas zhang et al 2015 showed that the area fraction of uibs in the arctic increased in response to the increasing light availability and nutrient availability in the upper 100 m of the ocean during 1988 2013 however compared to the particulate organic carbon concentrations observed by the impacts of climate on ecosystems and chemistry of the arctic pacific environment icescape program biomas model s results were inconsistent in simulating the uib s depth and subsurface chlorophyll maxima scm according to the model experiments of palmer et al 2014 on varying melt pond coverage there was no phytoplankton growth beneath the ice until the melt pond fraction increased to 10 the regional annual net primary production in the 0 pond run was 4 7 lower than the result of the 30 pond run however compared with the increasing trend in melt pond fraction the thinning of sea ice is more significant to increase the bloom potential in the arctic horvat et al 2017 lavoie et al 2009 indicated that the snow ice cover melt and or ice break up control s the phytoplankton bloom timing and the bloom s magnitude is nutrient limited additionally in terms of the community structure in the model study of slagstad and støle hansen 1991 it was shown that except for the diatoms that dominated the bloom phaeocystis also contribute to the nitrate exhaustion in the upper 30 m of the water column in the barents sea a simple primary production model described by assmy et al 2017 also studied the growth potential of phaeocystis under the sea ice cover north of svalbard the model reproduced the considerable increase of phaeocystis beneath the sea ice cover during the n ice2015 expedition from may to june 2015 however the model neglected effects of nutrient limitation grazing and non grazing mortality previous studies have indicated that solar radiation is important for biogeochemical simulations in high latitude regions and the light attenuation by sea ice plays an important role in calculating under ice radiation laufkötter et al 2015 lee et al 2016 simo matchim et al 2017 schourup kristensen et al 2018 in the literature e g palmer et al 2014 zhang et al 2015 mortenson et al 2017 and stroeve et al 2021 the common radiative forcing scheme is based on the area weighted average method castellani et al 2022 which was originally defined by perovich 2005 however because of the heterogeneous distribution of sea ice and the relative movement between ice and the underlying water column solar radiation penetrating into the water column may not be horizontally homogeneous it may imply large spatial fluctuations in a sub grid scale as the water column alternates among different surface conditions hill et al 2018 lowry et al 2018 massicotte et al 2019 ardyna et al 2020b as a result the area weighted average radiation scheme may generate misestimation of phytoplankton growth because of the nonlinear relationship between phytoplankton growth with light slagstad and støle hansen 1991 hill et al 2018 consequently the magnitude of uibs may also be misestimated in models zhang et al 2015 mortenson et al 2017 although several studies suggested that improvements could be achieved by using higher spatial resolution models allowing to better capture the heterogeneity of light penetration popova et al 2010 schourup kristensen et al 2018 2021 it is still hard to reproduce all aspects of the locally small scale 1 km sea ice features such as melt ponds and leads wang et al 2016 massicotte et al 2019 therefore the present study designs a new radiative forcing scheme to offset the simulation biases caused by the traditional radiative forcing scheme the main motivation of this study is to design and deploy a new radiative forcing scheme in a one dimensional 1d physical biogeochemical coupled model to improve the model s ability in reproducing the uib observed north of svalbard during the norwegian young sea ice expedition n ice2015 the rest of the paper is structured as follows in section 2 the numerical model and the two radiative forcing schemes are described in section 3 the model results are compared with the observed data during the drift of n ice2015 floe 3 and based on the results the differences between the two radiative forcing schemes and the regulating factors that drive uibs are discussed finally in section 4 some conclusions are provided 2 materials and methods 2 1 description of the n ice2015 expedition the n ice2015 expedition with the vessel lance frozen in the arctic ice pack provided a research platform for interdisciplinary investigation in the high arctic granskog et al 2016 during this expedition a phaeocystis dominated uib in the arctic ocean was captured assmy et al 2017 ardyna et al 2020a b this uib was encountered over the yermak plateau north of svalbard during the drift of floe 3 from may to early june 2015 fig 1 granskog et al 2018 analyses of the local currents and the chl a concentrations in this area implied that the bloom grew in situ beneath the ice pack the almost unchanged silicate concentration in the upper 50 m during the bloom period suggested that no substantial diatom growth had taken place in this area assmy et al 2017 leads in the ice pack were frequently created by ice divergence events prior to the bloom period itkin et al 2017 which is characteristic of the ice pack north of svalbard willmes and heinemann 2016 mixed layer depth shallowed dramatically after may 25th from an average of 64 m to an average of 6 m meyer et al 2017 and the water column was highly stratified when the bloom took place assmy et al 2017 the uib coincided with pycnocline shallowing and a high refrozen lead fraction which provided favorable conditions for the uib development even below sea ice covered with thick snow assmy et al 2017 the surface nitrate inventory was nearly depleted from 10 37 to 1 42 μ m ol l 1 due to the consumption by phytoplankton and small vertical nitrate flux caused by the strong upper ocean stratification during the bloom period randelhoff et al 2016 assmy et al 2017 n ice2015 provided novel interdisciplinary data from the high arctic granskog et al 2018 these data will be used to improve model initialization parameterization climatological nudging and validation 2 2 general description of the 1d model this study is based on a 1d version of the 3d physical biogeochemical coupled regional ocean modeling system carbon silicate nitrate ecosystem roms cosine model xiu and chai 2011 in this model the biogeochemical model is based on the cosine model developed by chai et al 2002 and is modified to contain 15 state variables including 1 seven dissolved matters i e nitrate no3 ammonium nh4 silicate si oh 4 phosphate po4 dissolved oxygen do dissolved inorganic carbon tco2 and total alkalinity talk 2 two kinds of particles i e particulate organic nitrogen pon and biogenic silica bsi 3 two phytoplankton types i e non diatoms p1 mainly phaeocystis in the present study and diatoms p2 and the corresponding chlorophyll chl a1 and chl a2 of these phytoplankton components 4 two grazer types i e microzooplankton z1 and mesozooplankton z2 note that all the above variables are described in detail in chai et al 2002 and xiu and chai 2011 2014 table b 2 provides a list of parameters used in the model and their units and values 2 3 model setup and data sources the 1d roms cosine model is set to run under a lagrangian coordinate implying that the position of the 1d model drifts along with the drift of floe 3 of the n ice2015 expedition fig 1 granskog et al 2018 the model is run at a time step of 600 s and the model s largest depth is fixed to 991 7 m the vertical coordinate is divided into 100 layers with the resolution varies from 0 58 m at the sea surface to 28 1 m at the bottom layer the simulation is initialized with the observed profiles of temperature salinity nitrate silicate phosphate ammonium phytoplankton and corresponding chl a assmy et al 2016 on may 18th before the uib started by fixing the known variables to the initial conditions and forcing of may 18th the model is spun up for three model years to reach a steady state to derive the initial biomass of the two zooplankton groups and the initial value of other state variables i e do pon bsi tco2 talk which cannot be obtained from the observations directly to make the physical environment realistic in this model the water temperature and salinity are assimilated daily from observations dodd et al 2016 the european centre for medium range weather forecasts ecmwf reanalysis data era 5 is used to produce the hourly atmospheric forcing including air temperature surface pressure relative humidity shortwave radiation net longwave radiation wind speed and precipitation moreover extensive field data of snow and sea ice thickness from floe 3 of the n ice2015 expedition rösel et al 2017 are used to calculate the mean thicknesses of different types of sea ice measured incident and transmitted photosynthetically available radiation par data are used to calculate the sea ice extinction coefficients taskjelle et al 2016 the areal fractions of thick ice thin ice and open water are taken from assmy et al 2017 the fraction of melt ponds is from the multi year average of the melt pond data provided by the integrated climate data center icdc http icdc zmaw de rösel et al 2012 istomina et al 2015 2 4 definition of two different radiative forcing schemes in the present study a new radiative forcing scheme is designed and used in the 1d roms cosine model the traditional radiative forcing scheme is also adopted by the model for comparison as shown in fig 2a and b we assume the pack ice over the water column is a mix of four sea surface types thick ice thin ice melt ponds open water and they are classified as 1 thick ice sea ice thickness larger than 28 cm with snow cover larger than 5 cm representing large areas of thick ice in the region 2 thin ice sea ice thickness less than or equal to 28 cm with snow cover less than or equal to 5 cm 3 melt ponds 4 open water we suppose this spatially heterogeneous pack ice drifts along with the underlying water column although there are relative motions between them accordingly two different radiative forcing schemes are established as 1 continuous radiative forcing scheme crfs this scheme was extensively used in previous studies e g palmer et al 2014 zhang et al 2015 assmy et al 2017 mortenson et al 2017 castellani et al 2022 in this scheme the water column is treated as a whole fig 2a and the par at the ice ocean interface is derived by eq 1 as the weighted mean of transmitted par for all surface conditions p a r s as shown in fig 3b the par time series at the sea water surface shows a continuous and smooth sinusoidal wave shape thus hereafter this radiative scheme is called the continuous radiative forcing scheme in this scheme phytoplankton growth g c o n at each time step is calculated as 1 p a r s i 1 n p a r s i f i c e i 2 g c o n f t p a r s n where p a r s i stands for the par under each type of surface conditions i namely thick thin ponded ice and open water n 4 stands for the different surface conditions considered in the model and f i c e i stands for the areal fraction of different surface types since the variations of sea surface types are provided daily f i c e i are fixed in a diurnal cycle also t and n represent the temperature and nutrients respectively 2 impulsive radiative forcing scheme irfs in this scheme we divide the underlying water column into several isolated sub columns and each of them can only be covered by one sea surface type at a time step fig 2b given that there are relative motions between the spatially heterogeneous ice pack and the underlying water column the model assumes a 144 time steps 24 h divided by 600 s time interval diurnal cycle with alternating periods of sea ice melt ponds and open water note that the time steps occupied by a certain surface type in one day is derived by its areal fraction f i c e i in that day for example 1 for thick ice is simulated as a diurnal cycle with 144 time steps of thick ice and zero steps of other surface types while the fractions of 0 91 0 03 0 04 and 0 02 for thick ice thin ice melt ponds and open water respectively are simulated as a diurnal cycle with 133 time steps of thick ice 4 time steps of thin ice 6 time steps of melt ponds and 3 time steps of open water fig 2c in this condition for each sub column the sea surface par value tends to have an impulsive shape with a higher value during open water or melt ponds and lower value under the ice covered conditions fig 3c thus it is called the impulsive radiative forcing scheme phytoplankton growth g i m p at each time step of is calculated as 3 g i m p f t p a r s i n in contrast with the crfs g i m p at each time step is calculated with one surface condition thick thin ponded ice or open water in this model this scheme converts the spatial sea ice variability into temporal sequences changes and attempts to reproduce the realistic conditions in which a water column experiences different surface types in a diurnal cycle in the present study in view of the spatial heterogeneity of the surface the water column is divided into 50 small sub columns fig 2b these sub columns are simulated in independent model runs and their diurnal sequences of four types of surface conditions are random finally when the 50 model runs are finished we calculate the ensemble mean of these simulation results as the final result of this scheme the ensemble mean represents the mean condition of the water column and is comparable with the traditional crfs furthermore melt ponds on sea ice strongly reduce the surface albedo and the extinction effect enhancing light transmission to the underlying water column rösel et al 2012 therefore in order to examine the model performance with the two radiative forcing schemes and the impact of melt ponds we configure three comparison cases as shown in table 1 cases 1 and 2 are used to examine the model improvement due to the new radiative forcing scheme case 3 is used to examine the modulating effect of melt ponds on the uibs 2 5 transmission of incident par through sea ice and the water column we use hourly shortwave radiation from ecmwf to simulate the daily light cycle in the model there is only part of the spectrum 400 700 nm relevant for biological processes arrigo et al 2014 castellani et al 2022 which is termed par therefore the par to shortwave radiation ratio of 0 43 is used to determine the incident par on the snow ice surface p a r i n in unit w m 2 zhang et al 2010 frants et al 2020 to calculate the intensity of sea surface par p a r s the procedure of light et al 2008 and duarte et al 2015 is followed 4 p a r s p a r i n 1 a l b s exp k s z s i 0 i c e exp k i c e z i c e where a l b s is the snow surface albedo k s and k i c e are extinction coefficients of snow and ice respectively also i 0 i c e denotes the fraction of radiation transmitting through the highly scattering surface of the ice and z s and z i c e are snow and sea ice thicknesses respectively it should be noted that extensive field surveys confirmed that snow ice thicknesses for thick thin ice did not change significantly during the drift of floe 3 thus although fractions of four types of surface condition vary the mean snow ice thicknesses for thick thin ice are constant during the simulation period the mean value of thin ice thickness is 25 cm with the snow cover of 5 cm and the mean value of thick ice thickness is 149 cm with the snow cover of 45 cm following assmy et al 2017 the coefficients used in eq 4 are adjusted using the n ice2015 dataset taskjelle et al 2016 for thick ice with thick snow some of the parameters in eq 4 including a l b s i 0 i c e and k i c e are from previous studies light et al 2008 taskjelle et al 2017 also z s and z i c e the mean thickness of thick snow and thick ice are 45 cm and 149 cm respectively k s for thick snow is derived based on the measured incident and transmitted par taskjelle et al 2016 and its value is 10 69 m 1 similarly for thin ice with thin snow transmittance measurements for snow ice and bare ice were done in the n ice2015 expedition according to these measurements and the known parameters a l b s and i 0 i c e light et al 2008 the extinction for thin bare ice can be estimated as 3 25 m 1 subsequently k s for thin snow 8 98 m 1 is estimated from the transmittance measurements with snow cover for melt ponds the a l b s i 0 i c e and k i c e are 0 251 0 645 and 0 99 respectively light et al 2008 see specific parameters in table b 2 in the water column light attenuation is calculated as a function of water column depth and chl a concentration chai et al 2002 xiu and chai 2014 5 p a r z p a r s exp k 1 z k 2 z 0 chl a 1 chl a 2 d z where k 1 is the light attenuation due to seawater 0 046 m 1 and k 2 is the light attenuation due to phytoplankton 0 03 m 1 3 results and discussion 3 1 overall comparison of the two radiative forcing schemes the simulation results show that all of the independent model runs with irfs for the 50 sub columns can reproduce the main features of the observed uib including the scm structure from late may to early june in 2015 the ensemble mean of these 50 model runs will be shown later the upper 50 m averaged chl a of these 50 model runs are convergent with a mean standard deviation of 0 092 fig 4a and b thus it implies that the diurnal sequence of different surface types does not significantly affect the simulation results mainly due to the relatively small light variability and the large predominance of one ice type over the others during the simulation period based on the observation simulation match up chl a the taylor diagram fig 4a with normalized standard deviation sd the root mean square difference rmsd and correlation coefficient r shows that the simulation results estimated by the irfs has a smaller sd 0 96 and rmsd 0 67 than those estimated by the crfs with values of 1 76 and 1 36 respectively the values also show that the model runs with the irfs have better model observed correlation relationship with a mean value of 0 76 than the crfs with a correlation coefficient of 0 64 to quantitatively compare the crfs and irfs cases the upper 50 m of the water column is divided into two layers by the mean mixed layer depth of 15 m during the bloom development comparisons between the observed and simulated chl a concentrations for the depth range 0 50 m and in both layers mentioned above are shown in fig 5 for the upper 50 m chl a is obviously overestimated by the crfs case with a bias of 1 79 mg m 3 while it is slightly underestimated by the irfs case with a bias of 0 04 mg m 3 fig 5a this can also be seen in fig 4b in which the crfs result shows a higher peak than the irfs result fig 5b shows an obvious overestimation of chl a within the depth of 0 15 m simulated by the crfs case with a bias of 3 34 mg m 3 in contrast the bias of the irfs case is 0 42 mg m 3 moreover the irfs case has higher model observed correlation and smaller rmsd than crfs case at 0 15 m fig 5b for the layer at 16 50 m the biases of irfs and crfs cases are 0 21 and 0 81 respectively and their r values are equal fig 5c the higher rmsd of the crfs case 5 46 indicates that for this depth range simulated chl a does not match observations very well 3 2 bloom process comparison of two radiative forcing scheme models as the sea ice concentration decline from may 23rd for the crfs model case p a r s increases accordingly and for the irfs case the period with high light exposure extends the daily average sea surface par processes are shown in fig 6a and b for both model cases daily par value increases from may 23rd and phytoplankton chl a increases correspondingly fig 6a f it implies that the impacts of increasing light penetrations on the initialization of rapid growth in under ice phytoplankton consequently nitrate is depleted to nearly zero from the surface to a depth of around 10 m for the continuous radiative case and to a depth of around 18 m for the irfs case fig 6g and h for the crfs case chl a remains close to initial values for only a short time 2 days and then increases rapidly on may 23rd exceeding the uib threshold of 2 5 mg m 3 lowry et al 2014 this increase occurs much earlier than the beginning of the observed uib fig 6e the simulated maximum chl a concentration is 17 1 mg m 3 which is more than twice the observed peak value 7 5 mg m 3 moreover par is attenuated rapidly in the water column resulting in a euphotic depth of 22 4 m during the bloom fig 6c as a result rapid phytoplankton growth is mainly confined to the surface layer leading to a significant vertical gradient of chl a across the euphotic depth during the bloom fig 6e for the irfs case the intermittent appearance of melt ponds and open water weakens the light attenuation due to snow ice which allows par to transmit to the deep layer intermittently fig 6d consequently the chl a distribution for the irfs case is more homogeneous than the crfs case in the vertical direction and the euphotic zone in the irfs is averaged of 43 0 m during the bloom which is comparable with previous study in the similar area with similar environmental conditions massicotte et al 2019 moreover the comparisons of chl a between observation and simulation results show that the irfs case can better reproduce the uib development than the crfs case chl a in the water column covered by the sea ice remains close to initial value 1 mg m 3 until thick ice reduces and the open water fraction starts to build up on may 24th phytoplankton bloom starts on may 24th and then the bloom forms with chl a greater than 2 5 mg m 3 between 0 30 m by may 26th with the increasing light transmission fig 6f over the next three days the bloom keeps on developing and peaks at 7 3 mg chl a m 3 in late may then the uib migrates downward following the nutricline forms a scm of 7 3 8 6 mg chl a m 3 at depth range of 11 31 m and deepens as time passes it is also worth mentioning that this modeled scm is consistent with the observational pattern in terms of depth and magnitude fig 6f 3 3 phytoplankton types simulated chl a concentrations of non diatoms and diatoms in the upper 50 m of the water column are shown in fig 7a and b note that the uib is dominated by non diatoms diatoms contribution is less than 2 2 of total chl a although a diatom increase is modeled between 30 50 m by the end of the simulation period fig 7b it is worth mentioning that this result is supported by the observational phytoplankton taxonomy data which shows that phaeocystis accounted for 55 92 of phytoplankton abundance also during the bloom period silicate was almost unconsumed suggesting that there was no substantial diatom growth during the observational period assmy et al 2017 diatom dominated uibs have been frequently reported from the arctic ocean mundy et al 2009 degerlund and eilertsen 2010 arrigo et al 2012 hill et al 2018 johnsen et al 2018 however the uib observed during the n ice2015 expedition is the first phaeocystis dominated uib assmy et al 2017 ardyna et al 2020b phaeocystis cells are possibly carried from lower latitudes to this area at greater depths by the atlantic water and then are mixed upwards to the upper ocean by the storm events in an earlier time of the year assmy et al 2017 leading to a higher phaeocystis concentration than diatoms in the initiation of the simulation the low light conditions beneath the snow covered drifting pack ice are apparently insufficient to sustain a diatom bloom in early spring phaeocystis are generally more competitive than diatoms in low light environment helping to maintain its dominance in the simulations sakshaug et al 2009 johnsen et al 2018 note that the photosynthetic parameterization of our model is from the onboard experiment cota et al 1994 assmy et al 2017 and phaeocystis dominance can also be seen in the model results moreover the low silicate inventory with the molar ratio of nitrogen to silicon n si much larger than 1 0 in this area limits diatom dominance ardyna et al 2020b as the surface silicate does not change significantly the n si ratio remains far higher than 1 0 until nitrate is nearly depleted by the uib at the end of may figs 6h and 7c this is quite different from the western arctic ocean where the water masses are influenced by pacific derived waters with higher silicate concentrations thus the dominant phytoplankton species in the pacific sector are represented by diatoms ardyna et al 2020a 3 4 growth limitation phytoplankton growth can be limited by temperature nutrients and light andersen 1989 smith and sakshaug 1990 gosselin et al 1997 hill and cota 2005 lee and whitledge 2005 campbell et al 2009 among the growth limiting factors light and nutrients are the decisive terms for arctic uibs popova et al 2010 lewis et al 2018 since the phaeocystis is the overwhelming dominant group in the n ice2015 uib light and nitrogen limitations and net growth of phaeocystis for both crfs and irfs cases are analyzed and the results are shown in fig 8 the limitation indices of light and nitrogen are calculated as 6 l l i m 1 exp α p a r μ m a x exp β p a r μ m a x 7 n l i m no 3 k n o 3 no 3 e φ 1 nh 4 nh 4 k n h 4 nh 4 where l l i m and n l i m represent the limitation indices of light and nitrogen respectively for every limitation index high value indicates less limitation also α is the initial slope of the photosynthesis irradiance curve β is the photoinhibition term μ m a x is the maximum growth rate k n o 3 and k n h 4 represent the half saturation constant for nitrate and ammonium and φ 1 is the nh 4 inhibition parameter values and units of all these parameters are shown in table b 2 for the irfs case following the thick ice decline the light limitation index increases rapidly from near zero to above 0 2 in the surface water from may 23rd fig 8a for the crfs case the light limitation index is higher than 0 1 immediately after the simulation starts and increases until the end of simulation when the bloom reaches peak value the light limitation index decreases sharply in the vertical direction especially under 20 m depth figs 6c and 8b as a result the light limitation index for the crfs case is much higher than that for the irfs case near the surface blue area above the solid black line in fig 8c while it is evidently lower in the deeper layer red area below the solid black line in fig 8c from may 24th the positive difference increases below the black line and reaches a positive peak on may 27th fig 8c which is related to earlier and overestimated bloom in the crfs case the irfs allows more par to intermittently penetrate through the upper water column and supports the phytoplankton growth in the deeper part 10 40 m meanwhile the crfs confine the bloom to the surface layer 15 m massive phytoplankton biomass accumulating near the surface further prevents par from reaching the deep water pavlov et al 2017 leading to the lower chl a concentration in deeper levels in both cases the nutrient limitation index keeps near 1 0 at the first five days and then decreases with the phytoplankton increase which vertically forms a nutricline fig 8d and e the major differences between fig 8d and e are the depth of the nutricline and the time when the nutrients in the upper 10 m depth are depleted there is a positive peak at near surface from may 26th to 28th in fig 8f which is because the earlier phytoplankton bloom leads to earlier nitrate depletion in the crfs case than in the irfs the maximal negative difference between 10 30 m from may 29th in fig 8f indicates the lower boundary of the phytoplankton bloom and the deeper scm in the irfs case than in the other case in addition the phytoplankton net growth rates of these two cases are quite different as shown in fig 8g the chl a concentration increment in the irfs case which is less than 0 1 mg m 3 day 1 can be neglected until may 23rd in contrast the net growth of phytoplankton chl a in the crfs case gradually increases since simulation starts and reaches the peak on may 24th within a shallower depth fig 8h thus the difference of net growth between these two cases is negative initially and then reaches the minimum value when the bloom develops fastest at the surface layer in the crfs case fig 8i soon afterward the positive maximum difference appears in the water column from the sea surface to the depth of 22 m note that above 8 2 m this maximum difference is due to nutrient limitation while below this depth the maximum difference is because of light limitation fig 8 shows the definite discrepancies of the phytoplankton growth process between these two models for both irfs and crfs cases an instantaneous light intensity of 0 016 w m 2 can support phaeocystis net growth when nutrients are plentiful note that this value is lower than the threshold values reported for arctic diatom blooms wang et al 2014 hill et al 2018 it implies the competitive advantage for low light conditions of phaeocystis than diatoms for the crfs case surface par is calculated by the weighted average of the par transmitted through different surface types and stays higher than the threshold all day thus a bloom develops earlier with the net growth of chl a exceeding 1 mg m 3 day 1 by the second day fig 8h as shown in eq 6 the relationship between par and phytoplankton growth is inherently nonlinear so that the crfs produces an overestimation of phytoplankton growth at surface though it is under high concentration sea ice floe for the irfs case because it generates an impulsive par field in the water column phytoplankton growth shows an impulsive pattern correspondingly under the thick ice solar radiation is attenuated to so extremely low value 0 016 w m 2 that can hardly support net phytoplankton growth therefore phytoplankton chl a may increase only in open water or under melt ponds while barely increasing under thick ice arrigo et al 2014 hill et al 2018 before may 24th the water column is covered by thick ice with thick snow for most of the day 99 sea ice concentration excluding ponded ice fig 6b net phytoplankton growth 2 5 mg m 3 day 1 accumulates during the ephemeral melt ponds open water conditions but these accumulated phytoplankton chl a will be completely consumed by self mortality and respiration during the thick ice periods therefore the bloom cannot start until may 24th when the daily net growth becomes positive with the decrease of thick ice fraction fig 8g to sum up in this study the bloom is triggered by the increasing par availability under a nutrient sufficient condition the irfs approach provides a more accurate averaging of the light field production does not scale linearly with light therefore light averaging prior to calculating production is mathematically inaccurate and thus produce inaccurate phytoplankton bloom when the bloom is progressing nutrients are reduced by phytoplankton growth and are rarely replenished much lower than the nitrate uptake from deeper water column due to shallow pycnocline and low mixing rates randelhoff et al 2016 it results in a nearly nitrate depleted surface layer afterward the surface bloom becomes nitrate limited primarily fig 8d and e additionally grazing pressure may be an important factor regulating bloom development campbell et al 2009 lee et al 2016 however in the present study low grazing on phaeocystis is simulated not shown and this result is supported by the finding that phaeocystis is considered unpalatable for the dominant calanus species ray et al 2016 hop et al 2021 3 5 impact of melt ponds on the model performance melt ponds are important for uibs to develop as they act like windows into the ocean and transmit 3 10 times more light than bare ice of the same thickness frey et al 2011 arrigo et al 2014 palmer et al 2014 in the present study the case 3 using the irfs without melt ponds is carried out to examine the impact of melt ponds simulation results show that this run can also reproduce the bloom process but chl a concentration exceeds the bloom threshold 2 5 mg m 3 only by may 30th which is four days later than the experiment with melt pond fraction from satellite fig 9a averaged chl a concentrations in the upper 50 m water column of the model runs with without melt ponds are shown in fig 9b for the run with melt ponds the averaged chl a reaches the peak value three days earlier may 30th vs june 2nd than in the no melt ponds run however the maximum averaged chl a value does not change significantly fig 9b this result agrees well with a previous study which indicated that doubling light intensity promotes an earlier bloom jin et al 2006 on the day of the peak surface chl a concentration the vertical extent of blooms in these two runs is 39 4 m melt pond coverage affects the progress of the phytoplankton bloom such as changes in the bloom initiation and peak timing but has little influence on bloom magnitude and depth it is worth mentioning that this finding supports the results of hill et al 2018 that 7 days simulated delay in melt ponds postponed the onset of phytoplankton growth but did not impact the maximum biomass this may essentially relate to the nutrient availability lavoie et al 2009 showed that the amount of nutrients available at the end of the winter could be the determining factor of the spring uib magnitude palmer et al 2014 also suggested that uibs are most likely to develop beneath sea ice with 10 melt pond coverage however it should be noted that their experiments did not include melt pond fraction between zero to 10 the results of the present study show that even a smaller fraction of ponded area than 10 can affect the occurrence of a uib 4 conclusions the 1d roms cosine model has been upgraded to adapt to the mix type ice cover condition in the arctic ocean by proposing a new impulsive radiative forcing scheme the impulsive radiative forcing scheme allows a random appearance of all ice conditions according to their areal fraction the model reproduces the temporal evolution of an under ice bloom in 2015 north of svalbard which was observed during the n ice2015 expedition ensemble runs show that the diurnal sequence of sea ice conditions does not influence the simulation results significantly compared with the widely used continuous radiative forcing scheme the impulsive radiative forcing scheme performs better with lower biases higher correlation coefficient and lower rmsd especially near the surface layer of the water column 0 15 m the simulation result of the continuous radiative case shows an earlier start of the bloom than observations and aggregation of chl a near the surface in contrast the simulation results of the impulsive radiative case agree well with observations and a deeper and later phytoplankton bloom and corresponding deepened subsurface chlorophyll maxima are also simulated the peak chlorophyll concentration of the impulsive radiative scheme is similar to observed data while that of the continuous radiative scheme is two times higher than observed data moreover sensitivity experiments with without melt pond cover in the impulsive radiative forcing scheme show that the introduction of melt ponds produces the bloom four days earlier but does not change the magnitude of chl a concentration significantly it indicates the important role of melt ponds in modulating the bloom timing this model is set to run under a lagrangian coordinate providing an approach for understanding the controlling process of observed ecological events during the expeditions as n ice2015 as arctic sea ice is becoming younger thinner and more fragmented with more leads and melt ponds schourup kristensen et al 2018 the irfs provides valuable insights into the treatment of heterogeneous sea ice surface in under ice biogeochemical simulations in a sub grid scale the 1d column can represent one grid cell in a 3d model and provides a tool for parameterization development mortenson et al 2017 this work is intended as a step to implement an improved radiative forcing scheme in the pan arctic model case credit authorship contribution statement yuexin gao methodology writing original draft visualization validation formal analysis data curation yang zhang resources methodology software writing review editing fei chai conceptualization program administration supervision funding acquisition mats a granskog resources validation writing review editing pedro duarte methodology writing review editing philipp assmy investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is supported by the national natural science foundation of china grant number 41730536 and 41941013 postgraduate research practice innovation program of jiangsu province china grant number kycx20 0418 the fundamental research funds for the central universities china grant number b200203133 and scientific research fund of the second institute of oceanography mnr grant number 14283 and jg2104 the n ice2015 expedition was supported by the former centre of ice climate and ecosystem ice at the norwegian polar institute p a was supported by the research council of norway project boom or bust grant number 244646 p d and m a g were supported by funding from the european union s horizon 2020 research and innovation programme through project crices climate relevant interactions and feedbacks the key role of sea ice and snow in the polar and global climate system grant number 101003826 also the support of eu project sidarus is acknowledged for the access to melt pond data appendix a see table a 1 appendix b see table b 2 
23823,in the present study a newly designed radiative forcing scheme i e impulsive radiative forcing scheme irfs is applied in the one dimensional regional ocean modeling system carbon silicate nitrate ecosystem roms cosine model to reproduce under ice phytoplankton blooms uibs in the arctic ocean the model results obtained with the irfs and the traditional continuous radiative forcing scheme crfs are compared with observations of an uib north of svalbard it is found that the new irfs performs much better than the traditional crfs with lower biases lower root mean square difference rmsd and a higher correlation coefficient r especially at the near surface layer of the water column 0 15 m it is also found that in the simulations with the crfs the uib started earlier and maximum chlorophyll concentration was more than twice the observed data however the uib with the irfs is similar to observations in terms of uib timing and magnitude since the irfs allows more solar radiation to penetrate through the upper water column phytoplankton growth is supported at greater water depth 10 40 m therefore this model reproduces a deeper phytoplankton bloom and corresponding deepened subsurface chlorophyll maxima which agrees well with the observations additionally the introduction of melt ponds into the irfs model plays a vital role in accelerating spring uibs because ponded ice can transmit more light however the magnitude of integrated chlorophyll a hardly changes between the model runs with and without melt ponds this study proposes a more accurate averaging of the light field that simply changes the averaging procedure to take into account horizontal light variability at the sub grid scale and provides an approach to improve radiative forcing scheme in the pan arctic model case keywords arctic ocean under ice phytoplankton blooms radiative forcing scheme physical biogeochemical model 1 introduction in recent decades the arctic ocean has experienced rapid changes in sea ice extent and thickness with old stable multi year ice being largely replaced by young thinner first year ice maslanik et al 2011 stroeve et al 2012 king et al 2018 according to the national snow and ice data center nsidc records the sea ice extent in the arctic showed a clear downward trend from 1978 to 2020 and reached its lowest level on record in september 2012 https nsidc org arcticseaicenews recently under ice phytoplankton blooms uibs were widely observed in the arctic mundy et al 2009 2014 arrigo et al 2012 assmy et al 2017 oziel et al 2019 as a result of sea ice thinning kwok and rothrock 2009 polyakov et al 2012 horvat et al 2017 and increased melt pond fraction rösel et al 2012 clement kinney et al 2020 the thinning sea ice and increasing melt pond coverage increases light transmission to the underlying water column that initializes uibs frey et al 2011 arrigo et al 2012 palmer et al 2014 zhang et al 2015 ardyna et al 2020a b additionally sea ice melting and water column stratification in spring contribute to driving bloom dynamics lowry et al 2018 accordingly uibs have been widely observed across the arctic ocean which may challenge the previous paradigms of arctic wide production that under ice phytoplankton production can be negligible due to the strong light attenuation of sea ice and snow arrigo and van dijken 2015 ardyna et al 2020a b payne et al 2021 massive uibs can generate ecological consequences as they enhance the arctic ocean s under ice productivity arrigo et al 2014 clement kinney et al 2020 however uibs may consume nutrients and thus limit pelagic phytoplankton growth in open waters after sea ice retreating jin et al 2016 therefore changes in the total primary production in the arctic ocean may or may not be correlated directly to sea ice changes depending on nutrient availability jin et al 2016 although uibs are critical to arctic production studies are limited due to sporadic observations limited by the harsh environment at high latitudes lee et al 2016 clement kinney et al 2020 also current satellite based estimates of high latitude annual primary production are confirmed to be underestimated by an order of magnitude because satellites cannot detect phytoplankton beneath sea ice arrigo et al 2012 2014 thus to bridge this gap physical biogeochemical models are important tools for understanding the ecosystem processes in the arctic ocean and for revealing their regulating factors jin et al 2006 horvat et al 2017 it is worth mentioning that multiple numerical pelagic biogeochemical models have been used successfully to study the arctic ocean planktonic ecosystems in various spatial temporal scales e g slagstad and støle hansen 1991 walsh et al 2004 lavoie et al 2009 zhang et al 2010 2015 mortenson et al 2017 schourup kristensen et al 2018 the significance of under ice productivity has been confirmed by many model studies in which the under ice production contributes about one third of the arctic total production popova et al 2010 jin et al 2016 schourup kristensen et al 2018 based on the three dimensional 3d biology ice ocean modeling and assimilation system biomas zhang et al 2015 showed that the area fraction of uibs in the arctic increased in response to the increasing light availability and nutrient availability in the upper 100 m of the ocean during 1988 2013 however compared to the particulate organic carbon concentrations observed by the impacts of climate on ecosystems and chemistry of the arctic pacific environment icescape program biomas model s results were inconsistent in simulating the uib s depth and subsurface chlorophyll maxima scm according to the model experiments of palmer et al 2014 on varying melt pond coverage there was no phytoplankton growth beneath the ice until the melt pond fraction increased to 10 the regional annual net primary production in the 0 pond run was 4 7 lower than the result of the 30 pond run however compared with the increasing trend in melt pond fraction the thinning of sea ice is more significant to increase the bloom potential in the arctic horvat et al 2017 lavoie et al 2009 indicated that the snow ice cover melt and or ice break up control s the phytoplankton bloom timing and the bloom s magnitude is nutrient limited additionally in terms of the community structure in the model study of slagstad and støle hansen 1991 it was shown that except for the diatoms that dominated the bloom phaeocystis also contribute to the nitrate exhaustion in the upper 30 m of the water column in the barents sea a simple primary production model described by assmy et al 2017 also studied the growth potential of phaeocystis under the sea ice cover north of svalbard the model reproduced the considerable increase of phaeocystis beneath the sea ice cover during the n ice2015 expedition from may to june 2015 however the model neglected effects of nutrient limitation grazing and non grazing mortality previous studies have indicated that solar radiation is important for biogeochemical simulations in high latitude regions and the light attenuation by sea ice plays an important role in calculating under ice radiation laufkötter et al 2015 lee et al 2016 simo matchim et al 2017 schourup kristensen et al 2018 in the literature e g palmer et al 2014 zhang et al 2015 mortenson et al 2017 and stroeve et al 2021 the common radiative forcing scheme is based on the area weighted average method castellani et al 2022 which was originally defined by perovich 2005 however because of the heterogeneous distribution of sea ice and the relative movement between ice and the underlying water column solar radiation penetrating into the water column may not be horizontally homogeneous it may imply large spatial fluctuations in a sub grid scale as the water column alternates among different surface conditions hill et al 2018 lowry et al 2018 massicotte et al 2019 ardyna et al 2020b as a result the area weighted average radiation scheme may generate misestimation of phytoplankton growth because of the nonlinear relationship between phytoplankton growth with light slagstad and støle hansen 1991 hill et al 2018 consequently the magnitude of uibs may also be misestimated in models zhang et al 2015 mortenson et al 2017 although several studies suggested that improvements could be achieved by using higher spatial resolution models allowing to better capture the heterogeneity of light penetration popova et al 2010 schourup kristensen et al 2018 2021 it is still hard to reproduce all aspects of the locally small scale 1 km sea ice features such as melt ponds and leads wang et al 2016 massicotte et al 2019 therefore the present study designs a new radiative forcing scheme to offset the simulation biases caused by the traditional radiative forcing scheme the main motivation of this study is to design and deploy a new radiative forcing scheme in a one dimensional 1d physical biogeochemical coupled model to improve the model s ability in reproducing the uib observed north of svalbard during the norwegian young sea ice expedition n ice2015 the rest of the paper is structured as follows in section 2 the numerical model and the two radiative forcing schemes are described in section 3 the model results are compared with the observed data during the drift of n ice2015 floe 3 and based on the results the differences between the two radiative forcing schemes and the regulating factors that drive uibs are discussed finally in section 4 some conclusions are provided 2 materials and methods 2 1 description of the n ice2015 expedition the n ice2015 expedition with the vessel lance frozen in the arctic ice pack provided a research platform for interdisciplinary investigation in the high arctic granskog et al 2016 during this expedition a phaeocystis dominated uib in the arctic ocean was captured assmy et al 2017 ardyna et al 2020a b this uib was encountered over the yermak plateau north of svalbard during the drift of floe 3 from may to early june 2015 fig 1 granskog et al 2018 analyses of the local currents and the chl a concentrations in this area implied that the bloom grew in situ beneath the ice pack the almost unchanged silicate concentration in the upper 50 m during the bloom period suggested that no substantial diatom growth had taken place in this area assmy et al 2017 leads in the ice pack were frequently created by ice divergence events prior to the bloom period itkin et al 2017 which is characteristic of the ice pack north of svalbard willmes and heinemann 2016 mixed layer depth shallowed dramatically after may 25th from an average of 64 m to an average of 6 m meyer et al 2017 and the water column was highly stratified when the bloom took place assmy et al 2017 the uib coincided with pycnocline shallowing and a high refrozen lead fraction which provided favorable conditions for the uib development even below sea ice covered with thick snow assmy et al 2017 the surface nitrate inventory was nearly depleted from 10 37 to 1 42 μ m ol l 1 due to the consumption by phytoplankton and small vertical nitrate flux caused by the strong upper ocean stratification during the bloom period randelhoff et al 2016 assmy et al 2017 n ice2015 provided novel interdisciplinary data from the high arctic granskog et al 2018 these data will be used to improve model initialization parameterization climatological nudging and validation 2 2 general description of the 1d model this study is based on a 1d version of the 3d physical biogeochemical coupled regional ocean modeling system carbon silicate nitrate ecosystem roms cosine model xiu and chai 2011 in this model the biogeochemical model is based on the cosine model developed by chai et al 2002 and is modified to contain 15 state variables including 1 seven dissolved matters i e nitrate no3 ammonium nh4 silicate si oh 4 phosphate po4 dissolved oxygen do dissolved inorganic carbon tco2 and total alkalinity talk 2 two kinds of particles i e particulate organic nitrogen pon and biogenic silica bsi 3 two phytoplankton types i e non diatoms p1 mainly phaeocystis in the present study and diatoms p2 and the corresponding chlorophyll chl a1 and chl a2 of these phytoplankton components 4 two grazer types i e microzooplankton z1 and mesozooplankton z2 note that all the above variables are described in detail in chai et al 2002 and xiu and chai 2011 2014 table b 2 provides a list of parameters used in the model and their units and values 2 3 model setup and data sources the 1d roms cosine model is set to run under a lagrangian coordinate implying that the position of the 1d model drifts along with the drift of floe 3 of the n ice2015 expedition fig 1 granskog et al 2018 the model is run at a time step of 600 s and the model s largest depth is fixed to 991 7 m the vertical coordinate is divided into 100 layers with the resolution varies from 0 58 m at the sea surface to 28 1 m at the bottom layer the simulation is initialized with the observed profiles of temperature salinity nitrate silicate phosphate ammonium phytoplankton and corresponding chl a assmy et al 2016 on may 18th before the uib started by fixing the known variables to the initial conditions and forcing of may 18th the model is spun up for three model years to reach a steady state to derive the initial biomass of the two zooplankton groups and the initial value of other state variables i e do pon bsi tco2 talk which cannot be obtained from the observations directly to make the physical environment realistic in this model the water temperature and salinity are assimilated daily from observations dodd et al 2016 the european centre for medium range weather forecasts ecmwf reanalysis data era 5 is used to produce the hourly atmospheric forcing including air temperature surface pressure relative humidity shortwave radiation net longwave radiation wind speed and precipitation moreover extensive field data of snow and sea ice thickness from floe 3 of the n ice2015 expedition rösel et al 2017 are used to calculate the mean thicknesses of different types of sea ice measured incident and transmitted photosynthetically available radiation par data are used to calculate the sea ice extinction coefficients taskjelle et al 2016 the areal fractions of thick ice thin ice and open water are taken from assmy et al 2017 the fraction of melt ponds is from the multi year average of the melt pond data provided by the integrated climate data center icdc http icdc zmaw de rösel et al 2012 istomina et al 2015 2 4 definition of two different radiative forcing schemes in the present study a new radiative forcing scheme is designed and used in the 1d roms cosine model the traditional radiative forcing scheme is also adopted by the model for comparison as shown in fig 2a and b we assume the pack ice over the water column is a mix of four sea surface types thick ice thin ice melt ponds open water and they are classified as 1 thick ice sea ice thickness larger than 28 cm with snow cover larger than 5 cm representing large areas of thick ice in the region 2 thin ice sea ice thickness less than or equal to 28 cm with snow cover less than or equal to 5 cm 3 melt ponds 4 open water we suppose this spatially heterogeneous pack ice drifts along with the underlying water column although there are relative motions between them accordingly two different radiative forcing schemes are established as 1 continuous radiative forcing scheme crfs this scheme was extensively used in previous studies e g palmer et al 2014 zhang et al 2015 assmy et al 2017 mortenson et al 2017 castellani et al 2022 in this scheme the water column is treated as a whole fig 2a and the par at the ice ocean interface is derived by eq 1 as the weighted mean of transmitted par for all surface conditions p a r s as shown in fig 3b the par time series at the sea water surface shows a continuous and smooth sinusoidal wave shape thus hereafter this radiative scheme is called the continuous radiative forcing scheme in this scheme phytoplankton growth g c o n at each time step is calculated as 1 p a r s i 1 n p a r s i f i c e i 2 g c o n f t p a r s n where p a r s i stands for the par under each type of surface conditions i namely thick thin ponded ice and open water n 4 stands for the different surface conditions considered in the model and f i c e i stands for the areal fraction of different surface types since the variations of sea surface types are provided daily f i c e i are fixed in a diurnal cycle also t and n represent the temperature and nutrients respectively 2 impulsive radiative forcing scheme irfs in this scheme we divide the underlying water column into several isolated sub columns and each of them can only be covered by one sea surface type at a time step fig 2b given that there are relative motions between the spatially heterogeneous ice pack and the underlying water column the model assumes a 144 time steps 24 h divided by 600 s time interval diurnal cycle with alternating periods of sea ice melt ponds and open water note that the time steps occupied by a certain surface type in one day is derived by its areal fraction f i c e i in that day for example 1 for thick ice is simulated as a diurnal cycle with 144 time steps of thick ice and zero steps of other surface types while the fractions of 0 91 0 03 0 04 and 0 02 for thick ice thin ice melt ponds and open water respectively are simulated as a diurnal cycle with 133 time steps of thick ice 4 time steps of thin ice 6 time steps of melt ponds and 3 time steps of open water fig 2c in this condition for each sub column the sea surface par value tends to have an impulsive shape with a higher value during open water or melt ponds and lower value under the ice covered conditions fig 3c thus it is called the impulsive radiative forcing scheme phytoplankton growth g i m p at each time step of is calculated as 3 g i m p f t p a r s i n in contrast with the crfs g i m p at each time step is calculated with one surface condition thick thin ponded ice or open water in this model this scheme converts the spatial sea ice variability into temporal sequences changes and attempts to reproduce the realistic conditions in which a water column experiences different surface types in a diurnal cycle in the present study in view of the spatial heterogeneity of the surface the water column is divided into 50 small sub columns fig 2b these sub columns are simulated in independent model runs and their diurnal sequences of four types of surface conditions are random finally when the 50 model runs are finished we calculate the ensemble mean of these simulation results as the final result of this scheme the ensemble mean represents the mean condition of the water column and is comparable with the traditional crfs furthermore melt ponds on sea ice strongly reduce the surface albedo and the extinction effect enhancing light transmission to the underlying water column rösel et al 2012 therefore in order to examine the model performance with the two radiative forcing schemes and the impact of melt ponds we configure three comparison cases as shown in table 1 cases 1 and 2 are used to examine the model improvement due to the new radiative forcing scheme case 3 is used to examine the modulating effect of melt ponds on the uibs 2 5 transmission of incident par through sea ice and the water column we use hourly shortwave radiation from ecmwf to simulate the daily light cycle in the model there is only part of the spectrum 400 700 nm relevant for biological processes arrigo et al 2014 castellani et al 2022 which is termed par therefore the par to shortwave radiation ratio of 0 43 is used to determine the incident par on the snow ice surface p a r i n in unit w m 2 zhang et al 2010 frants et al 2020 to calculate the intensity of sea surface par p a r s the procedure of light et al 2008 and duarte et al 2015 is followed 4 p a r s p a r i n 1 a l b s exp k s z s i 0 i c e exp k i c e z i c e where a l b s is the snow surface albedo k s and k i c e are extinction coefficients of snow and ice respectively also i 0 i c e denotes the fraction of radiation transmitting through the highly scattering surface of the ice and z s and z i c e are snow and sea ice thicknesses respectively it should be noted that extensive field surveys confirmed that snow ice thicknesses for thick thin ice did not change significantly during the drift of floe 3 thus although fractions of four types of surface condition vary the mean snow ice thicknesses for thick thin ice are constant during the simulation period the mean value of thin ice thickness is 25 cm with the snow cover of 5 cm and the mean value of thick ice thickness is 149 cm with the snow cover of 45 cm following assmy et al 2017 the coefficients used in eq 4 are adjusted using the n ice2015 dataset taskjelle et al 2016 for thick ice with thick snow some of the parameters in eq 4 including a l b s i 0 i c e and k i c e are from previous studies light et al 2008 taskjelle et al 2017 also z s and z i c e the mean thickness of thick snow and thick ice are 45 cm and 149 cm respectively k s for thick snow is derived based on the measured incident and transmitted par taskjelle et al 2016 and its value is 10 69 m 1 similarly for thin ice with thin snow transmittance measurements for snow ice and bare ice were done in the n ice2015 expedition according to these measurements and the known parameters a l b s and i 0 i c e light et al 2008 the extinction for thin bare ice can be estimated as 3 25 m 1 subsequently k s for thin snow 8 98 m 1 is estimated from the transmittance measurements with snow cover for melt ponds the a l b s i 0 i c e and k i c e are 0 251 0 645 and 0 99 respectively light et al 2008 see specific parameters in table b 2 in the water column light attenuation is calculated as a function of water column depth and chl a concentration chai et al 2002 xiu and chai 2014 5 p a r z p a r s exp k 1 z k 2 z 0 chl a 1 chl a 2 d z where k 1 is the light attenuation due to seawater 0 046 m 1 and k 2 is the light attenuation due to phytoplankton 0 03 m 1 3 results and discussion 3 1 overall comparison of the two radiative forcing schemes the simulation results show that all of the independent model runs with irfs for the 50 sub columns can reproduce the main features of the observed uib including the scm structure from late may to early june in 2015 the ensemble mean of these 50 model runs will be shown later the upper 50 m averaged chl a of these 50 model runs are convergent with a mean standard deviation of 0 092 fig 4a and b thus it implies that the diurnal sequence of different surface types does not significantly affect the simulation results mainly due to the relatively small light variability and the large predominance of one ice type over the others during the simulation period based on the observation simulation match up chl a the taylor diagram fig 4a with normalized standard deviation sd the root mean square difference rmsd and correlation coefficient r shows that the simulation results estimated by the irfs has a smaller sd 0 96 and rmsd 0 67 than those estimated by the crfs with values of 1 76 and 1 36 respectively the values also show that the model runs with the irfs have better model observed correlation relationship with a mean value of 0 76 than the crfs with a correlation coefficient of 0 64 to quantitatively compare the crfs and irfs cases the upper 50 m of the water column is divided into two layers by the mean mixed layer depth of 15 m during the bloom development comparisons between the observed and simulated chl a concentrations for the depth range 0 50 m and in both layers mentioned above are shown in fig 5 for the upper 50 m chl a is obviously overestimated by the crfs case with a bias of 1 79 mg m 3 while it is slightly underestimated by the irfs case with a bias of 0 04 mg m 3 fig 5a this can also be seen in fig 4b in which the crfs result shows a higher peak than the irfs result fig 5b shows an obvious overestimation of chl a within the depth of 0 15 m simulated by the crfs case with a bias of 3 34 mg m 3 in contrast the bias of the irfs case is 0 42 mg m 3 moreover the irfs case has higher model observed correlation and smaller rmsd than crfs case at 0 15 m fig 5b for the layer at 16 50 m the biases of irfs and crfs cases are 0 21 and 0 81 respectively and their r values are equal fig 5c the higher rmsd of the crfs case 5 46 indicates that for this depth range simulated chl a does not match observations very well 3 2 bloom process comparison of two radiative forcing scheme models as the sea ice concentration decline from may 23rd for the crfs model case p a r s increases accordingly and for the irfs case the period with high light exposure extends the daily average sea surface par processes are shown in fig 6a and b for both model cases daily par value increases from may 23rd and phytoplankton chl a increases correspondingly fig 6a f it implies that the impacts of increasing light penetrations on the initialization of rapid growth in under ice phytoplankton consequently nitrate is depleted to nearly zero from the surface to a depth of around 10 m for the continuous radiative case and to a depth of around 18 m for the irfs case fig 6g and h for the crfs case chl a remains close to initial values for only a short time 2 days and then increases rapidly on may 23rd exceeding the uib threshold of 2 5 mg m 3 lowry et al 2014 this increase occurs much earlier than the beginning of the observed uib fig 6e the simulated maximum chl a concentration is 17 1 mg m 3 which is more than twice the observed peak value 7 5 mg m 3 moreover par is attenuated rapidly in the water column resulting in a euphotic depth of 22 4 m during the bloom fig 6c as a result rapid phytoplankton growth is mainly confined to the surface layer leading to a significant vertical gradient of chl a across the euphotic depth during the bloom fig 6e for the irfs case the intermittent appearance of melt ponds and open water weakens the light attenuation due to snow ice which allows par to transmit to the deep layer intermittently fig 6d consequently the chl a distribution for the irfs case is more homogeneous than the crfs case in the vertical direction and the euphotic zone in the irfs is averaged of 43 0 m during the bloom which is comparable with previous study in the similar area with similar environmental conditions massicotte et al 2019 moreover the comparisons of chl a between observation and simulation results show that the irfs case can better reproduce the uib development than the crfs case chl a in the water column covered by the sea ice remains close to initial value 1 mg m 3 until thick ice reduces and the open water fraction starts to build up on may 24th phytoplankton bloom starts on may 24th and then the bloom forms with chl a greater than 2 5 mg m 3 between 0 30 m by may 26th with the increasing light transmission fig 6f over the next three days the bloom keeps on developing and peaks at 7 3 mg chl a m 3 in late may then the uib migrates downward following the nutricline forms a scm of 7 3 8 6 mg chl a m 3 at depth range of 11 31 m and deepens as time passes it is also worth mentioning that this modeled scm is consistent with the observational pattern in terms of depth and magnitude fig 6f 3 3 phytoplankton types simulated chl a concentrations of non diatoms and diatoms in the upper 50 m of the water column are shown in fig 7a and b note that the uib is dominated by non diatoms diatoms contribution is less than 2 2 of total chl a although a diatom increase is modeled between 30 50 m by the end of the simulation period fig 7b it is worth mentioning that this result is supported by the observational phytoplankton taxonomy data which shows that phaeocystis accounted for 55 92 of phytoplankton abundance also during the bloom period silicate was almost unconsumed suggesting that there was no substantial diatom growth during the observational period assmy et al 2017 diatom dominated uibs have been frequently reported from the arctic ocean mundy et al 2009 degerlund and eilertsen 2010 arrigo et al 2012 hill et al 2018 johnsen et al 2018 however the uib observed during the n ice2015 expedition is the first phaeocystis dominated uib assmy et al 2017 ardyna et al 2020b phaeocystis cells are possibly carried from lower latitudes to this area at greater depths by the atlantic water and then are mixed upwards to the upper ocean by the storm events in an earlier time of the year assmy et al 2017 leading to a higher phaeocystis concentration than diatoms in the initiation of the simulation the low light conditions beneath the snow covered drifting pack ice are apparently insufficient to sustain a diatom bloom in early spring phaeocystis are generally more competitive than diatoms in low light environment helping to maintain its dominance in the simulations sakshaug et al 2009 johnsen et al 2018 note that the photosynthetic parameterization of our model is from the onboard experiment cota et al 1994 assmy et al 2017 and phaeocystis dominance can also be seen in the model results moreover the low silicate inventory with the molar ratio of nitrogen to silicon n si much larger than 1 0 in this area limits diatom dominance ardyna et al 2020b as the surface silicate does not change significantly the n si ratio remains far higher than 1 0 until nitrate is nearly depleted by the uib at the end of may figs 6h and 7c this is quite different from the western arctic ocean where the water masses are influenced by pacific derived waters with higher silicate concentrations thus the dominant phytoplankton species in the pacific sector are represented by diatoms ardyna et al 2020a 3 4 growth limitation phytoplankton growth can be limited by temperature nutrients and light andersen 1989 smith and sakshaug 1990 gosselin et al 1997 hill and cota 2005 lee and whitledge 2005 campbell et al 2009 among the growth limiting factors light and nutrients are the decisive terms for arctic uibs popova et al 2010 lewis et al 2018 since the phaeocystis is the overwhelming dominant group in the n ice2015 uib light and nitrogen limitations and net growth of phaeocystis for both crfs and irfs cases are analyzed and the results are shown in fig 8 the limitation indices of light and nitrogen are calculated as 6 l l i m 1 exp α p a r μ m a x exp β p a r μ m a x 7 n l i m no 3 k n o 3 no 3 e φ 1 nh 4 nh 4 k n h 4 nh 4 where l l i m and n l i m represent the limitation indices of light and nitrogen respectively for every limitation index high value indicates less limitation also α is the initial slope of the photosynthesis irradiance curve β is the photoinhibition term μ m a x is the maximum growth rate k n o 3 and k n h 4 represent the half saturation constant for nitrate and ammonium and φ 1 is the nh 4 inhibition parameter values and units of all these parameters are shown in table b 2 for the irfs case following the thick ice decline the light limitation index increases rapidly from near zero to above 0 2 in the surface water from may 23rd fig 8a for the crfs case the light limitation index is higher than 0 1 immediately after the simulation starts and increases until the end of simulation when the bloom reaches peak value the light limitation index decreases sharply in the vertical direction especially under 20 m depth figs 6c and 8b as a result the light limitation index for the crfs case is much higher than that for the irfs case near the surface blue area above the solid black line in fig 8c while it is evidently lower in the deeper layer red area below the solid black line in fig 8c from may 24th the positive difference increases below the black line and reaches a positive peak on may 27th fig 8c which is related to earlier and overestimated bloom in the crfs case the irfs allows more par to intermittently penetrate through the upper water column and supports the phytoplankton growth in the deeper part 10 40 m meanwhile the crfs confine the bloom to the surface layer 15 m massive phytoplankton biomass accumulating near the surface further prevents par from reaching the deep water pavlov et al 2017 leading to the lower chl a concentration in deeper levels in both cases the nutrient limitation index keeps near 1 0 at the first five days and then decreases with the phytoplankton increase which vertically forms a nutricline fig 8d and e the major differences between fig 8d and e are the depth of the nutricline and the time when the nutrients in the upper 10 m depth are depleted there is a positive peak at near surface from may 26th to 28th in fig 8f which is because the earlier phytoplankton bloom leads to earlier nitrate depletion in the crfs case than in the irfs the maximal negative difference between 10 30 m from may 29th in fig 8f indicates the lower boundary of the phytoplankton bloom and the deeper scm in the irfs case than in the other case in addition the phytoplankton net growth rates of these two cases are quite different as shown in fig 8g the chl a concentration increment in the irfs case which is less than 0 1 mg m 3 day 1 can be neglected until may 23rd in contrast the net growth of phytoplankton chl a in the crfs case gradually increases since simulation starts and reaches the peak on may 24th within a shallower depth fig 8h thus the difference of net growth between these two cases is negative initially and then reaches the minimum value when the bloom develops fastest at the surface layer in the crfs case fig 8i soon afterward the positive maximum difference appears in the water column from the sea surface to the depth of 22 m note that above 8 2 m this maximum difference is due to nutrient limitation while below this depth the maximum difference is because of light limitation fig 8 shows the definite discrepancies of the phytoplankton growth process between these two models for both irfs and crfs cases an instantaneous light intensity of 0 016 w m 2 can support phaeocystis net growth when nutrients are plentiful note that this value is lower than the threshold values reported for arctic diatom blooms wang et al 2014 hill et al 2018 it implies the competitive advantage for low light conditions of phaeocystis than diatoms for the crfs case surface par is calculated by the weighted average of the par transmitted through different surface types and stays higher than the threshold all day thus a bloom develops earlier with the net growth of chl a exceeding 1 mg m 3 day 1 by the second day fig 8h as shown in eq 6 the relationship between par and phytoplankton growth is inherently nonlinear so that the crfs produces an overestimation of phytoplankton growth at surface though it is under high concentration sea ice floe for the irfs case because it generates an impulsive par field in the water column phytoplankton growth shows an impulsive pattern correspondingly under the thick ice solar radiation is attenuated to so extremely low value 0 016 w m 2 that can hardly support net phytoplankton growth therefore phytoplankton chl a may increase only in open water or under melt ponds while barely increasing under thick ice arrigo et al 2014 hill et al 2018 before may 24th the water column is covered by thick ice with thick snow for most of the day 99 sea ice concentration excluding ponded ice fig 6b net phytoplankton growth 2 5 mg m 3 day 1 accumulates during the ephemeral melt ponds open water conditions but these accumulated phytoplankton chl a will be completely consumed by self mortality and respiration during the thick ice periods therefore the bloom cannot start until may 24th when the daily net growth becomes positive with the decrease of thick ice fraction fig 8g to sum up in this study the bloom is triggered by the increasing par availability under a nutrient sufficient condition the irfs approach provides a more accurate averaging of the light field production does not scale linearly with light therefore light averaging prior to calculating production is mathematically inaccurate and thus produce inaccurate phytoplankton bloom when the bloom is progressing nutrients are reduced by phytoplankton growth and are rarely replenished much lower than the nitrate uptake from deeper water column due to shallow pycnocline and low mixing rates randelhoff et al 2016 it results in a nearly nitrate depleted surface layer afterward the surface bloom becomes nitrate limited primarily fig 8d and e additionally grazing pressure may be an important factor regulating bloom development campbell et al 2009 lee et al 2016 however in the present study low grazing on phaeocystis is simulated not shown and this result is supported by the finding that phaeocystis is considered unpalatable for the dominant calanus species ray et al 2016 hop et al 2021 3 5 impact of melt ponds on the model performance melt ponds are important for uibs to develop as they act like windows into the ocean and transmit 3 10 times more light than bare ice of the same thickness frey et al 2011 arrigo et al 2014 palmer et al 2014 in the present study the case 3 using the irfs without melt ponds is carried out to examine the impact of melt ponds simulation results show that this run can also reproduce the bloom process but chl a concentration exceeds the bloom threshold 2 5 mg m 3 only by may 30th which is four days later than the experiment with melt pond fraction from satellite fig 9a averaged chl a concentrations in the upper 50 m water column of the model runs with without melt ponds are shown in fig 9b for the run with melt ponds the averaged chl a reaches the peak value three days earlier may 30th vs june 2nd than in the no melt ponds run however the maximum averaged chl a value does not change significantly fig 9b this result agrees well with a previous study which indicated that doubling light intensity promotes an earlier bloom jin et al 2006 on the day of the peak surface chl a concentration the vertical extent of blooms in these two runs is 39 4 m melt pond coverage affects the progress of the phytoplankton bloom such as changes in the bloom initiation and peak timing but has little influence on bloom magnitude and depth it is worth mentioning that this finding supports the results of hill et al 2018 that 7 days simulated delay in melt ponds postponed the onset of phytoplankton growth but did not impact the maximum biomass this may essentially relate to the nutrient availability lavoie et al 2009 showed that the amount of nutrients available at the end of the winter could be the determining factor of the spring uib magnitude palmer et al 2014 also suggested that uibs are most likely to develop beneath sea ice with 10 melt pond coverage however it should be noted that their experiments did not include melt pond fraction between zero to 10 the results of the present study show that even a smaller fraction of ponded area than 10 can affect the occurrence of a uib 4 conclusions the 1d roms cosine model has been upgraded to adapt to the mix type ice cover condition in the arctic ocean by proposing a new impulsive radiative forcing scheme the impulsive radiative forcing scheme allows a random appearance of all ice conditions according to their areal fraction the model reproduces the temporal evolution of an under ice bloom in 2015 north of svalbard which was observed during the n ice2015 expedition ensemble runs show that the diurnal sequence of sea ice conditions does not influence the simulation results significantly compared with the widely used continuous radiative forcing scheme the impulsive radiative forcing scheme performs better with lower biases higher correlation coefficient and lower rmsd especially near the surface layer of the water column 0 15 m the simulation result of the continuous radiative case shows an earlier start of the bloom than observations and aggregation of chl a near the surface in contrast the simulation results of the impulsive radiative case agree well with observations and a deeper and later phytoplankton bloom and corresponding deepened subsurface chlorophyll maxima are also simulated the peak chlorophyll concentration of the impulsive radiative scheme is similar to observed data while that of the continuous radiative scheme is two times higher than observed data moreover sensitivity experiments with without melt pond cover in the impulsive radiative forcing scheme show that the introduction of melt ponds produces the bloom four days earlier but does not change the magnitude of chl a concentration significantly it indicates the important role of melt ponds in modulating the bloom timing this model is set to run under a lagrangian coordinate providing an approach for understanding the controlling process of observed ecological events during the expeditions as n ice2015 as arctic sea ice is becoming younger thinner and more fragmented with more leads and melt ponds schourup kristensen et al 2018 the irfs provides valuable insights into the treatment of heterogeneous sea ice surface in under ice biogeochemical simulations in a sub grid scale the 1d column can represent one grid cell in a 3d model and provides a tool for parameterization development mortenson et al 2017 this work is intended as a step to implement an improved radiative forcing scheme in the pan arctic model case credit authorship contribution statement yuexin gao methodology writing original draft visualization validation formal analysis data curation yang zhang resources methodology software writing review editing fei chai conceptualization program administration supervision funding acquisition mats a granskog resources validation writing review editing pedro duarte methodology writing review editing philipp assmy investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is supported by the national natural science foundation of china grant number 41730536 and 41941013 postgraduate research practice innovation program of jiangsu province china grant number kycx20 0418 the fundamental research funds for the central universities china grant number b200203133 and scientific research fund of the second institute of oceanography mnr grant number 14283 and jg2104 the n ice2015 expedition was supported by the former centre of ice climate and ecosystem ice at the norwegian polar institute p a was supported by the research council of norway project boom or bust grant number 244646 p d and m a g were supported by funding from the european union s horizon 2020 research and innovation programme through project crices climate relevant interactions and feedbacks the key role of sea ice and snow in the polar and global climate system grant number 101003826 also the support of eu project sidarus is acknowledged for the access to melt pond data appendix a see table a 1 appendix b see table b 2 
23824,viscous plastic rheology is widely used in the sea ice modeling community at increasingly high resolutions due to the high degree of non linearity of the rheological constraints accurate approximation of the jacobian is required to improve the efficiency of the implicit solvers of the sea ice momentum equation in pack ice we consider the analytical jacobian of the ice momentum equation and assess its approximation errors in the jacobian free newton krylov jfnk method and in the family of more traditional schemes which neglect the dependence of viscosity coefficients on the deformation tensor it is shown that this dependence provides a substantial contribution to the jacobian especially in the regions enriched by linear kinematic features like ridges and elongated polynyas numerical experiments indicate that performance of the newton solvers is also sensitive to errors associated with inexact computation of the search direction that may be caused in particular by numerical approximations of the jacobian which violate its dissipative property based on this analysis an improved selective damping strategy for the newtonian solver of the momentum equation is proposed a series of numerical experiments conducted in simulated pack ice environment demonstrate faster convergence of the updated solver with analytical jacobian as compared to the one based on the selectively damped jfnk method with inexact gmres solver in the inner loop keywords sea ice dynamics newton method jacobian damping 1 introduction accelerating changes in the arctic climate increase the interest in accurate simulations of sea ice dynamics and thermodynamics which relies on efficient techniques of solving the equations of the sea ice numerical models the main challenge in simulating sea ice dynamics comes from its rheology describing the relationship between the internal stress and deformation rate which is commonly represented by the viscous plastic vp approximation this approach was proposed by hibler 1979 who employed non linear dependence of the pack ice viscosity on the deformation rates to represent sea ice under low deformations as a very viscous newtonian fluid or as a plastic material once critical stress values have been reached although an impressive variety of other rheologies were proposed in recent years e g schreyer et al 2006 girard et al 2011 tsamados et al 2013 rampal et al 2016 ringeisen et al 2021 they are not widely adopted in the operational models as it is not completely clear which one of those provides the best representation of the sea ice mechanical properties for this reason the vp rheology remains the scheme of choice in the sea ice modeling community due to its relative simplicity and ability to provide realistic simulations under a wide range of environmental conditions e g kreyscher et al 2000 the major problem with ice modeling and vp rheology in particular are rather stiff constraints imposed by the momentum balance of the sea ice these constraints have to adequately describe abrupt changes in the magnitude of ice properties viscosity coefficients under smooth forcing variations such as transition from a diverging to a converging ice pack the emerging strong gradients in the coefficients can deteriorate stability of the applied numerical schemes a reasonable approach for dealing with this problem of the momentum equation is to use a time step of a few seconds in an attempt to explicitly resolve elastic oscillations emerging in sea ice hunke and dukowicz 1997 2002 however this approach appears to be computationally expensive bouillon et al 2013 and requires additional modifications lemieux et al 2012 kimmritz et al 2015 2016 for robust convergence to vp solutions furthermore it is not useful in climatological studies which require integrations for hundreds or thousands of years on coarse grids for these reasons investigation of implicit and semi implicit treatment of the vp momentum equation has been the subject of a number of studies in recent years e g lemieux et al 2012 losch et al 2014 lemieux et al 2014 auclair et al 2017 there is also a growing interest to vp ice dynamics from both theoretical brandt et al 2021 liu et al 2021 and applied mehlmann and richter 2017 2020 mehlmann et al 2021 mehlmann and korn 2021 mathematicians in particular mehlmann and richter 2017 investigated applicability of the selective jacobian damping technique to the weak formulation of the vp model with analytic jacobian they found much better performance of the newtonian solver with a modified damping algorithm proposed by mandal et al 2016 for viscous plastic fluids this result seems to challenge the existing notion that availability of the analytical jacobian does not bring any advantage in solving the vp momentum equation in comparison with the jacobian free newton krylov jfnk solvers based on finite difference approximations of the jacobian action on a vector e g losch et al 2014 in the present study we investigate utility of the analytic jacobian in the framework of the damping technique and assess the impact of the jacobian approximation errors on the convergence rate of a damped newtonian solver in particular we find the importance of maintaining the dissipative property of the rheological part of the jacobian and propose an improvement of the damping scheme of mandal et al 2016 using implicit filtering of the jacobian approximation errors this article is structured as follows in section 2 the governing equations of the sea ice dynamics are described with special focus on the linearization of the internal stress divergence under the vp rheological constraints section 3 contains an overview of the jacobian approximations in the vp ice models and quantitative assessment of these errors using a sequence of pack ice states from the cice6 model run operationally at the naval research laboratory in section 4 we analyze spectral properties of the jacobians in a simplified vp model based on the hibler s b grid discretization and expose the results of numerical experiments with the improved damping scheme discussion of the results and conclusions are provided in section 5 2 jacobian of the vp rheology 2 1 formulation the general equation describing the momentum balance in sea ice is 1 ρ h d t f k u div σ ϵ τ u where ρ is the sea ice density u u v h are the 2d fields of ice velocity and thickness d t is the operator of material time derivative f is the coriolis parameter k is the vertical unit vector τ stands for the force exerted on ice through its interaction with the bottom atmosphere and the ocean while σ and ϵ are the tensor fields of ice stress and ice deformation rate represented by 2 2 matrices 2 σ σ x x σ x y σ x y σ y y ϵ 1 2 2 x u x v y u x v y u 2 y v in the vp formulation σ is a function of ϵ relating internal ice stresses to ice deformation rates and velocities through the rheological relationship proposed by hibler 1977 1979 3 σ 2 η ϵ ζ η tr ϵ p 2 i ζ e p 2 δ η ζ e 2 where i is the 2 2 identity matrix 4 p h a h exp κ 1 a is the scalar field of the internal ice pressure with the empirical compactness strength parameter κ a is the ice concentration e is the yield curve axes ratio of the sea ice while ζ and η denote positive sea ice bulk and shear viscosity coefficients whose magnitudes depend e g hunke 2001 on the scalar field 5 δ ϵ e 2 1 tr ϵ 2 2 tr ϵ 2 δ m i n 2 1 2 where δ m i n is the regularization parameter e g kreyscher et al 2000 to simplify further treatment we introduce the auxiliary linear operation 6 ϵ ϵ tr ϵ e 2 1 2 i and merge two viscosity fields into a single one by setting 7 ζ p e δ these definitions reduce the constitutive relation 3 to the following form 8 σ ϵ ζ ϵ p 2 i p ϵ e δ i 2 in the vp sea ice modeling eqs 1 5 are augmented by two evolution equations for the fields of ice thickness and concentration that are explicitly integrated forward in time whereas the momentum equation is solved implicitly by substituting the rheological relationship 8 into 1 in this study we focus on the pack ice dynamics when the rheology term div σ dominates the momentum balance so one could further simplify the problem by setting d t t and consider the following form of the momentum equation 9 ρ h t f k u div ζ ϵ u 1 2 p τ u at this point it is necessary to note that the first term on the rhs of 9 is a homogeneous function of velocity and can therefore be represented as a product j u where j is the rheological part of the jacobian an important physical constraint imposed on the discretized form of j is its dissipative property e g hunke and dukowicz 2002 which requires the respective matrix representation of j to be negative semi definite nsd so that the rheological term u j u in the kinetic energy equation 10 ρ h t 1 2 u u u j u 1 2 u p u τ u should always dissipate energy this is especially important for implicit treatment of the momentum equation that employs the newton solver simulating the action of inverse jacobian on a vector to generate a search direction unfortunately keeping the dissipative property of j is somewhat tricky especially when the momentum equation is discretized in the strong formulation this difficulty is visible in the analytical form of the rheological jacobian action on a vector δ u which is related to the respective deformation rate δ ϵ via the relationships in 2 and 6 11 j δ u j 1 j 2 δ u div ζ δ ϵ 2 δ 2 ϵ tr ϵ δ ϵ here δ ζ and ϵ denote the background fields used in linearization the first term in eq 11 is obtained by varying ζ ϵ in eq 8 with respect to ϵ while keeping the viscosity at the background value the second term emerges as a result of varying velocities in the expression for the viscosity ζ appendix a and appears to have a somewhat more complex structure historically numerics of the vp sea ice models were formulated to preserve the nsd property of only the first term j 1 δ u div ζ δ ϵ in eq 11 this was not critical if the fixed point iterations were used to solve the momentum equation and viscosities were updated at the next approximation of the velocity field subsequent transition to faster converging newton solvers requires computation of j 2 δ u which is either obtained by automated differentiation ad of the code for j 1 δ u or approximated by finite differentiation of that code in view of the iterative nature of the non linear solvers of the momentum equation it is instructive to assess the relative magnitude of the two jacobian constituents as well as other sources of errors that may occur in the approximation of the jacobian action on a vector 3 jacobian approximations 3 1 incomplete linearization there is a considerable literature devoted to the technique of solving the momentum balance equation with vp rheology the simplest method is to iterate a linearized version of the equation using a fixed point or picard iteration this approach involves two embedded loops see e g lemieux et al 2008 lemieux and tremblay 2009 and references therein in the inner loop the momentum equation is solved using an approximation to j with ice viscosity coefficients being fixed at their background values i e by setting j j 1 in the second outer loop these coefficients are updated using velocities obtained on the completion of the inner loop in terms of the jacobian approximation the momentum equation in the inner loop is solved using incomplete linearization of j which is obtained by neglecting j 2 i e implicitly assuming that j 2 j 1 and then iteratively correcting a sequence of intermediate solutions in the outer loop this strategy encounters a number of problems including slow convergence of the outer loops which is especially evident at fine less than 5 km grid resolutions residual errors in the ice velocity field tend to be localized in the regions of strong ice convergence and deformation lemieux and tremblay 2009 we speculate that such behavior indicates certain deficiency of the approach that is related to the lack of information on the local gradient of the residual provided by the exact jacobian to assess the validity of such approximation in a realistic situation we analyzed the output of the cice6 hunke and lipscomb 2008 model run fig 1 at δ x 2 km resolution in the east siberian sea and forced by the output of the gofs system metzger et al 2014 run at 1 25 resolution one hundred daily ice velocity thickness and concentration fields in the region of heavy pack were given on 235 235 grid spanning the period between january 1 and april 10 2018 prior to analysis the velocity fields were filtered with the gaussian filter with the decorrelation length scale of l 1 2 δ x this was done to suppress grid scale variability of u associated with the residual elastic waves typical for the evp rheology of the cice6 model to estimate the relative magnitude of j 2 for each day we generated an ensemble of fifty random velocity perturbation fields δ u computed the respective deformation rates δ ϵ and calculated 100 50 values of j 1 2 δ u using cice6 output as the background for computing j 1 and j 2 in accordance with eq 11 after that the relative approximation errors 12 e 1 j 2 δ u j 1 j 2 δ u were computed at every grid point for all the 5000 samples these computations yield the average value e 1 0 65 0 06 with significant time variations in particular the approximation error was notably higher in the periods when the domain was densely populated by linear kinematic features lkfs fig 1a and was lower during the relaxation periods fig 1b such dependence may partly explain the structure of the residual velocity fields observed by lemieux and tremblay 2009 in the vp ice model runs with the picard solver of the momentum equation 3 2 finite difference approximation to improve the convergence lemieux et al 2010 introduced the jacobian free newton krylov jfnk solver in the practice of sea ice modeling the method is based on the finite difference approximation of the jacobian s action on the sea ice velocity field assuming fully implicit treatment of eq 9 time discretization of the momentum equation can be represented in the form 13 f u ρ h i δ t f k u j u u τ u 1 2 p ρ h u δ t 0 where overline denotes the unknown velocity at time t and all other variables are assumed to be known from the previous time step t δ t to avoid recomputing the jacobian in the process of the newton iterations its action on a vector u is approximated by the finite difference ɛ 1 f u ɛ u f u where ɛ is a sufficiently small number the respective approximation error for the non linear contribution to the jacobian 14 e 2 ɛ ɛ 1 f u ɛ u f u ρ h u δ t f k u j τ u u j τ u u was estimated similar to e 1 results of these computations are shown in fig 2 by the thick black line which demonstrates a significant loss of accuracy up to 5 orders in magnitude associated with the strong non linearity of j the loss is manifested by the delay of the linear reduction of e 2 ɛ visible in the upper right corner of fig 2 at the higher values of ɛ for comparison we removed j from eqs 13 14 to compute the same error dashed line in fig 2 in the case of much milder quadratic non linearity associated with external forcing it is remarkable that due to the strong non linearity of the rheological jacobian setting ɛ 1 0 6 used by lemieux et al 2010 provides an accuracy of only 10 which appears to be of the same order in magnitude as e 1 nevertheless lemieux et al 2010 found that the jfnk scheme significantly improved the convergence rate compared to picard iterations fig 2 also shows that the best accuracy is achieved at ɛ 1 0 10 which agrees with the result of losch et al 2014 who investigated scalability of the jfnk scheme in the coupled sea ice ocean model of the arctic the major advantages of the finite difference approach are the absence of the necessity to design additional software for explicit computation of j and ability to take into account albeit with an error of finite differentiation all the terms in the analytic expression for the jacobian among the disadvantages are amplification of the finite difference errors by the differential operators present in eq 11 especially in j 2 and violation of the condition ɛ u u in the regions where u is negligible although these deficiencies could in principle be removed by the exact analytic representation of the discrete jacobian they do not complete the list of possible error sources occurring during the newton iterations 3 3 inexact newton method in particular accumulated experience with applications of the newton method to vp sea ice modeling have shown computational advantages of interrupting the inner loop iterations at a moderate tolerance to avoid oversolving the linearized version of eq 13 the main objective of the inexact newton method e g lemieux et al 2010 is to find a reasonable balance between the computational cost and accuracy of computing the exact search directions especially at the initial stages of the newton iterations when these directions are far from optimal being beneficial overall this strategy generates an additional error in computing the newton search direction defined by the product of the inverse jacobian and the residual 13 the selective jacobian damping technique mandal et al 2016 attenuates these and other sources of numerical errors in the newton algorithm by selectively reducing their impact on the most error prone parts of the jacobian mehlmann and richter 2017 applied this technique to the vp sea ice model replacing the exact jacobian j j 1 j 2 in 11 by 15 j j 1 γ n 1 j 2 where γ n 1 is the adaptive parameter which selectively damps the second part of the rheological jacobian at the current iteration it is defined by 16 γ n 1 min 1 γ n γ 4 0 7 exp 1 5 q n γ n γ 1 γ n γ here q n is the relative reduction of the residual at the previous iteration and γ 0 2 is the background value of the damping parameter using inexact newton method with analytic jacobian mehlmann and richter demonstrated that selective damping of j 2 eq 15 drastically improves the convergence of the newton method with inexact gmres solver it is also noteworthy that errors in computing the newton search directions could be more destructive in the numerical schemes which maintain the nsd property only for a certain part of the jacobian e g j 1 using finite and or analytic differentiation of such schemes for computing the jacobian action on a vector yields approximations which violate the nsd property appendix b as a consequence such approximations may generate velocity fields that amplify the kinetic energy of ice cover and significantly slow down convergence of the newton iterates in the next section we explore the impact of such behavior using as a testbed a traditional b grid discretization of the momentum equation by hibler 1979 and then modify the selective damping scheme 16 to alleviate this impact 4 numerical experiments 4 1 methodology the numerical experiments were conducted using a simplified vp sea ice model with the momentum equation 9 and rheological constraints 4 8 formulated on the rectangular b grid with periodic boundary conditions and a standard set model parameters the proportionality coefficient in 4 was p 27 500 n m 2 while other parameters were e 2 κ 20 f 1 5 1 0 4 s 1 ρ 900 kg m 3 and δ m i n 2 1 0 10 s 1 the forcing term was set to 17 τ τ a τ o τ a c u u assuming motionless ocean with c 5 64 kg m 3 the atmospheric forcing component τ a was chosen to have the form 18 τ a x τ 0 9 cos x sin y sin x cos y 19 τ a y τ 0 9 sin x cos y cos x sin y where τ 0 0 035 n m 2 x 2 π x c t l y 2 π y l c l 2 t and l t are the size of the domain and the model integration time respectively this setting specifies forcing as a 2 2 checkerboard pattern of eddies that migrate westward by approximately one eddy diameter by the end of the model run to generate ridging in pack ice atmospheric eddies are characterized by wind convergence in the cyclones and divergence in the anticyclones experiments were conducted with the constant grid step δ x 4 km in both directions and the domain sizes n were varied with n 40 64 and 128 the time step δ t was set to 2160 s and was not changed explicit time integration of the evolution equations for ice thickness and concentration was performed for 160 time steps t 4 days using the lax wendroff scheme the momentum equation was treated implicitly numeric representation of the rheological term is the same as proposed by hibler 1979 thus keeping the nsd property of j 1 intact the second term j 2 was obtained by analytic differentiation of j 1 with respect to the velocities entering its matrix elements see appendix b for details in actual computations all the operators entering the evolution equations were represented by sparse matrices the two components of the jacobian had exactly 14 non zero elements in a row for j 1 and 18 non zero elements in j and j 2 eq b 8 in appendix b hereinafter we redefine j 1 and j 2 in accord with linearization of f in the vicinity of u in 13 20 j 1 j 1 u τ u u ρ h i δ t f k 21 j 2 j 2 u so that due to the change of their signs j 1 and j 2 now have to be represented by positive definite pd and nsd matrices respectively while j 1 is not restricted to the rheological part of the full jacobian but incorporates all other terms in order to remove the dependence on the initial conditions numerical experiments were designed as ten member ensemble runs of the model fig 3 each experiment was made with a certain configuration of the newton solver of the momentum equation and performance of the solver was assessed by averaging over the ensemble ensemble members were specified by setting the initial conditions for ice thickness and concentration as random realizations of a gaussian field with the decorrelation scale of 3 δ x the homogeneous and isotropic covariance functions for these fields had the mean values of 1 5 m and 97 for ice thickness and concentration respectively while their standard deviations were set to 0 3 m and 2 in addition ice concentration fields were capped by 100 from above the initial ice velocity was set to zero to solve the linearized momentum equation in the inner loop we used two methods the exact solver based on lu decomposition of the jacobian and inexact approach similar to the one used by lemieux et al 2012 but with the gmres solver preconditioned by the incomplete lu factorization of j 1 the line search in newton directions was defined by the damping parameter γ different from γ in eq 15 22 u n 1 u n γ j 1 f u n the values of γ were specified similar to mehlmann and richter 2017 no more than four attempts to reduce the residual in the search direction were performed with γ k defined by the sequence γ k 4 k k 0 3 newton iterations were terminated as soon as the residual either reached 0 01 of its initial value or its rms magnitude was less than 1 0 4 m s 4 2 spectral properties of the jacobian fig 4 shows a typical jacobian spectrum of an ensemble member obtained in the course of the experiments in accordance with the hibler s scheme the first part of the jacobian j 1 is positive definite although its condition number remains high 1 0 7 mostly due to the selected value of δ m i n the second part of the jacobian j 2 is asymmetric see appendix b and appears to violate the psd property of j this violation is however not severe as the difference between the real parts of the eigenvalues λ of j 1 and j is always positive while the imaginary parts of the eigenvalues are either zero for the leading modes or 1 2 orders in magnitude smaller than their real parts with an exception of the very tail of the spectrum where eigenvalues are more susceptible to the approximation errors of the numerical representation however it is the tail that defines the error related scatter of the newton search directions in eq 22 a closer look at the eigenvectors at the tail of the spectrum demonstrates much faster spatial variations of those corresponding to j as compared to j 1 fig 5 although these fine structures are likely to be responsible for emergence of the realistic features like lkfs in pack ice they could also generate spurious sources of energy if the respective modes provide positive contributions to the kinetic energy budget 10 in this aspect figs 4 5 illustrate the idea of selective damping of j 2 which provides a heuristic method of optimizing the balance between the realism of a search direction and potential errors in its structure a simple way to assess the impact of these errors on a search direction s j 1 f is to compute the sign of the dot product f s which should be positive if the numeric approximation of j 1 f keeps the pd property of the jacobian f j f 0 f intact this consideration could potentially improve the selective damping scheme 15 of the newton method 4 3 modifications of the damping scheme in the first series of experiments we estimated the computational efficiency of the jacobian damping without the adjustment of the damping parameter i e by simply setting γ c o n s t throughout newton iterations γ was varied in the range between 0 corresponding to picard iteration and 1 newton iteration results demonstrated nearly linear reduction of model integration time with a potential of 10 fold reduction at γ 1 as shown by the dashed line in fig 6a however the reduction of computation time flattened out at γ 0 6 and even started to increase at γ 0 9 moreover when γ 0 97 the model integration could not be completed because the momentum equation residual failed to decrease to the target values in less than 200 iterations at more than 10 consecutive time steps to explore possible reasons for such a behavior we computed the spectrum of the symmetric part of the jacobian j j t 2 which contributes to the kinetic energy budget and then counted the number n of negative eigenvalues λ k as well as their contribution 23 β k 1 n λ k 1 k 1 n λ k 1 to the trace of its inverse results of these computations are shown in fig 6b as it was expected from the cpu time assessment in fig 6a the relative number of the growing unstable modes as well as their contribution β to the inverse spectrum were completely absent for γ 0 4 and did not exceed 0 07 for γ 0 6 for larger values of the damping parameter n increases approximately 10 times to 0 7 while the contribution to the inverse spectrum rises much faster reaching 14 for γ 1 fig 6b this is indicative of a tendency for unstable modes to populate the tail of the jacobian spectrum the above observations provide an option to filter the approximation errors of the search direction s j 1 f by checking the sign of the dot product f s prior to executing the line search as mentioned earlier the dot product f s can serve as an indicator of errors in approximating the action of j on a vector because both j and j 1 should be represented by pd matrices and therefore satisfy the relationship sgn f j 1 f sgn f j f 0 for any velocity perturbation δ u f δ t so in the case of detecting a potentially unstable direction with δ u s 0 the damping parameter is reset to the safe background value γ another possibility to improve the damping scheme 16 is to introduce information on the line search efficiency at the previous iteration as an example one could reduce the threshold value q of the residual reduction rate which triggers the mechanism of decreasing the damping parameter under the min operator of eq 16 the threshold value is obtained by setting to one the expression in square brackets of 16 24 q 2 3 ln 4 1 γ 0 7 0 97 to introduce the line search information we elected to modify the numerator of the fraction under the logarithm in 24 as mentioned above in the course of the numerical experiments the background value of the damping parameter was set to γ 0 3 further experimentation with the ensemble runs revealed a noticeable improvement when the exponent of the numerator was changed from 1 to 0 9 k 80 where k is the number of line search attempts at the previous iteration the modification accelerated the reduction rate γ n 1 γ n of the damping parameter and the contribution of j 2 to the jacobian with the growth of the number of line search attempts per iteration as a result the damping scheme 16 was transformed to 25 γ n 1 γ f n s n 0 min 1 γ n γ 4 0 9 k 80 0 7 exp 1 5 q n γ n γ 1 γ n γ fig 7 compares the number of newton iterations required by the damping schemes 16 and 25 thin lines in both panels show the ensemble average values of the actual number of newton iterations on every time step while the thick lines are their 2 h smoothed values comparison shows that the major improvement is provided by the unstable directions filter first line in eq 25 which is responsible for nearly 70 of the newton iterations reduction of the background damping scheme the effect of adding the line search efficiency information is relatively minor but appears to be still significant an overall quantitative characterization of the modified damping scheme is given in table 1 a significant reduction is visible across all the three major parameters including the total model integration time 27 and the average number of function calls 36 per time step the most prominent reduction is observed in the number of line search failures 90 bottom of the third column that are more likely to occur when an unstable search direction is encountered 4 4 comparison with jfnk method in this section we compare results of computations carried out using the analytic jacobian and the exact linear solver for computing a search direction with performance of the jfnk solver where the jacobian s action is constructed via a first order finite differences and the newton correction determined via a preconditioned gmres solver in the jfnk setting the residual of the momentum equation was rescaled to have the unit norm prior to multiplication by ɛ 1 0 10 the approximation error as a function of ɛ was estimated using eq 14 and found to be consistent with errors of the gofs solution cf gray and black lines in fig 2 q to simulate selective damping in jfnk scheme we employed the analytic code for j 1 u which is supposed to be available for computing the rheological term φ u j 1 u u in the momentum equation so that the damped code consisted of two steps 26 u φ u ɛ u φ u ɛ 27 j u 1 γ j 1 u u γ u the first step eq 26 provides the finite difference approximation for the product of the rheological part of the jacobian j 1 j 2 by u while the second step yields its selectively damped version j 1 γ j 2 u through explicit computation of the product j 1 u u the damping parameter was computed in accord with eq 25 in both cases the computational cost of such a two stage operation is only 10 higher than that of 26 because both the background field u and j 1 u were stored prior to the gmres call the jfnk method was configured similar to lemieux et al 2012 with the only difference that we used incomplete lu preconditioner instead of doing the fixed number of successive over relaxation iterations overall the cost of the exact jacobian solver including computing j 1 and j 2 was on the average 110 times more expensive than that of a single finite difference approximation 26 used by the inexact jfnk solver this advantage was however outbalanced by a considerable number of the gmres function calls and more importantly by much larger line search failures in the process of newton iterations the upper panel in fig 8 shows a comparison of the number of newton iterations for a single ensemble member run it is remarkable that the number of jfnk outer loop iterations was very close to that of the exact solver with an exception of a few time steps when the damped newton method with jfnk solver failed to converge in less than 200 iterations these failures were basically the major cause which reduced the computational advantage of the jfnk scheme this effect is accumulated over the entire ensemble run requiring in total 28 more newton iterations for the jfnk method bottom panel in fig 8 this is consistent with the result of losch et al 2014 who observed a significant 30 reduction of the number of newton iterations when using the jacobian obtained by automated differentiation of the code for j 1 u u regarding the total computation time we also observed a considerable 25 improvement in comparison with jfnk solver whereas losch et al 2014 who used newton iterations without selective damping γ 1 found approximately equal computational cost of both methods the observed reduction of computer time is attributed to more frequent failures of the jfnk method 5 summary and discussion based on the analysis of various sources of the jacobian approximation errors and their impact on the newton search directions a modification of the selective jacobian damping method of mehlmann and richter 2017 is proposed the major idea is to use the dissipative property of the analytic jacobian in order to evade searches in the directions which tend to increase the kinetic energy of ice cover using analytic representation of the jacobian we also estimated the magnitudes of errors caused by neglecting the viscosity derivatives of the picard method and by finite differentiation of the jfnk scheme our findings are summarized as follows 1 dependence of the ice viscosity coefficients on the deformation rate provides an essential contribution to the jacobian their relative magnitude typically varies within 40 70 omitting this contribution results in the jacobian approximation errors of the same order in magnitude the magnitude of contribution from the viscosity derivatives strongly depends on the concentration of lkfs which tends to increase in the periods of stronger large scale convergence of the ice velocity 2 the finite differentiation method requires significant reduction down to ɛ 1 0 10 of the perturbations magnitude and the necessity to conduct differentiation in the double precision in particular our estimates show that using ɛ 1 0 6 in the pack ice may result in the approximation errors of 5 10 fig 2 which may inhibit convergence of the jfnk method 3 newton search directions are also affected by errors in computing the action of the inverse jacobian on the residual especially for the large values of the damping parameter these errors may emerge from violation of the dissipative property of the jacobian by the numerical scheme and or limited accuracy of the jacobian inversion they can be partly filtered by checking the sign of the residual projection on the search direction prior to execution of the line search 4 an additional 10 improvement to the adaptive damping scheme has been obtained by taking into account information on the line search efficiency at the previous iteration 5 ensemble runs of a simplified model with vp rheology have shown that the above modifications reduce the number of newton iterations by approximately 30 while using the analytic jacobian requires 1 3 times less computer time as compared to jfnk method the latter advantage of using analytic jacobian is not consistent with a general notion that jacobians obtained by automated differentiation of the code do not give any computational advantage in comparison with jacobian free methods we attribute this discrepancy to several factors first automated differentiation tools tend to provide less efficient codes than hand written second implementation of the adaptive damping in jacobian free method implies an additional function call required by the necessity to separate the jacobian into two parts eqs 26 27 finally a simplified model we used for the test case may have an advantage compared to the state of the art sea ice model involving several ice categories sophisticated physics and thermodynamics it should also be noted that the general problem of improving the efficiency of nonlinear solvers is a complex issue largely defined by their parallelization capabilities for that reason the iteration count used in this study for a simplified model run on a single processor may not translate directly into wall clock time in real applications the vp scenarios with embedded iterative loops especially involving the flow of information of the linear solver through iterations and other parallelization issues have a large room for optimization for these reasons we assume that the utility of implementating analytic jacobians with selective damping in realistic sea ice models should definitely require further investigation another important issue is related to keeping the dissipative property of the analytic jacobians historically numerics of ice models with vp rheology were not specifically designed for utilizing the newton method we have shown that application of ad tools to such numerical schemes provides jacobian approximations that violate the positive definite property which in turn may deteriorate convergence of the newton method a similar inhibiting effect could be produced by applying inexact inner loop solvers even if the jacobian is kept positive definite our experiments indicate that the selective jacobian damping algorithm 15 has a reasonably good potential to improve convergence of the implicit solver in the sea ice momentum equation from the viewpoint of computational efficiency selective damping also provides an additional advantage to the analytic jacobian representation because implementation of selective damping in the jacobian free algorithm requires running and development of the additional code to separate the action of the two jacobian components on a vector eqs 26 27 there are also numerous factors remaining to be explored in relation to the proposed improvement of the non linear solver these factors are responsible for strong intermittency of the stiffness matrix emerging in the course of time integration and could be dealt by adjustment of the model grid and or time stepping the latter could be improved by accumulating information on the spectral properties of the stiffness matrix and or peculiarities in the spatial structure of sea ice fields such as the lkf concentration mentioned in section 3 1 similar problems exist for elastic vp evp solvers which in contrast to the implicit time stepping of the momentum equation solve it explicitly in this case the time step is defined by the spatially varying speed of the elastic waves that tend to propagate faster along the ice ridges associated with the lkfs despite certain progress in dealing with the residual elastic wave effects and convergence of the evp solvers e g kimmritz et al 2015 2016 there is still a considerable room for improvement of their performance based on the analysis of the sea ice state the major problem is that such analysis has to be relatively inexpensive to prevent compromising the computational efficiency of a sea ice model with vp rheology which uses either explicit or implicit time stepping of the momentum equation in the light of the above problems a quick access to the analytic part of the rheological contribution to the jacobian could benefit the progress in improving the computational efficiency of the vp sea ice models the analytic jacobian is also a crucial ingredient of the data assimilation systems and adjoint sensitivity analyses involving sea ice models e g kauker et al 2009 heimbach et al 2010 and may also benefit general development of the variational approaches to construction of the numerical methods controlling lkf evolution associated with formation of ridges roberts et al 2019 and polynyas in the pack ice we are currently planning to compare performance of the inexact jfnk solvers with the ones featuring the analytic jacobian in a more realistic setting we believe that results will benefit and provide further guidance for the development of the vp models and their adjoints in the near future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the study was supported by the naval research laboratory projects optimization of rheology for advancing sea ice forecast 73 1u98 025 and precision assessment of remotely sensed data with error correlations 73 6c95 025 appendix a jacobian of the vp rheology since the variation of the second term in 8 with respect to velocity is zero we have to compute only the variation of the first term which is basically a 1 δ ϵ δ 1 δ δ ϵ ϵ δ δ δ applying the differential relationship for the trace of the n th power of a matrix a δ tr a n n tr a n 1 δ a to eq 5 yields expression for the variation of δ in the form a 2 δ δ 1 2 δ δ e 2 1 tr ϵ 2 2 tr ϵ 2 2 δ tr i e 2 1 2 tr ϵ ϵ δ ϵ 2 δ tr ϵ δ ϵ combining this with a 1 taking 7 into account and applying the divergence operator to the result yields 11 j 1 δ ϵ div ζ δ ϵ j 2 δ ϵ div 2 ζ δ 2 ϵ tr ϵ δ ϵ mehlmann and richter 2017 provide an alternative form of the jacobian using notation slightly different from 6 and 7 ϵ ϵ tr ϵ 1 2 i δ tr ϵ 2 2 e 2 ϵ ϵ δ m i n 2 1 2 ζ p 2 δ where stands for the inner product of two matrices their final expression for the two components of the jacobian have the form j 1 δ ϵ div ζ 2 e 2 δ ϵ i tr δ ϵ j 2 δ ϵ div ζ δ 2 2 e 2 ϵ i tr ϵ 2 e 2 ϵ δ ϵ tr ϵ tr δ ϵ which is equivalent to 11 appendix b numerical approximation of the jacobian let δ be the grid step and s denote the n n right shift matrix obtained from the identity matrix i by displacing its diagonal one step to the right and placing 1 at the bottom of the first column to account for the periodicity the 1d finite difference and averaging operators in a given direction r either x or y are then given by d r s r i δ and a r i s r 2 in two dimensions the finite difference operators are defined via krönecker products of these matrices with identity matrices in the complimentary direction b 1 d x d x i y d y i x d y b 2 a x a x i y a y i x a y in the similar manner the differential operators averaged in the complimentary direction are specified by b 3 d x d x a y t d y a x t d y these operators are used to project velocity derivatives on the scalar grid where the fields of pressure p and δ are calculated to obtain the viscosity ζ eqs 5 7 the averaging operators in b 3 are transposed because velocities on the b grid are shifted half a grid step with respect to the scalars using these definitions hibler s discretization of div σ can be written in the form b 4 j 1 u 1 2 α d x x d y y β d x y d y x β d y x d x y α d y y d x x u v with b 5 d x x d x t a y ζ d x d y y d y t a x ζ d y b 6 d x y a y d x t ζ d y d y x a x d y t ζ d x where square brackets in b 5 b 6 and hereinafter denote conversion of a vector to the diagonal matrix while α 1 e 2 and β 1 e 2 note that formulation b 4 b 6 of j 1 is symmetric as d x x d x x t d y y d y y t and d x y d y x t the latter property follows from the relationships d y t a x d y t and d x t a y d x t these symmetries guarantee dissipative negative semi definite property of j 1 in the ice kinetic energy equation the full analytical jacobian can be computed by differentiating the matrix elements of j 1 in b 4 with respect to the velocities that enter the operators in b 5 b 6 through the dependence of ζ on u another option is to use automatic differentiation of the code using tams giering and kaminski 1998 or similar software as it has been done by many authors e g losch et al 2014 in the present study j 2 was obtained analytically using the relationship for the vector valued function ζ u and arbitrary matrices p q and vector s b 7 u p q ζ s p s q ζ u noi where ζ u is the n 2 n matrix of the derivatives of ζ with respect to 2 n ice velocities plugging the matrices from b 5 b 6 into b 7 and substituting the result into b 4 yields the following expression for j 2 b 8 j 2 q 1 ζ p 1 q 1 ζ p 2 q 2 ζ p 1 q 2 ζ p 2 where ζ ζ δ 2 and the n 2 n 2 matrices q 1 2 p 1 2 are p 1 2 d y v β d x u d y v d x d y u d x v d y p 2 2 d x u β d x u d y v d y d y u d x v d x q 1 α d x t d x u a y d y t d y u a x β a y d x t d y v a x d y t d x v q 2 α d y t d y v a x d x t d x v a y β a x d y t d x u a y d x t d y u note that j 2 b 8 is not symmetric due to the specific formulation of the scheme b 4 for computing the product j 1 u this asymmetry destroys the positive semi definite property of j 2 and may be the cause of violation of the dissipative property of j 1 j 2 for certain configurations of the velocity field 
23824,viscous plastic rheology is widely used in the sea ice modeling community at increasingly high resolutions due to the high degree of non linearity of the rheological constraints accurate approximation of the jacobian is required to improve the efficiency of the implicit solvers of the sea ice momentum equation in pack ice we consider the analytical jacobian of the ice momentum equation and assess its approximation errors in the jacobian free newton krylov jfnk method and in the family of more traditional schemes which neglect the dependence of viscosity coefficients on the deformation tensor it is shown that this dependence provides a substantial contribution to the jacobian especially in the regions enriched by linear kinematic features like ridges and elongated polynyas numerical experiments indicate that performance of the newton solvers is also sensitive to errors associated with inexact computation of the search direction that may be caused in particular by numerical approximations of the jacobian which violate its dissipative property based on this analysis an improved selective damping strategy for the newtonian solver of the momentum equation is proposed a series of numerical experiments conducted in simulated pack ice environment demonstrate faster convergence of the updated solver with analytical jacobian as compared to the one based on the selectively damped jfnk method with inexact gmres solver in the inner loop keywords sea ice dynamics newton method jacobian damping 1 introduction accelerating changes in the arctic climate increase the interest in accurate simulations of sea ice dynamics and thermodynamics which relies on efficient techniques of solving the equations of the sea ice numerical models the main challenge in simulating sea ice dynamics comes from its rheology describing the relationship between the internal stress and deformation rate which is commonly represented by the viscous plastic vp approximation this approach was proposed by hibler 1979 who employed non linear dependence of the pack ice viscosity on the deformation rates to represent sea ice under low deformations as a very viscous newtonian fluid or as a plastic material once critical stress values have been reached although an impressive variety of other rheologies were proposed in recent years e g schreyer et al 2006 girard et al 2011 tsamados et al 2013 rampal et al 2016 ringeisen et al 2021 they are not widely adopted in the operational models as it is not completely clear which one of those provides the best representation of the sea ice mechanical properties for this reason the vp rheology remains the scheme of choice in the sea ice modeling community due to its relative simplicity and ability to provide realistic simulations under a wide range of environmental conditions e g kreyscher et al 2000 the major problem with ice modeling and vp rheology in particular are rather stiff constraints imposed by the momentum balance of the sea ice these constraints have to adequately describe abrupt changes in the magnitude of ice properties viscosity coefficients under smooth forcing variations such as transition from a diverging to a converging ice pack the emerging strong gradients in the coefficients can deteriorate stability of the applied numerical schemes a reasonable approach for dealing with this problem of the momentum equation is to use a time step of a few seconds in an attempt to explicitly resolve elastic oscillations emerging in sea ice hunke and dukowicz 1997 2002 however this approach appears to be computationally expensive bouillon et al 2013 and requires additional modifications lemieux et al 2012 kimmritz et al 2015 2016 for robust convergence to vp solutions furthermore it is not useful in climatological studies which require integrations for hundreds or thousands of years on coarse grids for these reasons investigation of implicit and semi implicit treatment of the vp momentum equation has been the subject of a number of studies in recent years e g lemieux et al 2012 losch et al 2014 lemieux et al 2014 auclair et al 2017 there is also a growing interest to vp ice dynamics from both theoretical brandt et al 2021 liu et al 2021 and applied mehlmann and richter 2017 2020 mehlmann et al 2021 mehlmann and korn 2021 mathematicians in particular mehlmann and richter 2017 investigated applicability of the selective jacobian damping technique to the weak formulation of the vp model with analytic jacobian they found much better performance of the newtonian solver with a modified damping algorithm proposed by mandal et al 2016 for viscous plastic fluids this result seems to challenge the existing notion that availability of the analytical jacobian does not bring any advantage in solving the vp momentum equation in comparison with the jacobian free newton krylov jfnk solvers based on finite difference approximations of the jacobian action on a vector e g losch et al 2014 in the present study we investigate utility of the analytic jacobian in the framework of the damping technique and assess the impact of the jacobian approximation errors on the convergence rate of a damped newtonian solver in particular we find the importance of maintaining the dissipative property of the rheological part of the jacobian and propose an improvement of the damping scheme of mandal et al 2016 using implicit filtering of the jacobian approximation errors this article is structured as follows in section 2 the governing equations of the sea ice dynamics are described with special focus on the linearization of the internal stress divergence under the vp rheological constraints section 3 contains an overview of the jacobian approximations in the vp ice models and quantitative assessment of these errors using a sequence of pack ice states from the cice6 model run operationally at the naval research laboratory in section 4 we analyze spectral properties of the jacobians in a simplified vp model based on the hibler s b grid discretization and expose the results of numerical experiments with the improved damping scheme discussion of the results and conclusions are provided in section 5 2 jacobian of the vp rheology 2 1 formulation the general equation describing the momentum balance in sea ice is 1 ρ h d t f k u div σ ϵ τ u where ρ is the sea ice density u u v h are the 2d fields of ice velocity and thickness d t is the operator of material time derivative f is the coriolis parameter k is the vertical unit vector τ stands for the force exerted on ice through its interaction with the bottom atmosphere and the ocean while σ and ϵ are the tensor fields of ice stress and ice deformation rate represented by 2 2 matrices 2 σ σ x x σ x y σ x y σ y y ϵ 1 2 2 x u x v y u x v y u 2 y v in the vp formulation σ is a function of ϵ relating internal ice stresses to ice deformation rates and velocities through the rheological relationship proposed by hibler 1977 1979 3 σ 2 η ϵ ζ η tr ϵ p 2 i ζ e p 2 δ η ζ e 2 where i is the 2 2 identity matrix 4 p h a h exp κ 1 a is the scalar field of the internal ice pressure with the empirical compactness strength parameter κ a is the ice concentration e is the yield curve axes ratio of the sea ice while ζ and η denote positive sea ice bulk and shear viscosity coefficients whose magnitudes depend e g hunke 2001 on the scalar field 5 δ ϵ e 2 1 tr ϵ 2 2 tr ϵ 2 δ m i n 2 1 2 where δ m i n is the regularization parameter e g kreyscher et al 2000 to simplify further treatment we introduce the auxiliary linear operation 6 ϵ ϵ tr ϵ e 2 1 2 i and merge two viscosity fields into a single one by setting 7 ζ p e δ these definitions reduce the constitutive relation 3 to the following form 8 σ ϵ ζ ϵ p 2 i p ϵ e δ i 2 in the vp sea ice modeling eqs 1 5 are augmented by two evolution equations for the fields of ice thickness and concentration that are explicitly integrated forward in time whereas the momentum equation is solved implicitly by substituting the rheological relationship 8 into 1 in this study we focus on the pack ice dynamics when the rheology term div σ dominates the momentum balance so one could further simplify the problem by setting d t t and consider the following form of the momentum equation 9 ρ h t f k u div ζ ϵ u 1 2 p τ u at this point it is necessary to note that the first term on the rhs of 9 is a homogeneous function of velocity and can therefore be represented as a product j u where j is the rheological part of the jacobian an important physical constraint imposed on the discretized form of j is its dissipative property e g hunke and dukowicz 2002 which requires the respective matrix representation of j to be negative semi definite nsd so that the rheological term u j u in the kinetic energy equation 10 ρ h t 1 2 u u u j u 1 2 u p u τ u should always dissipate energy this is especially important for implicit treatment of the momentum equation that employs the newton solver simulating the action of inverse jacobian on a vector to generate a search direction unfortunately keeping the dissipative property of j is somewhat tricky especially when the momentum equation is discretized in the strong formulation this difficulty is visible in the analytical form of the rheological jacobian action on a vector δ u which is related to the respective deformation rate δ ϵ via the relationships in 2 and 6 11 j δ u j 1 j 2 δ u div ζ δ ϵ 2 δ 2 ϵ tr ϵ δ ϵ here δ ζ and ϵ denote the background fields used in linearization the first term in eq 11 is obtained by varying ζ ϵ in eq 8 with respect to ϵ while keeping the viscosity at the background value the second term emerges as a result of varying velocities in the expression for the viscosity ζ appendix a and appears to have a somewhat more complex structure historically numerics of the vp sea ice models were formulated to preserve the nsd property of only the first term j 1 δ u div ζ δ ϵ in eq 11 this was not critical if the fixed point iterations were used to solve the momentum equation and viscosities were updated at the next approximation of the velocity field subsequent transition to faster converging newton solvers requires computation of j 2 δ u which is either obtained by automated differentiation ad of the code for j 1 δ u or approximated by finite differentiation of that code in view of the iterative nature of the non linear solvers of the momentum equation it is instructive to assess the relative magnitude of the two jacobian constituents as well as other sources of errors that may occur in the approximation of the jacobian action on a vector 3 jacobian approximations 3 1 incomplete linearization there is a considerable literature devoted to the technique of solving the momentum balance equation with vp rheology the simplest method is to iterate a linearized version of the equation using a fixed point or picard iteration this approach involves two embedded loops see e g lemieux et al 2008 lemieux and tremblay 2009 and references therein in the inner loop the momentum equation is solved using an approximation to j with ice viscosity coefficients being fixed at their background values i e by setting j j 1 in the second outer loop these coefficients are updated using velocities obtained on the completion of the inner loop in terms of the jacobian approximation the momentum equation in the inner loop is solved using incomplete linearization of j which is obtained by neglecting j 2 i e implicitly assuming that j 2 j 1 and then iteratively correcting a sequence of intermediate solutions in the outer loop this strategy encounters a number of problems including slow convergence of the outer loops which is especially evident at fine less than 5 km grid resolutions residual errors in the ice velocity field tend to be localized in the regions of strong ice convergence and deformation lemieux and tremblay 2009 we speculate that such behavior indicates certain deficiency of the approach that is related to the lack of information on the local gradient of the residual provided by the exact jacobian to assess the validity of such approximation in a realistic situation we analyzed the output of the cice6 hunke and lipscomb 2008 model run fig 1 at δ x 2 km resolution in the east siberian sea and forced by the output of the gofs system metzger et al 2014 run at 1 25 resolution one hundred daily ice velocity thickness and concentration fields in the region of heavy pack were given on 235 235 grid spanning the period between january 1 and april 10 2018 prior to analysis the velocity fields were filtered with the gaussian filter with the decorrelation length scale of l 1 2 δ x this was done to suppress grid scale variability of u associated with the residual elastic waves typical for the evp rheology of the cice6 model to estimate the relative magnitude of j 2 for each day we generated an ensemble of fifty random velocity perturbation fields δ u computed the respective deformation rates δ ϵ and calculated 100 50 values of j 1 2 δ u using cice6 output as the background for computing j 1 and j 2 in accordance with eq 11 after that the relative approximation errors 12 e 1 j 2 δ u j 1 j 2 δ u were computed at every grid point for all the 5000 samples these computations yield the average value e 1 0 65 0 06 with significant time variations in particular the approximation error was notably higher in the periods when the domain was densely populated by linear kinematic features lkfs fig 1a and was lower during the relaxation periods fig 1b such dependence may partly explain the structure of the residual velocity fields observed by lemieux and tremblay 2009 in the vp ice model runs with the picard solver of the momentum equation 3 2 finite difference approximation to improve the convergence lemieux et al 2010 introduced the jacobian free newton krylov jfnk solver in the practice of sea ice modeling the method is based on the finite difference approximation of the jacobian s action on the sea ice velocity field assuming fully implicit treatment of eq 9 time discretization of the momentum equation can be represented in the form 13 f u ρ h i δ t f k u j u u τ u 1 2 p ρ h u δ t 0 where overline denotes the unknown velocity at time t and all other variables are assumed to be known from the previous time step t δ t to avoid recomputing the jacobian in the process of the newton iterations its action on a vector u is approximated by the finite difference ɛ 1 f u ɛ u f u where ɛ is a sufficiently small number the respective approximation error for the non linear contribution to the jacobian 14 e 2 ɛ ɛ 1 f u ɛ u f u ρ h u δ t f k u j τ u u j τ u u was estimated similar to e 1 results of these computations are shown in fig 2 by the thick black line which demonstrates a significant loss of accuracy up to 5 orders in magnitude associated with the strong non linearity of j the loss is manifested by the delay of the linear reduction of e 2 ɛ visible in the upper right corner of fig 2 at the higher values of ɛ for comparison we removed j from eqs 13 14 to compute the same error dashed line in fig 2 in the case of much milder quadratic non linearity associated with external forcing it is remarkable that due to the strong non linearity of the rheological jacobian setting ɛ 1 0 6 used by lemieux et al 2010 provides an accuracy of only 10 which appears to be of the same order in magnitude as e 1 nevertheless lemieux et al 2010 found that the jfnk scheme significantly improved the convergence rate compared to picard iterations fig 2 also shows that the best accuracy is achieved at ɛ 1 0 10 which agrees with the result of losch et al 2014 who investigated scalability of the jfnk scheme in the coupled sea ice ocean model of the arctic the major advantages of the finite difference approach are the absence of the necessity to design additional software for explicit computation of j and ability to take into account albeit with an error of finite differentiation all the terms in the analytic expression for the jacobian among the disadvantages are amplification of the finite difference errors by the differential operators present in eq 11 especially in j 2 and violation of the condition ɛ u u in the regions where u is negligible although these deficiencies could in principle be removed by the exact analytic representation of the discrete jacobian they do not complete the list of possible error sources occurring during the newton iterations 3 3 inexact newton method in particular accumulated experience with applications of the newton method to vp sea ice modeling have shown computational advantages of interrupting the inner loop iterations at a moderate tolerance to avoid oversolving the linearized version of eq 13 the main objective of the inexact newton method e g lemieux et al 2010 is to find a reasonable balance between the computational cost and accuracy of computing the exact search directions especially at the initial stages of the newton iterations when these directions are far from optimal being beneficial overall this strategy generates an additional error in computing the newton search direction defined by the product of the inverse jacobian and the residual 13 the selective jacobian damping technique mandal et al 2016 attenuates these and other sources of numerical errors in the newton algorithm by selectively reducing their impact on the most error prone parts of the jacobian mehlmann and richter 2017 applied this technique to the vp sea ice model replacing the exact jacobian j j 1 j 2 in 11 by 15 j j 1 γ n 1 j 2 where γ n 1 is the adaptive parameter which selectively damps the second part of the rheological jacobian at the current iteration it is defined by 16 γ n 1 min 1 γ n γ 4 0 7 exp 1 5 q n γ n γ 1 γ n γ here q n is the relative reduction of the residual at the previous iteration and γ 0 2 is the background value of the damping parameter using inexact newton method with analytic jacobian mehlmann and richter demonstrated that selective damping of j 2 eq 15 drastically improves the convergence of the newton method with inexact gmres solver it is also noteworthy that errors in computing the newton search directions could be more destructive in the numerical schemes which maintain the nsd property only for a certain part of the jacobian e g j 1 using finite and or analytic differentiation of such schemes for computing the jacobian action on a vector yields approximations which violate the nsd property appendix b as a consequence such approximations may generate velocity fields that amplify the kinetic energy of ice cover and significantly slow down convergence of the newton iterates in the next section we explore the impact of such behavior using as a testbed a traditional b grid discretization of the momentum equation by hibler 1979 and then modify the selective damping scheme 16 to alleviate this impact 4 numerical experiments 4 1 methodology the numerical experiments were conducted using a simplified vp sea ice model with the momentum equation 9 and rheological constraints 4 8 formulated on the rectangular b grid with periodic boundary conditions and a standard set model parameters the proportionality coefficient in 4 was p 27 500 n m 2 while other parameters were e 2 κ 20 f 1 5 1 0 4 s 1 ρ 900 kg m 3 and δ m i n 2 1 0 10 s 1 the forcing term was set to 17 τ τ a τ o τ a c u u assuming motionless ocean with c 5 64 kg m 3 the atmospheric forcing component τ a was chosen to have the form 18 τ a x τ 0 9 cos x sin y sin x cos y 19 τ a y τ 0 9 sin x cos y cos x sin y where τ 0 0 035 n m 2 x 2 π x c t l y 2 π y l c l 2 t and l t are the size of the domain and the model integration time respectively this setting specifies forcing as a 2 2 checkerboard pattern of eddies that migrate westward by approximately one eddy diameter by the end of the model run to generate ridging in pack ice atmospheric eddies are characterized by wind convergence in the cyclones and divergence in the anticyclones experiments were conducted with the constant grid step δ x 4 km in both directions and the domain sizes n were varied with n 40 64 and 128 the time step δ t was set to 2160 s and was not changed explicit time integration of the evolution equations for ice thickness and concentration was performed for 160 time steps t 4 days using the lax wendroff scheme the momentum equation was treated implicitly numeric representation of the rheological term is the same as proposed by hibler 1979 thus keeping the nsd property of j 1 intact the second term j 2 was obtained by analytic differentiation of j 1 with respect to the velocities entering its matrix elements see appendix b for details in actual computations all the operators entering the evolution equations were represented by sparse matrices the two components of the jacobian had exactly 14 non zero elements in a row for j 1 and 18 non zero elements in j and j 2 eq b 8 in appendix b hereinafter we redefine j 1 and j 2 in accord with linearization of f in the vicinity of u in 13 20 j 1 j 1 u τ u u ρ h i δ t f k 21 j 2 j 2 u so that due to the change of their signs j 1 and j 2 now have to be represented by positive definite pd and nsd matrices respectively while j 1 is not restricted to the rheological part of the full jacobian but incorporates all other terms in order to remove the dependence on the initial conditions numerical experiments were designed as ten member ensemble runs of the model fig 3 each experiment was made with a certain configuration of the newton solver of the momentum equation and performance of the solver was assessed by averaging over the ensemble ensemble members were specified by setting the initial conditions for ice thickness and concentration as random realizations of a gaussian field with the decorrelation scale of 3 δ x the homogeneous and isotropic covariance functions for these fields had the mean values of 1 5 m and 97 for ice thickness and concentration respectively while their standard deviations were set to 0 3 m and 2 in addition ice concentration fields were capped by 100 from above the initial ice velocity was set to zero to solve the linearized momentum equation in the inner loop we used two methods the exact solver based on lu decomposition of the jacobian and inexact approach similar to the one used by lemieux et al 2012 but with the gmres solver preconditioned by the incomplete lu factorization of j 1 the line search in newton directions was defined by the damping parameter γ different from γ in eq 15 22 u n 1 u n γ j 1 f u n the values of γ were specified similar to mehlmann and richter 2017 no more than four attempts to reduce the residual in the search direction were performed with γ k defined by the sequence γ k 4 k k 0 3 newton iterations were terminated as soon as the residual either reached 0 01 of its initial value or its rms magnitude was less than 1 0 4 m s 4 2 spectral properties of the jacobian fig 4 shows a typical jacobian spectrum of an ensemble member obtained in the course of the experiments in accordance with the hibler s scheme the first part of the jacobian j 1 is positive definite although its condition number remains high 1 0 7 mostly due to the selected value of δ m i n the second part of the jacobian j 2 is asymmetric see appendix b and appears to violate the psd property of j this violation is however not severe as the difference between the real parts of the eigenvalues λ of j 1 and j is always positive while the imaginary parts of the eigenvalues are either zero for the leading modes or 1 2 orders in magnitude smaller than their real parts with an exception of the very tail of the spectrum where eigenvalues are more susceptible to the approximation errors of the numerical representation however it is the tail that defines the error related scatter of the newton search directions in eq 22 a closer look at the eigenvectors at the tail of the spectrum demonstrates much faster spatial variations of those corresponding to j as compared to j 1 fig 5 although these fine structures are likely to be responsible for emergence of the realistic features like lkfs in pack ice they could also generate spurious sources of energy if the respective modes provide positive contributions to the kinetic energy budget 10 in this aspect figs 4 5 illustrate the idea of selective damping of j 2 which provides a heuristic method of optimizing the balance between the realism of a search direction and potential errors in its structure a simple way to assess the impact of these errors on a search direction s j 1 f is to compute the sign of the dot product f s which should be positive if the numeric approximation of j 1 f keeps the pd property of the jacobian f j f 0 f intact this consideration could potentially improve the selective damping scheme 15 of the newton method 4 3 modifications of the damping scheme in the first series of experiments we estimated the computational efficiency of the jacobian damping without the adjustment of the damping parameter i e by simply setting γ c o n s t throughout newton iterations γ was varied in the range between 0 corresponding to picard iteration and 1 newton iteration results demonstrated nearly linear reduction of model integration time with a potential of 10 fold reduction at γ 1 as shown by the dashed line in fig 6a however the reduction of computation time flattened out at γ 0 6 and even started to increase at γ 0 9 moreover when γ 0 97 the model integration could not be completed because the momentum equation residual failed to decrease to the target values in less than 200 iterations at more than 10 consecutive time steps to explore possible reasons for such a behavior we computed the spectrum of the symmetric part of the jacobian j j t 2 which contributes to the kinetic energy budget and then counted the number n of negative eigenvalues λ k as well as their contribution 23 β k 1 n λ k 1 k 1 n λ k 1 to the trace of its inverse results of these computations are shown in fig 6b as it was expected from the cpu time assessment in fig 6a the relative number of the growing unstable modes as well as their contribution β to the inverse spectrum were completely absent for γ 0 4 and did not exceed 0 07 for γ 0 6 for larger values of the damping parameter n increases approximately 10 times to 0 7 while the contribution to the inverse spectrum rises much faster reaching 14 for γ 1 fig 6b this is indicative of a tendency for unstable modes to populate the tail of the jacobian spectrum the above observations provide an option to filter the approximation errors of the search direction s j 1 f by checking the sign of the dot product f s prior to executing the line search as mentioned earlier the dot product f s can serve as an indicator of errors in approximating the action of j on a vector because both j and j 1 should be represented by pd matrices and therefore satisfy the relationship sgn f j 1 f sgn f j f 0 for any velocity perturbation δ u f δ t so in the case of detecting a potentially unstable direction with δ u s 0 the damping parameter is reset to the safe background value γ another possibility to improve the damping scheme 16 is to introduce information on the line search efficiency at the previous iteration as an example one could reduce the threshold value q of the residual reduction rate which triggers the mechanism of decreasing the damping parameter under the min operator of eq 16 the threshold value is obtained by setting to one the expression in square brackets of 16 24 q 2 3 ln 4 1 γ 0 7 0 97 to introduce the line search information we elected to modify the numerator of the fraction under the logarithm in 24 as mentioned above in the course of the numerical experiments the background value of the damping parameter was set to γ 0 3 further experimentation with the ensemble runs revealed a noticeable improvement when the exponent of the numerator was changed from 1 to 0 9 k 80 where k is the number of line search attempts at the previous iteration the modification accelerated the reduction rate γ n 1 γ n of the damping parameter and the contribution of j 2 to the jacobian with the growth of the number of line search attempts per iteration as a result the damping scheme 16 was transformed to 25 γ n 1 γ f n s n 0 min 1 γ n γ 4 0 9 k 80 0 7 exp 1 5 q n γ n γ 1 γ n γ fig 7 compares the number of newton iterations required by the damping schemes 16 and 25 thin lines in both panels show the ensemble average values of the actual number of newton iterations on every time step while the thick lines are their 2 h smoothed values comparison shows that the major improvement is provided by the unstable directions filter first line in eq 25 which is responsible for nearly 70 of the newton iterations reduction of the background damping scheme the effect of adding the line search efficiency information is relatively minor but appears to be still significant an overall quantitative characterization of the modified damping scheme is given in table 1 a significant reduction is visible across all the three major parameters including the total model integration time 27 and the average number of function calls 36 per time step the most prominent reduction is observed in the number of line search failures 90 bottom of the third column that are more likely to occur when an unstable search direction is encountered 4 4 comparison with jfnk method in this section we compare results of computations carried out using the analytic jacobian and the exact linear solver for computing a search direction with performance of the jfnk solver where the jacobian s action is constructed via a first order finite differences and the newton correction determined via a preconditioned gmres solver in the jfnk setting the residual of the momentum equation was rescaled to have the unit norm prior to multiplication by ɛ 1 0 10 the approximation error as a function of ɛ was estimated using eq 14 and found to be consistent with errors of the gofs solution cf gray and black lines in fig 2 q to simulate selective damping in jfnk scheme we employed the analytic code for j 1 u which is supposed to be available for computing the rheological term φ u j 1 u u in the momentum equation so that the damped code consisted of two steps 26 u φ u ɛ u φ u ɛ 27 j u 1 γ j 1 u u γ u the first step eq 26 provides the finite difference approximation for the product of the rheological part of the jacobian j 1 j 2 by u while the second step yields its selectively damped version j 1 γ j 2 u through explicit computation of the product j 1 u u the damping parameter was computed in accord with eq 25 in both cases the computational cost of such a two stage operation is only 10 higher than that of 26 because both the background field u and j 1 u were stored prior to the gmres call the jfnk method was configured similar to lemieux et al 2012 with the only difference that we used incomplete lu preconditioner instead of doing the fixed number of successive over relaxation iterations overall the cost of the exact jacobian solver including computing j 1 and j 2 was on the average 110 times more expensive than that of a single finite difference approximation 26 used by the inexact jfnk solver this advantage was however outbalanced by a considerable number of the gmres function calls and more importantly by much larger line search failures in the process of newton iterations the upper panel in fig 8 shows a comparison of the number of newton iterations for a single ensemble member run it is remarkable that the number of jfnk outer loop iterations was very close to that of the exact solver with an exception of a few time steps when the damped newton method with jfnk solver failed to converge in less than 200 iterations these failures were basically the major cause which reduced the computational advantage of the jfnk scheme this effect is accumulated over the entire ensemble run requiring in total 28 more newton iterations for the jfnk method bottom panel in fig 8 this is consistent with the result of losch et al 2014 who observed a significant 30 reduction of the number of newton iterations when using the jacobian obtained by automated differentiation of the code for j 1 u u regarding the total computation time we also observed a considerable 25 improvement in comparison with jfnk solver whereas losch et al 2014 who used newton iterations without selective damping γ 1 found approximately equal computational cost of both methods the observed reduction of computer time is attributed to more frequent failures of the jfnk method 5 summary and discussion based on the analysis of various sources of the jacobian approximation errors and their impact on the newton search directions a modification of the selective jacobian damping method of mehlmann and richter 2017 is proposed the major idea is to use the dissipative property of the analytic jacobian in order to evade searches in the directions which tend to increase the kinetic energy of ice cover using analytic representation of the jacobian we also estimated the magnitudes of errors caused by neglecting the viscosity derivatives of the picard method and by finite differentiation of the jfnk scheme our findings are summarized as follows 1 dependence of the ice viscosity coefficients on the deformation rate provides an essential contribution to the jacobian their relative magnitude typically varies within 40 70 omitting this contribution results in the jacobian approximation errors of the same order in magnitude the magnitude of contribution from the viscosity derivatives strongly depends on the concentration of lkfs which tends to increase in the periods of stronger large scale convergence of the ice velocity 2 the finite differentiation method requires significant reduction down to ɛ 1 0 10 of the perturbations magnitude and the necessity to conduct differentiation in the double precision in particular our estimates show that using ɛ 1 0 6 in the pack ice may result in the approximation errors of 5 10 fig 2 which may inhibit convergence of the jfnk method 3 newton search directions are also affected by errors in computing the action of the inverse jacobian on the residual especially for the large values of the damping parameter these errors may emerge from violation of the dissipative property of the jacobian by the numerical scheme and or limited accuracy of the jacobian inversion they can be partly filtered by checking the sign of the residual projection on the search direction prior to execution of the line search 4 an additional 10 improvement to the adaptive damping scheme has been obtained by taking into account information on the line search efficiency at the previous iteration 5 ensemble runs of a simplified model with vp rheology have shown that the above modifications reduce the number of newton iterations by approximately 30 while using the analytic jacobian requires 1 3 times less computer time as compared to jfnk method the latter advantage of using analytic jacobian is not consistent with a general notion that jacobians obtained by automated differentiation of the code do not give any computational advantage in comparison with jacobian free methods we attribute this discrepancy to several factors first automated differentiation tools tend to provide less efficient codes than hand written second implementation of the adaptive damping in jacobian free method implies an additional function call required by the necessity to separate the jacobian into two parts eqs 26 27 finally a simplified model we used for the test case may have an advantage compared to the state of the art sea ice model involving several ice categories sophisticated physics and thermodynamics it should also be noted that the general problem of improving the efficiency of nonlinear solvers is a complex issue largely defined by their parallelization capabilities for that reason the iteration count used in this study for a simplified model run on a single processor may not translate directly into wall clock time in real applications the vp scenarios with embedded iterative loops especially involving the flow of information of the linear solver through iterations and other parallelization issues have a large room for optimization for these reasons we assume that the utility of implementating analytic jacobians with selective damping in realistic sea ice models should definitely require further investigation another important issue is related to keeping the dissipative property of the analytic jacobians historically numerics of ice models with vp rheology were not specifically designed for utilizing the newton method we have shown that application of ad tools to such numerical schemes provides jacobian approximations that violate the positive definite property which in turn may deteriorate convergence of the newton method a similar inhibiting effect could be produced by applying inexact inner loop solvers even if the jacobian is kept positive definite our experiments indicate that the selective jacobian damping algorithm 15 has a reasonably good potential to improve convergence of the implicit solver in the sea ice momentum equation from the viewpoint of computational efficiency selective damping also provides an additional advantage to the analytic jacobian representation because implementation of selective damping in the jacobian free algorithm requires running and development of the additional code to separate the action of the two jacobian components on a vector eqs 26 27 there are also numerous factors remaining to be explored in relation to the proposed improvement of the non linear solver these factors are responsible for strong intermittency of the stiffness matrix emerging in the course of time integration and could be dealt by adjustment of the model grid and or time stepping the latter could be improved by accumulating information on the spectral properties of the stiffness matrix and or peculiarities in the spatial structure of sea ice fields such as the lkf concentration mentioned in section 3 1 similar problems exist for elastic vp evp solvers which in contrast to the implicit time stepping of the momentum equation solve it explicitly in this case the time step is defined by the spatially varying speed of the elastic waves that tend to propagate faster along the ice ridges associated with the lkfs despite certain progress in dealing with the residual elastic wave effects and convergence of the evp solvers e g kimmritz et al 2015 2016 there is still a considerable room for improvement of their performance based on the analysis of the sea ice state the major problem is that such analysis has to be relatively inexpensive to prevent compromising the computational efficiency of a sea ice model with vp rheology which uses either explicit or implicit time stepping of the momentum equation in the light of the above problems a quick access to the analytic part of the rheological contribution to the jacobian could benefit the progress in improving the computational efficiency of the vp sea ice models the analytic jacobian is also a crucial ingredient of the data assimilation systems and adjoint sensitivity analyses involving sea ice models e g kauker et al 2009 heimbach et al 2010 and may also benefit general development of the variational approaches to construction of the numerical methods controlling lkf evolution associated with formation of ridges roberts et al 2019 and polynyas in the pack ice we are currently planning to compare performance of the inexact jfnk solvers with the ones featuring the analytic jacobian in a more realistic setting we believe that results will benefit and provide further guidance for the development of the vp models and their adjoints in the near future declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the study was supported by the naval research laboratory projects optimization of rheology for advancing sea ice forecast 73 1u98 025 and precision assessment of remotely sensed data with error correlations 73 6c95 025 appendix a jacobian of the vp rheology since the variation of the second term in 8 with respect to velocity is zero we have to compute only the variation of the first term which is basically a 1 δ ϵ δ 1 δ δ ϵ ϵ δ δ δ applying the differential relationship for the trace of the n th power of a matrix a δ tr a n n tr a n 1 δ a to eq 5 yields expression for the variation of δ in the form a 2 δ δ 1 2 δ δ e 2 1 tr ϵ 2 2 tr ϵ 2 2 δ tr i e 2 1 2 tr ϵ ϵ δ ϵ 2 δ tr ϵ δ ϵ combining this with a 1 taking 7 into account and applying the divergence operator to the result yields 11 j 1 δ ϵ div ζ δ ϵ j 2 δ ϵ div 2 ζ δ 2 ϵ tr ϵ δ ϵ mehlmann and richter 2017 provide an alternative form of the jacobian using notation slightly different from 6 and 7 ϵ ϵ tr ϵ 1 2 i δ tr ϵ 2 2 e 2 ϵ ϵ δ m i n 2 1 2 ζ p 2 δ where stands for the inner product of two matrices their final expression for the two components of the jacobian have the form j 1 δ ϵ div ζ 2 e 2 δ ϵ i tr δ ϵ j 2 δ ϵ div ζ δ 2 2 e 2 ϵ i tr ϵ 2 e 2 ϵ δ ϵ tr ϵ tr δ ϵ which is equivalent to 11 appendix b numerical approximation of the jacobian let δ be the grid step and s denote the n n right shift matrix obtained from the identity matrix i by displacing its diagonal one step to the right and placing 1 at the bottom of the first column to account for the periodicity the 1d finite difference and averaging operators in a given direction r either x or y are then given by d r s r i δ and a r i s r 2 in two dimensions the finite difference operators are defined via krönecker products of these matrices with identity matrices in the complimentary direction b 1 d x d x i y d y i x d y b 2 a x a x i y a y i x a y in the similar manner the differential operators averaged in the complimentary direction are specified by b 3 d x d x a y t d y a x t d y these operators are used to project velocity derivatives on the scalar grid where the fields of pressure p and δ are calculated to obtain the viscosity ζ eqs 5 7 the averaging operators in b 3 are transposed because velocities on the b grid are shifted half a grid step with respect to the scalars using these definitions hibler s discretization of div σ can be written in the form b 4 j 1 u 1 2 α d x x d y y β d x y d y x β d y x d x y α d y y d x x u v with b 5 d x x d x t a y ζ d x d y y d y t a x ζ d y b 6 d x y a y d x t ζ d y d y x a x d y t ζ d x where square brackets in b 5 b 6 and hereinafter denote conversion of a vector to the diagonal matrix while α 1 e 2 and β 1 e 2 note that formulation b 4 b 6 of j 1 is symmetric as d x x d x x t d y y d y y t and d x y d y x t the latter property follows from the relationships d y t a x d y t and d x t a y d x t these symmetries guarantee dissipative negative semi definite property of j 1 in the ice kinetic energy equation the full analytical jacobian can be computed by differentiating the matrix elements of j 1 in b 4 with respect to the velocities that enter the operators in b 5 b 6 through the dependence of ζ on u another option is to use automatic differentiation of the code using tams giering and kaminski 1998 or similar software as it has been done by many authors e g losch et al 2014 in the present study j 2 was obtained analytically using the relationship for the vector valued function ζ u and arbitrary matrices p q and vector s b 7 u p q ζ s p s q ζ u noi where ζ u is the n 2 n matrix of the derivatives of ζ with respect to 2 n ice velocities plugging the matrices from b 5 b 6 into b 7 and substituting the result into b 4 yields the following expression for j 2 b 8 j 2 q 1 ζ p 1 q 1 ζ p 2 q 2 ζ p 1 q 2 ζ p 2 where ζ ζ δ 2 and the n 2 n 2 matrices q 1 2 p 1 2 are p 1 2 d y v β d x u d y v d x d y u d x v d y p 2 2 d x u β d x u d y v d y d y u d x v d x q 1 α d x t d x u a y d y t d y u a x β a y d x t d y v a x d y t d x v q 2 α d y t d y v a x d x t d x v a y β a x d y t d x u a y d x t d y u note that j 2 b 8 is not symmetric due to the specific formulation of the scheme b 4 for computing the product j 1 u this asymmetry destroys the positive semi definite property of j 2 and may be the cause of violation of the dissipative property of j 1 j 2 for certain configurations of the velocity field 
