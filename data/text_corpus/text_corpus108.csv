index,text
540,nonstationary flood frequency analysis nffa has increasingly been applied to predict future floods under climate change the inference of nonstationarity from trend tests intt on historical floods is a widespread practice used to justify the application of nffa however its reliability has seldom been investigated this research examines future floods from interpretations of intt compared to those obtained from cause and effect processes by a hydrological model ince the study uses ince to quantify the changes in the regime and magnitude of floods due to potential climate change in the mid 21st century using multi model ensemble simulations under two greenhouse gas emissions scenarios i e rcp 2 6 and rcp 8 5 independent peaks over threshold from simulated streamflow were used to estimate the changes in future 2040 2064 flood regimes and magnitudes compared to their historical 1983 2007 counterparts for 29 unregulated catchments across alberta canada separation of extreme events and their fittings to generalized pareto distributions gpd were based on a hybrid approach that combined two developed automated threshold selection methods and four estimators for the parameters of the gpd based on comparing the results of intt and ince we show that future changes in floods contradict we also show that the future frequency curves shifted differently at different return periods compared to historical curves while in some instances future climate tended to decrease small floods and increase larger floods or vice versa finally flood magnitudes in 2 3 of the studied catchments in alberta are predicted to intensify accompanied by increases in the rate of occurrence and earlier shifts in the timing of floods for both climate scenarios whereas no considerable change in the duration was recognized keywords nonstationarity hydroclimatic evolutions peaks over threshold pot climate change and ensemble simulations future flood regimes alberta floods 1 introduction study of extreme hydrologic events such as floods is of great interest because of their significant and widespread impacts on societies ecosystems and economies detrimental impacts of floods typically include fatalities loss of property and damage to critical infrastructure further concerns are growing that future flooding events will become more frequent and severe hinkel et al 2014 huang et al 2014 jongman et al 2014 kay and jones 2012 in particular climate change is expected to alter the statistical properties of several climatic variables including seasonal and extreme precipitation which are likely to increase in the future gizaw and gan 2016 jiang et al 2017 ragno et al 2018 tan and gan 2017 for all the reasons above it is imperative to study potential changes in flood severity in the future nonstationary statistical approaches have increasingly been applied to study future floods and the inference of nonstationarity from outcomes of trend tests intt on historical floods is amongst the widely used techniques to assume the future behavior of floods chen et al 2017 gado and nguyen 2016 strupczewski et al 2001 the intt relies on the application of nonstationary frequency analysis using extreme value analysis eva see e g gilroy and mccuen 2012 machado et al 2015 obeysekera and salas 2014 villarini et al 2009 yan et al 2017 particularly in nonstationary eva probability distributions are fitted to existing historical records of flood discharges by assuming time varying parameters and then applying the nonstationary distributions to estimate the flood magnitudes that correspond to the desired return periods coles 2001 nonstationary eva approaches have evolved over time and have been employed to relate future flood probability distributions not only to time leclerc and ouarda 2007 tan and gan 2015 but also to other covariates such as climate variables or teleconnection indices e g arctic oscillation ao north atlantic oscillation index nao and el nino southern oscillation enso el adlouni et al 2007 lópez and francés 2013 obeysekera and salas 2014 silva et al 2016 yan et al 2017b and human interactions such as population density or urbanization gilroy and mccuen 2012 prosdocimi et al 2015 villarini et al 2009 drawbacks of nonstationary eva approaches lie in the use of covariates that may not correlate sufficiently with flooding events see e g archfield et al 2016 aryal et al 2018 barth et al 2018 burn and whitfield 2017 or in the lack of long term data for robust covariate attribution further in much of the literature the nonstationary analysis is based on the outcome of some null hypothesis significance tests for monotonic trends or abrupt changes applied to a finite time series of hydrological variables e g annual maxima the approach also assumes that historical hydrologic trends will continue into the future which is not necessarily true and may produce unrealistic results see e g luke et al 2017 serinaldi et al 2018 serinaldi and kilsby 2015 reliability of the nonstationary approach requires relating the time varying behavior to the underlying cause and effect processes that generate it serinaldi and kilsby 2015 which cannot be obtained from statistical approaches moreover historical floods may show statistically significant trends but when separated according to their generating processes such as snowmelt or large rain over snow trends can be insignificant e g as in alberta canada over the past 100 years see whitfield and pomeroy 2016 critically serinaldi and kilsby 2015 have argued that if we are not able to identify a cause and effect mechanism for the trend i e abrupt changes or monotonic we cannot infer their future evolution and thus cannot make hydrological predictions beyond the period of record several studies have further shown that stationary models for eva can be parsimonious as compared to their nonstationary counterparts see e g ganguli and coulibaly 2017 luke et al 2017 serago and vogel 2018 consequently it is imperative to account for cause and effect ince processes associated with hydroclimatic evolution i e nonstationarity in flood projections rather than simply relying on intt motivated by the abovementioned shortcomings this study aims to investigate future floods from ince compared to those obtained from intt where future streamflow projections derived from simulations of a physical process based hydrological model can be used to study the changes in flooding events into the future first to identify the evolutions of hydroclimatic conditions non overlapping periods i e historical and future can be simulated with the assumption of local stationarity within each period kavvas et al 2017 trinh et al 2016 however these non overlapping periods are usually short since time series input data for hydrological modeling are not often available for long periods of time therefore the reduced sample size of the flood series will likely increase the variance of parameter estimates of the probability distributions and thus increase the uncertainty of the estimates another issue that needs to be addressed next an ensemble of future climate projections from several general circulation models gcms after appropriate downscaling can be used in deriving sets of future streamflow time series for a study area finally flood peaks can be extracted from the simulated future streamflow to construct ensembles of probability distributions and then compared to their historical counterparts the approach presented in this study differs from others with respect to projecting future floods using a deterministic approach as well as compares the projections to the interpreted changes from the statistically detected trends first we implement an ince approach by using a hydrological model to calculate the potential changes in frequency and seasonality of floods due to climate change as well as the uncertainties that result from using multi model simulations i e variability across climate models second we investigate how to improve the skill of flood frequency fitted distributions derived from short streamflow time series by combining several peak flows extraction methods with various parameter estimators of the extreme value models third we assess how nonstationarity inferences from null hypothesis significance tests such as using nonparametric trend tests on records of historical floods compare to those obtained from cause and effect deterministic processes generated using a validated hydrological model 2 background on extreme value analysis extreme value theory evt or eva provides a practical and comprehensive framework for analyzing the probability of extreme events such as floods and their return periods coles 2001 two types of flow series employed for the study of flood extremes are the block maxima or the annual maxima am and the annual peak flows as assessed with the peaks over threshold pot method the am approach samples the highest value within a block of time usually a year e g annual maximum streamflow and then modeled by fitting a generalized extreme value gev distribution because the am approach arranges the data into blocks of equal length and chooses the highest in case of floods within the block it potentially discards essential information about other high independent flood events occurring within the same time block e g year or it can result in low discharge values sampled from dry years the pot approach is an attractive alternative to am that allows including more independent events as they are not selected at fixed intervals an optimum threshold or a truncation level denoted by u is selected as small as possible to retain the largest sample of excesses above the truncation level to be fitted to a generalized pareto distribution gpd coles 2001 lang et al 1999 the pot approach provides a comprehensive description of the extreme occurrences that retain both their magnitudes and timings lang et al 1999 therefore they can be used for investigating the impacts of climate change on flood magnitudes and several other flood attributes including rate of occurrence and duration of peak flows as well as seasonality i e flood timing as in am flood frequencies derived from pot series especially from short time series might be more robust than those from am bell et al 2007 bezak et al 2014 deidda 2010 since pot series will employ more than a minimum mean number of 1 65 events per year as suggested by cunnane 1973 whereas the am series contain only one event per year and thus might be more sensitive to outliers koutsoyiannis 2004 langousis et al 2013 it is noteworthy that if a priori chosen pareto distribution is the correct type of distribution and if it accurately describes the distribution of the excesses the larger sample of pot series reduces the variance in the estimated parameters of the fitted distribution roth et al 2016 2012 a wrong choice of the distribution however may severely underestimate or overestimate floods for large return periods papalexiou et al 2018 2013 another benefit of using pot over am strictly speaking for the same sample size is the ability to include the n largest extremes in records having n complete years where these extremes represent more accurately the tail of the distribution as they include other extreme values that might be omitted in the am series see i e papalexiou and montanari 2019 pot approach is however underemployed compared to am because of the challenges often encountered in its application for instance the choice of an appropriate threshold where a value that is too high may result in so few excesses that no distribution model can be fitted while a value that is too low may increase the chances of selecting nonextreme events such that the asymptotic assumption of the gpd is no longer valid resulting in an ill fitted tail and if the parent distribution is different from pareto this activity of threshold selection is known as the bias variance tradeoff coles 2001 roth et al 2012 note that the choice of the distribution of excesses over a high threshold to be a gpd is valid provided that the parent distribution is of power type papalexiou et al 2013 and the sample maximum tends to a non degenerate distribution observation fukutome et al 2015 lee and kim 2019 pickands 1975 where the threshold value tends to infinity or if it is very large papalexiou et al 2013 otherwise identifying a priori tail for the sample to be a gpd may not be accurate see e g papalexiou et al 2018 the extraction of peaks is not a trivial task and the absence of a formal framework to define an optimum threshold to extract excesses makes it even more challenging beguería 2005 langousis et al 2016 roth et al 2016 langousis et al 2016 rigorously reviewed statistical and graphical methods for the choice of a threshold while they yielded the best performance graphical methods depend on visual investigations that might not always be easy to apply and are highly subjective additionally the application of graphical threshold selection approaches becomes potentially unmanageable when the number of streamflow series to be analyzed is large with ensemble simulations as it is the case in this study therefore an automated threshold identification is necessary and employed in this research as described in section 3 3 2 another problem is that excesses derived from filtering the peaks over a threshold tend to cluster into dependent events see e g acero et al 2011 beguería and vicente serrano 2006 süveges and davison 2012 and especially in hydrologic data which violates the assumption of independence of excesses therefore when dependent excesses are detected to occur in groups extremely high flow is likely to be followed by another a careful declustering should be carried out which requires the definition of criteria to identify independent events and introduces a different source of subjectivity a few statistical tools have been developed to filter clustered realizations to yield datasets of independent events including statistical declustering methods brodie 2013 coles 2001 ferro and segers 2003 or other physically based criteria to determine a fixed interval at which only the highest peak is considered from each cluster exceedances separated by less than a fixed interval called the run parameter are considered a cluster maximum excess is extracted from a cluster coles 2001 the choice of the run parameters significantly affects the estimation of the gpd parameters davison and smith 1990 ferro and segers 2003 for instance fukutome et al 2015 showed that selection of unnecessarily large run parameters could have adverse effects on the estimations 3 methods and materials 3 1 study area and streamflow gauging records with an area of about 700 000 km2 the province of alberta has 17 river basins where most of them originate from the snowmelt dominated and glaciated highlands of the rocky mountains the study area includes eight of the 17 river basins in the province athabasca battle beaver bow north saskatchewan oldman peace and red deer fig 1 covering almost 60 of alberta several gauging stations in the eight river basins were selected at the main rivers and their large tributaries from the gauging database and flow records of the water survey of canada for intt analysis long period observation data from pristine gauging stations were necessary therefore the choice of the gauging stations was based on defining several criteria on observation data we selected streamflow gauging locations with at least 50 years of data over the province of alberta see fig 1 for the names and locations of the stations and tables s1 and s2 of the supplementary material for a descriptive summary of the selected stations so that they can be used to investigate how null hypothesis significance tests are used for nonstationarity inferences additionally stations were further filtered such that they have an active operation status with continuous recordings preliminary data screening through time series visualization was applied to the observed sets to investigate missing observations for long periods stations with more than two continuous years of missing data or 10 percent of the observations not available in any given year a year is considered missing with less than 330 days of observations were excluded further only natural gauging stations with no dams affecting the river flow were used these criteria yielded 29 hydrometric stations fig 1 comprising 50 to 108 years of daily records that represent the most natural streamflow conditions and thus represent the impacts of historical climate and are more likely to reflect the possible impacts of future climatic changes on the other hand for ince analysis river discharges were simulated for historical 1983 2007 and future 2040 2064 periods at the outlets of the same watersheds selected earlier it is worth noting that floods are the most frequent natural hazard buttle et al 2016 and costliest disaster sandink 2010 in canada and in particular alberta has witnessed several historic devastating and costly floods resulting in many deaths and disruptions from evacuations environment and climate change canada 2017 milrad et al 2015 pomeroy et al 2016 teufel et al 2017 making the province an interesting case to test our hypothesis additionally to the best of our knowledge there has been no other study conducted on the potential impacts of climate change on future floods in alberta both in terms of seasonality and design discharges 3 2 simulations of historical and future streamflow to set up the analysis for our ince approach the physically based hydrological model the soil and water assessment tool swat was used to derive the hydrologic projections of the selected watersheds in alberta the model underwent rigorous data selection and careful calibration and validation procedures to represent the hydrologic conditions of the province using observations from 130 hydrometric stations for the 1983 2007 period faramarzi et al 2017 faramarzi et al 2015 it has since been applied in several applications chunn et al 2019 gharib et al 2017 masud et al 2018b 2019 its spatially distributed features make it suitable to explain regional variation in the hydrologic cycle due to both human activities and climatic conditions to incorporate future climatic changes in the streamflow simulations for the selected watersheds we obtained future climate projections from the pacific climate impacts consortium pcic cannon 2015 at a grid resolution of 300 arc seconds 10 km pcic provides statistically downscaled gcm climate scenarios from 1950 to 2100 bürger et al 2013 2012 based on the coupled model intercomparison project phase 5 cmip5 taylor et al 2012 and the actual historical daily gridded climate data for canada mckenney et al 2011 the models in the pcic database are forced with the representative concentration pathways rcp to represent various scenarios of future greenhouse gas ghg concentrations see van vuuren et al 2011a for details pcic provides canada wide downscaled climate change projections using bias correction spatial disaggregation bcsd and bias correction constructed analogues with quantile mapping reordering bccaq methods http www pacificclimate org data in our study we used the projection derived using the bccaq method as it was evaluated by werner and cannon 2016 and was shown to pass the largest number of tests for hydrologic extremes in comparison to other methods including the bcsd using the climdex indices recommended by the world meteorological organization expert team on climate change detection and indices etccdi chen et al 2011 we further downscaled pcic data to alberta s condition based on daily historical climate data from an earlier study by faramarzi et al 2015 where a suite of five climate data sources including meteorological station based and gridded products were examined to reproduce historical flow records for 130 gauging stations by using a process based hydrological model a combination approach where several climate data were combined from different sources was found to be best in generating their corresponding streamflow this historical climate dataset was used to force the hydrological model to obtain historical streamflow for the 1983 2007 period the dataset was further used as the downscaling target for a second order bias correction of the pcic projections using the change factor method i e the delta method chen et al 2011 quilbé et al 2008 an empirical relationship between gcm and historical data was established in order to generate a downscaled gcm future output then the future climate datasets were used to drive the swat hydrological model for the future streamflow for the 2040 2064 period the model has been previously calibrated and validated based on observations from 130 hydrometric stations in alberta for the 1983 2007 period faramarzi et al 2017 faramarzi et al 2015 we further tested the model using three extreme discharges during the 1983 2007 period for each station the 0 9 0 95 and 0 99 quantiles were extracted for each month for every year from the daily historical simulations and observations and then the two were compared for this study to account for the uncertainty in the flood peaks projections resulting from the different climate models an ensemble approach was employed two emissions scenarios in an ensemble of five gcms i e canesm2 ccsm4 cnrm cm5 1 csiro mk3 6 0 and miroc5 were incorporated see table s3 in the supplementary material for additional information on the gcms the ensemble approach has been commonly employed in the hydrologic literature see e g cloke et al 2013 faramarzi et al 2013 huang et al 2014 kay et al 2009 kay and jones 2012 the choice of the individual members of the ensemble was based on the top five models that provide the widest spread in the projected future climate cannon 2015 for the western north america region classified by giorgi and francisco 2000 projections were obtained for the mid 21st century from 2040 to 2064 based on two greenhouse gas ghg emissions scenarios namely rcp 2 6 and rcp 8 5 the rcp 2 6 scenario indicates a low forcing level with mitigation and corrective policies aiming to decrease emissions with a peak of 3 1 w m 2 in the mid 21st century and limits the increase of global mean temperature to 2 c van vuuren et al 2011b whereas the rcp8 5 scenario is a high ghg emissions scenario with a rising radiative forcing pathway leading to 8 5 w m 2 by 2100 the ensemble changes in the temperature and precipitation for alberta for the two emissions scenarios are illustrated in figs s1 and s2 of the supplementary material for each member of the ensemble for each climate scenario the dataset was used to drive the swat model to obtain the future 2040 2064 streamflow for the studied watersheds 3 3 projection of changes in future floods 3 3 1 peak flow attributes and regime changes flood peaks data were extracted from the daily simulated streamflow series for the historical period and the projected data for the future period under each climate model and scenario since the study has a particular focus on high extremes four flood attributes were identified and derived from each pot series under the different model scenario projections i the annual rate of occurrence of independent exceedances above the threshold ii the annual mean date of occurrence of exceedances iii the duration of each flood event and iv the variation about the mean date of occurrence referred to as the flood regularity the first two flood attributes were calculated on an annual basis while the duration was calculated on an event basis the variation about the mean date was calculated as one value for each pot series for the historical simulations each time the daily flow exceeded a threshold that corresponds to the 90th percentile threshold p90 the peak flow was sampled p90 was chosen as it has been commonly used in earlier studies in utilizing the pot approach roth et al 2012 rydman 2018 whitfield and pomeroy 2016 in addition the 90th percentile in most of the 29 simulated catchments was less than the minimum of the annual maxima series of the historical data series therefore it ensures that at least one peak was sampled each year for the future simulations the same thresholds defined from the historical simulations were benchmarked and used to obtain the future flood peaks to quantify the changes in the four flood attributes independent flood peak events were extracted from each historical and future flow time series and were investigated for the four attributes the independence of peaks will be further discussed in the next section the rate of occurrences of flood peaks was determined by counting the total number of occurrences n of the pot events per year counts were then divided by the number of days in the year to obtain the annual rate of occurrence for each station flood duration was calculated as the total number of days the daily flow remained above the threshold for each flood event following burn et al 2010 the date of occurrence or the timing of the flood event and the regularity of the flood peaks were calculated based on a directional statistic by converting the julian date of an event occurrence for a given year to an angular value see section s1 in the supplementary material for equations and notations regularity is a dimensionless measure that ranges from 0 low regularity to 1 high regularity it defines the variability of the flooding date of occurrence about the mean date such that a regularity of 1 indicates that each event in the period of record occurs on the same date of the year while lower values indicate a wider spread in the timing of occurrence burn et al 2016 burn and whitfield 2015 to quantify the changes in the four flood attributes between the historical and the future pot series we aggregated the annual and the event basis attributes into averaged values for each station for each historical pot series and each model of the ensemble simulations for the future period then the percentage change in the rate of occurrence and regularity of floods and the difference between the mean date of occurrence and duration days of floods were calculated 3 3 2 selection of threshold and independent events determination of thresholds to extract peaks for assessing the changes in the 20 and 50 year return levels followed a different approach than that used in studying the changes in the four flood attributes defined in section 3 3 1 since the quality of the gpd fit depends significantly on the choice of the threshold beguería 2005 gharib et al 2017 liang et al 2019 northrop and coleman 2014 for that two threshold selection methods namely the likelihood ratio test lrt method and the square error method se were employed in this study as they have shown to outperform other methods zoglat et al 2014 we employed an algorithm developed in r by gharib et al 2017 to automate both the lrt and the se threshold selection methods following the procedure outlined by beirlant et al 2005 and zoglat et al 2014 in the lrt method one chooses a range of threshold candidates where ui and uk ui uk are two threshold candidates and xui and xuk are vectors of observations exceeding the two thresholds respectively indeed if ui is an acceptable threshold then uk is also acceptable this test is designed to compare two threshold candidates therefore when two thresholds are admissible the smallest one is optimal in this study for instance the first selected threshold i e ui was selected to be 0 9 quantiles of the streamflow on the other hand the se selection method aims to minimize the mean square error mse between the empirical i e based on actual events and the fitted i e calculated events distributions at a given gpd parameters estimator the method is particularly useful to compare several estimators as shown in gharib et al 2017 and especially when one of them could be biased zoglat et al 2014 it is critical to ensure that the exceedances over the threshold are independent and peak flows originate from different events therefore it is common to proceed with the choice of a high enough threshold until the asymptotic assumption of the fitted distribution is satisfied here after the selection of the threshold the independence of extracted flood peaks was based on defining a minimum period such that successive exceedances over the threshold are separated and are hydrologically independent within the time series this rule known as declustering considers the area of the catchment and imposes additional criteria that any intermediate flow between two peaks must drop below 75 of the lower of the two neighboring peaks using the following equation as described by uswrc 1976 1 t 5 days lo g 10 0 3861 a and p f min 0 75 min p f i p f i 1 where t is the minimum time in days between two independent peaks a is the basin area in square kilometers and pfmin is the minimum intermediate peak flow between two consecutive peak values pfi and pfi 1 in cubic meters per second these two conditions were considered in the pot analysis on the sava river in slovenia bezak et al 2014 and several rivers in germany merz et al 2016 the approach employed in this study is similar to the two step framework by bernardara et al 2014 in that it applies a physical threshold selection with a statistical optimization to define events as independent observations and achieves gpd convergence respectively before fitting a distribution the hypothesis that the samples of the derived flood peaks are independent and identically distributed was evaluated we assessed the dependence of exceedances over the selected threshold using the extremal index coles 2001 smith and weissman 1994 which measures the degree of clustering of extremes using a number between 0 clustered data and 1 perfectly independent data extracted peaks were examined for the simulated streamflow time series i e both historical and future series for the estimated thresholds corresponding to the 90th percentile lrt estimated and se estimated the r package extremes gilleland and katz 2016 was used for the estimation of the extremal index 3 3 3 fitting a generalized pareto distribution once the optimal thresholds are defined and independency is ensured one needs to fit a suitable probabilistic model to the pot series to estimate the design discharges for that the generalized pareto distribution gpd was used to model the independent peak flow extremes statistically let x be a random variable then the cumulative distribution function f x of the gpd with shape location and scale parameters ξ u and σ respectively derived from the exceedances of x above the threshold u both in cubic meters per second is defined as pickands 1975 2 f x p r x u x x u 1 1 ξ x u σ 1 ξ for ξ 0 1 exp x u σ for ξ 0 in order to increase the accuracy of flood frequency fitted distributions derived from the short streamflow time series i e 25 years and to accurately represent the datasets the parameters were estimated using the framework proposed by gharib et al 2017 in combining the threshold selection approaches with the parameters estimation methods several methods exist for the estimation of the gpd parameters see review by de zea bermudez and kotz 2010 in this study six combinations between two threshold selection approaches and four estimation methods were used to estimate the gpd parameters for each catchment the four estimators used were maximum likelihood estimator mle nonlinear weighted least square estimator nwls maximum goodness of fit anderson darling estimator mgfad and modified likelihood moment estimator newlme note that while each of these methods shows biases ideally the bias should reasonably be independent of the estimation method in that sense papalexiou et al 2013 provided an almost unbiased estimation method for the gev parameters through fitting the theoretical tails to the empirical ones by minimizing numerically a modified mean square error mse norm see also serinaldi and kilsby 2014 for gp distribution the quadratic upper tail anderson darling a2 goodness of fit test was used to assess the suitability of the gpd model and the quality of the fit which estimated a test statistic of the sum of squares of the differences between the empirical and fitted distribution functions with a weight function that emphasized discrepancies in both the upper and lower tails choulakian and stephens 2001 the statistic was used to select the best distribution among those fitted using the six combinations between the threshold selection approaches and the gpd parameters estimators for each member of the two ensemble scenarios for each catchment separately 3 4 at site growing and moving window trend approach on observed peak flow data to investigate intt approach and that how inferences from null hypothesis significance tests on historical observations may reflect future flood evolutions the existence of monotonic slowly varying trends in the historical observations increasing or decreasing was explored by employing the nonparametric mann kendall mk test kendall 1948 mann 1945 the daily historical observations obtained for the 29 hydrometric stations recall section 3 1 were used to calculate three flood seasonality attributes and three other characteristics that relate to the magnitudes of floods for the 29 catchments by proceeding all steps explained in section 3 3 the three seasonality variables are the annual rate of occurrence the mean annual peak timing and the peak events duration whereas for the flood magnitudes the three variables are the annual maximum peak the annual mean peak and the peak events magnitudes trend results are then compared to those obtained from the ince approach i e hydroclimatic simulations in order to examine the sufficiency of inferring future behavior i e supporting nonstationary frequency analysis from trend results further for the investigation of the effects of the time series length a growing and moving window trend analysis approach was employed such that for all possible combinations of start and end years for the data series length record with a minimum series length of 10 years and a maximum of the length of the entire record the trend test statistic was estimated and plotted against the corresponding start and end years 4 results and discussion 4 1 swat hydrological model simulations results of the statistical measures used to test the performance of the hydrological model in simulating the extreme streamflow quantiles as shown in table 1 showing that they were well reproduced by the hydrological model the model performance slightly decreased as the quantile value increased however since the study compared the changes in the future relative to the historical conditions using simulations of the model in both periods we assume that any presence of systematic errors in simulations of both periods is consistent and balanced out additional validation results for each station are presented in table s4 of the supplementary material 4 2 independence of peaks and performance of gpd estimators while the average numbers of sampled peak flow as illustrated in table 2 are considerably higher approximately 12 times than the recommended value of 1 65 multiplied by the number of years as defined by cunnane 1973 the values of the extremal index suggested a high degree of clustering of extremes therefore the excesses have been declustered using physically based criteria as described in section 3 3 2 first to determine clustered periods and second to select independent flood events within each cluster after declustering there was no evidence of the presence of clustered extremes in the derived pot datasets for both the historical and ensemble future simulations for the 29 catchments as shown in table 3 it is worth noting that in cases where after declustering the pot series the number of peaks was less than the critical value recommended by cunnane 1973 the threshold ui is decreased iteratively by a small step until the number of independent peaks is equal to or greater than the critical number for peaks which is 1 65 multiplied by the number of years i e 25 years of simulations it is important to emphasize that without a thorough examination of the assumption of independence every subsequent extreme value theory analysis is ill posed and as such the asymptotic conditions of the pareto distribution will be violated we realized that no matter how high the value of the threshold selected with the condition that the number of peaks is 1 65 times the number of years or higher the dependency of exceedances over the threshold will exist unless and only if a declustering routine is applied to the exceedances in order to decrease this dependency see for example chandler and bate 2007 coles 2001 fawcett and walshaw 2007 ferro and segers 2003 this is attributed to the fact that dependency in hydroclimatic variables is the rule not the exception and in practice observations are almost always dependent adamowski and bougadis 2003 hamed and rao 1998 kumar et al 2009 yue et al 2003 that was found during our preliminary extraction of independent peak flows for the 29 gauges across alberta based on thresholds that correspond to a 0 90 quantile as summarized in tables 2 and 3 the best fit gpd was chosen based on the minimum anderson darling statistic and after checking the corresponding p value results showed that the excesses are adequately described by a paretian distribution and that the gpd fits with the corresponding p values well exceed 75 fig s3 and tables s5 and s6 of the supplementary material it is worth noting that a few of the combinations did not converge when estimating the parameters of the gpd anderson darling statistics computed for several distributions fitted on the same data set can be problematic to compare since it could systematically favor the selection of more complex distributions with larger number of parameters delignette muller and dutang 2015 in such cases to discourage overfitting and assist with the ad statistic classical penalized criteria based on the log likelihood such as the akaike s information criterion aic and bayesian information criterion bic should also be considered burnham and anderson 2003 höge et al 2018 kim et al 2017 however it is not a problem when compared distributions are characterized by the same number of parameters as in the case of this study additional results on the performance of the estimators are provided in section s2 and figure s3 of the supplementary material 4 3 future projections of flood regimes and design discharges 4 3 1 changes in flood regimes under future climate using the mean ensemble projections five catchments of the 29 studied are expected to experience decreases ranging from 11 to 54 in the rate of occurrence of floods in the future period 2040 2064 relative to the historical period 1983 2007 fig 2 a and fig 4a with one catchment in each of the athabasca battle beaver north saskatchewan and peace river basins for rcp 2 6 the other 23 catchments showed increases ranging from 5 to 112 and only one catchment 07aa002 in the athabasca river basin showed no change on the other hand rcp 8 5 resulted in more intense changes than rcp 2 6 for the rate of occurrence as shown in figs 3 a and 4 a for rcp 8 5 only two catchments namely 07bf002 in the athabasca river basin and 05fa001 in the battle river basin are projected to experience decreases in the rate of occurrence of peak flows by 23 and 27 respectively whereas the other 27 catchments showed increases ranging from 6 6 to 143 the results indicate that the majority of the studied catchments in the peace river basin will likely experience considerable increases in the rate of floods occurrence with an average change of 41 and 57 in rcp 2 6 and rcp 8 5 figs 2a and 3a respectively followed by the catchments of the red deer 36 in rcp 2 6 and 46 in rcp 8 5 oldman 15 in rcp 2 6 and 20 in rcp 8 5 bow 14 9 in rcp 2 6 and 22 in rcp 8 5 athabasca 9 4 in rcp 2 6 and 22 in rcp 8 5 and north saskatchewan 5 8 in rcp 2 6 and 19 in rcp 8 5 river basins whereas the studied catchment of the battle river basin 05fa001 showed a decrease of 54 and 27 for rcp 2 6 and rcp 8 5 climate scenarios respectively the studied catchment of the beaver river basin showed contrasting changes in the rate of floods occurrence for both climate scenarios with a change of 14 and 16 for rcp 2 6 and rcp 8 5 respectively fig 4a it is important to note that the athabasca river basin had the highest number of catchments i e 11 catchments recall fig 1 and table s1 of the supplementary material represented in the study while river basins such as the battle and beaver had only one catchment presented therefore the results may not be inclusive to represent the entire river basin but should be seen unique to the catchments within each river basin given that most of the selected stations are tributaries recall fig 1 further an increase decrease in the regularity r of flood events indicates a decreased increased variability of flood occurrences about the mean date of flooding for rcp 2 6 the average ensemble projections showed that only six catchments had increases in regularity ranging from 3 6 to 29 whereas decreases dominated the other 23 catchments in a range of 3 6 to 43 figs 2b and 4b results also indicated that the largest decrease 43 occurred at one catchment 07hc001 in the peace river basin both catchments of the battle and beaver river basins showed increases in regularity by 29 and 10 respectively decreases dominated the catchments of the other five basins including the north saskatchewan 7 4 athabasca 8 8 red deer 16 oldman 20 and bow 27 river basins on the other hand for rcp 8 5 only one catchment 05fa001 of the 29 that is located in the battle river basin showed an increase of 7 5 in the regularity one remained unchanged while the other 27 catchments showed decreases ranging from 2 to 54 figs 3b and 4b further larger decreases are predicted for the rcp 8 5 climate scenario for the catchments of seven river basins ranging from 13 in the beaver river basin to 40 in the bow river basin and average decreases of 15 in the catchments of the peace 18 in athabasca 18 in north saskatchewan 23 in red deer and 28 in oldman river basins these results suggest that it is likely that the timing of the flood from one year to the next will be less predictable in alberta peak flows occur mostly during the spring and summer seasons when the highest rainfall and snowmelt occur the changes in the timing of flood events often imply shifts in the dominant flood generating processes such as snowmelt rainfall or rain over snow in analyzing the shifts in timing we considered a shift of one day as no change a result of less than one day may occur by taking the average ensemble projections in the analysis the results revealed that flood events are mostly occurring earlier in the future for most catchments for both climate scenarios as illustrated in figs 2c and 3c for rcp 2 6 and rcp 8 5 respectively of the 29 catchments for rcp 2 6 as shown in fig 4c the average multi model ensemble showed that the timing of flood events only in three catchments are projected to shift later in the year with a range of three days at 07be001 in the athabasca river basin to eight days at 07hc001 in the peace river basin while nine showed no change and 17 are projected to shift earlier ranging from two days at 07da001 in the athabasca river basin to 21 days at 05cc001 in the red deer river basin on the other hand for rcp 8 5 as shown in fig 4c nine of the 29 catchments showed later occurrence of flood peaks ranging from two days at 07da001 in the athabasca river basin to 14 days at 07hc001 in the peace river basin seven showed no change and earlier occurrences dominated the other 13 and are projected to shift earlier by two days at 05da007 in north saskatchewan river basin to 22 days at 05cc001 in red deer river basin it is anticipated that earlier floods due to warming conditions may reflect earlier snowmelt events and rain on snow events during the winter season burn et al 2016 burn and whitfield 2015 the results are also consistent with those of burn and whitfield 2017 for historical trends of timing of flood occurrences for a number of nival catchments in alberta i e catchments with flood events resulting from snowmelt or rain on snow events where most stations while may not depict a significant trend are dominated by earlier flood event occurrences and a few other showing later occurrences additionally the earlier flood occurrence was more dominant in the southern catchments as compared to the northern ones figs 2c and 3c this may be partially explained by the earlier melting of the snowpack associated with warmer temperatures in the southern part of the province masud et al 2018a moreover increases in the duration of flood events were more concentrated in the eastern part of the province rather than the western part for both rcp 2 6 and rcp 8 5 as shown in figs 2d and 3d this change could be attributed to the flood types generated downstream mainly by mixture processes of snowmelt and rainfall in both climate scenarios the two catchments of beaver and battle river basins are projected to experience significant increases in the duration of floods expressed as the duration that the peak flows are continuously above the defined thresholds these significant increases could be attributed to the fact that both river basins are prairie fed basins that rely solely on spring runoff and rain rather than snowpack and glacier melts that are expected to increase in the future masud et al 2018a the change in mean flood duration for the selected catchment of the beaver river basin will likely be in the order of 23 days and 27 days for rcp 2 6 and rcp 8 5 respectively and in the order of 18 days and 26 days for the studied catchment of the battle river basin respectively the catchments of the peace river basin showed an average decrease of three days for rcp 2 6 and about two days for rcp 8 5 for the catchments of the other five basins results indicate that only those in red deer river basin are expected to experience a average increase of one day for rcp 2 6 whereas for rcp 8 5 catchments of the athabasca north saskatchewan and red deer river basins showed increases in the duration in the range of one to two days and no change for those in the bow and oldman river basins in general most of the catchments have consistently shown concerned changes in the flood attributes for both climate scenarios that included projected increases in the rate of flood occurrence shifts to earlier flood events and increased variability of flood events about the mean date of occurrence suggesting a more difficulty in forecasting the timing of flood events from one year to another but insignificant changes in the duration of floods these findings are consistent with expectations that in warmer conditions more precipitation will occur as rain rather than snow resulting in a more significant number of events and earlier shifts in the timing of flood events burn et al 2016 4 3 2 changes in flood quantiles under future climate table 4 summarizes the percentage of catchments showing changes whether increasing or decreasing in the intensity of two extreme floods corresponding to the 20 and 50 year events referred to as q20 and q50 respectively for the means of the ensemble simulations event magnitudes corresponding to 20 or 50 year return periods for the mid century are mostly becoming more intense in both climate scenarios except for a few cases as shown in fig 5 on the one hand in rcp 2 6 17 catchments are projected to experience increases in q20 in the range of 4 to 52 and only one catchment remained unchanged while 20 catchments are expected to increase in q50 with a range of 2 to 104 as shown in fig 5 the catchments of the bow river basin had the highest average increase in q20 of 10 and in q50 of 12 followed by the catchments of red deer 9 in q20 and 5 in q50 beaver 9 in q20 and 2 in q50 oldman 7 in q20 and no change in q50 and athabasca river basin 3 in q20 and no change in q50 the studied catchments of the peace river basin showed both decreases and increases in q20 and q50 catchments of both north saskatchewan and battle river basins showed interesting results with contrasting change direction in q20 that in q50 indicating a decrease of 2 and 12 in q20 and an increase of 17 and 104 in q50 respectively on the other hand for rcp 8 5 of the 29 catchments 10 showed decreases in q20 ranging from 15 to 62 while 18 catchments showed increases ranging between 3 to 55 as presented in fig 5 for q50 nine catchments showed decreases ranging from 7 to 82 while increases dominated 17 of the catchments with a range of 7 to 86 and one showed no change the studied catchment of the beaver river basin 05fa001 showed notable increases in both q20 and q50 with changes of 26 and 49 respectively followed by the catchments of red deer oldman bow and athabasca river basins with an average change of 17 10 6 and 4 in q20 and 11 8 9 and no change in q50 respectively the results also indicate that the studied catchments of the peace river basin are expecting both decreases and increases in the future ranging from 62 to 44 for q20 and from 82 to 52 for q50 the catchments of the north saskatchewan river basin showed mostly decreases in both q20 and q50 except for one catchment 05db002 where increases of 55 and 86 are predicted respectively similar to the changes in the flood attributes the analysis showed that rcp 8 5 resulted in notably greater changes in flood magnitudes than rcp 2 6 it is also worth noting that no visible pattern can be drawn between the location of the catchment and the direction of or magnitude of change for both climate scenarios which may be attributed to local precipitation events dominating small and medium catchments in contrast to other larger catchments that are dominated by large snowmelt events or rain over snow however analysis of the size of the catchments results not presented showed no correlation between the direction or magnitude of change with the size of the catchment another reflection here is while the simulated flow is based on fully known processes using a model chain gcm swat hydrological model that does not mean that all the properties of simulated flow sequences should attribute directly to climate in fact the model chain can produce complex transformations which can result in 1 apparently stable behavior of finite size time series 2 complicate the attribution for four properties of floods and magnitudes 3 may result in omitting other important non climate factors including changes in land use or other socioeconomic factors e g population changes and adaptations therefore besides the scientific importance of detection and quantification of future changes it is also important to advance our understanding of the drivers responsible for those changes in each flood property not only to climate but also to other possible non climate factors see e g berghuijs et al 2016 hirsch and archfield 2015 kreibich et al 2019 neri et al 2019 4 4 uncertainty in future estimates the uncertainty arising from the different climate models in the multi model ensemble approach is illustrated in fig 4 for the two climate scenarios i e rcp 2 6 and rcp 8 5 for the flood seasonality attributes in most cases the mean of the ensemble represents the typical direction of change whether increasing or decreasing however there were a few cases where some gcms were showing a decrease when the mean is indicating an increase and vice versa for example station 05cc001 in the red deer river basin showed a mean change of 9 4 in the rate of flood occurrence for rcp 2 6 with minimum and maximum changes of 33 4 and 54 5 respectively such results indicate that the projected changes may vary widely among the different gcms furthermore even if two models project the same direction of change the underlying cause of that change can be very different nonetheless the change direction projected by the multi model mean can be significantly affected by the projection of one model which alone among the ensemble members may project a substantial increase or decrease in precipitation and thus an increase or decrease in the attributes of floods and their severity we showed that in cases opposite change directions are probable which would increase the uncertainty bounds in the future as found in some catchments of this study ideally a more comprehensive uncertainty assessment would involve a larger number of climate models and other hydrological models moreover for the estimation of the return levels corresponding to the 20 and 50 year return periods the range of changes resulting from each climate model in the ensemble simulation for each catchment is also presented in fig 5 with horizontal bounds notably there is increased uncertainty in flood estimates at higher return periods i e 50 year compared to smaller in sample i e 20 year return levels this finding could be attributed to the fact that the streamflow simulated by the hydrological model historical and future periods was limited to 25 years indeed the results presented here for the 50 year return periods are slightly extrapolated but such extrapolation is commonly practiced in the literature cloke et al 2013 huang et al 2014 kay et al 2009 kay and crooks 2014 the range confidence bands in this research were only presented from the different climate models as the analysis estimated uncertainty from using different models and neglected uncertainties arising from other sources including future greenhouse gas emissions downscaling from gcms or the hydrological model as well as the data selection and parameterization of the model the latter however was addressed and investigated in faramarzi et al 2015 there are a few occasions where the parameters of the fitted distribution i e shape scale and threshold vary considerably between models see parameters in figures s4 and s5 and their statistics in table s7 of the supplementary material kay et al 2009 for example showed that the uncertainty in their study of future flood frequency in england was dominated by the gcm structure and that a large bias in as few as one model in an ensemble of five models can significantly affect the ensemble mean see also camici et al 2013 huang et al 2014 qin and lu 2014 let alone the uncertainty arising from the assumptions underlying the choice of thresholds and the estimators used to fit the pareto distributions to derive the frequency curves which was addressed using a combination of two threshold selection approaches and four estimation methods for the parameters as proposed by gharib et al 2017 4 5 using intt versus ince in projecting changes in future floods how do the results obtained with the ince approach using process based hydrological and climate models relate to those from interpretations of nonparametric trend analysis using long term instrumental records i e intt for that at site trend tests were performed on the flood peaks of all the 29 hydrometric stations using long period observations i e 50 to 108 years of daily records the percentage of stations with significant trends at the 5 significance level using mann kendall mk trend test in three flood attributes and three other summary characteristics that represent flood magnitudes for the 29 catchments are presented in table 5 the percentage of catchments that demonstrated positive trends in flood attributes or magnitudes seldom agrees with those obtained by the cause and effect physical mechanisms rendered through the hydrological model for instance recalling the changes in section 4 3 2 and table 4 59 of the stations showed increases in q20 and 69 in q50 for rcp 2 6 and 62 of the stations showed increases in q20 and 35 in q50 rcp 8 5 whereas the trend tests table 5 showed that none of the stations have statistically significant trends for the six analyzed flood properties except for the mean annual peak flow and only for 3 of the stations one reason could be due to the length of the observations data series analyzed that notably changes the results of the trend tests note this does not necessarily mean that all properties of simulated peak flow sequences should show trends or similar the model chain gcm hydrological model can produce complex transformations which can result in apparently stable behavior of finite size time series the average duration of floods is an example nonetheless the peak flow series corresponding to the time series resulting from ince is nonstationary by construction to elaborate on how the length of data series may lead to different results and inferences we compared trends for the last 30 years of records versus the entire period refer to table s1 of the supplementary material for the length of data series for each gauging station as shown in table 5 percentages of stations exhibiting decreasing trends for example realized from testing the entire record versus the last 30 years seldom agree this implies that the choice of nonstationary extreme value models based on extrapolating historical trends can be incorrect and that nonstationary effects may not continue beyond the period of record and do not necessarily hold for the entire future see i e cooley 2013 luke et al 2017 serinaldi et al 2018 which further may lead to high uncertainty in future predictions serinaldi and kilsby 2015 note that the effects of spatiotemporal correlation which results in space time clusters generating local trends were not considered in applying the mk test relatively short samples of extreme events from persistent processes may appear independent but they preserve some properties of the underlying persistent process such as clustering thus applying e g mk neglecting the memory of the underlying process can yield over rejection alternatively modified mk tests can be employed hamed 2011 for instance serinaldi and kilsby 2018 showed that accounting for spatiotemporal dependence can yield different results and conclusions in studying the occurrence probability of pot events additionally the diagnostic plot of monotonic trends in fig 6 examines the changes concerning the length of the data series for one arbitrary station the bow river at banff 05bc001 with the longest record of 108 years of observed data using the growing and moving window trend analysis described in section 3 4 the figure revealed contrasting monotonic trend behavior for different window sizes and or lengths for the data series the results of the trend analysis can be particularly subjective when used to draw inference about the direction of change in the future these results help understand and articulate the concerns raised by various researchers in terms of misusing and misinterpreting the outcomes of null hypothesis significance tests such as trends tests on short term or long term observed data to justify the hypothesis on future hydroclimatic changes and future events greenland et al 2016 serinaldi et al 2018 serinaldi and kilsby 2016 results shown in fig 6 demonstrate how statistically significant trends were only identified for parts of the record patches outlined with black lines and how trend results can vary substantially with changing the time span of the test or the time period considered in addition the trend analysis showed that aside from the length of the time series and their start and end dates the results could differ significantly among the different flood attributes as each of them may describe a particular flood generating process e g annual maximum mean annual magnitude timing and duration our results may partially explain the findings by whitfield and pomeroy 2016 who showed that while there is a significant negative trend in floods over the past 100 years for the bow river at banff 05bc001 when the events are separated based on the generating process neither snowmelt floods nor rain over snow floods showed any trends over time one concludes that a process based simulations of the climatic and hydrologic evolutions can result in much different change or even opposite change signal than that from predicting future behavior from historical trends and more accurate owing to the well defined physical mechanism by the process based model of course validated and b even if there is no statistically significant trend in the magnitudes of extreme events there can still be a change in future floods which is also supportive of similar findings from other researchers burn and whitfield 2017 another interesting finding is that in some instances the 20 year return levels are projected to increase in magnitude while the 50 year return levels are projected to decrease or vice versa for example recall fig 5 station 05dc006 ram river near the mouth in the north saskatchewan river basin showed an increase in q50 even though q20 decreased for rcp 2 6 one would hypothesize a consistent shifting of the flood frequency curve either upward increase in floods intensity as in fig 7 a or downward decrease in intensities to reflect the changes in the climatic conditions for the future however the frequency curves are likely shifting differently at different return periods in some instances as shown in fig 7b for 05dc006 where the future climate tends to decrease small floods and increase large floods these changes in the flood quantiles are mostly associated with future climate due to the selection of watersheds that are not regulated and no changes assumed for the future in the land use and the river morphology therefore this finding suggests that the underlying stochastic processes that generate floods are not consistent as floods in alberta are mostly resulting from snowmelt compounded with rainfall finally the results from this study support some of the findings from other research examining floods in alberta for instance burn et al 2016 showed that canadian streams witnessed increased exceedances reduced maximum magnitudes and earlier flood events based on historical observation on floods from pristine basins with stable land use conditions across canada including alberta likewise burn and whitfield 2015 showed that the magnitude timing and the number and duration of high flow events exhibited both increasing and decreasing trends see also burn and whitfield 2018 the results from this research also provide new insights in terms of the changes in flood attributes and design discharges for several catchments in alberta with various drainage areas and characteristics under a range of possible changes in climate in the midcentury period in a previous study tan and gan 2015 examined 145 stations over canada including a handful in alberta under a nonstationary framework using time varying distribution parameters using a group of gamlss models while they concluded that nonstationary frequency analysis should be employed in the future as a substitute for the traditional stationary models the inference of nonstationarity from trend analysis results is often based on assumptions about the underlying deterministic processes which could lead to unrealistic representation of the future serinaldi et al 2018 serinaldi and kilsby 2015 and because nonstationarity implies by definition the knowledge of the law governing the evolution of the process in time serinaldi et al 2018 this law needs to be known a priori via external information and cannot be inferred from data because it means that we do not know it and therefore it cannot be deterministic this contradicts the definition itself of nonstationarity therefore parsimonious models luke et al 2017 ragno et al 2018 serago and vogel 2018 serinaldi and kilsby 2015 or physically based hydroclimatic models such as the one employed in this study may be favored these physically based models produce a what if analysis based on fully known processes including gcms hydrological models etc are fully specified albeit complex therefore when gcm outputs are used under different emissions scenarios e g rcp 2 6 or rcp 8 5 it is known a priori that the model is nonstationary as it involves a well defined pattern of driving emissions in other words we know the time law governing the evolution of ghg emissions therefore gcms are nonstationary by construction and their output is also nonstationary moreover since the flows results from a model chain gcm hydrological model it is also a nonstationary process by definition as it results from a model chain whereby there is at least a nonstationary component 5 conclusions nonstationary extreme value analysis under a changing climate is one of the most evolving research focuses in the field of hydrology however the inference of nonstationarity from trend tests on flood characteristics can lead to erroneous future projections both in terms of magnitude and seasonality this paper investigated using trend tests as statistical tools to provide evidence of nonstationarity and justify the application of nffa models for projecting future changes in floods intt versus using a physics based hydrological model that characterizes future hydroclimatic changes ince the main conclusions of this study are as follows 1 there can be changes in flood properties in the future even if there are no significant trends in the magnitudes or regimes of floods based on null hypothesis significance tests on historical observations such as mann kendall trend test using a growing and moving window approach trends over a prescribed range of possible start and end years 2 flood frequency analysis based on physics based simulations of the climatic and hydrologic changes over time can result in contrasting future changes in floods compared to the conventional practice that uses historical trends to rationalize nonstationary frequency analysis for the future simply because if the process is nonstationary then the past is not representative of the future and cannot be inferred from it 3 better fits to the exceedances over thresholds are attained through combining two automated selection approaches of optimal thresholds with four gpd parameters estimators to deal with the relatively short periods of the non overlapping simulations of the hydrological model 4 floods in the selected 29 catchments of alberta canada are generally intensifying with changes in the climate in the mid 21st century except in a small number of catchments about 2 3 of the catchments are expected to experience higher 50 year floods with projected increases of 2 104 mean 29 median 20 for rcp 2 6 and 7 86 mean 32 median 25 for rcp 8 5 further the majority of the studied catchments have consistently shown exacerbated changes in flood regimes for both climate scenarios these changes include projected increases in the rate of occurrence of floods shifts to earlier occurrences increased variability of the events about the mean date of occurrence whereas no significant change in the duration of floods was projected these conclusions were based on the examination of changes in flood properties in terms of both seasonality and design discharges with climate change in a set of unregulated catchments in alberta using ensemble simulations the use of a spatially distributed hydrological model allowed determination of changes at individual catchments which was necessary because the examined catchments both tributaries and main stems had a wide range of climatic and hydrologic characteristics independent peaks over threshold data allowed examination of changes in several flood properties including the rate of occurrence timing and duration and regularity of exceedances as well as magnitudes of the 20 and 50 year flood events under ensembles of projections for two climate scenarios it is worth noting that projected changes in the hydroclimatic conditions derived from the hydrological model have some limitations the model assumes no human modifications e g changes in land use and no fluvial transportation e g construction of dams or natural changes in landscapes such as those caused by forest fires to occur in the future which will undoubtedly affect runoff generation processes therefore future studies should aim to quantify the relative impacts of these and other factors through socio hydrological modeling approaches that incorporate hydrologic responses to human alterations and vice versa finally return periods were estimated by assuming local stationarity within the historical and future periods an acceptable approach given the short simulation period of 25 years declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment we gratefully acknowledge the generous funding from the campus alberta innovation program caip chair award grant res0034497 the natural sciences and engineering research council of canada discovery grants program grant res0043463 and the graduate student internship program of the university of alberta two eponymous reviewers francesco serinaldi and simon michael papalexiou and one anonymous reviewer are acknowledged for their review comments which helped us to improve the original manuscript supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103463 appendix supplementary materials image application 1 image application 2 
540,nonstationary flood frequency analysis nffa has increasingly been applied to predict future floods under climate change the inference of nonstationarity from trend tests intt on historical floods is a widespread practice used to justify the application of nffa however its reliability has seldom been investigated this research examines future floods from interpretations of intt compared to those obtained from cause and effect processes by a hydrological model ince the study uses ince to quantify the changes in the regime and magnitude of floods due to potential climate change in the mid 21st century using multi model ensemble simulations under two greenhouse gas emissions scenarios i e rcp 2 6 and rcp 8 5 independent peaks over threshold from simulated streamflow were used to estimate the changes in future 2040 2064 flood regimes and magnitudes compared to their historical 1983 2007 counterparts for 29 unregulated catchments across alberta canada separation of extreme events and their fittings to generalized pareto distributions gpd were based on a hybrid approach that combined two developed automated threshold selection methods and four estimators for the parameters of the gpd based on comparing the results of intt and ince we show that future changes in floods contradict we also show that the future frequency curves shifted differently at different return periods compared to historical curves while in some instances future climate tended to decrease small floods and increase larger floods or vice versa finally flood magnitudes in 2 3 of the studied catchments in alberta are predicted to intensify accompanied by increases in the rate of occurrence and earlier shifts in the timing of floods for both climate scenarios whereas no considerable change in the duration was recognized keywords nonstationarity hydroclimatic evolutions peaks over threshold pot climate change and ensemble simulations future flood regimes alberta floods 1 introduction study of extreme hydrologic events such as floods is of great interest because of their significant and widespread impacts on societies ecosystems and economies detrimental impacts of floods typically include fatalities loss of property and damage to critical infrastructure further concerns are growing that future flooding events will become more frequent and severe hinkel et al 2014 huang et al 2014 jongman et al 2014 kay and jones 2012 in particular climate change is expected to alter the statistical properties of several climatic variables including seasonal and extreme precipitation which are likely to increase in the future gizaw and gan 2016 jiang et al 2017 ragno et al 2018 tan and gan 2017 for all the reasons above it is imperative to study potential changes in flood severity in the future nonstationary statistical approaches have increasingly been applied to study future floods and the inference of nonstationarity from outcomes of trend tests intt on historical floods is amongst the widely used techniques to assume the future behavior of floods chen et al 2017 gado and nguyen 2016 strupczewski et al 2001 the intt relies on the application of nonstationary frequency analysis using extreme value analysis eva see e g gilroy and mccuen 2012 machado et al 2015 obeysekera and salas 2014 villarini et al 2009 yan et al 2017 particularly in nonstationary eva probability distributions are fitted to existing historical records of flood discharges by assuming time varying parameters and then applying the nonstationary distributions to estimate the flood magnitudes that correspond to the desired return periods coles 2001 nonstationary eva approaches have evolved over time and have been employed to relate future flood probability distributions not only to time leclerc and ouarda 2007 tan and gan 2015 but also to other covariates such as climate variables or teleconnection indices e g arctic oscillation ao north atlantic oscillation index nao and el nino southern oscillation enso el adlouni et al 2007 lópez and francés 2013 obeysekera and salas 2014 silva et al 2016 yan et al 2017b and human interactions such as population density or urbanization gilroy and mccuen 2012 prosdocimi et al 2015 villarini et al 2009 drawbacks of nonstationary eva approaches lie in the use of covariates that may not correlate sufficiently with flooding events see e g archfield et al 2016 aryal et al 2018 barth et al 2018 burn and whitfield 2017 or in the lack of long term data for robust covariate attribution further in much of the literature the nonstationary analysis is based on the outcome of some null hypothesis significance tests for monotonic trends or abrupt changes applied to a finite time series of hydrological variables e g annual maxima the approach also assumes that historical hydrologic trends will continue into the future which is not necessarily true and may produce unrealistic results see e g luke et al 2017 serinaldi et al 2018 serinaldi and kilsby 2015 reliability of the nonstationary approach requires relating the time varying behavior to the underlying cause and effect processes that generate it serinaldi and kilsby 2015 which cannot be obtained from statistical approaches moreover historical floods may show statistically significant trends but when separated according to their generating processes such as snowmelt or large rain over snow trends can be insignificant e g as in alberta canada over the past 100 years see whitfield and pomeroy 2016 critically serinaldi and kilsby 2015 have argued that if we are not able to identify a cause and effect mechanism for the trend i e abrupt changes or monotonic we cannot infer their future evolution and thus cannot make hydrological predictions beyond the period of record several studies have further shown that stationary models for eva can be parsimonious as compared to their nonstationary counterparts see e g ganguli and coulibaly 2017 luke et al 2017 serago and vogel 2018 consequently it is imperative to account for cause and effect ince processes associated with hydroclimatic evolution i e nonstationarity in flood projections rather than simply relying on intt motivated by the abovementioned shortcomings this study aims to investigate future floods from ince compared to those obtained from intt where future streamflow projections derived from simulations of a physical process based hydrological model can be used to study the changes in flooding events into the future first to identify the evolutions of hydroclimatic conditions non overlapping periods i e historical and future can be simulated with the assumption of local stationarity within each period kavvas et al 2017 trinh et al 2016 however these non overlapping periods are usually short since time series input data for hydrological modeling are not often available for long periods of time therefore the reduced sample size of the flood series will likely increase the variance of parameter estimates of the probability distributions and thus increase the uncertainty of the estimates another issue that needs to be addressed next an ensemble of future climate projections from several general circulation models gcms after appropriate downscaling can be used in deriving sets of future streamflow time series for a study area finally flood peaks can be extracted from the simulated future streamflow to construct ensembles of probability distributions and then compared to their historical counterparts the approach presented in this study differs from others with respect to projecting future floods using a deterministic approach as well as compares the projections to the interpreted changes from the statistically detected trends first we implement an ince approach by using a hydrological model to calculate the potential changes in frequency and seasonality of floods due to climate change as well as the uncertainties that result from using multi model simulations i e variability across climate models second we investigate how to improve the skill of flood frequency fitted distributions derived from short streamflow time series by combining several peak flows extraction methods with various parameter estimators of the extreme value models third we assess how nonstationarity inferences from null hypothesis significance tests such as using nonparametric trend tests on records of historical floods compare to those obtained from cause and effect deterministic processes generated using a validated hydrological model 2 background on extreme value analysis extreme value theory evt or eva provides a practical and comprehensive framework for analyzing the probability of extreme events such as floods and their return periods coles 2001 two types of flow series employed for the study of flood extremes are the block maxima or the annual maxima am and the annual peak flows as assessed with the peaks over threshold pot method the am approach samples the highest value within a block of time usually a year e g annual maximum streamflow and then modeled by fitting a generalized extreme value gev distribution because the am approach arranges the data into blocks of equal length and chooses the highest in case of floods within the block it potentially discards essential information about other high independent flood events occurring within the same time block e g year or it can result in low discharge values sampled from dry years the pot approach is an attractive alternative to am that allows including more independent events as they are not selected at fixed intervals an optimum threshold or a truncation level denoted by u is selected as small as possible to retain the largest sample of excesses above the truncation level to be fitted to a generalized pareto distribution gpd coles 2001 lang et al 1999 the pot approach provides a comprehensive description of the extreme occurrences that retain both their magnitudes and timings lang et al 1999 therefore they can be used for investigating the impacts of climate change on flood magnitudes and several other flood attributes including rate of occurrence and duration of peak flows as well as seasonality i e flood timing as in am flood frequencies derived from pot series especially from short time series might be more robust than those from am bell et al 2007 bezak et al 2014 deidda 2010 since pot series will employ more than a minimum mean number of 1 65 events per year as suggested by cunnane 1973 whereas the am series contain only one event per year and thus might be more sensitive to outliers koutsoyiannis 2004 langousis et al 2013 it is noteworthy that if a priori chosen pareto distribution is the correct type of distribution and if it accurately describes the distribution of the excesses the larger sample of pot series reduces the variance in the estimated parameters of the fitted distribution roth et al 2016 2012 a wrong choice of the distribution however may severely underestimate or overestimate floods for large return periods papalexiou et al 2018 2013 another benefit of using pot over am strictly speaking for the same sample size is the ability to include the n largest extremes in records having n complete years where these extremes represent more accurately the tail of the distribution as they include other extreme values that might be omitted in the am series see i e papalexiou and montanari 2019 pot approach is however underemployed compared to am because of the challenges often encountered in its application for instance the choice of an appropriate threshold where a value that is too high may result in so few excesses that no distribution model can be fitted while a value that is too low may increase the chances of selecting nonextreme events such that the asymptotic assumption of the gpd is no longer valid resulting in an ill fitted tail and if the parent distribution is different from pareto this activity of threshold selection is known as the bias variance tradeoff coles 2001 roth et al 2012 note that the choice of the distribution of excesses over a high threshold to be a gpd is valid provided that the parent distribution is of power type papalexiou et al 2013 and the sample maximum tends to a non degenerate distribution observation fukutome et al 2015 lee and kim 2019 pickands 1975 where the threshold value tends to infinity or if it is very large papalexiou et al 2013 otherwise identifying a priori tail for the sample to be a gpd may not be accurate see e g papalexiou et al 2018 the extraction of peaks is not a trivial task and the absence of a formal framework to define an optimum threshold to extract excesses makes it even more challenging beguería 2005 langousis et al 2016 roth et al 2016 langousis et al 2016 rigorously reviewed statistical and graphical methods for the choice of a threshold while they yielded the best performance graphical methods depend on visual investigations that might not always be easy to apply and are highly subjective additionally the application of graphical threshold selection approaches becomes potentially unmanageable when the number of streamflow series to be analyzed is large with ensemble simulations as it is the case in this study therefore an automated threshold identification is necessary and employed in this research as described in section 3 3 2 another problem is that excesses derived from filtering the peaks over a threshold tend to cluster into dependent events see e g acero et al 2011 beguería and vicente serrano 2006 süveges and davison 2012 and especially in hydrologic data which violates the assumption of independence of excesses therefore when dependent excesses are detected to occur in groups extremely high flow is likely to be followed by another a careful declustering should be carried out which requires the definition of criteria to identify independent events and introduces a different source of subjectivity a few statistical tools have been developed to filter clustered realizations to yield datasets of independent events including statistical declustering methods brodie 2013 coles 2001 ferro and segers 2003 or other physically based criteria to determine a fixed interval at which only the highest peak is considered from each cluster exceedances separated by less than a fixed interval called the run parameter are considered a cluster maximum excess is extracted from a cluster coles 2001 the choice of the run parameters significantly affects the estimation of the gpd parameters davison and smith 1990 ferro and segers 2003 for instance fukutome et al 2015 showed that selection of unnecessarily large run parameters could have adverse effects on the estimations 3 methods and materials 3 1 study area and streamflow gauging records with an area of about 700 000 km2 the province of alberta has 17 river basins where most of them originate from the snowmelt dominated and glaciated highlands of the rocky mountains the study area includes eight of the 17 river basins in the province athabasca battle beaver bow north saskatchewan oldman peace and red deer fig 1 covering almost 60 of alberta several gauging stations in the eight river basins were selected at the main rivers and their large tributaries from the gauging database and flow records of the water survey of canada for intt analysis long period observation data from pristine gauging stations were necessary therefore the choice of the gauging stations was based on defining several criteria on observation data we selected streamflow gauging locations with at least 50 years of data over the province of alberta see fig 1 for the names and locations of the stations and tables s1 and s2 of the supplementary material for a descriptive summary of the selected stations so that they can be used to investigate how null hypothesis significance tests are used for nonstationarity inferences additionally stations were further filtered such that they have an active operation status with continuous recordings preliminary data screening through time series visualization was applied to the observed sets to investigate missing observations for long periods stations with more than two continuous years of missing data or 10 percent of the observations not available in any given year a year is considered missing with less than 330 days of observations were excluded further only natural gauging stations with no dams affecting the river flow were used these criteria yielded 29 hydrometric stations fig 1 comprising 50 to 108 years of daily records that represent the most natural streamflow conditions and thus represent the impacts of historical climate and are more likely to reflect the possible impacts of future climatic changes on the other hand for ince analysis river discharges were simulated for historical 1983 2007 and future 2040 2064 periods at the outlets of the same watersheds selected earlier it is worth noting that floods are the most frequent natural hazard buttle et al 2016 and costliest disaster sandink 2010 in canada and in particular alberta has witnessed several historic devastating and costly floods resulting in many deaths and disruptions from evacuations environment and climate change canada 2017 milrad et al 2015 pomeroy et al 2016 teufel et al 2017 making the province an interesting case to test our hypothesis additionally to the best of our knowledge there has been no other study conducted on the potential impacts of climate change on future floods in alberta both in terms of seasonality and design discharges 3 2 simulations of historical and future streamflow to set up the analysis for our ince approach the physically based hydrological model the soil and water assessment tool swat was used to derive the hydrologic projections of the selected watersheds in alberta the model underwent rigorous data selection and careful calibration and validation procedures to represent the hydrologic conditions of the province using observations from 130 hydrometric stations for the 1983 2007 period faramarzi et al 2017 faramarzi et al 2015 it has since been applied in several applications chunn et al 2019 gharib et al 2017 masud et al 2018b 2019 its spatially distributed features make it suitable to explain regional variation in the hydrologic cycle due to both human activities and climatic conditions to incorporate future climatic changes in the streamflow simulations for the selected watersheds we obtained future climate projections from the pacific climate impacts consortium pcic cannon 2015 at a grid resolution of 300 arc seconds 10 km pcic provides statistically downscaled gcm climate scenarios from 1950 to 2100 bürger et al 2013 2012 based on the coupled model intercomparison project phase 5 cmip5 taylor et al 2012 and the actual historical daily gridded climate data for canada mckenney et al 2011 the models in the pcic database are forced with the representative concentration pathways rcp to represent various scenarios of future greenhouse gas ghg concentrations see van vuuren et al 2011a for details pcic provides canada wide downscaled climate change projections using bias correction spatial disaggregation bcsd and bias correction constructed analogues with quantile mapping reordering bccaq methods http www pacificclimate org data in our study we used the projection derived using the bccaq method as it was evaluated by werner and cannon 2016 and was shown to pass the largest number of tests for hydrologic extremes in comparison to other methods including the bcsd using the climdex indices recommended by the world meteorological organization expert team on climate change detection and indices etccdi chen et al 2011 we further downscaled pcic data to alberta s condition based on daily historical climate data from an earlier study by faramarzi et al 2015 where a suite of five climate data sources including meteorological station based and gridded products were examined to reproduce historical flow records for 130 gauging stations by using a process based hydrological model a combination approach where several climate data were combined from different sources was found to be best in generating their corresponding streamflow this historical climate dataset was used to force the hydrological model to obtain historical streamflow for the 1983 2007 period the dataset was further used as the downscaling target for a second order bias correction of the pcic projections using the change factor method i e the delta method chen et al 2011 quilbé et al 2008 an empirical relationship between gcm and historical data was established in order to generate a downscaled gcm future output then the future climate datasets were used to drive the swat hydrological model for the future streamflow for the 2040 2064 period the model has been previously calibrated and validated based on observations from 130 hydrometric stations in alberta for the 1983 2007 period faramarzi et al 2017 faramarzi et al 2015 we further tested the model using three extreme discharges during the 1983 2007 period for each station the 0 9 0 95 and 0 99 quantiles were extracted for each month for every year from the daily historical simulations and observations and then the two were compared for this study to account for the uncertainty in the flood peaks projections resulting from the different climate models an ensemble approach was employed two emissions scenarios in an ensemble of five gcms i e canesm2 ccsm4 cnrm cm5 1 csiro mk3 6 0 and miroc5 were incorporated see table s3 in the supplementary material for additional information on the gcms the ensemble approach has been commonly employed in the hydrologic literature see e g cloke et al 2013 faramarzi et al 2013 huang et al 2014 kay et al 2009 kay and jones 2012 the choice of the individual members of the ensemble was based on the top five models that provide the widest spread in the projected future climate cannon 2015 for the western north america region classified by giorgi and francisco 2000 projections were obtained for the mid 21st century from 2040 to 2064 based on two greenhouse gas ghg emissions scenarios namely rcp 2 6 and rcp 8 5 the rcp 2 6 scenario indicates a low forcing level with mitigation and corrective policies aiming to decrease emissions with a peak of 3 1 w m 2 in the mid 21st century and limits the increase of global mean temperature to 2 c van vuuren et al 2011b whereas the rcp8 5 scenario is a high ghg emissions scenario with a rising radiative forcing pathway leading to 8 5 w m 2 by 2100 the ensemble changes in the temperature and precipitation for alberta for the two emissions scenarios are illustrated in figs s1 and s2 of the supplementary material for each member of the ensemble for each climate scenario the dataset was used to drive the swat model to obtain the future 2040 2064 streamflow for the studied watersheds 3 3 projection of changes in future floods 3 3 1 peak flow attributes and regime changes flood peaks data were extracted from the daily simulated streamflow series for the historical period and the projected data for the future period under each climate model and scenario since the study has a particular focus on high extremes four flood attributes were identified and derived from each pot series under the different model scenario projections i the annual rate of occurrence of independent exceedances above the threshold ii the annual mean date of occurrence of exceedances iii the duration of each flood event and iv the variation about the mean date of occurrence referred to as the flood regularity the first two flood attributes were calculated on an annual basis while the duration was calculated on an event basis the variation about the mean date was calculated as one value for each pot series for the historical simulations each time the daily flow exceeded a threshold that corresponds to the 90th percentile threshold p90 the peak flow was sampled p90 was chosen as it has been commonly used in earlier studies in utilizing the pot approach roth et al 2012 rydman 2018 whitfield and pomeroy 2016 in addition the 90th percentile in most of the 29 simulated catchments was less than the minimum of the annual maxima series of the historical data series therefore it ensures that at least one peak was sampled each year for the future simulations the same thresholds defined from the historical simulations were benchmarked and used to obtain the future flood peaks to quantify the changes in the four flood attributes independent flood peak events were extracted from each historical and future flow time series and were investigated for the four attributes the independence of peaks will be further discussed in the next section the rate of occurrences of flood peaks was determined by counting the total number of occurrences n of the pot events per year counts were then divided by the number of days in the year to obtain the annual rate of occurrence for each station flood duration was calculated as the total number of days the daily flow remained above the threshold for each flood event following burn et al 2010 the date of occurrence or the timing of the flood event and the regularity of the flood peaks were calculated based on a directional statistic by converting the julian date of an event occurrence for a given year to an angular value see section s1 in the supplementary material for equations and notations regularity is a dimensionless measure that ranges from 0 low regularity to 1 high regularity it defines the variability of the flooding date of occurrence about the mean date such that a regularity of 1 indicates that each event in the period of record occurs on the same date of the year while lower values indicate a wider spread in the timing of occurrence burn et al 2016 burn and whitfield 2015 to quantify the changes in the four flood attributes between the historical and the future pot series we aggregated the annual and the event basis attributes into averaged values for each station for each historical pot series and each model of the ensemble simulations for the future period then the percentage change in the rate of occurrence and regularity of floods and the difference between the mean date of occurrence and duration days of floods were calculated 3 3 2 selection of threshold and independent events determination of thresholds to extract peaks for assessing the changes in the 20 and 50 year return levels followed a different approach than that used in studying the changes in the four flood attributes defined in section 3 3 1 since the quality of the gpd fit depends significantly on the choice of the threshold beguería 2005 gharib et al 2017 liang et al 2019 northrop and coleman 2014 for that two threshold selection methods namely the likelihood ratio test lrt method and the square error method se were employed in this study as they have shown to outperform other methods zoglat et al 2014 we employed an algorithm developed in r by gharib et al 2017 to automate both the lrt and the se threshold selection methods following the procedure outlined by beirlant et al 2005 and zoglat et al 2014 in the lrt method one chooses a range of threshold candidates where ui and uk ui uk are two threshold candidates and xui and xuk are vectors of observations exceeding the two thresholds respectively indeed if ui is an acceptable threshold then uk is also acceptable this test is designed to compare two threshold candidates therefore when two thresholds are admissible the smallest one is optimal in this study for instance the first selected threshold i e ui was selected to be 0 9 quantiles of the streamflow on the other hand the se selection method aims to minimize the mean square error mse between the empirical i e based on actual events and the fitted i e calculated events distributions at a given gpd parameters estimator the method is particularly useful to compare several estimators as shown in gharib et al 2017 and especially when one of them could be biased zoglat et al 2014 it is critical to ensure that the exceedances over the threshold are independent and peak flows originate from different events therefore it is common to proceed with the choice of a high enough threshold until the asymptotic assumption of the fitted distribution is satisfied here after the selection of the threshold the independence of extracted flood peaks was based on defining a minimum period such that successive exceedances over the threshold are separated and are hydrologically independent within the time series this rule known as declustering considers the area of the catchment and imposes additional criteria that any intermediate flow between two peaks must drop below 75 of the lower of the two neighboring peaks using the following equation as described by uswrc 1976 1 t 5 days lo g 10 0 3861 a and p f min 0 75 min p f i p f i 1 where t is the minimum time in days between two independent peaks a is the basin area in square kilometers and pfmin is the minimum intermediate peak flow between two consecutive peak values pfi and pfi 1 in cubic meters per second these two conditions were considered in the pot analysis on the sava river in slovenia bezak et al 2014 and several rivers in germany merz et al 2016 the approach employed in this study is similar to the two step framework by bernardara et al 2014 in that it applies a physical threshold selection with a statistical optimization to define events as independent observations and achieves gpd convergence respectively before fitting a distribution the hypothesis that the samples of the derived flood peaks are independent and identically distributed was evaluated we assessed the dependence of exceedances over the selected threshold using the extremal index coles 2001 smith and weissman 1994 which measures the degree of clustering of extremes using a number between 0 clustered data and 1 perfectly independent data extracted peaks were examined for the simulated streamflow time series i e both historical and future series for the estimated thresholds corresponding to the 90th percentile lrt estimated and se estimated the r package extremes gilleland and katz 2016 was used for the estimation of the extremal index 3 3 3 fitting a generalized pareto distribution once the optimal thresholds are defined and independency is ensured one needs to fit a suitable probabilistic model to the pot series to estimate the design discharges for that the generalized pareto distribution gpd was used to model the independent peak flow extremes statistically let x be a random variable then the cumulative distribution function f x of the gpd with shape location and scale parameters ξ u and σ respectively derived from the exceedances of x above the threshold u both in cubic meters per second is defined as pickands 1975 2 f x p r x u x x u 1 1 ξ x u σ 1 ξ for ξ 0 1 exp x u σ for ξ 0 in order to increase the accuracy of flood frequency fitted distributions derived from the short streamflow time series i e 25 years and to accurately represent the datasets the parameters were estimated using the framework proposed by gharib et al 2017 in combining the threshold selection approaches with the parameters estimation methods several methods exist for the estimation of the gpd parameters see review by de zea bermudez and kotz 2010 in this study six combinations between two threshold selection approaches and four estimation methods were used to estimate the gpd parameters for each catchment the four estimators used were maximum likelihood estimator mle nonlinear weighted least square estimator nwls maximum goodness of fit anderson darling estimator mgfad and modified likelihood moment estimator newlme note that while each of these methods shows biases ideally the bias should reasonably be independent of the estimation method in that sense papalexiou et al 2013 provided an almost unbiased estimation method for the gev parameters through fitting the theoretical tails to the empirical ones by minimizing numerically a modified mean square error mse norm see also serinaldi and kilsby 2014 for gp distribution the quadratic upper tail anderson darling a2 goodness of fit test was used to assess the suitability of the gpd model and the quality of the fit which estimated a test statistic of the sum of squares of the differences between the empirical and fitted distribution functions with a weight function that emphasized discrepancies in both the upper and lower tails choulakian and stephens 2001 the statistic was used to select the best distribution among those fitted using the six combinations between the threshold selection approaches and the gpd parameters estimators for each member of the two ensemble scenarios for each catchment separately 3 4 at site growing and moving window trend approach on observed peak flow data to investigate intt approach and that how inferences from null hypothesis significance tests on historical observations may reflect future flood evolutions the existence of monotonic slowly varying trends in the historical observations increasing or decreasing was explored by employing the nonparametric mann kendall mk test kendall 1948 mann 1945 the daily historical observations obtained for the 29 hydrometric stations recall section 3 1 were used to calculate three flood seasonality attributes and three other characteristics that relate to the magnitudes of floods for the 29 catchments by proceeding all steps explained in section 3 3 the three seasonality variables are the annual rate of occurrence the mean annual peak timing and the peak events duration whereas for the flood magnitudes the three variables are the annual maximum peak the annual mean peak and the peak events magnitudes trend results are then compared to those obtained from the ince approach i e hydroclimatic simulations in order to examine the sufficiency of inferring future behavior i e supporting nonstationary frequency analysis from trend results further for the investigation of the effects of the time series length a growing and moving window trend analysis approach was employed such that for all possible combinations of start and end years for the data series length record with a minimum series length of 10 years and a maximum of the length of the entire record the trend test statistic was estimated and plotted against the corresponding start and end years 4 results and discussion 4 1 swat hydrological model simulations results of the statistical measures used to test the performance of the hydrological model in simulating the extreme streamflow quantiles as shown in table 1 showing that they were well reproduced by the hydrological model the model performance slightly decreased as the quantile value increased however since the study compared the changes in the future relative to the historical conditions using simulations of the model in both periods we assume that any presence of systematic errors in simulations of both periods is consistent and balanced out additional validation results for each station are presented in table s4 of the supplementary material 4 2 independence of peaks and performance of gpd estimators while the average numbers of sampled peak flow as illustrated in table 2 are considerably higher approximately 12 times than the recommended value of 1 65 multiplied by the number of years as defined by cunnane 1973 the values of the extremal index suggested a high degree of clustering of extremes therefore the excesses have been declustered using physically based criteria as described in section 3 3 2 first to determine clustered periods and second to select independent flood events within each cluster after declustering there was no evidence of the presence of clustered extremes in the derived pot datasets for both the historical and ensemble future simulations for the 29 catchments as shown in table 3 it is worth noting that in cases where after declustering the pot series the number of peaks was less than the critical value recommended by cunnane 1973 the threshold ui is decreased iteratively by a small step until the number of independent peaks is equal to or greater than the critical number for peaks which is 1 65 multiplied by the number of years i e 25 years of simulations it is important to emphasize that without a thorough examination of the assumption of independence every subsequent extreme value theory analysis is ill posed and as such the asymptotic conditions of the pareto distribution will be violated we realized that no matter how high the value of the threshold selected with the condition that the number of peaks is 1 65 times the number of years or higher the dependency of exceedances over the threshold will exist unless and only if a declustering routine is applied to the exceedances in order to decrease this dependency see for example chandler and bate 2007 coles 2001 fawcett and walshaw 2007 ferro and segers 2003 this is attributed to the fact that dependency in hydroclimatic variables is the rule not the exception and in practice observations are almost always dependent adamowski and bougadis 2003 hamed and rao 1998 kumar et al 2009 yue et al 2003 that was found during our preliminary extraction of independent peak flows for the 29 gauges across alberta based on thresholds that correspond to a 0 90 quantile as summarized in tables 2 and 3 the best fit gpd was chosen based on the minimum anderson darling statistic and after checking the corresponding p value results showed that the excesses are adequately described by a paretian distribution and that the gpd fits with the corresponding p values well exceed 75 fig s3 and tables s5 and s6 of the supplementary material it is worth noting that a few of the combinations did not converge when estimating the parameters of the gpd anderson darling statistics computed for several distributions fitted on the same data set can be problematic to compare since it could systematically favor the selection of more complex distributions with larger number of parameters delignette muller and dutang 2015 in such cases to discourage overfitting and assist with the ad statistic classical penalized criteria based on the log likelihood such as the akaike s information criterion aic and bayesian information criterion bic should also be considered burnham and anderson 2003 höge et al 2018 kim et al 2017 however it is not a problem when compared distributions are characterized by the same number of parameters as in the case of this study additional results on the performance of the estimators are provided in section s2 and figure s3 of the supplementary material 4 3 future projections of flood regimes and design discharges 4 3 1 changes in flood regimes under future climate using the mean ensemble projections five catchments of the 29 studied are expected to experience decreases ranging from 11 to 54 in the rate of occurrence of floods in the future period 2040 2064 relative to the historical period 1983 2007 fig 2 a and fig 4a with one catchment in each of the athabasca battle beaver north saskatchewan and peace river basins for rcp 2 6 the other 23 catchments showed increases ranging from 5 to 112 and only one catchment 07aa002 in the athabasca river basin showed no change on the other hand rcp 8 5 resulted in more intense changes than rcp 2 6 for the rate of occurrence as shown in figs 3 a and 4 a for rcp 8 5 only two catchments namely 07bf002 in the athabasca river basin and 05fa001 in the battle river basin are projected to experience decreases in the rate of occurrence of peak flows by 23 and 27 respectively whereas the other 27 catchments showed increases ranging from 6 6 to 143 the results indicate that the majority of the studied catchments in the peace river basin will likely experience considerable increases in the rate of floods occurrence with an average change of 41 and 57 in rcp 2 6 and rcp 8 5 figs 2a and 3a respectively followed by the catchments of the red deer 36 in rcp 2 6 and 46 in rcp 8 5 oldman 15 in rcp 2 6 and 20 in rcp 8 5 bow 14 9 in rcp 2 6 and 22 in rcp 8 5 athabasca 9 4 in rcp 2 6 and 22 in rcp 8 5 and north saskatchewan 5 8 in rcp 2 6 and 19 in rcp 8 5 river basins whereas the studied catchment of the battle river basin 05fa001 showed a decrease of 54 and 27 for rcp 2 6 and rcp 8 5 climate scenarios respectively the studied catchment of the beaver river basin showed contrasting changes in the rate of floods occurrence for both climate scenarios with a change of 14 and 16 for rcp 2 6 and rcp 8 5 respectively fig 4a it is important to note that the athabasca river basin had the highest number of catchments i e 11 catchments recall fig 1 and table s1 of the supplementary material represented in the study while river basins such as the battle and beaver had only one catchment presented therefore the results may not be inclusive to represent the entire river basin but should be seen unique to the catchments within each river basin given that most of the selected stations are tributaries recall fig 1 further an increase decrease in the regularity r of flood events indicates a decreased increased variability of flood occurrences about the mean date of flooding for rcp 2 6 the average ensemble projections showed that only six catchments had increases in regularity ranging from 3 6 to 29 whereas decreases dominated the other 23 catchments in a range of 3 6 to 43 figs 2b and 4b results also indicated that the largest decrease 43 occurred at one catchment 07hc001 in the peace river basin both catchments of the battle and beaver river basins showed increases in regularity by 29 and 10 respectively decreases dominated the catchments of the other five basins including the north saskatchewan 7 4 athabasca 8 8 red deer 16 oldman 20 and bow 27 river basins on the other hand for rcp 8 5 only one catchment 05fa001 of the 29 that is located in the battle river basin showed an increase of 7 5 in the regularity one remained unchanged while the other 27 catchments showed decreases ranging from 2 to 54 figs 3b and 4b further larger decreases are predicted for the rcp 8 5 climate scenario for the catchments of seven river basins ranging from 13 in the beaver river basin to 40 in the bow river basin and average decreases of 15 in the catchments of the peace 18 in athabasca 18 in north saskatchewan 23 in red deer and 28 in oldman river basins these results suggest that it is likely that the timing of the flood from one year to the next will be less predictable in alberta peak flows occur mostly during the spring and summer seasons when the highest rainfall and snowmelt occur the changes in the timing of flood events often imply shifts in the dominant flood generating processes such as snowmelt rainfall or rain over snow in analyzing the shifts in timing we considered a shift of one day as no change a result of less than one day may occur by taking the average ensemble projections in the analysis the results revealed that flood events are mostly occurring earlier in the future for most catchments for both climate scenarios as illustrated in figs 2c and 3c for rcp 2 6 and rcp 8 5 respectively of the 29 catchments for rcp 2 6 as shown in fig 4c the average multi model ensemble showed that the timing of flood events only in three catchments are projected to shift later in the year with a range of three days at 07be001 in the athabasca river basin to eight days at 07hc001 in the peace river basin while nine showed no change and 17 are projected to shift earlier ranging from two days at 07da001 in the athabasca river basin to 21 days at 05cc001 in the red deer river basin on the other hand for rcp 8 5 as shown in fig 4c nine of the 29 catchments showed later occurrence of flood peaks ranging from two days at 07da001 in the athabasca river basin to 14 days at 07hc001 in the peace river basin seven showed no change and earlier occurrences dominated the other 13 and are projected to shift earlier by two days at 05da007 in north saskatchewan river basin to 22 days at 05cc001 in red deer river basin it is anticipated that earlier floods due to warming conditions may reflect earlier snowmelt events and rain on snow events during the winter season burn et al 2016 burn and whitfield 2015 the results are also consistent with those of burn and whitfield 2017 for historical trends of timing of flood occurrences for a number of nival catchments in alberta i e catchments with flood events resulting from snowmelt or rain on snow events where most stations while may not depict a significant trend are dominated by earlier flood event occurrences and a few other showing later occurrences additionally the earlier flood occurrence was more dominant in the southern catchments as compared to the northern ones figs 2c and 3c this may be partially explained by the earlier melting of the snowpack associated with warmer temperatures in the southern part of the province masud et al 2018a moreover increases in the duration of flood events were more concentrated in the eastern part of the province rather than the western part for both rcp 2 6 and rcp 8 5 as shown in figs 2d and 3d this change could be attributed to the flood types generated downstream mainly by mixture processes of snowmelt and rainfall in both climate scenarios the two catchments of beaver and battle river basins are projected to experience significant increases in the duration of floods expressed as the duration that the peak flows are continuously above the defined thresholds these significant increases could be attributed to the fact that both river basins are prairie fed basins that rely solely on spring runoff and rain rather than snowpack and glacier melts that are expected to increase in the future masud et al 2018a the change in mean flood duration for the selected catchment of the beaver river basin will likely be in the order of 23 days and 27 days for rcp 2 6 and rcp 8 5 respectively and in the order of 18 days and 26 days for the studied catchment of the battle river basin respectively the catchments of the peace river basin showed an average decrease of three days for rcp 2 6 and about two days for rcp 8 5 for the catchments of the other five basins results indicate that only those in red deer river basin are expected to experience a average increase of one day for rcp 2 6 whereas for rcp 8 5 catchments of the athabasca north saskatchewan and red deer river basins showed increases in the duration in the range of one to two days and no change for those in the bow and oldman river basins in general most of the catchments have consistently shown concerned changes in the flood attributes for both climate scenarios that included projected increases in the rate of flood occurrence shifts to earlier flood events and increased variability of flood events about the mean date of occurrence suggesting a more difficulty in forecasting the timing of flood events from one year to another but insignificant changes in the duration of floods these findings are consistent with expectations that in warmer conditions more precipitation will occur as rain rather than snow resulting in a more significant number of events and earlier shifts in the timing of flood events burn et al 2016 4 3 2 changes in flood quantiles under future climate table 4 summarizes the percentage of catchments showing changes whether increasing or decreasing in the intensity of two extreme floods corresponding to the 20 and 50 year events referred to as q20 and q50 respectively for the means of the ensemble simulations event magnitudes corresponding to 20 or 50 year return periods for the mid century are mostly becoming more intense in both climate scenarios except for a few cases as shown in fig 5 on the one hand in rcp 2 6 17 catchments are projected to experience increases in q20 in the range of 4 to 52 and only one catchment remained unchanged while 20 catchments are expected to increase in q50 with a range of 2 to 104 as shown in fig 5 the catchments of the bow river basin had the highest average increase in q20 of 10 and in q50 of 12 followed by the catchments of red deer 9 in q20 and 5 in q50 beaver 9 in q20 and 2 in q50 oldman 7 in q20 and no change in q50 and athabasca river basin 3 in q20 and no change in q50 the studied catchments of the peace river basin showed both decreases and increases in q20 and q50 catchments of both north saskatchewan and battle river basins showed interesting results with contrasting change direction in q20 that in q50 indicating a decrease of 2 and 12 in q20 and an increase of 17 and 104 in q50 respectively on the other hand for rcp 8 5 of the 29 catchments 10 showed decreases in q20 ranging from 15 to 62 while 18 catchments showed increases ranging between 3 to 55 as presented in fig 5 for q50 nine catchments showed decreases ranging from 7 to 82 while increases dominated 17 of the catchments with a range of 7 to 86 and one showed no change the studied catchment of the beaver river basin 05fa001 showed notable increases in both q20 and q50 with changes of 26 and 49 respectively followed by the catchments of red deer oldman bow and athabasca river basins with an average change of 17 10 6 and 4 in q20 and 11 8 9 and no change in q50 respectively the results also indicate that the studied catchments of the peace river basin are expecting both decreases and increases in the future ranging from 62 to 44 for q20 and from 82 to 52 for q50 the catchments of the north saskatchewan river basin showed mostly decreases in both q20 and q50 except for one catchment 05db002 where increases of 55 and 86 are predicted respectively similar to the changes in the flood attributes the analysis showed that rcp 8 5 resulted in notably greater changes in flood magnitudes than rcp 2 6 it is also worth noting that no visible pattern can be drawn between the location of the catchment and the direction of or magnitude of change for both climate scenarios which may be attributed to local precipitation events dominating small and medium catchments in contrast to other larger catchments that are dominated by large snowmelt events or rain over snow however analysis of the size of the catchments results not presented showed no correlation between the direction or magnitude of change with the size of the catchment another reflection here is while the simulated flow is based on fully known processes using a model chain gcm swat hydrological model that does not mean that all the properties of simulated flow sequences should attribute directly to climate in fact the model chain can produce complex transformations which can result in 1 apparently stable behavior of finite size time series 2 complicate the attribution for four properties of floods and magnitudes 3 may result in omitting other important non climate factors including changes in land use or other socioeconomic factors e g population changes and adaptations therefore besides the scientific importance of detection and quantification of future changes it is also important to advance our understanding of the drivers responsible for those changes in each flood property not only to climate but also to other possible non climate factors see e g berghuijs et al 2016 hirsch and archfield 2015 kreibich et al 2019 neri et al 2019 4 4 uncertainty in future estimates the uncertainty arising from the different climate models in the multi model ensemble approach is illustrated in fig 4 for the two climate scenarios i e rcp 2 6 and rcp 8 5 for the flood seasonality attributes in most cases the mean of the ensemble represents the typical direction of change whether increasing or decreasing however there were a few cases where some gcms were showing a decrease when the mean is indicating an increase and vice versa for example station 05cc001 in the red deer river basin showed a mean change of 9 4 in the rate of flood occurrence for rcp 2 6 with minimum and maximum changes of 33 4 and 54 5 respectively such results indicate that the projected changes may vary widely among the different gcms furthermore even if two models project the same direction of change the underlying cause of that change can be very different nonetheless the change direction projected by the multi model mean can be significantly affected by the projection of one model which alone among the ensemble members may project a substantial increase or decrease in precipitation and thus an increase or decrease in the attributes of floods and their severity we showed that in cases opposite change directions are probable which would increase the uncertainty bounds in the future as found in some catchments of this study ideally a more comprehensive uncertainty assessment would involve a larger number of climate models and other hydrological models moreover for the estimation of the return levels corresponding to the 20 and 50 year return periods the range of changes resulting from each climate model in the ensemble simulation for each catchment is also presented in fig 5 with horizontal bounds notably there is increased uncertainty in flood estimates at higher return periods i e 50 year compared to smaller in sample i e 20 year return levels this finding could be attributed to the fact that the streamflow simulated by the hydrological model historical and future periods was limited to 25 years indeed the results presented here for the 50 year return periods are slightly extrapolated but such extrapolation is commonly practiced in the literature cloke et al 2013 huang et al 2014 kay et al 2009 kay and crooks 2014 the range confidence bands in this research were only presented from the different climate models as the analysis estimated uncertainty from using different models and neglected uncertainties arising from other sources including future greenhouse gas emissions downscaling from gcms or the hydrological model as well as the data selection and parameterization of the model the latter however was addressed and investigated in faramarzi et al 2015 there are a few occasions where the parameters of the fitted distribution i e shape scale and threshold vary considerably between models see parameters in figures s4 and s5 and their statistics in table s7 of the supplementary material kay et al 2009 for example showed that the uncertainty in their study of future flood frequency in england was dominated by the gcm structure and that a large bias in as few as one model in an ensemble of five models can significantly affect the ensemble mean see also camici et al 2013 huang et al 2014 qin and lu 2014 let alone the uncertainty arising from the assumptions underlying the choice of thresholds and the estimators used to fit the pareto distributions to derive the frequency curves which was addressed using a combination of two threshold selection approaches and four estimation methods for the parameters as proposed by gharib et al 2017 4 5 using intt versus ince in projecting changes in future floods how do the results obtained with the ince approach using process based hydrological and climate models relate to those from interpretations of nonparametric trend analysis using long term instrumental records i e intt for that at site trend tests were performed on the flood peaks of all the 29 hydrometric stations using long period observations i e 50 to 108 years of daily records the percentage of stations with significant trends at the 5 significance level using mann kendall mk trend test in three flood attributes and three other summary characteristics that represent flood magnitudes for the 29 catchments are presented in table 5 the percentage of catchments that demonstrated positive trends in flood attributes or magnitudes seldom agrees with those obtained by the cause and effect physical mechanisms rendered through the hydrological model for instance recalling the changes in section 4 3 2 and table 4 59 of the stations showed increases in q20 and 69 in q50 for rcp 2 6 and 62 of the stations showed increases in q20 and 35 in q50 rcp 8 5 whereas the trend tests table 5 showed that none of the stations have statistically significant trends for the six analyzed flood properties except for the mean annual peak flow and only for 3 of the stations one reason could be due to the length of the observations data series analyzed that notably changes the results of the trend tests note this does not necessarily mean that all properties of simulated peak flow sequences should show trends or similar the model chain gcm hydrological model can produce complex transformations which can result in apparently stable behavior of finite size time series the average duration of floods is an example nonetheless the peak flow series corresponding to the time series resulting from ince is nonstationary by construction to elaborate on how the length of data series may lead to different results and inferences we compared trends for the last 30 years of records versus the entire period refer to table s1 of the supplementary material for the length of data series for each gauging station as shown in table 5 percentages of stations exhibiting decreasing trends for example realized from testing the entire record versus the last 30 years seldom agree this implies that the choice of nonstationary extreme value models based on extrapolating historical trends can be incorrect and that nonstationary effects may not continue beyond the period of record and do not necessarily hold for the entire future see i e cooley 2013 luke et al 2017 serinaldi et al 2018 which further may lead to high uncertainty in future predictions serinaldi and kilsby 2015 note that the effects of spatiotemporal correlation which results in space time clusters generating local trends were not considered in applying the mk test relatively short samples of extreme events from persistent processes may appear independent but they preserve some properties of the underlying persistent process such as clustering thus applying e g mk neglecting the memory of the underlying process can yield over rejection alternatively modified mk tests can be employed hamed 2011 for instance serinaldi and kilsby 2018 showed that accounting for spatiotemporal dependence can yield different results and conclusions in studying the occurrence probability of pot events additionally the diagnostic plot of monotonic trends in fig 6 examines the changes concerning the length of the data series for one arbitrary station the bow river at banff 05bc001 with the longest record of 108 years of observed data using the growing and moving window trend analysis described in section 3 4 the figure revealed contrasting monotonic trend behavior for different window sizes and or lengths for the data series the results of the trend analysis can be particularly subjective when used to draw inference about the direction of change in the future these results help understand and articulate the concerns raised by various researchers in terms of misusing and misinterpreting the outcomes of null hypothesis significance tests such as trends tests on short term or long term observed data to justify the hypothesis on future hydroclimatic changes and future events greenland et al 2016 serinaldi et al 2018 serinaldi and kilsby 2016 results shown in fig 6 demonstrate how statistically significant trends were only identified for parts of the record patches outlined with black lines and how trend results can vary substantially with changing the time span of the test or the time period considered in addition the trend analysis showed that aside from the length of the time series and their start and end dates the results could differ significantly among the different flood attributes as each of them may describe a particular flood generating process e g annual maximum mean annual magnitude timing and duration our results may partially explain the findings by whitfield and pomeroy 2016 who showed that while there is a significant negative trend in floods over the past 100 years for the bow river at banff 05bc001 when the events are separated based on the generating process neither snowmelt floods nor rain over snow floods showed any trends over time one concludes that a process based simulations of the climatic and hydrologic evolutions can result in much different change or even opposite change signal than that from predicting future behavior from historical trends and more accurate owing to the well defined physical mechanism by the process based model of course validated and b even if there is no statistically significant trend in the magnitudes of extreme events there can still be a change in future floods which is also supportive of similar findings from other researchers burn and whitfield 2017 another interesting finding is that in some instances the 20 year return levels are projected to increase in magnitude while the 50 year return levels are projected to decrease or vice versa for example recall fig 5 station 05dc006 ram river near the mouth in the north saskatchewan river basin showed an increase in q50 even though q20 decreased for rcp 2 6 one would hypothesize a consistent shifting of the flood frequency curve either upward increase in floods intensity as in fig 7 a or downward decrease in intensities to reflect the changes in the climatic conditions for the future however the frequency curves are likely shifting differently at different return periods in some instances as shown in fig 7b for 05dc006 where the future climate tends to decrease small floods and increase large floods these changes in the flood quantiles are mostly associated with future climate due to the selection of watersheds that are not regulated and no changes assumed for the future in the land use and the river morphology therefore this finding suggests that the underlying stochastic processes that generate floods are not consistent as floods in alberta are mostly resulting from snowmelt compounded with rainfall finally the results from this study support some of the findings from other research examining floods in alberta for instance burn et al 2016 showed that canadian streams witnessed increased exceedances reduced maximum magnitudes and earlier flood events based on historical observation on floods from pristine basins with stable land use conditions across canada including alberta likewise burn and whitfield 2015 showed that the magnitude timing and the number and duration of high flow events exhibited both increasing and decreasing trends see also burn and whitfield 2018 the results from this research also provide new insights in terms of the changes in flood attributes and design discharges for several catchments in alberta with various drainage areas and characteristics under a range of possible changes in climate in the midcentury period in a previous study tan and gan 2015 examined 145 stations over canada including a handful in alberta under a nonstationary framework using time varying distribution parameters using a group of gamlss models while they concluded that nonstationary frequency analysis should be employed in the future as a substitute for the traditional stationary models the inference of nonstationarity from trend analysis results is often based on assumptions about the underlying deterministic processes which could lead to unrealistic representation of the future serinaldi et al 2018 serinaldi and kilsby 2015 and because nonstationarity implies by definition the knowledge of the law governing the evolution of the process in time serinaldi et al 2018 this law needs to be known a priori via external information and cannot be inferred from data because it means that we do not know it and therefore it cannot be deterministic this contradicts the definition itself of nonstationarity therefore parsimonious models luke et al 2017 ragno et al 2018 serago and vogel 2018 serinaldi and kilsby 2015 or physically based hydroclimatic models such as the one employed in this study may be favored these physically based models produce a what if analysis based on fully known processes including gcms hydrological models etc are fully specified albeit complex therefore when gcm outputs are used under different emissions scenarios e g rcp 2 6 or rcp 8 5 it is known a priori that the model is nonstationary as it involves a well defined pattern of driving emissions in other words we know the time law governing the evolution of ghg emissions therefore gcms are nonstationary by construction and their output is also nonstationary moreover since the flows results from a model chain gcm hydrological model it is also a nonstationary process by definition as it results from a model chain whereby there is at least a nonstationary component 5 conclusions nonstationary extreme value analysis under a changing climate is one of the most evolving research focuses in the field of hydrology however the inference of nonstationarity from trend tests on flood characteristics can lead to erroneous future projections both in terms of magnitude and seasonality this paper investigated using trend tests as statistical tools to provide evidence of nonstationarity and justify the application of nffa models for projecting future changes in floods intt versus using a physics based hydrological model that characterizes future hydroclimatic changes ince the main conclusions of this study are as follows 1 there can be changes in flood properties in the future even if there are no significant trends in the magnitudes or regimes of floods based on null hypothesis significance tests on historical observations such as mann kendall trend test using a growing and moving window approach trends over a prescribed range of possible start and end years 2 flood frequency analysis based on physics based simulations of the climatic and hydrologic changes over time can result in contrasting future changes in floods compared to the conventional practice that uses historical trends to rationalize nonstationary frequency analysis for the future simply because if the process is nonstationary then the past is not representative of the future and cannot be inferred from it 3 better fits to the exceedances over thresholds are attained through combining two automated selection approaches of optimal thresholds with four gpd parameters estimators to deal with the relatively short periods of the non overlapping simulations of the hydrological model 4 floods in the selected 29 catchments of alberta canada are generally intensifying with changes in the climate in the mid 21st century except in a small number of catchments about 2 3 of the catchments are expected to experience higher 50 year floods with projected increases of 2 104 mean 29 median 20 for rcp 2 6 and 7 86 mean 32 median 25 for rcp 8 5 further the majority of the studied catchments have consistently shown exacerbated changes in flood regimes for both climate scenarios these changes include projected increases in the rate of occurrence of floods shifts to earlier occurrences increased variability of the events about the mean date of occurrence whereas no significant change in the duration of floods was projected these conclusions were based on the examination of changes in flood properties in terms of both seasonality and design discharges with climate change in a set of unregulated catchments in alberta using ensemble simulations the use of a spatially distributed hydrological model allowed determination of changes at individual catchments which was necessary because the examined catchments both tributaries and main stems had a wide range of climatic and hydrologic characteristics independent peaks over threshold data allowed examination of changes in several flood properties including the rate of occurrence timing and duration and regularity of exceedances as well as magnitudes of the 20 and 50 year flood events under ensembles of projections for two climate scenarios it is worth noting that projected changes in the hydroclimatic conditions derived from the hydrological model have some limitations the model assumes no human modifications e g changes in land use and no fluvial transportation e g construction of dams or natural changes in landscapes such as those caused by forest fires to occur in the future which will undoubtedly affect runoff generation processes therefore future studies should aim to quantify the relative impacts of these and other factors through socio hydrological modeling approaches that incorporate hydrologic responses to human alterations and vice versa finally return periods were estimated by assuming local stationarity within the historical and future periods an acceptable approach given the short simulation period of 25 years declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment we gratefully acknowledge the generous funding from the campus alberta innovation program caip chair award grant res0034497 the natural sciences and engineering research council of canada discovery grants program grant res0043463 and the graduate student internship program of the university of alberta two eponymous reviewers francesco serinaldi and simon michael papalexiou and one anonymous reviewer are acknowledged for their review comments which helped us to improve the original manuscript supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103463 appendix supplementary materials image application 1 image application 2 
541,relative permeability and capillary pressure are known as essential properties that have substantial impacts on the accuracy of reservoir simulations the effect of small scale heterogeneity and lamination in the rock structure is often ignored during the measurement of capillary pressure and relative permeability curves in core samples this study highlights the remarkable impact of anisotropy on the multiphase flow properties of stratified formations a series of steady state co2 brine drainage and imbibition tests are conducted at reservoir conditions in horizontal and vertical core samples of the tuscaloosa sandstone from the cranfield co2 injection site in mississippi the relative permeability curves represent an anisotropic behavior influenced by the heterogeneous and laminated structure of realistic rock samples the co2 saturation profiles during drainage and imbibition cycles indicate that the phase distribution in the pore space is controlled by core scale heterogeneity in the porosity distribution among the laminations that causes capillary pressure inhomogeneity using the saturation profile during the imbibition cycle the trapping characteristic of the horizontal and vertical rock samples are compared and we found that the capillary trapping is less likely in the vertical direction furthermore the centrifuge measured capillary pressure demonstrates distinctive characteristics for horizontal and vertical core samples since the flooding experiments are performed under capillary controlled flow the capillary pressure contrast in the laminated structure of the rock strongly affects the relative permeability the presented results can potentially improve the accuracy of the large scale simulations for the co2 post injection period in which the vertical displacement has an important role in the plume migration keywords relative permeability anisotropy core flooding experiment co2 sequestration 1 introduction geological storage of co2 in deep saline aquifers unminable coal seams and depleted oil and gas reservoirs represents a feasible solution for mitigating global warming shaffer 2010 bakhshian et al 2018 birkholzer et al 2015 bakhshian and sahimi 2017 dashtian et al 2019 2017 among these storage formations saline aquifers are the best option for long term geo sequestration because of their large storage potential and immediate accessibility mathias et al 2009 hayek et al 2009 choi et al 2013 having knowledge regarding the migration of co2 plumes their trapping mechanisms and degree of trapping in subsurface reservoirs is important to the design of co2 injection the prediction of co2 behavior during its storage and assessment of the security aspects of underground sequestration core scale experiments and numerical simulations are primary tools for investigating multiphase flow properties such as co2 saturation distribution trapping mechanisms and relative permeability bachu and bennion 2008 silin et al 2011 berg et al 2011 bennion and bachu 2008 bakhshian and hosseini 2019 bakhshian et al 2019 the poverty of relative permeability data is one of the issues in co2 storage imbus et al 2006 thus a detailed investigation in this area is required to better understand the multiphase flow characteristics in co2 brine flow understanding the anisotropic behavior of transport properties such as relative permeability is important in predicting the performance of flow in subsurface reservoirs the anisotropic characteristics have been usually neglected in laboratory measurements of relative permeability studies have shown that the directional dependence of fluid properties may arise from small scale heterogeneity induced by the sedimentary structure of rocks as well as from buoyancy effects prats and lake 2008 heterogeneous features of rock such as laminationas often cause anisotropy however they are not a necessary condition prats and lake 2008 claimed that the directional dependence of relative permeability can be observed because of buoyancy and flow direction even in homogeneous and isotropic rocks adebayo et al 2017 studied the effect of gravity and flow direction on multiphase flow properties such as relative permeability and residual saturation of homogeneous rock samples during core flooding tests at small flow rates their experiments highlight the interplay between capillarity and gravity in rock samples and demonstrate the anisotropic behavior of relative permeability unpredicted observations during field scale injections of co2 such as co2 plume shape early breakthrough and injectivity abnormalities have raised questions about the role of geological heterogeneity on multiphase flow the microscopic structure of rocks is typically heterogeneous which arises from mineral grains with various shapes and bedding planes planar beds of stratification along a preferential direction resulting from the original structure of the formation or induced by external stress fields young claimed that cross stratified sediment and shale are two main geological features which induce the anisotropy characteristics to the reservoirs young 1989 the small scale heterogeneity and anisotropy of rocks strongly affect the macroscopic properties such as permeability and capillarity wright et al 2006 clavaud et al 2008 zoback and byerlee 1976 holcomb and olsson 2003 moreover the orientation of the stratified layers at field scale induces anisotropy to the fluid flow characteristics through compartmentalization of the reservoir chandler et al 1989 rogers and grigg 2001 proposed that injectivity abnormalities during co2 flooding projects may arise from heterogeneity heterogeneous stratification in uncorrelated media causes a reduction of co2 channeling through the high permeability layers and slower co2 breakthrough roper et al 1992 hovorka et al 2004 claimed that the geological heterogeneity could lead to longer residence times and improved sequestration effectiveness the small scale heterogeneous structure of the rock has a remarkable impact on the directional dependence of permeability fields the anisotropic behavior of the relative permeability cannot be ignored in capillary controlled flow under which the small scale heterogeneity of the rock structure has a significant impact on the co2 displacement corey and rathjens 1956 corey and rathjens 1956 have shown that at a given saturation the relative permeability for fluid flow perpendicular to bedding planes is smaller than for flow parallel to the bedding it is claimed that the degree of anisotropy strongly depends on the measurement scales young 1989 kortekaas 1985 studied the oil water displacement characteristics as well as the directional dependence of relative permeability and capillary pressure curves in a cross bedded reservoir zone they showed that the small scale laminated geometry of the reservoir strongly affects the prediction of oil recovery gregersen and johannessen 2007 have done a study on the geological structure of the neogene utsira sand at the norwegian sleipner field and have suggested a channel like feature formed with a north south trend inducing permeability anisotropy in the formation the northward extension of the co2 plume obtained from seismic data confirms the anisotropic behavior gregersen 1998 zhu et al 2015 while there are extensive studies on the multiphase flow of co2 and brine in rock samples some questions remain unresolved one uncertainty includes the effect of structural and stratigraphic heterogeneity on the anisotropic behavior of relative permeability the present study takes a step further and presents an extensive experimental study to address the effect of bedding strata on flow characteristics in rock samples the objective of the present study is to investigate the influence of stratigraphic heterogeneity on the directional behavior of relative permeability and fluid saturation distribution in the tuscaloosa rock samples taken from the cranfield site in mississippi lu et al 2012 hosseini et al 2013 two horizontal and vertical composite samples of tuscaloosa are prepared through combining multiple core plugs taken from the same facies at the same depth of the cranfield site a series of steady state co2 brine drainage and imbibition tests are conducted in horizontal and vertical composite samples at reservoir pressure and temperature with fluids flowing parallel and perpendicular to the bedding structure of the rock the fluid distributions of supercritical co2 and brine during the co2 drainage and the brine imbibition are recorded using x ray scanning we also discuss the effect of stratification on anisotropic behavior of relative permeability curves and endpoint saturations additionally we present centrifuge capillary pressure measurements performed on various horizontal and vertical core samples 2 experimental procedure the cylindrical plug samples used in the experiments are cut horizontally and vertically to attain surfaces at different angles to the bedding lamination of the tuscaloosa formation the plug samples are extracted from the injection well cfu31f 1 located in the cranfield site lu et al 2012 sun et al 2016 we attempted to drill the samples from the same facies at the same depth the detailed properties of these core plug samples are reported in table 1 in the supplementary material the samples were cleaned and vacuum dried to a constant weight gas air permeability and porosity were measured on the cleaned and dried samples at 3400 psi 23 4 mpa net confining stress see fig 1 a the horizontal and vertical samples used in the flooding experiments are composite cores which consist of seven horizontal core plugs 1 h 2 h 3 h 4 h 5 h 6 h and 7 h reported in table 1 supplementary material and four vertical core plugs 1v 2v 3v and 5v reported in table 1 supplementary material tables 2 and 3 in the supplementary material summarize the properties of horizontal and vertical composite samples respectively the composite samples are prepared according to huppler s method huppler 1969 and subsequently loaded in the specially designed hassler type core holder which is constructed of a special alloy that allows penetration by the x rays used to monitor saturation changes during the steady state experiments the composite samples are brought to test conditions and then x ray scanned at 100 co2 saturation the absolute permeability to co2 is determined by injecting co2 at different constant flow rates and measuring the pressure drop in the composite samples at each flow rate the composite samples are subsequently vacuum saturated with a brine of the desired salinity containing 73 g l sodium iodide as the x ray blocker the samples are then x ray scanned at 100 brine saturation while determining brine permeability at three flow rates the systems are elevated to reservoir conditions the temperature of 252 f 122 c and fluid pressure of 5 000 psi 34 47 mpa co2 and brine used in the flooding experiments are pre equilibrated at the temperature and pressure of the experiment to avoid mass transfer between the phases during the co injection and inside the composite samples prior to the flooding experiments co2 and brine are fully saturated and their amounts are selected based on their mutual solubility wiebe and gaddy 1941 seo et al 2011 duan and sun 2003 to start the drainage experiments the non equilibrated brine is displaced by equilibrated brine 100 co2 saturated brine in the composite samples the samples are then x ray scanned at 100 equilibrated brine saturation while determining brine permeability at three flow rates following that the equilibrated brine and equilibrated co2 are then injected simultaneously at several increasing fractional flow f co 2 co2 flow rate divided by total flow rate to allow the gas saturation within the samples to increase saturation changes are monitored by x ray scan every 0 5 pv injection the injection is continued at each fractional flow until steady state in terms of the saturation profile and differential pressure within the samples is established flow rates and pressure differences are monitored throughout the tests at the final stage of drainage 100 co2 is injected while scanning the samples and effective permeability to gas at residual brine saturation is determined at two injection rates data presented in tables 4a and 4b in the supplementary material the systems are then cooled to ambient temperature and depressurized and final x ray scans are taken subsequently the composites are unloaded and submitted to dean stark extraction leached of salts with methanol and dried to a constant weight in a vacuum oven measured flow rates and pressure differences at equilibrium for each brine gas injection ratio are used to calculate the steady state relative permeability data for each sample using eqs 5 and 6 the co2 and brine saturations are determined by the x ray attenuation method using x ray scans measured at each saturation and base scans at 100 saturations from the following equation akbarabadi and piri 2013 1 s co 2 c t e x c t b s a t c t co 2 s a t c t b s a t s b 1 s co 2 where c t b s a t and c t co 2 s a t are the x ray attenuations for the sample saturated with brine and co2 respectively ct ex is the ct number of an image obtained from a partially saturated sample during the experiment to perform the imbibition tests the injection is reconnected to the bottom of the composite samples and the baseline saturation scan is performed the pressure drop has been monitored and the saturation scan is done every 0 5 pv the fractional flow step is continued until scans indicate no change in the saturation profile at any point by more than 2 of saturation other fractional flow steps are conducted and the corresponding pressure drop and saturation profile are recorded at steady state the details of the fractional flows and pressure drops during the imbibition tests are shown in tables 5a and 5b in the supplementary material capillary pressure measurements have been done on two horizontal 4 h and 5 h and two vertical core samples 1v and 2v the experiments are performed in a beckman j 6b high speed centrifuge at the effective stress of 5 000 psi maximum speed is chosen so as to achieve a bond number below 1e 5 sufficient time is allowed to ensure equilibrium at each spin speed tests are conducted at the same temperature as the relative permeability experiments the primary drainage experiments are conducted using 7 speed steps after maintaining hydrostatic equilibrium the amount of brine produced from the core sample is measured from the produced brine its average saturation at each centrifuge speed is estimated the capillary pressure at the inlet is calculated using the centrifuge speed finally the capillary pressure is plotted against the brine saturation for horizontal and vertical core samples fig 13a 3 results and discussion 3 1 steady state co2 saturation profile a series of steady state drainage and imbibition experiments were performed on horizontal and vertical composite samples from the cranfield site fig 1a represents the single phase permeability to air as a function of porosity for seven different horizontal core samples and five different vertical core samples the detailed properties of these core samples are reported in table 1 in the supplementary material comparing the permeability of the samples indicates that the permeability can represent different values in various directions in the same formation to correct absolute gas air permeability for the klinkenberg effect permeability of each sample was measured multiple times at different pore pressures and then extrapolated to infinite pressure al jabri et al 2015 the klinkenberg corrected gas permeability for different horizontal kkh and vertical kkv samples is shown in fig 1b the klinkenberg permeability is plotted against gas permeability fig 1c and dummytxdummy the following correlations are found for correcting gas permeability of horizontal and vertical samples 2 k k h 0 762 k a h 1 034 3 k k v 0 815 k a v 0 993 where kah and kav are absolute gas permeabilities for horizontal and vertical samples the difference between the measured gas permeability and the klinkenberg permeability arises from the slippage effect which was initially proposed by klinkenberg for gas flow in porous media klinkenberg 1941 the steady state core flooding experiments have been carried out by co injection of co2 and brine into horizontal and vertical composite core samples of tuscaloosa sandstone the porosity and permeability of the composite samples are presented in tables 2 and 3 in the supplementary material even though the porosity of the horizontal composite sample is less than that of the vertical sample its absolute permeability to brine kbh is around ten times greater than that measured for the vertical sample kbv yielding kbv kbh ratio of 0 09 this suggests that in the horizontal sample the pores are well connected and contribute significantly to fluid flow this anisotropy with respect to permeability appears to be the result of the lamina scale fabric of the samples and the sedimentary features in the sandstone formation halvorsen 1993 weber and van guens 1990 fig 2 a depicts the slice averaged porosity profile along the length for both horizontal and vertical composite samples as can be seen there is a significant variation in the porosity of the samples the same porosity heterogeneity has been observed in other core samples of krevor et al 2012 the average porosities of the horizontal and vertical cores are 26 1 1 48 and 27 6 1 1 respectively the degree of variation in the porosity of the horizontal sample is greater than the vertical sample the heterogeneity in the porosities of the samples indicates the strati graphic variation along their length the micro ct images of the cross sections of horizontal and vertical samples along their lengths see fig 2b represent a layered heterogeneity in their structure these ct images demonstrate the direction of laminations in each sample this shows that the rock is composed of alternating fine and coarse grain layers the effect of these laminated structures on co2 and brine distributions and relative permeability curves is shown soon after as previously indicated co2 and brine were chosen as the fluids flowing through the brine saturated core samples in drainage and subsequent imbibition experiments during the drainage experiment the co2 saturated brine injection has been done at different fractional flows under the reservoir conditions the co injection at each step is continued until a steady state is achieved and the brine production and the differential pressure across the samples become constant the total injection rate for drainage experiments has been increased to 706 27 ml hr and 101 52 ml hr for horizontal and vertical samples respectively these values correspond to the large injection rates near injection wells in the final stage of the drainage experiment pure co2 is injected through the sample when the steady state was reached during the final stage of the drainage test the sample is subjected to a bump flow through an increase in the co2 flow rate the rate of the bump flow which is based on the measurement range of transducers is chosen to control the capillary number this step is necessary to verify the endpoint relative permeability and the presence of any end effect induced by capillary presser discontinuity at the end of the primary drainage cycle the steady state imbibition experiments have been performed with co injection of co2 and brine the final stage of the imbibition test involved the injection of 100 brine through the sample the fractional flow as a function of co2 saturation during the drainage and imbibition in horizontal and vertical composite samples is shown in fig 3 the steady state sliced averaged co2 saturation profiles in the horizontal and vertical composite samples during drainage and imbibition experiments are shown in figs 4 and 5 respectively the core averaged co2 saturation at each fractional flow applied in the experiments are reported in tables 4 and 5 in the supplementary material the non smooth saturation distributions throughout the samples are representative of their non homogeneous structures and porosity variations in the composites at each stage of the drainage experiment the steady state co2 saturation profile in the horizontal sample shows a smaller gradient in the saturation than the profiles for the vertical sample flooding in the vertical composite sample has been performed perpendicular to the bedding of the rock thus the spikes in the saturation profiles of the vertical sample are sharper than those in the horizontal one the distinction between the co2 saturation profiles in the horizontal and vertical samples arises from capillary pressure differences attributed to the lamination orientation the differences in capillary pressure curves for horizontal and vertical core plug samples fig 13a indicate this fact in the case of the horizontal composite sample at the first stage of the drainage experiment f co 2 0 05 the average co2 saturation increases to 0 0402 whereas for the vertical sample in spite of the initially small flow rate f co 2 0 04 there is a significant increase in the co2 saturation 0 1917 for the horizontal sample the lamination structure is parallel to the flow direction and displacing the brine through the low permeability lamina layers cannot be easily achieved because of the large capillary pressure of the small porosity layers co2 might bypass those regions leading to the smaller change in the saturation of co2 bachu and bennion 2008 bachu 2013 thus at small injection rates the saturation of co2 increases slightly in the horizontal sample compared with the vertical one hence the sweep efficiency is not the same in different directions comparing the dependence of core averaged co2 saturation on the fractional flow fig 3a for horizontal and vertical samples during drainage experiments indicates that at equivalent gas fractional flow the co2 saturation in the vertical sample is greater than that in the horizontal sample in other words the co2 sweep efficiency in the vertical sample is higher than the one for the horizontal one this could be because of the back filling of the pore space behind the laminated layers in the vertical sample the residual brine saturation at the end of the drainage cycle is large for both horizontal and vertical samples this value is 0 672 for the horizontal sample and 0 636 for the vertical one the experimentally observed residual brine saturations are larger than those reported for other rock types with a homogeneous texture such as berea sandstone krevor et al 2012 niu et al 2015 the sliced average co2 saturation variations during the imbibition cycle indicate that there is an abrupt change in the co2 saturation of the vertical sample at the initial step of flow injection compared with the horizontal sample see fig 5 the main reason for this is the fact that the low porosity layers with high capillary entry pressures are aligned parallel to the flow direction and induce high resistance to the fluid movement and even bypass during imbibition in the horizontal sample huang et al 1995 as the co2 saturation profile for the vertical sample during the last cycle of the imbibition process fig 5b indicates at the upstream locations the co2 saturation is almost zero in other words the high injection rate high capillary number leads to the complete sweeping of co2 in the upstream as fig 5b shows there is a large co2 saturation contrast between the upstream and downstream layers of the vertical sample this gradient in the saturation is indicative of the capillary end effect and suggests that capillary heterogeneity controls the gas distribution downstream the co2 saturation profiles during the imbibition tests are used to compare the residual trapping characteristics of the vertical and horizontal samples the land trapping model land 1968 has been used to show the relationship between the initial saturation of co2 s 0 co 2 before imbibition and its residual saturation s r co 2 during 100 brine flooding 4 s r co 2 s 0 co 2 1 c s 0 co 2 where c is the land s coefficient we considered s 0 co 2 as the co2 saturation at the beginning of the imbibition test and s r co 2 as the co2 saturation at the end of imbibition cycle when c 0 it means co2 is completely trapped and while c it means no co2 is trapped so a larger value of c means a lower trapping efficiency to make the initial residual ir curve we use a range of residual saturation which is observed along the sample length corresponding to the range of initial saturation existing prior to the imbibition cycle the ir curves for the horizontal and vertical samples have been shown in fig 1 in the supplementary material the trapping coefficient c is found to be 2 68 and 7 76 for the horizontal and vertical composite samples respectively the large difference between the trapping coefficient of the horizontal sample and the vertical one arises from the higher injection rate during the imbibition cycle in the vertical sample 46 74 ml hr compared with the injection rate in the horizontal sample 35 73 ml hr at large injection rates the viscous force is dominant over the capillary force and triggers the displacement of the trapped co2 the dependence of residual trapping on the imbibition rate has been studied previously zuo and benson 2014 the experimental data show that even though the initial co2 saturation during the imbibition for the vertical sample is higher than the one for the horizontal sample the residual co2 saturation in the vertical sample is lower than the one in the horizontal sample at the end of the imbibition cycle lower capability of the vertical sample for co2 trapping than that one for the horizontal sample does not represent the risk of leakage in the storage formation in other words the present study only covers the fluid transport in a limited number of samples within the storage formation and hence to better understand the trapping characteristics of the entire formation further tests need to be done on a large number of samples in general we can conclude that the trapping characteristics of the rocks are highly directional dependence for instance in the tuscaloosa sample the trapping is stronger in the horizontal direction consequently the trapping capacity of the rock for the co2 plume immobilization during the injection period with dominant viscous forces causing mostly the horizontal flow is different from the post injection period with dominant buoyancy forces and vertical direction flow as the dependence of co2 saturation on porosity represents fig 6 the saturation of co2 in the horizontal sample is better correlated with the porosity in most of the regions of the sample in other words the saturation of co2 in high porosity regions is higher than that in low porosity regions whereas the correlation is poor in the vertical composite sample specifically at the last stage of drainage this indicates that the distribution of pores and hence capillary heterogeneity play key roles in controlling the saturation distribution pini and benson 2017 the brine production at various fractional flows during drainage tests for both horizontal and vertical composite samples is shown in fig 7 a results indicate that drainage in the vertical sample yields more brine production even though the co2 injection rates for the horizontal sample are higher than the one for the vertical sample see tables 4a and 4b in the supplementary material the higher residual brine saturation in the horizontal sample after the flooding supports this finding fig 7b shows the co2 production during the imbibition process in both horizontal and vertical samples the gas production during the imbibition in the vertical sample is higher than the production from the horizontal sample this causes a smaller residual co2 saturation in the vertical sample compared with the horizontal one 3 2 steady state relative permeability and capillary pressure the steady state relative permeability to co2 and brine can be obtained using the extended darcy s law krevor et al 2012 chen et al 2017 5 k r co 2 q co 2 μ co 2 l k b a δ p 6 k r b q b μ b l k b a δ p where k r co 2 and k r b are the relative permeability to co2 and brine kb is the single phase permeability to brine l and a are the length and the cross sectional area of the sample μ co 2 and μb are the viscosity of co2 and brine assumed constant q co 2 and qb are the flow rates of co2 and brine and δp is the pressure drop at each step of the experiment measured flow rates of co2 and brine and pressure drops at the equilibrium condition for each fractional flow during drainage and imbibition see tables 4a 4b 5a and 5b in the supplementary material have been used to calculate the steady state relative permeability curves for each sample the results have been shown in fig 8 for the horizontal and vertical composite samples the curves corresponding to the drainage of horizontal and vertical samples indicate that there is a sharp drop in the brine permeability as a small increase in the co2 saturation occurs this phenomenon is mainly because of the heterogeneous and laminated structure of the rock containing low porosity bedding planes with high capillary pressures that resist fluid flow this type of behavior has been also observed in sandstone formations with poorly sorted grains krevor et al 2012 dullien 1992 furthermore results show that the rate of decrease in the brine relative permeability in the horizontal sample is greater than that in the vertical sample consequently the brine saturation has not reached below 60 in the drainage experiments in each sample as the results show the co2 endpoint relative permeability during drainage for the vertical sample is below one the high residual brine saturation and low endpoint relative permeability to co2 are characteristics of the co2 brine system and have been observed in previous studies as well bachu and bennion 2008 perrin and benson 2010 bachu and bennion 2008 claimed that the interfacial tension ift plays an important role in controlling the relative permeability of the phases müller 2011 suggested that the low endpoint permeability of co2 and incomplete fluid displacement could be because of the structural heterogeneity or capillary end effects we attribute the low endpoint relative permeability of co2 observed in our drainage experiments to the higher capillary pressure that might have achieved in the vertical sample compare capillary pressure curves for horizontal and vertical core plugs presented in fig 13a this capillary pressure effect leads to the significant blockage of the co2 flow causing small co2 relative permeability furthermore the experimental data show that the endpoint drainage relative permeability of co2 for the horizontal sample exceeds one indicating that the permeability of co2 is enhanced by the presence of brine during the last step of the drainage test the non wetting phase co2 predominantly occupies the pore space and the wetting phase brine covers the rock surface as a thin layer the presence of the smaller layer of brine on the surface induces a slip boundary condition for the flow and causes an increase in the co2 flux and hence its relative permeability berg et al 2008 karabakal and bagci 2004 we also found that the crossover points of the drainage curves are above the 50 brine saturation that is typical of water wet systems craig 1971 the drainage and imbibition relative permeability curves represent different hysteresis trends a strong hysteric behavior is observed in relative permeability curves for the horizontal sample and appears to be influenced by the pore structure and different types of heterogeneity the brooks corey model has been used to fit the experimental drainage and imbibition relative permeability data the model is given by krevor et al 2012 brooks and corey 1964 al menhali et al 2015 7 k r b k r b max s b n b 8 k r co 2 k r co 2 max 1 s b n co 2 9 s b s b s r b 1 s r b s r co 2 where s b is the brine effective saturation s r b is the residual brine saturation at the end of the drainage cycle s r co 2 is the residual co2 saturation at the end of the imbibition cycle and nb and n co 2 are the corey exponents for brine and co2 respectively k r b max and k r co 2 max are the brine and co2 endpoint relative permeabilities although the brooks corey model was developed for a uniform system the model has been used by other researchers to model the relative permeability data in a heterogeneous sample such as tuscaloosa sandstone krevor et al 2012 this model is fitted to the drainage and imbibition relative permeability data for the horizontal and vertical composite samples for the curve fitting the drainage relative permeability data for the horizontal sample is normalized to obtain the endpoint drainage relative permeability equal to unity steady state drainage and imbibition relative permeability measured experimentally are compared with the best fit brooks corey model in fig 8 for both horizontal and vertical samples the agreement between the model and the experimental data is reasonable the brooks corey parameters are presented in tables 1 and 2 for drainage and imbibition tests respectively moreover we use another model proposed by corey et al for the relative permeability in laminated samples and fit the model to the drainage and imbibition relative permeability data for the horizontal and vertical composite samples the model is given by corey and rathjens 1956 10 k r b s b e 4 11 k r co 2 1 s b e 2 1 s b e 2 12 s b e s b s r b 1 s r b fig 9 represents the fits of the experimental data to the prediction of this model shown as model 2 this figure also compares the corey model predictions with the ones obtained by the brooks corey model model 1 results indicate that both models predict almost the same trend for the drainage relative permeability however the brooks corey model provides a better prediction for the imbibition relative permeability data to better show the anisotropic behavior of relative permeability the co2 and brine relative permeability curves for horizontal and vertical samples during drainage and imbibition are compared in fig 10 a and b respectively the results indicate that the relative permeability is directionally dependent the brine relative permeability curve is steeper when the flow is along the bedding orientation in the horizontal sample moreover the results show that co2 relative permeability represents more anisotropy than the brine relative permeability such anisotropic behavior of relative permeability can have a potential bearing on the field scale numerical simulations carried out in estimating co2 distribution during geological storage therefore it is crucial to consider appropriate relative permeability curves which are representative of the actual structural heterogeneity in a reservoir using measured values of co2 drainage relative permeability k r co 2 and brine saturation sb we calculate apparent values of brine effective saturation s b c using eq 11 these calculated values s b c are then plotted as a function of brine saturation sb and shown in fig 11 according to the definition of brine effective saturation eq 12 the ideal plot of s b c versus sb should follow a straight line we follow the same procedure using the brooks corey model eqs 8 and 9 and plot the same curve the results have been shown in fig 11 for horizontal and vertical samples using drainage gas relative permeability data the best straight lines that can fit the measured data have been shown with dashed lines in the figure if the curves are extrapolated to s b c 0 and s b c 1 the corresponding values of sb indicate s r b residual brine saturation and sm the lowest brine saturation at which the gas tortuosity is infinite respectively all curves extrapolate to values of sm greater than unity this deviation arises from the stratification parallel and perpendicular to flow in horizontal and vertical samples corey et al have shown that cores with uniform and isotropic structures represent values of sm 1 corey and rathjens 1956 to characterize the displacement patterns in the core flooding experiments the capillary number ca is calculated using the following equation virnovsky et al 2004 13 c a δ p l h δ p c where δp is the viscous pressure drop in the core during flooding and δpc is the characteristic difference in the capillary pressure h and l are core length scales in transverse and principal directions respectively the pressure drop measured during steady state drainage experiments in horizontal and vertical samples presented in tables 4a and 4b in the supplementary material has been used in the calculation of ca since the distribution of entry capillary pressure which represents the capillary heterogeneity of the samples is not available we use the capillary entry pressure values shown in fig 13a as the average of δpc in the calculations the calculated ca for our primary drainage experiments on vertical and horizontal samples are shown in fig 12 and compared with the data reported for steady state drainage co2 brine core floods in the literature al menhali et al 2015 reynolds and krevor 2015 performed an extensive study on the co2 brine drainage relative permeability data sets available in the literature and compared their capillary numbers they found that all reported relative permeability curves have been measured in the capillary dominated regime and the transition to viscous limited regime occurs at ca greater than 100 other studies might have reported smaller values of capillary number for the transition zone since their definition of capillary number is different from what is considered in reynolds and krevor 2015 the transition area from capillary to the viscous regime is shaded with gray in fig 12 the capillary numbers calculated in our study fall below c a 100 and thus all reported co2 brine relative permeability curves in this study are measured under capillary dominated conditions accordingly the multiphase flow behavior is strongly affected by the capillary heterogeneity of the samples which causes heterogeneity in the fluid distribution within the samples and the measured relative permeability curves which can be seen in the presented results co2 brine drainage centrifuge capillary pressure experiments have been carried out on two horizontal 4h and 5h and two vertical 1v and 2v core samples of the tuscaloosa sandstone the properties of the samples are reported in table 1 in the supplementary material fig 13a represents the co2 brine capillary pressure pc versus the brine endpoint saturation for different horizontal and vertical samples in the figure the experimentally measured capillary pressure data symbols in fig 13a are compared with the brooks corey model curves in fig 13a brooks and corey 1964 14 p c p e s b 1 λ where pe is the entry capillary pressure and λ represents the pore size distribution index pe λ and s r b are considered as the parameters that are calculated by fitting the experimental data with the model the corresponding estimated parameters of the model for different core samples are reported in table 3 the model agrees reasonably with the experimental data for all samples the capillary pressure curves are distinct from each other the differences between the curves for horizontal samples are broader than the ones for vertical samples this suggests the higher degree of heterogeneity in the horizontal direction compared with the vertical one comparing our capillary pressure data with a previous study krevor et al 2012 on other types of rocks indicates that for the equivalent range of saturation the capillary pressure in the tuscaloosa sample is higher than the one in those rock samples as table 3 represents distinct values of fitting parameters including entry capillary pressure residual water saturation and pore size distribution index are observed for various samples these distinctions reflect the influence of various heterogeneity on the capillary pressure curve thus the heterogeneity and the orientation of laminations with respect to the flow axis seem to have significant impacts on the degree of capillarity of the co2 brine system during drainage the capillary pressure experimental data have been scaled using dimensionless leverett j function relationship pini et al 2012 15 j p c σ cos θ k abs ϕ where σ represents the interfacial tension and θ is the contact angle j function which was proposed by leverett 1941 is a way to represent the capillary pressure curves for different permeabilities porosities interfacial tensions by a single curve fig 13 b shows the j function versus brine saturation for various horizontal and vertical core samples the results indicate that the behavior of j function is not the same for the horizontal and vertical directions the stronger capillary heterogeneity for the horizontal core samples is representative of more heterogeneity in the horizontal direction this finding is consistent with the higher degree of variations in the porosity profile in the horizontal direction as shown in fig 2a 4 conclusion the present experimental work captures the directional variability of relative permeability which is present in the actual field scenario but often neglected in the estimation of the relative permeability of co2 brine we investigate the effect of heterogeneous stratification on the anisotropic behavior of relative permeability curves as well as capillary pressure data through the flooding experiments on the horizontal drilled parallel to the lamination structure and vertical composite samples drilled normal to the lamination of the tuscaloosa sandstone from an actual co2 injection site in mississippi the results show that the small scale lamination exerts a significant influence on multiphase flow properties such as relative permeability and capillary pressure the relative permeability curves represent anisotropic behavior for the horizontal sample in which the flow is parallel to the bedding plane the permeability is controlled by the highly permeable layers whereas for the vertical sample the low permeable layers act as barriers and control the vertical permeability it is also found that the drainage efficiency is stronger in the vertical direction in which flow is perpendicular to the bedding planes moreover the capillary pressure saturation curves for different horizontal core samples are not identical this capillary heterogeneity reflects the structural heterogeneity and stratification at the core scale for vertical core samples the capillary heterogeneity is still available although the spread of capillary pressure saturation curves is narrow the stronger capillary heterogeneity for horizontal core samples is representative of more heterogeneity in the horizontal direction consequently neglecting the directional dependence of relative permeability in subsurface reservoirs could adversely affect the prediction of field scale studies for co2 plume migration in other words the relative permeability curves that can adequately predict the co2 plume behavior during its injection with dominant viscous forces and horizontal fluid flow cannot be applied for the post injection period that fluid mostly flow in the vertical direction due to the dominant buoyancy force furthermore the upscaling of these anisotropic properties measured experimentally and analyzing their effects on field scale performance requires having knowledge of the structure of the whole reservoir however the core scale experimental studies provide a quantitative analysis of the effect of small scale stratification on relative permeability curves and help gain a better understanding of the phenomena leading to the anisotropic behavior of multiphase flow properties credit authorship contribution statement sahar bakhshian conceptualization data curation writing original draft writing review editing seyyed a hosseini conceptualization data curation writing original draft writing review editing larry w lake conceptualization data curation writing original draft writing review editing declaration of competing interest the authors have no affiliation with any organization with a direct or indirect financial interest in the subject matter discussed in the manuscript acknowledgments the authors are grateful to anonymous reviewers and beg internal reviewers this work was supported by the secarb project managed by the southern states energy board and funded by the u s department of energy netl under contract numbers de fc26 05nt42590 and de fe0024433 publication authorized by the director bureau of economic geology jackson school of geosciences the university of texas at austin supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103464 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
541,relative permeability and capillary pressure are known as essential properties that have substantial impacts on the accuracy of reservoir simulations the effect of small scale heterogeneity and lamination in the rock structure is often ignored during the measurement of capillary pressure and relative permeability curves in core samples this study highlights the remarkable impact of anisotropy on the multiphase flow properties of stratified formations a series of steady state co2 brine drainage and imbibition tests are conducted at reservoir conditions in horizontal and vertical core samples of the tuscaloosa sandstone from the cranfield co2 injection site in mississippi the relative permeability curves represent an anisotropic behavior influenced by the heterogeneous and laminated structure of realistic rock samples the co2 saturation profiles during drainage and imbibition cycles indicate that the phase distribution in the pore space is controlled by core scale heterogeneity in the porosity distribution among the laminations that causes capillary pressure inhomogeneity using the saturation profile during the imbibition cycle the trapping characteristic of the horizontal and vertical rock samples are compared and we found that the capillary trapping is less likely in the vertical direction furthermore the centrifuge measured capillary pressure demonstrates distinctive characteristics for horizontal and vertical core samples since the flooding experiments are performed under capillary controlled flow the capillary pressure contrast in the laminated structure of the rock strongly affects the relative permeability the presented results can potentially improve the accuracy of the large scale simulations for the co2 post injection period in which the vertical displacement has an important role in the plume migration keywords relative permeability anisotropy core flooding experiment co2 sequestration 1 introduction geological storage of co2 in deep saline aquifers unminable coal seams and depleted oil and gas reservoirs represents a feasible solution for mitigating global warming shaffer 2010 bakhshian et al 2018 birkholzer et al 2015 bakhshian and sahimi 2017 dashtian et al 2019 2017 among these storage formations saline aquifers are the best option for long term geo sequestration because of their large storage potential and immediate accessibility mathias et al 2009 hayek et al 2009 choi et al 2013 having knowledge regarding the migration of co2 plumes their trapping mechanisms and degree of trapping in subsurface reservoirs is important to the design of co2 injection the prediction of co2 behavior during its storage and assessment of the security aspects of underground sequestration core scale experiments and numerical simulations are primary tools for investigating multiphase flow properties such as co2 saturation distribution trapping mechanisms and relative permeability bachu and bennion 2008 silin et al 2011 berg et al 2011 bennion and bachu 2008 bakhshian and hosseini 2019 bakhshian et al 2019 the poverty of relative permeability data is one of the issues in co2 storage imbus et al 2006 thus a detailed investigation in this area is required to better understand the multiphase flow characteristics in co2 brine flow understanding the anisotropic behavior of transport properties such as relative permeability is important in predicting the performance of flow in subsurface reservoirs the anisotropic characteristics have been usually neglected in laboratory measurements of relative permeability studies have shown that the directional dependence of fluid properties may arise from small scale heterogeneity induced by the sedimentary structure of rocks as well as from buoyancy effects prats and lake 2008 heterogeneous features of rock such as laminationas often cause anisotropy however they are not a necessary condition prats and lake 2008 claimed that the directional dependence of relative permeability can be observed because of buoyancy and flow direction even in homogeneous and isotropic rocks adebayo et al 2017 studied the effect of gravity and flow direction on multiphase flow properties such as relative permeability and residual saturation of homogeneous rock samples during core flooding tests at small flow rates their experiments highlight the interplay between capillarity and gravity in rock samples and demonstrate the anisotropic behavior of relative permeability unpredicted observations during field scale injections of co2 such as co2 plume shape early breakthrough and injectivity abnormalities have raised questions about the role of geological heterogeneity on multiphase flow the microscopic structure of rocks is typically heterogeneous which arises from mineral grains with various shapes and bedding planes planar beds of stratification along a preferential direction resulting from the original structure of the formation or induced by external stress fields young claimed that cross stratified sediment and shale are two main geological features which induce the anisotropy characteristics to the reservoirs young 1989 the small scale heterogeneity and anisotropy of rocks strongly affect the macroscopic properties such as permeability and capillarity wright et al 2006 clavaud et al 2008 zoback and byerlee 1976 holcomb and olsson 2003 moreover the orientation of the stratified layers at field scale induces anisotropy to the fluid flow characteristics through compartmentalization of the reservoir chandler et al 1989 rogers and grigg 2001 proposed that injectivity abnormalities during co2 flooding projects may arise from heterogeneity heterogeneous stratification in uncorrelated media causes a reduction of co2 channeling through the high permeability layers and slower co2 breakthrough roper et al 1992 hovorka et al 2004 claimed that the geological heterogeneity could lead to longer residence times and improved sequestration effectiveness the small scale heterogeneous structure of the rock has a remarkable impact on the directional dependence of permeability fields the anisotropic behavior of the relative permeability cannot be ignored in capillary controlled flow under which the small scale heterogeneity of the rock structure has a significant impact on the co2 displacement corey and rathjens 1956 corey and rathjens 1956 have shown that at a given saturation the relative permeability for fluid flow perpendicular to bedding planes is smaller than for flow parallel to the bedding it is claimed that the degree of anisotropy strongly depends on the measurement scales young 1989 kortekaas 1985 studied the oil water displacement characteristics as well as the directional dependence of relative permeability and capillary pressure curves in a cross bedded reservoir zone they showed that the small scale laminated geometry of the reservoir strongly affects the prediction of oil recovery gregersen and johannessen 2007 have done a study on the geological structure of the neogene utsira sand at the norwegian sleipner field and have suggested a channel like feature formed with a north south trend inducing permeability anisotropy in the formation the northward extension of the co2 plume obtained from seismic data confirms the anisotropic behavior gregersen 1998 zhu et al 2015 while there are extensive studies on the multiphase flow of co2 and brine in rock samples some questions remain unresolved one uncertainty includes the effect of structural and stratigraphic heterogeneity on the anisotropic behavior of relative permeability the present study takes a step further and presents an extensive experimental study to address the effect of bedding strata on flow characteristics in rock samples the objective of the present study is to investigate the influence of stratigraphic heterogeneity on the directional behavior of relative permeability and fluid saturation distribution in the tuscaloosa rock samples taken from the cranfield site in mississippi lu et al 2012 hosseini et al 2013 two horizontal and vertical composite samples of tuscaloosa are prepared through combining multiple core plugs taken from the same facies at the same depth of the cranfield site a series of steady state co2 brine drainage and imbibition tests are conducted in horizontal and vertical composite samples at reservoir pressure and temperature with fluids flowing parallel and perpendicular to the bedding structure of the rock the fluid distributions of supercritical co2 and brine during the co2 drainage and the brine imbibition are recorded using x ray scanning we also discuss the effect of stratification on anisotropic behavior of relative permeability curves and endpoint saturations additionally we present centrifuge capillary pressure measurements performed on various horizontal and vertical core samples 2 experimental procedure the cylindrical plug samples used in the experiments are cut horizontally and vertically to attain surfaces at different angles to the bedding lamination of the tuscaloosa formation the plug samples are extracted from the injection well cfu31f 1 located in the cranfield site lu et al 2012 sun et al 2016 we attempted to drill the samples from the same facies at the same depth the detailed properties of these core plug samples are reported in table 1 in the supplementary material the samples were cleaned and vacuum dried to a constant weight gas air permeability and porosity were measured on the cleaned and dried samples at 3400 psi 23 4 mpa net confining stress see fig 1 a the horizontal and vertical samples used in the flooding experiments are composite cores which consist of seven horizontal core plugs 1 h 2 h 3 h 4 h 5 h 6 h and 7 h reported in table 1 supplementary material and four vertical core plugs 1v 2v 3v and 5v reported in table 1 supplementary material tables 2 and 3 in the supplementary material summarize the properties of horizontal and vertical composite samples respectively the composite samples are prepared according to huppler s method huppler 1969 and subsequently loaded in the specially designed hassler type core holder which is constructed of a special alloy that allows penetration by the x rays used to monitor saturation changes during the steady state experiments the composite samples are brought to test conditions and then x ray scanned at 100 co2 saturation the absolute permeability to co2 is determined by injecting co2 at different constant flow rates and measuring the pressure drop in the composite samples at each flow rate the composite samples are subsequently vacuum saturated with a brine of the desired salinity containing 73 g l sodium iodide as the x ray blocker the samples are then x ray scanned at 100 brine saturation while determining brine permeability at three flow rates the systems are elevated to reservoir conditions the temperature of 252 f 122 c and fluid pressure of 5 000 psi 34 47 mpa co2 and brine used in the flooding experiments are pre equilibrated at the temperature and pressure of the experiment to avoid mass transfer between the phases during the co injection and inside the composite samples prior to the flooding experiments co2 and brine are fully saturated and their amounts are selected based on their mutual solubility wiebe and gaddy 1941 seo et al 2011 duan and sun 2003 to start the drainage experiments the non equilibrated brine is displaced by equilibrated brine 100 co2 saturated brine in the composite samples the samples are then x ray scanned at 100 equilibrated brine saturation while determining brine permeability at three flow rates following that the equilibrated brine and equilibrated co2 are then injected simultaneously at several increasing fractional flow f co 2 co2 flow rate divided by total flow rate to allow the gas saturation within the samples to increase saturation changes are monitored by x ray scan every 0 5 pv injection the injection is continued at each fractional flow until steady state in terms of the saturation profile and differential pressure within the samples is established flow rates and pressure differences are monitored throughout the tests at the final stage of drainage 100 co2 is injected while scanning the samples and effective permeability to gas at residual brine saturation is determined at two injection rates data presented in tables 4a and 4b in the supplementary material the systems are then cooled to ambient temperature and depressurized and final x ray scans are taken subsequently the composites are unloaded and submitted to dean stark extraction leached of salts with methanol and dried to a constant weight in a vacuum oven measured flow rates and pressure differences at equilibrium for each brine gas injection ratio are used to calculate the steady state relative permeability data for each sample using eqs 5 and 6 the co2 and brine saturations are determined by the x ray attenuation method using x ray scans measured at each saturation and base scans at 100 saturations from the following equation akbarabadi and piri 2013 1 s co 2 c t e x c t b s a t c t co 2 s a t c t b s a t s b 1 s co 2 where c t b s a t and c t co 2 s a t are the x ray attenuations for the sample saturated with brine and co2 respectively ct ex is the ct number of an image obtained from a partially saturated sample during the experiment to perform the imbibition tests the injection is reconnected to the bottom of the composite samples and the baseline saturation scan is performed the pressure drop has been monitored and the saturation scan is done every 0 5 pv the fractional flow step is continued until scans indicate no change in the saturation profile at any point by more than 2 of saturation other fractional flow steps are conducted and the corresponding pressure drop and saturation profile are recorded at steady state the details of the fractional flows and pressure drops during the imbibition tests are shown in tables 5a and 5b in the supplementary material capillary pressure measurements have been done on two horizontal 4 h and 5 h and two vertical core samples 1v and 2v the experiments are performed in a beckman j 6b high speed centrifuge at the effective stress of 5 000 psi maximum speed is chosen so as to achieve a bond number below 1e 5 sufficient time is allowed to ensure equilibrium at each spin speed tests are conducted at the same temperature as the relative permeability experiments the primary drainage experiments are conducted using 7 speed steps after maintaining hydrostatic equilibrium the amount of brine produced from the core sample is measured from the produced brine its average saturation at each centrifuge speed is estimated the capillary pressure at the inlet is calculated using the centrifuge speed finally the capillary pressure is plotted against the brine saturation for horizontal and vertical core samples fig 13a 3 results and discussion 3 1 steady state co2 saturation profile a series of steady state drainage and imbibition experiments were performed on horizontal and vertical composite samples from the cranfield site fig 1a represents the single phase permeability to air as a function of porosity for seven different horizontal core samples and five different vertical core samples the detailed properties of these core samples are reported in table 1 in the supplementary material comparing the permeability of the samples indicates that the permeability can represent different values in various directions in the same formation to correct absolute gas air permeability for the klinkenberg effect permeability of each sample was measured multiple times at different pore pressures and then extrapolated to infinite pressure al jabri et al 2015 the klinkenberg corrected gas permeability for different horizontal kkh and vertical kkv samples is shown in fig 1b the klinkenberg permeability is plotted against gas permeability fig 1c and dummytxdummy the following correlations are found for correcting gas permeability of horizontal and vertical samples 2 k k h 0 762 k a h 1 034 3 k k v 0 815 k a v 0 993 where kah and kav are absolute gas permeabilities for horizontal and vertical samples the difference between the measured gas permeability and the klinkenberg permeability arises from the slippage effect which was initially proposed by klinkenberg for gas flow in porous media klinkenberg 1941 the steady state core flooding experiments have been carried out by co injection of co2 and brine into horizontal and vertical composite core samples of tuscaloosa sandstone the porosity and permeability of the composite samples are presented in tables 2 and 3 in the supplementary material even though the porosity of the horizontal composite sample is less than that of the vertical sample its absolute permeability to brine kbh is around ten times greater than that measured for the vertical sample kbv yielding kbv kbh ratio of 0 09 this suggests that in the horizontal sample the pores are well connected and contribute significantly to fluid flow this anisotropy with respect to permeability appears to be the result of the lamina scale fabric of the samples and the sedimentary features in the sandstone formation halvorsen 1993 weber and van guens 1990 fig 2 a depicts the slice averaged porosity profile along the length for both horizontal and vertical composite samples as can be seen there is a significant variation in the porosity of the samples the same porosity heterogeneity has been observed in other core samples of krevor et al 2012 the average porosities of the horizontal and vertical cores are 26 1 1 48 and 27 6 1 1 respectively the degree of variation in the porosity of the horizontal sample is greater than the vertical sample the heterogeneity in the porosities of the samples indicates the strati graphic variation along their length the micro ct images of the cross sections of horizontal and vertical samples along their lengths see fig 2b represent a layered heterogeneity in their structure these ct images demonstrate the direction of laminations in each sample this shows that the rock is composed of alternating fine and coarse grain layers the effect of these laminated structures on co2 and brine distributions and relative permeability curves is shown soon after as previously indicated co2 and brine were chosen as the fluids flowing through the brine saturated core samples in drainage and subsequent imbibition experiments during the drainage experiment the co2 saturated brine injection has been done at different fractional flows under the reservoir conditions the co injection at each step is continued until a steady state is achieved and the brine production and the differential pressure across the samples become constant the total injection rate for drainage experiments has been increased to 706 27 ml hr and 101 52 ml hr for horizontal and vertical samples respectively these values correspond to the large injection rates near injection wells in the final stage of the drainage experiment pure co2 is injected through the sample when the steady state was reached during the final stage of the drainage test the sample is subjected to a bump flow through an increase in the co2 flow rate the rate of the bump flow which is based on the measurement range of transducers is chosen to control the capillary number this step is necessary to verify the endpoint relative permeability and the presence of any end effect induced by capillary presser discontinuity at the end of the primary drainage cycle the steady state imbibition experiments have been performed with co injection of co2 and brine the final stage of the imbibition test involved the injection of 100 brine through the sample the fractional flow as a function of co2 saturation during the drainage and imbibition in horizontal and vertical composite samples is shown in fig 3 the steady state sliced averaged co2 saturation profiles in the horizontal and vertical composite samples during drainage and imbibition experiments are shown in figs 4 and 5 respectively the core averaged co2 saturation at each fractional flow applied in the experiments are reported in tables 4 and 5 in the supplementary material the non smooth saturation distributions throughout the samples are representative of their non homogeneous structures and porosity variations in the composites at each stage of the drainage experiment the steady state co2 saturation profile in the horizontal sample shows a smaller gradient in the saturation than the profiles for the vertical sample flooding in the vertical composite sample has been performed perpendicular to the bedding of the rock thus the spikes in the saturation profiles of the vertical sample are sharper than those in the horizontal one the distinction between the co2 saturation profiles in the horizontal and vertical samples arises from capillary pressure differences attributed to the lamination orientation the differences in capillary pressure curves for horizontal and vertical core plug samples fig 13a indicate this fact in the case of the horizontal composite sample at the first stage of the drainage experiment f co 2 0 05 the average co2 saturation increases to 0 0402 whereas for the vertical sample in spite of the initially small flow rate f co 2 0 04 there is a significant increase in the co2 saturation 0 1917 for the horizontal sample the lamination structure is parallel to the flow direction and displacing the brine through the low permeability lamina layers cannot be easily achieved because of the large capillary pressure of the small porosity layers co2 might bypass those regions leading to the smaller change in the saturation of co2 bachu and bennion 2008 bachu 2013 thus at small injection rates the saturation of co2 increases slightly in the horizontal sample compared with the vertical one hence the sweep efficiency is not the same in different directions comparing the dependence of core averaged co2 saturation on the fractional flow fig 3a for horizontal and vertical samples during drainage experiments indicates that at equivalent gas fractional flow the co2 saturation in the vertical sample is greater than that in the horizontal sample in other words the co2 sweep efficiency in the vertical sample is higher than the one for the horizontal one this could be because of the back filling of the pore space behind the laminated layers in the vertical sample the residual brine saturation at the end of the drainage cycle is large for both horizontal and vertical samples this value is 0 672 for the horizontal sample and 0 636 for the vertical one the experimentally observed residual brine saturations are larger than those reported for other rock types with a homogeneous texture such as berea sandstone krevor et al 2012 niu et al 2015 the sliced average co2 saturation variations during the imbibition cycle indicate that there is an abrupt change in the co2 saturation of the vertical sample at the initial step of flow injection compared with the horizontal sample see fig 5 the main reason for this is the fact that the low porosity layers with high capillary entry pressures are aligned parallel to the flow direction and induce high resistance to the fluid movement and even bypass during imbibition in the horizontal sample huang et al 1995 as the co2 saturation profile for the vertical sample during the last cycle of the imbibition process fig 5b indicates at the upstream locations the co2 saturation is almost zero in other words the high injection rate high capillary number leads to the complete sweeping of co2 in the upstream as fig 5b shows there is a large co2 saturation contrast between the upstream and downstream layers of the vertical sample this gradient in the saturation is indicative of the capillary end effect and suggests that capillary heterogeneity controls the gas distribution downstream the co2 saturation profiles during the imbibition tests are used to compare the residual trapping characteristics of the vertical and horizontal samples the land trapping model land 1968 has been used to show the relationship between the initial saturation of co2 s 0 co 2 before imbibition and its residual saturation s r co 2 during 100 brine flooding 4 s r co 2 s 0 co 2 1 c s 0 co 2 where c is the land s coefficient we considered s 0 co 2 as the co2 saturation at the beginning of the imbibition test and s r co 2 as the co2 saturation at the end of imbibition cycle when c 0 it means co2 is completely trapped and while c it means no co2 is trapped so a larger value of c means a lower trapping efficiency to make the initial residual ir curve we use a range of residual saturation which is observed along the sample length corresponding to the range of initial saturation existing prior to the imbibition cycle the ir curves for the horizontal and vertical samples have been shown in fig 1 in the supplementary material the trapping coefficient c is found to be 2 68 and 7 76 for the horizontal and vertical composite samples respectively the large difference between the trapping coefficient of the horizontal sample and the vertical one arises from the higher injection rate during the imbibition cycle in the vertical sample 46 74 ml hr compared with the injection rate in the horizontal sample 35 73 ml hr at large injection rates the viscous force is dominant over the capillary force and triggers the displacement of the trapped co2 the dependence of residual trapping on the imbibition rate has been studied previously zuo and benson 2014 the experimental data show that even though the initial co2 saturation during the imbibition for the vertical sample is higher than the one for the horizontal sample the residual co2 saturation in the vertical sample is lower than the one in the horizontal sample at the end of the imbibition cycle lower capability of the vertical sample for co2 trapping than that one for the horizontal sample does not represent the risk of leakage in the storage formation in other words the present study only covers the fluid transport in a limited number of samples within the storage formation and hence to better understand the trapping characteristics of the entire formation further tests need to be done on a large number of samples in general we can conclude that the trapping characteristics of the rocks are highly directional dependence for instance in the tuscaloosa sample the trapping is stronger in the horizontal direction consequently the trapping capacity of the rock for the co2 plume immobilization during the injection period with dominant viscous forces causing mostly the horizontal flow is different from the post injection period with dominant buoyancy forces and vertical direction flow as the dependence of co2 saturation on porosity represents fig 6 the saturation of co2 in the horizontal sample is better correlated with the porosity in most of the regions of the sample in other words the saturation of co2 in high porosity regions is higher than that in low porosity regions whereas the correlation is poor in the vertical composite sample specifically at the last stage of drainage this indicates that the distribution of pores and hence capillary heterogeneity play key roles in controlling the saturation distribution pini and benson 2017 the brine production at various fractional flows during drainage tests for both horizontal and vertical composite samples is shown in fig 7 a results indicate that drainage in the vertical sample yields more brine production even though the co2 injection rates for the horizontal sample are higher than the one for the vertical sample see tables 4a and 4b in the supplementary material the higher residual brine saturation in the horizontal sample after the flooding supports this finding fig 7b shows the co2 production during the imbibition process in both horizontal and vertical samples the gas production during the imbibition in the vertical sample is higher than the production from the horizontal sample this causes a smaller residual co2 saturation in the vertical sample compared with the horizontal one 3 2 steady state relative permeability and capillary pressure the steady state relative permeability to co2 and brine can be obtained using the extended darcy s law krevor et al 2012 chen et al 2017 5 k r co 2 q co 2 μ co 2 l k b a δ p 6 k r b q b μ b l k b a δ p where k r co 2 and k r b are the relative permeability to co2 and brine kb is the single phase permeability to brine l and a are the length and the cross sectional area of the sample μ co 2 and μb are the viscosity of co2 and brine assumed constant q co 2 and qb are the flow rates of co2 and brine and δp is the pressure drop at each step of the experiment measured flow rates of co2 and brine and pressure drops at the equilibrium condition for each fractional flow during drainage and imbibition see tables 4a 4b 5a and 5b in the supplementary material have been used to calculate the steady state relative permeability curves for each sample the results have been shown in fig 8 for the horizontal and vertical composite samples the curves corresponding to the drainage of horizontal and vertical samples indicate that there is a sharp drop in the brine permeability as a small increase in the co2 saturation occurs this phenomenon is mainly because of the heterogeneous and laminated structure of the rock containing low porosity bedding planes with high capillary pressures that resist fluid flow this type of behavior has been also observed in sandstone formations with poorly sorted grains krevor et al 2012 dullien 1992 furthermore results show that the rate of decrease in the brine relative permeability in the horizontal sample is greater than that in the vertical sample consequently the brine saturation has not reached below 60 in the drainage experiments in each sample as the results show the co2 endpoint relative permeability during drainage for the vertical sample is below one the high residual brine saturation and low endpoint relative permeability to co2 are characteristics of the co2 brine system and have been observed in previous studies as well bachu and bennion 2008 perrin and benson 2010 bachu and bennion 2008 claimed that the interfacial tension ift plays an important role in controlling the relative permeability of the phases müller 2011 suggested that the low endpoint permeability of co2 and incomplete fluid displacement could be because of the structural heterogeneity or capillary end effects we attribute the low endpoint relative permeability of co2 observed in our drainage experiments to the higher capillary pressure that might have achieved in the vertical sample compare capillary pressure curves for horizontal and vertical core plugs presented in fig 13a this capillary pressure effect leads to the significant blockage of the co2 flow causing small co2 relative permeability furthermore the experimental data show that the endpoint drainage relative permeability of co2 for the horizontal sample exceeds one indicating that the permeability of co2 is enhanced by the presence of brine during the last step of the drainage test the non wetting phase co2 predominantly occupies the pore space and the wetting phase brine covers the rock surface as a thin layer the presence of the smaller layer of brine on the surface induces a slip boundary condition for the flow and causes an increase in the co2 flux and hence its relative permeability berg et al 2008 karabakal and bagci 2004 we also found that the crossover points of the drainage curves are above the 50 brine saturation that is typical of water wet systems craig 1971 the drainage and imbibition relative permeability curves represent different hysteresis trends a strong hysteric behavior is observed in relative permeability curves for the horizontal sample and appears to be influenced by the pore structure and different types of heterogeneity the brooks corey model has been used to fit the experimental drainage and imbibition relative permeability data the model is given by krevor et al 2012 brooks and corey 1964 al menhali et al 2015 7 k r b k r b max s b n b 8 k r co 2 k r co 2 max 1 s b n co 2 9 s b s b s r b 1 s r b s r co 2 where s b is the brine effective saturation s r b is the residual brine saturation at the end of the drainage cycle s r co 2 is the residual co2 saturation at the end of the imbibition cycle and nb and n co 2 are the corey exponents for brine and co2 respectively k r b max and k r co 2 max are the brine and co2 endpoint relative permeabilities although the brooks corey model was developed for a uniform system the model has been used by other researchers to model the relative permeability data in a heterogeneous sample such as tuscaloosa sandstone krevor et al 2012 this model is fitted to the drainage and imbibition relative permeability data for the horizontal and vertical composite samples for the curve fitting the drainage relative permeability data for the horizontal sample is normalized to obtain the endpoint drainage relative permeability equal to unity steady state drainage and imbibition relative permeability measured experimentally are compared with the best fit brooks corey model in fig 8 for both horizontal and vertical samples the agreement between the model and the experimental data is reasonable the brooks corey parameters are presented in tables 1 and 2 for drainage and imbibition tests respectively moreover we use another model proposed by corey et al for the relative permeability in laminated samples and fit the model to the drainage and imbibition relative permeability data for the horizontal and vertical composite samples the model is given by corey and rathjens 1956 10 k r b s b e 4 11 k r co 2 1 s b e 2 1 s b e 2 12 s b e s b s r b 1 s r b fig 9 represents the fits of the experimental data to the prediction of this model shown as model 2 this figure also compares the corey model predictions with the ones obtained by the brooks corey model model 1 results indicate that both models predict almost the same trend for the drainage relative permeability however the brooks corey model provides a better prediction for the imbibition relative permeability data to better show the anisotropic behavior of relative permeability the co2 and brine relative permeability curves for horizontal and vertical samples during drainage and imbibition are compared in fig 10 a and b respectively the results indicate that the relative permeability is directionally dependent the brine relative permeability curve is steeper when the flow is along the bedding orientation in the horizontal sample moreover the results show that co2 relative permeability represents more anisotropy than the brine relative permeability such anisotropic behavior of relative permeability can have a potential bearing on the field scale numerical simulations carried out in estimating co2 distribution during geological storage therefore it is crucial to consider appropriate relative permeability curves which are representative of the actual structural heterogeneity in a reservoir using measured values of co2 drainage relative permeability k r co 2 and brine saturation sb we calculate apparent values of brine effective saturation s b c using eq 11 these calculated values s b c are then plotted as a function of brine saturation sb and shown in fig 11 according to the definition of brine effective saturation eq 12 the ideal plot of s b c versus sb should follow a straight line we follow the same procedure using the brooks corey model eqs 8 and 9 and plot the same curve the results have been shown in fig 11 for horizontal and vertical samples using drainage gas relative permeability data the best straight lines that can fit the measured data have been shown with dashed lines in the figure if the curves are extrapolated to s b c 0 and s b c 1 the corresponding values of sb indicate s r b residual brine saturation and sm the lowest brine saturation at which the gas tortuosity is infinite respectively all curves extrapolate to values of sm greater than unity this deviation arises from the stratification parallel and perpendicular to flow in horizontal and vertical samples corey et al have shown that cores with uniform and isotropic structures represent values of sm 1 corey and rathjens 1956 to characterize the displacement patterns in the core flooding experiments the capillary number ca is calculated using the following equation virnovsky et al 2004 13 c a δ p l h δ p c where δp is the viscous pressure drop in the core during flooding and δpc is the characteristic difference in the capillary pressure h and l are core length scales in transverse and principal directions respectively the pressure drop measured during steady state drainage experiments in horizontal and vertical samples presented in tables 4a and 4b in the supplementary material has been used in the calculation of ca since the distribution of entry capillary pressure which represents the capillary heterogeneity of the samples is not available we use the capillary entry pressure values shown in fig 13a as the average of δpc in the calculations the calculated ca for our primary drainage experiments on vertical and horizontal samples are shown in fig 12 and compared with the data reported for steady state drainage co2 brine core floods in the literature al menhali et al 2015 reynolds and krevor 2015 performed an extensive study on the co2 brine drainage relative permeability data sets available in the literature and compared their capillary numbers they found that all reported relative permeability curves have been measured in the capillary dominated regime and the transition to viscous limited regime occurs at ca greater than 100 other studies might have reported smaller values of capillary number for the transition zone since their definition of capillary number is different from what is considered in reynolds and krevor 2015 the transition area from capillary to the viscous regime is shaded with gray in fig 12 the capillary numbers calculated in our study fall below c a 100 and thus all reported co2 brine relative permeability curves in this study are measured under capillary dominated conditions accordingly the multiphase flow behavior is strongly affected by the capillary heterogeneity of the samples which causes heterogeneity in the fluid distribution within the samples and the measured relative permeability curves which can be seen in the presented results co2 brine drainage centrifuge capillary pressure experiments have been carried out on two horizontal 4h and 5h and two vertical 1v and 2v core samples of the tuscaloosa sandstone the properties of the samples are reported in table 1 in the supplementary material fig 13a represents the co2 brine capillary pressure pc versus the brine endpoint saturation for different horizontal and vertical samples in the figure the experimentally measured capillary pressure data symbols in fig 13a are compared with the brooks corey model curves in fig 13a brooks and corey 1964 14 p c p e s b 1 λ where pe is the entry capillary pressure and λ represents the pore size distribution index pe λ and s r b are considered as the parameters that are calculated by fitting the experimental data with the model the corresponding estimated parameters of the model for different core samples are reported in table 3 the model agrees reasonably with the experimental data for all samples the capillary pressure curves are distinct from each other the differences between the curves for horizontal samples are broader than the ones for vertical samples this suggests the higher degree of heterogeneity in the horizontal direction compared with the vertical one comparing our capillary pressure data with a previous study krevor et al 2012 on other types of rocks indicates that for the equivalent range of saturation the capillary pressure in the tuscaloosa sample is higher than the one in those rock samples as table 3 represents distinct values of fitting parameters including entry capillary pressure residual water saturation and pore size distribution index are observed for various samples these distinctions reflect the influence of various heterogeneity on the capillary pressure curve thus the heterogeneity and the orientation of laminations with respect to the flow axis seem to have significant impacts on the degree of capillarity of the co2 brine system during drainage the capillary pressure experimental data have been scaled using dimensionless leverett j function relationship pini et al 2012 15 j p c σ cos θ k abs ϕ where σ represents the interfacial tension and θ is the contact angle j function which was proposed by leverett 1941 is a way to represent the capillary pressure curves for different permeabilities porosities interfacial tensions by a single curve fig 13 b shows the j function versus brine saturation for various horizontal and vertical core samples the results indicate that the behavior of j function is not the same for the horizontal and vertical directions the stronger capillary heterogeneity for the horizontal core samples is representative of more heterogeneity in the horizontal direction this finding is consistent with the higher degree of variations in the porosity profile in the horizontal direction as shown in fig 2a 4 conclusion the present experimental work captures the directional variability of relative permeability which is present in the actual field scenario but often neglected in the estimation of the relative permeability of co2 brine we investigate the effect of heterogeneous stratification on the anisotropic behavior of relative permeability curves as well as capillary pressure data through the flooding experiments on the horizontal drilled parallel to the lamination structure and vertical composite samples drilled normal to the lamination of the tuscaloosa sandstone from an actual co2 injection site in mississippi the results show that the small scale lamination exerts a significant influence on multiphase flow properties such as relative permeability and capillary pressure the relative permeability curves represent anisotropic behavior for the horizontal sample in which the flow is parallel to the bedding plane the permeability is controlled by the highly permeable layers whereas for the vertical sample the low permeable layers act as barriers and control the vertical permeability it is also found that the drainage efficiency is stronger in the vertical direction in which flow is perpendicular to the bedding planes moreover the capillary pressure saturation curves for different horizontal core samples are not identical this capillary heterogeneity reflects the structural heterogeneity and stratification at the core scale for vertical core samples the capillary heterogeneity is still available although the spread of capillary pressure saturation curves is narrow the stronger capillary heterogeneity for horizontal core samples is representative of more heterogeneity in the horizontal direction consequently neglecting the directional dependence of relative permeability in subsurface reservoirs could adversely affect the prediction of field scale studies for co2 plume migration in other words the relative permeability curves that can adequately predict the co2 plume behavior during its injection with dominant viscous forces and horizontal fluid flow cannot be applied for the post injection period that fluid mostly flow in the vertical direction due to the dominant buoyancy force furthermore the upscaling of these anisotropic properties measured experimentally and analyzing their effects on field scale performance requires having knowledge of the structure of the whole reservoir however the core scale experimental studies provide a quantitative analysis of the effect of small scale stratification on relative permeability curves and help gain a better understanding of the phenomena leading to the anisotropic behavior of multiphase flow properties credit authorship contribution statement sahar bakhshian conceptualization data curation writing original draft writing review editing seyyed a hosseini conceptualization data curation writing original draft writing review editing larry w lake conceptualization data curation writing original draft writing review editing declaration of competing interest the authors have no affiliation with any organization with a direct or indirect financial interest in the subject matter discussed in the manuscript acknowledgments the authors are grateful to anonymous reviewers and beg internal reviewers this work was supported by the secarb project managed by the southern states energy board and funded by the u s department of energy netl under contract numbers de fc26 05nt42590 and de fe0024433 publication authorized by the director bureau of economic geology jackson school of geosciences the university of texas at austin supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103464 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
542,pore scale velocity and turbulence structures near streambeds may control solute transport and dispersion in streams in this study pore scale flow and transport simulations are performed to investigate the effects of pore scale processes on anomalous transport which is often manifested by remarkably long residence times of solute particles in coupled free flow and porous media systems by solving the 2d reynolds averaged navier stokes equations integrated with a renormalization group k ε turbulence model we resolve complex pore scale flows featured by vortices and preferential flows then we incorporate the simulated velocity and turbulence fields into a lagrangian particle tracking model that considers advection turbulent diffusion and molecular diffusion simulation results reveal that the interplay between pore scale vortices and turbulence structures near the free flow permeable bed interface controls anomalous transport high porosity induces strong turbulence penetration and preferential flow paths within permeable beds the enhanced subsurface turbulence facilitates the escape of solute particles from recirculation zones via turbulent diffusion causing steep power law slopes in breakthrough curves btcs in contrast low porosity introduces heavy tailing in btcs from particles that are trapped in the near interface recirculation zones characterized by low velocities and limited turbulence we upscale and predict particle transport via a spatial markov model smm honoring the interplay between lagrangian velocity distribution and velocity correlation the smm reproduces anomalous transport behaviors obtained from the numerical simulations these results demonstrate that lagrangian velocity statistics effectively encode anomalous transport mechanisms in the coupled systems keywords anomalous transport free flow porous media interface pore scale simulation recirculation zone turbulence structures spatial markov model 1 introduction fluid flow and transport in coupled free flow and porous media systems is of great importance due to its wide applicability in natural and industrial processes such as nuclear waste storage and fuel cells you and liu 2002 bourgeat et al 2009 environmental engineering including flow and pollutant dispersion over aquatic canopies and porous beds in rivers as well as buildings in urban areas zhou and mendoza 1993 britter and hanna 2003 nepf 2012 and biological systems of biofilm formation landa marbán et al 2019 flow and mixing of surface and subsurface waters in a permeable bed also termed hyporheic flow is of particular interest in hydrology hyporheic flow is an essential hydrodynamic process controlling fluid flow mass transport and mixing in rivers and streams harvey et al 1996 elliott and brooks 1997 packman et al 2004 streamflows are typified by fast turbulent flows in a free flow layer and slow laminar flows in a porous layer however turbulence in surface water can extend to a shallow portion of the porous media defined as a turbulent transition layer corresponding to a non darcy flow regime as described in fig 1 nagaoka and ohgaki 1990 pokrajac et al 2007 manes et al 2009 nevertheless conventional models often assume that hyporheic flow is laminar modeling it as darcy flow wörman et al 2002 cardenas and wilson 2007 bottacin busolin and marion 2010 engdahl et al 2010 hester et al 2013 hester et al 2019 these approaches often underestimate the hyporheic exchange rate by orders of magnitude particularly in gravel beds with high permeability o connor et al 2008 o connor et al 2012 this is mainly because the extended turbulence into the transition layer commonly ignored in typical models significantly contributes to mass transfer across the free flow porous media interface higashino and stefan 2011 roche et al 2018 voermans et al 2018 to accurately model the effects of hyporheic exchange on solute transport in hydrologic systems it is critical to improve our mechanistic understanding of turbulent flow and transport through the free flow porous media interface velocimetry techniques like particle image velocimetry piv and laser doppler velocimetry ldv are increasingly being employed in exploring flow interactions between a free stream and a permeable bed goharzadeh et al 2005 liu et al 2008 pokrajac and manes 2009 blois et al 2012 yang et al 2015 kim et al 2018 wu and mirbod 2018 a common observation from these experiments is that turbulent shear stress is maximized at the free flow porous media interface with the strong interfacial turbulence causing extension of the turbulence structure into permeable beds from the experimental findings we can infer that solutes may significantly disperse into and out of the streambed by interfacial turbulent mixing of surface and subsurface waters during such an exchange process retarded subsurface velocities increase residence times of the solutes thereby producing anomalous non fickian transport in streams fernald et al 2001 cardenas 2008a aubeneau et al 2014 the key features of the anomalous transport are the unusually early arrival of tracers downstream and remarkably long residence time of tracers in field tracer tests breakthrough curves btcs commonly exhibit anomalous late time tailings attributed to the turbulent hyporheic exchange which cannot be described with fickian advection dispersion equation ade models harvey and bencala 1993 haggerty et al 2002 jonsson et al 2003 aubeneau et al 2014 recent studies investigated interfacial solute transport across the interface between the free flow region and the porous media region at darcy scale aquino et al 2015 li et al 2017 and roche et al 2019 implemented particle tracking methods on theoretically and experimentally derived profiles of streamwise velocity and turbulent diffusion by assuming that solute particles are only advected with positive streamwise velocities sherman et al 2019 simulated particle trajectories subject to instantaneous flow fields from direct numerical simulation dns modeling subsurface flows with the drag coefficient representing flow resistance like a darcy model these studies however modeled subsurface flows using simple analytical solutions or with a drag force term without directly considering or resolving the interfacial mass transfer phenomenon at the pore scale these macroscale approaches may underestimate the inertial effects of complex pore scale flow fields including preferential flows and vortices on particle transport several studies based on piv measurements revealed that vortices recirculation zones emerge at pore spaces between coarse grains beneath open channel flows blois et al 2012 kim et al 2018 the recirculation zones often act as transient storage zones where solutes are trapped and released slowly into channel flows highlighting a possible source of anomalous transport cardenas et al 2007 cardenas 2008b crevacore et al 2016 zhou et al 2019 therefore explicitly resolving subsurface flow structures at the pore scale is necessary to better understand the non fickian nature of transport in hyporheic flows some studies involved fully resolved pore scale flow simulations of coupled turbulent free flow and porous media flow where the porous media is idealized with an array of cubic or spherical grains the flow simulation were performed using reynolds averaged navier stokes rans equations with turbulence models like a standard k ε model and a reynolds stress model prinos et al 2003 yang et al 2018 as well as large eddy simulation leonardi et al 2018 fang et al 2018 lian et al 2019 and dns breugem and boersma 2005 kuwata and suga 2017 these studies suggest that recirculating flow structures dominate flow in some portions of porous media and moreover geometric characteristics like subsurface porosity strongly correlate to the size of these pore scale vortices yet these studies only involved flow analysis without studying transport phenomena thus the effects of the pore scale flow patterns on solute transport through the free flow porous media interface remain largely unknown the goal of this study is to evaluate the effects of the complex interplay between pore scale velocity and turbulence structures near the free flow porous media interfaces on flow and mass transport through coupled free flow and porous media systems more specifically we investigate how the pore scale flow structures such as vortices and preferential flows influence anomalous transport in a coupled free flow and porous media system in this study we fully resolve pore scale flow fields directly coupled with overlying turbulent free flows by solving 2d rans equations incorporating a turbulence model we first validate this hydrodynamic model with the experimental data prinos et al 2003 and then apply this model to investigate cases with different porosities and a wide range of reynolds numbers based on simulated velocity and turbulence fields we perform particle tracking simulations involving advection turbulent diffusion and molecular diffusion to advance fundamental understanding of flow and transport through free flow porous media interfaces we then perform the detailed analysis to elucidate the influence of pore scale vortices on anomalous transport finally we upscale solute transport using a stochastic random walk model parametrized with particle trajectory information from the numerical simulations and then conduct predictions of effective transport using the upscaled model 2 methods 2 1 hydrodynamic model we analyze mean and turbulent flow characteristics in coupled free flow and porous media systems using the open source fluid dynamics library openfoam which adopts a finite volume method for solving governing equations we use 2d rans equations as the governing equations for fluid flow 2d turbulence models can provide the general picture of the turbulent flows when one spatial direction is considerably constrained by geometry or applied body forces boffetta and ecke 2012 xia and francois 2017 2d turbulence model is relevant in this study because the mass exchange between the free flow zone and the porous media zone is mostly triggered by the vertical flows boano et al 2014 gomez velez and harvey 2014 unsteady forms of continuity and momentum equations in einstein notation in cartesian coordinates can be written as 1a u i x i 0 1b u i t u j u i x j 1 ρ p x i x j ν u i x j u j x i x j u i u j s i where ui and uj are the time averaged velocity vectors in the xi and xj directions of cartesian coordinates respectively herein xi and xj represent x axis and y axis properties when i j 1 while xi and xj denote y axis and x axis properties when i j 2 p is the fluid pressure ρ is the density of the fluid ν is the kinematic viscosity of the fluid ui and uj are the fluctuating velocity vectors in the xi and xj directions respectively si is the source term representing the pressure gradient to drive the flow in addition u i u j indicates the reynolds stress a product of the reynolds decomposition and the term should be modeled with turbulence closure models the rans turbulence models employ an eddy viscosity concept derived from boussinesq approximation which relates reynolds stresses to mean properties of turbulent flows a standard k ε model is one of the most widely used turbulence models in environmental hydraulics applications because of its good convergence with a minor computational overhead mößner and radespiel 2015 to close the governing equations this turbulence model includes two additional transport equations to solve for turbulent quantities of flows such as turbulent kinetic energy k and its dissipation rate ε nevertheless this conventional method has a limitation in accurately reproducing complex wall bounded flows at low reynolds number owing to the overestimation of an eddy viscosity shih et al 1995 hence we adopt a renormalization group rng k ε model yakhot et al 1992 to enhance the accuracy of flow simulation in the free flow and porous media systems the rng k ε model better resolves the near wall turbulent flows and many studies have reported that the model adequately reproduces flow characteristics near wall regions such as recirculation zones speziale and thangam et al 1992 dargahi 2006 cassan and belaud 2011 sinha et al 2017 the corresponding transport equations for k and ε are as follows 2a t ρ k x i ρ k u j x j μ μ t σ k k x j g k ρ ε s k 2b t ρ ε x i ρ ε u j x j μ μ t σ ε ε x j ε k c 1 ε g k c 2 ε ρ ε s ε where c 1ε σ k and σε are the empirical constants set to 1 42 0 7194 and 0 7194 respectively yakhot et al 1992 μ and μ t are the molecular viscosity and the dynamic turbulent viscosity respectively gk is the generation of turbulent kinetic energy arising from the mean velocity gradients sk and s ε are the moduli of the mean rate of strain tensors of k and ε respectively the main difference from the standard k ε model is that the rng k ε model treats c 2ε as a variable parameter to consider the different scales of motion by changing the production term which can be expressed as 3 c 2 ε c 2 ε c μ η 1 η η 0 1 β η 3 where c 2ε c μ β and η0 are constants set to 1 68 0 09 0 012 and 4 38 respectively yakhot et al 1992 the variable parameter η is obtained as 4 η k ε 2 s i j s i j where sij is the strain rate tensor 2 2 particle tracking model we simulate transport and spreading of solute particles using a 2d lagrangian particle tracking lpt model particle motion is governed by advection molecular diffusion and turbulent diffusion across the free flow porous media interface o connor and harvey 2008 voermans et al 2018 in consequence the particle trajectories are determined by the stochastic langevin equation described as follows in einstein notation 5 x i p t δ t x i p t u i x i p t u i x i p t δ t ξ i t 2 d m δ t where x i p is the particle position ξ i t is the unit gaussian distributed random number and dm is the molecular diffusion coefficient the fluctuating velocity ui in eq 5 characterizes turbulent diffusion whose length scale is usually much larger than that of molecular diffusion so that the former typically governs solute mixing in rivers and streams rutherford 1994 however the effects of molecular diffusion can be important in porous media and we consider both turbulent diffusion and molecular diffusion in this study since ui is not directly available from the rans simulation we apply a discrete random walk drw technique gosman and loannides 1983 to consider the effects of turbulent mixing on particle trajectories we model turbulent diffusion of particles as a succession of interactions between particles and eddies which have the finite length and time scales dehbi 2008 the drw method incorporates the mean turbulent flow properties and has been shown to successfully reproduce particle dispersion in environmental flows shams et al 2002 tian and ahmadi 2007 gao et al 2012 jayaraju et al 2015 according to the drw method ui can be coupled with k obtained from the flow simulation where k is the space dependent variable as follows 6 u i x i p t ζ i t 2 k 3 where ζ i t is the unit gaussian distributed random number for the velocity perturbation which is temporally varying so that ζ i t is updated after each eddy lifetime τ e defined as 7 τ e c μ 3 4 k ε ln r where r is the random number between zero and unity thus particles are assumed to be interacting with an eddy which has a constant value of ζ i during τ e when the time from the origin time of the eddy exceeds τ e another particle eddy interaction is generated by introducing new values of ζ i and τ e rybalko et al 2012 this process is repeated to consider spatio temporal evolution of turbulent eddies 2 3 upscaled transport model spatial markov model we upscale interfacial solute transport phenomena with an upscaled stochastic transport model known as spatial markov model smm which honors spatial markov properties of lagrangian velocity transitions le borgne et al 2008 this effective random walk model which is parameterized with lagrangian velocity statistics has been successfully applied to predict anomalous transport across a broad range of flows le borgne et al 2011 de anna et al 2013 kang et al 2014 dentz et al 2016 sund et al 2017 this modeling framework incorporates lagrangian velocity statistics by honoring the interplay between velocity distribution and velocity correlation velocity distribution captures velocity heterogeneity with one point statistics and velocity correlation captures spatial memory of velocity transitions with two point statistics dentz and bolster 2010 kang et al 2015b the series of particle positions and travel times in streamwise direction are described as 8 x n 1 x n ℓ 9 t n 1 t n τ n where τ n ℓ v n is the successive transition time of particles over the fixed spatial jump ℓ at the finite step n which varies from zero to n total where n total is the channel length l divided by ℓ v n is the corresponding lagrangian velocity and we can characterize the velocity distribution using a probability density function pdf of τ p τ in the smm framework τ τ n is correlated to a particle transition time at a previous step τ τ n 1 as the transition times are shown to exhibit spatial markovianity if sampled in space le borgne et al 2008 hence τ can be modeled using a transition matrix that characterizes one step correlation to assess the transition probabilities from the particle trajectories simulated with the 2d lpt model we discretize p τ into n classes ci 1 i n where i increases with the increase in τ and further define the conditional probability density r τ τ in this study the transition times are discretized equidistance in logarithmic scale to provide a better discretization for small transition times that control long residence time of particles kang et al 2015a with these lagrangian properties the transition matrix is subsequently defined as le borgne et al 2008 10 t i j τ i τ i 1 τ j τ j 1 r τ τ p τ d τ d τ τ j τ j 1 p τ d τ where tij describes the transition probability from the current transition time class j to the next transition time class i 2 4 configuration of numerical experiments 2 4 1 model validation cases the rans simulation incorporating the rng k ε turbulence model yields time averaged properties of turbulent flows for the model validation we compare our simulation results with experimental data available from prinos et al 2003 they investigated the 2d mean and turbulent flow characteristics in a 10 m long and 0 25 m wide open channel with an underlying permeable bed consisting of regular rods with a diameter d 0 01 m in the non staggered pattern as shown in fig 2 table 1 displays the geometric and hydrodynamic characteristics of the flow the free flow depth hf is set to either 0 03 m or 0 05 m referred to as case 250 30 and case 250 50 respectively the porous layer depth hp is 0 055 m and porosity is 0 8286 with these experimental setups prinos et al 2003 also conducted the numerical simulation using the 2d rans equations based on the standard k ε turbulence model 2 4 2 study cases after validating the hydrodynamic model with the experimental data we further study two different subsurface porosity scenarios where porosity is either 0 5 or 0 8 as shown in fig 3 the diameter of grains is set to 0 01 m so that this setup can be considered as coarse gravel beds here hf and hp are fixed to 0 045 m and 0 075 m respectively in addition we vary reynolds number ref ufhf ν by varying the inlet velocity uin where uf denotes the mean velocity of the surface layer over 0 y hf 1 the values of ref vary approximately from 2 000 to 12 000 which lead to froude number fr u f g h f to vary between 0 11 and 0 59 the investigated fr values are observable values in natural stream environments most of natural streams flow at fr below 0 3 and the flow at fr above 0 6 are infrequently observed davidian and cahal 1963 the geometric and hydraulic conditions as well as the computational mesh resolution for each study case are summarized in table 2 by studying these cases we can assess the sensitivity of flow and transport dynamics to porosity and ref for the 2d lpt simulation the total particle number of 5 104 is uniformly injected at the inlet of the free flow layer in this study we consider tracer injection at streams and no particles are injected at the porous layer mimicking tracer injection at a stream the time step is set to values which retain the courant number cr ui δt δx less than unity and dm is fixed to 2 10 9 m2 s representing the typical molecular diffusivity of liquid phases li and gregory 1974 2 4 3 simulation conditions the computational meshes are composed of quadrilateral cells the dense grids satisfying the dimensionless wall distance y yu ν to be less than unity near the fluid grain interfaces are generated note that u g h f s is the shear velocity this grid refinement is necessary to ensure the application of the enhanced wall treatment for accurately simulating the flows in the boundary layers salim and cheah 2009 escue and cui 2010 the resolutions of generated meshes for the model validation and study cases are listed in tables 1 and 2 respectively we apply the periodic boundary conditions to simulate the mean and turbulent flows for representative computational domains as illustrated in fig 2 because the validation and study cases have periodically repeating geometries in the streamwise direction at the free surface zero shear slip wall the symmetry boundary condition is applied to honor the condition of no surface oscillation which is valid for fr less than unity subcritical flow at the solid fluid boundaries at the grain surfaces the no slip boundary conditions are used the convection diffusion and gradient terms of the momentum equation are discretized using the gauss linear scheme this second order and unbounded scheme is also used for discretizing the turbulence transport equations the backward scheme of the second order and implicit method handles the discretization of the time derivative term for which the time step δt is set to the value that satisfies cr to be less than 0 5 the pressure implicit split operator piso algorithm is employed for coupling pressure and velocity to ensure mass conservation prasad et al 2015 we simulate until ui p k and ε in eqs 1 and 2 converge to the steady state values corresponding to the fully developed flow condition these values at the steady state are used for further flow analysis and particle tracking simulation 3 results and discussion 3 1 results of model validation fig 4 shows vertical profiles of the mean velocity magnitude and the turbulent kinetic energy for case 250 30 and case 250 50 both the mean velocity and turbulent kinetic energy are normalized with u to directly compare our simulation results from the rng k ε turbulence model with the experimental and numerical data from prinos et al 2003 to calculate u we derive the hydraulic slope s from the streamwise pressure gradient associated with si in eq 1b as shown in fig 4a and b the presence of a permeable bed reduces the mean velocity in the free flow layer and produces the slip velocity at the free flow porous media interface due to the interfacial momentum exchange the rng k ε turbulence model accurately reproduces these effects of the permeable bed on the mean velocity of the surface water thereby showing better agreement with the experimental data compared to the standard k ε turbulence model yet relatively large discrepancies between the simulated velocity and the measured velocity are found adjacent to the interface these differences may be attributed to the fact that the porous layer of the experimental channel is not long enough to reach the fully developed flow as reported by prinos et al 2003 as aforementioned in the 2d lpt model the turbulent kinetic energy k in eq 2a is a critical variable that controls effective particle dispersion via turbulent diffusion thus it is critically important to accurately simulate turbulent kinetic energy profiles because the turbulent diffusion term in the 2d lpt model estimated by the turbulent kinetic energy as shown in eq 6 controls the particle dispersion into the porous media as shown in fig 4 the rng k ε turbulence model reproduces spatially varying behaviors of turbulence and estimates peak values of turbulent kinetic energy and their locations more accurately than the standard k ε turbulence model furthermore the interaction of the turbulent free flows with the permeable bed results in the enhanced interfacial turbulence propagating through the porous regions 3 2 analysis of hydrodynamics 3 2 1 mean and turbulent flow characteristics we apply the validated hydrodynamic model to explore the influence of porosity and ref on the turbulent flow characteristics over and within permeable beds using the study cases shown in table 2 fig 5 presents vertical profiles of the simulated mean velocity magnitude and turbulent kinetic energy for each study case the mean velocity of the permeable bed is significantly higher in the porosity of 0 8 than in the porosity of 0 5 fig 5a and b this is because the higher porosity corresponds to more flows through the permeable bed and accordingly relatively low surface velocity is obtained to honor mass conservation table 2 moreover fig 5b inset shows that porosity determines up uf where up is the mean velocity of the subsurface layer over 1 y hp 0 because of the strong preferential flow paths observed between grains for the high porosity cases the porosity of 0 8 yields up uf 0 1 which is one order of magnitude greater than a value of up uf 0 01 for the porosity of 0 5 on the other hand this velocity ratio tends to remain relatively constant with respect to uin because the mean velocity structures in the limited water depth are more dependent on porosity than ref goharzadeh et al 2005 wu and mirbod 2018 the porosity further plays a vital role in turbulence structures fig 5c and d show that the higher porosity induces the greater penetration of turbulent kinetic energy into the permeable bed in order to quantify the penetration extent of turbulent flows we calculate the penetration length scale of turbulent kinetic energy δ k normalized by pore diameter d as follows 11 δ k 1 k int u 2 d y 0 075 m y 0 m f y d y where f y indicates the vertical profile of k u 2 inside the porous regions and k int u 2 is k u 2 at the free flow porous media interface of y 0 m fig 5d inset shows that the porosity of 0 8 introduces δ k ranging 0 420 0 667 which is about three times the values of δ k ranging 0 172 0 187 for the porosity of 0 5 in the high porosity cases δ k slightly increases with increasing ref which is originated from the fluctuation of the small turbulent kinetic energy below y hp 0 2 in the turbulent kinetic energy profile fig 5d however the turbulent kinetic energy near the interface of y hp between 0 2 and 0 is less sensitive to ref this implies that slight increase in δ k may have negligible effects on solute transport because solute exchange between the free flow and porous layers mostly takes place in the vicinity of the interface in summary the flow analysis results indicate that velocity and turbulence structures are significantly more sensitive to porosity than ref 3 2 2 recirculation zones the exchange of momentum between free flow and permeable layers which is associated with the interfacial slip velocities and turbulence leads to the occurrence of recirculation zones beneath the free flow porous media interface breugem and boersma 2005 kuwata and suga 2017 as depicted in fig 6 this figure also shows the spatial maps of mean flow velocity and turbulent kinetic energy for case 5010 and case 8010 the structures of recirculation zones rely strongly on porosity as the high porosity bed produces a single large vortex while the low porosity bed produces a pair of relatively small vortices directly below the interface the vertical stretch of the first vortex from the interface squares with red dashed lines in fig 6 enlarges proportional to δ k and up uf extending to the porous depth of y hp 0 1 and y hp 0 05 for the porosity of 0 8 and 0 5 respectively this tendency is consistent with simulation results from yang et al 2018 who reported that the vortex size increases monotonously with an increase in up uf the length scale of the vortices may significantly affect interfacial mass transfer dynamics because the greater extent of the near interface recirculating flows can cause solutes to penetrate deeper into the porous regions as solute exchange between the free flow and the porous media mainly occurs near the interface due to the steep decay of interfacial turbulence towards the channel bed fig 5c and d the mean and turbulent flow characteristics of the near interface recirculation zones can be considered as one of the key factors governing mass transfer between the surface and subsurface layers as shown in fig 6 the higher mean velocity and the stronger turbulence are observed when the porosity increases for the vortex regions located within the first grain layer 0 133 y hp 0 the spatial averaged values of u u and k u 2 for the porosity 0 8 case are u u 0 58 and k u 2 0 91 respectively which are about 1 5 times the values of u u 0 34 and k u 2 0 65 for the porosity 0 5 case such difference in the properties of the recirculation zones would be originated from the interfacial momentum exchange intrinsic to porosity the slow recirculating flows with the diminished turbulence for the low porosity cases may result in the strong trapping effects of the pore scale vortices which can invoke the heavy tailing in btcs by not only increasing residence times of solutes but also restricting the solutes to escape from these recirculation zones the interaction between the recirculation zones and solute transport will be further discussed in section 3 3 3 3 3 analysis of transport dynamics 3 3 1 tracer breakthrough curves we now analyze transport behaviors using btcs residence time distributions fig 7 shows the btcs at the downstream station located at l 3m obtained from 2d lpt simulations note that particles can breakthrough through both the free flow and porous layers as discussed in section 3 2 1 the mean and turbulent flow structures governing the particle transport patterns are not sensitive to the change in ref this is further demonstrated by showing that the btcs normalized by uin can be collapsed for the different values of ref fig 7a and b insets the dotted lines in fig 7a and b show the btcs of particles that did not travel through porous media below y hp 0 before reaching the downstream stations the residence times of these particles are much shorter than those of the particles that interact with the porous layer solid lines in fig 7a and b this consequently reveals that solute exchange at the free flow porous media interface is the crucial dynamics responsible for anomalous transport patterns distinguished by the tailing behaviors in the btcs we investigate the effects of porosity on mass transfer of particles to the permeable bed by measuring the percent mass of particles accumulated in the porous regions msub which is defined as the number of particles in the porous layer divided by the number of injected particles for each time step during the simulation periods fig 8 shows that msub initially increases as time elapses and then converges to specific values for the porosity of 0 8 particles accumulate up to msub 16 which is almost twice the value of the porosity 0 5 cases this infers that the enhanced turbulence inside the high porosity bed stimulates the particles to enter more easily into the porous regions as expected whereas we cannot observe the significant difference in msub with the variation of ref interestingly despite the smaller number of the particles captured in the low porosity bed owing to the limited extent of turbulence penetration into the permeable bed the porosity of 0 5 introduces stronger tails in btcs compared to those of the porosity of 0 8 as shown in fig 9 a this seemingly contradictory behavior in the btcs can be explained by understanding the interplay between vortices and turbulence structures within the permeable bed once particles diffuse into the subsurface regions the particles are significantly more stagnant in the low porosity bed than in the high porosity bed due to the stronger trapping effects by the recirculation zones the strong trapping effects originate from the low velocities and limited turbulence which lead to the strong tailing in the btcs on the other hand the high porosity bed allows particles to easily escape from the recirculation zones with the enhanced subsurface turbulence and transport through the preferential flow paths as shown in fig 6b this key finding from the 2d lpt simulation is consistent with the result of field tracer tests from aubeneau et al 2014 who reported that pea gravel beds low porosity which produces low subsurface velocities resulted in longer retention times of solute tracers than coarse gravel beds high porosity 3 3 2 lagrangian velocity statistics we characterize the lagrangian velocity statistics using the lagrangian velocity distribution and correlation the motion of the solute particles is discretized equidistantly with the fixed spatial step of ℓ in the main flow direction accordingly the velocity distribution can be represented by the distribution of the transition times τ n ℓ v n as previously defined the transition times are sampled at every ℓ 0 05 m from the particle trajectories fig 9b shows the pdf of the transition times which represents the transition time distribution from this figure the probability of having the long transition times low velocities increases with the decreasing porosity leading to the heavy tailed transition time distribution furthermore fig 9 demonstrates that the transition time pdf has the power law slope identical to that of the corresponding btcs therefore this implies that the effects of porosity on the anomalous tailing behavior in the btcs are encoded adequately in the transition time distributions however the transition time distribution alone does not include the property of the spatial velocity correlation structure which is another key factor that determines the anomalous transport behavior de anna et al 2013 kang et al 2015b thus we first evaluate the velocity autocorrelation functions for the given lag χ s δs and then estimate the correlation length scale ℓ c by integrating χ s δs over the distance dentz et al 2016 kang et al 2017 fig 9b inset shows that ℓ c is larger for larger porosity cases this tendency would be the result of the fast preferential flows developed in the high porosity bed fig 6b which contributes to the increase in the velocity correlation the existence of the finite correlation length along the particle trajectories implies that the lagrangian velocities transition times can be effectively describes as a spatial markov process le borgne et al 2008 dentz et al 2016 kang et al 2017 to consider the velocity correlation effects the series of the transition times sampled in space is characterized using the transition matrix in eq 10 we construct the 30 30 transition matrix to adequately capture the entire ranges of correlation effects le borgne et al 2011 as shown in fig 10 herein each transition time class is spaced equidistantly in the log scale and we choose ℓ 0 05 m which is smaller than the characteristic correlation length scale ℓ c to properly resolve the velocity correlation structure the constructed transition matrix is used to evaluate the one step correlation between τ n and τ n 1 fig 10 shows that the correlation is stronger for the high velocities short transition times than for the low velocities long transition times the porosity exerts a significant impact on the transition matrices the transition matrix for the porosity of 0 8 shows the emergence of the strong velocity correlation in the transition time classes between 9 and 10 dashed box in fig 10b corresponding to the preferential flow paths in porous media fig 6b where advection is dominant over molecular diffusion and turbulent diffusion particles can transport with high subsurface velocities through these preferential flow paths as illustrated with the snapshot of velocity field overlain by particle trajectories in fig 10b the dashed box in fig 10a is the result of the recirculation zones attributed to the porosity of 0 5 which will be discussed in detail in section 3 3 3 3 3 3 effects of recirculation zones on transport in order to assess the contributions of pore scale vortices on effective particle transport we quantify particle residence times in these local recirculation zones by measuring travel times of particles within the flow separation regions enclosed by dividing streamlines as indicated in fig 6 the residence time distribution of the particles captured in the recirculation zones defined above is shown in fig 11 where the tail in the residence time pdf is heavier in the porosity of 0 5 than in the porosity of 0 8 this is because for the low porosity the particles stay longer in the recirculation zones owing to the low velocity in the recirculation zones and the limited turbulence from this result one can notice that power law slopes of the residence time distributions in the recirculation zones resemble those of the btcs fig 9a this implies that the evolution of the late time tailing in the btcs is controlled by the mean and turbulent flow properties of the recirculation zones also we consistently observe that the btc tails depend strongly on porosity rather than ref as the mean residence times of the particles in the recirculation zones remain relatively constant across different flow conditions as shown in fig 11 inset the transition matrix fig 10 also reveals that the importance of the pore scale vortices on particle transport for the case with porosity 0 5 the particles belonging to the current transition time classes j 6 29 have high probability of traveling with the transition times of the classes i 6 in the next ℓ dashed box in fig 10a these next transition time classes correspond to the flow velocities immediately above the free flow porous media interface once the particles enter the low porosity bed the limited vertical extent of the near interface vortices and turbulence penetration fig 6a makes particles to stay near the interface as described with the snapshot of particle trajectories in fig 10a hence the particles in the porous region either stay in recirculation zones or diffuse back to the free flow regions through interfacial turbulent diffusion such transport mechanisms make the particles to mostly jump to the next ℓ with the interfacial flow velocities represented by the transition time classes i 6 the consequence of this intrinsic particle motion inherent to the low porosity is well illustrated in fig 9 this figure shows that for the porosity of 0 5 the btc measured at both the free flow and porous layers solid line is almost identical with that measured at the free flow layer only dotted line which confirms that passage routes through the downstream station are mostly limited to the free flow layer for the porosity of 0 8 in contrast the particles exit the study reach through both free flow and porous layers as they can jump actively into the fast preferential flow paths due to the extended stretch of the near interface vortices and turbulence penetration fig 6b 3 4 predictions with spatial markov model fig 12 shows btcs estimated at three different downstream locations for case 5010 and case 8010 the comparison between the smm predictions and the 2d lpt results shows that the smm successfully reproduces the first passage time distributions at all downstream stations and accurately captures the anomalous tailing behaviors in the btcs caused by the permeable bed induced velocity and turbulence structures such good agreement between the smm results and the 2d lpt model simulations validates that the lagrangian velocity statistics such as the velocity distribution and correlation effectively encode the particle transport and dispersion dynamics in the coupled free flow and porous media systems note that we applied the smm to all study cases but only presented two representative cases because no significant difference in the predicted btcs is found as a function of the flow condition in contrast an uncorrelated continuous time random walk ctrw model which does not consider the spatial velocity correlation between successive jumps fails to predict the tailing behavior as shown in fig 12 b inset this demonstrates that the spatial velocity correlation plays a critical role in determining the late time tailing in btcs in addition to further validate the predictability of the smm we parameterize the smm with the transition times obtained from the first 200 s of the simulation period the smm parametrized with the limited time window still predicts the btcs successfully as shown in fig 12 b inset recent studies also showed effective ways of parameterizing transition matrices of transition times from experimental data without running transport simulations kang et al 2015b sherman et al 2017 however the focus of this study is not in model parameter estimation but in demonstrating the applicability of the smm in free flow porous media interfaces the tail truncation time of btcs is one of the important features to evaluate the effects of hyporheic exchange on anomalous transport in streams drummond et al 2012 runkel 2015 nevertheless the truncation time cannot typically be observed in the field based tracer experiments due to limited experimental periods thereby being merely approximated by extrapolating the observation data aubeneau et al 2014 to complement this limitation we use results from smm to predict the btc truncation times according to the btcs predicted at x l 1 using the smm fig 12 the porosity of 0 5 introduces the truncation time of t 480 s which is about twice the value of t 240 s in the porosity of 0 8 therefore the truncation time also highlights the importance of porosity in determining the anomalous transport in the coupled free flow porous media system 4 conclusions this study highlights the importance of interfacial turbulence structures and recirculation flows in controlling solute transport through coupled free flow porous media systems by performing the pore scale simulations the mean and the turbulent flow profiles simulated via 2d rans equations involving the rng k ε turbulence model are consistent with those of experimental data the velocity and the turbulence structures within permeable beds are very sensitive to changes in porosity because the depth of turbulence penetration into the porous layer and the subsurface flow velocity increase with increasing porosity and also extends the near interface recirculation zones the 2d lpt simulations revealed that particle transport is significantly influenced by the complex interplay between the pore scale vortices and turbulence structures in permeable beds the extended turbulence allows more active turbulent diffusion of particles from the recirculation zones into the free flow regions or the preferential flow paths where the high velocities cause rapid breakthrough of solute particles consequently the high porosities cause steeper power law slopes than low porosities for the low porosity cases the strong tailings in btcs are attributed to particles trapped in the near interface recirculation zones characterized by low velocity and low turbulent kinetic energy compared to the higher porosity cases furthermore the power law slopes of the residence time distributions in recirculation zones resemble the scaling of btcs these results reveal that pore scale vortices exert dominant control over anomalous transport through free flow porous media interfaces we applied the smm for predictive modeling and successfully predicted solute transport we parametrized the upscaled model using the markovian transition matrix involving the lagrangian velocity transition time distribution and correlation information retrieved from the lpt simulated particle trajectories the effects of the pore scale vortices on transport are well captured in the transition matrix the transition matrix demonstrates that the limited extent of the near interface vortices and turbulence penetration inside the low porosity beds cause retention of particles in the vicinity of the interface with exit restricted to the free flow regions in contrast for high porosity beds the transition matrix shows that particles can also readily enter the preferential flow zones via strong turbulent diffusion the smm accurately reproduced the btcs indicating that the effects of the pore scale vortices on transport are effectively encoded in lagrangian velocity statistics this study elucidates the mechanisms of anomalous transport in the coupled system and suggests an effective way to incorporate the mechanisms into an upscaled model however to further generalize our findings particle transport in more realistic pore geometries should be investigated the mean and turbulent flow properties obtained in this study with the rans equations may be sensitive to the choice of a turbulence model les or dns methods can directly resolve eddies without a turbulence model and can more explicitly demonstrate the effects of recirculation zones on solute transport however we expect the main findings of this study will be independent of the turbulence models because the average velocity and turbulence fields should exert first order control on effective solute transport finally while this study is based on numerical analysis complementary experiments using piv and laser induced fluorescence lif will allow us to further advance our understanding of flow and transport mechanisms in the coupled free flow and porous media systems for example ling et al 2018 combined pore scale numerical simulations with microfluidics experiments to study saturated flow through channel porous media coupled systems and showed promising results by comparing with upscaled models declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors gratefully acknowledge support from the institute of engineering research and institute of construction and environmental engineering at seoul national university seoul south korea pkk also acknowledges the college of science engineering at the university of minnesota and the george and orpha gibson endowment for its generous support of hydrogeology and a grant from korea environment industry and technology institute keiti through subsurface environmental management sem project funded by the korea ministry of environment moe 2018002440003 we thank the minnesota supercomputing institute msi at the university of minnesota for computational resources and support supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103467 appendix supplementary materials image application 1 
542,pore scale velocity and turbulence structures near streambeds may control solute transport and dispersion in streams in this study pore scale flow and transport simulations are performed to investigate the effects of pore scale processes on anomalous transport which is often manifested by remarkably long residence times of solute particles in coupled free flow and porous media systems by solving the 2d reynolds averaged navier stokes equations integrated with a renormalization group k ε turbulence model we resolve complex pore scale flows featured by vortices and preferential flows then we incorporate the simulated velocity and turbulence fields into a lagrangian particle tracking model that considers advection turbulent diffusion and molecular diffusion simulation results reveal that the interplay between pore scale vortices and turbulence structures near the free flow permeable bed interface controls anomalous transport high porosity induces strong turbulence penetration and preferential flow paths within permeable beds the enhanced subsurface turbulence facilitates the escape of solute particles from recirculation zones via turbulent diffusion causing steep power law slopes in breakthrough curves btcs in contrast low porosity introduces heavy tailing in btcs from particles that are trapped in the near interface recirculation zones characterized by low velocities and limited turbulence we upscale and predict particle transport via a spatial markov model smm honoring the interplay between lagrangian velocity distribution and velocity correlation the smm reproduces anomalous transport behaviors obtained from the numerical simulations these results demonstrate that lagrangian velocity statistics effectively encode anomalous transport mechanisms in the coupled systems keywords anomalous transport free flow porous media interface pore scale simulation recirculation zone turbulence structures spatial markov model 1 introduction fluid flow and transport in coupled free flow and porous media systems is of great importance due to its wide applicability in natural and industrial processes such as nuclear waste storage and fuel cells you and liu 2002 bourgeat et al 2009 environmental engineering including flow and pollutant dispersion over aquatic canopies and porous beds in rivers as well as buildings in urban areas zhou and mendoza 1993 britter and hanna 2003 nepf 2012 and biological systems of biofilm formation landa marbán et al 2019 flow and mixing of surface and subsurface waters in a permeable bed also termed hyporheic flow is of particular interest in hydrology hyporheic flow is an essential hydrodynamic process controlling fluid flow mass transport and mixing in rivers and streams harvey et al 1996 elliott and brooks 1997 packman et al 2004 streamflows are typified by fast turbulent flows in a free flow layer and slow laminar flows in a porous layer however turbulence in surface water can extend to a shallow portion of the porous media defined as a turbulent transition layer corresponding to a non darcy flow regime as described in fig 1 nagaoka and ohgaki 1990 pokrajac et al 2007 manes et al 2009 nevertheless conventional models often assume that hyporheic flow is laminar modeling it as darcy flow wörman et al 2002 cardenas and wilson 2007 bottacin busolin and marion 2010 engdahl et al 2010 hester et al 2013 hester et al 2019 these approaches often underestimate the hyporheic exchange rate by orders of magnitude particularly in gravel beds with high permeability o connor et al 2008 o connor et al 2012 this is mainly because the extended turbulence into the transition layer commonly ignored in typical models significantly contributes to mass transfer across the free flow porous media interface higashino and stefan 2011 roche et al 2018 voermans et al 2018 to accurately model the effects of hyporheic exchange on solute transport in hydrologic systems it is critical to improve our mechanistic understanding of turbulent flow and transport through the free flow porous media interface velocimetry techniques like particle image velocimetry piv and laser doppler velocimetry ldv are increasingly being employed in exploring flow interactions between a free stream and a permeable bed goharzadeh et al 2005 liu et al 2008 pokrajac and manes 2009 blois et al 2012 yang et al 2015 kim et al 2018 wu and mirbod 2018 a common observation from these experiments is that turbulent shear stress is maximized at the free flow porous media interface with the strong interfacial turbulence causing extension of the turbulence structure into permeable beds from the experimental findings we can infer that solutes may significantly disperse into and out of the streambed by interfacial turbulent mixing of surface and subsurface waters during such an exchange process retarded subsurface velocities increase residence times of the solutes thereby producing anomalous non fickian transport in streams fernald et al 2001 cardenas 2008a aubeneau et al 2014 the key features of the anomalous transport are the unusually early arrival of tracers downstream and remarkably long residence time of tracers in field tracer tests breakthrough curves btcs commonly exhibit anomalous late time tailings attributed to the turbulent hyporheic exchange which cannot be described with fickian advection dispersion equation ade models harvey and bencala 1993 haggerty et al 2002 jonsson et al 2003 aubeneau et al 2014 recent studies investigated interfacial solute transport across the interface between the free flow region and the porous media region at darcy scale aquino et al 2015 li et al 2017 and roche et al 2019 implemented particle tracking methods on theoretically and experimentally derived profiles of streamwise velocity and turbulent diffusion by assuming that solute particles are only advected with positive streamwise velocities sherman et al 2019 simulated particle trajectories subject to instantaneous flow fields from direct numerical simulation dns modeling subsurface flows with the drag coefficient representing flow resistance like a darcy model these studies however modeled subsurface flows using simple analytical solutions or with a drag force term without directly considering or resolving the interfacial mass transfer phenomenon at the pore scale these macroscale approaches may underestimate the inertial effects of complex pore scale flow fields including preferential flows and vortices on particle transport several studies based on piv measurements revealed that vortices recirculation zones emerge at pore spaces between coarse grains beneath open channel flows blois et al 2012 kim et al 2018 the recirculation zones often act as transient storage zones where solutes are trapped and released slowly into channel flows highlighting a possible source of anomalous transport cardenas et al 2007 cardenas 2008b crevacore et al 2016 zhou et al 2019 therefore explicitly resolving subsurface flow structures at the pore scale is necessary to better understand the non fickian nature of transport in hyporheic flows some studies involved fully resolved pore scale flow simulations of coupled turbulent free flow and porous media flow where the porous media is idealized with an array of cubic or spherical grains the flow simulation were performed using reynolds averaged navier stokes rans equations with turbulence models like a standard k ε model and a reynolds stress model prinos et al 2003 yang et al 2018 as well as large eddy simulation leonardi et al 2018 fang et al 2018 lian et al 2019 and dns breugem and boersma 2005 kuwata and suga 2017 these studies suggest that recirculating flow structures dominate flow in some portions of porous media and moreover geometric characteristics like subsurface porosity strongly correlate to the size of these pore scale vortices yet these studies only involved flow analysis without studying transport phenomena thus the effects of the pore scale flow patterns on solute transport through the free flow porous media interface remain largely unknown the goal of this study is to evaluate the effects of the complex interplay between pore scale velocity and turbulence structures near the free flow porous media interfaces on flow and mass transport through coupled free flow and porous media systems more specifically we investigate how the pore scale flow structures such as vortices and preferential flows influence anomalous transport in a coupled free flow and porous media system in this study we fully resolve pore scale flow fields directly coupled with overlying turbulent free flows by solving 2d rans equations incorporating a turbulence model we first validate this hydrodynamic model with the experimental data prinos et al 2003 and then apply this model to investigate cases with different porosities and a wide range of reynolds numbers based on simulated velocity and turbulence fields we perform particle tracking simulations involving advection turbulent diffusion and molecular diffusion to advance fundamental understanding of flow and transport through free flow porous media interfaces we then perform the detailed analysis to elucidate the influence of pore scale vortices on anomalous transport finally we upscale solute transport using a stochastic random walk model parametrized with particle trajectory information from the numerical simulations and then conduct predictions of effective transport using the upscaled model 2 methods 2 1 hydrodynamic model we analyze mean and turbulent flow characteristics in coupled free flow and porous media systems using the open source fluid dynamics library openfoam which adopts a finite volume method for solving governing equations we use 2d rans equations as the governing equations for fluid flow 2d turbulence models can provide the general picture of the turbulent flows when one spatial direction is considerably constrained by geometry or applied body forces boffetta and ecke 2012 xia and francois 2017 2d turbulence model is relevant in this study because the mass exchange between the free flow zone and the porous media zone is mostly triggered by the vertical flows boano et al 2014 gomez velez and harvey 2014 unsteady forms of continuity and momentum equations in einstein notation in cartesian coordinates can be written as 1a u i x i 0 1b u i t u j u i x j 1 ρ p x i x j ν u i x j u j x i x j u i u j s i where ui and uj are the time averaged velocity vectors in the xi and xj directions of cartesian coordinates respectively herein xi and xj represent x axis and y axis properties when i j 1 while xi and xj denote y axis and x axis properties when i j 2 p is the fluid pressure ρ is the density of the fluid ν is the kinematic viscosity of the fluid ui and uj are the fluctuating velocity vectors in the xi and xj directions respectively si is the source term representing the pressure gradient to drive the flow in addition u i u j indicates the reynolds stress a product of the reynolds decomposition and the term should be modeled with turbulence closure models the rans turbulence models employ an eddy viscosity concept derived from boussinesq approximation which relates reynolds stresses to mean properties of turbulent flows a standard k ε model is one of the most widely used turbulence models in environmental hydraulics applications because of its good convergence with a minor computational overhead mößner and radespiel 2015 to close the governing equations this turbulence model includes two additional transport equations to solve for turbulent quantities of flows such as turbulent kinetic energy k and its dissipation rate ε nevertheless this conventional method has a limitation in accurately reproducing complex wall bounded flows at low reynolds number owing to the overestimation of an eddy viscosity shih et al 1995 hence we adopt a renormalization group rng k ε model yakhot et al 1992 to enhance the accuracy of flow simulation in the free flow and porous media systems the rng k ε model better resolves the near wall turbulent flows and many studies have reported that the model adequately reproduces flow characteristics near wall regions such as recirculation zones speziale and thangam et al 1992 dargahi 2006 cassan and belaud 2011 sinha et al 2017 the corresponding transport equations for k and ε are as follows 2a t ρ k x i ρ k u j x j μ μ t σ k k x j g k ρ ε s k 2b t ρ ε x i ρ ε u j x j μ μ t σ ε ε x j ε k c 1 ε g k c 2 ε ρ ε s ε where c 1ε σ k and σε are the empirical constants set to 1 42 0 7194 and 0 7194 respectively yakhot et al 1992 μ and μ t are the molecular viscosity and the dynamic turbulent viscosity respectively gk is the generation of turbulent kinetic energy arising from the mean velocity gradients sk and s ε are the moduli of the mean rate of strain tensors of k and ε respectively the main difference from the standard k ε model is that the rng k ε model treats c 2ε as a variable parameter to consider the different scales of motion by changing the production term which can be expressed as 3 c 2 ε c 2 ε c μ η 1 η η 0 1 β η 3 where c 2ε c μ β and η0 are constants set to 1 68 0 09 0 012 and 4 38 respectively yakhot et al 1992 the variable parameter η is obtained as 4 η k ε 2 s i j s i j where sij is the strain rate tensor 2 2 particle tracking model we simulate transport and spreading of solute particles using a 2d lagrangian particle tracking lpt model particle motion is governed by advection molecular diffusion and turbulent diffusion across the free flow porous media interface o connor and harvey 2008 voermans et al 2018 in consequence the particle trajectories are determined by the stochastic langevin equation described as follows in einstein notation 5 x i p t δ t x i p t u i x i p t u i x i p t δ t ξ i t 2 d m δ t where x i p is the particle position ξ i t is the unit gaussian distributed random number and dm is the molecular diffusion coefficient the fluctuating velocity ui in eq 5 characterizes turbulent diffusion whose length scale is usually much larger than that of molecular diffusion so that the former typically governs solute mixing in rivers and streams rutherford 1994 however the effects of molecular diffusion can be important in porous media and we consider both turbulent diffusion and molecular diffusion in this study since ui is not directly available from the rans simulation we apply a discrete random walk drw technique gosman and loannides 1983 to consider the effects of turbulent mixing on particle trajectories we model turbulent diffusion of particles as a succession of interactions between particles and eddies which have the finite length and time scales dehbi 2008 the drw method incorporates the mean turbulent flow properties and has been shown to successfully reproduce particle dispersion in environmental flows shams et al 2002 tian and ahmadi 2007 gao et al 2012 jayaraju et al 2015 according to the drw method ui can be coupled with k obtained from the flow simulation where k is the space dependent variable as follows 6 u i x i p t ζ i t 2 k 3 where ζ i t is the unit gaussian distributed random number for the velocity perturbation which is temporally varying so that ζ i t is updated after each eddy lifetime τ e defined as 7 τ e c μ 3 4 k ε ln r where r is the random number between zero and unity thus particles are assumed to be interacting with an eddy which has a constant value of ζ i during τ e when the time from the origin time of the eddy exceeds τ e another particle eddy interaction is generated by introducing new values of ζ i and τ e rybalko et al 2012 this process is repeated to consider spatio temporal evolution of turbulent eddies 2 3 upscaled transport model spatial markov model we upscale interfacial solute transport phenomena with an upscaled stochastic transport model known as spatial markov model smm which honors spatial markov properties of lagrangian velocity transitions le borgne et al 2008 this effective random walk model which is parameterized with lagrangian velocity statistics has been successfully applied to predict anomalous transport across a broad range of flows le borgne et al 2011 de anna et al 2013 kang et al 2014 dentz et al 2016 sund et al 2017 this modeling framework incorporates lagrangian velocity statistics by honoring the interplay between velocity distribution and velocity correlation velocity distribution captures velocity heterogeneity with one point statistics and velocity correlation captures spatial memory of velocity transitions with two point statistics dentz and bolster 2010 kang et al 2015b the series of particle positions and travel times in streamwise direction are described as 8 x n 1 x n ℓ 9 t n 1 t n τ n where τ n ℓ v n is the successive transition time of particles over the fixed spatial jump ℓ at the finite step n which varies from zero to n total where n total is the channel length l divided by ℓ v n is the corresponding lagrangian velocity and we can characterize the velocity distribution using a probability density function pdf of τ p τ in the smm framework τ τ n is correlated to a particle transition time at a previous step τ τ n 1 as the transition times are shown to exhibit spatial markovianity if sampled in space le borgne et al 2008 hence τ can be modeled using a transition matrix that characterizes one step correlation to assess the transition probabilities from the particle trajectories simulated with the 2d lpt model we discretize p τ into n classes ci 1 i n where i increases with the increase in τ and further define the conditional probability density r τ τ in this study the transition times are discretized equidistance in logarithmic scale to provide a better discretization for small transition times that control long residence time of particles kang et al 2015a with these lagrangian properties the transition matrix is subsequently defined as le borgne et al 2008 10 t i j τ i τ i 1 τ j τ j 1 r τ τ p τ d τ d τ τ j τ j 1 p τ d τ where tij describes the transition probability from the current transition time class j to the next transition time class i 2 4 configuration of numerical experiments 2 4 1 model validation cases the rans simulation incorporating the rng k ε turbulence model yields time averaged properties of turbulent flows for the model validation we compare our simulation results with experimental data available from prinos et al 2003 they investigated the 2d mean and turbulent flow characteristics in a 10 m long and 0 25 m wide open channel with an underlying permeable bed consisting of regular rods with a diameter d 0 01 m in the non staggered pattern as shown in fig 2 table 1 displays the geometric and hydrodynamic characteristics of the flow the free flow depth hf is set to either 0 03 m or 0 05 m referred to as case 250 30 and case 250 50 respectively the porous layer depth hp is 0 055 m and porosity is 0 8286 with these experimental setups prinos et al 2003 also conducted the numerical simulation using the 2d rans equations based on the standard k ε turbulence model 2 4 2 study cases after validating the hydrodynamic model with the experimental data we further study two different subsurface porosity scenarios where porosity is either 0 5 or 0 8 as shown in fig 3 the diameter of grains is set to 0 01 m so that this setup can be considered as coarse gravel beds here hf and hp are fixed to 0 045 m and 0 075 m respectively in addition we vary reynolds number ref ufhf ν by varying the inlet velocity uin where uf denotes the mean velocity of the surface layer over 0 y hf 1 the values of ref vary approximately from 2 000 to 12 000 which lead to froude number fr u f g h f to vary between 0 11 and 0 59 the investigated fr values are observable values in natural stream environments most of natural streams flow at fr below 0 3 and the flow at fr above 0 6 are infrequently observed davidian and cahal 1963 the geometric and hydraulic conditions as well as the computational mesh resolution for each study case are summarized in table 2 by studying these cases we can assess the sensitivity of flow and transport dynamics to porosity and ref for the 2d lpt simulation the total particle number of 5 104 is uniformly injected at the inlet of the free flow layer in this study we consider tracer injection at streams and no particles are injected at the porous layer mimicking tracer injection at a stream the time step is set to values which retain the courant number cr ui δt δx less than unity and dm is fixed to 2 10 9 m2 s representing the typical molecular diffusivity of liquid phases li and gregory 1974 2 4 3 simulation conditions the computational meshes are composed of quadrilateral cells the dense grids satisfying the dimensionless wall distance y yu ν to be less than unity near the fluid grain interfaces are generated note that u g h f s is the shear velocity this grid refinement is necessary to ensure the application of the enhanced wall treatment for accurately simulating the flows in the boundary layers salim and cheah 2009 escue and cui 2010 the resolutions of generated meshes for the model validation and study cases are listed in tables 1 and 2 respectively we apply the periodic boundary conditions to simulate the mean and turbulent flows for representative computational domains as illustrated in fig 2 because the validation and study cases have periodically repeating geometries in the streamwise direction at the free surface zero shear slip wall the symmetry boundary condition is applied to honor the condition of no surface oscillation which is valid for fr less than unity subcritical flow at the solid fluid boundaries at the grain surfaces the no slip boundary conditions are used the convection diffusion and gradient terms of the momentum equation are discretized using the gauss linear scheme this second order and unbounded scheme is also used for discretizing the turbulence transport equations the backward scheme of the second order and implicit method handles the discretization of the time derivative term for which the time step δt is set to the value that satisfies cr to be less than 0 5 the pressure implicit split operator piso algorithm is employed for coupling pressure and velocity to ensure mass conservation prasad et al 2015 we simulate until ui p k and ε in eqs 1 and 2 converge to the steady state values corresponding to the fully developed flow condition these values at the steady state are used for further flow analysis and particle tracking simulation 3 results and discussion 3 1 results of model validation fig 4 shows vertical profiles of the mean velocity magnitude and the turbulent kinetic energy for case 250 30 and case 250 50 both the mean velocity and turbulent kinetic energy are normalized with u to directly compare our simulation results from the rng k ε turbulence model with the experimental and numerical data from prinos et al 2003 to calculate u we derive the hydraulic slope s from the streamwise pressure gradient associated with si in eq 1b as shown in fig 4a and b the presence of a permeable bed reduces the mean velocity in the free flow layer and produces the slip velocity at the free flow porous media interface due to the interfacial momentum exchange the rng k ε turbulence model accurately reproduces these effects of the permeable bed on the mean velocity of the surface water thereby showing better agreement with the experimental data compared to the standard k ε turbulence model yet relatively large discrepancies between the simulated velocity and the measured velocity are found adjacent to the interface these differences may be attributed to the fact that the porous layer of the experimental channel is not long enough to reach the fully developed flow as reported by prinos et al 2003 as aforementioned in the 2d lpt model the turbulent kinetic energy k in eq 2a is a critical variable that controls effective particle dispersion via turbulent diffusion thus it is critically important to accurately simulate turbulent kinetic energy profiles because the turbulent diffusion term in the 2d lpt model estimated by the turbulent kinetic energy as shown in eq 6 controls the particle dispersion into the porous media as shown in fig 4 the rng k ε turbulence model reproduces spatially varying behaviors of turbulence and estimates peak values of turbulent kinetic energy and their locations more accurately than the standard k ε turbulence model furthermore the interaction of the turbulent free flows with the permeable bed results in the enhanced interfacial turbulence propagating through the porous regions 3 2 analysis of hydrodynamics 3 2 1 mean and turbulent flow characteristics we apply the validated hydrodynamic model to explore the influence of porosity and ref on the turbulent flow characteristics over and within permeable beds using the study cases shown in table 2 fig 5 presents vertical profiles of the simulated mean velocity magnitude and turbulent kinetic energy for each study case the mean velocity of the permeable bed is significantly higher in the porosity of 0 8 than in the porosity of 0 5 fig 5a and b this is because the higher porosity corresponds to more flows through the permeable bed and accordingly relatively low surface velocity is obtained to honor mass conservation table 2 moreover fig 5b inset shows that porosity determines up uf where up is the mean velocity of the subsurface layer over 1 y hp 0 because of the strong preferential flow paths observed between grains for the high porosity cases the porosity of 0 8 yields up uf 0 1 which is one order of magnitude greater than a value of up uf 0 01 for the porosity of 0 5 on the other hand this velocity ratio tends to remain relatively constant with respect to uin because the mean velocity structures in the limited water depth are more dependent on porosity than ref goharzadeh et al 2005 wu and mirbod 2018 the porosity further plays a vital role in turbulence structures fig 5c and d show that the higher porosity induces the greater penetration of turbulent kinetic energy into the permeable bed in order to quantify the penetration extent of turbulent flows we calculate the penetration length scale of turbulent kinetic energy δ k normalized by pore diameter d as follows 11 δ k 1 k int u 2 d y 0 075 m y 0 m f y d y where f y indicates the vertical profile of k u 2 inside the porous regions and k int u 2 is k u 2 at the free flow porous media interface of y 0 m fig 5d inset shows that the porosity of 0 8 introduces δ k ranging 0 420 0 667 which is about three times the values of δ k ranging 0 172 0 187 for the porosity of 0 5 in the high porosity cases δ k slightly increases with increasing ref which is originated from the fluctuation of the small turbulent kinetic energy below y hp 0 2 in the turbulent kinetic energy profile fig 5d however the turbulent kinetic energy near the interface of y hp between 0 2 and 0 is less sensitive to ref this implies that slight increase in δ k may have negligible effects on solute transport because solute exchange between the free flow and porous layers mostly takes place in the vicinity of the interface in summary the flow analysis results indicate that velocity and turbulence structures are significantly more sensitive to porosity than ref 3 2 2 recirculation zones the exchange of momentum between free flow and permeable layers which is associated with the interfacial slip velocities and turbulence leads to the occurrence of recirculation zones beneath the free flow porous media interface breugem and boersma 2005 kuwata and suga 2017 as depicted in fig 6 this figure also shows the spatial maps of mean flow velocity and turbulent kinetic energy for case 5010 and case 8010 the structures of recirculation zones rely strongly on porosity as the high porosity bed produces a single large vortex while the low porosity bed produces a pair of relatively small vortices directly below the interface the vertical stretch of the first vortex from the interface squares with red dashed lines in fig 6 enlarges proportional to δ k and up uf extending to the porous depth of y hp 0 1 and y hp 0 05 for the porosity of 0 8 and 0 5 respectively this tendency is consistent with simulation results from yang et al 2018 who reported that the vortex size increases monotonously with an increase in up uf the length scale of the vortices may significantly affect interfacial mass transfer dynamics because the greater extent of the near interface recirculating flows can cause solutes to penetrate deeper into the porous regions as solute exchange between the free flow and the porous media mainly occurs near the interface due to the steep decay of interfacial turbulence towards the channel bed fig 5c and d the mean and turbulent flow characteristics of the near interface recirculation zones can be considered as one of the key factors governing mass transfer between the surface and subsurface layers as shown in fig 6 the higher mean velocity and the stronger turbulence are observed when the porosity increases for the vortex regions located within the first grain layer 0 133 y hp 0 the spatial averaged values of u u and k u 2 for the porosity 0 8 case are u u 0 58 and k u 2 0 91 respectively which are about 1 5 times the values of u u 0 34 and k u 2 0 65 for the porosity 0 5 case such difference in the properties of the recirculation zones would be originated from the interfacial momentum exchange intrinsic to porosity the slow recirculating flows with the diminished turbulence for the low porosity cases may result in the strong trapping effects of the pore scale vortices which can invoke the heavy tailing in btcs by not only increasing residence times of solutes but also restricting the solutes to escape from these recirculation zones the interaction between the recirculation zones and solute transport will be further discussed in section 3 3 3 3 3 analysis of transport dynamics 3 3 1 tracer breakthrough curves we now analyze transport behaviors using btcs residence time distributions fig 7 shows the btcs at the downstream station located at l 3m obtained from 2d lpt simulations note that particles can breakthrough through both the free flow and porous layers as discussed in section 3 2 1 the mean and turbulent flow structures governing the particle transport patterns are not sensitive to the change in ref this is further demonstrated by showing that the btcs normalized by uin can be collapsed for the different values of ref fig 7a and b insets the dotted lines in fig 7a and b show the btcs of particles that did not travel through porous media below y hp 0 before reaching the downstream stations the residence times of these particles are much shorter than those of the particles that interact with the porous layer solid lines in fig 7a and b this consequently reveals that solute exchange at the free flow porous media interface is the crucial dynamics responsible for anomalous transport patterns distinguished by the tailing behaviors in the btcs we investigate the effects of porosity on mass transfer of particles to the permeable bed by measuring the percent mass of particles accumulated in the porous regions msub which is defined as the number of particles in the porous layer divided by the number of injected particles for each time step during the simulation periods fig 8 shows that msub initially increases as time elapses and then converges to specific values for the porosity of 0 8 particles accumulate up to msub 16 which is almost twice the value of the porosity 0 5 cases this infers that the enhanced turbulence inside the high porosity bed stimulates the particles to enter more easily into the porous regions as expected whereas we cannot observe the significant difference in msub with the variation of ref interestingly despite the smaller number of the particles captured in the low porosity bed owing to the limited extent of turbulence penetration into the permeable bed the porosity of 0 5 introduces stronger tails in btcs compared to those of the porosity of 0 8 as shown in fig 9 a this seemingly contradictory behavior in the btcs can be explained by understanding the interplay between vortices and turbulence structures within the permeable bed once particles diffuse into the subsurface regions the particles are significantly more stagnant in the low porosity bed than in the high porosity bed due to the stronger trapping effects by the recirculation zones the strong trapping effects originate from the low velocities and limited turbulence which lead to the strong tailing in the btcs on the other hand the high porosity bed allows particles to easily escape from the recirculation zones with the enhanced subsurface turbulence and transport through the preferential flow paths as shown in fig 6b this key finding from the 2d lpt simulation is consistent with the result of field tracer tests from aubeneau et al 2014 who reported that pea gravel beds low porosity which produces low subsurface velocities resulted in longer retention times of solute tracers than coarse gravel beds high porosity 3 3 2 lagrangian velocity statistics we characterize the lagrangian velocity statistics using the lagrangian velocity distribution and correlation the motion of the solute particles is discretized equidistantly with the fixed spatial step of ℓ in the main flow direction accordingly the velocity distribution can be represented by the distribution of the transition times τ n ℓ v n as previously defined the transition times are sampled at every ℓ 0 05 m from the particle trajectories fig 9b shows the pdf of the transition times which represents the transition time distribution from this figure the probability of having the long transition times low velocities increases with the decreasing porosity leading to the heavy tailed transition time distribution furthermore fig 9 demonstrates that the transition time pdf has the power law slope identical to that of the corresponding btcs therefore this implies that the effects of porosity on the anomalous tailing behavior in the btcs are encoded adequately in the transition time distributions however the transition time distribution alone does not include the property of the spatial velocity correlation structure which is another key factor that determines the anomalous transport behavior de anna et al 2013 kang et al 2015b thus we first evaluate the velocity autocorrelation functions for the given lag χ s δs and then estimate the correlation length scale ℓ c by integrating χ s δs over the distance dentz et al 2016 kang et al 2017 fig 9b inset shows that ℓ c is larger for larger porosity cases this tendency would be the result of the fast preferential flows developed in the high porosity bed fig 6b which contributes to the increase in the velocity correlation the existence of the finite correlation length along the particle trajectories implies that the lagrangian velocities transition times can be effectively describes as a spatial markov process le borgne et al 2008 dentz et al 2016 kang et al 2017 to consider the velocity correlation effects the series of the transition times sampled in space is characterized using the transition matrix in eq 10 we construct the 30 30 transition matrix to adequately capture the entire ranges of correlation effects le borgne et al 2011 as shown in fig 10 herein each transition time class is spaced equidistantly in the log scale and we choose ℓ 0 05 m which is smaller than the characteristic correlation length scale ℓ c to properly resolve the velocity correlation structure the constructed transition matrix is used to evaluate the one step correlation between τ n and τ n 1 fig 10 shows that the correlation is stronger for the high velocities short transition times than for the low velocities long transition times the porosity exerts a significant impact on the transition matrices the transition matrix for the porosity of 0 8 shows the emergence of the strong velocity correlation in the transition time classes between 9 and 10 dashed box in fig 10b corresponding to the preferential flow paths in porous media fig 6b where advection is dominant over molecular diffusion and turbulent diffusion particles can transport with high subsurface velocities through these preferential flow paths as illustrated with the snapshot of velocity field overlain by particle trajectories in fig 10b the dashed box in fig 10a is the result of the recirculation zones attributed to the porosity of 0 5 which will be discussed in detail in section 3 3 3 3 3 3 effects of recirculation zones on transport in order to assess the contributions of pore scale vortices on effective particle transport we quantify particle residence times in these local recirculation zones by measuring travel times of particles within the flow separation regions enclosed by dividing streamlines as indicated in fig 6 the residence time distribution of the particles captured in the recirculation zones defined above is shown in fig 11 where the tail in the residence time pdf is heavier in the porosity of 0 5 than in the porosity of 0 8 this is because for the low porosity the particles stay longer in the recirculation zones owing to the low velocity in the recirculation zones and the limited turbulence from this result one can notice that power law slopes of the residence time distributions in the recirculation zones resemble those of the btcs fig 9a this implies that the evolution of the late time tailing in the btcs is controlled by the mean and turbulent flow properties of the recirculation zones also we consistently observe that the btc tails depend strongly on porosity rather than ref as the mean residence times of the particles in the recirculation zones remain relatively constant across different flow conditions as shown in fig 11 inset the transition matrix fig 10 also reveals that the importance of the pore scale vortices on particle transport for the case with porosity 0 5 the particles belonging to the current transition time classes j 6 29 have high probability of traveling with the transition times of the classes i 6 in the next ℓ dashed box in fig 10a these next transition time classes correspond to the flow velocities immediately above the free flow porous media interface once the particles enter the low porosity bed the limited vertical extent of the near interface vortices and turbulence penetration fig 6a makes particles to stay near the interface as described with the snapshot of particle trajectories in fig 10a hence the particles in the porous region either stay in recirculation zones or diffuse back to the free flow regions through interfacial turbulent diffusion such transport mechanisms make the particles to mostly jump to the next ℓ with the interfacial flow velocities represented by the transition time classes i 6 the consequence of this intrinsic particle motion inherent to the low porosity is well illustrated in fig 9 this figure shows that for the porosity of 0 5 the btc measured at both the free flow and porous layers solid line is almost identical with that measured at the free flow layer only dotted line which confirms that passage routes through the downstream station are mostly limited to the free flow layer for the porosity of 0 8 in contrast the particles exit the study reach through both free flow and porous layers as they can jump actively into the fast preferential flow paths due to the extended stretch of the near interface vortices and turbulence penetration fig 6b 3 4 predictions with spatial markov model fig 12 shows btcs estimated at three different downstream locations for case 5010 and case 8010 the comparison between the smm predictions and the 2d lpt results shows that the smm successfully reproduces the first passage time distributions at all downstream stations and accurately captures the anomalous tailing behaviors in the btcs caused by the permeable bed induced velocity and turbulence structures such good agreement between the smm results and the 2d lpt model simulations validates that the lagrangian velocity statistics such as the velocity distribution and correlation effectively encode the particle transport and dispersion dynamics in the coupled free flow and porous media systems note that we applied the smm to all study cases but only presented two representative cases because no significant difference in the predicted btcs is found as a function of the flow condition in contrast an uncorrelated continuous time random walk ctrw model which does not consider the spatial velocity correlation between successive jumps fails to predict the tailing behavior as shown in fig 12 b inset this demonstrates that the spatial velocity correlation plays a critical role in determining the late time tailing in btcs in addition to further validate the predictability of the smm we parameterize the smm with the transition times obtained from the first 200 s of the simulation period the smm parametrized with the limited time window still predicts the btcs successfully as shown in fig 12 b inset recent studies also showed effective ways of parameterizing transition matrices of transition times from experimental data without running transport simulations kang et al 2015b sherman et al 2017 however the focus of this study is not in model parameter estimation but in demonstrating the applicability of the smm in free flow porous media interfaces the tail truncation time of btcs is one of the important features to evaluate the effects of hyporheic exchange on anomalous transport in streams drummond et al 2012 runkel 2015 nevertheless the truncation time cannot typically be observed in the field based tracer experiments due to limited experimental periods thereby being merely approximated by extrapolating the observation data aubeneau et al 2014 to complement this limitation we use results from smm to predict the btc truncation times according to the btcs predicted at x l 1 using the smm fig 12 the porosity of 0 5 introduces the truncation time of t 480 s which is about twice the value of t 240 s in the porosity of 0 8 therefore the truncation time also highlights the importance of porosity in determining the anomalous transport in the coupled free flow porous media system 4 conclusions this study highlights the importance of interfacial turbulence structures and recirculation flows in controlling solute transport through coupled free flow porous media systems by performing the pore scale simulations the mean and the turbulent flow profiles simulated via 2d rans equations involving the rng k ε turbulence model are consistent with those of experimental data the velocity and the turbulence structures within permeable beds are very sensitive to changes in porosity because the depth of turbulence penetration into the porous layer and the subsurface flow velocity increase with increasing porosity and also extends the near interface recirculation zones the 2d lpt simulations revealed that particle transport is significantly influenced by the complex interplay between the pore scale vortices and turbulence structures in permeable beds the extended turbulence allows more active turbulent diffusion of particles from the recirculation zones into the free flow regions or the preferential flow paths where the high velocities cause rapid breakthrough of solute particles consequently the high porosities cause steeper power law slopes than low porosities for the low porosity cases the strong tailings in btcs are attributed to particles trapped in the near interface recirculation zones characterized by low velocity and low turbulent kinetic energy compared to the higher porosity cases furthermore the power law slopes of the residence time distributions in recirculation zones resemble the scaling of btcs these results reveal that pore scale vortices exert dominant control over anomalous transport through free flow porous media interfaces we applied the smm for predictive modeling and successfully predicted solute transport we parametrized the upscaled model using the markovian transition matrix involving the lagrangian velocity transition time distribution and correlation information retrieved from the lpt simulated particle trajectories the effects of the pore scale vortices on transport are well captured in the transition matrix the transition matrix demonstrates that the limited extent of the near interface vortices and turbulence penetration inside the low porosity beds cause retention of particles in the vicinity of the interface with exit restricted to the free flow regions in contrast for high porosity beds the transition matrix shows that particles can also readily enter the preferential flow zones via strong turbulent diffusion the smm accurately reproduced the btcs indicating that the effects of the pore scale vortices on transport are effectively encoded in lagrangian velocity statistics this study elucidates the mechanisms of anomalous transport in the coupled system and suggests an effective way to incorporate the mechanisms into an upscaled model however to further generalize our findings particle transport in more realistic pore geometries should be investigated the mean and turbulent flow properties obtained in this study with the rans equations may be sensitive to the choice of a turbulence model les or dns methods can directly resolve eddies without a turbulence model and can more explicitly demonstrate the effects of recirculation zones on solute transport however we expect the main findings of this study will be independent of the turbulence models because the average velocity and turbulence fields should exert first order control on effective solute transport finally while this study is based on numerical analysis complementary experiments using piv and laser induced fluorescence lif will allow us to further advance our understanding of flow and transport mechanisms in the coupled free flow and porous media systems for example ling et al 2018 combined pore scale numerical simulations with microfluidics experiments to study saturated flow through channel porous media coupled systems and showed promising results by comparing with upscaled models declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors gratefully acknowledge support from the institute of engineering research and institute of construction and environmental engineering at seoul national university seoul south korea pkk also acknowledges the college of science engineering at the university of minnesota and the george and orpha gibson endowment for its generous support of hydrogeology and a grant from korea environment industry and technology institute keiti through subsurface environmental management sem project funded by the korea ministry of environment moe 2018002440003 we thank the minnesota supercomputing institute msi at the university of minnesota for computational resources and support supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103467 appendix supplementary materials image application 1 
543,understanding the physics of two phase flow of co2 and brine in porous geological formations is essential to sequestration of carbon dioxide in deep saline reservoirs as well as the older problem of enhanced oil recovery from hydrocarbon reservoirs by co2 injection a pilot co2 injection in decatur illinois was undertaken with the injection zone being the highly saline and heterogeneous mt simon sandstone in order to better understand the feasibility of full scale sequestration process this paper reports the results of an extensive study of the morphology of the sandstone and its heterogeneity and simulation of single phase and two phase flow of co2 and brine in the formation s three dimensional images as we demonstrate by extensive analysis the formation is much more heterogeneous than the typical sandstone such as berea sandstone in addition to characterizing the morphology of the sandstone and computing its important flow characteristics an important goal of the study is to compare the accuracy and computational efficiency of three distinct simulation approaches namely the lattice boltzmann lb approach direct numerical simulation dns of the governing equations of fluid flow that uses the finite volume method coupled with the openfoam simulator and pore network pn simulation after validating the simulators by comparing the computed relative permeabilities that they produce for berea sandstone we simulate displacement of brine by co2 at low and relatively high capillary numbers and compute the relative permeabilities and other quantities of interest we demonstrate that all the three methods provide consistent relative permeability saturation functions that are in close agreement with one another however although the lb and dns both produce similar relative permeabilities the dns approach is computationally more efficient because it simulates drainage by only a single set of computations over the entire saturation range whereas the lb simulation requires separate simulation for each set saturation thus the question of what method to use for simulating such flow processes at the scale of core plugs should mainly be addressed based on the computational time that one can afford and the computational resources that one has access to another important question addressed is the effect of the resolution of the computational grids or lattices used particularly when one uses the lb method with voxelized images of porous media we show that unlike many claims in the past one may need many lattice units per voxel in order to obtain reliable lattice independent results 1 introduction the physics of two phase flows in porous media is of utmost importance to many problems of practical interest such as co2 sequestration in deep saline reservoirs recovery of oil from hydrocarbon reservoirs transport of non aqueous phase liquid contaminants in aquifers and infiltration of rainfall into soil understanding and predicting the properties of such flow processes at various length scales are vital to addressing the problem of global warming as well as managing water resources and energy production there is increasing incentive for studying two phase flow of co2 and brine in porous media due to societal interest in geological sequestration of co2 the drastic increase in the amount of co2 in the atmosphere plays the most important role in global climate change friedlingstein and solomon 2005 metz et al 2005 nordbotten and celia 2011 the main source of the atmospheric co2 is combustion of fossil fuels for producing electricity in power plants among the various approaches that have been suggested for mitigating the problem co2 capture and storage ccs is believed to be a viable solution nordbotten and celia 2011 the ccs is a process associated with separating co2 from the other gases that are produced by power plants and other sources compressing and transporting it to storage locations and keeping it sequestered in onshore or offshore geological formations for very long times metz et al 2005 as an example the united states can inject up to 65 of the co2 produced by power plants deep into saline aquifers shukla et al 2010 since such a sequestration process appears to have great potential understanding the behavior of flow of brine and co2 in deep porous formations is vital juanes et al 2006 pruess and garcia 2002 to its successful implementation and should accompany any comprehensive study of geological storage of co2 that includes its economic feasibility site selection risk assessment environmental impact safety aspects monitoring and verification in addition to perspectives on retention time physical leakage brine displacement and microseismicity metz et al 2005 the illinois state geological survey carried out a pilot injection study to better understand the feasibility of full scale ccs the study site is in decatur illinois and the injection zone is the highly saline mt simon sandstone finley 2014 thus one goal of the present study is to analyze two phase flow of co2 and brine in mt simon sandstone and more generally in natural rock the phenomenon may be studied at various length scales including molecular core and field scales by experiments and computer simulation experiments are of course quite useful but can be difficult to implement as they are time consuming and expensive joekar niasar and hassanizadeh 2012 at the molecular scale the interaction between water and water co2 and mixed layer clay was recently studied rahromostaqim and sahimi 2018 2019 advances in modeling of porous media as well as development of efficient computer simulation together with increasing computer powers have made it possible to model and study in detail two phase flow of brine and co2 at core plug and larger length scales compared to experiments the computational approaches have the advantages of being generally less expensive and more flexible in implementing and changing parameters flow and displacement mechanisms and studying various mechanisms of displacements at the same time numerical simulation of flow of brine and co2 at field scale requires such inputs as the relative permeabilities and capillary pressure as functions of the saturation at the scale of the grid blocks which can be obtained by experiments or by pore scale modeling pore scale modeling celia et al 1995 can provide the required input data for field scale modeling provided that one takes into account the effect of the morphology of the core scale porous media and the various pore scale mechanisms of fluid displacements this is because pore scale flow affects significantly the characteristics of the process at larger scales including injection and storage of co2 in depleted reservoirs and other types of large scale porous formations juanes et al 2006 pruess and garcia 2002 raeini et al 2014 with advances in instrumentation it has become possible to obtain three dimensional 3d images of porous media with high resolution by for example x ray computed tomography ct blunt et al 2013 at pore scale detailed 3d geometry of rock and its void space can be captured by direct imaging using nondestructive x ray microtomography dunsmuir et al 1991 flannery et al 1987 various rock properties such as the permeability have been computed with the aid of micro ct images arns et al 2002 øren and bakke 2002 ramstad et al 2010 krevor et al 2012 bakhshian et al 2018 thus one can directly simulate two phase flows in the images which renders as unnecessary developing models of the pore space image based methods are however computationally expensive although recent advances in high performance computing as well as a new method that smoothens the image without changing its properties using curvelet transformations aljasmi and sahimi 2019 are making use of such methods increasingly common the methods that are used for simulating fluid flow in the images are either based on directly solving the governing equations for fluid flow i e the stokes equation using the finite volume method ferrari and lunati 2013 huang et al 2005 rabbani et al 2017 or based on the lattice boltzmann lb method boek and venturoli 2010 ferreol and rothman 1995 pan et al 2004 porter et al 2009 ramstad et al 2012 rothman 1990 the lb method has been demonstrated to be well suited for high performance parallel computing in the complex geometry of porous media ahrenholz et al 2008 chen et al 2018 ramstad et al 2012 tölke et al 2006 in addition advances in method based on the volume of fluids especially the new developments of surface force formulation have made it possible to efficiently model two phase flow by the finite volume method at lower capillary numbers gueyffier et al 1999 another approach is based on pore network models pnms sahimi 2011 blunt et al 2013 in which the pore space is simplified to a network of interconnected pore bodies and pore throats while the pnms are computationally very efficient and inexpensive they still involve some assumptions and approximations such as the definition of what constitutes a pore body or pore throat how to assign effective sizes to them etc ramstad et al 2012 joekar niasar and hassanizadeh 2012 therefore a detailed comparison between the results of the pnm computations with those obtained by the other two aforementioned methods will shed much light on its advantages and limitations the goal of this paper is twofold one is computing the drainage relative permeability functions for co2 and brine during injection of the former into a sample of mt simon sandstone this is not a trivial problem as mt simon sandstone is much more heterogeneous than typical sandstones studied in the past such as the berea sandstone moreover the viscosity ratio of the two fluids are much higher about 10 times larger than of that the typical oil water systems the two challenges lead to computational difficulties that require careful choices of the input parameters discretization and boundary conditions the second goal is evaluating the performance of the lb method and pnms by comparing the relative permeabilities computed by them with those obtained through the direct numerical simulation of the fluid flow in the image of the sandstone in addition we also study the effect of the capillary number i e the effect of flow on the results the organization of the rest of this paper is as follows in the next section the porous formation whose flow properties will be computed is described section 3 provides brief description of the three distinct computational approaches that we have utilized in our work the validation of the computational methods is described in section 4 while the main results of the paper are presented and discussed in section 5 in section 6 we discuss the significance of the resolution of the lattices used in the lb simulations the main results are summarized in the last section 2 mt simon sandstone the sample porous medium is from mt simon sandstone at a depth of 6700 feet the formation is located at verification well number 2 of a study site in decatur illinois where as mentioned earlier illinois state geological survey carried out a pilot injection study to better understand the feasibility of full scale ccs finley 2014 a core plug from the formation was scanned by micro ct imaging technique at the national energy technology laboratory netl of the u s department of energy which produced a series of gray scale scans table 1 presents the information of a cubic sample from the core plug a series of image processing steps were taken in fiji schindelin et al 2012 to filter and smooth images in order to distinguish void space from the solid grains via a thresholding algorithm the outcome was a segmented 12003 voxels sample with porosity of 27 1 and voxel size of 2 80 μm i e a 3 363 mm3 sample we took eight equal size subsamples each of size 5003 voxels from the center of the main sample to study its geometrical topological and flow properties table 2 presents a list of the subsamples with their corresponding porosity fig 1 presents both a high resolution cross section of the original sample and a 3d representation of a 5003 voxels subsample s2 one slice of this subsample in both gray scale and segmented format is presented in fig 2 table 3 presents the important properties of subsample s2 2 1 construction of the pore network to characterize the heterogeneity of mt simon sandstone as well as carrying out single and two phase flow simulations we extracted from the images the equivalent pnms of the eight sandstone subsamples to do so we used the maximal ball mb algorithm dong and blunt 2009 that searches the entire voxelized pore space in order to identify the largest possible spheres in the porous medium the algorithm was developed originally by silin and patzek 2006 and was extended and improved by al kharusi and blunt 2007 dong and blunt 2009 arand and hesser 2017 and raeini et al 2017 in the algorithm the input is the voxelized binarized geometry of the porous medium in which the solid and pore phases are stored as 1 and 0 respectively all the zero voxels are scanned and the largest possible voxelized sphere in the pore space for each of them is determined the resulting voxelized sphere for each pore voxel is taken as the mb in practice many mbs are inside the larger mbs and therefore should be removed the resulting mbs are sorted and clustered based on their size that helps identifying the ancestor mbs the local maximums based on the size and a chain of the mbs that are from one ancestor to another one dong and blunt 2009 each chain is segmented such that it represents a configuration of two pore bodies and their connecting pore throat finally by counting voxels of each element pore body or pore throat various geometrical features such as the location radius volume length and shape factor are calculated and stored the pore throat length is defined as the difference between the total pore throat length and the lengths of the neighboring pore bodies the pore body length is defined as a function of its radius and the total pore throat length is defined as center to center euclidean distance between two neighboring pore bodies dong and blunt 2009 the shape factor g summarizes all the irregularities of the geometry of the pore bodies and pore throats by g vl a2 where a is surface area and v is volume of the voxelized element l is defined as twice the distance between the center of the ancestor mb and the farthest voxel in that mb dong and blunt 2009 the shape factor is a key quantity that helps assigning familiar geometries such as circles squares and triangles to the cross sections of the pore bodies and pore throats in the pnm flow solvers patzek and kristensen 2001 patzek and silin 2001 fig 3 presents the resulting pnm for sample s2 of mt simon sandstone that we generated using the algorithm as well as the size distributions of its pore bodies and pore throats the ratio of the median pore throat length and the radius is about 16 7 table 4 presents the data for the connectivity of all the eight samples in terms of the average coordination number of their resulting pnms the connectivity density of the samples i e connectivity per unit volume is on the order of 2 10 5 pixel 3 while the ratio of their pore throat length and radii is similar to that of sample s2 also shown in table 4 is the degree of anisotropy da of all the eight samples the da is a measure of how highly oriented the pore structure of a medium is within a volume harrigan and mann 1984 odgaard and gundersen 1993 odgaard 1997 toriwaki and yonekura 2002 we used the bonej plugin in fiji the image processing package to calculate the da of the void space of the eight samples the method is based on the mean intercept length mil method by which a large number of equal length vectors originating from a random point within the pore space are drawn and an intercept is counted for each vector when it hits a boundary the mil is the vector length divided by the number of boundary hits a cloud of points is formed where each point represents the vector times its mil and then an ellipsoid is fitted to the cloud the anisotropy tensor is then constructed and the eigenvalues and eigenvectors related to the lengths and orientations of the ellipsoid s axes are computed odgaard 1997 the da is defined as 1 da 1 smallest eigenvalue largest eigenvalue the algorithm is stochastic and therefore new random points with the same vectors yield new mil counts the da must be updated until either the minimum number of sampling points is reached or the coefficient of variation of da becomes smaller than a threshold as table 4 indicates the samples are slightly anisotropic thus we ignore it in the flow calculations 2 2 analysis of the heterogeneity we carried extensive analysis of the morphology of the selected sample of mt simon sandstone in order to characterize the severity of its heterogeneity this was accomplished by analyzing the 3d image of sample s2 extracting its equivalent pn and comparing the results to those of a sample berea sandstone which is a fairly homogeneous porous medium and whose properties are presented in table 5 in the study of the heterogeneity via image analysis we took fifteen equal size subsamples each 1 8 of the original sample eight of which were from the corners six from the sides and one at the center we then computed the porosity and degree of anisotropy da of the subsamples the results are presented in fig 4 to quantify the variability across the subsamples we computed the coefficient of variation cv of each property for each sample the results are presented in table 6 according to which the cvs of the porosity and the da from the mt simon sandstone are larger than those for the berea sandstone sample hence indicating that the former has more variability is more heterogeneous in analyzing the heterogeneity of mt simon sandstone using the pn we used a stochastic approach whereby a calculation box with a size 1 8 of the pn extracted from the original sample was selected randomly then the average coordination number z of the pore bodies inside the calculation box was calculated since z quantifies the connectivity of the pore space well the results for 100 realizations of the mt simon sandstone sample s2 and their comparison with those for the berea sandstone sample are presented in fig 5 according to the data the cv of the average coordination numbers is 0 054 for the mt simon pn but 0 025 for the berea pn therefore the mt simon sandstone sample s2 encompasses more variability in its pore connectivity relative to the berea sandstone sample and thus it is more heterogeneous 2 3 determining the size of the representative elementary volume a careful study was undertaken in order to determine the size of the representative elementary volume rev for the flow studies it turned out that a size of 5003 voxels was large enough to represent the average flow properties fig 6 presents three computed properties of the sample versus its linear size calculated by fiji while fig 7 shows the variation of the absolute permeability computed by the lb simulation in order to identify the size of the rev the variation of the computed properties with the sample size becomes negligible at a size of about 3003 voxels thus justifying the choice of simulation sizes larger than the identified size using the three computational approaches described in the next section we also carried out single phase flow simulation with the eight subsamples employing the three aforementioned approaches namely the lb method direct numerical simulation of stokes flow using openfoam and pn calculations in order to evaluate the absolute permeability of each of the eight samples the results will be discussed shortly for now it suffices to say that they indicate that the original sample is highly heterogeneous since different subsamples from different locations have different average properties while they are also representative of a rev thus as mentioned earlier to study two phase flows we selected subsample s2 in table 2 whose characteristics are presented in table 3 3 computational approaches as mentioned earlier we have carried out extensive simulations of fluid flow using three distinct computational methods the details of each are as follows 3 1 the lattice boltzmann method as is well known the lb method is based on streaming collision and relaxation of a set of fluid particle distribution functions pdf on a lattice the no slip boundary conditions on solid surfaces are implemented by simply switching the directions of the particles on the surface nodes the so called bounce back scheme there are several lb schemes for simulating multiphase flows huang et al 2015 liu et al 2016 among them the color fluid model grunau et al 1993 gunstensen et al 1991 is capable of producing a relatively sharp interface between completely immiscible fluids which is why it has been widely adopted ahrenholz et al 2008 jiang and tsuji 2017 in addition it can deal with high viscosity ratios due to its independent control of the surface tension and viscosity chen et al 2018 in the present work we use a variant of the multiple relaxation time mrt color fluid lb simulator tölke 2002 tölke et al 2006 chen et al 2018 in the model each phase has its own set of pdfs and the discrete boltzmann s equation is solved for each fluid phase in our in house lb code we consider two sets of the d3q19 pdfs i e a 3d model with 19 velocities representing the two fluid phases referred to as the fluids r and b which follow the collision streaming procedure for the pdf 2 f i s x e i δ t t δ t f i s x t ω i s 3 ω i s 1 ω i s 2 s r b where ω i s 1 is the standard lb collision operator ω i s 2 is the perturbation step that generates the surface tension effect and ω i s 3 is the recoloring step that separates the two fluids the collision operators ω i s 1 and ω i s 2 are constructed under the mrt framework that increases stability and accuracy of the model lallemand and luo 2000 tölke et al 2006 chen et al 2018 d humieres 2002 more details of our in house code are given by chen et al 2018 the macroscopic quantities such as fluid velocity and pressure are computed by calculating the moments of the pdf since the outputs produced by the lb simulation are defined in terms of lattice units they must be converted to physical units ramstad et al 2012 sukop 2006 in the present work we simulate a method of measuring the relative permeabilities known as the steady state method in this method a predefined fractional flow of both fluid phases is injected into the pore space at constant flow rates while the pressure drop across the sample is constant steady state is reached when the downstream and upstream fractional flows are equal more details about the steady state measurement are given by honarpour et al 1986 in the lb model the predefined fractional flow is implemented as an initial randomly distributed saturation that will also be the target saturation we mirror the input geometry and impose periodic boundary conditions along the flow direction as well in order to allow both fluid phases enter and exit the model smoothly a body force is applied to each fluid phase to achieve the same pressure drop and avoid capillary end effects to ensure that steady state has been reached various quantities such as the flow rates should be monitored in order to check whether they converge to steady state values which are then used for the relative permeability calculation at the set target saturation a similar method of measuring relative permeabilities was described by ramstad et al 2012 3 2 direct numerical simulation the second computational method that we employed was direct numerical simulation dns using the openfoam open source for both single and two phase fluid flow the simulator uses finite volume discretization and solves the continuity and momentum equations the stokes equations in the pore space we used an unstructured mesh with grid size of 23 and 1 voxels in the pore volumes and throat and corner points between the solid boundaries respectively meaning that the grid blocks that are used in the throats and the corners are half the size in each direction of those used in the pores employing a modified openfoam mesh generator qaseminejad raeini 2013 the total number of grid blocks used to discretize the image volume was 10 815 820 for each capillary number the simulations employed 300 processors in parallel unlike the lb method the finite volume simulations are run under unsteady state conditions and the results are measured in a dynamic drainage simulation more details about the method and its implementations are given in the two phase flow solver of openfoam interfoam ubbink 1997 as usual darcy s law and its generalization to two phase flow are assumed there are various methods for upscaling the microscopic dynamic and capillary pressures to the darcy scale pressure but it is not clear which method averages the microscopic pressure most accurately raeini et al 2014 analyzed five methods in a steady state incompressible single phase flow calculation to obtain the darcy scale pressure drop among all the methods the velocity weighted average of the viscous forces as well as the velocity weighted average of the pore scale pressure gradient matched the experimental results most closely the same equations with some modifications can be used to calculate the macroscopic pressure drop in two phase flow in the dns simulations the velocity weighted average of the viscous forces was employed in order to calculate the total macroscopic pressure drop δpα in each phase 3 δ p α 1 q α u μ u d v α 4 μ β μ 1 1 β μ 2 where α may be either the wetting or non wetting phase qα is the flow rate of phase α u is the velocity vector and vα is the portion of flow volume filled with phase α in eq 4 μ1 and μ2 are viscosities of the two fluids and β is the volume fraction of fluid 1 in each grid cell more details on upscaling of pore scale forces are given by raeini et al 2014 various methods have been developed for including the interfacial tension in eulerian grids they include the continuous surface stress css gueyffier et al 1999 continuous surface force csf sharp surface force ssf francois et al 2006 and filtered surface force fsf raeini et al 2012 the main problem with the csf is the spurious velocity in the flow field which to some extent is controlled in the ssf method controlling the sharpness of the capillary pressure in the ssf method is accomplished by defining a sharpened indicator function in the fsf method the indicator is modified to have a smoother capillary force compared to the ssf approach for the interface motion this modification compresses the transition area of the capillary pressure with this implementation the issue with the non physical velocities that may arise is resolved and the capillary pressure transition area is only one grid block therefore the fsf formulation is used for the complex geometry used in this study 3 3 pore network model the pnm simulation of drainage displacement of brine by co2 was carried out under the quasi static condition which corresponds to low capillary number it uses an invasion percolation ip algorithm wilkinson and willemsen 1983 for the most efficient algorithm to simulate the ip see sheppard et al 1999 and knackstedt et al 2000 all the pore elements were initially saturated with the wetting phase pore elements become occupied by injecting non wetting phase through piston like displacement and based on the young laplace equation that connects the pressure in the two phases at the interface between them the complete procedure that we used is described by valvatne and blunt 2004 and need not be repeated here all the pore bodies and pore throats were assumed to triangular cross sections in all three approaches the usual generalized darcy s law for multiphase flows 5 v α k r α s α k μ α δ p α δ x was used to compute the relative permeabilities where kr αis the relative permeability of phase α sα is its saturation and vα is its corresponding darcy velocity which is proportional to total flow rate passing through the medium the relative permeability is generally a function of the phase saturation wettability and the structure of the pore space the competition between the capillary and viscous forces influences the displacement of one fluid by the second one which is expressed by the capillary number ca 6 ca μ q tot a σ where qtot refer to the total flowrate of phases μ is effective viscosity a is the cross sectional area and σ is the surface tension 4 test of the accuracy of the numerical approaches we tested our computational methods with an oil water system in a water wet berea sandstone sample the sample having the data listed in table 5 has been extensively studied and used in the literature raeini et al 2014 ramstad et al 2012 valvatne and blunt 2004 and is considered a benchmark we compare the calculated relative permeabilities of the oil water system during drainage with the experimental data oak et al 1990 in fig 8 table 7 presents the properties of the two phase flow system the lb results for the water relative permeabilities are slightly larger than the experimental data but as we discuss below this is due to the resolution of the lattice used in the simulation as the resolution increases the agreement between the lb results and the data improves significantly the agreement between the dns results and the data is excellent the results from the dns and lb methods are reported up to the water saturation of about 45 sw 0 45 where water permeability becomes negligible we did not further continue the simulations due to the limited computational resources 5 results and discussion after validating our computational methods with the experimental data we carried out extensive simulation of both single and two phase flow in the image of mt simon sandstone in what follows we present and discuss results 5 1 single phase flow as pointed out earlier the size of the rev for the single phase simulations with the eight subsamples was 5003 voxels using the dns we computed the single phase permeability for an image size of 5003 and resized subsamples of size 2503 voxels with the same physical size i e 1 43 mm3 but with a coarser image resolution of 5 6 μm with the upstream and downstream pressures of 5 pa and 0 pa the fluid density and viscosity were set to be the same as those of brine μ 0 0011 pa s and ρ 1100 kg m3 fig 9 shows the original mesh and the pressure distribution of the subsample s5 with 5003 voxels the same properties were used in the lb method to calculate the absolute permeabilities for both sizes however due to the low computational cost of simulation of single phase flow with the pnm no resizing was needed and the simulations were performed only with the original 5003 voxels samples the main purpose of carrying out the lb and dns simulations on the resized subsamples was reducing the size of the input geometry of our two phase flow simulations that reduces significantly the computational costs for both methods the absolute permeabilities of the eight subsamples calculated by the dns lb and pnm are reported in table 8 a few features of table 8 are worth pointing out i the absolute permeabilities computed by the dns and lb for the original 5003 subsamples are quite close to that of the resized 2503 subsamples this indicates that the resizing process honors the connectivity of the sample well the small increase in the permeabilities of the resized 2503 subsamples is due to the interpolation of the voxelized geometry during downsizing that removes minor irregularities in narrow pores and thus reduces flow resistance however this does not change the overall connectivity of the sample and the resulting permeabilities are still in good agreement as an example the absolute permeability of subsample s2 changes from 4278 md to 4211 md computed by the lb simulation after resizing while its porosity remains almost unchanged therefore the resized 2503 subsamples were considered as a good enough approximation of the original 5003 subsamples and were used in two phase flow simulations ii the permeabilities computed by the lb simulations agree with those computed by the dns for the 5003 images the difference between the two sets of results is about 10 or less in most cases this is also encouraging iii a comparison of all the computed absolute permeabilities of all the eight subsamples indicates that the original mt simon sandstone is indeed heterogeneous 5 2 two phase flow we used both the lb method and dns in addition to the quasi static pn computations to carry out simulation of drainage for the co2 brine pair in the mt simon sandstone sample s2 and evaluate the drainage relative permeabilities for two capillary numbers ca table 9 presents the properties of the co2 brine system used in the simulations we first carried out simulation of drainage with specified injection velocity or flow rate at the inlet and pressure boundary condition at the outlet to capture the invasion pattern of co2 through the initially brine saturated sample in addition initially the first 8 of the grid blocks were filled with the non wetting phase at the low capillary number the average inlet fluid velocity was 0 014 m s while for the high capillary number the inlet velocity was set at 0 0465 m s fig 10 shows the results produced by the lb simulation where the co2 front was injected into the sample from the left at an average wetting phase saturation of sw 0 50 indicating a fingering pattern and very heterogeneous spatial distribution of co2 in the pore space in order to have a quantitative comparison and consistency check of the results produced by the lb and dns methods we compare the dependence of the co2 saturation on the distance from the inlet along the direction of macroscopic flow the results are shown in fig 11 where co2 saturation represents an average taken over the cross sectional area the results produced by the two methods follow one another very closely in addition we computed the change in the brine saturation in the sample volume over time for the two ca numbers the results shown in fig 12 indicate again that the two simulation methods provide consistent and closely agreeing results this gave us confidence that a comparison between the relative permeabilities produced by the two methods as well as those produced by the pnm is viable and meaningful fig 13 compares the spatial distributions of co2 injected from left side and brine for two capillary numbers produced by the dns when the latter has reached its residual saturation consistent with what is known for the oil water pairs in porous media the displacement pattern at high capillary number is more uniform better connected and piston like with a lower residual saturation for the brine phase than that obtained with the lower capillary number that exhibits fingering pattern with a fractal structure perhaps this can be seen better if we consider a side view of the displacement patterns shown in fig 14 which are consistent with those shown in fig 13 thus depending on the heterogeneity of the pore space at lower capillary numbers the capillary fingering effect can be strongly dominant in that case there can be some fluctuations in the relative permeabilities unlike the smoother varying values for high capillary numbers it may also indicate that obtaining smoothly varying relative permeabilities for low capillary numbers entails using larger revs note that at the end of the simulations the calculated brine residual saturations for the high and low capillary number are 0 30 and 0 50 reached at times 54 ms and 122 ms respectively in fig 15 we compare the computed relative permeabilities of the co2 brine pair for the lower capillary number that we simulated all the relative permeabilities computed by the three methods are in good agreement with each other although the methodologies are completely different fig 16 compares the relative permeabilities computed by the lb method and the dns for the higher capillary number in this case too the results are in agreement with each other since our pnm simulator is designed for quasi static displacement by an ip like algorithm it could not be used for simulating an arbitrary value of the capillary number when the magnitude of the viscous forces is competitive with the capillary forces in such case one must use a dynamic pn simulator joekar niasar and hassanizadeh 2012 it should be pointed out that to compute the relative permeabilities by the lb simulator for each brine saturation a separate simulation should be carried out whereas they are computed by one complete simulation when the openfoam porefoam package raeini et al 2014 is used in the dns as it simulates the entire process from the beginning of injection of co2 to reaching the brine residual saturation but if the goal is to compute the quantities of interest for a single saturation then the lb method is more efficient the lb method has however a problem with spurious velocity which is resolved in the dns simulator that we employ in this study by using the fsf approach instead of the csf method see the earlier discussions to account for the interfacial forces note also that the pnm simulation particularly for low capillary numbers does not require high performance computational resources thus it is still a reliable method for low ca number systems if the pn used is accurate representation of the pore structure 6 the importance of resolution of the computational grid an important point should however be emphasized if the lb simulation is used with an image of a porous medium one must make sure that the resolution of the lattice used is high enough that is the results must be independent of the resolution for example in the calculations that we carried out it was not enough to have one lattice unit per voxel and thus the lattice with higher resolutions was needed fig 17 compares the results computed by the lb simulation obtained with two lattice resolutions for two ca numbers in the low resolution simulation one lattice unit was defined for each void space voxel whereas eight lattice units were utilized for each voxel of the input geometry in the high resolution simulation fig 17 indicates that only when high resolution lattices are used do the lb results converge to those obtained by the dns 7 summary and conclusions in order to study two phase flow of co2 brine in the three dimensional image of a heterogeneous porous medium the mt simon sandstone we first carried out a detailed quantitative study of the pore structure on several subsamples from the rock then we used three distinct computational approaches namely the lattice boltzmann method direct numerical simulation of the navier stokes equations and a pore network model extracted from the image the main process simulated was drainage displacement of brine by co2 the relative permeabilities of the two fluids for two capillary numbers were computed and compared provided that the computational grid in the dns and the lattice used in the lb simulation have high enough resolution the computed relative permeabilities agree very closely the dns approach requires however a single drainage simulation to compute the relative permeabilities over the entire intended range of saturation whereas the lb approach needs a separate steady state simulation for each saturation and therefore it requires more computational resources in addition the difference in the results produced by the dns and lb may be due to the different formulations used for the capillary forces parallel to the interfaces the fsf formulation used in the dns method eliminates non physical velocities whereas the csf formulation employed in the lb simulation results in nonphysical currents especially in complex geometries the relative permeabilities computed by the pnm at a low capillary number also agree with those obtained by the lb simulation and the dns although the pnm does not need any high performance computational resources therefore the question of which method to use for such simulations should be addressed based mainly on the computational time that they need and the computational resources that one has access too in addition one should carefully examine the effect of the resolution of the lattice used in the lb simulation improving the interfacial surface formulation in the lb simulation is expected to improve its accuracy leading to much closer agreement with the results obtained by the dns method declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported as part of the center for geological storage of co2 an energy frontier research center funded by the u s department of energy office of science basic energy sciences under award de sc0c12504 a h k and m r contributed equally to the paper 
543,understanding the physics of two phase flow of co2 and brine in porous geological formations is essential to sequestration of carbon dioxide in deep saline reservoirs as well as the older problem of enhanced oil recovery from hydrocarbon reservoirs by co2 injection a pilot co2 injection in decatur illinois was undertaken with the injection zone being the highly saline and heterogeneous mt simon sandstone in order to better understand the feasibility of full scale sequestration process this paper reports the results of an extensive study of the morphology of the sandstone and its heterogeneity and simulation of single phase and two phase flow of co2 and brine in the formation s three dimensional images as we demonstrate by extensive analysis the formation is much more heterogeneous than the typical sandstone such as berea sandstone in addition to characterizing the morphology of the sandstone and computing its important flow characteristics an important goal of the study is to compare the accuracy and computational efficiency of three distinct simulation approaches namely the lattice boltzmann lb approach direct numerical simulation dns of the governing equations of fluid flow that uses the finite volume method coupled with the openfoam simulator and pore network pn simulation after validating the simulators by comparing the computed relative permeabilities that they produce for berea sandstone we simulate displacement of brine by co2 at low and relatively high capillary numbers and compute the relative permeabilities and other quantities of interest we demonstrate that all the three methods provide consistent relative permeability saturation functions that are in close agreement with one another however although the lb and dns both produce similar relative permeabilities the dns approach is computationally more efficient because it simulates drainage by only a single set of computations over the entire saturation range whereas the lb simulation requires separate simulation for each set saturation thus the question of what method to use for simulating such flow processes at the scale of core plugs should mainly be addressed based on the computational time that one can afford and the computational resources that one has access to another important question addressed is the effect of the resolution of the computational grids or lattices used particularly when one uses the lb method with voxelized images of porous media we show that unlike many claims in the past one may need many lattice units per voxel in order to obtain reliable lattice independent results 1 introduction the physics of two phase flows in porous media is of utmost importance to many problems of practical interest such as co2 sequestration in deep saline reservoirs recovery of oil from hydrocarbon reservoirs transport of non aqueous phase liquid contaminants in aquifers and infiltration of rainfall into soil understanding and predicting the properties of such flow processes at various length scales are vital to addressing the problem of global warming as well as managing water resources and energy production there is increasing incentive for studying two phase flow of co2 and brine in porous media due to societal interest in geological sequestration of co2 the drastic increase in the amount of co2 in the atmosphere plays the most important role in global climate change friedlingstein and solomon 2005 metz et al 2005 nordbotten and celia 2011 the main source of the atmospheric co2 is combustion of fossil fuels for producing electricity in power plants among the various approaches that have been suggested for mitigating the problem co2 capture and storage ccs is believed to be a viable solution nordbotten and celia 2011 the ccs is a process associated with separating co2 from the other gases that are produced by power plants and other sources compressing and transporting it to storage locations and keeping it sequestered in onshore or offshore geological formations for very long times metz et al 2005 as an example the united states can inject up to 65 of the co2 produced by power plants deep into saline aquifers shukla et al 2010 since such a sequestration process appears to have great potential understanding the behavior of flow of brine and co2 in deep porous formations is vital juanes et al 2006 pruess and garcia 2002 to its successful implementation and should accompany any comprehensive study of geological storage of co2 that includes its economic feasibility site selection risk assessment environmental impact safety aspects monitoring and verification in addition to perspectives on retention time physical leakage brine displacement and microseismicity metz et al 2005 the illinois state geological survey carried out a pilot injection study to better understand the feasibility of full scale ccs the study site is in decatur illinois and the injection zone is the highly saline mt simon sandstone finley 2014 thus one goal of the present study is to analyze two phase flow of co2 and brine in mt simon sandstone and more generally in natural rock the phenomenon may be studied at various length scales including molecular core and field scales by experiments and computer simulation experiments are of course quite useful but can be difficult to implement as they are time consuming and expensive joekar niasar and hassanizadeh 2012 at the molecular scale the interaction between water and water co2 and mixed layer clay was recently studied rahromostaqim and sahimi 2018 2019 advances in modeling of porous media as well as development of efficient computer simulation together with increasing computer powers have made it possible to model and study in detail two phase flow of brine and co2 at core plug and larger length scales compared to experiments the computational approaches have the advantages of being generally less expensive and more flexible in implementing and changing parameters flow and displacement mechanisms and studying various mechanisms of displacements at the same time numerical simulation of flow of brine and co2 at field scale requires such inputs as the relative permeabilities and capillary pressure as functions of the saturation at the scale of the grid blocks which can be obtained by experiments or by pore scale modeling pore scale modeling celia et al 1995 can provide the required input data for field scale modeling provided that one takes into account the effect of the morphology of the core scale porous media and the various pore scale mechanisms of fluid displacements this is because pore scale flow affects significantly the characteristics of the process at larger scales including injection and storage of co2 in depleted reservoirs and other types of large scale porous formations juanes et al 2006 pruess and garcia 2002 raeini et al 2014 with advances in instrumentation it has become possible to obtain three dimensional 3d images of porous media with high resolution by for example x ray computed tomography ct blunt et al 2013 at pore scale detailed 3d geometry of rock and its void space can be captured by direct imaging using nondestructive x ray microtomography dunsmuir et al 1991 flannery et al 1987 various rock properties such as the permeability have been computed with the aid of micro ct images arns et al 2002 øren and bakke 2002 ramstad et al 2010 krevor et al 2012 bakhshian et al 2018 thus one can directly simulate two phase flows in the images which renders as unnecessary developing models of the pore space image based methods are however computationally expensive although recent advances in high performance computing as well as a new method that smoothens the image without changing its properties using curvelet transformations aljasmi and sahimi 2019 are making use of such methods increasingly common the methods that are used for simulating fluid flow in the images are either based on directly solving the governing equations for fluid flow i e the stokes equation using the finite volume method ferrari and lunati 2013 huang et al 2005 rabbani et al 2017 or based on the lattice boltzmann lb method boek and venturoli 2010 ferreol and rothman 1995 pan et al 2004 porter et al 2009 ramstad et al 2012 rothman 1990 the lb method has been demonstrated to be well suited for high performance parallel computing in the complex geometry of porous media ahrenholz et al 2008 chen et al 2018 ramstad et al 2012 tölke et al 2006 in addition advances in method based on the volume of fluids especially the new developments of surface force formulation have made it possible to efficiently model two phase flow by the finite volume method at lower capillary numbers gueyffier et al 1999 another approach is based on pore network models pnms sahimi 2011 blunt et al 2013 in which the pore space is simplified to a network of interconnected pore bodies and pore throats while the pnms are computationally very efficient and inexpensive they still involve some assumptions and approximations such as the definition of what constitutes a pore body or pore throat how to assign effective sizes to them etc ramstad et al 2012 joekar niasar and hassanizadeh 2012 therefore a detailed comparison between the results of the pnm computations with those obtained by the other two aforementioned methods will shed much light on its advantages and limitations the goal of this paper is twofold one is computing the drainage relative permeability functions for co2 and brine during injection of the former into a sample of mt simon sandstone this is not a trivial problem as mt simon sandstone is much more heterogeneous than typical sandstones studied in the past such as the berea sandstone moreover the viscosity ratio of the two fluids are much higher about 10 times larger than of that the typical oil water systems the two challenges lead to computational difficulties that require careful choices of the input parameters discretization and boundary conditions the second goal is evaluating the performance of the lb method and pnms by comparing the relative permeabilities computed by them with those obtained through the direct numerical simulation of the fluid flow in the image of the sandstone in addition we also study the effect of the capillary number i e the effect of flow on the results the organization of the rest of this paper is as follows in the next section the porous formation whose flow properties will be computed is described section 3 provides brief description of the three distinct computational approaches that we have utilized in our work the validation of the computational methods is described in section 4 while the main results of the paper are presented and discussed in section 5 in section 6 we discuss the significance of the resolution of the lattices used in the lb simulations the main results are summarized in the last section 2 mt simon sandstone the sample porous medium is from mt simon sandstone at a depth of 6700 feet the formation is located at verification well number 2 of a study site in decatur illinois where as mentioned earlier illinois state geological survey carried out a pilot injection study to better understand the feasibility of full scale ccs finley 2014 a core plug from the formation was scanned by micro ct imaging technique at the national energy technology laboratory netl of the u s department of energy which produced a series of gray scale scans table 1 presents the information of a cubic sample from the core plug a series of image processing steps were taken in fiji schindelin et al 2012 to filter and smooth images in order to distinguish void space from the solid grains via a thresholding algorithm the outcome was a segmented 12003 voxels sample with porosity of 27 1 and voxel size of 2 80 μm i e a 3 363 mm3 sample we took eight equal size subsamples each of size 5003 voxels from the center of the main sample to study its geometrical topological and flow properties table 2 presents a list of the subsamples with their corresponding porosity fig 1 presents both a high resolution cross section of the original sample and a 3d representation of a 5003 voxels subsample s2 one slice of this subsample in both gray scale and segmented format is presented in fig 2 table 3 presents the important properties of subsample s2 2 1 construction of the pore network to characterize the heterogeneity of mt simon sandstone as well as carrying out single and two phase flow simulations we extracted from the images the equivalent pnms of the eight sandstone subsamples to do so we used the maximal ball mb algorithm dong and blunt 2009 that searches the entire voxelized pore space in order to identify the largest possible spheres in the porous medium the algorithm was developed originally by silin and patzek 2006 and was extended and improved by al kharusi and blunt 2007 dong and blunt 2009 arand and hesser 2017 and raeini et al 2017 in the algorithm the input is the voxelized binarized geometry of the porous medium in which the solid and pore phases are stored as 1 and 0 respectively all the zero voxels are scanned and the largest possible voxelized sphere in the pore space for each of them is determined the resulting voxelized sphere for each pore voxel is taken as the mb in practice many mbs are inside the larger mbs and therefore should be removed the resulting mbs are sorted and clustered based on their size that helps identifying the ancestor mbs the local maximums based on the size and a chain of the mbs that are from one ancestor to another one dong and blunt 2009 each chain is segmented such that it represents a configuration of two pore bodies and their connecting pore throat finally by counting voxels of each element pore body or pore throat various geometrical features such as the location radius volume length and shape factor are calculated and stored the pore throat length is defined as the difference between the total pore throat length and the lengths of the neighboring pore bodies the pore body length is defined as a function of its radius and the total pore throat length is defined as center to center euclidean distance between two neighboring pore bodies dong and blunt 2009 the shape factor g summarizes all the irregularities of the geometry of the pore bodies and pore throats by g vl a2 where a is surface area and v is volume of the voxelized element l is defined as twice the distance between the center of the ancestor mb and the farthest voxel in that mb dong and blunt 2009 the shape factor is a key quantity that helps assigning familiar geometries such as circles squares and triangles to the cross sections of the pore bodies and pore throats in the pnm flow solvers patzek and kristensen 2001 patzek and silin 2001 fig 3 presents the resulting pnm for sample s2 of mt simon sandstone that we generated using the algorithm as well as the size distributions of its pore bodies and pore throats the ratio of the median pore throat length and the radius is about 16 7 table 4 presents the data for the connectivity of all the eight samples in terms of the average coordination number of their resulting pnms the connectivity density of the samples i e connectivity per unit volume is on the order of 2 10 5 pixel 3 while the ratio of their pore throat length and radii is similar to that of sample s2 also shown in table 4 is the degree of anisotropy da of all the eight samples the da is a measure of how highly oriented the pore structure of a medium is within a volume harrigan and mann 1984 odgaard and gundersen 1993 odgaard 1997 toriwaki and yonekura 2002 we used the bonej plugin in fiji the image processing package to calculate the da of the void space of the eight samples the method is based on the mean intercept length mil method by which a large number of equal length vectors originating from a random point within the pore space are drawn and an intercept is counted for each vector when it hits a boundary the mil is the vector length divided by the number of boundary hits a cloud of points is formed where each point represents the vector times its mil and then an ellipsoid is fitted to the cloud the anisotropy tensor is then constructed and the eigenvalues and eigenvectors related to the lengths and orientations of the ellipsoid s axes are computed odgaard 1997 the da is defined as 1 da 1 smallest eigenvalue largest eigenvalue the algorithm is stochastic and therefore new random points with the same vectors yield new mil counts the da must be updated until either the minimum number of sampling points is reached or the coefficient of variation of da becomes smaller than a threshold as table 4 indicates the samples are slightly anisotropic thus we ignore it in the flow calculations 2 2 analysis of the heterogeneity we carried extensive analysis of the morphology of the selected sample of mt simon sandstone in order to characterize the severity of its heterogeneity this was accomplished by analyzing the 3d image of sample s2 extracting its equivalent pn and comparing the results to those of a sample berea sandstone which is a fairly homogeneous porous medium and whose properties are presented in table 5 in the study of the heterogeneity via image analysis we took fifteen equal size subsamples each 1 8 of the original sample eight of which were from the corners six from the sides and one at the center we then computed the porosity and degree of anisotropy da of the subsamples the results are presented in fig 4 to quantify the variability across the subsamples we computed the coefficient of variation cv of each property for each sample the results are presented in table 6 according to which the cvs of the porosity and the da from the mt simon sandstone are larger than those for the berea sandstone sample hence indicating that the former has more variability is more heterogeneous in analyzing the heterogeneity of mt simon sandstone using the pn we used a stochastic approach whereby a calculation box with a size 1 8 of the pn extracted from the original sample was selected randomly then the average coordination number z of the pore bodies inside the calculation box was calculated since z quantifies the connectivity of the pore space well the results for 100 realizations of the mt simon sandstone sample s2 and their comparison with those for the berea sandstone sample are presented in fig 5 according to the data the cv of the average coordination numbers is 0 054 for the mt simon pn but 0 025 for the berea pn therefore the mt simon sandstone sample s2 encompasses more variability in its pore connectivity relative to the berea sandstone sample and thus it is more heterogeneous 2 3 determining the size of the representative elementary volume a careful study was undertaken in order to determine the size of the representative elementary volume rev for the flow studies it turned out that a size of 5003 voxels was large enough to represent the average flow properties fig 6 presents three computed properties of the sample versus its linear size calculated by fiji while fig 7 shows the variation of the absolute permeability computed by the lb simulation in order to identify the size of the rev the variation of the computed properties with the sample size becomes negligible at a size of about 3003 voxels thus justifying the choice of simulation sizes larger than the identified size using the three computational approaches described in the next section we also carried out single phase flow simulation with the eight subsamples employing the three aforementioned approaches namely the lb method direct numerical simulation of stokes flow using openfoam and pn calculations in order to evaluate the absolute permeability of each of the eight samples the results will be discussed shortly for now it suffices to say that they indicate that the original sample is highly heterogeneous since different subsamples from different locations have different average properties while they are also representative of a rev thus as mentioned earlier to study two phase flows we selected subsample s2 in table 2 whose characteristics are presented in table 3 3 computational approaches as mentioned earlier we have carried out extensive simulations of fluid flow using three distinct computational methods the details of each are as follows 3 1 the lattice boltzmann method as is well known the lb method is based on streaming collision and relaxation of a set of fluid particle distribution functions pdf on a lattice the no slip boundary conditions on solid surfaces are implemented by simply switching the directions of the particles on the surface nodes the so called bounce back scheme there are several lb schemes for simulating multiphase flows huang et al 2015 liu et al 2016 among them the color fluid model grunau et al 1993 gunstensen et al 1991 is capable of producing a relatively sharp interface between completely immiscible fluids which is why it has been widely adopted ahrenholz et al 2008 jiang and tsuji 2017 in addition it can deal with high viscosity ratios due to its independent control of the surface tension and viscosity chen et al 2018 in the present work we use a variant of the multiple relaxation time mrt color fluid lb simulator tölke 2002 tölke et al 2006 chen et al 2018 in the model each phase has its own set of pdfs and the discrete boltzmann s equation is solved for each fluid phase in our in house lb code we consider two sets of the d3q19 pdfs i e a 3d model with 19 velocities representing the two fluid phases referred to as the fluids r and b which follow the collision streaming procedure for the pdf 2 f i s x e i δ t t δ t f i s x t ω i s 3 ω i s 1 ω i s 2 s r b where ω i s 1 is the standard lb collision operator ω i s 2 is the perturbation step that generates the surface tension effect and ω i s 3 is the recoloring step that separates the two fluids the collision operators ω i s 1 and ω i s 2 are constructed under the mrt framework that increases stability and accuracy of the model lallemand and luo 2000 tölke et al 2006 chen et al 2018 d humieres 2002 more details of our in house code are given by chen et al 2018 the macroscopic quantities such as fluid velocity and pressure are computed by calculating the moments of the pdf since the outputs produced by the lb simulation are defined in terms of lattice units they must be converted to physical units ramstad et al 2012 sukop 2006 in the present work we simulate a method of measuring the relative permeabilities known as the steady state method in this method a predefined fractional flow of both fluid phases is injected into the pore space at constant flow rates while the pressure drop across the sample is constant steady state is reached when the downstream and upstream fractional flows are equal more details about the steady state measurement are given by honarpour et al 1986 in the lb model the predefined fractional flow is implemented as an initial randomly distributed saturation that will also be the target saturation we mirror the input geometry and impose periodic boundary conditions along the flow direction as well in order to allow both fluid phases enter and exit the model smoothly a body force is applied to each fluid phase to achieve the same pressure drop and avoid capillary end effects to ensure that steady state has been reached various quantities such as the flow rates should be monitored in order to check whether they converge to steady state values which are then used for the relative permeability calculation at the set target saturation a similar method of measuring relative permeabilities was described by ramstad et al 2012 3 2 direct numerical simulation the second computational method that we employed was direct numerical simulation dns using the openfoam open source for both single and two phase fluid flow the simulator uses finite volume discretization and solves the continuity and momentum equations the stokes equations in the pore space we used an unstructured mesh with grid size of 23 and 1 voxels in the pore volumes and throat and corner points between the solid boundaries respectively meaning that the grid blocks that are used in the throats and the corners are half the size in each direction of those used in the pores employing a modified openfoam mesh generator qaseminejad raeini 2013 the total number of grid blocks used to discretize the image volume was 10 815 820 for each capillary number the simulations employed 300 processors in parallel unlike the lb method the finite volume simulations are run under unsteady state conditions and the results are measured in a dynamic drainage simulation more details about the method and its implementations are given in the two phase flow solver of openfoam interfoam ubbink 1997 as usual darcy s law and its generalization to two phase flow are assumed there are various methods for upscaling the microscopic dynamic and capillary pressures to the darcy scale pressure but it is not clear which method averages the microscopic pressure most accurately raeini et al 2014 analyzed five methods in a steady state incompressible single phase flow calculation to obtain the darcy scale pressure drop among all the methods the velocity weighted average of the viscous forces as well as the velocity weighted average of the pore scale pressure gradient matched the experimental results most closely the same equations with some modifications can be used to calculate the macroscopic pressure drop in two phase flow in the dns simulations the velocity weighted average of the viscous forces was employed in order to calculate the total macroscopic pressure drop δpα in each phase 3 δ p α 1 q α u μ u d v α 4 μ β μ 1 1 β μ 2 where α may be either the wetting or non wetting phase qα is the flow rate of phase α u is the velocity vector and vα is the portion of flow volume filled with phase α in eq 4 μ1 and μ2 are viscosities of the two fluids and β is the volume fraction of fluid 1 in each grid cell more details on upscaling of pore scale forces are given by raeini et al 2014 various methods have been developed for including the interfacial tension in eulerian grids they include the continuous surface stress css gueyffier et al 1999 continuous surface force csf sharp surface force ssf francois et al 2006 and filtered surface force fsf raeini et al 2012 the main problem with the csf is the spurious velocity in the flow field which to some extent is controlled in the ssf method controlling the sharpness of the capillary pressure in the ssf method is accomplished by defining a sharpened indicator function in the fsf method the indicator is modified to have a smoother capillary force compared to the ssf approach for the interface motion this modification compresses the transition area of the capillary pressure with this implementation the issue with the non physical velocities that may arise is resolved and the capillary pressure transition area is only one grid block therefore the fsf formulation is used for the complex geometry used in this study 3 3 pore network model the pnm simulation of drainage displacement of brine by co2 was carried out under the quasi static condition which corresponds to low capillary number it uses an invasion percolation ip algorithm wilkinson and willemsen 1983 for the most efficient algorithm to simulate the ip see sheppard et al 1999 and knackstedt et al 2000 all the pore elements were initially saturated with the wetting phase pore elements become occupied by injecting non wetting phase through piston like displacement and based on the young laplace equation that connects the pressure in the two phases at the interface between them the complete procedure that we used is described by valvatne and blunt 2004 and need not be repeated here all the pore bodies and pore throats were assumed to triangular cross sections in all three approaches the usual generalized darcy s law for multiphase flows 5 v α k r α s α k μ α δ p α δ x was used to compute the relative permeabilities where kr αis the relative permeability of phase α sα is its saturation and vα is its corresponding darcy velocity which is proportional to total flow rate passing through the medium the relative permeability is generally a function of the phase saturation wettability and the structure of the pore space the competition between the capillary and viscous forces influences the displacement of one fluid by the second one which is expressed by the capillary number ca 6 ca μ q tot a σ where qtot refer to the total flowrate of phases μ is effective viscosity a is the cross sectional area and σ is the surface tension 4 test of the accuracy of the numerical approaches we tested our computational methods with an oil water system in a water wet berea sandstone sample the sample having the data listed in table 5 has been extensively studied and used in the literature raeini et al 2014 ramstad et al 2012 valvatne and blunt 2004 and is considered a benchmark we compare the calculated relative permeabilities of the oil water system during drainage with the experimental data oak et al 1990 in fig 8 table 7 presents the properties of the two phase flow system the lb results for the water relative permeabilities are slightly larger than the experimental data but as we discuss below this is due to the resolution of the lattice used in the simulation as the resolution increases the agreement between the lb results and the data improves significantly the agreement between the dns results and the data is excellent the results from the dns and lb methods are reported up to the water saturation of about 45 sw 0 45 where water permeability becomes negligible we did not further continue the simulations due to the limited computational resources 5 results and discussion after validating our computational methods with the experimental data we carried out extensive simulation of both single and two phase flow in the image of mt simon sandstone in what follows we present and discuss results 5 1 single phase flow as pointed out earlier the size of the rev for the single phase simulations with the eight subsamples was 5003 voxels using the dns we computed the single phase permeability for an image size of 5003 and resized subsamples of size 2503 voxels with the same physical size i e 1 43 mm3 but with a coarser image resolution of 5 6 μm with the upstream and downstream pressures of 5 pa and 0 pa the fluid density and viscosity were set to be the same as those of brine μ 0 0011 pa s and ρ 1100 kg m3 fig 9 shows the original mesh and the pressure distribution of the subsample s5 with 5003 voxels the same properties were used in the lb method to calculate the absolute permeabilities for both sizes however due to the low computational cost of simulation of single phase flow with the pnm no resizing was needed and the simulations were performed only with the original 5003 voxels samples the main purpose of carrying out the lb and dns simulations on the resized subsamples was reducing the size of the input geometry of our two phase flow simulations that reduces significantly the computational costs for both methods the absolute permeabilities of the eight subsamples calculated by the dns lb and pnm are reported in table 8 a few features of table 8 are worth pointing out i the absolute permeabilities computed by the dns and lb for the original 5003 subsamples are quite close to that of the resized 2503 subsamples this indicates that the resizing process honors the connectivity of the sample well the small increase in the permeabilities of the resized 2503 subsamples is due to the interpolation of the voxelized geometry during downsizing that removes minor irregularities in narrow pores and thus reduces flow resistance however this does not change the overall connectivity of the sample and the resulting permeabilities are still in good agreement as an example the absolute permeability of subsample s2 changes from 4278 md to 4211 md computed by the lb simulation after resizing while its porosity remains almost unchanged therefore the resized 2503 subsamples were considered as a good enough approximation of the original 5003 subsamples and were used in two phase flow simulations ii the permeabilities computed by the lb simulations agree with those computed by the dns for the 5003 images the difference between the two sets of results is about 10 or less in most cases this is also encouraging iii a comparison of all the computed absolute permeabilities of all the eight subsamples indicates that the original mt simon sandstone is indeed heterogeneous 5 2 two phase flow we used both the lb method and dns in addition to the quasi static pn computations to carry out simulation of drainage for the co2 brine pair in the mt simon sandstone sample s2 and evaluate the drainage relative permeabilities for two capillary numbers ca table 9 presents the properties of the co2 brine system used in the simulations we first carried out simulation of drainage with specified injection velocity or flow rate at the inlet and pressure boundary condition at the outlet to capture the invasion pattern of co2 through the initially brine saturated sample in addition initially the first 8 of the grid blocks were filled with the non wetting phase at the low capillary number the average inlet fluid velocity was 0 014 m s while for the high capillary number the inlet velocity was set at 0 0465 m s fig 10 shows the results produced by the lb simulation where the co2 front was injected into the sample from the left at an average wetting phase saturation of sw 0 50 indicating a fingering pattern and very heterogeneous spatial distribution of co2 in the pore space in order to have a quantitative comparison and consistency check of the results produced by the lb and dns methods we compare the dependence of the co2 saturation on the distance from the inlet along the direction of macroscopic flow the results are shown in fig 11 where co2 saturation represents an average taken over the cross sectional area the results produced by the two methods follow one another very closely in addition we computed the change in the brine saturation in the sample volume over time for the two ca numbers the results shown in fig 12 indicate again that the two simulation methods provide consistent and closely agreeing results this gave us confidence that a comparison between the relative permeabilities produced by the two methods as well as those produced by the pnm is viable and meaningful fig 13 compares the spatial distributions of co2 injected from left side and brine for two capillary numbers produced by the dns when the latter has reached its residual saturation consistent with what is known for the oil water pairs in porous media the displacement pattern at high capillary number is more uniform better connected and piston like with a lower residual saturation for the brine phase than that obtained with the lower capillary number that exhibits fingering pattern with a fractal structure perhaps this can be seen better if we consider a side view of the displacement patterns shown in fig 14 which are consistent with those shown in fig 13 thus depending on the heterogeneity of the pore space at lower capillary numbers the capillary fingering effect can be strongly dominant in that case there can be some fluctuations in the relative permeabilities unlike the smoother varying values for high capillary numbers it may also indicate that obtaining smoothly varying relative permeabilities for low capillary numbers entails using larger revs note that at the end of the simulations the calculated brine residual saturations for the high and low capillary number are 0 30 and 0 50 reached at times 54 ms and 122 ms respectively in fig 15 we compare the computed relative permeabilities of the co2 brine pair for the lower capillary number that we simulated all the relative permeabilities computed by the three methods are in good agreement with each other although the methodologies are completely different fig 16 compares the relative permeabilities computed by the lb method and the dns for the higher capillary number in this case too the results are in agreement with each other since our pnm simulator is designed for quasi static displacement by an ip like algorithm it could not be used for simulating an arbitrary value of the capillary number when the magnitude of the viscous forces is competitive with the capillary forces in such case one must use a dynamic pn simulator joekar niasar and hassanizadeh 2012 it should be pointed out that to compute the relative permeabilities by the lb simulator for each brine saturation a separate simulation should be carried out whereas they are computed by one complete simulation when the openfoam porefoam package raeini et al 2014 is used in the dns as it simulates the entire process from the beginning of injection of co2 to reaching the brine residual saturation but if the goal is to compute the quantities of interest for a single saturation then the lb method is more efficient the lb method has however a problem with spurious velocity which is resolved in the dns simulator that we employ in this study by using the fsf approach instead of the csf method see the earlier discussions to account for the interfacial forces note also that the pnm simulation particularly for low capillary numbers does not require high performance computational resources thus it is still a reliable method for low ca number systems if the pn used is accurate representation of the pore structure 6 the importance of resolution of the computational grid an important point should however be emphasized if the lb simulation is used with an image of a porous medium one must make sure that the resolution of the lattice used is high enough that is the results must be independent of the resolution for example in the calculations that we carried out it was not enough to have one lattice unit per voxel and thus the lattice with higher resolutions was needed fig 17 compares the results computed by the lb simulation obtained with two lattice resolutions for two ca numbers in the low resolution simulation one lattice unit was defined for each void space voxel whereas eight lattice units were utilized for each voxel of the input geometry in the high resolution simulation fig 17 indicates that only when high resolution lattices are used do the lb results converge to those obtained by the dns 7 summary and conclusions in order to study two phase flow of co2 brine in the three dimensional image of a heterogeneous porous medium the mt simon sandstone we first carried out a detailed quantitative study of the pore structure on several subsamples from the rock then we used three distinct computational approaches namely the lattice boltzmann method direct numerical simulation of the navier stokes equations and a pore network model extracted from the image the main process simulated was drainage displacement of brine by co2 the relative permeabilities of the two fluids for two capillary numbers were computed and compared provided that the computational grid in the dns and the lattice used in the lb simulation have high enough resolution the computed relative permeabilities agree very closely the dns approach requires however a single drainage simulation to compute the relative permeabilities over the entire intended range of saturation whereas the lb approach needs a separate steady state simulation for each saturation and therefore it requires more computational resources in addition the difference in the results produced by the dns and lb may be due to the different formulations used for the capillary forces parallel to the interfaces the fsf formulation used in the dns method eliminates non physical velocities whereas the csf formulation employed in the lb simulation results in nonphysical currents especially in complex geometries the relative permeabilities computed by the pnm at a low capillary number also agree with those obtained by the lb simulation and the dns although the pnm does not need any high performance computational resources therefore the question of which method to use for such simulations should be addressed based mainly on the computational time that they need and the computational resources that one has access too in addition one should carefully examine the effect of the resolution of the lattice used in the lb simulation improving the interfacial surface formulation in the lb simulation is expected to improve its accuracy leading to much closer agreement with the results obtained by the dns method declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported as part of the center for geological storage of co2 an energy frontier research center funded by the u s department of energy office of science basic energy sciences under award de sc0c12504 a h k and m r contributed equally to the paper 
544,predicting variable density flow and transport in aquifers is critical for the management of many coastal saline aquifers accurate characterization of hydrogeological parameters is critical for prediction and the characterization is often conducted by assimilating data into models however few studies have investigated the underlying physics controlling the value of information voi of data for aquifer characterization in this study we show how a greater understanding of the underlying physics controlling pressure and concentration data coupling can lead to improved characterization in variable density flow the key physics that controls the voi of pressure and concentration data is the non linear coupling between flow and transport via fluid density which causes the pressure field to experience transient changes according to the evolution of salinity distribution we first demonstrate the coupling between pressure and concentration data using information theory and then systematically investigate how the variable density flow impacts the voi of these data in relation to permeability estimation using an ensemble kalman filter we estimate the permeability field of saline aquifer systems in two scenarios of data usage pressure data only and pressure and concentration data jointly this study demonstrates that regardless of the data usage scenario the maximum voi of data is obtained when free convection and forced convection are balanced we further show that the advantage of joint inversion of pressure and concentration data decreases as the coupling effect between flow and transport increases finally we study how the level of permeability field heterogeneity affects the coupling which in turn controls voi of pressure and concentration data keywords variable density flow joint inversion mutual information value of information ensemble kalman filter aquifer characterization 1 introduction as seawater intrusion and freshwater shortages intensify managed aquifer recharge is becoming an attractive technology for many coastal saline aquifers dillon et al 2010 simmons 2005 managed aquifer recharge in saline aquifers involves injecting freshwater into a saline brackish aquifer to displace ambient saline groundwater this helps mitigate seawater intrusion and increase fresh groundwater resources decision making and management of well based managed aquifer recharge systems require optimization of well operations to meet site specific goals such as maximum displacement of saline groundwater or the maximum recovery of freshwater this requires evaluating multiple injection scenarios for which numerical simulations of subsurface flow and solute transport offer an economical alternative to expensive field experiments for reliable simulation results model parameters such as permeability and porosity are typically estimated via inverse modeling using observed values of state variables such as hydraulic head and tracer concentration data carrera et al 2005 hochstetler et al 2016 jeong and park 2019 lee and kitanidis 2014 li et al 2012 mclaughlin and townley 1996 yeh 1986 yeh and liu 2000 given restricted financial budgets for data sampling and hydrologic investigation an optimal data collection strategy e g data type measurement timing and location that provides informative measurements leube et al 2012 vilhelmsen and ferré 2017 must be identified in this context value of information voi analysis has been applied to groundwater problems abbaspour et al 1996 ben zvi et al 1988 dai et al 2016 dausman et al 2010 james and freeze 1993 james and gorelick 1994 ju et al 2018 man et al 2016 2017 norberg and rosén 2006 reichard and evans 1989 rojas et al 2010 wallis et al 2014 herein the voi of data means the usefulness of data for improving the performance of inverse estimation various frameworks for voi analysis have been proposed james and freeze 1993 proposed a bayesian decision making framework by evaluating the voi in a contaminated groundwater problem rojas et al 2010 analyzed how different sets of conditioning data impact the predictive uncertainty of multiple models nowak et al 2010 introduced a bayesian geostatistical approach to task driven experimental design when the geostatistical model for hydraulic conductivity is uncertain in the context of dynamically evolving subsurface transport dai et al 2016 embedded an ensemble kalman filter enkf into an analysis framework to assess the worth of dynamically monitored data in a contaminant transport setting although existing studies provide methodological frameworks that analyze voi and optimize monitoring protocols in a goal oriented way few studies have investigated the underlying physics controlling voi of data understanding the underlying physics is critical for maximizing voi of data and will contribute to optimizing well operation even before any measurements are made the interest of this work lies in the well based injection of freshwater into saline aquifers in this system flow and transport are coupled because the spatial salinity distribution determines the spatial fluid density distribution which leads to variable density flow massmann et al 2006 pool et al 2015 simmons 2005 simmons et al 2001 singha and gorelick 2005 ward et al 2007 werner et al 2013 zuurbier et al 2014 the coupling between flow and transport allows flow related measurements such as pressure data to contain transport information carrera et al 2010 consequently measurements can be more informative for estimating aquifer permeability although many studies have shown density effects on groundwater flow beinhorn et al 2005 dafflon et al 2011 leblanc et al 1991 müller et al 2010 shakas et al 2017 vereecken et al 2000 only a few have investigated the variable density effects on the voi of observation data kang et al 2017 xia et al 2018 yoon et al 2017 kang et al 2017 estimated the heterogeneous permeability field of a saline aquifer using fluid pressure data from an observational network consisting of multiple wells with pressure gauges at multiple depths to show that the coupling effects can improve the informativeness of pressure data in view of inverse estimation kang et al 2017 conducted the inverse modeling with different levels of density contrast between injected freshwater and the initial saline groundwater they demonstrated that the quality of the inverse estimation improved as the density contrast increased where a larger density contrast means greater coupling a recent study by xia et al 2018 also made a similar observation they estimated hydraulic conductivity fields by assimilating head data and observed higher voi of the data in a variable density compared to a density independent setting yoon et al 2017 showed that the degree of coupling could be quantified by a mixed convection ratio m which is the ratio between the two characteristic types of convection free convection due to buoyancy force and forced convection due to injection force the range of m that kang et al 2017 investigated is the forced convection dominant regime m 0 5 yoon et al 2017 investigated a broader range of m including the free convection dominant regime m 1 by varying freshwater injection rates as kang et al 2017 demonstrated yoon et al 2017 also showed that the inverse estimation improves as m increases within the forced convection dominant regime m 1 they further demonstrated that the inversion accuracy is maximized when the two convections are balanced m 1 and reduces as m increases beyond 1 when free convection overrides forced convection m 1 the injected freshwater cannot effectively displace the ambient saline groundwater in deeper aquifers due to the buoyancy effect poor sweeping efficiency reduces the coupling between flow and transport in the region the decrease in coupling reduces the additional voi from concentration field evolution yoon et al 2017 the change in the voi of pressure data according to m is indirect evidence that the two data types share information about each other in this study to directly verify that the coupling effect causes information share between pressure and concentration data we use the measure of mutual information in information theory which quantifies the amount of information one random variable contains about another cover and thomas 1991 moreover when it comes to including concentration data for aquifer characterization the coupling between pressure and concentration data leads to several research questions a how does the total voi of pressure and concentration data change according to the coupling effects b is there an optimal coupling regime that maximizes the total voi of both pressure and concentration data c how does the aquifer heterogeneity impact the coupling and subsequently the voi of both pressure and concentration data addressing these questions will improve the fundamental understanding of the coupling mechanism between flow and transport in variable density flows and significantly aid in designing an ideal data collection strategy to obtain informative measurements for aquifer characterization to address these questions we conduct synthetic experiments that estimate the permeability field for a broad range of the mixed convection ratio a wide range of heterogeneity and multiple permeability correlation structures to extend the generality of the experiments and provide statistics on the voi we conduct a large number as many as 25 of inversion runs for each combination of the mixed convection ratio heterogeneity level and correlation structure of permeability total of 5250 inversion runs this is a statistically more rigorous approach than previous studies where inverse modeling was conducted with a single or a small number of experiments for conditions of interest to this end we first run extensive numerical simulations of 2d density dependent flow and transport in a saline aquifer system where the flow is determined by the competition between the buoyancy force and the injection force an ensemble kalman filter enkf was then employed to estimate permeability fields by assimilating pressure and concentration data estimation performance was analyzed in terms of the accuracy and the uncertainty of estimated permeability fields and the predictability of the tracer breakthrough curve of injected freshwater in a realistic push pull setting this paper is structured as follows in section 2 we describe the physics of mixed convection in the variable density flow system which controls the degree of coupling between flow and transport we quantitatively demonstrate how coupling effects control the information content of pressure and concentration data using information theory in section 3 we present the inversion method using enkf and define the measures that quantify voi the results of the inverse modeling and the voi analysis are presented in section 4 finally we summarize our conclusions and guidelines for future work in section 5 2 coupling between pressure and concentration data in variable density flow 2 1 governing equations and mixed convection analysis the governing equations for variable density groundwater flow and transport consist of the continuity equation darcy s law and the advection dispersion equation as follows elenius et al 2012 hidalgo and carrera 2009 hidalgo et al 2012 kang et al 2017 landman and schotting 2007 riaz et al 2006 szulczewski and juanes 2013 yoon et al 2017 1a u 0 1b u k μ p ρ c g z 1c ϕ c t u c ϕ d eff c 0 here k is the permeability field μ is the dynamic viscosity of the fluid ρ is the fluid density g is the gravitational constant φ is the porosity and d eff is the effective dispersion tensor the scheidegger bear dispersion model is used to obtain the dispersion tensor ϕ d e f f i j ϕ d 0 β t u δ i j β l β t u i u j u where d 0 is the molecular diffusivity u is the magnitude of the darcy velocity β l is the longitudinal dispersivity and β t is the transverse dispersivity density is a linear function of concentration ρ ρ 0 ρ c c c 0 where ρ c 700 kg m 3 and ρ0 is the density of freshwater voss and souza 1987 c is the concentration of solute as a mass fraction of dissolved salt in water mass of dissolved salt per unit mass of fluid and c 0 0 kg kg for injected freshwater and c 1 0 035 kg kg for ambient saline groundwater the details of the model input parameters are shown in table 1 the pressure p is coupled with the spatial salinity distribution of c via the density term in eq 1b the coupling causes the pressure field to experience transient changes according to the evolution of salinity distribution namely variable density flow this implies that the pressure field contains the information about transport process carrera et al 2010 kang et al 2017 xia et al 2018 yoon et al 2017 to study the coupling effects on the states of pressure and concentration we simulate flow and transport in the aquifer system known as henry s problem henry 1964 as shown in fig 1 a the aquifer is initially saturated with saline groundwater and subject to the dirichlet and neumann boundary conditions as follows 2a p x l z t ρ s e a g z 2b u n x 0 z t v f o r c e d 2c u n x z 0 or b t 0 here n is the outward unit normal vector to the boundary we solve for the pressure field using a finite volume method with a two point flux approximation tpfa then solve for the concentration field using a finite volume method with an upwind scheme we use an explicit forward euler scheme for time integration leveque 2002 to avoid undesired boundary effects on the simulation we set the length of the aquifer in x direction as long as l 500 m while the first 100 m region is the domain of interest in the saline aquifer system the competition between natural convection and forced convection determines the degree of the variable density flow effects ward et al 2007 identified two characteristic velocities representing the two convections v f o r c e d q b ϕ for forced convection driven by the freshwater injection and v f r e e k δ ρ g μ ϕ for free convection driven by the density difference between the ambient saline groundwater and injected freshwater here b is the aquifer depth in the z direction q is the freshwater injection rate into a cross section of height b and unit thickness k is the mean permeability δρ is the density difference between the injected freshwater and initial groundwater the mixed convection ratio m is defined as v f r e e v f o r c e d k δ ρ g b μ q m is the ratio of the characteristic velocity of free convection to the characteristic velocity of forced convection and m determines the regime of the mixed convection kang et al 2017 ward et al 2007 yoon et al 2017 the forced convection becomes dominant as m decreases whereas the effect of free convection increases as m increases note that the mixed convection ratio can be varied not only by the injection rate q but also by the density difference between injected and ambient groundwater for example m 0 regardless of q when there is no density difference between injected and ambient groundwater in fig 1 we show the simulation results for four mixed convection ratios m 0 0 1 1 10 m 0 is the case when there is no density difference between the injected water and ambient groundwater when comparing different values of m the plume shapes are almost invariable when the forced convection outweighs the free convection m 1 the shape begins to deviate as the free convection overrides the forced convection m 1 as shown in fig 1 b fig 1 c shows the time evolution of pressure and concentration values at three locations during one pore volume injection pvi herein one pore volume is defined for the left 100 m region of the aquifer where we perform the inversion analysis in the forced convection dominant regime m 1 although the evolution of plume shapes fig 1 b and the concentration measurements fig 1 c insets is almost identical regardless of m the variability of pressure measurement increases as m increases the larger the value of m is the more significant the coupling effect is and the intensified coupling enforces the pressure field to be more sensitive to the evolution of the salinity distribution when the two characteristic convections are balanced m 1 the variability of pressure measurement increases further but then the variability decreases as m increases beyond one the decrease in the variability of pressure measurement can be attributed to the fact that when the free convection overrides the forced convection m 1 the ambient saline groundwater in the lower region is not displaced effectively and the evolution of the salinity distribution is limited to mostly the upper region as shown in fig 1 b the spatially limited evolution of the salinity distribution causes the pressure field to be less variable this implies that the sweeping efficiency of injected freshwater is a critical factor that determines the voi of pressure data yoon et al 2017 2 2 mutual information analysis the simulation results shown in section 2 1 imply that the coupling effects make the states of pressure and concentration influence each other and the amount of shared information varies according to the degree of coupling to directly quantify the amount of shared information between the two data types we use the measure of mutual information in information theory cover and thomas 1991 in this study the mutual information between the two variables p for pressure and c for concentration measures the amount of information that one of them contains about the other one the mutual information is defined using the joint distribution p p c and the product distribution p p p c as 3 m i p c p c p p c l o g 2 p p c p p p c here p p c p p p c determines how similar the joint distribution of the pair p c is to the product of the marginal distributions of p and c and can be viewed as the pointwise mutual information that is mi is the expected value of the pointwise mutual information mutual information mi p c is symmetric in p and c always non negative and equal to zero if and only if the random variables p and c are independent according to information theory mutual information measures the reduction in entropy uncertainty of a random variable when an observation of other variable is made as mi p c h p h p c here h x x p x log 2 p x is the entropy of a random variable x with a probability mass function p x compared to the correlation coefficient which is a measure of linear dependence mutual information is a more general measure in that it can detect the relationship between two random variables even if there is no linear dependence between them to the best of our knowledge our work is the first to analyze the mutual information of the multiple data types in the coupled system of variable density flow and transport we estimate the mutual information between pressure and concentration data collected from the 5 5 monitoring well network shown in fig 1 a to gain generality we estimate the mean and standard deviation of mutual information based on 25 ensembles of permeability fields for three different types of correlation structures table 1 the variance of the permeability fields is σln k 1 examples of permeability fields generated from the three types of correlation structures are shown in fig 2 as shown in fig 3 the mutual information increases and then decreases as m increases beyond one where the free convection starts to override the forced convection this behavior is similar to the change in variability of pressure data with respect to m as shown in fig 1 c note that the coupling effects intensify as m increases but the sweeping efficiency decreases when m becomes larger than one as aforementioned when m 1 the plume shape is almost identical fig 1 b and c insets for different m while the coupling effect increases as m increases the increased coupling induces the increase in mutual information as the free convection overrides the forced convection m 1 the deeper region of the aquifer cannot be swept by freshwater fig 1 b if we use information from all 25 monitoring points the reduction in sweeping efficiency causes a decrease in mutual information when m increases beyond one when we consider only the top layer of the monitoring wells where sweeping efficiency is almost identical across m values the mutual information monotonically increases as m increases implying that the mutual information is proportional to the coupling effects under identical sweeping efficiency this result is the first direct demonstration of the coupling effect increasing mutual information between the pressure and concentration data note that the increase in mutual information does not necessarily mean the increase in voi or data worth for aquifer characterization here the mutual information of the two data types is a measure of how much uncertainty in one of them can be reduced by knowing the other one to understand the impact of the mutuality on the voi of data in the context of aquifer characterization we need to conduct inversion analysis and estimate the data s worth for improving the performance of inversion 3 inversion analysis we now conduct synthetic experiments of inverse estimation that compares two scenarios of data usage 1 pressure data only 2 pressure and concentration data also to avoid being case specific we conduct a large number of inversion runs to provide statistical descriptions of our findings one of the challenges that we overcame in this study was the substantial computational cost involved with the large number of experiments and we manage the challenge by utilizing the high performance computing resources at the minnesota supercomputing institute we apply a localized ensemble kalman filter enkf to estimate heterogeneous permeability fields assuming the two scenarios of data usage and analyze the voi of data according to the scenario in this section we present the inversion method of enkf and define metrics for quantifying the voi of data in the sense of inverse estimation 3 1 ensemble kalman filter the ensemble kalman filter enkf is a monte carlo implementation of the kalman filter the enkf approximates the state covariance matrix with a sample covariance known as ensemble covariance which is computed from ensemble realizations of the state vector evensen 1994 2003 2009 the enkf was initially devised to update model states nowak 2009 reformulated the enkf as an inversion algorithm to estimate model parameters by assimilating the observation of the model states the reformulated enkf updating model parameters is often referred to as p space enkf schöniger et al 2012 in this study the parameter vector to be estimated is the log permeability at each grid cell x ln k while the state vector contains the state values of pressure and concentration at each grid cell as s p t c t t we denote the vector containing the predicted state values at measuring points by y the flow and transport model that predicts y is assumed as an error free model y f s x which implies that the accuracy of the model predictions is determined only by the uncertainty in the model parameter x to honor the measurement noise in observations y o a multivariate gaussian error ε with zero mean and covariance r are added to the observed values as y i f y i ϵ i for each realization i 1 ne where the superscript o f denote observation values and forecast values respectively and ne denotes the total number of ensemble members the state covariance matrix c yy is estimated from the ensemble by 4 c y y y f y f y f y f t the angle bracket denotes the ensemble average similarly the cross covariance matrix between the parameter of ln k and the states y f is obtained as 5 c x y x f x f y f y f t the p space enkf then updates each model parameter vector x i by 6 x i u x i f c xy c yy r 1 y o y i f where the covariance matrices multiplication c xy c yy r 1 is commonly called kalman gain the p space enkf in eq 6 updates only the parameter vector of log permeability and thus the state vector s can be inconsistent with the updated parameter to resolve the inconsistency we adopt an iterative scheme which updates the state variable by restarting the flow and transport simulation from t 0 forward in time to the next data assimilation point after updating the permeabilities gu and oliver 2007 showed that the iterative enkf enables better results than a non iterative enkf the predicted ensemble matrix is again updated using the data through eq 6 when new measurements are made this recursive procedure continues until all the measurements have been assimilated fig 4 shows a flow chart of this sequential data assimilation via the p space iterative enkf we apply a localization scheme to the covariance matrices in eq 6 to avoid spurious correlations between state components that are physically far apart the localization is a procedure to taper the covariance matrix according to the distance between grid points which replaces the ensemble kalman filter update in eq 6 with the following localized ensemble kalman filter lenkf update 7 x i u x i f τ d c xy τ d c yy r 1 y o y i f where is the schur product and τ d is the tapering function we use the tapering function based on the fifth order formulae proposed by gaspari and cohn 1999 defined as 8 τ d 1 4 d r 5 1 2 d r 4 5 8 d r 3 5 3 d r 2 1 0 d r 1 12 d r 5 1 2 d r 4 5 8 d r 3 5 3 d r 2 5 d r 4 2 3 d r 1 r d 2 r 0 2 r d where the distance d 2r is the range beyond which the tapering function yields zero correlation yoon et al 2017 applied the lenkf to an inverse problem similar to this study and demonstrated that the covariance localization in eq 7 could circumvent the issue of spurious correlation and improve the inversion quality 3 2 value of information metrics we quantify the value of information voi of pressure and concentration data in the sense of how much the data is useful for improving the performance of inverse estimation three criteria are considered improvement in accuracy reduction of uncertainty and improvement in model predictability two metrics for the criterion of accuracy and one metric for each of the other two criteria are used yoon et al 2017 the first metric is a normalized error estimate defined as 9 e e initial e e initial where e x true x is a euclidean distance l 2 norm between the true log permeability field x true ln k true and the mean of the updated ensemble of log permeability fields x ln k e initial is the error estimate of the initial permeability ensemble the normalized error estimates can be interpreted as the reduction in error achieved by assimilating data yoon et al 2017 the metric of reduced error can be distorted by outliers for example it is possible to have a considerable distance x true x due to a few outliers deviating significantly from the reference value even if the overall match of the permeability fields is good to supplement the weakness of the distance based metric in eq 9 we also measure the mapping accuracy which is the ratio of the number of accurately estimated grid cells to the total number of grid cells yoon and mckenna 2012 yoon et al 2017 because we just determine whether an estimate is correct or not for each grid cell to estimate the mapping accuracy the outlier effects can be minimized to calculate the mapping accuracy we need to define the criterion for an estimated log permeability value to be considered accurate we count a log permeability estimate as accurate when the difference between the true and estimated log permeability values is less than 15 of the difference between maximum and minimum values of the true log permeability as 0 15 max x true min x true third we estimate the uncertainty of the inverse estimation the posterior covariance of the log permeability field obtained after data y o is assimilated via eq 7 can be approximated as cov x y o x u x u x u x u t the uncertainty of the inverse estimate then can be quantified as λ tr cov x y o where the trace provides a scalar measure of the posterior variance of the updated log permeability neuman et al 2012 the voi of data in reducing uncertainty is defined as follows dai et al 2016 10 λ λ initial λ final λ initial where λinitial is the trace of the covariance matrix of the initial log permeability ensemble and λfinal is the trace of the posterior covariance of the finally updated log permeability ensemble the voi metric in eq 10 can be interpreted as the reduced uncertainty obtained by assimilating observation data finally we estimate the predictability of estimated permeability fields by calculating the error of recovery efficiency using the estimated permeability fields the ability to predict recovery efficiency is critically important in the system of aquifer recharge and recovery and it is one of the main motivations for conducting the task of inverse estimation the estimated permeability fields are used to simulate a freshwater recharge and recovery in a realistic push pull setting the aquifer domain is initially filled with seawater and then the injected freshwater displaces the saline water away of the injection well after injecting freshwater as much as 1 pvi of the leftmost 50 m by 100 m domain the injected freshwater is then recovered by extracting water from the same well with the same pumping rate as the injection rate until the maximum allowable cl concentration 5 mg l is reached the injection pumping rate is set to 375 m3 day which requires 4 days to inject 1 pvi of freshwater this rate enables the injected freshwater to displace the ambient seawater with high sweeping efficiency which is required to check the inversion quality in the deeper region of the aquifer the recovery efficiency is defined as re qre qin where qin and qre are the amount of injected and recovered freshwater respectively the measure for predictability error is defined as 11 y r e t r u e r e p r e d i c t r e t r u e where re true and re predict are the recovery efficiency predicted from using the true permeability field and the ensemble mean of the estimated permeability fields respectively 4 results and discussion 4 1 variable density flow effects on the value of information of data we conduct inverse estimation for two scenarios of data usage 1 pressure data only 2 pressure and concentration data we consider multi gaussian log permeability fields with three types of correlation structures characterized by three variogram models gaussian spherical and exponential we studied the three different variogram models to confirm our findings are independent of variogram types however note that gaussian variograms generate spatially very smooth conductivity fields we included a gaussian variogram model because it has been widely used in groundwater studies and especially in inversion studies gharamti et al 2015 mariethoz et al 2009 neuman et al 2012 phale and oliver 2011 riva and willmann 2009 also haugen et al 2008 reported a field example that can be characterized by gaussian variogram models fig 2 shows examples of the log permeability fields for each type of the variogram along with the locations of wells where observation data are to be collected there are five observation wells with a multilevel groundwater monitoring system at which we collect pressure and concentration values during freshwater injection experiments the collected data are assimilated through lenkf eq 7 to estimate the permeability field of the first 100 m by 50 m area of the aquifer the mean value of the permeability fields is e k 105 millidarcy and the variance of the log permeability fields is σ ln k 2 0 25 several well known field sites show the variance of the log permeability fields around 0 25 for example at borden ontario σ ln k 2 0 29 and cape cod massachusetts σ ln k 2 0 24 garabedian et al 1991 hess et al 1992 mackay et al 1986 the effects of σ ln k 2 will be discussed in detail in section 4 2 by studying five different σ ln k 2 values this study aims to analyze the impact of mixed convection on the voi of data for aquifer permeability field characterization to avoid being case specific we conduct 25 inversion runs for each value of mixed convection ratios m 0 0 001 0 01 0 1 1 5 10 whereas previous studies conducted a single inversion run for each m kang et al 2017 yoon et al 2017 the injection rates corresponding to the mixed convection ratios are shown in table 2 note that in this study the total number of inversion experiments is 25 data scenarios variogram models m σ ln k 2 25 2 3 7 5 5250 for each inversion run we generate 300 ensembles of log permeability fields the lenkf requires forward simulations as many as the ensemble size implying that even a single inversion run can be computationally demanding to reduce the computational costs we parallelize the forward simulations i e forecast procedure so that the computation time is independent of the ensemble size we conduct all inversion experiments using the high performance computing resources at minnesota supercomputing institute and all runs were completed within four wall clock days we assimilate the pressure data only or both pressure and concentration data through the lenkf at every 0 1 pvi up to 1 pvi of the left 100 m area of the aquifer that is there are ten times of data assimilation fig 5 shows the ensemble mean and variance of finally updated log permeability fields from the inversion runs for the three variogram types shown in fig 2 in all cases we can qualitatively observe the best imaging quality when m 1 the figure also shows that using both data types jointly gives better results than using a single data type of pressure especially when the degree of coupling is small e g m 0 01 on the contrary the advantage of assimilating both data types jointly is not obvious when m is large that is when the degree of coupling is large e g m 10 also as the coupling between pressure and concentration intensifies the ensemble standard deviation shows higher values in the bottom right area when m 10 the free convection overrides the forced convection and the injected freshwater cannot displace the ambient groundwater in the area see fig 1 b this causes the data collected in the area to have less voi for aquifer characterization which explains the high values of standard deviation we estimate the four voi metrics presented in section 3 2 for all of the 5250 inversion experiments the results and findings for the three variogram models are similar so we only present here the results of the experiments using the spherical variogram model the estimates of the error reduction and mapping accuracy which are the voi metrics based on the estimation accuracy are shown in fig 6 a and b respectively as shown by yoon et al 2017 we again confirm the optimality of the voi at m 1 when we use the single data type of pressure for all types of correlation structures the optimality also exists for joint inversion cases first columns of fig 6 for pressure data the optimality at m 1 is due to the additional information coming from transport data through flow and transport coupling yoon et al 2017 from this one may conjecture that when m 1 the inclusion of concentration data will not contribute much for inversion compared to less coupled conditions because the information of concentration is already present in pressure data however we find that the optimality at m 1 is maintained and also the inversion accuracy increases this implies that the optimal coupling increases not only the amount of shared information but also the total amount of information interestingly as shown in the last column of fig 6 the advantage of using the two data types jointly compared to using the single data type of pressure reduces as the mixed convection ratio increases which was also qualitatively observed in fig 5 we can reason that the incremental increase in voi obtained by adding the concentration data type reduces as m increases because the pressure data already contains information from the concentration data when the coupling is strong enough fig 6 c shows the estimates of the uncertainty reduction calculated with eq 10 in all types of the three variogram models the use of both data types reduces uncertainty compared to the use of the single data type of pressure like the two previous metrics for accuracy improvement the optimality is achieved for both scenarios of data usage when the two principal convections are balanced also the improvements obtained by using both data types compared to using pressure data only decrease as the coupling effects increase increasing m lastly fig 6 d shows the estimates of the predictability error of recovery efficiency the predicted error is minimum when m 1 for both scenarios of data usage in the forced convection dominant regime m 1 the joint usage of pressure and concentration data significantly outperforms the usage of the single data type of pressure when m increases beyond one the improvement in predictability error obtained by using both data types decreases as the coupling effect increases as shown in the right most column in fig 6 d the estimates of the four voi metrics consistently demonstrate that improved inversion quality can be achieved by using multiple data types also the results show that the balanced regime of mixed convection maximizes the voi regardless of the data usage scenario furthermore the increase in the voi achieved by adding concentration data decreases as the coupling effects increases see the right most columns in fig 6 this can be attributed to the fact that the coupling effects increase the amount of mutual information between both data types fig 2 and thereby the relative advantage of joint inversion decreases 4 2 variable density flow effects in highly heterogeneous systems the spatial variability of permeability in aquifer systems is often highly heterogeneous and can lead to very complex solute transport behavior dagan et al 1992 zheng et al 2011 inverse problems in the highly heterogeneous aquifer systems are especially challenging when spatially dense monitoring data are not available zhou et al 2014 in this section we further our analysis to understand the heterogeneity effects on the voi of observation data in variable density flows to investigate the heterogeneity effects in variable density flows we estimate the difference in voi for two regimes of variable density flow density independent flow regime m 0 and the optimal balanced mixed convection regime m 1 for different levels of heterogeneity up to σ ln k 2 3 as shown in fig 7 the difference can be interpreted as the improvements in voi in the balanced mixed convection regime m 1 compared to m 0 case two voi metrics are used the normalized error estimates eq 9 and the estimates of uncertainty reduction eq 10 the advantage of enforcing m 1 in the scenario using the single data type pressure is more significant than in the scenario using multiple data types also the improvements in the voi obtained by enforcing the balanced mixed convection regime decrease as the heterogeneity increases as shown in fig 7 as heterogeneity of the permeability field increases the flow structure in the aquifer shows strong preferential flow paths this implies that the evolution of the salinity distribution is mostly controlled by preferential flow paths caused by strong heterogeneity therefore the effects of density driven flow decrease as heterogeneity increases and thereby the coupling between flow and transport also becomes weak in fig 8 we show the improvements of voi achieved by using both pressure and concentration data compared to the case of using the single data of pressure as a function m for different levels of heterogeneity the inverse modeling results for the spherical variogram model is presented the voi analysis results for the two other types of variogram model are similar like the moderately heterogeneous case in section 4 1 the advantage of using the multiple types of data decreases as the degree of coupling increases for all degrees of heterogeneity this confirms our previous reasoning that the increased degree of coupling reduces the improvement in voi obtained by adding the concentration data because the pressure data already contains significant information of concentration data when the coupling is strong enough furthermore we observe that with any fixed value of m the advantage of using the multiple data types increases as the heterogeneity increases fig 8 as we previously discussed high permeability heterogeneity reduces the coupling between flow and transport which in turn reduces the mutual information between the pressure and concentration data consequently the advantage of using multiple data types increases as heterogeneity increases 5 conclusions the states of pressure and concentration are coupled in variable density groundwater flows using the measure of mutual information in information theory we directly demonstrated that the coupling causes pressure and concentration data to share information about each other the degree of coupling determines the amount of information shared this is the first direct demonstration that variable density flow causes information sharing between pressure and concentration data the mutual information metric can be practically useful for example the metric shows how much information is shared between data sets at each observation location this knowledge can be very useful for the design of data collection systems this is particularly attractive because the mutual information can be estimated without numerically expensive inversion runs to understand the coupling effects on the value of information voi of the data for aquifer characterization we conducted data assimilation analysis the degree of coupling was quantified by the mixed convection ratio m we investigated how the ratio controls the voi of pressure and concentration data in terms of permeability characterization two scenarios were studied 1 assimilating only pressure data 2 assimilating pressure and concentration data to avoid case specific results we conducted 25 inversion runs for each combination of the mixed convection ratio heterogeneity level and correlation structure of permeability using voi metrics based on accuracy uncertainty and predictability we rigorously showed that voi regardless of the data usage scenario is maximized when forced convection and free convection are balanced m 1 this implies that the optimal coupling regime increases not only the amount of shared information but also the total amount of information we also demonstrated the superiority of using multiple data types for aquifer characterization however the advantage of using multiple data types over a single data type decreases as coupling effects increase this is because an increase in the coupling high m results in greater information sharing consequently additional voi obtained by adding concentration data becomes less significant pressure data alone could therefore be enough for permeability estimation especially when coupling effects are significant furthermore we found that high heterogeneity of permeability fields reduces the coupling effects decreasing the mutual information between pressure and concentration data the advantage of using multiple data types for characterization therefore increases as aquifer heterogeneity increases these findings fundamentally improve our understanding of the coupling mechanism between flow and transport in variable density flows and how the coupling controls voi of pressure and concentration data in this study we investigated the impact of variable density flow on the voi of pressure and concentration data the most commonly used data types for aquifer characterization the recent advances in geophysical monitoring technology enable easy access to electrical geophysical data such as electrical conductivity and chargeability linde et al 2006 singha et al 2015 slater et al 2000 evaluating the impact of variable density flow on the voi of geophysical data will be a natural extension of this work understanding the link between the voi of data and the coupling effects in variable density flows will significantly aid the design of optimal data sampling strategies for aquifer characterization and help optimize injection extraction protocols declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge a grant 17awmp b066761 05 from awmp program funded by ministry of land infrastructure and transport of korean government and the support from future research program 2e27030 funded by the korea institute of science and technology kist pkk also acknowledges the college of science engineering at the university of minnesota and the george and orpha gibson endowment for its generous support of hydrogeology and the minnesota environment and natural resources trust fund as recommended by the legislative citizen commission on minnesota resources lccmr we thank the minnesota supercomputing institute msi at the university of minnesota for computational resources and support supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103468 appendix supplementary materials image application 1 
544,predicting variable density flow and transport in aquifers is critical for the management of many coastal saline aquifers accurate characterization of hydrogeological parameters is critical for prediction and the characterization is often conducted by assimilating data into models however few studies have investigated the underlying physics controlling the value of information voi of data for aquifer characterization in this study we show how a greater understanding of the underlying physics controlling pressure and concentration data coupling can lead to improved characterization in variable density flow the key physics that controls the voi of pressure and concentration data is the non linear coupling between flow and transport via fluid density which causes the pressure field to experience transient changes according to the evolution of salinity distribution we first demonstrate the coupling between pressure and concentration data using information theory and then systematically investigate how the variable density flow impacts the voi of these data in relation to permeability estimation using an ensemble kalman filter we estimate the permeability field of saline aquifer systems in two scenarios of data usage pressure data only and pressure and concentration data jointly this study demonstrates that regardless of the data usage scenario the maximum voi of data is obtained when free convection and forced convection are balanced we further show that the advantage of joint inversion of pressure and concentration data decreases as the coupling effect between flow and transport increases finally we study how the level of permeability field heterogeneity affects the coupling which in turn controls voi of pressure and concentration data keywords variable density flow joint inversion mutual information value of information ensemble kalman filter aquifer characterization 1 introduction as seawater intrusion and freshwater shortages intensify managed aquifer recharge is becoming an attractive technology for many coastal saline aquifers dillon et al 2010 simmons 2005 managed aquifer recharge in saline aquifers involves injecting freshwater into a saline brackish aquifer to displace ambient saline groundwater this helps mitigate seawater intrusion and increase fresh groundwater resources decision making and management of well based managed aquifer recharge systems require optimization of well operations to meet site specific goals such as maximum displacement of saline groundwater or the maximum recovery of freshwater this requires evaluating multiple injection scenarios for which numerical simulations of subsurface flow and solute transport offer an economical alternative to expensive field experiments for reliable simulation results model parameters such as permeability and porosity are typically estimated via inverse modeling using observed values of state variables such as hydraulic head and tracer concentration data carrera et al 2005 hochstetler et al 2016 jeong and park 2019 lee and kitanidis 2014 li et al 2012 mclaughlin and townley 1996 yeh 1986 yeh and liu 2000 given restricted financial budgets for data sampling and hydrologic investigation an optimal data collection strategy e g data type measurement timing and location that provides informative measurements leube et al 2012 vilhelmsen and ferré 2017 must be identified in this context value of information voi analysis has been applied to groundwater problems abbaspour et al 1996 ben zvi et al 1988 dai et al 2016 dausman et al 2010 james and freeze 1993 james and gorelick 1994 ju et al 2018 man et al 2016 2017 norberg and rosén 2006 reichard and evans 1989 rojas et al 2010 wallis et al 2014 herein the voi of data means the usefulness of data for improving the performance of inverse estimation various frameworks for voi analysis have been proposed james and freeze 1993 proposed a bayesian decision making framework by evaluating the voi in a contaminated groundwater problem rojas et al 2010 analyzed how different sets of conditioning data impact the predictive uncertainty of multiple models nowak et al 2010 introduced a bayesian geostatistical approach to task driven experimental design when the geostatistical model for hydraulic conductivity is uncertain in the context of dynamically evolving subsurface transport dai et al 2016 embedded an ensemble kalman filter enkf into an analysis framework to assess the worth of dynamically monitored data in a contaminant transport setting although existing studies provide methodological frameworks that analyze voi and optimize monitoring protocols in a goal oriented way few studies have investigated the underlying physics controlling voi of data understanding the underlying physics is critical for maximizing voi of data and will contribute to optimizing well operation even before any measurements are made the interest of this work lies in the well based injection of freshwater into saline aquifers in this system flow and transport are coupled because the spatial salinity distribution determines the spatial fluid density distribution which leads to variable density flow massmann et al 2006 pool et al 2015 simmons 2005 simmons et al 2001 singha and gorelick 2005 ward et al 2007 werner et al 2013 zuurbier et al 2014 the coupling between flow and transport allows flow related measurements such as pressure data to contain transport information carrera et al 2010 consequently measurements can be more informative for estimating aquifer permeability although many studies have shown density effects on groundwater flow beinhorn et al 2005 dafflon et al 2011 leblanc et al 1991 müller et al 2010 shakas et al 2017 vereecken et al 2000 only a few have investigated the variable density effects on the voi of observation data kang et al 2017 xia et al 2018 yoon et al 2017 kang et al 2017 estimated the heterogeneous permeability field of a saline aquifer using fluid pressure data from an observational network consisting of multiple wells with pressure gauges at multiple depths to show that the coupling effects can improve the informativeness of pressure data in view of inverse estimation kang et al 2017 conducted the inverse modeling with different levels of density contrast between injected freshwater and the initial saline groundwater they demonstrated that the quality of the inverse estimation improved as the density contrast increased where a larger density contrast means greater coupling a recent study by xia et al 2018 also made a similar observation they estimated hydraulic conductivity fields by assimilating head data and observed higher voi of the data in a variable density compared to a density independent setting yoon et al 2017 showed that the degree of coupling could be quantified by a mixed convection ratio m which is the ratio between the two characteristic types of convection free convection due to buoyancy force and forced convection due to injection force the range of m that kang et al 2017 investigated is the forced convection dominant regime m 0 5 yoon et al 2017 investigated a broader range of m including the free convection dominant regime m 1 by varying freshwater injection rates as kang et al 2017 demonstrated yoon et al 2017 also showed that the inverse estimation improves as m increases within the forced convection dominant regime m 1 they further demonstrated that the inversion accuracy is maximized when the two convections are balanced m 1 and reduces as m increases beyond 1 when free convection overrides forced convection m 1 the injected freshwater cannot effectively displace the ambient saline groundwater in deeper aquifers due to the buoyancy effect poor sweeping efficiency reduces the coupling between flow and transport in the region the decrease in coupling reduces the additional voi from concentration field evolution yoon et al 2017 the change in the voi of pressure data according to m is indirect evidence that the two data types share information about each other in this study to directly verify that the coupling effect causes information share between pressure and concentration data we use the measure of mutual information in information theory which quantifies the amount of information one random variable contains about another cover and thomas 1991 moreover when it comes to including concentration data for aquifer characterization the coupling between pressure and concentration data leads to several research questions a how does the total voi of pressure and concentration data change according to the coupling effects b is there an optimal coupling regime that maximizes the total voi of both pressure and concentration data c how does the aquifer heterogeneity impact the coupling and subsequently the voi of both pressure and concentration data addressing these questions will improve the fundamental understanding of the coupling mechanism between flow and transport in variable density flows and significantly aid in designing an ideal data collection strategy to obtain informative measurements for aquifer characterization to address these questions we conduct synthetic experiments that estimate the permeability field for a broad range of the mixed convection ratio a wide range of heterogeneity and multiple permeability correlation structures to extend the generality of the experiments and provide statistics on the voi we conduct a large number as many as 25 of inversion runs for each combination of the mixed convection ratio heterogeneity level and correlation structure of permeability total of 5250 inversion runs this is a statistically more rigorous approach than previous studies where inverse modeling was conducted with a single or a small number of experiments for conditions of interest to this end we first run extensive numerical simulations of 2d density dependent flow and transport in a saline aquifer system where the flow is determined by the competition between the buoyancy force and the injection force an ensemble kalman filter enkf was then employed to estimate permeability fields by assimilating pressure and concentration data estimation performance was analyzed in terms of the accuracy and the uncertainty of estimated permeability fields and the predictability of the tracer breakthrough curve of injected freshwater in a realistic push pull setting this paper is structured as follows in section 2 we describe the physics of mixed convection in the variable density flow system which controls the degree of coupling between flow and transport we quantitatively demonstrate how coupling effects control the information content of pressure and concentration data using information theory in section 3 we present the inversion method using enkf and define the measures that quantify voi the results of the inverse modeling and the voi analysis are presented in section 4 finally we summarize our conclusions and guidelines for future work in section 5 2 coupling between pressure and concentration data in variable density flow 2 1 governing equations and mixed convection analysis the governing equations for variable density groundwater flow and transport consist of the continuity equation darcy s law and the advection dispersion equation as follows elenius et al 2012 hidalgo and carrera 2009 hidalgo et al 2012 kang et al 2017 landman and schotting 2007 riaz et al 2006 szulczewski and juanes 2013 yoon et al 2017 1a u 0 1b u k μ p ρ c g z 1c ϕ c t u c ϕ d eff c 0 here k is the permeability field μ is the dynamic viscosity of the fluid ρ is the fluid density g is the gravitational constant φ is the porosity and d eff is the effective dispersion tensor the scheidegger bear dispersion model is used to obtain the dispersion tensor ϕ d e f f i j ϕ d 0 β t u δ i j β l β t u i u j u where d 0 is the molecular diffusivity u is the magnitude of the darcy velocity β l is the longitudinal dispersivity and β t is the transverse dispersivity density is a linear function of concentration ρ ρ 0 ρ c c c 0 where ρ c 700 kg m 3 and ρ0 is the density of freshwater voss and souza 1987 c is the concentration of solute as a mass fraction of dissolved salt in water mass of dissolved salt per unit mass of fluid and c 0 0 kg kg for injected freshwater and c 1 0 035 kg kg for ambient saline groundwater the details of the model input parameters are shown in table 1 the pressure p is coupled with the spatial salinity distribution of c via the density term in eq 1b the coupling causes the pressure field to experience transient changes according to the evolution of salinity distribution namely variable density flow this implies that the pressure field contains the information about transport process carrera et al 2010 kang et al 2017 xia et al 2018 yoon et al 2017 to study the coupling effects on the states of pressure and concentration we simulate flow and transport in the aquifer system known as henry s problem henry 1964 as shown in fig 1 a the aquifer is initially saturated with saline groundwater and subject to the dirichlet and neumann boundary conditions as follows 2a p x l z t ρ s e a g z 2b u n x 0 z t v f o r c e d 2c u n x z 0 or b t 0 here n is the outward unit normal vector to the boundary we solve for the pressure field using a finite volume method with a two point flux approximation tpfa then solve for the concentration field using a finite volume method with an upwind scheme we use an explicit forward euler scheme for time integration leveque 2002 to avoid undesired boundary effects on the simulation we set the length of the aquifer in x direction as long as l 500 m while the first 100 m region is the domain of interest in the saline aquifer system the competition between natural convection and forced convection determines the degree of the variable density flow effects ward et al 2007 identified two characteristic velocities representing the two convections v f o r c e d q b ϕ for forced convection driven by the freshwater injection and v f r e e k δ ρ g μ ϕ for free convection driven by the density difference between the ambient saline groundwater and injected freshwater here b is the aquifer depth in the z direction q is the freshwater injection rate into a cross section of height b and unit thickness k is the mean permeability δρ is the density difference between the injected freshwater and initial groundwater the mixed convection ratio m is defined as v f r e e v f o r c e d k δ ρ g b μ q m is the ratio of the characteristic velocity of free convection to the characteristic velocity of forced convection and m determines the regime of the mixed convection kang et al 2017 ward et al 2007 yoon et al 2017 the forced convection becomes dominant as m decreases whereas the effect of free convection increases as m increases note that the mixed convection ratio can be varied not only by the injection rate q but also by the density difference between injected and ambient groundwater for example m 0 regardless of q when there is no density difference between injected and ambient groundwater in fig 1 we show the simulation results for four mixed convection ratios m 0 0 1 1 10 m 0 is the case when there is no density difference between the injected water and ambient groundwater when comparing different values of m the plume shapes are almost invariable when the forced convection outweighs the free convection m 1 the shape begins to deviate as the free convection overrides the forced convection m 1 as shown in fig 1 b fig 1 c shows the time evolution of pressure and concentration values at three locations during one pore volume injection pvi herein one pore volume is defined for the left 100 m region of the aquifer where we perform the inversion analysis in the forced convection dominant regime m 1 although the evolution of plume shapes fig 1 b and the concentration measurements fig 1 c insets is almost identical regardless of m the variability of pressure measurement increases as m increases the larger the value of m is the more significant the coupling effect is and the intensified coupling enforces the pressure field to be more sensitive to the evolution of the salinity distribution when the two characteristic convections are balanced m 1 the variability of pressure measurement increases further but then the variability decreases as m increases beyond one the decrease in the variability of pressure measurement can be attributed to the fact that when the free convection overrides the forced convection m 1 the ambient saline groundwater in the lower region is not displaced effectively and the evolution of the salinity distribution is limited to mostly the upper region as shown in fig 1 b the spatially limited evolution of the salinity distribution causes the pressure field to be less variable this implies that the sweeping efficiency of injected freshwater is a critical factor that determines the voi of pressure data yoon et al 2017 2 2 mutual information analysis the simulation results shown in section 2 1 imply that the coupling effects make the states of pressure and concentration influence each other and the amount of shared information varies according to the degree of coupling to directly quantify the amount of shared information between the two data types we use the measure of mutual information in information theory cover and thomas 1991 in this study the mutual information between the two variables p for pressure and c for concentration measures the amount of information that one of them contains about the other one the mutual information is defined using the joint distribution p p c and the product distribution p p p c as 3 m i p c p c p p c l o g 2 p p c p p p c here p p c p p p c determines how similar the joint distribution of the pair p c is to the product of the marginal distributions of p and c and can be viewed as the pointwise mutual information that is mi is the expected value of the pointwise mutual information mutual information mi p c is symmetric in p and c always non negative and equal to zero if and only if the random variables p and c are independent according to information theory mutual information measures the reduction in entropy uncertainty of a random variable when an observation of other variable is made as mi p c h p h p c here h x x p x log 2 p x is the entropy of a random variable x with a probability mass function p x compared to the correlation coefficient which is a measure of linear dependence mutual information is a more general measure in that it can detect the relationship between two random variables even if there is no linear dependence between them to the best of our knowledge our work is the first to analyze the mutual information of the multiple data types in the coupled system of variable density flow and transport we estimate the mutual information between pressure and concentration data collected from the 5 5 monitoring well network shown in fig 1 a to gain generality we estimate the mean and standard deviation of mutual information based on 25 ensembles of permeability fields for three different types of correlation structures table 1 the variance of the permeability fields is σln k 1 examples of permeability fields generated from the three types of correlation structures are shown in fig 2 as shown in fig 3 the mutual information increases and then decreases as m increases beyond one where the free convection starts to override the forced convection this behavior is similar to the change in variability of pressure data with respect to m as shown in fig 1 c note that the coupling effects intensify as m increases but the sweeping efficiency decreases when m becomes larger than one as aforementioned when m 1 the plume shape is almost identical fig 1 b and c insets for different m while the coupling effect increases as m increases the increased coupling induces the increase in mutual information as the free convection overrides the forced convection m 1 the deeper region of the aquifer cannot be swept by freshwater fig 1 b if we use information from all 25 monitoring points the reduction in sweeping efficiency causes a decrease in mutual information when m increases beyond one when we consider only the top layer of the monitoring wells where sweeping efficiency is almost identical across m values the mutual information monotonically increases as m increases implying that the mutual information is proportional to the coupling effects under identical sweeping efficiency this result is the first direct demonstration of the coupling effect increasing mutual information between the pressure and concentration data note that the increase in mutual information does not necessarily mean the increase in voi or data worth for aquifer characterization here the mutual information of the two data types is a measure of how much uncertainty in one of them can be reduced by knowing the other one to understand the impact of the mutuality on the voi of data in the context of aquifer characterization we need to conduct inversion analysis and estimate the data s worth for improving the performance of inversion 3 inversion analysis we now conduct synthetic experiments of inverse estimation that compares two scenarios of data usage 1 pressure data only 2 pressure and concentration data also to avoid being case specific we conduct a large number of inversion runs to provide statistical descriptions of our findings one of the challenges that we overcame in this study was the substantial computational cost involved with the large number of experiments and we manage the challenge by utilizing the high performance computing resources at the minnesota supercomputing institute we apply a localized ensemble kalman filter enkf to estimate heterogeneous permeability fields assuming the two scenarios of data usage and analyze the voi of data according to the scenario in this section we present the inversion method of enkf and define metrics for quantifying the voi of data in the sense of inverse estimation 3 1 ensemble kalman filter the ensemble kalman filter enkf is a monte carlo implementation of the kalman filter the enkf approximates the state covariance matrix with a sample covariance known as ensemble covariance which is computed from ensemble realizations of the state vector evensen 1994 2003 2009 the enkf was initially devised to update model states nowak 2009 reformulated the enkf as an inversion algorithm to estimate model parameters by assimilating the observation of the model states the reformulated enkf updating model parameters is often referred to as p space enkf schöniger et al 2012 in this study the parameter vector to be estimated is the log permeability at each grid cell x ln k while the state vector contains the state values of pressure and concentration at each grid cell as s p t c t t we denote the vector containing the predicted state values at measuring points by y the flow and transport model that predicts y is assumed as an error free model y f s x which implies that the accuracy of the model predictions is determined only by the uncertainty in the model parameter x to honor the measurement noise in observations y o a multivariate gaussian error ε with zero mean and covariance r are added to the observed values as y i f y i ϵ i for each realization i 1 ne where the superscript o f denote observation values and forecast values respectively and ne denotes the total number of ensemble members the state covariance matrix c yy is estimated from the ensemble by 4 c y y y f y f y f y f t the angle bracket denotes the ensemble average similarly the cross covariance matrix between the parameter of ln k and the states y f is obtained as 5 c x y x f x f y f y f t the p space enkf then updates each model parameter vector x i by 6 x i u x i f c xy c yy r 1 y o y i f where the covariance matrices multiplication c xy c yy r 1 is commonly called kalman gain the p space enkf in eq 6 updates only the parameter vector of log permeability and thus the state vector s can be inconsistent with the updated parameter to resolve the inconsistency we adopt an iterative scheme which updates the state variable by restarting the flow and transport simulation from t 0 forward in time to the next data assimilation point after updating the permeabilities gu and oliver 2007 showed that the iterative enkf enables better results than a non iterative enkf the predicted ensemble matrix is again updated using the data through eq 6 when new measurements are made this recursive procedure continues until all the measurements have been assimilated fig 4 shows a flow chart of this sequential data assimilation via the p space iterative enkf we apply a localization scheme to the covariance matrices in eq 6 to avoid spurious correlations between state components that are physically far apart the localization is a procedure to taper the covariance matrix according to the distance between grid points which replaces the ensemble kalman filter update in eq 6 with the following localized ensemble kalman filter lenkf update 7 x i u x i f τ d c xy τ d c yy r 1 y o y i f where is the schur product and τ d is the tapering function we use the tapering function based on the fifth order formulae proposed by gaspari and cohn 1999 defined as 8 τ d 1 4 d r 5 1 2 d r 4 5 8 d r 3 5 3 d r 2 1 0 d r 1 12 d r 5 1 2 d r 4 5 8 d r 3 5 3 d r 2 5 d r 4 2 3 d r 1 r d 2 r 0 2 r d where the distance d 2r is the range beyond which the tapering function yields zero correlation yoon et al 2017 applied the lenkf to an inverse problem similar to this study and demonstrated that the covariance localization in eq 7 could circumvent the issue of spurious correlation and improve the inversion quality 3 2 value of information metrics we quantify the value of information voi of pressure and concentration data in the sense of how much the data is useful for improving the performance of inverse estimation three criteria are considered improvement in accuracy reduction of uncertainty and improvement in model predictability two metrics for the criterion of accuracy and one metric for each of the other two criteria are used yoon et al 2017 the first metric is a normalized error estimate defined as 9 e e initial e e initial where e x true x is a euclidean distance l 2 norm between the true log permeability field x true ln k true and the mean of the updated ensemble of log permeability fields x ln k e initial is the error estimate of the initial permeability ensemble the normalized error estimates can be interpreted as the reduction in error achieved by assimilating data yoon et al 2017 the metric of reduced error can be distorted by outliers for example it is possible to have a considerable distance x true x due to a few outliers deviating significantly from the reference value even if the overall match of the permeability fields is good to supplement the weakness of the distance based metric in eq 9 we also measure the mapping accuracy which is the ratio of the number of accurately estimated grid cells to the total number of grid cells yoon and mckenna 2012 yoon et al 2017 because we just determine whether an estimate is correct or not for each grid cell to estimate the mapping accuracy the outlier effects can be minimized to calculate the mapping accuracy we need to define the criterion for an estimated log permeability value to be considered accurate we count a log permeability estimate as accurate when the difference between the true and estimated log permeability values is less than 15 of the difference between maximum and minimum values of the true log permeability as 0 15 max x true min x true third we estimate the uncertainty of the inverse estimation the posterior covariance of the log permeability field obtained after data y o is assimilated via eq 7 can be approximated as cov x y o x u x u x u x u t the uncertainty of the inverse estimate then can be quantified as λ tr cov x y o where the trace provides a scalar measure of the posterior variance of the updated log permeability neuman et al 2012 the voi of data in reducing uncertainty is defined as follows dai et al 2016 10 λ λ initial λ final λ initial where λinitial is the trace of the covariance matrix of the initial log permeability ensemble and λfinal is the trace of the posterior covariance of the finally updated log permeability ensemble the voi metric in eq 10 can be interpreted as the reduced uncertainty obtained by assimilating observation data finally we estimate the predictability of estimated permeability fields by calculating the error of recovery efficiency using the estimated permeability fields the ability to predict recovery efficiency is critically important in the system of aquifer recharge and recovery and it is one of the main motivations for conducting the task of inverse estimation the estimated permeability fields are used to simulate a freshwater recharge and recovery in a realistic push pull setting the aquifer domain is initially filled with seawater and then the injected freshwater displaces the saline water away of the injection well after injecting freshwater as much as 1 pvi of the leftmost 50 m by 100 m domain the injected freshwater is then recovered by extracting water from the same well with the same pumping rate as the injection rate until the maximum allowable cl concentration 5 mg l is reached the injection pumping rate is set to 375 m3 day which requires 4 days to inject 1 pvi of freshwater this rate enables the injected freshwater to displace the ambient seawater with high sweeping efficiency which is required to check the inversion quality in the deeper region of the aquifer the recovery efficiency is defined as re qre qin where qin and qre are the amount of injected and recovered freshwater respectively the measure for predictability error is defined as 11 y r e t r u e r e p r e d i c t r e t r u e where re true and re predict are the recovery efficiency predicted from using the true permeability field and the ensemble mean of the estimated permeability fields respectively 4 results and discussion 4 1 variable density flow effects on the value of information of data we conduct inverse estimation for two scenarios of data usage 1 pressure data only 2 pressure and concentration data we consider multi gaussian log permeability fields with three types of correlation structures characterized by three variogram models gaussian spherical and exponential we studied the three different variogram models to confirm our findings are independent of variogram types however note that gaussian variograms generate spatially very smooth conductivity fields we included a gaussian variogram model because it has been widely used in groundwater studies and especially in inversion studies gharamti et al 2015 mariethoz et al 2009 neuman et al 2012 phale and oliver 2011 riva and willmann 2009 also haugen et al 2008 reported a field example that can be characterized by gaussian variogram models fig 2 shows examples of the log permeability fields for each type of the variogram along with the locations of wells where observation data are to be collected there are five observation wells with a multilevel groundwater monitoring system at which we collect pressure and concentration values during freshwater injection experiments the collected data are assimilated through lenkf eq 7 to estimate the permeability field of the first 100 m by 50 m area of the aquifer the mean value of the permeability fields is e k 105 millidarcy and the variance of the log permeability fields is σ ln k 2 0 25 several well known field sites show the variance of the log permeability fields around 0 25 for example at borden ontario σ ln k 2 0 29 and cape cod massachusetts σ ln k 2 0 24 garabedian et al 1991 hess et al 1992 mackay et al 1986 the effects of σ ln k 2 will be discussed in detail in section 4 2 by studying five different σ ln k 2 values this study aims to analyze the impact of mixed convection on the voi of data for aquifer permeability field characterization to avoid being case specific we conduct 25 inversion runs for each value of mixed convection ratios m 0 0 001 0 01 0 1 1 5 10 whereas previous studies conducted a single inversion run for each m kang et al 2017 yoon et al 2017 the injection rates corresponding to the mixed convection ratios are shown in table 2 note that in this study the total number of inversion experiments is 25 data scenarios variogram models m σ ln k 2 25 2 3 7 5 5250 for each inversion run we generate 300 ensembles of log permeability fields the lenkf requires forward simulations as many as the ensemble size implying that even a single inversion run can be computationally demanding to reduce the computational costs we parallelize the forward simulations i e forecast procedure so that the computation time is independent of the ensemble size we conduct all inversion experiments using the high performance computing resources at minnesota supercomputing institute and all runs were completed within four wall clock days we assimilate the pressure data only or both pressure and concentration data through the lenkf at every 0 1 pvi up to 1 pvi of the left 100 m area of the aquifer that is there are ten times of data assimilation fig 5 shows the ensemble mean and variance of finally updated log permeability fields from the inversion runs for the three variogram types shown in fig 2 in all cases we can qualitatively observe the best imaging quality when m 1 the figure also shows that using both data types jointly gives better results than using a single data type of pressure especially when the degree of coupling is small e g m 0 01 on the contrary the advantage of assimilating both data types jointly is not obvious when m is large that is when the degree of coupling is large e g m 10 also as the coupling between pressure and concentration intensifies the ensemble standard deviation shows higher values in the bottom right area when m 10 the free convection overrides the forced convection and the injected freshwater cannot displace the ambient groundwater in the area see fig 1 b this causes the data collected in the area to have less voi for aquifer characterization which explains the high values of standard deviation we estimate the four voi metrics presented in section 3 2 for all of the 5250 inversion experiments the results and findings for the three variogram models are similar so we only present here the results of the experiments using the spherical variogram model the estimates of the error reduction and mapping accuracy which are the voi metrics based on the estimation accuracy are shown in fig 6 a and b respectively as shown by yoon et al 2017 we again confirm the optimality of the voi at m 1 when we use the single data type of pressure for all types of correlation structures the optimality also exists for joint inversion cases first columns of fig 6 for pressure data the optimality at m 1 is due to the additional information coming from transport data through flow and transport coupling yoon et al 2017 from this one may conjecture that when m 1 the inclusion of concentration data will not contribute much for inversion compared to less coupled conditions because the information of concentration is already present in pressure data however we find that the optimality at m 1 is maintained and also the inversion accuracy increases this implies that the optimal coupling increases not only the amount of shared information but also the total amount of information interestingly as shown in the last column of fig 6 the advantage of using the two data types jointly compared to using the single data type of pressure reduces as the mixed convection ratio increases which was also qualitatively observed in fig 5 we can reason that the incremental increase in voi obtained by adding the concentration data type reduces as m increases because the pressure data already contains information from the concentration data when the coupling is strong enough fig 6 c shows the estimates of the uncertainty reduction calculated with eq 10 in all types of the three variogram models the use of both data types reduces uncertainty compared to the use of the single data type of pressure like the two previous metrics for accuracy improvement the optimality is achieved for both scenarios of data usage when the two principal convections are balanced also the improvements obtained by using both data types compared to using pressure data only decrease as the coupling effects increase increasing m lastly fig 6 d shows the estimates of the predictability error of recovery efficiency the predicted error is minimum when m 1 for both scenarios of data usage in the forced convection dominant regime m 1 the joint usage of pressure and concentration data significantly outperforms the usage of the single data type of pressure when m increases beyond one the improvement in predictability error obtained by using both data types decreases as the coupling effect increases as shown in the right most column in fig 6 d the estimates of the four voi metrics consistently demonstrate that improved inversion quality can be achieved by using multiple data types also the results show that the balanced regime of mixed convection maximizes the voi regardless of the data usage scenario furthermore the increase in the voi achieved by adding concentration data decreases as the coupling effects increases see the right most columns in fig 6 this can be attributed to the fact that the coupling effects increase the amount of mutual information between both data types fig 2 and thereby the relative advantage of joint inversion decreases 4 2 variable density flow effects in highly heterogeneous systems the spatial variability of permeability in aquifer systems is often highly heterogeneous and can lead to very complex solute transport behavior dagan et al 1992 zheng et al 2011 inverse problems in the highly heterogeneous aquifer systems are especially challenging when spatially dense monitoring data are not available zhou et al 2014 in this section we further our analysis to understand the heterogeneity effects on the voi of observation data in variable density flows to investigate the heterogeneity effects in variable density flows we estimate the difference in voi for two regimes of variable density flow density independent flow regime m 0 and the optimal balanced mixed convection regime m 1 for different levels of heterogeneity up to σ ln k 2 3 as shown in fig 7 the difference can be interpreted as the improvements in voi in the balanced mixed convection regime m 1 compared to m 0 case two voi metrics are used the normalized error estimates eq 9 and the estimates of uncertainty reduction eq 10 the advantage of enforcing m 1 in the scenario using the single data type pressure is more significant than in the scenario using multiple data types also the improvements in the voi obtained by enforcing the balanced mixed convection regime decrease as the heterogeneity increases as shown in fig 7 as heterogeneity of the permeability field increases the flow structure in the aquifer shows strong preferential flow paths this implies that the evolution of the salinity distribution is mostly controlled by preferential flow paths caused by strong heterogeneity therefore the effects of density driven flow decrease as heterogeneity increases and thereby the coupling between flow and transport also becomes weak in fig 8 we show the improvements of voi achieved by using both pressure and concentration data compared to the case of using the single data of pressure as a function m for different levels of heterogeneity the inverse modeling results for the spherical variogram model is presented the voi analysis results for the two other types of variogram model are similar like the moderately heterogeneous case in section 4 1 the advantage of using the multiple types of data decreases as the degree of coupling increases for all degrees of heterogeneity this confirms our previous reasoning that the increased degree of coupling reduces the improvement in voi obtained by adding the concentration data because the pressure data already contains significant information of concentration data when the coupling is strong enough furthermore we observe that with any fixed value of m the advantage of using the multiple data types increases as the heterogeneity increases fig 8 as we previously discussed high permeability heterogeneity reduces the coupling between flow and transport which in turn reduces the mutual information between the pressure and concentration data consequently the advantage of using multiple data types increases as heterogeneity increases 5 conclusions the states of pressure and concentration are coupled in variable density groundwater flows using the measure of mutual information in information theory we directly demonstrated that the coupling causes pressure and concentration data to share information about each other the degree of coupling determines the amount of information shared this is the first direct demonstration that variable density flow causes information sharing between pressure and concentration data the mutual information metric can be practically useful for example the metric shows how much information is shared between data sets at each observation location this knowledge can be very useful for the design of data collection systems this is particularly attractive because the mutual information can be estimated without numerically expensive inversion runs to understand the coupling effects on the value of information voi of the data for aquifer characterization we conducted data assimilation analysis the degree of coupling was quantified by the mixed convection ratio m we investigated how the ratio controls the voi of pressure and concentration data in terms of permeability characterization two scenarios were studied 1 assimilating only pressure data 2 assimilating pressure and concentration data to avoid case specific results we conducted 25 inversion runs for each combination of the mixed convection ratio heterogeneity level and correlation structure of permeability using voi metrics based on accuracy uncertainty and predictability we rigorously showed that voi regardless of the data usage scenario is maximized when forced convection and free convection are balanced m 1 this implies that the optimal coupling regime increases not only the amount of shared information but also the total amount of information we also demonstrated the superiority of using multiple data types for aquifer characterization however the advantage of using multiple data types over a single data type decreases as coupling effects increase this is because an increase in the coupling high m results in greater information sharing consequently additional voi obtained by adding concentration data becomes less significant pressure data alone could therefore be enough for permeability estimation especially when coupling effects are significant furthermore we found that high heterogeneity of permeability fields reduces the coupling effects decreasing the mutual information between pressure and concentration data the advantage of using multiple data types for characterization therefore increases as aquifer heterogeneity increases these findings fundamentally improve our understanding of the coupling mechanism between flow and transport in variable density flows and how the coupling controls voi of pressure and concentration data in this study we investigated the impact of variable density flow on the voi of pressure and concentration data the most commonly used data types for aquifer characterization the recent advances in geophysical monitoring technology enable easy access to electrical geophysical data such as electrical conductivity and chargeability linde et al 2006 singha et al 2015 slater et al 2000 evaluating the impact of variable density flow on the voi of geophysical data will be a natural extension of this work understanding the link between the voi of data and the coupling effects in variable density flows will significantly aid the design of optimal data sampling strategies for aquifer characterization and help optimize injection extraction protocols declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge a grant 17awmp b066761 05 from awmp program funded by ministry of land infrastructure and transport of korean government and the support from future research program 2e27030 funded by the korea institute of science and technology kist pkk also acknowledges the college of science engineering at the university of minnesota and the george and orpha gibson endowment for its generous support of hydrogeology and the minnesota environment and natural resources trust fund as recommended by the legislative citizen commission on minnesota resources lccmr we thank the minnesota supercomputing institute msi at the university of minnesota for computational resources and support supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 103468 appendix supplementary materials image application 1 
