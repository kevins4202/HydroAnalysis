index,text
6605,ephemeral gullies egs are important erosion features that could account for as much as 70 of total erosion on the loess plateau of china however few quantitative studies have been conducted in the field on the impact and mechanism of upslope sediment runoff in eg erosion processes a series of field rainfall simulation experiments were conducted on an artificial eg to investigate the impacts of upslope inflow with two flow rates 15 and 30 l min 1 and five sediment concentrations 20 40 80 120 and 160 g l 1 on runoff and erosion processes within the eg the results showed that the lower flow rate of 15 l min 1 increased soil loss by 26 compared with the higher inflow rate 30 l min 1 the lower inflow rate triggered greater sheet or rill erosion whereas the higher rate mainly strengthened the incision of the main eg channel and led to increasing gully erosion the channel shoulders expanded laterally very little especially under the higher flow rate inflow sediment concentration had a major influence on eg erosion processes with increasing sediment concentration eg erosion and total slope erosion first increased and then decreased when sediment concentration exceeded 120 g l 1 the inflow sediment began to be deposited and 120 g l 1 can be regarded as a critical value of eg erosion these results are beneficial to establish a soil erosion model and to control ephemeral gully erosion in loess areas keywords soil erosion ephemeral gully sediment concentration simulated rainfall loess soil 1 introduction soil erosion is a major environmental problem worldwide singer and warkentin 1996 sun et al 2014 yang et al 2003 gully erosion is the main source of sediment in a range of environments valentin et al 2005 and results in severe environmental and economic problems such as degradation of agricultural soil and surface water quality and damage to infrastructure and transportation corridors chen et al 2016 takken et al 2008 however less information is available on gully erosion processes compared with sheet or rill erosion castillo and gomez 2016 foster 1986 grissinger and agassi 1996a grissinger and agassi 1996b an ephemeral gully is a type of concentrated surface flow erosion that is larger than a rill but smaller than a permanent gully capra and la spada 2015 poesen et al 2003 according to the soil science society of america 2008 egs are small channels eroded by concentrated overland flow that can easily be filled by normal tillage only to reform again in the same location with additional runoff events gully erosion can contribute 10 94 of the sediment yield resulting from water erosion poesen et al 2003 it is estimated that the total soil erosion contributed by eg erosion is 30 100 in the united states usda nrcs 1996 and is greater than 50 in the loess belt and mediterranean region of western europe capra and la spada 2015 casali et al 1999 porto et al 2013 the loess plateau of china is a region with some of the most severe soil erosion in the world because of high intensity and short duration rainstorms highly erodible loess soil and steep slopes cheng et al 2007 egs are widely distributed on the loess plateau and eg erosion generally accounts for 30 70 of the total soil loss cheng et al 2007 although the proportion may be as high as 90 li et al 2004 zheng and gao 2000 the formation and development of egs mainly depend on rainfall runoff topographic features and soil conditions rainfall characteristics are important factors affecting the formation and development of egs a threshold of 51 mm for maximum 3 day total rainfall has been reported to produce an eg capra et al 2009 poesen et al 2003 vandekerckhove et al 2000 zheng and kang examined the effects of 31 028 m3 km 2 upslope inflow though sheet and rill runoff plots for eg erosion processes and found that upslope inflow increased the erosion rate of egs by 12 84 under laboratory simulated rainfall conditions and by 38 66 in natural field rainfall conditions zheng and kang 1998 however the effects of inflow of different sediment concentrations on ephemeral gully erosion were not reported eg erosion has been reported to decrease with an increase in the inflow sediment concentration guo et al 2015 decrease in the sediment concentration of upslope runoff increased soil loss downslope and changed the erosion process of the downslope area with the same gradient wu et al 2004 in addition the convergence of upslope inflow can increase flow velocity in the hillslope and eg channel zheng and kang 1998 a series of studies have shown that upslope inflow plays a significant role in downslope eg erosion huang et al 1999 li et al 2016 however little field experimental work has been conducted on the eg erosion processes impacted by inflow runoff sediment conditions especially soil erosion deposition transport processes in egs gong et al 2011 the majority of previous experiments on eg erosion processes were simulated using a laboratory soil box filled with disturbed soils the differences between disturbed and original soils had unavoidable influence on eg erosion processes this study investigated eg erosion processes on undisturbed soil conditions in the field to avoid the influence of disturbed soils the objectives of this study were to quantify soil erosion processes at different positions including the eg channel and channel shoulders to clarify the effects of inflow runoff sediment concentration on eg erosion and to determine a possible sediment concentration at which sediment yield eroded from egs is almost equal to zero and eg erosion reaches a non scouring and non silting state in this study field experiments were conducted to quantify how upslope inflow with different sediment concentrations affects eg erosion processes the experiments were designed to simulate eg erosion under simulated rainfall and upslope inflow conditions with different sediment concentrations such investigations would be beneficial to establishing a soil erosion model for loess areas and may have important significance for prevention of ephemeral gully erosion 2 study site and experimental set up 2 1 study site the field experiments were carried out at the ecological station affiliated with the state key laboratory of earth surface processes and resource ecology beijing normal university 40 15 32 n 115 37 01 e this station is located in the loess hilly region in huailai county hebei province north china this region is one of the key areas for implementing soil and water conservation projects in china tian et al 2015 the climate is semi arid continental with a mean annual temperature between 3 and 9 c based on local recorded data from 1950 to 2000 the mean annual precipitation ranges from 370 to 480 mm over 1950 2000 most of which occurs as short duration and high intensity rainstorms in the summer months the studied field site was a 20 meter hillslope the shrubs and herbaceous plants at the site were removed one year before the field experiments table 1 presents the physical properties of the soil in the 0 30 cm layer 2 2 experimental design egs typically occur on hillslopes with slope gradients ranging from 15 to 35 jiang et al 1999 qin et al 2010 zhang et al 1991 a 2 m 5 m runoff plot with a slope gradient of approximately 15 27 was established fig 1 c the pipe installed on the top of the runoff plot fig 1a to provide steady inflow was made of polyvinyl chloride pvc material 2 0 m in length and 0 15 m in diameter with a row of equally spaced 1 cm grooves 1 5 cm in length and 0 5 cm in width upslope inflow entered the runoff plots evenly by overflowing through the grooves and a steady flow plate fig 1a a tank with constant water head was used to supply water the water was filled before the start of the experiment and the inflow was controlled by a valve to maintain the same experimental simulated inflow a pvc pipe was set at the bottom of the plot to collect runoff and sediment within the plot an ephemeral gully 4 5 m long 1 m wide and 0 3 m deep with a similar v shape was constructed in the middle and two 0 5 m wide hillslopes were distributed outside the margin of the ephemeral gully fig 1d forty five erosion pins were placed in the ephemeral gully in nine rows and five columns the column spacing of the erosion pins was 0 25 m and the row spacing was 0 5 m fig 1b each erosion pin had 61 scales ranging from 15 to 15 cm and the minimum interval was 0 5 cm prior to each experiment the erosion pins were placed perpendicular to the slope qi et al 2012 yang et al 2010 after the experiment the recordings of the erosion pins were checked positive values showed erosion whereas negative values showed deposition given the high intensity and short duration rainstorms that occur on the loess plateau a representative erosive rainfall intensity 60 mm h 1 and two representative upslope inflow rates 15 l min 1 and 30 l min 1 with five different sediment concentrations 20 40 80 120 and 160 g l 1 were applied the runoff plots with egs were first subjected to simulated rainfall r and then subjected to combined rainfall runoff rr conditions the time interval between the r and rr runs was about 60 min in which the readings of the erosion pins and the formation characteristics of the rills and gully were determined and recorded each experiment e consisted of 3 h from start to finish including r rr and the interval between them the detailed experimental parameters are presented in table 2 the r runs included r1 r10 experiments which were subjected to almost the same conditions simulated rainfall intensity slope gradient soil water content and runoff plot treatment because of the different soil initial water contents table 2 three experiments r1 r6 and r7 were selected from the ten repeated experiments for more detailed observation in which not only soil water content gully locations and erosion pin readings but also flow velocity and runoff sediment samples were observed for the rr runs all the above mentioned items were carefully observed between the r and rr runs the readings of the erosion pins and the formation characteristics of the rills and gullies were recorded in addition the inflow rate was adjusted to the desired values and the water pressure was kept constant during the experiments the field experiments were conducted during the summer under hot conditions all experiments were conducted in the early morning about 05 00 am when wind velocity was less than 0 3 m s 1 thus wind disturbance was kept to a minimum 2 3 experimental procedure before the experiments silt laden flows with certain sediment concentrations were prepared using mixing equipment the topsoil 0 30 cm was sampled by cutting rings at the top middle and bottom of the plot to determine the antecedent soil moisture and dry bulk density different amounts of water were sprayed with a commonly used household sprayer or placed in the plot naturally to enable similar antecedent soil water contents 10 13 between different experiments all the experiments were conducted at 5 a m when wind disturbance was minimal after each experiment the plot was placed under natural conditions for a period of evaporation and infiltration after the surface soil was no longer bonded into blocks the surface soil layer of 10 30 cm was manually turned over 2 3 times during this process a certain amount of surface soil around the plot was gradually added to suitable positions of the plot and the original soil and added soil were mixed together the surface soil was gradually compacted and levelled layer by layer taking the above measures to reduce the amount of backfill used for the surface treatment and to minimise the difference of initial surface conditions between different experiments the experiments were conducted in the order of inflow rate and soil sediment concentration ranging from lowest to highest in addition prior careful levelling of the plot was undertaken to minimise the difference of microtopographic changes by taking these measures the microtopography of the whole plot the antecedent soil moisture and dry bulk density were basically the same before each experiment prior to each experiment rainfall intensity and uniformity were calibrated to meet the experimental requirements the simulated raindrops were produced by two opposite nozzles inside diameter of 7 mm with a distance of 7 0 m at water pressure of 0 15 mp for uniformity of more than 86 8 li and pan 2018 xu et al 2006 the mean raindrop diameter was estimated as 2 0 mm with raindrop terminal velocity similar to that of natural raindrops xu et al 2006 fig 2 shows the process of each experiment the 5 m long plot was separated into six slope segments from the upslope end to the downslope end which corresponded to six linear sections of 0 0 5 m 0 5 1 5 m 1 5 2 5 m 2 5 3 5 m 3 5 4 5 m and 4 5 5 m the inflow top and outflow bottom sections 0 0 5 m and 4 5 5 m were regarded as transition segments and the remaining four segments were therefore carefully measured for each slope segment three measuring stretches were chosen to measure the hillslope both sides and eg main channel velocities using a dye tracer kmno4 method in total 12 cross sections of the whole plot were measured at a time with 15 replicates during the entire experiment the observed values were used to revise flow velocity and then averaged to represent the flow velocity of the whole plot to avoid disturbance of the dye flowing downslope the measurements were conducted from the lower end to the upper end of the plot the length width depth and locations x y of new rills and gullies in the eg experiments were manually measured after each experiment the measurements were continuously conducted along channel at intervals of 5 10 cm shen et al 2015 making sure that each segment was equally uniform in depth and width the morphological characteristics of the egs combined with the measurement data were mapped to produce fig 7 these measurements were used to calculate the eg channel and tributary volumes which in turn were used to compute the amount of eg erosion with the soil bulk density to provide morphological evidence to analyse the morphological characteristics of the ephemeral gully photographs and videos were taken throughout each experiment in addition the eg networks before and after rr runs were mapped in detail according to the measurements and photographs inflow and outflow runoff samples were collected to calculate the erosion rate and the time intervals of sampling were 2 4 min twenty five litre buckets were used to contain the runoff sediment samples and after sufficient settling of sediment particles the runoff and sediment samples were separated the sediment samples were dried in an oven at 105 c for 48 h the runoff and dry sediment samples were respectively weighed to calculate sediment concentration and sediment delivery rate 3 data analysis 3 1 runoff velocity mean runoff velocity v was calculated based on surface runoff v s measured during the experiments 1 v k v s where v is the mean flow velocity m s 1 k is a coefficient equal to 0 8 for turbulent flow emmett 1970 xia et al 2004 and vs is surface runoff velocity m s 1 the flow velocity of the eg main channel v eg and hillslope v sl is calculated using the flow velocity measured at the corresponding position and vsl is the average of the slopes at both sides 3 2 ephemeral gully erosion calculation the eg erosion s eg values were measured using three methods the first is the volumetric method casalí et al 2006 govers and poesen 1988 vandaele and poesen 1995 the volume of the eg head is approximated as the volume of a triangular prism the rest of the ephemeral gully is divided into 40 60 segments depending on the morphological characteristic of the eg to make sure that each segment is equally uniform in depth and width and the ephemeral gully volume is calculated by measuring the length width and depth of all segments multiplying the volume by the bulk density of the soil to obtain the amount of eg erosion s v m c and the erosion amount of the eg channel shoulders s v c s is also obtained by the bulk density of the soil is multiplied the tributaries volume 2 s v l h b h 2 d h i 1 n l i b i d i γ where s v is the amount of erosion and sediment g l h is the length of the ephemeral gully head cm b h is the width of the ephemeral gully head cm d h is the depth of the ephemeral gully head cm i is the ephemeral gully segment number n is the total number of segments l i is the length of the ith segment of the ephemeral gully cm b i is the width of the ith segment of the ephemeral gully cm d i is the depth of the ith segment of the ephemeral gully cm and γ is the bulk density of the soil g cm3 the second method mainly relies on erosion pin readings hu et al 2010 qi et al 2012 yang et al 2010 there were a total of forty five erosion pins in the experiment and the control area of each pin was 0 2 m 0 5 m the readings of the erosion pin represents the average depth of erosion in the area under its control the middlemost column of erosion pins was considered the eg main channel s e m c of erosion and the rest of the columns were considered eg channel shoulder erosion s e c s the amount of ephemeral gully erosion is calculated with the following formula 3 s e a n c o s θ i 1 n d i γ where s e is the amount of erosion and sediment g i is the erosion pin number di is the ith erosion pin reading cm n is the total number of erosion pins γ is the bulk density of the soil g cm3 a is the horizontal projection area cm2 and θ is the slope gradient we also developed a combination method depending on the erosion pin readings and the measured morphological characteristics of the eg the formula for this calculation is expressed as follows 4 s c e g s v m c s e c s 5 s e c s a cs n c o s θ i 1 n d i γ 6 a cs l b b c o s θ where s c e g is the amount of eg erosion calculated by the combination method g s v m g is the amount of erosion in the main eg channel calculated by the volumetric method g s e s c is the amount of erosion in the eg channel shoulders calculated by the erosion pin method g i is the erosion pin number di is the reading cm for the ith erosion pin located in the eg channel shoulders n is the total number of erosion pins γ is the bulk density of the soil g cm3 a cs is the horizontal projection area cm2 θ is the slope l is the length of the eg m b is the width of the eg m and b is the average width of main eg channel measured by the volumetric method m the errors of the erosion pin method and the volumetric method are obtained by comparison with the combination method the total erosion s is estimated from the difference between the inflow and outflow sediment samples and hillslope erosion s sl is estimated by subtracting the eg erosion from the total erosion 4 results and discussion 4 1 determination of the erosion amount for the ephemeral gully to measure eg erosion more accurately two methods were used to calculate eg erosion table 3 the eg erosion amount calculated by the erosion pin method was generally larger than that from the volumetric method under experimental conditions especially when erosion on the eg channel shoulders cs was relatively severe the reason for this phenomenon was that microtopographic changes in the eg channel shoulders are difficult to measure manually although the volumetric method has the advantages of its simple and easy implementation the measurement accuracy may decrease when it is used to measure the irregular shape of the rills and gully in addition the erosion pin methods is not accurate enough to measure the amount of eg erosion although increasing the numbers of erosion pins can increase the accuracy of the erosion pin method excessive density of erosion pins will affect overland flow the two methods mentioned above therefore are not suitable for measuring the amount of eg erosion under the experimental conditions based on the combined method the measurement errors of the erosion pin method and the volumetric method are shown in table 3 the maximum error of the erosion pin and volumetric method are 34 and 27 respectively compared with the erosion pin method the traditional volumetric method is more stable its average error is about 15 under the different runoff conditions it should be noted that the error increases significantly when the erosion on the eg channel shoulders is more severe and it is difficult to improve the accuracy of the method when the eg channel shoulders are measured conversely the mean error of the erosion pin method decreases from 20 6 to 10 6 when erosion on the eg channel shoulders increases with increased upslope runoff the error of the erosion pin method varied greatly with inflow runoff sediment conditions the erosion pin method was mainly used to measure rill erosion and the error of the experimental results was 4 3 12 1 tian et al 2015 when the amount of soil erosion tended to be stable the error stabilised between 4 and 5 and the accuracy of the method for measuring the amount of soil erosion reached 92 77 or more yang et al 2010 however although increasing the numbers of erosion pins can increase the accuracy of the erosion pin method overly dense erosion pin distribution will affect overland flow determining the appropriate the number and arrangement of erosion pins requires further exploration and discussion combining the merits of the two methods a combination method formula 3 is proposed to represent the amount of eg erosion this method is used to calculate eg erosion after the whole experiment and it cannot be used to measure eg erosion after r runs this method requires two measurement data points whereas with the volumetric method measurements must be done carefully but the runoff plot can remain undisturbed to conduct the further experiments 4 2 erosion on hillslope and ephemeral gully to analyse erosion on the hillslope and in the eg table 4 shows the erosion amount under experimental conditions the eg erosion included the erosion in the eg channel and channel shoulders calculated by different methods the erosion pin method was used before and after rr runs and the combination method was used for calculating eg erosion after the whole experiment the soil loss of the runoff plot s under the inflow rate of 15 l min 1 rr1 rr5 was larger than that under a 30 l min 1 inflow rate rr6 rr10 that is s15l s30l table 4 the reason for this result may be that sheet erosion on the hillslope is more important for the eg under lower inflow conditions hillslope erosion accounts for an average of 75 2 of total erosion under 15 l min 1 conditions whereas hillslope erosion accounts for 57 4 under 30 l min 1 conditions fig 3 the 15 l min 1 inflow corresponded to smaller water depth than the 30 l min 1 inflow under the same simulated rainfall of 60 mm h 1 the raindrop splash had more significant effects on the smaller inflow rate and triggered more severe sheet erosion on the hillslope in addition the larger inflow rate tended to form concentrated flow into the eg channel which led to greater erosion on the main eg channel and the eg channel shoulders compared with the smaller inflow 15 l min 1 eg erosion including the main eg channel and eg channel shoulders accounted for only 16 37 of total erosion under lower inflow conditions whereas eg erosion accounted for 26 69 of total erosion under higher inflow conditions previous researchers huang et al 1999 li et al 2016 xu et al 2017 zheng and gao 2000 recognised that upslope inflow was a dominant factor controlling eg erosion at the same time many researchers capra et al 2009 gong et al 2011 wu et al 2004 have emphasised the importance of rainfall intensity on eg erosion it is apparent that both of these factors have important impacts on eg formation and development and that the combined effects of rainfall and upslope inflow on eg erosion must be considered in different areas this result differs from previous findings on ephemeral gully erosion under different upslope inflow and rainfall intensities on an 8 m long 2 m wide soil pan xu et al 2017 that study showed that the rate of soil loss of the eg could increase 0 57 6 22 times with inflow rates from 1 21 to 10 31 l min 1 and 50 mm h 1 rainfall intensity and with inflow rates from 1 81 to 15 45 l min 1 and 75 mm h 1 rainfall intensity the reason for this difference is that those researchers chose smaller inflow rates under those conditions the impacts of raindrops are all significant in the eg erosion process the other reason is that the sizes of the eg models differed we built a deeper eg model and the overland inflow gathered faster especially under a high runoff rate therefore the impact of increased upslope inflow on eg erosion was weakened in contrast with the total erosion amount of the whole runoff plot the erosion in the eg channel seg increased significantly with increasing inflow rate i e seg 15l seg 30l rr1 rr10 the average erosion amount of the ephemeral gully was 66 5 kg under an inflow rate of 15 l min 1 and 87 8 kg under an inflow rate of 30 l min 1 the proportion of erosion amount from the eg channel increased from 25 to 43 with the increasing inflow rate the inflow rate of 30 l min 1 tended to form concentrated flow and a large quantity of overland flow though the hillslope quickly converged on the eg channel increased erosion and developed more tributaries the smaller upslope inflow 15 l min 1 generated relatively thin overland flow and even caused greater erosion from the eg channel shoulders these results fit well with laboratory rainfall simulation experiments on eg erosion with different slopes and rainfall intensities ding and li 2010 guo et al 2012 zheng and gao 2000 inflow sediment concentration had a significant effect on erosion amount table 4 the sediment yield from the runoff plot s and the eg channel s eg first increased slightly and then decreased with increasing sediment concentration table 4 under the two different inflow runoff conditions the maximum net erosion amount s occurred at the sediment concentration of 40 g l 1 there is a certain sediment carrying capacity for a stable slope bed and runoff rate greater sediment concentrations of upslope inflow are associated with smaller amounts of eg erosion previous researchers ding and li 2010 wu et al 2004 zheng and gao 2000 have shown similar results where soil erosion decreased with increased inflow sediment concentration and recognised sediment concentration as one of the main factors influencing eg erosion the proportion of eg erosion s eg to total erosion s is less than 50 under sediment concentrations of less than 120 g l 1 fig 3 only when the sediment concentration increased from 120 g l 1 to 160 g l 1 did the proportion of eg erosion exceed 50 and even reached 69 the eg channel and hillslope respectively occupied half of the runoff plot area sediment concentration has a great effect on the erosion process fig 4 and table 5 this effect is manifested in two aspects the time required to achieve a steady soil loss rate and the change of the initial net erosion rate higher inflow sediment concentration was associated with an earlier the state of sediment non scouring and non silting in the eg channel under the same sediment concentrations conditions the time to reach a steady soil loss rate decreased with increasing inflow rate this trend may be related to the rainfall splashing effect on different upslope inflow conditions as mentioned above under the inflow rate of 15 l min 1 except for the sediment concentration of 160 g l 1 the erosion process does not reach a non scouring and non silting state until the end of the experiment 60 min however it would be 80 min after rainfall when the erosion process of the sediment would reach an equilibrium state under the inflow rate of 30 l min 1 the time to reach the equilibrium state was approximately 40 50 min after the start of rainfall when the sediment concentration increased from 120 g l 1 to 160 g l 1 sediment depositions occurred in the eg channel the sediment concentration also affected the initial net erosion rate under the same inflow rate and a sediment concentration of less than 120 g l 1 the net erosion rate increased with increasing sediment concentration when the sediment concentration was larger than 120 g l 1 the net erosion rate decreased dramatically with increased sediment concentration to further study the critical value of sediment concentration of upslope inflow a cumulative sediment concentration curve was determined fig 5 when the sediment concentration increased from 120 to 160 g l 1 the accumulated net erosion sediment yield was the lowest the 160 g l 1 curve showed a downward trend under both inflow rate conditions but it fell faster under 30 l min 1 inflow runoff conditions in other words deposition occurred because the influence of raindrop splashing is more significant with lower inflow runoff conditions more deposition occurs under higher inflow runoff conditions therefore we can assume that the entire hillslope will have the maximum soil loss when rainfall falls into the upslope drainage area and forms runoff with a sediment concentration of 120 g l 1 when the inflow sediment concentration increased to 160 g l 1 the sediment eroded from the eg decreased dramatically this finding indicates that inflow with sediment concentrations of 120 160 g l 1 leads to the maximum erosion amount for hillslopes with egs especially on the loess plateau with high intensity and short duration rainfall patterns determining the sediment concentration threshold that makes egs reach the non scouring and non silting state is beneficial for prevention of soil loss future work is needed to examine the effects of slope gradient and inflow sediment concentration on eg erosion processes 4 3 flow velocity of the hillslope and ephemeral gully the flow velocities of the main eg channel v eg are greater than those of the hillslope v sl fig 6 with increasing inflow rate the increment of v eg is larger this result is consistent with the results of previous studies che et al 2011 gong et al 2011 xu et al 2017 zheng and gao 2000 the flow velocity of different parts v eg and v sl under different sediment concentrations of 15 l min 1 inflow conditions results in more uniformity with smooth fluctuation around the average values 0 03 m s 1 compared with the smaller inflow rate v eg and v sl fluctuated greatly around the average values 0 07 m s 1 and 0 04 m s 1 with different sediment concentrations the v eg and v sl had different opposite tendencies in other words v sl decreased when v eg increased this trend is closely related with the morphological characteristic of the ephemeral gully ephemeral gullies are more shallow and wider under lower upslope inflow the gully is relatively straight and no obvious tributaries appears with less surface runoff into the eg the surface runoff in each longitudinal section is more uniform in contrast the eg channel is more narrow and deeper under higher upslope inflow and tributaries develop fully there is more surface runoff into the eg by tributaries the v eg and v sl are volatile because of randomness in the development of the eg the sediment concentration has a limited effect on the v eg when the upslope inflow increases the sediment concentration can change the morphology of the eg and then change the v eg in particular when the upslope inflow is 30 l min 1 and the sediment concentration is 120 g l 1 the development of the ephemeral gully and the v eg are significantly increased 4 4 morphological characteristics of the ephemeral gully many rills and gullies formed in the hillslope the main eg channel and the eg channel shoulders fig 7 there were differences in the morphology of the rills and gullies under different upslope inflow conditions the main channel of the ephemeral gully had a deeper but narrower gully under 30 l min 1 inflow conditions compared with 15 l min 1 inflow conditions the maximum depth increased from 9 24 to 11 57 cm with increased inflow rate and the average depth increased from 7 72 to 9 42 cm increasing by 25 and 22 respectively table 6 the maximum gully width decreased from 22 82 to 18 17 cm with increased inflow rate and the average width decreased from 18 18 to 16 39 cm decreases by 20 and 10 respectively the number of tributaries increased with increasing inflow rate the different inflow sediment concentrations greatly affected the morphological characteristics of the ephemeral gully both the gully width and the number of tributaries decreased with increased sediment concentration the changes of eg channel depth were small the increased number of tributaries triggered the gathering of overland runoff in the main gully more easily and aggravated downward erosion the sediment carrying capacity of flow is constant and the soil erosion amount decreased with increased inflow sediment concentration therefore the number of tributaries and the depth and width of the main gully decreased 5 conclusions runoff and sediment processes were investigated in field runoff plots with egs under simulated rainfall and upslope laden inflow and the effects of inflow rate and sediment concentration on eg erosion deposition processes were further analysed the main findings were as follows 1 taking the amount of eg erosion calculated by the combined method as a benchmark two common measurement methods the volumetric method and erosion pin method yielded considerable errors the average error of the erosion pin method was from 20 6 to 10 6 with upslope inflow increasing from 15 l min 1 to 30 l min 1 the traditional measurement method was more stable with average error of about 15 under different upslope inflow conditions 2 the erosion caused by 15 l min 1 runoff was greater than that caused by 30 l min 1 runoff the smaller inflow rate triggered greater sheet or rill erosion whereas the greater rate mainly concentrated in the ephemeral gully channel and led to increasing gully erosion 3 the sediment concentration of upslope inflow had great influence on the eg erosion deposition processes the sediment concentration of 120 g l 1 was a critical value when it was exceeded sediment deposition began in the egs when the sediment concentration increased to 160 g l 1 a large amount of sediment was deposited in the runoff plot in the final stage of the experiment these results can help to accurately assess eg erosion processes and predict soil loss in loess areas 6 declaration of interest statement we declare that we have no financial and personal relationships with other people or organizations that can inappropriately influence our work there is no professional or other personal interest of any nature or kind in any product service and company that could be construed as influencing the position presented in or the review of the manuscript entitled acknowledgements the authors wish to thank all of the technicians involved in field and laboratory work this research was jointly funded by the national natural science foundation of china project 41771305 41530858 the national key r d program of china 2017yfc0504702 and the 111 project of china b18006 we thank sara j mason m sc from liwen bianji edanz editing china www liwenbianji cn ac for editing the english text of a draft of this manuscript 
6605,ephemeral gullies egs are important erosion features that could account for as much as 70 of total erosion on the loess plateau of china however few quantitative studies have been conducted in the field on the impact and mechanism of upslope sediment runoff in eg erosion processes a series of field rainfall simulation experiments were conducted on an artificial eg to investigate the impacts of upslope inflow with two flow rates 15 and 30 l min 1 and five sediment concentrations 20 40 80 120 and 160 g l 1 on runoff and erosion processes within the eg the results showed that the lower flow rate of 15 l min 1 increased soil loss by 26 compared with the higher inflow rate 30 l min 1 the lower inflow rate triggered greater sheet or rill erosion whereas the higher rate mainly strengthened the incision of the main eg channel and led to increasing gully erosion the channel shoulders expanded laterally very little especially under the higher flow rate inflow sediment concentration had a major influence on eg erosion processes with increasing sediment concentration eg erosion and total slope erosion first increased and then decreased when sediment concentration exceeded 120 g l 1 the inflow sediment began to be deposited and 120 g l 1 can be regarded as a critical value of eg erosion these results are beneficial to establish a soil erosion model and to control ephemeral gully erosion in loess areas keywords soil erosion ephemeral gully sediment concentration simulated rainfall loess soil 1 introduction soil erosion is a major environmental problem worldwide singer and warkentin 1996 sun et al 2014 yang et al 2003 gully erosion is the main source of sediment in a range of environments valentin et al 2005 and results in severe environmental and economic problems such as degradation of agricultural soil and surface water quality and damage to infrastructure and transportation corridors chen et al 2016 takken et al 2008 however less information is available on gully erosion processes compared with sheet or rill erosion castillo and gomez 2016 foster 1986 grissinger and agassi 1996a grissinger and agassi 1996b an ephemeral gully is a type of concentrated surface flow erosion that is larger than a rill but smaller than a permanent gully capra and la spada 2015 poesen et al 2003 according to the soil science society of america 2008 egs are small channels eroded by concentrated overland flow that can easily be filled by normal tillage only to reform again in the same location with additional runoff events gully erosion can contribute 10 94 of the sediment yield resulting from water erosion poesen et al 2003 it is estimated that the total soil erosion contributed by eg erosion is 30 100 in the united states usda nrcs 1996 and is greater than 50 in the loess belt and mediterranean region of western europe capra and la spada 2015 casali et al 1999 porto et al 2013 the loess plateau of china is a region with some of the most severe soil erosion in the world because of high intensity and short duration rainstorms highly erodible loess soil and steep slopes cheng et al 2007 egs are widely distributed on the loess plateau and eg erosion generally accounts for 30 70 of the total soil loss cheng et al 2007 although the proportion may be as high as 90 li et al 2004 zheng and gao 2000 the formation and development of egs mainly depend on rainfall runoff topographic features and soil conditions rainfall characteristics are important factors affecting the formation and development of egs a threshold of 51 mm for maximum 3 day total rainfall has been reported to produce an eg capra et al 2009 poesen et al 2003 vandekerckhove et al 2000 zheng and kang examined the effects of 31 028 m3 km 2 upslope inflow though sheet and rill runoff plots for eg erosion processes and found that upslope inflow increased the erosion rate of egs by 12 84 under laboratory simulated rainfall conditions and by 38 66 in natural field rainfall conditions zheng and kang 1998 however the effects of inflow of different sediment concentrations on ephemeral gully erosion were not reported eg erosion has been reported to decrease with an increase in the inflow sediment concentration guo et al 2015 decrease in the sediment concentration of upslope runoff increased soil loss downslope and changed the erosion process of the downslope area with the same gradient wu et al 2004 in addition the convergence of upslope inflow can increase flow velocity in the hillslope and eg channel zheng and kang 1998 a series of studies have shown that upslope inflow plays a significant role in downslope eg erosion huang et al 1999 li et al 2016 however little field experimental work has been conducted on the eg erosion processes impacted by inflow runoff sediment conditions especially soil erosion deposition transport processes in egs gong et al 2011 the majority of previous experiments on eg erosion processes were simulated using a laboratory soil box filled with disturbed soils the differences between disturbed and original soils had unavoidable influence on eg erosion processes this study investigated eg erosion processes on undisturbed soil conditions in the field to avoid the influence of disturbed soils the objectives of this study were to quantify soil erosion processes at different positions including the eg channel and channel shoulders to clarify the effects of inflow runoff sediment concentration on eg erosion and to determine a possible sediment concentration at which sediment yield eroded from egs is almost equal to zero and eg erosion reaches a non scouring and non silting state in this study field experiments were conducted to quantify how upslope inflow with different sediment concentrations affects eg erosion processes the experiments were designed to simulate eg erosion under simulated rainfall and upslope inflow conditions with different sediment concentrations such investigations would be beneficial to establishing a soil erosion model for loess areas and may have important significance for prevention of ephemeral gully erosion 2 study site and experimental set up 2 1 study site the field experiments were carried out at the ecological station affiliated with the state key laboratory of earth surface processes and resource ecology beijing normal university 40 15 32 n 115 37 01 e this station is located in the loess hilly region in huailai county hebei province north china this region is one of the key areas for implementing soil and water conservation projects in china tian et al 2015 the climate is semi arid continental with a mean annual temperature between 3 and 9 c based on local recorded data from 1950 to 2000 the mean annual precipitation ranges from 370 to 480 mm over 1950 2000 most of which occurs as short duration and high intensity rainstorms in the summer months the studied field site was a 20 meter hillslope the shrubs and herbaceous plants at the site were removed one year before the field experiments table 1 presents the physical properties of the soil in the 0 30 cm layer 2 2 experimental design egs typically occur on hillslopes with slope gradients ranging from 15 to 35 jiang et al 1999 qin et al 2010 zhang et al 1991 a 2 m 5 m runoff plot with a slope gradient of approximately 15 27 was established fig 1 c the pipe installed on the top of the runoff plot fig 1a to provide steady inflow was made of polyvinyl chloride pvc material 2 0 m in length and 0 15 m in diameter with a row of equally spaced 1 cm grooves 1 5 cm in length and 0 5 cm in width upslope inflow entered the runoff plots evenly by overflowing through the grooves and a steady flow plate fig 1a a tank with constant water head was used to supply water the water was filled before the start of the experiment and the inflow was controlled by a valve to maintain the same experimental simulated inflow a pvc pipe was set at the bottom of the plot to collect runoff and sediment within the plot an ephemeral gully 4 5 m long 1 m wide and 0 3 m deep with a similar v shape was constructed in the middle and two 0 5 m wide hillslopes were distributed outside the margin of the ephemeral gully fig 1d forty five erosion pins were placed in the ephemeral gully in nine rows and five columns the column spacing of the erosion pins was 0 25 m and the row spacing was 0 5 m fig 1b each erosion pin had 61 scales ranging from 15 to 15 cm and the minimum interval was 0 5 cm prior to each experiment the erosion pins were placed perpendicular to the slope qi et al 2012 yang et al 2010 after the experiment the recordings of the erosion pins were checked positive values showed erosion whereas negative values showed deposition given the high intensity and short duration rainstorms that occur on the loess plateau a representative erosive rainfall intensity 60 mm h 1 and two representative upslope inflow rates 15 l min 1 and 30 l min 1 with five different sediment concentrations 20 40 80 120 and 160 g l 1 were applied the runoff plots with egs were first subjected to simulated rainfall r and then subjected to combined rainfall runoff rr conditions the time interval between the r and rr runs was about 60 min in which the readings of the erosion pins and the formation characteristics of the rills and gully were determined and recorded each experiment e consisted of 3 h from start to finish including r rr and the interval between them the detailed experimental parameters are presented in table 2 the r runs included r1 r10 experiments which were subjected to almost the same conditions simulated rainfall intensity slope gradient soil water content and runoff plot treatment because of the different soil initial water contents table 2 three experiments r1 r6 and r7 were selected from the ten repeated experiments for more detailed observation in which not only soil water content gully locations and erosion pin readings but also flow velocity and runoff sediment samples were observed for the rr runs all the above mentioned items were carefully observed between the r and rr runs the readings of the erosion pins and the formation characteristics of the rills and gullies were recorded in addition the inflow rate was adjusted to the desired values and the water pressure was kept constant during the experiments the field experiments were conducted during the summer under hot conditions all experiments were conducted in the early morning about 05 00 am when wind velocity was less than 0 3 m s 1 thus wind disturbance was kept to a minimum 2 3 experimental procedure before the experiments silt laden flows with certain sediment concentrations were prepared using mixing equipment the topsoil 0 30 cm was sampled by cutting rings at the top middle and bottom of the plot to determine the antecedent soil moisture and dry bulk density different amounts of water were sprayed with a commonly used household sprayer or placed in the plot naturally to enable similar antecedent soil water contents 10 13 between different experiments all the experiments were conducted at 5 a m when wind disturbance was minimal after each experiment the plot was placed under natural conditions for a period of evaporation and infiltration after the surface soil was no longer bonded into blocks the surface soil layer of 10 30 cm was manually turned over 2 3 times during this process a certain amount of surface soil around the plot was gradually added to suitable positions of the plot and the original soil and added soil were mixed together the surface soil was gradually compacted and levelled layer by layer taking the above measures to reduce the amount of backfill used for the surface treatment and to minimise the difference of initial surface conditions between different experiments the experiments were conducted in the order of inflow rate and soil sediment concentration ranging from lowest to highest in addition prior careful levelling of the plot was undertaken to minimise the difference of microtopographic changes by taking these measures the microtopography of the whole plot the antecedent soil moisture and dry bulk density were basically the same before each experiment prior to each experiment rainfall intensity and uniformity were calibrated to meet the experimental requirements the simulated raindrops were produced by two opposite nozzles inside diameter of 7 mm with a distance of 7 0 m at water pressure of 0 15 mp for uniformity of more than 86 8 li and pan 2018 xu et al 2006 the mean raindrop diameter was estimated as 2 0 mm with raindrop terminal velocity similar to that of natural raindrops xu et al 2006 fig 2 shows the process of each experiment the 5 m long plot was separated into six slope segments from the upslope end to the downslope end which corresponded to six linear sections of 0 0 5 m 0 5 1 5 m 1 5 2 5 m 2 5 3 5 m 3 5 4 5 m and 4 5 5 m the inflow top and outflow bottom sections 0 0 5 m and 4 5 5 m were regarded as transition segments and the remaining four segments were therefore carefully measured for each slope segment three measuring stretches were chosen to measure the hillslope both sides and eg main channel velocities using a dye tracer kmno4 method in total 12 cross sections of the whole plot were measured at a time with 15 replicates during the entire experiment the observed values were used to revise flow velocity and then averaged to represent the flow velocity of the whole plot to avoid disturbance of the dye flowing downslope the measurements were conducted from the lower end to the upper end of the plot the length width depth and locations x y of new rills and gullies in the eg experiments were manually measured after each experiment the measurements were continuously conducted along channel at intervals of 5 10 cm shen et al 2015 making sure that each segment was equally uniform in depth and width the morphological characteristics of the egs combined with the measurement data were mapped to produce fig 7 these measurements were used to calculate the eg channel and tributary volumes which in turn were used to compute the amount of eg erosion with the soil bulk density to provide morphological evidence to analyse the morphological characteristics of the ephemeral gully photographs and videos were taken throughout each experiment in addition the eg networks before and after rr runs were mapped in detail according to the measurements and photographs inflow and outflow runoff samples were collected to calculate the erosion rate and the time intervals of sampling were 2 4 min twenty five litre buckets were used to contain the runoff sediment samples and after sufficient settling of sediment particles the runoff and sediment samples were separated the sediment samples were dried in an oven at 105 c for 48 h the runoff and dry sediment samples were respectively weighed to calculate sediment concentration and sediment delivery rate 3 data analysis 3 1 runoff velocity mean runoff velocity v was calculated based on surface runoff v s measured during the experiments 1 v k v s where v is the mean flow velocity m s 1 k is a coefficient equal to 0 8 for turbulent flow emmett 1970 xia et al 2004 and vs is surface runoff velocity m s 1 the flow velocity of the eg main channel v eg and hillslope v sl is calculated using the flow velocity measured at the corresponding position and vsl is the average of the slopes at both sides 3 2 ephemeral gully erosion calculation the eg erosion s eg values were measured using three methods the first is the volumetric method casalí et al 2006 govers and poesen 1988 vandaele and poesen 1995 the volume of the eg head is approximated as the volume of a triangular prism the rest of the ephemeral gully is divided into 40 60 segments depending on the morphological characteristic of the eg to make sure that each segment is equally uniform in depth and width and the ephemeral gully volume is calculated by measuring the length width and depth of all segments multiplying the volume by the bulk density of the soil to obtain the amount of eg erosion s v m c and the erosion amount of the eg channel shoulders s v c s is also obtained by the bulk density of the soil is multiplied the tributaries volume 2 s v l h b h 2 d h i 1 n l i b i d i γ where s v is the amount of erosion and sediment g l h is the length of the ephemeral gully head cm b h is the width of the ephemeral gully head cm d h is the depth of the ephemeral gully head cm i is the ephemeral gully segment number n is the total number of segments l i is the length of the ith segment of the ephemeral gully cm b i is the width of the ith segment of the ephemeral gully cm d i is the depth of the ith segment of the ephemeral gully cm and γ is the bulk density of the soil g cm3 the second method mainly relies on erosion pin readings hu et al 2010 qi et al 2012 yang et al 2010 there were a total of forty five erosion pins in the experiment and the control area of each pin was 0 2 m 0 5 m the readings of the erosion pin represents the average depth of erosion in the area under its control the middlemost column of erosion pins was considered the eg main channel s e m c of erosion and the rest of the columns were considered eg channel shoulder erosion s e c s the amount of ephemeral gully erosion is calculated with the following formula 3 s e a n c o s θ i 1 n d i γ where s e is the amount of erosion and sediment g i is the erosion pin number di is the ith erosion pin reading cm n is the total number of erosion pins γ is the bulk density of the soil g cm3 a is the horizontal projection area cm2 and θ is the slope gradient we also developed a combination method depending on the erosion pin readings and the measured morphological characteristics of the eg the formula for this calculation is expressed as follows 4 s c e g s v m c s e c s 5 s e c s a cs n c o s θ i 1 n d i γ 6 a cs l b b c o s θ where s c e g is the amount of eg erosion calculated by the combination method g s v m g is the amount of erosion in the main eg channel calculated by the volumetric method g s e s c is the amount of erosion in the eg channel shoulders calculated by the erosion pin method g i is the erosion pin number di is the reading cm for the ith erosion pin located in the eg channel shoulders n is the total number of erosion pins γ is the bulk density of the soil g cm3 a cs is the horizontal projection area cm2 θ is the slope l is the length of the eg m b is the width of the eg m and b is the average width of main eg channel measured by the volumetric method m the errors of the erosion pin method and the volumetric method are obtained by comparison with the combination method the total erosion s is estimated from the difference between the inflow and outflow sediment samples and hillslope erosion s sl is estimated by subtracting the eg erosion from the total erosion 4 results and discussion 4 1 determination of the erosion amount for the ephemeral gully to measure eg erosion more accurately two methods were used to calculate eg erosion table 3 the eg erosion amount calculated by the erosion pin method was generally larger than that from the volumetric method under experimental conditions especially when erosion on the eg channel shoulders cs was relatively severe the reason for this phenomenon was that microtopographic changes in the eg channel shoulders are difficult to measure manually although the volumetric method has the advantages of its simple and easy implementation the measurement accuracy may decrease when it is used to measure the irregular shape of the rills and gully in addition the erosion pin methods is not accurate enough to measure the amount of eg erosion although increasing the numbers of erosion pins can increase the accuracy of the erosion pin method excessive density of erosion pins will affect overland flow the two methods mentioned above therefore are not suitable for measuring the amount of eg erosion under the experimental conditions based on the combined method the measurement errors of the erosion pin method and the volumetric method are shown in table 3 the maximum error of the erosion pin and volumetric method are 34 and 27 respectively compared with the erosion pin method the traditional volumetric method is more stable its average error is about 15 under the different runoff conditions it should be noted that the error increases significantly when the erosion on the eg channel shoulders is more severe and it is difficult to improve the accuracy of the method when the eg channel shoulders are measured conversely the mean error of the erosion pin method decreases from 20 6 to 10 6 when erosion on the eg channel shoulders increases with increased upslope runoff the error of the erosion pin method varied greatly with inflow runoff sediment conditions the erosion pin method was mainly used to measure rill erosion and the error of the experimental results was 4 3 12 1 tian et al 2015 when the amount of soil erosion tended to be stable the error stabilised between 4 and 5 and the accuracy of the method for measuring the amount of soil erosion reached 92 77 or more yang et al 2010 however although increasing the numbers of erosion pins can increase the accuracy of the erosion pin method overly dense erosion pin distribution will affect overland flow determining the appropriate the number and arrangement of erosion pins requires further exploration and discussion combining the merits of the two methods a combination method formula 3 is proposed to represent the amount of eg erosion this method is used to calculate eg erosion after the whole experiment and it cannot be used to measure eg erosion after r runs this method requires two measurement data points whereas with the volumetric method measurements must be done carefully but the runoff plot can remain undisturbed to conduct the further experiments 4 2 erosion on hillslope and ephemeral gully to analyse erosion on the hillslope and in the eg table 4 shows the erosion amount under experimental conditions the eg erosion included the erosion in the eg channel and channel shoulders calculated by different methods the erosion pin method was used before and after rr runs and the combination method was used for calculating eg erosion after the whole experiment the soil loss of the runoff plot s under the inflow rate of 15 l min 1 rr1 rr5 was larger than that under a 30 l min 1 inflow rate rr6 rr10 that is s15l s30l table 4 the reason for this result may be that sheet erosion on the hillslope is more important for the eg under lower inflow conditions hillslope erosion accounts for an average of 75 2 of total erosion under 15 l min 1 conditions whereas hillslope erosion accounts for 57 4 under 30 l min 1 conditions fig 3 the 15 l min 1 inflow corresponded to smaller water depth than the 30 l min 1 inflow under the same simulated rainfall of 60 mm h 1 the raindrop splash had more significant effects on the smaller inflow rate and triggered more severe sheet erosion on the hillslope in addition the larger inflow rate tended to form concentrated flow into the eg channel which led to greater erosion on the main eg channel and the eg channel shoulders compared with the smaller inflow 15 l min 1 eg erosion including the main eg channel and eg channel shoulders accounted for only 16 37 of total erosion under lower inflow conditions whereas eg erosion accounted for 26 69 of total erosion under higher inflow conditions previous researchers huang et al 1999 li et al 2016 xu et al 2017 zheng and gao 2000 recognised that upslope inflow was a dominant factor controlling eg erosion at the same time many researchers capra et al 2009 gong et al 2011 wu et al 2004 have emphasised the importance of rainfall intensity on eg erosion it is apparent that both of these factors have important impacts on eg formation and development and that the combined effects of rainfall and upslope inflow on eg erosion must be considered in different areas this result differs from previous findings on ephemeral gully erosion under different upslope inflow and rainfall intensities on an 8 m long 2 m wide soil pan xu et al 2017 that study showed that the rate of soil loss of the eg could increase 0 57 6 22 times with inflow rates from 1 21 to 10 31 l min 1 and 50 mm h 1 rainfall intensity and with inflow rates from 1 81 to 15 45 l min 1 and 75 mm h 1 rainfall intensity the reason for this difference is that those researchers chose smaller inflow rates under those conditions the impacts of raindrops are all significant in the eg erosion process the other reason is that the sizes of the eg models differed we built a deeper eg model and the overland inflow gathered faster especially under a high runoff rate therefore the impact of increased upslope inflow on eg erosion was weakened in contrast with the total erosion amount of the whole runoff plot the erosion in the eg channel seg increased significantly with increasing inflow rate i e seg 15l seg 30l rr1 rr10 the average erosion amount of the ephemeral gully was 66 5 kg under an inflow rate of 15 l min 1 and 87 8 kg under an inflow rate of 30 l min 1 the proportion of erosion amount from the eg channel increased from 25 to 43 with the increasing inflow rate the inflow rate of 30 l min 1 tended to form concentrated flow and a large quantity of overland flow though the hillslope quickly converged on the eg channel increased erosion and developed more tributaries the smaller upslope inflow 15 l min 1 generated relatively thin overland flow and even caused greater erosion from the eg channel shoulders these results fit well with laboratory rainfall simulation experiments on eg erosion with different slopes and rainfall intensities ding and li 2010 guo et al 2012 zheng and gao 2000 inflow sediment concentration had a significant effect on erosion amount table 4 the sediment yield from the runoff plot s and the eg channel s eg first increased slightly and then decreased with increasing sediment concentration table 4 under the two different inflow runoff conditions the maximum net erosion amount s occurred at the sediment concentration of 40 g l 1 there is a certain sediment carrying capacity for a stable slope bed and runoff rate greater sediment concentrations of upslope inflow are associated with smaller amounts of eg erosion previous researchers ding and li 2010 wu et al 2004 zheng and gao 2000 have shown similar results where soil erosion decreased with increased inflow sediment concentration and recognised sediment concentration as one of the main factors influencing eg erosion the proportion of eg erosion s eg to total erosion s is less than 50 under sediment concentrations of less than 120 g l 1 fig 3 only when the sediment concentration increased from 120 g l 1 to 160 g l 1 did the proportion of eg erosion exceed 50 and even reached 69 the eg channel and hillslope respectively occupied half of the runoff plot area sediment concentration has a great effect on the erosion process fig 4 and table 5 this effect is manifested in two aspects the time required to achieve a steady soil loss rate and the change of the initial net erosion rate higher inflow sediment concentration was associated with an earlier the state of sediment non scouring and non silting in the eg channel under the same sediment concentrations conditions the time to reach a steady soil loss rate decreased with increasing inflow rate this trend may be related to the rainfall splashing effect on different upslope inflow conditions as mentioned above under the inflow rate of 15 l min 1 except for the sediment concentration of 160 g l 1 the erosion process does not reach a non scouring and non silting state until the end of the experiment 60 min however it would be 80 min after rainfall when the erosion process of the sediment would reach an equilibrium state under the inflow rate of 30 l min 1 the time to reach the equilibrium state was approximately 40 50 min after the start of rainfall when the sediment concentration increased from 120 g l 1 to 160 g l 1 sediment depositions occurred in the eg channel the sediment concentration also affected the initial net erosion rate under the same inflow rate and a sediment concentration of less than 120 g l 1 the net erosion rate increased with increasing sediment concentration when the sediment concentration was larger than 120 g l 1 the net erosion rate decreased dramatically with increased sediment concentration to further study the critical value of sediment concentration of upslope inflow a cumulative sediment concentration curve was determined fig 5 when the sediment concentration increased from 120 to 160 g l 1 the accumulated net erosion sediment yield was the lowest the 160 g l 1 curve showed a downward trend under both inflow rate conditions but it fell faster under 30 l min 1 inflow runoff conditions in other words deposition occurred because the influence of raindrop splashing is more significant with lower inflow runoff conditions more deposition occurs under higher inflow runoff conditions therefore we can assume that the entire hillslope will have the maximum soil loss when rainfall falls into the upslope drainage area and forms runoff with a sediment concentration of 120 g l 1 when the inflow sediment concentration increased to 160 g l 1 the sediment eroded from the eg decreased dramatically this finding indicates that inflow with sediment concentrations of 120 160 g l 1 leads to the maximum erosion amount for hillslopes with egs especially on the loess plateau with high intensity and short duration rainfall patterns determining the sediment concentration threshold that makes egs reach the non scouring and non silting state is beneficial for prevention of soil loss future work is needed to examine the effects of slope gradient and inflow sediment concentration on eg erosion processes 4 3 flow velocity of the hillslope and ephemeral gully the flow velocities of the main eg channel v eg are greater than those of the hillslope v sl fig 6 with increasing inflow rate the increment of v eg is larger this result is consistent with the results of previous studies che et al 2011 gong et al 2011 xu et al 2017 zheng and gao 2000 the flow velocity of different parts v eg and v sl under different sediment concentrations of 15 l min 1 inflow conditions results in more uniformity with smooth fluctuation around the average values 0 03 m s 1 compared with the smaller inflow rate v eg and v sl fluctuated greatly around the average values 0 07 m s 1 and 0 04 m s 1 with different sediment concentrations the v eg and v sl had different opposite tendencies in other words v sl decreased when v eg increased this trend is closely related with the morphological characteristic of the ephemeral gully ephemeral gullies are more shallow and wider under lower upslope inflow the gully is relatively straight and no obvious tributaries appears with less surface runoff into the eg the surface runoff in each longitudinal section is more uniform in contrast the eg channel is more narrow and deeper under higher upslope inflow and tributaries develop fully there is more surface runoff into the eg by tributaries the v eg and v sl are volatile because of randomness in the development of the eg the sediment concentration has a limited effect on the v eg when the upslope inflow increases the sediment concentration can change the morphology of the eg and then change the v eg in particular when the upslope inflow is 30 l min 1 and the sediment concentration is 120 g l 1 the development of the ephemeral gully and the v eg are significantly increased 4 4 morphological characteristics of the ephemeral gully many rills and gullies formed in the hillslope the main eg channel and the eg channel shoulders fig 7 there were differences in the morphology of the rills and gullies under different upslope inflow conditions the main channel of the ephemeral gully had a deeper but narrower gully under 30 l min 1 inflow conditions compared with 15 l min 1 inflow conditions the maximum depth increased from 9 24 to 11 57 cm with increased inflow rate and the average depth increased from 7 72 to 9 42 cm increasing by 25 and 22 respectively table 6 the maximum gully width decreased from 22 82 to 18 17 cm with increased inflow rate and the average width decreased from 18 18 to 16 39 cm decreases by 20 and 10 respectively the number of tributaries increased with increasing inflow rate the different inflow sediment concentrations greatly affected the morphological characteristics of the ephemeral gully both the gully width and the number of tributaries decreased with increased sediment concentration the changes of eg channel depth were small the increased number of tributaries triggered the gathering of overland runoff in the main gully more easily and aggravated downward erosion the sediment carrying capacity of flow is constant and the soil erosion amount decreased with increased inflow sediment concentration therefore the number of tributaries and the depth and width of the main gully decreased 5 conclusions runoff and sediment processes were investigated in field runoff plots with egs under simulated rainfall and upslope laden inflow and the effects of inflow rate and sediment concentration on eg erosion deposition processes were further analysed the main findings were as follows 1 taking the amount of eg erosion calculated by the combined method as a benchmark two common measurement methods the volumetric method and erosion pin method yielded considerable errors the average error of the erosion pin method was from 20 6 to 10 6 with upslope inflow increasing from 15 l min 1 to 30 l min 1 the traditional measurement method was more stable with average error of about 15 under different upslope inflow conditions 2 the erosion caused by 15 l min 1 runoff was greater than that caused by 30 l min 1 runoff the smaller inflow rate triggered greater sheet or rill erosion whereas the greater rate mainly concentrated in the ephemeral gully channel and led to increasing gully erosion 3 the sediment concentration of upslope inflow had great influence on the eg erosion deposition processes the sediment concentration of 120 g l 1 was a critical value when it was exceeded sediment deposition began in the egs when the sediment concentration increased to 160 g l 1 a large amount of sediment was deposited in the runoff plot in the final stage of the experiment these results can help to accurately assess eg erosion processes and predict soil loss in loess areas 6 declaration of interest statement we declare that we have no financial and personal relationships with other people or organizations that can inappropriately influence our work there is no professional or other personal interest of any nature or kind in any product service and company that could be construed as influencing the position presented in or the review of the manuscript entitled acknowledgements the authors wish to thank all of the technicians involved in field and laboratory work this research was jointly funded by the national natural science foundation of china project 41771305 41530858 the national key r d program of china 2017yfc0504702 and the 111 project of china b18006 we thank sara j mason m sc from liwen bianji edanz editing china www liwenbianji cn ac for editing the english text of a draft of this manuscript 
6606,limestone dolomite gypsum anhydrite and salt are rocks which can be dissolved either by water alone or in the case of limestone and dolomite more efficiently by water enriched with carbon dioxide with time the secondary porosity in these rocks increases substantially and flow through these soluble rocks becomes very effective and fast the time period for a substantial increase in secondary porosity ranges from years salt to 10 000 100 000 years limestone dolomite the temporal evolution of such a soluble rock can be described by numerical models coupling flow transport and dissolution on the fracture scale numerous models describe fingering and wormhole formation in soluble rocks on the aquifer scale numerical models predict preferential flow patterns and a strong exchange flow component we present results from three dimensional numerical models describing the evolution of a karst aquifer in its early stage our numerical approach which describes the large aquifer scale is capable to simulate the strongly heterogeneous development of secondary permeability in the aquifer based on irregularities in the model e g geometry chemistry lithology hydrology preferential pathways evolve under a catchment control situation limiting the inflow into the system through the amount of water available from a catchment we compare qualitatively our large aquifer scale results to small fracture scale results and show that the fingering described by the latter models is driven by similar mechanisms as the preferential growth in the former models keywords karst fractured aquifer modelling evolution 1 introduction groundwater flow and transport through a karst aquifer is a challenging task to discuss because of the rapid change in permeability of the karst host rocks the karst host rock is a soluble rock such as dolomite limestone anhydrite gypsum or salt in all of these rock types water circulating through fissures bedding partings and pore spaces can dissolve material and thus enlarge the permeability of the host rock fig 1 in most cases this enlargement results in fairly heterogeneous flow paths within the karst aquifer which are efficiently drained by fast and focussed flow as a result a karst aquifer is prone to groundwater contamination and thus a challenge for water authorities as fractures and bedding partings are enlarged with time by chemical dissolution to the meter scale within geologically short periods 10 000 100 000 years these dissolutionally enlarged voids can also become mechanically unstable and result in either continuous or sudden collapse manifested along the surface with different types of sinkholes besides field observations hydraulic pumping tests and laboratory experiments the nature of an evolving karst aquifer can be addressed by numerical means a real situation is analysed simplified and described by the relevant physical and chemical processes and these processes are then transferred to mathematical models which are solved numerically to provide a description of the relevant properties of a karst aquifer in the last decades the evolution of karst features has been described numerically from two different perspectives which we categorise into small fracture scale and large aquifer scale approaches in this paper the small fracture scale refers here to discretisations on the meter to ten meter scale with cm resolution describing fractures the large aquifer scale refers to the 100 m to kilometer scale with meter resolution describing an aquifer small fracture scale modeling on the small fracture scale a fracture present in the host rock is discretised and modelled in two or three dimensions based on the relevant governing equations flow transport reaction continuity most of the work published focusses on porous flow models with reactive transport e g bekri et al 1997 dijk and berkowitz 1998 hanna and rajaram 1998 andre and rajaram 2005 szymczak and ladd 2006 szymczak and ladd 2009 szymczak and ladd 2011 szymczak and ladd 2011 szymczak and ladd 2013 chaudhuri et al 2008 chaudhuri et al 2013 upadhyay et al 2015 starchenko et al 2016 in the majority of the approaches fractures with lengths between the meter and the ten meter scale are discussed which are represented by a dense mesh of grid points in two or three dimensions flow is driven by either fixed head or fixed recharge conditions and the fracture evolving is often characterised by a strong fingering as the initially homogeneous dissolution front breaks due to irregularities in the model e g in initial width initial chemistry this fingering of the flow pattern is responsible for a more rapid evolution of the fracture when compared to a homogenous flow front large aquifer scale modeling on the large aquifer scale a karst aquifer is modelled by a set of inter connected fractures by discretising each fracture into a one dimensional element thereafter called single isolated fracture and connecting each of these fractures in two or three dimensions to resemble an entire karst aquifer again solving the relevant governing equations flow transport reaction continuity here a first generation of models is based on the concept of a single isolated fracture e g dreybrodt 1990 dreybrodt 1992 dreybrodt 1996 dreybrodt and gabrovšek 2000 palmer 1991 kaufmann 2002 the single isolated fracture in these approach resembles the most favourable flow path of a two dimensional fracture often regarded along the intersection of a fracture and a bedding parting fig 2 based on this simplifying assumption of a single isolated fracture which reflects the preferential flow path evolving in the fracture scale models two dimensional models of a karst aquifer have been modelled extensively e g bauer et al 2002 bauer et al 2003 clemens et al 1996 clemens et al 1997 clemens et al 1998 clemens et al 1999 dreybrodt and gabrovšek 2002 dreybrodt et al 2005 siemers and dreybrodt 1998 gabrovšek et al 2000 gabrovšek and dreybrodt 2000 gabrovšek and dreybrodt 2001 gabrovšek et al 2004 gabrovšek and dreybrodt 2010 gabrovšek and stepišnik 2011 groves and howard 1994 groves and howard 1994 howard and groves 1995 kaufmann and braun 1999 kaufmann and braun 2000 kaufmann 2003 kaufmann 2003 kaufmann 2003 kaufmann 2005 romanov et al 2002 romanov et al 2003 romanov et al 2003 romanov et al 2007 epting et al 2009 romanov et al 2010 romanov et al 2012 hiller et al 2014 in all of the above mentioned models exchange of flow between fractures in the network plays a crucial role as this effect termed exchange flow in the karst evolution modelling community is responsible for the strong coupling of flow and transport between individual fractures this exchange in turn significantly reduces the evolution time of the modelled aquifer the concept of aquifer scale evolution modelling in two dimensions has also been successfully applied to real case scenarios such as the evolution of maze caves in the western ukraine rehrl et al 2008 and the development of bathy phreatic loops in the blaukarst system in southern germany kaufmann and romanov 2008 in the last two decades aquifer scale karst evolution models have then been extended into the third dimension e g annable and sudicky 1998 annable 2003 kaufmann 2009 kaufmann et al 2010 and applied successfully to various real case scenarios such as dam sites e g hiller et al 2011 hiller et al 2012 and collapse sinkholes e g kaufmann and romanov 2016 in this paper we will discuss the validity of the aquifer scale numerical modelling approaches which have been challenged in the last decade we present three dimensional large aquifer scale numerical models whose evolving fracture geometry is driven by irregularities in initial geometry hydraulic boundary conditions rock lithology or chemistry our objectives are twofold firstly the presentation of preferential karstification patterns evolving under a catchment control situation which is characterised by a limited allogenic inflow this inflow condition differs from typical constant head conditions used commonly in the literature secondly a qualitative comparison of the evolved preferential karstification patterns resulting from exchange flow in our models with fingering and wormholes described in the small fracture scale literature we discuss and show that the exchange flow and the fingering are essentially the same mechanisms we have organised the paper as follows in section 2 we summarise the criticism of the aquifer scale approach in the literature we then recall the major results from the numerical models of the aquifer scale community which basically pre date the criticism discussed earlier in section 3 we then present results of karst aquifer evolution models in three dimensions highlighting the different modes of karstification which can be well correlated to real field situations 2 exchange flow we summarise findings from the recent literature on fracture scale and aquifer scale evolution modelling and emphasise some of the conclusions drawn from that modelling which are used to challenge the approach of the aquifer scale evolution models we respond to these challenges following a strategy discussing the main properties describing the temporal evolution of a karst aquifer such as the terms breakthrough time exchange flow non linear kinetics and preferential flow which we will discuss below szymczak et al have published a number of papers e g szymczak and ladd 2006 szymczak and ladd 2009 szymczak and ladd 2011 szymczak and ladd 2011 szymczak and ladd 2013 in which they correctly emphasise the role of exchange flow in the evolution of a single fracture of finite width and length with an initial height often described by an irregular initial surface they conclude that modelling a single fracture in two dimensions will result in the breakup of the dissolution front causing finger flow and thus a preferential enlargement of certain flow paths in the fracture while other parts remain small thus a two dimensional fracture will evolve faster than a fracture of similar dimensions but modelled as a one dimensional fracture only as an example in szymczak and ladd 2011 by comparing a one dimensional 20 m long fracture with an initial height of 0 2 mm to a two dimensional fracture with initial height of 0 2 mm and 10 m width but an irregular surface in the order of 20 nm come to the conclusion that the size of the two dimensional fracture evolves about one order of magnitude faster when compared to the evolution of the size of the one dimensional fracture with this statement szymczak and ladd 2011 challenge the relevance of the aquifer scale karst evolution models they conclude that fracture dissolution is always two dimensional and cannot be usefully approximated by one dimensional models quotation from szymczak and ladd 2011 see page 426 similar statements can be found in their later publications additionally szymczak and ladd 2011 report that for the two dimensional fracture the difference in breakthrough time between linear and non linear dissolution kinetics in only of secondary importance while for the one dimensional fracture non linear kinetics will speed up breakthrough by one order of magnitude when compared to a one dimensional fracture evolving under linear kinetics note that there are cases when a one dimensional fracture does not evolve significantly at all 2 1 breakthrough time for a single isolated fracture with flow through the fracture driven by a constant head boundary condition and water entering the fracture being under saturated with respect to calcite material from the fracture walls will be removed by dissolution enlarging the fracture and thus increasing the flow rate a positive feedback mechanism between flow rate and dissolution will result in an evolving fracture which experiences an increase in flow rate over several orders of magnitude over a short period of time this sudden increase in flow rate is termed breakthrough time in the literature e g dreybrodt 1996 the breakthrough time depends on several key parameter values i structural parameters e g fracture length l m initial fracture width d m ii hydraulic parameters e g head drop δ h m iii chemical parameters e g calcium equilibrium concentration c eq mol m3 linear rate law coefficient k 1 mol m2 s dreybrodt 1996 has derived an analytical approximation for the breakthrough time t b based on a simple mass balance and several simplifying assumptions constant fracture width calcium flux rate at the exit of fracture controls evolution 1 t b ad 3 l 8 3 δ h 4 3 c eq 4 3 k 1 1 3 with the proportionality constant a depending on the choice of the standard parameters thus the breakthrough time is a characteristic time for one dimensional single isolated fractures describing the time when the flow rate at the exit of the fracture increases by several orders of magnitude in comparably short time as stated in the aquifer scale literature see introduction for reference list the concept of breakthrough time can be used as a measure to characterise the evolution of a karst aquifer 2 2 exchange flow however it has been shown with both two and three dimensional aquifer scale evolution models that exchange flow significantly reduces breakthrough time the concept of exchange flow has arisen from aquifer scale evolution models in two dimensions with a network of inter connected fractures embedding a larger fracture in the central domain of such a two dimensional network of smaller fractures with exchange of flow between all fractures the development of the two dimensional aquifer strongly depends on the ratio of the initial width of the central fracture d central and the surrounding fractures d exchange we discuss the effect of exchange flow using the benchmark scenario for a two dimensional karst aquifer performed by bauer et al 2000 2002 2003 2010 in fig 3 the setup of this benchmark scenario is shown the model domain is 750 375 m with 101 51 nodal points resulting in a fracture network with each fracture 7 5 m long all fractures can exchange water at the connecting nodal points thus the term exchange flow the hydraulic head drop from left to right was set to 100 m resulting in an hydraulic head gradient of 0 1 3 top and bottom boundaries are impervious water undersaturated with respect to calcium enters on the left side c in 0 mol m 3 and the calcium equilibrium concentration is c eq 2 11 mol m 3 a typical value for limestone depending on the model chosen fractures are either rectangular features with initial width a 0 and height b 0 m or circular conduits with diameter d 0 m as already discussed above the central fracture in the modelling domain had a different initial width compared to the surrounding fracture network if the surrounding fractures are orders of magnitude smaller than the central fracture breakthrough of the two dimensional system is comparable to the one dimensional analogue fig 3 marker 1 with data taken from romanov et al 2002 once the initial fracture width of the surrounding fractures increases flow is diverted into these fractures and this flow diversion enhances dissolution the two dimensional aquifer develops faster by about one order of magnitude in time at most see fig 3 marker 2 finally when the initial fracture width of the surrounding fractures is identical to the initial fracture width of the central fracture all fractures connecting input and output boundaries evolve essentially as single fractures because there is no flow component perpendicular to the flow field initiated to induce exchange flow fig 3 marker 3 this two dimensional feedback effect between a network of fractures has been termed exchange flow in the literature see romanov et al 2002 romanov et al 2003 gabrovšek et al 2004 it basically describes the same effect as the fingering in the fracture scale evolution models a heterogeneity in the model be it a variation in initial fracture width in hydraulic pressure drop in calcium input or equilibrium concentration in the calcium rate law or even the inaccuracy of the numerical solver causes flow deviating from the one dimensional flow direction driven by the global head drop and thus a disturbance breaking up the initially uniform dissolution front therefore criticism of szymczak and ladd 2011 concerning the aquifer scale evolution models the one dimensional paradigm is not applicable to two and three dimensional aquifer scale evolution models as here the same mechanisms discussed in the fracture scale models cause a deviation from a one dimensional flow pattern and a related faster evolution of the aquifer scale models 2 3 non linear kinetics for a large number of soluble rocks laboratory measurements of dissolution kinetics have revealed a non linear flux rate for solution being close to saturation for limestone a non linear behaviour of the calcium flux rate has been found for calcium concentrations above around 90 of the calcium equilibrium concentration e g plummer et al 1978 svensson and dreybrodt 1992 eisenlohr et al 1999 for gypsum and anhydrite a similar threshold of around 95 of the calcium equilibrium concentration has been found e g james and lupton 1978 gobran and miyamoto 1985 lebedev and lekhov 1990 jeschke et al 2001 jeschke 2002 above which the flux rate becomes non linear a common hypothesis to explain this non linearity in calcium flux is the accumulation of impurities in the rock e g clay marl on the reactive surface which inhibits dissolution e g buhmann and dreybrodt 1985 buhmann and dreybrodt 1985 buhmann and dreybrodt 1987 only very pure rocks e g artificially created calcite and gypsum for industrial purposes do show a purely linear calcium flux rate the sharp drop in calcium flux rate close to equilibrium termed kinetic trigger in the literature has been used by white 1977 to explain the existence of large cave systems as the non linear flux rate is responsible for a much larger penetration length of aggressive water into a karst aquifer a linear rate law would result in a much shorter penetration length of only a few meters thus apparently contradicting the existence of large cave systems the effect of a linear versus a non linear calcium flux rate on the evolution of an aquifer in soluble rocks has been discussed extensively in the literature e g dreybrodt et al 1996 gabrovsek 2000 dreybrodt et al 2005 while the kinetic trigger has provided a good explanation for the evolution of aquifer scale models a linear rate law can also achieve breakthrough of a single isolated fracture when the limiting effect of diffusion on the dissolution is taken into account gabrovsek 2000 the results of szymczak and ladd 2011 therefore confirm that a non linear calcium flux rate also termed kinetic trigger is not always needed for the evolution of fractures in soluble rock 2 4 preferential flow path with the argumentation presented above we have shown that the aquifer scale evolution models do take heterogeneous flow and accelerated evolution through feedback in multiple dimensions into account the concept of exchange flow widely used in the aquifer scale modelling community pre dates the fingering discussion by szymczak et al since their 2006 publication however we like to emphasise again our rationale behind the concept of the single isolated fracture used as element on the level of the numerical grid resolution as already pointed out in the introduction the single isolated fracture represented the most probable flow path along the intersection of a fracture and a bedding parting in the soluble rock fig 2 most karst rocks many limestone rocks gypsum as well as anhydrite are characterised by fractures and bedding partings as a result of their complicated history from evaporation of a warm ocean precipitation of the mineral species and sub sequent burial compaction and finally tectonically induced uplift from this complicated history a preferential pattern of permeability in the soluble rock is present already from its onset of karstification often referred to as a dual porosity model with rock matrix and fractures only few exceptions such as the young highly porous limestones in florida with no significant fracturing deviate from this scheme with the most recent publication from starchenko et al 2016 modelling the early onset of preferential flow paths within two and three dimensional fractures on the fracture scale our concept of assuming single isolated fractures mimicking the preferential flow in 2d fractures on the grid scale of the aquifer size evolution models has been validated as reasonable assumption here the authors use a three dimensional setup of a fracture with flow driven by a pressure gradient they report the development of elliptical channels as preferential pathways in the fracture on time scales of tens of years characterising the initial stage of karstification these preferential pathways then control the further evolution of the fracture our approximation of a single isolated fracture basically resembles these preferential flow paths we have argued that our large aquifer scale karst evolution models are capable to describe the dissolution of material from fracture networks in soluble rocks our exchange flow mechanism first described in romanov et al 2002 is essentially the pendant of the breakup of a dissolution front with sub sequent fingering described by szymczak and ladd 2011 and follow up papers on the small fracture scale models the positive feedback mechanism between flow and dissolution induced by our exchange flow results in the same one order of magnitude reduction in fracture evolution as described by the two dimensional single fracture of szymczak and ladd 2011 and this order of magnitude estimate of the breakthrough time is basically describing the accuracy of our model predictions in time controlled by numerous uncertainties and heterogeneities in soluble rock properties and hydraulic boundary conditions thus while both the fracture scale and the aquifer scale models are based on the same set of equations describing the physical and chemical development of the system they show a similar reduction in breakthrough time once exchange flow is allowed the order of magnitude drop in breakthrough time for both the fracture scale and the aquifer scale models reveals a one to one mapping of the evolved features thus up and downscaling between the size of the model geometries should be possible we regard the model described by starchenko et al 2016 as a proof of our concept of the existence of a preferential flow path which develops in a multi dimensional fracture fairly fast and then carries the majority of flow in the next section we will continue to provide insights into the effectivity of modelling the evolution of karst aquifer systems with large aquifer scale evolution models and we emphasize the effects of different types of heterogeneities 3 modes of karstification we pick up the discussion of exchange flow from our benchmark scenarios which were conducted in two dimensions and extend the different mechanisms discussed with two dimensional modelling into the third dimension our main intention is to provide insights into the different patterns of preferential flow evolving in a large aquifer scale evolution model which are mainly controlled by irregularities initially present in the model which can be as diverse as irregularities in initial geometry initial hydraulic boundary conditions initial chemistry of the inflowing solution or other factors such as the macroscopic setup of the soluble rock we focus on limestone as soluble rock but the results are at least qualitatively transferrable to other rock types such as anhydrite and gypsum our models cover a wide range of field scenarios all are based on an inflow boundary condition describing the catchment flow control of a karst aquifer commonly encountered in nature e g palmer 1991 the influx of water is in this models controlled by the catchment area and once the fractures and bedding partings in the aquifer scale models are sufficiently enlarged the hydraulic gradient drops significantly and the then more mature karst aquifer evolve slower after breakthrough thus the model presented here differ from the majority of early aquifer scale karst evolution models presented in the literature by assuming a more realistic inflow boundary condition the model description has been published elsewhere see for example kaufmann et al 2010 in more detail thus here we provide only a brief review the program socks3d soluble rocks solves the following set of equations in a three dimensional modeling domain for a porous fractured aquifer under steady state or transient flow conditions 2 s s h t q q c p a f c d t m rock ρ rock f c the first equation is a conservation equation for flow with h m the hydraulic head q m s the darcy velocity s s 1 m the specific storage 1 m the nabla operator and t s time the second equation is the transport equation for the calcium concentration c mol m3 with p π d m and a π d 2 4 m2 the perimeter and the cross section of a circular fracture d m the fracture diameter f mol m2 s the calcium flux rate and c mol m3 the calcium concentration the third equation describes the reactive enlargement of a fracture with m rock kg mol the atomic mass and ρ rock kg m3 the density of the soluble rock darcy velocity is given by 3 q k h with k m s the hydraulic conductivity for fracture elements the hydraulic conductivity is given as 4 k f lam t ρ g 10 π η d t 2 laminar k f turb t 2 g fq i d t turbulent with ρ kg m3 the density of the fluid g m s2 the gravitational acceleration η pa s the viscosity of the fluid f the friction factor and q i m s the darcy flow rate component in flow direction from the previous iteration step note that flow in the presence of turbulence becomes non linear the transition from laminar to turbulent flow is controlled by the dimensionless reynolds number re relating inertial to viscous forces we use re 2000 as threshold for the transition from laminar to turbulent flow for matrix elements the hydraulic conductivity is derived from the kozeny carman relation e g lee and farmer 1993 xu and yu 2008 5 k m t ρ g 10 π η d t 2 l φ t 3 1 φ t 2 with φ the porosity of the rock matrix scaled between 0 no pores and 1 only pores l a tortuosity factor accounting for the complex geometry of the flow through the pores and d defined as typical grain size calcium flux rates for limestone are known both from laboratory experiments and numerical modelling 6 f k i m i c c eq n i i 1 3 with k i mol m2 s a rate coefficient m i a flux rate regime coefficient c mol m3 the actual calcium concentration c eq mol m3 the calcium equilibrium concentration and n i a power law exponent see kaufmann et al 2010 for more details the rate coefficient depends on both surface controlled rates and diffusion controlled rates 7 k i k i s k i d k i s k i d with k i s mol m2 s the surface controlled rate coefficient and with k i d 2 dc eq d mol m2 s the diffusion controlled rate coefficient and d m2 s the diffusion coefficient the calcium equilibrium concentration for a solution saturated with respect to calcite can be derived as an analytical expression to excellent accuracy e g dreybrodt 1988 when just the major molecules calcium and bicarbonate are used in the equation of electro neutrality 8 c eq 3 k 1 k c k h 4 k 2 γ ca 2 γ hco 3 2 p co 2 with k h t z the equilibrium constant for the dissolution of atmospheric carbon dioxide into water henri constant k 0 t z the equilibrium constant for the reaction of water and carbon dioxide to carbonic acid k 1 t z and k 2 t z the equilibrium constants for the dissociation of carbonic acid into bicarbonate carbonate and hydrogen k c t z the equilibrium constant for dissolved calcite γ ca 2 and γ hco 3 the activity coefficients for calcium and bicarbonate and p co 2 atm the carbon dioxide partial pressure this relation is valid under open system conditions where the solution is in contact with co2 containing atmosphere hence the co2 consumed for dissolution is replenished from the atmosphere under closed system conditions relevant during early speleogenesis or for deep flow paths carbon dioxide is not replenished and thus its concentration in the solution decreases as dissolution proceeds e g dreybrodt 1988 9 p co 2 p co 2 i c eq k h 1 1 k 0 with p co 2 i atm the initial carbon dioxide partial pressure the scenarios shown depict an idealised karst aquifer 200 m long 100 m wide and extending 20 m in the vertical direction fig 4 the surface of the model is located in 20 m height discretisation is chosen to obtain a spacing of 1 m in all directions resulting in roughly 400 000 matrix elements and 1 15 million fracture elements matrix conductivity is fixed to k m 10 7 m s matrix storativity to s m 5 10 6 1 m the initial fracture width of the circular conduits follows a log normal distribution with mean and standard deviation of d μ 0 1 mm and d σ 0 0001 mm storativity in the fractures is low s f 10 8 1 m flow through the aquifer is driven from west left to the east right with around 20000 m3 a inflow in an elevation between 0 and 4 m thus 16 m below surface mimicking a regional flow component this inflow corresponds to a catchment area of 40 000 m2 and a recharge rate of 500 mm yr inflowing water has already reached 90 of the possible calcium concentration thus c in 0 9 c eq the equilibrium calcium concentration derived from 8 has been calculated for a temperature of t 10 c and a carbon dioxide pressure of 50 000 ppm along the east at 4 m elevation a fixed head boundary condition simulates a local creek as base level as it can be seen in fig 4 the hydraulic pressure contours reveal flow from input in the west towards the base level in the east which is only slightly disturbed by the heterogeneous fracture conductivities resulting from the log normal distribution of fracture width 3 1 reference model our reference model is based on a log normal distribution of initial fracture width with a mean of d μ 0 1 mm and a small standard deviation of d σ 0 0001 mm 0 1 μ m the evolution of fracture width is shown in fig 5 for three snapshots in time after 3700 years of evolution several clusters of enlarged fractures have evolved from the western left input side growing into the aquifer fractures in these clustered areas have evolved to 2 5 mm width on average the clusters more or less follow the main pressure gradient resembling finger like preferential flow paths but no strong coupling between the clusters flow is still fairly uniform in front of the evolved clusters with water being pushed into the yet less developed part of the aquifer from the tips of the cluster fingers the evolution of clusters of enlarged fractures clearly indicate that exchange flow is present in this model but in the case of this reference run not too effective still this model will evolve about an order of magnitude faster than a single isolated fracture model as we have discussed already in our discussion of the breakthrough time see fig 3 hydraulic pressure contours are pushed towards the eastern right outflow side while the pressure distribution within the area of enlarged clusters is more uniform thus the snapshot in time reveals a similar evolution of the karst aquifer as in the case of a constant head inflow boundary condition close to breakthrough 6200 years into the evolution only two clusters remain in competition with each other the other clusters already have lost their ability to capture enough aggressive solution thus exchange flow has contributed to selectively favour two remaining preferential flow paths the lowermost cluster is close to breakthrough as it can be seen from the hydraulic contour pushed to the right side increasing the hydraulic gradient for this cluster over the short distance missing towards the fixed head boundary condition at the right side the model run is terminated after 10 000 years of evolution time here only one cluster close to the centre of the modelling domain has reached the western outflow side with a central channel enlarged to the 20 cm size the other clusters have not reached the outflow boundary and their evolution is significantly slowed down because the inflow boundary condition effectively limits flow in the mature aquifer the pressure drop has fallen below the 10 cm threshold over the entire aquifer here a clear difference in evolution is observed when compared to already published aquifer scale evolution models e g bauer et al 2000 romanov et al 2002 romanov et al 2003 kaufmann et al 2010 the inflow boundary condition limits the amount of water available for dissolutional enlargement after breakthrough has occurred thus it more accurately describes a catchment control situation usually encountered in karst systems under natural boundary conditions this behaviour can also be seen in the two statistical quantities average hydraulic head and flow rate out of the model through the eastern boundary fig 10 in the first 1 000 years the average head black dashed line is around 9 m and fairly constant then starts to drop and after 2000 years reaches the base level value assigned as outflow boundary condition around the same time the flow rate out of the model domain black solid line increases by several orders of magnitude then starts to level off this increase in flow rate marks a transitional event in the evolution of the aquifer system similar to the breakthrough time defined for one dimensional fractures inspecting the pattern of the evolved clusters with its linear structures in the down gradient direction of the induced flow shows that there is not much coupling between different clusters in the direction perpendicular to flow the reason is the small standard deviation for the initial fracture width which provides enough competitive flow paths from west to east 3 2 strong exchange flow in the next model we increase the standard deviation for the initial fracture width to d μ 0 05 mm the resulting wider log normal distribution of initial fracture width is responsible for less direct flow paths resulting in a more sinusoidal evolution of referential flow paths this model which we term exchange flow highlights the effect of initial geometry variations on the preferential flow pattern this can be seen in fig 6 after 3400 years of evolution time as before several clusters of enlarged fractures started evolving from the western inflow boundary towards the eastern outflow boundary however the preferential pathways are more sinusoidal now with a significant flow component perpendicular to the main west east flow direction the reason for this more complicated flow pattern is the wider distribution of initial fracture widths there are simply less direct pathways from the start on the wider distribution of initial fracture width enhances the exchange flow component significantly now the aquifer experiences more competing flow paths at this stage three clusters are still developing at a similar pace with the central cluster having already a slight advantage still fracture enlargement is driven in the main direction of flow from left to right 5800 years into the evolution the aquifer is close to breakthrough the central cluster has significantly outpaced the other two clusters in evolution attracting most of the flow the two other clusters almost stop developing after 10 000 years of evolution time the preferential pathway has reached the outflow boundary the hydraulic pressure has dropped by an order of magnitude and the preferential path has grown to the 20 cm size and beyond under constant head conditions a flow path of this size would experience turbulent flow which is considered in our numerical model however the inflow boundary condition used limits the amount of available water and thus reduces the pressure gradient thus from this time on development of secondary permeability is strongly reduced it becomes clear that the fixed inflow boundary condition when compared to a fixed head boundary condition controls the evolution after breakthrough as a karst aquifer driven with inflow condition is more realistic with its catchment controlled recharge this setup should be preferred when discussing a karst aquifer beyond its first breakthrough event the statistical parameter average head and flow rate leaving the model domain fig 10 solid and dashed blue lines show a similar evolution as in the reference case just accelerated by about 500 years 3 3 limited karstification we continue looking into the effect of rock lithology if instead of a pure limestone we consider a rock composed on thin layers of soluble limestone interbedded with thicker layers of insoluble marls the dissolution of the limestone fractures is limited by the thickness of the limestone beds we term this case limited karstification e g romanov et al 2010 and in the example restrict the limestone beds to a maximum thickness of d max 1 cm again we use the initial fracture distribution of the exchange flow example three snapshots in time for this scenario are shown in fig 7 after 3400 years of evolution the secondary permeability of the aquifer has evolved in the same way as the exchange flow model which is clear as both share the same setup and not very many of the fractures have yet reached the limitation threshold of 1 cm width the exchange flow in the model again controls the creation of several competing flow paths about 6500 years into the evolution three competing clusters have evolved as in the exchange flow case this time however the three clusters develop more uniformly as the limiting growth causes more fractures to be enlarged once a fracture has reached its maximum width the aggressive solution simply starts enlarging neighbouring fractures thus close to breakthrough the evolution of secondary permeability is more uniform than in the exchangeflow example but still the central cluster has obtained an advantage the difference caused by the limited karstification setup becomes more evident after 10 000 years of evolution the central cluster has reached the outflow boundary on the right side and the other two prominent pathways have established a connection to the winning central cluster they merge around 130 m into the aquifer with it in general more of the side passages for flow abandoned in the exchange flow setup remain active as they all compete for flow because of the growth threshold the secondary permeability is thus much more widely distributed and reveals a more homogeneous picture of fractures enlarged to similar sizes the statistical parameter average head and flow rate leaving the model domain fig 10 dashed and solid red lines show a similar evolution as in the exchange case for times before the re organisation of flow which is clear in view of the similar parameter setup after a preferential flow path has evolved however the restricted growth of fractures limits outflow to a fixed value 3 4 mixing corrosion next we investigate the influence of a variation in chemistry on the preferential flow pattern evolving we use the initial fracture distribution of the exchange flow example but we saturate the incoming water with respect to calcite c in c eq however we assign a carbon dioxide pressure of 50 000 ppm to the top 50 m of inflow along the western boundary but only 400 ppm to the bottom 50 m with this choice we argue to mimic inflow from two independent catchments a northern catchment with soil cover enhancing the co2 level and a southern catchment collecting water from bare rock thus the co2 pressure remains at atmospheric levels in fig 8 three snapshots in time are again shown for this model setup after 3 700 years of evolution a cluster of enlarged fractures develops along the central part of the model domain no fracture enlargement occurs in the other parts of the aquifer the reason is the saturated solution entering the aquifer along the western side inhibiting the evolution of secondary permeability here however in the narrow region where both saturated solutions mix the non linear dependence of the calcium equilibrium concentration on carbon dioxide pressure termed mixing corrosion in the literature e g bögli 1971 bögli 1978 results in aggressive solution able to dissolve the soluble rock we stress that the change in chemistry of the inflowing solution inhibits the positive feedback between flow and dissolution in large parts of the aquifer only the narrow zone where water from the two catchments mix is actively developing thus exchange flow outside of the mixing zone is inhibited resulting in a completely different evolution after 8700 years the cluster of enlarged fractures has almost reached the right side of the model the aquifer is close to the breakthrough condition still within the mixing zone several enlarged clusters compete for flow here substantial exchange flow between the enlarged fractures is driving the competition the contoured head distribution close to breakthrough reveals that along the inflow side flow is driven towards the enlarged cluster in the central part focussing water into the mixing zone along the tip of the enlarged cluster however flow is diverging out of the mixing zone keeping competition open for three sets of clusters which try to reach the right hand side first after 10 000 years of evolution a preferential flow path has evolved along the mixing zone which reaches 20 cm fracture width and beyond note that the incoming saturated solution which inhibits dissolution except where the waters mix keeps the hydraulic pressure higher along the northern and southern portions of the western side throughout the entire evolution time in the case of the mixing model the statistical parameter average head fig 10 dashed pink line indicates a later re organisation of flow after around 4000 years the flow rate leaving the model domain solid pink line however reflects the higher hydraulic heads along the northern and southern parts of the inflow boundary which reflect the inhibited dissolution due to the saturated solution entering the aquifer here the higher heads elevate the flow rates in the entire aquifer 3 5 sink recharge in the last setup we explore the role of the hydraulic boundary conditions by restricting inflow to two small areas located around the north western and south western corners here 50 000 m3 a are entering the subsurface at each corner as the initial fracture distribution is taken from the exchange flow example exchange flow will be comparable to the other scenarios in fig 9 again three snapshots in time are shown after 3800 years of evolution two clusters of enlarged fractures started growing from each sink area the general growth direction of the preferential flow clusters is directed towards the base level in the east thus along the main hydraulic gradient the irregular distribution of initial fracture widths perturbs this pattern it is also responsible for the faster growth of the southern cluster as here initially larger fractures provide an easier percolation path when compared to the northern cluster however a second growth mode can also be observed as both clusters of preferential flow also act as local base levels through there enhanced permeability side passages in the direction perpendicular of the large scale west east hydraulic gradient start evolving trying to reach the cluster on the opposite side 7800 years into the evolution the southern cluster is close to breakthrough while the northern cluster lags behind with its evolution several branches have started to growth in this northern cluster one in the general flow directions towards the base level in the east the others trying to connect to the southern cluster the flow directions can directly be derived from the bended head contour flow from the tips of the northern cluster is directed both in north south and west east direction for the last snapshot we have chosen a longer evolution time of 15 000 years this snapshot enables us to show the re orientation of the northern cluster after the breakthrough of the southern cluster the northern cluster with its slightly disadvantageous flow path connects to the established flow path of the southern cluster because flow resistance along this flow path is smallest thus the preferential pathways originally developing independently towards the base level along the eastern side merge later on and continue as a single drainage path due to the heterogeneities in the model setup inflow and initial fracture distribution the smaller total inflow resulting from the sink input scenario results in an average head much lower than in the previous cases fig 10 dashed green line but the temporal evolution though occurring later at around 9000 years is similar flow out of the model domain solid green line again depicts the transition from initial to more mature permeability evolution 4 conclusions we have used the socks3d large scale karst aquifer model to discuss the development and evolution of secondary permeability in a karst aquifer our aim has been to emphasize on the one hand the role of exchange flow in aquifer scale evolution models and on the other hand discussing other structural chemical or hydraulic parameters such as fracture distribution rock lithology chemistry and hydrology controlling the evolution all models clearly reveal the importance of exchange flow which reduces breakthrough time by an order of magnitude when related to models not considering exchange flow however the pattern of the evolving secondary permeability is mainly controlled by the structural chemical and hydraulic parameters i the initial fracture distribution controls the tortuosity of the preferential pathways with a wider initial distribution enhancing exchange flow and creating more sinusoidal flow paths these findings confirm earlier investigations based on fixed head boundary conditions by kaufmann et al 2010 ii if the soluble rock is more impure e g limestone is only present as thin layers between insoluble layers the secondary permeability develops more uniform exchange flow becomes even more important in agreement with previous results from romanov et al 2010 based on fixed head boundary conditions iii for inflowing solutions being saturated with respect to calcite but having different carbon dioxide concentration mixing corrosion becomes decisive with a distinct pattern of secondary permeability evolving similar to published results e g romanov et al 2003 obtained for fixed head boundary conditions iv finally changing inflow from regional contributions to localised sink input will confine the evolution of secondary permeability to pathways from sinks to base level thus resulting in systems which appear more branchwork controlled using the socks3d large scale karst aquifer model described above we have been able to demonstrate that the main critical point of the one dimensional paradigm e g szymczak and ladd 2011 namely that the basic elements of our large aquifer scale models develop way too slow is not justified allowing exchange along the length of the fracture we reach several targets 1 obtain evolution times comparable with the breakthrough times reported when the conduits are represented as 2d 3d rough structures 2 represent the fractures embedded into a complex system porous media preferential pathways bedding planes which is closer to reality in comparison with the fractures which cannot exchange solution along their lengths used by the small fracture scale approach 3 because our modelling approach requires much less resources we are able to model the karstification of large karst aquifers this will be very difficult even nowadays if every basic element of the model has to be represented by 2d 3d elements so which approach is better this depends on the target of the study if the target is the evolution of a real large scale karst aquifer then in our opinion it is better to use large aquifer scale model on the other hand if the focus of the study is a detailed pictures of the evolution of a single fracture then the small fracture scale model is probably better suited finally we have shortly described two modelling approaches each with its strengths and weaknesses the small fracture scale model represents the fractures in an aquifer by isolated 2d 3d conduits while the large aquifer scale model uses 1d conduits but allows them to exchange solution along the fracture network as they are not isolated both approaches obtain comparable evolution times for karst systems which approach is preferred however depends on the target of the study declaration of interests none declared acknowledgements we thank corrado corradini as responsible editor and two anonymous referees for their thorough reviews which helped to significantly improve the manuscript gk acknowledges funding from the dfg under research grant ka1723 6 2 figures were prepared using gmt software wessel and smith 1998 
6606,limestone dolomite gypsum anhydrite and salt are rocks which can be dissolved either by water alone or in the case of limestone and dolomite more efficiently by water enriched with carbon dioxide with time the secondary porosity in these rocks increases substantially and flow through these soluble rocks becomes very effective and fast the time period for a substantial increase in secondary porosity ranges from years salt to 10 000 100 000 years limestone dolomite the temporal evolution of such a soluble rock can be described by numerical models coupling flow transport and dissolution on the fracture scale numerous models describe fingering and wormhole formation in soluble rocks on the aquifer scale numerical models predict preferential flow patterns and a strong exchange flow component we present results from three dimensional numerical models describing the evolution of a karst aquifer in its early stage our numerical approach which describes the large aquifer scale is capable to simulate the strongly heterogeneous development of secondary permeability in the aquifer based on irregularities in the model e g geometry chemistry lithology hydrology preferential pathways evolve under a catchment control situation limiting the inflow into the system through the amount of water available from a catchment we compare qualitatively our large aquifer scale results to small fracture scale results and show that the fingering described by the latter models is driven by similar mechanisms as the preferential growth in the former models keywords karst fractured aquifer modelling evolution 1 introduction groundwater flow and transport through a karst aquifer is a challenging task to discuss because of the rapid change in permeability of the karst host rocks the karst host rock is a soluble rock such as dolomite limestone anhydrite gypsum or salt in all of these rock types water circulating through fissures bedding partings and pore spaces can dissolve material and thus enlarge the permeability of the host rock fig 1 in most cases this enlargement results in fairly heterogeneous flow paths within the karst aquifer which are efficiently drained by fast and focussed flow as a result a karst aquifer is prone to groundwater contamination and thus a challenge for water authorities as fractures and bedding partings are enlarged with time by chemical dissolution to the meter scale within geologically short periods 10 000 100 000 years these dissolutionally enlarged voids can also become mechanically unstable and result in either continuous or sudden collapse manifested along the surface with different types of sinkholes besides field observations hydraulic pumping tests and laboratory experiments the nature of an evolving karst aquifer can be addressed by numerical means a real situation is analysed simplified and described by the relevant physical and chemical processes and these processes are then transferred to mathematical models which are solved numerically to provide a description of the relevant properties of a karst aquifer in the last decades the evolution of karst features has been described numerically from two different perspectives which we categorise into small fracture scale and large aquifer scale approaches in this paper the small fracture scale refers here to discretisations on the meter to ten meter scale with cm resolution describing fractures the large aquifer scale refers to the 100 m to kilometer scale with meter resolution describing an aquifer small fracture scale modeling on the small fracture scale a fracture present in the host rock is discretised and modelled in two or three dimensions based on the relevant governing equations flow transport reaction continuity most of the work published focusses on porous flow models with reactive transport e g bekri et al 1997 dijk and berkowitz 1998 hanna and rajaram 1998 andre and rajaram 2005 szymczak and ladd 2006 szymczak and ladd 2009 szymczak and ladd 2011 szymczak and ladd 2011 szymczak and ladd 2013 chaudhuri et al 2008 chaudhuri et al 2013 upadhyay et al 2015 starchenko et al 2016 in the majority of the approaches fractures with lengths between the meter and the ten meter scale are discussed which are represented by a dense mesh of grid points in two or three dimensions flow is driven by either fixed head or fixed recharge conditions and the fracture evolving is often characterised by a strong fingering as the initially homogeneous dissolution front breaks due to irregularities in the model e g in initial width initial chemistry this fingering of the flow pattern is responsible for a more rapid evolution of the fracture when compared to a homogenous flow front large aquifer scale modeling on the large aquifer scale a karst aquifer is modelled by a set of inter connected fractures by discretising each fracture into a one dimensional element thereafter called single isolated fracture and connecting each of these fractures in two or three dimensions to resemble an entire karst aquifer again solving the relevant governing equations flow transport reaction continuity here a first generation of models is based on the concept of a single isolated fracture e g dreybrodt 1990 dreybrodt 1992 dreybrodt 1996 dreybrodt and gabrovšek 2000 palmer 1991 kaufmann 2002 the single isolated fracture in these approach resembles the most favourable flow path of a two dimensional fracture often regarded along the intersection of a fracture and a bedding parting fig 2 based on this simplifying assumption of a single isolated fracture which reflects the preferential flow path evolving in the fracture scale models two dimensional models of a karst aquifer have been modelled extensively e g bauer et al 2002 bauer et al 2003 clemens et al 1996 clemens et al 1997 clemens et al 1998 clemens et al 1999 dreybrodt and gabrovšek 2002 dreybrodt et al 2005 siemers and dreybrodt 1998 gabrovšek et al 2000 gabrovšek and dreybrodt 2000 gabrovšek and dreybrodt 2001 gabrovšek et al 2004 gabrovšek and dreybrodt 2010 gabrovšek and stepišnik 2011 groves and howard 1994 groves and howard 1994 howard and groves 1995 kaufmann and braun 1999 kaufmann and braun 2000 kaufmann 2003 kaufmann 2003 kaufmann 2003 kaufmann 2005 romanov et al 2002 romanov et al 2003 romanov et al 2003 romanov et al 2007 epting et al 2009 romanov et al 2010 romanov et al 2012 hiller et al 2014 in all of the above mentioned models exchange of flow between fractures in the network plays a crucial role as this effect termed exchange flow in the karst evolution modelling community is responsible for the strong coupling of flow and transport between individual fractures this exchange in turn significantly reduces the evolution time of the modelled aquifer the concept of aquifer scale evolution modelling in two dimensions has also been successfully applied to real case scenarios such as the evolution of maze caves in the western ukraine rehrl et al 2008 and the development of bathy phreatic loops in the blaukarst system in southern germany kaufmann and romanov 2008 in the last two decades aquifer scale karst evolution models have then been extended into the third dimension e g annable and sudicky 1998 annable 2003 kaufmann 2009 kaufmann et al 2010 and applied successfully to various real case scenarios such as dam sites e g hiller et al 2011 hiller et al 2012 and collapse sinkholes e g kaufmann and romanov 2016 in this paper we will discuss the validity of the aquifer scale numerical modelling approaches which have been challenged in the last decade we present three dimensional large aquifer scale numerical models whose evolving fracture geometry is driven by irregularities in initial geometry hydraulic boundary conditions rock lithology or chemistry our objectives are twofold firstly the presentation of preferential karstification patterns evolving under a catchment control situation which is characterised by a limited allogenic inflow this inflow condition differs from typical constant head conditions used commonly in the literature secondly a qualitative comparison of the evolved preferential karstification patterns resulting from exchange flow in our models with fingering and wormholes described in the small fracture scale literature we discuss and show that the exchange flow and the fingering are essentially the same mechanisms we have organised the paper as follows in section 2 we summarise the criticism of the aquifer scale approach in the literature we then recall the major results from the numerical models of the aquifer scale community which basically pre date the criticism discussed earlier in section 3 we then present results of karst aquifer evolution models in three dimensions highlighting the different modes of karstification which can be well correlated to real field situations 2 exchange flow we summarise findings from the recent literature on fracture scale and aquifer scale evolution modelling and emphasise some of the conclusions drawn from that modelling which are used to challenge the approach of the aquifer scale evolution models we respond to these challenges following a strategy discussing the main properties describing the temporal evolution of a karst aquifer such as the terms breakthrough time exchange flow non linear kinetics and preferential flow which we will discuss below szymczak et al have published a number of papers e g szymczak and ladd 2006 szymczak and ladd 2009 szymczak and ladd 2011 szymczak and ladd 2011 szymczak and ladd 2013 in which they correctly emphasise the role of exchange flow in the evolution of a single fracture of finite width and length with an initial height often described by an irregular initial surface they conclude that modelling a single fracture in two dimensions will result in the breakup of the dissolution front causing finger flow and thus a preferential enlargement of certain flow paths in the fracture while other parts remain small thus a two dimensional fracture will evolve faster than a fracture of similar dimensions but modelled as a one dimensional fracture only as an example in szymczak and ladd 2011 by comparing a one dimensional 20 m long fracture with an initial height of 0 2 mm to a two dimensional fracture with initial height of 0 2 mm and 10 m width but an irregular surface in the order of 20 nm come to the conclusion that the size of the two dimensional fracture evolves about one order of magnitude faster when compared to the evolution of the size of the one dimensional fracture with this statement szymczak and ladd 2011 challenge the relevance of the aquifer scale karst evolution models they conclude that fracture dissolution is always two dimensional and cannot be usefully approximated by one dimensional models quotation from szymczak and ladd 2011 see page 426 similar statements can be found in their later publications additionally szymczak and ladd 2011 report that for the two dimensional fracture the difference in breakthrough time between linear and non linear dissolution kinetics in only of secondary importance while for the one dimensional fracture non linear kinetics will speed up breakthrough by one order of magnitude when compared to a one dimensional fracture evolving under linear kinetics note that there are cases when a one dimensional fracture does not evolve significantly at all 2 1 breakthrough time for a single isolated fracture with flow through the fracture driven by a constant head boundary condition and water entering the fracture being under saturated with respect to calcite material from the fracture walls will be removed by dissolution enlarging the fracture and thus increasing the flow rate a positive feedback mechanism between flow rate and dissolution will result in an evolving fracture which experiences an increase in flow rate over several orders of magnitude over a short period of time this sudden increase in flow rate is termed breakthrough time in the literature e g dreybrodt 1996 the breakthrough time depends on several key parameter values i structural parameters e g fracture length l m initial fracture width d m ii hydraulic parameters e g head drop δ h m iii chemical parameters e g calcium equilibrium concentration c eq mol m3 linear rate law coefficient k 1 mol m2 s dreybrodt 1996 has derived an analytical approximation for the breakthrough time t b based on a simple mass balance and several simplifying assumptions constant fracture width calcium flux rate at the exit of fracture controls evolution 1 t b ad 3 l 8 3 δ h 4 3 c eq 4 3 k 1 1 3 with the proportionality constant a depending on the choice of the standard parameters thus the breakthrough time is a characteristic time for one dimensional single isolated fractures describing the time when the flow rate at the exit of the fracture increases by several orders of magnitude in comparably short time as stated in the aquifer scale literature see introduction for reference list the concept of breakthrough time can be used as a measure to characterise the evolution of a karst aquifer 2 2 exchange flow however it has been shown with both two and three dimensional aquifer scale evolution models that exchange flow significantly reduces breakthrough time the concept of exchange flow has arisen from aquifer scale evolution models in two dimensions with a network of inter connected fractures embedding a larger fracture in the central domain of such a two dimensional network of smaller fractures with exchange of flow between all fractures the development of the two dimensional aquifer strongly depends on the ratio of the initial width of the central fracture d central and the surrounding fractures d exchange we discuss the effect of exchange flow using the benchmark scenario for a two dimensional karst aquifer performed by bauer et al 2000 2002 2003 2010 in fig 3 the setup of this benchmark scenario is shown the model domain is 750 375 m with 101 51 nodal points resulting in a fracture network with each fracture 7 5 m long all fractures can exchange water at the connecting nodal points thus the term exchange flow the hydraulic head drop from left to right was set to 100 m resulting in an hydraulic head gradient of 0 1 3 top and bottom boundaries are impervious water undersaturated with respect to calcium enters on the left side c in 0 mol m 3 and the calcium equilibrium concentration is c eq 2 11 mol m 3 a typical value for limestone depending on the model chosen fractures are either rectangular features with initial width a 0 and height b 0 m or circular conduits with diameter d 0 m as already discussed above the central fracture in the modelling domain had a different initial width compared to the surrounding fracture network if the surrounding fractures are orders of magnitude smaller than the central fracture breakthrough of the two dimensional system is comparable to the one dimensional analogue fig 3 marker 1 with data taken from romanov et al 2002 once the initial fracture width of the surrounding fractures increases flow is diverted into these fractures and this flow diversion enhances dissolution the two dimensional aquifer develops faster by about one order of magnitude in time at most see fig 3 marker 2 finally when the initial fracture width of the surrounding fractures is identical to the initial fracture width of the central fracture all fractures connecting input and output boundaries evolve essentially as single fractures because there is no flow component perpendicular to the flow field initiated to induce exchange flow fig 3 marker 3 this two dimensional feedback effect between a network of fractures has been termed exchange flow in the literature see romanov et al 2002 romanov et al 2003 gabrovšek et al 2004 it basically describes the same effect as the fingering in the fracture scale evolution models a heterogeneity in the model be it a variation in initial fracture width in hydraulic pressure drop in calcium input or equilibrium concentration in the calcium rate law or even the inaccuracy of the numerical solver causes flow deviating from the one dimensional flow direction driven by the global head drop and thus a disturbance breaking up the initially uniform dissolution front therefore criticism of szymczak and ladd 2011 concerning the aquifer scale evolution models the one dimensional paradigm is not applicable to two and three dimensional aquifer scale evolution models as here the same mechanisms discussed in the fracture scale models cause a deviation from a one dimensional flow pattern and a related faster evolution of the aquifer scale models 2 3 non linear kinetics for a large number of soluble rocks laboratory measurements of dissolution kinetics have revealed a non linear flux rate for solution being close to saturation for limestone a non linear behaviour of the calcium flux rate has been found for calcium concentrations above around 90 of the calcium equilibrium concentration e g plummer et al 1978 svensson and dreybrodt 1992 eisenlohr et al 1999 for gypsum and anhydrite a similar threshold of around 95 of the calcium equilibrium concentration has been found e g james and lupton 1978 gobran and miyamoto 1985 lebedev and lekhov 1990 jeschke et al 2001 jeschke 2002 above which the flux rate becomes non linear a common hypothesis to explain this non linearity in calcium flux is the accumulation of impurities in the rock e g clay marl on the reactive surface which inhibits dissolution e g buhmann and dreybrodt 1985 buhmann and dreybrodt 1985 buhmann and dreybrodt 1987 only very pure rocks e g artificially created calcite and gypsum for industrial purposes do show a purely linear calcium flux rate the sharp drop in calcium flux rate close to equilibrium termed kinetic trigger in the literature has been used by white 1977 to explain the existence of large cave systems as the non linear flux rate is responsible for a much larger penetration length of aggressive water into a karst aquifer a linear rate law would result in a much shorter penetration length of only a few meters thus apparently contradicting the existence of large cave systems the effect of a linear versus a non linear calcium flux rate on the evolution of an aquifer in soluble rocks has been discussed extensively in the literature e g dreybrodt et al 1996 gabrovsek 2000 dreybrodt et al 2005 while the kinetic trigger has provided a good explanation for the evolution of aquifer scale models a linear rate law can also achieve breakthrough of a single isolated fracture when the limiting effect of diffusion on the dissolution is taken into account gabrovsek 2000 the results of szymczak and ladd 2011 therefore confirm that a non linear calcium flux rate also termed kinetic trigger is not always needed for the evolution of fractures in soluble rock 2 4 preferential flow path with the argumentation presented above we have shown that the aquifer scale evolution models do take heterogeneous flow and accelerated evolution through feedback in multiple dimensions into account the concept of exchange flow widely used in the aquifer scale modelling community pre dates the fingering discussion by szymczak et al since their 2006 publication however we like to emphasise again our rationale behind the concept of the single isolated fracture used as element on the level of the numerical grid resolution as already pointed out in the introduction the single isolated fracture represented the most probable flow path along the intersection of a fracture and a bedding parting in the soluble rock fig 2 most karst rocks many limestone rocks gypsum as well as anhydrite are characterised by fractures and bedding partings as a result of their complicated history from evaporation of a warm ocean precipitation of the mineral species and sub sequent burial compaction and finally tectonically induced uplift from this complicated history a preferential pattern of permeability in the soluble rock is present already from its onset of karstification often referred to as a dual porosity model with rock matrix and fractures only few exceptions such as the young highly porous limestones in florida with no significant fracturing deviate from this scheme with the most recent publication from starchenko et al 2016 modelling the early onset of preferential flow paths within two and three dimensional fractures on the fracture scale our concept of assuming single isolated fractures mimicking the preferential flow in 2d fractures on the grid scale of the aquifer size evolution models has been validated as reasonable assumption here the authors use a three dimensional setup of a fracture with flow driven by a pressure gradient they report the development of elliptical channels as preferential pathways in the fracture on time scales of tens of years characterising the initial stage of karstification these preferential pathways then control the further evolution of the fracture our approximation of a single isolated fracture basically resembles these preferential flow paths we have argued that our large aquifer scale karst evolution models are capable to describe the dissolution of material from fracture networks in soluble rocks our exchange flow mechanism first described in romanov et al 2002 is essentially the pendant of the breakup of a dissolution front with sub sequent fingering described by szymczak and ladd 2011 and follow up papers on the small fracture scale models the positive feedback mechanism between flow and dissolution induced by our exchange flow results in the same one order of magnitude reduction in fracture evolution as described by the two dimensional single fracture of szymczak and ladd 2011 and this order of magnitude estimate of the breakthrough time is basically describing the accuracy of our model predictions in time controlled by numerous uncertainties and heterogeneities in soluble rock properties and hydraulic boundary conditions thus while both the fracture scale and the aquifer scale models are based on the same set of equations describing the physical and chemical development of the system they show a similar reduction in breakthrough time once exchange flow is allowed the order of magnitude drop in breakthrough time for both the fracture scale and the aquifer scale models reveals a one to one mapping of the evolved features thus up and downscaling between the size of the model geometries should be possible we regard the model described by starchenko et al 2016 as a proof of our concept of the existence of a preferential flow path which develops in a multi dimensional fracture fairly fast and then carries the majority of flow in the next section we will continue to provide insights into the effectivity of modelling the evolution of karst aquifer systems with large aquifer scale evolution models and we emphasize the effects of different types of heterogeneities 3 modes of karstification we pick up the discussion of exchange flow from our benchmark scenarios which were conducted in two dimensions and extend the different mechanisms discussed with two dimensional modelling into the third dimension our main intention is to provide insights into the different patterns of preferential flow evolving in a large aquifer scale evolution model which are mainly controlled by irregularities initially present in the model which can be as diverse as irregularities in initial geometry initial hydraulic boundary conditions initial chemistry of the inflowing solution or other factors such as the macroscopic setup of the soluble rock we focus on limestone as soluble rock but the results are at least qualitatively transferrable to other rock types such as anhydrite and gypsum our models cover a wide range of field scenarios all are based on an inflow boundary condition describing the catchment flow control of a karst aquifer commonly encountered in nature e g palmer 1991 the influx of water is in this models controlled by the catchment area and once the fractures and bedding partings in the aquifer scale models are sufficiently enlarged the hydraulic gradient drops significantly and the then more mature karst aquifer evolve slower after breakthrough thus the model presented here differ from the majority of early aquifer scale karst evolution models presented in the literature by assuming a more realistic inflow boundary condition the model description has been published elsewhere see for example kaufmann et al 2010 in more detail thus here we provide only a brief review the program socks3d soluble rocks solves the following set of equations in a three dimensional modeling domain for a porous fractured aquifer under steady state or transient flow conditions 2 s s h t q q c p a f c d t m rock ρ rock f c the first equation is a conservation equation for flow with h m the hydraulic head q m s the darcy velocity s s 1 m the specific storage 1 m the nabla operator and t s time the second equation is the transport equation for the calcium concentration c mol m3 with p π d m and a π d 2 4 m2 the perimeter and the cross section of a circular fracture d m the fracture diameter f mol m2 s the calcium flux rate and c mol m3 the calcium concentration the third equation describes the reactive enlargement of a fracture with m rock kg mol the atomic mass and ρ rock kg m3 the density of the soluble rock darcy velocity is given by 3 q k h with k m s the hydraulic conductivity for fracture elements the hydraulic conductivity is given as 4 k f lam t ρ g 10 π η d t 2 laminar k f turb t 2 g fq i d t turbulent with ρ kg m3 the density of the fluid g m s2 the gravitational acceleration η pa s the viscosity of the fluid f the friction factor and q i m s the darcy flow rate component in flow direction from the previous iteration step note that flow in the presence of turbulence becomes non linear the transition from laminar to turbulent flow is controlled by the dimensionless reynolds number re relating inertial to viscous forces we use re 2000 as threshold for the transition from laminar to turbulent flow for matrix elements the hydraulic conductivity is derived from the kozeny carman relation e g lee and farmer 1993 xu and yu 2008 5 k m t ρ g 10 π η d t 2 l φ t 3 1 φ t 2 with φ the porosity of the rock matrix scaled between 0 no pores and 1 only pores l a tortuosity factor accounting for the complex geometry of the flow through the pores and d defined as typical grain size calcium flux rates for limestone are known both from laboratory experiments and numerical modelling 6 f k i m i c c eq n i i 1 3 with k i mol m2 s a rate coefficient m i a flux rate regime coefficient c mol m3 the actual calcium concentration c eq mol m3 the calcium equilibrium concentration and n i a power law exponent see kaufmann et al 2010 for more details the rate coefficient depends on both surface controlled rates and diffusion controlled rates 7 k i k i s k i d k i s k i d with k i s mol m2 s the surface controlled rate coefficient and with k i d 2 dc eq d mol m2 s the diffusion controlled rate coefficient and d m2 s the diffusion coefficient the calcium equilibrium concentration for a solution saturated with respect to calcite can be derived as an analytical expression to excellent accuracy e g dreybrodt 1988 when just the major molecules calcium and bicarbonate are used in the equation of electro neutrality 8 c eq 3 k 1 k c k h 4 k 2 γ ca 2 γ hco 3 2 p co 2 with k h t z the equilibrium constant for the dissolution of atmospheric carbon dioxide into water henri constant k 0 t z the equilibrium constant for the reaction of water and carbon dioxide to carbonic acid k 1 t z and k 2 t z the equilibrium constants for the dissociation of carbonic acid into bicarbonate carbonate and hydrogen k c t z the equilibrium constant for dissolved calcite γ ca 2 and γ hco 3 the activity coefficients for calcium and bicarbonate and p co 2 atm the carbon dioxide partial pressure this relation is valid under open system conditions where the solution is in contact with co2 containing atmosphere hence the co2 consumed for dissolution is replenished from the atmosphere under closed system conditions relevant during early speleogenesis or for deep flow paths carbon dioxide is not replenished and thus its concentration in the solution decreases as dissolution proceeds e g dreybrodt 1988 9 p co 2 p co 2 i c eq k h 1 1 k 0 with p co 2 i atm the initial carbon dioxide partial pressure the scenarios shown depict an idealised karst aquifer 200 m long 100 m wide and extending 20 m in the vertical direction fig 4 the surface of the model is located in 20 m height discretisation is chosen to obtain a spacing of 1 m in all directions resulting in roughly 400 000 matrix elements and 1 15 million fracture elements matrix conductivity is fixed to k m 10 7 m s matrix storativity to s m 5 10 6 1 m the initial fracture width of the circular conduits follows a log normal distribution with mean and standard deviation of d μ 0 1 mm and d σ 0 0001 mm storativity in the fractures is low s f 10 8 1 m flow through the aquifer is driven from west left to the east right with around 20000 m3 a inflow in an elevation between 0 and 4 m thus 16 m below surface mimicking a regional flow component this inflow corresponds to a catchment area of 40 000 m2 and a recharge rate of 500 mm yr inflowing water has already reached 90 of the possible calcium concentration thus c in 0 9 c eq the equilibrium calcium concentration derived from 8 has been calculated for a temperature of t 10 c and a carbon dioxide pressure of 50 000 ppm along the east at 4 m elevation a fixed head boundary condition simulates a local creek as base level as it can be seen in fig 4 the hydraulic pressure contours reveal flow from input in the west towards the base level in the east which is only slightly disturbed by the heterogeneous fracture conductivities resulting from the log normal distribution of fracture width 3 1 reference model our reference model is based on a log normal distribution of initial fracture width with a mean of d μ 0 1 mm and a small standard deviation of d σ 0 0001 mm 0 1 μ m the evolution of fracture width is shown in fig 5 for three snapshots in time after 3700 years of evolution several clusters of enlarged fractures have evolved from the western left input side growing into the aquifer fractures in these clustered areas have evolved to 2 5 mm width on average the clusters more or less follow the main pressure gradient resembling finger like preferential flow paths but no strong coupling between the clusters flow is still fairly uniform in front of the evolved clusters with water being pushed into the yet less developed part of the aquifer from the tips of the cluster fingers the evolution of clusters of enlarged fractures clearly indicate that exchange flow is present in this model but in the case of this reference run not too effective still this model will evolve about an order of magnitude faster than a single isolated fracture model as we have discussed already in our discussion of the breakthrough time see fig 3 hydraulic pressure contours are pushed towards the eastern right outflow side while the pressure distribution within the area of enlarged clusters is more uniform thus the snapshot in time reveals a similar evolution of the karst aquifer as in the case of a constant head inflow boundary condition close to breakthrough 6200 years into the evolution only two clusters remain in competition with each other the other clusters already have lost their ability to capture enough aggressive solution thus exchange flow has contributed to selectively favour two remaining preferential flow paths the lowermost cluster is close to breakthrough as it can be seen from the hydraulic contour pushed to the right side increasing the hydraulic gradient for this cluster over the short distance missing towards the fixed head boundary condition at the right side the model run is terminated after 10 000 years of evolution time here only one cluster close to the centre of the modelling domain has reached the western outflow side with a central channel enlarged to the 20 cm size the other clusters have not reached the outflow boundary and their evolution is significantly slowed down because the inflow boundary condition effectively limits flow in the mature aquifer the pressure drop has fallen below the 10 cm threshold over the entire aquifer here a clear difference in evolution is observed when compared to already published aquifer scale evolution models e g bauer et al 2000 romanov et al 2002 romanov et al 2003 kaufmann et al 2010 the inflow boundary condition limits the amount of water available for dissolutional enlargement after breakthrough has occurred thus it more accurately describes a catchment control situation usually encountered in karst systems under natural boundary conditions this behaviour can also be seen in the two statistical quantities average hydraulic head and flow rate out of the model through the eastern boundary fig 10 in the first 1 000 years the average head black dashed line is around 9 m and fairly constant then starts to drop and after 2000 years reaches the base level value assigned as outflow boundary condition around the same time the flow rate out of the model domain black solid line increases by several orders of magnitude then starts to level off this increase in flow rate marks a transitional event in the evolution of the aquifer system similar to the breakthrough time defined for one dimensional fractures inspecting the pattern of the evolved clusters with its linear structures in the down gradient direction of the induced flow shows that there is not much coupling between different clusters in the direction perpendicular to flow the reason is the small standard deviation for the initial fracture width which provides enough competitive flow paths from west to east 3 2 strong exchange flow in the next model we increase the standard deviation for the initial fracture width to d μ 0 05 mm the resulting wider log normal distribution of initial fracture width is responsible for less direct flow paths resulting in a more sinusoidal evolution of referential flow paths this model which we term exchange flow highlights the effect of initial geometry variations on the preferential flow pattern this can be seen in fig 6 after 3400 years of evolution time as before several clusters of enlarged fractures started evolving from the western inflow boundary towards the eastern outflow boundary however the preferential pathways are more sinusoidal now with a significant flow component perpendicular to the main west east flow direction the reason for this more complicated flow pattern is the wider distribution of initial fracture widths there are simply less direct pathways from the start on the wider distribution of initial fracture width enhances the exchange flow component significantly now the aquifer experiences more competing flow paths at this stage three clusters are still developing at a similar pace with the central cluster having already a slight advantage still fracture enlargement is driven in the main direction of flow from left to right 5800 years into the evolution the aquifer is close to breakthrough the central cluster has significantly outpaced the other two clusters in evolution attracting most of the flow the two other clusters almost stop developing after 10 000 years of evolution time the preferential pathway has reached the outflow boundary the hydraulic pressure has dropped by an order of magnitude and the preferential path has grown to the 20 cm size and beyond under constant head conditions a flow path of this size would experience turbulent flow which is considered in our numerical model however the inflow boundary condition used limits the amount of available water and thus reduces the pressure gradient thus from this time on development of secondary permeability is strongly reduced it becomes clear that the fixed inflow boundary condition when compared to a fixed head boundary condition controls the evolution after breakthrough as a karst aquifer driven with inflow condition is more realistic with its catchment controlled recharge this setup should be preferred when discussing a karst aquifer beyond its first breakthrough event the statistical parameter average head and flow rate leaving the model domain fig 10 solid and dashed blue lines show a similar evolution as in the reference case just accelerated by about 500 years 3 3 limited karstification we continue looking into the effect of rock lithology if instead of a pure limestone we consider a rock composed on thin layers of soluble limestone interbedded with thicker layers of insoluble marls the dissolution of the limestone fractures is limited by the thickness of the limestone beds we term this case limited karstification e g romanov et al 2010 and in the example restrict the limestone beds to a maximum thickness of d max 1 cm again we use the initial fracture distribution of the exchange flow example three snapshots in time for this scenario are shown in fig 7 after 3400 years of evolution the secondary permeability of the aquifer has evolved in the same way as the exchange flow model which is clear as both share the same setup and not very many of the fractures have yet reached the limitation threshold of 1 cm width the exchange flow in the model again controls the creation of several competing flow paths about 6500 years into the evolution three competing clusters have evolved as in the exchange flow case this time however the three clusters develop more uniformly as the limiting growth causes more fractures to be enlarged once a fracture has reached its maximum width the aggressive solution simply starts enlarging neighbouring fractures thus close to breakthrough the evolution of secondary permeability is more uniform than in the exchangeflow example but still the central cluster has obtained an advantage the difference caused by the limited karstification setup becomes more evident after 10 000 years of evolution the central cluster has reached the outflow boundary on the right side and the other two prominent pathways have established a connection to the winning central cluster they merge around 130 m into the aquifer with it in general more of the side passages for flow abandoned in the exchange flow setup remain active as they all compete for flow because of the growth threshold the secondary permeability is thus much more widely distributed and reveals a more homogeneous picture of fractures enlarged to similar sizes the statistical parameter average head and flow rate leaving the model domain fig 10 dashed and solid red lines show a similar evolution as in the exchange case for times before the re organisation of flow which is clear in view of the similar parameter setup after a preferential flow path has evolved however the restricted growth of fractures limits outflow to a fixed value 3 4 mixing corrosion next we investigate the influence of a variation in chemistry on the preferential flow pattern evolving we use the initial fracture distribution of the exchange flow example but we saturate the incoming water with respect to calcite c in c eq however we assign a carbon dioxide pressure of 50 000 ppm to the top 50 m of inflow along the western boundary but only 400 ppm to the bottom 50 m with this choice we argue to mimic inflow from two independent catchments a northern catchment with soil cover enhancing the co2 level and a southern catchment collecting water from bare rock thus the co2 pressure remains at atmospheric levels in fig 8 three snapshots in time are again shown for this model setup after 3 700 years of evolution a cluster of enlarged fractures develops along the central part of the model domain no fracture enlargement occurs in the other parts of the aquifer the reason is the saturated solution entering the aquifer along the western side inhibiting the evolution of secondary permeability here however in the narrow region where both saturated solutions mix the non linear dependence of the calcium equilibrium concentration on carbon dioxide pressure termed mixing corrosion in the literature e g bögli 1971 bögli 1978 results in aggressive solution able to dissolve the soluble rock we stress that the change in chemistry of the inflowing solution inhibits the positive feedback between flow and dissolution in large parts of the aquifer only the narrow zone where water from the two catchments mix is actively developing thus exchange flow outside of the mixing zone is inhibited resulting in a completely different evolution after 8700 years the cluster of enlarged fractures has almost reached the right side of the model the aquifer is close to the breakthrough condition still within the mixing zone several enlarged clusters compete for flow here substantial exchange flow between the enlarged fractures is driving the competition the contoured head distribution close to breakthrough reveals that along the inflow side flow is driven towards the enlarged cluster in the central part focussing water into the mixing zone along the tip of the enlarged cluster however flow is diverging out of the mixing zone keeping competition open for three sets of clusters which try to reach the right hand side first after 10 000 years of evolution a preferential flow path has evolved along the mixing zone which reaches 20 cm fracture width and beyond note that the incoming saturated solution which inhibits dissolution except where the waters mix keeps the hydraulic pressure higher along the northern and southern portions of the western side throughout the entire evolution time in the case of the mixing model the statistical parameter average head fig 10 dashed pink line indicates a later re organisation of flow after around 4000 years the flow rate leaving the model domain solid pink line however reflects the higher hydraulic heads along the northern and southern parts of the inflow boundary which reflect the inhibited dissolution due to the saturated solution entering the aquifer here the higher heads elevate the flow rates in the entire aquifer 3 5 sink recharge in the last setup we explore the role of the hydraulic boundary conditions by restricting inflow to two small areas located around the north western and south western corners here 50 000 m3 a are entering the subsurface at each corner as the initial fracture distribution is taken from the exchange flow example exchange flow will be comparable to the other scenarios in fig 9 again three snapshots in time are shown after 3800 years of evolution two clusters of enlarged fractures started growing from each sink area the general growth direction of the preferential flow clusters is directed towards the base level in the east thus along the main hydraulic gradient the irregular distribution of initial fracture widths perturbs this pattern it is also responsible for the faster growth of the southern cluster as here initially larger fractures provide an easier percolation path when compared to the northern cluster however a second growth mode can also be observed as both clusters of preferential flow also act as local base levels through there enhanced permeability side passages in the direction perpendicular of the large scale west east hydraulic gradient start evolving trying to reach the cluster on the opposite side 7800 years into the evolution the southern cluster is close to breakthrough while the northern cluster lags behind with its evolution several branches have started to growth in this northern cluster one in the general flow directions towards the base level in the east the others trying to connect to the southern cluster the flow directions can directly be derived from the bended head contour flow from the tips of the northern cluster is directed both in north south and west east direction for the last snapshot we have chosen a longer evolution time of 15 000 years this snapshot enables us to show the re orientation of the northern cluster after the breakthrough of the southern cluster the northern cluster with its slightly disadvantageous flow path connects to the established flow path of the southern cluster because flow resistance along this flow path is smallest thus the preferential pathways originally developing independently towards the base level along the eastern side merge later on and continue as a single drainage path due to the heterogeneities in the model setup inflow and initial fracture distribution the smaller total inflow resulting from the sink input scenario results in an average head much lower than in the previous cases fig 10 dashed green line but the temporal evolution though occurring later at around 9000 years is similar flow out of the model domain solid green line again depicts the transition from initial to more mature permeability evolution 4 conclusions we have used the socks3d large scale karst aquifer model to discuss the development and evolution of secondary permeability in a karst aquifer our aim has been to emphasize on the one hand the role of exchange flow in aquifer scale evolution models and on the other hand discussing other structural chemical or hydraulic parameters such as fracture distribution rock lithology chemistry and hydrology controlling the evolution all models clearly reveal the importance of exchange flow which reduces breakthrough time by an order of magnitude when related to models not considering exchange flow however the pattern of the evolving secondary permeability is mainly controlled by the structural chemical and hydraulic parameters i the initial fracture distribution controls the tortuosity of the preferential pathways with a wider initial distribution enhancing exchange flow and creating more sinusoidal flow paths these findings confirm earlier investigations based on fixed head boundary conditions by kaufmann et al 2010 ii if the soluble rock is more impure e g limestone is only present as thin layers between insoluble layers the secondary permeability develops more uniform exchange flow becomes even more important in agreement with previous results from romanov et al 2010 based on fixed head boundary conditions iii for inflowing solutions being saturated with respect to calcite but having different carbon dioxide concentration mixing corrosion becomes decisive with a distinct pattern of secondary permeability evolving similar to published results e g romanov et al 2003 obtained for fixed head boundary conditions iv finally changing inflow from regional contributions to localised sink input will confine the evolution of secondary permeability to pathways from sinks to base level thus resulting in systems which appear more branchwork controlled using the socks3d large scale karst aquifer model described above we have been able to demonstrate that the main critical point of the one dimensional paradigm e g szymczak and ladd 2011 namely that the basic elements of our large aquifer scale models develop way too slow is not justified allowing exchange along the length of the fracture we reach several targets 1 obtain evolution times comparable with the breakthrough times reported when the conduits are represented as 2d 3d rough structures 2 represent the fractures embedded into a complex system porous media preferential pathways bedding planes which is closer to reality in comparison with the fractures which cannot exchange solution along their lengths used by the small fracture scale approach 3 because our modelling approach requires much less resources we are able to model the karstification of large karst aquifers this will be very difficult even nowadays if every basic element of the model has to be represented by 2d 3d elements so which approach is better this depends on the target of the study if the target is the evolution of a real large scale karst aquifer then in our opinion it is better to use large aquifer scale model on the other hand if the focus of the study is a detailed pictures of the evolution of a single fracture then the small fracture scale model is probably better suited finally we have shortly described two modelling approaches each with its strengths and weaknesses the small fracture scale model represents the fractures in an aquifer by isolated 2d 3d conduits while the large aquifer scale model uses 1d conduits but allows them to exchange solution along the fracture network as they are not isolated both approaches obtain comparable evolution times for karst systems which approach is preferred however depends on the target of the study declaration of interests none declared acknowledgements we thank corrado corradini as responsible editor and two anonymous referees for their thorough reviews which helped to significantly improve the manuscript gk acknowledges funding from the dfg under research grant ka1723 6 2 figures were prepared using gmt software wessel and smith 1998 
6607,a flood hazard is one of the most common and destructive natural disasters flood risk reduction with non engineering measures has become the primary goal for flood management this paper proposes an approach to improve the flood control operation for cascade reservoirs by minimizing flood control risk a framework of reservoir flood control operation coupled with risk assessment rfcora and the corresponding rfcora model are proposed to reduce risk the model contains three sub modules a real time reservoir flood control operation simulation module is developed in which a flood discharge control chart is used to determine the flood magnitude and flood release is obtained by operation rules entropy weighted fuzzy comprehensive evaluation method is applied to assess the risk level in the flood risk assessment module finally the flood release is updated according to the developed outflow adjustment optimization module aimed at minimizing flood control risk by combing future inflow information in addition another model without outflow adjustment optimization is set to be a comparative experiment the water system of the upper yellow river is selected as a case study to verify the model the results show that the framework and rfcora model developed in this paper can decrease the time duration in the highest risk level without increasing the maximum water level and maximum outflow of reservoirs the approach proposed in this paper based on flood control operation and flood risk assessment can be extended to flood mitigation in other water systems in similar situations keywords real time reservoir flood control operation flood risk assessment fuzzy comprehensive evaluation cascade reservoirs yellow river 1 introduction flooding is probably the most devastating widespread and frequent natural disaster facing human societies teng et al 2017 in the past several decades nearly one third of all natural disasters in the world were floods recent research has shown that the intensity frequency and severity of floods can increase due to global climate change apurv et al 2015 arnell and gosling 2016 alfieri et al 2017 dams and reservoirs play a vital role in water flow regulation and flood peak reduction which is considered a major engineering measure for flood control with the improvement of hydrological observation and management non engineering measures especially reservoir operation plays an important role in flood management ahmad and simonovic 2000 chang et al 2014a chang et al 2014b jenkins et al 2017 reservoir flood control operation rfco is a complex multi objective decision making problem the key issues are how to balance the conflict between the safety of the reservoir itself and the downstream and how to balance the water resources utilization benefits and flood control furthermore the objectives vary constantly with the flood control situation thereby increasing the difficulty of decision making scientists have been striving to identify good methods to solve these problems current studies on rfco can be roughly classified into optimization model and simulation model the former especially the multi objective optimization model can provide optimal solutions based on the given flood process in these models the highest water level and maximum release are often taken into account to ensure the safety of the upstream and downstream luo et al 2015 qi et al 2017 while the final water level and power generation are regarded as objectives for water resources utilization liu et al 2017 qin et al 2009 however the flood process is unknown in real time reservoir flood control operation rrfco in addition an oversimplified optimization model may lead to unreasonable solutions due to the solving method limitation for a large scale flood control system with multiple reservoirs and multiple tasks therefore the managers prefer to choose a rules based simulation model to determine water release according to real time flood information and updated forecast information specifically several researchers developed a multi phase rrfco model considering the differences in decision mechanisms and targets between each flood phase i e before flood before peak flow and after peak flow hsu et al 2015 chou and wu 2015 another common approach for rrfco is multi hierarchical operation model this approach means that the flood control rules are decomposed into several hierarchies according to the flood magnitude which presents different operation modes and different objectives moreover it is consistent with the actual decision making process and is easily implemented for managers hu et al 2015 described hierarchical rules of the three gorges reservoir based on the inflow and water level of the reservoir which can significantly improve the regulation in flood season and the comprehensive utilization benefits sun et al 2005 set up a flood forecasting and dispatching model system according to the flood peak and volume which has already been successfully used in the reservoir flood control decision support system however there exist some problems when using the simulation models for instance the rules based simulation model is strongly dependent on the operation rules which are often predefined at the planning stage of the reservoir construction through simulation techniques zhou et al 2015 in other words the rules were made based on the designed floods and did not consider the future inflow which may not suitable for all floods especially in the changing environment derived from climate change and human activities therefore it is necessary to improve the reservoir water release for real time floods by combining future inflow further the inflow or water level or both of them is often used to determine the flood magnitude and water release lei et al 2018 in fact there are large uncertainties in this process that can introduce risks therefore another significant issue for managers is how to assess the flood risk and decrease it the research focus of flood risk assessment fra is on the probability of unexpected events and the magnitude of negative consequences kellens et al 2013 for the former flood risk probability or rate is usually adopted to assess the generalized risk fan et al 2017 zhou et al 2018 and the vulnerability and resilience are also considered to formulate risk joyce et al 2018 for the latter the flood risk is often divided into several levels albano et al 2017 xiao et al 2017 chen et al 2015 specifically in rrfco the prediction error is one of the main sources of risk a lot of studies have explored the flood risk derived from prediction error and its influence on flood limited water level huang et al 2018 ding et al 2015 moreover the dividing standard of flood magnitude and flood damage is characteristic of fuzziness it is not objective to determine the flood magnitude or flood damage by judging whether the inflow or water level exceeds a fixed value or not this fuzziness is related to the preference of decision maker and causes risk in flood control operation therefore it is worth assessing the flood risk degree according to the real time flood conditions and impacts further flood defense or flood control is gradually turning into flood risk management or risk reduction in recent years according to the idea of risk management norén et al 2016 for most water systems with multiple reservoirs how to reduce the flood risk through non engineering measures is an important issue hence calculating the systemic risk level and advancing appropriate measures for risk reduction according to the reservoir flood control operation mode are of great significance for flood management huang and hsieh 2010 developed an early warning model for real time reservoir flood operation and introduced responses that increase water release as a result of a specific alert signal this study has offered a good example of real time flood operation for one reservoir however this problem becomes more complex for water systems with multiple reservoirs due to the multi dimensional rfco multi factorial fra and the difficulty of response measures determination therefore we intend to extend this early warning system for real time flood operation from one reservoir to cascade reservoirs and improve the determining manners for response measures this study aims to improve the flood control operation for cascade reservoirs by minimizing flood risk for this purpose a framework of reservoir flood control operation for cascade reservoirs coupled with risk assessment rfcora and the corresponding rfcora model are proposed specifically the model contains three sub modules real time reservoir flood control operation simulation module for conventional flood water release flood risk assessment module for risk level and outflow adjustment optimization module for updated flood release next the model and methodology are performed in the upstream of the yellow river with multiple reservoirs and protection objects to demonstrate its effectiveness on risk mitigation compared to a conventional model without outflow adjustment optimization the major contributions are as follows 1 a rfcora model for cascade reservoirs is developed by coupling real time reservoir flood control operation and flood risk management 2 an outflow adjustment optimization method is proposed to obtain updated water release for risk reduction by combing future inflow 2 methodology in this research the rfcora model contains three modules namely a real time reservoir flood control operation simulation module a flood risk assessment module and an outflow adjustment optimization module it can be divided into three steps shown in fig 1 step 1 develop a real time reservoir flood control operation simulation module module 1 to obtain the conventional reservoir water release in this module we need to estimate the flood magnitude first next the outflow at every period can be determined based on the given operation rules step 2 construct a multi factorial flood risk assessment module module 2 to obtain the risk level according to the results obtained by sub module 1 in this module the entropy weighted fuzzy comprehensive evaluation method is applied to calculate the risk level in addition the influence factors and evaluation levels must be determined in advance step 3 establish an outflow adjustment optimization module module 3 and get the applicable outflow increment of each risk level this step contains four detailed procedures 1 determine the response measures and their implementing mode with future inflow to address the different risk levels 2 obtain the updated reservoir release according to the original results obtained by module 1 and the outflow increment decision variables generated by cuckoo search cs randomly note that the updated reservoir outflow is subject to the future maximum allowable outflow that is determined by the future flood magnitude 3 calculate the updated flood risk level according to the updated reservoir release with the flood risk assessment module module 2 in step 2 4 calculate the value of objective function fitness and determine whether the algorithm meets the termination condition maximum number of iterations if the algorithm meets the termination condition output the optimal results otherwise return to procedure 2 2 1 real time reservoir flood control operation module a multi hierarchical simulation model is usually applied to real time reservoir flood control operation due to its clear operation rules and good feasibility of the implementation plan note that there are two major issues in the model for one reservoir first flood magnitude judgment is a crucial procedure for flood control operation in general flood control operation is typical complex decision making regarding problems with multiple objectives multiple constraints and multiple stages this operation is often considered in multi dimensional tradeoffs between not only the upstream and downstream but also the flood control and benefit promotion in actual operation the flood control operation objective and adaptive mode are often determined according to the flood magnitude specifically for small and medium floods the decision makers focus on the comprehensive utilization benefits of the reservoir while the safety of the dam and protected objects in the downstream is the primary task for large floods moreover making flood control operation rules is another key factor for flood management because these rules determine the flood water release process of reservoirs further the operation objectives of the water system are tightly related to deriving operation rules for flood control in the process of rrfco we need judge the flood magnitude first then determine the flood water release according to the operation rules that can be in the form of scheduling functions the flood control scheduling function of one reservoir is generally defined as follows 1 q out f q in z q out 1 q in q 1 min q 1 max z z 1 min z 1 max q out 2 q in q 2 min q 2 max z z 2 min z 2 max q out k q in q k min q k max z z k min z k max where q out q in and z are the outflow inflow and water level of reservoir respectively q o u t k is the maximum allowable outflow for hierarchy k k 1 2 k q k m i n and q k m a x represent the boundaries of reservoir inflow for hierarchy k z k m i n and z k m a x are the boundaries of water level for hierarchy k one or both of the two indexes is used to determine the flood magnitude and water release for different reservoirs sometimes the water level can be replaced with water storage note that the flood control scheduling function works in the rising limb of a flood in the falling limb the reservoir releases flood water as soon as possible in the main flood season or stores some flood water at the end of flood season in particular for the cascade reservoirs that have strong hydraulic connections and share the flood control tasks of a water system the joint operation rules of cascade reservoirs are necessary the difference is that the joint operation rules are relatively complex because they must consider the regulating capacity of each reservoir and the region floods combination therefore for different water systems the joint operation rules are various and difficult to be expressed as a unified flood control scheduling function in general if one reservoir undertakes the flood control task the flood control operation rules have been made in the planning and design stage in actual operation the designed rules may be used or modified as actual operation rules hence we can use the actual operation rules to set up the real time reservoir flood control operation model for cascade reservoirs we can build the joint operation model according to the flood control task and the flood water allocation rules between different reservoirs that have been predefined in the planning and design stage 2 2 flood risk assessment module at present there are various alternative methods for flood risk assessment including fuzzy comprehensive evaluation projection pursuit evaluation and artificial neural network given that the risk concept itself is vague fuzzy mathematics is usually used to assess flood risk chen et al 2015 albano et al 2017 further it is identified as more suitable compared to other traditional evaluation methods jiang et al 2009 it is noted that the determination of weights is an indispensable part of these methods however subjective method is usually applied to weights determination which is closely related to human influence and subjective preference thus the evaluation results are easy to deviate from the objective situation it is important to seek simple and practical evaluation methods for flood risk that simultaneously consider subjective and objective weights since the entropy weighted fuzzy comprehensive evaluation method combines both weights of various factors it was applied to the risk assessments of water shortage flood hazard and other fields luo et al 2008 wang et al 2012 mei et al 2016 there are two main steps for this method first the fuzzy comprehensive evaluation method was used to build a flood risk evaluation model next information entropy was adopted to calculate the comprehensive weights combined with the subjective weights 2 2 1 fuzzy comprehensive evaluation method the fuzzy comprehensive evaluation method was first proposed by wang 1980 to resolve complex decision making problems with multiple factors and levels based on fuzzy transformation principle which can reflect the vague feature of the evaluation object due to the simplicity and validity of the method it has been broadly applied in many fields to systematically address this method the steps are shown below step 1 determine the influence factors and evaluation levels in this paper the risk comes from the fuzziness of flood magnitude judgment and the flood damage degree classification therefore the parameters related to flood magnitude judgment and the flood control standard of downstream projects can be considered as influence factors including rainfall inflow outflow water storage and water level in particular for cascade reservoirs that have strong hydraulic connections and share the for flood control tasks we need select the influence factors that are related to the joint operation rules that are the basis of real time reservoir flood control operation further the evaluation levels can be divided according to the value of influence factors and management requirement for example if there are five stages for the reservoir floods the evaluation level of outflow can be divided into five levels or more step 2 establish the fuzzy evaluation matrix 2 u u 1 1 u 1 2 u 1 n u 2 1 u 2 2 u 2 n u m 1 u m 2 u m n where m 1 2 m n 1 2 n m and n are the number of influence factors and evaluation levels respectively 0 u m n 1 and u m n denotes the membership degree of factor m to level n which is generally determined with membership functions such as triangular parabolic and trapezoidal distribution step 3 calculate the weight set 3 w w 1 w 2 w m where w m is the weight coefficient and 0 w m 1 m 1 m w m 1 which reflects the importance of each factor in this paper the weight of each factor is the comprehensive weight that contains objective and subjective weight the objective weight is calculated by the following entropy weight method in chapter 2 2 2 while the subjective weight is determined from the decision maker step 4 determine the evaluation result 4 r w u r 1 r 2 r n where r n is the integrated membership degree is the fuzzy operator and is written as m in this paper in general the maximum acts as the final evaluation result however this approach may not be suitable in certain cases for instance if the maximum is less than 0 5 the integrated risk level can be obtained by cumulative membership degree the cumulative membership degree should satisfy the following formula huang and hsieh 2010 5 n 1 l r n 0 5 n 1 l 1 r n where n 1 l r n is the cumulative membership degree of r n n 1 2 l the integrated risk level l is obtained when the cumulative membership degree begins to exceed 0 5 2 2 2 entropy weight method information entropy can reflect the degree of disorder of information and be used to measure the validity of information in other words if the entropy value is small the information is useful and the corresponding evaluation object is important indicating that it should obtain a high weight otherwise the evaluation object gains a small weight therefore the entropy weight method is an objective approach for weight determination it was often applied to the comprehensive evaluation combining the fuzzy comprehensive evaluation model in many fields luo et al 2008 wang et al 2012 mei et al 2016 according to the fuzzy evaluation matrix the entropy of factor i is expressed as follows 6 h m 1 ln m n 1 n φ m n ln φ m n where φ m n denotes the frequency of factor m and φ m n u m n n 1 n u m n however when φ m n 0 ln φ m n is not allowed mathematically therefore we suppose φ m n ln φ m n 0 when φ m n 0 thus the objective weight of factor i is calculated as follows 7 w om 1 h m m m 1 m h m next combining the subjective weight the comprehensive weight is shown below 8 w m w om w sm m 1 m w om w sm where w om and w sm are the objective and subjective weight respectively and w m is the comprehensive weight coefficient thus the method combines the expert opinions and objective data attributes together which is considered more scientific and credible to some extent 2 3 outflow adjustment optimization module 2 3 1 problem formulation for flood management besides issuing warnings it is more significant for administrators to take measures to manage and mitigate the flood impacts specifically adjusting the water release process is one manner of risk treatment that can be implemented for reservoirs further this risk treatment means selections among various options how to choose the best option is another crucial problem of this module therefore we select an optimization method to solve the problem which can obtain the ideal scheme with the lowest risk rapidly in the optimization module the outflow adjustment corresponding to risk level is regarded as the decision variables and obtained by the optimized algorithm i e cs the details are shown below to reduce the risk the expected scheduling results should achieve two objectives one is the minimization of the highest risk level and the other is the minimization of time duration in the highest risk level with the weighted method the two objectives is transformed into single objective which is defined as 9 f min α l max t max where l max is the highest risk level t max is the number of period in the highest risk level α is a coefficient and is 100 in this paper because the highest risk level has a priority compared with the number of period in the highest risk level given the number of computing periods 45 in this paper we set the value of the coefficient as 100 which is larger than the number of computing periods the main constraint conditions are shown below in addition except the decision variables constraint the others are satisfied in the joint reservoir operation model which can alleviate the burden of optimization 1 decision variables constraint q d 2 q d 3 q d 4 q d 5 10 2 water balance constraint v i t 1 v i t q in i t q out i t δ t 11 3 reservoir water level constraint z min i t z i t z max i t 12 4 outflow constraint q out min i t q out i t q out max i t 13 where q d 2 q d 3 q d 4 and q d 5 represent the outflow increments corresponding to the risk levels of 2 3 4 and 5 respectively v i t and v i t 1 are the storage of reservoir i at period t and period t 1 respectively q in i t and q out i t means the inflow and outflow of reservoir i at period t respectively z i t z min i t and z max i t are the water level the minimum and maximum water level of reservoir i at period t respectively q out min i t and q out max i t represent the minimum and maximum outflow of reservoir i at period t respectively note that this module can be applied to water system with one reservoir or cascade reservoirs in particular if there are two cascade reservoirs that have strong hydraulic connections and share the flood control tasks selecting one reservoir to implement outflow adjustment optimization and change the outflow of the other reservoir according to the joint operation rules is more practical and reasonable than independent outflow optimization of the two reservoirs this is because the real time reservoir flood control operation and risk assessment are based on the joint operation rules 2 3 2 model solution cuckoo search cs is a heuristic optimization algorithm that was first proposed by yang and deb 2009 this method is based on the brood parasitism of cuckoos and lévy flight walton et al 2011 specifically cuckoos may lay their eggs in the nest of other host birds the host birds may find the eggs with a probability p a and these birds will either throw the eggs away or abandon the nest this phenomenon means the cuckoos have to find a new nest elsewhere in addition lévy flight is a random walk that performs the search pattern the detailed theory and idealized rules can be observed in the reference yang and deb 2013 this method just has one parameter i e the probability for an alien egg to be discovered besides the number of populations moreover this method is proved to be higher solution quality higher search efficiency and shorter computing time over other methods such as pso de and ga nguyen and vo 2015 therefore it has been used in many fields due to its advantages of fewer parameters and good global searching ability basu and chowdhury 2013 thang et al 2014 amed and salam 2014 in this paper it is applied to solve the optimization model for applicable new water release in the outflow increment optimization model the flow chart of this algorithm is shown in fig 2 3 case study 3 1 study area the yellow river yr possessing a length of 5464 km and a drainage area of 7 95 105 km2 is the second longest river in china the upstream portion of the yellow river uyr accounts for 51 3 of the total area of the yellow river basin and it yields 54 of the total runoff of the yr specifically the upper reach is rich in both water resources and hydropower resources therefore there are several reservoirs in this reach that shoulder the significant tasks of benefit promotion and damage reduction however as one of the five flood sources of the yr it often suffers from floods which may cause major disasters to the downstream with the comprehensive effect of climate change regional water transfer and sediment accumulation the channel flow capacity significantly reduces thereby even increasing the flood control pressure of this reach liu et al 2017 the flood water of the uyr is primarily from the upper reach to lanzhou due to the long duration and large area of precipitation in addition with the regulation and storage of vegetation and marshes the fluctuation of a flood is relatively gentle generally a flood in this area usually occurs in july or september and lasts approximately 40 days this flood water brings threats to the downstream especially the lanzhou city and ningxia inner mongolia reach of the yr or even flow into the middle and lower reaches of the yr which may lead to the coincidence of floods for instance in 1981 the flood peak flow was 5600 m3 s in lanzhou station with continuous rain for 35 days next it became 7000 m3 s in huayuankou station in the downstream after encountering the flood of the weihe river a tributary of the yr therefore it is of great significance to research flood management of this water system at present the longyangxia reservoir lyx and the liujiaxia reservoir ljx have been sharing the major flood control task of the complex system with multiple reservoirs since 1987 while the other reservoirs in the downstream are regarded as protection objects the distribution and flood control standard of the reservoirs in the uyr are shown in fig 3 and table 1 respectively even though lyx and ljx have impounded most of the flood water depending on joint flood control operation the system still lacks an effective flood risk management mechanism for flood mitigation the data employed in this paper is the design floods of different frequencies which is provided by the northwest survey and design institute of state power corporation of china now renamed the northwest engineering corporation limited of power construction corporation of china 3 2 real time reservoir flood control operation lyx and ljx have been sharing the major flood control task of the complex system with multiple reservoirs since 1987 thereby reducing the flood damage in the upstream of the yr according to the design objectives they need to not only ensure the safety of the dams and the protected objects in the downstream but also maximize the utilization of flood resources in this paper by considering the characteristics of flow compensation and flood volume compensation a flood discharge control chart shown in fig 4 is applied to the flood magnitude judgment for ljx which is a design result of flood control northwest investigation and design institute of state power corporation 2003 this chart means that both the flood peak flow and total flood storage in the corresponding period are greater than the corresponding design value of a particular frequency the flood of ljx is identified less than the frequency specifically if q in 2 t w that means the daily inflow of ljx m3 s and the total flood storage of lyx and ljx 108 m3 lays on area a the flood frequency is greater than 1 and the maximum allowable discharge is 4290 m3 s if q in 2 t w lays on area b the flood frequency is less than 1 and greater than 0 1 the maximum allowable discharge is 4510 m3 s similarly if q in 2 t w lays on area c the flood frequency is less than 0 1 and greater than 0 05 the maximum allowable discharge is 7260 m3 s if q in 2 t w lays on area d the flood frequency is less than 0 05 and ljx remains open the dotted line means that just one factor flood storage exceeds the designed value however the inflow does not reach to the designed value therefore the flood frequency is unchanged and the reservoir has no need to increase outflow in contrast for lyx the design flood peak flow is the only judgment index employed in other words if q in 1 t 4200 inflow of lyx m3 s the maximum allowable discharge is 2000 m3 s if 4200 q in 1 t 7040 the maximum allowable discharge is 4000 m3 s if q in 1 t 7040 the maximum allowable discharge is 6000 m3 s more importantly the flood control operation rules of the two reservoirs are also different specially ljx uses the single reservoir flood control rules as shown in formula 1 note that the water level is replaced with water storage and the water storage is the total flood storage of lyx and ljx in contrast lyx uses compensation scheduling rules by controlling the flood storage ratio of lyx and ljx note that its outflow also satisfies the maximum allowable discharge constraint this joint operation mode can well realize the flow compensation and water volume compensation especially the latter between the two reservoirs all the joint operation rules are summarized as follows 1 lyx and ljx should store the flood water according to the ratio of 4 0 4 5 to 1 0 2 the discharge flow of lyx and ljx must not be greater than the maximum permissible discharge of the corresponding frequency flood in all periods and must not be greater than the average daily inflow in rising limb 3 the water level of lyx and ljx must be below the corresponding design water level 4 the outflow varies within the range of 1000 m3 s furthermore a joint reservoir flood control operation simulation model was built based on the flood discharge control chart and operation rules the sketch is shown in fig 5 in practice the interval is one day and the travel time from lyx to ljx is approximately one day hence the total flood storage at period t is the sum of the flood storage of lyx at period t 1 and flood storage of ljx at period t in this model moreover the actual inflow of ljx is equal to the outflow of lyx plus the intervening area flow it is noted that the flood storage ratio of lyx to ljx is used to solve the regional flood composition problem for simplified calculation for the real time flood control of cascade reservoirs a simulation model with simulation rules can ensure the maneuverability of flood control schemes 3 3 flood risk assessment in this paper entropy weighted fuzzy comprehensive evaluation was applied to assess the flood operation risk first three applicable evaluation factors that are closely related to reservoir flood control were selected one is the natural inflow of ljx natural inflow of lyx plus the intervening area flow which reflects the flood magnitude of the region the second is the total flood storage of lyx and ljx which represents the utilization of flood control storage capacity of cascade reservoirs in addition the last is the outflow of ljx which signifies the security threat to the downstream thus the flood operation risk is identified as the comprehensive risk that involves the flood situation reservoir safety and protected object security next we use five levels 1 2 3 4 5 to evaluate the risk degree of each factor moreover the higher the level the greater the risk specifically for the first and last indicator the design flood peak flow and maximum allowable outflow of different frequencies are adopted to grade respectively in addition considering the large difference between 4510 m3 s and 7260 m3 s an outflow of 6000 m3 s is added in grading for the second factor based on the maximum flood storage of different frequency floods the total reservoir capacity for flood control of lyx and ljx is graded next we apply triangular and trapezoidal distributions to build membership functions of the three indicators the membership degree of each factor to the levels is determined by the membership functions the membership functions with the range of 0 1 established in this paper are shown in fig 6 in this way the fuzzy evaluation matrix is developed thus the comprehensive weights of these factors are calculated with the entropy weight method using formula 7 note that a given subjective weight set is needed to perform this task in this paper we presume that w s 1 the subjective weight of inflow is 0 3 for the subjective weight of flood storage we first calculate p the proportion of flood storage to total flood control capacity and then calculate the weight with w s 2 1 w s 1 p thus the subjective weight of outflow can be expressed with w s 3 1 w s 1 w s 2 in this way the subjective weight varies with time if the total flood storage is large its subjective weight is heavy while the subjective weight of outflow is small in other words the dam safety is a priority when suffering large flood after getting the weight set the flood operation risk can be calculated by formulas 4 and 5 3 4 outflow adjustment optimization given that the outflow of ljx is determined first in the flood control operation module next the outflow of lyx is calculated based the flood storage ratio of the two reservoirs shown in fig 5 therefore increasing the outflow of ljx and adjusting the flood storage of lyx based on risk level are regarded as easily implemented response strategies which can also be called feedback operation the specific procedures are as follows 1 pre estimate the future flood magnitude and the future maximum allowable discharge of ljx according to the future inflow for the next three days and the discharge control chart of ljx 2 determine the updated outflow of ljx at current period according to the original outflow of ljx obtained by sub module 1 and the value of outflow adjustment the decision variables of the optimization module note that the updated outflow of ljx is the sum of the original outflow of ljx and the value of outflow adjustment and the future maximum allowable discharge of ljx is the constraint condition of current updated outflow 3 calculate the updated outflow of lyx at current period according to the original outflow of lyx obtained by sub module 1 and the flood storage ratio of the two reservoirs in other words if the flood storage ratio is larger than 4 5 increase the outflow of lyx conversely if the flood storage ratio is small than 4 0 decrease the outflow of lyx in particular for ljx different warning signals represent different outflow increments except for level 1 the other four levels signify updated reservoir releases moreover the higher the level the greater the outflow increment for lyx its outflow changes with the flood storage based on the flood storage ratio it can be observed that the feedback operation is equal to pre discharge approach thereby decreasing the flood risk note that future inflow and scheduling results based on the joint reservoir operation model are needed in this process in this paper the future inflow is derived from the design floods rather than forecast model because this paper focuses on flood control operation 4 results and discussion based on this model the design floods were used as inputs to obtain flood control results next we selected the optimal solution to analyze the reasonability of the model scenario 1 in addition these data were also used to enable a two scenario analysis based only on the first and second modules without outflow adjustment optimization scenario 2 the comparison results are shown in table 2 and figs 7 9 it is seen from table 2 that for the flood with 0 1 frequency the days with the highest risk level in scenario 1 decrease by one day without increasing the maximum water level and maximum outflow of lyx and ljx compared with scenario 2 the maximum water level of lyx and ljx in scenario 1 are even lower than those in scenario 2 however the final water level of ljx in scenario 1 are even higher than that in scenario 2 from fig 7 it can be seen that the outflow of lyx in scenario 1 is larger than that in scenario 2 not exceeding the maximum outflow 4000 m3 s at period 17 and period 30 45 indicating that lyx pre releases flood water in rising limb and releases more flood water in falling limb in scenario 1 unlike lyx ljx pre releases some flood water only in rising limb in scenario 1 and the outflow stays at 4510 m3 s to the end due to the operation rules therefore the maximum water level and final water level of lyx in scenario 1 are lower compared with scenario 2 while the final water level of ljx in scenario 1 becomes higher namely ljx stores more flood water in falling limb compared with scenario 2 the primary reason for this phenomenon is the flood storage ratio of the two reservoirs in response measures lyx needs to adjust its outflow again based on the ratio in scenario 1 and the real ratio is too large from period 30 to 45 in scenario 2 therefore lyx discharges more water to increase the ratio at these times while ljx undertakes more flood storage risk to alleviate the lyx and downstream risks in falling limb in scenario 1 note that the maximum and final total flood storage volume of lyx and ljx in scenario 1 are smaller than those in scenario 2 this operation mode does not increase the maximum risk but keeps the total risk of the water system the lowest because risk does not go away the key of risk response is risk transfer and sharing the purpose of risk transfer is to reduce global risk through various measures which means minimize the flood losses with minimum cost in this flood the cost is extending the time of reservoir flood control operation it can be seen from table 2 and fig 8 that for the flood with 0 01 frequency the days with the highest risk level in scenario 1 decrease by three days without increasing the maximum water level of lyx the maximum outflow of lyx and ljx compared with scenario 2 the maximum outflow of ljx even decreases to 7260 m3 s in scenario 1 which is the maximum allowable discharge of flood with 0 05 frequency thereby lowering the risk of downstream however both the maximum water level and final water level of ljx increase slightly in scenario 1 in terms of flood regulating processes of reservoirs both lyx and ljx pre release some flood water in rising limb in scenario 1 note that the maximum and final total flood storage volume of lyx and ljx in scenario 1 are still smaller than those in scenario 2 in short the results show that the model proposed in scenario 1 can reduce the flood control operation risk compared with scenario 2 the table 2 and fig 9 show that unlike the previous two floods there is no change of the days with the highest risk level between the two scenarios but the flood release of lyx and ljx have varied similarly lyx and ljx pre release some flood water in rising limb in scenario 1 the maximum water level final water level and maximum outflow of lyx in scenario 1 do not exceed those in scenario 2 and are even less than them nevertheless all of the three statistical parameters mentioned above for ljx in scenario 1 are larger than those in scenario 2 note that the maximum and final total flood storage volume of lyx and ljx in scenario 1 are still smaller than those in scenario 2 moreover the real flood storage ratios of the two reservoirs in falling limbs in scenario 1 decrease compared with scenario 2 which is still larger than 4 5 in other words a part of risk shifts from lyx to ljx and downstream in scenario 1 thereby making the risk share more balanced compared with scenario 2 the change rules of the comprehensive risk level are shown in fig 10 this figure shows that the highest risk level varies from 3 to 5 with the decrease of the flood frequency indicating that the greater the flood is the higher the risk degree is furthermore the days with the highest risk level for the floods with frequency of 0 1 and 0 01 decrease by 1 and 3 days respectively this result shows that the model proposed in scenario 1 can reduce the flood risk compared with scenario 2 in addition the risk level changes from the fluctuation of the flood specifically for the flood with 0 1 frequency the risk level increases from 1 to 3 at first and later decreases to 2 likewise for the flood with 0 01 frequency it increases from 1 to 4 at first and ultimately decreases to 1 for the pmf it rises from 1 to 4 at first and falls to 2 and 3 at last in scenario 1 and scenario 2 respectively moreover even though the highest risk level and its duration do not change between the two scenarios the days with the second highest risk level decrease by 2 days in scenario 1 compared with scenario 2 in conclusion the results can verify the rationality and superiority of the model proposed in scenario 1 finally we select the second flood to analyze the risk level change of each factor shown in fig 11 and table 3 it should be noted that the inflow risks in scenario 1 and in scenario 2 are the same because the input is the design flood it can be seen from fig 11 and table 3 that the inflow risk level varies from 1 to 4 and drops to 1 at the end similarly the outflow risk level rises from 1 to 5 but eventually drops only to 4 in scenario 1 and in scenario 2 the reason is that the final water level of the reservoir still exceeds the flood limited water level indicating that the reservoir must release flood water with a large flow in addition the difference between the two scenarios is that the outflow risk level increases earlier in scenario 1 due to the flood pre discharge dispatching of the reservoir for the flood storage risk the highest risk level in scenario 1 is less than that in scenario 2 indicating that the maximum flood storage has decreased compared to scenario 2 we can find that the comprehensive risk level is only 1 in the last several periods even though the outflow risk is 4 since both the inflow and flood storage risks are small 5 conclusions given the limitations of multi hierarchical simulation model for real time flood control operation and the idea of flood risk management this paper is aiming to improve the flood control operation for cascade reservoirs by minimizing flood risk therefore a framework of reservoir flood control operation for cascade reservoirs coupled with risk assessment and the corresponding rfcora model that contains three sub modules are proposed further the methodology regarding the determination of the flood risk level and reservoir release to mitigate flood risk is presented the upper yellow river with multiple reservoirs and multiple protection objects was selected as a case study another model without outflow adjustment optimization is set to be a comparative experiment the results show that the framework and rfcora model developed in this paper can reduce the flood risk of a water system with cascade reservoirs the methodology can be adopted in the real time operation of a flood control system by integrating the flood forecast however further research is needed to improve the flood risk management of water systems as the influence factors play a highly important role in the risk estimation other factors associated with flood management can further enhance the comprehensiveness to assess the flood risk moreover because reliable flood forecasting information is needed as input adding a flood forecast sub module can make the model more complete in addition multiple floods through monte carlo simulation experiment can be used to make new flood control operation rules though certain restrictions exist in this study it provides an alternative way of flood risk reduction which is of significance for decision makers to improve the flood control operation by identifying the flood risk degree and implementing response strategies in the reservoir flood control operation acknowledgements this research was supported by the national key research and development program of china 2016yfc0400906 and the natural science foundation of china 91647112 51679187 and 51679189 the authors gratefully thank the northwest engineering corporation limited of power construction corporation of china for providing the data which can be freely accessed by contacting the first author by e mail mengxuejiao 163 com sincere gratitude is extended to the editor and the anonymous reviewers for their professional comments and corrections 
6607,a flood hazard is one of the most common and destructive natural disasters flood risk reduction with non engineering measures has become the primary goal for flood management this paper proposes an approach to improve the flood control operation for cascade reservoirs by minimizing flood control risk a framework of reservoir flood control operation coupled with risk assessment rfcora and the corresponding rfcora model are proposed to reduce risk the model contains three sub modules a real time reservoir flood control operation simulation module is developed in which a flood discharge control chart is used to determine the flood magnitude and flood release is obtained by operation rules entropy weighted fuzzy comprehensive evaluation method is applied to assess the risk level in the flood risk assessment module finally the flood release is updated according to the developed outflow adjustment optimization module aimed at minimizing flood control risk by combing future inflow information in addition another model without outflow adjustment optimization is set to be a comparative experiment the water system of the upper yellow river is selected as a case study to verify the model the results show that the framework and rfcora model developed in this paper can decrease the time duration in the highest risk level without increasing the maximum water level and maximum outflow of reservoirs the approach proposed in this paper based on flood control operation and flood risk assessment can be extended to flood mitigation in other water systems in similar situations keywords real time reservoir flood control operation flood risk assessment fuzzy comprehensive evaluation cascade reservoirs yellow river 1 introduction flooding is probably the most devastating widespread and frequent natural disaster facing human societies teng et al 2017 in the past several decades nearly one third of all natural disasters in the world were floods recent research has shown that the intensity frequency and severity of floods can increase due to global climate change apurv et al 2015 arnell and gosling 2016 alfieri et al 2017 dams and reservoirs play a vital role in water flow regulation and flood peak reduction which is considered a major engineering measure for flood control with the improvement of hydrological observation and management non engineering measures especially reservoir operation plays an important role in flood management ahmad and simonovic 2000 chang et al 2014a chang et al 2014b jenkins et al 2017 reservoir flood control operation rfco is a complex multi objective decision making problem the key issues are how to balance the conflict between the safety of the reservoir itself and the downstream and how to balance the water resources utilization benefits and flood control furthermore the objectives vary constantly with the flood control situation thereby increasing the difficulty of decision making scientists have been striving to identify good methods to solve these problems current studies on rfco can be roughly classified into optimization model and simulation model the former especially the multi objective optimization model can provide optimal solutions based on the given flood process in these models the highest water level and maximum release are often taken into account to ensure the safety of the upstream and downstream luo et al 2015 qi et al 2017 while the final water level and power generation are regarded as objectives for water resources utilization liu et al 2017 qin et al 2009 however the flood process is unknown in real time reservoir flood control operation rrfco in addition an oversimplified optimization model may lead to unreasonable solutions due to the solving method limitation for a large scale flood control system with multiple reservoirs and multiple tasks therefore the managers prefer to choose a rules based simulation model to determine water release according to real time flood information and updated forecast information specifically several researchers developed a multi phase rrfco model considering the differences in decision mechanisms and targets between each flood phase i e before flood before peak flow and after peak flow hsu et al 2015 chou and wu 2015 another common approach for rrfco is multi hierarchical operation model this approach means that the flood control rules are decomposed into several hierarchies according to the flood magnitude which presents different operation modes and different objectives moreover it is consistent with the actual decision making process and is easily implemented for managers hu et al 2015 described hierarchical rules of the three gorges reservoir based on the inflow and water level of the reservoir which can significantly improve the regulation in flood season and the comprehensive utilization benefits sun et al 2005 set up a flood forecasting and dispatching model system according to the flood peak and volume which has already been successfully used in the reservoir flood control decision support system however there exist some problems when using the simulation models for instance the rules based simulation model is strongly dependent on the operation rules which are often predefined at the planning stage of the reservoir construction through simulation techniques zhou et al 2015 in other words the rules were made based on the designed floods and did not consider the future inflow which may not suitable for all floods especially in the changing environment derived from climate change and human activities therefore it is necessary to improve the reservoir water release for real time floods by combining future inflow further the inflow or water level or both of them is often used to determine the flood magnitude and water release lei et al 2018 in fact there are large uncertainties in this process that can introduce risks therefore another significant issue for managers is how to assess the flood risk and decrease it the research focus of flood risk assessment fra is on the probability of unexpected events and the magnitude of negative consequences kellens et al 2013 for the former flood risk probability or rate is usually adopted to assess the generalized risk fan et al 2017 zhou et al 2018 and the vulnerability and resilience are also considered to formulate risk joyce et al 2018 for the latter the flood risk is often divided into several levels albano et al 2017 xiao et al 2017 chen et al 2015 specifically in rrfco the prediction error is one of the main sources of risk a lot of studies have explored the flood risk derived from prediction error and its influence on flood limited water level huang et al 2018 ding et al 2015 moreover the dividing standard of flood magnitude and flood damage is characteristic of fuzziness it is not objective to determine the flood magnitude or flood damage by judging whether the inflow or water level exceeds a fixed value or not this fuzziness is related to the preference of decision maker and causes risk in flood control operation therefore it is worth assessing the flood risk degree according to the real time flood conditions and impacts further flood defense or flood control is gradually turning into flood risk management or risk reduction in recent years according to the idea of risk management norén et al 2016 for most water systems with multiple reservoirs how to reduce the flood risk through non engineering measures is an important issue hence calculating the systemic risk level and advancing appropriate measures for risk reduction according to the reservoir flood control operation mode are of great significance for flood management huang and hsieh 2010 developed an early warning model for real time reservoir flood operation and introduced responses that increase water release as a result of a specific alert signal this study has offered a good example of real time flood operation for one reservoir however this problem becomes more complex for water systems with multiple reservoirs due to the multi dimensional rfco multi factorial fra and the difficulty of response measures determination therefore we intend to extend this early warning system for real time flood operation from one reservoir to cascade reservoirs and improve the determining manners for response measures this study aims to improve the flood control operation for cascade reservoirs by minimizing flood risk for this purpose a framework of reservoir flood control operation for cascade reservoirs coupled with risk assessment rfcora and the corresponding rfcora model are proposed specifically the model contains three sub modules real time reservoir flood control operation simulation module for conventional flood water release flood risk assessment module for risk level and outflow adjustment optimization module for updated flood release next the model and methodology are performed in the upstream of the yellow river with multiple reservoirs and protection objects to demonstrate its effectiveness on risk mitigation compared to a conventional model without outflow adjustment optimization the major contributions are as follows 1 a rfcora model for cascade reservoirs is developed by coupling real time reservoir flood control operation and flood risk management 2 an outflow adjustment optimization method is proposed to obtain updated water release for risk reduction by combing future inflow 2 methodology in this research the rfcora model contains three modules namely a real time reservoir flood control operation simulation module a flood risk assessment module and an outflow adjustment optimization module it can be divided into three steps shown in fig 1 step 1 develop a real time reservoir flood control operation simulation module module 1 to obtain the conventional reservoir water release in this module we need to estimate the flood magnitude first next the outflow at every period can be determined based on the given operation rules step 2 construct a multi factorial flood risk assessment module module 2 to obtain the risk level according to the results obtained by sub module 1 in this module the entropy weighted fuzzy comprehensive evaluation method is applied to calculate the risk level in addition the influence factors and evaluation levels must be determined in advance step 3 establish an outflow adjustment optimization module module 3 and get the applicable outflow increment of each risk level this step contains four detailed procedures 1 determine the response measures and their implementing mode with future inflow to address the different risk levels 2 obtain the updated reservoir release according to the original results obtained by module 1 and the outflow increment decision variables generated by cuckoo search cs randomly note that the updated reservoir outflow is subject to the future maximum allowable outflow that is determined by the future flood magnitude 3 calculate the updated flood risk level according to the updated reservoir release with the flood risk assessment module module 2 in step 2 4 calculate the value of objective function fitness and determine whether the algorithm meets the termination condition maximum number of iterations if the algorithm meets the termination condition output the optimal results otherwise return to procedure 2 2 1 real time reservoir flood control operation module a multi hierarchical simulation model is usually applied to real time reservoir flood control operation due to its clear operation rules and good feasibility of the implementation plan note that there are two major issues in the model for one reservoir first flood magnitude judgment is a crucial procedure for flood control operation in general flood control operation is typical complex decision making regarding problems with multiple objectives multiple constraints and multiple stages this operation is often considered in multi dimensional tradeoffs between not only the upstream and downstream but also the flood control and benefit promotion in actual operation the flood control operation objective and adaptive mode are often determined according to the flood magnitude specifically for small and medium floods the decision makers focus on the comprehensive utilization benefits of the reservoir while the safety of the dam and protected objects in the downstream is the primary task for large floods moreover making flood control operation rules is another key factor for flood management because these rules determine the flood water release process of reservoirs further the operation objectives of the water system are tightly related to deriving operation rules for flood control in the process of rrfco we need judge the flood magnitude first then determine the flood water release according to the operation rules that can be in the form of scheduling functions the flood control scheduling function of one reservoir is generally defined as follows 1 q out f q in z q out 1 q in q 1 min q 1 max z z 1 min z 1 max q out 2 q in q 2 min q 2 max z z 2 min z 2 max q out k q in q k min q k max z z k min z k max where q out q in and z are the outflow inflow and water level of reservoir respectively q o u t k is the maximum allowable outflow for hierarchy k k 1 2 k q k m i n and q k m a x represent the boundaries of reservoir inflow for hierarchy k z k m i n and z k m a x are the boundaries of water level for hierarchy k one or both of the two indexes is used to determine the flood magnitude and water release for different reservoirs sometimes the water level can be replaced with water storage note that the flood control scheduling function works in the rising limb of a flood in the falling limb the reservoir releases flood water as soon as possible in the main flood season or stores some flood water at the end of flood season in particular for the cascade reservoirs that have strong hydraulic connections and share the flood control tasks of a water system the joint operation rules of cascade reservoirs are necessary the difference is that the joint operation rules are relatively complex because they must consider the regulating capacity of each reservoir and the region floods combination therefore for different water systems the joint operation rules are various and difficult to be expressed as a unified flood control scheduling function in general if one reservoir undertakes the flood control task the flood control operation rules have been made in the planning and design stage in actual operation the designed rules may be used or modified as actual operation rules hence we can use the actual operation rules to set up the real time reservoir flood control operation model for cascade reservoirs we can build the joint operation model according to the flood control task and the flood water allocation rules between different reservoirs that have been predefined in the planning and design stage 2 2 flood risk assessment module at present there are various alternative methods for flood risk assessment including fuzzy comprehensive evaluation projection pursuit evaluation and artificial neural network given that the risk concept itself is vague fuzzy mathematics is usually used to assess flood risk chen et al 2015 albano et al 2017 further it is identified as more suitable compared to other traditional evaluation methods jiang et al 2009 it is noted that the determination of weights is an indispensable part of these methods however subjective method is usually applied to weights determination which is closely related to human influence and subjective preference thus the evaluation results are easy to deviate from the objective situation it is important to seek simple and practical evaluation methods for flood risk that simultaneously consider subjective and objective weights since the entropy weighted fuzzy comprehensive evaluation method combines both weights of various factors it was applied to the risk assessments of water shortage flood hazard and other fields luo et al 2008 wang et al 2012 mei et al 2016 there are two main steps for this method first the fuzzy comprehensive evaluation method was used to build a flood risk evaluation model next information entropy was adopted to calculate the comprehensive weights combined with the subjective weights 2 2 1 fuzzy comprehensive evaluation method the fuzzy comprehensive evaluation method was first proposed by wang 1980 to resolve complex decision making problems with multiple factors and levels based on fuzzy transformation principle which can reflect the vague feature of the evaluation object due to the simplicity and validity of the method it has been broadly applied in many fields to systematically address this method the steps are shown below step 1 determine the influence factors and evaluation levels in this paper the risk comes from the fuzziness of flood magnitude judgment and the flood damage degree classification therefore the parameters related to flood magnitude judgment and the flood control standard of downstream projects can be considered as influence factors including rainfall inflow outflow water storage and water level in particular for cascade reservoirs that have strong hydraulic connections and share the for flood control tasks we need select the influence factors that are related to the joint operation rules that are the basis of real time reservoir flood control operation further the evaluation levels can be divided according to the value of influence factors and management requirement for example if there are five stages for the reservoir floods the evaluation level of outflow can be divided into five levels or more step 2 establish the fuzzy evaluation matrix 2 u u 1 1 u 1 2 u 1 n u 2 1 u 2 2 u 2 n u m 1 u m 2 u m n where m 1 2 m n 1 2 n m and n are the number of influence factors and evaluation levels respectively 0 u m n 1 and u m n denotes the membership degree of factor m to level n which is generally determined with membership functions such as triangular parabolic and trapezoidal distribution step 3 calculate the weight set 3 w w 1 w 2 w m where w m is the weight coefficient and 0 w m 1 m 1 m w m 1 which reflects the importance of each factor in this paper the weight of each factor is the comprehensive weight that contains objective and subjective weight the objective weight is calculated by the following entropy weight method in chapter 2 2 2 while the subjective weight is determined from the decision maker step 4 determine the evaluation result 4 r w u r 1 r 2 r n where r n is the integrated membership degree is the fuzzy operator and is written as m in this paper in general the maximum acts as the final evaluation result however this approach may not be suitable in certain cases for instance if the maximum is less than 0 5 the integrated risk level can be obtained by cumulative membership degree the cumulative membership degree should satisfy the following formula huang and hsieh 2010 5 n 1 l r n 0 5 n 1 l 1 r n where n 1 l r n is the cumulative membership degree of r n n 1 2 l the integrated risk level l is obtained when the cumulative membership degree begins to exceed 0 5 2 2 2 entropy weight method information entropy can reflect the degree of disorder of information and be used to measure the validity of information in other words if the entropy value is small the information is useful and the corresponding evaluation object is important indicating that it should obtain a high weight otherwise the evaluation object gains a small weight therefore the entropy weight method is an objective approach for weight determination it was often applied to the comprehensive evaluation combining the fuzzy comprehensive evaluation model in many fields luo et al 2008 wang et al 2012 mei et al 2016 according to the fuzzy evaluation matrix the entropy of factor i is expressed as follows 6 h m 1 ln m n 1 n φ m n ln φ m n where φ m n denotes the frequency of factor m and φ m n u m n n 1 n u m n however when φ m n 0 ln φ m n is not allowed mathematically therefore we suppose φ m n ln φ m n 0 when φ m n 0 thus the objective weight of factor i is calculated as follows 7 w om 1 h m m m 1 m h m next combining the subjective weight the comprehensive weight is shown below 8 w m w om w sm m 1 m w om w sm where w om and w sm are the objective and subjective weight respectively and w m is the comprehensive weight coefficient thus the method combines the expert opinions and objective data attributes together which is considered more scientific and credible to some extent 2 3 outflow adjustment optimization module 2 3 1 problem formulation for flood management besides issuing warnings it is more significant for administrators to take measures to manage and mitigate the flood impacts specifically adjusting the water release process is one manner of risk treatment that can be implemented for reservoirs further this risk treatment means selections among various options how to choose the best option is another crucial problem of this module therefore we select an optimization method to solve the problem which can obtain the ideal scheme with the lowest risk rapidly in the optimization module the outflow adjustment corresponding to risk level is regarded as the decision variables and obtained by the optimized algorithm i e cs the details are shown below to reduce the risk the expected scheduling results should achieve two objectives one is the minimization of the highest risk level and the other is the minimization of time duration in the highest risk level with the weighted method the two objectives is transformed into single objective which is defined as 9 f min α l max t max where l max is the highest risk level t max is the number of period in the highest risk level α is a coefficient and is 100 in this paper because the highest risk level has a priority compared with the number of period in the highest risk level given the number of computing periods 45 in this paper we set the value of the coefficient as 100 which is larger than the number of computing periods the main constraint conditions are shown below in addition except the decision variables constraint the others are satisfied in the joint reservoir operation model which can alleviate the burden of optimization 1 decision variables constraint q d 2 q d 3 q d 4 q d 5 10 2 water balance constraint v i t 1 v i t q in i t q out i t δ t 11 3 reservoir water level constraint z min i t z i t z max i t 12 4 outflow constraint q out min i t q out i t q out max i t 13 where q d 2 q d 3 q d 4 and q d 5 represent the outflow increments corresponding to the risk levels of 2 3 4 and 5 respectively v i t and v i t 1 are the storage of reservoir i at period t and period t 1 respectively q in i t and q out i t means the inflow and outflow of reservoir i at period t respectively z i t z min i t and z max i t are the water level the minimum and maximum water level of reservoir i at period t respectively q out min i t and q out max i t represent the minimum and maximum outflow of reservoir i at period t respectively note that this module can be applied to water system with one reservoir or cascade reservoirs in particular if there are two cascade reservoirs that have strong hydraulic connections and share the flood control tasks selecting one reservoir to implement outflow adjustment optimization and change the outflow of the other reservoir according to the joint operation rules is more practical and reasonable than independent outflow optimization of the two reservoirs this is because the real time reservoir flood control operation and risk assessment are based on the joint operation rules 2 3 2 model solution cuckoo search cs is a heuristic optimization algorithm that was first proposed by yang and deb 2009 this method is based on the brood parasitism of cuckoos and lévy flight walton et al 2011 specifically cuckoos may lay their eggs in the nest of other host birds the host birds may find the eggs with a probability p a and these birds will either throw the eggs away or abandon the nest this phenomenon means the cuckoos have to find a new nest elsewhere in addition lévy flight is a random walk that performs the search pattern the detailed theory and idealized rules can be observed in the reference yang and deb 2013 this method just has one parameter i e the probability for an alien egg to be discovered besides the number of populations moreover this method is proved to be higher solution quality higher search efficiency and shorter computing time over other methods such as pso de and ga nguyen and vo 2015 therefore it has been used in many fields due to its advantages of fewer parameters and good global searching ability basu and chowdhury 2013 thang et al 2014 amed and salam 2014 in this paper it is applied to solve the optimization model for applicable new water release in the outflow increment optimization model the flow chart of this algorithm is shown in fig 2 3 case study 3 1 study area the yellow river yr possessing a length of 5464 km and a drainage area of 7 95 105 km2 is the second longest river in china the upstream portion of the yellow river uyr accounts for 51 3 of the total area of the yellow river basin and it yields 54 of the total runoff of the yr specifically the upper reach is rich in both water resources and hydropower resources therefore there are several reservoirs in this reach that shoulder the significant tasks of benefit promotion and damage reduction however as one of the five flood sources of the yr it often suffers from floods which may cause major disasters to the downstream with the comprehensive effect of climate change regional water transfer and sediment accumulation the channel flow capacity significantly reduces thereby even increasing the flood control pressure of this reach liu et al 2017 the flood water of the uyr is primarily from the upper reach to lanzhou due to the long duration and large area of precipitation in addition with the regulation and storage of vegetation and marshes the fluctuation of a flood is relatively gentle generally a flood in this area usually occurs in july or september and lasts approximately 40 days this flood water brings threats to the downstream especially the lanzhou city and ningxia inner mongolia reach of the yr or even flow into the middle and lower reaches of the yr which may lead to the coincidence of floods for instance in 1981 the flood peak flow was 5600 m3 s in lanzhou station with continuous rain for 35 days next it became 7000 m3 s in huayuankou station in the downstream after encountering the flood of the weihe river a tributary of the yr therefore it is of great significance to research flood management of this water system at present the longyangxia reservoir lyx and the liujiaxia reservoir ljx have been sharing the major flood control task of the complex system with multiple reservoirs since 1987 while the other reservoirs in the downstream are regarded as protection objects the distribution and flood control standard of the reservoirs in the uyr are shown in fig 3 and table 1 respectively even though lyx and ljx have impounded most of the flood water depending on joint flood control operation the system still lacks an effective flood risk management mechanism for flood mitigation the data employed in this paper is the design floods of different frequencies which is provided by the northwest survey and design institute of state power corporation of china now renamed the northwest engineering corporation limited of power construction corporation of china 3 2 real time reservoir flood control operation lyx and ljx have been sharing the major flood control task of the complex system with multiple reservoirs since 1987 thereby reducing the flood damage in the upstream of the yr according to the design objectives they need to not only ensure the safety of the dams and the protected objects in the downstream but also maximize the utilization of flood resources in this paper by considering the characteristics of flow compensation and flood volume compensation a flood discharge control chart shown in fig 4 is applied to the flood magnitude judgment for ljx which is a design result of flood control northwest investigation and design institute of state power corporation 2003 this chart means that both the flood peak flow and total flood storage in the corresponding period are greater than the corresponding design value of a particular frequency the flood of ljx is identified less than the frequency specifically if q in 2 t w that means the daily inflow of ljx m3 s and the total flood storage of lyx and ljx 108 m3 lays on area a the flood frequency is greater than 1 and the maximum allowable discharge is 4290 m3 s if q in 2 t w lays on area b the flood frequency is less than 1 and greater than 0 1 the maximum allowable discharge is 4510 m3 s similarly if q in 2 t w lays on area c the flood frequency is less than 0 1 and greater than 0 05 the maximum allowable discharge is 7260 m3 s if q in 2 t w lays on area d the flood frequency is less than 0 05 and ljx remains open the dotted line means that just one factor flood storage exceeds the designed value however the inflow does not reach to the designed value therefore the flood frequency is unchanged and the reservoir has no need to increase outflow in contrast for lyx the design flood peak flow is the only judgment index employed in other words if q in 1 t 4200 inflow of lyx m3 s the maximum allowable discharge is 2000 m3 s if 4200 q in 1 t 7040 the maximum allowable discharge is 4000 m3 s if q in 1 t 7040 the maximum allowable discharge is 6000 m3 s more importantly the flood control operation rules of the two reservoirs are also different specially ljx uses the single reservoir flood control rules as shown in formula 1 note that the water level is replaced with water storage and the water storage is the total flood storage of lyx and ljx in contrast lyx uses compensation scheduling rules by controlling the flood storage ratio of lyx and ljx note that its outflow also satisfies the maximum allowable discharge constraint this joint operation mode can well realize the flow compensation and water volume compensation especially the latter between the two reservoirs all the joint operation rules are summarized as follows 1 lyx and ljx should store the flood water according to the ratio of 4 0 4 5 to 1 0 2 the discharge flow of lyx and ljx must not be greater than the maximum permissible discharge of the corresponding frequency flood in all periods and must not be greater than the average daily inflow in rising limb 3 the water level of lyx and ljx must be below the corresponding design water level 4 the outflow varies within the range of 1000 m3 s furthermore a joint reservoir flood control operation simulation model was built based on the flood discharge control chart and operation rules the sketch is shown in fig 5 in practice the interval is one day and the travel time from lyx to ljx is approximately one day hence the total flood storage at period t is the sum of the flood storage of lyx at period t 1 and flood storage of ljx at period t in this model moreover the actual inflow of ljx is equal to the outflow of lyx plus the intervening area flow it is noted that the flood storage ratio of lyx to ljx is used to solve the regional flood composition problem for simplified calculation for the real time flood control of cascade reservoirs a simulation model with simulation rules can ensure the maneuverability of flood control schemes 3 3 flood risk assessment in this paper entropy weighted fuzzy comprehensive evaluation was applied to assess the flood operation risk first three applicable evaluation factors that are closely related to reservoir flood control were selected one is the natural inflow of ljx natural inflow of lyx plus the intervening area flow which reflects the flood magnitude of the region the second is the total flood storage of lyx and ljx which represents the utilization of flood control storage capacity of cascade reservoirs in addition the last is the outflow of ljx which signifies the security threat to the downstream thus the flood operation risk is identified as the comprehensive risk that involves the flood situation reservoir safety and protected object security next we use five levels 1 2 3 4 5 to evaluate the risk degree of each factor moreover the higher the level the greater the risk specifically for the first and last indicator the design flood peak flow and maximum allowable outflow of different frequencies are adopted to grade respectively in addition considering the large difference between 4510 m3 s and 7260 m3 s an outflow of 6000 m3 s is added in grading for the second factor based on the maximum flood storage of different frequency floods the total reservoir capacity for flood control of lyx and ljx is graded next we apply triangular and trapezoidal distributions to build membership functions of the three indicators the membership degree of each factor to the levels is determined by the membership functions the membership functions with the range of 0 1 established in this paper are shown in fig 6 in this way the fuzzy evaluation matrix is developed thus the comprehensive weights of these factors are calculated with the entropy weight method using formula 7 note that a given subjective weight set is needed to perform this task in this paper we presume that w s 1 the subjective weight of inflow is 0 3 for the subjective weight of flood storage we first calculate p the proportion of flood storage to total flood control capacity and then calculate the weight with w s 2 1 w s 1 p thus the subjective weight of outflow can be expressed with w s 3 1 w s 1 w s 2 in this way the subjective weight varies with time if the total flood storage is large its subjective weight is heavy while the subjective weight of outflow is small in other words the dam safety is a priority when suffering large flood after getting the weight set the flood operation risk can be calculated by formulas 4 and 5 3 4 outflow adjustment optimization given that the outflow of ljx is determined first in the flood control operation module next the outflow of lyx is calculated based the flood storage ratio of the two reservoirs shown in fig 5 therefore increasing the outflow of ljx and adjusting the flood storage of lyx based on risk level are regarded as easily implemented response strategies which can also be called feedback operation the specific procedures are as follows 1 pre estimate the future flood magnitude and the future maximum allowable discharge of ljx according to the future inflow for the next three days and the discharge control chart of ljx 2 determine the updated outflow of ljx at current period according to the original outflow of ljx obtained by sub module 1 and the value of outflow adjustment the decision variables of the optimization module note that the updated outflow of ljx is the sum of the original outflow of ljx and the value of outflow adjustment and the future maximum allowable discharge of ljx is the constraint condition of current updated outflow 3 calculate the updated outflow of lyx at current period according to the original outflow of lyx obtained by sub module 1 and the flood storage ratio of the two reservoirs in other words if the flood storage ratio is larger than 4 5 increase the outflow of lyx conversely if the flood storage ratio is small than 4 0 decrease the outflow of lyx in particular for ljx different warning signals represent different outflow increments except for level 1 the other four levels signify updated reservoir releases moreover the higher the level the greater the outflow increment for lyx its outflow changes with the flood storage based on the flood storage ratio it can be observed that the feedback operation is equal to pre discharge approach thereby decreasing the flood risk note that future inflow and scheduling results based on the joint reservoir operation model are needed in this process in this paper the future inflow is derived from the design floods rather than forecast model because this paper focuses on flood control operation 4 results and discussion based on this model the design floods were used as inputs to obtain flood control results next we selected the optimal solution to analyze the reasonability of the model scenario 1 in addition these data were also used to enable a two scenario analysis based only on the first and second modules without outflow adjustment optimization scenario 2 the comparison results are shown in table 2 and figs 7 9 it is seen from table 2 that for the flood with 0 1 frequency the days with the highest risk level in scenario 1 decrease by one day without increasing the maximum water level and maximum outflow of lyx and ljx compared with scenario 2 the maximum water level of lyx and ljx in scenario 1 are even lower than those in scenario 2 however the final water level of ljx in scenario 1 are even higher than that in scenario 2 from fig 7 it can be seen that the outflow of lyx in scenario 1 is larger than that in scenario 2 not exceeding the maximum outflow 4000 m3 s at period 17 and period 30 45 indicating that lyx pre releases flood water in rising limb and releases more flood water in falling limb in scenario 1 unlike lyx ljx pre releases some flood water only in rising limb in scenario 1 and the outflow stays at 4510 m3 s to the end due to the operation rules therefore the maximum water level and final water level of lyx in scenario 1 are lower compared with scenario 2 while the final water level of ljx in scenario 1 becomes higher namely ljx stores more flood water in falling limb compared with scenario 2 the primary reason for this phenomenon is the flood storage ratio of the two reservoirs in response measures lyx needs to adjust its outflow again based on the ratio in scenario 1 and the real ratio is too large from period 30 to 45 in scenario 2 therefore lyx discharges more water to increase the ratio at these times while ljx undertakes more flood storage risk to alleviate the lyx and downstream risks in falling limb in scenario 1 note that the maximum and final total flood storage volume of lyx and ljx in scenario 1 are smaller than those in scenario 2 this operation mode does not increase the maximum risk but keeps the total risk of the water system the lowest because risk does not go away the key of risk response is risk transfer and sharing the purpose of risk transfer is to reduce global risk through various measures which means minimize the flood losses with minimum cost in this flood the cost is extending the time of reservoir flood control operation it can be seen from table 2 and fig 8 that for the flood with 0 01 frequency the days with the highest risk level in scenario 1 decrease by three days without increasing the maximum water level of lyx the maximum outflow of lyx and ljx compared with scenario 2 the maximum outflow of ljx even decreases to 7260 m3 s in scenario 1 which is the maximum allowable discharge of flood with 0 05 frequency thereby lowering the risk of downstream however both the maximum water level and final water level of ljx increase slightly in scenario 1 in terms of flood regulating processes of reservoirs both lyx and ljx pre release some flood water in rising limb in scenario 1 note that the maximum and final total flood storage volume of lyx and ljx in scenario 1 are still smaller than those in scenario 2 in short the results show that the model proposed in scenario 1 can reduce the flood control operation risk compared with scenario 2 the table 2 and fig 9 show that unlike the previous two floods there is no change of the days with the highest risk level between the two scenarios but the flood release of lyx and ljx have varied similarly lyx and ljx pre release some flood water in rising limb in scenario 1 the maximum water level final water level and maximum outflow of lyx in scenario 1 do not exceed those in scenario 2 and are even less than them nevertheless all of the three statistical parameters mentioned above for ljx in scenario 1 are larger than those in scenario 2 note that the maximum and final total flood storage volume of lyx and ljx in scenario 1 are still smaller than those in scenario 2 moreover the real flood storage ratios of the two reservoirs in falling limbs in scenario 1 decrease compared with scenario 2 which is still larger than 4 5 in other words a part of risk shifts from lyx to ljx and downstream in scenario 1 thereby making the risk share more balanced compared with scenario 2 the change rules of the comprehensive risk level are shown in fig 10 this figure shows that the highest risk level varies from 3 to 5 with the decrease of the flood frequency indicating that the greater the flood is the higher the risk degree is furthermore the days with the highest risk level for the floods with frequency of 0 1 and 0 01 decrease by 1 and 3 days respectively this result shows that the model proposed in scenario 1 can reduce the flood risk compared with scenario 2 in addition the risk level changes from the fluctuation of the flood specifically for the flood with 0 1 frequency the risk level increases from 1 to 3 at first and later decreases to 2 likewise for the flood with 0 01 frequency it increases from 1 to 4 at first and ultimately decreases to 1 for the pmf it rises from 1 to 4 at first and falls to 2 and 3 at last in scenario 1 and scenario 2 respectively moreover even though the highest risk level and its duration do not change between the two scenarios the days with the second highest risk level decrease by 2 days in scenario 1 compared with scenario 2 in conclusion the results can verify the rationality and superiority of the model proposed in scenario 1 finally we select the second flood to analyze the risk level change of each factor shown in fig 11 and table 3 it should be noted that the inflow risks in scenario 1 and in scenario 2 are the same because the input is the design flood it can be seen from fig 11 and table 3 that the inflow risk level varies from 1 to 4 and drops to 1 at the end similarly the outflow risk level rises from 1 to 5 but eventually drops only to 4 in scenario 1 and in scenario 2 the reason is that the final water level of the reservoir still exceeds the flood limited water level indicating that the reservoir must release flood water with a large flow in addition the difference between the two scenarios is that the outflow risk level increases earlier in scenario 1 due to the flood pre discharge dispatching of the reservoir for the flood storage risk the highest risk level in scenario 1 is less than that in scenario 2 indicating that the maximum flood storage has decreased compared to scenario 2 we can find that the comprehensive risk level is only 1 in the last several periods even though the outflow risk is 4 since both the inflow and flood storage risks are small 5 conclusions given the limitations of multi hierarchical simulation model for real time flood control operation and the idea of flood risk management this paper is aiming to improve the flood control operation for cascade reservoirs by minimizing flood risk therefore a framework of reservoir flood control operation for cascade reservoirs coupled with risk assessment and the corresponding rfcora model that contains three sub modules are proposed further the methodology regarding the determination of the flood risk level and reservoir release to mitigate flood risk is presented the upper yellow river with multiple reservoirs and multiple protection objects was selected as a case study another model without outflow adjustment optimization is set to be a comparative experiment the results show that the framework and rfcora model developed in this paper can reduce the flood risk of a water system with cascade reservoirs the methodology can be adopted in the real time operation of a flood control system by integrating the flood forecast however further research is needed to improve the flood risk management of water systems as the influence factors play a highly important role in the risk estimation other factors associated with flood management can further enhance the comprehensiveness to assess the flood risk moreover because reliable flood forecasting information is needed as input adding a flood forecast sub module can make the model more complete in addition multiple floods through monte carlo simulation experiment can be used to make new flood control operation rules though certain restrictions exist in this study it provides an alternative way of flood risk reduction which is of significance for decision makers to improve the flood control operation by identifying the flood risk degree and implementing response strategies in the reservoir flood control operation acknowledgements this research was supported by the national key research and development program of china 2016yfc0400906 and the natural science foundation of china 91647112 51679187 and 51679189 the authors gratefully thank the northwest engineering corporation limited of power construction corporation of china for providing the data which can be freely accessed by contacting the first author by e mail mengxuejiao 163 com sincere gratitude is extended to the editor and the anonymous reviewers for their professional comments and corrections 
6608,reference evapotranspiration eto is a variable of great importance for several purposes such as hydrological studies and irrigation scheduling the fao 56 penman monteith fao 56 pm equation is recommended to estimate eto given its good accuracy however the estimation of eto poses a challenge when the availability of meteorological data is limited since the fao 56 pm equation requires data on temperature relative humidity solar radiation and wind speed this study evaluates for the first time the performance of alternative equations artificial neural network ann and support vector machine svm for the estimation of daily eto across the entirety of brazil using measured data on temperature and relative humidity or only temperature two strategies not yet used in brazil were used to develop the ann and svm models i the definition of groups of weather stations with similar climatic characteristics using the k means clustering algorithm to develop models specific for each group and ii the addition of previous meteorological data as input for the models data from 203 weather stations distributed across brazil were used the ann and svm models showed higher performances than the equations that were studied even when they were calibrated the evaluated strategies clustering and previous days provided considerable performance gains for the temperature based models the best performance was obtained by the ann developed with the strategy of clustering and the use of data from two previous days as input however due to the similar performance and greater generalization capacity the ann developed without clustering and with the use of data from four previous days is recommended for the temperature and relative humidity based models the ann developed with data from four previous days was the best option keywords cluster analysis irrigation lagged data machine learning time series 1 introduction the estimation of reference evapotranspiration eto is an important step in tasks such as hydrological studies irrigation scheduling and water resources management the water requirements of crops can be calculated from eto which is especially important in countries with large irrigated areas such as brazil according to the national water agency of brazil ana 2017 in 2015 brazil had an irrigated area of 6 95 million hectares with a prospect of reaching 10 09 million hectares by 2030 eto can be determined using lysimeters which provides accurate measurements typically used in the development and validation of other methods allen et al 2011 lópez urrea et al 2006 however given the cost and complexity of a lysimeter its use is typically restricted to research allen et al 2011 thus the use of mathematical models based on meteorological data recorded by weather stations is a more suitable approach for practical applications the food and agriculture organization fao recommends using the fao 56 penman monteith fao 56 pm equation as a reference method for the estimation of eto allen et al 1998 this equation despite having a recognized accuracy on a global scale landeras et al 2008 lópez urrea et al 2006 requires a large number of measured meteorological data maximum and minimum air temperature relative humidity solar radiation and wind speed due to the common unavailability of a portion of the data required by the fao 56 pm equation observed mainly in developing countries yassin et al 2016 such as brazil several studies have been carried out aiming at the development and evaluation of empirical equations with reduced data requirements ahooghalandari et al 2016 hargreaves and samani 1985 oudin et al 2005 valiantzas 2013 allen et al 1998 aiming at the use of the fao 56 pm equation in the absence of data on solar radiation relative humidity and wind speed proposed alternative procedures to estimate these variables such approaches although requiring less data have a variable performance according to the climatic conditions of the places where they are used maestre valero et al 2013 providing in some cases unsatisfactory results among the various empirical models those based on temperature are especially important since this variable is commonly measured by most weather stations mendicino and senatore 2013 furthermore models based on temperature are widely used mattar et al 2016 valipour 2014 exner kittridge 2012 and valiantzas 2012 concluded that the addition of relative humidity as an input for eto models may yield better performances at a low additional cost given the relatively low investment to add a relative humidity sensor to a weather station in addition low cost portable thermohygrometers exist that can measure temperature and relative humidity in recent years several studies have addressed the estimation of eto using machine learning models feng et al 2016 kisi and alizamir 2018 mattar 2018 mehdizadeh et al 2017 wen et al 2015 yassin et al 2016 such as artificial neural network ann and support vector machine svm in these studies ann often exhibits superior performance over conventional techniques huo et al 2012 kumar et al 2011 landeras et al 2008 shiri et al 2014a similarly svm also has shown good performance for the estimation of eto fan et al 2018 kisi and çimen 2009 tabari et al 2012 wen et al 2015 evapotranspiration is a nonlinear dynamic and complex system therefore it is difficult to derive a formula capable of representing all the physical processes involved wen et al 2015 thus machine learning models are alternatives to traditional techniques due to their high capacity to address complex and nonlinear problems however it is important to mention that empirical equations are simpler and can be more easily used most of the studies in eto modeling using machine learning apply locally trained models which limits their validity to a small scale given the empirical basis machine learning models as well as empirical equations have limitations to estimate eto in places different from those where they were developed a larger scale model can be obtained by developing models that are capable of mapping eto processes in space or that have been trained with data representative of several localities kumar et al 2011 in brazil studies in eto modeling using machine learning are limited to specific regions or at most to a given state of the country althoff et al 2018 alves sobrinho et al 2011 ferraz 2014 tangune and escobedo 2018 zanetti et al 2007 2008 thus there is still a gap in the efficiency of machine learning models valid for the entirety of brazil according to our literature search even traditional empirical equations have not been evaluated that focus on the entire country machine learning models developed for regional scenarios i e model trained with pooled data from several weather stations although they can have higher generalization capacity typically exhibit reduced performance in relation to local scenarios due to the high nonlinearity and low similarity between data used for training shiri et al 2014a although locally developed models have better performance for the site where they were developed they can show poor performance when used in other places since they can be highly site specific kiafar et al 2017 assessing the performance of models developed with data of a particular station and evaluated with data from another station concluded that the encountered relationships might not be able to properly generalize out of the training station thus regional models could represent an important alternative to estimate eto in places where there are no meteorological data for the development or calibration of local models in addition regional models can be more easily adopted in practical situations since a single model can be used in an entire region studies using regional or also termed generalized models remain limited in the literature feng et al 2017 karimi et al 2017 kisi and kilic 2016 shiri et al 2012 2013 2014b given the trade off between generalization capacity and the performance of models developed for large areas the development of models specific for regions with similar climatic conditions can provide performance increments given the lower climatic variability within the same region this approach is especially important in the case of brazil which has a very large territorial extension being the world s fifth largest country and a very diverse climate in this sense clustering algorithms such as the well known k means could be used to group weather stations with similar characteristics and thus to define climatically homogeneous regions it is expected that once a climatic homogeneous region has been defined a single eto model can be developed and used for all places in this region with less performance reduction in relation to local models only a few studies have used this kind of approach jato espino et al 2016 macêdo et al 2018 shiri 2017 another strategy to achieve possible performance gains in the estimation of eto using machine learning would be to use meteorological data from previous days in addition to the data of the current day as input for models shiri and kişi 2011 estimating daily pan evaporation showed that adding the air temperature sunshine duration or solar radiation wind speed and relative humidity values of the previous day increased the accuracy of gene expression programming gep adaptive neuro fuzzy inference system anfis and ann models kim et al 2013 estimated daily pan evaporation under lag time patterns mehdizadeh 2018 used multivariate adaptive regression splines mars and gep to estimate eto based on eto values from previous days in addition to studies addressing the estimation of eto some studies have addressed forecasting of future eto values based on past data alves et al 2017 forecasted eto for the next day eto t 1 using air temperature values karbasi 2018 and landeras et al 2009 forecasted future daily and weekly eto respectively based on the eto from past periods therefore these last studies also suggest that the use of previous data along with current data can help a model to better learn how to estimate eto of the current day with a positive contribution of the time series despite previous meteorological data being readily available and possessing the potential to increase the accuracy of eto models there are only a limited number of studies addressing this topic according to our literature review there are no studies evaluating the use of previous data for the estimation of eto which is different than eto forecasting using ann and svm in this context the objective of this study was to evaluate for the first time the performance of alternative equations original and calibrated ann and svm for the estimation of daily eto in the entirety of brazil using measured data on temperature and relative humidity or only temperature two strategies not yet used in brazil were used to develop the ann and svm models i the definition of groups of weather stations with similar climatic characteristics using the k means algorithm to develop models specific for each group and ii the addition of data from previous days as input for the models 2 materials and methods 2 1 database and study sites daily data from weather stations of the brazilian national institute of meteorology inmet available from the meteorological database for teaching and research bdmep were used data from 2001 to 2015 were collected from 203 stations located in several regions of brazil 971 695 observations given the large territorial extension of brazil the weather stations are located in places with high climatic diversity as shown in fig 1 the daily data used were composed of maximum and minimum air temperature c mean relative humidity sunshine duration h and mean wind speed at 10 m m s 1 wind speed was converted to 2 m height and sunshine duration was used to calculate solar radiation according to allen et al 1998 due to the presence of failures in the database preprocessing was performed excluding days with missing data or with inconsistent values data considered to be inconsistent were those that presented a minimum temperature greater than the maximum temperature negative sunshine duration or sunshine duration higher than the photoperiod negative or greater than 100 relative humidity and wind speed 10 m height with a negative or greater than 15 m s 1 value 2 2 models for estimation of eto given the absence of direct measurements daily eto estimated by the fao 56 pm equation eq 1 was used as reference for the development and evaluation of the models studied which is a common and very accepted practice allen et al 1998 shiri 2017 all the procedures to estimate eto using the fao 56 pm equation were performed according to allen et al 1998 1 et o 0 408 δ r n g γ 900 t avg 273 u 2 e s e a δ γ 1 0 34 u 2 where eto is the reference evapotranspiration mm day 1 rn is the net solar radiation mj m 2 day 1 g is the soil heat flux mj m 2 day 1 considered to be null for daily estimates tavg is the daily mean air temperature c u2 is the wind speed at a 2 m height m s 1 es is the saturation vapor pressure kpa ea is the actual vapor pressure kpa δis the slope of the saturation vapor pressure function kpa c 1 and γ is the psychometric constant kpa c 1 2 2 1 alternative equations six empirical equations commonly reported in the literature were used these equations and their respective input meteorological data are presented in table 1 in addition to the equations presented above the penman monteith equation with missing data was also used estimating unavailable data this approach was used to estimate eto with only measured data on air temperature pmt and with temperature and relative humidity pmrh to accomplish these estimations actual vapor pressure and solar radiation were estimated using eqs 2 and 3 respectively and wind speed was set at 2 m s 1 as recommended by allen et al 1998 2 e a 0 611 exp 17 27 t min t min 237 3 where ea is the actual vapor pressure kpa and tmin is the minimum air temperature c 3 r s 0 16 r a t max t min 0 5 where rs is the solar radiation mj m 2 day 1 ra is the extraterrestrial radiation mj m 2 day 1 tmax is the maximum air temperature c and tmin is the minimum air temperature c the equations were calibrated using pooled data of all the stations studied for the period 2001 to 2010 based on simple linear regression as suggested by allen et al 1998 and used by several authors citakoglu et al 2014 feng et al 2017 to accomplish this eto estimated by the fao 56 pm equation was used as the dependent variable and eto estimated by the evaluated equation was used as the independent variable thus calibrated eto was obtained according to the following equation 4 et o cal a b et o where eto cal is the reference evapotranspiration estimated by the calibrated equation mm day 1 a and b are the calibration parameters and eto is the reference evapotranspiration estimated by the original equation mm day 1 2 2 2 artificial neural network an ann is an information processing system that simulates the ability of the human brain to find patterns and learn from trial and error typically consisting of a series of processing elements called neurons which are interconnected by synaptic weights patil and deka 2016 the most common architecture of an ann is composed of an input layer where the data are introduced into the ann hidden layer s where the data are processed and an output layer where the results are produced landeras et al 2009 in an ann each neuron receives weighted inputs which can be the input variables or the outputs of neurons of the previous layer then sums the inputs adds a bias term and passes the result activation value by an activation function the hyperbolic tangent eq 7 and logistic are activation functions that are commonly used the output yj of a neuron j in the ith layer is computed according to the following equations more details regarding ann can be found in kumar et al 2011 5 i j i 1 n w i j x i b i 6 y j f i j 7 f x e x e x e x e x where ij is the activation value of neuron j of the ith layer wij is the weight of the ith input and the neuron j of the layer xi is the ith input value bi is the ith bias term yj is the output of the neuron j and f x is the activation function in this study anns of the feed forward multilayer perceptron type were employed the adam training algorithm kingma and ba 2014 the name of which is derived from adaptive moment estimation was used this algorithm typically provides fast convergence and does not require large adjustments in hyperparameters the anns were implemented using the tensorflow and keras libraries for the python programming language the number of hidden layers number of neurons in each layer learning rate and activation function were selected by means of trial and error selecting the configuration that resulted in smaller prediction errors in the end it was possible to use a single architecture described in the sequence for all cases however the number of training epochs needed to be individually set for each case to prevent overfitting or underfitting the training optimization process was monitored using the visualization tool tensorboard to identify possible overfitting or underfitting problems the anns employed consisted of an input layer two hidden layers and an output layer the size of the input layer varied according to the number of inputs the hidden layers were composed of fifty neurons in each layer and the output layer was composed of one neuron the activation function used in the neurons of the hidden layers was the hyperbolic tangent and in the output layer since it is a regression task the linear function was used the general architecture of the anns is shown in fig 2 although the anns used have a large number of neurons in relation to most of the published studies kumar et al 2011 in this study the anns were developed with a large number of training examples which reduces problems with overfitting and allows more complex models to be used in addition in previous tests the architecture selected was found to be more efficient than other simpler types 2 2 3 support vector machine svm is a supervised machine learning algorithm used for regression and classification in svm for regression also known in the literature as support vector regression svr the relationship between a dependent variable y and a set of independent variables x is determined by f x according to the following equation 8 f x ω φ x b where ω is the weight vector φ x is a nonlinear function that maps the input space vector x into a high dimensional feature space and b is the bias term as shown in eq 8 svm applies a linear regression in a high dimensional feature space obtained from the input space by nonlinear mapping to convert input data to a high dimensional feature space kernel functions such as linear lin polynomial poly and radial basis function rbf are used in this study rbf kernel was used mehdizadeh et al 2017 and tabari et al 2012 found better performance using this kernel the parameters ω and b are estimated by minimizing the error function below 9 1 2 ω 2 c 1 n 1 n l ε f x i y i 10 l ε f x i y i 0 i f f x i y i ε f x i y i ε o t h e r w i s e where 1 2 ω 2 is the regularization term c is a positive constant termed penalty parameter lɛ is the ε insensitive error function f xi is the predicted value yi is the target value and ε is the tube size of svm to train a svm model when using rbf kernel eq 11 parameters c ε and γ should be properly set to obtain satisfactory performance in this study these parameters were selected by means of trial and error more details regarding svm are presented in gocić et al 2015 the scikit learn library for the python programming language was used to implement the svm models 11 k x i x j e x p γ x i x j 2 γ 0 2 3 data management and development of the machine learning models initially the machine learning models were developed using pooled data from all the weather stations i e the data from all the stations were combined into a single dataset such that the models obtained would be able to estimate eto in any region of brazil two data availability scenarios were evaluated temperature based models using only measured data on maximum and minimum air temperature and temperature and relative humidity based models using measured data on maximum and minimum air temperature and relative humidity in addition to the measured data in both cases extraterrestrial radiation was used this variable was calculated based on latitude and day of the year allen et al 1998 the performances of the developed anns and svms were compared to the performances of original and calibrated empirical equations with the same measured data requirements two strategies were also adopted to obtain models with better performances the first strategy was the clustering of the weather stations based on their mean climatic characteristics using the k means algorithm with the subsequent development of models specific for each group for the development of the models pooled data of all weather stations belonging to each group were used the second strategy was to add previous meteorological data as input for the models these strategies were evaluated individually and together with the following combinations anns and svms developed for brazil as a whole with and without previous data and anns and svms developed for specific groups of weather stations with and without previous data to train the machine learning models data from the period of 2001 to 2010 10 years of all the weather stations studied were used 654 896 observations these data after being randomized were divided into training 75 and validation 25 sets the data of the training set were used in the training process of the anns and svms and the data of the validation set were used for hyperparameters optimization for the svm for the models developed for brazil as a whole only approximately 40 of the data of the training set were used to develop the models because svm requires a relatively long time to train using all data of the training set and during the development of a model it must be trained several times to adjust hyperparameters according to cervantes et al 2008 an alternative to fitting svm models in large datasets is to select representative training data from the dataset for the svm models developed for groups of stations all data of the training set were used the performance of the ann and svm models was evaluated with data from the test set referring to the period of 2011 2015 5 years before the training of the machine learning models input and output variables were standardized according to eq 12 to avoid convergence problems to reflect the real use of the models the mean µ and standard deviation σ were computed using only the data of the training set 12 x ni x i μ σ where xni is the standardized value xi is the observed value µ is the mean and σ is the standard deviation 2 4 weather station clustering for each weather station the mean daily values of the maximum minimum and mean temperature temperature range relative humidity sunshine duration wind speed extraterrestrial radiation and eto fao 56 pm with full dataset were obtained these variables were used to group the stations by means of the k means algorithm for this step data from 2001 to 2010 were used to remove the effect of different scales the variables were standardized according to eq 12 k means is an unsupervised algorithm the use of which is quite common in clustering tasks according to zhou and zhao 2013 a clustering algorithm causes objects of the same group to have high similarity and objects of different groups to have low similarity the goal of the k means algorithm is to divide n objects into k clusters groups with the result being each object belongs to the closest group the clustering process is based on the proximity between objects e g weather stations measured by euclidean distance or other distance measures according to li et al 2017 for a given set of observations x1 x2 xn in which each observation x is a d dimensional feature vector f1 f2 fd k means aims to partition the n objects into k n groups g g1 g2 gk to minimize the within group sum of squares sum of the squares of the distances of each object to the centroid of its group the mathematical representation of the k means goal is presented in eq 13 13 m i n j 1 k i 1 n x i j c j 2 where x i j c j is the distance between an observation x i j and the centroid cj of the group in this study the distance measure was euclidean and the choice in the number of groups was made with the aid of the silhouette coefficient kodinariya and makwana 2013 the result being the creation of five groups k means typically uses euclidean distance the partition of the weather stations in their respective groups is illustrated in fig 3 2 5 previous data as input previous meteorological data were used along with data of the current day as inputs for the machine learning models the addition of data from one to six previous days was evaluated the meteorological variables considered in the data from previous days were the same as those of the current day for example the temperature and relative humidity based models developed with two previous days used the maximum and minimum air temperature relative humidity and extraterrestrial radiation of the current day and of the two previous days the input combinations used are presented in table 2 2 6 performance comparison criteria the performance of the models was evaluated for each weather station with data from the period 2011 to 2015 5 years 316 799 observations the statistical indicators used include root mean square error rmse mean bias error mbe and coefficient of determination r2 according to the following equations 14 r m s e 1 n p i o i 2 15 m b e 1 n p i o i 16 r 2 p i p o i o p i p 2 o i o 2 2 where pi is the predicted value mm day 1 oi is the observed value mm day 1 p is the mean of the predicted values mm day 1 o is the mean of the observed values mm day 1 and n is the number of data pairs 3 results and discussion 3 1 temperature based models the penman monteith equation using only measured data on temperature pmt had the best performance among the original temperature based equations featuring a lower rmse mean value and higher r2 mean value fig 4 on the other hand the oudin equation oud had the worst performance the hargreaves samani hs and hamon ham equations exhibited intermediate performances both being similar to each other similarly almorox et al 2015 evaluating on a global scale 11 temperature based models for the estimation of monthly eto concluded that the hs model had the best overall performance later almorox et al 2018 compared the performance of the pmt and hs equations on a global scale concluding that the pmt equation produced better results the pmt equation also performed better than the hs equation in a study carried out by alencar et al 2015 in the state of minas gerais brazil it is important to emphasize that the pmt equation conserves part of its physical base which probably makes it more suitable for use under highly diverse climatic conditions as are characteristic in brazil after being calibrated all the equations had lower rmse mean values the r2 is not affected by calibration by linear regression the calibrated pmt and hs equations had the best performances exhibiting very similar rmse values the temperature based artificial neural network annt and support vector machine svmt had the same rmse and r2 mean values and when compared to the original and calibrated pmt and hs equations exhibited better performances when compared to the original pmt and hs equations the annt and svmt had 13 and 23 lower rmse mean values respectively and when compared to the calibrated equations they had 9 and 8 lower rmse mean values respectively this result demonstrates the typical ability of machine learning models to address complex tasks as reported in several studies in eto modeling antonopoulos and antonopoulos 2017 yassin et al 2016 the clustering strategy without previous data led to an 11 reduction of the rmse mean value for the annt and svmt in relation to their versions developed for brazil as a whole general fig 5 the r2 mean value had a slight increase for both models 4 when adding data from previous days as input the models developed for specific groups of stations clustering continued to have better performances but with less difference this behavior confirms the dependency between the performance of empirical models and the climatic characteristics of the region where they are developed and later applied maestre valero et al 2013 the use of data from previous days provided better performances for the annt and svmt models developed for brazil as a whole and for those developed for groups of weather stations for the general annt the rmse mean value was reduced by 10 when four previous days were used for the clustering annt the rmse mean value was reduced by 6 when two previous days were used the r2 mean value increased slightly in both cases the use of more than four and two previous days did not promote more performance gains for the general and clustering annt respectively for the general and clustering svmt the best performance was achieved using six and five previous days respectively it should be emphasized that for the annt and svmt the most expressive performance gain occurred when one previous day was used with decreasing performance gains occurring when adding more previous days for the annt the individual use of the clustering and data from previous days provided very similar performance gains with 11 and 10 reductions of rmse respectively and a 4 increase of r2 in both cases the best combination of these techniques clustering two previous days promoted a 16 reduction in rmse and 7 increase in r2 for the svmt the individual use of the clustering provided performance gains that were slightly better than those obtained using previous days individually in the first case rmse was reduced by 11 and in the second case it was reduced by 7 the best combination of these techniques clustering five previous days promoted a 16 reduction in rmse and 6 increase in r2 comparing the annt and svmt models both exhibited similar performances however the annt was slightly better when previous days were used especially for the general models 3 2 temperature and relative humidity based models similar to that observed for the temperature based models the penman monteith equation using only measured data on temperature and relative humidity pmrh had the lowest rmse and the highest r2 among the original equations evaluated fig 6 the valiantzas val equation had the second best performance among the original equations however the rmse mean value obtained by the val equation was 24 higher than that obtained by the pmrh equation the romanenko rom and schendel sch equations performed the worst with sch exhibiting the highest rmse and the lowest r2 although the rom and sch equations use temperature and relative humidity they performed worse than the temperature based equations evaluated kiafar et al 2017 also reported a poorer performance of sch compared with the hs equation this behavior is probably because the rom and sch equations do not use extraterrestrial radiation or photoperiod as input in contrast to the temperature based models evaluated the pmrh and val equations probably due to their partial physical bases were more suitable to estimate eto under different climatic conditions for the conditions evaluated the results are different from those obtained by valiantzas 2013 who reported better performance of the val equation compared to the pmrh equation after calibration the pmrh equation continued to exhibit the best performance however as opposed to the other equations rmse was not reduced the temperature and relative humidity based artificial neural network annrh and support vector machine svmrh exhibited similar performances surpassing the pmrh equation with approximately 15 reduction in rmse this result reinforces the superiority of machine learning models for the estimation of eto compared with conventional equations corroborating the findings of kumar et al 2011 and shiri et al 2014a the performance gains provided by the clustering in this scenario fig 7 were less significant than those observed for the temperature based models fig 5 especially for the annrh models the highest rmse reductions 8 were found for the svmrh models developed without data from previous days and with data from two previous days the use of relative humidity facilitates eto modeling providing a greater generalization capacity for the models and consequently more uniform performances in varied climates thus the development of models specific for regions with homogeneous climates produces less expressive performance gains in comparison to those obtained for temperature based models the addition of data from previous days as an input promoted a 10 reduction in rmse for the general annrh when using four previous days for the clustering annrh rmse was reduced by 5 when using two previous days the addition of previous days above the mentioned values did not promote more performance gains for the general svmrh the addition of four previous days promoted an 8 reduction in rmse for the clustering svmrh the addition of two previous days promoted a 5 reduction in rmse the r2 values exhibited only slight increases in both cases for the annrh the individual use of data from previous days provided slightly higher performance gains than those provided by the clustering employed individually the use of these strategies promoted 10 and 7 reductions in rmse and 4 and 3 increases in r2 respectively the best combination of these techniques clustering two previous days promoted a reduction in rmse and an increase in r2 that was approximately equal to those promoted by the use of previous days four days individually for the svmrh the performance gains obtained by the use of data from previous days and clustering individually were identical reducing rmse by 8 and increasing r2 by 3 the best combination of these techniques clustering two previous days promoted a reduction in rmse and an increase in r2 slightly higher than those promoted by the use of previous days four days individually comparing the annrh and svmrh annrh performed slightly better in the case of the general models however they exhibited the same performance when clustering was used 3 3 spatialization of the performance of the models the rmse and mbe values obtained for each weather station in both data availability scenarios by the best empirical equation best machine learning model best machine learning model clustering best combination of machine learning model data from previous days and best combination of machine learning model clustering data from previous days were spatialized in brazilian territory figs 8 and 9 in cases where the ann and svm had the same performance the ann was selected given the better overall performance of this algorithm in this study the spatialization of these indicators allows the efficiency of the models to be evaluated for different regions of brazil as well as the performance of the models to be correlated with the climatic characteristics of the places where they were applied in general the models that used relative humidity exhibited lower rmse values and lower mbe absolute values emphasizing the importance of this variable the calibrated hs pmrh and annt models were those that presented eto estimates with more evident overestimations and underestimations higher mbe absolute values in addition to higher rmse values the annrh had less expressive overestimations and underestimations with few points exhibiting high mbe absolute values the highest rmse values were typically found in northeastern brazil however it should be remembered that this region has the highest eto mean values fig 1 thus given the relation between rmse and the range of the analyzed variable the rmse values found in this region become proportionally similar to those obtained in other regions of the country in general the greatest underestimations of eto were observed in northeastern brazil this behavior is possibly explained by the low relative humidity high sunshine duration and high wind speed typical of this region fig 1 these characteristics result in increasing eto that is not entirely captured by the models evaluated since they do not incorporate these variables as inputs except for relative humidity used in part of the models the lack of solar radiation in this case sunshine duration and relative humidity can be partially suppressed by air temperature temperature range given the correlation between these variables allen et al 1998 hargreaves and allen 2003 on the other hand wind has a great effect on eto in dry and hot environments as in northeastern brazil given the greater removal of water vapor stored in the air allen et al 1998 3 4 overall evaluation among the equations evaluated the penman monteith equation with missing data pmt and pmrh showed the best overall performance in both data availability scenarios studied this behavior is possibly related to the physical basis of this equation partially conserved the empirical equations commonly reported in the literature are typically developed for specific or less extensive climatic conditions which limits their use maestre valero et al 2013 except for the pmrh equation calibration improved the mean performance of all the equations comparing the pmt and pmrh equations which were the best performing among the original equations evaluated in their respective data availability scenarios rmse was reduced by 23 and r2 was increased by 17 when using the pmrh equation considering the calibrated equations rmse was reduced by 18 and r2 was increased by 18 when using the original or calibrated pmrh equation which exhibited equal performance between them in relation to the calibrated hs which was the temperature based calibrated equation with the lowest rmse for the machine learning models developed in a conventional manner i e without clustering and previous days the use of relative humidity resulted in approximately 24 reduction in rmse and 16 increase in r2 similarly the models developed with clustering and the use of data from previous days also benefited from the addition of relative humidity as an input these results demonstrate the importance of relative humidity in eto modeling in brazil corroborating with the present study almorox et al 2015 concluded that temperature based models exhibit low correlation with eto estimated by the fao 56 pm equation in tropical climates given the role of other climatic variables such as vapor pressure deficit models developed for large areas in this case the entirety of brazil typically perform better in places resembling the average characteristics of the dataset used in the development of the models thus sites with more discrepant characteristics in relation to the average values of the dataset tend to present stronger overestimations or underestimations of eto shiri et al 2014a also reported the typical difficulty of developing regional models given the high nonlinearity contained in the data used for model training by segmenting brazil into homogeneous areas the models are developed and applied under conditions of lower climatic variability reaching higher and more uniform performances according to the results obtained in this study it was also verified that the smaller the number of meteorological variables used as input the lower the generalization capacity of the model which increases the dependency between the performance of the model and the climatic characteristics of its place of application thus in these cases there is greater benefit when the clustering technique is used by analyzing the weather station groups obtained in this study fig 3 based on previous knowledge of brazilian climate and köppen s climate classification for brazil alvares et al 2013 there was good agreement with the previously recognized climatic zones this behavior combined with the performance gain obtained by the models developed using this technique indicates k means to be a promising alternative for the delimitation of homogeneous climatic zones corroborating the findings of zhang and yan 2014 and zscheischler et al 2012 thus this approach can benefit future studies on the development and adjustment of eto models in addition to other types of studies the use of data from previous days as inputs proved to be a satisfactory strategy for the development of machine learning models promoting considerable performance gains especially when the clustering technique was not employed this approach also has the potential to benefit the development of other types of models such as empirical equations or other artificial intelligence models the combined use of clustering and data from previous days promoted more expressive performance gains compare with the individual use of previous days only for the temperature based models despite the potential of both strategies the individual use of previous days has the advantage of producing models with greater generalization capacity allowing a single model to be applied in any region of brazil this higher generalization capacity provides the models with a greater ability to address extreme events or atypical climatic behavior given the greater diversity of data used in their development thus even that the combination of these techniques has promoted some performance gains given the relatively low performance improvement the use of general models with data from previous days can become more advantageous comparing the machine learning models the ann models were determined to be slightly better than the svm exhibiting lower rmse values mainly when previous days were used for the models developed without previous days and clustering the ann and svm models exhibited equivalent performance these results are in contrast with kisi and çimen 2009 and wen et al 2015 who found better performance of svm than ann however there are many factors involved with the performance of ann and svm models such as the ann training algorithm used and the settings of the hyperparameters of the models regarding the reliability of machine learning models pereira et al 2015 warned that many trends defined by machine learning models remain empirical and may not translate well in time and space however the present study explores models developed with a large amount of data that are variant in space and time which confers greater reliability to the models obtained 4 conclusions ann svm and empirical equations were evaluated for the estimation of eto in the entirety of brazil using measured data on temperature and relative humidity or only temperature two little explored approaches were employed i the definition of groups of weather stations with similar characteristics by the k means clustering algorithm and ii the use of previous meteorological data as input for the models the groups of weather stations were used to develop models specific for each group the models were also developed in a conventional manner i e without data from previous days and trained with pooled data from all of brazil the penman monteith equations with missing data pmt and pmrh exhibited the best overall performance among the calibrated and original equations in their corresponding data availability scenarios after calibration better results were obtained for approximately all equations except for the pmrh equation the calibrated hs equation exhibited a performance equivalent to the calibrated pmt equation when compared to the machine learning models the equations were surpassed by the models developed in a conventional way and under the strategies of clustering and use of data from previous days the clustering and the use of data from previous days provided performance gains when used individually and when combined the individual use of data from previous days had the advantage of producing models with greater generalization capacity since they are trained with more diverse data and can be used in any region of brazil for the temperature based models the best performance was obtained by the ann developed with the clustering strategy and the use of data from two previous days however due to the similar performance and greater generalization capacity the ann developed without clustering and with the use of data from four previous days is recommended for the temperature and relative humidity based models the ann developed with data from four previous days was the best option the use of relative humidity in addition to temperature increased the generalization capacity of the models and provided performance gains for all models evaluated representing an option for improving the estimation of eto at a low additional cost finally clustering and the use of data from previous days could be applied in future studies to develop eto models in other regions and using different machine learning algorithms special attention should be given to regional models due to their key role in places where there are no data available to develop local models declaration of interests none acknowledgments the authors wish to thank the national council for scientific and technological development cnpq for providing a scholarship to the first author and the brazilian national institute of meteorology inmet for the meteorological data used this study was financed in part by the coordenação de aperfeiçoamento de pessoal de nível superior brasil capes finance code 001 
6608,reference evapotranspiration eto is a variable of great importance for several purposes such as hydrological studies and irrigation scheduling the fao 56 penman monteith fao 56 pm equation is recommended to estimate eto given its good accuracy however the estimation of eto poses a challenge when the availability of meteorological data is limited since the fao 56 pm equation requires data on temperature relative humidity solar radiation and wind speed this study evaluates for the first time the performance of alternative equations artificial neural network ann and support vector machine svm for the estimation of daily eto across the entirety of brazil using measured data on temperature and relative humidity or only temperature two strategies not yet used in brazil were used to develop the ann and svm models i the definition of groups of weather stations with similar climatic characteristics using the k means clustering algorithm to develop models specific for each group and ii the addition of previous meteorological data as input for the models data from 203 weather stations distributed across brazil were used the ann and svm models showed higher performances than the equations that were studied even when they were calibrated the evaluated strategies clustering and previous days provided considerable performance gains for the temperature based models the best performance was obtained by the ann developed with the strategy of clustering and the use of data from two previous days as input however due to the similar performance and greater generalization capacity the ann developed without clustering and with the use of data from four previous days is recommended for the temperature and relative humidity based models the ann developed with data from four previous days was the best option keywords cluster analysis irrigation lagged data machine learning time series 1 introduction the estimation of reference evapotranspiration eto is an important step in tasks such as hydrological studies irrigation scheduling and water resources management the water requirements of crops can be calculated from eto which is especially important in countries with large irrigated areas such as brazil according to the national water agency of brazil ana 2017 in 2015 brazil had an irrigated area of 6 95 million hectares with a prospect of reaching 10 09 million hectares by 2030 eto can be determined using lysimeters which provides accurate measurements typically used in the development and validation of other methods allen et al 2011 lópez urrea et al 2006 however given the cost and complexity of a lysimeter its use is typically restricted to research allen et al 2011 thus the use of mathematical models based on meteorological data recorded by weather stations is a more suitable approach for practical applications the food and agriculture organization fao recommends using the fao 56 penman monteith fao 56 pm equation as a reference method for the estimation of eto allen et al 1998 this equation despite having a recognized accuracy on a global scale landeras et al 2008 lópez urrea et al 2006 requires a large number of measured meteorological data maximum and minimum air temperature relative humidity solar radiation and wind speed due to the common unavailability of a portion of the data required by the fao 56 pm equation observed mainly in developing countries yassin et al 2016 such as brazil several studies have been carried out aiming at the development and evaluation of empirical equations with reduced data requirements ahooghalandari et al 2016 hargreaves and samani 1985 oudin et al 2005 valiantzas 2013 allen et al 1998 aiming at the use of the fao 56 pm equation in the absence of data on solar radiation relative humidity and wind speed proposed alternative procedures to estimate these variables such approaches although requiring less data have a variable performance according to the climatic conditions of the places where they are used maestre valero et al 2013 providing in some cases unsatisfactory results among the various empirical models those based on temperature are especially important since this variable is commonly measured by most weather stations mendicino and senatore 2013 furthermore models based on temperature are widely used mattar et al 2016 valipour 2014 exner kittridge 2012 and valiantzas 2012 concluded that the addition of relative humidity as an input for eto models may yield better performances at a low additional cost given the relatively low investment to add a relative humidity sensor to a weather station in addition low cost portable thermohygrometers exist that can measure temperature and relative humidity in recent years several studies have addressed the estimation of eto using machine learning models feng et al 2016 kisi and alizamir 2018 mattar 2018 mehdizadeh et al 2017 wen et al 2015 yassin et al 2016 such as artificial neural network ann and support vector machine svm in these studies ann often exhibits superior performance over conventional techniques huo et al 2012 kumar et al 2011 landeras et al 2008 shiri et al 2014a similarly svm also has shown good performance for the estimation of eto fan et al 2018 kisi and çimen 2009 tabari et al 2012 wen et al 2015 evapotranspiration is a nonlinear dynamic and complex system therefore it is difficult to derive a formula capable of representing all the physical processes involved wen et al 2015 thus machine learning models are alternatives to traditional techniques due to their high capacity to address complex and nonlinear problems however it is important to mention that empirical equations are simpler and can be more easily used most of the studies in eto modeling using machine learning apply locally trained models which limits their validity to a small scale given the empirical basis machine learning models as well as empirical equations have limitations to estimate eto in places different from those where they were developed a larger scale model can be obtained by developing models that are capable of mapping eto processes in space or that have been trained with data representative of several localities kumar et al 2011 in brazil studies in eto modeling using machine learning are limited to specific regions or at most to a given state of the country althoff et al 2018 alves sobrinho et al 2011 ferraz 2014 tangune and escobedo 2018 zanetti et al 2007 2008 thus there is still a gap in the efficiency of machine learning models valid for the entirety of brazil according to our literature search even traditional empirical equations have not been evaluated that focus on the entire country machine learning models developed for regional scenarios i e model trained with pooled data from several weather stations although they can have higher generalization capacity typically exhibit reduced performance in relation to local scenarios due to the high nonlinearity and low similarity between data used for training shiri et al 2014a although locally developed models have better performance for the site where they were developed they can show poor performance when used in other places since they can be highly site specific kiafar et al 2017 assessing the performance of models developed with data of a particular station and evaluated with data from another station concluded that the encountered relationships might not be able to properly generalize out of the training station thus regional models could represent an important alternative to estimate eto in places where there are no meteorological data for the development or calibration of local models in addition regional models can be more easily adopted in practical situations since a single model can be used in an entire region studies using regional or also termed generalized models remain limited in the literature feng et al 2017 karimi et al 2017 kisi and kilic 2016 shiri et al 2012 2013 2014b given the trade off between generalization capacity and the performance of models developed for large areas the development of models specific for regions with similar climatic conditions can provide performance increments given the lower climatic variability within the same region this approach is especially important in the case of brazil which has a very large territorial extension being the world s fifth largest country and a very diverse climate in this sense clustering algorithms such as the well known k means could be used to group weather stations with similar characteristics and thus to define climatically homogeneous regions it is expected that once a climatic homogeneous region has been defined a single eto model can be developed and used for all places in this region with less performance reduction in relation to local models only a few studies have used this kind of approach jato espino et al 2016 macêdo et al 2018 shiri 2017 another strategy to achieve possible performance gains in the estimation of eto using machine learning would be to use meteorological data from previous days in addition to the data of the current day as input for models shiri and kişi 2011 estimating daily pan evaporation showed that adding the air temperature sunshine duration or solar radiation wind speed and relative humidity values of the previous day increased the accuracy of gene expression programming gep adaptive neuro fuzzy inference system anfis and ann models kim et al 2013 estimated daily pan evaporation under lag time patterns mehdizadeh 2018 used multivariate adaptive regression splines mars and gep to estimate eto based on eto values from previous days in addition to studies addressing the estimation of eto some studies have addressed forecasting of future eto values based on past data alves et al 2017 forecasted eto for the next day eto t 1 using air temperature values karbasi 2018 and landeras et al 2009 forecasted future daily and weekly eto respectively based on the eto from past periods therefore these last studies also suggest that the use of previous data along with current data can help a model to better learn how to estimate eto of the current day with a positive contribution of the time series despite previous meteorological data being readily available and possessing the potential to increase the accuracy of eto models there are only a limited number of studies addressing this topic according to our literature review there are no studies evaluating the use of previous data for the estimation of eto which is different than eto forecasting using ann and svm in this context the objective of this study was to evaluate for the first time the performance of alternative equations original and calibrated ann and svm for the estimation of daily eto in the entirety of brazil using measured data on temperature and relative humidity or only temperature two strategies not yet used in brazil were used to develop the ann and svm models i the definition of groups of weather stations with similar climatic characteristics using the k means algorithm to develop models specific for each group and ii the addition of data from previous days as input for the models 2 materials and methods 2 1 database and study sites daily data from weather stations of the brazilian national institute of meteorology inmet available from the meteorological database for teaching and research bdmep were used data from 2001 to 2015 were collected from 203 stations located in several regions of brazil 971 695 observations given the large territorial extension of brazil the weather stations are located in places with high climatic diversity as shown in fig 1 the daily data used were composed of maximum and minimum air temperature c mean relative humidity sunshine duration h and mean wind speed at 10 m m s 1 wind speed was converted to 2 m height and sunshine duration was used to calculate solar radiation according to allen et al 1998 due to the presence of failures in the database preprocessing was performed excluding days with missing data or with inconsistent values data considered to be inconsistent were those that presented a minimum temperature greater than the maximum temperature negative sunshine duration or sunshine duration higher than the photoperiod negative or greater than 100 relative humidity and wind speed 10 m height with a negative or greater than 15 m s 1 value 2 2 models for estimation of eto given the absence of direct measurements daily eto estimated by the fao 56 pm equation eq 1 was used as reference for the development and evaluation of the models studied which is a common and very accepted practice allen et al 1998 shiri 2017 all the procedures to estimate eto using the fao 56 pm equation were performed according to allen et al 1998 1 et o 0 408 δ r n g γ 900 t avg 273 u 2 e s e a δ γ 1 0 34 u 2 where eto is the reference evapotranspiration mm day 1 rn is the net solar radiation mj m 2 day 1 g is the soil heat flux mj m 2 day 1 considered to be null for daily estimates tavg is the daily mean air temperature c u2 is the wind speed at a 2 m height m s 1 es is the saturation vapor pressure kpa ea is the actual vapor pressure kpa δis the slope of the saturation vapor pressure function kpa c 1 and γ is the psychometric constant kpa c 1 2 2 1 alternative equations six empirical equations commonly reported in the literature were used these equations and their respective input meteorological data are presented in table 1 in addition to the equations presented above the penman monteith equation with missing data was also used estimating unavailable data this approach was used to estimate eto with only measured data on air temperature pmt and with temperature and relative humidity pmrh to accomplish these estimations actual vapor pressure and solar radiation were estimated using eqs 2 and 3 respectively and wind speed was set at 2 m s 1 as recommended by allen et al 1998 2 e a 0 611 exp 17 27 t min t min 237 3 where ea is the actual vapor pressure kpa and tmin is the minimum air temperature c 3 r s 0 16 r a t max t min 0 5 where rs is the solar radiation mj m 2 day 1 ra is the extraterrestrial radiation mj m 2 day 1 tmax is the maximum air temperature c and tmin is the minimum air temperature c the equations were calibrated using pooled data of all the stations studied for the period 2001 to 2010 based on simple linear regression as suggested by allen et al 1998 and used by several authors citakoglu et al 2014 feng et al 2017 to accomplish this eto estimated by the fao 56 pm equation was used as the dependent variable and eto estimated by the evaluated equation was used as the independent variable thus calibrated eto was obtained according to the following equation 4 et o cal a b et o where eto cal is the reference evapotranspiration estimated by the calibrated equation mm day 1 a and b are the calibration parameters and eto is the reference evapotranspiration estimated by the original equation mm day 1 2 2 2 artificial neural network an ann is an information processing system that simulates the ability of the human brain to find patterns and learn from trial and error typically consisting of a series of processing elements called neurons which are interconnected by synaptic weights patil and deka 2016 the most common architecture of an ann is composed of an input layer where the data are introduced into the ann hidden layer s where the data are processed and an output layer where the results are produced landeras et al 2009 in an ann each neuron receives weighted inputs which can be the input variables or the outputs of neurons of the previous layer then sums the inputs adds a bias term and passes the result activation value by an activation function the hyperbolic tangent eq 7 and logistic are activation functions that are commonly used the output yj of a neuron j in the ith layer is computed according to the following equations more details regarding ann can be found in kumar et al 2011 5 i j i 1 n w i j x i b i 6 y j f i j 7 f x e x e x e x e x where ij is the activation value of neuron j of the ith layer wij is the weight of the ith input and the neuron j of the layer xi is the ith input value bi is the ith bias term yj is the output of the neuron j and f x is the activation function in this study anns of the feed forward multilayer perceptron type were employed the adam training algorithm kingma and ba 2014 the name of which is derived from adaptive moment estimation was used this algorithm typically provides fast convergence and does not require large adjustments in hyperparameters the anns were implemented using the tensorflow and keras libraries for the python programming language the number of hidden layers number of neurons in each layer learning rate and activation function were selected by means of trial and error selecting the configuration that resulted in smaller prediction errors in the end it was possible to use a single architecture described in the sequence for all cases however the number of training epochs needed to be individually set for each case to prevent overfitting or underfitting the training optimization process was monitored using the visualization tool tensorboard to identify possible overfitting or underfitting problems the anns employed consisted of an input layer two hidden layers and an output layer the size of the input layer varied according to the number of inputs the hidden layers were composed of fifty neurons in each layer and the output layer was composed of one neuron the activation function used in the neurons of the hidden layers was the hyperbolic tangent and in the output layer since it is a regression task the linear function was used the general architecture of the anns is shown in fig 2 although the anns used have a large number of neurons in relation to most of the published studies kumar et al 2011 in this study the anns were developed with a large number of training examples which reduces problems with overfitting and allows more complex models to be used in addition in previous tests the architecture selected was found to be more efficient than other simpler types 2 2 3 support vector machine svm is a supervised machine learning algorithm used for regression and classification in svm for regression also known in the literature as support vector regression svr the relationship between a dependent variable y and a set of independent variables x is determined by f x according to the following equation 8 f x ω φ x b where ω is the weight vector φ x is a nonlinear function that maps the input space vector x into a high dimensional feature space and b is the bias term as shown in eq 8 svm applies a linear regression in a high dimensional feature space obtained from the input space by nonlinear mapping to convert input data to a high dimensional feature space kernel functions such as linear lin polynomial poly and radial basis function rbf are used in this study rbf kernel was used mehdizadeh et al 2017 and tabari et al 2012 found better performance using this kernel the parameters ω and b are estimated by minimizing the error function below 9 1 2 ω 2 c 1 n 1 n l ε f x i y i 10 l ε f x i y i 0 i f f x i y i ε f x i y i ε o t h e r w i s e where 1 2 ω 2 is the regularization term c is a positive constant termed penalty parameter lɛ is the ε insensitive error function f xi is the predicted value yi is the target value and ε is the tube size of svm to train a svm model when using rbf kernel eq 11 parameters c ε and γ should be properly set to obtain satisfactory performance in this study these parameters were selected by means of trial and error more details regarding svm are presented in gocić et al 2015 the scikit learn library for the python programming language was used to implement the svm models 11 k x i x j e x p γ x i x j 2 γ 0 2 3 data management and development of the machine learning models initially the machine learning models were developed using pooled data from all the weather stations i e the data from all the stations were combined into a single dataset such that the models obtained would be able to estimate eto in any region of brazil two data availability scenarios were evaluated temperature based models using only measured data on maximum and minimum air temperature and temperature and relative humidity based models using measured data on maximum and minimum air temperature and relative humidity in addition to the measured data in both cases extraterrestrial radiation was used this variable was calculated based on latitude and day of the year allen et al 1998 the performances of the developed anns and svms were compared to the performances of original and calibrated empirical equations with the same measured data requirements two strategies were also adopted to obtain models with better performances the first strategy was the clustering of the weather stations based on their mean climatic characteristics using the k means algorithm with the subsequent development of models specific for each group for the development of the models pooled data of all weather stations belonging to each group were used the second strategy was to add previous meteorological data as input for the models these strategies were evaluated individually and together with the following combinations anns and svms developed for brazil as a whole with and without previous data and anns and svms developed for specific groups of weather stations with and without previous data to train the machine learning models data from the period of 2001 to 2010 10 years of all the weather stations studied were used 654 896 observations these data after being randomized were divided into training 75 and validation 25 sets the data of the training set were used in the training process of the anns and svms and the data of the validation set were used for hyperparameters optimization for the svm for the models developed for brazil as a whole only approximately 40 of the data of the training set were used to develop the models because svm requires a relatively long time to train using all data of the training set and during the development of a model it must be trained several times to adjust hyperparameters according to cervantes et al 2008 an alternative to fitting svm models in large datasets is to select representative training data from the dataset for the svm models developed for groups of stations all data of the training set were used the performance of the ann and svm models was evaluated with data from the test set referring to the period of 2011 2015 5 years before the training of the machine learning models input and output variables were standardized according to eq 12 to avoid convergence problems to reflect the real use of the models the mean µ and standard deviation σ were computed using only the data of the training set 12 x ni x i μ σ where xni is the standardized value xi is the observed value µ is the mean and σ is the standard deviation 2 4 weather station clustering for each weather station the mean daily values of the maximum minimum and mean temperature temperature range relative humidity sunshine duration wind speed extraterrestrial radiation and eto fao 56 pm with full dataset were obtained these variables were used to group the stations by means of the k means algorithm for this step data from 2001 to 2010 were used to remove the effect of different scales the variables were standardized according to eq 12 k means is an unsupervised algorithm the use of which is quite common in clustering tasks according to zhou and zhao 2013 a clustering algorithm causes objects of the same group to have high similarity and objects of different groups to have low similarity the goal of the k means algorithm is to divide n objects into k clusters groups with the result being each object belongs to the closest group the clustering process is based on the proximity between objects e g weather stations measured by euclidean distance or other distance measures according to li et al 2017 for a given set of observations x1 x2 xn in which each observation x is a d dimensional feature vector f1 f2 fd k means aims to partition the n objects into k n groups g g1 g2 gk to minimize the within group sum of squares sum of the squares of the distances of each object to the centroid of its group the mathematical representation of the k means goal is presented in eq 13 13 m i n j 1 k i 1 n x i j c j 2 where x i j c j is the distance between an observation x i j and the centroid cj of the group in this study the distance measure was euclidean and the choice in the number of groups was made with the aid of the silhouette coefficient kodinariya and makwana 2013 the result being the creation of five groups k means typically uses euclidean distance the partition of the weather stations in their respective groups is illustrated in fig 3 2 5 previous data as input previous meteorological data were used along with data of the current day as inputs for the machine learning models the addition of data from one to six previous days was evaluated the meteorological variables considered in the data from previous days were the same as those of the current day for example the temperature and relative humidity based models developed with two previous days used the maximum and minimum air temperature relative humidity and extraterrestrial radiation of the current day and of the two previous days the input combinations used are presented in table 2 2 6 performance comparison criteria the performance of the models was evaluated for each weather station with data from the period 2011 to 2015 5 years 316 799 observations the statistical indicators used include root mean square error rmse mean bias error mbe and coefficient of determination r2 according to the following equations 14 r m s e 1 n p i o i 2 15 m b e 1 n p i o i 16 r 2 p i p o i o p i p 2 o i o 2 2 where pi is the predicted value mm day 1 oi is the observed value mm day 1 p is the mean of the predicted values mm day 1 o is the mean of the observed values mm day 1 and n is the number of data pairs 3 results and discussion 3 1 temperature based models the penman monteith equation using only measured data on temperature pmt had the best performance among the original temperature based equations featuring a lower rmse mean value and higher r2 mean value fig 4 on the other hand the oudin equation oud had the worst performance the hargreaves samani hs and hamon ham equations exhibited intermediate performances both being similar to each other similarly almorox et al 2015 evaluating on a global scale 11 temperature based models for the estimation of monthly eto concluded that the hs model had the best overall performance later almorox et al 2018 compared the performance of the pmt and hs equations on a global scale concluding that the pmt equation produced better results the pmt equation also performed better than the hs equation in a study carried out by alencar et al 2015 in the state of minas gerais brazil it is important to emphasize that the pmt equation conserves part of its physical base which probably makes it more suitable for use under highly diverse climatic conditions as are characteristic in brazil after being calibrated all the equations had lower rmse mean values the r2 is not affected by calibration by linear regression the calibrated pmt and hs equations had the best performances exhibiting very similar rmse values the temperature based artificial neural network annt and support vector machine svmt had the same rmse and r2 mean values and when compared to the original and calibrated pmt and hs equations exhibited better performances when compared to the original pmt and hs equations the annt and svmt had 13 and 23 lower rmse mean values respectively and when compared to the calibrated equations they had 9 and 8 lower rmse mean values respectively this result demonstrates the typical ability of machine learning models to address complex tasks as reported in several studies in eto modeling antonopoulos and antonopoulos 2017 yassin et al 2016 the clustering strategy without previous data led to an 11 reduction of the rmse mean value for the annt and svmt in relation to their versions developed for brazil as a whole general fig 5 the r2 mean value had a slight increase for both models 4 when adding data from previous days as input the models developed for specific groups of stations clustering continued to have better performances but with less difference this behavior confirms the dependency between the performance of empirical models and the climatic characteristics of the region where they are developed and later applied maestre valero et al 2013 the use of data from previous days provided better performances for the annt and svmt models developed for brazil as a whole and for those developed for groups of weather stations for the general annt the rmse mean value was reduced by 10 when four previous days were used for the clustering annt the rmse mean value was reduced by 6 when two previous days were used the r2 mean value increased slightly in both cases the use of more than four and two previous days did not promote more performance gains for the general and clustering annt respectively for the general and clustering svmt the best performance was achieved using six and five previous days respectively it should be emphasized that for the annt and svmt the most expressive performance gain occurred when one previous day was used with decreasing performance gains occurring when adding more previous days for the annt the individual use of the clustering and data from previous days provided very similar performance gains with 11 and 10 reductions of rmse respectively and a 4 increase of r2 in both cases the best combination of these techniques clustering two previous days promoted a 16 reduction in rmse and 7 increase in r2 for the svmt the individual use of the clustering provided performance gains that were slightly better than those obtained using previous days individually in the first case rmse was reduced by 11 and in the second case it was reduced by 7 the best combination of these techniques clustering five previous days promoted a 16 reduction in rmse and 6 increase in r2 comparing the annt and svmt models both exhibited similar performances however the annt was slightly better when previous days were used especially for the general models 3 2 temperature and relative humidity based models similar to that observed for the temperature based models the penman monteith equation using only measured data on temperature and relative humidity pmrh had the lowest rmse and the highest r2 among the original equations evaluated fig 6 the valiantzas val equation had the second best performance among the original equations however the rmse mean value obtained by the val equation was 24 higher than that obtained by the pmrh equation the romanenko rom and schendel sch equations performed the worst with sch exhibiting the highest rmse and the lowest r2 although the rom and sch equations use temperature and relative humidity they performed worse than the temperature based equations evaluated kiafar et al 2017 also reported a poorer performance of sch compared with the hs equation this behavior is probably because the rom and sch equations do not use extraterrestrial radiation or photoperiod as input in contrast to the temperature based models evaluated the pmrh and val equations probably due to their partial physical bases were more suitable to estimate eto under different climatic conditions for the conditions evaluated the results are different from those obtained by valiantzas 2013 who reported better performance of the val equation compared to the pmrh equation after calibration the pmrh equation continued to exhibit the best performance however as opposed to the other equations rmse was not reduced the temperature and relative humidity based artificial neural network annrh and support vector machine svmrh exhibited similar performances surpassing the pmrh equation with approximately 15 reduction in rmse this result reinforces the superiority of machine learning models for the estimation of eto compared with conventional equations corroborating the findings of kumar et al 2011 and shiri et al 2014a the performance gains provided by the clustering in this scenario fig 7 were less significant than those observed for the temperature based models fig 5 especially for the annrh models the highest rmse reductions 8 were found for the svmrh models developed without data from previous days and with data from two previous days the use of relative humidity facilitates eto modeling providing a greater generalization capacity for the models and consequently more uniform performances in varied climates thus the development of models specific for regions with homogeneous climates produces less expressive performance gains in comparison to those obtained for temperature based models the addition of data from previous days as an input promoted a 10 reduction in rmse for the general annrh when using four previous days for the clustering annrh rmse was reduced by 5 when using two previous days the addition of previous days above the mentioned values did not promote more performance gains for the general svmrh the addition of four previous days promoted an 8 reduction in rmse for the clustering svmrh the addition of two previous days promoted a 5 reduction in rmse the r2 values exhibited only slight increases in both cases for the annrh the individual use of data from previous days provided slightly higher performance gains than those provided by the clustering employed individually the use of these strategies promoted 10 and 7 reductions in rmse and 4 and 3 increases in r2 respectively the best combination of these techniques clustering two previous days promoted a reduction in rmse and an increase in r2 that was approximately equal to those promoted by the use of previous days four days individually for the svmrh the performance gains obtained by the use of data from previous days and clustering individually were identical reducing rmse by 8 and increasing r2 by 3 the best combination of these techniques clustering two previous days promoted a reduction in rmse and an increase in r2 slightly higher than those promoted by the use of previous days four days individually comparing the annrh and svmrh annrh performed slightly better in the case of the general models however they exhibited the same performance when clustering was used 3 3 spatialization of the performance of the models the rmse and mbe values obtained for each weather station in both data availability scenarios by the best empirical equation best machine learning model best machine learning model clustering best combination of machine learning model data from previous days and best combination of machine learning model clustering data from previous days were spatialized in brazilian territory figs 8 and 9 in cases where the ann and svm had the same performance the ann was selected given the better overall performance of this algorithm in this study the spatialization of these indicators allows the efficiency of the models to be evaluated for different regions of brazil as well as the performance of the models to be correlated with the climatic characteristics of the places where they were applied in general the models that used relative humidity exhibited lower rmse values and lower mbe absolute values emphasizing the importance of this variable the calibrated hs pmrh and annt models were those that presented eto estimates with more evident overestimations and underestimations higher mbe absolute values in addition to higher rmse values the annrh had less expressive overestimations and underestimations with few points exhibiting high mbe absolute values the highest rmse values were typically found in northeastern brazil however it should be remembered that this region has the highest eto mean values fig 1 thus given the relation between rmse and the range of the analyzed variable the rmse values found in this region become proportionally similar to those obtained in other regions of the country in general the greatest underestimations of eto were observed in northeastern brazil this behavior is possibly explained by the low relative humidity high sunshine duration and high wind speed typical of this region fig 1 these characteristics result in increasing eto that is not entirely captured by the models evaluated since they do not incorporate these variables as inputs except for relative humidity used in part of the models the lack of solar radiation in this case sunshine duration and relative humidity can be partially suppressed by air temperature temperature range given the correlation between these variables allen et al 1998 hargreaves and allen 2003 on the other hand wind has a great effect on eto in dry and hot environments as in northeastern brazil given the greater removal of water vapor stored in the air allen et al 1998 3 4 overall evaluation among the equations evaluated the penman monteith equation with missing data pmt and pmrh showed the best overall performance in both data availability scenarios studied this behavior is possibly related to the physical basis of this equation partially conserved the empirical equations commonly reported in the literature are typically developed for specific or less extensive climatic conditions which limits their use maestre valero et al 2013 except for the pmrh equation calibration improved the mean performance of all the equations comparing the pmt and pmrh equations which were the best performing among the original equations evaluated in their respective data availability scenarios rmse was reduced by 23 and r2 was increased by 17 when using the pmrh equation considering the calibrated equations rmse was reduced by 18 and r2 was increased by 18 when using the original or calibrated pmrh equation which exhibited equal performance between them in relation to the calibrated hs which was the temperature based calibrated equation with the lowest rmse for the machine learning models developed in a conventional manner i e without clustering and previous days the use of relative humidity resulted in approximately 24 reduction in rmse and 16 increase in r2 similarly the models developed with clustering and the use of data from previous days also benefited from the addition of relative humidity as an input these results demonstrate the importance of relative humidity in eto modeling in brazil corroborating with the present study almorox et al 2015 concluded that temperature based models exhibit low correlation with eto estimated by the fao 56 pm equation in tropical climates given the role of other climatic variables such as vapor pressure deficit models developed for large areas in this case the entirety of brazil typically perform better in places resembling the average characteristics of the dataset used in the development of the models thus sites with more discrepant characteristics in relation to the average values of the dataset tend to present stronger overestimations or underestimations of eto shiri et al 2014a also reported the typical difficulty of developing regional models given the high nonlinearity contained in the data used for model training by segmenting brazil into homogeneous areas the models are developed and applied under conditions of lower climatic variability reaching higher and more uniform performances according to the results obtained in this study it was also verified that the smaller the number of meteorological variables used as input the lower the generalization capacity of the model which increases the dependency between the performance of the model and the climatic characteristics of its place of application thus in these cases there is greater benefit when the clustering technique is used by analyzing the weather station groups obtained in this study fig 3 based on previous knowledge of brazilian climate and köppen s climate classification for brazil alvares et al 2013 there was good agreement with the previously recognized climatic zones this behavior combined with the performance gain obtained by the models developed using this technique indicates k means to be a promising alternative for the delimitation of homogeneous climatic zones corroborating the findings of zhang and yan 2014 and zscheischler et al 2012 thus this approach can benefit future studies on the development and adjustment of eto models in addition to other types of studies the use of data from previous days as inputs proved to be a satisfactory strategy for the development of machine learning models promoting considerable performance gains especially when the clustering technique was not employed this approach also has the potential to benefit the development of other types of models such as empirical equations or other artificial intelligence models the combined use of clustering and data from previous days promoted more expressive performance gains compare with the individual use of previous days only for the temperature based models despite the potential of both strategies the individual use of previous days has the advantage of producing models with greater generalization capacity allowing a single model to be applied in any region of brazil this higher generalization capacity provides the models with a greater ability to address extreme events or atypical climatic behavior given the greater diversity of data used in their development thus even that the combination of these techniques has promoted some performance gains given the relatively low performance improvement the use of general models with data from previous days can become more advantageous comparing the machine learning models the ann models were determined to be slightly better than the svm exhibiting lower rmse values mainly when previous days were used for the models developed without previous days and clustering the ann and svm models exhibited equivalent performance these results are in contrast with kisi and çimen 2009 and wen et al 2015 who found better performance of svm than ann however there are many factors involved with the performance of ann and svm models such as the ann training algorithm used and the settings of the hyperparameters of the models regarding the reliability of machine learning models pereira et al 2015 warned that many trends defined by machine learning models remain empirical and may not translate well in time and space however the present study explores models developed with a large amount of data that are variant in space and time which confers greater reliability to the models obtained 4 conclusions ann svm and empirical equations were evaluated for the estimation of eto in the entirety of brazil using measured data on temperature and relative humidity or only temperature two little explored approaches were employed i the definition of groups of weather stations with similar characteristics by the k means clustering algorithm and ii the use of previous meteorological data as input for the models the groups of weather stations were used to develop models specific for each group the models were also developed in a conventional manner i e without data from previous days and trained with pooled data from all of brazil the penman monteith equations with missing data pmt and pmrh exhibited the best overall performance among the calibrated and original equations in their corresponding data availability scenarios after calibration better results were obtained for approximately all equations except for the pmrh equation the calibrated hs equation exhibited a performance equivalent to the calibrated pmt equation when compared to the machine learning models the equations were surpassed by the models developed in a conventional way and under the strategies of clustering and use of data from previous days the clustering and the use of data from previous days provided performance gains when used individually and when combined the individual use of data from previous days had the advantage of producing models with greater generalization capacity since they are trained with more diverse data and can be used in any region of brazil for the temperature based models the best performance was obtained by the ann developed with the clustering strategy and the use of data from two previous days however due to the similar performance and greater generalization capacity the ann developed without clustering and with the use of data from four previous days is recommended for the temperature and relative humidity based models the ann developed with data from four previous days was the best option the use of relative humidity in addition to temperature increased the generalization capacity of the models and provided performance gains for all models evaluated representing an option for improving the estimation of eto at a low additional cost finally clustering and the use of data from previous days could be applied in future studies to develop eto models in other regions and using different machine learning algorithms special attention should be given to regional models due to their key role in places where there are no data available to develop local models declaration of interests none acknowledgments the authors wish to thank the national council for scientific and technological development cnpq for providing a scholarship to the first author and the brazilian national institute of meteorology inmet for the meteorological data used this study was financed in part by the coordenação de aperfeiçoamento de pessoal de nível superior brasil capes finance code 001 
6609,floods are one of the most devastating natural disasters especially in the midstream plain area of the huaihe river basin hrb in china where it is densely populated this region has suffered from serious backwater flood problems due to its topography and geomorphology additional storage space is critical for this region in order to control flood the middle reach of the huaihe river is a coal rich region the large subsidence areas caused by coal mining may help reduce the issue of insufficient flood storage space and therefore evaluation of the flood storage capacity in the subsidence areas becomes necessary a distributed coupled surface water groundwater model modcycle was redeveloped to simulate the interaction between the rivers the water in the subsidence areas and groundwater the model was used to simulate maximum flood storage capacity in the subsidence areas and the ability to reduce flood peaks two scenarios were created for land subsidence conditions in 2010 and 2030 where typical flood events in 2003 were used it is revealed that for the 2010 scenario there was flood overflow even with the maximum storage space used whereas for the 2030 scenario the subsidence areas could completely contain the flood water and therefore eliminate the backwater flood problem compared with the 2010 subsidence scenario the water levels in the depressions can also be significantly reduced in the 2030 subsidence scenario our results from an integrated hydrological modeling s perspective suggest that using the subsidence areas caused by coal mining for flood storage has the potential to alleviate the problem of backwater flood in the study area and in the meantime provides an alternative management approach for handling the subsidence areas keywords flood storage and water logging control coal mining subsidence area distributedhydrological model backwater flood huaihe river 1 introduction floods are one of the most serious natural disasters in the world which lead to heavy losses particularly in densely populated areas barredo 2007 jonkman and vrijling 2008 deb et al 2018 in order to alleviate this kind of disasters a number of useful measures have been taken such as flood forecasting risk management and assessment etc brian et al 2007 hunter et al 2007 zevenbergen et al 2008 cloke and pappenberger 2009 merz et al 2010 hapuarachchi et al 2011 kundzewicz et al 2010 the huaihe river basin hrb located in east of china is a densely populated area where floods are frequent in the low plain areas of the middle reaches of the hrb the water level along the main channel is often higher than the water level in the tributaries during flood season due to its special topography and drainage pattern zhou et al 2002 this causes the flood water in the tributaries cannot be discharged to the main channel in a timely manner and thereby forms a so called backwater flood a practical way to alleviate the backwater flood problem is through flood storage in the affected areas where the local lakes play an important role however the existing lakes in the middle hrb are not sufficient to meet the demand of increased storage capacity in years where large floods are frequent the middle reach of the hrb is a coal rich area where intensive coal mining has results in numerous coal mining subsidence areas the capacity of the subsidence region has reached 314 million m3 and the area of subsided land is about 108 3 km2 in 2010 cumt and the huainan mining group 2013 the previous management strategy for the coal mining subsidence areas is by backfilling the subsided land the restoration approach however this method is not very efficient since the subsidence areas are usually located in very deserted places and there is lack of backfilling material as a result the land restoration rate is only 6 since the middle hrb suffers from both the backwater flood problems and inefficient land restoration of the coal mine subsidence it is an alternative management approach to utilize the subsidence areas for flood storage in order to propose this new management plan it is necessary to evaluate the flood storage and drainage capacity of the subsidence area however it is known that in the middle hrb the interactions between rivers groundwater natural lakes and subsidence areas are complicated previous studies have shown that distributed hydrological model is an effective tool in simulating floods bell et al 2009 rozalis et al 2010 however commonly used model codes have made significant simplifications when dealing with surface depressions for example swat and she only generalizes the depression areas to water storage nodes on the main channel network and thus cannot simulate water level variations while accounting for the geometry of the depressions neitsch et al 2011 abbott et al 1986a b besides the simulation of the exchange between the depressions and the groundwater also lacks detailed description neitsch et al 2011 abbott et al 1986a b several models have been developed particularly to cope with flood of lakes ponds wetlands and reservoirs weng et al 2003 chen et al 2007 nakayama and watanabe 2008 siviglia et al 2009 camnasio 2011 chen et al 2015 however these models lack the description of runoff generation and confluence process at large basin scale moreover the phenomenon of the so called backwater flood has not been given enough attention in the existing research in the present study a relatively new model code modcycle lu et al 2012 2014a is used as the research tool the model is further developed based on the previous version where new modules are added concerning the bottom geometry of the depressions the exchange of surface depressions and the underlying groundwater and the backwater flood effect the newly added features make the modcycle code an ideal instrument for analyzing the nested water management problem in the middle hrb therefore the objectives of our study is to find out the maximum flood storage capacity in the subsidence areas and to what extent the use of the subsidence areas can help reduce water level of flood 2 study area and subsidence area 2 1 study area the study area is located in the north shore of the middle reaches of the hrb fig 1 and is surrounded by the huaihe river yinghe river and cihuaixin river with a total area of 4013 km2 the river system in the study area flows to the southeast into the huaihe river thereby forming a relatively independent confluence system the average annual precipitation in the study area is between 438 and 1618 mm during the period 1954 and 2010 the average annual precipitation from 2001 to 2010 is 965 mm precipitation is temporally uneven during the year where the flood season june to september accounts for 50 80 of the total annual precipitation the hrb is located in the climate transition zone between north and south china where the climate regime is complex and the probability of extreme rainfall is high many tributaries in the basin have a fan shaped network structure allowing flood collection to be rapid during the flood season the water level along the main channel rapidly rises up due to the slow water flow velocity therefore backwater flood is formed since the tributaries cannot discharge into the mainstream the riverbed lakes which are prevalent in the lower reaches of the tributaries of the huaihe river are products of the backwater flood such as the huajia lake hjl chengbei lake cbl and nihe lake nhl in the lower reaches of the main tributaries of the xifei river xfr yongxing river yxr and nihei river nhr as shown in fig 1 2 2 subsidence areas the distribution of coal mining subsidence areas in 2010 and the prediction in 2030 are shown in fig 2 according to china university of mining and technology cumt and the huainan mining group 2013 the subsidence area in 2010 is divided into seven zones xieqiao xq zhangji zj guqiao gq dingjixi djx dingjidong djd panyipansan pyps and panbei pb which has a total area of 108 3 km2 a maximum depth of 7 6 m and a total subsidence volume of 314 million m3 by 2030 the subsidence area will be further expanded and merged to form five separate subsidence areas xifeiriver1 xfr1 xifeiriver2 xfr2 yongxingriver1 yxr1 yongxingriver2 yxr2 and niheihe nhh which would have a total area of 305 4 km2 a maximum depth of 14 5 m and a total subsidence volume of 1 14 billion m3 in this paper since the flood storage and drainage capacity of these lakes and subsidence areas are not easy to divide these should be considered as a whole and collectively referred to as depression 3 method and data 3 1 model the hydrological model developed in this study is based on the distributed coupled surface water groundwater model modcycle modcycle is physically based and has been successfully applied in various case studies including the hrb zhang et al 2012a b lu et al 2012 2014a b in order to evaluate the flood storage capacity and the drainage capacity of the depressions modcycle is modified in order to better simulate the interaction between rivers water in depressions and groundwater wang et al 2017 the water balance calculation of a depression is closely related to the groundwater level so a new module which is capable of simulating the depression was added into modcycle in addition the improved model also considers the influence of main channel water level which would affect how the depression is discharged this would allow to compute of the storage and detention of flood volume in the study area the following sections describe mostly the flood storage and waterlogging control in the depressions while other details regarding the modcycle code can be found in lu et al 2012 li et al 2016 and wang et al 2017 3 1 1 overall water balance equation in a depression generally there may be a number of confluent channels in the upstream of a single depression the discharge in the downstream is generally controlled manually through outlets and the depression is divided into a water area and a no water area as shown in fig 3 during the simulation the water area and the no water area in a dynamic reciprocal relationship the size of each area depends on the change of the water s edge and the sum of the water area and the no water area equals the area of the depression assuming that the water level is equal at any point in the depression fig 4 1 a t a w a nw where a t is the total area or range of the depression which is fixed during the simulation m2 a w is the average area of the water area m2 a nw is the average area of the non water area m2 for a single depression the water balance equation in arbitrary period can be described as 2 v n v n 1 δ t n p q up r nw g gw in g nw in δ t n e g gw out w q dr in the equation there are nine water flux components related to the water balance in the water area of the depression as shown in fig 3 wherein n is the number of the current simulation period v n and v n 1 are the water volumes of the depression at the closing and beginning of the simulation period m3 δ t n is the time step for the current simulation period during the simulation a daily time step is adopted δ t n 1 d p q up r nw g gw in and g nw in are respectively the water area precipitation m3d 1 the incoming flow from the upper reaches of the depression m3d 1 the runoff producing flow of the non water area the recharge flow effused from the groundwater to the water area m3d 1 and the groundwater flow effused from the non water area flows to the water area in each time step m3d 1 e g gw out and w are respectively the water surface evaporation m3d 1 the seepage into the aquifer of the water area m3d 1 and the water withdrawal in each time step m3d 1 q dr is the discharge from the depression in each time step through the sluices and pumping stations m3d 1 this study only gives the calculation principle of q dr 3 1 2 for other calculation principles please see the reference wang et al 2017 3 1 2 specific items in the water balance equation within a time step one day the calculation of the precipitation p m3d 1 and evaporation e m3d 1 of the depression on the water areas are calculated by multiplying the measured daily value by the water area of the day the incoming flow from the upper rivers of the depression q up m3d 1 is the total water of all the rivers into the depression which derived from the hydrologic simulation of the modcycle the runoff producing flow of the non water area r nw m3d 1 is calculated by the scs curve number equation neitsch et al 2011 the water withdrawal w m3d 1 from the depression is reserved for other usage which is beyond the scope of the present study the interaction between the depression and the groundwater aquifer including g gw in g nw in and g gw out is calculated by darcy formula based on the average water level of the depression and the groundwater level at each grid cell the detailed calculation process can be found in the reference wang et al 2017 the following focuses on the calculation of the downstream discharge of the depression the discharge of the depression is calculated in three cases and the depression discharge equations were established eqs 3 4 and 5 respectively when there are only sluices in the downstream of the depression and the water level in the downstream river has no effect on the discharge of the depression the formula for depression discharge is as follows 3 q dr min max q s v n v max v n v ctl h l h max q dr min q s v n v ctl h max h l h ctl q dr 0 h l h ctl where q dr is the discharge of the depression to the downstream on day m3d 1 v n is the initial storage capacity of the depression on the day before discharge m3 v max is the storage capacity corresponding to the maximum allowable water level in the depression m3 h l is the average water level of the depression on the day before discharge m h max is the allowable highest water level in the depression m h ctl is the discharge control water level of the depression m v ctl is the storage capacity of the depression corresponding to the h ctl q s is the discharge of the sluice when water depth is h l m3d 1 the discharge of depression of the sluice q s is calculated using the conventional weir equation swamee 1988 for the depressions without sluices downstream such as the depression formed by coal mining the outflow is also calculated by the conventional weir equation wherein the outflow elevation is the river bottom elevation of the downstream river channel and the outflow capacity is the discharge capacity of the downstream river channel when there are only sluices in the downstream of the depression and the water level in the downstream river affect the discharge of the depression the formula for depression discharge is as follows 4 q dr v n v max h l h max h e h max q dr min max q s v n v max v n v e h l h max h e q dr min q s v n v ctl h max h l h ctl h ctl h e q dr min q s v n v e h max h l h e h e h ctl q dr 0 h l h ctl o r h l h e where h e is the external water level m v e is the storage capacity of the depression corresponding to the h e when there are not only sluices but also pumping stations downstream of the depression the formula for depression discharge is as follows 5 q dr min max q p v n v max v n v ctl h e h l h max q dr min max q s q p v n v max v n v ctl h l h max h l h e q dr min q p v n v ctl h max h l h ctl h e h l q dr min q s q p v n v ctl h max h l h ctl h e h l q dr 0 h l h ctl where q p is the drainage capacity of the pump station m3d 1 when there are not only sluices but also pumping stations downstream of the depression the control strategy for the discharge is that the depression does not need to be discharged q dr 0 when the average water level of the depression h l is lower than the discharge control level h ctl when the average water level of the depression h l is located between the discharge control water level h ctl and the maximum allowable water level h max and the average water level of the depression h l is higher than the external water level h e the sluice and pumping station together discharge the water when the average water level of the depression h l is located between the discharge control water level h ctl and the maximum allowable water level h max and the average water level of the depression h l is below the external water level h e the sluice will not be able to drain and only the pumping station can perform the forced drainage when the average water level of the depression h l is higher than the maximum allowable water level h max and the average water level of the depression h l is higher than the external water level h e the sluice and the pumping station work together to remove the excess water exceeding the maximum allowable storage capacity when the average water level of the depression h l is higher than the maximum allowable water level h max and the external water level h e is higher than the average water level of the depression h l only the pumping station can discharge the water 3 1 3 coupling of surface water and groundwater in a depression although the depression has its own water balance equation some water balance items are related to the surface water and groundwater the hydraulic connection between the depression and the river system is mainly reflected by the confluence of the upstream river channel to the depression and the discharge from the depression to the downstream river channel therefore the relationship between the depression and the surrounding river channels is established then the water exchange between the river channel and the depression can be calculated by the simulation of basin runoff and confluence and the discharge of the depression in the coupling of the water in the depression and groundwater the depression grid cells belongs to the grid cells of the groundwater flow model fig 5 shows the logical processes for operating the revised modcycle code it is noted that fig 5 only shows the computational processing part of the module while the input data processing and statistical output parts of the module are not included it describes what happens in of a single depression and the processing of multiple depressions will be a repetition of the same process 3 2 data hydrological and meteorological data from 2001 to 2010 are used to developed the model details can be seen in lu et al 2016a and wang et al 2017 the following focuses on data related to flood storage and waterlogging control in the depressions 3 2 1 typical flood to be simulated according to the measured rainstorm in the study area and the measured flood volume and water level fluctuation in the mainstream of the huaihe river lu et al 2016b the six floods with the greatest degree of flood damage from 1951 to 2010 were selected which occurred in 1954 2003 1991 2007 1968 and 1956 in the order of large to small among these the flood that occurred in 2003 is the second largest flood in history and its data are available after overall consideration the flood in 2003 was selected as a typical flood to evaluate the flood storage and waterlogging control in the depression in 2010 and 2030 3 2 2 area and storage capacity of depression the arcgis tool was used to extract the area of each depression within the distribution in the study area then according to the relationship between the water level and storage capacity and the relationship between the water level and the water surface area the maximum storage capacity of each depression was calculated table 1 3 2 3 discharge control parameters of each depression the relative relationship between the water level of the huaihe river and the water level of its tributaries is the key to study the flood storage and waterlogging control in the depression if the water level of the huaihe river is lower than the water level of the tributaries in the study area the discharge sluice of the depression in the lower reaches of the tributary of the huaihe river is free to discharge water when the water level of the huaihe river is higher than that of the tributaries in the study area the discharge sluice will fail completely and only the pumping station can perform the forced drainage the water levels of the depression in the lower reaches of the tributaries in the study area can be calculated through the model while the water level of the huaihe river is required to be entered since the discharge of the depressions in the lower reaches of the tributaries are also subject to their own characteristic water levels sluices and pumping stations and other conditions it is also necessary to know the maximum allowable water level of each depression discharge control water level discharge capacity design flow of a sluice drainage capacity of a pumping station and other discharge control parameters in different level years the main discharge control parameters for each depression in different level years are shown in table 2 4 results the flood disasters in the study area are characterized by the so called backwater flood and determining whether the tributary channels have enough storage and detention capacity is the key to tackle this problem therefore in assessing flood storage and waterlogging control in the study area this study evaluated the amount of flood volume stored during the backwater flood that is the storage capacity at the maximum water level during the flood minus the storage capacity at the starting water level of the flood this study evaluated and calculated the amount of flood water in depressions that were stored during the backwater flood in the 2010 and 2030 subsidence scenarios then the reduction effect of the water levels during the backwater flood were compared in two subsidence scenarios thereby providing certain reference for the long term management and utilization of coal mining subsidence areas 4 1 simulation of surface water and groundwater the hydrological model of the study area from 2001 to 2010 was evaluated and validated from the surface water level and groundwater level the entire simulation process is divided into three phases the first phase is from 2001 to 2002 which is the preheating period the second phase is from 2003 to 2006 which is the calibration period the third phase is from 2007 to 2010 this stage is the validation period the measured data from a temporary water level observation station and six shallow groundwater observation wells in the study area are used for model calibration and validation the position of these sites are shown in fig 1 and the results show that the simulation has achieved good results lu et al 2016a wang et al 2017 according to the purpose of this study the water levels of the rivers and flow are critical calibration targets simulated water levels and flow are basis for flood analysis and evaluation of flood storage and waterlogging control in subsidence areas this study only shows the calibration and validation process of the water level of the xfr and one of the groundwater observation wells as shown in fig 6 the xfr has no fixed hydrological station and the only measured data are the water level data in flood period of 2003 and 2007 which can be used for model calibration and validation separately the position of the two sites used for display are shown in fig 1 as shown in fig 6 the model achieves relatively high accuracy in simulating the actual flood water level which is beneficial to the evaluation of flood storage and waterlogging control in depressions on the other hand because of the limitation of the simulation scale the model cannot simulate the groundwater depth of a single well and can only simulate the average groundwater depth within a certain area i e one grid cell of the groundwater model so it is difficult to obtain a precise fit with the measured processes of the groundwater depth but the periodicity and amplitude of groundwater depth fluctuations still could supports the simulation results the water balance simulation of soil water system surface water system and groundwater system in the study area from 2003 to 2010 is shown in table 3 it can be seen that the water balance errors of the three systems are all within a reasonable range in addition two important hydrological parameters affecting the hydrological cycle simulation are compared with the previous research results including the runoff coefficient and the recharge coefficient the runoff coefficient is the key to hydrological cycle savenije 1996 the average annual precipitation in the hrb is about 894 mm and the average annual runoff is about 230 mm zhang et al 2012a b it can be calculated that the average annual runoff coefficient is about 0 26 modcycle simulation shows that the total surface runoff of the study area from 2003 to 2010 is about 1 2 billion m3 and the total surface precipitation is about 4 billion m3 the average annual runoff coefficient of the model simulation is calculated to be about 0 3 which is basically consistent with the previous research result in terms of recharge coefficient some scholars have calculated the average annual rainfall recharge coefficient of the hrb by lysimeter measurement and soil moisture model and its value is 0 25 chen et al 2008 modcycle simulation shows the average annual soil infiltration in the study area from 2003 to 2010 is about 1 016 billion m3 and the average annual surface precipitation is 4 billion m3 the recharge coefficient of the model simulation is calculated to be about 0 25 which is consistent with the previous research result it should be noted that the hydrological cycle simulations in depressions in 2010 and 2030 were both based on the basic data from 2001 to 2010 in order to establish the same basis for comparison of the storage and detention capacity of the same flood disasters in different subsidence scenarios 4 2 evaluation of flood storage and waterlogging control effect on typical floods in these two subsidence scenarios the flood water in each tributary confluence zone was finally imported into the hjl cbl and nhl respectively then this was allowed to flow or was pumped into the huaihe river through its own sluices or pumping stations after being stored and detained by the lakes therefore the inversion calculation of water amounts for typical floods during the flood seasons was carried out separately according to the flood incoming processes in these three lakes fig 7 show the change process line of water levels internal water of hjl cbl and nhl in different subsidence scenarios during the typical backwater flood in 2003 as well as the change process line of water levels external water of the huaihe river at the corresponding estuary to the huaihe river and the incoming process of the cumulative flood volume the simulation results in the 2030 level year are obtained using the 2030 subsidence terrain to replace the 2010 subsidence terrain in case other input data remained unchanged the evaluation results are shown in table 4 according to statistics in the 2010 subsidence scenario the total accumulated water volume during the backwater flood period caused by the typical flood in 2003 in the study area was 765 million m3 the pumping station pumped 253 million m3 and the flood volume stored in the subsidence area was 389 million m3 from the point of view of flood storage and waterlogging control the storage capacity and its distribution in the depression of the study area in 2010 could not cope with the typical flood in 2003 which was mainly due to the overflow of water in the xfr confluence zone that is the lack of storage and detention space the overflow volume is 85 million m3 in the 2030 subsidence scenario the total accumulated water volume during the backwater flood period caused by the typical flood in 2003 was 958 million m3 which is 193 million m3 greater than the subsidence scenario in 2010 and this is mainly due to the decline in water level in the xfr confluence zone the increased time of the backwater flood will lead to an increase in the amount of incoming water the pumping station pumped 375 million m3 which was 122 million m3 more than that in the 2010 subsidence scenario the sluice will discharge 51 million m3 which is 51 million m3 more than that in the 2010 subsidence scenario the water stored mainly by the storage capacities of the depressions will be 548 million m3 which is 159 million m3 more than that in the 2010 subsidence scenario from the point of view of waterlogging control the storage capacity and its distribution in the study area in 2030 will be able to cope with the typical floods in 2003 and there will be no overflow phenomenon in all the confluence zones it shows that in 2030 with the increasing effect of the storage capacity of the coal mining subsidence areas the study area has the basic ability to cope with the typical flood in 2003 4 3 contrast analysis of the water level reduction effect of a typical backwater flood one of the most important indicators of flood risk during the flood season is the internal water level the water levels of lakes in the lower reaches of the huaihe river tributaries the lower the water level during the flood season is the lower the risk of flooding in the study area will be this section compares the internal water levels in these two subsidence scenarios and analyzes the reduction effect of the internal water levels under the 2030 subsidence scenario compared with those under the 2010 subsidence scenario fig 8 based on the simulation in both scenarios the results of the water level change in each lake are summarized in table 5 from the comparison of results in the 2030 subsidence scenario hjl and nhl would benefit from the expansion of the coal mining subsidence areas and the increased adjustable storage capacity the water level during the flood season would obviously reduce among these the water level of hjl obviously reduced and the water level in a typical flood year in 2003 is 0 59 m and the flood level of the nhl drop by 0 41 m cbl is special wherein in the 2030 subsidence scenario the flood level will rise the reason is that the flood peak of the cbl occurred in the backwater flood the sluice cannot drain away water only the pumping station can pump water and in the 2030 subsidence scenario due to the merger of part of the xfr confluence zone the yxr confluence zone increased affected by the confluence pattern the amount of the incoming water of the cbl in the downstream is greater than that in the 2010 subsidence scenario therefore the water level in the 2030 subsidence scenario rises in a short period 5 discussion and conclusions backwater flood is a serious problem that frequently occur in the middle reaches of the hrb hence getting sufficient flood storage and detention space is of great importance for flood prevention and waterlogging control in the region the large subsidence areas formed by coal mining and its annual expansion can effectively increase the potential storage and detention space in this region a distributed surface water groundwater model was developed based on the modcycle code and was used for simulation of the entire hydrological cycle in the middle hrb with special attention given to the water balance at the subsidence areas the calibrated model was used to simulate the water levels and flood storage volumes of depressions two scenarios were created for analyzing subsidence conditions in 2010 and 2030 respectively the flood events in 2003 were selected to evaluate the capacity of flood storage and waterlogging control in these two scenarios simulation results showed that for the 2010 subsidence condition a great amount of overflow was generated in response to the 2003 flood however the subsidence condition in 2030 was able to contain typical floods as in 2003 as for the reduction of water level in the lakes connecting to the main streams during flood season the 2030 scenario can stabilize the water levels of the lakes connecting to the huaihe river to a more reasonable degree except for cbl comparing to the 2010 subsidence scenario in addition this study revealed that although the storage capacity of the coal mining subsidence increases with time the depressions still remain scattered as shown in fig 2 since connected depressions may be able to increase the overall storage capacity zhou et al 2014 chang et al 2017 it is suggested that the coal mining subsidence areas should be connected through artificial channels in order to maximize their functionality at present the management strategies for the subsidence areas have two types transformation and reclamation krümmelbein et al 2012 zipper et al 2013 transformation is mainly to construct a new ecological environment such as a park or wetland which is applicable to places with little pressure on land and population krümmelbein et al 2012 on the other hand reclamation refers to restoring the lands to its original condition by physical chemical and or biological means sheoran et al 2010 however both of these two methods require substantial amount of manpower materials and financial resources it is rather an inexpensive way to utilize the subsidence areas in its natural form the study area historically suffered from serious backwater flood problems converting the coal mining subsidence areas into flood storage and detention areas has the potential not only to reduce local flood risks but also to provide a new alternative for utilizing the subsidence areas in a meaningful way our research from a joint surface water groundwater management perspective shares valuable first hand experience on utilizing coal mining subsidence areas which can be useful to regions with similar problems in other parts of the world although we have demonstrated that it is a feasible way to develop the coal mining subsidence areas into flood storage and detention areas it also needs to mention that such kind of management strategy may have a serious impact on the ecological environment if the flood is stored in the coal mining subsidence area for too long the water quality will deteriorate alhamed and wohnlich 2014 nieva et al 2018 for example the ph of the water may decrease and the concentration of heavy metals may increase which not only reduces the usability of the stored flood water but may also cause pollution to the groundwater and damage to the surrounding ecological systems moyéet al 2017 barkett and akün 2018 nieva et al 2018 therefore it is critical to secure water quality at the coal mining subsidence areas which will be one of the main research tasks in our next stage at present there is much research focusing on abandoned mine water treatment such as remediation of heavy metal contaminated groundwater originated from abandoned mine using lime and calcium carbonate lee et al 2007 and the remediation of acid mine drainage fallavena et al 2018 which can provide useful insights for our future work declaration of interests none acknowledgements this research was supported and funded by the national key research and development program of china grant no 2016yfc0401404 the project of representative achievements of state key laboratory of simulation and regulation of water cycles in river basins grant no skl2018cg01 the national science fund for distinguished young scholars grant no 51625904 and the national natural science foundation of china grant no 51509264 the authors would like to thank huainan mining industry group co ltd and china university of mining and technology who provided the subsidence data and some other data and local water departments who provided a lot of valuable hydrologic data appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 03 044 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6609,floods are one of the most devastating natural disasters especially in the midstream plain area of the huaihe river basin hrb in china where it is densely populated this region has suffered from serious backwater flood problems due to its topography and geomorphology additional storage space is critical for this region in order to control flood the middle reach of the huaihe river is a coal rich region the large subsidence areas caused by coal mining may help reduce the issue of insufficient flood storage space and therefore evaluation of the flood storage capacity in the subsidence areas becomes necessary a distributed coupled surface water groundwater model modcycle was redeveloped to simulate the interaction between the rivers the water in the subsidence areas and groundwater the model was used to simulate maximum flood storage capacity in the subsidence areas and the ability to reduce flood peaks two scenarios were created for land subsidence conditions in 2010 and 2030 where typical flood events in 2003 were used it is revealed that for the 2010 scenario there was flood overflow even with the maximum storage space used whereas for the 2030 scenario the subsidence areas could completely contain the flood water and therefore eliminate the backwater flood problem compared with the 2010 subsidence scenario the water levels in the depressions can also be significantly reduced in the 2030 subsidence scenario our results from an integrated hydrological modeling s perspective suggest that using the subsidence areas caused by coal mining for flood storage has the potential to alleviate the problem of backwater flood in the study area and in the meantime provides an alternative management approach for handling the subsidence areas keywords flood storage and water logging control coal mining subsidence area distributedhydrological model backwater flood huaihe river 1 introduction floods are one of the most serious natural disasters in the world which lead to heavy losses particularly in densely populated areas barredo 2007 jonkman and vrijling 2008 deb et al 2018 in order to alleviate this kind of disasters a number of useful measures have been taken such as flood forecasting risk management and assessment etc brian et al 2007 hunter et al 2007 zevenbergen et al 2008 cloke and pappenberger 2009 merz et al 2010 hapuarachchi et al 2011 kundzewicz et al 2010 the huaihe river basin hrb located in east of china is a densely populated area where floods are frequent in the low plain areas of the middle reaches of the hrb the water level along the main channel is often higher than the water level in the tributaries during flood season due to its special topography and drainage pattern zhou et al 2002 this causes the flood water in the tributaries cannot be discharged to the main channel in a timely manner and thereby forms a so called backwater flood a practical way to alleviate the backwater flood problem is through flood storage in the affected areas where the local lakes play an important role however the existing lakes in the middle hrb are not sufficient to meet the demand of increased storage capacity in years where large floods are frequent the middle reach of the hrb is a coal rich area where intensive coal mining has results in numerous coal mining subsidence areas the capacity of the subsidence region has reached 314 million m3 and the area of subsided land is about 108 3 km2 in 2010 cumt and the huainan mining group 2013 the previous management strategy for the coal mining subsidence areas is by backfilling the subsided land the restoration approach however this method is not very efficient since the subsidence areas are usually located in very deserted places and there is lack of backfilling material as a result the land restoration rate is only 6 since the middle hrb suffers from both the backwater flood problems and inefficient land restoration of the coal mine subsidence it is an alternative management approach to utilize the subsidence areas for flood storage in order to propose this new management plan it is necessary to evaluate the flood storage and drainage capacity of the subsidence area however it is known that in the middle hrb the interactions between rivers groundwater natural lakes and subsidence areas are complicated previous studies have shown that distributed hydrological model is an effective tool in simulating floods bell et al 2009 rozalis et al 2010 however commonly used model codes have made significant simplifications when dealing with surface depressions for example swat and she only generalizes the depression areas to water storage nodes on the main channel network and thus cannot simulate water level variations while accounting for the geometry of the depressions neitsch et al 2011 abbott et al 1986a b besides the simulation of the exchange between the depressions and the groundwater also lacks detailed description neitsch et al 2011 abbott et al 1986a b several models have been developed particularly to cope with flood of lakes ponds wetlands and reservoirs weng et al 2003 chen et al 2007 nakayama and watanabe 2008 siviglia et al 2009 camnasio 2011 chen et al 2015 however these models lack the description of runoff generation and confluence process at large basin scale moreover the phenomenon of the so called backwater flood has not been given enough attention in the existing research in the present study a relatively new model code modcycle lu et al 2012 2014a is used as the research tool the model is further developed based on the previous version where new modules are added concerning the bottom geometry of the depressions the exchange of surface depressions and the underlying groundwater and the backwater flood effect the newly added features make the modcycle code an ideal instrument for analyzing the nested water management problem in the middle hrb therefore the objectives of our study is to find out the maximum flood storage capacity in the subsidence areas and to what extent the use of the subsidence areas can help reduce water level of flood 2 study area and subsidence area 2 1 study area the study area is located in the north shore of the middle reaches of the hrb fig 1 and is surrounded by the huaihe river yinghe river and cihuaixin river with a total area of 4013 km2 the river system in the study area flows to the southeast into the huaihe river thereby forming a relatively independent confluence system the average annual precipitation in the study area is between 438 and 1618 mm during the period 1954 and 2010 the average annual precipitation from 2001 to 2010 is 965 mm precipitation is temporally uneven during the year where the flood season june to september accounts for 50 80 of the total annual precipitation the hrb is located in the climate transition zone between north and south china where the climate regime is complex and the probability of extreme rainfall is high many tributaries in the basin have a fan shaped network structure allowing flood collection to be rapid during the flood season the water level along the main channel rapidly rises up due to the slow water flow velocity therefore backwater flood is formed since the tributaries cannot discharge into the mainstream the riverbed lakes which are prevalent in the lower reaches of the tributaries of the huaihe river are products of the backwater flood such as the huajia lake hjl chengbei lake cbl and nihe lake nhl in the lower reaches of the main tributaries of the xifei river xfr yongxing river yxr and nihei river nhr as shown in fig 1 2 2 subsidence areas the distribution of coal mining subsidence areas in 2010 and the prediction in 2030 are shown in fig 2 according to china university of mining and technology cumt and the huainan mining group 2013 the subsidence area in 2010 is divided into seven zones xieqiao xq zhangji zj guqiao gq dingjixi djx dingjidong djd panyipansan pyps and panbei pb which has a total area of 108 3 km2 a maximum depth of 7 6 m and a total subsidence volume of 314 million m3 by 2030 the subsidence area will be further expanded and merged to form five separate subsidence areas xifeiriver1 xfr1 xifeiriver2 xfr2 yongxingriver1 yxr1 yongxingriver2 yxr2 and niheihe nhh which would have a total area of 305 4 km2 a maximum depth of 14 5 m and a total subsidence volume of 1 14 billion m3 in this paper since the flood storage and drainage capacity of these lakes and subsidence areas are not easy to divide these should be considered as a whole and collectively referred to as depression 3 method and data 3 1 model the hydrological model developed in this study is based on the distributed coupled surface water groundwater model modcycle modcycle is physically based and has been successfully applied in various case studies including the hrb zhang et al 2012a b lu et al 2012 2014a b in order to evaluate the flood storage capacity and the drainage capacity of the depressions modcycle is modified in order to better simulate the interaction between rivers water in depressions and groundwater wang et al 2017 the water balance calculation of a depression is closely related to the groundwater level so a new module which is capable of simulating the depression was added into modcycle in addition the improved model also considers the influence of main channel water level which would affect how the depression is discharged this would allow to compute of the storage and detention of flood volume in the study area the following sections describe mostly the flood storage and waterlogging control in the depressions while other details regarding the modcycle code can be found in lu et al 2012 li et al 2016 and wang et al 2017 3 1 1 overall water balance equation in a depression generally there may be a number of confluent channels in the upstream of a single depression the discharge in the downstream is generally controlled manually through outlets and the depression is divided into a water area and a no water area as shown in fig 3 during the simulation the water area and the no water area in a dynamic reciprocal relationship the size of each area depends on the change of the water s edge and the sum of the water area and the no water area equals the area of the depression assuming that the water level is equal at any point in the depression fig 4 1 a t a w a nw where a t is the total area or range of the depression which is fixed during the simulation m2 a w is the average area of the water area m2 a nw is the average area of the non water area m2 for a single depression the water balance equation in arbitrary period can be described as 2 v n v n 1 δ t n p q up r nw g gw in g nw in δ t n e g gw out w q dr in the equation there are nine water flux components related to the water balance in the water area of the depression as shown in fig 3 wherein n is the number of the current simulation period v n and v n 1 are the water volumes of the depression at the closing and beginning of the simulation period m3 δ t n is the time step for the current simulation period during the simulation a daily time step is adopted δ t n 1 d p q up r nw g gw in and g nw in are respectively the water area precipitation m3d 1 the incoming flow from the upper reaches of the depression m3d 1 the runoff producing flow of the non water area the recharge flow effused from the groundwater to the water area m3d 1 and the groundwater flow effused from the non water area flows to the water area in each time step m3d 1 e g gw out and w are respectively the water surface evaporation m3d 1 the seepage into the aquifer of the water area m3d 1 and the water withdrawal in each time step m3d 1 q dr is the discharge from the depression in each time step through the sluices and pumping stations m3d 1 this study only gives the calculation principle of q dr 3 1 2 for other calculation principles please see the reference wang et al 2017 3 1 2 specific items in the water balance equation within a time step one day the calculation of the precipitation p m3d 1 and evaporation e m3d 1 of the depression on the water areas are calculated by multiplying the measured daily value by the water area of the day the incoming flow from the upper rivers of the depression q up m3d 1 is the total water of all the rivers into the depression which derived from the hydrologic simulation of the modcycle the runoff producing flow of the non water area r nw m3d 1 is calculated by the scs curve number equation neitsch et al 2011 the water withdrawal w m3d 1 from the depression is reserved for other usage which is beyond the scope of the present study the interaction between the depression and the groundwater aquifer including g gw in g nw in and g gw out is calculated by darcy formula based on the average water level of the depression and the groundwater level at each grid cell the detailed calculation process can be found in the reference wang et al 2017 the following focuses on the calculation of the downstream discharge of the depression the discharge of the depression is calculated in three cases and the depression discharge equations were established eqs 3 4 and 5 respectively when there are only sluices in the downstream of the depression and the water level in the downstream river has no effect on the discharge of the depression the formula for depression discharge is as follows 3 q dr min max q s v n v max v n v ctl h l h max q dr min q s v n v ctl h max h l h ctl q dr 0 h l h ctl where q dr is the discharge of the depression to the downstream on day m3d 1 v n is the initial storage capacity of the depression on the day before discharge m3 v max is the storage capacity corresponding to the maximum allowable water level in the depression m3 h l is the average water level of the depression on the day before discharge m h max is the allowable highest water level in the depression m h ctl is the discharge control water level of the depression m v ctl is the storage capacity of the depression corresponding to the h ctl q s is the discharge of the sluice when water depth is h l m3d 1 the discharge of depression of the sluice q s is calculated using the conventional weir equation swamee 1988 for the depressions without sluices downstream such as the depression formed by coal mining the outflow is also calculated by the conventional weir equation wherein the outflow elevation is the river bottom elevation of the downstream river channel and the outflow capacity is the discharge capacity of the downstream river channel when there are only sluices in the downstream of the depression and the water level in the downstream river affect the discharge of the depression the formula for depression discharge is as follows 4 q dr v n v max h l h max h e h max q dr min max q s v n v max v n v e h l h max h e q dr min q s v n v ctl h max h l h ctl h ctl h e q dr min q s v n v e h max h l h e h e h ctl q dr 0 h l h ctl o r h l h e where h e is the external water level m v e is the storage capacity of the depression corresponding to the h e when there are not only sluices but also pumping stations downstream of the depression the formula for depression discharge is as follows 5 q dr min max q p v n v max v n v ctl h e h l h max q dr min max q s q p v n v max v n v ctl h l h max h l h e q dr min q p v n v ctl h max h l h ctl h e h l q dr min q s q p v n v ctl h max h l h ctl h e h l q dr 0 h l h ctl where q p is the drainage capacity of the pump station m3d 1 when there are not only sluices but also pumping stations downstream of the depression the control strategy for the discharge is that the depression does not need to be discharged q dr 0 when the average water level of the depression h l is lower than the discharge control level h ctl when the average water level of the depression h l is located between the discharge control water level h ctl and the maximum allowable water level h max and the average water level of the depression h l is higher than the external water level h e the sluice and pumping station together discharge the water when the average water level of the depression h l is located between the discharge control water level h ctl and the maximum allowable water level h max and the average water level of the depression h l is below the external water level h e the sluice will not be able to drain and only the pumping station can perform the forced drainage when the average water level of the depression h l is higher than the maximum allowable water level h max and the average water level of the depression h l is higher than the external water level h e the sluice and the pumping station work together to remove the excess water exceeding the maximum allowable storage capacity when the average water level of the depression h l is higher than the maximum allowable water level h max and the external water level h e is higher than the average water level of the depression h l only the pumping station can discharge the water 3 1 3 coupling of surface water and groundwater in a depression although the depression has its own water balance equation some water balance items are related to the surface water and groundwater the hydraulic connection between the depression and the river system is mainly reflected by the confluence of the upstream river channel to the depression and the discharge from the depression to the downstream river channel therefore the relationship between the depression and the surrounding river channels is established then the water exchange between the river channel and the depression can be calculated by the simulation of basin runoff and confluence and the discharge of the depression in the coupling of the water in the depression and groundwater the depression grid cells belongs to the grid cells of the groundwater flow model fig 5 shows the logical processes for operating the revised modcycle code it is noted that fig 5 only shows the computational processing part of the module while the input data processing and statistical output parts of the module are not included it describes what happens in of a single depression and the processing of multiple depressions will be a repetition of the same process 3 2 data hydrological and meteorological data from 2001 to 2010 are used to developed the model details can be seen in lu et al 2016a and wang et al 2017 the following focuses on data related to flood storage and waterlogging control in the depressions 3 2 1 typical flood to be simulated according to the measured rainstorm in the study area and the measured flood volume and water level fluctuation in the mainstream of the huaihe river lu et al 2016b the six floods with the greatest degree of flood damage from 1951 to 2010 were selected which occurred in 1954 2003 1991 2007 1968 and 1956 in the order of large to small among these the flood that occurred in 2003 is the second largest flood in history and its data are available after overall consideration the flood in 2003 was selected as a typical flood to evaluate the flood storage and waterlogging control in the depression in 2010 and 2030 3 2 2 area and storage capacity of depression the arcgis tool was used to extract the area of each depression within the distribution in the study area then according to the relationship between the water level and storage capacity and the relationship between the water level and the water surface area the maximum storage capacity of each depression was calculated table 1 3 2 3 discharge control parameters of each depression the relative relationship between the water level of the huaihe river and the water level of its tributaries is the key to study the flood storage and waterlogging control in the depression if the water level of the huaihe river is lower than the water level of the tributaries in the study area the discharge sluice of the depression in the lower reaches of the tributary of the huaihe river is free to discharge water when the water level of the huaihe river is higher than that of the tributaries in the study area the discharge sluice will fail completely and only the pumping station can perform the forced drainage the water levels of the depression in the lower reaches of the tributaries in the study area can be calculated through the model while the water level of the huaihe river is required to be entered since the discharge of the depressions in the lower reaches of the tributaries are also subject to their own characteristic water levels sluices and pumping stations and other conditions it is also necessary to know the maximum allowable water level of each depression discharge control water level discharge capacity design flow of a sluice drainage capacity of a pumping station and other discharge control parameters in different level years the main discharge control parameters for each depression in different level years are shown in table 2 4 results the flood disasters in the study area are characterized by the so called backwater flood and determining whether the tributary channels have enough storage and detention capacity is the key to tackle this problem therefore in assessing flood storage and waterlogging control in the study area this study evaluated the amount of flood volume stored during the backwater flood that is the storage capacity at the maximum water level during the flood minus the storage capacity at the starting water level of the flood this study evaluated and calculated the amount of flood water in depressions that were stored during the backwater flood in the 2010 and 2030 subsidence scenarios then the reduction effect of the water levels during the backwater flood were compared in two subsidence scenarios thereby providing certain reference for the long term management and utilization of coal mining subsidence areas 4 1 simulation of surface water and groundwater the hydrological model of the study area from 2001 to 2010 was evaluated and validated from the surface water level and groundwater level the entire simulation process is divided into three phases the first phase is from 2001 to 2002 which is the preheating period the second phase is from 2003 to 2006 which is the calibration period the third phase is from 2007 to 2010 this stage is the validation period the measured data from a temporary water level observation station and six shallow groundwater observation wells in the study area are used for model calibration and validation the position of these sites are shown in fig 1 and the results show that the simulation has achieved good results lu et al 2016a wang et al 2017 according to the purpose of this study the water levels of the rivers and flow are critical calibration targets simulated water levels and flow are basis for flood analysis and evaluation of flood storage and waterlogging control in subsidence areas this study only shows the calibration and validation process of the water level of the xfr and one of the groundwater observation wells as shown in fig 6 the xfr has no fixed hydrological station and the only measured data are the water level data in flood period of 2003 and 2007 which can be used for model calibration and validation separately the position of the two sites used for display are shown in fig 1 as shown in fig 6 the model achieves relatively high accuracy in simulating the actual flood water level which is beneficial to the evaluation of flood storage and waterlogging control in depressions on the other hand because of the limitation of the simulation scale the model cannot simulate the groundwater depth of a single well and can only simulate the average groundwater depth within a certain area i e one grid cell of the groundwater model so it is difficult to obtain a precise fit with the measured processes of the groundwater depth but the periodicity and amplitude of groundwater depth fluctuations still could supports the simulation results the water balance simulation of soil water system surface water system and groundwater system in the study area from 2003 to 2010 is shown in table 3 it can be seen that the water balance errors of the three systems are all within a reasonable range in addition two important hydrological parameters affecting the hydrological cycle simulation are compared with the previous research results including the runoff coefficient and the recharge coefficient the runoff coefficient is the key to hydrological cycle savenije 1996 the average annual precipitation in the hrb is about 894 mm and the average annual runoff is about 230 mm zhang et al 2012a b it can be calculated that the average annual runoff coefficient is about 0 26 modcycle simulation shows that the total surface runoff of the study area from 2003 to 2010 is about 1 2 billion m3 and the total surface precipitation is about 4 billion m3 the average annual runoff coefficient of the model simulation is calculated to be about 0 3 which is basically consistent with the previous research result in terms of recharge coefficient some scholars have calculated the average annual rainfall recharge coefficient of the hrb by lysimeter measurement and soil moisture model and its value is 0 25 chen et al 2008 modcycle simulation shows the average annual soil infiltration in the study area from 2003 to 2010 is about 1 016 billion m3 and the average annual surface precipitation is 4 billion m3 the recharge coefficient of the model simulation is calculated to be about 0 25 which is consistent with the previous research result it should be noted that the hydrological cycle simulations in depressions in 2010 and 2030 were both based on the basic data from 2001 to 2010 in order to establish the same basis for comparison of the storage and detention capacity of the same flood disasters in different subsidence scenarios 4 2 evaluation of flood storage and waterlogging control effect on typical floods in these two subsidence scenarios the flood water in each tributary confluence zone was finally imported into the hjl cbl and nhl respectively then this was allowed to flow or was pumped into the huaihe river through its own sluices or pumping stations after being stored and detained by the lakes therefore the inversion calculation of water amounts for typical floods during the flood seasons was carried out separately according to the flood incoming processes in these three lakes fig 7 show the change process line of water levels internal water of hjl cbl and nhl in different subsidence scenarios during the typical backwater flood in 2003 as well as the change process line of water levels external water of the huaihe river at the corresponding estuary to the huaihe river and the incoming process of the cumulative flood volume the simulation results in the 2030 level year are obtained using the 2030 subsidence terrain to replace the 2010 subsidence terrain in case other input data remained unchanged the evaluation results are shown in table 4 according to statistics in the 2010 subsidence scenario the total accumulated water volume during the backwater flood period caused by the typical flood in 2003 in the study area was 765 million m3 the pumping station pumped 253 million m3 and the flood volume stored in the subsidence area was 389 million m3 from the point of view of flood storage and waterlogging control the storage capacity and its distribution in the depression of the study area in 2010 could not cope with the typical flood in 2003 which was mainly due to the overflow of water in the xfr confluence zone that is the lack of storage and detention space the overflow volume is 85 million m3 in the 2030 subsidence scenario the total accumulated water volume during the backwater flood period caused by the typical flood in 2003 was 958 million m3 which is 193 million m3 greater than the subsidence scenario in 2010 and this is mainly due to the decline in water level in the xfr confluence zone the increased time of the backwater flood will lead to an increase in the amount of incoming water the pumping station pumped 375 million m3 which was 122 million m3 more than that in the 2010 subsidence scenario the sluice will discharge 51 million m3 which is 51 million m3 more than that in the 2010 subsidence scenario the water stored mainly by the storage capacities of the depressions will be 548 million m3 which is 159 million m3 more than that in the 2010 subsidence scenario from the point of view of waterlogging control the storage capacity and its distribution in the study area in 2030 will be able to cope with the typical floods in 2003 and there will be no overflow phenomenon in all the confluence zones it shows that in 2030 with the increasing effect of the storage capacity of the coal mining subsidence areas the study area has the basic ability to cope with the typical flood in 2003 4 3 contrast analysis of the water level reduction effect of a typical backwater flood one of the most important indicators of flood risk during the flood season is the internal water level the water levels of lakes in the lower reaches of the huaihe river tributaries the lower the water level during the flood season is the lower the risk of flooding in the study area will be this section compares the internal water levels in these two subsidence scenarios and analyzes the reduction effect of the internal water levels under the 2030 subsidence scenario compared with those under the 2010 subsidence scenario fig 8 based on the simulation in both scenarios the results of the water level change in each lake are summarized in table 5 from the comparison of results in the 2030 subsidence scenario hjl and nhl would benefit from the expansion of the coal mining subsidence areas and the increased adjustable storage capacity the water level during the flood season would obviously reduce among these the water level of hjl obviously reduced and the water level in a typical flood year in 2003 is 0 59 m and the flood level of the nhl drop by 0 41 m cbl is special wherein in the 2030 subsidence scenario the flood level will rise the reason is that the flood peak of the cbl occurred in the backwater flood the sluice cannot drain away water only the pumping station can pump water and in the 2030 subsidence scenario due to the merger of part of the xfr confluence zone the yxr confluence zone increased affected by the confluence pattern the amount of the incoming water of the cbl in the downstream is greater than that in the 2010 subsidence scenario therefore the water level in the 2030 subsidence scenario rises in a short period 5 discussion and conclusions backwater flood is a serious problem that frequently occur in the middle reaches of the hrb hence getting sufficient flood storage and detention space is of great importance for flood prevention and waterlogging control in the region the large subsidence areas formed by coal mining and its annual expansion can effectively increase the potential storage and detention space in this region a distributed surface water groundwater model was developed based on the modcycle code and was used for simulation of the entire hydrological cycle in the middle hrb with special attention given to the water balance at the subsidence areas the calibrated model was used to simulate the water levels and flood storage volumes of depressions two scenarios were created for analyzing subsidence conditions in 2010 and 2030 respectively the flood events in 2003 were selected to evaluate the capacity of flood storage and waterlogging control in these two scenarios simulation results showed that for the 2010 subsidence condition a great amount of overflow was generated in response to the 2003 flood however the subsidence condition in 2030 was able to contain typical floods as in 2003 as for the reduction of water level in the lakes connecting to the main streams during flood season the 2030 scenario can stabilize the water levels of the lakes connecting to the huaihe river to a more reasonable degree except for cbl comparing to the 2010 subsidence scenario in addition this study revealed that although the storage capacity of the coal mining subsidence increases with time the depressions still remain scattered as shown in fig 2 since connected depressions may be able to increase the overall storage capacity zhou et al 2014 chang et al 2017 it is suggested that the coal mining subsidence areas should be connected through artificial channels in order to maximize their functionality at present the management strategies for the subsidence areas have two types transformation and reclamation krümmelbein et al 2012 zipper et al 2013 transformation is mainly to construct a new ecological environment such as a park or wetland which is applicable to places with little pressure on land and population krümmelbein et al 2012 on the other hand reclamation refers to restoring the lands to its original condition by physical chemical and or biological means sheoran et al 2010 however both of these two methods require substantial amount of manpower materials and financial resources it is rather an inexpensive way to utilize the subsidence areas in its natural form the study area historically suffered from serious backwater flood problems converting the coal mining subsidence areas into flood storage and detention areas has the potential not only to reduce local flood risks but also to provide a new alternative for utilizing the subsidence areas in a meaningful way our research from a joint surface water groundwater management perspective shares valuable first hand experience on utilizing coal mining subsidence areas which can be useful to regions with similar problems in other parts of the world although we have demonstrated that it is a feasible way to develop the coal mining subsidence areas into flood storage and detention areas it also needs to mention that such kind of management strategy may have a serious impact on the ecological environment if the flood is stored in the coal mining subsidence area for too long the water quality will deteriorate alhamed and wohnlich 2014 nieva et al 2018 for example the ph of the water may decrease and the concentration of heavy metals may increase which not only reduces the usability of the stored flood water but may also cause pollution to the groundwater and damage to the surrounding ecological systems moyéet al 2017 barkett and akün 2018 nieva et al 2018 therefore it is critical to secure water quality at the coal mining subsidence areas which will be one of the main research tasks in our next stage at present there is much research focusing on abandoned mine water treatment such as remediation of heavy metal contaminated groundwater originated from abandoned mine using lime and calcium carbonate lee et al 2007 and the remediation of acid mine drainage fallavena et al 2018 which can provide useful insights for our future work declaration of interests none acknowledgements this research was supported and funded by the national key research and development program of china grant no 2016yfc0401404 the project of representative achievements of state key laboratory of simulation and regulation of water cycles in river basins grant no skl2018cg01 the national science fund for distinguished young scholars grant no 51625904 and the national natural science foundation of china grant no 51509264 the authors would like to thank huainan mining industry group co ltd and china university of mining and technology who provided the subsidence data and some other data and local water departments who provided a lot of valuable hydrologic data appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 03 044 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
