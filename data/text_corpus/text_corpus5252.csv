index,text
26260,as an important tool for air quality simulation the community multiscale air quality cmaq model is widely used in the environmental modeling community however setting up and running the cmaq model could be challenging for many scientists especially when they have limited computing resources and little experience in handling large scale input data in this study we explore the cloud based web processing service wps and present the cloud wps framework to support implementing earth science model as wps specifically to make cmaq easier to use for scientists through the latest standard based web service technology cmaq ws a prototype of cmaq as a service is developed and tested the result of the experiment shows the framework significantly improves not only the performance of but also ease of use of the cmaq model thus providing great benefits to the environmental modeling community meanwhile the proposed framework provides a general solution to integrate earth science model wps and cloud infrastructure which can greatly reduce the workload of earth scientists keywords cmaq wps cloud computing earth science model web service ogc 1 introduction the volume of earth observation eo data is growing in the exponential level during the past decade according to the statistic of nasa s earth observing system data and information system eosdis the average daily archive growth of eo data is 15 3 tb day between oct 1 2016 to sept 30 2017 and the total archive volume is 23 8 pb which has been increased over 3 times with 7 4 pb as in 2012 eosdis 2018 as the result the computing and storing capabilities of traditional desktop gis tools are becoming limited and insufficient scientists may face a lot of big data issues while processing large volume of eo data such as how to unify the formats of different remote sensing data how to obtain useful information in the huge volume of data how to improve the efficiency of remote sensing data management analysis and how to facilitate data security accessibility connectivity and quality di 2016 di et al 2016 fortunately with the rapid development of information technology new approaches such as big data management analysis cloud computing service web services the internet of things iot machine learning semantic web workflow sensor web scalable database data intensive computing and advanced analytics are being enabled in the geographic information system gis and remote sensing which drive gis from the traditional geographic information systems to geographic information services giservices yue et al 2015a the dissemination of massive web based giservices significantly lowered the entry barrier for accessing eo data and greatly simplified the workflow for processing eo data swain et al 2015 tan et al 2016 vitolo et al 2015 yue et al 2015b giservices have very extensive applications in many societal sectors ranging from government academia to industry for example geoss global earth observation system of systems coordinates a set of independent earth observation information and processing resources with contributions from countries around the world and international organization members of the group on earth observations geo to facilitate access monitoring sharing of global environmental data and information via giservices it makes use of web as a platform to implement a system of system architecture nativi et al 2015 geobrain and its geonas geobrain online analysis system integrate web service based analysis and ogc standards based data access to discover retrieve analyze and visualize geospatial data di 2004a the seps self adaptive earth predictive system framework sets the general sensor web approach for coupling earth system models with eo data via giservices chen et al 2010 di 2007 yu et al 2010 zhang et al 2012 along with the development of giservices the concept of model web model as a service and service oriented architecture soa are proposed to facilitate the interoperability of models across environmental modeling community castronova et al 2013 goodall et al 2011 granell et al 2010 nativi et al 2013 on the other hand as a major technology for delivering computing to address big data challenges cloud computing provides a cost effective way for earth scientists to store access and model with the large volume of eo data buyya et al 2009 nativi et al 2015 rather than using the traditional desktop gis software on the local pc modeling eo data with the cloud based giservices system can relieve users especially non technical ones from the time consuming eo big data processing and requirement on local high end computing facility due to the high performance computing capability offered by the powerful server end infrastructure a series of studies on utilizing cloud based cyberinfrastructure to facilitate giservices have been done horsburgh et al 2016 jin et al 2017 morsy et al 2018 sun et al 2017b wang et al 2013 it is known that the traditional way of setting up the earth science model for researchers and scientists who do not have the strong technical background can be difficult since most models are open source project that many scientists and institutes have contributed to the process of installing and configuring the model is not as easy as commercial software even after successful installation users may still face many barriers including the difficulty of collecting input data from different sources incompatibility of data formats unavailability of the data products and limitation of computing resources from the perspective of modelers a series of questions are put forward can the installation and configuration processes of the earth science model be simplified can the earth science model be published as a service can the service be accessed and interoperated through the standardized interface can the performance of the model be improved by moving the computing from local to the cloud to address the above questions in this study we present a cloud based web processing service wps framework specifically the community multiscale air quality cmaq model an essential tool that is being widely used for air quality and pollution simulation in the environmental modeling community is implemented as cmaq ws a prototype of cmaq as a service based on the proposed framework the following is the structure of this paper section 2 introduces the design of the cloud wps framework section 3 demonstrates system architecture workflow and benchmark of cmaq ws section 4 summarizes the answers to the questions that posed above addresses limitation of the current implementation and discusses the potential improvement methods and future works the conclusion is given in section 5 2 design of cloud wps framework 2 1 opengis web processing service the opengis web processing service is an ogc open geospatial consortium web service interface standard for geospatial processing services generally a web service could be described as the self contained self describing modular applications that can be published located and dynamically invoked across the web di 2004b further a geospatial web service is a modular web application that provides services on geospatial data information and knowledge di et al 2005 ogc web services ows refers to those services that reflect ogc vision for geospatial data and application interoperability and is one of the most widely used geospatial web services with the proliferation of giservices a lot of ogc standards and specifications have been developed among them wps serves as the standard for the application service that provides the capability to wrap any geospatial processing capability regardless of the source as a web service with a standard interface so that it can be integrated into existing web service workflows besides ogc also has developed a series of web service specifications that have been widely disseminated in geospatial domains such as catalogue services for the web csw sensor observation service sos web coverage service wcs web feature service wfs and web map service wms ogc wps standard defines 1 rules for standardizing how inputs and outputs requests and responses for geospatial processing services such as polygon overlay 2 how a client can request the execution of a process 3 how the output from the process is handled and 4 an interface that facilitates the publishing of geospatial processes and clients discovery of and binding to those processes ogc 2018a due to the popularity of wps in the geospatial field several open source giservices packages have implemented wps such as 52 north wps pywps and geoserver wps many wps based products have been developed to facilitate the geoprocessing over the web dubois et al 2013 feng et al 2011 rosatti et al 2018 yue et al 2010 currently opengis web processing service 1 0 0 ogc 2007 is the most widely used wps interface standard core operations defined in wps 1 0 interface standard include getcapabilities describeprocess and execute which are similar with other ogc web services such as wcs wfs and wms as the continuation of wps 1 0 standard interface wps 2 0 2 ogc 2018b the latest version of ogc wps interface standard offers two new core operations getstatus and getresult supporting both immediate processing for quick computational tasks and asynchronous processing for more complex and time consuming tasks however due to the retro compatibility issue wps 2 0 does not interoperate very well with wps 1 0 table 1 summarizes the description of core operations offered by the wps standard interface 2 2 cloud computing technology cloud computing technology plays an important role in giservices by shifting the computing resources to the cloud the computing capability available for users could be far more powerful than what a single local device such as a workstation desktop laptop smartphone or tablet can ever offer according to the description by national institute of standards and technology nist the cloud could be described with 1 five essential characteristics on demand self service broad network access resource pooling rapid elasticity measured service 2 three service models software as a service saas platform as a service paas infrastructure as a service iaas and 3 four deployment models private cloud community cloud public cloud and hybrid cloud the architecture of spatial cloud computing covering iaas paas saas and daas has been discussed in yang et al 2011 the feasibility of integrating geospatial web services and cloud infrastructure for eo data processing has been explored in many studies chen et al 2012 shao et al 2012 zhang et al 2017 compared with the conventional client server architecture the cloud based architecture provides a more flexible environment for earth scientists to publish geospatial services and applications as two most common cloud deployment models public cloud and private cloud have been widely used to support giservices public cloud is the cloud service that is open to any user according to the difference in computing resources and services consumers would be charged differently from the vendors public cloud providers such as amazon web services aws microsoft azure google cloud ibm cloud and oracle cloud offer similar services on computing storage databases developer management tool and application services comparing with the public cloud a private cloud provides more flexible operations and capabilities but only available to a specific organization or a group of permitted users characterized by its privacy a private cloud is managed by an organization or person the user belongs to or knows rather than some provider whom the user does not know thus it is accessed only by a specific group of users and is not open to the public in most cases a private cloud can be quickly set up with the open source iaas cloud management frameworks such as eucalyptus openstack cloudstack and opennebula both public and private clouds have been used to facilitate environmental modeling ercan et al 2014 essawy et al 2018 kurtz et al 2017 2 3 high level architecture of the cloud wps framework this study has developed the cloud wps framework to facilitate publishing the earth science model as the open standard based web service over the cloud fig 1 shows the high level architecture of the cloud wps framework the architecture consists of four building blocks hardware platform service and client and each block has a number of subcomponents this framework is designed based on the existing cloud computing service model ghazouani and slimani 2017 yang et al 2011 the hardware block is the foundational block of the cloud based wps framework which consists of the physical cloud infrastructure generally the physical cloud infrastructure is built with the server cluster and provides the essential raw computing resources for the cloud the computing capability supported by the cloud depends on the computing resources e g cpu memory disk and bandwidth the server cluster offers the cloud wps framework supports both public cloud and the private cloud which means it could be implemented inside in both public clouds e g aws google cloud azure or private clouds powered by the open source iaas cloud management frameworks e g eucalyptus openstack cloudstack and opennebula the platform block handles what paas cloud service model does and basically follows the architecture of paas which consists of networking storage servers virtualization operating system middleware and runtime it is responsible for 1 provision of the managed application development and deployment platform 2 virtualization and virtual machine vm support above the physical servers 3 optimization of networking capabilities and management of ips and 4 automatic scale and load balance of computing instances to integrate wps with the existing cloud service model the service client block are added on the top of the framework as the components of saas layer it is the core part of the framework which provides protocols standard interfaces security authentication to wrap all earth science models eo data and geospatial processes into geospatial web services models data and processes are hosted inside the vms that managed by the cloud platform in each vm the service is published through the standardized geospatial web service such as wps wcs wms and wfs therefore in this framework all services are independently deployed but interoperable with each other when users send a request to execute a model the model ready vm would be called and the entire computation would be executed inside the cloud infrastructure moreover the service client block provides the user interface with client interaction modules such as visualization analysis management and other applications the web based client can be accessed by any web browser on a desktop laptop smartphone and tablet as a gateway of the framework the client allows users to send a request and receive the result from the server without worry about the details of the development and deployment of the model processes and applications 2 4 interoperability of the cloud wps framework fig 2 illustrates the relationship among the components of the cloud wps enabled system and the interoperability with other earth science information systems the users of the cloud wps framework enabled system could be divided into four groups earth scientists developers administrators and other users each group of users plays its specific roles and holds specific permission and privilege earth scientists are the top level users who have the permission to directly manipulate model processes and data through geospatial web services developers have the permission of accessing cloud instances and are responsible for developing and publishing earth science models as geospatial web services administrators have the root permission of accessing the cloud management module other users share the computing resources with earth scientists but only have the permission of accessing their own instances or web services as shown in fig 2 in a cloud wps framework enabled system all models processes data and web services are deployed inside the vms all vms are isolated but can be interoperable with each other like all private cloud platforms the cloud wps framework enabled system is powered by the cloud management module which plays the role of deploying and managing large networks of both physical server zones and virtual servers besides the service and data deployed in the local cloud infrastructure the framework is interoperable with other data service providers such as nasa and noaa moreover it can be built as a part of the hybrid cloud by integrating with public clouds and private clouds all vms in the cloud wps framework enabled can be disseminated through general vm formats e g qcow2 compatible with most of the cloud platforms the model pre installed vm could be encapsulated as the model template with the model template users could deploy and reproduce one or more model ready vms inside any cloud 3 prototype of cmaq as a service 3 1 cmaq model global air pollution and air quality issues have made a huge impact on climate environment and especially human health akimoto 2003 u s environmental protection agency usepa set six common air pollutants as the criteria air pollutants ground level ozone particulate matter carbon monoxide lead sulfur dioxide and nitrogen dioxide usepa 2017 each pollutant has the specific physical and chemical property which could affect human health and natural environment at different levels and in different ways kampa and castanas 2008 as a well vetted peer reviewed scientific model for modeling and simulating air quality community multiscale air quality cmaq model provides the capability of estimating the distribution of ozone particulates toxics and acid deposition in the atmosphere cmas 2018 before implementing cmaq as web processing service it is essential to understand how cmaq model works the core cmaq programs and its workflow is described in fig 3 major processors and the chemical transport models of cmaq modeling system includes sparse matrix operator kernel emissions smoke model meteorology model mm5 or wrf meteorology chemistry interface processor mcip photolysis rate processor jproc initial conditions processor icon boundary conditions processor bcon and cmaq chemical transport model cctm among them emission model and meteorology model are third party programs which are not part of cmaq program but supply the necessary input data for air quality simulation mcip icon bcon and jproc are standard cmaq preprocessors providing the mandatory inputs for cctm the output generated by cctm then feeds back to icon and bcon for nested simulations the function of each preprocessor is described as follow icon initial conditions processor icon preprocessor outputs a gridded binary netcdf file of the chemical conditions of the chemical condition for the first hour of simulation in the modeling domain bcon boundary conditions processor bcon preprocessor outputs a gridded binary netcdf file of the chemical conditions along the horizontal boundaries of the modeling domain mcip meteorology chemistry interface processor mcip preprocessor outputs the netcdf formatted meteorology data required by smoke and cctm jproc photolysis rate processor jproc preprocessor outputs the chemical mechanism specific clear sky photolysis rates at fixed altitudes solar hour angles and latitude bands from tabulated absorption cross section and quantum yield csqy data cctm cmaq chemistry transport model cctm is the core processor of cmaq which simulates continuous atmospheric chemical conditions by integrating the outputs from the above preprocessors and smoke cctm outputs binary netcdf files of gridded and temporally resolved air pollutant information including 3 d cctm hourly concentration file conc 3 d cctm ending concentration file cgrid 3 d cctm integral average concentration file aconc 2 d cctm dry deposition file drydep 2 d cctm wet deposition file wetdep 2 d cctm visibility file aerovis table 2 describes the details of the cctm output files 3 2 system architecture cmaq ws a prototype of cmaq as a service is developed based on the cloud wps framework a suite of advanced techniques software and services have been applied to the implementation of this prototype as shown in fig 4 the prototype consists of four major components geobrain cloud cmaq ws cyberconnector and the internet this section describes the major components of the cmaq ws prototype 3 2 1 geobrain cloud all vm instances of the cmaq ws are powered by the geobrain cloud http cloud csiss gmu edu a private cloud platform running by center for spatial information science and systems george mason university geobrain cloud mainly serves for geospatial web services and provides computing source for eo data processing besides a large volume of eo data such as landsat data and modis data are archived inside the cloud it is built with iaas architecture using apache cloudstack as the management framework to manage the network storage computing resources and vms by taking advantage of the powerful open framework the cloud management module offers an elastic and flexible mechanism to assign the load to particular services and dynamically assign the computing resources depending on the input data volume users and developers may access geobrain cloud in different ways including web user interface command line tools and a full featured restful api by integrating the ec2 compatibility interface for apache cloudstack geobrain cloud offers the api that is compatible with api of aws ec2 and s3 the deployment of geobrain cloud is based on the small scale deployment architecture as shown is fig 5 the cloud platform physically contains one management server one layer 2 switch network file system nfs server and computing node geobrain cloud currently manages over 300 cpu cores 500 gb ram and 600 tb storage in total plus a cluster of nvidia tesla k80 gpus are equipped in the geobrain cloud s computing node which is mainly used for offering computing capability for advanced machine learning tasks 3 2 2 cyberconnector cyberconnector is an earthcube building block supporting the automatic preparation and feeding of on demand eo data into earth science models it adopts open geospatial standards specifications to process the eo and geoprocessing workflow in the implementation of cmaq ws cyberconnector 1 automates the handshaking between vms that distributed in application layer interface layer service layer 2 plays as the front end client between users and the service and 3 connects the cmaq ws with the internet and other clouds additionally cyberconnector offers the capability to automatic tailor multi source eo data to model ready input files and feed earth science models which could save a tremendous amount of time and effort for earth science modelers sun et al 2017a the procedure of using cyberconnector to execute cmaq ws is simple it utilizes virtual data products vdp to build geoprocessing workflow cyberconnector provides a web based user interface allowing users to search and order vdp fig 6 shows the screenshot of using cyberconnector to search and order vdp in this case cmaq ws is implemented as a vdp which can be searched and ordered through the cyberconnector web client after the order of cmaq ws is placed cmaq required input data would be automatically tailored from different sources through cyberconnector and delivered to the cmaq vms once the process is done the result will be sent to users via emails 3 2 3 cmaq ws cmaq ws is the core component of this prototype it is composed of a bunch of vm instances according to the difference in the functionality the instances deployed inside the cmaq ws can be divided into three layers application layer interface layer and service layer the followings are a description of the implementation and functionality in each layer the application layer is the gateway of cmaq ws where the web based clients are deployed as the front end client to access cmaq ws the web based client of cyberconnector is deployed inside this layer besides we implemented a lightweight web application to test the prototype it is deployed inside the application layer as well the user interface of the cmaq ws test client is shown in fig 7 two required inputs in the cmaq processes are cmaq input configuration file and cloud configuration file cmaq input configuration file contains the information of all input data that required by the cmaq model cloud configuration file contains the preference of the cloud instance such as cpu cores and memory size of the task the interface layer provides the standard interface to bridge the application layer and the service layer standard geospatial services including wps wms wfs and wcs are implemented in this layer the prototype adopts wps as the standard interface to access cmaq model when a user calls the cmaq service a wps request is sent from the client vm that deployed inside the application layer after the process is done the cmaq output data would be returned through wps standard interface when the process is finished in this study cmaq ws was implemented and tested with both wps 1 0 and wps 2 0 standard interface we used the pywps as the framework of wps 1 0 standard interface and manually implemented core components of wps 2 0 standard interface to support asynchronous wps processes all basic wps operations such as getcapabilities describeprocess execute are supported with wps 1 0 2 0 getstatus and getresult are supported with wps 2 0 the service layer hosts a number of model instances geoprocessing instances and eo data instances cmaq model is implemented as the model instance where cmaq and its dependent libraries software packages are installed cmaq program an open source cmaq implementation developed and released by usepa computational exposure division is the main software package of the cmaq model instance this prototype used cmaq program v5 1 as the implementation of the cmaq model in addition required libraries and dependencies such as netcdf i o api and mpich need to be pre installed and configured inside the instance before running cmaq model netcdf network common data form is the software library that developed and maintained by unidata http www unidata ucar edu to improve interoperability and re usability netcdf became an ogc standards in 2011 and climate and forecast cf extension to netcdf core data model standard was approved in 2013 domenico and nativi 2013 as the essential component to run cmaq model netcdf c library and netcdf fortran library need to be installed models 3 edss input output applications programming interface i o api version 5 1 is another required library for cmaq version 5 1 it provides model developers with the programming library for data storage and access and is available in c and fortran mpich is the library enabling multiple processors for running cmaq 3 3 workflow the workflow of cmaq ws is demonstrated as the sequence diagram in fig 8 before initiating a cmaq processing task users could get the list of available processes by sending getcapabilities request and check the description of specific processes by sending describeprocess request with cmaq ws web client cyberconnector web client or any other wps client then user executes the cmaq process with required wps inputs url of input data and url of configuration file to initiate a cmaq processing task after the request is sent cmaq model vms are automatically instantiated and the task will be assigned to a particular instance based on the cloud configuration file by taking advantage of the elasticity of the cloud the cmaq model vms are dynamically allocated by wps requests then all input data will be fetched and fed into the cmaq instance three sources of the cmaq input data are accepted in this prototype local data servers vms where the required input data are stored geoprocessing model e g wrf model services where the required input data are tailored and generated and other data providers from the internet after fetching required input data the cmaq model starts running inside the cmaq model vms once the process is done the output data are copied from the cmaq model vms to the data server then the cmaq model vms are automatically destroyed the url of the output data is returned as the output of the process and cyberconnector will notify users via email the running state of the cmaq processes could be checked through the getstatus operation either the status of running or done is returned depending on the actual processing status and the final product could be retrieved through getresult operation the user can download the cmaq output data from the data server with the output url the prototype can be integrated as a part of the geoprocessing workflow fig 9 illustrates the sequence diagram of building a geoprocessing model workflow with the prototype in this workflow cmaq ws is not directly requested by users instead as a part of the requested geoprocessing model workflow service cmaq ws is called when the required cmaq input data is ready during the process of the service the output of cmaq ws then would be used for the rest steps of the workflow the final output of the workflow is copied stored in the local data server as the intermediate data of the workflow all output data from the cmaq ws would be removed with the destruction of geoprocessing model vm the prototype provides an easy to use dissemination solution all components of the prototype including client wps interface cmaq geoprocessing model service data server are implemented as vm instance each component can be disseminated through vm template in qcow2 format which is a general vm format compatible with major cloud platforms with the vm templates image users can upload the template image to the private or public cloud platforms such as openstack cloudstack and aws 3 4 benchmark and validation a series of experiments on the implementation using the cmaqv5 1 benchmark data as the input dataset has been conducted in this study the cmaqv5 1 benchmark data is the open access dataset which can be downloaded at https www cmascenter org download software cmaq tracker cmaq5 1 cfm to generate the cctm data all input data need to be fed into the prototype and cmaq processes need to be executed three basic processes which cmaq model executes in the prototype are 1 mcip to prepare the cmaq ready meteorological data from the wrf output 2 icon and bcon to create initial and boundary conditions input data and 3 cctm to estimate air quality fields assuming the wrf meteorology and smoke emissions data are ready to use wps is expected to do is to generate icon profile bcon profile and cctm output data in this experiment it takes only a few seconds to generate icon profile and bcon profile however generating cctm output data could take a couple of hours the prototype aims to publish cmaq model as the web processing service it could be a tough job for users to run cmaq model through wps 1 0 due to the longtime process of cctm and unavailability of asynchronous processing capability in wps 1 0 to handle this issue the cloud wps framework adopts the wps 2 0 standard interface which provides the asynchronous processing capability a group of tests with different computing resource offerings have been conducted for testing the performance of cmaq ws the instance types and the specification that geobrain cloud offers are listed in table 3 the cmaq program supports serial mode and message passing interface mpi mode serial mode only allows cmaq model running on a single cpu core no matter how much the instance offers mpi on the other hand is a standard interface for parallel computing pacheco 1997 running the cmaq model in mpi mode could make the most of the power of multi core cpu and substantially reducing the computation time this test compares the performance of cmaq ws in both serial mode and mpi mode fig 10 displays the test result of running the cmaq ws with multiple instance type in the serial mode increasing the number of cpu cores does not observably improve the performance of cmaq ws in the mpi mode the performance is significantly improved with the increasing of the number of cpu cores there is no distinct difference for the performance of the service while running on the small instance with single cpu core to validate the output data the cctm outputs have been compared with cmaq reference benchmark data which could be accessed at https www cmascenter org cmaq the result shows the content and size of cctm data generated from the prototype are the same as the reference benchmark data fig 11 displays the selected pollutants of cmaq hourly average concentration aconc data generated by the cmaq ws fig 12 compares the output aconc data of cmaq ws and cmaq reference benchmark data 4 discussion this section is organized to 1 summarize the answers to the questions that are posed in section 1 2 address some limitations on the current implementation and 3 discuss the potential improvement methods and the future work the first question is how the cloud wps framework simplifies the installation and configuration process of the earth science model in the case of the implementation of cmaq as a service since the cmaq ws has been pre installed and configured inside the vm which is instantiated from the model ready vm template image users do not have to spend time on the installation and configuration of cmaq model technically developers still have to set up the original vm template image and this process is required and not simplified but once the model vm template image is ready the model vm would be directly instantiated without installation and configuration for each use of any user the second question is how can the model be published as a service and interoperated through the standardized interface the feasibility of implementing cmaq model as the wps has been explored in this study with the support of ogc wps standard interface the cmaq ws is interoperable with any standardized service as the originality of this work the cloud wps framework provides a general solution to integrate earth science model wps and cloud infrastructure in a cloud wps framework enabled system all models geoprocessing are eo data are deployed as vm instance all instances are isolated but can be interoperable with each other the third question is how much performance of the model can be improved by moving the computing from local to the cloud the implementation of the cmaq ws prototype is completely powered by geobrain cloud it is an iaas architecture based cloud platform that offers a lot of advantages including 1 services and applications that are deployed on the cloud are easy to access and data stored in the cloud are easy to share 2 rather than storing in the local storage of individual computing devices data and software that stored in the cloud are more reliable and ready for use 3 computing capability offered by the cloud infrastructure is much more powerful and flexible than local computing resources traditionally available to researchers and 4 users do not have to take responsibility for maintaining the computing resources these merits could significantly benefit the earth scientists especially those who are non professional it users but dealing with large scale eo data processing the originality of this work is the cloud wps framework which provides a general solution to integrate earth science model wps and cloud infrastructure compared to the traditional way of earth science modeling this framework brings a lot of benefits such as simplicity ease of use and no local computing resource requirement to earth scientists however the current prototypical implementation of the cloud wps framework still has some limitations the input data of the cmaq model are usually generated from the wrf model in this study we focused on the implementation of the cmaq model and assumed that the wrf meteorology and smoke emissions data are ready to use to build a full environmental modeling system and implement wrf cmaq two way coupled model upon the current prototype the wrf as a service needs to be implemented along with the cmaq as a service the prototype has been implemented only on the geobrain cloud platform and tested internally to test its interoperability between the geobrain cloud and other private and public cloud the prototype needs to be migrated to other private and public cloud although the dissemination of vm is not a labor intensive task the large size of the model vm template image could be a limitation when disseminating the vm for each instance of the prototype it contains not only model related programs but the entire operating system a potential solution is adding a docker container layer between the service layer and the platform layer in each vm instance by integrating the framework with docker the model client data or standard interface could be exported as the docker image and may significantly facilitate the dissemination of the service in the next stage we are going to tackle the above limitations and improve the proposed framework additionally further tests will be performed by applying advanced parallel computing approaches such as mapreduce with a larger volume of data from different sources the cmaq model will be updated from cmaqv5 1 to cmaqv5 2 which is the latest version of cmaq software moreover more earth science models other than cmaq will be tested with the cloud wps framework to make the prototype more powerful and more flexible a series of upgrades to the current geospatial web services and cloud infrastructure will be conducted more services and datasets will be registered into cyberconnector and more high performance computing resources will be added to the geobrain cloud with the improvement of both software and hardware more features and functions of cloud based wps will be explored in the future 5 conclusion this study explored the cloud based web processing service and presented the cloud wps framework particularly a prototype of cmaq as a service was implemented as cmaq ws all components of the prototype including web based client standard interfaces models eo data and geoprocessing were deployed as vm instances managed by geobrain cloud and seamlessly bridged by the cyberconnector a group of validation experiments were performed using the cmaqv5 1 benchmark dataset to validate the implementation the result shows the proposed framework provides a general solution for integrated manipulation of models data and processes through ogc standard interfaces over the cloud by implementing cmaq ws inside the cloud infrastructure the performance of the cmaq model can be significantly improved meanwhile earth scientists would be relieved from model installation data collection and large scale computation so that they can concentrate on research issues instead of tedious tasks on software installation and maintenance as well as data collection and preprocessing acknowledgment this work is supported by grants from nsf earthcube program grants icer 1440294 and ags 1740693 pi dr liping di and ogc testbed 13 the authors would like to thank ms julia di of columbia university for editing and proofreading the manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 11 019 
26260,as an important tool for air quality simulation the community multiscale air quality cmaq model is widely used in the environmental modeling community however setting up and running the cmaq model could be challenging for many scientists especially when they have limited computing resources and little experience in handling large scale input data in this study we explore the cloud based web processing service wps and present the cloud wps framework to support implementing earth science model as wps specifically to make cmaq easier to use for scientists through the latest standard based web service technology cmaq ws a prototype of cmaq as a service is developed and tested the result of the experiment shows the framework significantly improves not only the performance of but also ease of use of the cmaq model thus providing great benefits to the environmental modeling community meanwhile the proposed framework provides a general solution to integrate earth science model wps and cloud infrastructure which can greatly reduce the workload of earth scientists keywords cmaq wps cloud computing earth science model web service ogc 1 introduction the volume of earth observation eo data is growing in the exponential level during the past decade according to the statistic of nasa s earth observing system data and information system eosdis the average daily archive growth of eo data is 15 3 tb day between oct 1 2016 to sept 30 2017 and the total archive volume is 23 8 pb which has been increased over 3 times with 7 4 pb as in 2012 eosdis 2018 as the result the computing and storing capabilities of traditional desktop gis tools are becoming limited and insufficient scientists may face a lot of big data issues while processing large volume of eo data such as how to unify the formats of different remote sensing data how to obtain useful information in the huge volume of data how to improve the efficiency of remote sensing data management analysis and how to facilitate data security accessibility connectivity and quality di 2016 di et al 2016 fortunately with the rapid development of information technology new approaches such as big data management analysis cloud computing service web services the internet of things iot machine learning semantic web workflow sensor web scalable database data intensive computing and advanced analytics are being enabled in the geographic information system gis and remote sensing which drive gis from the traditional geographic information systems to geographic information services giservices yue et al 2015a the dissemination of massive web based giservices significantly lowered the entry barrier for accessing eo data and greatly simplified the workflow for processing eo data swain et al 2015 tan et al 2016 vitolo et al 2015 yue et al 2015b giservices have very extensive applications in many societal sectors ranging from government academia to industry for example geoss global earth observation system of systems coordinates a set of independent earth observation information and processing resources with contributions from countries around the world and international organization members of the group on earth observations geo to facilitate access monitoring sharing of global environmental data and information via giservices it makes use of web as a platform to implement a system of system architecture nativi et al 2015 geobrain and its geonas geobrain online analysis system integrate web service based analysis and ogc standards based data access to discover retrieve analyze and visualize geospatial data di 2004a the seps self adaptive earth predictive system framework sets the general sensor web approach for coupling earth system models with eo data via giservices chen et al 2010 di 2007 yu et al 2010 zhang et al 2012 along with the development of giservices the concept of model web model as a service and service oriented architecture soa are proposed to facilitate the interoperability of models across environmental modeling community castronova et al 2013 goodall et al 2011 granell et al 2010 nativi et al 2013 on the other hand as a major technology for delivering computing to address big data challenges cloud computing provides a cost effective way for earth scientists to store access and model with the large volume of eo data buyya et al 2009 nativi et al 2015 rather than using the traditional desktop gis software on the local pc modeling eo data with the cloud based giservices system can relieve users especially non technical ones from the time consuming eo big data processing and requirement on local high end computing facility due to the high performance computing capability offered by the powerful server end infrastructure a series of studies on utilizing cloud based cyberinfrastructure to facilitate giservices have been done horsburgh et al 2016 jin et al 2017 morsy et al 2018 sun et al 2017b wang et al 2013 it is known that the traditional way of setting up the earth science model for researchers and scientists who do not have the strong technical background can be difficult since most models are open source project that many scientists and institutes have contributed to the process of installing and configuring the model is not as easy as commercial software even after successful installation users may still face many barriers including the difficulty of collecting input data from different sources incompatibility of data formats unavailability of the data products and limitation of computing resources from the perspective of modelers a series of questions are put forward can the installation and configuration processes of the earth science model be simplified can the earth science model be published as a service can the service be accessed and interoperated through the standardized interface can the performance of the model be improved by moving the computing from local to the cloud to address the above questions in this study we present a cloud based web processing service wps framework specifically the community multiscale air quality cmaq model an essential tool that is being widely used for air quality and pollution simulation in the environmental modeling community is implemented as cmaq ws a prototype of cmaq as a service based on the proposed framework the following is the structure of this paper section 2 introduces the design of the cloud wps framework section 3 demonstrates system architecture workflow and benchmark of cmaq ws section 4 summarizes the answers to the questions that posed above addresses limitation of the current implementation and discusses the potential improvement methods and future works the conclusion is given in section 5 2 design of cloud wps framework 2 1 opengis web processing service the opengis web processing service is an ogc open geospatial consortium web service interface standard for geospatial processing services generally a web service could be described as the self contained self describing modular applications that can be published located and dynamically invoked across the web di 2004b further a geospatial web service is a modular web application that provides services on geospatial data information and knowledge di et al 2005 ogc web services ows refers to those services that reflect ogc vision for geospatial data and application interoperability and is one of the most widely used geospatial web services with the proliferation of giservices a lot of ogc standards and specifications have been developed among them wps serves as the standard for the application service that provides the capability to wrap any geospatial processing capability regardless of the source as a web service with a standard interface so that it can be integrated into existing web service workflows besides ogc also has developed a series of web service specifications that have been widely disseminated in geospatial domains such as catalogue services for the web csw sensor observation service sos web coverage service wcs web feature service wfs and web map service wms ogc wps standard defines 1 rules for standardizing how inputs and outputs requests and responses for geospatial processing services such as polygon overlay 2 how a client can request the execution of a process 3 how the output from the process is handled and 4 an interface that facilitates the publishing of geospatial processes and clients discovery of and binding to those processes ogc 2018a due to the popularity of wps in the geospatial field several open source giservices packages have implemented wps such as 52 north wps pywps and geoserver wps many wps based products have been developed to facilitate the geoprocessing over the web dubois et al 2013 feng et al 2011 rosatti et al 2018 yue et al 2010 currently opengis web processing service 1 0 0 ogc 2007 is the most widely used wps interface standard core operations defined in wps 1 0 interface standard include getcapabilities describeprocess and execute which are similar with other ogc web services such as wcs wfs and wms as the continuation of wps 1 0 standard interface wps 2 0 2 ogc 2018b the latest version of ogc wps interface standard offers two new core operations getstatus and getresult supporting both immediate processing for quick computational tasks and asynchronous processing for more complex and time consuming tasks however due to the retro compatibility issue wps 2 0 does not interoperate very well with wps 1 0 table 1 summarizes the description of core operations offered by the wps standard interface 2 2 cloud computing technology cloud computing technology plays an important role in giservices by shifting the computing resources to the cloud the computing capability available for users could be far more powerful than what a single local device such as a workstation desktop laptop smartphone or tablet can ever offer according to the description by national institute of standards and technology nist the cloud could be described with 1 five essential characteristics on demand self service broad network access resource pooling rapid elasticity measured service 2 three service models software as a service saas platform as a service paas infrastructure as a service iaas and 3 four deployment models private cloud community cloud public cloud and hybrid cloud the architecture of spatial cloud computing covering iaas paas saas and daas has been discussed in yang et al 2011 the feasibility of integrating geospatial web services and cloud infrastructure for eo data processing has been explored in many studies chen et al 2012 shao et al 2012 zhang et al 2017 compared with the conventional client server architecture the cloud based architecture provides a more flexible environment for earth scientists to publish geospatial services and applications as two most common cloud deployment models public cloud and private cloud have been widely used to support giservices public cloud is the cloud service that is open to any user according to the difference in computing resources and services consumers would be charged differently from the vendors public cloud providers such as amazon web services aws microsoft azure google cloud ibm cloud and oracle cloud offer similar services on computing storage databases developer management tool and application services comparing with the public cloud a private cloud provides more flexible operations and capabilities but only available to a specific organization or a group of permitted users characterized by its privacy a private cloud is managed by an organization or person the user belongs to or knows rather than some provider whom the user does not know thus it is accessed only by a specific group of users and is not open to the public in most cases a private cloud can be quickly set up with the open source iaas cloud management frameworks such as eucalyptus openstack cloudstack and opennebula both public and private clouds have been used to facilitate environmental modeling ercan et al 2014 essawy et al 2018 kurtz et al 2017 2 3 high level architecture of the cloud wps framework this study has developed the cloud wps framework to facilitate publishing the earth science model as the open standard based web service over the cloud fig 1 shows the high level architecture of the cloud wps framework the architecture consists of four building blocks hardware platform service and client and each block has a number of subcomponents this framework is designed based on the existing cloud computing service model ghazouani and slimani 2017 yang et al 2011 the hardware block is the foundational block of the cloud based wps framework which consists of the physical cloud infrastructure generally the physical cloud infrastructure is built with the server cluster and provides the essential raw computing resources for the cloud the computing capability supported by the cloud depends on the computing resources e g cpu memory disk and bandwidth the server cluster offers the cloud wps framework supports both public cloud and the private cloud which means it could be implemented inside in both public clouds e g aws google cloud azure or private clouds powered by the open source iaas cloud management frameworks e g eucalyptus openstack cloudstack and opennebula the platform block handles what paas cloud service model does and basically follows the architecture of paas which consists of networking storage servers virtualization operating system middleware and runtime it is responsible for 1 provision of the managed application development and deployment platform 2 virtualization and virtual machine vm support above the physical servers 3 optimization of networking capabilities and management of ips and 4 automatic scale and load balance of computing instances to integrate wps with the existing cloud service model the service client block are added on the top of the framework as the components of saas layer it is the core part of the framework which provides protocols standard interfaces security authentication to wrap all earth science models eo data and geospatial processes into geospatial web services models data and processes are hosted inside the vms that managed by the cloud platform in each vm the service is published through the standardized geospatial web service such as wps wcs wms and wfs therefore in this framework all services are independently deployed but interoperable with each other when users send a request to execute a model the model ready vm would be called and the entire computation would be executed inside the cloud infrastructure moreover the service client block provides the user interface with client interaction modules such as visualization analysis management and other applications the web based client can be accessed by any web browser on a desktop laptop smartphone and tablet as a gateway of the framework the client allows users to send a request and receive the result from the server without worry about the details of the development and deployment of the model processes and applications 2 4 interoperability of the cloud wps framework fig 2 illustrates the relationship among the components of the cloud wps enabled system and the interoperability with other earth science information systems the users of the cloud wps framework enabled system could be divided into four groups earth scientists developers administrators and other users each group of users plays its specific roles and holds specific permission and privilege earth scientists are the top level users who have the permission to directly manipulate model processes and data through geospatial web services developers have the permission of accessing cloud instances and are responsible for developing and publishing earth science models as geospatial web services administrators have the root permission of accessing the cloud management module other users share the computing resources with earth scientists but only have the permission of accessing their own instances or web services as shown in fig 2 in a cloud wps framework enabled system all models processes data and web services are deployed inside the vms all vms are isolated but can be interoperable with each other like all private cloud platforms the cloud wps framework enabled system is powered by the cloud management module which plays the role of deploying and managing large networks of both physical server zones and virtual servers besides the service and data deployed in the local cloud infrastructure the framework is interoperable with other data service providers such as nasa and noaa moreover it can be built as a part of the hybrid cloud by integrating with public clouds and private clouds all vms in the cloud wps framework enabled can be disseminated through general vm formats e g qcow2 compatible with most of the cloud platforms the model pre installed vm could be encapsulated as the model template with the model template users could deploy and reproduce one or more model ready vms inside any cloud 3 prototype of cmaq as a service 3 1 cmaq model global air pollution and air quality issues have made a huge impact on climate environment and especially human health akimoto 2003 u s environmental protection agency usepa set six common air pollutants as the criteria air pollutants ground level ozone particulate matter carbon monoxide lead sulfur dioxide and nitrogen dioxide usepa 2017 each pollutant has the specific physical and chemical property which could affect human health and natural environment at different levels and in different ways kampa and castanas 2008 as a well vetted peer reviewed scientific model for modeling and simulating air quality community multiscale air quality cmaq model provides the capability of estimating the distribution of ozone particulates toxics and acid deposition in the atmosphere cmas 2018 before implementing cmaq as web processing service it is essential to understand how cmaq model works the core cmaq programs and its workflow is described in fig 3 major processors and the chemical transport models of cmaq modeling system includes sparse matrix operator kernel emissions smoke model meteorology model mm5 or wrf meteorology chemistry interface processor mcip photolysis rate processor jproc initial conditions processor icon boundary conditions processor bcon and cmaq chemical transport model cctm among them emission model and meteorology model are third party programs which are not part of cmaq program but supply the necessary input data for air quality simulation mcip icon bcon and jproc are standard cmaq preprocessors providing the mandatory inputs for cctm the output generated by cctm then feeds back to icon and bcon for nested simulations the function of each preprocessor is described as follow icon initial conditions processor icon preprocessor outputs a gridded binary netcdf file of the chemical conditions of the chemical condition for the first hour of simulation in the modeling domain bcon boundary conditions processor bcon preprocessor outputs a gridded binary netcdf file of the chemical conditions along the horizontal boundaries of the modeling domain mcip meteorology chemistry interface processor mcip preprocessor outputs the netcdf formatted meteorology data required by smoke and cctm jproc photolysis rate processor jproc preprocessor outputs the chemical mechanism specific clear sky photolysis rates at fixed altitudes solar hour angles and latitude bands from tabulated absorption cross section and quantum yield csqy data cctm cmaq chemistry transport model cctm is the core processor of cmaq which simulates continuous atmospheric chemical conditions by integrating the outputs from the above preprocessors and smoke cctm outputs binary netcdf files of gridded and temporally resolved air pollutant information including 3 d cctm hourly concentration file conc 3 d cctm ending concentration file cgrid 3 d cctm integral average concentration file aconc 2 d cctm dry deposition file drydep 2 d cctm wet deposition file wetdep 2 d cctm visibility file aerovis table 2 describes the details of the cctm output files 3 2 system architecture cmaq ws a prototype of cmaq as a service is developed based on the cloud wps framework a suite of advanced techniques software and services have been applied to the implementation of this prototype as shown in fig 4 the prototype consists of four major components geobrain cloud cmaq ws cyberconnector and the internet this section describes the major components of the cmaq ws prototype 3 2 1 geobrain cloud all vm instances of the cmaq ws are powered by the geobrain cloud http cloud csiss gmu edu a private cloud platform running by center for spatial information science and systems george mason university geobrain cloud mainly serves for geospatial web services and provides computing source for eo data processing besides a large volume of eo data such as landsat data and modis data are archived inside the cloud it is built with iaas architecture using apache cloudstack as the management framework to manage the network storage computing resources and vms by taking advantage of the powerful open framework the cloud management module offers an elastic and flexible mechanism to assign the load to particular services and dynamically assign the computing resources depending on the input data volume users and developers may access geobrain cloud in different ways including web user interface command line tools and a full featured restful api by integrating the ec2 compatibility interface for apache cloudstack geobrain cloud offers the api that is compatible with api of aws ec2 and s3 the deployment of geobrain cloud is based on the small scale deployment architecture as shown is fig 5 the cloud platform physically contains one management server one layer 2 switch network file system nfs server and computing node geobrain cloud currently manages over 300 cpu cores 500 gb ram and 600 tb storage in total plus a cluster of nvidia tesla k80 gpus are equipped in the geobrain cloud s computing node which is mainly used for offering computing capability for advanced machine learning tasks 3 2 2 cyberconnector cyberconnector is an earthcube building block supporting the automatic preparation and feeding of on demand eo data into earth science models it adopts open geospatial standards specifications to process the eo and geoprocessing workflow in the implementation of cmaq ws cyberconnector 1 automates the handshaking between vms that distributed in application layer interface layer service layer 2 plays as the front end client between users and the service and 3 connects the cmaq ws with the internet and other clouds additionally cyberconnector offers the capability to automatic tailor multi source eo data to model ready input files and feed earth science models which could save a tremendous amount of time and effort for earth science modelers sun et al 2017a the procedure of using cyberconnector to execute cmaq ws is simple it utilizes virtual data products vdp to build geoprocessing workflow cyberconnector provides a web based user interface allowing users to search and order vdp fig 6 shows the screenshot of using cyberconnector to search and order vdp in this case cmaq ws is implemented as a vdp which can be searched and ordered through the cyberconnector web client after the order of cmaq ws is placed cmaq required input data would be automatically tailored from different sources through cyberconnector and delivered to the cmaq vms once the process is done the result will be sent to users via emails 3 2 3 cmaq ws cmaq ws is the core component of this prototype it is composed of a bunch of vm instances according to the difference in the functionality the instances deployed inside the cmaq ws can be divided into three layers application layer interface layer and service layer the followings are a description of the implementation and functionality in each layer the application layer is the gateway of cmaq ws where the web based clients are deployed as the front end client to access cmaq ws the web based client of cyberconnector is deployed inside this layer besides we implemented a lightweight web application to test the prototype it is deployed inside the application layer as well the user interface of the cmaq ws test client is shown in fig 7 two required inputs in the cmaq processes are cmaq input configuration file and cloud configuration file cmaq input configuration file contains the information of all input data that required by the cmaq model cloud configuration file contains the preference of the cloud instance such as cpu cores and memory size of the task the interface layer provides the standard interface to bridge the application layer and the service layer standard geospatial services including wps wms wfs and wcs are implemented in this layer the prototype adopts wps as the standard interface to access cmaq model when a user calls the cmaq service a wps request is sent from the client vm that deployed inside the application layer after the process is done the cmaq output data would be returned through wps standard interface when the process is finished in this study cmaq ws was implemented and tested with both wps 1 0 and wps 2 0 standard interface we used the pywps as the framework of wps 1 0 standard interface and manually implemented core components of wps 2 0 standard interface to support asynchronous wps processes all basic wps operations such as getcapabilities describeprocess execute are supported with wps 1 0 2 0 getstatus and getresult are supported with wps 2 0 the service layer hosts a number of model instances geoprocessing instances and eo data instances cmaq model is implemented as the model instance where cmaq and its dependent libraries software packages are installed cmaq program an open source cmaq implementation developed and released by usepa computational exposure division is the main software package of the cmaq model instance this prototype used cmaq program v5 1 as the implementation of the cmaq model in addition required libraries and dependencies such as netcdf i o api and mpich need to be pre installed and configured inside the instance before running cmaq model netcdf network common data form is the software library that developed and maintained by unidata http www unidata ucar edu to improve interoperability and re usability netcdf became an ogc standards in 2011 and climate and forecast cf extension to netcdf core data model standard was approved in 2013 domenico and nativi 2013 as the essential component to run cmaq model netcdf c library and netcdf fortran library need to be installed models 3 edss input output applications programming interface i o api version 5 1 is another required library for cmaq version 5 1 it provides model developers with the programming library for data storage and access and is available in c and fortran mpich is the library enabling multiple processors for running cmaq 3 3 workflow the workflow of cmaq ws is demonstrated as the sequence diagram in fig 8 before initiating a cmaq processing task users could get the list of available processes by sending getcapabilities request and check the description of specific processes by sending describeprocess request with cmaq ws web client cyberconnector web client or any other wps client then user executes the cmaq process with required wps inputs url of input data and url of configuration file to initiate a cmaq processing task after the request is sent cmaq model vms are automatically instantiated and the task will be assigned to a particular instance based on the cloud configuration file by taking advantage of the elasticity of the cloud the cmaq model vms are dynamically allocated by wps requests then all input data will be fetched and fed into the cmaq instance three sources of the cmaq input data are accepted in this prototype local data servers vms where the required input data are stored geoprocessing model e g wrf model services where the required input data are tailored and generated and other data providers from the internet after fetching required input data the cmaq model starts running inside the cmaq model vms once the process is done the output data are copied from the cmaq model vms to the data server then the cmaq model vms are automatically destroyed the url of the output data is returned as the output of the process and cyberconnector will notify users via email the running state of the cmaq processes could be checked through the getstatus operation either the status of running or done is returned depending on the actual processing status and the final product could be retrieved through getresult operation the user can download the cmaq output data from the data server with the output url the prototype can be integrated as a part of the geoprocessing workflow fig 9 illustrates the sequence diagram of building a geoprocessing model workflow with the prototype in this workflow cmaq ws is not directly requested by users instead as a part of the requested geoprocessing model workflow service cmaq ws is called when the required cmaq input data is ready during the process of the service the output of cmaq ws then would be used for the rest steps of the workflow the final output of the workflow is copied stored in the local data server as the intermediate data of the workflow all output data from the cmaq ws would be removed with the destruction of geoprocessing model vm the prototype provides an easy to use dissemination solution all components of the prototype including client wps interface cmaq geoprocessing model service data server are implemented as vm instance each component can be disseminated through vm template in qcow2 format which is a general vm format compatible with major cloud platforms with the vm templates image users can upload the template image to the private or public cloud platforms such as openstack cloudstack and aws 3 4 benchmark and validation a series of experiments on the implementation using the cmaqv5 1 benchmark data as the input dataset has been conducted in this study the cmaqv5 1 benchmark data is the open access dataset which can be downloaded at https www cmascenter org download software cmaq tracker cmaq5 1 cfm to generate the cctm data all input data need to be fed into the prototype and cmaq processes need to be executed three basic processes which cmaq model executes in the prototype are 1 mcip to prepare the cmaq ready meteorological data from the wrf output 2 icon and bcon to create initial and boundary conditions input data and 3 cctm to estimate air quality fields assuming the wrf meteorology and smoke emissions data are ready to use wps is expected to do is to generate icon profile bcon profile and cctm output data in this experiment it takes only a few seconds to generate icon profile and bcon profile however generating cctm output data could take a couple of hours the prototype aims to publish cmaq model as the web processing service it could be a tough job for users to run cmaq model through wps 1 0 due to the longtime process of cctm and unavailability of asynchronous processing capability in wps 1 0 to handle this issue the cloud wps framework adopts the wps 2 0 standard interface which provides the asynchronous processing capability a group of tests with different computing resource offerings have been conducted for testing the performance of cmaq ws the instance types and the specification that geobrain cloud offers are listed in table 3 the cmaq program supports serial mode and message passing interface mpi mode serial mode only allows cmaq model running on a single cpu core no matter how much the instance offers mpi on the other hand is a standard interface for parallel computing pacheco 1997 running the cmaq model in mpi mode could make the most of the power of multi core cpu and substantially reducing the computation time this test compares the performance of cmaq ws in both serial mode and mpi mode fig 10 displays the test result of running the cmaq ws with multiple instance type in the serial mode increasing the number of cpu cores does not observably improve the performance of cmaq ws in the mpi mode the performance is significantly improved with the increasing of the number of cpu cores there is no distinct difference for the performance of the service while running on the small instance with single cpu core to validate the output data the cctm outputs have been compared with cmaq reference benchmark data which could be accessed at https www cmascenter org cmaq the result shows the content and size of cctm data generated from the prototype are the same as the reference benchmark data fig 11 displays the selected pollutants of cmaq hourly average concentration aconc data generated by the cmaq ws fig 12 compares the output aconc data of cmaq ws and cmaq reference benchmark data 4 discussion this section is organized to 1 summarize the answers to the questions that are posed in section 1 2 address some limitations on the current implementation and 3 discuss the potential improvement methods and the future work the first question is how the cloud wps framework simplifies the installation and configuration process of the earth science model in the case of the implementation of cmaq as a service since the cmaq ws has been pre installed and configured inside the vm which is instantiated from the model ready vm template image users do not have to spend time on the installation and configuration of cmaq model technically developers still have to set up the original vm template image and this process is required and not simplified but once the model vm template image is ready the model vm would be directly instantiated without installation and configuration for each use of any user the second question is how can the model be published as a service and interoperated through the standardized interface the feasibility of implementing cmaq model as the wps has been explored in this study with the support of ogc wps standard interface the cmaq ws is interoperable with any standardized service as the originality of this work the cloud wps framework provides a general solution to integrate earth science model wps and cloud infrastructure in a cloud wps framework enabled system all models geoprocessing are eo data are deployed as vm instance all instances are isolated but can be interoperable with each other the third question is how much performance of the model can be improved by moving the computing from local to the cloud the implementation of the cmaq ws prototype is completely powered by geobrain cloud it is an iaas architecture based cloud platform that offers a lot of advantages including 1 services and applications that are deployed on the cloud are easy to access and data stored in the cloud are easy to share 2 rather than storing in the local storage of individual computing devices data and software that stored in the cloud are more reliable and ready for use 3 computing capability offered by the cloud infrastructure is much more powerful and flexible than local computing resources traditionally available to researchers and 4 users do not have to take responsibility for maintaining the computing resources these merits could significantly benefit the earth scientists especially those who are non professional it users but dealing with large scale eo data processing the originality of this work is the cloud wps framework which provides a general solution to integrate earth science model wps and cloud infrastructure compared to the traditional way of earth science modeling this framework brings a lot of benefits such as simplicity ease of use and no local computing resource requirement to earth scientists however the current prototypical implementation of the cloud wps framework still has some limitations the input data of the cmaq model are usually generated from the wrf model in this study we focused on the implementation of the cmaq model and assumed that the wrf meteorology and smoke emissions data are ready to use to build a full environmental modeling system and implement wrf cmaq two way coupled model upon the current prototype the wrf as a service needs to be implemented along with the cmaq as a service the prototype has been implemented only on the geobrain cloud platform and tested internally to test its interoperability between the geobrain cloud and other private and public cloud the prototype needs to be migrated to other private and public cloud although the dissemination of vm is not a labor intensive task the large size of the model vm template image could be a limitation when disseminating the vm for each instance of the prototype it contains not only model related programs but the entire operating system a potential solution is adding a docker container layer between the service layer and the platform layer in each vm instance by integrating the framework with docker the model client data or standard interface could be exported as the docker image and may significantly facilitate the dissemination of the service in the next stage we are going to tackle the above limitations and improve the proposed framework additionally further tests will be performed by applying advanced parallel computing approaches such as mapreduce with a larger volume of data from different sources the cmaq model will be updated from cmaqv5 1 to cmaqv5 2 which is the latest version of cmaq software moreover more earth science models other than cmaq will be tested with the cloud wps framework to make the prototype more powerful and more flexible a series of upgrades to the current geospatial web services and cloud infrastructure will be conducted more services and datasets will be registered into cyberconnector and more high performance computing resources will be added to the geobrain cloud with the improvement of both software and hardware more features and functions of cloud based wps will be explored in the future 5 conclusion this study explored the cloud based web processing service and presented the cloud wps framework particularly a prototype of cmaq as a service was implemented as cmaq ws all components of the prototype including web based client standard interfaces models eo data and geoprocessing were deployed as vm instances managed by geobrain cloud and seamlessly bridged by the cyberconnector a group of validation experiments were performed using the cmaqv5 1 benchmark dataset to validate the implementation the result shows the proposed framework provides a general solution for integrated manipulation of models data and processes through ogc standard interfaces over the cloud by implementing cmaq ws inside the cloud infrastructure the performance of the cmaq model can be significantly improved meanwhile earth scientists would be relieved from model installation data collection and large scale computation so that they can concentrate on research issues instead of tedious tasks on software installation and maintenance as well as data collection and preprocessing acknowledgment this work is supported by grants from nsf earthcube program grants icer 1440294 and ags 1740693 pi dr liping di and ogc testbed 13 the authors would like to thank ms julia di of columbia university for editing and proofreading the manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 11 019 
26261,a few management tools can simultaneously describe dissolved and particulate p losses from agricultural fields in this study a phosphorus p management tool was developed based on most recent scientific findings to meet this need and it was subsequently incorporated into root zone water quality model 2 rzwqm2 to take advantage of its featured hydrologic and agricultural management subroutines the rzwqm2 p model was evaluated against data collected in a tile drained corn soybean rotated field fertilized with inorganic p at south woodslee ontario the results indicate that overall the model satisfactorily simulated dissolved reactive p and particulate p losses through surface runoff and tile drainage with nash sutcliffe model efficiency coefficient 0 65 percent bias within 25 and index of agreement 0 75 rzwqm2 p is a promising tool for p management particularly for subsurface drained fields further testing is needed to assess its performance under different fertilization manure soil climate and cropping conditions keywords p modelling eutrophication rzwqm2 subsurface drainage surface runoff abbreviations list p phosphorus p org frsh fresh organic p p org stbl stable organic p p inorg stbl stable inorganic p p inorg act active inorganic p plab labile p pool p inorg h 2 oex man manure water extractable inorganic p p org h 2 oex man manure water extractable organic p p inorg stbl man manure stable inorganic p p org stbl man manure stable organic p p av fert available fertilizer p p res fert residual fertilizer p p dr dissolved reactive p p part particulate p pudr dissolved unreactive p fertp fertilizer p manp manure p p tot soil total p p sum sum of p dr p part pbias percent bias nse nash sutcliffe model efficiency ioa index of agreement gh grain harvested ob observed sim simulated et evapotranspiration s soil water change rzwqm2 root zone water quality model version 2 rzwqm2 p root zone water quality model version 2 phosphorus pb air entry pressure  pore size index k sat saturated hydraulic conductivity k lat lateral hydraulic conductivity  soil bulk density om soil organic matter content  fc volumetric soil moisture content at field capacity  soil porosity  wp volumetric soil moisture content at permanent wilting point ph soil ph 1 introduction agriculture phosphorus p demand accounts for 80 90 of global phosphorus consumption the supply of p is heavily dependent on mined rock phosphate a non renewable resource becoming increasingly scarce and expensive day by day in plants phosphorus plays a role in cellular energy transfer respiration and photosynthesis and is a structural component of the nucleic acids of genes and chromosomes as well as many coenzymes phosphoproteins and phospholipids grant et al 2001 while proper crop growth and the maintenance of high yields are critical to agricultural production crop p use efficiency in the year of application is rather low 15 30 syers et al 2008 the build up of legacy p in soils under long term application has increasingly caused p losses from soil to surface waters such p losses from agricultural fields via water and sediment have become a serious environmental concern degrading the quality of water in fresh water bodies e g lakes and rivers as well as brackish sea waters e g sea coast rivers outlets by causing a rapid increase in algal populations leading to eutrophication guildford and hecky 2000 such algae infested water is resulting in adverse ecological conditions for aquatic flora and fauna it is now an established fact that excessive p loading of fresh water bodies and coastal sea areas can be confidently attributed to an over application of fertilizer in upstream agricultural fields it is estimated that 80 of the p pollution reaching lake champlain s missisquoi bay originated in upstream agricultural lands hegman et al 1999 in quebec alone some 156 lakes were already deemed polluted by p msss 2007 as removal of excess p from water by chemical surampalli et al 1995 or biological oehmen et al 2007 means is complex expensive and time consuming remediation of eutrophication in rivers and lakes is difficult one practical option to mitigate this problem is to arrest p loss right at the source by adopting proper agricultural management practices to control p loss from an agricultural field one must understand the p dynamics of an agricultural field kleinman et al 2015 indicated that computer modelling drawing on measured p data was a currently priority in achieving this goal of available agricultural p management models icecream tattari et al 2001 seems to be the best at simulating p losses through tile drains radcliffe et al 2015 however in the absence of a water table based tile drainage component icecream uses matrix and macropore flow flux at a certain soil depth to mimic tile drainage qi and qi 2016 radcliffe et al 2015 icecream adopts simple storage routing concepts to simulate matrix flow within the soil profile this can be improved by adopting the soil matric potential based richards equation richards 1931 to simulate matrix flow and hooghoudt s equation bouwer and van schilfgaarde 1963 to simulate tile drainage with no separate p pool to simulate manure and fertilizer p dynamics icecream assumes that manure or fertilizer p are mixed with the soil upon application modelling p in an agricultural field involves modelling of hydrological processes on and below the ground surface and the effects of agricultural management practices a p model needs to simulate both surface hydrological processes e g soil evaporation plant transpiration runoff and soil erosion and subsurface hydrological processes e g infiltration matrix flow preferential flow or macropore flow flow to tile drainage fluctuation of water tables root water and nutrient uptake and soil moisture redistribution agricultural management practices such as surface irrigation and sub irrigation drainage fertilization tillage and residue management and crop rotation influence the fate and transport of p the success of a p model greatly depends on how effectively and efficiently the model captures these hydrological processes and how these processes are parameterized within the model rzwqm2 ahuja et al 2000 a widely tested field scale process based model is an ideal option as a base of a p model because it is equipped with subroutines to simulate all the hydrological processes and agricultural management practices mentioned above it has been extensively evaluated at locations across the united states fang et al 2014 gillette et al 2018 hanson et al 1999 ma et al 2004 2007a 2007b malone et al 2014 qi et al 2011 2013 thorp et al 2008 wang et al 2015 and in canada ahmed et al 2007a 2007b al abed et al 1997 madani et al 2002 jiang et al 2018 nonetheless current p models lack the capacity to adequately simulate p losses particularly those occurring through tile drainage radcliffe et al 2015 in this study an attempt was made to develop a model based on most recent scientific finding regarding the fate and transport of p from an agricultural field available in the literature and to test this new p management tool against measured hydrologic and p data in a tile drained cropland 2 materials and methods 2 1 p model the p model fig 1 is designed with five different soil p pools three inorganic namely labile p plab active inorganic p p inorg act and stable inorganic p p inorg stbl and two organic pools namely fresh organic p pool p org frsh and stable organic p pool p org stbl respectively following the nomenclature of jones et al 1984 besides these soil p pools as an advanced feature the model also has four surface manure p pools and two surface fertilizer p pools to simulate p dynamics arising from the application of fertilizer and manure vadas 2014 the manure p pools p man are inorganic water extractable p p inorg h 2 oex man inorganic stable p p inorg stbl man organic water extractable p p org h 2 oex man and organic stable p p inorg stbl man the fertilizer p pools p fert were available fertilizer p p av fert and residual fertilizer p p res fert p org frsh fresh organic p p org stbl stable organic p p inorg stbl stable inorganic p p inorg act active inorganic p plab labile p pool p inorg h 2 oex man manure water extractable inorganic p p inorg h 2 oex man manure water extractable organic p p inorg stbl man manure stable inorganic p p org stbl man manure stable organic p p av fert available fertilizer p p res fert residual fertilizer p p dr dissolved reactive p p part particulate p fertp fertilizer p manp manure p among these p pools the p lab pool is considered to be in dissolved form and the most dynamic p pool in addition it is the only p pool from which plants can uptake p plant root density is the highest near the soil surface so plant p uptake in the upper portion of the soil profile is more than that in deeper layers this depth distribution of plant p uptake is controlled by plant p uptake distribution parameter the governing equations of plant p uptake were adopted from neitsch et al 2011 there is constant absorption and desorption happens among these three inorganic p pools to maintain an equilibrium the p lab pool is in rapid equilibrium with the p inorg act pool which is in slow equilibrium with the p inorg stbl pool the rapid adsorption and desorption of inorganic p in the soil between plab and p inorg act is simulated based on jones et al 1984 with advanced dynamic absorption and desorption as prescribed by vadas et al 2006 this modification enables the model to simulate p movement among these pools by using a dynamically changing rate factor rather than a constant rate factor the slow adsorption and desorption of inorganic p in the soil between p inorg act and p inorg stbl is simulated based on jones et al 1984 after decomposition p from plant residues and soil humus are added to the p org frsh pool and the p org stbl pool respectively mineralization happens from p org frsh pool and mineralized p is added to the p lab and the p org stbl pools a slow mineralization also follows in the p org stbl pool and mineralized p is added to the p lab pool immobilization happens in the p lab pool and immobilized p is added to the p org frsh pool when fertilizer and or manure is applied in the field the fertilizer and or manure p is subsequently added to the p fert and p man pools based on application depth type and properties of fertilizer and or manure applied vadas 2014 these independent p man and p fert pools enable the model to simulate more precisely the p dynamics arising from the application of fertilizer and manure in an agricultural field then the leaching and decomposition takes place from these pools decomposed and leached p are added to the soil p pools the ability of the p model to simulate p dr through tile flow is improved by adopting the recommendations of francesconi et al 2016 whereas the p part loss through tile drainage is simulated by considering colloidal particle transport through macropore flow jarvis et al 1999 larsson et al 2007 in the model the first soil layer is set to a 0 01 m depth as the model assumes that particle bound p originates from the first 0 01 m depth of the soil profile all the p pools contribute to p part loss whereas the p lab pool p org h 2 oex man and p inorg h 2 oex man pools and all the p fert pools contribute to p dr loss to simulate p dr and p part loss through tile drainage the linear groundwater reservoir based approach as suggested by steenhuis et al 1997 was used in this approach p dr is generated through matrix flow and macropore flow while p part is only generated through macropore flow and is first to contribute to a groundwater reservoir subsequently a daily mass balance is calculated then p dr and p part is lost along with the tile drainage water from this groundwater reservoir all the equations used in the model are provided in the attached supplementary documents 2 2 rzwqm2 overview developed by the usda ars the rzwqm2 model ahuja et al 2000 is a field scale one dimensional model which integrates physical biological chemical and hydrological processes and simulates crop growth hydrologic cycle fate and transport of nutrients and pesticides under different agronomic management practices and climate patterns within the rzwqm model soil water retention is described using the brooks corey equation brooks and corey 1964 the green ampt approach green and ampt 1911 is used to compute the infiltration the model employs the richards equation richards 1931 to simulate soil water redistribution following infiltration in the soil profile tile drainage flow is calculated by hooghoudt s steady state equation bouwer and van schilfgaarde 1963 and the macropore flow is governed by the poiseuille s law the simultaneous heat and water shaw model flerchinger 1987 is linked to rzwqm to simulate ice in soil snow accumulation snow melting as well as soil freeze thaw cycles the crop growth can be simulated either by embedded dssat 4 0 crop models jones et al 2003 or a generic crop production model hanson 2000 whereas evapotranspiration is estimated using the double layer shuttleworth wallace model shuttleworth and wallace 1985 2 3 p model and rzwqm2 integration the p model described above was first developed then incorporated into the rzwqm2 model while the p model simulates p dynamics the rzwqm2 governs the physical biological chemical and hydrological processes that influence the p simulation the developed p model combined with rzwqm2 performs as a single tool the p model being dependent on rzwqm2 for the simulation of crop growth runoff drainage soil moisture and its flux soil temperature sediment yield macropore flow residue and soil humus decomposition and agriculture management practices all these components are simulated by rzwqm2 within its original functionalities and then the p model uses model outputs to simulate p dynamics and p loss through surface runoff and tile drainage from an agricultural field the p model s working algorithms along with its dependencies on rzwqm2 are presented in fig 2 2 4 field experiment to evaluate the p model observed runoff and drainage water flow as well as p dr and p part mass in both runoff and tile drainage water were collected from an agriculture agri food canada aafc experimental site the hon eugene f whelan research farm near south woodslee on 42 21n 82 74w from june 2008 to december 2012 the site was comprised of 16 plots 67 1 m 15 2 m receiving different fertilizer types and drainage system treatments among these plot numbers 5 and 9 selected for the present study received inorganic npk fertilizer applications and were subject to standard tile drainage depth 0 85 m spacing 3 8 m zhang et al 2013 the crop was rotated between maize zea mays l and soybean glycine max l merr in alternating years in 2008 2010 and 2012 maize was planted at a density of 79 800 seeds ha 1 while in 2009 and 2011 soybean was planted at a at a density of 486 700 seeds ha 1 the inorganic fertilizers 114 5 kg p 2 o 5 ha 1 roughly 50 kg p ha 1 200 kg n ha 1 from nh 4 no 3 and 100 kg k ha 1 from kcl were surface applied before planting in the maize planting years chisel plow tillage was done each year after harvest or in the following year before planting the dates of cropping and other crop management practices are presented in table 1 the p content in corn and soybean grain were measured after harvest between 20 october and 13 december each year grain samples were dried at 55 c ground and passed through a 1 mm sieve and digested using a h2so4 h2o2 procedure phosphorus concentrations in all of the filtrates and digests were determined using a quikchem flow injection auto analyzer lachat instruments employing the ammonium molybdate ascorbic acid reduction method murphy and riley 1962 the soil type was clay loam and the measured soil properties for plots 5 9 were averaged table 2 and used as the soil input data for the model the soil profile was delineated into six layers the soil properties such as soil texture field capacity fc permanent wilting point wp and saturated hydraulic conductivity k sat were measured before the start of the experiment soil bulk density  and porosity  were measured in 2010 where as k sat was measured in the year 2008 prior to the onset of the experiment in 2008 soil p was measured using the olsen p method olsen et al 1954 volumetric soil moistures  for the soil layer ranging in depth between 0 and 0 08 m were measured twice a week using a portable probe while soil temperature tsoil at depth of 0 05 m was measured hourly from june to october for the years 2010 2011 and 2012 using sensors hourly tsoil were averaged to obtain daily mean tsoil the required weather data air temperature precipitation relative humidity solar radiation and wind speed to run the model were collected for the period of 1st jan 2008 to 31st dec 2012 from the automated meteorological weather station located at the whelan farm located less than 500 m from the experimental site during the winter 1st oct 30th april of 2009 2010 and 2011 rain gauge inaccuracies for snowfall precipitation led to data being obtained from environment canada s harrow weather station station id 6133362 42 030n 82 90 0w located 16 6 km from the study field in each experimental plot there was a catch basin similar to a sewage sink at their downstream end to collect the surface runoff surface runoff and tile drainage from the experimental plot were directed to a central instrumentation building via underground pvc pipes in the instrumentation building the flow rate was measured automatically using electronic flowmeters and recorded in a multi channel data logger surface runoff and tile drainage water samples were collected automatically using autosamplers calpso 2000s buhler gmbh company surface and tile water samples were collected continuously year round proportionally to flow volume samples being taken for every 1000 l of flow during the growing season and for every 3000 l of flow during the non growing seasons after the collection the samples were analyzed in the laboratory for p dr and total dissolved p p td using an acidified ammonium persulfate nh4 2s2o2 oxidation procedure usepa 1983 unfiltered water samples were analyzed for total p p tot using the sulfuric acid hydrogen peroxide digestion method usepa 1983 the p part was computed by the difference between p tot and p td 2 5 model calibration and validation the rzwqm2 with this newly developed p model was run using the four and a half years june 2008 dec 2012 of data collected from the experimental site there were some limitations on flow event separation during the flow data collection so to ensure the precision of p loss estimation the collected data was aggregated into 19 different periods table 3 and out of these the first twelve periods 01 june 2008 to 21 dec 2010 two and half years were used for calibrating the model while the last seven periods 22 dec 2010 to 09 dec 2012 two years were used for validating the model during the calibration process parameters related to soil moisture soil temperature surface runoff and tile drainage were initially calibrated as these processes control the p loss from an agricultural field then the parameters related to p loss through surface runoff and tile drainage were calibrated the calibration was undertaken manually while changing the calibration parameters within the range as obtained from prior studies and available literature by a trial and error method following the protocol given by ma et al 2011 and iterated several times until a good match with the observed data was obtained three model evaluation statistics nash sutcliffe efficiency nse percent bias pbias and index of agreement ioa moriasi et al 2007 2015 served to evaluate the performance of the model in simulating hydrology soil moisture soil temperature and p loss through surface runoff and tile drainage model performance was catergorised as very good good statisfatory and unsatifactory based on the criterion of those model evaluation statistics as recommended by moriasi et al 2007 2015 the model is regarded to perform satisfactorily when nse 0 50 and good when nse 0 65 model performance is deemed to be satisfactory when pbias is between 15 and 25 for water flow and is between 40 and 70 for p and it is deemed to be good when pbias is between 10 and 15 for water flow and is between 25 and 40 for p moriasi et al 2007 model performance is regarded as acceptable when ioa 0 75 moriasi et al 2015 in rzwqm2 model soil moisture content is parametrized with air entry pressure pb and pore size distribution index  initially the values pb and  were set to the default values of these parameters according to soil texture as given by ma et al 2011 then subsequently these values were adjusted to match the observed values the value of  was found to be more sensitive than that of pb in soil water simulations an increase in  resulted in reduction in soil water content whereas an increase of pb led to increase of soil water content once the soil moisture content was calibrated and a good fit with the observed value was found then calibration of runoff and tile drainage followed to calibrate runoff parameters such as saturated hydraulic conductivity k sat surface crust hydraulic conductivity k crust and albedo were adjusted in rzwqm2 runoff is simulated when the rainfall rate exceeds the infiltration rate ma et al 2012 so the top layer k sat and k crust values were adjusted to obtain a good fit with the observed runoff furthermore the albedo was adjusted for simulation of evapotranspiration which in turn affected surface runoff for tile drainage calibration k sat pb and lateral hydraulic conductivity k lat were adjusted increasing k sat resulted in an increase in tile drainage whereas increasing pb resulted in decrease in tile drainage moreover k lat had very prominent influence in tile drainage simulation and it was adjusted to 2 k sat in addition pb was slightly adjusted to better match tile drainage without hampering the previous calibration for soil moisture the loss of p dr through surface runoff was calibrated by adjusting the soil p extraction coefficient while calibration of p dr loss through tile drainage depended on macroporosity pb and  of the deeper soil layers in the model macropore flow is initiated when the top soil layer becomes saturated and p dr carried away through macropore flow depends on the volume of macropore flow therefore to control the p dr loading to the groundwater reservoir the macroporosity value was adjusted finally the pb and  of the deeper soil layers were slightly adjusted to control the p dr loading to groundwater reservoir by matrix flow without altering the earlier results for tile drainage and soil moisture simulations the p part loss through surface runoff was calibrated by adjusting usle soil loss coefficients soil erodibility factor cover and management factor support practice factor and manning s n these parameters control the sediment yield thereby controlling the p part loss through surface runoff increasing soil erodibility increased the sediment yield while increasing the manning s n reduced it accordingly to obtain a good match of p part loss through surface runoff these two parameters were carefully adjusted along with the cover and management factor and support practice factor the p part loss through tile drainage is controlled by parameters like soil replenishment rate coefficient soil detachability coefficient and soil filtration coefficient these parameters govern the colloidal particle loss to subsurface flow hence limit the p part loss through tile drainage the high soil filtration coefficient leads to less colloidal particle loss whereas the increase of soil detachability coefficient and soil replenishment rate coefficient leads to more colloidal particle loss so these parameters were carefully balanced over the calibration period to get a reasonable simulation with respect to p part loss through tile drainage finally to adjust the plant p uptake from the p lab pool the p uptake distribution parameter for each crop was adjusted calibrated soil hydraulic parameters and their values are presented in table 4 and all other calibrated parameters are presented in table 5 3 results 3 1 soil moisture and soil temperature the time series of simulated and observed soil temperature tsoil at 0 05 m depth and soil moisture  between 0 and 0 08 m depths are presented in fig 3 the simulation statistics are summarized in table 6 model simulation of  and tsoil ware satisfactory with nse of 0 64 pbias of 0 30 and ioa of 0 89 and with nse of 0 59 pbias of 13 08 and ioa of 0 89 respectively 3 2 hydrology simulated vs observed surface runoff and tile drainage are depicted in fig 4 a and b respectively and the accuracy statistics presented in table 7 for the calibration period simulation in surface runoff was very good and in tile flow was satisfactory based on the model evaluation criteria during the calibration period surface runoff was estimated with pbais of 12 47 and with nse of 0 85 while drainage was estimated with pbais of 12 46 and the nse of 0 60 the simulated average annual runoff and tile drainage were 129 57 mm and 375 43 mm table 8 respectively these values were very close to the observed annual mean values overall the model s performance was very good in simulating runoff nse 0 75 pbias within 10 and ioa 0 75 and good in simulating tile drainage nse 0 65 pbias within 10 and ioa 0 75 the simulated vs observed water balance components are summarized in table 8 during the four and a half years of simulation simulated average annual et 449 73 mm was 47 45 of the observed annual precipitation 947 71 mm this was similar to annual et that was 45 of measured precipitation in the same region tan et al 2002 between the simulated average annual surface runoff and tile drainage most 74 34 of the water moved out of the field through the tile drainage system 3 3 dissolved reactive phosphorus p dr loss simulated and observed p dr loss through runoff and drainage for the calibration and validation periods are presented in fig 5 aand b and the simulation statistics are summarized in table 7 the simulation statistics show that the p model s simulation of p dr loss through surface runoff during the calibration period was in very good agreement with the observed data nse 0 75 pbias within 25 and ioa 0 75 whereas for tile drainage it was good nse 0 65 pbias within 25 and ioa 0 75 during the validation period simulated p dr loss through runoff was satisfactory and simulated p dr loss through tile drainage was good table 7 overall the p model could simulate the p dr loss through both surface runoff and tile drainage in very good agreement with the observed data nse 0 75 pbias within 25 and ioa 0 75 and it was found that most of the p dr 75 74 of total simulated p dr loss was lost through the tile drainage system during the simulation period table 9 3 4 particulate phosphorus ppart loss simulated p part loss through runoff and tile drainage agreed well with the observed data simulation results and statistics are presented in fig 5cand d and table 7 respectively analysis of observed data revealed that 68 07 of the net p loss p dr p part was lost in the form of p part and tile drainage contributed 63 47 of the total p part loss more p part loss than the surface runoff table 9 the model captured this well and simulated 68 04 of the net p loss in the form of p part and simulated tile drainage p part loss was 63 36 of the total p part loss overall the model s ability in simulating p part loss through surface runoff and subsurface drainage was very good and good respectively fig 5c and d and table 7 3 5 sum of pdr and ppart p s u m loss the simulation results of the sum of p dr and p part loss psum through surface runoff and tile drainage and its statistics are presented in fig 5e f g and table 7 respectively observed data revealed that tile drainage dominated the p sum loss composing 67 04 of total annual p sum loss while the simulated p sum loss through tile drainage was 67 32 of the total annual p sum loss the simulation of p sum loss through surface runoff was very good nse 0 75 pbias within 25 and ioa 0 75 while it was good during the validation period nse 0 65 pbias within 25 and ioa 0 75 the simulation of p sum loss tile drainage during the calibration and validation period was good and very good respectively overall the p sum loss simulations through both surface runoff and tile drainage were very good table 7 the simulation of total p sum loss from the field such as sum of p dr in both runoff and drainage and p part in both runoff and drainage for the entire simulation period was also very good fig 5g and table 7 4 discussion the field experiment showed that subsurface drainage was the major pathway of p loss from the field comprising 67 04 of total annual average p sum loss the annual average p sum loss through tile drainage was dominated by p part which accounted for 63 47 of total annual average p sum loss through tile drainage table 9 in contrast a study conducted by qi et al 2017 with the icecream model at the same site reported that icecream failed to simulate the p part loss through tile drainage and that soil moisture content was also not simulated satisfactorily they concluded that it could be improved by adopting the soil matric potential based richards equation to simulate soil matrix flow radcliffe et al 2015 noted that although icecream was one of the best p simulation models available to date it lacked macropore and tile drainage components the newly developed p model combined with rzwqm2 addressed all the concerns that were previously highlighted qi et al 2017 reported that icecream simulated p dr loss through tile drainage within 18 of observed values and with nse of 0 66 while it failed to simulate p part loss through tile drainage nse 0 0 and pbias 44 while comparing the simulation results of this study table 7 with those of qi et al 2017 we found that the p model s capability was particularly improved in its simulation of p loss through the tile drainage system the model s simulation of p loss particularly through tile drainage system improved after the proper calibration of soil moisture the adoption of richards equation led to better soil moisture and soil matrix flux simulations table 6 this had a direct impact on p dynamics as soil moisture governs the decomposition and mineralization rate and p flows among the various pools and soil matrix flux determines the amount of p loading to the tile drainage system the use of poiseuille s law resulted in better macropore flow simulations which is one of the major pathways of p dr and p part loading to the tiles finally the use of hooghoudt s steady state equation further improved tile drainage simulations and p loss through tile drainage soil temperature also has an important role in simulation of p dynamics in agricultural fields an acceptable soil temperature simulation table 6 led to good estimation of p flow rate among various p pools decomposition and mineralization rates of residue and soil organic matter analysis of the observed data for both growing seasons periods 2 3 7 8 11 12 15 17 19 and non growing seasons periods 1 4 6 9 10 13 14 revealed that 75 71 of total drainage volume and 60 14 of total runoff volume occurred in the non growing seasons consequently the p loss during non growing seasons was dominant during non growing seasons runoff carried away 56 24 of the total runoff bound p dr whereas 64 47 of total tile drainage bound p dr loss occurred during non growing seasons the same was observed for the p part loss with 64 97 of total runoff associated p part and 74 34 of total drainage associated p part being lost during the non growing seasons p sum loss in the non growing seasons during the whole simulation years comprised 68 19 of total p sum loss through surface and subsurface water flow the newly developed model satisfactorily simulated the fact that the major flow and p loss from the field occurred during non growing seasons for simulated discharge 66 97 of total runoff and 67 91 of total drainage occurred in the non growing seasons whereas simulated p sum loss during non growing seasons represented 65 76 of the total p sum lost through surface and subsurface water flow these simulated results also corresponded well to the observations of king et al 2015 who found that the non growing period represents a significant proportion of annual discharge and p loss the developed rzwqm2 p model is easy to run with menu driven graphical user interface although the data required to run the model seems to be meticulous but it can be easily collected from many resources when in situ measurement is not feasible weather data can be obtained from online resources for free or with nominal charges agricultural management data can be collected while interviewing the farmer or the farm manager of the site it can also be made available from various factsheets as published time to time by various agricultural agencies soil data can be derived using basic county soil survey information along with pedotransfer functions schaap et al 2001 or tables as provided by ma et al 2011 and rawls et al 1982 initial soil p values can be estimated while running the model for certain amount of years prior to start of actual simulation year with typical agronomical management practices and cropping system of the site rzwqm2 p has in built database of crop phenology parameters for most common crop cultivars this database can be used to default the crop phenology parameters computer simulation models inevitably have some limitations because they are built on assumptions and simplified version of the very complex real world phenomenon in this context rzwqm2 p model is limited to one dimensional and assuming soil as a homogeneous medium the model is not designed to simulate dissolved unreactive p pudr loss it also assumes that ppart originates from the first 0 01 m soil layer and only the macropore flow contribute to tile drainage bound ppart loss another shortcoming of rzwqm2 p is that it is a field scale model which cannot be applied over large scale watershed despite these limitations and assumptions rzwqm2 p can be used in a wide range of scenarios to mitigate p pollution under various agricultural management practices along with different cropping systems that are commonly adopted in north america agricultural management practices include tile drainage control drainage with or without sub irrigation various type of tillage application surface sub surface and injected inorganic fertilizer manure application manure type includes poultry swine beef cattle and dairy cattle under solid and liquid phases rzwqm2 p can also be applied to identify the impact of winter manure application which is a common practice in many areas of north america in this present study we presented the development of rzwqm2 p and its very first evaluation with a tile drained corn soybean rotated field under inorganic p fertilization over a period of four and half years the evaluation resulted in satisfactory performance of the model over the both calibration and validation periods although rzwqm2 p seems to be a promising tool to manage agricultural p under the given management practices to be certain about the efficacy of the model further tests are recommended at several other locations under different fertilization i e manure soil climate and crop conditions for a longer period with more observational data 5 conclusions in this study a model based p management tool was developed to simulate the fate and transport of p dr and p part from an agricultural field based on most recent scientific findings while overcoming the limitations of the icecream model as highlighted by previous researchers qi et al 2017 radcliffe et al 2015 and taking advantage of the process based agro hydrologic model rzwqm2 the new p model incorporated into rzwqm2 combined the proven strengths in simulating the impacts of agricultural management practices and hydrological processes in an agricultural field with the ability to simulate p dynamics the p model was evaluated against four and a half years of data collected from a subsurface drained corn soybean rotated field with clay loam soil in southwestern ontario canada the simulation results showed that the newly developed model performed satisfactorily in simulating the p dr and p part losses through both surface runoff and subsurface drainage with all periods nash sutcliffe model efficiency coefficient 0 65 percent bias within 25 and index of agreement 0 75 the p model s p loss simulating ability was improved particularly through tile drainage by adopting richards equation for simulation of soil matrix flow and hooghoudt s equation for simulation of tile drainage flow the use of poiseuille s law may have resulted in better macropore flow simulations which led to better simulations of p part loading to the tile system however this needs further investigations the simulation results were consistent with the observed trend that the non growing season dominated the p loss over growing seasons tile drainage contributed more towards these losses and p part was the major form of p loss the newly developed p module integrated with rzwqm2 is a promising tool for p management particularly for subsurface drained fields further tests are needed to evaluate this model under different fertilization manure soil climate and crop conditions software availability 1 name of the software root zone water quality model 2 phosphorus rzwqm2 p 2 developer details debasis sadhukhan and zhiming qi department of bioresource engineering macdonald campus mcgill university sainte anne de bellevue qc canada h9x 3v9 email debasis sadhukhan mail mcgill ca zhiming qi mcgill ca 3 year first available 2018 4 hardware and software required general pc with 4 gb ram and 1 gb of free space winnows 7 or higher 5 availability http www water environment lab mcgill ca 6 cost free 7 program size 72 1 mb 8 program language english acknowledgements this research is sponsored by natural sciences and engineering research council of canada nserc discovery grant rgpin 04784 14 development of a model based phosphorus management tool for manure applications in subsurface drained field the authors also sincerely acknowledge the financial supports of ms erin hogg a distinguished mcgill alumnus through a sustainable agriculture doctoral fellowship to carry forward this research appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 12 007 
26261,a few management tools can simultaneously describe dissolved and particulate p losses from agricultural fields in this study a phosphorus p management tool was developed based on most recent scientific findings to meet this need and it was subsequently incorporated into root zone water quality model 2 rzwqm2 to take advantage of its featured hydrologic and agricultural management subroutines the rzwqm2 p model was evaluated against data collected in a tile drained corn soybean rotated field fertilized with inorganic p at south woodslee ontario the results indicate that overall the model satisfactorily simulated dissolved reactive p and particulate p losses through surface runoff and tile drainage with nash sutcliffe model efficiency coefficient 0 65 percent bias within 25 and index of agreement 0 75 rzwqm2 p is a promising tool for p management particularly for subsurface drained fields further testing is needed to assess its performance under different fertilization manure soil climate and cropping conditions keywords p modelling eutrophication rzwqm2 subsurface drainage surface runoff abbreviations list p phosphorus p org frsh fresh organic p p org stbl stable organic p p inorg stbl stable inorganic p p inorg act active inorganic p plab labile p pool p inorg h 2 oex man manure water extractable inorganic p p org h 2 oex man manure water extractable organic p p inorg stbl man manure stable inorganic p p org stbl man manure stable organic p p av fert available fertilizer p p res fert residual fertilizer p p dr dissolved reactive p p part particulate p pudr dissolved unreactive p fertp fertilizer p manp manure p p tot soil total p p sum sum of p dr p part pbias percent bias nse nash sutcliffe model efficiency ioa index of agreement gh grain harvested ob observed sim simulated et evapotranspiration s soil water change rzwqm2 root zone water quality model version 2 rzwqm2 p root zone water quality model version 2 phosphorus pb air entry pressure  pore size index k sat saturated hydraulic conductivity k lat lateral hydraulic conductivity  soil bulk density om soil organic matter content  fc volumetric soil moisture content at field capacity  soil porosity  wp volumetric soil moisture content at permanent wilting point ph soil ph 1 introduction agriculture phosphorus p demand accounts for 80 90 of global phosphorus consumption the supply of p is heavily dependent on mined rock phosphate a non renewable resource becoming increasingly scarce and expensive day by day in plants phosphorus plays a role in cellular energy transfer respiration and photosynthesis and is a structural component of the nucleic acids of genes and chromosomes as well as many coenzymes phosphoproteins and phospholipids grant et al 2001 while proper crop growth and the maintenance of high yields are critical to agricultural production crop p use efficiency in the year of application is rather low 15 30 syers et al 2008 the build up of legacy p in soils under long term application has increasingly caused p losses from soil to surface waters such p losses from agricultural fields via water and sediment have become a serious environmental concern degrading the quality of water in fresh water bodies e g lakes and rivers as well as brackish sea waters e g sea coast rivers outlets by causing a rapid increase in algal populations leading to eutrophication guildford and hecky 2000 such algae infested water is resulting in adverse ecological conditions for aquatic flora and fauna it is now an established fact that excessive p loading of fresh water bodies and coastal sea areas can be confidently attributed to an over application of fertilizer in upstream agricultural fields it is estimated that 80 of the p pollution reaching lake champlain s missisquoi bay originated in upstream agricultural lands hegman et al 1999 in quebec alone some 156 lakes were already deemed polluted by p msss 2007 as removal of excess p from water by chemical surampalli et al 1995 or biological oehmen et al 2007 means is complex expensive and time consuming remediation of eutrophication in rivers and lakes is difficult one practical option to mitigate this problem is to arrest p loss right at the source by adopting proper agricultural management practices to control p loss from an agricultural field one must understand the p dynamics of an agricultural field kleinman et al 2015 indicated that computer modelling drawing on measured p data was a currently priority in achieving this goal of available agricultural p management models icecream tattari et al 2001 seems to be the best at simulating p losses through tile drains radcliffe et al 2015 however in the absence of a water table based tile drainage component icecream uses matrix and macropore flow flux at a certain soil depth to mimic tile drainage qi and qi 2016 radcliffe et al 2015 icecream adopts simple storage routing concepts to simulate matrix flow within the soil profile this can be improved by adopting the soil matric potential based richards equation richards 1931 to simulate matrix flow and hooghoudt s equation bouwer and van schilfgaarde 1963 to simulate tile drainage with no separate p pool to simulate manure and fertilizer p dynamics icecream assumes that manure or fertilizer p are mixed with the soil upon application modelling p in an agricultural field involves modelling of hydrological processes on and below the ground surface and the effects of agricultural management practices a p model needs to simulate both surface hydrological processes e g soil evaporation plant transpiration runoff and soil erosion and subsurface hydrological processes e g infiltration matrix flow preferential flow or macropore flow flow to tile drainage fluctuation of water tables root water and nutrient uptake and soil moisture redistribution agricultural management practices such as surface irrigation and sub irrigation drainage fertilization tillage and residue management and crop rotation influence the fate and transport of p the success of a p model greatly depends on how effectively and efficiently the model captures these hydrological processes and how these processes are parameterized within the model rzwqm2 ahuja et al 2000 a widely tested field scale process based model is an ideal option as a base of a p model because it is equipped with subroutines to simulate all the hydrological processes and agricultural management practices mentioned above it has been extensively evaluated at locations across the united states fang et al 2014 gillette et al 2018 hanson et al 1999 ma et al 2004 2007a 2007b malone et al 2014 qi et al 2011 2013 thorp et al 2008 wang et al 2015 and in canada ahmed et al 2007a 2007b al abed et al 1997 madani et al 2002 jiang et al 2018 nonetheless current p models lack the capacity to adequately simulate p losses particularly those occurring through tile drainage radcliffe et al 2015 in this study an attempt was made to develop a model based on most recent scientific finding regarding the fate and transport of p from an agricultural field available in the literature and to test this new p management tool against measured hydrologic and p data in a tile drained cropland 2 materials and methods 2 1 p model the p model fig 1 is designed with five different soil p pools three inorganic namely labile p plab active inorganic p p inorg act and stable inorganic p p inorg stbl and two organic pools namely fresh organic p pool p org frsh and stable organic p pool p org stbl respectively following the nomenclature of jones et al 1984 besides these soil p pools as an advanced feature the model also has four surface manure p pools and two surface fertilizer p pools to simulate p dynamics arising from the application of fertilizer and manure vadas 2014 the manure p pools p man are inorganic water extractable p p inorg h 2 oex man inorganic stable p p inorg stbl man organic water extractable p p org h 2 oex man and organic stable p p inorg stbl man the fertilizer p pools p fert were available fertilizer p p av fert and residual fertilizer p p res fert p org frsh fresh organic p p org stbl stable organic p p inorg stbl stable inorganic p p inorg act active inorganic p plab labile p pool p inorg h 2 oex man manure water extractable inorganic p p inorg h 2 oex man manure water extractable organic p p inorg stbl man manure stable inorganic p p org stbl man manure stable organic p p av fert available fertilizer p p res fert residual fertilizer p p dr dissolved reactive p p part particulate p fertp fertilizer p manp manure p among these p pools the p lab pool is considered to be in dissolved form and the most dynamic p pool in addition it is the only p pool from which plants can uptake p plant root density is the highest near the soil surface so plant p uptake in the upper portion of the soil profile is more than that in deeper layers this depth distribution of plant p uptake is controlled by plant p uptake distribution parameter the governing equations of plant p uptake were adopted from neitsch et al 2011 there is constant absorption and desorption happens among these three inorganic p pools to maintain an equilibrium the p lab pool is in rapid equilibrium with the p inorg act pool which is in slow equilibrium with the p inorg stbl pool the rapid adsorption and desorption of inorganic p in the soil between plab and p inorg act is simulated based on jones et al 1984 with advanced dynamic absorption and desorption as prescribed by vadas et al 2006 this modification enables the model to simulate p movement among these pools by using a dynamically changing rate factor rather than a constant rate factor the slow adsorption and desorption of inorganic p in the soil between p inorg act and p inorg stbl is simulated based on jones et al 1984 after decomposition p from plant residues and soil humus are added to the p org frsh pool and the p org stbl pool respectively mineralization happens from p org frsh pool and mineralized p is added to the p lab and the p org stbl pools a slow mineralization also follows in the p org stbl pool and mineralized p is added to the p lab pool immobilization happens in the p lab pool and immobilized p is added to the p org frsh pool when fertilizer and or manure is applied in the field the fertilizer and or manure p is subsequently added to the p fert and p man pools based on application depth type and properties of fertilizer and or manure applied vadas 2014 these independent p man and p fert pools enable the model to simulate more precisely the p dynamics arising from the application of fertilizer and manure in an agricultural field then the leaching and decomposition takes place from these pools decomposed and leached p are added to the soil p pools the ability of the p model to simulate p dr through tile flow is improved by adopting the recommendations of francesconi et al 2016 whereas the p part loss through tile drainage is simulated by considering colloidal particle transport through macropore flow jarvis et al 1999 larsson et al 2007 in the model the first soil layer is set to a 0 01 m depth as the model assumes that particle bound p originates from the first 0 01 m depth of the soil profile all the p pools contribute to p part loss whereas the p lab pool p org h 2 oex man and p inorg h 2 oex man pools and all the p fert pools contribute to p dr loss to simulate p dr and p part loss through tile drainage the linear groundwater reservoir based approach as suggested by steenhuis et al 1997 was used in this approach p dr is generated through matrix flow and macropore flow while p part is only generated through macropore flow and is first to contribute to a groundwater reservoir subsequently a daily mass balance is calculated then p dr and p part is lost along with the tile drainage water from this groundwater reservoir all the equations used in the model are provided in the attached supplementary documents 2 2 rzwqm2 overview developed by the usda ars the rzwqm2 model ahuja et al 2000 is a field scale one dimensional model which integrates physical biological chemical and hydrological processes and simulates crop growth hydrologic cycle fate and transport of nutrients and pesticides under different agronomic management practices and climate patterns within the rzwqm model soil water retention is described using the brooks corey equation brooks and corey 1964 the green ampt approach green and ampt 1911 is used to compute the infiltration the model employs the richards equation richards 1931 to simulate soil water redistribution following infiltration in the soil profile tile drainage flow is calculated by hooghoudt s steady state equation bouwer and van schilfgaarde 1963 and the macropore flow is governed by the poiseuille s law the simultaneous heat and water shaw model flerchinger 1987 is linked to rzwqm to simulate ice in soil snow accumulation snow melting as well as soil freeze thaw cycles the crop growth can be simulated either by embedded dssat 4 0 crop models jones et al 2003 or a generic crop production model hanson 2000 whereas evapotranspiration is estimated using the double layer shuttleworth wallace model shuttleworth and wallace 1985 2 3 p model and rzwqm2 integration the p model described above was first developed then incorporated into the rzwqm2 model while the p model simulates p dynamics the rzwqm2 governs the physical biological chemical and hydrological processes that influence the p simulation the developed p model combined with rzwqm2 performs as a single tool the p model being dependent on rzwqm2 for the simulation of crop growth runoff drainage soil moisture and its flux soil temperature sediment yield macropore flow residue and soil humus decomposition and agriculture management practices all these components are simulated by rzwqm2 within its original functionalities and then the p model uses model outputs to simulate p dynamics and p loss through surface runoff and tile drainage from an agricultural field the p model s working algorithms along with its dependencies on rzwqm2 are presented in fig 2 2 4 field experiment to evaluate the p model observed runoff and drainage water flow as well as p dr and p part mass in both runoff and tile drainage water were collected from an agriculture agri food canada aafc experimental site the hon eugene f whelan research farm near south woodslee on 42 21n 82 74w from june 2008 to december 2012 the site was comprised of 16 plots 67 1 m 15 2 m receiving different fertilizer types and drainage system treatments among these plot numbers 5 and 9 selected for the present study received inorganic npk fertilizer applications and were subject to standard tile drainage depth 0 85 m spacing 3 8 m zhang et al 2013 the crop was rotated between maize zea mays l and soybean glycine max l merr in alternating years in 2008 2010 and 2012 maize was planted at a density of 79 800 seeds ha 1 while in 2009 and 2011 soybean was planted at a at a density of 486 700 seeds ha 1 the inorganic fertilizers 114 5 kg p 2 o 5 ha 1 roughly 50 kg p ha 1 200 kg n ha 1 from nh 4 no 3 and 100 kg k ha 1 from kcl were surface applied before planting in the maize planting years chisel plow tillage was done each year after harvest or in the following year before planting the dates of cropping and other crop management practices are presented in table 1 the p content in corn and soybean grain were measured after harvest between 20 october and 13 december each year grain samples were dried at 55 c ground and passed through a 1 mm sieve and digested using a h2so4 h2o2 procedure phosphorus concentrations in all of the filtrates and digests were determined using a quikchem flow injection auto analyzer lachat instruments employing the ammonium molybdate ascorbic acid reduction method murphy and riley 1962 the soil type was clay loam and the measured soil properties for plots 5 9 were averaged table 2 and used as the soil input data for the model the soil profile was delineated into six layers the soil properties such as soil texture field capacity fc permanent wilting point wp and saturated hydraulic conductivity k sat were measured before the start of the experiment soil bulk density  and porosity  were measured in 2010 where as k sat was measured in the year 2008 prior to the onset of the experiment in 2008 soil p was measured using the olsen p method olsen et al 1954 volumetric soil moistures  for the soil layer ranging in depth between 0 and 0 08 m were measured twice a week using a portable probe while soil temperature tsoil at depth of 0 05 m was measured hourly from june to october for the years 2010 2011 and 2012 using sensors hourly tsoil were averaged to obtain daily mean tsoil the required weather data air temperature precipitation relative humidity solar radiation and wind speed to run the model were collected for the period of 1st jan 2008 to 31st dec 2012 from the automated meteorological weather station located at the whelan farm located less than 500 m from the experimental site during the winter 1st oct 30th april of 2009 2010 and 2011 rain gauge inaccuracies for snowfall precipitation led to data being obtained from environment canada s harrow weather station station id 6133362 42 030n 82 90 0w located 16 6 km from the study field in each experimental plot there was a catch basin similar to a sewage sink at their downstream end to collect the surface runoff surface runoff and tile drainage from the experimental plot were directed to a central instrumentation building via underground pvc pipes in the instrumentation building the flow rate was measured automatically using electronic flowmeters and recorded in a multi channel data logger surface runoff and tile drainage water samples were collected automatically using autosamplers calpso 2000s buhler gmbh company surface and tile water samples were collected continuously year round proportionally to flow volume samples being taken for every 1000 l of flow during the growing season and for every 3000 l of flow during the non growing seasons after the collection the samples were analyzed in the laboratory for p dr and total dissolved p p td using an acidified ammonium persulfate nh4 2s2o2 oxidation procedure usepa 1983 unfiltered water samples were analyzed for total p p tot using the sulfuric acid hydrogen peroxide digestion method usepa 1983 the p part was computed by the difference between p tot and p td 2 5 model calibration and validation the rzwqm2 with this newly developed p model was run using the four and a half years june 2008 dec 2012 of data collected from the experimental site there were some limitations on flow event separation during the flow data collection so to ensure the precision of p loss estimation the collected data was aggregated into 19 different periods table 3 and out of these the first twelve periods 01 june 2008 to 21 dec 2010 two and half years were used for calibrating the model while the last seven periods 22 dec 2010 to 09 dec 2012 two years were used for validating the model during the calibration process parameters related to soil moisture soil temperature surface runoff and tile drainage were initially calibrated as these processes control the p loss from an agricultural field then the parameters related to p loss through surface runoff and tile drainage were calibrated the calibration was undertaken manually while changing the calibration parameters within the range as obtained from prior studies and available literature by a trial and error method following the protocol given by ma et al 2011 and iterated several times until a good match with the observed data was obtained three model evaluation statistics nash sutcliffe efficiency nse percent bias pbias and index of agreement ioa moriasi et al 2007 2015 served to evaluate the performance of the model in simulating hydrology soil moisture soil temperature and p loss through surface runoff and tile drainage model performance was catergorised as very good good statisfatory and unsatifactory based on the criterion of those model evaluation statistics as recommended by moriasi et al 2007 2015 the model is regarded to perform satisfactorily when nse 0 50 and good when nse 0 65 model performance is deemed to be satisfactory when pbias is between 15 and 25 for water flow and is between 40 and 70 for p and it is deemed to be good when pbias is between 10 and 15 for water flow and is between 25 and 40 for p moriasi et al 2007 model performance is regarded as acceptable when ioa 0 75 moriasi et al 2015 in rzwqm2 model soil moisture content is parametrized with air entry pressure pb and pore size distribution index  initially the values pb and  were set to the default values of these parameters according to soil texture as given by ma et al 2011 then subsequently these values were adjusted to match the observed values the value of  was found to be more sensitive than that of pb in soil water simulations an increase in  resulted in reduction in soil water content whereas an increase of pb led to increase of soil water content once the soil moisture content was calibrated and a good fit with the observed value was found then calibration of runoff and tile drainage followed to calibrate runoff parameters such as saturated hydraulic conductivity k sat surface crust hydraulic conductivity k crust and albedo were adjusted in rzwqm2 runoff is simulated when the rainfall rate exceeds the infiltration rate ma et al 2012 so the top layer k sat and k crust values were adjusted to obtain a good fit with the observed runoff furthermore the albedo was adjusted for simulation of evapotranspiration which in turn affected surface runoff for tile drainage calibration k sat pb and lateral hydraulic conductivity k lat were adjusted increasing k sat resulted in an increase in tile drainage whereas increasing pb resulted in decrease in tile drainage moreover k lat had very prominent influence in tile drainage simulation and it was adjusted to 2 k sat in addition pb was slightly adjusted to better match tile drainage without hampering the previous calibration for soil moisture the loss of p dr through surface runoff was calibrated by adjusting the soil p extraction coefficient while calibration of p dr loss through tile drainage depended on macroporosity pb and  of the deeper soil layers in the model macropore flow is initiated when the top soil layer becomes saturated and p dr carried away through macropore flow depends on the volume of macropore flow therefore to control the p dr loading to the groundwater reservoir the macroporosity value was adjusted finally the pb and  of the deeper soil layers were slightly adjusted to control the p dr loading to groundwater reservoir by matrix flow without altering the earlier results for tile drainage and soil moisture simulations the p part loss through surface runoff was calibrated by adjusting usle soil loss coefficients soil erodibility factor cover and management factor support practice factor and manning s n these parameters control the sediment yield thereby controlling the p part loss through surface runoff increasing soil erodibility increased the sediment yield while increasing the manning s n reduced it accordingly to obtain a good match of p part loss through surface runoff these two parameters were carefully adjusted along with the cover and management factor and support practice factor the p part loss through tile drainage is controlled by parameters like soil replenishment rate coefficient soil detachability coefficient and soil filtration coefficient these parameters govern the colloidal particle loss to subsurface flow hence limit the p part loss through tile drainage the high soil filtration coefficient leads to less colloidal particle loss whereas the increase of soil detachability coefficient and soil replenishment rate coefficient leads to more colloidal particle loss so these parameters were carefully balanced over the calibration period to get a reasonable simulation with respect to p part loss through tile drainage finally to adjust the plant p uptake from the p lab pool the p uptake distribution parameter for each crop was adjusted calibrated soil hydraulic parameters and their values are presented in table 4 and all other calibrated parameters are presented in table 5 3 results 3 1 soil moisture and soil temperature the time series of simulated and observed soil temperature tsoil at 0 05 m depth and soil moisture  between 0 and 0 08 m depths are presented in fig 3 the simulation statistics are summarized in table 6 model simulation of  and tsoil ware satisfactory with nse of 0 64 pbias of 0 30 and ioa of 0 89 and with nse of 0 59 pbias of 13 08 and ioa of 0 89 respectively 3 2 hydrology simulated vs observed surface runoff and tile drainage are depicted in fig 4 a and b respectively and the accuracy statistics presented in table 7 for the calibration period simulation in surface runoff was very good and in tile flow was satisfactory based on the model evaluation criteria during the calibration period surface runoff was estimated with pbais of 12 47 and with nse of 0 85 while drainage was estimated with pbais of 12 46 and the nse of 0 60 the simulated average annual runoff and tile drainage were 129 57 mm and 375 43 mm table 8 respectively these values were very close to the observed annual mean values overall the model s performance was very good in simulating runoff nse 0 75 pbias within 10 and ioa 0 75 and good in simulating tile drainage nse 0 65 pbias within 10 and ioa 0 75 the simulated vs observed water balance components are summarized in table 8 during the four and a half years of simulation simulated average annual et 449 73 mm was 47 45 of the observed annual precipitation 947 71 mm this was similar to annual et that was 45 of measured precipitation in the same region tan et al 2002 between the simulated average annual surface runoff and tile drainage most 74 34 of the water moved out of the field through the tile drainage system 3 3 dissolved reactive phosphorus p dr loss simulated and observed p dr loss through runoff and drainage for the calibration and validation periods are presented in fig 5 aand b and the simulation statistics are summarized in table 7 the simulation statistics show that the p model s simulation of p dr loss through surface runoff during the calibration period was in very good agreement with the observed data nse 0 75 pbias within 25 and ioa 0 75 whereas for tile drainage it was good nse 0 65 pbias within 25 and ioa 0 75 during the validation period simulated p dr loss through runoff was satisfactory and simulated p dr loss through tile drainage was good table 7 overall the p model could simulate the p dr loss through both surface runoff and tile drainage in very good agreement with the observed data nse 0 75 pbias within 25 and ioa 0 75 and it was found that most of the p dr 75 74 of total simulated p dr loss was lost through the tile drainage system during the simulation period table 9 3 4 particulate phosphorus ppart loss simulated p part loss through runoff and tile drainage agreed well with the observed data simulation results and statistics are presented in fig 5cand d and table 7 respectively analysis of observed data revealed that 68 07 of the net p loss p dr p part was lost in the form of p part and tile drainage contributed 63 47 of the total p part loss more p part loss than the surface runoff table 9 the model captured this well and simulated 68 04 of the net p loss in the form of p part and simulated tile drainage p part loss was 63 36 of the total p part loss overall the model s ability in simulating p part loss through surface runoff and subsurface drainage was very good and good respectively fig 5c and d and table 7 3 5 sum of pdr and ppart p s u m loss the simulation results of the sum of p dr and p part loss psum through surface runoff and tile drainage and its statistics are presented in fig 5e f g and table 7 respectively observed data revealed that tile drainage dominated the p sum loss composing 67 04 of total annual p sum loss while the simulated p sum loss through tile drainage was 67 32 of the total annual p sum loss the simulation of p sum loss through surface runoff was very good nse 0 75 pbias within 25 and ioa 0 75 while it was good during the validation period nse 0 65 pbias within 25 and ioa 0 75 the simulation of p sum loss tile drainage during the calibration and validation period was good and very good respectively overall the p sum loss simulations through both surface runoff and tile drainage were very good table 7 the simulation of total p sum loss from the field such as sum of p dr in both runoff and drainage and p part in both runoff and drainage for the entire simulation period was also very good fig 5g and table 7 4 discussion the field experiment showed that subsurface drainage was the major pathway of p loss from the field comprising 67 04 of total annual average p sum loss the annual average p sum loss through tile drainage was dominated by p part which accounted for 63 47 of total annual average p sum loss through tile drainage table 9 in contrast a study conducted by qi et al 2017 with the icecream model at the same site reported that icecream failed to simulate the p part loss through tile drainage and that soil moisture content was also not simulated satisfactorily they concluded that it could be improved by adopting the soil matric potential based richards equation to simulate soil matrix flow radcliffe et al 2015 noted that although icecream was one of the best p simulation models available to date it lacked macropore and tile drainage components the newly developed p model combined with rzwqm2 addressed all the concerns that were previously highlighted qi et al 2017 reported that icecream simulated p dr loss through tile drainage within 18 of observed values and with nse of 0 66 while it failed to simulate p part loss through tile drainage nse 0 0 and pbias 44 while comparing the simulation results of this study table 7 with those of qi et al 2017 we found that the p model s capability was particularly improved in its simulation of p loss through the tile drainage system the model s simulation of p loss particularly through tile drainage system improved after the proper calibration of soil moisture the adoption of richards equation led to better soil moisture and soil matrix flux simulations table 6 this had a direct impact on p dynamics as soil moisture governs the decomposition and mineralization rate and p flows among the various pools and soil matrix flux determines the amount of p loading to the tile drainage system the use of poiseuille s law resulted in better macropore flow simulations which is one of the major pathways of p dr and p part loading to the tiles finally the use of hooghoudt s steady state equation further improved tile drainage simulations and p loss through tile drainage soil temperature also has an important role in simulation of p dynamics in agricultural fields an acceptable soil temperature simulation table 6 led to good estimation of p flow rate among various p pools decomposition and mineralization rates of residue and soil organic matter analysis of the observed data for both growing seasons periods 2 3 7 8 11 12 15 17 19 and non growing seasons periods 1 4 6 9 10 13 14 revealed that 75 71 of total drainage volume and 60 14 of total runoff volume occurred in the non growing seasons consequently the p loss during non growing seasons was dominant during non growing seasons runoff carried away 56 24 of the total runoff bound p dr whereas 64 47 of total tile drainage bound p dr loss occurred during non growing seasons the same was observed for the p part loss with 64 97 of total runoff associated p part and 74 34 of total drainage associated p part being lost during the non growing seasons p sum loss in the non growing seasons during the whole simulation years comprised 68 19 of total p sum loss through surface and subsurface water flow the newly developed model satisfactorily simulated the fact that the major flow and p loss from the field occurred during non growing seasons for simulated discharge 66 97 of total runoff and 67 91 of total drainage occurred in the non growing seasons whereas simulated p sum loss during non growing seasons represented 65 76 of the total p sum lost through surface and subsurface water flow these simulated results also corresponded well to the observations of king et al 2015 who found that the non growing period represents a significant proportion of annual discharge and p loss the developed rzwqm2 p model is easy to run with menu driven graphical user interface although the data required to run the model seems to be meticulous but it can be easily collected from many resources when in situ measurement is not feasible weather data can be obtained from online resources for free or with nominal charges agricultural management data can be collected while interviewing the farmer or the farm manager of the site it can also be made available from various factsheets as published time to time by various agricultural agencies soil data can be derived using basic county soil survey information along with pedotransfer functions schaap et al 2001 or tables as provided by ma et al 2011 and rawls et al 1982 initial soil p values can be estimated while running the model for certain amount of years prior to start of actual simulation year with typical agronomical management practices and cropping system of the site rzwqm2 p has in built database of crop phenology parameters for most common crop cultivars this database can be used to default the crop phenology parameters computer simulation models inevitably have some limitations because they are built on assumptions and simplified version of the very complex real world phenomenon in this context rzwqm2 p model is limited to one dimensional and assuming soil as a homogeneous medium the model is not designed to simulate dissolved unreactive p pudr loss it also assumes that ppart originates from the first 0 01 m soil layer and only the macropore flow contribute to tile drainage bound ppart loss another shortcoming of rzwqm2 p is that it is a field scale model which cannot be applied over large scale watershed despite these limitations and assumptions rzwqm2 p can be used in a wide range of scenarios to mitigate p pollution under various agricultural management practices along with different cropping systems that are commonly adopted in north america agricultural management practices include tile drainage control drainage with or without sub irrigation various type of tillage application surface sub surface and injected inorganic fertilizer manure application manure type includes poultry swine beef cattle and dairy cattle under solid and liquid phases rzwqm2 p can also be applied to identify the impact of winter manure application which is a common practice in many areas of north america in this present study we presented the development of rzwqm2 p and its very first evaluation with a tile drained corn soybean rotated field under inorganic p fertilization over a period of four and half years the evaluation resulted in satisfactory performance of the model over the both calibration and validation periods although rzwqm2 p seems to be a promising tool to manage agricultural p under the given management practices to be certain about the efficacy of the model further tests are recommended at several other locations under different fertilization i e manure soil climate and crop conditions for a longer period with more observational data 5 conclusions in this study a model based p management tool was developed to simulate the fate and transport of p dr and p part from an agricultural field based on most recent scientific findings while overcoming the limitations of the icecream model as highlighted by previous researchers qi et al 2017 radcliffe et al 2015 and taking advantage of the process based agro hydrologic model rzwqm2 the new p model incorporated into rzwqm2 combined the proven strengths in simulating the impacts of agricultural management practices and hydrological processes in an agricultural field with the ability to simulate p dynamics the p model was evaluated against four and a half years of data collected from a subsurface drained corn soybean rotated field with clay loam soil in southwestern ontario canada the simulation results showed that the newly developed model performed satisfactorily in simulating the p dr and p part losses through both surface runoff and subsurface drainage with all periods nash sutcliffe model efficiency coefficient 0 65 percent bias within 25 and index of agreement 0 75 the p model s p loss simulating ability was improved particularly through tile drainage by adopting richards equation for simulation of soil matrix flow and hooghoudt s equation for simulation of tile drainage flow the use of poiseuille s law may have resulted in better macropore flow simulations which led to better simulations of p part loading to the tile system however this needs further investigations the simulation results were consistent with the observed trend that the non growing season dominated the p loss over growing seasons tile drainage contributed more towards these losses and p part was the major form of p loss the newly developed p module integrated with rzwqm2 is a promising tool for p management particularly for subsurface drained fields further tests are needed to evaluate this model under different fertilization manure soil climate and crop conditions software availability 1 name of the software root zone water quality model 2 phosphorus rzwqm2 p 2 developer details debasis sadhukhan and zhiming qi department of bioresource engineering macdonald campus mcgill university sainte anne de bellevue qc canada h9x 3v9 email debasis sadhukhan mail mcgill ca zhiming qi mcgill ca 3 year first available 2018 4 hardware and software required general pc with 4 gb ram and 1 gb of free space winnows 7 or higher 5 availability http www water environment lab mcgill ca 6 cost free 7 program size 72 1 mb 8 program language english acknowledgements this research is sponsored by natural sciences and engineering research council of canada nserc discovery grant rgpin 04784 14 development of a model based phosphorus management tool for manure applications in subsurface drained field the authors also sincerely acknowledge the financial supports of ms erin hogg a distinguished mcgill alumnus through a sustainable agriculture doctoral fellowship to carry forward this research appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 12 007 
26262,urban stormwater management is shifting its attention from traditional centralized engineering solutions to a distributed and greener approach namely green infrastructure gi however uncertainties concerning gi s efficacy for reducing runoff and pollutants are a barrier to the adoption of gi one strategy to deal with the uncertainty is to implement gi adaptively in which stormwater managers can learn and adjust their plans over time to avoid undesired outcomes we propose a new class of gi planning methods based on two stage stochastic programming and bayesian learning which accounts for projected information gains and decision makers objectives and willingness to accept risk in the hypothetical example the model identifies four categories of investment strategies and quantifies their benefits and costs all in greedy investment plus deferral mixed investments plus deferral and learn and adjust which strategy is optimal depends on the user s risk attitudes and the alternatives costs and risks keywords adaptive management green infrastructure learning stormwater management stochastic programming 1 introduction green infrastructure gi sometimes referred to as low impact development or best management practices is a distributed approach that reduces urban stormwater runoff through on site infiltration storage and evaporation to improve water quality in downstream water courses examples of gi practices are rain gardens rain barrels tree trenches permeable pavement and green roofs gi is gaining popularity due to its potential social and economic benefits environmental protection agency 2010 among major us cities philadelphia is the first that has committed to gi as the primary solution for stormwater problems pwd 2011 starting in 2011 philadelphia plans to invest 2 4 billion on gi over 25 years other cities such as washington dc chicago portland and seattle are also implementing gi at site or neighborhood scales environmental protection agency 2010 however the runoff and pollution reductions provided by gis depend on for example their specific designs local climate characteristics underlying soil properties and vegetation montalto et al 2011 also gi performance may deteriorate with time maintenance costs and the upstream and downstream relationships of multiple gis add further to the uncertainty of the efficacy and expense of gi which complicates stormwater management planning and can result in a failure to meet management goals chocat et al 2007 roy et al 2008 researchers have developed tools for designing sizing and selection of gi for stormwater management at the site scale lee et al 2005 loiciga et al 2013 massoudieh et al 2017 morales torres et al 2016 zhen et al 2004 as well as watershed scale investment planning models for managing water quality and runoff volume mcgarity 2012 montaseri et al 2015 sebti et al 2016 yet uncertainty has not been recognized by these optimization frameworks because of the uncertain interactions of gi climate and human activities it is crucial to recognize risks and the opportunity to learn when planning barton et al 2012 williams and brown 2014 i e to manage adaptively an experienced planner or stormwater engineer may have a good sense of the extent of potential learning from experimentation such as field trials of gi however we argue that formalizing the learning process and estimating the value of learning can be worthwhile even when quantification is difficult this has not been done in previous gi optimization models in this paper we propose a new method for gi investment planning based on two stage stochastic programming tsp in which we incorporate projected information gains and decision makers risk attitudes and objectives the projected knowledge gains are assumed to be a function of the amount of investments of in gi these gains are called learning throughout this paper and are used to update our knowledge beliefs concerning of the gi cost effectiveness in the later stages based on the idea of bayesian inference to our knowledge this is the first time that risk aversion and learning have been included in dynamic optimization models for adaptive stormwater management this method aims at providing guidance regarding the choice of gi practices investment timing and amount risks of failing to meet management goals and maximization of benefits including social and economic benefits in the hypothetical example in section 4 the goal of the two stage decision problem is to maximize cumulative stormwater reductions given a fixed budget for the 40 year planning horizon where early investments at year 1 may result in learning that updates our understanding of the gi cost effectiveness in later decision stage at year 11 in the example we identify four broad classes of strategies which we call all in greedy investment plus deferral mixed investment plus wait and see and learn and adjust this range of possibilities involves tradeoffs between cost expected stormwater reduction and risks the best choice in a given situation depends both on case study specific parameters and the decision maker s willingness to accept risks the remainder of this paper is organized as follows in the next section we summarize the literature on adaptive management risks associated with gi and the use of stochastic programming to model learning there are indeed previous models for water resource management that include uncertainty and risk aversion and models for managing ecosystems and climate change that represent learning yet models that simultaneously consider both risk aversion and learning for adaptive management have not been proposed or implemented in stormwater management or other related fields section 3 explains the building blocks of the proposed method and illustrates the ideas with a decision tree example section 4 shows the results from a hypothetical example to illustrate the method which is formulated as mixed integer linear programming with risk constraints sections 5 discusses the sensitivity of the solutions and presents conclusions finally the mathematical formulation is presented in the appendix 2 literature review 2 1 adaptive stormwater management adaptive management is a framework for long term planning under uncertainty it was first proposed by holling 1978 for environmental assessment and management and by walters and hilborn 1976 in ecological management it is now widely recognized and applied in those contexts lovell and taylor 2013 mccarthy and possingham 2007 southwell et al 2016 williams 2011 adaptive management can be characterized as a process of learning to manage by managing to learn bormann et al 1994 in which decisions at each planning stage must balance the cost and benefits to future decisions of learning to reduce uncertainty versus investing to yield immediate benefits williams 2011 this paper presents a general methodology for quantitative implementation of adaptive management that is designed to provide useful information in the form of quantified risks and the costs and benefits of learning 2 2 risks in stormwater management with gi researchers have recognized that there exist risks in managing stormwater and have tried to address them chocat et al 2007 pointed out three particular types of risks involved with gi 1 transferring maintenance responsibility to end users may result in degraded performance 2 uncertainties in the transition path from the centralized system to decentralized systems and 3 residual contamination in stormwater retained and treated by gi which could cause human health concerns in addition roy et al 2008 flagged the risks of underestimating costs of gi installation and maintenance missing management goals loss of functionality and community resistance to installations particularly in municipalities of lower socio economic status with relatively few natural environmental assets however quantifying the risks associated with stormwater management is challenging a few studies have tried to estimate the risks of stormwater pollution for example stormwater pollution risks to ecosystems novotny and witte 1997 overflow risks from detention basins guo 2002 and sediment pollution risks from combined sewer overflows csos in receiving waters rossi et al 2005 yet neither optimization models nor decision support tools in general have been developed to manage risks or evaluate adaptive strategies in stormwater management 2 3 stochastic programming applications and learning two stage or more generally multi stage stochastic programming tsp is a logical way to model the implementation of adaptive management as it can analyze here and now investments while considering opportunities to change course in future stages depending on what is learned and their probabilities shapiro and philpott 2007 generalizations of tsp including stochastic dynamic programming and partially observable markov decision processes describe sequential decision processes where decisions are made in each stage based on the decision maker s beliefs concerning the underlying state of nature and the expected value of some objective monahan 1982 white 1991 chance constrained and risk averse programming are other optimization approaches that use probability distributions and can be compatible with tsp housh et al 2013 krokhmal et al 2001 wang and huang 2014 other approaches to decision making under uncertainty attempt to avoid the use of probabilities one is robust decision making rdm which was developed for the problems with deep uncertainty i e uncertainty is highly subjective such that different experts estimates of probability distributions may be very different from each other lempert and collins 2007 rdm generates plausible scenarios and attempts to identify strategies that work well across all scenarios instead of using a probability distribution and an objective based on probability weighted expected value rdm applications can be found in the climate change and water supply literature beh et al 2017 kasprzyk et al 2013 lan et al 2015 mortazavi naeini et al 2015 however rdm does not naturally lend itself to quantifying the value of learning in adaptive management so our approach instead relies on tsp risk aversion in which decision makers place greater weight on poor outcomes compared to use of expected probability weighted values has been considered in many environmental management problems e g baker 2009 chao and hobbs 1997 piantadosi et al 2008 the particular implementation of risk aversion that we use conditional value at risk cvar explicitly defined below has been applied in water supply allocation and storage problems to explore risk expected value tradeoffs paydar and qureshi 2012 piantadosi et al 2008 webby et al 2007 but not in water quality management ours is the first use of cvar to address risk in water pollution investments learning has been considered in a wide range of environmental applications usually in the form of bayesian analysis kim et al 2003 and jacobi et al 2013 applied stochastic dynamic programming to fishery and water quality management respectively where research and monitoring learning are optimized in the first stage followed by decisions concerning land and ecosystem management actions in the second stage harrison 2007 developed a bayesian programming method for water quality control problems varouchakis et al 2016 applied bayesian decision analysis in reservoir construction planning problem a number of analyses of uncertainty and learning can be found in the climate policy literature see golub et al 2014 for instance baker 2009 presented a tsp model for optimizing carbon emissions abatement with learning about uncertain climate change damages while webster et al 2017 applied tsp to consider optimal research into climate mitigation technologies whose performance is uncertain in their stochastic dynamic programming models the state variables e g the belief of climate change and mean water level are updated by bayes law with new observations which is the type of learning we implement in our models below in summary we have found that stochastic programming has been used to implement adaptive management in related contexts but not in gi planning itself learning has been addressed but the construction of the likelihood function is often challenging which limits the applicability of bayesian approaches the method presented in the following section uses simple learning curve functions to depict the relationship of the here and now gi investment and learning which provides an intuitive way to express the amount of learning while avoiding the need to explicitly construct likelihood functions 3 methodology the primary objective of urban stormwater management is to reduce runoff in order to prevent sewer overflows and improve water quality in streams while the problem can be formulated as a multi objective optimization for simplicity our formulation considers only one objective to be optimized i e runoff reduction subject to constraints on the other objectives e g a fiscal budget and the risk of undesired outcomes in this section we only explain the general scheme of the method and present the full mixed integer linear program implementation of the tsp in the appendix section 3 1 presents a decision tree example that we use to illustrate the underlying logic of the method for representing learning and adaptive gi investment planning section 3 2 presents the basic stochastic programming framework and then explains the modeling of risk aversion and learning in that framework 3 1 decision tree representation of the adaptive gi investment planning model in the case of gi planning with two investment decision stages denoted by stages i and ii the manager needs to make investment planning with several distinct gis whose performance stormwater reductions are uncertain and independent we summarize the manager s problem as follows decisions choose the gi investment portfolio in stage i given a budget shared with both stages while considering the opportunity to change course in stage ii in order to o maximize the objective of expected reductions in total stormwater runoff over a multidecadal time horizon while o satisfying a risk constraint concerning the annual runoff reduction in stage ii and a fixed budget shared by both stages assumptions o the manager is risk averse regarding the possibility of failing to meet the state ii reduction target in annual stormwater reduction o investment in a particular type of gi in stage i will result in learning if the investment exceeds some threshold this learning can be taken advantage of in stage ii by investing more in that type of gi if it turns out to be highly effective or investing in other types if the first type is instead found to be relatively ineffective o learning about one type of gi provides no information about the performance of others o gis are installed in parallel i e no interactions among gi installations so that the reduction in stormwater can be summed we next use a decision tree schematic to illustrate the underlying logic of the method interested readers can refer to the appendix for details of the mathematical formulation 3 1 1 decision tree example a decision tree involves decision nodes squares chance nodes circles and outcomes at the end of the tree branches the chronologic sequence of decisions and chance events proceeds from left to right a decision node represents a point in time when decisions must be made among the alternatives represented as arcs exiting the right side of the node a chance node stands for random events each represented by arcs exiting the right whose probabilities sum to 1 and the outcomes show the objective function values realized for a particular sequence of decisions and random events represented by the nodes and arcs leading from the left most node to the terminal node on the right fig 1 is a schematic in that only some of the nodes and branches are shown for clarity in this example the manager can make investments in either or both stages i and ii which can consist of investments in any or all of n types of gi in general each type can have different levels of efficiency and uncertainty in stormwater reduction per investment following the terminology of bayesian statistics the distribution of the gi performance in stage i representing our current understanding about the technology is called the prior distribution c i and the updated distribution in stage ii representing our new knowledge given the experience learned from the stage i investment is called the posterior distribution c i i s in probability the posterior distribution is a conditional probability of the outcome given what is learned we assumed three types of learning as follows no learning nl the posterior distribution is the same as the prior distribution partial learning pl the variance of the posterior distribution is less than the prior distribution but not 0 and full learning fl the posterior distribution has zero variance certainty pl and fl are achieved for a particular gi type if investment x i in that type exceeds thresholds respectively denoted as t h p l and t h f l t h p l t h f l which of the types of learning that happens depends on which of the thresholds are met that is if the investment in stage i denoted x i is less than t h p l nothing is learned and the posterior distribution is the prior distribution between t h p l and t h f l then pl takes place and otherwise fl takes place we defer the discussion of the learning and investment relationship to the next subsection and focus our discussion here on the decision problem to account for uncertainty m i scenarios indexed by s are generated after the stage i decision is made and m i i scenarios indexed by r are defined to follow each stage ii decision the total number of scenarios is m i m i i each stage i scenario contains a realization of stormwater reduction and a learning outcome the posterior distribution from the stage i investment while each state ii scenario describes a realized reduction for investments in the second stage to help the reader understand the process we present a numerical example of a pl branch of the decision tree fig 2 in this example the manager has two investment options gi1 whose performance is normally distributed mean and variance equal to 0 5 gallon per per year gal yr and 0 04 gal yr 2 respectively and gi2 which provides 0 48 gal yr stormwater reduction with certainty the total budget for the two stage planning problem is 100m and the investment decisions are made at year 1 and 11 we assume that once the first stage s gi is installed it will continue providing stormwater reduction until the end of the planning horizon and therefore the installations in stage i can provide stormwater reduction for 40 years while if installed in stage ii a gi reduces stormwater only for 30 years costs are not discounted in this example the manager s objective is to maximize the total stormwater reduction over the 40 year planning horizon however the manager may also be concerned with the risk of very low reductions occurring in stage ii as we explain below moving forward in time from left to right in fig 2 first the manager decided to invest 40m in gi1 and none in gi2 because she knows that the former investment would result in pl and reduce the performance uncertainty in gi1 to an assumed value of 0 01 gal yr 2 however she does not know which scenario s she would be in prior to entering stage ii either one of the two stage i scenarios could happen scenario s 1 consists of a realization of a performance of 0 7 gal yr reduction for the investment made in gi1 in stage i and a posterior distribution with mean and variance equal to 0 675 gal yr and 0 01 gal yr 2 respectively meanwhile scenario s 2 could consist of a realization of 0 6 gal yr reduction for that gi and a posterior distribution with mean and variance equal to 0 325 gal yr and 0 01 gal yr 2 respectively note that those two realized performance values are consistent with the assumed prior mean and variance i e mean 0 675 0 325 2 0 5 variance 0 675 0 5 2 0 325 0 5 2 2 0 01 0 04 more details of the preservation of the prior mean and variance can be found in the appendix note also that although we only have two scenarios for each chance node for brevity a large number of scenarios is recommended to better represent the random distributions in stage ii the manager then makes another investment decision which depends on which scenario she is in if she is in scenario s 1 the stage ii investment would be to allocate the remaining part of the budget 60m in gi1 in order to take advantage of its high expected performance in the posterior distribution whereas if she is in scenario s 2 she would rather invest the remaining budget in gi2 since the expected value of the posterior distribution for gi1 s performance is lower than 0 48 gal yr the final outcomes at the end of the tree are the total stormwater reduction for the 40 year planning horizon we assume equal probability for each scenario 50 so that we can calculate the stormwater reduction under each combination of first and second stage scenarios s r as shown in table 1 and the expected reduction of the first stage decision x i 40 m 0 1840 mg in contrast if learning is not considered a risk neutral manager would invest all her budget in gi1 in stage i all in and receive an expected value of 2000 mg stormwater reduction 0 5 40 yr 0 7 gal yr 0 5 40 yr 0 3 gal yr however if she is risk averse and would like to make sure the annual reduction she received at the end of the planning horizon would be higher than some management goal she may want to instead consider the investment option in fig 2 although the investment presented in fig 2 provides less total stormwater reduction 1840 mg 0 25 2515 0 25 2155 0 5 1 344 next to last column of table 1 this is 160 mg less than the all in case the worst annual reduction 40 8 mg yr under s 2 is higher than the worst reduction of the all in strategy 100m 0 3 gal 30 mg yr this example is just one branch of the decision tree in which the pl takes place there could be other investment strategies that show different tradeoffs between expected reduction and risk in the nl fl and other pl branches which are not shown it is worth noting that the mean of particular posteriors for particular scenarios s could be higher or lower than the prior s mean however the overall mean is preserved when averaged across all scenarios while the posterior variance is always reduced because of our learning assumption moreover the realizations of the prior may not correspond to the means of the posteriors for example the first stage realization for a particular gi might be a disappointingly low stormwater reduction per of investment yet as a result of this experience engineers may also have learned how to improve that gi s design which improves the mean of the posterior distribution of gal for that gi as another example the reduction realized in the first stage could be high however the stormwater managers may find that the best locations have been taken so that remaining sites would cost more for installing gi which results in a lower mean of the posterior distribution compared to the prior distribution rather than defining a decision tree by discretizing values of stage i and ii investments x in this manner and then solving it by standard backward induction methods we instead solve a stochastic optimization problem with the same logical structure using mixed integer linear programming as described in the appendix this allows us to treat x as continuous variables and risk constraints can also be imposed which is done only with difficulty in a decision tree the proposed method can handle a large number of scenarios and gi types and is in general easy to solve furthermore our formulation allows the user to define learnings discussed in the next subsection by changing the fiscal budget and target cvar our risk metric in the proposed method tradeoffs between expenditures risk and expected stormwater reductions can be explored as we illustrate with the example described in section 4 3 1 2 learning and learning curve functions learning is the process of understanding the system of interest specifically in statistics learning is the process of updating one s beliefs about the system from new observations or new findings where a belief is expressed as the distribution of a random variable the traditional bayesian approach assumes a prior distribution for a random variable based on current understanding while representing learning by the adjustments in the distribution in the later stages kelly and kolstad 1999 for example such adjustments might depend on what is learned and include a a reduction in the variance of the probability distribution and or b a change in the mean of the distribution as shown in the decision tree example above in practice the prior distribution of some uncertain variable c i can be updated using bayes law with actual observations after research or monitoring take place although the actual observation is not available at the first planning stage we will usually expect that more gi investment will result in a more significant reduction in uncertainty of gi performance in later stages the underlying assumption is that implementation experience can be transformed into the knowledge of the systems through a process which is described as a learning curve function berglund and sderholm 2006 ferioli et al 2009 sderholm and sundqvist 2007 we adopt learning curve functions in our model and use them to describe how the bayesian updating process will be affected by the level of investment for example learning curves denoted g x might show how the variance changes using 1 step 2 step or linear functions as shown in fig 3 in the figure the 1 step function shows that if the investment is larger than or equal to 8m learning occurs and the variance is reduced to zero otherwise the variance will remain unchanged the 2 step function has three states no learning nl partial learning pl and full learning fl with 100 25 and 0 variance respectively corresponding to investment under 8m between 8m and 15m and over 15m on the other hand the linear function shows that the variance reduction is proportional to any investment less than 20m learning curves can be very general for instance representing shifts in the mean of the uncertain variable such that the average over the posteriors is better than the prior because learning has improved the technology the users can choose the form and parameterization of the learning curves to reflect expert judgment statistical analyses or both 3 2 two stage stochastic programming with cvar constraints this section introduces a general mathematical statement of the proposed method which can help readers to understand the full formulation in the appendix 3 2 1 basic two stage stochastic programming tsp a generic formulation of a tsp model is as follows risk aversion is ignored for the moment so the objective eq 1 is to maximize the expected reductions in runoff subject to a resource budget constraint and the non negativity constraints eqs 2 and 3 choose x i x i i in order to maximize 1 f i x i x i i e c i x i e s s c i i s x i i s subject to 2 a x i x i i s b 0 s s 3 x i 0 x i i 0 notation s is the set of future scenarios and s s is the index of the scenarios x i and x i i s r 1 n are the decision vectors representing the investments in n types of gi in stage i and in scenario s stage ii respectively x i i x i i s for all s s f i x i x i i is the overall expected benefit function e g expected reductions in stormwater runoff c i r n 1 is a random vector representing the gi s performance coefficients e g gal yr in stage i c i i s r n 1 is a random vectors representing the gi s performance coefficients in scenario s stage ii a r m n and b r m 1 are constant matrices for linear resource constraints the probability distribution of c i is the prior distribution while c i i s is the posterior distribution given that scenario s has occurred updating the prior of c i to the posterior of c i i s given s is the process of learning matrices a and b are deterministic in the problem formulations above but they could also be stochastic a special case of the tsp model is one with a deterministic second stage problem however in the simplest case in which the decision maker is risk neutral it makes no difference whether the second stage problem has residual uncertainty in the objective function or not since the objective is to maximize expected performance we can just use the expected value of c i i s in the second stage objective this is however not true if the decision maker is risk averse in which case a formulation that includes the decision maker s risk attitude is needed this generalization is the subject of the next subsection 3 2 2 risk averse optimization a decision maker s risk averse preferences can be modeled with constraints on some risk measures see artzner et al 1999 let f x be the uncertain value of the objective function assuming that f x is to be maximized given decisions x conditional value at risk cvar is the risk measure used in this paper and is a popular measure because of certain mathematical properties it possesses to explain cvar we first introduce another popular risk metric value at risk var var is the value of the  quantile of the uncertain objective f x given that the decisions are x  is a specified number ranging from 0 to 1 indicating the probability of the least acceptable outcome to the decision maker cvar is the conditional mean of the outcomes worse than v a r  x given  and the decisions x therefore c v a r  v a r  the mathematical expressions of the two risk measures are as follows var 4 v a r  x m i n y p r o b f x y  cvar 5 c v a r  x 1  0  v a r y x d y fig 4 illustrates the meaning of standard deviation  var and cvar for a standard normal distribution mean 0 variance 1 and  0 025 the var and cvar measures are indices of bad outcomes and so more is desired if f x is to be maximized as is the case here with stormwater reductions thus to represent a limit on risk they would be constrained by imposing lower bounds we chose to constrain cvar because it has two appealing properties a ease of computation a linear program can be used fx1 when there are discrete scenarios rockafellar and uryasev 2000 and b cvar reflects the distribution of outcomes below var penalizing distributions whose tails encompass more extreme values by adding cvar constraints the optimization model can represent risk averse preferences if the constraint is binding the result is likely to be an investment that increases the expected performance in the worst case scenarios those with a cumulative probability less than  however this will likely be at the expense of a deterioration in the expected value of the objective 1 that is there will be tradeoffs between risk and expected performance adding cvar constraints in tsp directly makes it a non linear problem because of the nonlinearity of the probability distribution function however rockafellar and uryasev 2000 proposed a linear programming formulation with monte carlo sampling that approximates the cvar problem we adopt a variant of that model krokhmal et al 2001 that maximizes the expectation of f x subject to cvar constraints 6 6 z k  f k x f o r a l l k 1 2 m  1 1  s s p k z k c v a r  where k is the index of m realizations of the random variables  is an auxiliary variable for v a r  calculation z k is an auxiliary variable for the calculation of the loss exceeding v a r  under realization k which has probability p k f k x is the function of some metric that we would like to constrain the risk on under realization k and c v a r  is a specified number representing the least acceptable outcome e g the smallest runoff reduction that is acceptable our implementation is somewhat more complex to account for the two stage nature of the problem in which overall performance depends on realizations in both stage i earlier years and stage ii later years more details are provided in the appendix 4 a hypothetical example 4 1 overview of assumptions the modeling framework summarized above is general in that it gives us the flexibility to build versions based on a range of assumptions about learning to assess whether considering learning could significantly change the optimal stage i investment decisions in the illustrative example of this section we implement two versions the multi level learning ml model and the technology improvement ti model the details for both of which are presented in the appendix the ml model assumes that the first stage investment for a given gi type could yield either nl pl or fl as in the two step learning function shown in fig 3 meanwhile the ti model assumes that learning not only reduces the variance but also increases the expected value of the posterior distributions of stormwater reductions the ti model can be viewed as having two learning curves for each gi type showing the impact of learning upon the mean and variance respectively of the posterior distributions whereas the ml model only has a single learning curve function corresponding to just the posterior variance in this two stage planning example we make the following assumptions 1 the stormwater manager can invest in three gi types called gi 1 gi 2 and gi 3 2 the types have random first stage performance stormwater reduction in gal yr levels c i 1 c i 2 and c i 3 respectively 3 a budget of 100m is available which can be optimally split between stages i and ii the planning horizon is 40 years stage i begins at year 1 and stage ii will begin at year 11 4 the decision variables are how to distribute the 100m budget between the stages and among the gi types the distribution of the budget allocated to stage ii among gi types depends on the scenario s 5 the objective function is to maximize the total probability weighted annualized runoff reduction in million gallons year mg yr resulting from the investments with the reductions summed over a 40 year planning horizon once a gi type is installed it will continue to provide stormwater benefits until the end of the planning horizon year 40 6 constraints on investment include the overall budget constraint nonnegativity for all investments in each stage and definitions of cvar and learning relationships defined above also see the appendix a prespecified lower bound is placed on cvar 0 1 that is the manager specifies a minimum acceptable stormwater reduction corresponding to the conditional expectation of the worst 10 of the outcomes in the examples we vary cvar 0 1 mg yr from 0 to 60 to represent increasing degrees of risk aversion the relationships between first stage investments and learning are summarized in sections 4 2 and 4 3 the final set of assumptions concern the three gi types they represent three distinct technologies gi 1 is a low cost and well understood technology a low variance for c i 1 with the lowest learning thresholds for both pl and fl gi 2 is more cost efficient than gi 1 in terms of expected gal yr performance but the uncertainty associated with its performance and its learning thresholds are also higher and gi 3 is a new technology with little empirical data for its cost effectiveness but is believed to have the highest expected cost efficiency as well as the most uncertainty about its gal yr performance and also the highest learning thresholds for both pl and fl table 2 shows the assumptions made about their first stage performance in this example the learning curves variance reduction for each gi type used in the ml model are shown in fig 5 there g i x 1 i 1 2 3 signifies that the investment is not enough to trigger learning nl g i x 0 25 means the investment results in partial learning pl and the variance is reduced to one fourth of the original value and g i x 0 means that perfect information is provided in stage ii fl so that variance is reduced to zero the pl 75 reduction and fl 100 reduction thresholds are 5m and 10m respectively for gi 1 8m and 15m respectively for gi 2 and 15m and 30m respectively for gi 3 in the rest of section 4 we show the stage i decisions resulting from the ml and ti models sections 4 2 and 4 3 respectively for a range of cvar values which represent different levels of risk aversion also we show the tradeoff between expected stormwater reduction and risk indicating that a substantial improvement in risk can be purchased with a slight deterioration in expected reduction the specific learning assumptions used in the ml and ti models are described in their respective sections 4 2 results from the ml model assumes no technological improvement to represent uncertainty in gi performance we generated 1000 stage i scenarios s as well as 5 stage ii scenarios r for each stage i scenario we generated more state i scenarios because computational experience shows that a larger sample size in stage i can help solutions to converge but that increasing sample sizes in the later stage has less of an effect ji et al 2005 the issue of solution convergence is discussed further in section 5 1 the ml model is solved for values of cvar ranging from 16 mg yr to 42 mg yr under the 100m budget and the resulting first stage investments in the three gi types are shown in fig 6 left axis the figure also shows the probability weighted average stormwater reduction averaged over the 40 year time horizon right axis at a cvar of 16 mg yr the cvar constraint no longer binds and the risk neutral solution results i e this is the solution that maximizes the expected annual stormwater reduction achieving 60 mg yr higher values of the cvar lower the risk of poor stormwater results but at the expense of lower expected performance cvar can be feasibly increased as far as 42 mg yr which represents a 163 increase at that level expected stormwater reduction however falls about 13 from 60 to 52 mg yr whether that deterioration in expected performance is justified by the reduced risk of abysmal performance is a value judgment that the decision makers must make informed by the results of the model depending on the degree of risk aversion the optimal strategy falls into one of four groups the results suggest that a risk neutral decision maker should invest all 100m in gi 3 in stage i because gi 3 has the largest expected benefit which is shown as the all in solutions when cvar 16 mg yr there appear to be insufficient incentives to invest in other technologies or to wait to obtain better estimates of gi performance however if the manager is risk averse she may prefer to save some budget for future investment or mix her investment with more than one gi type or to take advantage of learning for example when 16 cvar 24 mg yr the model suggests investments in gi 3 but also to save some budget for the later stage in case gi 3 turns out to be worse than expected called greedy investment with deferral strategy when 24 cvar 41 mg yr the model suggests investments in both gi 2 and gi 3 while saving some budget to take advantage of learning from fl or pl called mixed investment with deferral strategy in gi 2 and gi 3 finally when 41 cvar 42 mg yr the model suggests investing only for learning pl for gi 1 and gi 3 fl for gi 2 and saving the rest of the budget to invest in the second stage in order to minimize the risk i e maximize cvar which we call the learn and adjust strategy not surprisingly the most investment strategies suggest investing early because to wait means that there is no reduction in the first 10 years which lowers the total runoff reduction over the 40 year time horizon 4 3 results from the ti model assumes technology improvement the ti model adds another set of learning curve functions fig 7 denoted h i x for i 1 2 3 to the above ml model such that if the learning criteria are met the expected values of gi performance c i i 1 c i i 2 and c i i 3 will improve by 50 20 and 0 respectively as a result compared to the ml model of section 4 2 the model has a higher incentive to make here and now stage i investments for reducing uncertainty and increasing the expected values fig 8 moreover under the technology improvement assumption the cvar value can be as high as 51 mg yr and still yield a feasible solution because of the increase in performance resulting from stage i investment while in the ml model the cvar cannot exceed 42 mg yr finally when cvar is set to 39 mg yr or higher the ti model also suggests an investment of 5m in gi 1 to obtain pl whereas this technology is not invested in by the ml model except the most risk averse case this is because gi 1 being more uncertain has a higher potential to increase its performance so that it may become a preferable option in stage ii if its uncertain second stage performance turns out to be relatively high but if we do not invest in gi 1 in stage i we may be disappointed by the achieved runoff reduction in stage ii if gi 2 and gi 3 both turn out to be less efficient than expected fig 8 shows the model s objective expected stormwater reduction over 40 years as a function of cvar it reveals that without considering risk aversion the objective value is 60 mg yr the same as in fig 6 which like the ml model is an outcome of the all in strategy it turns out that under risk neutrality the expected gains in technology effectiveness in stage ii are not justified by the loss of efficiency resulting from the stage i investments necessary to achieve those gains however in the presence of risk aversion cvar can be increased to 51 mg yr if the decision maker is willing to accept a loss of 5 6 mg yr from 60 to 54 4 in expected value this occurs from investing the minimal amount needed in stage i to achieve the technology improvements and posterior variance reductions that are possible in all three technologies also when applying a mixed investment plus wait and see strategy cvar in the range of 21 47 the objective curve is higher than the results in fig 5 which is a result of technology improvements the technology improvement assumption can be viewed as indicating that a drop in cost or an increase in efficiency for a particular gi is forecasted as possible in the near future then the ti model can help answer the question of how stage i investments can help expedite these improvements by providing several distinct solutions mixes of gis for the decision makers to ponder with some solutions emphasizing reducing uncertainty and others focused on improving expected stormwater reductions 5 discussion section 4 has shown that in this hypothetical example the ml and ti models both suggest four distinct investment strategies depending on the learning assumptions decision maker s risk attitudes and the particular parameter values assumed for the model in a more realistic case study the choices of the model input assumptions need to reflect the conditions and the opportunities in the study area these will include the probability distributions and learning costs resource and other physical and regulatory constraints however the user should keep in mind that as with the results of any model the precise numerical results should be viewed skeptically and that the most valuable outputs are insights as to which investment alternatives appear most economic and why in this paper we focus on the definition and illustration of the method future work will apply the method to a realistic case study in this section we consider two crucial implementation issues the first issue is solution instability due to scenario sampling errors in which the optimal investments may be a function of the particular sample that is taken section 5 1 presents a solution stability analysis to examine the variability of the solutions and the resulting risk levels the second issue which is discussed in section 5 2 is the impact of alternative learning assumptions since they are based on expert judgment and are likely to be imprecise and significantly impact the solution 5 1 are solutions robust to sample error the technique we used to solve the ml and ti models in section 4 1 and 4 2 relies on generating scenarios to approximate the random distributions which are subject to sample error a large sample size can reduce this error but will increase computational costs our numerical example presented in section 4 1 has 14 013 decision variables and 18 013 constraints respectively which takes about 10 30 min to solve on a conventional laptop intel core i7 4 gb ram therefore it is not practical to include much larger samples a solution stability analysis can provide information about solution variability due to sampling errors which also provides alternative solutions for the decision maker to consider to evaluate whether the sample size is adequate and to assess the resulting variability of the solutions we perform a solution stability analysis by running a monte carlo simulation of the ml model section 4 1 100 times with each of the 100 solutions obtained setting cvar 0 1 to 40 mg yr recall that the number of scenarios is 1000 and 5 for stage i and ii respectively fig 9 shows the results from the monte carlo simulation runs the histograms of the first stage solutions indicate that it is optimal to invest x 1 0 in gi 1 in all solutions and x 2 8 m pl in gi 2 for 9 of the solutions and x 2 15 m pl for 91 of the solutions for gi 3 it suggests a range of x 3 31 m to 43m fl with an average investment of 38 5m meanwhile the cvar 0 1 value is set to 40 but the 90 exceedance value var 0 1 can vary from 45 to 47 mg yr and the expected annualized runoff reduction can vary from 54 2 to 55 mg yr thus the pattern of investment is somewhat stable in the face of sample error but the precise level of risk and expected performance of the system can vary larger sample sizes would result in smaller variations the stormwater manager can choose an investment decision and run the monte carlo simulation to evaluate the variability of the objective and cvar values for example fig 10 shows the histograms of the objective and cvar values of the initial gi investment plan of 0m 15m 30m from 100 simulation runs which are in the ranges of 53 7 54 1 and 40 3 43 respectively this analysis provides additional information regarding the stability of the resulting expected outcomes and risk levels 5 2 how do first stage recommendations depend on learning opportunities and risk aversion decision makers can adjust learning assumptions to explore whether the possible benefits of learning can justify significantly different portfolios of the first stage investments a trivial example is that a risk neutral decision maker would apply the same all in strategy in the previous ml and ti examples figs 6 and 8 even though the latter has an additional technology improvement assumption on the contrary a risk averse decision maker with the cvar set to 36 mg yr would likely adopt a mixed investment with deferral strategy but the investment portfolio in the ml example fig 6 consists of only gi 2 and gi 3 whereas the investment portfolio in the ti example fig 8 also includes an investment in gi 1 besides our method can be used to evaluate active learning opportunities by applying a weight of zero to the first stage reduction in the objective so that the objective of the planning problem only focuses on the second stage reduction and considered the first stage decision as representing possibilities for active experiments as an example we modify the ti model changing the technology improvement assumption to increase the effectiveness of gi 1 gi 2 and gi 3 by 60 20 and 0 respectively then the model would suggest a stage i investment portfolio of 5m 8m and 15m for gi 1 gi 2 and gi 3 respectively for a risk neutral decision maker but in the risk averse case would recommend decreasing the investment in gi 3 because of its high uncertainty case 1 in fig 11 if the learning assumption is changed to increase the effectiveness of gi 1 gi 2 and gi 3 by 60 30 and 10 respectively then the model would suggest investing 8m and 15m in gi 2 and gi 3 respectively in stage i for a risk neutral decision maker but would recommend adding an investment of 5m in gi 1 for a risk averse decision maker case 2 in fig 11 gi1 is not included in the risk neutral case because of its low efficacy without learning but is added in the risk averse case because of its low uncertainty and improved efficacy in the second stage thus whether risk aversion results in adding or subtracting types of investments from the first stage decisions depends on the magnitude of technology improvement in the learning assumptions 6 conclusion and final remarks we have presented a new class of methods for adaptive stormwater management incorporating decision maker s risk attitudes and learning followed by a hypothetical numerical example although the stochastic programming based method is developed for stormwater management it can also be applied to other adaptive management problems involving uncertainty and learning e g natural resources management and climate change we have described the general model set up above with detailed formulations in the appendix two different models are presented which reflect two distinct assumptions about the effect of learning the multi level learning ml model which assumes learning can only reduce variance and technology improvement ti model which assumes learning would also improve the overall performance of gi then the models are tested in the numerical example where the numerical results show that four basic types of investment strategies could be optimal figs 6 and 8 all in invest all the budget in the first planning stage in one technology greedy investment with deferral invest most budget in one technology in the first stage and save a small amount of budget for the later uses mixed investment with deferral having a mix of investments in the first stage to achieve partial or full learning pl and fl and saving a portion of the budget for the later stage to take advantage of the learning outcomes and learn and adjust early investment mainly for learning pl and or fl to defer the major decisions to the second stage when the learning outcomes are revealed in the results from the ti model fig 8 we see that possible technology improvement can provide additional incentive to invest in learning early stage i and invest in technologies that have potential to improve their effectiveness however the optimal investment strategy would depend on the decision maker s risk attitudes the learning assumptions and the particular parameter values finally we show that the solutions of the first stage investments and the resulting cvar estimates can be sensitive to sampling error in choosing scenarios solution stability analyses 5 1 can provide the decision makers more information concerning the risks var and cvar associated with the recommended gi portfolios future work includes a more realistic case study where in which the learning assumptions and the prior distributions of the gi performance are derived from discussions with the experts and stakeholders another future direction could be to improve the computation efficiency by applying heuristic search or scenario s reduction methods acknowledgment this research was funded by united states environmental protection agency usepa grant number 83555501 its contents are solely the responsibility of the grantee and do not necessarily represent the official views of the usepa further usepa does not endorse the purchase of any commercial products or services mentioned in the publication we thank c harman a mcgarity and d sheer for their guidance appendix a model formulations we now present the technical details of the model following rockafellar and uryasev 2000 cvar modeling method we discretize continuous random distributions by taking a sample of realizations and assigning a probability to each realization unfortunately to represent many possible degrees of learning under a continuous learning curve function an impractically large number of samples is required therefore to avoid the resulting computational problems we use step functions to approximate the learning curves so that we only need to generate a reasonably number of realizations of future scenarios one set of realizations per step for clarity our model denotes random variables with a tilde a 1 overall model formulation the proposed method allows us to build models under various assumptions about learning to assess whether considering learning could significantly change optimal here and now decisions however the exact formulation depends on the learning assumptions as examples sections a 2 shows the formulation of a multi level learning ml model which assumes that learning can only reduce the uncertainty of gi performance whereas the technology improvement ti model in section a 3 assumes that learning can reduce uncertainty and meanwhile stimulate improvement in the expected performance the ti model can be viewed as an extension of the ml model since it has the assumption that learning would improve overall gi performance in addition to the uncertainty reduction both models are applied to solve the hypothetical problem in section 4 a 1 1 prior and posterior distributions following the terminology of bayesian statistics the distribution of the gi performance in stage i representing our current understanding about the technology is called the prior distribution and the updated distribution in stage ii representing our new knowledge given the experience learned from the stage i investment is called the posterior distribution in probability theory the posterior distribution is defined as the conditional probability given what is learned the proposed method assumed that distribution parameters e g mean and variance of the posterior are functions of the stage i investment which can be derived from the data and experts judgments the assumptions come from the idea that more experience with gi would reduce the uncertainty of its performance we are interested in the overall performance of many gi practices but not the performance of individual gis and could result in better designs and installations and therefore more reduction of stormwater these functions are named learning curve functions a 1 2 learning curve functions the prior distributions denoted c i are assumed normal distributions with a mean  and a variance  2  and  2 are vectors whose elements  i and  i 2 i 1 2 3 are the mean and variance of the three gi practices the variance is the measure of uncertainty applied in this example the learning curve function for uncertainty variance reduction is in the form of a two step function see fig 3 indicating which of the three learning cases no learning nl partial learning pl and full learning fl would happen given an investment the learning curve function for uncertainty reduction of a gi type denoted g x i x i being the stage i investment in that gi is defined as follows for both ml and ti models a 1 g x i  2 i f t h p l x i n l t a k e s p l a c e   2  0 1 i f t h p l x i t h f l p l t a k e s p l a c e 0 i f t h f l x i f l t a k e s p l a c e where  is a user specified number to represent the variance reduction under pl and t h p l and t h f l are the thresholds for investments needed for the pl and fl cases respectively for example the two step function in fig 3 has  0 25 t h p l 8 and t h f l 15 the function says that if the investment is higher than the learning threshold of fl t h f l the variance of the posterior distribution is reduced to 0 certainty if the investment is between the investment thresholds of pl and fl then the variance is reduced to   2 otherwise the variance of the posterior distribution remains the same as the prior meanwhile the learning curve function for mean improvement used in the ti model denoted h x i is assumed to have only one level in the hypothetical example section 4 with a threshold equal to the threshold for pl t h p l as shown as below a 2 h x i    1 i f t h p l x i  i f x i t h p l where  is scaling constant that adjusts the posterior mean the function says that if an investment exceeds the threshold for pl t h p l the average performance would increase to   in a more general case g x i could have more than one pl option representing different levels of variance reduction and h x i could have multiple levels as well table a 1 priors and posteriors of ml and ti models in nl fl and pl cases assuming that priors and posteriors are normal distributions table a 1 learnings prior nl posterior fl posterior pl posterior multi level learning ml model c i   2 c i i f s certainty c i i p s c i p s   2 technology improvement ti model c i   2 c i i f s t i certainty c i i p s t i c i p s t i   2 table a1 illustrates how the posteriors change with the learning assumptions c i i p s and c i i p s t i denote the posterior stage ii distributions learned in the pl case for the ml and the ti models respectively c i i f s and c i i f s t i denote the stage ii realized performance value learned in the fl case for the ml and the ti models respectively and c i p s and c i p s t i denote the expected values of the posterior distributions in the pl case for the ml and the ti models respectively the values of c i i f s c i i f s t i c i p s and c i p s t i are random samples generated consistent with the assumptions concerning the prior and posterior distributions the notation for the realized values and distributions are scalars for one gi and are vectors for multiple gi types as in the formulations of the ml and ti models more details of the sampling processes are presented with the model formulations in section a 2 and a 3 a 2 ml model the ml model maximizes the probability weighted annualized stormwater reductions over the entire time horizon million gallon year mg yr subject to resource constraints e g budget logical constraints learning and auxiliary constraints that relate the amount of learning nl pl or fl for each gi type to the amount of the first stage investment x i in that gi and the cvar constraints that place a lower bound upon the annual stormwater reduction in the second stage resulting from all gi investments that have been made representing the risk of failing to meet the management goal note that the mathematical notation of the model formulations is in vector form instead of scalars a 2 1 scenarios and random sample sets instead of directly working with the probability density functions and solving a non linear programming problem the proposed method uses scenarios to approximate the random distributions so that the problem could be solved by linear programming the random variables in the hypothetical example are the gi performance in stormwater reduction per m investment per year and the scenarios are the possible outcomes of the random gi performance in the learning cases in stage i and ii a scenario consists of a set of values representing a possible outcome which are the realized gi performance in stage i and ii for each gi technology and each of the learnings i e nl pl and fl cases the performances of the gi practices are assumed to be statistically independent that is the performance of one gi gives us no information about the performance of the other gi the sampling procedure is described as follows 1 stage i m i samples are drawn from c i the prior distribution vector of the gi performance in which the elements are the prior distributions of each gi denoted c i s s s i 1 2 m i for the realizations of performance for each gi resulting from stage i s investment 2 stage ii the nl case the sampling process for each scenario s is the same as described in stage i since the posterior and prior distributions are the same and the samples are denoted by c i i n s r s s i 1 2 m i r s i i 1 2 m i i the fl case the assumption of no uncertainty in stage ii means one realization per scenario denoted c i i f s unlike the nl case where m i i realizations are needed to represent the posterior uncertainty the pl case the generation of posterior realizations is more complex in pl case the posterior distributions in the pl case denoted c i i p s is assumed to have a reduced variance   2  0 1 according to the learning curve g x i and a mean of  the prior mean from the law of total variance the prior variance must equal the preposterior variance v a r c i e v a r c i i p s v a r e c i i p s from this we can derive that v a r e c i i p s 1   2  0 1 similarly from the law of total expectation we can derive e c i e e c i i p s  as it should be if there is no technology improvement considered therefore the posterior mean e c i i p s of stage ii realizations c i i p s r for the pl case given scenario s is itself a random variable with mean equal to  and variance equal to 1   2 denoted c i p this allows us to generate realizations of c i i p s for each scenario s by first drawing a posterior mean denoted c i p s for that scenario s from c i p then a sample set of realizations of individual c i i p s r r s i i can be drawn from a distribution with mean c i p s and variance   2 denoted c i i p s r r s i i this process is repeated for each scenario s it is worth noting that the above process implies that mean performance of the posterior c i p is statistically independent of the observed stage i gi performance c i s in that scenario this represents the situation in which experience with implementation results in learning not only in the form of observations of the performance of stage i investments but also concerning the hydrological characteristics and installation and maintenance costs for the remaining candidate sites for example the managers and engineers may develop new gi siting strategies and designs based on the new knowledge of the watershed which improves the performance of gis or they may realize that the remaining gi candidate sites have poor soil properties which would lower the overall gi performance alternatively it is possible to assume nonzero or even perfect correlation of stage ii performance with what is observed in stage i in which case the main information obtained in stage i is the observed performance of that stage s investments a 2 2 mathematical formulation the ml model formulation which is a specific implementation of the general model in section 4 2 is as follows decision variables x i the stage i investment vector whose elements x i i i n 1 2 n represent the investment in n gi types x i r 1 n x i i n s the stage ii investment decision vector for the nl case in scenario s whose elements x i i n s i represent the investment in n gi types s s i x i i n s r 1 n x i i p s the stage ii investment decision vector for the pl case in scenario s whose elements x i i p s i represent the investment in n gi types s s i x i i p s r 1 n x i i f s the stage ii investment decision vector for the fl case in scenario s whose elements x i i f s i represent the investment in n gi types s s i x i i f s r 1 n l f a binary vector whose elements l f i indicate whether 1 or not 0 fl occurs for each of the n gi types l f r n 1 l p a binary vector whose elements l p i indicate whether or not pl occurs for each of the n gi types l p r n 1 l n a binary vector whose elements l n i indicate whether or not nl occurs for each of the n gi types l n r n 1  an auxiliary variable used to calculate v a r   r z s r the stormwater reduction below  in scenario s s s i r s i i 1 2 m i i z s r r constants a a matrix of resource land budget etc consumption rates per unit of investment in each gi type for each of k resource constraints a r k n b resource upper bounds b r k  the mean of the prior distribution of stormwater reduction rates for the n gi types at stage i  e c i  r 1 n c i s the realization of the stormwater reduction rate in stage i in scenario s for s s i c i s r 1 n c i p s the expected value of the posterior of the stormwater reduction rate for the pl case in scenario s for all s s i c i p s r 1 n c i i f s the second stage realization of the stormwater reduction rate for the fl case in scenario s for s s i c i i f s r 1 n c i i n s r the second stage realization of the stormwater reduction rate for the nl case in scenario s r s s i and r s i i c i i n s r r 1 n c i i p s r the second stage realization of the stormwater reduction rate for the pl case in scenario s r s s i and r s i i c i i p s r r 1 n c v a r  the user specified tolerable risk level for the second stage annual stormwater reduction  0 1 c v a r  r m a large number e g m 10 6 t i t i i the number of years in the planning horizon of stages i and ii respectively t i t i i r t h f l t h p l the investment thresholds for fl and pl respectively t h f l t h p l r 1 n t h i f l and t h i p l i n 1 2 n are the elements of their respective vectors objective and constraints a 3 m a x i m i z e f i x i x i i n 1 x i i n m i x i i f 1 x i i f m i x i i p 1 x i i p m i  x i t i i t i t i i 1 m i s 1 m i  x i i n s c i i f s x i i f s c i p s x i i p s s u b j e c t t o a 3 1 a x i x i i n s x i i f s x i i p s b 0 s s i resource constraints a 3 2 x i i t h i p l l p i 0 x i i t h u f l l f i 0 x i i m l f i t h i f l x i i m l p i l f i t h i p l l n i l p i l f i 1 u 1 2 n learning constraints a 3 3 x i i n s i m l n i 0 x i i p s i m l p i 0 x i i f s i m l f i 0 u 1 2 n and s s i auxiliary constraints a 3 4 z s r  f i i s r x i x i i n s x i i f s x i i p s s s i r s i i  1 1  m i m i i s 1 m i r 1 m i i z s r c v a r  cvar constraints a 3 5 f i i s r x i x i i n s x i i f s x i i p s c i s x i c i i n s r x i i n s c i i f s x i i f s c i i p s r x i i p s s s i r s i i a 3 6 x i x i i n s x i i p s x i i f s 0 s s i non negativity the objective a 3 maximizes the expected annual average stormwater reduction over the entire time horizon with the second stage reduction being discounted by the ratio of the second stage planning horizon to the total planning years constraint a 3 1 sets a lower bound for the resources e g budget and suitable sites constraints a 3 2 and a 3 3 are logical constraints that identify which learning type happens in the second stage by setting the upper bound of the corresponding second stage decision variable to m while restricting the upper bounds of the other second stage decision variables to zero constraints a 3 4 enforce a lower bound on cvar which requires the evaluation of the stormwater reduction in each scenario s r by eq a 3 5 finally constraints a 3 6 force the investment decisions to be non negative a 3 the ti model we assume that the investment could result in a technology improvement which increases the mean of the posteriors therefore the realized reduction in stage ii in the fl case denoted c i i f s t i should be sampled from a distribution with mean    1 to account for improvement by learning in the pl case the posterior mean c i p s t i for each s is generated from c i p t i where var c i p t i 1   2  0 1 and e c i p t i   denoted c i p s t i the random second stage samples in the pl case are generated from c i i s t i c i p s t i   2 the objective f i a 3 and f i i s r a 3 5 in the ml model are revised as follows while the form of the constraints remains unchanged objective a 4 m a x i m i z e f i x i x i i n 1 x i i n m i x i i f 1 x i i f m i x i i p 1 x i i p m i m a x i m i z e f i x i x i i n 1 x i i n m i x i i f 1 x i i f m i x i i p 1 x i i p m i  x i t i i t i t i i 1 m i s 1 m i  x i i n s c i i f s t i x i i f s c i p s t i x i i p s a 4 1 f i i s r x i x i i n s x i i f s x i i p s c i s x i c i i n s r x i i n s c i i f s t i x i i f s c i i p s r t i x i i p s for all s s i r s i i 
26262,urban stormwater management is shifting its attention from traditional centralized engineering solutions to a distributed and greener approach namely green infrastructure gi however uncertainties concerning gi s efficacy for reducing runoff and pollutants are a barrier to the adoption of gi one strategy to deal with the uncertainty is to implement gi adaptively in which stormwater managers can learn and adjust their plans over time to avoid undesired outcomes we propose a new class of gi planning methods based on two stage stochastic programming and bayesian learning which accounts for projected information gains and decision makers objectives and willingness to accept risk in the hypothetical example the model identifies four categories of investment strategies and quantifies their benefits and costs all in greedy investment plus deferral mixed investments plus deferral and learn and adjust which strategy is optimal depends on the user s risk attitudes and the alternatives costs and risks keywords adaptive management green infrastructure learning stormwater management stochastic programming 1 introduction green infrastructure gi sometimes referred to as low impact development or best management practices is a distributed approach that reduces urban stormwater runoff through on site infiltration storage and evaporation to improve water quality in downstream water courses examples of gi practices are rain gardens rain barrels tree trenches permeable pavement and green roofs gi is gaining popularity due to its potential social and economic benefits environmental protection agency 2010 among major us cities philadelphia is the first that has committed to gi as the primary solution for stormwater problems pwd 2011 starting in 2011 philadelphia plans to invest 2 4 billion on gi over 25 years other cities such as washington dc chicago portland and seattle are also implementing gi at site or neighborhood scales environmental protection agency 2010 however the runoff and pollution reductions provided by gis depend on for example their specific designs local climate characteristics underlying soil properties and vegetation montalto et al 2011 also gi performance may deteriorate with time maintenance costs and the upstream and downstream relationships of multiple gis add further to the uncertainty of the efficacy and expense of gi which complicates stormwater management planning and can result in a failure to meet management goals chocat et al 2007 roy et al 2008 researchers have developed tools for designing sizing and selection of gi for stormwater management at the site scale lee et al 2005 loiciga et al 2013 massoudieh et al 2017 morales torres et al 2016 zhen et al 2004 as well as watershed scale investment planning models for managing water quality and runoff volume mcgarity 2012 montaseri et al 2015 sebti et al 2016 yet uncertainty has not been recognized by these optimization frameworks because of the uncertain interactions of gi climate and human activities it is crucial to recognize risks and the opportunity to learn when planning barton et al 2012 williams and brown 2014 i e to manage adaptively an experienced planner or stormwater engineer may have a good sense of the extent of potential learning from experimentation such as field trials of gi however we argue that formalizing the learning process and estimating the value of learning can be worthwhile even when quantification is difficult this has not been done in previous gi optimization models in this paper we propose a new method for gi investment planning based on two stage stochastic programming tsp in which we incorporate projected information gains and decision makers risk attitudes and objectives the projected knowledge gains are assumed to be a function of the amount of investments of in gi these gains are called learning throughout this paper and are used to update our knowledge beliefs concerning of the gi cost effectiveness in the later stages based on the idea of bayesian inference to our knowledge this is the first time that risk aversion and learning have been included in dynamic optimization models for adaptive stormwater management this method aims at providing guidance regarding the choice of gi practices investment timing and amount risks of failing to meet management goals and maximization of benefits including social and economic benefits in the hypothetical example in section 4 the goal of the two stage decision problem is to maximize cumulative stormwater reductions given a fixed budget for the 40 year planning horizon where early investments at year 1 may result in learning that updates our understanding of the gi cost effectiveness in later decision stage at year 11 in the example we identify four broad classes of strategies which we call all in greedy investment plus deferral mixed investment plus wait and see and learn and adjust this range of possibilities involves tradeoffs between cost expected stormwater reduction and risks the best choice in a given situation depends both on case study specific parameters and the decision maker s willingness to accept risks the remainder of this paper is organized as follows in the next section we summarize the literature on adaptive management risks associated with gi and the use of stochastic programming to model learning there are indeed previous models for water resource management that include uncertainty and risk aversion and models for managing ecosystems and climate change that represent learning yet models that simultaneously consider both risk aversion and learning for adaptive management have not been proposed or implemented in stormwater management or other related fields section 3 explains the building blocks of the proposed method and illustrates the ideas with a decision tree example section 4 shows the results from a hypothetical example to illustrate the method which is formulated as mixed integer linear programming with risk constraints sections 5 discusses the sensitivity of the solutions and presents conclusions finally the mathematical formulation is presented in the appendix 2 literature review 2 1 adaptive stormwater management adaptive management is a framework for long term planning under uncertainty it was first proposed by holling 1978 for environmental assessment and management and by walters and hilborn 1976 in ecological management it is now widely recognized and applied in those contexts lovell and taylor 2013 mccarthy and possingham 2007 southwell et al 2016 williams 2011 adaptive management can be characterized as a process of learning to manage by managing to learn bormann et al 1994 in which decisions at each planning stage must balance the cost and benefits to future decisions of learning to reduce uncertainty versus investing to yield immediate benefits williams 2011 this paper presents a general methodology for quantitative implementation of adaptive management that is designed to provide useful information in the form of quantified risks and the costs and benefits of learning 2 2 risks in stormwater management with gi researchers have recognized that there exist risks in managing stormwater and have tried to address them chocat et al 2007 pointed out three particular types of risks involved with gi 1 transferring maintenance responsibility to end users may result in degraded performance 2 uncertainties in the transition path from the centralized system to decentralized systems and 3 residual contamination in stormwater retained and treated by gi which could cause human health concerns in addition roy et al 2008 flagged the risks of underestimating costs of gi installation and maintenance missing management goals loss of functionality and community resistance to installations particularly in municipalities of lower socio economic status with relatively few natural environmental assets however quantifying the risks associated with stormwater management is challenging a few studies have tried to estimate the risks of stormwater pollution for example stormwater pollution risks to ecosystems novotny and witte 1997 overflow risks from detention basins guo 2002 and sediment pollution risks from combined sewer overflows csos in receiving waters rossi et al 2005 yet neither optimization models nor decision support tools in general have been developed to manage risks or evaluate adaptive strategies in stormwater management 2 3 stochastic programming applications and learning two stage or more generally multi stage stochastic programming tsp is a logical way to model the implementation of adaptive management as it can analyze here and now investments while considering opportunities to change course in future stages depending on what is learned and their probabilities shapiro and philpott 2007 generalizations of tsp including stochastic dynamic programming and partially observable markov decision processes describe sequential decision processes where decisions are made in each stage based on the decision maker s beliefs concerning the underlying state of nature and the expected value of some objective monahan 1982 white 1991 chance constrained and risk averse programming are other optimization approaches that use probability distributions and can be compatible with tsp housh et al 2013 krokhmal et al 2001 wang and huang 2014 other approaches to decision making under uncertainty attempt to avoid the use of probabilities one is robust decision making rdm which was developed for the problems with deep uncertainty i e uncertainty is highly subjective such that different experts estimates of probability distributions may be very different from each other lempert and collins 2007 rdm generates plausible scenarios and attempts to identify strategies that work well across all scenarios instead of using a probability distribution and an objective based on probability weighted expected value rdm applications can be found in the climate change and water supply literature beh et al 2017 kasprzyk et al 2013 lan et al 2015 mortazavi naeini et al 2015 however rdm does not naturally lend itself to quantifying the value of learning in adaptive management so our approach instead relies on tsp risk aversion in which decision makers place greater weight on poor outcomes compared to use of expected probability weighted values has been considered in many environmental management problems e g baker 2009 chao and hobbs 1997 piantadosi et al 2008 the particular implementation of risk aversion that we use conditional value at risk cvar explicitly defined below has been applied in water supply allocation and storage problems to explore risk expected value tradeoffs paydar and qureshi 2012 piantadosi et al 2008 webby et al 2007 but not in water quality management ours is the first use of cvar to address risk in water pollution investments learning has been considered in a wide range of environmental applications usually in the form of bayesian analysis kim et al 2003 and jacobi et al 2013 applied stochastic dynamic programming to fishery and water quality management respectively where research and monitoring learning are optimized in the first stage followed by decisions concerning land and ecosystem management actions in the second stage harrison 2007 developed a bayesian programming method for water quality control problems varouchakis et al 2016 applied bayesian decision analysis in reservoir construction planning problem a number of analyses of uncertainty and learning can be found in the climate policy literature see golub et al 2014 for instance baker 2009 presented a tsp model for optimizing carbon emissions abatement with learning about uncertain climate change damages while webster et al 2017 applied tsp to consider optimal research into climate mitigation technologies whose performance is uncertain in their stochastic dynamic programming models the state variables e g the belief of climate change and mean water level are updated by bayes law with new observations which is the type of learning we implement in our models below in summary we have found that stochastic programming has been used to implement adaptive management in related contexts but not in gi planning itself learning has been addressed but the construction of the likelihood function is often challenging which limits the applicability of bayesian approaches the method presented in the following section uses simple learning curve functions to depict the relationship of the here and now gi investment and learning which provides an intuitive way to express the amount of learning while avoiding the need to explicitly construct likelihood functions 3 methodology the primary objective of urban stormwater management is to reduce runoff in order to prevent sewer overflows and improve water quality in streams while the problem can be formulated as a multi objective optimization for simplicity our formulation considers only one objective to be optimized i e runoff reduction subject to constraints on the other objectives e g a fiscal budget and the risk of undesired outcomes in this section we only explain the general scheme of the method and present the full mixed integer linear program implementation of the tsp in the appendix section 3 1 presents a decision tree example that we use to illustrate the underlying logic of the method for representing learning and adaptive gi investment planning section 3 2 presents the basic stochastic programming framework and then explains the modeling of risk aversion and learning in that framework 3 1 decision tree representation of the adaptive gi investment planning model in the case of gi planning with two investment decision stages denoted by stages i and ii the manager needs to make investment planning with several distinct gis whose performance stormwater reductions are uncertain and independent we summarize the manager s problem as follows decisions choose the gi investment portfolio in stage i given a budget shared with both stages while considering the opportunity to change course in stage ii in order to o maximize the objective of expected reductions in total stormwater runoff over a multidecadal time horizon while o satisfying a risk constraint concerning the annual runoff reduction in stage ii and a fixed budget shared by both stages assumptions o the manager is risk averse regarding the possibility of failing to meet the state ii reduction target in annual stormwater reduction o investment in a particular type of gi in stage i will result in learning if the investment exceeds some threshold this learning can be taken advantage of in stage ii by investing more in that type of gi if it turns out to be highly effective or investing in other types if the first type is instead found to be relatively ineffective o learning about one type of gi provides no information about the performance of others o gis are installed in parallel i e no interactions among gi installations so that the reduction in stormwater can be summed we next use a decision tree schematic to illustrate the underlying logic of the method interested readers can refer to the appendix for details of the mathematical formulation 3 1 1 decision tree example a decision tree involves decision nodes squares chance nodes circles and outcomes at the end of the tree branches the chronologic sequence of decisions and chance events proceeds from left to right a decision node represents a point in time when decisions must be made among the alternatives represented as arcs exiting the right side of the node a chance node stands for random events each represented by arcs exiting the right whose probabilities sum to 1 and the outcomes show the objective function values realized for a particular sequence of decisions and random events represented by the nodes and arcs leading from the left most node to the terminal node on the right fig 1 is a schematic in that only some of the nodes and branches are shown for clarity in this example the manager can make investments in either or both stages i and ii which can consist of investments in any or all of n types of gi in general each type can have different levels of efficiency and uncertainty in stormwater reduction per investment following the terminology of bayesian statistics the distribution of the gi performance in stage i representing our current understanding about the technology is called the prior distribution c i and the updated distribution in stage ii representing our new knowledge given the experience learned from the stage i investment is called the posterior distribution c i i s in probability the posterior distribution is a conditional probability of the outcome given what is learned we assumed three types of learning as follows no learning nl the posterior distribution is the same as the prior distribution partial learning pl the variance of the posterior distribution is less than the prior distribution but not 0 and full learning fl the posterior distribution has zero variance certainty pl and fl are achieved for a particular gi type if investment x i in that type exceeds thresholds respectively denoted as t h p l and t h f l t h p l t h f l which of the types of learning that happens depends on which of the thresholds are met that is if the investment in stage i denoted x i is less than t h p l nothing is learned and the posterior distribution is the prior distribution between t h p l and t h f l then pl takes place and otherwise fl takes place we defer the discussion of the learning and investment relationship to the next subsection and focus our discussion here on the decision problem to account for uncertainty m i scenarios indexed by s are generated after the stage i decision is made and m i i scenarios indexed by r are defined to follow each stage ii decision the total number of scenarios is m i m i i each stage i scenario contains a realization of stormwater reduction and a learning outcome the posterior distribution from the stage i investment while each state ii scenario describes a realized reduction for investments in the second stage to help the reader understand the process we present a numerical example of a pl branch of the decision tree fig 2 in this example the manager has two investment options gi1 whose performance is normally distributed mean and variance equal to 0 5 gallon per per year gal yr and 0 04 gal yr 2 respectively and gi2 which provides 0 48 gal yr stormwater reduction with certainty the total budget for the two stage planning problem is 100m and the investment decisions are made at year 1 and 11 we assume that once the first stage s gi is installed it will continue providing stormwater reduction until the end of the planning horizon and therefore the installations in stage i can provide stormwater reduction for 40 years while if installed in stage ii a gi reduces stormwater only for 30 years costs are not discounted in this example the manager s objective is to maximize the total stormwater reduction over the 40 year planning horizon however the manager may also be concerned with the risk of very low reductions occurring in stage ii as we explain below moving forward in time from left to right in fig 2 first the manager decided to invest 40m in gi1 and none in gi2 because she knows that the former investment would result in pl and reduce the performance uncertainty in gi1 to an assumed value of 0 01 gal yr 2 however she does not know which scenario s she would be in prior to entering stage ii either one of the two stage i scenarios could happen scenario s 1 consists of a realization of a performance of 0 7 gal yr reduction for the investment made in gi1 in stage i and a posterior distribution with mean and variance equal to 0 675 gal yr and 0 01 gal yr 2 respectively meanwhile scenario s 2 could consist of a realization of 0 6 gal yr reduction for that gi and a posterior distribution with mean and variance equal to 0 325 gal yr and 0 01 gal yr 2 respectively note that those two realized performance values are consistent with the assumed prior mean and variance i e mean 0 675 0 325 2 0 5 variance 0 675 0 5 2 0 325 0 5 2 2 0 01 0 04 more details of the preservation of the prior mean and variance can be found in the appendix note also that although we only have two scenarios for each chance node for brevity a large number of scenarios is recommended to better represent the random distributions in stage ii the manager then makes another investment decision which depends on which scenario she is in if she is in scenario s 1 the stage ii investment would be to allocate the remaining part of the budget 60m in gi1 in order to take advantage of its high expected performance in the posterior distribution whereas if she is in scenario s 2 she would rather invest the remaining budget in gi2 since the expected value of the posterior distribution for gi1 s performance is lower than 0 48 gal yr the final outcomes at the end of the tree are the total stormwater reduction for the 40 year planning horizon we assume equal probability for each scenario 50 so that we can calculate the stormwater reduction under each combination of first and second stage scenarios s r as shown in table 1 and the expected reduction of the first stage decision x i 40 m 0 1840 mg in contrast if learning is not considered a risk neutral manager would invest all her budget in gi1 in stage i all in and receive an expected value of 2000 mg stormwater reduction 0 5 40 yr 0 7 gal yr 0 5 40 yr 0 3 gal yr however if she is risk averse and would like to make sure the annual reduction she received at the end of the planning horizon would be higher than some management goal she may want to instead consider the investment option in fig 2 although the investment presented in fig 2 provides less total stormwater reduction 1840 mg 0 25 2515 0 25 2155 0 5 1 344 next to last column of table 1 this is 160 mg less than the all in case the worst annual reduction 40 8 mg yr under s 2 is higher than the worst reduction of the all in strategy 100m 0 3 gal 30 mg yr this example is just one branch of the decision tree in which the pl takes place there could be other investment strategies that show different tradeoffs between expected reduction and risk in the nl fl and other pl branches which are not shown it is worth noting that the mean of particular posteriors for particular scenarios s could be higher or lower than the prior s mean however the overall mean is preserved when averaged across all scenarios while the posterior variance is always reduced because of our learning assumption moreover the realizations of the prior may not correspond to the means of the posteriors for example the first stage realization for a particular gi might be a disappointingly low stormwater reduction per of investment yet as a result of this experience engineers may also have learned how to improve that gi s design which improves the mean of the posterior distribution of gal for that gi as another example the reduction realized in the first stage could be high however the stormwater managers may find that the best locations have been taken so that remaining sites would cost more for installing gi which results in a lower mean of the posterior distribution compared to the prior distribution rather than defining a decision tree by discretizing values of stage i and ii investments x in this manner and then solving it by standard backward induction methods we instead solve a stochastic optimization problem with the same logical structure using mixed integer linear programming as described in the appendix this allows us to treat x as continuous variables and risk constraints can also be imposed which is done only with difficulty in a decision tree the proposed method can handle a large number of scenarios and gi types and is in general easy to solve furthermore our formulation allows the user to define learnings discussed in the next subsection by changing the fiscal budget and target cvar our risk metric in the proposed method tradeoffs between expenditures risk and expected stormwater reductions can be explored as we illustrate with the example described in section 4 3 1 2 learning and learning curve functions learning is the process of understanding the system of interest specifically in statistics learning is the process of updating one s beliefs about the system from new observations or new findings where a belief is expressed as the distribution of a random variable the traditional bayesian approach assumes a prior distribution for a random variable based on current understanding while representing learning by the adjustments in the distribution in the later stages kelly and kolstad 1999 for example such adjustments might depend on what is learned and include a a reduction in the variance of the probability distribution and or b a change in the mean of the distribution as shown in the decision tree example above in practice the prior distribution of some uncertain variable c i can be updated using bayes law with actual observations after research or monitoring take place although the actual observation is not available at the first planning stage we will usually expect that more gi investment will result in a more significant reduction in uncertainty of gi performance in later stages the underlying assumption is that implementation experience can be transformed into the knowledge of the systems through a process which is described as a learning curve function berglund and sderholm 2006 ferioli et al 2009 sderholm and sundqvist 2007 we adopt learning curve functions in our model and use them to describe how the bayesian updating process will be affected by the level of investment for example learning curves denoted g x might show how the variance changes using 1 step 2 step or linear functions as shown in fig 3 in the figure the 1 step function shows that if the investment is larger than or equal to 8m learning occurs and the variance is reduced to zero otherwise the variance will remain unchanged the 2 step function has three states no learning nl partial learning pl and full learning fl with 100 25 and 0 variance respectively corresponding to investment under 8m between 8m and 15m and over 15m on the other hand the linear function shows that the variance reduction is proportional to any investment less than 20m learning curves can be very general for instance representing shifts in the mean of the uncertain variable such that the average over the posteriors is better than the prior because learning has improved the technology the users can choose the form and parameterization of the learning curves to reflect expert judgment statistical analyses or both 3 2 two stage stochastic programming with cvar constraints this section introduces a general mathematical statement of the proposed method which can help readers to understand the full formulation in the appendix 3 2 1 basic two stage stochastic programming tsp a generic formulation of a tsp model is as follows risk aversion is ignored for the moment so the objective eq 1 is to maximize the expected reductions in runoff subject to a resource budget constraint and the non negativity constraints eqs 2 and 3 choose x i x i i in order to maximize 1 f i x i x i i e c i x i e s s c i i s x i i s subject to 2 a x i x i i s b 0 s s 3 x i 0 x i i 0 notation s is the set of future scenarios and s s is the index of the scenarios x i and x i i s r 1 n are the decision vectors representing the investments in n types of gi in stage i and in scenario s stage ii respectively x i i x i i s for all s s f i x i x i i is the overall expected benefit function e g expected reductions in stormwater runoff c i r n 1 is a random vector representing the gi s performance coefficients e g gal yr in stage i c i i s r n 1 is a random vectors representing the gi s performance coefficients in scenario s stage ii a r m n and b r m 1 are constant matrices for linear resource constraints the probability distribution of c i is the prior distribution while c i i s is the posterior distribution given that scenario s has occurred updating the prior of c i to the posterior of c i i s given s is the process of learning matrices a and b are deterministic in the problem formulations above but they could also be stochastic a special case of the tsp model is one with a deterministic second stage problem however in the simplest case in which the decision maker is risk neutral it makes no difference whether the second stage problem has residual uncertainty in the objective function or not since the objective is to maximize expected performance we can just use the expected value of c i i s in the second stage objective this is however not true if the decision maker is risk averse in which case a formulation that includes the decision maker s risk attitude is needed this generalization is the subject of the next subsection 3 2 2 risk averse optimization a decision maker s risk averse preferences can be modeled with constraints on some risk measures see artzner et al 1999 let f x be the uncertain value of the objective function assuming that f x is to be maximized given decisions x conditional value at risk cvar is the risk measure used in this paper and is a popular measure because of certain mathematical properties it possesses to explain cvar we first introduce another popular risk metric value at risk var var is the value of the  quantile of the uncertain objective f x given that the decisions are x  is a specified number ranging from 0 to 1 indicating the probability of the least acceptable outcome to the decision maker cvar is the conditional mean of the outcomes worse than v a r  x given  and the decisions x therefore c v a r  v a r  the mathematical expressions of the two risk measures are as follows var 4 v a r  x m i n y p r o b f x y  cvar 5 c v a r  x 1  0  v a r y x d y fig 4 illustrates the meaning of standard deviation  var and cvar for a standard normal distribution mean 0 variance 1 and  0 025 the var and cvar measures are indices of bad outcomes and so more is desired if f x is to be maximized as is the case here with stormwater reductions thus to represent a limit on risk they would be constrained by imposing lower bounds we chose to constrain cvar because it has two appealing properties a ease of computation a linear program can be used fx1 when there are discrete scenarios rockafellar and uryasev 2000 and b cvar reflects the distribution of outcomes below var penalizing distributions whose tails encompass more extreme values by adding cvar constraints the optimization model can represent risk averse preferences if the constraint is binding the result is likely to be an investment that increases the expected performance in the worst case scenarios those with a cumulative probability less than  however this will likely be at the expense of a deterioration in the expected value of the objective 1 that is there will be tradeoffs between risk and expected performance adding cvar constraints in tsp directly makes it a non linear problem because of the nonlinearity of the probability distribution function however rockafellar and uryasev 2000 proposed a linear programming formulation with monte carlo sampling that approximates the cvar problem we adopt a variant of that model krokhmal et al 2001 that maximizes the expectation of f x subject to cvar constraints 6 6 z k  f k x f o r a l l k 1 2 m  1 1  s s p k z k c v a r  where k is the index of m realizations of the random variables  is an auxiliary variable for v a r  calculation z k is an auxiliary variable for the calculation of the loss exceeding v a r  under realization k which has probability p k f k x is the function of some metric that we would like to constrain the risk on under realization k and c v a r  is a specified number representing the least acceptable outcome e g the smallest runoff reduction that is acceptable our implementation is somewhat more complex to account for the two stage nature of the problem in which overall performance depends on realizations in both stage i earlier years and stage ii later years more details are provided in the appendix 4 a hypothetical example 4 1 overview of assumptions the modeling framework summarized above is general in that it gives us the flexibility to build versions based on a range of assumptions about learning to assess whether considering learning could significantly change the optimal stage i investment decisions in the illustrative example of this section we implement two versions the multi level learning ml model and the technology improvement ti model the details for both of which are presented in the appendix the ml model assumes that the first stage investment for a given gi type could yield either nl pl or fl as in the two step learning function shown in fig 3 meanwhile the ti model assumes that learning not only reduces the variance but also increases the expected value of the posterior distributions of stormwater reductions the ti model can be viewed as having two learning curves for each gi type showing the impact of learning upon the mean and variance respectively of the posterior distributions whereas the ml model only has a single learning curve function corresponding to just the posterior variance in this two stage planning example we make the following assumptions 1 the stormwater manager can invest in three gi types called gi 1 gi 2 and gi 3 2 the types have random first stage performance stormwater reduction in gal yr levels c i 1 c i 2 and c i 3 respectively 3 a budget of 100m is available which can be optimally split between stages i and ii the planning horizon is 40 years stage i begins at year 1 and stage ii will begin at year 11 4 the decision variables are how to distribute the 100m budget between the stages and among the gi types the distribution of the budget allocated to stage ii among gi types depends on the scenario s 5 the objective function is to maximize the total probability weighted annualized runoff reduction in million gallons year mg yr resulting from the investments with the reductions summed over a 40 year planning horizon once a gi type is installed it will continue to provide stormwater benefits until the end of the planning horizon year 40 6 constraints on investment include the overall budget constraint nonnegativity for all investments in each stage and definitions of cvar and learning relationships defined above also see the appendix a prespecified lower bound is placed on cvar 0 1 that is the manager specifies a minimum acceptable stormwater reduction corresponding to the conditional expectation of the worst 10 of the outcomes in the examples we vary cvar 0 1 mg yr from 0 to 60 to represent increasing degrees of risk aversion the relationships between first stage investments and learning are summarized in sections 4 2 and 4 3 the final set of assumptions concern the three gi types they represent three distinct technologies gi 1 is a low cost and well understood technology a low variance for c i 1 with the lowest learning thresholds for both pl and fl gi 2 is more cost efficient than gi 1 in terms of expected gal yr performance but the uncertainty associated with its performance and its learning thresholds are also higher and gi 3 is a new technology with little empirical data for its cost effectiveness but is believed to have the highest expected cost efficiency as well as the most uncertainty about its gal yr performance and also the highest learning thresholds for both pl and fl table 2 shows the assumptions made about their first stage performance in this example the learning curves variance reduction for each gi type used in the ml model are shown in fig 5 there g i x 1 i 1 2 3 signifies that the investment is not enough to trigger learning nl g i x 0 25 means the investment results in partial learning pl and the variance is reduced to one fourth of the original value and g i x 0 means that perfect information is provided in stage ii fl so that variance is reduced to zero the pl 75 reduction and fl 100 reduction thresholds are 5m and 10m respectively for gi 1 8m and 15m respectively for gi 2 and 15m and 30m respectively for gi 3 in the rest of section 4 we show the stage i decisions resulting from the ml and ti models sections 4 2 and 4 3 respectively for a range of cvar values which represent different levels of risk aversion also we show the tradeoff between expected stormwater reduction and risk indicating that a substantial improvement in risk can be purchased with a slight deterioration in expected reduction the specific learning assumptions used in the ml and ti models are described in their respective sections 4 2 results from the ml model assumes no technological improvement to represent uncertainty in gi performance we generated 1000 stage i scenarios s as well as 5 stage ii scenarios r for each stage i scenario we generated more state i scenarios because computational experience shows that a larger sample size in stage i can help solutions to converge but that increasing sample sizes in the later stage has less of an effect ji et al 2005 the issue of solution convergence is discussed further in section 5 1 the ml model is solved for values of cvar ranging from 16 mg yr to 42 mg yr under the 100m budget and the resulting first stage investments in the three gi types are shown in fig 6 left axis the figure also shows the probability weighted average stormwater reduction averaged over the 40 year time horizon right axis at a cvar of 16 mg yr the cvar constraint no longer binds and the risk neutral solution results i e this is the solution that maximizes the expected annual stormwater reduction achieving 60 mg yr higher values of the cvar lower the risk of poor stormwater results but at the expense of lower expected performance cvar can be feasibly increased as far as 42 mg yr which represents a 163 increase at that level expected stormwater reduction however falls about 13 from 60 to 52 mg yr whether that deterioration in expected performance is justified by the reduced risk of abysmal performance is a value judgment that the decision makers must make informed by the results of the model depending on the degree of risk aversion the optimal strategy falls into one of four groups the results suggest that a risk neutral decision maker should invest all 100m in gi 3 in stage i because gi 3 has the largest expected benefit which is shown as the all in solutions when cvar 16 mg yr there appear to be insufficient incentives to invest in other technologies or to wait to obtain better estimates of gi performance however if the manager is risk averse she may prefer to save some budget for future investment or mix her investment with more than one gi type or to take advantage of learning for example when 16 cvar 24 mg yr the model suggests investments in gi 3 but also to save some budget for the later stage in case gi 3 turns out to be worse than expected called greedy investment with deferral strategy when 24 cvar 41 mg yr the model suggests investments in both gi 2 and gi 3 while saving some budget to take advantage of learning from fl or pl called mixed investment with deferral strategy in gi 2 and gi 3 finally when 41 cvar 42 mg yr the model suggests investing only for learning pl for gi 1 and gi 3 fl for gi 2 and saving the rest of the budget to invest in the second stage in order to minimize the risk i e maximize cvar which we call the learn and adjust strategy not surprisingly the most investment strategies suggest investing early because to wait means that there is no reduction in the first 10 years which lowers the total runoff reduction over the 40 year time horizon 4 3 results from the ti model assumes technology improvement the ti model adds another set of learning curve functions fig 7 denoted h i x for i 1 2 3 to the above ml model such that if the learning criteria are met the expected values of gi performance c i i 1 c i i 2 and c i i 3 will improve by 50 20 and 0 respectively as a result compared to the ml model of section 4 2 the model has a higher incentive to make here and now stage i investments for reducing uncertainty and increasing the expected values fig 8 moreover under the technology improvement assumption the cvar value can be as high as 51 mg yr and still yield a feasible solution because of the increase in performance resulting from stage i investment while in the ml model the cvar cannot exceed 42 mg yr finally when cvar is set to 39 mg yr or higher the ti model also suggests an investment of 5m in gi 1 to obtain pl whereas this technology is not invested in by the ml model except the most risk averse case this is because gi 1 being more uncertain has a higher potential to increase its performance so that it may become a preferable option in stage ii if its uncertain second stage performance turns out to be relatively high but if we do not invest in gi 1 in stage i we may be disappointed by the achieved runoff reduction in stage ii if gi 2 and gi 3 both turn out to be less efficient than expected fig 8 shows the model s objective expected stormwater reduction over 40 years as a function of cvar it reveals that without considering risk aversion the objective value is 60 mg yr the same as in fig 6 which like the ml model is an outcome of the all in strategy it turns out that under risk neutrality the expected gains in technology effectiveness in stage ii are not justified by the loss of efficiency resulting from the stage i investments necessary to achieve those gains however in the presence of risk aversion cvar can be increased to 51 mg yr if the decision maker is willing to accept a loss of 5 6 mg yr from 60 to 54 4 in expected value this occurs from investing the minimal amount needed in stage i to achieve the technology improvements and posterior variance reductions that are possible in all three technologies also when applying a mixed investment plus wait and see strategy cvar in the range of 21 47 the objective curve is higher than the results in fig 5 which is a result of technology improvements the technology improvement assumption can be viewed as indicating that a drop in cost or an increase in efficiency for a particular gi is forecasted as possible in the near future then the ti model can help answer the question of how stage i investments can help expedite these improvements by providing several distinct solutions mixes of gis for the decision makers to ponder with some solutions emphasizing reducing uncertainty and others focused on improving expected stormwater reductions 5 discussion section 4 has shown that in this hypothetical example the ml and ti models both suggest four distinct investment strategies depending on the learning assumptions decision maker s risk attitudes and the particular parameter values assumed for the model in a more realistic case study the choices of the model input assumptions need to reflect the conditions and the opportunities in the study area these will include the probability distributions and learning costs resource and other physical and regulatory constraints however the user should keep in mind that as with the results of any model the precise numerical results should be viewed skeptically and that the most valuable outputs are insights as to which investment alternatives appear most economic and why in this paper we focus on the definition and illustration of the method future work will apply the method to a realistic case study in this section we consider two crucial implementation issues the first issue is solution instability due to scenario sampling errors in which the optimal investments may be a function of the particular sample that is taken section 5 1 presents a solution stability analysis to examine the variability of the solutions and the resulting risk levels the second issue which is discussed in section 5 2 is the impact of alternative learning assumptions since they are based on expert judgment and are likely to be imprecise and significantly impact the solution 5 1 are solutions robust to sample error the technique we used to solve the ml and ti models in section 4 1 and 4 2 relies on generating scenarios to approximate the random distributions which are subject to sample error a large sample size can reduce this error but will increase computational costs our numerical example presented in section 4 1 has 14 013 decision variables and 18 013 constraints respectively which takes about 10 30 min to solve on a conventional laptop intel core i7 4 gb ram therefore it is not practical to include much larger samples a solution stability analysis can provide information about solution variability due to sampling errors which also provides alternative solutions for the decision maker to consider to evaluate whether the sample size is adequate and to assess the resulting variability of the solutions we perform a solution stability analysis by running a monte carlo simulation of the ml model section 4 1 100 times with each of the 100 solutions obtained setting cvar 0 1 to 40 mg yr recall that the number of scenarios is 1000 and 5 for stage i and ii respectively fig 9 shows the results from the monte carlo simulation runs the histograms of the first stage solutions indicate that it is optimal to invest x 1 0 in gi 1 in all solutions and x 2 8 m pl in gi 2 for 9 of the solutions and x 2 15 m pl for 91 of the solutions for gi 3 it suggests a range of x 3 31 m to 43m fl with an average investment of 38 5m meanwhile the cvar 0 1 value is set to 40 but the 90 exceedance value var 0 1 can vary from 45 to 47 mg yr and the expected annualized runoff reduction can vary from 54 2 to 55 mg yr thus the pattern of investment is somewhat stable in the face of sample error but the precise level of risk and expected performance of the system can vary larger sample sizes would result in smaller variations the stormwater manager can choose an investment decision and run the monte carlo simulation to evaluate the variability of the objective and cvar values for example fig 10 shows the histograms of the objective and cvar values of the initial gi investment plan of 0m 15m 30m from 100 simulation runs which are in the ranges of 53 7 54 1 and 40 3 43 respectively this analysis provides additional information regarding the stability of the resulting expected outcomes and risk levels 5 2 how do first stage recommendations depend on learning opportunities and risk aversion decision makers can adjust learning assumptions to explore whether the possible benefits of learning can justify significantly different portfolios of the first stage investments a trivial example is that a risk neutral decision maker would apply the same all in strategy in the previous ml and ti examples figs 6 and 8 even though the latter has an additional technology improvement assumption on the contrary a risk averse decision maker with the cvar set to 36 mg yr would likely adopt a mixed investment with deferral strategy but the investment portfolio in the ml example fig 6 consists of only gi 2 and gi 3 whereas the investment portfolio in the ti example fig 8 also includes an investment in gi 1 besides our method can be used to evaluate active learning opportunities by applying a weight of zero to the first stage reduction in the objective so that the objective of the planning problem only focuses on the second stage reduction and considered the first stage decision as representing possibilities for active experiments as an example we modify the ti model changing the technology improvement assumption to increase the effectiveness of gi 1 gi 2 and gi 3 by 60 20 and 0 respectively then the model would suggest a stage i investment portfolio of 5m 8m and 15m for gi 1 gi 2 and gi 3 respectively for a risk neutral decision maker but in the risk averse case would recommend decreasing the investment in gi 3 because of its high uncertainty case 1 in fig 11 if the learning assumption is changed to increase the effectiveness of gi 1 gi 2 and gi 3 by 60 30 and 10 respectively then the model would suggest investing 8m and 15m in gi 2 and gi 3 respectively in stage i for a risk neutral decision maker but would recommend adding an investment of 5m in gi 1 for a risk averse decision maker case 2 in fig 11 gi1 is not included in the risk neutral case because of its low efficacy without learning but is added in the risk averse case because of its low uncertainty and improved efficacy in the second stage thus whether risk aversion results in adding or subtracting types of investments from the first stage decisions depends on the magnitude of technology improvement in the learning assumptions 6 conclusion and final remarks we have presented a new class of methods for adaptive stormwater management incorporating decision maker s risk attitudes and learning followed by a hypothetical numerical example although the stochastic programming based method is developed for stormwater management it can also be applied to other adaptive management problems involving uncertainty and learning e g natural resources management and climate change we have described the general model set up above with detailed formulations in the appendix two different models are presented which reflect two distinct assumptions about the effect of learning the multi level learning ml model which assumes learning can only reduce variance and technology improvement ti model which assumes learning would also improve the overall performance of gi then the models are tested in the numerical example where the numerical results show that four basic types of investment strategies could be optimal figs 6 and 8 all in invest all the budget in the first planning stage in one technology greedy investment with deferral invest most budget in one technology in the first stage and save a small amount of budget for the later uses mixed investment with deferral having a mix of investments in the first stage to achieve partial or full learning pl and fl and saving a portion of the budget for the later stage to take advantage of the learning outcomes and learn and adjust early investment mainly for learning pl and or fl to defer the major decisions to the second stage when the learning outcomes are revealed in the results from the ti model fig 8 we see that possible technology improvement can provide additional incentive to invest in learning early stage i and invest in technologies that have potential to improve their effectiveness however the optimal investment strategy would depend on the decision maker s risk attitudes the learning assumptions and the particular parameter values finally we show that the solutions of the first stage investments and the resulting cvar estimates can be sensitive to sampling error in choosing scenarios solution stability analyses 5 1 can provide the decision makers more information concerning the risks var and cvar associated with the recommended gi portfolios future work includes a more realistic case study where in which the learning assumptions and the prior distributions of the gi performance are derived from discussions with the experts and stakeholders another future direction could be to improve the computation efficiency by applying heuristic search or scenario s reduction methods acknowledgment this research was funded by united states environmental protection agency usepa grant number 83555501 its contents are solely the responsibility of the grantee and do not necessarily represent the official views of the usepa further usepa does not endorse the purchase of any commercial products or services mentioned in the publication we thank c harman a mcgarity and d sheer for their guidance appendix a model formulations we now present the technical details of the model following rockafellar and uryasev 2000 cvar modeling method we discretize continuous random distributions by taking a sample of realizations and assigning a probability to each realization unfortunately to represent many possible degrees of learning under a continuous learning curve function an impractically large number of samples is required therefore to avoid the resulting computational problems we use step functions to approximate the learning curves so that we only need to generate a reasonably number of realizations of future scenarios one set of realizations per step for clarity our model denotes random variables with a tilde a 1 overall model formulation the proposed method allows us to build models under various assumptions about learning to assess whether considering learning could significantly change optimal here and now decisions however the exact formulation depends on the learning assumptions as examples sections a 2 shows the formulation of a multi level learning ml model which assumes that learning can only reduce the uncertainty of gi performance whereas the technology improvement ti model in section a 3 assumes that learning can reduce uncertainty and meanwhile stimulate improvement in the expected performance the ti model can be viewed as an extension of the ml model since it has the assumption that learning would improve overall gi performance in addition to the uncertainty reduction both models are applied to solve the hypothetical problem in section 4 a 1 1 prior and posterior distributions following the terminology of bayesian statistics the distribution of the gi performance in stage i representing our current understanding about the technology is called the prior distribution and the updated distribution in stage ii representing our new knowledge given the experience learned from the stage i investment is called the posterior distribution in probability theory the posterior distribution is defined as the conditional probability given what is learned the proposed method assumed that distribution parameters e g mean and variance of the posterior are functions of the stage i investment which can be derived from the data and experts judgments the assumptions come from the idea that more experience with gi would reduce the uncertainty of its performance we are interested in the overall performance of many gi practices but not the performance of individual gis and could result in better designs and installations and therefore more reduction of stormwater these functions are named learning curve functions a 1 2 learning curve functions the prior distributions denoted c i are assumed normal distributions with a mean  and a variance  2  and  2 are vectors whose elements  i and  i 2 i 1 2 3 are the mean and variance of the three gi practices the variance is the measure of uncertainty applied in this example the learning curve function for uncertainty variance reduction is in the form of a two step function see fig 3 indicating which of the three learning cases no learning nl partial learning pl and full learning fl would happen given an investment the learning curve function for uncertainty reduction of a gi type denoted g x i x i being the stage i investment in that gi is defined as follows for both ml and ti models a 1 g x i  2 i f t h p l x i n l t a k e s p l a c e   2  0 1 i f t h p l x i t h f l p l t a k e s p l a c e 0 i f t h f l x i f l t a k e s p l a c e where  is a user specified number to represent the variance reduction under pl and t h p l and t h f l are the thresholds for investments needed for the pl and fl cases respectively for example the two step function in fig 3 has  0 25 t h p l 8 and t h f l 15 the function says that if the investment is higher than the learning threshold of fl t h f l the variance of the posterior distribution is reduced to 0 certainty if the investment is between the investment thresholds of pl and fl then the variance is reduced to   2 otherwise the variance of the posterior distribution remains the same as the prior meanwhile the learning curve function for mean improvement used in the ti model denoted h x i is assumed to have only one level in the hypothetical example section 4 with a threshold equal to the threshold for pl t h p l as shown as below a 2 h x i    1 i f t h p l x i  i f x i t h p l where  is scaling constant that adjusts the posterior mean the function says that if an investment exceeds the threshold for pl t h p l the average performance would increase to   in a more general case g x i could have more than one pl option representing different levels of variance reduction and h x i could have multiple levels as well table a 1 priors and posteriors of ml and ti models in nl fl and pl cases assuming that priors and posteriors are normal distributions table a 1 learnings prior nl posterior fl posterior pl posterior multi level learning ml model c i   2 c i i f s certainty c i i p s c i p s   2 technology improvement ti model c i   2 c i i f s t i certainty c i i p s t i c i p s t i   2 table a1 illustrates how the posteriors change with the learning assumptions c i i p s and c i i p s t i denote the posterior stage ii distributions learned in the pl case for the ml and the ti models respectively c i i f s and c i i f s t i denote the stage ii realized performance value learned in the fl case for the ml and the ti models respectively and c i p s and c i p s t i denote the expected values of the posterior distributions in the pl case for the ml and the ti models respectively the values of c i i f s c i i f s t i c i p s and c i p s t i are random samples generated consistent with the assumptions concerning the prior and posterior distributions the notation for the realized values and distributions are scalars for one gi and are vectors for multiple gi types as in the formulations of the ml and ti models more details of the sampling processes are presented with the model formulations in section a 2 and a 3 a 2 ml model the ml model maximizes the probability weighted annualized stormwater reductions over the entire time horizon million gallon year mg yr subject to resource constraints e g budget logical constraints learning and auxiliary constraints that relate the amount of learning nl pl or fl for each gi type to the amount of the first stage investment x i in that gi and the cvar constraints that place a lower bound upon the annual stormwater reduction in the second stage resulting from all gi investments that have been made representing the risk of failing to meet the management goal note that the mathematical notation of the model formulations is in vector form instead of scalars a 2 1 scenarios and random sample sets instead of directly working with the probability density functions and solving a non linear programming problem the proposed method uses scenarios to approximate the random distributions so that the problem could be solved by linear programming the random variables in the hypothetical example are the gi performance in stormwater reduction per m investment per year and the scenarios are the possible outcomes of the random gi performance in the learning cases in stage i and ii a scenario consists of a set of values representing a possible outcome which are the realized gi performance in stage i and ii for each gi technology and each of the learnings i e nl pl and fl cases the performances of the gi practices are assumed to be statistically independent that is the performance of one gi gives us no information about the performance of the other gi the sampling procedure is described as follows 1 stage i m i samples are drawn from c i the prior distribution vector of the gi performance in which the elements are the prior distributions of each gi denoted c i s s s i 1 2 m i for the realizations of performance for each gi resulting from stage i s investment 2 stage ii the nl case the sampling process for each scenario s is the same as described in stage i since the posterior and prior distributions are the same and the samples are denoted by c i i n s r s s i 1 2 m i r s i i 1 2 m i i the fl case the assumption of no uncertainty in stage ii means one realization per scenario denoted c i i f s unlike the nl case where m i i realizations are needed to represent the posterior uncertainty the pl case the generation of posterior realizations is more complex in pl case the posterior distributions in the pl case denoted c i i p s is assumed to have a reduced variance   2  0 1 according to the learning curve g x i and a mean of  the prior mean from the law of total variance the prior variance must equal the preposterior variance v a r c i e v a r c i i p s v a r e c i i p s from this we can derive that v a r e c i i p s 1   2  0 1 similarly from the law of total expectation we can derive e c i e e c i i p s  as it should be if there is no technology improvement considered therefore the posterior mean e c i i p s of stage ii realizations c i i p s r for the pl case given scenario s is itself a random variable with mean equal to  and variance equal to 1   2 denoted c i p this allows us to generate realizations of c i i p s for each scenario s by first drawing a posterior mean denoted c i p s for that scenario s from c i p then a sample set of realizations of individual c i i p s r r s i i can be drawn from a distribution with mean c i p s and variance   2 denoted c i i p s r r s i i this process is repeated for each scenario s it is worth noting that the above process implies that mean performance of the posterior c i p is statistically independent of the observed stage i gi performance c i s in that scenario this represents the situation in which experience with implementation results in learning not only in the form of observations of the performance of stage i investments but also concerning the hydrological characteristics and installation and maintenance costs for the remaining candidate sites for example the managers and engineers may develop new gi siting strategies and designs based on the new knowledge of the watershed which improves the performance of gis or they may realize that the remaining gi candidate sites have poor soil properties which would lower the overall gi performance alternatively it is possible to assume nonzero or even perfect correlation of stage ii performance with what is observed in stage i in which case the main information obtained in stage i is the observed performance of that stage s investments a 2 2 mathematical formulation the ml model formulation which is a specific implementation of the general model in section 4 2 is as follows decision variables x i the stage i investment vector whose elements x i i i n 1 2 n represent the investment in n gi types x i r 1 n x i i n s the stage ii investment decision vector for the nl case in scenario s whose elements x i i n s i represent the investment in n gi types s s i x i i n s r 1 n x i i p s the stage ii investment decision vector for the pl case in scenario s whose elements x i i p s i represent the investment in n gi types s s i x i i p s r 1 n x i i f s the stage ii investment decision vector for the fl case in scenario s whose elements x i i f s i represent the investment in n gi types s s i x i i f s r 1 n l f a binary vector whose elements l f i indicate whether 1 or not 0 fl occurs for each of the n gi types l f r n 1 l p a binary vector whose elements l p i indicate whether or not pl occurs for each of the n gi types l p r n 1 l n a binary vector whose elements l n i indicate whether or not nl occurs for each of the n gi types l n r n 1  an auxiliary variable used to calculate v a r   r z s r the stormwater reduction below  in scenario s s s i r s i i 1 2 m i i z s r r constants a a matrix of resource land budget etc consumption rates per unit of investment in each gi type for each of k resource constraints a r k n b resource upper bounds b r k  the mean of the prior distribution of stormwater reduction rates for the n gi types at stage i  e c i  r 1 n c i s the realization of the stormwater reduction rate in stage i in scenario s for s s i c i s r 1 n c i p s the expected value of the posterior of the stormwater reduction rate for the pl case in scenario s for all s s i c i p s r 1 n c i i f s the second stage realization of the stormwater reduction rate for the fl case in scenario s for s s i c i i f s r 1 n c i i n s r the second stage realization of the stormwater reduction rate for the nl case in scenario s r s s i and r s i i c i i n s r r 1 n c i i p s r the second stage realization of the stormwater reduction rate for the pl case in scenario s r s s i and r s i i c i i p s r r 1 n c v a r  the user specified tolerable risk level for the second stage annual stormwater reduction  0 1 c v a r  r m a large number e g m 10 6 t i t i i the number of years in the planning horizon of stages i and ii respectively t i t i i r t h f l t h p l the investment thresholds for fl and pl respectively t h f l t h p l r 1 n t h i f l and t h i p l i n 1 2 n are the elements of their respective vectors objective and constraints a 3 m a x i m i z e f i x i x i i n 1 x i i n m i x i i f 1 x i i f m i x i i p 1 x i i p m i  x i t i i t i t i i 1 m i s 1 m i  x i i n s c i i f s x i i f s c i p s x i i p s s u b j e c t t o a 3 1 a x i x i i n s x i i f s x i i p s b 0 s s i resource constraints a 3 2 x i i t h i p l l p i 0 x i i t h u f l l f i 0 x i i m l f i t h i f l x i i m l p i l f i t h i p l l n i l p i l f i 1 u 1 2 n learning constraints a 3 3 x i i n s i m l n i 0 x i i p s i m l p i 0 x i i f s i m l f i 0 u 1 2 n and s s i auxiliary constraints a 3 4 z s r  f i i s r x i x i i n s x i i f s x i i p s s s i r s i i  1 1  m i m i i s 1 m i r 1 m i i z s r c v a r  cvar constraints a 3 5 f i i s r x i x i i n s x i i f s x i i p s c i s x i c i i n s r x i i n s c i i f s x i i f s c i i p s r x i i p s s s i r s i i a 3 6 x i x i i n s x i i p s x i i f s 0 s s i non negativity the objective a 3 maximizes the expected annual average stormwater reduction over the entire time horizon with the second stage reduction being discounted by the ratio of the second stage planning horizon to the total planning years constraint a 3 1 sets a lower bound for the resources e g budget and suitable sites constraints a 3 2 and a 3 3 are logical constraints that identify which learning type happens in the second stage by setting the upper bound of the corresponding second stage decision variable to m while restricting the upper bounds of the other second stage decision variables to zero constraints a 3 4 enforce a lower bound on cvar which requires the evaluation of the stormwater reduction in each scenario s r by eq a 3 5 finally constraints a 3 6 force the investment decisions to be non negative a 3 the ti model we assume that the investment could result in a technology improvement which increases the mean of the posteriors therefore the realized reduction in stage ii in the fl case denoted c i i f s t i should be sampled from a distribution with mean    1 to account for improvement by learning in the pl case the posterior mean c i p s t i for each s is generated from c i p t i where var c i p t i 1   2  0 1 and e c i p t i   denoted c i p s t i the random second stage samples in the pl case are generated from c i i s t i c i p s t i   2 the objective f i a 3 and f i i s r a 3 5 in the ml model are revised as follows while the form of the constraints remains unchanged objective a 4 m a x i m i z e f i x i x i i n 1 x i i n m i x i i f 1 x i i f m i x i i p 1 x i i p m i m a x i m i z e f i x i x i i n 1 x i i n m i x i i f 1 x i i f m i x i i p 1 x i i p m i  x i t i i t i t i i 1 m i s 1 m i  x i i n s c i i f s t i x i i f s c i p s t i x i i p s a 4 1 f i i s r x i x i i n s x i i f s x i i p s c i s x i c i i n s r x i i n s c i i f s t i x i i f s c i i p s r t i x i i p s for all s s i r s i i 
26263,we present a new priority rated optimization model prom for multi sector water resource assessment allocation and management prom utilizes flow duration curves fdc demand to supply ratio dsr and utility indices ui to evaluate and optimize priority based multi sector water allocation dsr links demand volume and priority with corresponding supply volume and likelihood derived from segmentation of fdc the ui function assigns weights to ranges of dsr to assess the existing and potential alternative management scenarios supply reliability and ui values are used in a combinatorial optimization scheme to estimate allocated volume flow rate and percent exceedance prom is applied in the mara river basin of kenya tanzania and results showed potential improvement over the current management practice towards sustainability of the mara serengeti ecosystem prom bridges the gap between environmental and economic models while providing a user friendly platform for direct stakeholder involvement to explore alternative water allocation scenarios keywords demand supply ratio flow duration curve combinatorial optimization water resource management demand priority mara river water allocation prom software data availability software information name of software priority rated optimization model prom developer shimelis b dessu contact tel 305 401 5898 email sbehailu gmail com 11200 sw 8 st ahc5 364 florida international university miami fl 33172 usa availability www go fiu edu prom required hardware pc required software windows 7 or latest and text editor programming language matlab 2018a 1 introduction water management computer models have become an integral part of water resource management to protect the environment ensure public safety and maximize economic benefits through sustainable balance of available water and corresponding demand these models can be broadly classified as environmental economic or multi sector water management models environmental water management models seek to achieve sustainable ecological and ecosystem service outcomes acreman et al 2014 king and brown 2010 tharme 2003 flow duration curves fdc vogel and fennessey 1994 qian 2015 yilmaz et al 2008 have been widely used in environmental models to capture and preserve the natural hydrologic regime the fdc transforms a flow hydrograph into the percentage of time the flow would likely be available during the period of analysis fig 1 the objective of economic water management is to maximize economic benefits of water use based on average available water eg babel et al 2005 draper et al 2003 nishikawa 1998 noory et al 2011 reca et al 2001 blending environmental and economic water management objectives in multi sector management models has been challenging due to the anthropocentric nature of water management griffen 2006 and difficulty in monetizing environmental services multi sector water management models eg fredericks et al 1998 krogt 2008 perera et al 2005 yates et al 2005 zagona et al 2001 work around this limitation using a pre established set of demand priorities as a proxy to capture tangible and intangible benefits associated with economic and environmental services acreman and dunbar 2004 acreman et al 2014 mcclain et al 2014 and regulatory and policy constraints fredericks et al 1998 yates et al 2005 to identify optimal water allocation alternatives multi sector water allocation approaches depend on the average available resource from which allocations would come on the basis of demand priorities compromising the need to preserve the hydrologic regime for environmental objectives and providing an impression of equal likelihood of supply to all water use sectors considered in the management hence current multi sector models lack sufficient connection between demand priorities and the likelihood of corresponding supply by combining the flexibility of fdc to estimate volume and likelihood of supply and integrating priorities to demand to supply ratio dsr we present the development and application of a new priority rated optimization model prom for multi sector water resources management systems to bridge the gap in integrating environmental and economic management objectives fdc is widely used in flood forecasting and design of hydraulic structures vogel and fennessey 1994 and environmental water management mcclain et al 2014 vogel and fennessey 1995 environmental water management models employing fdc include probflo o brien et al 2018 desktop reserve model drm kashaigili et al 2007 ecological limits of hydrologic alteration eloha poff et al 2010 building block methodology bbm king and louw 1998 and downstream response to imposed flow transformation drift king et al 2003 2008 probflo o brien et al 2018 is a regional scale ecological risk evaluation tool that combines frequency duration and magnitude of flow and is applied in the mara river basin of kenya and tanzania and the senqu river basin in lesotho kashaigili et al 2007 applied drm based on exceedance probabilities of high and low flow events to derive ecological flow requirements in the ruaha national park tanzania eloha integrates existing hydrologic techniques and environmental flow methods eg bbm and drift to support comprehensive regional flow management king et al 2008 poff et al 2010 recent examples of fdc include characterization of environmental river flow requirements in the mara river of kenya and tanzania dessu et al 2014 mcclain et al 2014 and a comprehensive review of methods and results from long term studies in africa and south east asia as presented by king and brown 2010 despite the advantage of fdc to capture the variability of a natural system we have not encountered its implementation in any generic multi sector water management model hence the fdc is utilized in prom as the basis to determine the quantity and likelihood of water availability fig 1 multi sector management models link priorities with demand sectors and allocate water based on the proportional partitioning of the total available water among competing demands generic multi sector water management models include the water evaluation and planning weap model yates et al 2005 modular river basin network simulation modsim model fredericks et al 1998 resource allocation model realm perera et al 2005 riverware magee et al 2001 zagona et al 2001 river basin simulation model ribasim krogt 2008 and mike hydro basin dhi 2018 the objective functions of these models rely on the benefit risk and socio economic factors expressed with the priority of each demand sector weap implements a node link network of water demand and supply to redistribute resources among demand sectors based on a user specified priority of demands at each node modsim utilizes a basin simulation model employing an efficient minimum cost network flow optimization algorithm over a river basin to redistribute water on the basis of priorities such as water rights ownership contracts and interstate compacts fredericks et al 1998 mike hydro basin and riverware follow the order of priority providing optimal allocation for the higher priority using linear optimization of deviations from objective functions dhi 2018 magee et al 2001 the demand priorities in these models reflect the order of satisfying the demand from the total available volume where priorities are not explicitly linked to likelihood of achieving the priority portioned allocation among sectors hence users only know the allocated volume but not how likely the supply will be available prom extendes the demand priority based approach of these models by combining supply volume and likelihood derived from segmentation of fdc with demand volume and priority respectively raskin et al 1997 used demand to availability ratio to evaluate long range global freshwater status and vrsmarty et al 2000 matched the ratios to stress conditions based on a range of the demand to availability ratio our research extends the approaches in previous studies by estimating the available water based on fdc and labelling the ratio as demand to supply ratio dsr since the intrinsic variability of supply affects management decisions and water consumption priorities were extended to dsr rather than just demand to reflect likelihood of corresponding supply volume extracted from partitioning fdc we introduce a utility function to link ranges of dsr with user defined utility indices ui to assess the existing and potential alternative management scenarios ui facilitates direct stakeholder involvement in sectoral integration to explore consequences of alternative management scenarios the implementation of the fdc format in prom streamlines integration of best practices from economic and environmental water management in multi sector models and provides flexible stakeholder protection without over under allocation of water which is possible if average available water is used for all sectors qian 2015 the objective of this paper is to present the conceptual framework the assessment and optimization algorithm and a practical application of prom for multi sector water resources management the specific objectives are to 1 introduce the application of fdc dsr and ui to evaluate and optimize priority based water allocation based on a combinatorial optimization scheme and 2 demonstrate the application of prom for water allocation of the mara river basin mrb in kenya tanzania we used the competing environmental flow requirement and consumptive water use in the mrb to demonstrate basic procedures to bridge the environmental and economic water management and provide a template for application in other watersheds 2 description of prom 2 1 prom conceptual framework the comparative illustration of prom and common multi sector water management models is illustrated in fig 1 while the average available resource is estimated from a flow hydrograph prom first transforms the hydrograph to a fdc fdc provides the likelihood of achieving a given flow in the river as percent exceedance hence the available water can be partitioned into blocks of volume and associated likelihoods the number of blocks can be linked to corresponding number and priority of demand sectors while multi sector models proportionally allocate the total available water based on demand priorities prom links the likelihood of each block of supply to the corresponding priority of the demand the general algorithm of prom is outlined in fig 2 the model framework has five modules that 1 define the management system layout flow data and demand attributes fig 2 box 1 2 estimate supply and corresponding demand volume fig 2 box 2 3 assess supply demand relationships and priorities fig 2 box 3 4 generate feasible management alternatives and identify optimal path to allocate resource fig 2 box 4 and 5 allocate available water for the optimal scenario fig 2 box 5 2 2 management system setup prom represents water management systems as a node link network where nodes represent distinct spatial locations of water use such as sub basins reservoirs and water control structures connected by flow of water fig 2 box 1 the model takes user input from node to to node to generate flow direction representing the node link system network for the water budget fig 2 box 1 blocks are defined by grouping demand sectors in the system into mutually exclusive demand groups based on their water allocation priority the available water at each node will also be partitioned into the number of demand blocks with volumes of higher reliability assigned to high priority blocks management layers represent a group of demand blocks across the system with the same set of demand sectors and priorities a management time step is the smallest duration used in the evaluation and decision process the current version of prom as presented here is optimized for a monthly time step 2 3 supply and demand analysis 2 3 1 supply analysis prom inputs daily time series of measured simulated flow fig 2 box 1 and generates monthly fdc fig 2 box 2 at the outlet of each node the fdc is a plot that shows the relative percentage of time that flow past a specific point is likely to equal or exceed a specified value of interest as 1 f d c q  q q n n n 1 100 where  q p q q q q 1 q n q q n q n 1 n n 1 100 p is the percent probability that a given flow q will be equaled or exceeded q is a set of all observed or simulated flow magnitudes n is the rank of q for a period of record from the largest to the smallest value and n is the number of flow events for the period of record or simulation fdcs can be sliced into blocks on the basis of flow rates corresponding to time exceeded yilmaz et al 2008 fig 1 the number of blocks depends on the complexity of the management types of water demand and requirement and stakeholder needs the net available volume for each node is determined by accounting the incoming and outgoing quantities and portioned among the demand blocks as 2 v i j k min q i  q i j    j y 0 y k 1 v i j y where v i j k is the available volume for node i time step j and block k  is percentage of the time flow q is equaled or exceeded over the duration of time step  j corresponding duration to the time unit of the flow y refers to the next higher priority block k 1 and and v i j 0 0 2 3 2 demand analysis water demand estimates rely on census data past and current water consumption and projected future water demand monthly demand volumes are often estimated for individual water demand sectors eg domestic commercial livestock irrigation and mining used in watershed scale management fig 2 box 1 the block demand volumes are computed as the sum of the demand volumes of all sectors in the same allocation priority accordingly prom is optimized to take total monthly water demand estimates for each block for a planning horizon demand volume d i j k for each node sub basin i month j and block k is provided in the demand input user interface is determined as 3 d i j k m 1 m d i j k m where d i j k is the combined demand volume of node i time step j and block k and d is demand volume of sector m belonging to each priority block k the total demand at a node and in the system are computed as the sum all demands at each node and through the system fig 2 box 2 2 4 resource assessment and evaluation a supply demand relationship is built by employing supply reliability and demand satisfaction as a function of water productivity regulatory policies and priorities fig 2 box 3 at a given node i time step j and demand group k the status of resource utilization is assessed by the demand to supply ratio dsr on the basis of magnitude and frequency that reflect supply reliability requirements for each demand as 4 d s r i j k d i j k v i j k 100 where d i j k 0 v i j k 0 a n d d s r 0 100 dsr i j k is the demand to supply ratio of demand volume d and available volume v at node i time step j and block k small dsr values may indicate little water demand to the available quantity suggesting lower stress on the resource as the dsr increases the likelihood of satisfying the demand decreases which indicates a more stressed system hence the water resource status of a basin can be grouped into stress categories based on dsr categorical partitions of dsr raskin et al 1997 vrsmarty et al 2000 can be represented by a mapping function to observe the management consequences if the system is low water stressed supply management would suffice to ensure efficiency whereas if the map reveals considerable high water stress combined basin wide supply and demand management may be needed to improve water use efficiency and sustainability prom employs a user defined scalar utility index function ui to assess performance and decision consequences to the state of the system measured by dsr the ui reflect relative priority economic benefits risk regulatory and policy implications or the expected condition of the resource given the dsr the ui maps unique non negative utility indices to corresponding dsr ranges as 5 u i i j k u i 1 d s r i j k  1 u i 2  1 d s r i j k  2 u i n d s r i j k  n 1 where ui is the utility function ui is user defined utility value  is the cutoff dsr value and n is the number of indices defined by the number of dsr intervals prom generates a color coded tabular status map of the spatial and temporal distribution of the ui the status map provides a quick performance overview of existing or alternative management paths the aggregate sum of ui at each node and layer represents the total benefit cost of the management scenario if u values are inversely related to priority larger sums will suggest higher stress on the system and ui increases when dsr jumps a class break 2 5 optimization the model synthesizes hydrological and water demand data to estimate resource availability to meet corresponding demand and formulates an optimization scheme based on demand to supply ratio and water use priorities fig 2 box 4 the block based approach in prom is suitable for piece wise formulation and implementation of the combinatorial optimization the prom optimization module utilizes the flexibility to adjust the cutoff magnitude duration of supply based on a group of demand sectors to maximize water allocation in a feasible space the feasible space is defined by physical and user defined constraints fig 3 physical constraints establish positive resource and non negative demand at every block and ensure that the total demand at a node does not exceed the respective total available resource as 6 c o n s t r a i n t s v i j k 0 a n d d i j k 0 v i j d i j a n d v i j d i j k d s r m i n d i j k v i j k d s r m a x where v i j k and d i j k are the volume and demand respectively determined at node i time step j and block k dsr min and dsr max are the minimum and maximum dsr allowed in the system within the feasible space prom scans for alternative combinations of dsr from user defined minimum to maximum fig 3 since there are infinite feasible dsr combinations in the feasible space prom uses an incremental dsr dsr and divides the feasible space into sub spaces defined by iso dsr lines dsr z each management block k can be assigned any point on the iso dsr lines depending on the demand and supply volume resulting in a set of possible combination of dsr the possible set of points on one or more iso dsr lines for all priorities produce management paths ranging from the first alternative path being all points on the dsr dsr min to the last path being defined by points on the dsr dsr max iso dsr line alternative management scenarios within the feasible space are generated by increasing the minimum dsr dsrmin with a predefined dsr as 7 dsr z k min dsr m i n z 1  dsr dsr m a x z 1 2 z where d s r is the feasible set of dsr generated at the interval z for block k and the total number of intervals z 1 i n t d s r m a x d s r m i n  d s r for k demand blocks and z unique dsr values at each node zk combinations of d s r ui values will be generated by convention low ui values are assigned to high priority blocks so that higher priority demands are supplied with the more probable flow rates since the last block d s r value is calculated from the residual volume only zk 1 set of assigned d s r values are needed for example a user defined dsr range of 1 10 and dsr 2 generates six z 6 unique dsr d s r of 1 3 5 7 9 and 10 d s r representing six iso dsr lines in the feasible space shown in fig 3 if there are three priority groups the number of combinations of dsr to be assigned will be 6 for the first and second priority groups resulting in 36 alternative management paths the third block dsr will be assigned based on the amount of water left after the first and second priorities were satisfied for each set of demand supply ratio in the feasible space d s r the corresponding supply volume is determined as 8 v i j k d i j k d s r i j k i f v i j v i j k m a x v m i n v i j k 1 k 1 v i j k i f v i j v i j k where v i j k is the volume corresponding node i time step j and block k d s r is the assigned dsr with in the feasible space v min i j is the minimum volume assigned for each block v i j is the available volume and v min i j is the and minimum possible volume prom runs water balance for the d v combination to ensure the values are in the feasible space if these values fail to satisfy the constraints the model generates adjusted dsr d s r from the assigned d s r value on the basis of the available supply and corresponding demand as 9 dsr i j k d s r i j k i f v i j v i j k m i n d s r m a x d i j k v i j k i f 0 v i j v i j k where dsr is the adjusted dsr d i j k is the volume corresponding node i time step j and block k v min i j is the minimum volume assigned for each block v i j k is the available volume and d min i j is the minimum possible demand the adjusted dsr dsr values are mapped to the utility function eqn 5 and the total utility index ui z is determined as 10 u i z i 1 i j 1 j k 1 k u i i j k where ui z is the total utility for scenario z and ui i j k are the utility indices at node i time step j and block k ui z measures the system wide performance and may result in multiple combinations of similar or close values for multiple scenarios in addition to the total utility that measures system wide performance alternative management scenarios were evaluated based on a reliability function that measures the efficiency of each layer based on reliability of supply at each block time step and node reliability at each node r is defined as the percent ratio of the allocated volume to the volume needed to match the demand based on the assigned dsr the system reliability r at each management layer is evaluated as the sum of reliability for each layer divided by the number of blocks in the layer 11 r z k 1 i j i 1 i j 1 j r i j k where r m i n 100 v i j k 100 v i j k v i j k is the possible allocated volume given available supply and v i j k is the volume based on assigned dsr at node i time step j and block k prom approaches the optimization as a sequence of two decision stages 1 maximize the total utility benefit over the entire system and 2 select the best possible combination of reliabilities for all layers in the order from the highest to the lowest allocation priority block for low ui values assigned to high priority blocks the optimization scheme seeks to minimize stress in the system ui while maximizing the distribution reliability r of the resource at each management layer hence the decision variables ui and r are used to seek for the optimal scenario while the state variable dsr determines the specific condition of the management system the optimal management scenario will be the path where ui z is minimum and r z k is maximum therefore the objective function will rank ui and negative of reliability r in the system function dsr z k and extract minimum dsr combination in the feasible space prom implements a combinatorial optimization scheme korte et al 2012 lenstra 1997 to minimize penalties maximize benefits expressed by the utility indices across management layer and in the system as 12 o b j f dsr z k m i n r a n k u i z r a n k r z k where objf dsr z k is the objective function searching for the minimum system wide utility ui and maximum reliability r z k in the order from the highest to the lowest priority 2 6 allocation once the optimal management path is identified the allocated volume of water is determined from the optimal dsr combinations by solving the water budget fig 2 box 5 13 v i j k d i j k dsr i j k where v i j k is the allocated volume for demand d based on dsr at node i time step j and block k flow rate and percent exceedance for the optimal volume are extracted from the fdc when exact dsr values are preferred and set by stakeholders for the system water allocation is determined by estimating the corresponding demand or supply volume of the selected management option in addition if ranges of dsr values are suggested by stakeholders for each layer a value that best meets the management needs of the system should be selected 3 application of prom in the mara river basin 3 1 introduction prom was applied in the mara river basin mrb to assess current conditions and allocate water resources among competing multi sector water demands the mara river flows from the highlands of kenya through the iconic massai mara national reserve mmnr and serengeti natinal park snp ecosystems to lake victoria in tanzania fig 4 water management challenges in the mrb have been linked to water shortage threatening livelihood of residents in the basin and sustainability of the mara serengeti ecosystem dessu et al 2014 gereta and wolanski 1998 mcclain et al 2014 norton griffiths 1996 recent water allocation studies in mrb were focused either on environmental preservation mcclain et al 2014 o brien et al 2018 or cover limited areas in the basin metobwa et al 2018 metobwa et al 2018 conducted water demand simulation in the mrb for two future demand management scenarios from a reference year of 2010 2045 using the weap model for the kenyan side of the mrb their results suggested that under demand management scenarios water demand in the basin may be reduced by about 30 from 4 9 to 3 5 billion cubic meters their analyses neither address the efficiency of current resource management practice nor present the detailed analysis of the available resource kenya and tanzania have crafted ecosystem centered regulatory policies as a guiding framework rather than a common structural intervention we have not encountered any comprehensive water resource assessment and allocation model developed and implemented to address the competing environmental needs and consumptive water use in the basin the existing policies on the management of national water resources by the tanzanian and kenyan governments prioritize the distribution of water resources among competing water demands on the basis of reliability of flow in three blocks reserve flow flow available more than 95 of the time normal flow available from 80 95 of the time and flood flow flow available less than 80 of the time rk water act 2002 urt wrm act 2008 detailed basin wide evaluation of the baseline minimum provisions is essential to ensure minimum environmental flow requirements and consumptive demands are optimally distributed we applied prom to assess the performance of the current baseline provisions and seek for optimal management options that may improve water use efficiency in the mrb 3 2 description of the mara river basin the mara river drains 13 750 km2 combined area of south western kenya and north western tanzania over a stretch of 395 km length before entering lake victoria fig 4 mrb has a bi modal rainfall distribution driven by the migration of the inter tropical convergence zone the first and longer rain period of the year occurs between march and june while the second and shorter rain period is between september and december annual rainfall decreases with altitude ranging from 1000 to 1750 mm in the upper reaches 900 1000 mm in the middle and 300 850 mm at the lower reaches of the river surface water availability in the basin varies from annual average flow rate of 8 1 m3 s and 8 5 m3 s at the upstream nyangores and amala rivers to less than 1 m3 s eastern ephemeral rivers talek and sand rivers to 24 m3 s at the mara mine station of the downstream mara river the mrb was divided into twelve sub basins nodes on the basis of water use type land use topography climate administrative boundary and soil type fig 4 the headwaters sub basin 1 and 2 are characterized by protected forest and urban centers the commercial irrigation farms sub basin 3 and 4 extract water from mara river livestock husbandry is the major economic activity of the massai tribe lamprey and reid 2004 living in conservancies sub basins 4 to 7 the mmnr sub basin 8 and snp sub basin 9 are protected wild life reserves and major tourist destinations in kenya and tanzania respectively sub basin 10 represents densely populated rural settlement and small scale irrigation the downstream mrb is known for high grade gold mining at the north mara mine nmm sub basin 11 and buhemba mines sub basin 12 the last segment of the mara river is the flood plain wetland sub basin 12 3 3 data and model setup 3 3 1 flow volume and system layout the mrb water management system layout was represented by a node link diagram connecting the twelve sub basins following the stream flow direction of the mara river and its tributaries fig 5 a implementation of fig 2 box 1 the flow simulations were done using a calibrated and validated model developed by dessu and melesse 2012 using the soil and water assessment tool arnold et al 1998 fig 5b monthly fdc at each sub basin was generated from simulated daily flow at the outlet of each unit fig 5b and c the total available monthly volume at each sub basin fdc is divided among the three blocks as reserve q95 normal q80 to q95 and flood q80 fig 5c net available resource volume was determined for each node and block from the monthly fdcs and the minimum flow requirement fig 6 a d using eqn 2 a minimum flow volume of 0 0001mcm was set for any instant that the available volume in a block is too small or zero to ensure a realistic dsr value 3 3 2 demand volume there are six consumptive water demand sectors in the mara river basin human wildlife livestock tourism irrigation and mining christensen et al 2007 these demand sectors were grouped into three demand blocks environmental domestic and agro industry to correspond with the three blocks of resource availability reserve normal and flood the water demand for the year 2009 was estimated by dessu et al 2014 based on demographic data from census conducted in 2009 for kenya and 2002 for tanzania tnbs mara 2006 wildlife population data from aerial wildlife count conducted in june 2010 by kenya wildlife services kiambi et al 2012 ogutu et al 2011 livestock population data from census reports tourist and visitors survey data rknbs es 2009 irrigation data from agricultural census knbs ihbs 2007 tnsca mara 2012 and mining data from nmm abg 2011 respectively the demand estimated for the year 2009 was used as a baseline to project total and block wise water demand in 2015 fig 6e h human demand is comprised of basic human demand and enhanced human demand basic human need is the legal minimum amount of water consumption by an individual 25 l per day per capita to which water supply can be curtailed during scarcity for drinking and hygiene purposes as required by the water act of kenya and tanzania dessu et al 2014 rk water act 2002 urt nwp 2002 enhanced human demand represents additional water consumption of an individual above the basic human demand given access and availability of water dessu et al 2014 wildlife water demand was estimated as the sum of the product of each wildlife population and their respective average water consumption per animal species environmental demand is the sum of wildlife and basic human water demand this is a simplified methodology and may not satisfy all requirements of wetlands and aquatic species occurring in the mrb for which a near natural flow regime should be aimed for poff et al 2010 monthly human water demand was distributed based on the number of days in each month monthly wildlife water demand was estimated based on the count of resident and migratory wildlife population based on their spatial and temporal migration pattern kiambi et al 2012 ogutu et al 2011 3 3 3 demand and supply assessment the 2015 dsr status of the mrb was mapped to utility indices to represent the relative stress on the water resource from the consumptive demands depending on the range of dsr at each demand block raskin et al 1997 classified a basin as low water stressed when the demand is less than 10 of the available water at the source and highly water stressed when the demand exceeds 40 of the supply the set of utility indices 0 1 2 and 3 are assigned to represent the stress on the water resource as low dsr 10 medium 10 dsr 20 medium high 20 dsr 40 and high dsr 40 respectively raskin et al 1997 vrsmarty et al 2000 the implementation of these values in the utility function described in eqn 5 is shown in eqn 14 14 u i i j k 0 d s r i j k 10 1 10 d s r i j k 20 2 20 d s r i j k 40 3 d s r i j k 40 where ui is the utility index corresponding to the dsr at node i time step j and block k the dsr and ui under the minimum flow requirement were mapped from the available resource for each block 3 3 4 optimization and allocation the optimization scheme checks the system performance by searching for the minimum of the sum of the utility indices for the three layers of management while maximizing the reliability of the allocation at each layer the optimization scheme runs iterations between the minimum and maximum dsr and the lower and upper dsr values used as the starting dsr for the second optimization scheme a 2 or less difference between the ui and reliability of successive iterations were used as convergence criteria the optimal ui values were converted to corresponding dsr values on the basis of minimum requirement available resource and demand fig 2 box 4 the allocated flow volume was estimated dividing dsr by demand when the demand was below the minimum required available resource the minimum provision was maintained as shown in the optimal dsr fig 2 box 5 3 4 results and discussions monthly utility indices were determined at each sub basin of mrb based on block wise dsr table 1 a to d the 2015 utility indices table 1e for the total available based on minimum requirements showed higher water stress in the dry season except for headwaters 1 and 2 and the flood plain 12 the irrigation farms 3 4 mara serengeti wild life reserves 8 9 and the wildlife dispersal areas 5 6 and 7 were exposed to higher water stress compared to the headwaters and downstream sub basins the non optimized baseline reserve and normal volumes table 1f and g were under high stress compared to the flood volume table 1h when the water resource status was compared by block the reserve volume in the basin was highly stressed more than 50 of the time in seven sub basins and the normal volume suggested that sub basins 3 to 7 are under high stress for more than 70 of the time along with a moderate stress at the headwaters based on the block wise resource evaluation eastern sub basins 6 7 experience year round high water stress associated to their low rainfall and ephemeral streams in the dry season the relative abundance of low stress in the baseline agro industry ui status map table 1h while the higher priority demands are under high stress may suggest the need to seek for potential alternative management scenarios to move water from the agro industry in order to reduce shortage in the environment and domestic layers the feasible space for optimization was defined by dsrmin 1 dsrmax 60 and dsr 0 1 table 2 implementation of eqn 7 and fig 3 the resulting optimal combination of total ui and dsr were 309 and 9 9 the final optimal reliability of supply for the environmental domestic and agro industry were 82 1 73 5 and 77 respectively table 2 since the basin wide demand and supply does not change the optimal allocation only affects the block wise distribution of water without changing the status map for the total demand in the basin the optimization reduced the number of high water stress blocks from 79 table 1f to 19 table 3 d for the reserve flow environmental demand and from 67 table 1g to 30 table 3e for the normal flow domestic demand without affecting the status of flood flow agro industry group table 1h table 3f under the optimal combination the status of water resource utilization in the system has been reduced considerably for the middle and downstream sub basins the objective function in prom has two decision variable ui and reliability r ui refers to the status of supply given the demand based on ranges of dsr the allocated optimal volume was determined based on the optimal dsr and ui table 2 some of the blocks with a very high stress have demands higher than the net available resource dsr 99 where only the amount available was allocated to optimally satisfy the demand in each layer on the basis of reliability during the dry months of january and february flow to sub basin 3 is possible only after the demand in 1 and 2 are satisfied accordingly the optimal combination of ui and r suggested that keeping the january environmental demand for sub basin 3 at low stress reduce basin wide performance forcing the downstream sub basins to higher water stress level sub basin 3 has an optimal dsr of 11 table 2a for environmental demand corresponding to medium stress ui table 2d while the agro industry is met under low stress conditions table 2f this does not imply that agro industry demands were satisfied before environmental demands of higher priority rather the environmental and domestic demand were satisfied in a way that provides the best possible basin wide reliability without affecting the optimal ui for each layer given the water shortage the flow rate and percent time exceedance for the optimal allocated flow rates were extracted from the respective fdcs fig 7 the block wise monthly flow rates specify the amount of flow to be allocated to each demand block fig 7a c abstraction to the domestic and agro industry demands will be allowed once the flow rate in the river exceeds the amount specified to the environmental demand the flow rates of agro industry represent the total flow rate allocated for both environmental requirement and domestic uses for example the august flow for the massai mara national reserve in kenya sub basin 8 should exceed 16 m3 s to initiate domestic abstraction and 24 m3 s for agro industry abstraction respectively from january to march downstream sub basins heavily depend on flow from headwater sub basin 1 and 2 thereby requiring the optimal allocation to supply the basin with a new water yield as balance the order of priority as well as the system wide reliability the percent time exceedance distribution fig 7d to e indicates that the single minimum flow requirement for the mrb may not be an efficient approach to reduce the stress in the system sub basins with relatively low rainfall input sub basins 5 6 and 7 have lower percent exceedances suggesting a significant portion of the flow may need to be allocated to the environmental and domestic demands compared to allocated volume specific optimal set of flow rates by location and month provide better monitoring and management of resource while providing sufficient protection to the sensitive ecosystem of the mara serengeti ecosystem the minimum exceedances were shown to be effective only when sub basins have sufficient water yield as in the case of the head water sub basins 1 2 and the downstream sub basins 9 to 12 therefore these minimum requirements may need to reflect the individual attributes and importance of each sub basin to ensure environmental sustainability and economic growth 3 5 summary prom was applied to evaluate current water management and seek optimal allocation scenarios among competing multi sector water demand sectors in the mrb the initial evaluation of baseline minimum flow allocation results have shown that the mara serengeti ecosystem is under high water stress and the minimum reserve and normal flow provision may not be sufficient to meet the environmental and domestic demands moreover unchecked extractions to meet agro industry demands from the mara river upstream of the mara serengeti and downstream wetland may have ecological impact on the pristine ecosystem given the growing population and water demand in the urban settlements of the upper mrb intensive watershed management or storage infrastructure may help to balance augment seasonal water shortage in the basin prom results showed potential improvement in the management of the mrb model soutput are displayed in user friendly color coded tables to observe the overall system status the final optimal allocation results are readily available for monitoring and evaluation both in volume and flow rate along with percent time exceedance for each priority group and sub basin based on the final allocated flow and corresponding percent exceedances setting basin wide minimum guidelines in multi sector water resource systems where priority of allocation was tied to reliability of resource may not be an efficient approach prom provided a comprehensive water allocation platform for the mrb to engage stakeholders and ensure fair and efficient distribution of the resource among competing demands the current model can also be used to assess future scenarios given water demand projections 4 conclusion numerous water management models have been developed to facilitate efficient and sustainable distribution of water among competing demands these models were developed for environmental sustainability economic water management or combination of both economic models are likely to add environmental component that fit to their underlying economic framework and become multi sector models the limitation of such an approach is that more attention is given to one component while minimal mathematical representation is included in the other the structure of prom overcomes these limitations and allows concurrent integration of both environmental and economic water management based on flexibility of fdc and prioritizing water use sectors water resource assessment and allocation follows layers of priority enabling provision to the high priority groups while maximizing the overall system wide efficiency prom combines demand to supply ratio and user defined utility indices to assess water utilization and seek for efficient allocation using combinatorial optimization prom is stakeholder centered optimization procedure to match demand and available water at all levels model results are displayed in user friendly color coded outputs to observe the overall system status the initial resource assessmetn and final optimal allocation outputs are readily available for monitoring and evaluation both in volume and flow rate along with percent time exceedance for each priority group and sub basin the application of prom in the mrb has provided a road map to improve the current high water stress in the iconic mara serengeti ecosystem the model results suggest increasing the minimum environmental flow requirements to offset seasonal water shortage the application example can serve as a template for similar watersheds to facilitate participation and decision process in the planning and management of water resources finally prom will add a new perspective in fair and efficient multi sector management of supply and demand setup decision process and establishes evaluation and feedback mechanism acknowledgement the authors acknowledge the anonymous reviewers for their invaluable input to improve the content and presentation in the manuscript this material is partially supported by the united states agency for international development usaid through transboundary water for biodiversity and human health in the mara river basin under award no 623 a 00 05 00350 00 2005 2012 this is contribution number 894 from the southeast environmental research center in the institute of water environment at florida international university appendix a supplementary data the following are the supplementary data to this article prom interface dsr demand supply ratio prom dsr prom interface demand volume prom demand prom interface flow duration curves prom fdc prom interface optimum flow exceedance prom optexceedance prom interface optimum flow prom optflow prom interface optimum resource prom optresource prom interface optimal scenarios prom optscenario prom interface optimization prom optimization prom interface resource volume prom resource prom interface utility indices prom ui prom user interface prom userintrfce prom application example outputs prom interface data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 11 014 
26263,we present a new priority rated optimization model prom for multi sector water resource assessment allocation and management prom utilizes flow duration curves fdc demand to supply ratio dsr and utility indices ui to evaluate and optimize priority based multi sector water allocation dsr links demand volume and priority with corresponding supply volume and likelihood derived from segmentation of fdc the ui function assigns weights to ranges of dsr to assess the existing and potential alternative management scenarios supply reliability and ui values are used in a combinatorial optimization scheme to estimate allocated volume flow rate and percent exceedance prom is applied in the mara river basin of kenya tanzania and results showed potential improvement over the current management practice towards sustainability of the mara serengeti ecosystem prom bridges the gap between environmental and economic models while providing a user friendly platform for direct stakeholder involvement to explore alternative water allocation scenarios keywords demand supply ratio flow duration curve combinatorial optimization water resource management demand priority mara river water allocation prom software data availability software information name of software priority rated optimization model prom developer shimelis b dessu contact tel 305 401 5898 email sbehailu gmail com 11200 sw 8 st ahc5 364 florida international university miami fl 33172 usa availability www go fiu edu prom required hardware pc required software windows 7 or latest and text editor programming language matlab 2018a 1 introduction water management computer models have become an integral part of water resource management to protect the environment ensure public safety and maximize economic benefits through sustainable balance of available water and corresponding demand these models can be broadly classified as environmental economic or multi sector water management models environmental water management models seek to achieve sustainable ecological and ecosystem service outcomes acreman et al 2014 king and brown 2010 tharme 2003 flow duration curves fdc vogel and fennessey 1994 qian 2015 yilmaz et al 2008 have been widely used in environmental models to capture and preserve the natural hydrologic regime the fdc transforms a flow hydrograph into the percentage of time the flow would likely be available during the period of analysis fig 1 the objective of economic water management is to maximize economic benefits of water use based on average available water eg babel et al 2005 draper et al 2003 nishikawa 1998 noory et al 2011 reca et al 2001 blending environmental and economic water management objectives in multi sector management models has been challenging due to the anthropocentric nature of water management griffen 2006 and difficulty in monetizing environmental services multi sector water management models eg fredericks et al 1998 krogt 2008 perera et al 2005 yates et al 2005 zagona et al 2001 work around this limitation using a pre established set of demand priorities as a proxy to capture tangible and intangible benefits associated with economic and environmental services acreman and dunbar 2004 acreman et al 2014 mcclain et al 2014 and regulatory and policy constraints fredericks et al 1998 yates et al 2005 to identify optimal water allocation alternatives multi sector water allocation approaches depend on the average available resource from which allocations would come on the basis of demand priorities compromising the need to preserve the hydrologic regime for environmental objectives and providing an impression of equal likelihood of supply to all water use sectors considered in the management hence current multi sector models lack sufficient connection between demand priorities and the likelihood of corresponding supply by combining the flexibility of fdc to estimate volume and likelihood of supply and integrating priorities to demand to supply ratio dsr we present the development and application of a new priority rated optimization model prom for multi sector water resources management systems to bridge the gap in integrating environmental and economic management objectives fdc is widely used in flood forecasting and design of hydraulic structures vogel and fennessey 1994 and environmental water management mcclain et al 2014 vogel and fennessey 1995 environmental water management models employing fdc include probflo o brien et al 2018 desktop reserve model drm kashaigili et al 2007 ecological limits of hydrologic alteration eloha poff et al 2010 building block methodology bbm king and louw 1998 and downstream response to imposed flow transformation drift king et al 2003 2008 probflo o brien et al 2018 is a regional scale ecological risk evaluation tool that combines frequency duration and magnitude of flow and is applied in the mara river basin of kenya and tanzania and the senqu river basin in lesotho kashaigili et al 2007 applied drm based on exceedance probabilities of high and low flow events to derive ecological flow requirements in the ruaha national park tanzania eloha integrates existing hydrologic techniques and environmental flow methods eg bbm and drift to support comprehensive regional flow management king et al 2008 poff et al 2010 recent examples of fdc include characterization of environmental river flow requirements in the mara river of kenya and tanzania dessu et al 2014 mcclain et al 2014 and a comprehensive review of methods and results from long term studies in africa and south east asia as presented by king and brown 2010 despite the advantage of fdc to capture the variability of a natural system we have not encountered its implementation in any generic multi sector water management model hence the fdc is utilized in prom as the basis to determine the quantity and likelihood of water availability fig 1 multi sector management models link priorities with demand sectors and allocate water based on the proportional partitioning of the total available water among competing demands generic multi sector water management models include the water evaluation and planning weap model yates et al 2005 modular river basin network simulation modsim model fredericks et al 1998 resource allocation model realm perera et al 2005 riverware magee et al 2001 zagona et al 2001 river basin simulation model ribasim krogt 2008 and mike hydro basin dhi 2018 the objective functions of these models rely on the benefit risk and socio economic factors expressed with the priority of each demand sector weap implements a node link network of water demand and supply to redistribute resources among demand sectors based on a user specified priority of demands at each node modsim utilizes a basin simulation model employing an efficient minimum cost network flow optimization algorithm over a river basin to redistribute water on the basis of priorities such as water rights ownership contracts and interstate compacts fredericks et al 1998 mike hydro basin and riverware follow the order of priority providing optimal allocation for the higher priority using linear optimization of deviations from objective functions dhi 2018 magee et al 2001 the demand priorities in these models reflect the order of satisfying the demand from the total available volume where priorities are not explicitly linked to likelihood of achieving the priority portioned allocation among sectors hence users only know the allocated volume but not how likely the supply will be available prom extendes the demand priority based approach of these models by combining supply volume and likelihood derived from segmentation of fdc with demand volume and priority respectively raskin et al 1997 used demand to availability ratio to evaluate long range global freshwater status and vrsmarty et al 2000 matched the ratios to stress conditions based on a range of the demand to availability ratio our research extends the approaches in previous studies by estimating the available water based on fdc and labelling the ratio as demand to supply ratio dsr since the intrinsic variability of supply affects management decisions and water consumption priorities were extended to dsr rather than just demand to reflect likelihood of corresponding supply volume extracted from partitioning fdc we introduce a utility function to link ranges of dsr with user defined utility indices ui to assess the existing and potential alternative management scenarios ui facilitates direct stakeholder involvement in sectoral integration to explore consequences of alternative management scenarios the implementation of the fdc format in prom streamlines integration of best practices from economic and environmental water management in multi sector models and provides flexible stakeholder protection without over under allocation of water which is possible if average available water is used for all sectors qian 2015 the objective of this paper is to present the conceptual framework the assessment and optimization algorithm and a practical application of prom for multi sector water resources management the specific objectives are to 1 introduce the application of fdc dsr and ui to evaluate and optimize priority based water allocation based on a combinatorial optimization scheme and 2 demonstrate the application of prom for water allocation of the mara river basin mrb in kenya tanzania we used the competing environmental flow requirement and consumptive water use in the mrb to demonstrate basic procedures to bridge the environmental and economic water management and provide a template for application in other watersheds 2 description of prom 2 1 prom conceptual framework the comparative illustration of prom and common multi sector water management models is illustrated in fig 1 while the average available resource is estimated from a flow hydrograph prom first transforms the hydrograph to a fdc fdc provides the likelihood of achieving a given flow in the river as percent exceedance hence the available water can be partitioned into blocks of volume and associated likelihoods the number of blocks can be linked to corresponding number and priority of demand sectors while multi sector models proportionally allocate the total available water based on demand priorities prom links the likelihood of each block of supply to the corresponding priority of the demand the general algorithm of prom is outlined in fig 2 the model framework has five modules that 1 define the management system layout flow data and demand attributes fig 2 box 1 2 estimate supply and corresponding demand volume fig 2 box 2 3 assess supply demand relationships and priorities fig 2 box 3 4 generate feasible management alternatives and identify optimal path to allocate resource fig 2 box 4 and 5 allocate available water for the optimal scenario fig 2 box 5 2 2 management system setup prom represents water management systems as a node link network where nodes represent distinct spatial locations of water use such as sub basins reservoirs and water control structures connected by flow of water fig 2 box 1 the model takes user input from node to to node to generate flow direction representing the node link system network for the water budget fig 2 box 1 blocks are defined by grouping demand sectors in the system into mutually exclusive demand groups based on their water allocation priority the available water at each node will also be partitioned into the number of demand blocks with volumes of higher reliability assigned to high priority blocks management layers represent a group of demand blocks across the system with the same set of demand sectors and priorities a management time step is the smallest duration used in the evaluation and decision process the current version of prom as presented here is optimized for a monthly time step 2 3 supply and demand analysis 2 3 1 supply analysis prom inputs daily time series of measured simulated flow fig 2 box 1 and generates monthly fdc fig 2 box 2 at the outlet of each node the fdc is a plot that shows the relative percentage of time that flow past a specific point is likely to equal or exceed a specified value of interest as 1 f d c q  q q n n n 1 100 where  q p q q q q 1 q n q q n q n 1 n n 1 100 p is the percent probability that a given flow q will be equaled or exceeded q is a set of all observed or simulated flow magnitudes n is the rank of q for a period of record from the largest to the smallest value and n is the number of flow events for the period of record or simulation fdcs can be sliced into blocks on the basis of flow rates corresponding to time exceeded yilmaz et al 2008 fig 1 the number of blocks depends on the complexity of the management types of water demand and requirement and stakeholder needs the net available volume for each node is determined by accounting the incoming and outgoing quantities and portioned among the demand blocks as 2 v i j k min q i  q i j    j y 0 y k 1 v i j y where v i j k is the available volume for node i time step j and block k  is percentage of the time flow q is equaled or exceeded over the duration of time step  j corresponding duration to the time unit of the flow y refers to the next higher priority block k 1 and and v i j 0 0 2 3 2 demand analysis water demand estimates rely on census data past and current water consumption and projected future water demand monthly demand volumes are often estimated for individual water demand sectors eg domestic commercial livestock irrigation and mining used in watershed scale management fig 2 box 1 the block demand volumes are computed as the sum of the demand volumes of all sectors in the same allocation priority accordingly prom is optimized to take total monthly water demand estimates for each block for a planning horizon demand volume d i j k for each node sub basin i month j and block k is provided in the demand input user interface is determined as 3 d i j k m 1 m d i j k m where d i j k is the combined demand volume of node i time step j and block k and d is demand volume of sector m belonging to each priority block k the total demand at a node and in the system are computed as the sum all demands at each node and through the system fig 2 box 2 2 4 resource assessment and evaluation a supply demand relationship is built by employing supply reliability and demand satisfaction as a function of water productivity regulatory policies and priorities fig 2 box 3 at a given node i time step j and demand group k the status of resource utilization is assessed by the demand to supply ratio dsr on the basis of magnitude and frequency that reflect supply reliability requirements for each demand as 4 d s r i j k d i j k v i j k 100 where d i j k 0 v i j k 0 a n d d s r 0 100 dsr i j k is the demand to supply ratio of demand volume d and available volume v at node i time step j and block k small dsr values may indicate little water demand to the available quantity suggesting lower stress on the resource as the dsr increases the likelihood of satisfying the demand decreases which indicates a more stressed system hence the water resource status of a basin can be grouped into stress categories based on dsr categorical partitions of dsr raskin et al 1997 vrsmarty et al 2000 can be represented by a mapping function to observe the management consequences if the system is low water stressed supply management would suffice to ensure efficiency whereas if the map reveals considerable high water stress combined basin wide supply and demand management may be needed to improve water use efficiency and sustainability prom employs a user defined scalar utility index function ui to assess performance and decision consequences to the state of the system measured by dsr the ui reflect relative priority economic benefits risk regulatory and policy implications or the expected condition of the resource given the dsr the ui maps unique non negative utility indices to corresponding dsr ranges as 5 u i i j k u i 1 d s r i j k  1 u i 2  1 d s r i j k  2 u i n d s r i j k  n 1 where ui is the utility function ui is user defined utility value  is the cutoff dsr value and n is the number of indices defined by the number of dsr intervals prom generates a color coded tabular status map of the spatial and temporal distribution of the ui the status map provides a quick performance overview of existing or alternative management paths the aggregate sum of ui at each node and layer represents the total benefit cost of the management scenario if u values are inversely related to priority larger sums will suggest higher stress on the system and ui increases when dsr jumps a class break 2 5 optimization the model synthesizes hydrological and water demand data to estimate resource availability to meet corresponding demand and formulates an optimization scheme based on demand to supply ratio and water use priorities fig 2 box 4 the block based approach in prom is suitable for piece wise formulation and implementation of the combinatorial optimization the prom optimization module utilizes the flexibility to adjust the cutoff magnitude duration of supply based on a group of demand sectors to maximize water allocation in a feasible space the feasible space is defined by physical and user defined constraints fig 3 physical constraints establish positive resource and non negative demand at every block and ensure that the total demand at a node does not exceed the respective total available resource as 6 c o n s t r a i n t s v i j k 0 a n d d i j k 0 v i j d i j a n d v i j d i j k d s r m i n d i j k v i j k d s r m a x where v i j k and d i j k are the volume and demand respectively determined at node i time step j and block k dsr min and dsr max are the minimum and maximum dsr allowed in the system within the feasible space prom scans for alternative combinations of dsr from user defined minimum to maximum fig 3 since there are infinite feasible dsr combinations in the feasible space prom uses an incremental dsr dsr and divides the feasible space into sub spaces defined by iso dsr lines dsr z each management block k can be assigned any point on the iso dsr lines depending on the demand and supply volume resulting in a set of possible combination of dsr the possible set of points on one or more iso dsr lines for all priorities produce management paths ranging from the first alternative path being all points on the dsr dsr min to the last path being defined by points on the dsr dsr max iso dsr line alternative management scenarios within the feasible space are generated by increasing the minimum dsr dsrmin with a predefined dsr as 7 dsr z k min dsr m i n z 1  dsr dsr m a x z 1 2 z where d s r is the feasible set of dsr generated at the interval z for block k and the total number of intervals z 1 i n t d s r m a x d s r m i n  d s r for k demand blocks and z unique dsr values at each node zk combinations of d s r ui values will be generated by convention low ui values are assigned to high priority blocks so that higher priority demands are supplied with the more probable flow rates since the last block d s r value is calculated from the residual volume only zk 1 set of assigned d s r values are needed for example a user defined dsr range of 1 10 and dsr 2 generates six z 6 unique dsr d s r of 1 3 5 7 9 and 10 d s r representing six iso dsr lines in the feasible space shown in fig 3 if there are three priority groups the number of combinations of dsr to be assigned will be 6 for the first and second priority groups resulting in 36 alternative management paths the third block dsr will be assigned based on the amount of water left after the first and second priorities were satisfied for each set of demand supply ratio in the feasible space d s r the corresponding supply volume is determined as 8 v i j k d i j k d s r i j k i f v i j v i j k m a x v m i n v i j k 1 k 1 v i j k i f v i j v i j k where v i j k is the volume corresponding node i time step j and block k d s r is the assigned dsr with in the feasible space v min i j is the minimum volume assigned for each block v i j is the available volume and v min i j is the and minimum possible volume prom runs water balance for the d v combination to ensure the values are in the feasible space if these values fail to satisfy the constraints the model generates adjusted dsr d s r from the assigned d s r value on the basis of the available supply and corresponding demand as 9 dsr i j k d s r i j k i f v i j v i j k m i n d s r m a x d i j k v i j k i f 0 v i j v i j k where dsr is the adjusted dsr d i j k is the volume corresponding node i time step j and block k v min i j is the minimum volume assigned for each block v i j k is the available volume and d min i j is the minimum possible demand the adjusted dsr dsr values are mapped to the utility function eqn 5 and the total utility index ui z is determined as 10 u i z i 1 i j 1 j k 1 k u i i j k where ui z is the total utility for scenario z and ui i j k are the utility indices at node i time step j and block k ui z measures the system wide performance and may result in multiple combinations of similar or close values for multiple scenarios in addition to the total utility that measures system wide performance alternative management scenarios were evaluated based on a reliability function that measures the efficiency of each layer based on reliability of supply at each block time step and node reliability at each node r is defined as the percent ratio of the allocated volume to the volume needed to match the demand based on the assigned dsr the system reliability r at each management layer is evaluated as the sum of reliability for each layer divided by the number of blocks in the layer 11 r z k 1 i j i 1 i j 1 j r i j k where r m i n 100 v i j k 100 v i j k v i j k is the possible allocated volume given available supply and v i j k is the volume based on assigned dsr at node i time step j and block k prom approaches the optimization as a sequence of two decision stages 1 maximize the total utility benefit over the entire system and 2 select the best possible combination of reliabilities for all layers in the order from the highest to the lowest allocation priority block for low ui values assigned to high priority blocks the optimization scheme seeks to minimize stress in the system ui while maximizing the distribution reliability r of the resource at each management layer hence the decision variables ui and r are used to seek for the optimal scenario while the state variable dsr determines the specific condition of the management system the optimal management scenario will be the path where ui z is minimum and r z k is maximum therefore the objective function will rank ui and negative of reliability r in the system function dsr z k and extract minimum dsr combination in the feasible space prom implements a combinatorial optimization scheme korte et al 2012 lenstra 1997 to minimize penalties maximize benefits expressed by the utility indices across management layer and in the system as 12 o b j f dsr z k m i n r a n k u i z r a n k r z k where objf dsr z k is the objective function searching for the minimum system wide utility ui and maximum reliability r z k in the order from the highest to the lowest priority 2 6 allocation once the optimal management path is identified the allocated volume of water is determined from the optimal dsr combinations by solving the water budget fig 2 box 5 13 v i j k d i j k dsr i j k where v i j k is the allocated volume for demand d based on dsr at node i time step j and block k flow rate and percent exceedance for the optimal volume are extracted from the fdc when exact dsr values are preferred and set by stakeholders for the system water allocation is determined by estimating the corresponding demand or supply volume of the selected management option in addition if ranges of dsr values are suggested by stakeholders for each layer a value that best meets the management needs of the system should be selected 3 application of prom in the mara river basin 3 1 introduction prom was applied in the mara river basin mrb to assess current conditions and allocate water resources among competing multi sector water demands the mara river flows from the highlands of kenya through the iconic massai mara national reserve mmnr and serengeti natinal park snp ecosystems to lake victoria in tanzania fig 4 water management challenges in the mrb have been linked to water shortage threatening livelihood of residents in the basin and sustainability of the mara serengeti ecosystem dessu et al 2014 gereta and wolanski 1998 mcclain et al 2014 norton griffiths 1996 recent water allocation studies in mrb were focused either on environmental preservation mcclain et al 2014 o brien et al 2018 or cover limited areas in the basin metobwa et al 2018 metobwa et al 2018 conducted water demand simulation in the mrb for two future demand management scenarios from a reference year of 2010 2045 using the weap model for the kenyan side of the mrb their results suggested that under demand management scenarios water demand in the basin may be reduced by about 30 from 4 9 to 3 5 billion cubic meters their analyses neither address the efficiency of current resource management practice nor present the detailed analysis of the available resource kenya and tanzania have crafted ecosystem centered regulatory policies as a guiding framework rather than a common structural intervention we have not encountered any comprehensive water resource assessment and allocation model developed and implemented to address the competing environmental needs and consumptive water use in the basin the existing policies on the management of national water resources by the tanzanian and kenyan governments prioritize the distribution of water resources among competing water demands on the basis of reliability of flow in three blocks reserve flow flow available more than 95 of the time normal flow available from 80 95 of the time and flood flow flow available less than 80 of the time rk water act 2002 urt wrm act 2008 detailed basin wide evaluation of the baseline minimum provisions is essential to ensure minimum environmental flow requirements and consumptive demands are optimally distributed we applied prom to assess the performance of the current baseline provisions and seek for optimal management options that may improve water use efficiency in the mrb 3 2 description of the mara river basin the mara river drains 13 750 km2 combined area of south western kenya and north western tanzania over a stretch of 395 km length before entering lake victoria fig 4 mrb has a bi modal rainfall distribution driven by the migration of the inter tropical convergence zone the first and longer rain period of the year occurs between march and june while the second and shorter rain period is between september and december annual rainfall decreases with altitude ranging from 1000 to 1750 mm in the upper reaches 900 1000 mm in the middle and 300 850 mm at the lower reaches of the river surface water availability in the basin varies from annual average flow rate of 8 1 m3 s and 8 5 m3 s at the upstream nyangores and amala rivers to less than 1 m3 s eastern ephemeral rivers talek and sand rivers to 24 m3 s at the mara mine station of the downstream mara river the mrb was divided into twelve sub basins nodes on the basis of water use type land use topography climate administrative boundary and soil type fig 4 the headwaters sub basin 1 and 2 are characterized by protected forest and urban centers the commercial irrigation farms sub basin 3 and 4 extract water from mara river livestock husbandry is the major economic activity of the massai tribe lamprey and reid 2004 living in conservancies sub basins 4 to 7 the mmnr sub basin 8 and snp sub basin 9 are protected wild life reserves and major tourist destinations in kenya and tanzania respectively sub basin 10 represents densely populated rural settlement and small scale irrigation the downstream mrb is known for high grade gold mining at the north mara mine nmm sub basin 11 and buhemba mines sub basin 12 the last segment of the mara river is the flood plain wetland sub basin 12 3 3 data and model setup 3 3 1 flow volume and system layout the mrb water management system layout was represented by a node link diagram connecting the twelve sub basins following the stream flow direction of the mara river and its tributaries fig 5 a implementation of fig 2 box 1 the flow simulations were done using a calibrated and validated model developed by dessu and melesse 2012 using the soil and water assessment tool arnold et al 1998 fig 5b monthly fdc at each sub basin was generated from simulated daily flow at the outlet of each unit fig 5b and c the total available monthly volume at each sub basin fdc is divided among the three blocks as reserve q95 normal q80 to q95 and flood q80 fig 5c net available resource volume was determined for each node and block from the monthly fdcs and the minimum flow requirement fig 6 a d using eqn 2 a minimum flow volume of 0 0001mcm was set for any instant that the available volume in a block is too small or zero to ensure a realistic dsr value 3 3 2 demand volume there are six consumptive water demand sectors in the mara river basin human wildlife livestock tourism irrigation and mining christensen et al 2007 these demand sectors were grouped into three demand blocks environmental domestic and agro industry to correspond with the three blocks of resource availability reserve normal and flood the water demand for the year 2009 was estimated by dessu et al 2014 based on demographic data from census conducted in 2009 for kenya and 2002 for tanzania tnbs mara 2006 wildlife population data from aerial wildlife count conducted in june 2010 by kenya wildlife services kiambi et al 2012 ogutu et al 2011 livestock population data from census reports tourist and visitors survey data rknbs es 2009 irrigation data from agricultural census knbs ihbs 2007 tnsca mara 2012 and mining data from nmm abg 2011 respectively the demand estimated for the year 2009 was used as a baseline to project total and block wise water demand in 2015 fig 6e h human demand is comprised of basic human demand and enhanced human demand basic human need is the legal minimum amount of water consumption by an individual 25 l per day per capita to which water supply can be curtailed during scarcity for drinking and hygiene purposes as required by the water act of kenya and tanzania dessu et al 2014 rk water act 2002 urt nwp 2002 enhanced human demand represents additional water consumption of an individual above the basic human demand given access and availability of water dessu et al 2014 wildlife water demand was estimated as the sum of the product of each wildlife population and their respective average water consumption per animal species environmental demand is the sum of wildlife and basic human water demand this is a simplified methodology and may not satisfy all requirements of wetlands and aquatic species occurring in the mrb for which a near natural flow regime should be aimed for poff et al 2010 monthly human water demand was distributed based on the number of days in each month monthly wildlife water demand was estimated based on the count of resident and migratory wildlife population based on their spatial and temporal migration pattern kiambi et al 2012 ogutu et al 2011 3 3 3 demand and supply assessment the 2015 dsr status of the mrb was mapped to utility indices to represent the relative stress on the water resource from the consumptive demands depending on the range of dsr at each demand block raskin et al 1997 classified a basin as low water stressed when the demand is less than 10 of the available water at the source and highly water stressed when the demand exceeds 40 of the supply the set of utility indices 0 1 2 and 3 are assigned to represent the stress on the water resource as low dsr 10 medium 10 dsr 20 medium high 20 dsr 40 and high dsr 40 respectively raskin et al 1997 vrsmarty et al 2000 the implementation of these values in the utility function described in eqn 5 is shown in eqn 14 14 u i i j k 0 d s r i j k 10 1 10 d s r i j k 20 2 20 d s r i j k 40 3 d s r i j k 40 where ui is the utility index corresponding to the dsr at node i time step j and block k the dsr and ui under the minimum flow requirement were mapped from the available resource for each block 3 3 4 optimization and allocation the optimization scheme checks the system performance by searching for the minimum of the sum of the utility indices for the three layers of management while maximizing the reliability of the allocation at each layer the optimization scheme runs iterations between the minimum and maximum dsr and the lower and upper dsr values used as the starting dsr for the second optimization scheme a 2 or less difference between the ui and reliability of successive iterations were used as convergence criteria the optimal ui values were converted to corresponding dsr values on the basis of minimum requirement available resource and demand fig 2 box 4 the allocated flow volume was estimated dividing dsr by demand when the demand was below the minimum required available resource the minimum provision was maintained as shown in the optimal dsr fig 2 box 5 3 4 results and discussions monthly utility indices were determined at each sub basin of mrb based on block wise dsr table 1 a to d the 2015 utility indices table 1e for the total available based on minimum requirements showed higher water stress in the dry season except for headwaters 1 and 2 and the flood plain 12 the irrigation farms 3 4 mara serengeti wild life reserves 8 9 and the wildlife dispersal areas 5 6 and 7 were exposed to higher water stress compared to the headwaters and downstream sub basins the non optimized baseline reserve and normal volumes table 1f and g were under high stress compared to the flood volume table 1h when the water resource status was compared by block the reserve volume in the basin was highly stressed more than 50 of the time in seven sub basins and the normal volume suggested that sub basins 3 to 7 are under high stress for more than 70 of the time along with a moderate stress at the headwaters based on the block wise resource evaluation eastern sub basins 6 7 experience year round high water stress associated to their low rainfall and ephemeral streams in the dry season the relative abundance of low stress in the baseline agro industry ui status map table 1h while the higher priority demands are under high stress may suggest the need to seek for potential alternative management scenarios to move water from the agro industry in order to reduce shortage in the environment and domestic layers the feasible space for optimization was defined by dsrmin 1 dsrmax 60 and dsr 0 1 table 2 implementation of eqn 7 and fig 3 the resulting optimal combination of total ui and dsr were 309 and 9 9 the final optimal reliability of supply for the environmental domestic and agro industry were 82 1 73 5 and 77 respectively table 2 since the basin wide demand and supply does not change the optimal allocation only affects the block wise distribution of water without changing the status map for the total demand in the basin the optimization reduced the number of high water stress blocks from 79 table 1f to 19 table 3 d for the reserve flow environmental demand and from 67 table 1g to 30 table 3e for the normal flow domestic demand without affecting the status of flood flow agro industry group table 1h table 3f under the optimal combination the status of water resource utilization in the system has been reduced considerably for the middle and downstream sub basins the objective function in prom has two decision variable ui and reliability r ui refers to the status of supply given the demand based on ranges of dsr the allocated optimal volume was determined based on the optimal dsr and ui table 2 some of the blocks with a very high stress have demands higher than the net available resource dsr 99 where only the amount available was allocated to optimally satisfy the demand in each layer on the basis of reliability during the dry months of january and february flow to sub basin 3 is possible only after the demand in 1 and 2 are satisfied accordingly the optimal combination of ui and r suggested that keeping the january environmental demand for sub basin 3 at low stress reduce basin wide performance forcing the downstream sub basins to higher water stress level sub basin 3 has an optimal dsr of 11 table 2a for environmental demand corresponding to medium stress ui table 2d while the agro industry is met under low stress conditions table 2f this does not imply that agro industry demands were satisfied before environmental demands of higher priority rather the environmental and domestic demand were satisfied in a way that provides the best possible basin wide reliability without affecting the optimal ui for each layer given the water shortage the flow rate and percent time exceedance for the optimal allocated flow rates were extracted from the respective fdcs fig 7 the block wise monthly flow rates specify the amount of flow to be allocated to each demand block fig 7a c abstraction to the domestic and agro industry demands will be allowed once the flow rate in the river exceeds the amount specified to the environmental demand the flow rates of agro industry represent the total flow rate allocated for both environmental requirement and domestic uses for example the august flow for the massai mara national reserve in kenya sub basin 8 should exceed 16 m3 s to initiate domestic abstraction and 24 m3 s for agro industry abstraction respectively from january to march downstream sub basins heavily depend on flow from headwater sub basin 1 and 2 thereby requiring the optimal allocation to supply the basin with a new water yield as balance the order of priority as well as the system wide reliability the percent time exceedance distribution fig 7d to e indicates that the single minimum flow requirement for the mrb may not be an efficient approach to reduce the stress in the system sub basins with relatively low rainfall input sub basins 5 6 and 7 have lower percent exceedances suggesting a significant portion of the flow may need to be allocated to the environmental and domestic demands compared to allocated volume specific optimal set of flow rates by location and month provide better monitoring and management of resource while providing sufficient protection to the sensitive ecosystem of the mara serengeti ecosystem the minimum exceedances were shown to be effective only when sub basins have sufficient water yield as in the case of the head water sub basins 1 2 and the downstream sub basins 9 to 12 therefore these minimum requirements may need to reflect the individual attributes and importance of each sub basin to ensure environmental sustainability and economic growth 3 5 summary prom was applied to evaluate current water management and seek optimal allocation scenarios among competing multi sector water demand sectors in the mrb the initial evaluation of baseline minimum flow allocation results have shown that the mara serengeti ecosystem is under high water stress and the minimum reserve and normal flow provision may not be sufficient to meet the environmental and domestic demands moreover unchecked extractions to meet agro industry demands from the mara river upstream of the mara serengeti and downstream wetland may have ecological impact on the pristine ecosystem given the growing population and water demand in the urban settlements of the upper mrb intensive watershed management or storage infrastructure may help to balance augment seasonal water shortage in the basin prom results showed potential improvement in the management of the mrb model soutput are displayed in user friendly color coded tables to observe the overall system status the final optimal allocation results are readily available for monitoring and evaluation both in volume and flow rate along with percent time exceedance for each priority group and sub basin based on the final allocated flow and corresponding percent exceedances setting basin wide minimum guidelines in multi sector water resource systems where priority of allocation was tied to reliability of resource may not be an efficient approach prom provided a comprehensive water allocation platform for the mrb to engage stakeholders and ensure fair and efficient distribution of the resource among competing demands the current model can also be used to assess future scenarios given water demand projections 4 conclusion numerous water management models have been developed to facilitate efficient and sustainable distribution of water among competing demands these models were developed for environmental sustainability economic water management or combination of both economic models are likely to add environmental component that fit to their underlying economic framework and become multi sector models the limitation of such an approach is that more attention is given to one component while minimal mathematical representation is included in the other the structure of prom overcomes these limitations and allows concurrent integration of both environmental and economic water management based on flexibility of fdc and prioritizing water use sectors water resource assessment and allocation follows layers of priority enabling provision to the high priority groups while maximizing the overall system wide efficiency prom combines demand to supply ratio and user defined utility indices to assess water utilization and seek for efficient allocation using combinatorial optimization prom is stakeholder centered optimization procedure to match demand and available water at all levels model results are displayed in user friendly color coded outputs to observe the overall system status the initial resource assessmetn and final optimal allocation outputs are readily available for monitoring and evaluation both in volume and flow rate along with percent time exceedance for each priority group and sub basin the application of prom in the mrb has provided a road map to improve the current high water stress in the iconic mara serengeti ecosystem the model results suggest increasing the minimum environmental flow requirements to offset seasonal water shortage the application example can serve as a template for similar watersheds to facilitate participation and decision process in the planning and management of water resources finally prom will add a new perspective in fair and efficient multi sector management of supply and demand setup decision process and establishes evaluation and feedback mechanism acknowledgement the authors acknowledge the anonymous reviewers for their invaluable input to improve the content and presentation in the manuscript this material is partially supported by the united states agency for international development usaid through transboundary water for biodiversity and human health in the mara river basin under award no 623 a 00 05 00350 00 2005 2012 this is contribution number 894 from the southeast environmental research center in the institute of water environment at florida international university appendix a supplementary data the following are the supplementary data to this article prom interface dsr demand supply ratio prom dsr prom interface demand volume prom demand prom interface flow duration curves prom fdc prom interface optimum flow exceedance prom optexceedance prom interface optimum flow prom optflow prom interface optimum resource prom optresource prom interface optimal scenarios prom optscenario prom interface optimization prom optimization prom interface resource volume prom resource prom interface utility indices prom ui prom user interface prom userintrfce prom application example outputs prom interface data profile data profile appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2018 11 014 
26264,the installation of green infrastructure gi can revitalize communities while reducing sewage overflows and improving runoff quality however determining the proper gi investment is a challenging management task numerical hydrologic models such as the storm water management model swmm are the primary design tool for gi a new open source multi objective swmm optimization tool was developed by connecting swmm with the existing optimization software toolkit for research involving computational heuristics ostrich in contrast to similar tools it is open source and has a large selection of parallelized algorithms a case study of stormwater management in buffalo new york demonstrated how the tool can illuminate trade offs between the cost of rain barrel placement and the resulting reduction in combined sewer overflows in the future this tool could be used to optimize different types of gi features and contribute to a broader decision support framework for urban land use and stormwater management keywords green infrastructure multi objective optimization swmm rain barrel 1 introduction expanding urban populations and climate change continue to challenge the development of sustainable cities ward et al 2017 the increasing scarcity of urban land and competing demands over its use necessitates innovative planning solutions that appropriately balance stormwater management energy production recreation and other societal priorities green infrastructure gi is one solution that reduces stormwater runoff while improving surface water quality and providing other community benefits however determining the spatial allocation and appropriate investment in gi is a challenging management task yang and chui 2018 which has been explored by many researchers recently lee et al 2012 snll et al 2016 torres et al 2019 zhang and chui 2018 a eaton 2018 when applied to stormwater management numerical hydrologic models are the primary gi design tool in particular the storm water management model swmm is the most popular open source code for simulating systems with gi rossman 2015 which can be used for different purposes like stormwater runoff simulation ghodsi et al 2016 a zhang and chui 2018 b yazdi et al 2018 alamdari 2018 parameter calibration chow et al 2012 alamdari et al 2017 wagner et al 2018 and gi lid low impact development optimization huang et al 2018 coupling swmm with software that optimizes model inputs has two important applications 1 automation of the calibration process which can include hundreds of model parameters many of them spatially variable and 2 identification of strategies for placing gi and other engineered features to achieve management objectives such as the reduction of combined sewer overflows csos although the tool developed through this study can be used for both applications this paper focuses on the management scenario optimization of swmm for calibration is most commonly formulated as a single objective problem that minimizes the aggregate difference between observations and model predictions balascio et al 1998 ashbolt et al 2013 chen and goldscheider 2014 niazi et al 2017 however for management applications multi objective optimization moo is needed to consider tradeoffs between different goals such as minimizing costs reducing runoff volume and improving runoff quality moo tools developed to date include publically distributed software such as sustain riverson and lee 2012 and greenplan it sfei 2015 as well as in house code developed by researchers karamouz and nazif 2013 krebs et al 2014 li et al 2015 ghodsi et al 2016 b giacomoni and joseph 2017 yang and chui 2018 although some of these tools are free to download or can be provided upon request almost none are open source limiting their potential use furthermore most available tools support only one search algorithm typically the non dominated sorting genetic algorithm nsga ii however different search algorithms can vary substantially in terms of computational time and the ability to find a global solution in the presence of local minima this issue has been explored for stormwater applications by sebti et al 2016 this paper presents a new open source tool that connects swmm with the optimization software toolkit for research involving computational heuristics ostrich matott 2017 ostrich swmm which is freely distributed via a github repository provides numerous heuristic optimization algorithms many of which are parallelized that the user can apply to optimize gi types sizing and placement ostrich swmm pre processing directly modifies a swmm model to implement gi while its post processing functionality allows for the extraction of response variables the main research goal of this study was to highlight ostrich swmm s ability to use single and multi objective optimization to balance tradeoffs between different management goals this was demonstrated through a buffalo ny case study in which rain barrel placement was optimized to balance cso reduction with implementation cost in addition a preliminary performance assessment was conducted to compare three parallelized single objective optimization algorithms asynchronous parallel dynamically dimensioned search simulated annealing and real coded genetic algorithm 2 methodology 2 1 linkage of ostrich and swmm ostrich implements a wide variety of algorithms that are suitable for simulation based optimization and automatic calibration matott 2017 many of the algorithms such as dynamically dimensioned search tolson and shoemaker 2007 simulated annealing dougherty and marryott 1991 and genetic algorithm goldberg 1989 are parallelized and can take advantage of distributed computing resources such as those available at the university at buffalo center for computational research ub ccr www buffalo edu ccr ostrich has been applied to several simulation based optimization problems involving groundwater remediation bartelt hunt et al 2006 matott et al 2006a 2006b 2009 2011 2012 ostrich has also been integrated with several environmental modeling systems including frames johnston et al 2011 and mesh haghnegahdar et al 2014 ostrich follows the approach of pest doherty 2004 and ucode poeter and hill 1999 to achieve model independence by using template files to perturb model input and parsing instructions to extract model output as illustrated in fig 1 a ostrich typically uses a direct connection approach that is driven by a configuration file ostrich config and a set of model template files model tpl the configuration file establishes the optimization algorithm objective function design calibration parameters and constraints the template files are copies of required model inputs e g the swmm inp file in which numerical values for parameters were replaced by unique mnemonics ostrich uses these mnemonics to perform find and replace operations and convert template files into syntactically correct model input files containing desired parameter settings i e x in fig 1 for a given step of an optimization algorithm for each parameter perturbation ostrich runs a user specified executable or script which runs the modeling engine e g swmm5 exe along with any required pre and post processing instructions after a given model invocation is complete ostrich parses the model output i e y x in fig 1 to extract objective function information this process repeats until the optimization algorithm reaches its stopping criterion ostrich stores various optimization results e g optimal parameter set and corresponding objective function value for each iteration in a set of human readable output files ostrich can also be instructed to preserve all or some of the model input and output files associated with the different invocations of the modeling engine the ostrich user manual matott 2017 contains a full description of ostrich and its features and usage the direct connection approach is ill suited for inserting gi components into swmm because the process requires more than a simple find and replace operation instead a new section describing the new gi component must be added to the input file additionally the subcatchment swmm model unit that drains to a particular outlet associated with the new gi component must be split into multiple subcatchments some containing the new gi control e g rain barrels and connected roof area and one representing the remainder of the original subcatchment another difficulty of the direct connection approach is that the primary output file of the swmm5 engine is binary which ostrich is not capable of parsing consequently the pre and post processing wrapper ostrich swmm was developed to facilitate these linkages fig 1b the ostrich swmm interface was implemented as a python module that consumes a pair of json javascript object notation severance 2012 files and a clean version of the swmm inp file i e a version with no gi interventions based on the json files contents ostrich swmm will add gi components to the clean model and create a modified input file that is syntactically correct and maintains the initial total subcatchment area following swmm5 guidelines rossman 2015 each gi control is carved out of the existing parent subcatchment in which it is placed ostrich swmm subtracts the combined area of gi controls to be implemented in a particular subcatchment from the initial subcatchment area to obtain the new parent subcatchment area the new impervious and pervious area in the parent subcatchment are calculated in a similar manner the gi and parent subcatchments are iteratively adjusted by the ostrich optimization routines after processing a given json input file ostrich swmm will invoke the swmm5 numerical engine and post process the resulting binary output file this post processing is facilitated by swmmtoolbox https pypi python org pypi swmmtoolbox a python module for reading swmm5 binary output files once the output files are read information about predicted flows is written to a csv file that can be easily parsed by ostrich 2 2 optimization of gi interventions ostrich swmm allows for any optimization algorithm implemented by ostrich to be used in the optimization of gi interventions within a given swmm model preliminary tests of the interface emphasized the optimal placement of rain barrels rb in a case study derived from a portion of the full city of buffalo combined sewer system css model for this system cso events occur when flow exceeds the capacity of the downstream conveyances or treatment facilities a common phenomenon during large storms the objective of these preliminary efforts was to minimize the number of cso events and or total cso volume at a single problematic outfall located in the south central district of the system rain barrels are an attractive means of reducing runoff in urban settings because they can be easily installed in high density residential areas aad et al 2010 walsh et al 2014 swmm inputs for 284 l 75 us gallons rain barrels and their associated rooftops in this study were based on the properties implemented by aad et al 2010 all of the numerical experiments leveraged parallel processing to obtain the optimal distribution of rain barrels throughout the same submodel of the buffalo css in the swmm input file different types of rain barrels can be set up as gi controls with appropriate storage and drain parameters the storage and drain parameters for the 284 l rain barrel see table 1 were the same as those defined by macro 2018 rain barrel overflows were assumed to drain to the subcatchments pervious areas the ostrich swmm interface includes a python sub module that encapsulates the various steps required to insert a rain barrel into a swmm input file and adjust the parent subcatchment accordingly the percent of the subcatchment s impervious area treated by the rain barrel fromimp is adjusted by ostrich swmm based on the selected number of rain barrels and their associated rooftops after the rain barrel receives runoff from the roof any overflows and scheduled draining are routed to the pervious area of the parent subcatchment the development of ostrich swmm support for other gi features e g permeable pavement vegetative swales green roofs etc is an ongoing research effort 2 3 study domain the case study involved a submodel of the buffalo css located in the south central sewer district with a cso outfall on the buffalo river fig 2 which was extracted from a full model developed by malcolm pirnie arcadis in 2014 the submodel included 163 subcatchments with an average area of 0 1 km2 each with dummy conduits simulating connections with the full model without implementing gi the submodel predicted 29 cso events and a total overflow volume of more than 132 500 m3 over the course of buffalo s representative rainfall year of 1993 as established by malcolm pirnie arcadis and buffalo sewer authority 2014 total precipitation in 1993 was 982 2 mm which is within 5 of buffalo s average annual precipitation of 1027 9 mm fig 3 u s climate data 2018 2 4 multi objective optimization problem formulation due to the budget constrained nature of gi programs a multi objective optimization moo approach is needed to balance the cost of gi installation with the resulting reductions in cso frequency and volume referring to the pareto front produced for number of cso events and overflow volume other authors lucas and sample 2015 found that lid practices that reduce runoff volume were more effective at reducing overflow volume than reducing overflow events the reverse was true for deep tunnel storage regulatory policy is often set by minimizing the number of overflow events whereas available literature suggests flow volume is what causes negative environmental impacts from csos quijano et al 2017 considering multiple objectives while optimizing rain barrel placement can illuminate tradeoffs between the conflicting objectives of different stakeholders to facilitate visualization of results the three objective problem was configured as a series of two objective problems equations 1 3 each defined as the optimization of a vector composed of a pair of objective functions that were subjected to the same inequality constraint equation 4 1 minimize f 1 f 1 d f 2 d d   2 minimize f 2 f 1 d f 3 d d   3 minimize f 3 f 2 d f 3 d d   subject to 4 h 1 d d i max d i 0 where d is a vector of decision variables in the decision space  equation 5 and each f d is calculated from ostrich swmm response variables equations 6 8 max di is based on the total impervious area in a particular subcatchment iai and the area taken up by an individual rain barrel arb and tis connected roof aroof equation 9 5 d nrb 1 nrb 2 nrb n 6 f1 d ncso number of cso events over simulation period 7 f2 d fvol total cso volume over simulation period 8 f 3 d cost 150 i 0 n d i 9 max d i ia i a roof a rb nrbi represents the number of rain barrels added to an individual subcatchment with n being the total number of subcatchments for this study the cost of purchasing and installing a 284 l rain barrel was assumed to be 150 the pareto archived dynamically dimensioned search padds is one of several ostrich algorithms that identifies the tradeoff curve pareto front for conflicting objectives the solutions along this curve are non dominated meaning that one objective function can t be improved without making the other objective function worse per the guidelines of asadzadeh and tolson 2013 padds was applied using a perturbation value of 0 2 the exact hyper volume contribution selection metric and a stopping criterion of 3000 iterations 2 5 problem formulation for comparing single objective optimization algorithms ostrich provides an extensive set of search algorithms for use in single and multi objective optimization to illustrate how different algorithms could be compared with ostrich swmm the same single objective gi problem was solved using three parallelized algorithms asynchronous parallel dynamically dimensioned search paradds simulated annealing sa and real coded genetic algorithm rga for this comparison the single objective optimization problem was formulated as follows 10 minimize f2 d fvol subject to 11 h 1 d d i max d i 0 12 h 2 d cost 2 500 000 0 the additive penalty method was applied using a cost factor of 100 000 to weight total cost constraint equation 11 violations to characterize performance and solution variability 11 trials were run for each algorithm utilizing two 16 core nodes in parallel 3 results 3 1 baseline measurement of maximum impact before conducting an optimization analysis preliminary numerical experiments were used to evaluate the minimum and maximum impacts of rain barrel placement on the number and total volume of cso events ncso and fvol and implementation cost table 2 shows the predicted results before base model and after configuring the model to accommodate the maximum practical number of rain barrels for the available rooftop area this arrangement was able to reduce ncso for the 1993 simulation from 29 events for the base model to only 4 events for the maximum impact case which also reduced fvol by 88 relative to the base model 3 2 multi objective optimization results a separate optimization was performed for each of the two objective formulations minimizing f 1 produced a single non dominated solution because ncso and fvol are not competing objectives fig 4 each dominated solution represents an iteration of padds that had at least one f 1 component greater than the corresponding component for the non dominated solution the optimal solution implements 28 573 rb at a cost of 4 285 950 to reduce ncso to 4 and decrease fvol by 83 the spread of dominated solutions for this problem shows that the same ncso can be associated with a wide range of fvol and that the same fvol can be associated with different ncso due to the varying sizes of cso events during the simulation period the pareto front produced for the ncso and cost moo problem f 2 contained four non dominated solutions fig 5 based on a decision maker s priorities any non dominated solution along this front could be selected as the preferred solution these results show that the maximum impact of reducing ncso from 29 to 4 can be achieved for a much lower cost relative to the maximum impact scenario by optimizing the placement of rain barrels in the model domain it should be noted that ncso is a discrete variable the number of rain barrels in each subcatchment obtained from the optimal solution when ncso is 4 is shown in fig 2 it varies significantly among subcatchments ranging from zero to 1146 but the subcatchments with larger number of rain barrels 150 do not show any obvious spatial distribution pattern the solution to the fvol and cost problem formulation f3 had 99 non dominated solutions along the pareto front fig 6 there is a wider spread for this tradeoff curve because both objectives are continuous variables as opposed to ncso which is discrete the fvol for the majority of the optimal solutions is lower than the fvol for the solutions on the ncso and cost curve the solution with the lowest fvol and highest cost along the front had six cso events and 29 of the original fvol the fvol and cost optimization produced rb arrangements with higher costs than the ncso and cost optimization after the same number of iterations all of the moo trials had a run time of 25 h using 20 16 core nodes in parallel for a total of 320 processors per optimization each swmm model simulation on these nodes required approximately 40 min of processing time because the user can impose a computational constraint on the optimization process e g maximum number of model runs some portions of the pareto front may be delineated with reduced precision for example as shown in fig 6 non dominated solutions were not identified for some values of fvol which ranged from 60 000 m3 to 73 000 m3 the occurrence of such gaps is application specific and can be addressed by interpolating to fill gaps within the calculated front and or increasing the computational budget 3 3 comparison between different single objective algorithms even though they were subjected to the same constraints the different algorithms did not generate the same optimal solution when each numerical experiment was repeated 11 times paradds generated the lowest median fvol with the fastest computational time compared to sa and rga while sa had the least solution variability table 3 and fig 7 the kernel probability distribution plot shape first and third quartiles box median vertical line mean diamond and additional observations circle for the trials are displayed in fig 7 the differences in fvol were statistically significant based on the wilcoxon mann whitney test mann and whitney 1947 overall paradds significantly outperformed the other algorithms the different constrained single objective optimization solutions are compared to the pareto front found by minimizing f 3 in fig 6 the median paradds solution was very close to the intersection of the f 3 pareto front and the cost constraint of 2 500 000 the sa and rga median solutions represent local minima these results indicate that paradds had the best performance overall for the buffalo case study further research is needed to make a general recommendation for which algorithm in the ostrich package is best to use for optimizing gi projects 4 conclusions to address a need for an open source swmm optimization tool that can do single and multi objective optimization of model components to meet different management goals a new tool called ostrich swmm was developed it includes more than a dozen heuristic optimization algorithms that can be used to optimize gi investment i e maximizing cso reduction and minimizing cost for a case study of optimizing rain barrel placement in buffalo new york the pareto archived dynamically dimensioned search algorithm successfully generated a pareto front for the conflicting objectives of cso reduction and total gi implementation cost three additional optimization algorithms were applied to a single objective problem with a cost constraint for this problem asynchronous parallel dynamically dimensioned search outperformed simulated annealing and real coded genetic algorithm a more comprehensive comparison between algorithms and optimizing the sizing and placement of multiple types of gi using ostrich swmm will be the subject of future work software availability name of software ostrich swmm availability https github com ubccr ostrich swmm cost free acknowledgements we would like to acknowledge university at buffalo renew institute seed grant for financial support buffalo sewer authority for providing swmm model and ub ccr for providing computational resources kristina macro would like to acknowledge the support of the schomburg fellowship program the opinions and findings presented in this paper are solely those of the authors and do not represent the opinions of the bsa and or any other state and federal agency mentioned in the manuscript 
26264,the installation of green infrastructure gi can revitalize communities while reducing sewage overflows and improving runoff quality however determining the proper gi investment is a challenging management task numerical hydrologic models such as the storm water management model swmm are the primary design tool for gi a new open source multi objective swmm optimization tool was developed by connecting swmm with the existing optimization software toolkit for research involving computational heuristics ostrich in contrast to similar tools it is open source and has a large selection of parallelized algorithms a case study of stormwater management in buffalo new york demonstrated how the tool can illuminate trade offs between the cost of rain barrel placement and the resulting reduction in combined sewer overflows in the future this tool could be used to optimize different types of gi features and contribute to a broader decision support framework for urban land use and stormwater management keywords green infrastructure multi objective optimization swmm rain barrel 1 introduction expanding urban populations and climate change continue to challenge the development of sustainable cities ward et al 2017 the increasing scarcity of urban land and competing demands over its use necessitates innovative planning solutions that appropriately balance stormwater management energy production recreation and other societal priorities green infrastructure gi is one solution that reduces stormwater runoff while improving surface water quality and providing other community benefits however determining the spatial allocation and appropriate investment in gi is a challenging management task yang and chui 2018 which has been explored by many researchers recently lee et al 2012 snll et al 2016 torres et al 2019 zhang and chui 2018 a eaton 2018 when applied to stormwater management numerical hydrologic models are the primary gi design tool in particular the storm water management model swmm is the most popular open source code for simulating systems with gi rossman 2015 which can be used for different purposes like stormwater runoff simulation ghodsi et al 2016 a zhang and chui 2018 b yazdi et al 2018 alamdari 2018 parameter calibration chow et al 2012 alamdari et al 2017 wagner et al 2018 and gi lid low impact development optimization huang et al 2018 coupling swmm with software that optimizes model inputs has two important applications 1 automation of the calibration process which can include hundreds of model parameters many of them spatially variable and 2 identification of strategies for placing gi and other engineered features to achieve management objectives such as the reduction of combined sewer overflows csos although the tool developed through this study can be used for both applications this paper focuses on the management scenario optimization of swmm for calibration is most commonly formulated as a single objective problem that minimizes the aggregate difference between observations and model predictions balascio et al 1998 ashbolt et al 2013 chen and goldscheider 2014 niazi et al 2017 however for management applications multi objective optimization moo is needed to consider tradeoffs between different goals such as minimizing costs reducing runoff volume and improving runoff quality moo tools developed to date include publically distributed software such as sustain riverson and lee 2012 and greenplan it sfei 2015 as well as in house code developed by researchers karamouz and nazif 2013 krebs et al 2014 li et al 2015 ghodsi et al 2016 b giacomoni and joseph 2017 yang and chui 2018 although some of these tools are free to download or can be provided upon request almost none are open source limiting their potential use furthermore most available tools support only one search algorithm typically the non dominated sorting genetic algorithm nsga ii however different search algorithms can vary substantially in terms of computational time and the ability to find a global solution in the presence of local minima this issue has been explored for stormwater applications by sebti et al 2016 this paper presents a new open source tool that connects swmm with the optimization software toolkit for research involving computational heuristics ostrich matott 2017 ostrich swmm which is freely distributed via a github repository provides numerous heuristic optimization algorithms many of which are parallelized that the user can apply to optimize gi types sizing and placement ostrich swmm pre processing directly modifies a swmm model to implement gi while its post processing functionality allows for the extraction of response variables the main research goal of this study was to highlight ostrich swmm s ability to use single and multi objective optimization to balance tradeoffs between different management goals this was demonstrated through a buffalo ny case study in which rain barrel placement was optimized to balance cso reduction with implementation cost in addition a preliminary performance assessment was conducted to compare three parallelized single objective optimization algorithms asynchronous parallel dynamically dimensioned search simulated annealing and real coded genetic algorithm 2 methodology 2 1 linkage of ostrich and swmm ostrich implements a wide variety of algorithms that are suitable for simulation based optimization and automatic calibration matott 2017 many of the algorithms such as dynamically dimensioned search tolson and shoemaker 2007 simulated annealing dougherty and marryott 1991 and genetic algorithm goldberg 1989 are parallelized and can take advantage of distributed computing resources such as those available at the university at buffalo center for computational research ub ccr www buffalo edu ccr ostrich has been applied to several simulation based optimization problems involving groundwater remediation bartelt hunt et al 2006 matott et al 2006a 2006b 2009 2011 2012 ostrich has also been integrated with several environmental modeling systems including frames johnston et al 2011 and mesh haghnegahdar et al 2014 ostrich follows the approach of pest doherty 2004 and ucode poeter and hill 1999 to achieve model independence by using template files to perturb model input and parsing instructions to extract model output as illustrated in fig 1 a ostrich typically uses a direct connection approach that is driven by a configuration file ostrich config and a set of model template files model tpl the configuration file establishes the optimization algorithm objective function design calibration parameters and constraints the template files are copies of required model inputs e g the swmm inp file in which numerical values for parameters were replaced by unique mnemonics ostrich uses these mnemonics to perform find and replace operations and convert template files into syntactically correct model input files containing desired parameter settings i e x in fig 1 for a given step of an optimization algorithm for each parameter perturbation ostrich runs a user specified executable or script which runs the modeling engine e g swmm5 exe along with any required pre and post processing instructions after a given model invocation is complete ostrich parses the model output i e y x in fig 1 to extract objective function information this process repeats until the optimization algorithm reaches its stopping criterion ostrich stores various optimization results e g optimal parameter set and corresponding objective function value for each iteration in a set of human readable output files ostrich can also be instructed to preserve all or some of the model input and output files associated with the different invocations of the modeling engine the ostrich user manual matott 2017 contains a full description of ostrich and its features and usage the direct connection approach is ill suited for inserting gi components into swmm because the process requires more than a simple find and replace operation instead a new section describing the new gi component must be added to the input file additionally the subcatchment swmm model unit that drains to a particular outlet associated with the new gi component must be split into multiple subcatchments some containing the new gi control e g rain barrels and connected roof area and one representing the remainder of the original subcatchment another difficulty of the direct connection approach is that the primary output file of the swmm5 engine is binary which ostrich is not capable of parsing consequently the pre and post processing wrapper ostrich swmm was developed to facilitate these linkages fig 1b the ostrich swmm interface was implemented as a python module that consumes a pair of json javascript object notation severance 2012 files and a clean version of the swmm inp file i e a version with no gi interventions based on the json files contents ostrich swmm will add gi components to the clean model and create a modified input file that is syntactically correct and maintains the initial total subcatchment area following swmm5 guidelines rossman 2015 each gi control is carved out of the existing parent subcatchment in which it is placed ostrich swmm subtracts the combined area of gi controls to be implemented in a particular subcatchment from the initial subcatchment area to obtain the new parent subcatchment area the new impervious and pervious area in the parent subcatchment are calculated in a similar manner the gi and parent subcatchments are iteratively adjusted by the ostrich optimization routines after processing a given json input file ostrich swmm will invoke the swmm5 numerical engine and post process the resulting binary output file this post processing is facilitated by swmmtoolbox https pypi python org pypi swmmtoolbox a python module for reading swmm5 binary output files once the output files are read information about predicted flows is written to a csv file that can be easily parsed by ostrich 2 2 optimization of gi interventions ostrich swmm allows for any optimization algorithm implemented by ostrich to be used in the optimization of gi interventions within a given swmm model preliminary tests of the interface emphasized the optimal placement of rain barrels rb in a case study derived from a portion of the full city of buffalo combined sewer system css model for this system cso events occur when flow exceeds the capacity of the downstream conveyances or treatment facilities a common phenomenon during large storms the objective of these preliminary efforts was to minimize the number of cso events and or total cso volume at a single problematic outfall located in the south central district of the system rain barrels are an attractive means of reducing runoff in urban settings because they can be easily installed in high density residential areas aad et al 2010 walsh et al 2014 swmm inputs for 284 l 75 us gallons rain barrels and their associated rooftops in this study were based on the properties implemented by aad et al 2010 all of the numerical experiments leveraged parallel processing to obtain the optimal distribution of rain barrels throughout the same submodel of the buffalo css in the swmm input file different types of rain barrels can be set up as gi controls with appropriate storage and drain parameters the storage and drain parameters for the 284 l rain barrel see table 1 were the same as those defined by macro 2018 rain barrel overflows were assumed to drain to the subcatchments pervious areas the ostrich swmm interface includes a python sub module that encapsulates the various steps required to insert a rain barrel into a swmm input file and adjust the parent subcatchment accordingly the percent of the subcatchment s impervious area treated by the rain barrel fromimp is adjusted by ostrich swmm based on the selected number of rain barrels and their associated rooftops after the rain barrel receives runoff from the roof any overflows and scheduled draining are routed to the pervious area of the parent subcatchment the development of ostrich swmm support for other gi features e g permeable pavement vegetative swales green roofs etc is an ongoing research effort 2 3 study domain the case study involved a submodel of the buffalo css located in the south central sewer district with a cso outfall on the buffalo river fig 2 which was extracted from a full model developed by malcolm pirnie arcadis in 2014 the submodel included 163 subcatchments with an average area of 0 1 km2 each with dummy conduits simulating connections with the full model without implementing gi the submodel predicted 29 cso events and a total overflow volume of more than 132 500 m3 over the course of buffalo s representative rainfall year of 1993 as established by malcolm pirnie arcadis and buffalo sewer authority 2014 total precipitation in 1993 was 982 2 mm which is within 5 of buffalo s average annual precipitation of 1027 9 mm fig 3 u s climate data 2018 2 4 multi objective optimization problem formulation due to the budget constrained nature of gi programs a multi objective optimization moo approach is needed to balance the cost of gi installation with the resulting reductions in cso frequency and volume referring to the pareto front produced for number of cso events and overflow volume other authors lucas and sample 2015 found that lid practices that reduce runoff volume were more effective at reducing overflow volume than reducing overflow events the reverse was true for deep tunnel storage regulatory policy is often set by minimizing the number of overflow events whereas available literature suggests flow volume is what causes negative environmental impacts from csos quijano et al 2017 considering multiple objectives while optimizing rain barrel placement can illuminate tradeoffs between the conflicting objectives of different stakeholders to facilitate visualization of results the three objective problem was configured as a series of two objective problems equations 1 3 each defined as the optimization of a vector composed of a pair of objective functions that were subjected to the same inequality constraint equation 4 1 minimize f 1 f 1 d f 2 d d   2 minimize f 2 f 1 d f 3 d d   3 minimize f 3 f 2 d f 3 d d   subject to 4 h 1 d d i max d i 0 where d is a vector of decision variables in the decision space  equation 5 and each f d is calculated from ostrich swmm response variables equations 6 8 max di is based on the total impervious area in a particular subcatchment iai and the area taken up by an individual rain barrel arb and tis connected roof aroof equation 9 5 d nrb 1 nrb 2 nrb n 6 f1 d ncso number of cso events over simulation period 7 f2 d fvol total cso volume over simulation period 8 f 3 d cost 150 i 0 n d i 9 max d i ia i a roof a rb nrbi represents the number of rain barrels added to an individual subcatchment with n being the total number of subcatchments for this study the cost of purchasing and installing a 284 l rain barrel was assumed to be 150 the pareto archived dynamically dimensioned search padds is one of several ostrich algorithms that identifies the tradeoff curve pareto front for conflicting objectives the solutions along this curve are non dominated meaning that one objective function can t be improved without making the other objective function worse per the guidelines of asadzadeh and tolson 2013 padds was applied using a perturbation value of 0 2 the exact hyper volume contribution selection metric and a stopping criterion of 3000 iterations 2 5 problem formulation for comparing single objective optimization algorithms ostrich provides an extensive set of search algorithms for use in single and multi objective optimization to illustrate how different algorithms could be compared with ostrich swmm the same single objective gi problem was solved using three parallelized algorithms asynchronous parallel dynamically dimensioned search paradds simulated annealing sa and real coded genetic algorithm rga for this comparison the single objective optimization problem was formulated as follows 10 minimize f2 d fvol subject to 11 h 1 d d i max d i 0 12 h 2 d cost 2 500 000 0 the additive penalty method was applied using a cost factor of 100 000 to weight total cost constraint equation 11 violations to characterize performance and solution variability 11 trials were run for each algorithm utilizing two 16 core nodes in parallel 3 results 3 1 baseline measurement of maximum impact before conducting an optimization analysis preliminary numerical experiments were used to evaluate the minimum and maximum impacts of rain barrel placement on the number and total volume of cso events ncso and fvol and implementation cost table 2 shows the predicted results before base model and after configuring the model to accommodate the maximum practical number of rain barrels for the available rooftop area this arrangement was able to reduce ncso for the 1993 simulation from 29 events for the base model to only 4 events for the maximum impact case which also reduced fvol by 88 relative to the base model 3 2 multi objective optimization results a separate optimization was performed for each of the two objective formulations minimizing f 1 produced a single non dominated solution because ncso and fvol are not competing objectives fig 4 each dominated solution represents an iteration of padds that had at least one f 1 component greater than the corresponding component for the non dominated solution the optimal solution implements 28 573 rb at a cost of 4 285 950 to reduce ncso to 4 and decrease fvol by 83 the spread of dominated solutions for this problem shows that the same ncso can be associated with a wide range of fvol and that the same fvol can be associated with different ncso due to the varying sizes of cso events during the simulation period the pareto front produced for the ncso and cost moo problem f 2 contained four non dominated solutions fig 5 based on a decision maker s priorities any non dominated solution along this front could be selected as the preferred solution these results show that the maximum impact of reducing ncso from 29 to 4 can be achieved for a much lower cost relative to the maximum impact scenario by optimizing the placement of rain barrels in the model domain it should be noted that ncso is a discrete variable the number of rain barrels in each subcatchment obtained from the optimal solution when ncso is 4 is shown in fig 2 it varies significantly among subcatchments ranging from zero to 1146 but the subcatchments with larger number of rain barrels 150 do not show any obvious spatial distribution pattern the solution to the fvol and cost problem formulation f3 had 99 non dominated solutions along the pareto front fig 6 there is a wider spread for this tradeoff curve because both objectives are continuous variables as opposed to ncso which is discrete the fvol for the majority of the optimal solutions is lower than the fvol for the solutions on the ncso and cost curve the solution with the lowest fvol and highest cost along the front had six cso events and 29 of the original fvol the fvol and cost optimization produced rb arrangements with higher costs than the ncso and cost optimization after the same number of iterations all of the moo trials had a run time of 25 h using 20 16 core nodes in parallel for a total of 320 processors per optimization each swmm model simulation on these nodes required approximately 40 min of processing time because the user can impose a computational constraint on the optimization process e g maximum number of model runs some portions of the pareto front may be delineated with reduced precision for example as shown in fig 6 non dominated solutions were not identified for some values of fvol which ranged from 60 000 m3 to 73 000 m3 the occurrence of such gaps is application specific and can be addressed by interpolating to fill gaps within the calculated front and or increasing the computational budget 3 3 comparison between different single objective algorithms even though they were subjected to the same constraints the different algorithms did not generate the same optimal solution when each numerical experiment was repeated 11 times paradds generated the lowest median fvol with the fastest computational time compared to sa and rga while sa had the least solution variability table 3 and fig 7 the kernel probability distribution plot shape first and third quartiles box median vertical line mean diamond and additional observations circle for the trials are displayed in fig 7 the differences in fvol were statistically significant based on the wilcoxon mann whitney test mann and whitney 1947 overall paradds significantly outperformed the other algorithms the different constrained single objective optimization solutions are compared to the pareto front found by minimizing f 3 in fig 6 the median paradds solution was very close to the intersection of the f 3 pareto front and the cost constraint of 2 500 000 the sa and rga median solutions represent local minima these results indicate that paradds had the best performance overall for the buffalo case study further research is needed to make a general recommendation for which algorithm in the ostrich package is best to use for optimizing gi projects 4 conclusions to address a need for an open source swmm optimization tool that can do single and multi objective optimization of model components to meet different management goals a new tool called ostrich swmm was developed it includes more than a dozen heuristic optimization algorithms that can be used to optimize gi investment i e maximizing cso reduction and minimizing cost for a case study of optimizing rain barrel placement in buffalo new york the pareto archived dynamically dimensioned search algorithm successfully generated a pareto front for the conflicting objectives of cso reduction and total gi implementation cost three additional optimization algorithms were applied to a single objective problem with a cost constraint for this problem asynchronous parallel dynamically dimensioned search outperformed simulated annealing and real coded genetic algorithm a more comprehensive comparison between algorithms and optimizing the sizing and placement of multiple types of gi using ostrich swmm will be the subject of future work software availability name of software ostrich swmm availability https github com ubccr ostrich swmm cost free acknowledgements we would like to acknowledge university at buffalo renew institute seed grant for financial support buffalo sewer authority for providing swmm model and ub ccr for providing computational resources kristina macro would like to acknowledge the support of the schomburg fellowship program the opinions and findings presented in this paper are solely those of the authors and do not represent the opinions of the bsa and or any other state and federal agency mentioned in the manuscript 
