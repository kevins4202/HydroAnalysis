index,text
6570,we explored the feasibility of an improved design of a co2 leakage monitoring network at a geologic storage site to effectively represent co2 pathways a rule based percolation model was adopted rather than the rigorous multiphase flow model based on darcy s equation five different monitoring network designs were compared using a few scenarios and multiple correlated random field realizations the ensemble results showed that given the detection uncertainty across the entire sensor network regular spacing deployment of sensors is the most effective method when a sufficient number of sensors is available the results also showed that an aggressive monitoring design based on information of the spatial permeability distribution near the surface can be a viable method when a limited number of sensors is employed however such an aggressive design can lead to elevated uncertainty in leakage detectability keywords co2 leakage monitoring network design rule based percolation model co2 storage site monte carlo simulation 1 introduction a monitoring measurement and verification mmv plan is essential for ensuring safe co2 storage in geologic formations romanak et al 2012 as part of an mmv plan near surface monitoring is necessary at a co2 storage site to meet regulations reduce potential risk and obtain public acceptance leakage of injected co2 from a reservoir can have an adverse effect on the near surface environment however this occurrence can be reduced by establishing a site specific monitoring network design and by employing mitigation measures the optimal design for a near surface monitoring network is thus critical to successfully detect co2 and to enable the mmv plan to be used effectively yang et al 2017 chen et al 2018 therefore the goal of this study is to determine whether an optimal monitoring network design can be selected based on an understanding of near surface heterogeneity when co2 migrates from a reservoir into an overlying aquifer through unanticipated leakage pathways in the intervening low permeability layer a portion of the injected co2 may leak to the surface in the event of a small number of seepages independent processes such as buoyancy capillarity and pressure build up under a low permeability layer acting within the aquifer have a greater influence than the reservoir pressure gradient on gaseous phase co2 migration the co2 gas in an aquifer can migrate through a highly branched path that is substantially influenced by complexities in the localized heterogeneity of the constituent medium bryant et al 2008 saadatpoor et al 2010 to optimize the design of a monitoring network in consideration of the site characteristics it is essential to develop a model that reflects the detailed hydraulic properties of an aquifer including capillary entry pressure and permeability in addition a model that represents co2 movement in an aquifer must be able to reproduce the complicated migration patterns of gaseous co2 however obtaining detailed hydraulic properties of thick aquifers is technically impractical and co2 leakage locations are nearly impossible to predict furthermore previous studies have argued that a simulation of the preferential flow pathways of non wetting fluids based on darcy s law is computationally demanding when both the detailed capillarity and heterogeneity of parameters are considered meckel et al 2015 krishnamurthy et al 2017 moreover the computational time needs to be improved oldenburg et al 2016 under these considerations probabilistic approaches that rely on a large number of samples monte carlo simulations based on a practically executable simulation method are viable methods for designing a monitoring network for co2 leakage detection a practically executable simulation method can be used to avoid extreme computational time by using a few model simplification assumptions and by employing gaseous co2 macroscopic quasi static models such as a vertical equilibrium model gasda and nordbotten 2009 bandilla et al 2015 invasion percolation ip model cavanagh 2013 cavanagh and haszeldine 2014 or a rule based percolation rp model similar to that used by parker and park 2004 and park and parker 2005 although many similarities exist between the theories of ip and rp models the rule based model was chosen for this study as the practically executable simulation method because it can be more effectively incorporated with well defined macroscopic hydraulic parameters such as intrinsic and relative permeability effective saturation capillary pressure and mass flux several studies have provided useful tools for designing a monitoring network in a probabilistic framework cortis et al 2008 yang et al 2011 sun et al 2013a sun et al 2013b yang et al 2017 however few have focused on a sensor network design that reflects the heterogeneity of an aquifer which significantly affects the pathways of gaseous co2 this study introduces a conceptual procedure for designing co2 monitoring networks at geologic storage sites where only a portion of the near surface heterogeneity is assumed to be known a macroscopic rp model representing gaseous phase co2 migration pathways under a vertical equilibrium state in terms of mass flux is developed and several monitoring network designs are proposed finally the effectiveness of the monitoring network designs is validated through the ensemble statistics of multiple simulations based on subsurface heterogeneity realizations 2 model development a rule based percolation model fig 1 conceptually illustrates that co2 leaks to an aquifer through an imperfect caprock overlying a reservoir in which injected supercritical co2 was stored assuming that the pressure gradients between the reservoir and aquifer are not well connected a small portion of the co2 mass continuously leaks into the aquifer co2 enters as a gaseous phase immediately upon reaching the aquifer level under these circumstances 1 the density difference between co2 and water 2 a subsurface pressure buildup caused by the continuous supply of co2 gas and 3 air entry pressure heterogeneity caused by heterogeneous pore distributions are the controlling forces for co2 gas migration into the aquifer an equilibrium state is reached in the upward movement of co2 as it passes in a gaseous state through the aquifer from the lower aquifer to the surface it is assumed that a volume of the aquifer media with lower air entry pressure is more easily invaded by co2 gas without diffusion or dissolution of mass this assumption may be oversimplified however the dissolution of gaseous phase co2 into groundwater is considered to be the worst case in terms of surface co2 leakage nevertheless it should be noted that the lack of dissolution can be a favorable condition in terms of the detectability dissolution of co2 during lateral movement in the aquifer will attenuate the flux and will thus decrease its probability of being detected in an observation well however the investigation of this phenomenon is beyond the scope of the present study from this perspective co2 flux reduction within the unsaturated zone by dissolution and dispersion are also ignored to maximize co2 leakage at the surface however it is clear that the unsaturated zone could also have an important impact on the spatial leakage distribution owing to the effects of permeability heterogeneity the model developed below was used to determine the air entry pressure head where the water retention curve is defined by an empiric statistical approach van genuchten 1980 1 θ 1 1 α h n m where θ is the effective saturation given by θ θ θ r θ s θ r θ is the water content θ r is the residual water content θ s is the water content at saturation α l 1 is an empirical parameter describing the position of the maximum pore size distribution n and m 1 1 n are empirical parameters characterizing the width of the pore size distribution and h h 0 l is the capillary pressure head the air entry pressure head associated with the maximum pore size of the constituent medium is based on the tangential projection line from the inflection point of the retention curve to θ 1 which can be derived by taking the second derivative of eq 1 as follows 2 2 θ h 2 α n m n 2 h n 2 1 α h n m 2 α h n m where the first derivative of eq 1 is 3 θ h α n m n h n 1 1 α h n m 1 the inflection point can be obtained by equating the second derivative eq 2 to zero which results in h inf m 1 n α where the corresponding effective saturation is θ inf 1 1 m m at this point the slope of the tangential line σ is 4 σ α n m m 1 1 m m 1 and the equation for the tangential line is θ σ h h i θ inf therefore the modified van genuchten curve is given by 5 θ 1 1 α h n m 0 θ θ inf σ h h inf θ inf θ inf θ 1 from eq 5 the air entry pressure head h ae l becomes h ae h inf θ s θ inf σ in this study a small portion of trapped air is assumed θ s 0 99 to facilitate co2 gas invasion into the pores a detailed explanation of the above equations can be found in supplementary material i fig s1 the hydraulic head of the aquifer prior to the introduction of co2 gas is under an equilibrium state where the pressure value p ml 1t 2 follows p ρ w g ψ in which ρ w ml 3 is the density of water g lt 2 is gravitational acceleration and ψ l is the depth from the water table or pressure head if the co2 gas pressure head of a cell multiplied by the ratio of the density difference between co2 gas and water i e ρ w ρ c o 2 ρ w considering that the buoyancy exceeds the minimum required head of the neighboring cell i e ψ h ae the cell can be invaded by co2 gas to define the flow rate of co2 gas two dimensional darcy s law is employed as follows supplementary material i fig s2 6 h i h i 1 q k δ l δ r where h i l is the co2 gas pressure head of the percolated cell h i 1 l is the co2 head of the source cell q l2t 1 is the two dimensional co2 gas flow rate and δ l l is the length along the flow direction from the center of the source cell to the center of the percolated cell the length of the cell edge perpendicular to the flow direction which is denoted as δ r l can be either δ x or δ z depending on the flow direction where δ x and δ z are the horizontal and vertical discretization intervals respectively the hydraulic conductivity k lt 1 is given by k k s s k r s k s i k r i 2 where k s s and k s i are the saturated hydraulic conductivity of the source and invaded cells respectively and k r s and k r i are the relative permeability of the source and invaded cells respectively the relative permeability of a non wetting fluid co2 is given by 7 k r θ θ c o 2 1 2 1 1 θ c o 2 1 m m 2 a non zero relative permeability i e min k r 0 01 is assumed to promote co2 migration with respect to the two dimensional flow rate q the horizontal and vertical values are computed separately where the horizontal flow rate q h dissipates as the number of horizontally percolated cells increases and is defined as q h q sum n h 0 furthermore the vertical flow rate q v dissipates as the number of vertically percolated cells increases and is defined as q v q sum n h here q sum is the total flow rate introduced into the aquifer by the underlying reservoir n h 0 is the number of the periphery cells of a co2 lens in a layer and n h is the number of vertically percolated cells because the co2 gas is continuously supplied it is assumed that the co2 gas pressure head gradually increases until the invasion of an adjacent cell and follows the relationship h updated h old 2 δ h where δ h q k s k r sequential layer by layer computation is performed until the cumulative mass flux m n satisfies the condition m n q sum ρ n where 8 m n δ x δ z p n φ n i n 1 t k n h n h n 1 and ρ n is mean density of layer n the calculation of the corresponding layer is then terminated and that of the next layer begins in eq 8 p n is a density vector of gaseous co2 φ n is a porosity vector and i n 1 is an invasion indicator vector whereby the value is 1 if the cell is vertically invaded otherwise it is zero k n lt 1 is a vector representing the average hydraulic conductivity between layers n and n 1 and h n l is the co2 pressure head vector of the n th layer the permeability field is generated via sequential gaussian simulation sgsim by assuming that the values are spatially correlated random variables following a log normal distribution deutsch and journel 1998 for convenience in generating the van genuchten model parameter fields it is assumed that the values of α and n are perfectly correlated to the value of k s based on the following relationships α max p 3 α p 1 α log 10 k s p 2 α a n d n p 1 n k s p 2 n p 3 n which are fitting functions constructed on the basis of the corresponding statistical models proposed by carsel and parrish 1988 the fitting results for the random variables in the above functions are p 1 3 α 7 4 9 6 0 01 and p 1 3 n 0 93 0 31 1 1 these fitting results were used in all of our percolation simulations 3 results and discussion a two dimensional domain measuring 2000 100 m x and y discretized as 400 200 cells was used for the percolation simulations the corresponding spatially correlated permeability fields were generated by the sgsim model with a log normal distribution four different scenarios were considered during the generation of the permeability fields the first scenario c1 used correlation lengths of 1000 m and 10 m along the horizontal λ h and vertical λ v axes respectively and the log transformed mean log μ and variance log σ 2 of the permeability fields were targeted as 1 corresponding to 0 368 m day and 1 respectively in the second scenario c2 λ h λ v log μ and log σ 2 were set as 1000 m 10 m 1 and 4 respectively in the third scenario c3 λ h λ v log μ and log σ 2 were set as 200 m 10 m 1 and 1 respectively and in the fourth scenario c4 λ h λ v log μ and log σ 2 were set as 200 m 10 m 1 and 4 respectively these scenarios are summarized in table 1 for the two dimensional co2 flow rate a fictitious rate of 1 10 4 m2 day co2 was assigned to three central cells of the bottom layer in total 400 permeability fields were employed in our simulations with 100 percolation simulations for each scenario moreover no regional hydraulic gradient was assumed which justifies the lack of plume dissipation owing to dissolution in an equilibrium state representative results from the four different scenarios are shown in fig 2 and the remaining results are provided in supplementary material ii with 20 simulation results per scenario in fig 2 the filled red colored areas represent the simulated co2 plume in a quasi static condition and ramified pathways where c1 c2 and c3 c4 are respectively from identical correlated random fields with different permeability variances the background is a log transformed permeability field where yellow and blue indicate high and low permeability respectively in the figure c2 and c4 which have higher variances contain more divergent co2 pathways and are strongly affected by the juxtaposition of permeable spatial structures in contrast c1 and c3 contain less divergent pathways indicating that the spatial structures are less influenced by the relatively lower permeability contrasts among the structures in c2 which has a longer permeability correlation scale and higher permeability variance it is difficult for the co2 gas to find media having low air entry pressures in addition more pools with higher accumulation of co2 gas are present along the pathways which show high variance from the median pathway the less divergent patterns of c1 and c3 can be attributed to the lower variances in media permeability co2 gas does not build sufficient pressure along the pathways and its invasion is limited to media with relatively high permeability these observations along with the additional results provided in the supplementary material ii suggest that the spatial extent of surface co2 leakage pathways is approximately proportional to the horizontal correlation scale and the variance of the aquifer permeability the overall observations suggest that significant uncertainty could occur in estimating the co2 plume particularly when both the correlation scale and variance of aquifer permeability are large determining the optimal deployment of co2 monitoring devices is thus more difficult under these conditions we then tested several monitoring network designs to obtain the optimal arrangement of co2 monitoring devices at a geologic storage site in this study the type of sensor is not specified it is simply assumed that the well containing the sensor is typically 10 m or 5 m from the top boundary the surface and that co2 leakage can be detected along the entire well length the following schemes were tested regular spacing deployment s1 pure random deployment s2 high permeability preferential deployment s3 the first derivative method s4 and second derivative method s5 the schemes used and the descriptions are summarized in table 2 in s1 a predetermined number 2 5 10 or 20 of monitoring devices were deployed with a regular spacing of 100 m given that the influenced surface area owing to geologic co2 storage is tens of kilometers in the actual three dimensional space 20 sensors the maximum number of sensors applied within a length of 2000 m is not a small number in s2 a predetermined number of the 400 uppermost cells were randomly selected for the deployment of monitoring devices and in s3 a predetermined number of locations with the highest rankings was selected for deployment based on the average permeability values up to the length of the observation well among 80 randomly chosen candidate locations s4 and s5 were strategies used to find permeability peaks and inflection points respectively and were based on the regressed surface from the permeability values at 80 randomly sampled locations simple kriging deutsch and journel 1998 was used in the regression the spatial correlation scale was assumed to be known from the sampled data therefore it was assumed that vertically averaged permeability information relating to the uppermost 10 m was available in s4 a predetermined number of locations with the lowest absolute permeability derivatives with respect to the horizontal direction divided by the permeability value were chosen as preferential locations for sensor deployment which was employed only to find the peak permeability value locations finally in s5 a predetermined number of locations with the lowest absolute values of the product of the permeability s first and second derivatives with respect to the horizontal direction were preferentially selected with this scheme a permeability transition zone with a slow change rate thick margin was found the scheme of s5 was developed on the basis of observed co2 migration pathways that were realized by the proposed model where the most frequent pathways were found to form along transition zones between high and low permeability values in equation form the optimal location for deployment of a co2 monitoring sensor using s4 and s5 corresponds respectively to x s 4 argmin x 1 k k ξ ξ x a n d x s 5 argmin x k ξ 2 k ξ 2 ξ x where k is the permeability and x s 4 and x s 5 are candidate sensor locations for s4 and s5 respectively table 3 summarizes the overall co2 gas detection statistics when applying the above sensor deployment schemes to the four scenarios 100 simulations per scenario at two different well depths of 5 m and 10 m to obtain the ensemble detection probability of each scheme 200 evaluations were performed per simulation in each evaluation a sequential process of randomly choosing 80 locations sampling the permeability and estimating the permeability distribution was repeated both the ensemble mean and standard deviation are provided in the table the overall mean values suggest the detectability of co2 leakage for individual sensors by applying a different monitoring design however the standard deviation provides information on uncertainty for individual sensors with respect to a particular design application of the tested deployment designs s1 was used as the reference scheme given the large number of evaluations it was expected that the ensemble mean of pure random deployment s2 would be close to that of s1 this was verified for both well depths of 5 m and 10 m as shown in table 3 however a comparison of s1 and s2 revealed that the ensemble standard deviation values of s2 were consistently larger than those of s1 the averages of ensemble mean values for s1 and s2 including c1 through c4 and well depths of 5 and 10 m were 0 0609 and 0 0607 respectively whereas the averages of the ensemble standard deviation values were 0 0427 and 0 0627 this observation suggests that the pure random scheme of s2 is less stable compared with the regular spacing scheme considering its effective deployment method for site wide co2 monitoring in many practical cases monitoring wells from initial survey boreholes are often selected on the basis of schemes s3 through s5 however it is interesting to observe that the ensemble mean values of s3 were consistently lower than those of the other schemes the averages of ensemble mean and standard deviation values were 0 0524 and 0 0951 for s3 respectively the ineffectiveness of s3 suggests that the simple selection of 20 locations of the randomly chosen 80 locations may not be an effective method for determining the locations of co2 monitoring sensors and should thus be avoided this finding also implies that a more systematic approach is necessary for designing an effective co2 leakage monitoring network than simply choosing higher permeability locations among multiple random locations to develop a more systematic monitoring network design permeability observations near the surface and their spatial relationships should be used therefore as an alternative to s3 we investigated whether the positions of peak permeability or the permeability transition zone based on s4 and s5 respectively could be selected to determine the best positions for installing co2 leakage monitoring sensors both schemes require spatial interpolation thus simple kriging was used the average ensemble mean value for s4 was 0 0666 which is slightly better than the reference case of s1 at 0 0609 however a vast increase in the uncertainty was noted regarding detectability between the average ensemble standard deviation values for s1 and s4 at 0 0427 and 0 1037 respectively the average ensemble mean value of s5 was 0 0773 which shows an improvement of about a 27 compared with s1 s5 consistently showed the highest ensemble mean value of all scenarios although the uncertainty with respect to the average ensemble standard deviation was also the highest at 0 1064 by this analysis alone it is difficult to conclude that s5 is more effective than the s1 reference method the simulations and computations imply that adopting the near surface spatial correlation of permeability when deploying monitoring sensors provides no promising improvement in the ability to detect co2 leakage as a result of the associated increased uncertainty as an alternative to the detection probability of individual sensors a successful detection rate across the monitoring network was evaluated by applying a design for detecting co2 leakage in this computation if at least one monitoring sensor in the network detected co2 leakage it was considered successful in addition four network designs with different numbers of sensors were compared including the use of 20 10 5 or 2 sensors at 100 m 200 m 400 m and 1000 m average intervals respectively table 4 summarizes the success rate of each scheme for each scenario the success rate of the regular spacing scheme of s1 was superior to that of the other schemes when 20 sensors were used in deployment with 20 sensors deployed the average success rates of s1 to s5 for all scenarios were 0 8975 0 6906 0 3035 0 4356 and 0 5497 respectively however a sensor deployment with short spatial interval is not practical yang et al 2011 considering the large surface area influenced by leaked co2 jones et al 2015 as the number of sensors decreased the average success rate of s1 showed a sharp decline fig 3 on the contrary the decline in success rate of designs s2 s5 was relatively moderate and was commonly higher than that of s1 when two sensors were used at an average interval of 1 km this observation suggests that s1 may be a better sensor network design when the sensor density per area is higher with a low spatial sensor density however a design that uses spatial permeability correlation particularly s5 can be considered as an alternative fig 4 includes example histograms based on scenario c1 and a well depth of 10 m using 20 sensors each graphic in the figure shows the detection ratio by a co2 leakage sensor the number of sensors detecting co2 leakage was divided by the total number of sensors x axis versus the frequency y axis obtained from 100 percolation realizations with 200 repeated sensor deployments in the figure a through e correspond to applications of monitoring network designs s1 s5 respectively fig 4 a shows that the detection ratio of s1 ranged from 0 to 0 35 where the ratio from 0 05 to 0 1 was the most frequent the limited detection ratio of s1 explains the lowest ensemble standard deviation table 3 the remaining designs had essentially similar ranges from 0 to 0 6 except for s2 which had an upper limit of 0 55 the general frequency distribution was skewed to a higher detection ratio among the designs a zero detection ratio was the least frequent in s1 followed by s2 and s5 this observation agrees with a successful detection ratio obtained throughout the sensor network for each specific design as shown in table 4 fig 5 shows histograms similar to those in fig 4 based on scenario c1 and a well depth of 10 m except that only five sensors were used in each sensor network the overall pattern of the frequency distributions was similar to that shown in fig 3 which was generally skewed to a higher detection ratio in the histograms the frequencies of the zero detection ratio were essentially similar whereas that for s5 fig 4 e was the lowest and that for s3 fig 4 c was the highest in terms of the detection ratio range that of s1 was the narrowest at 0 0 4 whereas that of the others was 0 0 8 of the latter the frequency reduction rate with an increase in the detection ratio was the slowest for s5 the overall results suggest that s1 is a stable design when using a large number of sensors whereas s5 can be used aggressively when the number of sensors is limited 4 summary and conclusions it is extremely difficult to determine the optimal deployment of co2 leakage monitoring sensors at geologic storage sites for two reasons co2 migration is highly sensitive to the subsurface heterogeneity and obtaining a detailed characterization of full scale aquifer heterogeneity is nearly impossible in this situation a statistical approach based on monte carlo simulation that considers the statistics of various parameters is a viable method for delineating as optimal monitoring design however multiphase flow simulation requires a large number of computational resources which are currently unavailable for this reason a rule based two dimensional percolation model that is similar to an invasion percolation model was developed in this study using various scenarios and monitoring networks multiple simulations were conducted and the sensor detection probabilities were compared although several idealized conditions were assumed the simulated co2 pathways showed intuitive migration patterns within the hypothetical aquifer with a heterogeneity in permeability using the developed rule based percolation method multiple simulations were then conducted using permeability field realizations based on an sgsim model with both short and long horizontal scales and small and large permeability variances according to the simulation results five different monitoring network designs were applied to obtain the ensemble detection probabilities of co2 surface leakage the results reveal the ineffectiveness of high permeability preferential deployment s3 that may be intuitively chosen as an effective monitoring network design because the permeability information near the surface is limited the results also demonstrated that the second derivative method s5 had the highest ensemble mean value among all schemes although it contains increased uncertainty with respect to the success rate across the monitoring network of a design applied to a particular site the regular spaced deployment of s1 proved to be the best strategy when a sufficient number of sensors is available with a decreased number of sensors however the success rate of s1 showed a dramatic drop and the advantages of the designs using spatial permeability correlation particularly s5 were more pronounced in summary permeability information near the surface including spatial correlation may be useful for optimizing the design of a co2 leakage monitoring network however the benefits are indirect and depend on the spatial density of the sensor optimizing the sensor configuration or predicting the leakage locations prior to an actual leakage incident is extremely difficult even if partial information is available near the surface of the co2 storage site this is because the migration pathway of co2 gas in an aquifer is affected by the complicated relationship of structures with different permeabilities whereas the near surface process may be less significant considering the uncertainties presented in this study it was found that simple deployment with regular spacing is the most relevant and robust method for detecting co2 leakage at a geologic storage site when the spatial density of the sensor is high contrarily if a limited number of sensors is used such as that in more realistic cases application of an aggressive monitoring design is required using all available information for this purpose the information of spatial permeability distribution near the surface can be used to configure a co2 leakage monitoring network as suggested in the present study however such aggressive designs can be accompanied by an increase in leakage detection uncertainty which will be investigated further in subsequent studies the methodology used in this study can be extended to other similar problems such as air sparging and steam assisted gravity drainage this study is a conceptual study that aims to provide information on improving a monitoring network design and the results are therefore not yet fully applicable for use in actual conditions the study needs to be extended into a three dimensional space to enable its practical usage and it is expected that the complicated relationship of structures with different permeabilities will exert a greater influence in three dimensional space nevertheless we consider that this study is valuable because it presents the potential to apply these results to a practical situation declaration of interests none acknowledgements all software programs were written in matlab the sample data used in this study are available upon request from the corresponding author egpark knu ac kr funding financial support for this study was provided by the korea environmental industry and technology institute project title development and field verification of environmental risk estimation system for co2 leakage project 2018001810004 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 02 042 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 supplementary data 6 supplementary data 7 
6570,we explored the feasibility of an improved design of a co2 leakage monitoring network at a geologic storage site to effectively represent co2 pathways a rule based percolation model was adopted rather than the rigorous multiphase flow model based on darcy s equation five different monitoring network designs were compared using a few scenarios and multiple correlated random field realizations the ensemble results showed that given the detection uncertainty across the entire sensor network regular spacing deployment of sensors is the most effective method when a sufficient number of sensors is available the results also showed that an aggressive monitoring design based on information of the spatial permeability distribution near the surface can be a viable method when a limited number of sensors is employed however such an aggressive design can lead to elevated uncertainty in leakage detectability keywords co2 leakage monitoring network design rule based percolation model co2 storage site monte carlo simulation 1 introduction a monitoring measurement and verification mmv plan is essential for ensuring safe co2 storage in geologic formations romanak et al 2012 as part of an mmv plan near surface monitoring is necessary at a co2 storage site to meet regulations reduce potential risk and obtain public acceptance leakage of injected co2 from a reservoir can have an adverse effect on the near surface environment however this occurrence can be reduced by establishing a site specific monitoring network design and by employing mitigation measures the optimal design for a near surface monitoring network is thus critical to successfully detect co2 and to enable the mmv plan to be used effectively yang et al 2017 chen et al 2018 therefore the goal of this study is to determine whether an optimal monitoring network design can be selected based on an understanding of near surface heterogeneity when co2 migrates from a reservoir into an overlying aquifer through unanticipated leakage pathways in the intervening low permeability layer a portion of the injected co2 may leak to the surface in the event of a small number of seepages independent processes such as buoyancy capillarity and pressure build up under a low permeability layer acting within the aquifer have a greater influence than the reservoir pressure gradient on gaseous phase co2 migration the co2 gas in an aquifer can migrate through a highly branched path that is substantially influenced by complexities in the localized heterogeneity of the constituent medium bryant et al 2008 saadatpoor et al 2010 to optimize the design of a monitoring network in consideration of the site characteristics it is essential to develop a model that reflects the detailed hydraulic properties of an aquifer including capillary entry pressure and permeability in addition a model that represents co2 movement in an aquifer must be able to reproduce the complicated migration patterns of gaseous co2 however obtaining detailed hydraulic properties of thick aquifers is technically impractical and co2 leakage locations are nearly impossible to predict furthermore previous studies have argued that a simulation of the preferential flow pathways of non wetting fluids based on darcy s law is computationally demanding when both the detailed capillarity and heterogeneity of parameters are considered meckel et al 2015 krishnamurthy et al 2017 moreover the computational time needs to be improved oldenburg et al 2016 under these considerations probabilistic approaches that rely on a large number of samples monte carlo simulations based on a practically executable simulation method are viable methods for designing a monitoring network for co2 leakage detection a practically executable simulation method can be used to avoid extreme computational time by using a few model simplification assumptions and by employing gaseous co2 macroscopic quasi static models such as a vertical equilibrium model gasda and nordbotten 2009 bandilla et al 2015 invasion percolation ip model cavanagh 2013 cavanagh and haszeldine 2014 or a rule based percolation rp model similar to that used by parker and park 2004 and park and parker 2005 although many similarities exist between the theories of ip and rp models the rule based model was chosen for this study as the practically executable simulation method because it can be more effectively incorporated with well defined macroscopic hydraulic parameters such as intrinsic and relative permeability effective saturation capillary pressure and mass flux several studies have provided useful tools for designing a monitoring network in a probabilistic framework cortis et al 2008 yang et al 2011 sun et al 2013a sun et al 2013b yang et al 2017 however few have focused on a sensor network design that reflects the heterogeneity of an aquifer which significantly affects the pathways of gaseous co2 this study introduces a conceptual procedure for designing co2 monitoring networks at geologic storage sites where only a portion of the near surface heterogeneity is assumed to be known a macroscopic rp model representing gaseous phase co2 migration pathways under a vertical equilibrium state in terms of mass flux is developed and several monitoring network designs are proposed finally the effectiveness of the monitoring network designs is validated through the ensemble statistics of multiple simulations based on subsurface heterogeneity realizations 2 model development a rule based percolation model fig 1 conceptually illustrates that co2 leaks to an aquifer through an imperfect caprock overlying a reservoir in which injected supercritical co2 was stored assuming that the pressure gradients between the reservoir and aquifer are not well connected a small portion of the co2 mass continuously leaks into the aquifer co2 enters as a gaseous phase immediately upon reaching the aquifer level under these circumstances 1 the density difference between co2 and water 2 a subsurface pressure buildup caused by the continuous supply of co2 gas and 3 air entry pressure heterogeneity caused by heterogeneous pore distributions are the controlling forces for co2 gas migration into the aquifer an equilibrium state is reached in the upward movement of co2 as it passes in a gaseous state through the aquifer from the lower aquifer to the surface it is assumed that a volume of the aquifer media with lower air entry pressure is more easily invaded by co2 gas without diffusion or dissolution of mass this assumption may be oversimplified however the dissolution of gaseous phase co2 into groundwater is considered to be the worst case in terms of surface co2 leakage nevertheless it should be noted that the lack of dissolution can be a favorable condition in terms of the detectability dissolution of co2 during lateral movement in the aquifer will attenuate the flux and will thus decrease its probability of being detected in an observation well however the investigation of this phenomenon is beyond the scope of the present study from this perspective co2 flux reduction within the unsaturated zone by dissolution and dispersion are also ignored to maximize co2 leakage at the surface however it is clear that the unsaturated zone could also have an important impact on the spatial leakage distribution owing to the effects of permeability heterogeneity the model developed below was used to determine the air entry pressure head where the water retention curve is defined by an empiric statistical approach van genuchten 1980 1 θ 1 1 α h n m where θ is the effective saturation given by θ θ θ r θ s θ r θ is the water content θ r is the residual water content θ s is the water content at saturation α l 1 is an empirical parameter describing the position of the maximum pore size distribution n and m 1 1 n are empirical parameters characterizing the width of the pore size distribution and h h 0 l is the capillary pressure head the air entry pressure head associated with the maximum pore size of the constituent medium is based on the tangential projection line from the inflection point of the retention curve to θ 1 which can be derived by taking the second derivative of eq 1 as follows 2 2 θ h 2 α n m n 2 h n 2 1 α h n m 2 α h n m where the first derivative of eq 1 is 3 θ h α n m n h n 1 1 α h n m 1 the inflection point can be obtained by equating the second derivative eq 2 to zero which results in h inf m 1 n α where the corresponding effective saturation is θ inf 1 1 m m at this point the slope of the tangential line σ is 4 σ α n m m 1 1 m m 1 and the equation for the tangential line is θ σ h h i θ inf therefore the modified van genuchten curve is given by 5 θ 1 1 α h n m 0 θ θ inf σ h h inf θ inf θ inf θ 1 from eq 5 the air entry pressure head h ae l becomes h ae h inf θ s θ inf σ in this study a small portion of trapped air is assumed θ s 0 99 to facilitate co2 gas invasion into the pores a detailed explanation of the above equations can be found in supplementary material i fig s1 the hydraulic head of the aquifer prior to the introduction of co2 gas is under an equilibrium state where the pressure value p ml 1t 2 follows p ρ w g ψ in which ρ w ml 3 is the density of water g lt 2 is gravitational acceleration and ψ l is the depth from the water table or pressure head if the co2 gas pressure head of a cell multiplied by the ratio of the density difference between co2 gas and water i e ρ w ρ c o 2 ρ w considering that the buoyancy exceeds the minimum required head of the neighboring cell i e ψ h ae the cell can be invaded by co2 gas to define the flow rate of co2 gas two dimensional darcy s law is employed as follows supplementary material i fig s2 6 h i h i 1 q k δ l δ r where h i l is the co2 gas pressure head of the percolated cell h i 1 l is the co2 head of the source cell q l2t 1 is the two dimensional co2 gas flow rate and δ l l is the length along the flow direction from the center of the source cell to the center of the percolated cell the length of the cell edge perpendicular to the flow direction which is denoted as δ r l can be either δ x or δ z depending on the flow direction where δ x and δ z are the horizontal and vertical discretization intervals respectively the hydraulic conductivity k lt 1 is given by k k s s k r s k s i k r i 2 where k s s and k s i are the saturated hydraulic conductivity of the source and invaded cells respectively and k r s and k r i are the relative permeability of the source and invaded cells respectively the relative permeability of a non wetting fluid co2 is given by 7 k r θ θ c o 2 1 2 1 1 θ c o 2 1 m m 2 a non zero relative permeability i e min k r 0 01 is assumed to promote co2 migration with respect to the two dimensional flow rate q the horizontal and vertical values are computed separately where the horizontal flow rate q h dissipates as the number of horizontally percolated cells increases and is defined as q h q sum n h 0 furthermore the vertical flow rate q v dissipates as the number of vertically percolated cells increases and is defined as q v q sum n h here q sum is the total flow rate introduced into the aquifer by the underlying reservoir n h 0 is the number of the periphery cells of a co2 lens in a layer and n h is the number of vertically percolated cells because the co2 gas is continuously supplied it is assumed that the co2 gas pressure head gradually increases until the invasion of an adjacent cell and follows the relationship h updated h old 2 δ h where δ h q k s k r sequential layer by layer computation is performed until the cumulative mass flux m n satisfies the condition m n q sum ρ n where 8 m n δ x δ z p n φ n i n 1 t k n h n h n 1 and ρ n is mean density of layer n the calculation of the corresponding layer is then terminated and that of the next layer begins in eq 8 p n is a density vector of gaseous co2 φ n is a porosity vector and i n 1 is an invasion indicator vector whereby the value is 1 if the cell is vertically invaded otherwise it is zero k n lt 1 is a vector representing the average hydraulic conductivity between layers n and n 1 and h n l is the co2 pressure head vector of the n th layer the permeability field is generated via sequential gaussian simulation sgsim by assuming that the values are spatially correlated random variables following a log normal distribution deutsch and journel 1998 for convenience in generating the van genuchten model parameter fields it is assumed that the values of α and n are perfectly correlated to the value of k s based on the following relationships α max p 3 α p 1 α log 10 k s p 2 α a n d n p 1 n k s p 2 n p 3 n which are fitting functions constructed on the basis of the corresponding statistical models proposed by carsel and parrish 1988 the fitting results for the random variables in the above functions are p 1 3 α 7 4 9 6 0 01 and p 1 3 n 0 93 0 31 1 1 these fitting results were used in all of our percolation simulations 3 results and discussion a two dimensional domain measuring 2000 100 m x and y discretized as 400 200 cells was used for the percolation simulations the corresponding spatially correlated permeability fields were generated by the sgsim model with a log normal distribution four different scenarios were considered during the generation of the permeability fields the first scenario c1 used correlation lengths of 1000 m and 10 m along the horizontal λ h and vertical λ v axes respectively and the log transformed mean log μ and variance log σ 2 of the permeability fields were targeted as 1 corresponding to 0 368 m day and 1 respectively in the second scenario c2 λ h λ v log μ and log σ 2 were set as 1000 m 10 m 1 and 4 respectively in the third scenario c3 λ h λ v log μ and log σ 2 were set as 200 m 10 m 1 and 1 respectively and in the fourth scenario c4 λ h λ v log μ and log σ 2 were set as 200 m 10 m 1 and 4 respectively these scenarios are summarized in table 1 for the two dimensional co2 flow rate a fictitious rate of 1 10 4 m2 day co2 was assigned to three central cells of the bottom layer in total 400 permeability fields were employed in our simulations with 100 percolation simulations for each scenario moreover no regional hydraulic gradient was assumed which justifies the lack of plume dissipation owing to dissolution in an equilibrium state representative results from the four different scenarios are shown in fig 2 and the remaining results are provided in supplementary material ii with 20 simulation results per scenario in fig 2 the filled red colored areas represent the simulated co2 plume in a quasi static condition and ramified pathways where c1 c2 and c3 c4 are respectively from identical correlated random fields with different permeability variances the background is a log transformed permeability field where yellow and blue indicate high and low permeability respectively in the figure c2 and c4 which have higher variances contain more divergent co2 pathways and are strongly affected by the juxtaposition of permeable spatial structures in contrast c1 and c3 contain less divergent pathways indicating that the spatial structures are less influenced by the relatively lower permeability contrasts among the structures in c2 which has a longer permeability correlation scale and higher permeability variance it is difficult for the co2 gas to find media having low air entry pressures in addition more pools with higher accumulation of co2 gas are present along the pathways which show high variance from the median pathway the less divergent patterns of c1 and c3 can be attributed to the lower variances in media permeability co2 gas does not build sufficient pressure along the pathways and its invasion is limited to media with relatively high permeability these observations along with the additional results provided in the supplementary material ii suggest that the spatial extent of surface co2 leakage pathways is approximately proportional to the horizontal correlation scale and the variance of the aquifer permeability the overall observations suggest that significant uncertainty could occur in estimating the co2 plume particularly when both the correlation scale and variance of aquifer permeability are large determining the optimal deployment of co2 monitoring devices is thus more difficult under these conditions we then tested several monitoring network designs to obtain the optimal arrangement of co2 monitoring devices at a geologic storage site in this study the type of sensor is not specified it is simply assumed that the well containing the sensor is typically 10 m or 5 m from the top boundary the surface and that co2 leakage can be detected along the entire well length the following schemes were tested regular spacing deployment s1 pure random deployment s2 high permeability preferential deployment s3 the first derivative method s4 and second derivative method s5 the schemes used and the descriptions are summarized in table 2 in s1 a predetermined number 2 5 10 or 20 of monitoring devices were deployed with a regular spacing of 100 m given that the influenced surface area owing to geologic co2 storage is tens of kilometers in the actual three dimensional space 20 sensors the maximum number of sensors applied within a length of 2000 m is not a small number in s2 a predetermined number of the 400 uppermost cells were randomly selected for the deployment of monitoring devices and in s3 a predetermined number of locations with the highest rankings was selected for deployment based on the average permeability values up to the length of the observation well among 80 randomly chosen candidate locations s4 and s5 were strategies used to find permeability peaks and inflection points respectively and were based on the regressed surface from the permeability values at 80 randomly sampled locations simple kriging deutsch and journel 1998 was used in the regression the spatial correlation scale was assumed to be known from the sampled data therefore it was assumed that vertically averaged permeability information relating to the uppermost 10 m was available in s4 a predetermined number of locations with the lowest absolute permeability derivatives with respect to the horizontal direction divided by the permeability value were chosen as preferential locations for sensor deployment which was employed only to find the peak permeability value locations finally in s5 a predetermined number of locations with the lowest absolute values of the product of the permeability s first and second derivatives with respect to the horizontal direction were preferentially selected with this scheme a permeability transition zone with a slow change rate thick margin was found the scheme of s5 was developed on the basis of observed co2 migration pathways that were realized by the proposed model where the most frequent pathways were found to form along transition zones between high and low permeability values in equation form the optimal location for deployment of a co2 monitoring sensor using s4 and s5 corresponds respectively to x s 4 argmin x 1 k k ξ ξ x a n d x s 5 argmin x k ξ 2 k ξ 2 ξ x where k is the permeability and x s 4 and x s 5 are candidate sensor locations for s4 and s5 respectively table 3 summarizes the overall co2 gas detection statistics when applying the above sensor deployment schemes to the four scenarios 100 simulations per scenario at two different well depths of 5 m and 10 m to obtain the ensemble detection probability of each scheme 200 evaluations were performed per simulation in each evaluation a sequential process of randomly choosing 80 locations sampling the permeability and estimating the permeability distribution was repeated both the ensemble mean and standard deviation are provided in the table the overall mean values suggest the detectability of co2 leakage for individual sensors by applying a different monitoring design however the standard deviation provides information on uncertainty for individual sensors with respect to a particular design application of the tested deployment designs s1 was used as the reference scheme given the large number of evaluations it was expected that the ensemble mean of pure random deployment s2 would be close to that of s1 this was verified for both well depths of 5 m and 10 m as shown in table 3 however a comparison of s1 and s2 revealed that the ensemble standard deviation values of s2 were consistently larger than those of s1 the averages of ensemble mean values for s1 and s2 including c1 through c4 and well depths of 5 and 10 m were 0 0609 and 0 0607 respectively whereas the averages of the ensemble standard deviation values were 0 0427 and 0 0627 this observation suggests that the pure random scheme of s2 is less stable compared with the regular spacing scheme considering its effective deployment method for site wide co2 monitoring in many practical cases monitoring wells from initial survey boreholes are often selected on the basis of schemes s3 through s5 however it is interesting to observe that the ensemble mean values of s3 were consistently lower than those of the other schemes the averages of ensemble mean and standard deviation values were 0 0524 and 0 0951 for s3 respectively the ineffectiveness of s3 suggests that the simple selection of 20 locations of the randomly chosen 80 locations may not be an effective method for determining the locations of co2 monitoring sensors and should thus be avoided this finding also implies that a more systematic approach is necessary for designing an effective co2 leakage monitoring network than simply choosing higher permeability locations among multiple random locations to develop a more systematic monitoring network design permeability observations near the surface and their spatial relationships should be used therefore as an alternative to s3 we investigated whether the positions of peak permeability or the permeability transition zone based on s4 and s5 respectively could be selected to determine the best positions for installing co2 leakage monitoring sensors both schemes require spatial interpolation thus simple kriging was used the average ensemble mean value for s4 was 0 0666 which is slightly better than the reference case of s1 at 0 0609 however a vast increase in the uncertainty was noted regarding detectability between the average ensemble standard deviation values for s1 and s4 at 0 0427 and 0 1037 respectively the average ensemble mean value of s5 was 0 0773 which shows an improvement of about a 27 compared with s1 s5 consistently showed the highest ensemble mean value of all scenarios although the uncertainty with respect to the average ensemble standard deviation was also the highest at 0 1064 by this analysis alone it is difficult to conclude that s5 is more effective than the s1 reference method the simulations and computations imply that adopting the near surface spatial correlation of permeability when deploying monitoring sensors provides no promising improvement in the ability to detect co2 leakage as a result of the associated increased uncertainty as an alternative to the detection probability of individual sensors a successful detection rate across the monitoring network was evaluated by applying a design for detecting co2 leakage in this computation if at least one monitoring sensor in the network detected co2 leakage it was considered successful in addition four network designs with different numbers of sensors were compared including the use of 20 10 5 or 2 sensors at 100 m 200 m 400 m and 1000 m average intervals respectively table 4 summarizes the success rate of each scheme for each scenario the success rate of the regular spacing scheme of s1 was superior to that of the other schemes when 20 sensors were used in deployment with 20 sensors deployed the average success rates of s1 to s5 for all scenarios were 0 8975 0 6906 0 3035 0 4356 and 0 5497 respectively however a sensor deployment with short spatial interval is not practical yang et al 2011 considering the large surface area influenced by leaked co2 jones et al 2015 as the number of sensors decreased the average success rate of s1 showed a sharp decline fig 3 on the contrary the decline in success rate of designs s2 s5 was relatively moderate and was commonly higher than that of s1 when two sensors were used at an average interval of 1 km this observation suggests that s1 may be a better sensor network design when the sensor density per area is higher with a low spatial sensor density however a design that uses spatial permeability correlation particularly s5 can be considered as an alternative fig 4 includes example histograms based on scenario c1 and a well depth of 10 m using 20 sensors each graphic in the figure shows the detection ratio by a co2 leakage sensor the number of sensors detecting co2 leakage was divided by the total number of sensors x axis versus the frequency y axis obtained from 100 percolation realizations with 200 repeated sensor deployments in the figure a through e correspond to applications of monitoring network designs s1 s5 respectively fig 4 a shows that the detection ratio of s1 ranged from 0 to 0 35 where the ratio from 0 05 to 0 1 was the most frequent the limited detection ratio of s1 explains the lowest ensemble standard deviation table 3 the remaining designs had essentially similar ranges from 0 to 0 6 except for s2 which had an upper limit of 0 55 the general frequency distribution was skewed to a higher detection ratio among the designs a zero detection ratio was the least frequent in s1 followed by s2 and s5 this observation agrees with a successful detection ratio obtained throughout the sensor network for each specific design as shown in table 4 fig 5 shows histograms similar to those in fig 4 based on scenario c1 and a well depth of 10 m except that only five sensors were used in each sensor network the overall pattern of the frequency distributions was similar to that shown in fig 3 which was generally skewed to a higher detection ratio in the histograms the frequencies of the zero detection ratio were essentially similar whereas that for s5 fig 4 e was the lowest and that for s3 fig 4 c was the highest in terms of the detection ratio range that of s1 was the narrowest at 0 0 4 whereas that of the others was 0 0 8 of the latter the frequency reduction rate with an increase in the detection ratio was the slowest for s5 the overall results suggest that s1 is a stable design when using a large number of sensors whereas s5 can be used aggressively when the number of sensors is limited 4 summary and conclusions it is extremely difficult to determine the optimal deployment of co2 leakage monitoring sensors at geologic storage sites for two reasons co2 migration is highly sensitive to the subsurface heterogeneity and obtaining a detailed characterization of full scale aquifer heterogeneity is nearly impossible in this situation a statistical approach based on monte carlo simulation that considers the statistics of various parameters is a viable method for delineating as optimal monitoring design however multiphase flow simulation requires a large number of computational resources which are currently unavailable for this reason a rule based two dimensional percolation model that is similar to an invasion percolation model was developed in this study using various scenarios and monitoring networks multiple simulations were conducted and the sensor detection probabilities were compared although several idealized conditions were assumed the simulated co2 pathways showed intuitive migration patterns within the hypothetical aquifer with a heterogeneity in permeability using the developed rule based percolation method multiple simulations were then conducted using permeability field realizations based on an sgsim model with both short and long horizontal scales and small and large permeability variances according to the simulation results five different monitoring network designs were applied to obtain the ensemble detection probabilities of co2 surface leakage the results reveal the ineffectiveness of high permeability preferential deployment s3 that may be intuitively chosen as an effective monitoring network design because the permeability information near the surface is limited the results also demonstrated that the second derivative method s5 had the highest ensemble mean value among all schemes although it contains increased uncertainty with respect to the success rate across the monitoring network of a design applied to a particular site the regular spaced deployment of s1 proved to be the best strategy when a sufficient number of sensors is available with a decreased number of sensors however the success rate of s1 showed a dramatic drop and the advantages of the designs using spatial permeability correlation particularly s5 were more pronounced in summary permeability information near the surface including spatial correlation may be useful for optimizing the design of a co2 leakage monitoring network however the benefits are indirect and depend on the spatial density of the sensor optimizing the sensor configuration or predicting the leakage locations prior to an actual leakage incident is extremely difficult even if partial information is available near the surface of the co2 storage site this is because the migration pathway of co2 gas in an aquifer is affected by the complicated relationship of structures with different permeabilities whereas the near surface process may be less significant considering the uncertainties presented in this study it was found that simple deployment with regular spacing is the most relevant and robust method for detecting co2 leakage at a geologic storage site when the spatial density of the sensor is high contrarily if a limited number of sensors is used such as that in more realistic cases application of an aggressive monitoring design is required using all available information for this purpose the information of spatial permeability distribution near the surface can be used to configure a co2 leakage monitoring network as suggested in the present study however such aggressive designs can be accompanied by an increase in leakage detection uncertainty which will be investigated further in subsequent studies the methodology used in this study can be extended to other similar problems such as air sparging and steam assisted gravity drainage this study is a conceptual study that aims to provide information on improving a monitoring network design and the results are therefore not yet fully applicable for use in actual conditions the study needs to be extended into a three dimensional space to enable its practical usage and it is expected that the complicated relationship of structures with different permeabilities will exert a greater influence in three dimensional space nevertheless we consider that this study is valuable because it presents the potential to apply these results to a practical situation declaration of interests none acknowledgements all software programs were written in matlab the sample data used in this study are available upon request from the corresponding author egpark knu ac kr funding financial support for this study was provided by the korea environmental industry and technology institute project title development and field verification of environmental risk estimation system for co2 leakage project 2018001810004 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 02 042 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 supplementary data 4 supplementary data 5 supplementary data 6 supplementary data 7 
6571,cave monitoring is crucial for the interpretation of climatic and environmental significances of various geological proxies in speleothem therefore the hydrochemical and stable isotopic compositions δ18o δd mg ca sr ca and ba ca of karst cave waters during 2005 2016 ce were constantly monitored in furong cave chongqing city southwest china a comparison with local hydrological conditions led to 4 main conclusions as follows 1 the mg ca ratio is significantly responsive to the changes in drought wet conditions outside the cave which increased in drought years and decreased in wet years respectively seasonal variation of sr ca is more significant than those of mg ca and ba ca ratios 2 prior calcite precipitation pcp incongruent calcite dissolution icd water rock interaction wri and pco2 of soil and cave air may account for the changes in trace element ratios in the epikarst which resulted in a complex variation of element ratios in the cave drip water in general wri in drought years is stronger than that in wet years and that in low discharge sites is stronger than in high discharge sites seasonal variation of ca2 concentration induced by pcp exerts significant impact on the evolution of sr ca ratio in drip water 3 δ18o and δd of drip water are influenced by the mixing effect leading to the result that their seasonal variations are less significant than that of precipitation 4 at least in the study period the ratios of trace elements in the drip water in furong cave mainly reflected the variations of local hydrological conditions drought or wet dominated by precipitation because of the mixing effect of groundwater high resolution δ18o record e g seasonal and annual of speleothem in furong cave may not be recommendable however the δ18o is potentially a reliable proxy in speleothems to record the change of rainfall on decadal and longer timescales keywords drip water trace element ratios stable isotopes pcp icd wri rainfall 1 introduction as geological carriers for paleoclimate change speleothems are mostly composed of calcium carbonate with multiple proxies such as δ18o δ13c and trace element ratios these proxies were used for the reconstruction of paleorainfall paleovegetation paleohydrogeology and paleoenvironment roberts et al 1998 lauritzen and lundberg 1999 wang et al 2001 2008 yuan et al 2004 johnson et al 2006 fairchild and treble 2009 cheng et al 2009 2012 2016 jo et al 2010 wong and breecker 2015 owing to the fact that controlling factors of the proxies of speleothem are numerous and complex interpretation of climate information based on these proxies is controversial mcdermott et al 1999 fairchild et al 2006 however cave drip water a signal transmitter between speleothems and external climate environment is of great significance to explore the depositional mechanism of speleothem and interpret the climate information from various proxies tooth and fairchild 2003 oster et al 2012 the negative isotope excursion with the increased precipitations namely amount effect have been widely accepted in the communities of paleoclimate dansgaard 1964 however many studies also have suggested that a direct link between the speleothem δ18o records and precipitation is debatable liu et al 2015 found that the strongest period of the east asian summer monsoon easm occurred in the early holocene period referred from the chinese speleothem δ18o record challenging the view of mid holocene easm maximum based on lakes loess and pollen records from northern china and all of these holocene chinese speleothem δ18o records also exhibited a similar trend of variation indicating a common climate signal e g rainfall or asian summer monsoon intensity however the instrumental data and models indicated a significant different spatial variation in rainfall between northern and southern china liu et al 2015 therefore it is believed that the speleothem δ18o cannot represent the changes in intensity of easm accurately liu et al 2015 2017 on the other hand inconsistency between speleothem δ18o records and solar radiation in northern hemisphere have been noted and clemens et al suggested that the speleothem δ18o in the asian monsoon region may not be a simple proxy for the intensity of summer monsoon which may also reflect the changes in moisture sources and transport pathway clemens et al 2010 some studies have presented that on interannual to decadal timescales the δ18o and δd values of precipitation were significantly affected by the changes in moisture sources which could be attributed to the changes in atmospheric circulation such as el niño southern oscillation enso tan 2014 2016 recorded changes in asian summer monsoon asm intensity and the effect of rainfall in the upper reaches on moisture source yang et al 2016 the trace elements in cave water mainly come from bedrock and soil zhou et al 2009 2012 a series of physical and chemical processes in epikarst including water rock interaction wri prior calcite precipitation pcp incongruent calcite dissolution icd mixing of old and fresh water and dilution effects by fracture water in the bedrock may affect the changes in trace element ratios in cave drip water and speleothem tooth and fairchild 2003 spötl et al 2005 sherwin and baldini 2011 the above mentioned factors which may affect the changes of trace element ratios in drip water have direct or indirect links with precipitation the combination of δ18o and trace element ratios is important for the reconstruction of paleoclimate based on speleothems oster et al 2012 however there is a lack of testing with long time monitoring data for whether or not the δ18o or trace element ratios can reflect the changes in precipitation in this paper we summarized the 12 year monitoring work in furong cave southwest china and presented a comprehensive analysis on the interannual and seasonal variation of trace element ratios δ18o and δd of drip water combined with the changes in atmospheric circulation characterized by enso and the changes in local temperature and precipitation we discussed the response of δ18o δd and trace element ratios of drip water to external climate signals this paper is mainly focused on the following scientific questions 1 are there any difference between the responses of element ratios and isotopic compositions of cave drip water corresponding to the external environment 2 whether or not the change of elements ratios made response to extreme flood and drought events outside furong cave which is covered by 300 500 m thick bedrock 3 whether or not drip water δ18o values preserve high resolution e g seasonal annual signals from meteoric precipitation note that the 300 to 500 m aquifer zone above furong cave is far thicker than other monitoring caves in easm region such as xianren cave 40 140 m liangfeng cave 80 140 m shihua cave 30 130 m and so on luo and wang 2008 cai et al 2010 duan et al 2012 exhibiting some differences in hydrochemical characteristics and stable isotopic compositions of drip waters in furong cave one of the most important reasons is the different residence time of ground water for each cave because of the different thickness of overlying bedrock data interpretations for short monitoring durations are complicated by mostly unknown water transit times through the karst our exceptionally long monitoring work allows comparing confidently with hydrological factors related to rainfall changes and variations in the epikarst in addition previous studies commonly analyzed single indicator in drip water e g δ18o element ratios or δ13c li et al 2011 2012 duan et al 2016 li and li 2018 but comprehensive studies combining δ18o and trace element ratios are rarely reported the main objective of this study is to distinguish the climate implications of the multiple proxies e g δ18o and trace element ratios in cave drip water we do believe that the inferences of this long monitoring study are significant for the interpretation of climatic implications of the proxies in speleothems 2 study area 2 1 physical geography background chongqing is located in the southwest region of china the local climate is characterized by the subtropical humid monsoon climate which is dominated by east asian summer monsoon easm and indian summer monsoon ism in the summer months and by asian winter monsoon awm in the winter months fig 1 a furong cave 29 14 n 107 55 e is located in wulong county chongqing city on the east bank of furongjiang river a branch of yangtze river furong cave developed in the middle cambrian dolomite limestone strata and the local topography is characterized by a typical steep karst gorge li et al 2011 the altitude at the entrance of furong cave is approximately 480 m above the sea level a s l appendix fig 1b and the main tunnel is approximately 2800 m in length 30 50 m in height and 2 30 m in width furong cave belongs to tianxing furong cave karst system which is a typical karst area of carbonate aquifer characterized by high permeability to absorb store and transmit precipitation zhu et al 2007 another hydrogeological feature is that the 300 500 m thick aquifer zone above furong cave leads to numerous complex flow paths of groundwater li et al 2011 the relative humidity of cave air is close to 95 100 and the average temperature is 16 16 3 c in the inner chamber of furong cave li et al 2011 in the 12 year monitoring period from 2005 to 2016 the average annual rainfall was 1079 mm outside furong cave in general in the rainy season from april to october every year the precipitation accounted for over 85 of the total precipitation and the annual average temperature was 17 9 c outside furong cave fig 2 h 2 2 monitoring sites five soil co2 monitoring sites namely sa sb sc sd and se were set up along both sides of the valley overlying furong cave appendix fig 1a li et al 2012 li and li 2018 the pipelines for soil co2 monitoring were buried in the soil profiles at the depth of 50 cm six drip water monitoring sites dw1 mp1 mp2 mp3 mp4 and mp5 were set up in furong cave fig 1c li et al 2011 dw1 and mp1 were 3 m apart with the drip height being approximately 22 m split into multi drip during the process of falling drip site mp2 was located on the top of a speleothem 2 m in height with the falling height being 27 m mp3 was on the cavity wall with a short soda straw stalactite as the outlet and the drip height was approximately 30 cm li et al 2011 mp4 and mp5 were approximately 1 5 m apart with each other and the drip heights were 14 m and 13 m respectively li et al 2012 the deposition rates of active sediments were 0 87 5 69 0 71 5 31 and 4 13 mg day respectively at the five drip water monitoring sites mp1 mp2 mp3 mp4 and mp5 huang et al 2015 3 data and methods 3 1 meteorological data during the period of year 2005 2016 a portable meteorological station was set up outside furong cave to collect meteorological data precipitation was recorded using an automatic rainfall monitoring instrument rg3 m onset usa at a frequency of once every 2 min with the precision being 1 0 the air temperature was continuously recorded at 2 h intervals by the u12 011 temperature recorder onset usa with an error of 0 1 c the monthly average rainfall and air temperature outside furong cave were calculated on the basis of the recorded meteoric data which were downloaded via the hobo software every month the drought years and the wet years were distinguished according to the precipitation anomaly percentage which was calculated as follows 1 dp p p p 100 where dp is the percentage of precipitation anomaly p is the annual precipitation in the year and p is the average multi year precipitation classification of drought and wet years was based on the dp value a year with the dp value being less than or equal to 15 was defined as a drought year and that with a dp value being above or equal to 15 was defined as a wet year wei et al 2017 according to the principles of climate statistics in the china monsoon region a year is divided into four seasons as spring march may summer june august autumn september november and winter december february of the following year deng et al 2017 enso frequently occurs with changes in the large scale atmospheric circulation the indexes of the sea surface temperature anomaly ssta of the niño 3 4 zone 5 n 5 s 170 w 120 w are commonly used to define enso ropelewski and jones 1987 trenberth 1997 according to the definition by the national oceanic and atmospheric administration usa if the three month sliding average of ssta in the niño 3 4 zone is 0 5 c 0 5 c and lasts for five consecutive months the event can be defined as an el niño la niña event the ssta values of the niño 3 4 zone were downloaded from the following official websites http www cpc ncep noaa gov data indices sstoi indices ssta 3 2 stable isotopic composition of rainwater on the basis of the principles of global network of isotopes in precipitation drafted by international atomic energy agency https nucleus iaea org wiser index php rainwater samples for stable isotope analyses were collected outside of furong cave during the period from may 2006 to september 2016 approximately 1 cm thick liquid paraffin was filled into the rainwater collection barrel to prevent the evaporation in addition foam insulation and tinfoil paper were used to cover the barrel to prevent the effect of solar radiation on the chemical composition of rainwater the collected rainwater was regularly sampled at the end of each month and then preserved in a refrigerator at 5 c next 5 ml water samples were taken from these samples to evaluate the stable hydrogen and oxygen isotopic compositions 3 3 stable isotopic compositions and trace element ratios of drip water drip water samples were collected during the period of october 2005 to september 2016 the sites of dw1 and mp3 were monitored from october 2005 to september 2016 and the other drip sites were monitored from october 2008 to september 2016 polyethylene bottles and caps for sample collecting were boiled for 5 h in a 1 5 vol ratio of nitric acid then washed with ultra pure water and dried out naturally in an ultra clean room bench class 100 clean for each monitoring site 50 ml of drip water was filtered through pre washed 0 45 µm millipore nitrocellulose filters packaged in a cleaned polyethylene bottle and acidified to ph 2 0 by adding a trace level of ultrapure hno3 1 1 volume ratio for the analyses of trace elements the concentrations of cations ca2 mg2 ba2 and sr2 were measured with the optima 2100dv inductively coupled plasma emission spectrometer icp oes perkin elmer usa the detection limit was 1 µgl 1 and the analytical error was 2 the collection and analytical methods of the deposition rate and trace element compositions of the active deposits under the monitored drip water referred to huang et al 2015 furthermore 5 ml of drip water for the analysis of δ18o δd was collected and stored in the refrigerator at 5 c the isotopic composition δ18o δd of the rainwater and drip water samples was determined with a liquid water isotope analyzer lwia dlt 100 los gatos research usa 1 5 ml volumes of water samples were analyzed 6 times and the average of the last four measurements was used to calculate the value of the measured sample lgr3a lgr4a lgr5a los gatos research usa were used as reference standards to be cross checked the analytical absolute error for δ18o was 0 2 and 0 5 for δd the result of δ18o δd was presented as the relative value to vienna standard mean ocean water v smow value zhou and li 2017 δ 18 o 18o 16 o sample 18o 16o v smow 18 o 16 o v smow 10 3 δ d d h sample d h v smow d h v smow 10 3 3 4 discharge of drip water and pco2 of soil and cave air during the period from january 2010 to september 2016 20 ml cylinders were used to measure the discharge of drip water ml min the variation in the cave air pco2 concentration was monitored near the drip water sites mp1 mp4 with a handheld testo 535 co2 monitor made in germany the measuring range was 0 9999 ppm for the instrument and the resolution was higher than 1 ppm with an error of 2 there were no measured pco2 data for dw1 and mp5 because the distance between dw1 and mp1 was merely 3 m and the distance between mp4 and mp5 was only 1 5 m fig 1c during the period from july 2010 to september 2016 co2 concentration of soil air was monitored above furong cave appendix fig 1a soil air was pumped out by the collector ap 20 and the co2 concentration of soil air was determined by the detector tube 126sa komyokk japan with a precision of 100 ppm 4 model of pcp icd and wri according to mg ca and sr ca ratios of the active cave sediments and drip water trace element distribution coefficients of kdmg and kdsr between h2o and caco3 could be calculated morse and bender 1990 huang and fairchild 2001 day and henderson 2013 the specific calculation formulas are as follows 2 kd mg mg ca crystal mg ca solution 3 kd sr sr ca crystal sr ca solution where kdmg and kdsr are the distribution coefficients of mg and sr respectively the processes of pcp icd and wri in the epikarst zone may influence the ratios of mg ca and sr ca in drip water roberts et al 1998 tremaine and froelich 2013 casteel and banner 2015 before the groundwater reached the ceiling of the cave to form drip water carbonate was deposited in the epikarst zone along with the degassing of co2 wong et al 2011 during the process of deposition ca2 deposited preferentially over mg2 and sr2 which contributed to the reduction of ca2 in the drip water and increased the mg ca and sr ca ratios in the drip water and the speleothem tremaine and froelich 2013 this hydrochemical process has been defined as pcp morse and bender 1990 huang and fairchild 2001 day and henderson 2013 icd is another interaction between calcite and water which takes place as the elements mg2 and sr2 dissolve preferentially into solution relative to ca2 fairchild et al 2000 sinclair 2011 sinclair et al 2012 casteel and banner 2015 particularly on the fresh surface of the calcite mineral brantley 2008 it also results in an increase in mg ca and sr ca for speleothems and drip water an obvious positive correlation between mg ca and sr ca may be associated with pcp and icd because either pcp preferential precipitation of ca2 or icd preferential dissolution of mg2 and sr2 may increase the mg ca and sr ca ratios pcp and icd are indistinguishable in the epikarst sinclair et al 2012 casteel and banner 2015 in this article these two processes are combined as pcp icd in contrast wri generally indicates the recrystallization of calcite dolomite or the incongruent dissolution of dolomite even with the effect of pcp icd wri may result in an increase in mg ca and sr ca ratios of the solution fairchild et al 2000 musgrove and banner 2004 wong et al 2011 on the basis of kdmg and kdsr sinclair proposed the pcp icd wri model for mg ca and sr ca ratios of drip water utilizing the value of kdsr 1 kdmg 1 to assess the different effects of pcp icd and wri on drip water with groundwater passing through the epikarst zone sinclair 2011 sinclair et al 2012 simulation results indicated that when the residence time of groundwater in the epikarst zone was relatively short t 0 the slope of ln sr ca versus ln mg ca for drip water tended to be close to the value of kdsr 1 kdmg 1 fig 5 in sinclair 2011 and the drip water was obviously influenced by pcp icd in contrast with an increase in the residence time of groundwater the slope of ln mg ca versus ln sr ca got closer to zero and the drip water was mainly influenced by wri fig 5 in sinclair 2011 on the basis of the values of kdsr and kdmg presented by banner 1995 and huang and fairchild 2001 sinclair proposed a possible range of kdsr 1 kdmg 1 0 709 1 003 sinclair et al 2012 the model results showed that the slopes of ln mg ca versus ln sr ca falling in the range of kdsr 1 kdmg 1 of 0 709 1 003 proving the leading role of pcp icd processes when the groundwater passing through the epikarst zone to form drip water sinclair et al 2012 casteel and banner 2015 in contrast mixed wri and pcp icd processes were indicated by slopes under 0 709 lower slope reflected stronger wri sinclair 2011 sinclair et al 2012 on the basis of the above mentioned conclusions casteel and banner monitored texas cave usa and noted significant differences in the effects of pcp icd and wri between the high discharge sites and the low discharge sites casteel and banner 2015 in addition tadros et al found obvious differences in the effects of pcp icd and wri between the drought years and the wet years in harrie wood cave australia tadros et al 2016 5 results 5 1 annual rainfall and discharge of drip water the average annual precipitation outside of furong cave was 1079 mm during the period of 2005 2016 the annual precipitations in year 2006 2009 and 2011 were 850 751 and 847 mm respectively which were 229 328 and 232 mm lower than the 12 year average value respectively in contrast the dp values were 27 44 and 27 respectively which were lower than 15 accordingly the three years were classified as drought the annual precipitations of 2007 and 2016 were 1352 and 1498 mm respectively which were 273 and 419 mm higher than 1079 mm respectively at the same time the dp values were 20 and 27 respectively which were higher than 15 these two years were classified as wet the precipitations of the other years were relatively close to the 12 year average value and thus these years were classified as normal fig 2a and h the average discharge monitored at the six drip water sites dw1 and mp1 mp5 in furong cave were 8 7 11 7 20 4 9 1 3 and 0 7 ml min respectively appendix table 1 with the discharge of 8 ml min as the standard the six drip water sites were divided into high discharge sites dw1 mp1 and mp2 and low discharge sites mp3 mp4 and mp5 the standard deviation sd of the discharge at the high discharge sites was higher than that at the low discharge sites appendix table 1 indicating that the high discharge sites responded more sensitively to the external climatic situation moreover the discharge at different drip water sites varied considerably which can be attributed to the differences in the thickness of overlying strata and the flow path of groundwater through the epikarst zone huang et al 2016 at the same time the discharge of mp2 site exhibited a relative remarkable response to external precipitation appendix fig 2d and e which presented in high discharge corresponding to local precipitation indicating less residence time compared with others drip sites huang et al 2016 5 2 mg ca sr ca and ba ca of drip water the mg ca values for all drip water samples dw1 and mp1 mp5 are summarized in table 1 although no clear seasonal characteristics were identified fig 2b the mg ca values in the winter season were higher than that in the summer season fig 3 a the variation ranges for 1000 sr ca and for all the drip water monitoring sites dw1 and mp1 mp5 were 0 55 1 11 table 1 seasonal characteristics were observed for the changes of 1000 sr ca for all drip water samples with higher values in winter and spring and lower values in summer and autumn except for the winter of 2010 2011 fig 2c on the other hand the average value of drip water 1000 sr ca in summer was lower than that in winter for all drip water sites fig 3b which also confirmed the seasonal changes in 1000 sr ca a similar trend was observed for the change in 1000 ba ca for the drip water at all sites but the absolute values were considerably different among these monitoring sites for example the average value of 1000 ba ca for mp1 was approximately three times that for mp3 table 1 and fig 2d 5 3 δ18o and δd in meteoric water and drip water the δ18o of precipitation exhibited an obvious seasonal variation with lighter values in summer and heavier values in winter fig 2e based on δ18o and δd values of the rainwater samples outside furong cave the equation of the local meteoric water line lmwl was δd 9 06δ18o 20 44 and the correlation coefficient was r 0 99 p 0 01 fig 4 the δ18o and δd values of drip water dw1 and mp1 mp5 changed in the range from 8 9 to 4 3 and from 51 2 to 38 1 respectively table 1 which were distributed around the lmwl indicating that the drip water preserved the isotopic signal of precipitation fig 4 5 4 calculation results of pcp icd and wri model the kdmg and kdsr values of active sediments drip water system in furong cave during 2009 2016 were calculated using equations 1 and 2 the ranges of kdmg and kdsr were 0 02 0 09 and 0 04 0 31 with the average value being 0 03 and 0 16 respectively thus we calculated the value of kdsr 1 kdmg 1 for the drip water in furong cave it fluctuated in the range of 0 727 0 988 falling within the predicted range of 0 709 1 003 from sinclair et al 2012 appendix fig 3 in general for all drip water samples in furong cave the slope of ln mg ca versus ln sr ca varied from 0 17 to 0 39 fig 5a and b the slopes of ln mg ca versus ln sr ca in wet year and drought year are 0 31 and 0 24 respectively and a reduced slope of ln mg ca versus ln sr ca was found in drought years fig 5 c 6 discussions 6 1 causes for the change of trace element ratios the changes of mg ca ratio in drip water responded to the changes in local hydrological conditions drought and wet on interannual scale fig 2b during the drought years 2006 2009 and 2011 with decreased precipitation fig 2a more trace elements were dissolved from the bedrock because of the extended residence time of groundwater and enhanced wri in general dissolution of calcite was faster than that of dolomite with enhanced wri more dolomite dissolved and more mg2 released into groundwater fairchild et al 2000 in addition the occurrence of pcp with preferential deposition of ca2 relative to mg2 and sr2 also resulted in a higher mg ca ratio karmann et al 2007 wong et al 2011 tremaine and froelich 2013 casteel and banner 2015 in contrast in wet years with increased precipitation 2007 and 2016 fig 2a groundwater penetrated rapidly shortening the time of wri what s more accelerated bedrock dissolution resulted from higher contribution of rainwater can increase the concentration of metal ions with more increase of ca2 compared to mg2 and finally lead to lower mg ca fig 2b in theory the distribution coefficient of mg between solution and calcite was mainly determined by temperature mucci and morse 1983 morse and bender 1990 therefore the cave temperature was also considered as a potential factor for the evolution of the mg ca ratio in the drip water gascoyne 1983 huang and fairchild 2001 however air temperature in furong cave was stable at 16 0 16 3 c li et al 2011 therefore air temperature in furong cave was not a main reason for the evolution of mg ca ratio in drip water in summary changes in precipitation and wri were the main reasons for the evolution of mg ca ratio of drip water in dry and wet years correlation coefficients r between the concentration of ca2 and 1000 sr ca and that between the concentration of sr2 and 1000 sr ca of the drip water in furong cave were 0 52 p 0 01 and 0 22 p 0 01 respectively fig 6 c and 6d which indicated that the change of 1000 sr ca was mainly controlled by the concentration of ca2 the occurrence of pcp during the drought months of winter and spring with the deposition of ca2 accounted for the increase in 1000 sr ca in drip water the pco2 of cave air was also an important factor for the evolution of 1000 sr ca ratio in drip water burton and walter 1991 banner et al 2007 wong et al 2011 sherwin and baldini 2011 treble et al 2015 in summer months the average values of soil air co2 concentrations at five monitoring sites sa sb sc sd se above furong cave were 7974 8096 7286 5028 8524 ppm respectively and the cave air co2 concentrations at four monitoring sites mp1 mp2 mp3 mp4 in furong cave were 1390 1523 1537 and 1386 ppm respectively in contrasts in winter months the average values of soil air co2 concentrations at the five monitoring sites were 1481 1793 592 898 662 ppm and the cave air co2 concentrations at four monitoring sites mp1 mp2 mp3 mp4 in furong cave were 1071 1045 1115 1209 ppm respectively monitoring results showed a significant seasonal variation of air pco2 in the soil and cave air which was higher in summer months and lower in winter months the change in cave air pco2 lagged by 1 2 months compared with that in soil appendix fig 2a and b li and li 2018 in addition an obvious correlation was observed between cave air pco2 and soil co2 except for sc mp1 and se mp3 appendix table 2 indicating that the change in cave air pco2 was mainly controlled by soil co2 li and li 2018 with an increase of precipitation in summer months enhanced biological activities led to massive soil co2 entering the cave through groundwater and fissures resulting in an increase in pco2 of cave air breecker et al 2012 meyer et al 2014 the increase in cave air pco2 depressed the degassing of co2 from the cave water and the deposition of speleothem baldini et al 2008 which also led to a lower 1000 sr ca and mg ca ratios in drip water appendix fig 2a 2b 2c fig 3 a previous study showed that 1000 ba ca in soil and bedrock above furong cave presented a significant spatial variation and changed in the range of 4 27 59 28 and 0 04 0 25 respectively xiang et al 2011 three types of flow patterns namely conduit flow fissure flow and seepage flow have been observed when the groundwater migrates through the vadose zone baldini et al 2006 the migration rate was considerably different for these three types of flows resulting in different residence time of the groundwater in the bedrock and the soil finally leading to different dissolution rate of minerals from the soil and the bedrock fairchild et al 2006 and obviously different values of 1000 ba ca for all these drip sites it is plausible that considerable effect of the soil and the bedrock overlying furong cave shielded the response of 1000 ba ca in drip water to the change in local precipitation the correlation coefficient r between the concentration of ba2 and 1000 ba ca was 0 69 p 0 01 which was significantly higher than that between the concentration of ca2 and 1000 ba ca r 0 33 p 0 01 fig 6e and f it indicated that the change in ba2 exerted a larger influence on the change in 1000 ba ca than ca2 did therefore the deposition of ca2 was not the major reason for the change in 1000 ba ca in drip water no seasonal characteristics were observed for the change in 1000 ba ca fig 2d which might be attributed to the different spatial distributions of ba2 concentrations in the soil and the bedrock overlying furong cave xiang et al 2011 6 2 causes for the change of δ18o and δd in meteoric water and drip water compared with the global meteoric water line gmwl δd 8δ18o 10 craig 1961 there was a greater slope and intercept in the local meteoric water line lmwl fig 4 which can be attributed to the difference in moisture sources in different seasons for this monsoon prevailing area for this region in rainy season summer months the moisture mainly comes from the tropical ocean e g indian ocean ding and liu 2008 liu et al 2008 2010 while in dry seasons of winter and spring the moisture mainly comes from continent air mass transported by the westerlies and the revaporizing vapor from local water sources the stable isotopes of hydrogen and oxygen in the moisture and the vapor were fractionated several times in the processes of transportation and revaporization resulting in a larger slope and intercept in the lmwl li et al 2010 zhou and li 2017 on the other hand no clear seasonal change in δ18o and δd of drip water was observed fig 2f and g which was attributed to the mixing effect of the groundwater when it flowed through the vadose zone pape et al 2010 li et al 2011 partin et al 2013 genty et al 2014 the thickness of overlying strata was 300 500 m above furong cave which resulted in a long residence time of the precipitation and groundwater in the bedrock smoothening the seasonal signals of δ18o and δd in the precipitation li et al 2011 although the mixing effect of the groundwater depressed the changes in δ18o and δd in drip water a significant change of drip water δ18o and δd was observed in the winter of 2009 and the winter spring of 2014 2015 fig 2f and g previous reports on mulu karst system 4 n 114 e in northwestern borneo yangkou cave 29 02 n 107 11 e in southwest china and jiguan cave 33 46 n 111 34 e in central china indicated that δ18o of cave drip water did make response to enso moerman et al 2014 chen and li 2018 sun et al 2018 the la niña event occurred with constant negative ssta in the niño 3 4 zone during 2007 2009 with the negative isotope excursion appendix fig 4a 4b 4c 4d in this situation with the northward and eastward migration of the weakened western pacific subtropical high wpsh tan and nan 2010 chen and li 2018 vapor from distant moisture source india ocean increased obviously in the monsoon region of china and the vapor from the western pacific ocean decreased tan 2014 chen and li 2018 the change in moisture source finally led to depleted δ18o of precipitation and drip water in the monsoon region of china in the la niña scenario in contrast continuous positive ssta in the niño 3 4 zone indicated the formation of the el niño event during 2014 2015 with the positive isotope excursion appendix fig 4f 4g 4h 4i in this period the wpsh strengthened then migrated southward introducing water vapor to south china along the south margin of the wpsh tan and nan 2010 with this atmospheric circulation pattern more vapor from the relatively close moisture source west pacific and south china sea was transported into the monsoon region of china and resulted in heavier δ18o in precipitation and drip water nan et al 2014 tan 2016 in furong cave the significant change in δ18o δd for the high discharge drip water sites in the winter of 2009 can be attributed to a la niña event appendix fig 4a 4b 4c 4d in contrast the higher drip water δ18o δd values in the winter spring of 2014 2015 responded to an el niño event appendix fig 4f 4g 4h 4i the decreased precipitation in 2007 2009 increased the residence time of groundwater in the epikarst zone and then the drip water responded to enso with a longer time lag than that in 2014 2015 appendix fig 4 more importantly no amount effect between the δ18o of precipitation drip water and local precipitation was observed in 2007 2009 and 2014 2015 it was found that monthly precipitation anomaly exhibited a decreased trend in 2007 2009 outside of furong cave appendix fig 4e however the δ18o of precipitation and drip water were depleted during 2007 2009 appendix fig 4b 4c 4d in addition the δ18o values of precipitation and drip water exhibited heavier values with local precipitation increased during 2014 2015 which was also contrary to amount effect dansgaard 1964 appendix fig 4g 4h 4i 4j it is plausible that at least in the monitoring period although there was a lag of several months between the response of the drip water and the local precipitation the δ18o and δd values of local precipitation and drip water collected from the high discharge monitoring sites in furong cave may be influenced by the changes of moisture source which potentially have the ability to record the changes in atmospheric circulations such as el niño and la niña scenarios zhou and li 2017 chen and li 2018 however further monitoring is essential to remove the randomness and confirm this inference 6 3 assessment on pcp icd and wri for different discharge and hydrological condition during the migration through bedrock above the cave the precipitation and groundwater were affected by pcp icd and wri in the epikarst zone with a change in trace element ratios tooth and fairchild 2003 baldini et al 2006 wong et al 2011 casteel and banner 2015 tadros et al 2016 the slopes of ln mg ca versus ln sr ca in drip water samples with high discharge dw1 mp1 and mp2 and those in drip water samples with low discharge mp3 mp4 and mp5 changed in the range of 0 36 0 39 and 0 17 0 29 respectively fig 5a and 5b it indicated that wri was stronger at the low discharge sites than that at the high discharge sites low discharge sites were mainly supplied by a seepage flow with a relatively slow migration of groundwater high dissolution of bedrock and strong wri casteel and banner 2015 in contrast high discharge sites were supplied by the conduit and fissure flows with a relatively high rate and weak wri in addition wri in the drought years was stronger than that in the wet years because of the minor slope of ln mg ca versus ln sr ca in the drought years fig 5c it can be attributed to the fact that precipitation and groundwater has longer residence times in the bedrock in drought years all the above analyses showed that in the drought years and at the low discharge sites the prolongation of the residence time of groundwater in bedrock and soil strengthened the process of wri significantly li et al 2013 changes in local hydrological conditions were related to the changes in trace element ratios of drip water 6 4 climatic significance comparison of trace element ratios and stable isotopes in drip water during the period of this study different characteristics for the changes in mg ca 1000 sr ca 1000 ba ca δ18o and δd of the drip water in furong cave were observed fig 2 there was a seasonal variation of 1000 sr ca which increased in winter and spring and decreased in summer and autumn fig 2c however the mg ca ratio in drip water responded to the change in local hydrological conditions i e increase of precipitation led to lower mg ca and decrease of precipitation resulted in higher mg ca fig 2b note that no correlation was observed between the drip water δ18o and the monthly precipitation p 0 1 fig 7 a indicating that drip water δ18o did not exhibit the amount effect and could not respond sensitively to the change in the precipitation δ18o fig 2e f 7a although the isotopic composition of drip water inherited the isotopic signal of precipitation section 6 2 the 300 500 m thick bedrock above furong cave led to sufficient mixing of the groundwater in the epikarst zone and shielded the seasonal change in precipitation δ18o li et al 2011 2012 on the other hand by comparing with average δ18o of the drip water and monthly precipitation anomaly outside furong cave over the past 12 years the δ18o of drip water still follows the change of local precipitation at interannual and longer timescales fig 8 a and b however significant correlations were observed between drip water mg ca ratio and monthly precipitation for all drip water sites for dw1 mp1 mp2 mp4 and mp5 p 0 01 for mp3 p 0 05 indicating that the change in drip water mg ca ratio reflected the change in local precipitation fig 7b because of the uncertainty of residence time of groundwater for each drip site it is difficult to estimate the exact residence time of ground water under current technical conditions therefore we do not take residence time of groundwater into account when calculating the correlation between the drip water δ18o and mg ca ratio with the monthly precipitation amount in summary for all drip water samples in furong cave the mg ca ratios and δ18o had different responses to the change in external climate the changes in mg ca ratio were dominated by the variation in local precipitation hydrological conditions while the changes in δ18o of drip water did not make sensitive response to precipitation the different expressions of pcp icd and wri in drip water with high and low discharge in furong cave indicated that the speleothem fed by different drip water underwent different chemical processes therefore a replication test i e demonstration of similar isotopic profiles of two or more sets of speleothems dorale and liu 2009 was more scientifically reliable and robust in paleoclimate reconstruction based on the records of speleothem series of abrupt climatic events on the centennial millennial time scales such as greenland interstadials heinrich events and younger dryas have been recorded by the speleothem records from the china monsoon regions wang et al 2001 2008 li et al 2007 2014 2017 han et al 2016 zhang et al 2017 the speleothem δ18o in furong cave also recorded the change in asm at the termination of the last glacial period li et al 2011 no correlation was observed between the δ18o of drip water and local rainfall assuming no time lag between drip water and local meteoric water fig 7a in contrast change in trace element ratios of drip water eventually made response to the change of local precipitation indicating that the δ18o and the trace element ratios reflected different climatic signals on the monthly and seasonal timescales figs 2 and 7 7 conclusions based on the 12 year monitoring of the δ18o δd and trace element ratios of drip water and local hydrological conditions outside of furong cave southwest china the main conclusions were as follows 1 the mg ca of drip water responded to local hydrological conditions with lower values in wet years and higher values in drought years a seasonal characteristic was observed for the change in 1000 sr ca with an increase in winter and spring and a reduction in summer and autumn the change in ca2 with pcp had an important influence on the change in 1000 sr ca of drip water 2 analysis with the pcp icd wri model may reveal that the influence of wri in the epikarst zone was stronger than that of pcp icd in drought years and the influence of wri on drip water with high discharge was weaker than that on drip water low discharge 3 the δ18o and δd of drip water in furong cave preserved the isotopic signal of precipitation and the range of seasonal change was depressed by the mixing effect with old water in the epikarst zone without any expression of the amount effect on monthly timescale 4 the high resolution e g seasonal and annual δ18o record of speleothem in furong cave may not be useful however δ18o record of speleothem in furong cave may follow with local precipitation on decadal and longer timescales in addition the trace element ratios are potentially reliable proxies in speleothems to record the change of rainfall on annual and seasonal timescales declarations of interest all authors declare no competing interests acknowledgments we would like to express our sincere gratitude to the management department of furong cave for considerable help in the field since 2005 the editor peter k kitanidis associate editor dongmei han and three anonymous reviewers are greatly appreciated for their constructive comments to improve the quality of this paper this research was supported by national natural science foundation of china nsfc no 41772170 and the fundamental research funds for the central universities nos xdjk2017a010 and xdjk2013a012 to t y li a professional english translator dr xiang xinyi southwest university china is also greatly appreciated for her effort in polishing the final version of the manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 02 052 appendix a supplementary data the following are the supplementary data to this article supplementary fig 1 a distribution of soil co2 monitoring sites black triangles sa se above furong cave the black shadow indicates the location of furong cave and the contour lines with elevation are shown as well b profile of furongjiang river and the mountain in which furong cave formed modified from li et al 2012 supplementary fig 2 a variation of soil co2 at five monitoring sites sa se b cave air pco2 at four monitoring sites mp1 mp4 in furong cave c 1000 sr ca d monthly discharge of drip water dw1 and mp1 mp5 e monthly precipitation blue histograms and average air temperature red dots outside furong cave the pink bands indicate summer months june august in easm region supplementary fig 3 variations of kdsr 1 kdmg 1 for drip waters mp1 mp5 in furong cave the red dashed lines represent the possible maximum range of kdsr 1 kdmg 1 based on the published values of kdsr and kdmg by sinclair et al 2012 supplementary fig 4 response of drip water δ18o δd to enso for the high discharge drip waters dw1 mp1 and mp2 in furong cave a f ssta b g δ18o of precipitation c h drip water δ18o d i drip water δd e j monthly precipitation anomaly mm the fitting red dashed lines indicated the trend for the changes the δ18o and δd of the drip waters exhausted enriched during the la niña el niño situations respectively although there was a lag of a few months because of the 300 500 m thick aquifer zone above furong cave supplementary data 1 
6571,cave monitoring is crucial for the interpretation of climatic and environmental significances of various geological proxies in speleothem therefore the hydrochemical and stable isotopic compositions δ18o δd mg ca sr ca and ba ca of karst cave waters during 2005 2016 ce were constantly monitored in furong cave chongqing city southwest china a comparison with local hydrological conditions led to 4 main conclusions as follows 1 the mg ca ratio is significantly responsive to the changes in drought wet conditions outside the cave which increased in drought years and decreased in wet years respectively seasonal variation of sr ca is more significant than those of mg ca and ba ca ratios 2 prior calcite precipitation pcp incongruent calcite dissolution icd water rock interaction wri and pco2 of soil and cave air may account for the changes in trace element ratios in the epikarst which resulted in a complex variation of element ratios in the cave drip water in general wri in drought years is stronger than that in wet years and that in low discharge sites is stronger than in high discharge sites seasonal variation of ca2 concentration induced by pcp exerts significant impact on the evolution of sr ca ratio in drip water 3 δ18o and δd of drip water are influenced by the mixing effect leading to the result that their seasonal variations are less significant than that of precipitation 4 at least in the study period the ratios of trace elements in the drip water in furong cave mainly reflected the variations of local hydrological conditions drought or wet dominated by precipitation because of the mixing effect of groundwater high resolution δ18o record e g seasonal and annual of speleothem in furong cave may not be recommendable however the δ18o is potentially a reliable proxy in speleothems to record the change of rainfall on decadal and longer timescales keywords drip water trace element ratios stable isotopes pcp icd wri rainfall 1 introduction as geological carriers for paleoclimate change speleothems are mostly composed of calcium carbonate with multiple proxies such as δ18o δ13c and trace element ratios these proxies were used for the reconstruction of paleorainfall paleovegetation paleohydrogeology and paleoenvironment roberts et al 1998 lauritzen and lundberg 1999 wang et al 2001 2008 yuan et al 2004 johnson et al 2006 fairchild and treble 2009 cheng et al 2009 2012 2016 jo et al 2010 wong and breecker 2015 owing to the fact that controlling factors of the proxies of speleothem are numerous and complex interpretation of climate information based on these proxies is controversial mcdermott et al 1999 fairchild et al 2006 however cave drip water a signal transmitter between speleothems and external climate environment is of great significance to explore the depositional mechanism of speleothem and interpret the climate information from various proxies tooth and fairchild 2003 oster et al 2012 the negative isotope excursion with the increased precipitations namely amount effect have been widely accepted in the communities of paleoclimate dansgaard 1964 however many studies also have suggested that a direct link between the speleothem δ18o records and precipitation is debatable liu et al 2015 found that the strongest period of the east asian summer monsoon easm occurred in the early holocene period referred from the chinese speleothem δ18o record challenging the view of mid holocene easm maximum based on lakes loess and pollen records from northern china and all of these holocene chinese speleothem δ18o records also exhibited a similar trend of variation indicating a common climate signal e g rainfall or asian summer monsoon intensity however the instrumental data and models indicated a significant different spatial variation in rainfall between northern and southern china liu et al 2015 therefore it is believed that the speleothem δ18o cannot represent the changes in intensity of easm accurately liu et al 2015 2017 on the other hand inconsistency between speleothem δ18o records and solar radiation in northern hemisphere have been noted and clemens et al suggested that the speleothem δ18o in the asian monsoon region may not be a simple proxy for the intensity of summer monsoon which may also reflect the changes in moisture sources and transport pathway clemens et al 2010 some studies have presented that on interannual to decadal timescales the δ18o and δd values of precipitation were significantly affected by the changes in moisture sources which could be attributed to the changes in atmospheric circulation such as el niño southern oscillation enso tan 2014 2016 recorded changes in asian summer monsoon asm intensity and the effect of rainfall in the upper reaches on moisture source yang et al 2016 the trace elements in cave water mainly come from bedrock and soil zhou et al 2009 2012 a series of physical and chemical processes in epikarst including water rock interaction wri prior calcite precipitation pcp incongruent calcite dissolution icd mixing of old and fresh water and dilution effects by fracture water in the bedrock may affect the changes in trace element ratios in cave drip water and speleothem tooth and fairchild 2003 spötl et al 2005 sherwin and baldini 2011 the above mentioned factors which may affect the changes of trace element ratios in drip water have direct or indirect links with precipitation the combination of δ18o and trace element ratios is important for the reconstruction of paleoclimate based on speleothems oster et al 2012 however there is a lack of testing with long time monitoring data for whether or not the δ18o or trace element ratios can reflect the changes in precipitation in this paper we summarized the 12 year monitoring work in furong cave southwest china and presented a comprehensive analysis on the interannual and seasonal variation of trace element ratios δ18o and δd of drip water combined with the changes in atmospheric circulation characterized by enso and the changes in local temperature and precipitation we discussed the response of δ18o δd and trace element ratios of drip water to external climate signals this paper is mainly focused on the following scientific questions 1 are there any difference between the responses of element ratios and isotopic compositions of cave drip water corresponding to the external environment 2 whether or not the change of elements ratios made response to extreme flood and drought events outside furong cave which is covered by 300 500 m thick bedrock 3 whether or not drip water δ18o values preserve high resolution e g seasonal annual signals from meteoric precipitation note that the 300 to 500 m aquifer zone above furong cave is far thicker than other monitoring caves in easm region such as xianren cave 40 140 m liangfeng cave 80 140 m shihua cave 30 130 m and so on luo and wang 2008 cai et al 2010 duan et al 2012 exhibiting some differences in hydrochemical characteristics and stable isotopic compositions of drip waters in furong cave one of the most important reasons is the different residence time of ground water for each cave because of the different thickness of overlying bedrock data interpretations for short monitoring durations are complicated by mostly unknown water transit times through the karst our exceptionally long monitoring work allows comparing confidently with hydrological factors related to rainfall changes and variations in the epikarst in addition previous studies commonly analyzed single indicator in drip water e g δ18o element ratios or δ13c li et al 2011 2012 duan et al 2016 li and li 2018 but comprehensive studies combining δ18o and trace element ratios are rarely reported the main objective of this study is to distinguish the climate implications of the multiple proxies e g δ18o and trace element ratios in cave drip water we do believe that the inferences of this long monitoring study are significant for the interpretation of climatic implications of the proxies in speleothems 2 study area 2 1 physical geography background chongqing is located in the southwest region of china the local climate is characterized by the subtropical humid monsoon climate which is dominated by east asian summer monsoon easm and indian summer monsoon ism in the summer months and by asian winter monsoon awm in the winter months fig 1 a furong cave 29 14 n 107 55 e is located in wulong county chongqing city on the east bank of furongjiang river a branch of yangtze river furong cave developed in the middle cambrian dolomite limestone strata and the local topography is characterized by a typical steep karst gorge li et al 2011 the altitude at the entrance of furong cave is approximately 480 m above the sea level a s l appendix fig 1b and the main tunnel is approximately 2800 m in length 30 50 m in height and 2 30 m in width furong cave belongs to tianxing furong cave karst system which is a typical karst area of carbonate aquifer characterized by high permeability to absorb store and transmit precipitation zhu et al 2007 another hydrogeological feature is that the 300 500 m thick aquifer zone above furong cave leads to numerous complex flow paths of groundwater li et al 2011 the relative humidity of cave air is close to 95 100 and the average temperature is 16 16 3 c in the inner chamber of furong cave li et al 2011 in the 12 year monitoring period from 2005 to 2016 the average annual rainfall was 1079 mm outside furong cave in general in the rainy season from april to october every year the precipitation accounted for over 85 of the total precipitation and the annual average temperature was 17 9 c outside furong cave fig 2 h 2 2 monitoring sites five soil co2 monitoring sites namely sa sb sc sd and se were set up along both sides of the valley overlying furong cave appendix fig 1a li et al 2012 li and li 2018 the pipelines for soil co2 monitoring were buried in the soil profiles at the depth of 50 cm six drip water monitoring sites dw1 mp1 mp2 mp3 mp4 and mp5 were set up in furong cave fig 1c li et al 2011 dw1 and mp1 were 3 m apart with the drip height being approximately 22 m split into multi drip during the process of falling drip site mp2 was located on the top of a speleothem 2 m in height with the falling height being 27 m mp3 was on the cavity wall with a short soda straw stalactite as the outlet and the drip height was approximately 30 cm li et al 2011 mp4 and mp5 were approximately 1 5 m apart with each other and the drip heights were 14 m and 13 m respectively li et al 2012 the deposition rates of active sediments were 0 87 5 69 0 71 5 31 and 4 13 mg day respectively at the five drip water monitoring sites mp1 mp2 mp3 mp4 and mp5 huang et al 2015 3 data and methods 3 1 meteorological data during the period of year 2005 2016 a portable meteorological station was set up outside furong cave to collect meteorological data precipitation was recorded using an automatic rainfall monitoring instrument rg3 m onset usa at a frequency of once every 2 min with the precision being 1 0 the air temperature was continuously recorded at 2 h intervals by the u12 011 temperature recorder onset usa with an error of 0 1 c the monthly average rainfall and air temperature outside furong cave were calculated on the basis of the recorded meteoric data which were downloaded via the hobo software every month the drought years and the wet years were distinguished according to the precipitation anomaly percentage which was calculated as follows 1 dp p p p 100 where dp is the percentage of precipitation anomaly p is the annual precipitation in the year and p is the average multi year precipitation classification of drought and wet years was based on the dp value a year with the dp value being less than or equal to 15 was defined as a drought year and that with a dp value being above or equal to 15 was defined as a wet year wei et al 2017 according to the principles of climate statistics in the china monsoon region a year is divided into four seasons as spring march may summer june august autumn september november and winter december february of the following year deng et al 2017 enso frequently occurs with changes in the large scale atmospheric circulation the indexes of the sea surface temperature anomaly ssta of the niño 3 4 zone 5 n 5 s 170 w 120 w are commonly used to define enso ropelewski and jones 1987 trenberth 1997 according to the definition by the national oceanic and atmospheric administration usa if the three month sliding average of ssta in the niño 3 4 zone is 0 5 c 0 5 c and lasts for five consecutive months the event can be defined as an el niño la niña event the ssta values of the niño 3 4 zone were downloaded from the following official websites http www cpc ncep noaa gov data indices sstoi indices ssta 3 2 stable isotopic composition of rainwater on the basis of the principles of global network of isotopes in precipitation drafted by international atomic energy agency https nucleus iaea org wiser index php rainwater samples for stable isotope analyses were collected outside of furong cave during the period from may 2006 to september 2016 approximately 1 cm thick liquid paraffin was filled into the rainwater collection barrel to prevent the evaporation in addition foam insulation and tinfoil paper were used to cover the barrel to prevent the effect of solar radiation on the chemical composition of rainwater the collected rainwater was regularly sampled at the end of each month and then preserved in a refrigerator at 5 c next 5 ml water samples were taken from these samples to evaluate the stable hydrogen and oxygen isotopic compositions 3 3 stable isotopic compositions and trace element ratios of drip water drip water samples were collected during the period of october 2005 to september 2016 the sites of dw1 and mp3 were monitored from october 2005 to september 2016 and the other drip sites were monitored from october 2008 to september 2016 polyethylene bottles and caps for sample collecting were boiled for 5 h in a 1 5 vol ratio of nitric acid then washed with ultra pure water and dried out naturally in an ultra clean room bench class 100 clean for each monitoring site 50 ml of drip water was filtered through pre washed 0 45 µm millipore nitrocellulose filters packaged in a cleaned polyethylene bottle and acidified to ph 2 0 by adding a trace level of ultrapure hno3 1 1 volume ratio for the analyses of trace elements the concentrations of cations ca2 mg2 ba2 and sr2 were measured with the optima 2100dv inductively coupled plasma emission spectrometer icp oes perkin elmer usa the detection limit was 1 µgl 1 and the analytical error was 2 the collection and analytical methods of the deposition rate and trace element compositions of the active deposits under the monitored drip water referred to huang et al 2015 furthermore 5 ml of drip water for the analysis of δ18o δd was collected and stored in the refrigerator at 5 c the isotopic composition δ18o δd of the rainwater and drip water samples was determined with a liquid water isotope analyzer lwia dlt 100 los gatos research usa 1 5 ml volumes of water samples were analyzed 6 times and the average of the last four measurements was used to calculate the value of the measured sample lgr3a lgr4a lgr5a los gatos research usa were used as reference standards to be cross checked the analytical absolute error for δ18o was 0 2 and 0 5 for δd the result of δ18o δd was presented as the relative value to vienna standard mean ocean water v smow value zhou and li 2017 δ 18 o 18o 16 o sample 18o 16o v smow 18 o 16 o v smow 10 3 δ d d h sample d h v smow d h v smow 10 3 3 4 discharge of drip water and pco2 of soil and cave air during the period from january 2010 to september 2016 20 ml cylinders were used to measure the discharge of drip water ml min the variation in the cave air pco2 concentration was monitored near the drip water sites mp1 mp4 with a handheld testo 535 co2 monitor made in germany the measuring range was 0 9999 ppm for the instrument and the resolution was higher than 1 ppm with an error of 2 there were no measured pco2 data for dw1 and mp5 because the distance between dw1 and mp1 was merely 3 m and the distance between mp4 and mp5 was only 1 5 m fig 1c during the period from july 2010 to september 2016 co2 concentration of soil air was monitored above furong cave appendix fig 1a soil air was pumped out by the collector ap 20 and the co2 concentration of soil air was determined by the detector tube 126sa komyokk japan with a precision of 100 ppm 4 model of pcp icd and wri according to mg ca and sr ca ratios of the active cave sediments and drip water trace element distribution coefficients of kdmg and kdsr between h2o and caco3 could be calculated morse and bender 1990 huang and fairchild 2001 day and henderson 2013 the specific calculation formulas are as follows 2 kd mg mg ca crystal mg ca solution 3 kd sr sr ca crystal sr ca solution where kdmg and kdsr are the distribution coefficients of mg and sr respectively the processes of pcp icd and wri in the epikarst zone may influence the ratios of mg ca and sr ca in drip water roberts et al 1998 tremaine and froelich 2013 casteel and banner 2015 before the groundwater reached the ceiling of the cave to form drip water carbonate was deposited in the epikarst zone along with the degassing of co2 wong et al 2011 during the process of deposition ca2 deposited preferentially over mg2 and sr2 which contributed to the reduction of ca2 in the drip water and increased the mg ca and sr ca ratios in the drip water and the speleothem tremaine and froelich 2013 this hydrochemical process has been defined as pcp morse and bender 1990 huang and fairchild 2001 day and henderson 2013 icd is another interaction between calcite and water which takes place as the elements mg2 and sr2 dissolve preferentially into solution relative to ca2 fairchild et al 2000 sinclair 2011 sinclair et al 2012 casteel and banner 2015 particularly on the fresh surface of the calcite mineral brantley 2008 it also results in an increase in mg ca and sr ca for speleothems and drip water an obvious positive correlation between mg ca and sr ca may be associated with pcp and icd because either pcp preferential precipitation of ca2 or icd preferential dissolution of mg2 and sr2 may increase the mg ca and sr ca ratios pcp and icd are indistinguishable in the epikarst sinclair et al 2012 casteel and banner 2015 in this article these two processes are combined as pcp icd in contrast wri generally indicates the recrystallization of calcite dolomite or the incongruent dissolution of dolomite even with the effect of pcp icd wri may result in an increase in mg ca and sr ca ratios of the solution fairchild et al 2000 musgrove and banner 2004 wong et al 2011 on the basis of kdmg and kdsr sinclair proposed the pcp icd wri model for mg ca and sr ca ratios of drip water utilizing the value of kdsr 1 kdmg 1 to assess the different effects of pcp icd and wri on drip water with groundwater passing through the epikarst zone sinclair 2011 sinclair et al 2012 simulation results indicated that when the residence time of groundwater in the epikarst zone was relatively short t 0 the slope of ln sr ca versus ln mg ca for drip water tended to be close to the value of kdsr 1 kdmg 1 fig 5 in sinclair 2011 and the drip water was obviously influenced by pcp icd in contrast with an increase in the residence time of groundwater the slope of ln mg ca versus ln sr ca got closer to zero and the drip water was mainly influenced by wri fig 5 in sinclair 2011 on the basis of the values of kdsr and kdmg presented by banner 1995 and huang and fairchild 2001 sinclair proposed a possible range of kdsr 1 kdmg 1 0 709 1 003 sinclair et al 2012 the model results showed that the slopes of ln mg ca versus ln sr ca falling in the range of kdsr 1 kdmg 1 of 0 709 1 003 proving the leading role of pcp icd processes when the groundwater passing through the epikarst zone to form drip water sinclair et al 2012 casteel and banner 2015 in contrast mixed wri and pcp icd processes were indicated by slopes under 0 709 lower slope reflected stronger wri sinclair 2011 sinclair et al 2012 on the basis of the above mentioned conclusions casteel and banner monitored texas cave usa and noted significant differences in the effects of pcp icd and wri between the high discharge sites and the low discharge sites casteel and banner 2015 in addition tadros et al found obvious differences in the effects of pcp icd and wri between the drought years and the wet years in harrie wood cave australia tadros et al 2016 5 results 5 1 annual rainfall and discharge of drip water the average annual precipitation outside of furong cave was 1079 mm during the period of 2005 2016 the annual precipitations in year 2006 2009 and 2011 were 850 751 and 847 mm respectively which were 229 328 and 232 mm lower than the 12 year average value respectively in contrast the dp values were 27 44 and 27 respectively which were lower than 15 accordingly the three years were classified as drought the annual precipitations of 2007 and 2016 were 1352 and 1498 mm respectively which were 273 and 419 mm higher than 1079 mm respectively at the same time the dp values were 20 and 27 respectively which were higher than 15 these two years were classified as wet the precipitations of the other years were relatively close to the 12 year average value and thus these years were classified as normal fig 2a and h the average discharge monitored at the six drip water sites dw1 and mp1 mp5 in furong cave were 8 7 11 7 20 4 9 1 3 and 0 7 ml min respectively appendix table 1 with the discharge of 8 ml min as the standard the six drip water sites were divided into high discharge sites dw1 mp1 and mp2 and low discharge sites mp3 mp4 and mp5 the standard deviation sd of the discharge at the high discharge sites was higher than that at the low discharge sites appendix table 1 indicating that the high discharge sites responded more sensitively to the external climatic situation moreover the discharge at different drip water sites varied considerably which can be attributed to the differences in the thickness of overlying strata and the flow path of groundwater through the epikarst zone huang et al 2016 at the same time the discharge of mp2 site exhibited a relative remarkable response to external precipitation appendix fig 2d and e which presented in high discharge corresponding to local precipitation indicating less residence time compared with others drip sites huang et al 2016 5 2 mg ca sr ca and ba ca of drip water the mg ca values for all drip water samples dw1 and mp1 mp5 are summarized in table 1 although no clear seasonal characteristics were identified fig 2b the mg ca values in the winter season were higher than that in the summer season fig 3 a the variation ranges for 1000 sr ca and for all the drip water monitoring sites dw1 and mp1 mp5 were 0 55 1 11 table 1 seasonal characteristics were observed for the changes of 1000 sr ca for all drip water samples with higher values in winter and spring and lower values in summer and autumn except for the winter of 2010 2011 fig 2c on the other hand the average value of drip water 1000 sr ca in summer was lower than that in winter for all drip water sites fig 3b which also confirmed the seasonal changes in 1000 sr ca a similar trend was observed for the change in 1000 ba ca for the drip water at all sites but the absolute values were considerably different among these monitoring sites for example the average value of 1000 ba ca for mp1 was approximately three times that for mp3 table 1 and fig 2d 5 3 δ18o and δd in meteoric water and drip water the δ18o of precipitation exhibited an obvious seasonal variation with lighter values in summer and heavier values in winter fig 2e based on δ18o and δd values of the rainwater samples outside furong cave the equation of the local meteoric water line lmwl was δd 9 06δ18o 20 44 and the correlation coefficient was r 0 99 p 0 01 fig 4 the δ18o and δd values of drip water dw1 and mp1 mp5 changed in the range from 8 9 to 4 3 and from 51 2 to 38 1 respectively table 1 which were distributed around the lmwl indicating that the drip water preserved the isotopic signal of precipitation fig 4 5 4 calculation results of pcp icd and wri model the kdmg and kdsr values of active sediments drip water system in furong cave during 2009 2016 were calculated using equations 1 and 2 the ranges of kdmg and kdsr were 0 02 0 09 and 0 04 0 31 with the average value being 0 03 and 0 16 respectively thus we calculated the value of kdsr 1 kdmg 1 for the drip water in furong cave it fluctuated in the range of 0 727 0 988 falling within the predicted range of 0 709 1 003 from sinclair et al 2012 appendix fig 3 in general for all drip water samples in furong cave the slope of ln mg ca versus ln sr ca varied from 0 17 to 0 39 fig 5a and b the slopes of ln mg ca versus ln sr ca in wet year and drought year are 0 31 and 0 24 respectively and a reduced slope of ln mg ca versus ln sr ca was found in drought years fig 5 c 6 discussions 6 1 causes for the change of trace element ratios the changes of mg ca ratio in drip water responded to the changes in local hydrological conditions drought and wet on interannual scale fig 2b during the drought years 2006 2009 and 2011 with decreased precipitation fig 2a more trace elements were dissolved from the bedrock because of the extended residence time of groundwater and enhanced wri in general dissolution of calcite was faster than that of dolomite with enhanced wri more dolomite dissolved and more mg2 released into groundwater fairchild et al 2000 in addition the occurrence of pcp with preferential deposition of ca2 relative to mg2 and sr2 also resulted in a higher mg ca ratio karmann et al 2007 wong et al 2011 tremaine and froelich 2013 casteel and banner 2015 in contrast in wet years with increased precipitation 2007 and 2016 fig 2a groundwater penetrated rapidly shortening the time of wri what s more accelerated bedrock dissolution resulted from higher contribution of rainwater can increase the concentration of metal ions with more increase of ca2 compared to mg2 and finally lead to lower mg ca fig 2b in theory the distribution coefficient of mg between solution and calcite was mainly determined by temperature mucci and morse 1983 morse and bender 1990 therefore the cave temperature was also considered as a potential factor for the evolution of the mg ca ratio in the drip water gascoyne 1983 huang and fairchild 2001 however air temperature in furong cave was stable at 16 0 16 3 c li et al 2011 therefore air temperature in furong cave was not a main reason for the evolution of mg ca ratio in drip water in summary changes in precipitation and wri were the main reasons for the evolution of mg ca ratio of drip water in dry and wet years correlation coefficients r between the concentration of ca2 and 1000 sr ca and that between the concentration of sr2 and 1000 sr ca of the drip water in furong cave were 0 52 p 0 01 and 0 22 p 0 01 respectively fig 6 c and 6d which indicated that the change of 1000 sr ca was mainly controlled by the concentration of ca2 the occurrence of pcp during the drought months of winter and spring with the deposition of ca2 accounted for the increase in 1000 sr ca in drip water the pco2 of cave air was also an important factor for the evolution of 1000 sr ca ratio in drip water burton and walter 1991 banner et al 2007 wong et al 2011 sherwin and baldini 2011 treble et al 2015 in summer months the average values of soil air co2 concentrations at five monitoring sites sa sb sc sd se above furong cave were 7974 8096 7286 5028 8524 ppm respectively and the cave air co2 concentrations at four monitoring sites mp1 mp2 mp3 mp4 in furong cave were 1390 1523 1537 and 1386 ppm respectively in contrasts in winter months the average values of soil air co2 concentrations at the five monitoring sites were 1481 1793 592 898 662 ppm and the cave air co2 concentrations at four monitoring sites mp1 mp2 mp3 mp4 in furong cave were 1071 1045 1115 1209 ppm respectively monitoring results showed a significant seasonal variation of air pco2 in the soil and cave air which was higher in summer months and lower in winter months the change in cave air pco2 lagged by 1 2 months compared with that in soil appendix fig 2a and b li and li 2018 in addition an obvious correlation was observed between cave air pco2 and soil co2 except for sc mp1 and se mp3 appendix table 2 indicating that the change in cave air pco2 was mainly controlled by soil co2 li and li 2018 with an increase of precipitation in summer months enhanced biological activities led to massive soil co2 entering the cave through groundwater and fissures resulting in an increase in pco2 of cave air breecker et al 2012 meyer et al 2014 the increase in cave air pco2 depressed the degassing of co2 from the cave water and the deposition of speleothem baldini et al 2008 which also led to a lower 1000 sr ca and mg ca ratios in drip water appendix fig 2a 2b 2c fig 3 a previous study showed that 1000 ba ca in soil and bedrock above furong cave presented a significant spatial variation and changed in the range of 4 27 59 28 and 0 04 0 25 respectively xiang et al 2011 three types of flow patterns namely conduit flow fissure flow and seepage flow have been observed when the groundwater migrates through the vadose zone baldini et al 2006 the migration rate was considerably different for these three types of flows resulting in different residence time of the groundwater in the bedrock and the soil finally leading to different dissolution rate of minerals from the soil and the bedrock fairchild et al 2006 and obviously different values of 1000 ba ca for all these drip sites it is plausible that considerable effect of the soil and the bedrock overlying furong cave shielded the response of 1000 ba ca in drip water to the change in local precipitation the correlation coefficient r between the concentration of ba2 and 1000 ba ca was 0 69 p 0 01 which was significantly higher than that between the concentration of ca2 and 1000 ba ca r 0 33 p 0 01 fig 6e and f it indicated that the change in ba2 exerted a larger influence on the change in 1000 ba ca than ca2 did therefore the deposition of ca2 was not the major reason for the change in 1000 ba ca in drip water no seasonal characteristics were observed for the change in 1000 ba ca fig 2d which might be attributed to the different spatial distributions of ba2 concentrations in the soil and the bedrock overlying furong cave xiang et al 2011 6 2 causes for the change of δ18o and δd in meteoric water and drip water compared with the global meteoric water line gmwl δd 8δ18o 10 craig 1961 there was a greater slope and intercept in the local meteoric water line lmwl fig 4 which can be attributed to the difference in moisture sources in different seasons for this monsoon prevailing area for this region in rainy season summer months the moisture mainly comes from the tropical ocean e g indian ocean ding and liu 2008 liu et al 2008 2010 while in dry seasons of winter and spring the moisture mainly comes from continent air mass transported by the westerlies and the revaporizing vapor from local water sources the stable isotopes of hydrogen and oxygen in the moisture and the vapor were fractionated several times in the processes of transportation and revaporization resulting in a larger slope and intercept in the lmwl li et al 2010 zhou and li 2017 on the other hand no clear seasonal change in δ18o and δd of drip water was observed fig 2f and g which was attributed to the mixing effect of the groundwater when it flowed through the vadose zone pape et al 2010 li et al 2011 partin et al 2013 genty et al 2014 the thickness of overlying strata was 300 500 m above furong cave which resulted in a long residence time of the precipitation and groundwater in the bedrock smoothening the seasonal signals of δ18o and δd in the precipitation li et al 2011 although the mixing effect of the groundwater depressed the changes in δ18o and δd in drip water a significant change of drip water δ18o and δd was observed in the winter of 2009 and the winter spring of 2014 2015 fig 2f and g previous reports on mulu karst system 4 n 114 e in northwestern borneo yangkou cave 29 02 n 107 11 e in southwest china and jiguan cave 33 46 n 111 34 e in central china indicated that δ18o of cave drip water did make response to enso moerman et al 2014 chen and li 2018 sun et al 2018 the la niña event occurred with constant negative ssta in the niño 3 4 zone during 2007 2009 with the negative isotope excursion appendix fig 4a 4b 4c 4d in this situation with the northward and eastward migration of the weakened western pacific subtropical high wpsh tan and nan 2010 chen and li 2018 vapor from distant moisture source india ocean increased obviously in the monsoon region of china and the vapor from the western pacific ocean decreased tan 2014 chen and li 2018 the change in moisture source finally led to depleted δ18o of precipitation and drip water in the monsoon region of china in the la niña scenario in contrast continuous positive ssta in the niño 3 4 zone indicated the formation of the el niño event during 2014 2015 with the positive isotope excursion appendix fig 4f 4g 4h 4i in this period the wpsh strengthened then migrated southward introducing water vapor to south china along the south margin of the wpsh tan and nan 2010 with this atmospheric circulation pattern more vapor from the relatively close moisture source west pacific and south china sea was transported into the monsoon region of china and resulted in heavier δ18o in precipitation and drip water nan et al 2014 tan 2016 in furong cave the significant change in δ18o δd for the high discharge drip water sites in the winter of 2009 can be attributed to a la niña event appendix fig 4a 4b 4c 4d in contrast the higher drip water δ18o δd values in the winter spring of 2014 2015 responded to an el niño event appendix fig 4f 4g 4h 4i the decreased precipitation in 2007 2009 increased the residence time of groundwater in the epikarst zone and then the drip water responded to enso with a longer time lag than that in 2014 2015 appendix fig 4 more importantly no amount effect between the δ18o of precipitation drip water and local precipitation was observed in 2007 2009 and 2014 2015 it was found that monthly precipitation anomaly exhibited a decreased trend in 2007 2009 outside of furong cave appendix fig 4e however the δ18o of precipitation and drip water were depleted during 2007 2009 appendix fig 4b 4c 4d in addition the δ18o values of precipitation and drip water exhibited heavier values with local precipitation increased during 2014 2015 which was also contrary to amount effect dansgaard 1964 appendix fig 4g 4h 4i 4j it is plausible that at least in the monitoring period although there was a lag of several months between the response of the drip water and the local precipitation the δ18o and δd values of local precipitation and drip water collected from the high discharge monitoring sites in furong cave may be influenced by the changes of moisture source which potentially have the ability to record the changes in atmospheric circulations such as el niño and la niña scenarios zhou and li 2017 chen and li 2018 however further monitoring is essential to remove the randomness and confirm this inference 6 3 assessment on pcp icd and wri for different discharge and hydrological condition during the migration through bedrock above the cave the precipitation and groundwater were affected by pcp icd and wri in the epikarst zone with a change in trace element ratios tooth and fairchild 2003 baldini et al 2006 wong et al 2011 casteel and banner 2015 tadros et al 2016 the slopes of ln mg ca versus ln sr ca in drip water samples with high discharge dw1 mp1 and mp2 and those in drip water samples with low discharge mp3 mp4 and mp5 changed in the range of 0 36 0 39 and 0 17 0 29 respectively fig 5a and 5b it indicated that wri was stronger at the low discharge sites than that at the high discharge sites low discharge sites were mainly supplied by a seepage flow with a relatively slow migration of groundwater high dissolution of bedrock and strong wri casteel and banner 2015 in contrast high discharge sites were supplied by the conduit and fissure flows with a relatively high rate and weak wri in addition wri in the drought years was stronger than that in the wet years because of the minor slope of ln mg ca versus ln sr ca in the drought years fig 5c it can be attributed to the fact that precipitation and groundwater has longer residence times in the bedrock in drought years all the above analyses showed that in the drought years and at the low discharge sites the prolongation of the residence time of groundwater in bedrock and soil strengthened the process of wri significantly li et al 2013 changes in local hydrological conditions were related to the changes in trace element ratios of drip water 6 4 climatic significance comparison of trace element ratios and stable isotopes in drip water during the period of this study different characteristics for the changes in mg ca 1000 sr ca 1000 ba ca δ18o and δd of the drip water in furong cave were observed fig 2 there was a seasonal variation of 1000 sr ca which increased in winter and spring and decreased in summer and autumn fig 2c however the mg ca ratio in drip water responded to the change in local hydrological conditions i e increase of precipitation led to lower mg ca and decrease of precipitation resulted in higher mg ca fig 2b note that no correlation was observed between the drip water δ18o and the monthly precipitation p 0 1 fig 7 a indicating that drip water δ18o did not exhibit the amount effect and could not respond sensitively to the change in the precipitation δ18o fig 2e f 7a although the isotopic composition of drip water inherited the isotopic signal of precipitation section 6 2 the 300 500 m thick bedrock above furong cave led to sufficient mixing of the groundwater in the epikarst zone and shielded the seasonal change in precipitation δ18o li et al 2011 2012 on the other hand by comparing with average δ18o of the drip water and monthly precipitation anomaly outside furong cave over the past 12 years the δ18o of drip water still follows the change of local precipitation at interannual and longer timescales fig 8 a and b however significant correlations were observed between drip water mg ca ratio and monthly precipitation for all drip water sites for dw1 mp1 mp2 mp4 and mp5 p 0 01 for mp3 p 0 05 indicating that the change in drip water mg ca ratio reflected the change in local precipitation fig 7b because of the uncertainty of residence time of groundwater for each drip site it is difficult to estimate the exact residence time of ground water under current technical conditions therefore we do not take residence time of groundwater into account when calculating the correlation between the drip water δ18o and mg ca ratio with the monthly precipitation amount in summary for all drip water samples in furong cave the mg ca ratios and δ18o had different responses to the change in external climate the changes in mg ca ratio were dominated by the variation in local precipitation hydrological conditions while the changes in δ18o of drip water did not make sensitive response to precipitation the different expressions of pcp icd and wri in drip water with high and low discharge in furong cave indicated that the speleothem fed by different drip water underwent different chemical processes therefore a replication test i e demonstration of similar isotopic profiles of two or more sets of speleothems dorale and liu 2009 was more scientifically reliable and robust in paleoclimate reconstruction based on the records of speleothem series of abrupt climatic events on the centennial millennial time scales such as greenland interstadials heinrich events and younger dryas have been recorded by the speleothem records from the china monsoon regions wang et al 2001 2008 li et al 2007 2014 2017 han et al 2016 zhang et al 2017 the speleothem δ18o in furong cave also recorded the change in asm at the termination of the last glacial period li et al 2011 no correlation was observed between the δ18o of drip water and local rainfall assuming no time lag between drip water and local meteoric water fig 7a in contrast change in trace element ratios of drip water eventually made response to the change of local precipitation indicating that the δ18o and the trace element ratios reflected different climatic signals on the monthly and seasonal timescales figs 2 and 7 7 conclusions based on the 12 year monitoring of the δ18o δd and trace element ratios of drip water and local hydrological conditions outside of furong cave southwest china the main conclusions were as follows 1 the mg ca of drip water responded to local hydrological conditions with lower values in wet years and higher values in drought years a seasonal characteristic was observed for the change in 1000 sr ca with an increase in winter and spring and a reduction in summer and autumn the change in ca2 with pcp had an important influence on the change in 1000 sr ca of drip water 2 analysis with the pcp icd wri model may reveal that the influence of wri in the epikarst zone was stronger than that of pcp icd in drought years and the influence of wri on drip water with high discharge was weaker than that on drip water low discharge 3 the δ18o and δd of drip water in furong cave preserved the isotopic signal of precipitation and the range of seasonal change was depressed by the mixing effect with old water in the epikarst zone without any expression of the amount effect on monthly timescale 4 the high resolution e g seasonal and annual δ18o record of speleothem in furong cave may not be useful however δ18o record of speleothem in furong cave may follow with local precipitation on decadal and longer timescales in addition the trace element ratios are potentially reliable proxies in speleothems to record the change of rainfall on annual and seasonal timescales declarations of interest all authors declare no competing interests acknowledgments we would like to express our sincere gratitude to the management department of furong cave for considerable help in the field since 2005 the editor peter k kitanidis associate editor dongmei han and three anonymous reviewers are greatly appreciated for their constructive comments to improve the quality of this paper this research was supported by national natural science foundation of china nsfc no 41772170 and the fundamental research funds for the central universities nos xdjk2017a010 and xdjk2013a012 to t y li a professional english translator dr xiang xinyi southwest university china is also greatly appreciated for her effort in polishing the final version of the manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 02 052 appendix a supplementary data the following are the supplementary data to this article supplementary fig 1 a distribution of soil co2 monitoring sites black triangles sa se above furong cave the black shadow indicates the location of furong cave and the contour lines with elevation are shown as well b profile of furongjiang river and the mountain in which furong cave formed modified from li et al 2012 supplementary fig 2 a variation of soil co2 at five monitoring sites sa se b cave air pco2 at four monitoring sites mp1 mp4 in furong cave c 1000 sr ca d monthly discharge of drip water dw1 and mp1 mp5 e monthly precipitation blue histograms and average air temperature red dots outside furong cave the pink bands indicate summer months june august in easm region supplementary fig 3 variations of kdsr 1 kdmg 1 for drip waters mp1 mp5 in furong cave the red dashed lines represent the possible maximum range of kdsr 1 kdmg 1 based on the published values of kdsr and kdmg by sinclair et al 2012 supplementary fig 4 response of drip water δ18o δd to enso for the high discharge drip waters dw1 mp1 and mp2 in furong cave a f ssta b g δ18o of precipitation c h drip water δ18o d i drip water δd e j monthly precipitation anomaly mm the fitting red dashed lines indicated the trend for the changes the δ18o and δd of the drip waters exhausted enriched during the la niña el niño situations respectively although there was a lag of a few months because of the 300 500 m thick aquifer zone above furong cave supplementary data 1 
6572,localizing leaks of water and fluids from storage tanks and water reservoirs with geomembranes is an important task for a variety of environmental applications and water resources applications the minimally intrusive mise à la masse method is used to detect leaks with the current injected inside the reservoir and a return current electrode located remotely we test a new approach for the inversion of the voltage data using sandbox experiments and numerical modeling a method similar to the self potential inversion method is proposed to inverse the voltages recorded around the tank or reservoir a global objective function with a data misfit term and regularization term is minimized to invert the voltages in the inversion process a depth weighting matrix is used to strengthen the depth resolution of the current source and the minimum support method is used to avoid oversmoothed results in terms of leak detection the distributions of electrical current density on the walls of reservoir indicate the position of leaks the results show that the inversion method with source compaction accurately identifies the location of single leaks for two separated leaks there is an obvious bias for the deeper hole and the bias increases with its depth for three holes the source compaction method generally identifies the location of the three leaks when their depth ranges are similar when one of the leaks becomes deeper localization of the deeper one becomes more difficult the influence of the size of the leak on the inversion results is also investigated the inversion algorithm overestimates the depth of small leaks while it slightly underestimates the depth of large leaks for a leak having the form of a crack the inversion results using the source compaction method agree with the position of the leak and its shape keywords geophysics mise à la masse hydrogeophysics leak mountain reservoir 1 introduction as the world s most important source of drinking water the quality of groundwater should be preserved from the spread of various types of contaminants see world health organization 2006 underground storage tanks used to store inorganic liquid chemicals hydrocarbons and organic compounds can leak because of corrosion and deformation during long term operations jacob and alexander 2010 in addition there is currently an increase of the construction of mountain reservoirs using specific geomembranes for instance in high density polyethylene hdp to store water which is used in the beginning of winter to prepare snow for the ski runs poulain et al 2011 large water reservoirs are most often equipped with drainage systems to collect leaks but many reservoirs do not have this type of drainage equipment and the detection of leaks in the embankment becomes an important technical problem peyras et al 2008 the leaks associated with a storage tank or a water reservoir or a pond with an insulating and impervious boundary is difficult to detect by visual inspection until the leak poses serious pollution to the surrounding groundwater environments or leakage becomes important the most common methods of leak detection include volumetric and mass measurements statistical inventory reconciliation liquid sensing probes and fiber optic sensing probes e g adec 2000 colombo et al 2009 the volumetric and mass measurement and statistical inventory reconciliation use an unexplained loss of mass to indicate the presence of a leak but are not able to detect the positions of leaks musthafa et al 2017 in probe measurements the liquid or chemical content is estimated from the physical properties that are measured by the probes according to the corresponding calibration curves probe measurements provide accurate information about a leak but they have to be preembedded in positions close to the leak the approach is costly when a large number of probes around the storage facility are required cheap non invasive and non destructive techniques are needed to localize leaks of underground storage tanks and reservoirs various active techniques are described in the literature e g manataki et al 2014 but their interpretation in terms of leakage is usually ambiguous especially for mountain reservoirs due to the undulating topography as a geophysical technique the mise à la masse method was originally developed for ore mineral exploration e g parasnis 1967 ketola 1972 it was later used in environmental geophysics and hydrogeology e g binley et al 1997 gan 2017 perri et al 2018 including for the detection of leaks ramirez et al 1996 daily et al 2004 the mise à la masse method is a kind of mix between the resistivity and self potential methods one being an active technique and the second being a passive technique the underlying idea is to illuminate a conductive body at depth by injecting a current that would preferentially flow through this body the resulting electrical potential distribution distorted by the shape of the conductive body is measured in principle two current electrodes a and b are required and a number of voltage measurements are performed with respect to a reference at the ground surface of the earth the voltage measurements themselves are similar in their principle to what is done in a self potential survey corwin and hoover 1979 revil and jardani 2013 one of the current electrodes say a is used to inject the current in the conductive body while the second electrode say b is placed remotely i e far from the survey area by using a mobile potential electrode say m i we consider a total of n stations covered by this electrode the potentials relative to the reference potential electrode n fixed can be mapped the electrical potential map provides some information regarding the shape of the conductive body e g kirsch 2006 the mise à la masse method has been used to find out groundwater flow direction e g white 1994 pant 2004 perri et al 2018 to delineate conductive tracer plumes e g osiensky and donaldson 1995 de carlo et al 2013 and investigate plant roots e g mary et al 2018 binley et al 1997 used the mise à la masse method to evaluate the bottom leakage of environmental barriers in their paper the genetic algorithm was used to inverse the positions of leaks but the searching space will highly increase with the number of leaks currently there is a need to improve the performance of the mise à la masse method for leak detection especially under the three dimensional 3d conditions the goal of the present study is to advance the use of this technique for the detection of leaks in storage tanks and water reservoirs with impervious and insulating geomembranes in this study several tests are carried out using a sandbox experiment for evaluating the position of the leaks on the walls of the reservoir a method similar to self potential localized inversion technique discussed by haas et al 2013 is proposed for the first time for the mise à la masse method these source localization approaches are also similar to what has been proposed in electroencephalography for the localization of brain activity from the voltage distribution measured on the scalp grech et al 2008 2 materials and methods 2 1 experiment setup in order to evaluate the performance of the mise à la masse method for leak detection a plexiglass box with the dimensions of 53 7 cm length 28 5 cm width and 33 4 cm height was used see figs 1 and 2 the silica sand was used in the experiment its physical properties are reported in table 1 the dry density and porosity of this sand are 1 4 g cm3 and 0 37 0 01 respectively the sand was used to fill the sandbox and its overall thickness was 25 cm the box was placed in a room with a constant temperature of 20 2 c the tap water used for the experiment has an electrical conductivity of 440 μs cm at 25 c in order to minimize the entrapment of gas bubbles in the sandbox water was added first then the sand grains until the prescribed thickness of sand was reached the excess water above the sand was pumped out from the tank prior to performing the geophysical measurements the sand was let settling for 24 h so it could compact by gravity the electrical resistivity of the silica sand saturated with the tap water was measured and its value is 100 ω m at room temperature 20 c a plastic reservoir with a height of 8 1 cm and a diameter of 6 cm was used to simulate the storage tank figs 1 and 2 the reservoir was filled with the same tap water used to saturate the sand the water reservoir reached the top surface of the sand and was located in the center of the sandbox the height of the reservoir in the sand is 8 cm the diameter of the leak was set to 0 4 cm experiments were conducted with different leaks in order to study the effect of the number of leaks their depth and their size each leak position is described by two indices an azimuth and a depth in cylindrical coordinates the azimuth denotes the outward direction of leak from the vertical central axis of reservoir with respect to x axis the azimuth is set to 0 rad along the x axis and increases counter clockwise in the x y plane fig 2 the depth is the vertical distance from the leak center to the surface of sandbox table 2 summarizes the physical sandbox experiments we performed the 12 experiments include 4 single leak tests 4 dual leak tests and 4 triple leak tests 2 2 mise à la masse experiments a total of 64 stainless steel electrodes with the diameter of 0 3 cm and a length of 0 7 cm were setup on the sand at the top surface of the sand body fig 1a the positive current electrode a i e current injected in the sand was placed in the water filled reservoir the negative return current electrode b was placed at the left center of the sand body surface i e in a remote position with respect to the monitoring network of electrodes figs 1 and 2 the reference potential electrode n was located close to the right bottom corner at the sand body surface a total of n 61 scanning electrodes m i were used to measure the distributions of potential difference fig 1 these electrodes were radially organized around the reservoir there are 16 electrodes in a lap and the angle between adjacent electrodes is 0 39 rad i e 22 5 from inner to outer distance from the reservoir the distances between the electrode laps and the reservoir boundary were set up to 1 cm 3 cm 6 cm and 10 cm see fig 1a for details in order to keep the position of the electrodes at the same place all of electrodes were fixed on a polyvinyl chloride framework an abem terrameter sas 1000 resistivity meter was used to carry out the mise à la masse measurements the supply current i was set at 20 ma the data of potential differences and corresponding standard deviations were logged automatically we used a total of 64 electrodes two of them being used as the current electrodes therefore there was a total of 62 voltage electrodes one being used as the reference voltage electrode n consequently we had m 61 voltage stations fig 1 2 3 forward modeling we discuss now the forward numerical modeling step of our analysis forward modeling was carried out to simulate the mise à la masse acquisition combining ohm s law with a continuity equation for the electrical charge in an isotropic medium yields the following elliptic equation e g rubin and hubbard 2005 1 σ ψ i δ x x s δ y y s δ z z s where ψ is the electrical potential in v σ denotes the electrical conductivity s m of the material i is the volumetric intensity of the injected current in a m3 δ denotes the dirac distribution and x s y s and z s are the spatial coordinates of a given current electrode in our case eq 1 was numerically solved with two current electrodes a and b with the current of i and i respectively eq 1 is solved with the following boundary conditions 2 ψ 0 on γ d 3 n σ ψ 0 on γ n where γ d and γ n denote dirichlet boundary and neumann boundary respectively the quantity n denotes the unit normal vector of the neumann boundary γ n in practice dirichlet boundary is referred to as a fixed potential boundary while neumann boundary specifies the insulation boundary in our sandbox experiment the upper surface was in contact with air and the remaining five faces were in contact with insulated plexiglass hence the six boundaries of the sand body corresponded to neumann boundaries using a finite element discretization eq 1 is written in a linear form 4 ψ km where ψ denotes an n vector corresponding to the forward electrical potential differences which could be measured with scanning electrodes m is a m model vector corresponding to the source current density at each cell on walls of reservoir n is the number of measured potential stations data while m is the number of discretized cells composing the side faces of reservoir the quantity k denotes the n m kernel matrix it corresponds to the collection of green s functions more precisely each column of k corresponds to the measured electrical potential differences by setting a unit source current density at the corresponding cell and zero current density at the remaining cells because the kernel matrix accounts for the boundary conditions electrical conductivity distribution and electrodes array distribution the green s functions are obtained through numerical modeling using the finite element method with the software comsol multiphysics 5 3 comsol 2017 soueid ahmed et al 2018 the numerical calculation was carried m times by successively setting a unit source current density at one cell and zero current density at the remaining cells ψ and m in eq 4 correspond to ψ x y z and i δ x x s δ y y s δ z z s in eq 1 respectively the remaining term at the left hand of eq 1 corresponds to k 1 in eq 4 for the forward modeling the sandbox was subdivided into approximately twenty thousand tetrahedra fig 2b in the physical and numerical experiments the positive current electrode a was placed in the center of the water filled reservoir when there is a leak in the side face of the reservoir all of the electrical current lines will cross this leak because the reservoir is insulating for the sandbox the leak acts like a positive secondary current source leaks at different positions cause different distributions of potential differences in order to simulate the potential responses the side faces of the plastic reservoir were divided into 48 slices along its circumference and 20 slices along its vertical direction there was therefore a total of 960 cells in the side faces of the reservoir the size of each cell was 0 4 cm 0 4 cm the collection of green functions with a single leak of 0 4 cm diameter at each cell was obtained thanks to the forward modeling using the finite element method the potential difference distributions with two or more leaks is easily obtained using the superposition principle since the problem is linear between the current sources and the voltage distribution 2 4 inverse modeling we propose a method similar to the self potential inversion method see minsley et al 2007 jardani et al 2008 haas et al 2013 soueid ahmed et al 2013 the following objective function with the sum of a data misfit term and a regularization term is subject to minimization see tikhonov and arsenin 1977 5 p λ m w d km ψ obs 2 λ w m m 2 where the first term denotes the data misfit term and the second term denotes the regularization term the quantity λ is a regularization parameter under the constraint of 0 λ the quantity ψ obs is the n vector corresponding to the measured potential difference data the quantity w d diag 1 ε1 1 εn denotes a square diagonal weighting matrix and the symbol diag means that the matrix is a diagonal matrix with elements being the reciprocal of the standard deviations the other elements are set to zero because the noise on the data is assumed to be uncorrelated the quantity w m is a weighting matrix in the regularization term it can be associated to the model covariance matrix in the present case an identity matrix i zero order derivative or minimum norm for w m was used hansen 1992 mao and revil 2016 the optimized model vector can be obtained with a single step as following tikhonov and arsenin 1977 6 m k t w d t w d k λ w m t w m 1 k t w d t w d ψ obs in application because the electric field strength decays as 1 r 2 r being the distance between a source point and an observation point in a homogeneous half space the sensitivity of the potential field decays quickly with the distance to the leak to provide the deeper cells with the equal probability of obtaining nonzero source current density during the inversion compared to the shallow cells in side faces of reservoir a generalized depth weighting function is incorporated into the kernel matrix k the depth weighting matrix is designed to the total sensitivity of observations for a unit current source at a particular cell on walls of reservoir the diagonal elements of the matrix are defined by 7 λ diag j 1 n k ji 2 1 4 i 1 2 m and the off diagonal elements are zero mao and revil 2016 for leak detection a constraint that requires the source model to be localized makes sense elsewhere the source term should be zero to avoid oversmoothed results in the distributions of secondary current density in the side faces of reservoir the minimum support ms method is used zhdanov and tolstaya 2004 this iterative step is done to reach a compact source current density the ms function is defined as 8 m s i 1 m m i 2 m i k 1 2 β 2 where the k 1 subscript refers to a prior estimate of current source density distribution m on walls of reservoir in eq 8 β is a small threshold number the ms function allows the greatest of parameters to have amplitude less than β while the remaining parameters greater than β are not constrained zhdanov and tolstaya 2004 the value of 0 01 was assigned to β in this inversion with the depth weighting matrix and ms function a new diagonal weight matrix is determined as 9 π diag λ ii 2 m i k 1 2 β 2 i 1 2 m the kernel matrix is revised as k k π 1 and eq 6 is therefore modified to be 10 m k t w d t w d k λ w m t w m 1 k t w d t w d ψ obs the actual data inversion starts with a model of uniform current density distribution on the walls of reservoir the initial value of λ is set to 1 and the value is updated with the ratio of data misfit term to regularization term in eq 11 with the new kernel matrix the objective function is transformed into 11 p λ m w d k m ψ obs 2 λ w m m 2 after each iteration the current density of sources can be transformed back to an unscaled current density according to m π 1 m the inversion calculation is repeated until the objective function decrease to a stable value or the maximum iteration steps are reached the distributions of unscaled source current density from the last iteration are used to provide the best estimates of the positions of leaks 3 experimental results 3 1 distribution of measured potential differences the contour maps of the potential difference distribution obtained in the physical experiment with a single leak are shown in fig 3 the values of electrical potential difference close to the leak are the highest the leak is located right below the maximum voltage measured on the top surface of the sand body because the negative current source is located at the leftmost out of the figure area the minimum potential value always locates at the leftmost electrode fig 4 presents the variations of the electrical potential difference obtained for this case for a given current the magnitude of the potential values decreases with the depth of the leak it becomes therefore more challenging to evaluate the position of deep leaks due to the weak signal obtained at the ground surface fig 3d and 4d fig 5 shows the contour maps of the measured potential differences with two leaks with azimuths of 0 rad and 3 14 rad fig 6 shows the variations in the electrical potential differences in order to analyze the impact of hole with the azimuth of 3 14 rad the depth of hole with the azimuth of 0 rad was fixed at 1 0 cm and the depths of hole with the azimuth of 3 14 rad were successively set to 1 0 cm 3 0 cm 5 0 cm and 7 0 cm the maximum values of potential decrease with the number of leaks for a single leak and for two leaks located at the same depth the maximum values are 25 5 v fig 4a and 12 1 v fig 6a respectively the potential values on the left side of the surface of the sand body are mainly dominated by the electrical anomaly associated with the leak on the left of the reservoir and decrease with depth while the potential values for the leak on the right side of the reservoir remain unchanged when the left leak became deeper e g 5 cm there is still a visible difference of potentials around it compared with the distribution of a single leak fig 3a fig 7 presents the contour maps of electrical potentials obtained experimentally with three leaks the depth of leak with the azimuth of 1 57 rad was changed from 1 0 cm to 7 0 cm while the depth of the leaks with azimuths of 0 rad and 3 14 rad was fixed at a depth of 1 0 cm compared to figs 3 and 5 the maximum value of the electrical potential decreases to 10 1 v fig 8 shows the variations in the electrical potentials there are three anomalies when the three leaks are at the same depth when the depth of the leak with the azimuth of 1 57 rad increases the corresponding maximum values gradually become insignificant because of the overlap of potential signals from another two leaks the potential signals from two shallow leaks are too strong to cover the signal from the deeper leak 3 2 evaluation of leaks when the leak is deep the weak signals make the inversion hard to identify its precise position the inversion processes for a single leak at 7 cm depth are shown in fig 9 the distributions of source current density are shown at iterations 1 3 6 and 10 in the compaction processes during the inversion iteration 10 corresponds to the last iteration for which the focus target and therefore convergence is reached it can be seen that the magnitude of the source current density peaks at the true location of the target the inversion results show the accurate location of leak although the electrical potential signal is weak fig 3d fig 10 presents the distributions of source current density for a single leak hole at different locations the inversion method with source compaction accurately identifies the location of single leak the results of two separated leaks are also presented in fig 11 although both of the leaks are identified there is an obvious bias in terms of locating the deeper leak and the bias increases with the depth of this leak for a shallow leak the inversion results are generally accurate due to the strong voltages associated with the leak the signals from the deeper leak could be in the range of noise so that it is prone to noise which deteriorate the inversion results fig 12 shows the distributions of source current density for three leaks the source compaction method generally identifies the location for three leaks with the same depth i e 1 cm although an artifact source appears in the lower right corner when the middle leak becomes deeper it is difficult for the proposed inversion method to identify such a leak some erroneous locations for the leakage start showing up several obvious artifacts appear in fig 12b and c the deeper leak at the depth of 7 cm totally disappears in the inversion results see fig 12d 4 discussion besides the parameters set in the experiment there are still several factors influencing the inversion results such as the distribution of electrical resistivity and the size of the leak the distribution of electrical resistivity is one of the key factors influencing the results in the experiment a homogeneous resistivity of 100 ω m was used in the field experiment electrical resistivity tomography could be carried out to obtain the distribution of electrical resistivity which is beneficial for constructing the kernel matrix and producing better source results regarding the issue related to the size of the leak we supposed that identical size i e diameter 0 4 cm for the leaks and cells in the experiment in application we don t know the actual size of the leak in order to test the influence of actual size on the evaluation results we simulated the forward and inversion processes random noises of 0 5 were added to the simulated potential data the depth of the leak was set to 5 0 cm the simulated results with a single leak of 0 2 cm 0 3 cm 0 6 cm and 0 8 cm are shown in fig 13 all of the sources are located in the interval 3 142 0 131 rad 3 142 0 131 rad along the circumference the quantity 0 131 rad denotes the discretization of the azimuthal angle in radian i e 7 5 the size of the leak has also an obvious influence on the evaluated depth resulting from the inversion in general the algorithm overestimates the depth for the smaller size of hole i e 0 3 cm while it slightly underestimates the depth for the bigger size of the leak i e 0 6 cm and 0 8 cm the leak with the diameter of 0 2 mm is wrongly located the evaluated depth was 6 2 cm and the bias increases to 1 2 cm in order to further investigate the influence of the size of the leak on the inversion results we numerically simulated the potential data and then we contaminated these data with a white noise level of a maximum of 5 before proceeding to the inversion of these synthetic data the kernel matrix with cell of 0 4 cm 0 4 cm was used in the inversion process fig 14 shows the comparison of inversed depth for different size holes the dotted lines denote the real depths of holes while the scatter points denote the inverted depths although the results are influenced by the noise the inversion method generally overestimates the depth for the leak hole with diameter less than 0 4 cm compared with the bigger size the magnitude of depth bias becomes larger for the smaller size of leak the potential difference data of inner lap of electrodes i e no 2 17 in fig 1a are used to illustrate the influence of hole size in fig 15 compared with potential data with the hole of 0 4 cm diameter the peak values of electrical potential i e from 2 36 rad to 3 93 rad decrease while other values increase for the leak of 0 2 cm diameter i e the solid circles in fig 15a and d in the opposite for a leak of 0 8 cm in diameter the peak values of the electrical potential i e from 2 36 rad to 3 93 rad increase while the other values decrease i e the crosses in fig 15a and d the variable magnitudes for the leak of 0 2 cm diameter are almost twice of that for the leak hole of 0 8 cm in diameter for example comparing to the peak of potential i e 3 28 v in fig 15d with a leak of 0 4 cm the potential magnitude decreases by 0 77 v for the leak of 0 2 cm diameter while that increases by 0 44 v for the leak of 0 8 cm when the diameter of a leak is kept at 0 4 cm the surface potential decreases with the depth of the leak which has the similar influence with the shrink of the size of the leak fig 15b and e on the contrary compared with the decreased depth of the leak the increase in the size of the leak has a similar influence on the surface potential fig 15c and f the fundamental reason of this phenomenon lies in the fact that the inversion of potential data is ill posed and does not have a unique solution besides the case of an isolated circular leak other shape of leak can be investigated for instance we evaluate a leak having the shape of a crack which can be due to for instance the deformation of the geomembrane over time the linear superposition of distributed holes is used to model such a crack and random noises with a level of 0 5 are added to the simulated potential data fig 16 shows the inversion results three holes and five holes used to simulate the crack the inversion method slightly underestimates the depth of the resulting leak at the tilt direction in general the inversion results show however the correct position of such a leak which indicates that the source compaction method could be used to evaluate the leakages due to elongated leaks in the geomembrane 5 conclusions as an inexpensive minimally invasive nondestructive geophysical technique the mise à la masse method can be used to detect leakages in the underground storage tank or reservoir a series of sandbox experiments were conducted to evaluate a new strategy of leak detection for evaluating the position of the leaks a method similar to the self potential inversion method was proposed in the forward modeling the elliptic equation for the electrical potential was solved with the finite element method and the kernel matrix was obtained in the inversion process a global objective function with a data misfit term and regularization term was used a depth weighting matrix was used to strengthen the depth resolution and the minimum support method was used to avoid the oversmoothed result the results show that the inversion method with source compaction accurately identifies the location of single leak hole for two separated leak holes there is an obvious bias for the deeper hole and the bias increases with the depth for three leaks the source compaction method generally identifies the location when their depths are similar when one of the leaks is deeper it may be more difficult for the inversion algorithm to correctly identify the deeper leak the influence of the size of leak on the inversion results is also analyzed the inversion algorithm overestimates the depth for a small size leak while it slightly underestimates the depth of big leaks for a leak having the shape of a crack elongated leak the inversion results show the correct position and shape of the leak which indicates that the source compaction method could be efficiently used to evaluate the position of such leaks the next step will be to apply this method to the field in principle the present approach is entirely scalable since the current used in the field can be increased by improving the contact impedance between the electrodes a and b and the soil or the bottom of the reservoir in absence of leak it would be impossible to inject any current in present of leak the compaction algorithm should be able to localize the position and size of the leak acknowledgements this work was supported by the state key laboratory of geohazard prevention and geoenvironment protection chengdu university of technology no 2007da810083 it is also supported by the project resba alcotra funded by the european community the postdoc of abdellahi soueid ahmed is funded by edf through a contract with the cnrs we thank the two referees for their very useful review of our manuscript appendix a supplementary material supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 02 046 appendix a supplementary material the following are the supplementary data to this article supplementary data 1 
6572,localizing leaks of water and fluids from storage tanks and water reservoirs with geomembranes is an important task for a variety of environmental applications and water resources applications the minimally intrusive mise à la masse method is used to detect leaks with the current injected inside the reservoir and a return current electrode located remotely we test a new approach for the inversion of the voltage data using sandbox experiments and numerical modeling a method similar to the self potential inversion method is proposed to inverse the voltages recorded around the tank or reservoir a global objective function with a data misfit term and regularization term is minimized to invert the voltages in the inversion process a depth weighting matrix is used to strengthen the depth resolution of the current source and the minimum support method is used to avoid oversmoothed results in terms of leak detection the distributions of electrical current density on the walls of reservoir indicate the position of leaks the results show that the inversion method with source compaction accurately identifies the location of single leaks for two separated leaks there is an obvious bias for the deeper hole and the bias increases with its depth for three holes the source compaction method generally identifies the location of the three leaks when their depth ranges are similar when one of the leaks becomes deeper localization of the deeper one becomes more difficult the influence of the size of the leak on the inversion results is also investigated the inversion algorithm overestimates the depth of small leaks while it slightly underestimates the depth of large leaks for a leak having the form of a crack the inversion results using the source compaction method agree with the position of the leak and its shape keywords geophysics mise à la masse hydrogeophysics leak mountain reservoir 1 introduction as the world s most important source of drinking water the quality of groundwater should be preserved from the spread of various types of contaminants see world health organization 2006 underground storage tanks used to store inorganic liquid chemicals hydrocarbons and organic compounds can leak because of corrosion and deformation during long term operations jacob and alexander 2010 in addition there is currently an increase of the construction of mountain reservoirs using specific geomembranes for instance in high density polyethylene hdp to store water which is used in the beginning of winter to prepare snow for the ski runs poulain et al 2011 large water reservoirs are most often equipped with drainage systems to collect leaks but many reservoirs do not have this type of drainage equipment and the detection of leaks in the embankment becomes an important technical problem peyras et al 2008 the leaks associated with a storage tank or a water reservoir or a pond with an insulating and impervious boundary is difficult to detect by visual inspection until the leak poses serious pollution to the surrounding groundwater environments or leakage becomes important the most common methods of leak detection include volumetric and mass measurements statistical inventory reconciliation liquid sensing probes and fiber optic sensing probes e g adec 2000 colombo et al 2009 the volumetric and mass measurement and statistical inventory reconciliation use an unexplained loss of mass to indicate the presence of a leak but are not able to detect the positions of leaks musthafa et al 2017 in probe measurements the liquid or chemical content is estimated from the physical properties that are measured by the probes according to the corresponding calibration curves probe measurements provide accurate information about a leak but they have to be preembedded in positions close to the leak the approach is costly when a large number of probes around the storage facility are required cheap non invasive and non destructive techniques are needed to localize leaks of underground storage tanks and reservoirs various active techniques are described in the literature e g manataki et al 2014 but their interpretation in terms of leakage is usually ambiguous especially for mountain reservoirs due to the undulating topography as a geophysical technique the mise à la masse method was originally developed for ore mineral exploration e g parasnis 1967 ketola 1972 it was later used in environmental geophysics and hydrogeology e g binley et al 1997 gan 2017 perri et al 2018 including for the detection of leaks ramirez et al 1996 daily et al 2004 the mise à la masse method is a kind of mix between the resistivity and self potential methods one being an active technique and the second being a passive technique the underlying idea is to illuminate a conductive body at depth by injecting a current that would preferentially flow through this body the resulting electrical potential distribution distorted by the shape of the conductive body is measured in principle two current electrodes a and b are required and a number of voltage measurements are performed with respect to a reference at the ground surface of the earth the voltage measurements themselves are similar in their principle to what is done in a self potential survey corwin and hoover 1979 revil and jardani 2013 one of the current electrodes say a is used to inject the current in the conductive body while the second electrode say b is placed remotely i e far from the survey area by using a mobile potential electrode say m i we consider a total of n stations covered by this electrode the potentials relative to the reference potential electrode n fixed can be mapped the electrical potential map provides some information regarding the shape of the conductive body e g kirsch 2006 the mise à la masse method has been used to find out groundwater flow direction e g white 1994 pant 2004 perri et al 2018 to delineate conductive tracer plumes e g osiensky and donaldson 1995 de carlo et al 2013 and investigate plant roots e g mary et al 2018 binley et al 1997 used the mise à la masse method to evaluate the bottom leakage of environmental barriers in their paper the genetic algorithm was used to inverse the positions of leaks but the searching space will highly increase with the number of leaks currently there is a need to improve the performance of the mise à la masse method for leak detection especially under the three dimensional 3d conditions the goal of the present study is to advance the use of this technique for the detection of leaks in storage tanks and water reservoirs with impervious and insulating geomembranes in this study several tests are carried out using a sandbox experiment for evaluating the position of the leaks on the walls of the reservoir a method similar to self potential localized inversion technique discussed by haas et al 2013 is proposed for the first time for the mise à la masse method these source localization approaches are also similar to what has been proposed in electroencephalography for the localization of brain activity from the voltage distribution measured on the scalp grech et al 2008 2 materials and methods 2 1 experiment setup in order to evaluate the performance of the mise à la masse method for leak detection a plexiglass box with the dimensions of 53 7 cm length 28 5 cm width and 33 4 cm height was used see figs 1 and 2 the silica sand was used in the experiment its physical properties are reported in table 1 the dry density and porosity of this sand are 1 4 g cm3 and 0 37 0 01 respectively the sand was used to fill the sandbox and its overall thickness was 25 cm the box was placed in a room with a constant temperature of 20 2 c the tap water used for the experiment has an electrical conductivity of 440 μs cm at 25 c in order to minimize the entrapment of gas bubbles in the sandbox water was added first then the sand grains until the prescribed thickness of sand was reached the excess water above the sand was pumped out from the tank prior to performing the geophysical measurements the sand was let settling for 24 h so it could compact by gravity the electrical resistivity of the silica sand saturated with the tap water was measured and its value is 100 ω m at room temperature 20 c a plastic reservoir with a height of 8 1 cm and a diameter of 6 cm was used to simulate the storage tank figs 1 and 2 the reservoir was filled with the same tap water used to saturate the sand the water reservoir reached the top surface of the sand and was located in the center of the sandbox the height of the reservoir in the sand is 8 cm the diameter of the leak was set to 0 4 cm experiments were conducted with different leaks in order to study the effect of the number of leaks their depth and their size each leak position is described by two indices an azimuth and a depth in cylindrical coordinates the azimuth denotes the outward direction of leak from the vertical central axis of reservoir with respect to x axis the azimuth is set to 0 rad along the x axis and increases counter clockwise in the x y plane fig 2 the depth is the vertical distance from the leak center to the surface of sandbox table 2 summarizes the physical sandbox experiments we performed the 12 experiments include 4 single leak tests 4 dual leak tests and 4 triple leak tests 2 2 mise à la masse experiments a total of 64 stainless steel electrodes with the diameter of 0 3 cm and a length of 0 7 cm were setup on the sand at the top surface of the sand body fig 1a the positive current electrode a i e current injected in the sand was placed in the water filled reservoir the negative return current electrode b was placed at the left center of the sand body surface i e in a remote position with respect to the monitoring network of electrodes figs 1 and 2 the reference potential electrode n was located close to the right bottom corner at the sand body surface a total of n 61 scanning electrodes m i were used to measure the distributions of potential difference fig 1 these electrodes were radially organized around the reservoir there are 16 electrodes in a lap and the angle between adjacent electrodes is 0 39 rad i e 22 5 from inner to outer distance from the reservoir the distances between the electrode laps and the reservoir boundary were set up to 1 cm 3 cm 6 cm and 10 cm see fig 1a for details in order to keep the position of the electrodes at the same place all of electrodes were fixed on a polyvinyl chloride framework an abem terrameter sas 1000 resistivity meter was used to carry out the mise à la masse measurements the supply current i was set at 20 ma the data of potential differences and corresponding standard deviations were logged automatically we used a total of 64 electrodes two of them being used as the current electrodes therefore there was a total of 62 voltage electrodes one being used as the reference voltage electrode n consequently we had m 61 voltage stations fig 1 2 3 forward modeling we discuss now the forward numerical modeling step of our analysis forward modeling was carried out to simulate the mise à la masse acquisition combining ohm s law with a continuity equation for the electrical charge in an isotropic medium yields the following elliptic equation e g rubin and hubbard 2005 1 σ ψ i δ x x s δ y y s δ z z s where ψ is the electrical potential in v σ denotes the electrical conductivity s m of the material i is the volumetric intensity of the injected current in a m3 δ denotes the dirac distribution and x s y s and z s are the spatial coordinates of a given current electrode in our case eq 1 was numerically solved with two current electrodes a and b with the current of i and i respectively eq 1 is solved with the following boundary conditions 2 ψ 0 on γ d 3 n σ ψ 0 on γ n where γ d and γ n denote dirichlet boundary and neumann boundary respectively the quantity n denotes the unit normal vector of the neumann boundary γ n in practice dirichlet boundary is referred to as a fixed potential boundary while neumann boundary specifies the insulation boundary in our sandbox experiment the upper surface was in contact with air and the remaining five faces were in contact with insulated plexiglass hence the six boundaries of the sand body corresponded to neumann boundaries using a finite element discretization eq 1 is written in a linear form 4 ψ km where ψ denotes an n vector corresponding to the forward electrical potential differences which could be measured with scanning electrodes m is a m model vector corresponding to the source current density at each cell on walls of reservoir n is the number of measured potential stations data while m is the number of discretized cells composing the side faces of reservoir the quantity k denotes the n m kernel matrix it corresponds to the collection of green s functions more precisely each column of k corresponds to the measured electrical potential differences by setting a unit source current density at the corresponding cell and zero current density at the remaining cells because the kernel matrix accounts for the boundary conditions electrical conductivity distribution and electrodes array distribution the green s functions are obtained through numerical modeling using the finite element method with the software comsol multiphysics 5 3 comsol 2017 soueid ahmed et al 2018 the numerical calculation was carried m times by successively setting a unit source current density at one cell and zero current density at the remaining cells ψ and m in eq 4 correspond to ψ x y z and i δ x x s δ y y s δ z z s in eq 1 respectively the remaining term at the left hand of eq 1 corresponds to k 1 in eq 4 for the forward modeling the sandbox was subdivided into approximately twenty thousand tetrahedra fig 2b in the physical and numerical experiments the positive current electrode a was placed in the center of the water filled reservoir when there is a leak in the side face of the reservoir all of the electrical current lines will cross this leak because the reservoir is insulating for the sandbox the leak acts like a positive secondary current source leaks at different positions cause different distributions of potential differences in order to simulate the potential responses the side faces of the plastic reservoir were divided into 48 slices along its circumference and 20 slices along its vertical direction there was therefore a total of 960 cells in the side faces of the reservoir the size of each cell was 0 4 cm 0 4 cm the collection of green functions with a single leak of 0 4 cm diameter at each cell was obtained thanks to the forward modeling using the finite element method the potential difference distributions with two or more leaks is easily obtained using the superposition principle since the problem is linear between the current sources and the voltage distribution 2 4 inverse modeling we propose a method similar to the self potential inversion method see minsley et al 2007 jardani et al 2008 haas et al 2013 soueid ahmed et al 2013 the following objective function with the sum of a data misfit term and a regularization term is subject to minimization see tikhonov and arsenin 1977 5 p λ m w d km ψ obs 2 λ w m m 2 where the first term denotes the data misfit term and the second term denotes the regularization term the quantity λ is a regularization parameter under the constraint of 0 λ the quantity ψ obs is the n vector corresponding to the measured potential difference data the quantity w d diag 1 ε1 1 εn denotes a square diagonal weighting matrix and the symbol diag means that the matrix is a diagonal matrix with elements being the reciprocal of the standard deviations the other elements are set to zero because the noise on the data is assumed to be uncorrelated the quantity w m is a weighting matrix in the regularization term it can be associated to the model covariance matrix in the present case an identity matrix i zero order derivative or minimum norm for w m was used hansen 1992 mao and revil 2016 the optimized model vector can be obtained with a single step as following tikhonov and arsenin 1977 6 m k t w d t w d k λ w m t w m 1 k t w d t w d ψ obs in application because the electric field strength decays as 1 r 2 r being the distance between a source point and an observation point in a homogeneous half space the sensitivity of the potential field decays quickly with the distance to the leak to provide the deeper cells with the equal probability of obtaining nonzero source current density during the inversion compared to the shallow cells in side faces of reservoir a generalized depth weighting function is incorporated into the kernel matrix k the depth weighting matrix is designed to the total sensitivity of observations for a unit current source at a particular cell on walls of reservoir the diagonal elements of the matrix are defined by 7 λ diag j 1 n k ji 2 1 4 i 1 2 m and the off diagonal elements are zero mao and revil 2016 for leak detection a constraint that requires the source model to be localized makes sense elsewhere the source term should be zero to avoid oversmoothed results in the distributions of secondary current density in the side faces of reservoir the minimum support ms method is used zhdanov and tolstaya 2004 this iterative step is done to reach a compact source current density the ms function is defined as 8 m s i 1 m m i 2 m i k 1 2 β 2 where the k 1 subscript refers to a prior estimate of current source density distribution m on walls of reservoir in eq 8 β is a small threshold number the ms function allows the greatest of parameters to have amplitude less than β while the remaining parameters greater than β are not constrained zhdanov and tolstaya 2004 the value of 0 01 was assigned to β in this inversion with the depth weighting matrix and ms function a new diagonal weight matrix is determined as 9 π diag λ ii 2 m i k 1 2 β 2 i 1 2 m the kernel matrix is revised as k k π 1 and eq 6 is therefore modified to be 10 m k t w d t w d k λ w m t w m 1 k t w d t w d ψ obs the actual data inversion starts with a model of uniform current density distribution on the walls of reservoir the initial value of λ is set to 1 and the value is updated with the ratio of data misfit term to regularization term in eq 11 with the new kernel matrix the objective function is transformed into 11 p λ m w d k m ψ obs 2 λ w m m 2 after each iteration the current density of sources can be transformed back to an unscaled current density according to m π 1 m the inversion calculation is repeated until the objective function decrease to a stable value or the maximum iteration steps are reached the distributions of unscaled source current density from the last iteration are used to provide the best estimates of the positions of leaks 3 experimental results 3 1 distribution of measured potential differences the contour maps of the potential difference distribution obtained in the physical experiment with a single leak are shown in fig 3 the values of electrical potential difference close to the leak are the highest the leak is located right below the maximum voltage measured on the top surface of the sand body because the negative current source is located at the leftmost out of the figure area the minimum potential value always locates at the leftmost electrode fig 4 presents the variations of the electrical potential difference obtained for this case for a given current the magnitude of the potential values decreases with the depth of the leak it becomes therefore more challenging to evaluate the position of deep leaks due to the weak signal obtained at the ground surface fig 3d and 4d fig 5 shows the contour maps of the measured potential differences with two leaks with azimuths of 0 rad and 3 14 rad fig 6 shows the variations in the electrical potential differences in order to analyze the impact of hole with the azimuth of 3 14 rad the depth of hole with the azimuth of 0 rad was fixed at 1 0 cm and the depths of hole with the azimuth of 3 14 rad were successively set to 1 0 cm 3 0 cm 5 0 cm and 7 0 cm the maximum values of potential decrease with the number of leaks for a single leak and for two leaks located at the same depth the maximum values are 25 5 v fig 4a and 12 1 v fig 6a respectively the potential values on the left side of the surface of the sand body are mainly dominated by the electrical anomaly associated with the leak on the left of the reservoir and decrease with depth while the potential values for the leak on the right side of the reservoir remain unchanged when the left leak became deeper e g 5 cm there is still a visible difference of potentials around it compared with the distribution of a single leak fig 3a fig 7 presents the contour maps of electrical potentials obtained experimentally with three leaks the depth of leak with the azimuth of 1 57 rad was changed from 1 0 cm to 7 0 cm while the depth of the leaks with azimuths of 0 rad and 3 14 rad was fixed at a depth of 1 0 cm compared to figs 3 and 5 the maximum value of the electrical potential decreases to 10 1 v fig 8 shows the variations in the electrical potentials there are three anomalies when the three leaks are at the same depth when the depth of the leak with the azimuth of 1 57 rad increases the corresponding maximum values gradually become insignificant because of the overlap of potential signals from another two leaks the potential signals from two shallow leaks are too strong to cover the signal from the deeper leak 3 2 evaluation of leaks when the leak is deep the weak signals make the inversion hard to identify its precise position the inversion processes for a single leak at 7 cm depth are shown in fig 9 the distributions of source current density are shown at iterations 1 3 6 and 10 in the compaction processes during the inversion iteration 10 corresponds to the last iteration for which the focus target and therefore convergence is reached it can be seen that the magnitude of the source current density peaks at the true location of the target the inversion results show the accurate location of leak although the electrical potential signal is weak fig 3d fig 10 presents the distributions of source current density for a single leak hole at different locations the inversion method with source compaction accurately identifies the location of single leak the results of two separated leaks are also presented in fig 11 although both of the leaks are identified there is an obvious bias in terms of locating the deeper leak and the bias increases with the depth of this leak for a shallow leak the inversion results are generally accurate due to the strong voltages associated with the leak the signals from the deeper leak could be in the range of noise so that it is prone to noise which deteriorate the inversion results fig 12 shows the distributions of source current density for three leaks the source compaction method generally identifies the location for three leaks with the same depth i e 1 cm although an artifact source appears in the lower right corner when the middle leak becomes deeper it is difficult for the proposed inversion method to identify such a leak some erroneous locations for the leakage start showing up several obvious artifacts appear in fig 12b and c the deeper leak at the depth of 7 cm totally disappears in the inversion results see fig 12d 4 discussion besides the parameters set in the experiment there are still several factors influencing the inversion results such as the distribution of electrical resistivity and the size of the leak the distribution of electrical resistivity is one of the key factors influencing the results in the experiment a homogeneous resistivity of 100 ω m was used in the field experiment electrical resistivity tomography could be carried out to obtain the distribution of electrical resistivity which is beneficial for constructing the kernel matrix and producing better source results regarding the issue related to the size of the leak we supposed that identical size i e diameter 0 4 cm for the leaks and cells in the experiment in application we don t know the actual size of the leak in order to test the influence of actual size on the evaluation results we simulated the forward and inversion processes random noises of 0 5 were added to the simulated potential data the depth of the leak was set to 5 0 cm the simulated results with a single leak of 0 2 cm 0 3 cm 0 6 cm and 0 8 cm are shown in fig 13 all of the sources are located in the interval 3 142 0 131 rad 3 142 0 131 rad along the circumference the quantity 0 131 rad denotes the discretization of the azimuthal angle in radian i e 7 5 the size of the leak has also an obvious influence on the evaluated depth resulting from the inversion in general the algorithm overestimates the depth for the smaller size of hole i e 0 3 cm while it slightly underestimates the depth for the bigger size of the leak i e 0 6 cm and 0 8 cm the leak with the diameter of 0 2 mm is wrongly located the evaluated depth was 6 2 cm and the bias increases to 1 2 cm in order to further investigate the influence of the size of the leak on the inversion results we numerically simulated the potential data and then we contaminated these data with a white noise level of a maximum of 5 before proceeding to the inversion of these synthetic data the kernel matrix with cell of 0 4 cm 0 4 cm was used in the inversion process fig 14 shows the comparison of inversed depth for different size holes the dotted lines denote the real depths of holes while the scatter points denote the inverted depths although the results are influenced by the noise the inversion method generally overestimates the depth for the leak hole with diameter less than 0 4 cm compared with the bigger size the magnitude of depth bias becomes larger for the smaller size of leak the potential difference data of inner lap of electrodes i e no 2 17 in fig 1a are used to illustrate the influence of hole size in fig 15 compared with potential data with the hole of 0 4 cm diameter the peak values of electrical potential i e from 2 36 rad to 3 93 rad decrease while other values increase for the leak of 0 2 cm diameter i e the solid circles in fig 15a and d in the opposite for a leak of 0 8 cm in diameter the peak values of the electrical potential i e from 2 36 rad to 3 93 rad increase while the other values decrease i e the crosses in fig 15a and d the variable magnitudes for the leak of 0 2 cm diameter are almost twice of that for the leak hole of 0 8 cm in diameter for example comparing to the peak of potential i e 3 28 v in fig 15d with a leak of 0 4 cm the potential magnitude decreases by 0 77 v for the leak of 0 2 cm diameter while that increases by 0 44 v for the leak of 0 8 cm when the diameter of a leak is kept at 0 4 cm the surface potential decreases with the depth of the leak which has the similar influence with the shrink of the size of the leak fig 15b and e on the contrary compared with the decreased depth of the leak the increase in the size of the leak has a similar influence on the surface potential fig 15c and f the fundamental reason of this phenomenon lies in the fact that the inversion of potential data is ill posed and does not have a unique solution besides the case of an isolated circular leak other shape of leak can be investigated for instance we evaluate a leak having the shape of a crack which can be due to for instance the deformation of the geomembrane over time the linear superposition of distributed holes is used to model such a crack and random noises with a level of 0 5 are added to the simulated potential data fig 16 shows the inversion results three holes and five holes used to simulate the crack the inversion method slightly underestimates the depth of the resulting leak at the tilt direction in general the inversion results show however the correct position of such a leak which indicates that the source compaction method could be used to evaluate the leakages due to elongated leaks in the geomembrane 5 conclusions as an inexpensive minimally invasive nondestructive geophysical technique the mise à la masse method can be used to detect leakages in the underground storage tank or reservoir a series of sandbox experiments were conducted to evaluate a new strategy of leak detection for evaluating the position of the leaks a method similar to the self potential inversion method was proposed in the forward modeling the elliptic equation for the electrical potential was solved with the finite element method and the kernel matrix was obtained in the inversion process a global objective function with a data misfit term and regularization term was used a depth weighting matrix was used to strengthen the depth resolution and the minimum support method was used to avoid the oversmoothed result the results show that the inversion method with source compaction accurately identifies the location of single leak hole for two separated leak holes there is an obvious bias for the deeper hole and the bias increases with the depth for three leaks the source compaction method generally identifies the location when their depths are similar when one of the leaks is deeper it may be more difficult for the inversion algorithm to correctly identify the deeper leak the influence of the size of leak on the inversion results is also analyzed the inversion algorithm overestimates the depth for a small size leak while it slightly underestimates the depth of big leaks for a leak having the shape of a crack elongated leak the inversion results show the correct position and shape of the leak which indicates that the source compaction method could be efficiently used to evaluate the position of such leaks the next step will be to apply this method to the field in principle the present approach is entirely scalable since the current used in the field can be increased by improving the contact impedance between the electrodes a and b and the soil or the bottom of the reservoir in absence of leak it would be impossible to inject any current in present of leak the compaction algorithm should be able to localize the position and size of the leak acknowledgements this work was supported by the state key laboratory of geohazard prevention and geoenvironment protection chengdu university of technology no 2007da810083 it is also supported by the project resba alcotra funded by the european community the postdoc of abdellahi soueid ahmed is funded by edf through a contract with the cnrs we thank the two referees for their very useful review of our manuscript appendix a supplementary material supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 02 046 appendix a supplementary material the following are the supplementary data to this article supplementary data 1 
6573,different river networks in nature have distinct features depending on regional constraints these affect the development of the river network and form different characteristics the differences in drainage networks help in distinguishing between various network types and understanding natural processes the aim of this study is to develop a new and simple classification method for determining various river network types based on a critical parameter of river networks the tributary junction angle for the analysis fifty river networks are predefined as five network types dendritic parallel pinnate rectangular and trellis networks the tributary junction angles are calculated for each drainage network type and then the beta distribution is employed to identify distributional characteristics of the junction angles parameter estimates of the beta distribution are used to classify different river networks because the estimates provide classified features of natural processes support vector machines are then utilized to determine the network classification with the parameter estimates furthermore the results are validated against classification using a different approach with commonly used statistics the proposed method can clearly distinguish between different network types except for the rectangular and trellis types in addition parameter estimates of the beta distribution indicate differences in drainage network types more clearly than the statistics of the angles overall the parameter estimates of beta distribution have high potential for application to the classification of river networks keywords drainage network types tributary junction angles beta distribution support vector machines 1 introduction in nature river networks can present significantly distinct characteristics depending on physiographic climatic and topographic constraints which affect the occurrence of drainage networks considering the differences among river networks the features of drainage networks can be analyzed and various classes of channel network can be determined such as dendritic parallel pinnate rectangular and trellis networks abrahams and flint 1983 howard 1967 parvis 1949 phillips and schumm 1987 zernitz 1932 zhang and guilbert 2013 a dendritic network typically has a tree like pattern characterized by wide basin shapes and tributaries merging at moderately acute junction angles a parallel network tends to represent a parallel form with straight stream courses and tributaries merging at acute angles a pinnate network has a feather like pattern with very straight major stream courses oriented along a single direction and many small tributaries merging at highly acute angles a rectangular network has channel sinuosity characterized by many right angle bends and tributaries that merge at right angles a trellis network exhibits a lattice like pattern with many short tributaries that merge at nearly right angles examples of these networks are shown in fig 1 in the present study these five river network types are used to develop a classification system however more network types exist in nature for example radial and centripetal networks represent the arrangement of drainage patterns where streams flow inward toward a closed central depression a radial network is characterized by volcanoes domes and erosion residuals a centripetal network is associated with craters calderas and other depressions as a modification of the radial pattern reticulate networks form as a net and generally occur on floodplains and deltas where rivers interlace with each other to account for such differences between various channel networks several authors have developed methods to classify network types using several river network features for instance argialas et al 1988 distinguished eight drainage network types including dendritic parallel pinnate rectangular and trellis based on fifteen attributes of networks ichoku and chorowicz 1994 developed a quantitative classification system to determine different networks using fourteen network characteristics based on digital elevation models dems mejía and niemann 2008 also proposed another classification method to identify five types of channel networks using three measures derived from scaling invariance in the planform geometry of drainage networks the three measures are the incremental accumulation of basin area along channels irregularity of stream courses and junction angles shaped by merging channels in a more recent study jung et al 2015 presented a river network classification method based on the secondary tributary lengths and tributary junction angles jung et al 2015 analyzed the cumulative distributions of the secondary tributary lengths in different ranges of junction angles to derive the exponent of the power law for the classification although these approaches objectively discriminate between various drainage networks quantitatively in the classification of networks they require several characteristics of channel networks and involve complex procedures different characteristics of river networks play a significant role in hydrological studies such as regional frequency analysis for obtaining hydrological estimates of ungauged basins chebana and ouarda 2009 in regional frequency analysis defining homogenous regions with a high level of hydrological similarity is significant for acquiring hydrological information the delineation of groups of regions depends on a set of physiographical and meteorological variables which influence the development of river basins wazneh et al 2015 different river network types may be potentially used as an important indicator in the estimation step of regional frequency analysis jung et al 2017 this may significantly enhance the quality of regional hydrological estimates of ungauged sites in the present work we aim to propose a simple and robust method for river network classification using the beta distribution of tributary junction angles two shape parameters of the beta distribution have been used for classification analysis and hydrological analysis arai et al 1995 bhunya et al 2004 seo and baek 2004 with this beta distribution this study directly determines river network types of fifty river networks in the usa by establishing a relationship between the parameters to identify the classification system of each network type we use support vector machines svms which are supervised machine learning classifiers then river basins classified using another method are used to validate the proposed approach the remainder of this paper is organized as follows section 2 describes the data sets used in the present study section 3 presents the methodologies for classifying the drainage networks section 4 gives the results and discussion section 5 summarizes the conclusions 2 data and methodology 2 1 data set in this study fifty drainage networks are selected for development of the new approach for classifying drainage networks into dendritic parallel pinnate rectangular and trellis types following previous studies on classifying drainage networks abrahams and flint 1983 jung and ouarda 2017 lubowe 1964 phillips and schumm 1987 zernitz 1932 several studies considered fifty river networks in proposing new methods for network classification jung et al 2015 mejía and niemann 2008 the fifty networks used in the present work are shown in table 1 along with the locations of the basin outlet basin areas and drainage network types the selected river networks have basin sizes ranging from 6 to 898 km2 in addition 10 river networks in the usa are used to test the proposed method table 2 for the river network classification dems were obtained from the seamless data distribution system sdds of the u s geological survey usgs these dems are used to estimate flow directions then the flow directions are used to determine contributing areas by summing up the total areas flowing through all grid cells to define the watersheds the dems have a horizontal resolution of 1 and a grid cell of 30 m with a linear dimension the spatial resolution is 30 m which is commonly used for the analysis of drainage networks ijjasz vasquez and bras 1995 moglen and bras 1995 o callaghan and mark 1984 tarboton et al 1991 mejía and niemann 2008 used different grid cell sizes such as 30 m and 90 m in examining channel networks while proposing a method for river network classification and they found that the classification results were not affected by the different resolutions 2 2 methodology 2 2 1 estimation of tributary junction angles among various features of river networks the tributary junction angle has been used to investigate river basins and identify differences in channel networks affected by local conditions variations in the tributary junction angles of different river networks have been observed abrahams and flint 1983 hackney and carling 2011 jung et al 2015 phillips and schumm 1987 in particular parallel and pinnate networks tend to have an abundance of very acute tributary junction angles while rectangular and trellis networks tend to have an abundance of nearly perpendicular tributary junction angles with the identification of characteristics of the tributary junction angles river network classification methods have been examined and proposed to improve our understanding of natural processes mejía and niemann 2008 jung et al 2015 in river network analysis the tributary junction angle at every junction between the primary and secondary tributaries is estimated as a major parameter of river networks the primary tributary is obtained based on the chord between the junction and a point determined by the euclidean distance upstream from the junction on the larger tributary in a river basin the secondary tributary is obtained based on the chord between the junction and a point determined by the euclidean distance upstream from the junction on the smaller tributary in the river basin a comprehensive description of the method for calculating the tributary junction angles is presented in mejía and niemann 2008 primary and secondary tributaries were originally used in the study of mejía and niemann 2008 and applied for the classification of river networks jung et al 2015 pieri 1984 determined that junction angles at the two main tributaries increase as ratios between the tributary slopes and the tributary magnitudes which influence the development of river networks increase niemann et al 2001 examined the two tributaries for incision rates that affect the evolution of drainage networks mejía and niemann 2008 found that the size distributions of secondary tributaries are different for various river networks and jung et al 2015 studied the size distributions by evaluating the values of junction angles of the two tributaries thus we focused on primary and secondary tributaries for river network classification however third and fourth tributaries also exist in the river basins 2 2 2 beta distribution the beta distribution has been widely employed in modeling data with upper and lower boundaries to identify natural processes and patterns gupta and nadarajah 2004 the tributary junction angle of river basins represents a doubled bounded variable that ranges from 0 to 180 which indicates a decent fit to the analysis of beta distribution in addition the beta distribution can be used to model a broad range of distribution shapes because it has two shape parameters considering these characteristics the beta distribution is suitable for modeling the tributary junction angle and is thus used for the classification in this study to apply the beta distribution estimates of the tributary junction angle are rescaled from 0 to 1 by the equation 1 x θ 180 where θ and x are the tributary junction angles and rescaled tributary junction angles respectively with the rescaled angles the probability density function of the employed beta distribution is then given by 2 f x α β γ α β γ α γ β x α 1 1 x β 1 where α β and γ are the 1st shape parameter 2nd shape parameter and gamma function respectively in this study the maximum likelihood method is used for fitting the beta distribution because this method provides good performance and is commonly used for fitting the two parameter beta distribution owen 2008 detailed information on the maximum likelihood method for the beta distribution is available in the literature gupta and nadarajah 2004 hahn and shapiro 1994 if the river basins have similar distributional characteristics of tributary junction angles they may represent the same drainage network type when parameters of the beta distribution of the angles in the river basins appear to be similar the drainage network types of the basins are the same hence we use the parameter estimates of the beta distribution to obtain variables representing the distributional characteristics of the angles and to gain input variables for river network type classification 2 2 3 support vector machine mejía and niemann 2008 analyzed drainage pattern recognition in channel networks based on a decision tree to provide river network classification zhang and guilbert 2013 used fuzzy logic to conduct network classification by examining automatic drainage type recognition in the present work svm is adopted to identify drainage network types based on the parameter estimates of the beta distribution for the tributary junction angles after analyzing the beta distribution of the tributary junction angles we classify the different network types based on svm which is a supervised classifier broadly used in various fields for classifications fukuda and hirosawa 2001 furey et al 2000 kavzoglu and colkesen 2009 melgani and bruzzone 2004 svm was developed for solving classification problems based on mathematics unlike other machine learning algorithms such as random forest artificial neural network and fuzzy inference for example in the case of linear classification problems every procedure in the svm can be proved by a mathematical basis given this property svm provides good performance for classifiers especially for linearly separable cases svm was developed for building classifiers that maximize the margin that is a distance between any two groups the distance between two groups is determined by the distance between support vectors the support vector indicates the nearest vector to another group to find the hyperplane for maximizing the margin between the support vectors the following optimization problem with its constraints needs to be solved 3 min 1 2 w t w c j ξ j subject to equality constraints 4 y j f θ j 1 ξ j 5 ξ j 0 where w is the weight matrix w r 2 and θ j α j β j t indicates the beta distribution parameter estimates of the tributary junction angles for the jth basin and y j is an indicator for identifying the group to which a data point or vector belongs for example if the jth data belongs to the first group the value of y j is 1 if the jth data belongs to the second group the value of y j is 1 y j f θ j θ j t w b where b is bias ξ j is a nonnegative slack variable that allows the application of linearly inseparable data and c is a weight for the slack variable as svm is a binary classifier an additional algorithm the error correcting output code multiclass model ecoc is applied to classify the multi class data the application of ecoc enables multi class classification based on a number of binary classifiers ecoc with svm is then used for the river network classification detailed information on the ecoc and svm is available in the literature cristianini and shawe taylor 2000 dietterich and bakiri 1995 escalera et al 2009 fürnkranz 2002 hastie et al 2009 radeva 2010 in addition a drainage network classification model is determined and built using the statistical and machine learning toolbox in matlab https www mathworks com help stats 3 results and discussion 3 1 statistics of tributary junction angles to apply distributional information obtained from the tributary junction angles of different river networks the distribution shape of each drainage network type is identified histograms of the angles for the five river network types are presented in fig 2 the histograms reveal dissimilarities in the distribution shapes it can be visually observed that the histograms of the tributary junction angles for the same network types are similar while histograms of different network types are dissimilar the results indicate that the distributional characteristics of the tributary junction angles are useful in identifying river network features and classifying drainage networks the mean standard deviation coefficient of variation coefficient of skewness and coefficient of kurtosis have been widely employed to represent distributional information of data moment and moment ratio diagrams have also been used to identify the appropriate distribution for a given data set ashkar and ouarda 1996 hosking and wallis 2005 vargo et al 2010 vogel and fennessey 1993 the moment diagram uses statistical moments like mean and standard deviation and the moment ratio diagram uses dimensionless statistics like coefficients of variation skewness and kurtosis in this study the standard deviation and coefficient of skewness are used to draw the moment diagram the coefficients of variation and skewness are employed in the moment ratio diagram in the case of the drainage network classification using the tributary junction angle a diagram of standard deviation versus coefficient of skewness is more distinguishable than a diagram of coefficient of variation versus coefficient of skewness fig 3 presents the coefficients of variation and skewness for the tributary junction angles of the drainage network types the river networks overlap and are located on the area of the beta distribution except for one basin the distribution of the tributary junction angles appears to be a beta distribution because the drainage networks in the diagram are within the area of the beta distribution as the angles for different drainage types follow the same distribution model the coefficient of variation and coefficient of skewness are not used in this study the standard deviation and coefficient of skewness are therefore used to determine the distributional characteristics of the tributary junction angles for the different river networks a diagram of standard deviation versus coefficient of skewness for the tributary junction angle is presented in fig 4 a the dendritic parallel and pinnate networks can be clearly classified using the standard deviation and skewness except for two basins with a parallel network and a pinnate network that overlap however rectangular and trellis networks cannot be clearly classified based on these statistics although the standard deviation and coefficient of skewness tend to show differences they do not provide a clear indication table 3 presents the statistical ranges including the mean standard deviation and coefficient of skewness of the tributary junction angles parameter estimates of the beta distribution for the angles are therefore used to classify the different river networks the parameters of the distribution model more directly reflect distributional characteristics of data than do the statistics of the tributary junction angles using this approach dendritic parallel and pinnate networks are easily classified and distinct as shown in fig 4 b however the parameter estimates of the rectangular and trellis networks appear indistinct table 4 shows the ranges of the parameter estimates for the beta distribution of the tributary junction angles the rectangular networks have channel sinuosity with a large number of right angle bends and tributaries merging at nearly right angles the trellis networks have low channel sinuosity with small channels that are more numerous and shorter than large channels and tributaries merging at nearly right angles since the rectangular and trellis networks have abundant right angles the results of the parameter estimates tend to be indistinct however the rectangular and trellis networks are physically different and other features can be analyzed to clarify the classification the junction angle increases as the ratio of the two tributary orders increases lubowe 1964 as the ratio of the tributary magnitudes increases pieri 1984 the ratio of the two tributary slopes increases horton 1932 these characteristics attributable to differences in the angles can be considered in the classification moreover differences between dendritic parallel and pinnate networks may affect hydrological responses related to hydrological frequency analysis the determination of differences between dendritic parallel and pinnate networks is meaningful to enhance hydrological models and to offer hydrological information several authors attempted identify the characteristics of different river network types using junction angles and to identify the meaning of the differences in terms of hydrology phillips and schumm 1987 indicated that junction angles form owing to different conditions that affect the occurrence of river network type they presented showed that differences between dendritic and parallel pinnate networks are meaningful for understanding the development of different drainage networks and the characterization of hydrological features in river basins dendritic networks are characterized by junction angles with moderately acute angles parallel networks have large tributaries and acute junction angles whereas small tributaries tend to merge with major channels at orthogonal junction angles in pinnate networks all tributaries have very acute junction angles mejía and niemann 2008 investigated the differences between drainage networks by focusing on dendritic parallel pinnate rectangular and trellis networks they used three measures including drainage area increment stream course irregularity and tributary junction angle however in their analysis tributary junction angles could not distinguish between dendritic parallel and pinnate networks jung et al 2011 and jung and ouarda 2017 investigated typical conditions under which different drainage networks occur jung et al 2011 determined that dendritic networks develop on mild surfaces while parallel networks develop on sloping surfaces jung and ouarda 2017 identified that pinnate networks can exist in arid and semi arid regions where rivers have sandy and clay loams and an erodible surface 3 2 river network classification to examine in detail the distribution shapes of the five drainage network types fitted beta probability density functions pdfs are plotted in fig 5 a e and pdfs of mean parameter estimates for the employed drainage networks are presented in fig 5 f pdf shapes of the employed basins within the same drainage network type are similar except for the pdf shapes of the pinnate and parallel network types for instance there are large variations in the pdf shapes of the parallel networks which are clearly distinguishable from the pdf shapes of other network types similar results are observed in the pdf shapes of the pinnate networks furthermore the pdf shapes of the mean parameter estimates of the beta distribution for the dendritic parallel and pinnate networks are different the pdf shape of the dendritic network is the flattest and is dispersed among the tested network types parallel networks have the most kurtotic shape and pinnate networks have a relatively high mean value nevertheless the rectangular and trellis networks have very similar pdf shapes the results indicate that the distributional characteristics of tributary junction angles are not sufficient for distinguishing rectangular and trellis networks for classifying river networks a rule based on the distributional characteristics of the tributary junction angles should be considered the river network classification diagram is built as the rule to determine drainage network types based on parameter estimates of the beta distribution of the angles then the linear svm is employed for the classifier because the parameter estimates of the beta distribution may be linearly separable for any two network types among the tested drainage network types the results of classification using ecoc based on svm is presented in fig 6 four groups are clearly classified the location of one basin of the parallel network type is very close to the rectangular and trellis network groups this basin is presented in fig 5 b where the shape of one grey line is similar to the shapes of the rectangular and trellis networks however it remains difficult to classify the rectangular and trellis networks thus they are considered as one group in the classification note that rectangular and trellis networks can be classified by using a classification method suggested by jung et al 2015 who used junction angles and secondary tributary lengths to distinguish between the network types for validation of the proposed method 10 river basins in the usa are applied for classification fig 7 two of the river networks are dendritic one is parallel and seven are represented rectangular or trellis network types network classification using the proposed approach are consistent with those using the method of jung et al 2015 this validates the accuracy of the proposed method and the advantages of which over existing approaches are that 1 only tributary junction angles are required and 2 robust and simple classification is easily provided based on the specified distribution model with the svm 4 conclusions and recommendations this study proposed a new method for classifying drainage network types for this purpose the distributional characteristics of the tributary junction angles of different river networks were examined parameters of the beta distribution were employed to identify the characteristics of the angles fifty river basins were considered to investigate the applicability of the proposed method the method was applied to the identification of five river network types dendritic parallel pinnate rectangular and trellis the parameter estimates of the beta distribution were then classified using ecoc with svms the advantages of the proposed method over existing approaches are that only the tributary junction angle is required to identify river network types and that robust and simple classification can be achieved using the specified distribution model with svm the following conclusions could be drawn 1 the beta distribution can represent the distributional characteristics of the tributary junction angles of the five drainage network types parameter estimates of the beta distribution indicate differences in drainage network types more clearly than do the statistics of the angles 2 the proposed method clearly classifies dendritic parallel and pinnate networks these three network types have distinguishable distributional characteristics regarding tributary junction angles they can be classified by statistics and the parameters of beta distribution as the parameters of beta distribution provide better identification than the statistics the use of parameters of beta distribution is a superior option in the classification of river networks 3 the proposed method exhibited a limitation in that rectangular and trellis network types cannot be readily distinguished because the pdfs of their tributary junction angles are similar in order to identify rectangular and trellis network types other network features can be analyzed or additional classification methods can be employed the results of this study will serve as a reference for further studies on the distributional characteristics of tributary junction angles and drainage network classification although the distributional features of the angles may not provide sufficient information for classifying rectangular and trellis networks other information related to the angles will be tested to classify these drainage network types in future research the features of angles and river network types may be applicable to hydrological studies such as regional frequency analysis for determining quantile estimates of ungauged sites the classification of river network types may play a significant role in the estimation step of regional frequency analysis in which explicit correlations are required between hydrological quantiles and physiographical and meteorological variables the river network types classified based on the similarity may further enhance the quality of quantile estimates affected by homogenous characteristics of river basins in hydrological models such analyses will be conducted in the future to provide improved models for estimating regional quantiles declaration of interests none acknowledgments the authors are grateful to the associate editor and to the anonymous reviewers for their comments which greatly helped improve the quality of the manuscript this research was supported by the korea environmental industry technology institute keiti grant funded by the ministry of environment grant 18awmp b083066 05 and by basic science research program through the national research foundation of korea nrf funded by the ministry of science ict future planning nrf 2016r1c1b103711 
6573,different river networks in nature have distinct features depending on regional constraints these affect the development of the river network and form different characteristics the differences in drainage networks help in distinguishing between various network types and understanding natural processes the aim of this study is to develop a new and simple classification method for determining various river network types based on a critical parameter of river networks the tributary junction angle for the analysis fifty river networks are predefined as five network types dendritic parallel pinnate rectangular and trellis networks the tributary junction angles are calculated for each drainage network type and then the beta distribution is employed to identify distributional characteristics of the junction angles parameter estimates of the beta distribution are used to classify different river networks because the estimates provide classified features of natural processes support vector machines are then utilized to determine the network classification with the parameter estimates furthermore the results are validated against classification using a different approach with commonly used statistics the proposed method can clearly distinguish between different network types except for the rectangular and trellis types in addition parameter estimates of the beta distribution indicate differences in drainage network types more clearly than the statistics of the angles overall the parameter estimates of beta distribution have high potential for application to the classification of river networks keywords drainage network types tributary junction angles beta distribution support vector machines 1 introduction in nature river networks can present significantly distinct characteristics depending on physiographic climatic and topographic constraints which affect the occurrence of drainage networks considering the differences among river networks the features of drainage networks can be analyzed and various classes of channel network can be determined such as dendritic parallel pinnate rectangular and trellis networks abrahams and flint 1983 howard 1967 parvis 1949 phillips and schumm 1987 zernitz 1932 zhang and guilbert 2013 a dendritic network typically has a tree like pattern characterized by wide basin shapes and tributaries merging at moderately acute junction angles a parallel network tends to represent a parallel form with straight stream courses and tributaries merging at acute angles a pinnate network has a feather like pattern with very straight major stream courses oriented along a single direction and many small tributaries merging at highly acute angles a rectangular network has channel sinuosity characterized by many right angle bends and tributaries that merge at right angles a trellis network exhibits a lattice like pattern with many short tributaries that merge at nearly right angles examples of these networks are shown in fig 1 in the present study these five river network types are used to develop a classification system however more network types exist in nature for example radial and centripetal networks represent the arrangement of drainage patterns where streams flow inward toward a closed central depression a radial network is characterized by volcanoes domes and erosion residuals a centripetal network is associated with craters calderas and other depressions as a modification of the radial pattern reticulate networks form as a net and generally occur on floodplains and deltas where rivers interlace with each other to account for such differences between various channel networks several authors have developed methods to classify network types using several river network features for instance argialas et al 1988 distinguished eight drainage network types including dendritic parallel pinnate rectangular and trellis based on fifteen attributes of networks ichoku and chorowicz 1994 developed a quantitative classification system to determine different networks using fourteen network characteristics based on digital elevation models dems mejía and niemann 2008 also proposed another classification method to identify five types of channel networks using three measures derived from scaling invariance in the planform geometry of drainage networks the three measures are the incremental accumulation of basin area along channels irregularity of stream courses and junction angles shaped by merging channels in a more recent study jung et al 2015 presented a river network classification method based on the secondary tributary lengths and tributary junction angles jung et al 2015 analyzed the cumulative distributions of the secondary tributary lengths in different ranges of junction angles to derive the exponent of the power law for the classification although these approaches objectively discriminate between various drainage networks quantitatively in the classification of networks they require several characteristics of channel networks and involve complex procedures different characteristics of river networks play a significant role in hydrological studies such as regional frequency analysis for obtaining hydrological estimates of ungauged basins chebana and ouarda 2009 in regional frequency analysis defining homogenous regions with a high level of hydrological similarity is significant for acquiring hydrological information the delineation of groups of regions depends on a set of physiographical and meteorological variables which influence the development of river basins wazneh et al 2015 different river network types may be potentially used as an important indicator in the estimation step of regional frequency analysis jung et al 2017 this may significantly enhance the quality of regional hydrological estimates of ungauged sites in the present work we aim to propose a simple and robust method for river network classification using the beta distribution of tributary junction angles two shape parameters of the beta distribution have been used for classification analysis and hydrological analysis arai et al 1995 bhunya et al 2004 seo and baek 2004 with this beta distribution this study directly determines river network types of fifty river networks in the usa by establishing a relationship between the parameters to identify the classification system of each network type we use support vector machines svms which are supervised machine learning classifiers then river basins classified using another method are used to validate the proposed approach the remainder of this paper is organized as follows section 2 describes the data sets used in the present study section 3 presents the methodologies for classifying the drainage networks section 4 gives the results and discussion section 5 summarizes the conclusions 2 data and methodology 2 1 data set in this study fifty drainage networks are selected for development of the new approach for classifying drainage networks into dendritic parallel pinnate rectangular and trellis types following previous studies on classifying drainage networks abrahams and flint 1983 jung and ouarda 2017 lubowe 1964 phillips and schumm 1987 zernitz 1932 several studies considered fifty river networks in proposing new methods for network classification jung et al 2015 mejía and niemann 2008 the fifty networks used in the present work are shown in table 1 along with the locations of the basin outlet basin areas and drainage network types the selected river networks have basin sizes ranging from 6 to 898 km2 in addition 10 river networks in the usa are used to test the proposed method table 2 for the river network classification dems were obtained from the seamless data distribution system sdds of the u s geological survey usgs these dems are used to estimate flow directions then the flow directions are used to determine contributing areas by summing up the total areas flowing through all grid cells to define the watersheds the dems have a horizontal resolution of 1 and a grid cell of 30 m with a linear dimension the spatial resolution is 30 m which is commonly used for the analysis of drainage networks ijjasz vasquez and bras 1995 moglen and bras 1995 o callaghan and mark 1984 tarboton et al 1991 mejía and niemann 2008 used different grid cell sizes such as 30 m and 90 m in examining channel networks while proposing a method for river network classification and they found that the classification results were not affected by the different resolutions 2 2 methodology 2 2 1 estimation of tributary junction angles among various features of river networks the tributary junction angle has been used to investigate river basins and identify differences in channel networks affected by local conditions variations in the tributary junction angles of different river networks have been observed abrahams and flint 1983 hackney and carling 2011 jung et al 2015 phillips and schumm 1987 in particular parallel and pinnate networks tend to have an abundance of very acute tributary junction angles while rectangular and trellis networks tend to have an abundance of nearly perpendicular tributary junction angles with the identification of characteristics of the tributary junction angles river network classification methods have been examined and proposed to improve our understanding of natural processes mejía and niemann 2008 jung et al 2015 in river network analysis the tributary junction angle at every junction between the primary and secondary tributaries is estimated as a major parameter of river networks the primary tributary is obtained based on the chord between the junction and a point determined by the euclidean distance upstream from the junction on the larger tributary in a river basin the secondary tributary is obtained based on the chord between the junction and a point determined by the euclidean distance upstream from the junction on the smaller tributary in the river basin a comprehensive description of the method for calculating the tributary junction angles is presented in mejía and niemann 2008 primary and secondary tributaries were originally used in the study of mejía and niemann 2008 and applied for the classification of river networks jung et al 2015 pieri 1984 determined that junction angles at the two main tributaries increase as ratios between the tributary slopes and the tributary magnitudes which influence the development of river networks increase niemann et al 2001 examined the two tributaries for incision rates that affect the evolution of drainage networks mejía and niemann 2008 found that the size distributions of secondary tributaries are different for various river networks and jung et al 2015 studied the size distributions by evaluating the values of junction angles of the two tributaries thus we focused on primary and secondary tributaries for river network classification however third and fourth tributaries also exist in the river basins 2 2 2 beta distribution the beta distribution has been widely employed in modeling data with upper and lower boundaries to identify natural processes and patterns gupta and nadarajah 2004 the tributary junction angle of river basins represents a doubled bounded variable that ranges from 0 to 180 which indicates a decent fit to the analysis of beta distribution in addition the beta distribution can be used to model a broad range of distribution shapes because it has two shape parameters considering these characteristics the beta distribution is suitable for modeling the tributary junction angle and is thus used for the classification in this study to apply the beta distribution estimates of the tributary junction angle are rescaled from 0 to 1 by the equation 1 x θ 180 where θ and x are the tributary junction angles and rescaled tributary junction angles respectively with the rescaled angles the probability density function of the employed beta distribution is then given by 2 f x α β γ α β γ α γ β x α 1 1 x β 1 where α β and γ are the 1st shape parameter 2nd shape parameter and gamma function respectively in this study the maximum likelihood method is used for fitting the beta distribution because this method provides good performance and is commonly used for fitting the two parameter beta distribution owen 2008 detailed information on the maximum likelihood method for the beta distribution is available in the literature gupta and nadarajah 2004 hahn and shapiro 1994 if the river basins have similar distributional characteristics of tributary junction angles they may represent the same drainage network type when parameters of the beta distribution of the angles in the river basins appear to be similar the drainage network types of the basins are the same hence we use the parameter estimates of the beta distribution to obtain variables representing the distributional characteristics of the angles and to gain input variables for river network type classification 2 2 3 support vector machine mejía and niemann 2008 analyzed drainage pattern recognition in channel networks based on a decision tree to provide river network classification zhang and guilbert 2013 used fuzzy logic to conduct network classification by examining automatic drainage type recognition in the present work svm is adopted to identify drainage network types based on the parameter estimates of the beta distribution for the tributary junction angles after analyzing the beta distribution of the tributary junction angles we classify the different network types based on svm which is a supervised classifier broadly used in various fields for classifications fukuda and hirosawa 2001 furey et al 2000 kavzoglu and colkesen 2009 melgani and bruzzone 2004 svm was developed for solving classification problems based on mathematics unlike other machine learning algorithms such as random forest artificial neural network and fuzzy inference for example in the case of linear classification problems every procedure in the svm can be proved by a mathematical basis given this property svm provides good performance for classifiers especially for linearly separable cases svm was developed for building classifiers that maximize the margin that is a distance between any two groups the distance between two groups is determined by the distance between support vectors the support vector indicates the nearest vector to another group to find the hyperplane for maximizing the margin between the support vectors the following optimization problem with its constraints needs to be solved 3 min 1 2 w t w c j ξ j subject to equality constraints 4 y j f θ j 1 ξ j 5 ξ j 0 where w is the weight matrix w r 2 and θ j α j β j t indicates the beta distribution parameter estimates of the tributary junction angles for the jth basin and y j is an indicator for identifying the group to which a data point or vector belongs for example if the jth data belongs to the first group the value of y j is 1 if the jth data belongs to the second group the value of y j is 1 y j f θ j θ j t w b where b is bias ξ j is a nonnegative slack variable that allows the application of linearly inseparable data and c is a weight for the slack variable as svm is a binary classifier an additional algorithm the error correcting output code multiclass model ecoc is applied to classify the multi class data the application of ecoc enables multi class classification based on a number of binary classifiers ecoc with svm is then used for the river network classification detailed information on the ecoc and svm is available in the literature cristianini and shawe taylor 2000 dietterich and bakiri 1995 escalera et al 2009 fürnkranz 2002 hastie et al 2009 radeva 2010 in addition a drainage network classification model is determined and built using the statistical and machine learning toolbox in matlab https www mathworks com help stats 3 results and discussion 3 1 statistics of tributary junction angles to apply distributional information obtained from the tributary junction angles of different river networks the distribution shape of each drainage network type is identified histograms of the angles for the five river network types are presented in fig 2 the histograms reveal dissimilarities in the distribution shapes it can be visually observed that the histograms of the tributary junction angles for the same network types are similar while histograms of different network types are dissimilar the results indicate that the distributional characteristics of the tributary junction angles are useful in identifying river network features and classifying drainage networks the mean standard deviation coefficient of variation coefficient of skewness and coefficient of kurtosis have been widely employed to represent distributional information of data moment and moment ratio diagrams have also been used to identify the appropriate distribution for a given data set ashkar and ouarda 1996 hosking and wallis 2005 vargo et al 2010 vogel and fennessey 1993 the moment diagram uses statistical moments like mean and standard deviation and the moment ratio diagram uses dimensionless statistics like coefficients of variation skewness and kurtosis in this study the standard deviation and coefficient of skewness are used to draw the moment diagram the coefficients of variation and skewness are employed in the moment ratio diagram in the case of the drainage network classification using the tributary junction angle a diagram of standard deviation versus coefficient of skewness is more distinguishable than a diagram of coefficient of variation versus coefficient of skewness fig 3 presents the coefficients of variation and skewness for the tributary junction angles of the drainage network types the river networks overlap and are located on the area of the beta distribution except for one basin the distribution of the tributary junction angles appears to be a beta distribution because the drainage networks in the diagram are within the area of the beta distribution as the angles for different drainage types follow the same distribution model the coefficient of variation and coefficient of skewness are not used in this study the standard deviation and coefficient of skewness are therefore used to determine the distributional characteristics of the tributary junction angles for the different river networks a diagram of standard deviation versus coefficient of skewness for the tributary junction angle is presented in fig 4 a the dendritic parallel and pinnate networks can be clearly classified using the standard deviation and skewness except for two basins with a parallel network and a pinnate network that overlap however rectangular and trellis networks cannot be clearly classified based on these statistics although the standard deviation and coefficient of skewness tend to show differences they do not provide a clear indication table 3 presents the statistical ranges including the mean standard deviation and coefficient of skewness of the tributary junction angles parameter estimates of the beta distribution for the angles are therefore used to classify the different river networks the parameters of the distribution model more directly reflect distributional characteristics of data than do the statistics of the tributary junction angles using this approach dendritic parallel and pinnate networks are easily classified and distinct as shown in fig 4 b however the parameter estimates of the rectangular and trellis networks appear indistinct table 4 shows the ranges of the parameter estimates for the beta distribution of the tributary junction angles the rectangular networks have channel sinuosity with a large number of right angle bends and tributaries merging at nearly right angles the trellis networks have low channel sinuosity with small channels that are more numerous and shorter than large channels and tributaries merging at nearly right angles since the rectangular and trellis networks have abundant right angles the results of the parameter estimates tend to be indistinct however the rectangular and trellis networks are physically different and other features can be analyzed to clarify the classification the junction angle increases as the ratio of the two tributary orders increases lubowe 1964 as the ratio of the tributary magnitudes increases pieri 1984 the ratio of the two tributary slopes increases horton 1932 these characteristics attributable to differences in the angles can be considered in the classification moreover differences between dendritic parallel and pinnate networks may affect hydrological responses related to hydrological frequency analysis the determination of differences between dendritic parallel and pinnate networks is meaningful to enhance hydrological models and to offer hydrological information several authors attempted identify the characteristics of different river network types using junction angles and to identify the meaning of the differences in terms of hydrology phillips and schumm 1987 indicated that junction angles form owing to different conditions that affect the occurrence of river network type they presented showed that differences between dendritic and parallel pinnate networks are meaningful for understanding the development of different drainage networks and the characterization of hydrological features in river basins dendritic networks are characterized by junction angles with moderately acute angles parallel networks have large tributaries and acute junction angles whereas small tributaries tend to merge with major channels at orthogonal junction angles in pinnate networks all tributaries have very acute junction angles mejía and niemann 2008 investigated the differences between drainage networks by focusing on dendritic parallel pinnate rectangular and trellis networks they used three measures including drainage area increment stream course irregularity and tributary junction angle however in their analysis tributary junction angles could not distinguish between dendritic parallel and pinnate networks jung et al 2011 and jung and ouarda 2017 investigated typical conditions under which different drainage networks occur jung et al 2011 determined that dendritic networks develop on mild surfaces while parallel networks develop on sloping surfaces jung and ouarda 2017 identified that pinnate networks can exist in arid and semi arid regions where rivers have sandy and clay loams and an erodible surface 3 2 river network classification to examine in detail the distribution shapes of the five drainage network types fitted beta probability density functions pdfs are plotted in fig 5 a e and pdfs of mean parameter estimates for the employed drainage networks are presented in fig 5 f pdf shapes of the employed basins within the same drainage network type are similar except for the pdf shapes of the pinnate and parallel network types for instance there are large variations in the pdf shapes of the parallel networks which are clearly distinguishable from the pdf shapes of other network types similar results are observed in the pdf shapes of the pinnate networks furthermore the pdf shapes of the mean parameter estimates of the beta distribution for the dendritic parallel and pinnate networks are different the pdf shape of the dendritic network is the flattest and is dispersed among the tested network types parallel networks have the most kurtotic shape and pinnate networks have a relatively high mean value nevertheless the rectangular and trellis networks have very similar pdf shapes the results indicate that the distributional characteristics of tributary junction angles are not sufficient for distinguishing rectangular and trellis networks for classifying river networks a rule based on the distributional characteristics of the tributary junction angles should be considered the river network classification diagram is built as the rule to determine drainage network types based on parameter estimates of the beta distribution of the angles then the linear svm is employed for the classifier because the parameter estimates of the beta distribution may be linearly separable for any two network types among the tested drainage network types the results of classification using ecoc based on svm is presented in fig 6 four groups are clearly classified the location of one basin of the parallel network type is very close to the rectangular and trellis network groups this basin is presented in fig 5 b where the shape of one grey line is similar to the shapes of the rectangular and trellis networks however it remains difficult to classify the rectangular and trellis networks thus they are considered as one group in the classification note that rectangular and trellis networks can be classified by using a classification method suggested by jung et al 2015 who used junction angles and secondary tributary lengths to distinguish between the network types for validation of the proposed method 10 river basins in the usa are applied for classification fig 7 two of the river networks are dendritic one is parallel and seven are represented rectangular or trellis network types network classification using the proposed approach are consistent with those using the method of jung et al 2015 this validates the accuracy of the proposed method and the advantages of which over existing approaches are that 1 only tributary junction angles are required and 2 robust and simple classification is easily provided based on the specified distribution model with the svm 4 conclusions and recommendations this study proposed a new method for classifying drainage network types for this purpose the distributional characteristics of the tributary junction angles of different river networks were examined parameters of the beta distribution were employed to identify the characteristics of the angles fifty river basins were considered to investigate the applicability of the proposed method the method was applied to the identification of five river network types dendritic parallel pinnate rectangular and trellis the parameter estimates of the beta distribution were then classified using ecoc with svms the advantages of the proposed method over existing approaches are that only the tributary junction angle is required to identify river network types and that robust and simple classification can be achieved using the specified distribution model with svm the following conclusions could be drawn 1 the beta distribution can represent the distributional characteristics of the tributary junction angles of the five drainage network types parameter estimates of the beta distribution indicate differences in drainage network types more clearly than do the statistics of the angles 2 the proposed method clearly classifies dendritic parallel and pinnate networks these three network types have distinguishable distributional characteristics regarding tributary junction angles they can be classified by statistics and the parameters of beta distribution as the parameters of beta distribution provide better identification than the statistics the use of parameters of beta distribution is a superior option in the classification of river networks 3 the proposed method exhibited a limitation in that rectangular and trellis network types cannot be readily distinguished because the pdfs of their tributary junction angles are similar in order to identify rectangular and trellis network types other network features can be analyzed or additional classification methods can be employed the results of this study will serve as a reference for further studies on the distributional characteristics of tributary junction angles and drainage network classification although the distributional features of the angles may not provide sufficient information for classifying rectangular and trellis networks other information related to the angles will be tested to classify these drainage network types in future research the features of angles and river network types may be applicable to hydrological studies such as regional frequency analysis for determining quantile estimates of ungauged sites the classification of river network types may play a significant role in the estimation step of regional frequency analysis in which explicit correlations are required between hydrological quantiles and physiographical and meteorological variables the river network types classified based on the similarity may further enhance the quality of quantile estimates affected by homogenous characteristics of river basins in hydrological models such analyses will be conducted in the future to provide improved models for estimating regional quantiles declaration of interests none acknowledgments the authors are grateful to the associate editor and to the anonymous reviewers for their comments which greatly helped improve the quality of the manuscript this research was supported by the korea environmental industry technology institute keiti grant funded by the ministry of environment grant 18awmp b083066 05 and by basic science research program through the national research foundation of korea nrf funded by the ministry of science ict future planning nrf 2016r1c1b103711 
6574,utilizing the readily available inexpensive remotely sensed satellite data products in combination with markov chain methods for estimating water levels and discharge anywhere along the vast river networks around the world is one of the most interesting and promising fields in hydrology this study presents two new extensions of markov chain mc methods namely the online markov chains o mc and extreme online markov chains eo mc methods to improve the prediction accuracy the o mc method has the advantage of the online implementation of the correct variable states and the eo mc method has the advantage of online updating the markov matrix mm along with the online implementation of the correct variable states the new o mc and the eo mc methods were evaluated using short term satellites signal predictions for six different case study rivers the monte carlo uncertainty analysis was used to measure the reliability of the new mc based methods each model was developed 1000 times to calculate two indices namely the 95 percent predicted uncertainties 95ppu and average distance factor d factor the performances of mc and two extensions of o mc and eo mc were also examined for cases where we lack the training data the training percent trpr of the entire dataset gradually decreased from 90 to 1 and the performance of the models in producing accurate future signals in the non observed dataset is calculated the input variable imitation ivi problem was considered for the mc based methods and the results were compared with the linear regression lr multi layer perceptron mlp extreme learning machine elm and radial basis function rbf regression methods the results showed that the performance of eo mc and o mc are better than the simple mc method in addition it is concluded that eo mc and o mc have very similar performance in the uncertainty analysis and both methods are robust techniques the main advantage of eo mc compared with the o mc method is highlighted when the number of training samples are very low finally considering the ivi problem the new o mc and eo mc methods significantly outperformed the lr mlp elm and rbf methods abbreviations 95ppu 95 percent predicted uncertainties δ average absolute deviation d factor average distance factor aue average uncertainty error r 2 coefficient of determination he horizontal error ivi input variable imitation mm markov matrices maxtotdata maximum amount of total dataset mse mean squared error mintotdata minimum amount of total dataset m modeled statenum number of states totnum number of total dataset samples trnum number of train dataset samples o observed opn observed peak number staterange range of the states rmse root mean squared error rn run number smpn simultaneous modeled peak number sn step number tspr testing percent ith day currstate the state of the current day i 1th day nextstate the state of the next day totdata total dataset trpr training percent ve vertical error keywords input variable imitation markov chains monte carlo uncertainty analysis online training river discharge satellite information 1 introduction climate change effects have increased the severity of floods and this phenomenon adversely affects more people compared to other natural disasters de groeve and riva 2009 early warning systems rely on timely and accurate forecasts to minimize the loss of life from floods despite the importance of this problem the state of knowledge in this field has yet to take full advantage of the major new developments in more accurate remotely sensed inexpensive and readily available data products these data products having global spatial coverage combined with advanced new machine learning tools for real time analysis and modelling of river water levels and discharge allow for flood forecasting and inundation mapping tools for early warning systems artificial intelligence ai methods have been widely used in many fields of hydrology wang et al 2017a modeled the pan evaporation ep at six stations of yangtze river using different environmental factors the authors used three novel ai methods of fuzzy genetic fg an adaptive neuro fuzzy inference system with grid partition anfis gp and m5 model tree m5tree methods as another study wang et al 2017b modeled ep with limited climatic parameters using six different ai methods of mlp generalized regression neural network grnn fg support vector regression svr multivariate adaptive regression spline mars and anfis gp bou fakhreddine et al 2018 predicted the daily river flow using a two phase constructive fuzzy inference hybrid model in combination with the re sampled data in order to increase the prediction performance the authors used the rainfall and river flow measurements as the input variables zounemat kermani and mahdavi meymand 2019 developed a hybrid method by combining two different ai methods of mlp and anfis with four optimization algorithms to estimate the flow rate passing a piano key weir free surface control structure one of the most popular fields in hydrology that has been recently modeled using ai techniques is flood water levels for instance he et al 2014 utilized the mlp svr and anfis in river flow prediction problems chen et al 2015 modeled the altamaha river using different optimization algorithms fuzzy patterns and continuity equation in a hybrid ai method using the feedforward and recurrent neural network darras et al 2017 modeled flash floods and found that the recurrent procedure performs better for longer lead time and feedforward procedure performs better for short range flash floods predictions young et al 2017 developed a combination model that was formed from the svr method and hydrologic models and applied that model to simulate the rainfall runoff during typhoon events by combining the wavelet transformation and mlp rainfall runoff of the told river was predicted up to two months in advance successfully by alizadeh et al 2017 the above mentioned studies demonstrated the prediction power of regression based methods in flood forecasting however these studies all used in situ hydrometric survey data that is not available in many parts of the world the number of hydrometric stations around the world is in decline to due economic constraints calmant and seyler 2006 khan et al 2012 perdikaris et al 2018 shiklomanov et al 2002 sivapalan 2003 stokstad 1999 the main interest of researchers in this field is to use satellite information to model and predict the hydrological problems brakenridge et al 2007 jiang et al 2014 khan et al 2011 su et al 2008 temimi et al 2011 temimi et al 2007 zeynoddin et al 2018 2019 one of the well known and popular satellite missions which was successfully utilized in river discharge simulations is the passive microwave sensors of the advanced microwave scanning radiometer amsr satellite brakenridge et al 2007 which started at the dartmouth flood observatory dfo and followed by the joint research center jrc the amse calculates the water surface area of rivers by measuring the difference between land and water brightness temperatures the amsr gathered data are validated with the global flood detection system gfds and are accessible at www gdacs org de groeve 2010 used the amsr observations in order to calculate the size of the floods and concluded that the floods could be predicted using the upstream information and that they can be recognized at least two hours after their occurrence the river discharges were calibrated to the satellite amsr information by brakenridge et al 2012 and cohen et al 2012 the authors made a hydrological model to calculate the river discharges using the satellite information at the same time and concluded that the amsr satellite signals have the ability to model in situ river discharges accurately using the upstream satellite remote sensing data and the wave propagation concept hirpa et al 2013 forecasted the river discharges and concluded that there is a good correlation between satellite information and in situ gauge measurements the research of khan et al 2014 showed that the remote sensing data could be utilized with the in situ sparsely gauges to detect the floods in large basins revilla romero et al 2014 tested 322 rivers to find the best correlation between the satellite and in situ discharge information and the high correlation areas were used to fill the real time ground based measurements gaps using the moderate resolution imaging spectroradiometer modis sensors revilla romero et al 2015 and van dijk et al 2016 simulated the rivers discharge successfully and showed that this sensor could be used in modeling the in situ information zaji et al 2018a presented a method to use upstream satellite pixels in order to predict the future of rivers discharges zaji et al 2018b c showed that using the introduced preprocessing method the in situ rivers discharges could be modeled more accurately using the satellite information according to the literature river discharges could be calibrated using the satellites signals so that in order to predict the future river discharges for flood monitoring or adjusting the relative hydraulic structure using the satellite information it is necessary to predict the satellite signals accurately in this study two novel extensions of the mc method namely o mc and eo mc are developed and used to predict the short term satellite signals dissimilar to the mc which just uses the last state of the training dataset to develop the non observed dataset the o mc method updates the correct states during the prediction the eo mc however is one further step ahead in this procedure both of the states and the mm are updated during the non observed prediction then the performance of the models are measured using common statistical indices and the reliability of the models is calculated by means of the monte carlo uncertainty analysis in addition the applicability of the models for the case of lacking the source information is calculated by diminishing the trpr gradually and simultaneously increasing the non observed dataset samples in this test the trpr is reduced from 90 to 1 in 90 steps 1 decrement at each step finally this study focusses on one of the most important regression methods limitations in predicting the future condition of a phenomenon using its past information in many cases the regression methods choose the easiest way and simply imitate their input variables instead of actually predicting the future here the ivi amount of the mc o mc and eo mc methods are calculated and compared with the ivi amounts of the simple lr and three well known ai methods mlp elm and rbf the rest of the paper is organized as follows in the next section the methodology of the procedures is described in the first part of this section the gathering method of the satellite information and the connection formulation to the satellite signals is described after that the calculation processes of the mc o mc and eo mc are described in the last part of the methodology section the considered case study rivers are introduced after that in the first part of the results section the results of modeling the considered case studies using the mc o mc and eo mc models are presented and the performance of the models are assessed using the common statistical indices then the uncertainty analysis of the models us discussed in the next part in the last part of the results section the ivi defect of the mc o mc and eo mc models are calculated and the results are compared with the results of the lr mlp elm and rbf regression methods by using the case studies finally the entire results and implications of the present study are summarized in the conclusion section 2 methodology the methodology which is proposed in the present investigation is based on brakenridge et al 2012 these authors proposed some equations in order to calibrate the satellite information and in situ rivers discharge in the presented equations the amsr satellite signals were used as the input variable and the output was the considered river discharges they proved that by having the satellite information the river discharge parameter could be modeled accurately it also could be concluded that by having the calibration equations the need for daily measurements of river discharge is diminished and only some occasionally measurements are needed for the recalibration purposes the idea of using satellite signals instead of in situ information and diminishing the gauge station measurements has lots of advantages such as decreasing the maintenance cost of the gauge stations however in this case in order to predict the future river discharge there are not any continuous in situ measurement datasets and forecasting the future river discharge using the past information is not possible to solve this shortage one of the simplest ways is to predict the future of satellite signals instead of predicting the discharge of the rivers because the historical information of the satellite signals is available completely and there are numerous accurate methods to calibrate them to the river discharge for this reason this study is focused on predicting the satellite signals using its own past information instead of predicting the river discharges this section has three parts in the first part the used satellite formulation and its relation to river discharge are described after having a glance at the traditional mc method s formulation its two extensions of o mc and eo mc are described in the third part the case studies which are used in order to examine the results of the mc o mc and eo mc and comparing their results with the lr and ai models are introduced finally in the last part of this section the traditional statistical indices such as root mean squared error rmse mean squared error mse coefficient of determination r2 and average absolute deviation δ and the new index of measuring the truly modeling error in time series prediction models ivi which are used in order to compare the considered models are introduced 2 1 satellite based information previous studies showed that by using the brightness temperature measurement of amse descending orbit h polarization in 36 ghz band the changes of the rivers discharge could be calibrated accurately without concerning the weather conditions brakenridge et al 2005 de groeve et al 2015 the satellite signals are calculated using the brightness temperature tb which is calculated using the following equation 1 t b ε t where ε is the emissivity coefficient and t is the physical temperature of the considered area identifying the amount of water in a portion of land is done using the differences of ε which is about 0 5 for the wet surfaces and 0 75 to 0 95 for the dry surfaces sharkov 2003 so that in case of having a similar physical temperature the tb of a full of surface water pixel is considerably lower than the tb of a dry pixel however as mentioned before each pixel of the amsr sensor covers a relatively large area when the goal is to measure the river s properties in almost all instances a portion of each rivers pixels covered with water w and the remaining area of the considered pixel is covered with land 1 w therefore the brightness temperature of each pixel calculated using the eq 2 in this equation tb l and tb w are the brightness temperature of the land and water portions of the considered pixel respectively 2 t b 1 w t b l w t b w it should be noted that because of the close position of the dry and wet areas of a pixel in this equation the physical temperature could be considered constant to write the eq 2 in the form of eq 3 in this equation the variables of εl and εw are the dry and wet areas emissivity coefficients respectively 3 t b t 1 w ε 1 w ε w in order to remove the effect of different physical temperatures at different times of the year and eliminate the t term from eq 3 the river pixel tb m brightness temperature is always divided by an adjacent fully dry pixel tb c as a calibration pixel so that the final satellite signal equation which is used to calculate the characteristics of the river is obtained as follows kugler and de groeve 2007 4 s t b c t b m t 1 0 ε 1 0 ε w t 1 w ε 1 w ε w ε 1 1 w ε 1 w ε w the reason for choosing the adjacent pixel as the calibration pixel is to have an almost similar physical temperature in both pixels so that the t terms are considered equal in the last equation from eq 4 the s variable is related to two constants of εl and εw and one variable of w so that all the signal changes are related to the amount of w according to eq 4 the number of s increases by increasing the water portion of the pixel and vice versa the footprint size of the amsr satellite sensor that is used in the present study as the satellite signals information is 8 12 km2 so that the entire surface of the earth was divided into 4000 2000 pixels in order to achieve the satellite signals all of the amsr images were downloaded from www gdacs org and after that according to the latitude longitude of the considered point of the rivers the measurement pixels and the calibration pixels were selected for each considered case study finally the satellite signal dataset of each river was achieved using eq 4 according to the above equations it is clear that the number of satellite signals is changed in regard to the amount of water in the pixel the changes in the satellite signals could be considered as a proxy for the changes in the river discharge the discharge of a river q is calculated using the concept of continuity and related to the width and depth of the river b and d respectively and the flow velocity v as follows 5 q b d v in river having non vertical channel banks the effects of changing w and d on discharge are almost similar bjerklie et al 2005 and both of them are better predictors compared with the v brakenridge et al 2012 by considering the width of a river as its occupant area in the considered satellite pixel the river discharge could be calibrated to the satellite signals accurately brakenridge et al 2012 2 2 markov chain methods mc is a simple modeling and prediction method that works based on the stochastic procedure serfozo 2009 in order to describe a sequence of possible events gagniuc 2017 in this stochastic procedure the markov property should be satisfied rozanov 1982 the markov property is being satisfied if the future prediction of a process could be made independent of the history of that process consider the following statement 6 x n n 0 1 2 here xn is a stochastic procedure that has a finite number of possible values the statement of xn being equal to i infers that at time n the procedure is in state i here is an assumption that when the procedure is in state i then there is a fixed possibility of pij that the next procedure s state is j therefore we have 7 p ij p x n 1 j x n i n x n 1 i n 1 x 1 i 1 x 0 i 0 all of the n values and the j i in 1 i 0 are non negative amounts this equation represents the base mc procedure the pij says that if the current position of a process is i there is a pij probability that its next state is j and it follows the following equation 8 j 0 p ij 1 i 0 1 j 0 p ij 0 by having all of the p indices the mm is developed as follows which is the first order one step transition matrix 9 mm p 00 p 01 p 02 p 10 p 11 p 12 p i 0 p i 1 p i 2 in order to evaluate the mm in this study the procedure shown in fig 1 is followed according to this figure three steps should be done in order to reach the mm the first step is the dividing phase in this step the total data is divided into two different partitions the training dataset which is used in order to evaluate the models and the testing dataset which is used to validate the models after preparing the datasets the state matrix is evaluated in the second step of fig 1 before calculating the state matrix a number of total states should be inputted to the code by the user the number of state coefficients depends on the considered problem in this study different amounts of statenum variable were tested and it was concluded that for the considered case studies the best results are achieved by having 20 states thus for all of the mc base modeling which are presented in this study the number of states coefficient considered is 20 by having the number of states and the range of each state which are calculated in this part the state matrix is calculated in order to achieve the following matrix 10 state mintotdata mintotdata s t a t e r a n g e mintotdata s t a t e r a n g e mintotdata 2 s t a t e r a n g e mintotdata 2 s t a t e r a n g e mintotdata 3 s t a t e r a n g e mintotdata statenum 1 s t a t e r a n g e mintotdata s t a t e n u m s t a t e r a n g e this is a matrix with statenum rows and two columns each row of this matrix represents the minimum and maximum range of the row number state by its first and second columns amounts after evaluating the state matrix according to fig 1 the mm could be evaluated at the last step the last step comprises from two different pseudocodes the first one is to develop the raw mm and the second one is to normalize it for developing the mm the train samples and the rows of the state matrix are considered according to each other using two nested for loops in addition in this part the state of the i th and i 1 th samples of the training dataset are calculated by using two if conditions after the first pseudocode a raw mm has been developed however because of the probability rule the sum of the values of each row of mm should be one so that at the second pseudocode the achieved mm is normalized mc based methods use the training dataset in order to develop the mm then by using that matrix the testing samples are predicted the main difference among mc o mc and eo mc methods is their procedure of predicting the test dataset samples that are non observed for the models the output generation step of the considered mc based methods is presented in fig 2 this step is only formed from one for a loop as could be seen in this loop the test dataset is considered the first line of this for loop is to evaluate the nextstate which is obtained by using the obtained mm matrix it should be noted when i is equal to one and there is the first for loop the finalstate is actually the state of the last sample of the training dataset after evaluating the nextstate at the second line of the for loop the output data is calculated using the state matrix to do that a random number between the first and second columns of the nextstate th row of the state matrix is selected as the output value as mentioned when the i counter of the for loop is equal to one the finalstate is obtained from the last sample of the trdata however for other i values i 2 3 number of tsdata elements the finalstate should be determined in the for loop itself the standard mc model simply inserts the computed nextstate into the finalstate variable and starts the next loop however according to fig 2 the o mc model has a different procedure in this method after predicting the next day the nextstate is updated online by using the past day s real information so that in this procedure in order to calculate the nextstate the real state of the current day is used the only difference between the mc and o mc models is that the o mc uses the past test days information and make its predictions online the eo mc is one step ahead of the o mc method in this procedure the same process of o mc is done in order to find the real nextstate variable according to the passed day s information however there is an additional process in this algorithm as mentioned before the mm is evaluated by using the training dataset here after finishing each day the past test day s information tsdata i is added to the total training dataset and the same procedure of fig 1 is done again to find a new mm after that the procedure is continued using the real finalstate and online updated mm matrix 2 3 case studies in order to investigate the standard mc and two extensions of o mc and eo mc methods and to compare their results with the lr method and three ai methods of mlp elm and rbf in this study six different rivers are considered the ultimate goal of the present modeling is to reduce the need for labor intensive and expensive in situ measurements and to have an approximately worldwide coverage of the behavior of rivers however in order to examine the performance of the models it was important to choose rivers with accurate in situ discharge measurements therefore as shown in fig 3 the willamette red connecticut white pee dee and missouri rivers were chosen all of the rivers are in the united states because of their continuous long term measurement records in fig 3 according to the position of the gauge station of the river the closest pixel was selected as the measurement pixel of that river the position of the in situ gauge station and the satellite pixel of each river is shown in table 1 according to eq 4 in order to calculate the satellite signal the calibration pixel along with the measurement pixel are required however selecting a dry pixel close to the measurement one is not that easy when a high number of measurement pixels is considered therefore in this study the method of de groeve et al 2015 is applied according to this method it is obvious that the hottest nearby pixel should be the driest pixel as well this assumption is shown in the following equation 11 t b max t b w 0 t b min w according to eq 11 by decreasing the water portion of a pixel the brightness temperature increased because of the higher emissivity coefficient of the dry areas compare with the wet ones therefore according to eq 12 the driest pixel is the hottest nearby pixel as well and this pixel is selected as the calibration pixel 12 t b c max t b however in order to prevent the unexpected bugs because of low accuracy of one pixel as the hottest pixel instead of considering only the amount of one pixel according to de groeve et al 2015 a 9 9 pixel sheet is considered around of each measurement pixel and the 95th percentile of their brightness temperature is considered as the brightness temperature of the calibration pixel to use at the eq 4 in satellite signal measurement procedure 2 4 calculating the accuracy and reliability of the predictions as mentioned before the goal of the present study is to predict the satellite signals using its historical information forecasting the satellite signals using its own past information has many advantages because in this way there is no need to measure other relative parameters and the signals dataset is enough for the prediction procedure so that this method could be used especially in regions with limited economic resources without any concern of needing to determine other relative parameters however according to zaji et al 2018a there is a big defect in predicting the satellite signals using its historical information that has been neglected up to now this defect which occurrs in any regression based method can ruin the applicability of the models and make their results worthless that is why in the present study to extensions of the mc method namely o mc and eo mc are developed to be used in satellite signal time series prediction and their results are compared with lr mlp elm and rbf as some well known regression and ai methods to show that defect we need to identify two kinds of time series prediction errors the first kind of error which is called the traditional errors are calculated by using the traditional indices such as rmse mse r2 and δ which are presented in eqs 13 to 16 13 rmse i 1 n m i o i 2 n 14 mse i 1 n m i o i 2 n 15 r 2 1 i 1 n m i o i 2 i 1 n m i m i 2 16 δ i 1 n m i o i i 1 n m i where n is the total number of samples oi is the ith observed sample and mi is the ith modeled one all of the previous studies that used regression based models in order to predict the time series have used this kind of error to evaluate their models performance however in this study it is shown that in the case of predicting the future of a phenomenon using its own past information employing only this indices is not enough and a model cannot refer to a strong predictor by only considering them the traditional indices which are presented in eqs 13 to 16 are definitely needed for evaluating the accuracy of the predicted samples versus the observations or measurements however it should be considered with the new type of error simultaneously to show the importance of this defect andto define the new type of error consider the example of fig 4 in this figure the observations or measurements of four sequential samples of a considered time series are plotted with the blue line suppose that the goal is to predict today s amount by using the past day s information so that in each stage the past day s information is presented to the regression based model as the input variable and the predicted amount is considered as the output of the model in this figure the predicted amounts are plotted with an orange line according to the traditional indices the better model has the closer amount of each day s observation to each day s prediction as shown in this figure this type of error is shown by ve according to eqs 13 to 16 all of the traditional statistical indices are calculated according to this type of error as mentioned in this modeling the previous day s information is used as the input variable and today s information is the output actually the mentioned defect of regression models is arising here because of the close amounts of the considered two sequence days almost all of the regression based methods such as the lr and the ai based methods imitate their input variables instead of actually predicting today s amount of the time series in these cases the amount of traditional statistical indices become very good and that is why many studies acknowledge the very powerful capabilities of regression methods in forecasting the time series in order to calculate this defect a new type of error he is defined according to the schematic in fig 4 when a model imitates its input variable instead of a real prediction of the future the modeled amount of each day becomes almost exactly equal to the observation amount of the last day by considering the fact that the goal is to predict the amount of the time series dataset one day in advance if this defect occurs in a modeling procedure then the prediction results become worthless in fig 4 he is defined to be used to calculate the ivi index which can calculate the input imitation box in the regression modeling according to the following box in this box firstly the opn and smpn are predefined to zero after that a for loop is defined to consider all of the o and m datasets from the second samples to the end 1 one the reason for choosing the range of the second sample to the end 1 is in the definition of the peak point in this study a peak point refers to a point which has a higher or lower value compared with its past and forward points thus for all of the considered points the past and the forward points information are needed that is why the for loop starts with the second sample of the dataset and ends at the ns 1 one the for loop consists of two nested if conditions the first if condition tries to find the high peak points samples with higher values compared with their around samples and the second if condition tries to find the low peak points samples with lower values compared with their surrounding samples each of the if conditions consist of another inner if condition the outer if condition looks for the peak points at the o dataset and calculates the sum of them by using the opn variable the inner if condition looks into the m dataset to find the samples that are a peak at exactly the same time the o dataset s sample is a peak and calculates the sum of these two values at the smpn variable smpn is the number of peak points in the modeled dataset that occurs at exactly the same time of a peak occurrence in the observed dataset and opn is the number of peak points of the observed dataset it is clear that in an ideal situation with having an exact model the opn and smpn values should be equal on the other hand if a model imitates its input variable instead of really predicting the future none of the peak points of the observation dataset occur at the same time with the modeled dataset and smpn value becomes very low finally according to box 1 ivi is obtained by calculating 1 minus the division of smpn to opn therefore in an ideal model without input variable imitation the ivi becomes equal to 0 and in a model that imitates its input variables where all of its peaks occur with a delay related to the observed dataset the ivi becomes equal to 1 box 1 ivi calculation 3 results the results section contains four parts in the first part the considered six case studies are modeled using the mc and its two extensions of o mc and eo mc and their performance is compared after that in the second part of this section the mc based uncertainty analysis is done on the considered models to assess their reliability in addition in this part some additional calculations are done on the model s errors after running each model 1000 times the third part of this section calculates the ability of the models to deal with a lower number of training samples in this part the performance of the mc o mc and eo mc models in different situations with a lower number of training samples is assessed finally the performances of the mc extensions are compared with the mlp elm rbf and lr methods in this part the comparisons are made in two phases by using the first and second types of the indices which were presented in the previous sections to do that mse is considered as the index of the first type errors the vertical errors and ivi is calculated as the second type errors the horizontal errors 3 1 developing the mc based models in this part the considered case studies of willamette red connecticut white pee dee and missouri rivers satellite information are modeled using the simple mc model and its two developed extensions of o mc and eo mc as mentioned above the main difference between mc and o mc is the online updating of the current state in each day in addition to the online updating of the current state in each arrived day eo mc benefits from online updating the mm matrix during the test dataset modeling as well the results of the mc o mc and eo mc in modelling the considered case studies are plotted in fig 5 and their modelling statistical indices are presented in table 2 from fig 5 and table 2 because of the complexity of the missouri river s satellite signals the performances of the o mc and eo mc with rmse indices of 0 0089 and 0 0071 respectively are far better compared with the simple mc model with the rmse of 0 0251 clearly using the modeled dataset state of each day as the base for predicting the next day is not possible and the considered modifications are necessary in addition the eo mc performance is slightly better compare with the o mc which indicates the importance of the eo mc specific modification compares with the o mc for the pee dee river the dataset has fewer jumps and is more convenient and predictable compared with the missouri dataset because of the greater simplicity of this dataset the performance of the mc o mc and the eo mc with the rmse values of 0 0097 0 008 and 0 0062 respectively are relatively close to each other according to the rmse this dataset could be predicted with each of the considered models however according to fig 5 by modeling the pee dee river s signals using the simple mc model in about five points very large jumps occur in the modeling dataset these jumps are considered as the outlier samples for the o mc model these outliers are reduced to three and the minimum number of outlier samples occur in the eo mc modeling which has only one outlier sample in this case the eo mc performs better compare with the other two methods for the red river s satellite signals modeling the rmse amounts of the o mc and eo mc are similar to each other and equal to 0 0102 and both of these models perform far better compare with the simple mc with rmse of 0 0367 comparing the performance of the red river according to fig 5 shows that the performance of the mc model is not good for most of the time periods however both of the o mc and eo mc models perform very well in addition it is obvious that the outlier samples of the eo mc are less compared with the o mc the performance of the mc o mc and eo mc models of the white river are similar to the red river in this case the o mc and eo mc models with rmse of 0 0086 and 0 0081 perform similarly and the results of both of them are better compared with the simple mc model having rmse of 0 0246 for both of the red and white rivers the mc model even could not predict the trend and the periodic terms of the datasets and their results are meaningless for the case of willamette river the o mc and eo mc with equal rmse of 0 0066 performs much better compared with the mc model with rmse of 0 0242 in this case the performance of mc is not very good however this method almost predicts the trend and periodic terms of the time series accurately similar to some of the previous case studies in this case the significant advantage of the eo mc compare to the o mc model is to reduce the outlier samples for the connecticut river the mc predicts the trend pretty well however this model has some large outliers and its rmse statistical index with a value of 0 0267 is not very well the eo mc with rmse of 0 0063 performs better compared with the o mc with rmse of 0 0071 by considering all of the case studies the performance of the o mc and eo mc models are much better compared with the mc models the eo mc models perform better compared with the o mc in most of the cases in addition the eo mc has considerably fewer outlier samples compared with the other models 3 2 uncertainty analysis of the mc based models using the uncertainty analysis the complete range of possible results of the considered model could be obtained in addition by using this method the probability of the results of a model falling in a considered range is calculated applying the uncertainty analysis on the developed models helps to find its trustworthiness and reliability according to the previous sections the satellite based information of six different rivers in the united states is predicted using the simple mc and two extensions namely o mc and eo mc in addition the o mc performs much better compared with the simple mc model moreover the performance of eo mc is pretty similar to the o mc however in some situations the eo mc performs slightly better and exhibit a lower number of outlier samples in its results in this section the uncertainty of all three considered models is analyzed to accomplish this the monte carlo based uncertainty analysis which is developed by abbaspour et al 2007 and used as a powerful uncertainty analyzer in numerous studies in the literature noori et al 2015 raheli et al 2017 freeman et al 2018 is utilized monte carlo uncertainty analysis uses two indices in its procedure the first index is the 95ppu that calculates the percentage of samples that are within a specific range and the second index is the d factor that estimates the average distance of the 95ppu ranges in the uncertainty analysis of the present study in order to calculate the empirical cumulative distribution probability of the samples each of the considered methods were run 1000 times for each considered case study river for all of the present modeling procedures 90 of total samples of the dataset is considered for training the models and the remaining 10 is considered for the validating phase total samples number of the willamette red connecticut white pee dee and missouri rivers are 4576 4573 4567 5131 5222 and 4557 respectively after 1000 times modeling runs of each considered methods there are 4576 4573 4567 5131 5222 and 4557 empirical cumulative distribution probabilities for the above rivers respectively the lower xl and upper xu 95ppu probabilities are the 2 5th and 97 5th percentiles of the obtained empirical cumulative distribution probabilities respectively in an ideal situation 100 of the modeled samples should be in the 95ppu ranges and d factor should be close to zero however because of the complexity of the considered time series achieving these values is not possible according to the abbaspour et al 2007 good ranges of these two factors is completely problem dependent and in high quality modeling samples 80 to 100 of them should be bracketed by the 95ppu ranges and the average distance between xu and xl should be smaller compared with the standard deviation having a good balance between the two factors ensures that we have most of the samples within the 95ppu range while seeking the smallest possible uncertainty area according to d factor the average width of the 95ppu factor δ x is calculated according to 17 δ x 1 n i 1 n x u x l where n is a number of the considered dataset using the δ x formulation the d factor is defined as follow 18 d factor δ x σ where σ is the standard deviation of the samples here the 95ppu index is also used to show the number of samples that are bracketed in the 95ppu upper and lower ranges this index is calculated as 19 c c o u n t x mod e l i x u i x mod e l i x l i i 1 t o n 20 95 p p u c n 100 where c is the number of bracketed samples the results of the uncertainty analysis for the considered models and case studies are presented in fig 6 and table 3 for the missouri river case study the mc model s 95ppu brackets all of the samples so that its value is 100 however this good value of the 95ppu should be considered along with d factor according to fig 6 because of the high amount of d factor this prediction is not valuable in this case the 95ppu amounts of the o mc and eo mc models are the same and are equal to 99 7807 it is obvious that their 95ppu amount is lower compared with the simple mc model however the results are much better compared with the simple mc because of their lower amounts of the d factor the d factor amounts for the o mc and eo mc are 3 5576 and 3 5277 respectively comparing the results of the o mc and the eo mc shows that in this case the eo mc achieves better performance because this model brackets most of the samples in smaller 95ppu ranges the results of the pee dee river are the same as the missouri river the 95ppu of the simple mc model is 100 and its value for both of the o mc and eo mc models is 99 4253 however the advantage of o mc and eo mc models compared with the simple mc is in their lower amounts of d factor which is 6 1042 and 6 1054 respectively it is obvious that the o mc and eo mc uncertainty analysis results for this case is approximately the same however because of its lower d factor amount the o mc model performs slightly better the uncertainty analysis results of the red and white rivers are similar despite the missouri and pee dee rivers that have the simple mc 95ppu amounts of 100 in these cases the mc model could not evaluate all of the observation samples and the 95ppu of the red and white case studies are 56 0175 and 77 193 respectively for the red river it is obvious that the mc model could not predict most of the second half samples of the dataset even once in a thousand runs in this case the value of the 95ppu increases considerably for the o mc and eo mc models in addition the amount of the d factor which is 11 3612 for the mc model decreases significantly to 3 1849 and 3 1711 for the o mc and eo mc models respectively because of the same values of the 95ppu for the o mc and eo mc modes the uncertainty analysis of the eo mc with a lower amount of d factor is slightly better compared with the o mc model for the white river the uncertainty analysis of the o mc performs better compared with eo mc because of its higher amount of 95ppu and lower amount of d factor and both of the models perform significantly better compared with the mc model because of its low amount of 95ppu and high amount of d factor considering the willamette river the 95ppu has its highest performance in the eo mc model that is equal to 99 345 on the other hand the lowest amount of d factor is equal to 1 6137 which is obtained by o mc model so that in this case it is not possible to choose the best model but it is obvious that both of the o mc and eo mc models perform considerably better compared with the simple mc model for the connecticut river similar to the red and white rivers models the 95ppu amount is considerably low and simple mc could not model all of the samples even after one thousand model runs in addition the d factor value of this method is very high therefore mc is not a reliable model in this case comparing the o mc and eo mc models show that the eo mc model with 95ppu of 100 and d factor of 4 974 performs the best finally considering all of the six case studies uncertainty analysis results together it is clear that in most of them the simple mc with high d factor values shows that this model is not reliable and by using this model with complex time series most of the results samples are producing casually and they are not reliable to use in real world situations however it should be considered that the advantage of the simple mc model compare with its extensions is its ability to produce predictions several days ahead of time without needing their last day information to use as the models input variable the results of this section also showed that the uncertainty analysis performance of the o mc and eo mc models are almost identical in some cases the eo mc model performed slightly better as mentioned before the advantage of the o mc compare with the mc model is its online adjusting of the last stage in its procedure in addition the advantage of the eo mc model compared with the mc model is online adjusting the last stage and mm in the training and testing procedure therefore the most important parameter that affects the uncertainty analysis performance is the online last stage adjusting technology and this adjustment leads to higher reliability for the models compared with the online adjustment of the mm in the uncertainty analysis all of the models were run 1000 times and in each run all of its samples were generated so that for the willamette red connecticut white pee dee and missouri rivers a total of 4576000 4573000 4567000 5131000 5222000 and 4 557 000 samples were generated respectively the analysis of the errors of these samples is presented in fig 7 here the generated samples were subtracted from the observations and the error amount of each predicted sample was obtained and then histograms of errors distributions are plotted all of the o mc and eo mc models error samples closely followed the normal distribution shape however many of the mc errors do not follow the normal distribution for normal distribution datasets 68 of the samples are bracketed into the σ to the σ range where σ is the standard deviation of the samples the σ and σ amounts for each model is plotted in fig 7 with blue lines and the value of the σ for each model is presented in table 3 in addition the aue amounts of each model are calculated using averaging the total number of error samples and are also presented in table 3 according to fig 7 and table 3 the absolute amounts of aue and σ of the o mc and eo mc models are considerably lower compared with the mc models in addition the mc extension models do not have the simple mc defects such as skewness and not following the normal distribution 3 3 training dataset reduction as complete and qualified datasets are used for modeling and the number of data that considered as train data for modeling is high in such cases most modeling and time series prediction methods reach acceptable results but in real conditions such data are not always available and in many cases the number of train data is far less than the amount used in this article for modeling 90 of the data is considered as training data and the remaining 10 of the data is considered as test data so that for missouri pee dee red white willamette and connecticut rivers the train datasets samples numbers were 4101 4700 4116 4618 4118 and 4110 respectively and the test datasets samples numbers were 456 552 457 513 458 and 457 respectively it is clear that the number of train data is much more than the amount of test data which also increase the accuracy of the models to investigate the ability of the models studied in the absence of such long time series for train data this paper evaluates the strength of the models under study in the lack of train data conditions hence the reduction in train data is proceeded as a step to step as stated at first the percentage of train data is 90 so at each stage reduce one percent of the number of train data in each step and add one percent to test data the process of lowering train data is continued for 89 steps so in the last step the number of train data will be 1 and the number of test data will reach 99 for the considered case studies of missouri pee dee red white willamette and connecticut rivers at the last step of the train reduction the number of training datasets samples become 46 52 46 51 46 and 46 respectively and the number of the test datasets samples are 4511 5170 4527 5080 4530 and 4521 it is complicated to predict more than 4500 data as test data using only about 50 data as train data therefore the accuracy of the models decreases with incremental steps the modeling procedure of training dataset reduction is shown in fig 8 according to fig 8 sn starts from 1 and continues to 90 in each sn the model is executed ten times and its average error is stored in the arne variable this process was performed for all three mc o mc and eo mc models and all case studies the results are presented in fig 9 as shown in fig 9 in all cases after reducing a certain amount of train data the accuracy of the mc models has increased significantly this sudden increase in the error value of mc models in most rivers occurred in the range of sn 30 to 45 meaning that the percentage of train data reached 45 60 of the total data however for the connecticut river this sudden increase in sn error was approximately 20 where the train data was approximately 70 of the total data comparing the results of the o mc and eo mc models versus the results of the mc model represents a significant improvement this improvement in model resistance versus reduction in the number of train data in mc extension models results from the online update of models during the prediction and therefore this is the most significant advantage of these models compared to the simple mc by examining the results of the o mc models it is observed that firstly the modeling error value is much lower than the simple mc models secondly the sudden increase in the amount of model error caused by the decrease in the percentage of train data occurred in these models in the sn between 80 and 90 where the percentage of train data was between 1 and 10 indicating that these models are much more resistant to mc models the uncertainty of the o mc and eo mc models was similar and in some cases the eo mc model provides relatively better results however the main advantage of the eo mc model compared to the o mc model in this section is evident the eo mc model due to its robust update structure drives the modeling forward so that after passing through every day it uses the information of that day and other days to update the mm and correct the final step number as shown in fig 9 the eo mc model is capable of performing the modeling even with 1 of the total data in the train data without leaking the error value seen in the mc and o mc models this excellent performance of the eo mc model compared to the o mc is due to the update of the mm in any sn value hence when for example we are on the last step and only 1 of the data is used for train data at first mm is formed with only about 45 samples in the training dataset and the first test data is predicted however the different point of this model is that when we passed through the day we predicted the model automatically uses those data in making a better and more complete mm this trend continues until the last sample predicted in the test data and by increasing the number of days passed the model gradually performs better 3 4 considering the ivi problem of mc based methods in comparison with other regression methods in the previous parts of the results section the performance of mc o mc and eo mc was compared together after that the reliably and robustness of the models were studied next the performance of the models in a situation that there are not enough train dataset samples was compared together in this part one of the most important regression based model defect is considered predicting the future of a phenomenon using its past information is very important in many fields of science this procedure is very economical as well by using the historical information of a phenomenon to predict its future we do not need to measure and use the other surrounding information however predicting the future using the historical information by using the regression methods usually leads to the ivi problem which was discussed in the previous sections in order to examine the ivi problem the lr method and three well known ai methods of mlp elm and rbf are considered and compared with the o mc and eo mc methods which were considered in this study as mentioned the o mc and eo mc models use the previous day as the input variable in order to predict the amount of the considered problem for the present day so that in order to have a fair comparison in the mlp elm rbf and lr models the same input combination is selected for the modeling procedure unfortunately most of the indices that were used in the previous studies in order to examine the performance of the regression based prediction models can be categorized as the ve and none of them considered the he problem in addition the objective function used in the training procedure of the regression based methods is in the ve category so that by running the regression models in each iteration or step of the modeling the model checks its results with the observations using one of the ve indices such as mse therefore for them the best model is a model with the lowest mse as possible however when we use the last day information in a time series in order to predict the information for the present day in most of the cases the best answer for today is the last day information and the considered regression model reaches its lowest mse by transferring its input variable which is the last day s information to the output variable which is supposed to be the present day information without any manipulations in these cases the ve indices are significantly low that is why many researchers know the regression based methods as powerful future predictors however the results are not applicable and are meaningless here the mse index is considered as a proxy of the ve indices and the ivi index which is introduced in box 1 is considered as a he index the results of modeling for all case studies using the mlp elm rbf lr o mc and eo mc are presented in table 4 and fig 10 for the missouri case study the lr model reaches the lowest amount of the mse index compared with the other methods however it could be seen that the ivi of this model is 1 this means that the predicted samples peaks have not occurred at the same time as the observation samples at all and this model s results are unreliable in fact this model is presenting the past day information as the output when it is supposed to predict the next day the results of the mlp elm and rbf models are similar to the lr model in all of them the mse is very low and the ivi is almost 1 however the results of the o mc and the eo mc are completely different it could be seen that for the present case study the mse index of the o mc and eo mc are about five and three times higher respectively compared with the lr model at first glance the lr method has better performance in predicting the future satellite information of the missouri river however by considering the ivi indices of the o mc and eo mc models it is clear that these models have a far lower input imitation compare with the other methods in each modeling procedure a balance should be made between its mse precision and its ivi and neither of them should be considered separately in addition in most cases by decreasing the mse amount the ivi amount increases and vice versa in the present case study the mlp elm rbf and lr have a very low mse however they also have a very high amount of ivi as well for the missouri river as an example at the eo mc model the mse increases a little and the ivi decreases to have a balance between them for the pee dee river for another time by considering the mse index the lr performance is better to compare with all of the other methods however similar to the missouri river the ivi amounts of mlp elm and rbf methods are almost one here for another time the performance of the o mc and eo mc are considerably better compared with the other methods according to table 4 except for the red and white rivers for all of the case studies the lr model mse index performs the best results this is an unexpected result in the real world despite the lr model which used the linear equations the mlp elm and rbf models use nonlinear equations and are much more complex compared with the lr model actually these results do not show that the lr model is more accurate compared with the other ones here all of the lr mlp elm and rbf models simply imitate their input variables and none of them actually address the actual time series prediction problem this explains why there is no difference in the results of the nonlinear powerful regression methods and simple linear ones and why the mse and the ivi indices of all of the mlp elm rbf and lr models are very similar to each other according to fig 4 when a model imitates its input variables instead of actually predicting the future the predicted values are completely similar to the observations but occur one step ahead of them here in fig 10 only fifty samples of the dataset are plotted in order to see this defect completely form this figure it is obvious that all of the lr mlp elm and rbf models have the input imitation problem their modeled samples are completely similar to the observation ones and they only occur one day ahead of the observation samples which is the difference between the input variable time and the output variable time despite the lr mlp elm and rbf models the o mc and eo mc have difficulty with the complex problem of predicting the future using past information instead of simply copying the input variables as shown in fig 10 4 conclusions forecasting river water levels and discharge are one of the most important fields in hydraulic engineering one of the popular methods is to use historical time series of river discharges to predict the future values however in many countries river monitoring is done at a very limited number of gauge stations due to budget constraints to address this in this study remotely sensed satellite signals are used instead of the in situ discharge monitoring to develop an accessible method to forecast river flows the prediction was made using the mc model in addition the results of the mc model are improved by introducing two additional extensions of the model the first extension is referred to as the o mc which benefits from online updating of the optimum state number during the training procedure and the second extension is referred to as the eo mc which benefits from updating the online state number as well as updating the markov matrix mm updating the flood discharge predictions were completed for six case study rivers including connecticut missouri pee dee red white and willamette rivers and the results were evaluated in four different phases as follows 1 in the first phase the considered case studies satellite signals were calculated using the mc o mc and eo mc models and we concluded that the o mc and eo mc models outperformed the standard mc model in addition we showed that despite having better performance of eo mc compare with the o mc in most of the considered cases the performance of both methods was almost indistinguishable 2 in the second phase the uncertainty analysis was completed on each of the mc o mc and eo mc methods using 1000 simulations for each case study to calculate the 95ppu and d factor indices we concluded that the mc model with large d factor for the considered rivers is not reliable to be used in practical situations with complex time series in addition similar to the last phase the performance of both o mc and eo mc models were close to each other and both of them were far better compared with the simple mc model considering the fact that the difference between the eo mc and o mc is updating the mm matrix during the training procedure it was also concluded that the most important mc improvement in order to increase the uncertainty analysis performance is online updating the state s number which is done in both o mc and eo mc models 3 in the third phase the training dataset percentage was gradually reduced from 90 down to 1 in 1 increments in each train dataset reduction step the considered models were run again and the results were evaluated in this phase the performance of the mc model was decreased significantly after about a 30 reduction in train dataset for most of the case studies however the performance of o mc models only begins to decrease remarkably after about 80 reduction in the training dataset despite the mc and o mc models because of updating the mm matrix during the training the performance of eo mc remained constant for all of the steps we concluded that the advantage of eo mc compares with o mc is where the considered case studies are suffering from lack of training samples 4 many powerful regression methods could be considered instead of mc based models however to highlight the advantage of mc based models we compared the performance of o mc and eo mc models with four regression based models of mlp elm rbf and lr here it was shown that in cases that the goal is to predict the short term time series using its own historical information most of the regression based methods trapped in delivering the model s input variables as the considered output variable instead of really struggling with the time series prediction complexities in order to measure this defect a new statistical index namely ivi was introduced it was shown that for all of the considered regression based models the ivi index was almost one which indicates that those models present the last day amount as the output this index should be considered in all of the time series prediction models in the considered regression based models despite reaching very high accuracy related to extremely low mse amounts of them because of that high amount of ivi the results of them were worthless for the o mc and eo mc however despite having higher amounts of mse index the ivi index amounts were remarkably lower compared with the regression based methods therefore the obtained results could be considered in real word future predictions declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper the authors declare the following financial interests personal relationships which may be considered as potential competing interests 
6574,utilizing the readily available inexpensive remotely sensed satellite data products in combination with markov chain methods for estimating water levels and discharge anywhere along the vast river networks around the world is one of the most interesting and promising fields in hydrology this study presents two new extensions of markov chain mc methods namely the online markov chains o mc and extreme online markov chains eo mc methods to improve the prediction accuracy the o mc method has the advantage of the online implementation of the correct variable states and the eo mc method has the advantage of online updating the markov matrix mm along with the online implementation of the correct variable states the new o mc and the eo mc methods were evaluated using short term satellites signal predictions for six different case study rivers the monte carlo uncertainty analysis was used to measure the reliability of the new mc based methods each model was developed 1000 times to calculate two indices namely the 95 percent predicted uncertainties 95ppu and average distance factor d factor the performances of mc and two extensions of o mc and eo mc were also examined for cases where we lack the training data the training percent trpr of the entire dataset gradually decreased from 90 to 1 and the performance of the models in producing accurate future signals in the non observed dataset is calculated the input variable imitation ivi problem was considered for the mc based methods and the results were compared with the linear regression lr multi layer perceptron mlp extreme learning machine elm and radial basis function rbf regression methods the results showed that the performance of eo mc and o mc are better than the simple mc method in addition it is concluded that eo mc and o mc have very similar performance in the uncertainty analysis and both methods are robust techniques the main advantage of eo mc compared with the o mc method is highlighted when the number of training samples are very low finally considering the ivi problem the new o mc and eo mc methods significantly outperformed the lr mlp elm and rbf methods abbreviations 95ppu 95 percent predicted uncertainties δ average absolute deviation d factor average distance factor aue average uncertainty error r 2 coefficient of determination he horizontal error ivi input variable imitation mm markov matrices maxtotdata maximum amount of total dataset mse mean squared error mintotdata minimum amount of total dataset m modeled statenum number of states totnum number of total dataset samples trnum number of train dataset samples o observed opn observed peak number staterange range of the states rmse root mean squared error rn run number smpn simultaneous modeled peak number sn step number tspr testing percent ith day currstate the state of the current day i 1th day nextstate the state of the next day totdata total dataset trpr training percent ve vertical error keywords input variable imitation markov chains monte carlo uncertainty analysis online training river discharge satellite information 1 introduction climate change effects have increased the severity of floods and this phenomenon adversely affects more people compared to other natural disasters de groeve and riva 2009 early warning systems rely on timely and accurate forecasts to minimize the loss of life from floods despite the importance of this problem the state of knowledge in this field has yet to take full advantage of the major new developments in more accurate remotely sensed inexpensive and readily available data products these data products having global spatial coverage combined with advanced new machine learning tools for real time analysis and modelling of river water levels and discharge allow for flood forecasting and inundation mapping tools for early warning systems artificial intelligence ai methods have been widely used in many fields of hydrology wang et al 2017a modeled the pan evaporation ep at six stations of yangtze river using different environmental factors the authors used three novel ai methods of fuzzy genetic fg an adaptive neuro fuzzy inference system with grid partition anfis gp and m5 model tree m5tree methods as another study wang et al 2017b modeled ep with limited climatic parameters using six different ai methods of mlp generalized regression neural network grnn fg support vector regression svr multivariate adaptive regression spline mars and anfis gp bou fakhreddine et al 2018 predicted the daily river flow using a two phase constructive fuzzy inference hybrid model in combination with the re sampled data in order to increase the prediction performance the authors used the rainfall and river flow measurements as the input variables zounemat kermani and mahdavi meymand 2019 developed a hybrid method by combining two different ai methods of mlp and anfis with four optimization algorithms to estimate the flow rate passing a piano key weir free surface control structure one of the most popular fields in hydrology that has been recently modeled using ai techniques is flood water levels for instance he et al 2014 utilized the mlp svr and anfis in river flow prediction problems chen et al 2015 modeled the altamaha river using different optimization algorithms fuzzy patterns and continuity equation in a hybrid ai method using the feedforward and recurrent neural network darras et al 2017 modeled flash floods and found that the recurrent procedure performs better for longer lead time and feedforward procedure performs better for short range flash floods predictions young et al 2017 developed a combination model that was formed from the svr method and hydrologic models and applied that model to simulate the rainfall runoff during typhoon events by combining the wavelet transformation and mlp rainfall runoff of the told river was predicted up to two months in advance successfully by alizadeh et al 2017 the above mentioned studies demonstrated the prediction power of regression based methods in flood forecasting however these studies all used in situ hydrometric survey data that is not available in many parts of the world the number of hydrometric stations around the world is in decline to due economic constraints calmant and seyler 2006 khan et al 2012 perdikaris et al 2018 shiklomanov et al 2002 sivapalan 2003 stokstad 1999 the main interest of researchers in this field is to use satellite information to model and predict the hydrological problems brakenridge et al 2007 jiang et al 2014 khan et al 2011 su et al 2008 temimi et al 2011 temimi et al 2007 zeynoddin et al 2018 2019 one of the well known and popular satellite missions which was successfully utilized in river discharge simulations is the passive microwave sensors of the advanced microwave scanning radiometer amsr satellite brakenridge et al 2007 which started at the dartmouth flood observatory dfo and followed by the joint research center jrc the amse calculates the water surface area of rivers by measuring the difference between land and water brightness temperatures the amsr gathered data are validated with the global flood detection system gfds and are accessible at www gdacs org de groeve 2010 used the amsr observations in order to calculate the size of the floods and concluded that the floods could be predicted using the upstream information and that they can be recognized at least two hours after their occurrence the river discharges were calibrated to the satellite amsr information by brakenridge et al 2012 and cohen et al 2012 the authors made a hydrological model to calculate the river discharges using the satellite information at the same time and concluded that the amsr satellite signals have the ability to model in situ river discharges accurately using the upstream satellite remote sensing data and the wave propagation concept hirpa et al 2013 forecasted the river discharges and concluded that there is a good correlation between satellite information and in situ gauge measurements the research of khan et al 2014 showed that the remote sensing data could be utilized with the in situ sparsely gauges to detect the floods in large basins revilla romero et al 2014 tested 322 rivers to find the best correlation between the satellite and in situ discharge information and the high correlation areas were used to fill the real time ground based measurements gaps using the moderate resolution imaging spectroradiometer modis sensors revilla romero et al 2015 and van dijk et al 2016 simulated the rivers discharge successfully and showed that this sensor could be used in modeling the in situ information zaji et al 2018a presented a method to use upstream satellite pixels in order to predict the future of rivers discharges zaji et al 2018b c showed that using the introduced preprocessing method the in situ rivers discharges could be modeled more accurately using the satellite information according to the literature river discharges could be calibrated using the satellites signals so that in order to predict the future river discharges for flood monitoring or adjusting the relative hydraulic structure using the satellite information it is necessary to predict the satellite signals accurately in this study two novel extensions of the mc method namely o mc and eo mc are developed and used to predict the short term satellite signals dissimilar to the mc which just uses the last state of the training dataset to develop the non observed dataset the o mc method updates the correct states during the prediction the eo mc however is one further step ahead in this procedure both of the states and the mm are updated during the non observed prediction then the performance of the models are measured using common statistical indices and the reliability of the models is calculated by means of the monte carlo uncertainty analysis in addition the applicability of the models for the case of lacking the source information is calculated by diminishing the trpr gradually and simultaneously increasing the non observed dataset samples in this test the trpr is reduced from 90 to 1 in 90 steps 1 decrement at each step finally this study focusses on one of the most important regression methods limitations in predicting the future condition of a phenomenon using its past information in many cases the regression methods choose the easiest way and simply imitate their input variables instead of actually predicting the future here the ivi amount of the mc o mc and eo mc methods are calculated and compared with the ivi amounts of the simple lr and three well known ai methods mlp elm and rbf the rest of the paper is organized as follows in the next section the methodology of the procedures is described in the first part of this section the gathering method of the satellite information and the connection formulation to the satellite signals is described after that the calculation processes of the mc o mc and eo mc are described in the last part of the methodology section the considered case study rivers are introduced after that in the first part of the results section the results of modeling the considered case studies using the mc o mc and eo mc models are presented and the performance of the models are assessed using the common statistical indices then the uncertainty analysis of the models us discussed in the next part in the last part of the results section the ivi defect of the mc o mc and eo mc models are calculated and the results are compared with the results of the lr mlp elm and rbf regression methods by using the case studies finally the entire results and implications of the present study are summarized in the conclusion section 2 methodology the methodology which is proposed in the present investigation is based on brakenridge et al 2012 these authors proposed some equations in order to calibrate the satellite information and in situ rivers discharge in the presented equations the amsr satellite signals were used as the input variable and the output was the considered river discharges they proved that by having the satellite information the river discharge parameter could be modeled accurately it also could be concluded that by having the calibration equations the need for daily measurements of river discharge is diminished and only some occasionally measurements are needed for the recalibration purposes the idea of using satellite signals instead of in situ information and diminishing the gauge station measurements has lots of advantages such as decreasing the maintenance cost of the gauge stations however in this case in order to predict the future river discharge there are not any continuous in situ measurement datasets and forecasting the future river discharge using the past information is not possible to solve this shortage one of the simplest ways is to predict the future of satellite signals instead of predicting the discharge of the rivers because the historical information of the satellite signals is available completely and there are numerous accurate methods to calibrate them to the river discharge for this reason this study is focused on predicting the satellite signals using its own past information instead of predicting the river discharges this section has three parts in the first part the used satellite formulation and its relation to river discharge are described after having a glance at the traditional mc method s formulation its two extensions of o mc and eo mc are described in the third part the case studies which are used in order to examine the results of the mc o mc and eo mc and comparing their results with the lr and ai models are introduced finally in the last part of this section the traditional statistical indices such as root mean squared error rmse mean squared error mse coefficient of determination r2 and average absolute deviation δ and the new index of measuring the truly modeling error in time series prediction models ivi which are used in order to compare the considered models are introduced 2 1 satellite based information previous studies showed that by using the brightness temperature measurement of amse descending orbit h polarization in 36 ghz band the changes of the rivers discharge could be calibrated accurately without concerning the weather conditions brakenridge et al 2005 de groeve et al 2015 the satellite signals are calculated using the brightness temperature tb which is calculated using the following equation 1 t b ε t where ε is the emissivity coefficient and t is the physical temperature of the considered area identifying the amount of water in a portion of land is done using the differences of ε which is about 0 5 for the wet surfaces and 0 75 to 0 95 for the dry surfaces sharkov 2003 so that in case of having a similar physical temperature the tb of a full of surface water pixel is considerably lower than the tb of a dry pixel however as mentioned before each pixel of the amsr sensor covers a relatively large area when the goal is to measure the river s properties in almost all instances a portion of each rivers pixels covered with water w and the remaining area of the considered pixel is covered with land 1 w therefore the brightness temperature of each pixel calculated using the eq 2 in this equation tb l and tb w are the brightness temperature of the land and water portions of the considered pixel respectively 2 t b 1 w t b l w t b w it should be noted that because of the close position of the dry and wet areas of a pixel in this equation the physical temperature could be considered constant to write the eq 2 in the form of eq 3 in this equation the variables of εl and εw are the dry and wet areas emissivity coefficients respectively 3 t b t 1 w ε 1 w ε w in order to remove the effect of different physical temperatures at different times of the year and eliminate the t term from eq 3 the river pixel tb m brightness temperature is always divided by an adjacent fully dry pixel tb c as a calibration pixel so that the final satellite signal equation which is used to calculate the characteristics of the river is obtained as follows kugler and de groeve 2007 4 s t b c t b m t 1 0 ε 1 0 ε w t 1 w ε 1 w ε w ε 1 1 w ε 1 w ε w the reason for choosing the adjacent pixel as the calibration pixel is to have an almost similar physical temperature in both pixels so that the t terms are considered equal in the last equation from eq 4 the s variable is related to two constants of εl and εw and one variable of w so that all the signal changes are related to the amount of w according to eq 4 the number of s increases by increasing the water portion of the pixel and vice versa the footprint size of the amsr satellite sensor that is used in the present study as the satellite signals information is 8 12 km2 so that the entire surface of the earth was divided into 4000 2000 pixels in order to achieve the satellite signals all of the amsr images were downloaded from www gdacs org and after that according to the latitude longitude of the considered point of the rivers the measurement pixels and the calibration pixels were selected for each considered case study finally the satellite signal dataset of each river was achieved using eq 4 according to the above equations it is clear that the number of satellite signals is changed in regard to the amount of water in the pixel the changes in the satellite signals could be considered as a proxy for the changes in the river discharge the discharge of a river q is calculated using the concept of continuity and related to the width and depth of the river b and d respectively and the flow velocity v as follows 5 q b d v in river having non vertical channel banks the effects of changing w and d on discharge are almost similar bjerklie et al 2005 and both of them are better predictors compared with the v brakenridge et al 2012 by considering the width of a river as its occupant area in the considered satellite pixel the river discharge could be calibrated to the satellite signals accurately brakenridge et al 2012 2 2 markov chain methods mc is a simple modeling and prediction method that works based on the stochastic procedure serfozo 2009 in order to describe a sequence of possible events gagniuc 2017 in this stochastic procedure the markov property should be satisfied rozanov 1982 the markov property is being satisfied if the future prediction of a process could be made independent of the history of that process consider the following statement 6 x n n 0 1 2 here xn is a stochastic procedure that has a finite number of possible values the statement of xn being equal to i infers that at time n the procedure is in state i here is an assumption that when the procedure is in state i then there is a fixed possibility of pij that the next procedure s state is j therefore we have 7 p ij p x n 1 j x n i n x n 1 i n 1 x 1 i 1 x 0 i 0 all of the n values and the j i in 1 i 0 are non negative amounts this equation represents the base mc procedure the pij says that if the current position of a process is i there is a pij probability that its next state is j and it follows the following equation 8 j 0 p ij 1 i 0 1 j 0 p ij 0 by having all of the p indices the mm is developed as follows which is the first order one step transition matrix 9 mm p 00 p 01 p 02 p 10 p 11 p 12 p i 0 p i 1 p i 2 in order to evaluate the mm in this study the procedure shown in fig 1 is followed according to this figure three steps should be done in order to reach the mm the first step is the dividing phase in this step the total data is divided into two different partitions the training dataset which is used in order to evaluate the models and the testing dataset which is used to validate the models after preparing the datasets the state matrix is evaluated in the second step of fig 1 before calculating the state matrix a number of total states should be inputted to the code by the user the number of state coefficients depends on the considered problem in this study different amounts of statenum variable were tested and it was concluded that for the considered case studies the best results are achieved by having 20 states thus for all of the mc base modeling which are presented in this study the number of states coefficient considered is 20 by having the number of states and the range of each state which are calculated in this part the state matrix is calculated in order to achieve the following matrix 10 state mintotdata mintotdata s t a t e r a n g e mintotdata s t a t e r a n g e mintotdata 2 s t a t e r a n g e mintotdata 2 s t a t e r a n g e mintotdata 3 s t a t e r a n g e mintotdata statenum 1 s t a t e r a n g e mintotdata s t a t e n u m s t a t e r a n g e this is a matrix with statenum rows and two columns each row of this matrix represents the minimum and maximum range of the row number state by its first and second columns amounts after evaluating the state matrix according to fig 1 the mm could be evaluated at the last step the last step comprises from two different pseudocodes the first one is to develop the raw mm and the second one is to normalize it for developing the mm the train samples and the rows of the state matrix are considered according to each other using two nested for loops in addition in this part the state of the i th and i 1 th samples of the training dataset are calculated by using two if conditions after the first pseudocode a raw mm has been developed however because of the probability rule the sum of the values of each row of mm should be one so that at the second pseudocode the achieved mm is normalized mc based methods use the training dataset in order to develop the mm then by using that matrix the testing samples are predicted the main difference among mc o mc and eo mc methods is their procedure of predicting the test dataset samples that are non observed for the models the output generation step of the considered mc based methods is presented in fig 2 this step is only formed from one for a loop as could be seen in this loop the test dataset is considered the first line of this for loop is to evaluate the nextstate which is obtained by using the obtained mm matrix it should be noted when i is equal to one and there is the first for loop the finalstate is actually the state of the last sample of the training dataset after evaluating the nextstate at the second line of the for loop the output data is calculated using the state matrix to do that a random number between the first and second columns of the nextstate th row of the state matrix is selected as the output value as mentioned when the i counter of the for loop is equal to one the finalstate is obtained from the last sample of the trdata however for other i values i 2 3 number of tsdata elements the finalstate should be determined in the for loop itself the standard mc model simply inserts the computed nextstate into the finalstate variable and starts the next loop however according to fig 2 the o mc model has a different procedure in this method after predicting the next day the nextstate is updated online by using the past day s real information so that in this procedure in order to calculate the nextstate the real state of the current day is used the only difference between the mc and o mc models is that the o mc uses the past test days information and make its predictions online the eo mc is one step ahead of the o mc method in this procedure the same process of o mc is done in order to find the real nextstate variable according to the passed day s information however there is an additional process in this algorithm as mentioned before the mm is evaluated by using the training dataset here after finishing each day the past test day s information tsdata i is added to the total training dataset and the same procedure of fig 1 is done again to find a new mm after that the procedure is continued using the real finalstate and online updated mm matrix 2 3 case studies in order to investigate the standard mc and two extensions of o mc and eo mc methods and to compare their results with the lr method and three ai methods of mlp elm and rbf in this study six different rivers are considered the ultimate goal of the present modeling is to reduce the need for labor intensive and expensive in situ measurements and to have an approximately worldwide coverage of the behavior of rivers however in order to examine the performance of the models it was important to choose rivers with accurate in situ discharge measurements therefore as shown in fig 3 the willamette red connecticut white pee dee and missouri rivers were chosen all of the rivers are in the united states because of their continuous long term measurement records in fig 3 according to the position of the gauge station of the river the closest pixel was selected as the measurement pixel of that river the position of the in situ gauge station and the satellite pixel of each river is shown in table 1 according to eq 4 in order to calculate the satellite signal the calibration pixel along with the measurement pixel are required however selecting a dry pixel close to the measurement one is not that easy when a high number of measurement pixels is considered therefore in this study the method of de groeve et al 2015 is applied according to this method it is obvious that the hottest nearby pixel should be the driest pixel as well this assumption is shown in the following equation 11 t b max t b w 0 t b min w according to eq 11 by decreasing the water portion of a pixel the brightness temperature increased because of the higher emissivity coefficient of the dry areas compare with the wet ones therefore according to eq 12 the driest pixel is the hottest nearby pixel as well and this pixel is selected as the calibration pixel 12 t b c max t b however in order to prevent the unexpected bugs because of low accuracy of one pixel as the hottest pixel instead of considering only the amount of one pixel according to de groeve et al 2015 a 9 9 pixel sheet is considered around of each measurement pixel and the 95th percentile of their brightness temperature is considered as the brightness temperature of the calibration pixel to use at the eq 4 in satellite signal measurement procedure 2 4 calculating the accuracy and reliability of the predictions as mentioned before the goal of the present study is to predict the satellite signals using its historical information forecasting the satellite signals using its own past information has many advantages because in this way there is no need to measure other relative parameters and the signals dataset is enough for the prediction procedure so that this method could be used especially in regions with limited economic resources without any concern of needing to determine other relative parameters however according to zaji et al 2018a there is a big defect in predicting the satellite signals using its historical information that has been neglected up to now this defect which occurrs in any regression based method can ruin the applicability of the models and make their results worthless that is why in the present study to extensions of the mc method namely o mc and eo mc are developed to be used in satellite signal time series prediction and their results are compared with lr mlp elm and rbf as some well known regression and ai methods to show that defect we need to identify two kinds of time series prediction errors the first kind of error which is called the traditional errors are calculated by using the traditional indices such as rmse mse r2 and δ which are presented in eqs 13 to 16 13 rmse i 1 n m i o i 2 n 14 mse i 1 n m i o i 2 n 15 r 2 1 i 1 n m i o i 2 i 1 n m i m i 2 16 δ i 1 n m i o i i 1 n m i where n is the total number of samples oi is the ith observed sample and mi is the ith modeled one all of the previous studies that used regression based models in order to predict the time series have used this kind of error to evaluate their models performance however in this study it is shown that in the case of predicting the future of a phenomenon using its own past information employing only this indices is not enough and a model cannot refer to a strong predictor by only considering them the traditional indices which are presented in eqs 13 to 16 are definitely needed for evaluating the accuracy of the predicted samples versus the observations or measurements however it should be considered with the new type of error simultaneously to show the importance of this defect andto define the new type of error consider the example of fig 4 in this figure the observations or measurements of four sequential samples of a considered time series are plotted with the blue line suppose that the goal is to predict today s amount by using the past day s information so that in each stage the past day s information is presented to the regression based model as the input variable and the predicted amount is considered as the output of the model in this figure the predicted amounts are plotted with an orange line according to the traditional indices the better model has the closer amount of each day s observation to each day s prediction as shown in this figure this type of error is shown by ve according to eqs 13 to 16 all of the traditional statistical indices are calculated according to this type of error as mentioned in this modeling the previous day s information is used as the input variable and today s information is the output actually the mentioned defect of regression models is arising here because of the close amounts of the considered two sequence days almost all of the regression based methods such as the lr and the ai based methods imitate their input variables instead of actually predicting today s amount of the time series in these cases the amount of traditional statistical indices become very good and that is why many studies acknowledge the very powerful capabilities of regression methods in forecasting the time series in order to calculate this defect a new type of error he is defined according to the schematic in fig 4 when a model imitates its input variable instead of a real prediction of the future the modeled amount of each day becomes almost exactly equal to the observation amount of the last day by considering the fact that the goal is to predict the amount of the time series dataset one day in advance if this defect occurs in a modeling procedure then the prediction results become worthless in fig 4 he is defined to be used to calculate the ivi index which can calculate the input imitation box in the regression modeling according to the following box in this box firstly the opn and smpn are predefined to zero after that a for loop is defined to consider all of the o and m datasets from the second samples to the end 1 one the reason for choosing the range of the second sample to the end 1 is in the definition of the peak point in this study a peak point refers to a point which has a higher or lower value compared with its past and forward points thus for all of the considered points the past and the forward points information are needed that is why the for loop starts with the second sample of the dataset and ends at the ns 1 one the for loop consists of two nested if conditions the first if condition tries to find the high peak points samples with higher values compared with their around samples and the second if condition tries to find the low peak points samples with lower values compared with their surrounding samples each of the if conditions consist of another inner if condition the outer if condition looks for the peak points at the o dataset and calculates the sum of them by using the opn variable the inner if condition looks into the m dataset to find the samples that are a peak at exactly the same time the o dataset s sample is a peak and calculates the sum of these two values at the smpn variable smpn is the number of peak points in the modeled dataset that occurs at exactly the same time of a peak occurrence in the observed dataset and opn is the number of peak points of the observed dataset it is clear that in an ideal situation with having an exact model the opn and smpn values should be equal on the other hand if a model imitates its input variable instead of really predicting the future none of the peak points of the observation dataset occur at the same time with the modeled dataset and smpn value becomes very low finally according to box 1 ivi is obtained by calculating 1 minus the division of smpn to opn therefore in an ideal model without input variable imitation the ivi becomes equal to 0 and in a model that imitates its input variables where all of its peaks occur with a delay related to the observed dataset the ivi becomes equal to 1 box 1 ivi calculation 3 results the results section contains four parts in the first part the considered six case studies are modeled using the mc and its two extensions of o mc and eo mc and their performance is compared after that in the second part of this section the mc based uncertainty analysis is done on the considered models to assess their reliability in addition in this part some additional calculations are done on the model s errors after running each model 1000 times the third part of this section calculates the ability of the models to deal with a lower number of training samples in this part the performance of the mc o mc and eo mc models in different situations with a lower number of training samples is assessed finally the performances of the mc extensions are compared with the mlp elm rbf and lr methods in this part the comparisons are made in two phases by using the first and second types of the indices which were presented in the previous sections to do that mse is considered as the index of the first type errors the vertical errors and ivi is calculated as the second type errors the horizontal errors 3 1 developing the mc based models in this part the considered case studies of willamette red connecticut white pee dee and missouri rivers satellite information are modeled using the simple mc model and its two developed extensions of o mc and eo mc as mentioned above the main difference between mc and o mc is the online updating of the current state in each day in addition to the online updating of the current state in each arrived day eo mc benefits from online updating the mm matrix during the test dataset modeling as well the results of the mc o mc and eo mc in modelling the considered case studies are plotted in fig 5 and their modelling statistical indices are presented in table 2 from fig 5 and table 2 because of the complexity of the missouri river s satellite signals the performances of the o mc and eo mc with rmse indices of 0 0089 and 0 0071 respectively are far better compared with the simple mc model with the rmse of 0 0251 clearly using the modeled dataset state of each day as the base for predicting the next day is not possible and the considered modifications are necessary in addition the eo mc performance is slightly better compare with the o mc which indicates the importance of the eo mc specific modification compares with the o mc for the pee dee river the dataset has fewer jumps and is more convenient and predictable compared with the missouri dataset because of the greater simplicity of this dataset the performance of the mc o mc and the eo mc with the rmse values of 0 0097 0 008 and 0 0062 respectively are relatively close to each other according to the rmse this dataset could be predicted with each of the considered models however according to fig 5 by modeling the pee dee river s signals using the simple mc model in about five points very large jumps occur in the modeling dataset these jumps are considered as the outlier samples for the o mc model these outliers are reduced to three and the minimum number of outlier samples occur in the eo mc modeling which has only one outlier sample in this case the eo mc performs better compare with the other two methods for the red river s satellite signals modeling the rmse amounts of the o mc and eo mc are similar to each other and equal to 0 0102 and both of these models perform far better compare with the simple mc with rmse of 0 0367 comparing the performance of the red river according to fig 5 shows that the performance of the mc model is not good for most of the time periods however both of the o mc and eo mc models perform very well in addition it is obvious that the outlier samples of the eo mc are less compared with the o mc the performance of the mc o mc and eo mc models of the white river are similar to the red river in this case the o mc and eo mc models with rmse of 0 0086 and 0 0081 perform similarly and the results of both of them are better compared with the simple mc model having rmse of 0 0246 for both of the red and white rivers the mc model even could not predict the trend and the periodic terms of the datasets and their results are meaningless for the case of willamette river the o mc and eo mc with equal rmse of 0 0066 performs much better compared with the mc model with rmse of 0 0242 in this case the performance of mc is not very good however this method almost predicts the trend and periodic terms of the time series accurately similar to some of the previous case studies in this case the significant advantage of the eo mc compare to the o mc model is to reduce the outlier samples for the connecticut river the mc predicts the trend pretty well however this model has some large outliers and its rmse statistical index with a value of 0 0267 is not very well the eo mc with rmse of 0 0063 performs better compared with the o mc with rmse of 0 0071 by considering all of the case studies the performance of the o mc and eo mc models are much better compared with the mc models the eo mc models perform better compared with the o mc in most of the cases in addition the eo mc has considerably fewer outlier samples compared with the other models 3 2 uncertainty analysis of the mc based models using the uncertainty analysis the complete range of possible results of the considered model could be obtained in addition by using this method the probability of the results of a model falling in a considered range is calculated applying the uncertainty analysis on the developed models helps to find its trustworthiness and reliability according to the previous sections the satellite based information of six different rivers in the united states is predicted using the simple mc and two extensions namely o mc and eo mc in addition the o mc performs much better compared with the simple mc model moreover the performance of eo mc is pretty similar to the o mc however in some situations the eo mc performs slightly better and exhibit a lower number of outlier samples in its results in this section the uncertainty of all three considered models is analyzed to accomplish this the monte carlo based uncertainty analysis which is developed by abbaspour et al 2007 and used as a powerful uncertainty analyzer in numerous studies in the literature noori et al 2015 raheli et al 2017 freeman et al 2018 is utilized monte carlo uncertainty analysis uses two indices in its procedure the first index is the 95ppu that calculates the percentage of samples that are within a specific range and the second index is the d factor that estimates the average distance of the 95ppu ranges in the uncertainty analysis of the present study in order to calculate the empirical cumulative distribution probability of the samples each of the considered methods were run 1000 times for each considered case study river for all of the present modeling procedures 90 of total samples of the dataset is considered for training the models and the remaining 10 is considered for the validating phase total samples number of the willamette red connecticut white pee dee and missouri rivers are 4576 4573 4567 5131 5222 and 4557 respectively after 1000 times modeling runs of each considered methods there are 4576 4573 4567 5131 5222 and 4557 empirical cumulative distribution probabilities for the above rivers respectively the lower xl and upper xu 95ppu probabilities are the 2 5th and 97 5th percentiles of the obtained empirical cumulative distribution probabilities respectively in an ideal situation 100 of the modeled samples should be in the 95ppu ranges and d factor should be close to zero however because of the complexity of the considered time series achieving these values is not possible according to the abbaspour et al 2007 good ranges of these two factors is completely problem dependent and in high quality modeling samples 80 to 100 of them should be bracketed by the 95ppu ranges and the average distance between xu and xl should be smaller compared with the standard deviation having a good balance between the two factors ensures that we have most of the samples within the 95ppu range while seeking the smallest possible uncertainty area according to d factor the average width of the 95ppu factor δ x is calculated according to 17 δ x 1 n i 1 n x u x l where n is a number of the considered dataset using the δ x formulation the d factor is defined as follow 18 d factor δ x σ where σ is the standard deviation of the samples here the 95ppu index is also used to show the number of samples that are bracketed in the 95ppu upper and lower ranges this index is calculated as 19 c c o u n t x mod e l i x u i x mod e l i x l i i 1 t o n 20 95 p p u c n 100 where c is the number of bracketed samples the results of the uncertainty analysis for the considered models and case studies are presented in fig 6 and table 3 for the missouri river case study the mc model s 95ppu brackets all of the samples so that its value is 100 however this good value of the 95ppu should be considered along with d factor according to fig 6 because of the high amount of d factor this prediction is not valuable in this case the 95ppu amounts of the o mc and eo mc models are the same and are equal to 99 7807 it is obvious that their 95ppu amount is lower compared with the simple mc model however the results are much better compared with the simple mc because of their lower amounts of the d factor the d factor amounts for the o mc and eo mc are 3 5576 and 3 5277 respectively comparing the results of the o mc and the eo mc shows that in this case the eo mc achieves better performance because this model brackets most of the samples in smaller 95ppu ranges the results of the pee dee river are the same as the missouri river the 95ppu of the simple mc model is 100 and its value for both of the o mc and eo mc models is 99 4253 however the advantage of o mc and eo mc models compared with the simple mc is in their lower amounts of d factor which is 6 1042 and 6 1054 respectively it is obvious that the o mc and eo mc uncertainty analysis results for this case is approximately the same however because of its lower d factor amount the o mc model performs slightly better the uncertainty analysis results of the red and white rivers are similar despite the missouri and pee dee rivers that have the simple mc 95ppu amounts of 100 in these cases the mc model could not evaluate all of the observation samples and the 95ppu of the red and white case studies are 56 0175 and 77 193 respectively for the red river it is obvious that the mc model could not predict most of the second half samples of the dataset even once in a thousand runs in this case the value of the 95ppu increases considerably for the o mc and eo mc models in addition the amount of the d factor which is 11 3612 for the mc model decreases significantly to 3 1849 and 3 1711 for the o mc and eo mc models respectively because of the same values of the 95ppu for the o mc and eo mc modes the uncertainty analysis of the eo mc with a lower amount of d factor is slightly better compared with the o mc model for the white river the uncertainty analysis of the o mc performs better compared with eo mc because of its higher amount of 95ppu and lower amount of d factor and both of the models perform significantly better compared with the mc model because of its low amount of 95ppu and high amount of d factor considering the willamette river the 95ppu has its highest performance in the eo mc model that is equal to 99 345 on the other hand the lowest amount of d factor is equal to 1 6137 which is obtained by o mc model so that in this case it is not possible to choose the best model but it is obvious that both of the o mc and eo mc models perform considerably better compared with the simple mc model for the connecticut river similar to the red and white rivers models the 95ppu amount is considerably low and simple mc could not model all of the samples even after one thousand model runs in addition the d factor value of this method is very high therefore mc is not a reliable model in this case comparing the o mc and eo mc models show that the eo mc model with 95ppu of 100 and d factor of 4 974 performs the best finally considering all of the six case studies uncertainty analysis results together it is clear that in most of them the simple mc with high d factor values shows that this model is not reliable and by using this model with complex time series most of the results samples are producing casually and they are not reliable to use in real world situations however it should be considered that the advantage of the simple mc model compare with its extensions is its ability to produce predictions several days ahead of time without needing their last day information to use as the models input variable the results of this section also showed that the uncertainty analysis performance of the o mc and eo mc models are almost identical in some cases the eo mc model performed slightly better as mentioned before the advantage of the o mc compare with the mc model is its online adjusting of the last stage in its procedure in addition the advantage of the eo mc model compared with the mc model is online adjusting the last stage and mm in the training and testing procedure therefore the most important parameter that affects the uncertainty analysis performance is the online last stage adjusting technology and this adjustment leads to higher reliability for the models compared with the online adjustment of the mm in the uncertainty analysis all of the models were run 1000 times and in each run all of its samples were generated so that for the willamette red connecticut white pee dee and missouri rivers a total of 4576000 4573000 4567000 5131000 5222000 and 4 557 000 samples were generated respectively the analysis of the errors of these samples is presented in fig 7 here the generated samples were subtracted from the observations and the error amount of each predicted sample was obtained and then histograms of errors distributions are plotted all of the o mc and eo mc models error samples closely followed the normal distribution shape however many of the mc errors do not follow the normal distribution for normal distribution datasets 68 of the samples are bracketed into the σ to the σ range where σ is the standard deviation of the samples the σ and σ amounts for each model is plotted in fig 7 with blue lines and the value of the σ for each model is presented in table 3 in addition the aue amounts of each model are calculated using averaging the total number of error samples and are also presented in table 3 according to fig 7 and table 3 the absolute amounts of aue and σ of the o mc and eo mc models are considerably lower compared with the mc models in addition the mc extension models do not have the simple mc defects such as skewness and not following the normal distribution 3 3 training dataset reduction as complete and qualified datasets are used for modeling and the number of data that considered as train data for modeling is high in such cases most modeling and time series prediction methods reach acceptable results but in real conditions such data are not always available and in many cases the number of train data is far less than the amount used in this article for modeling 90 of the data is considered as training data and the remaining 10 of the data is considered as test data so that for missouri pee dee red white willamette and connecticut rivers the train datasets samples numbers were 4101 4700 4116 4618 4118 and 4110 respectively and the test datasets samples numbers were 456 552 457 513 458 and 457 respectively it is clear that the number of train data is much more than the amount of test data which also increase the accuracy of the models to investigate the ability of the models studied in the absence of such long time series for train data this paper evaluates the strength of the models under study in the lack of train data conditions hence the reduction in train data is proceeded as a step to step as stated at first the percentage of train data is 90 so at each stage reduce one percent of the number of train data in each step and add one percent to test data the process of lowering train data is continued for 89 steps so in the last step the number of train data will be 1 and the number of test data will reach 99 for the considered case studies of missouri pee dee red white willamette and connecticut rivers at the last step of the train reduction the number of training datasets samples become 46 52 46 51 46 and 46 respectively and the number of the test datasets samples are 4511 5170 4527 5080 4530 and 4521 it is complicated to predict more than 4500 data as test data using only about 50 data as train data therefore the accuracy of the models decreases with incremental steps the modeling procedure of training dataset reduction is shown in fig 8 according to fig 8 sn starts from 1 and continues to 90 in each sn the model is executed ten times and its average error is stored in the arne variable this process was performed for all three mc o mc and eo mc models and all case studies the results are presented in fig 9 as shown in fig 9 in all cases after reducing a certain amount of train data the accuracy of the mc models has increased significantly this sudden increase in the error value of mc models in most rivers occurred in the range of sn 30 to 45 meaning that the percentage of train data reached 45 60 of the total data however for the connecticut river this sudden increase in sn error was approximately 20 where the train data was approximately 70 of the total data comparing the results of the o mc and eo mc models versus the results of the mc model represents a significant improvement this improvement in model resistance versus reduction in the number of train data in mc extension models results from the online update of models during the prediction and therefore this is the most significant advantage of these models compared to the simple mc by examining the results of the o mc models it is observed that firstly the modeling error value is much lower than the simple mc models secondly the sudden increase in the amount of model error caused by the decrease in the percentage of train data occurred in these models in the sn between 80 and 90 where the percentage of train data was between 1 and 10 indicating that these models are much more resistant to mc models the uncertainty of the o mc and eo mc models was similar and in some cases the eo mc model provides relatively better results however the main advantage of the eo mc model compared to the o mc model in this section is evident the eo mc model due to its robust update structure drives the modeling forward so that after passing through every day it uses the information of that day and other days to update the mm and correct the final step number as shown in fig 9 the eo mc model is capable of performing the modeling even with 1 of the total data in the train data without leaking the error value seen in the mc and o mc models this excellent performance of the eo mc model compared to the o mc is due to the update of the mm in any sn value hence when for example we are on the last step and only 1 of the data is used for train data at first mm is formed with only about 45 samples in the training dataset and the first test data is predicted however the different point of this model is that when we passed through the day we predicted the model automatically uses those data in making a better and more complete mm this trend continues until the last sample predicted in the test data and by increasing the number of days passed the model gradually performs better 3 4 considering the ivi problem of mc based methods in comparison with other regression methods in the previous parts of the results section the performance of mc o mc and eo mc was compared together after that the reliably and robustness of the models were studied next the performance of the models in a situation that there are not enough train dataset samples was compared together in this part one of the most important regression based model defect is considered predicting the future of a phenomenon using its past information is very important in many fields of science this procedure is very economical as well by using the historical information of a phenomenon to predict its future we do not need to measure and use the other surrounding information however predicting the future using the historical information by using the regression methods usually leads to the ivi problem which was discussed in the previous sections in order to examine the ivi problem the lr method and three well known ai methods of mlp elm and rbf are considered and compared with the o mc and eo mc methods which were considered in this study as mentioned the o mc and eo mc models use the previous day as the input variable in order to predict the amount of the considered problem for the present day so that in order to have a fair comparison in the mlp elm rbf and lr models the same input combination is selected for the modeling procedure unfortunately most of the indices that were used in the previous studies in order to examine the performance of the regression based prediction models can be categorized as the ve and none of them considered the he problem in addition the objective function used in the training procedure of the regression based methods is in the ve category so that by running the regression models in each iteration or step of the modeling the model checks its results with the observations using one of the ve indices such as mse therefore for them the best model is a model with the lowest mse as possible however when we use the last day information in a time series in order to predict the information for the present day in most of the cases the best answer for today is the last day information and the considered regression model reaches its lowest mse by transferring its input variable which is the last day s information to the output variable which is supposed to be the present day information without any manipulations in these cases the ve indices are significantly low that is why many researchers know the regression based methods as powerful future predictors however the results are not applicable and are meaningless here the mse index is considered as a proxy of the ve indices and the ivi index which is introduced in box 1 is considered as a he index the results of modeling for all case studies using the mlp elm rbf lr o mc and eo mc are presented in table 4 and fig 10 for the missouri case study the lr model reaches the lowest amount of the mse index compared with the other methods however it could be seen that the ivi of this model is 1 this means that the predicted samples peaks have not occurred at the same time as the observation samples at all and this model s results are unreliable in fact this model is presenting the past day information as the output when it is supposed to predict the next day the results of the mlp elm and rbf models are similar to the lr model in all of them the mse is very low and the ivi is almost 1 however the results of the o mc and the eo mc are completely different it could be seen that for the present case study the mse index of the o mc and eo mc are about five and three times higher respectively compared with the lr model at first glance the lr method has better performance in predicting the future satellite information of the missouri river however by considering the ivi indices of the o mc and eo mc models it is clear that these models have a far lower input imitation compare with the other methods in each modeling procedure a balance should be made between its mse precision and its ivi and neither of them should be considered separately in addition in most cases by decreasing the mse amount the ivi amount increases and vice versa in the present case study the mlp elm rbf and lr have a very low mse however they also have a very high amount of ivi as well for the missouri river as an example at the eo mc model the mse increases a little and the ivi decreases to have a balance between them for the pee dee river for another time by considering the mse index the lr performance is better to compare with all of the other methods however similar to the missouri river the ivi amounts of mlp elm and rbf methods are almost one here for another time the performance of the o mc and eo mc are considerably better compared with the other methods according to table 4 except for the red and white rivers for all of the case studies the lr model mse index performs the best results this is an unexpected result in the real world despite the lr model which used the linear equations the mlp elm and rbf models use nonlinear equations and are much more complex compared with the lr model actually these results do not show that the lr model is more accurate compared with the other ones here all of the lr mlp elm and rbf models simply imitate their input variables and none of them actually address the actual time series prediction problem this explains why there is no difference in the results of the nonlinear powerful regression methods and simple linear ones and why the mse and the ivi indices of all of the mlp elm rbf and lr models are very similar to each other according to fig 4 when a model imitates its input variables instead of actually predicting the future the predicted values are completely similar to the observations but occur one step ahead of them here in fig 10 only fifty samples of the dataset are plotted in order to see this defect completely form this figure it is obvious that all of the lr mlp elm and rbf models have the input imitation problem their modeled samples are completely similar to the observation ones and they only occur one day ahead of the observation samples which is the difference between the input variable time and the output variable time despite the lr mlp elm and rbf models the o mc and eo mc have difficulty with the complex problem of predicting the future using past information instead of simply copying the input variables as shown in fig 10 4 conclusions forecasting river water levels and discharge are one of the most important fields in hydraulic engineering one of the popular methods is to use historical time series of river discharges to predict the future values however in many countries river monitoring is done at a very limited number of gauge stations due to budget constraints to address this in this study remotely sensed satellite signals are used instead of the in situ discharge monitoring to develop an accessible method to forecast river flows the prediction was made using the mc model in addition the results of the mc model are improved by introducing two additional extensions of the model the first extension is referred to as the o mc which benefits from online updating of the optimum state number during the training procedure and the second extension is referred to as the eo mc which benefits from updating the online state number as well as updating the markov matrix mm updating the flood discharge predictions were completed for six case study rivers including connecticut missouri pee dee red white and willamette rivers and the results were evaluated in four different phases as follows 1 in the first phase the considered case studies satellite signals were calculated using the mc o mc and eo mc models and we concluded that the o mc and eo mc models outperformed the standard mc model in addition we showed that despite having better performance of eo mc compare with the o mc in most of the considered cases the performance of both methods was almost indistinguishable 2 in the second phase the uncertainty analysis was completed on each of the mc o mc and eo mc methods using 1000 simulations for each case study to calculate the 95ppu and d factor indices we concluded that the mc model with large d factor for the considered rivers is not reliable to be used in practical situations with complex time series in addition similar to the last phase the performance of both o mc and eo mc models were close to each other and both of them were far better compared with the simple mc model considering the fact that the difference between the eo mc and o mc is updating the mm matrix during the training procedure it was also concluded that the most important mc improvement in order to increase the uncertainty analysis performance is online updating the state s number which is done in both o mc and eo mc models 3 in the third phase the training dataset percentage was gradually reduced from 90 down to 1 in 1 increments in each train dataset reduction step the considered models were run again and the results were evaluated in this phase the performance of the mc model was decreased significantly after about a 30 reduction in train dataset for most of the case studies however the performance of o mc models only begins to decrease remarkably after about 80 reduction in the training dataset despite the mc and o mc models because of updating the mm matrix during the training the performance of eo mc remained constant for all of the steps we concluded that the advantage of eo mc compares with o mc is where the considered case studies are suffering from lack of training samples 4 many powerful regression methods could be considered instead of mc based models however to highlight the advantage of mc based models we compared the performance of o mc and eo mc models with four regression based models of mlp elm rbf and lr here it was shown that in cases that the goal is to predict the short term time series using its own historical information most of the regression based methods trapped in delivering the model s input variables as the considered output variable instead of really struggling with the time series prediction complexities in order to measure this defect a new statistical index namely ivi was introduced it was shown that for all of the considered regression based models the ivi index was almost one which indicates that those models present the last day amount as the output this index should be considered in all of the time series prediction models in the considered regression based models despite reaching very high accuracy related to extremely low mse amounts of them because of that high amount of ivi the results of them were worthless for the o mc and eo mc however despite having higher amounts of mse index the ivi index amounts were remarkably lower compared with the regression based methods therefore the obtained results could be considered in real word future predictions declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper the authors declare the following financial interests personal relationships which may be considered as potential competing interests 
