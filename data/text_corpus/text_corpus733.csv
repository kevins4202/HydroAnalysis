index,text
3665,in this study the applicability of machine learning models was investigated for real time flood forecasting of a small river basin with a short time of concentration and the modes were compared with the storage function model sfm a rainfall runoff model bokha stream basin located in the namhan river korea was selected as the study area flood water level forecasting was performed for heungcheon bridge station which is located in the downstream of bokha stream using hydrological data observed at bokha bridge station located in the upstream of the stream for each of the upstream and downstream basins rainfall water level and discharge data from 2005 to 2020 were collected at two stations and especially the collected rainfall data were classified into 53 rainfall events using interevent time definition ietd analysis of rainfall data in addition flood water level forecasting at downstream point was performed using machine learning models such as gb gradient boosting svm support vector model and lstm long short term memory also the sfm which is a rainfall runoff model was used for the forecasting for the application of machine learning models 33 rainfall events were used for learning and 23 rainfall events were used for evaluation with the sfm the flood discharge was forecasted first and then the flood water level was forecasted through the rating curve the flood water level forecasted by each model was compared with the observed flood water level and predictive power for each model was evaluated by calculating nrmse normalized root mean squared error the nrmses for the models were ranged from 0 18 to 0 27 and the predictive power was good in the order of the lstm model at 0 18 followed by the sfm at 0 21 therefore the lstm model showed the best predictive power and was selected as the optimal model for real time flood water level forecasting in this study however the sfm is currently employed in korea for flood forecasting and warning and the model well incorporates the basin characteristics showing relatively good predictive power based on the models presented in this study an optimal model suitable for real time flood water level forecasting can be selected for flood forecasting and warning points of a small river basin and it is expected that the forecasting results can be used as base data for decision making keywords flood water level forecasting storage function model gradient boosting gb support vector model svm long short term memory lstm 1 introduction there has been a global trend of increasing intensity of localized heavy rainfall due to climate change this leads to increased possibility of casualties and property damage from flood and in south korea with its geographical and climate characteristics the country is subject to the damage from annual events of monsoon and typhoon and most of the damages occur in small river basins where flood forecasting and warning systems have not been established the damage caused by flood in south korea over the last 10 years has been estimated to reach about 120 million usd annually mois 2019 for minimization of damage caused by continuous flood establishment of structural measures e g dam and levee and non structural measures flood forecasting and warning system and disaster information map is imperative structural measures involving the construction of large scale structures have practical difficulties because the environmental aspects and local residents must be considered in addition as natural disasters escalate in their scale and intensity due to climate change and rapid urbanization the design frequency of structural measures needs to be increased but this would involve several limitations such as economic feasibility chang and lee 2015 lee et al 2016 kim and han 2016 choi et al 2018 kim et al 2019 from international perspective due to the above limitations of structural measures flood forecasting and warning system has been in operation as non structural measures to reduce flood damage and alerts and warnings are issued through real time flood forecasting in the united states the operation of forecasting system in the hydrology sector by the national weather service nws of national oceanic and atmospheric administration noaa consists of 13 river forecast centers rfc and 122 weather forecast offices wfos the observation and forecast data of rfc such as the current and forecasted water level at the forecast points are provided through interactive tools in japan flood forecasting and warning system is handled by the ministry of land infrastructure transport and tourism and local governments and for events such as the water level elevation in rivers and inundation sections are divided and set for 109 rivers designated in advance and flood forecasting of rivers is conducted with information such as water level or discharge the flood control office fco in south korea uses the storage function model sfm which is one of the hydrological models for flood control management and flood forecasting and warning system has been constructed and in operation at 65 major flood forecasting and warning points kim et al 2008 lee et al 2018a lee et al 2019b however in applying the rainfall runoff model to the actual flood runoff phenomenon the most challenging aspect is to determine the parameters in addition no objective and reasonable method for determining parameters has been proposed to date and in determining the parameters of the model empirical formulas are used or parameters are adjusted relying on the judgment of hydrology engineers therefore much experience and accumulated know how are important for accurate determination on issuing flood forecasting song et al 2006 liu et al 2014 liu et al 2016 azama et al 2017 in addition for the calculation of the flood discharge accurate observation of rainfall and forecasting of rainfall are instrumental and for forecasting of water level of a river from the flood discharge calculated from the rainfall the water level data observed at major points and rating curve flood stage are necessary in order to collect these basic data rainfall monitoring stations and water level stations need to be installed and operated at each point but installation at all points has practical limitations in addition since the discharge data observed at water level stations tend to have different discharge values for the same water level due to various improvement work for each river over several years there are limitations in forecasting flood discharge by testing and adjusting the models based on the past discharge data tayfur et al 2018 bae et al 2019 kim et al 2020 there have been a number of domestic and international studies that have investigated on the development of equations for estimating parameters suitable for basin characteristics in order to enhance the applicability of the sfm however these previous studies have not used runoff data meeting various basin conditions which is the most basic data but most of these studies performed flood discharge forecasting by estimating parameters for past timepoints utilizing numerous indicators such as basin area slope and land use assem et al 2017 park et al 2018 kratzert et al 2018 mok et al 2020 van et al 2020 recently active research has been conducted on model development in which a model is trained and performs forecasting based on data common types of machine learning based models include artificial neural networks anns and svms models such as gb recurrent neural network rnn and lstm have been the latest development of machine learning models these models show fewer parameter adjustments and higher forecasting performance than physics based models and have been demonstrated to be an effective alternative to physics based models tayfur and singh 2006 behzad et al 2009 ghumman et al 2011 mosavi et al 2018 han et al 2019 in addition there have been a number of studies addressing the problems of the physics based rainfall runoff model sfm developing the flood forecasting model suitable for the basin characteristics and estimating the optimal parameters of each model however most of the study areas for these prior studies are located in the main stream and the flood forecasting and warning systems were also developed for flooding in the large river basin therefore flood forecasting and warning systems in upstream points and small river basin have not yet been established due to various problems such as lack of hydrological data and limitations of models therefore for the development of flood forecasting and warning system for steep mountain rivers or small rivers with a short time of concentration the rainfall runoff model currently in operation by the fco in korea and machine learning models were comparatively analyzed to propose a model for real time flood water level forecasting tables 1 3 2 methodology and material 2 1 storage function model the storage function model sfm is a model for flood runoff analysis developed by kimura in japan in 1961 the model has been developed primarily in consideration of basins in mountainous areas in addition the flood runoff in nature can be analyzed in consideration of the characteristics of the unsteady flow that changes very slowly and the nonlinearity which is the characteristic of the flood runoff can be sufficiently considered with the model as shown in fig 1 the storage function model classifies basin into three categories according to the runoff characteristics runoff area infiltration area and percolation area each area was conceptually hypothesized as follows runoff area an impervious area where rainfall contributes to runoff from the initial stage infiltration area where rainfall contributes to runoff after infiltrating the ground surface and satisfying the saturation rainfall in a certain amount of soil and percolation area where rainfall does not directly contribute to runoff but is immediately discharged to the ground surface sung et al 2008 in addition the following assumptions were made to apply the storage function model to basin the channel section i o of the basin is inclined from the upstream direction to the downstream direction and rainfall r a v e occurs uniformly across the basin and the runoff for excess rainfall in the small river basin flows into the river and stored according to the channel shape and discharged through the outlet of the basin sung et al 2008 here r a v e represents average rainfall over the basin a is the area of the study area k m 2 a r is area of runoff area k m 2 a i is area of infiltration area k m 2 and a p indicates area of percolation area k m 2 f s a is the area ratio contributing to the runoff of the study area a r a i a f 1 runoff area ratio against the study area a r a f s a f 1 is the infiltration area ratio against the study area a i a 1 f s a percolation area ratio against the study area a p a r s a indicates saturation rainfall h for the surface infiltration area l is the channel length s l is the channel storage q i is the channel inflow and q l indicates the runoff volume of the channel in the storage function model it is assumed that the flood runoff is a surface runoff that can be expressed by the manning formula and the storage of the basin and the channel section is expressed as an exponential function of the runoff as shown in eq 1 1 s l k q l p eq 1 is the equation of motion for the flood wave and k p indicates the storage coefficient for basin or channel section here the continuity equation for one basin is expressed as eq 2 which is a water budget equation 2 1 3 6 f r a v e a q l d s l d t where f indicates the inflow coefficient r a v e is the hourly basin average rainfall mm hr a is the basin area k m 2 q l t q t t l is the direct runoff volume m 3 s from the basin in consideration of the basin lag time t l and s l indicates the basin storage m 3 in order to calculate the basin runoff rearranging the continuity equation and equation of motion for the basin for the unit inflow r a v e unit runoff height q l and unit storage height s l gives eqs 3 and 4 3 r a v e q l d s l d t 4 s l k q l p it is assumed that in the initial stage of rainfall rainfall runoff does not occur due to infiltration across the entire basin and as rainfall increases runoff begins to occur in some areas and then eventually occurs across the entire basin therefore the runoff volume from basin considering the baseline discharge can be expressed as in eq 5 5 q a 3 6 f 1 q l 1 f 1 q s a l q i where f 1 indicates first runoff rate q l unit runoff height mm hr by total rainfall q s a l is unit runoff height mm hr by rainfall after the saturation point and q i is baseline discharge m 3 s the continuity equation for one channel section is expressed as eq 6 6 j 1 n f j i j q l d s l d t where f i indicates the average inflow coefficient i j is the inflow from basin and tributary basin to the channel m 3 s q l is runoff volume m 3 discharged from the downstream end of the channel section considering the lag time t l with q l t q t t l and s l indicates the actual storage m 3 stored in the channel section from the above the storage coefficient k and p can be easily obtained from the past flood runoff data and if the relationship between s l and q l can be obtained then s l of eq 3 eq 4 and eq 6 can be expressed in terms of q l it is possible to calculate the flood runoff if the basin average rainfall r a v e in basin runoff and channel inflow i l in channel runoff are given 2 2 support vector machine support vector machine svm was proposed by vapnik 1995 and since the introduction it has been reported as a method that can be applied to various types of data with very accurate classification results in various problems such as document classification and customer classification choi et al 2013 svm is a method of finding a hyperplane defined by support vectors that can linearly classify vectors of different classes with the maximum margin for the distance between the classes lee et al 2016 data that cannot be classified linearly are mapped from the plane to a high dimensional space using a kernel function and then classified representative types of kernel functions include polynomial sigmoid and radial basis functions park et al 2006 svm is mainly used for forecasting of classification problems and a method that has extended svm by introducing an ε insensitive loss function so that it can be used for regression analysis is called support vector regression svr kim et al 2012 that is svm is used to classify data into 1 class and 1 class in a classification problem but svr has further generalized svm for forecasting of arbitrary real values therefore real time flood forecasting was performed using svr and rbf which has been reported to have superior performance as a kernel function was applied tay and cao 2001 in this study a real time flood forecasting model using svm was developed fig 2 shows the conceptual diagram of svm fig 3 2 3 gradient boosting in machine learning boosting refers to a method of creating strong learners with accurate performance by combining relatively inaccurate weak learners heo et al 2018 even if the accuracy is low the first tree model is constructed and the forecasting error is corrected in the second tree model in this way the weaknesses are continuously improved in the next tree model finally constructing strong learners hastie et al 2009 piryonesi and el diraby 2020 madeh piryonesi and el diraby 2021 the loss function quantifies the error of the forecasting model and to find the parameters in the model that minimize the loss function value machine learning models usually employ a gradient descent method gradient boosting gb performs the process of minimizing the parameter loss function in the model function space and derivatives of the loss function are taken with respect to a function of the tree model that has been trained so far as shown in the following eq 7 not with respect to parameters of the model 7 f i 1 f i p δ j δ f i that is in the gb model the derivative value of the tree model function serves to represent the weakness of the model that performed learning so far and when the tree model is constructed the derivative values are used to improve the weaknesses thereby boosting the performance 2 4 long short term memory long short term memory lstm model introduced by hochreiter and schmidhuber 1997 is a type of recurrent neural network rnn that directly learns from time series data le et al 2019 the general rnn has the disadvantage of updating only the learning results of the hidden layer for the entire time on the other hand although lstm is a kind of rnn it has added a cell state structure to the hidden layer and store information about the input data for a longer period of time thereby resolving the limitations of the rnn adeyemi et al 2018 the lstm model consists of a number of blocks each block includes cells representing the state over time and three non linear gates that regulate the flow of data the forget gate input gate and output gate han et al 2021 the forget gate f t performs calculation on which information to discard and applies the h t 1 of the previous step and x t of the current step to the sigmoid function to obtain a value between 0 and 1 this is multiplied by the current state and in the process forget gate decides whether to use or discard the information 8 f t σ w f h t 1 x t b f next a sigmoid function called input gate i t decides which data to update through the hyperbolic tangent function c t vectors the new candidate values are created these are combined with the i t values and added to the cell state 9 i t σ w i h t 1 x t b i 10 c t t a n h w c h t 1 x t b c using the results of eq 8 eq 9 and eq 10 a new cell state c t 1 is created by updating the previous state c t eq 11 can be used to update the information state of the current step 11 c t f t c t 1 i t c t the final result is derived through the output gate o t and this can be regarded as a step to determine which part of the cell state to derive to this end eq 12 is used and the current cell state is updated using eq 13 12 o t σ w o h t 1 x t b o 13 h t o t t a n h c t 2 5 principal component analysis principal component analysis pca uses the covariance matrix or correlation matrix of multivariate data to find a new principal component pc that is expressed as a linear combination of the original variables and aims to describe the movement of the entire variables with a small number of principal components thereby reducing dimensionality hotelling 1933 when the covariance matrix for the set of independent variables x x 1 x 2 x m is σ the diagonal element of σ is the variance of each independent variable σ 1 2 σ 2 2 σ m 2 here when σ 1 2 σ 2 2 σ m 2 are multiplied by λ 1 λ 2 λ m σ 0 in this case λ 1 λ 2 λ m in descending order indicate the eigenvalues as for the eigenvectors the solution corresponding to each eigen value is e 1 e 2 e m when the set of eigenvectors is e e 1 e 2 e m principal components satisfy y e x the m variables derived in this way are referred to as principal components and the principal components are independent of each other wold et al 1987 there are multiple ways to determine the number of principal components m values with eigenvalues of 1 or larger are selected as described above or values with a cumulative variance of 90 or larger are selected in fig 4 the cumulative variance is 90 or larger for the three principal component and in terms of eigenvalues the eigenvalue is one or larger for the three principal component in this study the number of principal components m was determined in the same way since there is high correlation between various dynamic variables in this study there would be a problem of multicollinearity and thus only a small number of principal components derived through pca were used as independent variables 2 6 k fold cross validation k fold cross validation randomly divides a data set into the same size and uses one of them for the validation data set then the remaining k 1 data are used for the training data set and this process is sequentially repeated k times perform validation on the given entire data set stone 1974 stone 1977 the advantage of k fold cross validation is that all cases are used for training and validation and each case is used only once for validation thus preventing overfitting kim 2013 in addition k fold cross validation has the advantage that all data can be used for learning and evaluation when the number of data is insufficient fig 5 shows the conceptual diagram of k fold cross validation in this study k fold cross validation was considered in order to use all data for learning and evaluation 3 applications of machine learning and sfm for real time flood forecasting 3 1 study area in this study the following four aspects were considered when selecting a study area 1 in terms of geomorphological aspect small to medium sized rivers were considered for upstream basin 2 in terms of flood damage basin with flood damage of small to medium scale was considered 3 for acquisition of hydrological data the area where sufficient volume of data on water level discharge and rainfall during the past rainfall event can be collected was considered 4 the study area has more than two water level stations in the basin and the upstream monitoring station was used as a secondary station and the downstream station was the main monitoring station for forecasting of flood discharge in consideration of the above four aspects finally bokha stream basin of namhan river upstream was selected as the study area examining the average scale of flood damage in the bokha stream it was estimated that there were 27 deaths an inundated area of 233 ha and 2 5 million usd in damage to public facilities resulting in an annual damage amount of 5 5 million usd in 2000 the total damage amount was 13 3 million usd in 2001 the total damage amount reached 28 5 million usd and in 2002 the total damage amount was 7 4 million usd indicating that the flood damage of bokha stream basin was most extensive between 2000 and 2002 in addition the main flood events that caused devastating damage in the bokha stream basin in the past include flood events in 1925 1936 1995 and 2002 and flood by continuous heavy rainfall occurred in 1965 1972 1984 and 1990 the latest flood records include the rainfall events in 2002 2006 and 2009 therefore in this study we aim to forecast the water level at heungcheon bridge station of yeoju city a point in fig 6 in downstream using the water level and rainfall data at bokha bridge station of icheon city b point in fig 6 in upstream of bokha stream basin the fig 6 below is a schematic of the study area which is bokha stream basin 3 2 selection of rainfall events used this study aims to perform real time flood forecasting using only event specific data by classifying rainfall events during the flood season and not performing forecast using all the data of meteorological stations and water level stations when examining long term data of continuous hourly rainfall there are interevent records indicating that there are continuous or discontinuous rainfall records in order to separate each individual rainfall event from these continuous or discontinuous rainfall records a criterion needs to be set that can distinguish the start and end of each rainfall event choi et al 2010 interevent time definition ietd can be defined as a minimum interevent time separating each rainfall event from long term rainfall data that is if the interevent time between rainfall records is shorter than the ietd the two rainfall records before and after the interevent time are considered as one rainfall event and if the interevent time between rainfall records is longer than the ietd the two rainfall records before and after the interevent time are considered as two respective rainfall events kwon et al 2004 autocorrelation analysis determines ietd through correlation between rainfall events the lag time at which rainfall correlation becomes 0 is defined as ietd as a method of calculating ietd to separate long term continuous rainfall into each independent rainfall event a correlation between rainfall events is assumed in the rainfall time series autocorrelation refers to the correlation between rainfall events in the rainfall time series and the time interval between each observation time is referred to as lag time lee et al 2004 the correlation coefficient r k is expressed as eq 14 below 14 r k y t y y t k y y t y 2 where y is the sample mean of the data series and k indicates the lag time autocorrelation analysis was used to consider lag time and the range was determined as a section within the 95 confidence interval the conceptual diagram for ietd is shown in fig 7 below and the lag time corresponding to the confidence interval for each small river basin is seven hours as shown in fig 8 in this study in order to select rainfall events from the observation start date of yeoju city heungcheon bridge station to the recent date of august 31 2020 june july august and september cases when the runoff volume was 100 m 3 s or larger were checked and considering the interevent time a total of 53 rainfall events were finally selected 3 3 flood water level as dependent variable the rating curve is a curve showing the relationship between the river water level and discharge by measuring the water level and discharge at specific observation points and using a regression equation from the past to present the river cross sections has undergone changes and the flow velocity also has changed and thus rating curve has been changed by various conditions therefore there are various rating curves for the water level and runoff data of yeoju city heungcheon bridge station and icheon city bokha bridge station as for the water level and runoff data provided by the flood control office the data are recorded based on the rating curve applied in the past and this led to multiple problems one of the representative problems is that there are various values of runoff for the reference water level that is since there are multiple discharge data for a single water level confusion may arise as to which data is the discharge value that can serve as the true value in this study the rating curve used for each rainfall event was used to calculate the flood discharge for the water level 3 4 independent variables for machine learning models for development of a real time flood water level forecasting model water level and discharge data at bokha bridge station were collected from january 1 2007 to august 31 2020 data measured at rainfall stations and water level stations of bokha stream basin were used as independent variables for real time flood water level forecasting the list of independent variables comprises as follows areal average rainfall for each small river basin rainfall of previous five days for small river basin cn for each small river basin water level data up to the lead time at bokha bridge station at 40 min 50 min 60 min 70 min 80 min 90 min and 100 min the sum of the time of concentration of all basins and channels from the upstream basin of the bokha stream to the end of the heungcheon bridge station is calculated at about 1 2 h 72 min in particular the lag time of the channel section between the bokha bridge station and the heungcheon bridge station is calculated at about 0 61 40 min in addition when examining the difference between the peak water level timepoint of bokha bridge station and the peak water level timepoint of heungcheon bridge station it can be seen that although there is a difference according to the rainfall pattern the difference is in the range between 40 min and 100 min on average in general small to medium rivers require a lead time for flood evacuation of at least 30 min that is in order to derive the forecasted water level value for 30 min in heungcheon bridge station in this study the water levels in 10 minute intervals from 40 min to 100 min for icheon city bokha bridge station lead time were selected as independent variables there are seven water level data from 40 min to 100 min of lead time and the number of variables is large and the similarity between each variable is high so it is highly likely that a multicollinearity problem will occur therefore in this study pca was performed and principal components with cumulative variance of 90 were extracted and these were used as independent variables for learning finally in this study a total of 16 independent variables were used to construct an ai model the list of independent variables comprises as follows three of areal average rainfall for each small river basin three of rainfall of previous three days fir small river basin three of cn for each small river basin seven of water level data considering the lead time of icheon city bokha bridge station 3 5 parameters of storage function model flood forecasting in south korea adopts the rainfall runoff method as an event model for floods over a certain period of time and the models that have been developed and operated by each of flood control offices of the four major national rivers have been standardized and reconstructed as an integrated flood forecasting and warning system the calculation procedure of this model consists of the following processes 1 construction of the effective rainfall calculation model 2 the basin runoff calculation and 3 the calculation of the channel runoff and converting the water level of the river from the rating curve the storage function model is somewhat complex in terms of applying the model constants and hydrological expertise is required when running the model such as high quality hydrological data or precise basin geomorphological data to determine the model constant currently for flood control offices in south korea various models are applied to the basin runoff but for the channel runoff the storage function model is used as the basic model in addition default values are used without parameter adjustment for storage coefficients used in channel runoff calculation however for forecasting of the flood discharge runoff constant f1 fsa rsa and storage coefficient k p ti need to be adjusted therefore in this study bokha stream basin the study area was divided into upstream a midstream b and downstream c and for initial runoff rate saturation runoff rate and saturation rainfall for each flood event fixed values were used and storage coefficient k storage coefficient p and lag time t l were calculated for each rainfall event the hydrological flood prediction model using the rainfall runoff model is sensitive to temporal and spatial changes in rainfall there is a limit to calculating the runoff due to regional torrential rain in the upstream areas where the flood arrival time is short and the very narrow areas of small rivers in addition since there is currently no objective and reasonable method for determining parameters empirical expressions are used to determine the parameters and correction is dependent on the judgment of hydrologists as the flood discharge was calculated based on the judgement of the hydrologist there was a problem that subjective factors were dominated rather than objective factors the rainfall runoff model is highly dependent on hydrologists and when adjusting the parameters of each model it is set based on flood events at past times the problem with this is that parameters must be readjusted when flood events are different from the flood that occurred in the past and this process takes a considerable amount of time in this system long experience and know how are very important factors for accurate judgement on whether to issue flood forecasts in the absence of hydrologists problems with the implementation and issuance of flood forecasting and warning models may arise so it is judged that research should be conducted to supplement these problems 3 6 development of machine learning model for real time flood forecasting in this study the problems of the current flood forecasting and warning system described above were addressed and a model for real time flood forecasting was developed in consideration of these problems examining the flood forecasting procedure and the standards for issuing and lifting of flood warnings these are focused on the water level rather than on the flood discharge we aim to develop a model that can predict the water level that meets the flood forecasting procedure the criteria for issuing and lifting the flood warning for real time flood water level forecasting a storage function model and three types of machine learning models were used fig 9 shows the flow chart of development of model for real time flood forecasting the calculation process to predict the water level value of heungcheon bridge station which is the purpose of the study is as follows 1 for development of machine learning models for real time flood forecasting for dependent variables water level data at yeoju city heungcheon bridge station were collected from january 1 2007 to august 31 2020 in 10 minute intervals instead of using all the collected data only data for 53 rainfall events were used and the total number of data was 12 683 independent variables used in the study were areal average rainfall for each small river basin the preceding five day rainfall for each small river basin the runoff curve index for each small river basin and the water level from the water level station of icheon city bokha bridge station 2 for development of a model using dependent variables and independent variables data were divided into learning section and evaluation section the learning section used data from 2007 to 2015 and the number of data is 8 397 the evaluation section used data from 2016 to 2020 and the number of data was 4 286 3 a total of 16 independent variables were used to develop the water level forecasting model of which data of bokha bridge station water level prior to 40 min 50 min 60 min 70 min 80 min 90 min and 100 min are highly correlated with each other which may lead to the problem of multicollinearity therefore in order to tackle the problem of multicollinearity the dimensionality of variables with high correlation was reduced by pca 4 for analysis of the results according to the correlation between independent variables the models were divided into two types the first is a model using all independent variables and the second is a model using reduced independent variables derived through pca for data for each small river basin and previous water levels 5 in order to derive the optimal parameter values for each model the pca used the stepwise method and the svm model randomly selected the parameters sigma and cost to derive the optimal value the predictive power was evaluated using both polynomial and sigmoid but only the results for rbf were presented because the performance was inferior to rbf for gb model the optimal values were derived by randomly selecting the parameters of the model which are shrinkage interaction depth n minobsinnode and n trees finally for the lstm model optimal values were derived by adjusting activation epoch optimizer learning rate and loss 6 in order to construct a model using the optimal parameter values derived for each model the k fold cross validation method was used for training and verification of all data in the learning section 7 finally the predictive power of the rainfall runoff model and the machine learning models was evaluated and the model with the best predictive power evaluation result was presented as model for real time flood forecasting we aimed to develop a model optimized for real time flood forecasting for basins with a short time of concentration and present the applicability of the developed model the hardware information used to run the e1071 gbm keras and tensorflow packages and software in r studio is as follows cpu amd ryzen 7 3700x gpu nvidia geforce gtx 1660 for reference r studio packages are open access data 3 7 evaluation of predictive power for a proper model selection 3 7 1 evaluation of predictive power for storage function model the basis for determining how close the forecast values calculated by the flood forecasting model are to the measured values is called goodness of fit the coefficient of efficiency has been widely adopted in a number of data mining and model evaluation and this coefficient is closely related to the coefficient of determination it is desirable if there is a unique indicator or object function for goodness of fit evaluation but this is not possible in practice actually the object function varies depending on the forecasting model to be evaluated the flood forecasting model focuses on the peak flow and the long term runoff forecasting model focuses on the drought flow therefore in this study the storage function model before the adjustment of parameters and the storage function model with adjusted parameters were comparatively analyzed in addition predictive power was evaluated for the evaluation sections of three models in which the dimensionality of the independent variables was reduced using pca as a predictive power evaluation method coefficient of determination and the nrmse were used in order to determine the correlation and errors for water level station data for each event and the predicted results and for evaluation of the errors for peak flow q peak and t peak methods were used for comparative analysis of the model results the predictive power evaluation results before adjusting the parameters showed r 2 0 81 nrmse 0 30 q peak 0 70 and t peak 150 the predictive power evaluation results after adjusting the parameters showed r 2 0 91 nrmse 0 21 q peak 0 04 and t peak 28 comparative analysis on the predictive power evaluation results before and after adjusting the parameters confirmed that the flood forecasting performance has improved after the adjustment however these are forecasted values that have been adjusted for the past time points and in this case it is unreasonable to regard these results as the predictive power evaluation for future flood for the rainfall runoff model superior predictive power evaluation result was obtained after adjusting parameters compared to the values before the parameter adjustment and this is thought to be the advantage of the rainfall runoff model that is the rainfall runoff model adjusts parameters for past rainfall events and the model s predictive power is excellent for past rainfall events however in the case of an uncertain rainfall events in the future the parameters need to be readjusted which is recalculated by hydrology research this indicates that the model has limitations in terms of predictive power for future event forecasting 3 7 2 evaluation of predictive power for machine learning model in the rainfall runoff model in order to predict the water level of a river from the flood discharge calculated using rainfall the observed water level data at major points and rating curve are instrumental in addition in order to collect such basic data rainfall monitoring stations and water level stations need to be installed and operated at each point but installation of those stations at all points has practical limitations in addition there is a limit in predicting future flood discharge by testing and adjusting the model based on the past discharge data with the rainfall runoff model therefore in order to overcome these limitations this study aimed to develop a model that predicts the water level of a small river basin using machine learning models the results of evaluating predictive power of three machine learning models for each rainfall event are shown in table 4 below for the evaluation sections only the results of predictive power evaluation for svm in the forecasting evaluation section were r 2 0 70 nrmse 0 27 q peak 0 20 and t peak 57 the results of predictive power evaluation for gb in the forecasting evaluation section were r 2 0 80 nrmse 0 25 q peak 0 19 and t peak 88 and the results of predictive power evaluation for lstm in the forecasting evaluation section were r 2 0 87 nrmse 0 21 q peak 0 01 t peak 10 the result of predictive power evaluation for each rainfall event showed that lstm matches the measured water level values better than svm and gb and has superior predictive power for peak values required for flood forecasting in general for large river basins the standard proposed by the world meteorological organization wmo is a forecast with three hours of lead time in addition in the case of medium sized rivers water level forecasting with one or two hour of lead time is the target and in the case of small rivers or rivers in steep mountain that have short time of concentration as in the case of this study area the target lead time is 30 min to one hour the result of machine learning model developed in this study shows that forecast with 30 minute lead time is possible in addition the developed method has advantages that parameters do not need to be adjusted each time for a new rainfall event and a rating curve is not necessarily required fig 10 shows the water level data measured at the water level station and the water level values forecasted using svm gb and lstm models only eight event sections are shown as examples out of 20 evaluation sections for events 39 40 44 46 50 and 53 the peak value of the water level was one and the lstm model was the best predictor of the trend and peak runoff among the three models in addition it was found that for peak value forecasting in which the water level increases decreases and then increases again the lstm model was the best predictor of the trend and peak runoff among the three models in fig 11 the box plot is schematized to show the distribution of the minimum and maximum predicted values for each model here the box plot is a graph that can confirm the distribution of data through the calculated statistics minimum value first quartile second quartile third quartile maximum value from the data the first quartile represents the bottom of the box the third quartile represents the top of the box the minimum value is expressed as a value obtained by subtracting 1 5 iqr interquatile range from the first quartile and the maximum value is expressed as a value obtained by adding 1 5 iqr from the third quartile in addition values outside the minimum and maximum values are expressed as potential outliers 4 summary and conclusions damage caused by natural disasters continues to pose a threat across the globe this study aimed to develop a model for real time flood forecasting as measures of reducing flood damage which occurs most frequently out of natural disasters in south korea in particular the flood forecasting and warning system currently operated by the ministry of environment s flood control offices of the 4 major rivers is mainly focused on large river basins and rainfall runoff model is the basic model with comparative analysis of the runoff model and the machine learning models we propose a method of model development for real time flood forecasting suitable for a basin with a short time of concentration the findings of this study are outlined as follows 1 for real time flood water level forecasting a bokha stream basin with water level stations at upstream and downstream points is selected as a study area and in order to collect the rainfall data and water level data of the upstream and downstream basins the water level data and runoff data were collected in 10 minute intervals from january 1 2007 to august 31 2020 the rating curve was used to adjust for the missing values of the collected water level and runoff data 2 using the storage function model which is currently employed for flood forecasting and warning in south korea we performed real time forecasting of the flood discharge at downstream points flood discharge was derived using the storage function model for each of the 53 events in total and the obtained values were compared with the runoff data measured at the water level station and the accuracy of the flood discharge estimation for each model was comparatively analyzed in addition in order to compare and select the final model for real time flood forecasting the flood discharge was converted to the water level using the rating curve 3 the water level data and rainfall data of the upstream points of the basin were processed to be used as independent variables and the model was constructed using the water level at the downstream points as the dependent variables the water level data of yeoju city heungcheon bridge station was used as the dependent variables and for independent variables pca was used to resolve the problem of multicollinearity the accuracy of each model was examined by comparing the forecasted results with the water level data observed at the water level station 4 finally predictive power was evaluated for evaluation sections of 7 models in total which are a storage function model with adjusted parameters three models using all independent variables data and three models that reduced the dimensionality of the independent variables using pca as predictive power evaluation methods coefficient of determination rmse nrmse q peak t peak and nse were used and the result of the models were compared as a result of the predictive power evaluation lstm which shows the best predictive power was selected as the final model for real time flood forecasting there are several limitations in this study and the first is the use of validated input data examining the forecasted water level result graph although there is a difference depending on the rainfall event perturbation can be seen in the forecasted value of the ai machine learning models this is a case in which the variability of the input data itself that is the actual water level value in 10 minute intervals causes disturbance it is thought that in the process of learning in the model there were many input data with such disturbance during the rainfall event and this was also reflected in the learning result because the result value of these models cannot be manually changed the quality control of the input data is critical that is superior results can be obtained if learning is performed by correcting these outliers and missing values through validation of the data after collecting hydrological data however since such phenomena may actually occur in the field research on a model that can derive accurate results depending on the processing of the data and environment given is thought to be necessary the second limitation is the inaccuracy of the rating curve there are so many rating curves for bokha bridge station and heungcheon bridge station and although the most recent rating curve is highly likely to be accurate the rating curve used at the time for each rainfall event was used in this study which led to errors if reliable and high quality hydrometeorological data water level runoff and rainfall data for each small river in south korea can be acquired and utilized it will significantly contribute to improving forecasting performance with precise advancement of the model for forecasting of future flood models are developed and operated using the past flood discharge data in south korea however the rainfall runoff model currently employed in the country manages the runoff model through parameter adjustment relaying on the experience of hydrology research every time a new flood event occurs in addition when adjusting the parameters of the rainfall runoff model the flood discharge should be predicted by adjusting within the range of each parameter however there are cases that in order to match the peak water level the value out of the range is artificially introduced for forecasting of flood discharge in this case the problem arises that the parameter values are fixed for past data and they need to be newly adjusted for every new rainfall event this problem occurred in this study in the case of rainfall runoff model and there were cases where the values out of the range were applied for adjustment in order to adjust the parameters to the past events the overall forecasting performance of the rainfall runoff model may appear to be good but when comparing the model with the ai based models after identifying the problems and limitations of the rainfall runoff model we can see that the forecasting performance of the ai models was excellent in addition the rainfall runoff model currently in operation is constructed and run as a forecasting system mainly for large river basin and in this case there are forecasting uncertainties of the model in cases of rainfall events in which the peak water level is observed in the initial stage or basins of steep mountain areas and small rivers and thus the ai models used in this study are thought to serve as good alternatives to the rainfall runoff model recently machine learning models using various ai techniques have been developed and continuous research needs to be conducted on the utilization of customized ai techniques suitable for each basin characteristic using these models therefore if the model for real time flood forecasting proposed in this study can be used it will be of great use and benefit to the accurate and prompt decision making process of non research on flood forecasting and warning moreover if machine learning techniques can be adopted for flood forecasting and warning systems in countries where there is a lack in the pool of hydrology research such as southeast asia and africa it will be highly useful however since all data are based on hydrometeorological data there are various uncertainties therefore it is imperative to acquire reliable data and conduct continuous research to reduce these uncertainties credit authorship contribution statement donghyun kim conceptualization methodology software formal analysis investigation data curation writing original draft writing review editing visualization joonseok lee methodology software validation investigation writing original draft jongsung kim methodology software validation investigation writing original draft myungjin lee methodology software validation investigation writing original draft wonjoon wang methodology software validation investigation writing original draft hung soo kim conceptualization resources writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by a grant 2018 mois31 009 from fundamental technology development program for extreme disaster response funded by korean ministry of interior and safety mois 
3665,in this study the applicability of machine learning models was investigated for real time flood forecasting of a small river basin with a short time of concentration and the modes were compared with the storage function model sfm a rainfall runoff model bokha stream basin located in the namhan river korea was selected as the study area flood water level forecasting was performed for heungcheon bridge station which is located in the downstream of bokha stream using hydrological data observed at bokha bridge station located in the upstream of the stream for each of the upstream and downstream basins rainfall water level and discharge data from 2005 to 2020 were collected at two stations and especially the collected rainfall data were classified into 53 rainfall events using interevent time definition ietd analysis of rainfall data in addition flood water level forecasting at downstream point was performed using machine learning models such as gb gradient boosting svm support vector model and lstm long short term memory also the sfm which is a rainfall runoff model was used for the forecasting for the application of machine learning models 33 rainfall events were used for learning and 23 rainfall events were used for evaluation with the sfm the flood discharge was forecasted first and then the flood water level was forecasted through the rating curve the flood water level forecasted by each model was compared with the observed flood water level and predictive power for each model was evaluated by calculating nrmse normalized root mean squared error the nrmses for the models were ranged from 0 18 to 0 27 and the predictive power was good in the order of the lstm model at 0 18 followed by the sfm at 0 21 therefore the lstm model showed the best predictive power and was selected as the optimal model for real time flood water level forecasting in this study however the sfm is currently employed in korea for flood forecasting and warning and the model well incorporates the basin characteristics showing relatively good predictive power based on the models presented in this study an optimal model suitable for real time flood water level forecasting can be selected for flood forecasting and warning points of a small river basin and it is expected that the forecasting results can be used as base data for decision making keywords flood water level forecasting storage function model gradient boosting gb support vector model svm long short term memory lstm 1 introduction there has been a global trend of increasing intensity of localized heavy rainfall due to climate change this leads to increased possibility of casualties and property damage from flood and in south korea with its geographical and climate characteristics the country is subject to the damage from annual events of monsoon and typhoon and most of the damages occur in small river basins where flood forecasting and warning systems have not been established the damage caused by flood in south korea over the last 10 years has been estimated to reach about 120 million usd annually mois 2019 for minimization of damage caused by continuous flood establishment of structural measures e g dam and levee and non structural measures flood forecasting and warning system and disaster information map is imperative structural measures involving the construction of large scale structures have practical difficulties because the environmental aspects and local residents must be considered in addition as natural disasters escalate in their scale and intensity due to climate change and rapid urbanization the design frequency of structural measures needs to be increased but this would involve several limitations such as economic feasibility chang and lee 2015 lee et al 2016 kim and han 2016 choi et al 2018 kim et al 2019 from international perspective due to the above limitations of structural measures flood forecasting and warning system has been in operation as non structural measures to reduce flood damage and alerts and warnings are issued through real time flood forecasting in the united states the operation of forecasting system in the hydrology sector by the national weather service nws of national oceanic and atmospheric administration noaa consists of 13 river forecast centers rfc and 122 weather forecast offices wfos the observation and forecast data of rfc such as the current and forecasted water level at the forecast points are provided through interactive tools in japan flood forecasting and warning system is handled by the ministry of land infrastructure transport and tourism and local governments and for events such as the water level elevation in rivers and inundation sections are divided and set for 109 rivers designated in advance and flood forecasting of rivers is conducted with information such as water level or discharge the flood control office fco in south korea uses the storage function model sfm which is one of the hydrological models for flood control management and flood forecasting and warning system has been constructed and in operation at 65 major flood forecasting and warning points kim et al 2008 lee et al 2018a lee et al 2019b however in applying the rainfall runoff model to the actual flood runoff phenomenon the most challenging aspect is to determine the parameters in addition no objective and reasonable method for determining parameters has been proposed to date and in determining the parameters of the model empirical formulas are used or parameters are adjusted relying on the judgment of hydrology engineers therefore much experience and accumulated know how are important for accurate determination on issuing flood forecasting song et al 2006 liu et al 2014 liu et al 2016 azama et al 2017 in addition for the calculation of the flood discharge accurate observation of rainfall and forecasting of rainfall are instrumental and for forecasting of water level of a river from the flood discharge calculated from the rainfall the water level data observed at major points and rating curve flood stage are necessary in order to collect these basic data rainfall monitoring stations and water level stations need to be installed and operated at each point but installation at all points has practical limitations in addition since the discharge data observed at water level stations tend to have different discharge values for the same water level due to various improvement work for each river over several years there are limitations in forecasting flood discharge by testing and adjusting the models based on the past discharge data tayfur et al 2018 bae et al 2019 kim et al 2020 there have been a number of domestic and international studies that have investigated on the development of equations for estimating parameters suitable for basin characteristics in order to enhance the applicability of the sfm however these previous studies have not used runoff data meeting various basin conditions which is the most basic data but most of these studies performed flood discharge forecasting by estimating parameters for past timepoints utilizing numerous indicators such as basin area slope and land use assem et al 2017 park et al 2018 kratzert et al 2018 mok et al 2020 van et al 2020 recently active research has been conducted on model development in which a model is trained and performs forecasting based on data common types of machine learning based models include artificial neural networks anns and svms models such as gb recurrent neural network rnn and lstm have been the latest development of machine learning models these models show fewer parameter adjustments and higher forecasting performance than physics based models and have been demonstrated to be an effective alternative to physics based models tayfur and singh 2006 behzad et al 2009 ghumman et al 2011 mosavi et al 2018 han et al 2019 in addition there have been a number of studies addressing the problems of the physics based rainfall runoff model sfm developing the flood forecasting model suitable for the basin characteristics and estimating the optimal parameters of each model however most of the study areas for these prior studies are located in the main stream and the flood forecasting and warning systems were also developed for flooding in the large river basin therefore flood forecasting and warning systems in upstream points and small river basin have not yet been established due to various problems such as lack of hydrological data and limitations of models therefore for the development of flood forecasting and warning system for steep mountain rivers or small rivers with a short time of concentration the rainfall runoff model currently in operation by the fco in korea and machine learning models were comparatively analyzed to propose a model for real time flood water level forecasting tables 1 3 2 methodology and material 2 1 storage function model the storage function model sfm is a model for flood runoff analysis developed by kimura in japan in 1961 the model has been developed primarily in consideration of basins in mountainous areas in addition the flood runoff in nature can be analyzed in consideration of the characteristics of the unsteady flow that changes very slowly and the nonlinearity which is the characteristic of the flood runoff can be sufficiently considered with the model as shown in fig 1 the storage function model classifies basin into three categories according to the runoff characteristics runoff area infiltration area and percolation area each area was conceptually hypothesized as follows runoff area an impervious area where rainfall contributes to runoff from the initial stage infiltration area where rainfall contributes to runoff after infiltrating the ground surface and satisfying the saturation rainfall in a certain amount of soil and percolation area where rainfall does not directly contribute to runoff but is immediately discharged to the ground surface sung et al 2008 in addition the following assumptions were made to apply the storage function model to basin the channel section i o of the basin is inclined from the upstream direction to the downstream direction and rainfall r a v e occurs uniformly across the basin and the runoff for excess rainfall in the small river basin flows into the river and stored according to the channel shape and discharged through the outlet of the basin sung et al 2008 here r a v e represents average rainfall over the basin a is the area of the study area k m 2 a r is area of runoff area k m 2 a i is area of infiltration area k m 2 and a p indicates area of percolation area k m 2 f s a is the area ratio contributing to the runoff of the study area a r a i a f 1 runoff area ratio against the study area a r a f s a f 1 is the infiltration area ratio against the study area a i a 1 f s a percolation area ratio against the study area a p a r s a indicates saturation rainfall h for the surface infiltration area l is the channel length s l is the channel storage q i is the channel inflow and q l indicates the runoff volume of the channel in the storage function model it is assumed that the flood runoff is a surface runoff that can be expressed by the manning formula and the storage of the basin and the channel section is expressed as an exponential function of the runoff as shown in eq 1 1 s l k q l p eq 1 is the equation of motion for the flood wave and k p indicates the storage coefficient for basin or channel section here the continuity equation for one basin is expressed as eq 2 which is a water budget equation 2 1 3 6 f r a v e a q l d s l d t where f indicates the inflow coefficient r a v e is the hourly basin average rainfall mm hr a is the basin area k m 2 q l t q t t l is the direct runoff volume m 3 s from the basin in consideration of the basin lag time t l and s l indicates the basin storage m 3 in order to calculate the basin runoff rearranging the continuity equation and equation of motion for the basin for the unit inflow r a v e unit runoff height q l and unit storage height s l gives eqs 3 and 4 3 r a v e q l d s l d t 4 s l k q l p it is assumed that in the initial stage of rainfall rainfall runoff does not occur due to infiltration across the entire basin and as rainfall increases runoff begins to occur in some areas and then eventually occurs across the entire basin therefore the runoff volume from basin considering the baseline discharge can be expressed as in eq 5 5 q a 3 6 f 1 q l 1 f 1 q s a l q i where f 1 indicates first runoff rate q l unit runoff height mm hr by total rainfall q s a l is unit runoff height mm hr by rainfall after the saturation point and q i is baseline discharge m 3 s the continuity equation for one channel section is expressed as eq 6 6 j 1 n f j i j q l d s l d t where f i indicates the average inflow coefficient i j is the inflow from basin and tributary basin to the channel m 3 s q l is runoff volume m 3 discharged from the downstream end of the channel section considering the lag time t l with q l t q t t l and s l indicates the actual storage m 3 stored in the channel section from the above the storage coefficient k and p can be easily obtained from the past flood runoff data and if the relationship between s l and q l can be obtained then s l of eq 3 eq 4 and eq 6 can be expressed in terms of q l it is possible to calculate the flood runoff if the basin average rainfall r a v e in basin runoff and channel inflow i l in channel runoff are given 2 2 support vector machine support vector machine svm was proposed by vapnik 1995 and since the introduction it has been reported as a method that can be applied to various types of data with very accurate classification results in various problems such as document classification and customer classification choi et al 2013 svm is a method of finding a hyperplane defined by support vectors that can linearly classify vectors of different classes with the maximum margin for the distance between the classes lee et al 2016 data that cannot be classified linearly are mapped from the plane to a high dimensional space using a kernel function and then classified representative types of kernel functions include polynomial sigmoid and radial basis functions park et al 2006 svm is mainly used for forecasting of classification problems and a method that has extended svm by introducing an ε insensitive loss function so that it can be used for regression analysis is called support vector regression svr kim et al 2012 that is svm is used to classify data into 1 class and 1 class in a classification problem but svr has further generalized svm for forecasting of arbitrary real values therefore real time flood forecasting was performed using svr and rbf which has been reported to have superior performance as a kernel function was applied tay and cao 2001 in this study a real time flood forecasting model using svm was developed fig 2 shows the conceptual diagram of svm fig 3 2 3 gradient boosting in machine learning boosting refers to a method of creating strong learners with accurate performance by combining relatively inaccurate weak learners heo et al 2018 even if the accuracy is low the first tree model is constructed and the forecasting error is corrected in the second tree model in this way the weaknesses are continuously improved in the next tree model finally constructing strong learners hastie et al 2009 piryonesi and el diraby 2020 madeh piryonesi and el diraby 2021 the loss function quantifies the error of the forecasting model and to find the parameters in the model that minimize the loss function value machine learning models usually employ a gradient descent method gradient boosting gb performs the process of minimizing the parameter loss function in the model function space and derivatives of the loss function are taken with respect to a function of the tree model that has been trained so far as shown in the following eq 7 not with respect to parameters of the model 7 f i 1 f i p δ j δ f i that is in the gb model the derivative value of the tree model function serves to represent the weakness of the model that performed learning so far and when the tree model is constructed the derivative values are used to improve the weaknesses thereby boosting the performance 2 4 long short term memory long short term memory lstm model introduced by hochreiter and schmidhuber 1997 is a type of recurrent neural network rnn that directly learns from time series data le et al 2019 the general rnn has the disadvantage of updating only the learning results of the hidden layer for the entire time on the other hand although lstm is a kind of rnn it has added a cell state structure to the hidden layer and store information about the input data for a longer period of time thereby resolving the limitations of the rnn adeyemi et al 2018 the lstm model consists of a number of blocks each block includes cells representing the state over time and three non linear gates that regulate the flow of data the forget gate input gate and output gate han et al 2021 the forget gate f t performs calculation on which information to discard and applies the h t 1 of the previous step and x t of the current step to the sigmoid function to obtain a value between 0 and 1 this is multiplied by the current state and in the process forget gate decides whether to use or discard the information 8 f t σ w f h t 1 x t b f next a sigmoid function called input gate i t decides which data to update through the hyperbolic tangent function c t vectors the new candidate values are created these are combined with the i t values and added to the cell state 9 i t σ w i h t 1 x t b i 10 c t t a n h w c h t 1 x t b c using the results of eq 8 eq 9 and eq 10 a new cell state c t 1 is created by updating the previous state c t eq 11 can be used to update the information state of the current step 11 c t f t c t 1 i t c t the final result is derived through the output gate o t and this can be regarded as a step to determine which part of the cell state to derive to this end eq 12 is used and the current cell state is updated using eq 13 12 o t σ w o h t 1 x t b o 13 h t o t t a n h c t 2 5 principal component analysis principal component analysis pca uses the covariance matrix or correlation matrix of multivariate data to find a new principal component pc that is expressed as a linear combination of the original variables and aims to describe the movement of the entire variables with a small number of principal components thereby reducing dimensionality hotelling 1933 when the covariance matrix for the set of independent variables x x 1 x 2 x m is σ the diagonal element of σ is the variance of each independent variable σ 1 2 σ 2 2 σ m 2 here when σ 1 2 σ 2 2 σ m 2 are multiplied by λ 1 λ 2 λ m σ 0 in this case λ 1 λ 2 λ m in descending order indicate the eigenvalues as for the eigenvectors the solution corresponding to each eigen value is e 1 e 2 e m when the set of eigenvectors is e e 1 e 2 e m principal components satisfy y e x the m variables derived in this way are referred to as principal components and the principal components are independent of each other wold et al 1987 there are multiple ways to determine the number of principal components m values with eigenvalues of 1 or larger are selected as described above or values with a cumulative variance of 90 or larger are selected in fig 4 the cumulative variance is 90 or larger for the three principal component and in terms of eigenvalues the eigenvalue is one or larger for the three principal component in this study the number of principal components m was determined in the same way since there is high correlation between various dynamic variables in this study there would be a problem of multicollinearity and thus only a small number of principal components derived through pca were used as independent variables 2 6 k fold cross validation k fold cross validation randomly divides a data set into the same size and uses one of them for the validation data set then the remaining k 1 data are used for the training data set and this process is sequentially repeated k times perform validation on the given entire data set stone 1974 stone 1977 the advantage of k fold cross validation is that all cases are used for training and validation and each case is used only once for validation thus preventing overfitting kim 2013 in addition k fold cross validation has the advantage that all data can be used for learning and evaluation when the number of data is insufficient fig 5 shows the conceptual diagram of k fold cross validation in this study k fold cross validation was considered in order to use all data for learning and evaluation 3 applications of machine learning and sfm for real time flood forecasting 3 1 study area in this study the following four aspects were considered when selecting a study area 1 in terms of geomorphological aspect small to medium sized rivers were considered for upstream basin 2 in terms of flood damage basin with flood damage of small to medium scale was considered 3 for acquisition of hydrological data the area where sufficient volume of data on water level discharge and rainfall during the past rainfall event can be collected was considered 4 the study area has more than two water level stations in the basin and the upstream monitoring station was used as a secondary station and the downstream station was the main monitoring station for forecasting of flood discharge in consideration of the above four aspects finally bokha stream basin of namhan river upstream was selected as the study area examining the average scale of flood damage in the bokha stream it was estimated that there were 27 deaths an inundated area of 233 ha and 2 5 million usd in damage to public facilities resulting in an annual damage amount of 5 5 million usd in 2000 the total damage amount was 13 3 million usd in 2001 the total damage amount reached 28 5 million usd and in 2002 the total damage amount was 7 4 million usd indicating that the flood damage of bokha stream basin was most extensive between 2000 and 2002 in addition the main flood events that caused devastating damage in the bokha stream basin in the past include flood events in 1925 1936 1995 and 2002 and flood by continuous heavy rainfall occurred in 1965 1972 1984 and 1990 the latest flood records include the rainfall events in 2002 2006 and 2009 therefore in this study we aim to forecast the water level at heungcheon bridge station of yeoju city a point in fig 6 in downstream using the water level and rainfall data at bokha bridge station of icheon city b point in fig 6 in upstream of bokha stream basin the fig 6 below is a schematic of the study area which is bokha stream basin 3 2 selection of rainfall events used this study aims to perform real time flood forecasting using only event specific data by classifying rainfall events during the flood season and not performing forecast using all the data of meteorological stations and water level stations when examining long term data of continuous hourly rainfall there are interevent records indicating that there are continuous or discontinuous rainfall records in order to separate each individual rainfall event from these continuous or discontinuous rainfall records a criterion needs to be set that can distinguish the start and end of each rainfall event choi et al 2010 interevent time definition ietd can be defined as a minimum interevent time separating each rainfall event from long term rainfall data that is if the interevent time between rainfall records is shorter than the ietd the two rainfall records before and after the interevent time are considered as one rainfall event and if the interevent time between rainfall records is longer than the ietd the two rainfall records before and after the interevent time are considered as two respective rainfall events kwon et al 2004 autocorrelation analysis determines ietd through correlation between rainfall events the lag time at which rainfall correlation becomes 0 is defined as ietd as a method of calculating ietd to separate long term continuous rainfall into each independent rainfall event a correlation between rainfall events is assumed in the rainfall time series autocorrelation refers to the correlation between rainfall events in the rainfall time series and the time interval between each observation time is referred to as lag time lee et al 2004 the correlation coefficient r k is expressed as eq 14 below 14 r k y t y y t k y y t y 2 where y is the sample mean of the data series and k indicates the lag time autocorrelation analysis was used to consider lag time and the range was determined as a section within the 95 confidence interval the conceptual diagram for ietd is shown in fig 7 below and the lag time corresponding to the confidence interval for each small river basin is seven hours as shown in fig 8 in this study in order to select rainfall events from the observation start date of yeoju city heungcheon bridge station to the recent date of august 31 2020 june july august and september cases when the runoff volume was 100 m 3 s or larger were checked and considering the interevent time a total of 53 rainfall events were finally selected 3 3 flood water level as dependent variable the rating curve is a curve showing the relationship between the river water level and discharge by measuring the water level and discharge at specific observation points and using a regression equation from the past to present the river cross sections has undergone changes and the flow velocity also has changed and thus rating curve has been changed by various conditions therefore there are various rating curves for the water level and runoff data of yeoju city heungcheon bridge station and icheon city bokha bridge station as for the water level and runoff data provided by the flood control office the data are recorded based on the rating curve applied in the past and this led to multiple problems one of the representative problems is that there are various values of runoff for the reference water level that is since there are multiple discharge data for a single water level confusion may arise as to which data is the discharge value that can serve as the true value in this study the rating curve used for each rainfall event was used to calculate the flood discharge for the water level 3 4 independent variables for machine learning models for development of a real time flood water level forecasting model water level and discharge data at bokha bridge station were collected from january 1 2007 to august 31 2020 data measured at rainfall stations and water level stations of bokha stream basin were used as independent variables for real time flood water level forecasting the list of independent variables comprises as follows areal average rainfall for each small river basin rainfall of previous five days for small river basin cn for each small river basin water level data up to the lead time at bokha bridge station at 40 min 50 min 60 min 70 min 80 min 90 min and 100 min the sum of the time of concentration of all basins and channels from the upstream basin of the bokha stream to the end of the heungcheon bridge station is calculated at about 1 2 h 72 min in particular the lag time of the channel section between the bokha bridge station and the heungcheon bridge station is calculated at about 0 61 40 min in addition when examining the difference between the peak water level timepoint of bokha bridge station and the peak water level timepoint of heungcheon bridge station it can be seen that although there is a difference according to the rainfall pattern the difference is in the range between 40 min and 100 min on average in general small to medium rivers require a lead time for flood evacuation of at least 30 min that is in order to derive the forecasted water level value for 30 min in heungcheon bridge station in this study the water levels in 10 minute intervals from 40 min to 100 min for icheon city bokha bridge station lead time were selected as independent variables there are seven water level data from 40 min to 100 min of lead time and the number of variables is large and the similarity between each variable is high so it is highly likely that a multicollinearity problem will occur therefore in this study pca was performed and principal components with cumulative variance of 90 were extracted and these were used as independent variables for learning finally in this study a total of 16 independent variables were used to construct an ai model the list of independent variables comprises as follows three of areal average rainfall for each small river basin three of rainfall of previous three days fir small river basin three of cn for each small river basin seven of water level data considering the lead time of icheon city bokha bridge station 3 5 parameters of storage function model flood forecasting in south korea adopts the rainfall runoff method as an event model for floods over a certain period of time and the models that have been developed and operated by each of flood control offices of the four major national rivers have been standardized and reconstructed as an integrated flood forecasting and warning system the calculation procedure of this model consists of the following processes 1 construction of the effective rainfall calculation model 2 the basin runoff calculation and 3 the calculation of the channel runoff and converting the water level of the river from the rating curve the storage function model is somewhat complex in terms of applying the model constants and hydrological expertise is required when running the model such as high quality hydrological data or precise basin geomorphological data to determine the model constant currently for flood control offices in south korea various models are applied to the basin runoff but for the channel runoff the storage function model is used as the basic model in addition default values are used without parameter adjustment for storage coefficients used in channel runoff calculation however for forecasting of the flood discharge runoff constant f1 fsa rsa and storage coefficient k p ti need to be adjusted therefore in this study bokha stream basin the study area was divided into upstream a midstream b and downstream c and for initial runoff rate saturation runoff rate and saturation rainfall for each flood event fixed values were used and storage coefficient k storage coefficient p and lag time t l were calculated for each rainfall event the hydrological flood prediction model using the rainfall runoff model is sensitive to temporal and spatial changes in rainfall there is a limit to calculating the runoff due to regional torrential rain in the upstream areas where the flood arrival time is short and the very narrow areas of small rivers in addition since there is currently no objective and reasonable method for determining parameters empirical expressions are used to determine the parameters and correction is dependent on the judgment of hydrologists as the flood discharge was calculated based on the judgement of the hydrologist there was a problem that subjective factors were dominated rather than objective factors the rainfall runoff model is highly dependent on hydrologists and when adjusting the parameters of each model it is set based on flood events at past times the problem with this is that parameters must be readjusted when flood events are different from the flood that occurred in the past and this process takes a considerable amount of time in this system long experience and know how are very important factors for accurate judgement on whether to issue flood forecasts in the absence of hydrologists problems with the implementation and issuance of flood forecasting and warning models may arise so it is judged that research should be conducted to supplement these problems 3 6 development of machine learning model for real time flood forecasting in this study the problems of the current flood forecasting and warning system described above were addressed and a model for real time flood forecasting was developed in consideration of these problems examining the flood forecasting procedure and the standards for issuing and lifting of flood warnings these are focused on the water level rather than on the flood discharge we aim to develop a model that can predict the water level that meets the flood forecasting procedure the criteria for issuing and lifting the flood warning for real time flood water level forecasting a storage function model and three types of machine learning models were used fig 9 shows the flow chart of development of model for real time flood forecasting the calculation process to predict the water level value of heungcheon bridge station which is the purpose of the study is as follows 1 for development of machine learning models for real time flood forecasting for dependent variables water level data at yeoju city heungcheon bridge station were collected from january 1 2007 to august 31 2020 in 10 minute intervals instead of using all the collected data only data for 53 rainfall events were used and the total number of data was 12 683 independent variables used in the study were areal average rainfall for each small river basin the preceding five day rainfall for each small river basin the runoff curve index for each small river basin and the water level from the water level station of icheon city bokha bridge station 2 for development of a model using dependent variables and independent variables data were divided into learning section and evaluation section the learning section used data from 2007 to 2015 and the number of data is 8 397 the evaluation section used data from 2016 to 2020 and the number of data was 4 286 3 a total of 16 independent variables were used to develop the water level forecasting model of which data of bokha bridge station water level prior to 40 min 50 min 60 min 70 min 80 min 90 min and 100 min are highly correlated with each other which may lead to the problem of multicollinearity therefore in order to tackle the problem of multicollinearity the dimensionality of variables with high correlation was reduced by pca 4 for analysis of the results according to the correlation between independent variables the models were divided into two types the first is a model using all independent variables and the second is a model using reduced independent variables derived through pca for data for each small river basin and previous water levels 5 in order to derive the optimal parameter values for each model the pca used the stepwise method and the svm model randomly selected the parameters sigma and cost to derive the optimal value the predictive power was evaluated using both polynomial and sigmoid but only the results for rbf were presented because the performance was inferior to rbf for gb model the optimal values were derived by randomly selecting the parameters of the model which are shrinkage interaction depth n minobsinnode and n trees finally for the lstm model optimal values were derived by adjusting activation epoch optimizer learning rate and loss 6 in order to construct a model using the optimal parameter values derived for each model the k fold cross validation method was used for training and verification of all data in the learning section 7 finally the predictive power of the rainfall runoff model and the machine learning models was evaluated and the model with the best predictive power evaluation result was presented as model for real time flood forecasting we aimed to develop a model optimized for real time flood forecasting for basins with a short time of concentration and present the applicability of the developed model the hardware information used to run the e1071 gbm keras and tensorflow packages and software in r studio is as follows cpu amd ryzen 7 3700x gpu nvidia geforce gtx 1660 for reference r studio packages are open access data 3 7 evaluation of predictive power for a proper model selection 3 7 1 evaluation of predictive power for storage function model the basis for determining how close the forecast values calculated by the flood forecasting model are to the measured values is called goodness of fit the coefficient of efficiency has been widely adopted in a number of data mining and model evaluation and this coefficient is closely related to the coefficient of determination it is desirable if there is a unique indicator or object function for goodness of fit evaluation but this is not possible in practice actually the object function varies depending on the forecasting model to be evaluated the flood forecasting model focuses on the peak flow and the long term runoff forecasting model focuses on the drought flow therefore in this study the storage function model before the adjustment of parameters and the storage function model with adjusted parameters were comparatively analyzed in addition predictive power was evaluated for the evaluation sections of three models in which the dimensionality of the independent variables was reduced using pca as a predictive power evaluation method coefficient of determination and the nrmse were used in order to determine the correlation and errors for water level station data for each event and the predicted results and for evaluation of the errors for peak flow q peak and t peak methods were used for comparative analysis of the model results the predictive power evaluation results before adjusting the parameters showed r 2 0 81 nrmse 0 30 q peak 0 70 and t peak 150 the predictive power evaluation results after adjusting the parameters showed r 2 0 91 nrmse 0 21 q peak 0 04 and t peak 28 comparative analysis on the predictive power evaluation results before and after adjusting the parameters confirmed that the flood forecasting performance has improved after the adjustment however these are forecasted values that have been adjusted for the past time points and in this case it is unreasonable to regard these results as the predictive power evaluation for future flood for the rainfall runoff model superior predictive power evaluation result was obtained after adjusting parameters compared to the values before the parameter adjustment and this is thought to be the advantage of the rainfall runoff model that is the rainfall runoff model adjusts parameters for past rainfall events and the model s predictive power is excellent for past rainfall events however in the case of an uncertain rainfall events in the future the parameters need to be readjusted which is recalculated by hydrology research this indicates that the model has limitations in terms of predictive power for future event forecasting 3 7 2 evaluation of predictive power for machine learning model in the rainfall runoff model in order to predict the water level of a river from the flood discharge calculated using rainfall the observed water level data at major points and rating curve are instrumental in addition in order to collect such basic data rainfall monitoring stations and water level stations need to be installed and operated at each point but installation of those stations at all points has practical limitations in addition there is a limit in predicting future flood discharge by testing and adjusting the model based on the past discharge data with the rainfall runoff model therefore in order to overcome these limitations this study aimed to develop a model that predicts the water level of a small river basin using machine learning models the results of evaluating predictive power of three machine learning models for each rainfall event are shown in table 4 below for the evaluation sections only the results of predictive power evaluation for svm in the forecasting evaluation section were r 2 0 70 nrmse 0 27 q peak 0 20 and t peak 57 the results of predictive power evaluation for gb in the forecasting evaluation section were r 2 0 80 nrmse 0 25 q peak 0 19 and t peak 88 and the results of predictive power evaluation for lstm in the forecasting evaluation section were r 2 0 87 nrmse 0 21 q peak 0 01 t peak 10 the result of predictive power evaluation for each rainfall event showed that lstm matches the measured water level values better than svm and gb and has superior predictive power for peak values required for flood forecasting in general for large river basins the standard proposed by the world meteorological organization wmo is a forecast with three hours of lead time in addition in the case of medium sized rivers water level forecasting with one or two hour of lead time is the target and in the case of small rivers or rivers in steep mountain that have short time of concentration as in the case of this study area the target lead time is 30 min to one hour the result of machine learning model developed in this study shows that forecast with 30 minute lead time is possible in addition the developed method has advantages that parameters do not need to be adjusted each time for a new rainfall event and a rating curve is not necessarily required fig 10 shows the water level data measured at the water level station and the water level values forecasted using svm gb and lstm models only eight event sections are shown as examples out of 20 evaluation sections for events 39 40 44 46 50 and 53 the peak value of the water level was one and the lstm model was the best predictor of the trend and peak runoff among the three models in addition it was found that for peak value forecasting in which the water level increases decreases and then increases again the lstm model was the best predictor of the trend and peak runoff among the three models in fig 11 the box plot is schematized to show the distribution of the minimum and maximum predicted values for each model here the box plot is a graph that can confirm the distribution of data through the calculated statistics minimum value first quartile second quartile third quartile maximum value from the data the first quartile represents the bottom of the box the third quartile represents the top of the box the minimum value is expressed as a value obtained by subtracting 1 5 iqr interquatile range from the first quartile and the maximum value is expressed as a value obtained by adding 1 5 iqr from the third quartile in addition values outside the minimum and maximum values are expressed as potential outliers 4 summary and conclusions damage caused by natural disasters continues to pose a threat across the globe this study aimed to develop a model for real time flood forecasting as measures of reducing flood damage which occurs most frequently out of natural disasters in south korea in particular the flood forecasting and warning system currently operated by the ministry of environment s flood control offices of the 4 major rivers is mainly focused on large river basins and rainfall runoff model is the basic model with comparative analysis of the runoff model and the machine learning models we propose a method of model development for real time flood forecasting suitable for a basin with a short time of concentration the findings of this study are outlined as follows 1 for real time flood water level forecasting a bokha stream basin with water level stations at upstream and downstream points is selected as a study area and in order to collect the rainfall data and water level data of the upstream and downstream basins the water level data and runoff data were collected in 10 minute intervals from january 1 2007 to august 31 2020 the rating curve was used to adjust for the missing values of the collected water level and runoff data 2 using the storage function model which is currently employed for flood forecasting and warning in south korea we performed real time forecasting of the flood discharge at downstream points flood discharge was derived using the storage function model for each of the 53 events in total and the obtained values were compared with the runoff data measured at the water level station and the accuracy of the flood discharge estimation for each model was comparatively analyzed in addition in order to compare and select the final model for real time flood forecasting the flood discharge was converted to the water level using the rating curve 3 the water level data and rainfall data of the upstream points of the basin were processed to be used as independent variables and the model was constructed using the water level at the downstream points as the dependent variables the water level data of yeoju city heungcheon bridge station was used as the dependent variables and for independent variables pca was used to resolve the problem of multicollinearity the accuracy of each model was examined by comparing the forecasted results with the water level data observed at the water level station 4 finally predictive power was evaluated for evaluation sections of 7 models in total which are a storage function model with adjusted parameters three models using all independent variables data and three models that reduced the dimensionality of the independent variables using pca as predictive power evaluation methods coefficient of determination rmse nrmse q peak t peak and nse were used and the result of the models were compared as a result of the predictive power evaluation lstm which shows the best predictive power was selected as the final model for real time flood forecasting there are several limitations in this study and the first is the use of validated input data examining the forecasted water level result graph although there is a difference depending on the rainfall event perturbation can be seen in the forecasted value of the ai machine learning models this is a case in which the variability of the input data itself that is the actual water level value in 10 minute intervals causes disturbance it is thought that in the process of learning in the model there were many input data with such disturbance during the rainfall event and this was also reflected in the learning result because the result value of these models cannot be manually changed the quality control of the input data is critical that is superior results can be obtained if learning is performed by correcting these outliers and missing values through validation of the data after collecting hydrological data however since such phenomena may actually occur in the field research on a model that can derive accurate results depending on the processing of the data and environment given is thought to be necessary the second limitation is the inaccuracy of the rating curve there are so many rating curves for bokha bridge station and heungcheon bridge station and although the most recent rating curve is highly likely to be accurate the rating curve used at the time for each rainfall event was used in this study which led to errors if reliable and high quality hydrometeorological data water level runoff and rainfall data for each small river in south korea can be acquired and utilized it will significantly contribute to improving forecasting performance with precise advancement of the model for forecasting of future flood models are developed and operated using the past flood discharge data in south korea however the rainfall runoff model currently employed in the country manages the runoff model through parameter adjustment relaying on the experience of hydrology research every time a new flood event occurs in addition when adjusting the parameters of the rainfall runoff model the flood discharge should be predicted by adjusting within the range of each parameter however there are cases that in order to match the peak water level the value out of the range is artificially introduced for forecasting of flood discharge in this case the problem arises that the parameter values are fixed for past data and they need to be newly adjusted for every new rainfall event this problem occurred in this study in the case of rainfall runoff model and there were cases where the values out of the range were applied for adjustment in order to adjust the parameters to the past events the overall forecasting performance of the rainfall runoff model may appear to be good but when comparing the model with the ai based models after identifying the problems and limitations of the rainfall runoff model we can see that the forecasting performance of the ai models was excellent in addition the rainfall runoff model currently in operation is constructed and run as a forecasting system mainly for large river basin and in this case there are forecasting uncertainties of the model in cases of rainfall events in which the peak water level is observed in the initial stage or basins of steep mountain areas and small rivers and thus the ai models used in this study are thought to serve as good alternatives to the rainfall runoff model recently machine learning models using various ai techniques have been developed and continuous research needs to be conducted on the utilization of customized ai techniques suitable for each basin characteristic using these models therefore if the model for real time flood forecasting proposed in this study can be used it will be of great use and benefit to the accurate and prompt decision making process of non research on flood forecasting and warning moreover if machine learning techniques can be adopted for flood forecasting and warning systems in countries where there is a lack in the pool of hydrology research such as southeast asia and africa it will be highly useful however since all data are based on hydrometeorological data there are various uncertainties therefore it is imperative to acquire reliable data and conduct continuous research to reduce these uncertainties credit authorship contribution statement donghyun kim conceptualization methodology software formal analysis investigation data curation writing original draft writing review editing visualization joonseok lee methodology software validation investigation writing original draft jongsung kim methodology software validation investigation writing original draft myungjin lee methodology software validation investigation writing original draft wonjoon wang methodology software validation investigation writing original draft hung soo kim conceptualization resources writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by a grant 2018 mois31 009 from fundamental technology development program for extreme disaster response funded by korean ministry of interior and safety mois 
3666,compound flooding caused by high rainfalls and tides may salinize the soil deteriorate the water quality and damage the ecosystems in coastal areas traditionally compound flood risk is estimated using the joint probabilities of a rainfall and a tide level when they are simultaneously or individually exceeded this results in bias because flood risk should represent the exceeding probability of a flood magnitude not of the triggers values in this study a new approach is proposed to determine the exceedance probability for a flood depth induced by the compound effects of rainfall and tide through the combination of copula analysis numerical simulation multiple regression and monte carlo integration a frequently flooded coastal area in chiayi taiwan was selected as the study subject the results show that realistic flood risk should range between the joint probabilities of rainfall and tide levels being simultaneously or individually exceeded thus when the joint probabilities are used to determine the thresholds of rainfall and tide for flood warning and hydraulic design the misestimation of flood risk will result in errors such as incorrect alarms and inaccurate protections with a ratio of 37 in a case study with 10 year return period these errors can be reduced using a hybrid cumulative probability function developed in this study for selecting the best rainfall and tide thresholds with local maximum or minimum cumulative flood probabilities the proposed approach is efficient and general so it can be promoted in different fields for risk assessment influenced by bivariate variables keywords compound flooding rainfall tide probability risk 1 introduction compound flooding in coastal areas caused by rainfall and tide has increased in recent years under climate change wahl et al 2015 bevacqua et al 2019 under high tide levels flood water contributed by seawater overflow or intrusion leads to soil salinization crop withering and infrastructure erosion triet et al 2020 yu et al 2021 under high rainfalls the sediments heavy metals organic compounds and pesticides washed down by surface runoff deteriorate water quality and damage the ecosystems in coastal areas zoppini et al 2019 paerl et al 2020 under the compound effects of high rainfalls and tides flood duration and extent increase and the impacts of individual factors are amplified hsiao et al 2021 to estimate the risk of compound flooding the analysis of rainfall tide correlation has become a crucial task in recent years the copula theorem proposed by sklar 1959 has been widely used to describe the joint probability of rainfall and tide in coastal areas compared with traditional bivariate models the copula is more convenient in its application because it establishes the joint cumulative distribution function cdf for multiple variables independently to marginal distribution structures xu et al 2014 used copula models to investigate the joint probability between rainfall and tide and showed that flood risk was increased by tide levels in fuzhou city located in a southeast coast of china zheng et al 2014 applied three copula models with different data selection methods to estimate the compound flood risk for the hawkesbury nepean catchment in australia zellou and rahali 2019 adopted a copula model to assess coastal flood risk at the estuary of the bouregreg river in morocco showing that the flood extents can be greatly underestimated without considering the correction between rainfall and tide once the copula models are determined hydraulic models are often used to simulate the flood hazards when specific rainfall and tide levels are exceeded simultaneously namely the and scenario or individually namely the or scenario lian et al 2013 applied the one dimensional 1d hec ras model to obtain the isolines of flood severity for the river system in fuzhou city under the and scenario zellou and rahal 2019 used the caesar lisflood model coulthard et al 2013 to predict the maximum flood extents in the bouregreg estuary of morocco for a 116 year joint return period event under the and scenario moftakhari et al 2019 combined a 1d steady shallow water equation and a two dimensional 2d hydraulic model to simulate the flooding for the estuaries in southern california affected by extreme tide levels and river discharges they found that the flood hazards defined by the or scenario were more conservative than those defined by the and scenario for a given joint return period saharia et al 2020 generated inundation maps with different return periods of seiche and flow under the and scenario through the integration of a hydrodynamic model hec ras and bivariate copula for the buffalo river basin next to lake erie new york tanim and goharian 2021 integrated a coastal hydrodynamic model delft3d and the storm water management model swmm to simulate the flood depth in the chittagong city next to bangladesh bay and adjusted the outputs according to uncertainty analysis based on a multivariate gaussian copula in the linkage between the copula and hydraulic models the fundamental question is how to select the best pair of rainfall and tide levels in forcing hydraulic models under the and or or scenario there exist many combinations of rainfall and tide levels which can generate different flood magnitudes for a specific joint return period this implies that the influence of rainfall and tide on flooding is nonlinear and the exceedance probability of a flood magnitude cannot be represented by the joint probability of rainfall and tide that triggers the flooding in other words the probability of compound flooding should be determined based on the flood magnitudes simulated from all rainfall tide pairs defined by a copula model not from a rainfall tide pair with a predetermined joint return period this can be realized through a monte carlo simulation which generates thousands of flood magnitudes for frequency analysis based on different pairs of rainfall and tide unfortunately the copula based monte carlo simulation requires many computations so it is mainly applied in 1d simulations currently yazdi et al 2014 peng et al 2017 for 2d problems such as compound flooding how to accurately and efficiently determine realistic flood risk through the linking of copula and hydraulic models remains an issue that has not been solved in this study a new approach is proposed to predict the realistic risk of compound flooding related to flood magnitudes considering the dependence between rainfall and tide unlike traditional monte carlo simulation methods the proposed approach is more efficient because it requires only a limited number of numerical simulations through the combination of multiple regression and monte carlo integration on a copula domain detailed comparisons are made to highlight the differences between the results predicted by the proposed method and those obtained from conventional and and or scenarios the findings in this research are valuable for flood disaster management in coastal areas 2 study area and data the study area is shown in fig 1 which is located in the coastal area of chiayi county taiwan belongs to the longgong river watershed and has an area of 260 km2 the area has a mean annual temperature of 21 24 and an average annual rainfall of 1 600 mm mostly concentrated between may and september the topography of the study area is very low lying 1 83 m in average due to land subsidence caused by decades long groundwater pumping for fish farming during high tides the water level in the channels exceeds the ground surface which reduces drainage efficiency and results in severe flooding whenever heavy rainfall occurs taking the flood event on august 23 2018 namely the 0823 event as an example the co occurrence of heavy rainfall and a high tide led to disastrous flooding that lasted for 5 days with an economic loss of 60 million us dollars in chiayi county in this study the observation data for 27 historical events from 1993 to 2019 recorded at donghouliao rain station and dongshi tide station were collected which can be obtained online via the hydrological information system of wra water resources agency 2021 for each year the time periods with maximum 24 hour rainfall amounts were pinpointed to obtain the maximum annual rainfall r and the highest tide level t for copula analysis in the same period as summarized in table 1 a discordancy test based on boxplots has been proceeded and no outliers were found among the selected historical data the highest value of r was 0 62 m or 620 mm recorded during the 0823 event in 2018 and the highest value of t was 2 26 m in 1996 the pearson correlation coefficient for r and t is 0 33 with a significance level of 0 05 indicating that there exists a moderate correlation between rainfall and tide to estimate the flood magnitudes under different r and t values the rainfall hyetographs and tide hydrographs for each event in table 1 were input as the boundary conditions to trigger a hydraulic model for flood depth and extent simulation 3 methodology this research uses three steps to calculate compound flood risk which are shown in different colors in the flowchart of fig 2 first for the 27 historical events the data of rainfall r and tide level t are collected and input for copula analysis and hydraulic simulation at the same time in the copula analysis the best fit marginal and copula distributions for r and t are determined in the hydraulic simulation the rainfall hyetographs and tide hydrographs are introduce to calculate the flood depths which are expressed as a function of r and t through multiple regression and with that a flood depth contour line can be determined for each historical event second combining the copula and regression function obtained in the previous step and monte carlo integration we calculate the cumulative flood probabilities for all events and establish a hybrid cdf for estimating compound flood risk based on flood depth scenario i e the fd scenario as described later third using the hybrid cdf the realistic flood risks are calculated and compared with those estimated based on and and or scenarios for evaluating the errors in flood warning and protection under specific return periods details are described as follows 3 1 bivariate copula analysis the copula is a cdf used to describe the correlation of multiple variables from the marginal probabilities of individual variables nelsen 2006 according to sklar s theorem 1959 the bivariate copula c 0 1 2 for r and t can be expressed as 1 f c r t c f r r f t t where f c is the joint cdf for r and t f r and f t are the marginal cdfs for r and t respectively the copula function c is a two dimensional distribution which satisfies the conditions c r 0 c 0 t 0 c r 1 r for r 0 1 c 1 t t for t 0 1 and c r 2 t 2 c r 2 t 1 c r 1 t 2 c r 1 t 1 0 for 0 r 1 r 2 1 and 0 t 1 t 2 1 the marginal distributions are univariate distributions that can be determined independently of the copula function in this study five univariate distributions including the normal lognormal gev weibull and gamma are compared to determine the most appropriate marginal distributions for rainfall and tide five bivariate copula models out of the archimedean family were selected for comparison including the clayton frank gumbel joe and plackett as defined in table 2 archimedean copulas were considered because they are better at describing r t correlations under high return periods zellou and rahali 2019 the parameters in the univariate and copula distributions were determined using the maximum likelihood estimation mle method in which the best fit distributions were selected based on parametric statistics according to their performance as evaluated by akaike information criteria aic akaike 1973 and bayesian information criteria bic schwarz 1978 2 aic 2 m 2 l n l 3 bic m ln n 2 l n l where m is the number of parameters l is the maximized likelihood value of the model the aic and bic consider the dependence of parameters without resulting in overfitting silva and lopes 2008 3 2 hydraulic model for hydraulic simulation the cos flow model coupled overland sewer flow model developed by jang et al 2018 2019 was adopted the cos flow model is a high precision flood model that combines a 2d overland flow module and a 1d channel flow module to simultaneously simulate surface runoff channel flow and their interactions the cos flow model was applied to simulate the 0823 event in the study area and showed a satisfactory level of accuracy in predicting the flood depth and extent of compound flooding hsiao et al 2021 the overland flow module solves the dynamic shallow water equations as below 4 h t u h x v h y q q a o 5 u t u u x v u y g h z x g u n x 2 u 2 v 2 h 4 3 q hg 6 v t u v x v v y g h z y g v n y 2 u 2 v 2 h 4 3 q hg where u and v are the flow velocities in x and y directions respectively h is the water depth q is the effective rainfall z is the elevation of bed topography n x and n y are the manning s coefficients in x and y directions respectively q represents the discharge received from the 1d module the alternate direction explicit method and the courant friedrichs lewy cfl restrictions courant et al 1967 were used to improve numerical accuracy and stability respectively the 1d channel flow module uses the implicit backward euler method ascher and petzold 1998 and the picard iteration method picard 1890 to solve the 1d dynamic shallow water equation 7 a t v a s q l 8 v a t v a s g a h s z s s n s 2 v v r 4 3 where a is the cross sectional area of flow in channels v is the flow velocity in channels r is the hydraulic radius h s denotes the flow depth in channels z s is the elevation of channel bottom and n s is the manning s coefficient in s direction by subtracting the infiltration obtained from the runoff curve number method nrcs 2004 the hyetographs of effective rainfall q can be determined and served as the upstream boundary conditions to initiate overland flow routing meanwhile the hydrographs of tide level were input as the boundary conditions of water elevation h z at the river estuaries in this study a structured mesh system with a grid size of 40 m was used and the grid center bed elevation z was interpolated from a lidar derived digital terrain model dtm with 1 m resolution to speed up the simulation the program codes were parallelized via the openmp open multi processing platform for multi core computers details about the cos flow model can be found in hsiao et al 2021 3 3 flood risk analysis traditionally the joint exceedance probabilities under and and or scenarios are used for flood risk estimation salvadori et al 2004 9 p and p r r t t 1 f r r f t t f c r t 10 p or p r r t t 1 f c r t where r and t are specific values for rainfall and tide respectively p and and p or are the joint exceedance probabilities for and and or scenarios respectively the p and is often adopted to estimate the return period for an extreme event with a specific pair of r and t whereas the p or is used to estimate the chance of failure for an hydraulic system designed under a specific value of r or t biondi and de luca 2017 although the concepts of and and or are widely used they may not actually represent flood risk because the p and and p or are related to rainfall and tide instead of their influence on flooding based on the concept of frequency analysis chow 1964 realistic flood risk should be the exceedance probability for a flood magnitude to occur not the joint probability of r and t that triggers the flood magnitude if flooding is only triggered by one variable the exceedance probabilities of flood magnitude and the variable can be quite similar but for compound flooding the flood risk may greatly deviate from the joint exceedance probability because the influence of r and t on flooding is nonlinear and associated with local conditions such as topography drainage and land use in this study the average flood depth fd simulated by the hydraulic model was used to represent the flood magnitude and the exceedance probability of fd can be expressed by the equation below 11 p d d 1 f d d where d is a random variable for fd d is a given fd f d is the cdf for fd since eq 11 determines the flood risk based on fd it is named the fd scenario hereinafter as a function of rainfall and tide fd can be expressed by d r t and f d d can be calculated using the following equation 12 f d d s c f r r f t t d s r t s where c f r r f t t is the best fit copula for r and t s is the area bounded by the contour line d r t d and the two axes of rainfall and tide in the schematic diagram fig 3 on the contour line all the r t pairs result in the same fd of d but the contributions of r and t are different through multiple regression the function d r t can be determined from the relationship between the d values simulated by the hydraulic model and the values of r and t for historical events in light of the complexity of the copula and regression functions analytical solutions may not always exist for f d thus the integration in eq 12 can be conducted numerically using monte carlo integration newman and barkema 1999 wang et al 2009 through the following steps 1 sample n random pairs of u 1 and u 2 based on the best fit copula distribution 2 determine the rainfall and tide values for each sample using r f r 1 u 1 and t f t 1 u 2 according to marginal distributions respectively 3 substitute the r and t values into d r t to determine the flood depth for each sample 4 calculate the value of m as the number of samples with a flood depth less than or equal to d 5 f d d m n where n is set as one million and the whole process is repeated for 100 times to obtain the mean value of f d d following the steps above the cumulative flood probability f d d can be determined for any d value and the function of f d can be determined through the fitting of univariate distributions unlike the copula and frequency analyses which uses aic and bic to select the best distribution the best fit cdf for f d is the one with the smallest root mean square error rmse since the population of cumulative flood probability for all d values have been obtained from the monte carlo integration in this study the multivariate copula analysis toolbox mvcat mathworks 2021a in matlab developed by hydroclimate research lab in university of california was adopted to construct the copula models and compute the return periods the statistics and machine learning toolbox mathworks 2021b in matlab was adopted for monte carlo integration to generate random data pairs from the selected copula distributions once the function of f d is determined the exceedance probability for fd resulting from a given r t pair can be expressed as f d d r t and then eq 11 can be modified as 13 p d d r t 1 f d d r t the return periods for and or and fd scenarios are defined as the reciprocals of exceedance probability respectively 14 t and 1 p r r t t 15 t or 1 p r r t t 16 t fd 1 p d d r t t and and t or estimate the joint return period of an r t pair regardless of flooding whereas t fd estimates the return period of fd caused by an r t pair by considering the nonlinearity among rainfall tide and flooding 4 results 4 1 copula analysis table 3 summarizes the goodness of fit for rainfall tide copula and fd distributions having relatively small aic and bic values the lognormal gamma and frank distributions were selected as the most appropriate distributions for rainfall tide and copula respectively fig 4 a and fig 4 b compare the empirical and five theoretical distributions for rainfall and tide respectively fig 5 a shows the cumulative probability for the frank copula and fig 5 b shows the joint probability density related to rainfall and tide with higher concentrations around r 0 2 m and t 1 5 m based on the copula analysis the marginal cumulative probabilities of rainfall and tide f r and f t respectively and the joint return periods for rainfall and tide under and and or scenarios t and and t or defined by eq 14 and 15 respectively were determined for each event as displayed in table 1 it can be seen that the two events in 1996 and 2018 possess the highest values of t and greater than120 year caused by extreme tide levels f t 0 99 and rainfall f r 0 99 respectively compared with t and the annual variation of t or is less sensitive 4 2 flood simulation to estimate fd under different r t pairs the rainfall hyetograph and tide hydrograph for the 27 events in table 1 were introduced into the cos flow model for hydraulic simulation two of the flood simulation results are illustrated in fig 6 a and fig 6 b for the events in 1996 and 2018 with extreme tides and rainfall respectively it is seen that the flood areas resulting from the extreme tides were more concentrated along the coast than those induced by the extreme rainfall to reflect the impacts of flood hazard the maximum water levels in the grids among roads residential industrial and commercial areas were averaged to obtain the fd for each event shown as the values of d in table 1 using nonlinear programming with an objective to minimize the rmse the function d r t can be regressed as below 17 d r t 10 31 r 3 07 0 29 t 2 65 the fds simulated by the hydraulic model and those predicted by eq 17 are in good agreement with r m s e 0 19 m and r 2 0 93 as shown in fig 7 the phenomenon d 0 0 0 indicates that eq 17 is physically reasonable because there is no flooding when both rainfall and tide equal zero when either r or t equals zero fd still increases with the other factor following a power law compared with tide rainfall has a higher influence on fd since the power of r is higher 4 3 flood risk analysis using the boundary contour line defined by eq 17 the monte carlo integration was proceeded on the copula domain to obtain the mean value of cumulative flood probability f d for each historical event with a standard deviation of 0 0001 as listed in table 1 once the f d is determined it can be related to d by fitting univariate distributions in table 3 the lognormal distribution was selected for having the smallest rmse value and the flood cdf can be described as 18 f d d r t 1 2 1 e r f l n d r t μ 2 σ where erf is the error function also called the gauss error function d r t is determined by eq 17 μ 0 16 and σ 0 51 are the coefficients determined by nonlinear programming with an objective to minimize the rmse with r m s e 0 003 m and r 2 1 the cumulative flood probabilities obtained by eq 18 perfectly coincide with those from monte caro integration without accounting for the error from eq 17 as shown in fig 8 unlike conventional distribution functions eq 18 is a hybrid form of cdf because it merges a bivariate function into a univariate cdf affected by hydraulic and topographical conditions the hybrid cdf of eq 18 may have different forms and parameters for different areas introducing eq 18 into eq 13 and eq 16 the value of t fd can be calculated and compared with the t and and t or for each event as listed in table 1 overall the return periods were largest for the and scenario medium for the fd scenario and smallest for the or scenario especially for extreme events taking the event in 2018 as an example the return periods were 127 29 2 10 and 49 02 years for the and or and fd scenarios respectively this means that event based flood risks i e the exceedance probabilities of fd were underestimated by the and scenario and overestimated by the or scenario fig 9 shows the contour lines of the return periods for the and or and fd scenarios in which the cycles represent the observed r t pairs of annual events in the figure each fd contour line is intersected by multiple and and or contour lines showing that the r t pairs resulting in the same t fd may have different t and and t or and vice versa the values of t and t or and t fd are compared in table 4 under different return periods of rainfall t r and tide t t since the frank copula is symmetric the values of t and and t or are symmetric against the diagonal axis when rainfall and tide have the same return period the t fd does not show such a symmetric pattern because rainfall and tide have uneven influences on fd overall t fd is more sensitive to rainfall than to tide at t t 2 year the value of t fd increases by 25 times from 1 86 to 48 88 when t r increases from 2 to 100 years in contrast at t r 2 year the value of t fd only increases by 11 times from 1 86 to 22 73 when t t increases from 2 to 100 years for a given r t pair the values of return period show great discrepancies with an increasing pattern from t or t fd to t and especially at high return periods for example the values of t or t fd and t and are equal to 50 92 445 88 and 2795 40 years at t r t t 100 year respectively this means that great biases happen in applications if the and and or scenarios are used for flood risk estimation 4 4 applications under a given return period the and scenario is often used to select a specific pair of r and t as thresholds for issuing flood warning which may result in errors from the aspect of fd scenario fig 10 compares the contour lines of 10 year return period for and and fd scenarios it is seen that all the r t pairs on the contour line with t and 10 year have t fd values smaller than 10 years if we select an r t pair on the contour line as the thresholds for flood warning the false alarm ratio can be expressed as 19 p t fd t and r r t t p o p and where p and is the occurrence probability in the area bounded by the red dash line p o represents the occurrence probability in the orange area which can be determined by monte carlo integration in contrast for the r t pairs in the green area with t fd 10 only a portion is included by the read dash square and the miss alarm ratio is 20 1 p r r t t t fd t and 1 p and p o p fd where p fd is the occurrence probability in the green area since p fd p and 1 10 eq 20 can be reduced to p o p and which is equivalent to the false alarm ratio in eq 19 this phenomenon is statistically reasonable because when a percentage of the population are incorrectly sampled the same percentage of the population will be missed traditionally the or scenario is used to estimate the failure chance of a flood protection system designed for a specific rainfall or tide fig 11 compares the contour lines of 10 year return period for or and fd scenarios in which the r t pairs on the contour line with t or 10 year have t fd values larger than 10 years if an r t pair on the contour line of t or is selected as the thresholds for hydraulic design the over protection ratio is 21 p t fd t or r r t t p e p or where p or is the occurrence probability in the area bounded by the red dash lines p e represents the occurrence probability in the orange area in the green area with t fd 10 a portion of the r t pairs are not included in the area bounded by the red dash lines which leads to a ratio of under protection 22 1 p r r t t t fd t or 1 p or p e p fd since p fd p or 1 10 eq 22 can also be reduced to p e p or which is equivalent to the over protection ratio fig 12 a and fig 12 b show the ratios of incorrect alarm miss or false alarm and inaccurate protection over or under protection against fd with different r t conditions respectively although all the r t pairs in the figure are selected from the contour lines of 10 year return period under and or or scenario the flood risks are different for having different fd values this results in different levels of incorrect alarm and inaccurate protection for flood warning and hydraulic design respectively in fig 12 a when fd increases to 1 81 m the incorrect alarm ratio slightly decreases from 0 37 to a minimum value of 0 33 at the point with r 0 17 m and t 1 96 m in fig 12 b when fd decreases to 2 9 m the inaccurate protection ratio decreases rapidly to a minimum value of 0 14 at the point with r 0 45 m and t 2 07 m this implies that by selecting the r t pairs with the largest and smallest fds or cumulative flood probabilities under and and or scenarios the errors in flood warning and hydraulic design can be minimized respectively 5 discussions 5 1 novelty traditionally compound flood risk was often estimated by the joint exceedance probability of rainfall and tide under and o or scenario lian et al 2013 zheng et al 2014 zellou and rahali 2019 this results in bias because an event with a higher joint exceedance probability may instead have a lower flood risk and vice versa this phenomenon can be seen from the comparison between events 1994 and 2006 in table 1 in which the former with t and 3 06 and t fd 1 82 has a smaller t and but a larger t fd compared with the latter with t and 6 09 and t fd 1 54 using the fd scenario proposed in this study this kind of bias was systematically analyzed for the first time 5 2 impact in coastal areas flood warning and hydraulic design are often performed under specific r t conditions with an acceptable flood risk if the flood risk for a r t condition is overestimated but selected as a threshold for flood warning and hydraulic design the evacuation expenses and engineering damages will exceed the expectation because of high false alarms and failure chance respectively on the contrary if the flood risk is underestimated flood losses and engineering costs will exceed expectation because of high miss alarms and protection standards respectively although various algorithms were proposed in previous works xu et al 2014 sadegh et al 2018 moftakhari et al 2019 how to select the best r t thresholds has not reached an agreement owing to the limitation of using and and or scenarios in this study we used 10 year return period as a case study showing that incorrect alarms and inaccurate protections are significant and inevitable under the and and or scenarios but it can be minimized using the proposed approach to select the best r t thresholds 5 3 strength the approach proposed in this research can be used to obtain the realistic flood risk with limited data and computation resources the main reason is that all the statistical analysis and hydraulic simulations are performed based on historical events without the need to generate additional r t data through the usage of hydraulic simulation and multiple regression for determining the relationship between r t and d at the first place the flood risk can be directly calculated by monte carlo integration on the copula domain however in traditional monte carlo approaches purvis et al 2008 wang et al 2009 numerous r t samples must be generated for hydraulic simulation prior to flood risk estimation based on hypothetical rain hyetograph tide hydrograph and their phase combination this not only requires a lot of computation time but also results in inconsistency between statistical and hydraulic results due to the inclusion of hypothetical samples 5 4 applicability most of the bivariate flood risk models required the users to have professional knowledge about copula analysis and hydraulic simulation which limited the applicability in this study all information in the analysing phase has been incorporated into a hybrid cdf for estimating the flood risk under any r t condition which can be easily applied by users without relevant knowledge using the general framework proposed in this study localized hybrid cdfs can be established for the cities lian et al 2013 tanim and goharian 2021 estuaries moftakhari et al 2019 zellou and rahal 2019 and catchments zheng et al 2014 saharia et al 2020 in previous works based on their copula and hydraulic models the researchers can update the cdf when variables and parameters change which ensure the applicability and performance of the bivariate flood risk model at the same time 6 conclusions in coastal areas the joint probabilities of rainfall and tide are often used to estimate the risk of compound flooding under and and or scenarios however under the two scenarios there exist many pairs of rainfall and tide that can generate different flood magnitudes for a given return period this is attributed to the nonlinear influences of rainfall and tide on flood magnitudes and thus the flood risk cannot be determined only by the correlation of triggers in this study an innovative approach was proposed to estimate the realistic risk of compound flooding based on the fd scenario through the combination of copula analysis hydraulic simulation multiple regression and monte carlo integration for a coastal area in chiayi county taiwan the results are summarized as follows 1 for a given condition of rainfall and tide the return period estimated by the fd scenario is smaller than that by and scenario and larger than that by or scenario 2 incorrect alarms with equivalent false and miss alarm ratios and inaccurate protections with equivalent over and under protection ratios occur when and and or scenarios are used for flood warning and hydraulic design respectively 3 base on the fd scenario a hybrid cdf is established to determine the cumulative probability for any given flood depth which is expressed as a regression function of rainfall and tide in a nonlinear form 4 for flood warning and hydraulic design the hybrid cdf can be used to determine the best pair of rainfall and tide by maximizing and minimizing cumulative flood probabilities respectively declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by the ministry of science of technology grant number most 110 2625 m 006 006 the authors would like to thank the central weather bureau and the water resources agency for providing the research data 
3666,compound flooding caused by high rainfalls and tides may salinize the soil deteriorate the water quality and damage the ecosystems in coastal areas traditionally compound flood risk is estimated using the joint probabilities of a rainfall and a tide level when they are simultaneously or individually exceeded this results in bias because flood risk should represent the exceeding probability of a flood magnitude not of the triggers values in this study a new approach is proposed to determine the exceedance probability for a flood depth induced by the compound effects of rainfall and tide through the combination of copula analysis numerical simulation multiple regression and monte carlo integration a frequently flooded coastal area in chiayi taiwan was selected as the study subject the results show that realistic flood risk should range between the joint probabilities of rainfall and tide levels being simultaneously or individually exceeded thus when the joint probabilities are used to determine the thresholds of rainfall and tide for flood warning and hydraulic design the misestimation of flood risk will result in errors such as incorrect alarms and inaccurate protections with a ratio of 37 in a case study with 10 year return period these errors can be reduced using a hybrid cumulative probability function developed in this study for selecting the best rainfall and tide thresholds with local maximum or minimum cumulative flood probabilities the proposed approach is efficient and general so it can be promoted in different fields for risk assessment influenced by bivariate variables keywords compound flooding rainfall tide probability risk 1 introduction compound flooding in coastal areas caused by rainfall and tide has increased in recent years under climate change wahl et al 2015 bevacqua et al 2019 under high tide levels flood water contributed by seawater overflow or intrusion leads to soil salinization crop withering and infrastructure erosion triet et al 2020 yu et al 2021 under high rainfalls the sediments heavy metals organic compounds and pesticides washed down by surface runoff deteriorate water quality and damage the ecosystems in coastal areas zoppini et al 2019 paerl et al 2020 under the compound effects of high rainfalls and tides flood duration and extent increase and the impacts of individual factors are amplified hsiao et al 2021 to estimate the risk of compound flooding the analysis of rainfall tide correlation has become a crucial task in recent years the copula theorem proposed by sklar 1959 has been widely used to describe the joint probability of rainfall and tide in coastal areas compared with traditional bivariate models the copula is more convenient in its application because it establishes the joint cumulative distribution function cdf for multiple variables independently to marginal distribution structures xu et al 2014 used copula models to investigate the joint probability between rainfall and tide and showed that flood risk was increased by tide levels in fuzhou city located in a southeast coast of china zheng et al 2014 applied three copula models with different data selection methods to estimate the compound flood risk for the hawkesbury nepean catchment in australia zellou and rahali 2019 adopted a copula model to assess coastal flood risk at the estuary of the bouregreg river in morocco showing that the flood extents can be greatly underestimated without considering the correction between rainfall and tide once the copula models are determined hydraulic models are often used to simulate the flood hazards when specific rainfall and tide levels are exceeded simultaneously namely the and scenario or individually namely the or scenario lian et al 2013 applied the one dimensional 1d hec ras model to obtain the isolines of flood severity for the river system in fuzhou city under the and scenario zellou and rahal 2019 used the caesar lisflood model coulthard et al 2013 to predict the maximum flood extents in the bouregreg estuary of morocco for a 116 year joint return period event under the and scenario moftakhari et al 2019 combined a 1d steady shallow water equation and a two dimensional 2d hydraulic model to simulate the flooding for the estuaries in southern california affected by extreme tide levels and river discharges they found that the flood hazards defined by the or scenario were more conservative than those defined by the and scenario for a given joint return period saharia et al 2020 generated inundation maps with different return periods of seiche and flow under the and scenario through the integration of a hydrodynamic model hec ras and bivariate copula for the buffalo river basin next to lake erie new york tanim and goharian 2021 integrated a coastal hydrodynamic model delft3d and the storm water management model swmm to simulate the flood depth in the chittagong city next to bangladesh bay and adjusted the outputs according to uncertainty analysis based on a multivariate gaussian copula in the linkage between the copula and hydraulic models the fundamental question is how to select the best pair of rainfall and tide levels in forcing hydraulic models under the and or or scenario there exist many combinations of rainfall and tide levels which can generate different flood magnitudes for a specific joint return period this implies that the influence of rainfall and tide on flooding is nonlinear and the exceedance probability of a flood magnitude cannot be represented by the joint probability of rainfall and tide that triggers the flooding in other words the probability of compound flooding should be determined based on the flood magnitudes simulated from all rainfall tide pairs defined by a copula model not from a rainfall tide pair with a predetermined joint return period this can be realized through a monte carlo simulation which generates thousands of flood magnitudes for frequency analysis based on different pairs of rainfall and tide unfortunately the copula based monte carlo simulation requires many computations so it is mainly applied in 1d simulations currently yazdi et al 2014 peng et al 2017 for 2d problems such as compound flooding how to accurately and efficiently determine realistic flood risk through the linking of copula and hydraulic models remains an issue that has not been solved in this study a new approach is proposed to predict the realistic risk of compound flooding related to flood magnitudes considering the dependence between rainfall and tide unlike traditional monte carlo simulation methods the proposed approach is more efficient because it requires only a limited number of numerical simulations through the combination of multiple regression and monte carlo integration on a copula domain detailed comparisons are made to highlight the differences between the results predicted by the proposed method and those obtained from conventional and and or scenarios the findings in this research are valuable for flood disaster management in coastal areas 2 study area and data the study area is shown in fig 1 which is located in the coastal area of chiayi county taiwan belongs to the longgong river watershed and has an area of 260 km2 the area has a mean annual temperature of 21 24 and an average annual rainfall of 1 600 mm mostly concentrated between may and september the topography of the study area is very low lying 1 83 m in average due to land subsidence caused by decades long groundwater pumping for fish farming during high tides the water level in the channels exceeds the ground surface which reduces drainage efficiency and results in severe flooding whenever heavy rainfall occurs taking the flood event on august 23 2018 namely the 0823 event as an example the co occurrence of heavy rainfall and a high tide led to disastrous flooding that lasted for 5 days with an economic loss of 60 million us dollars in chiayi county in this study the observation data for 27 historical events from 1993 to 2019 recorded at donghouliao rain station and dongshi tide station were collected which can be obtained online via the hydrological information system of wra water resources agency 2021 for each year the time periods with maximum 24 hour rainfall amounts were pinpointed to obtain the maximum annual rainfall r and the highest tide level t for copula analysis in the same period as summarized in table 1 a discordancy test based on boxplots has been proceeded and no outliers were found among the selected historical data the highest value of r was 0 62 m or 620 mm recorded during the 0823 event in 2018 and the highest value of t was 2 26 m in 1996 the pearson correlation coefficient for r and t is 0 33 with a significance level of 0 05 indicating that there exists a moderate correlation between rainfall and tide to estimate the flood magnitudes under different r and t values the rainfall hyetographs and tide hydrographs for each event in table 1 were input as the boundary conditions to trigger a hydraulic model for flood depth and extent simulation 3 methodology this research uses three steps to calculate compound flood risk which are shown in different colors in the flowchart of fig 2 first for the 27 historical events the data of rainfall r and tide level t are collected and input for copula analysis and hydraulic simulation at the same time in the copula analysis the best fit marginal and copula distributions for r and t are determined in the hydraulic simulation the rainfall hyetographs and tide hydrographs are introduce to calculate the flood depths which are expressed as a function of r and t through multiple regression and with that a flood depth contour line can be determined for each historical event second combining the copula and regression function obtained in the previous step and monte carlo integration we calculate the cumulative flood probabilities for all events and establish a hybrid cdf for estimating compound flood risk based on flood depth scenario i e the fd scenario as described later third using the hybrid cdf the realistic flood risks are calculated and compared with those estimated based on and and or scenarios for evaluating the errors in flood warning and protection under specific return periods details are described as follows 3 1 bivariate copula analysis the copula is a cdf used to describe the correlation of multiple variables from the marginal probabilities of individual variables nelsen 2006 according to sklar s theorem 1959 the bivariate copula c 0 1 2 for r and t can be expressed as 1 f c r t c f r r f t t where f c is the joint cdf for r and t f r and f t are the marginal cdfs for r and t respectively the copula function c is a two dimensional distribution which satisfies the conditions c r 0 c 0 t 0 c r 1 r for r 0 1 c 1 t t for t 0 1 and c r 2 t 2 c r 2 t 1 c r 1 t 2 c r 1 t 1 0 for 0 r 1 r 2 1 and 0 t 1 t 2 1 the marginal distributions are univariate distributions that can be determined independently of the copula function in this study five univariate distributions including the normal lognormal gev weibull and gamma are compared to determine the most appropriate marginal distributions for rainfall and tide five bivariate copula models out of the archimedean family were selected for comparison including the clayton frank gumbel joe and plackett as defined in table 2 archimedean copulas were considered because they are better at describing r t correlations under high return periods zellou and rahali 2019 the parameters in the univariate and copula distributions were determined using the maximum likelihood estimation mle method in which the best fit distributions were selected based on parametric statistics according to their performance as evaluated by akaike information criteria aic akaike 1973 and bayesian information criteria bic schwarz 1978 2 aic 2 m 2 l n l 3 bic m ln n 2 l n l where m is the number of parameters l is the maximized likelihood value of the model the aic and bic consider the dependence of parameters without resulting in overfitting silva and lopes 2008 3 2 hydraulic model for hydraulic simulation the cos flow model coupled overland sewer flow model developed by jang et al 2018 2019 was adopted the cos flow model is a high precision flood model that combines a 2d overland flow module and a 1d channel flow module to simultaneously simulate surface runoff channel flow and their interactions the cos flow model was applied to simulate the 0823 event in the study area and showed a satisfactory level of accuracy in predicting the flood depth and extent of compound flooding hsiao et al 2021 the overland flow module solves the dynamic shallow water equations as below 4 h t u h x v h y q q a o 5 u t u u x v u y g h z x g u n x 2 u 2 v 2 h 4 3 q hg 6 v t u v x v v y g h z y g v n y 2 u 2 v 2 h 4 3 q hg where u and v are the flow velocities in x and y directions respectively h is the water depth q is the effective rainfall z is the elevation of bed topography n x and n y are the manning s coefficients in x and y directions respectively q represents the discharge received from the 1d module the alternate direction explicit method and the courant friedrichs lewy cfl restrictions courant et al 1967 were used to improve numerical accuracy and stability respectively the 1d channel flow module uses the implicit backward euler method ascher and petzold 1998 and the picard iteration method picard 1890 to solve the 1d dynamic shallow water equation 7 a t v a s q l 8 v a t v a s g a h s z s s n s 2 v v r 4 3 where a is the cross sectional area of flow in channels v is the flow velocity in channels r is the hydraulic radius h s denotes the flow depth in channels z s is the elevation of channel bottom and n s is the manning s coefficient in s direction by subtracting the infiltration obtained from the runoff curve number method nrcs 2004 the hyetographs of effective rainfall q can be determined and served as the upstream boundary conditions to initiate overland flow routing meanwhile the hydrographs of tide level were input as the boundary conditions of water elevation h z at the river estuaries in this study a structured mesh system with a grid size of 40 m was used and the grid center bed elevation z was interpolated from a lidar derived digital terrain model dtm with 1 m resolution to speed up the simulation the program codes were parallelized via the openmp open multi processing platform for multi core computers details about the cos flow model can be found in hsiao et al 2021 3 3 flood risk analysis traditionally the joint exceedance probabilities under and and or scenarios are used for flood risk estimation salvadori et al 2004 9 p and p r r t t 1 f r r f t t f c r t 10 p or p r r t t 1 f c r t where r and t are specific values for rainfall and tide respectively p and and p or are the joint exceedance probabilities for and and or scenarios respectively the p and is often adopted to estimate the return period for an extreme event with a specific pair of r and t whereas the p or is used to estimate the chance of failure for an hydraulic system designed under a specific value of r or t biondi and de luca 2017 although the concepts of and and or are widely used they may not actually represent flood risk because the p and and p or are related to rainfall and tide instead of their influence on flooding based on the concept of frequency analysis chow 1964 realistic flood risk should be the exceedance probability for a flood magnitude to occur not the joint probability of r and t that triggers the flood magnitude if flooding is only triggered by one variable the exceedance probabilities of flood magnitude and the variable can be quite similar but for compound flooding the flood risk may greatly deviate from the joint exceedance probability because the influence of r and t on flooding is nonlinear and associated with local conditions such as topography drainage and land use in this study the average flood depth fd simulated by the hydraulic model was used to represent the flood magnitude and the exceedance probability of fd can be expressed by the equation below 11 p d d 1 f d d where d is a random variable for fd d is a given fd f d is the cdf for fd since eq 11 determines the flood risk based on fd it is named the fd scenario hereinafter as a function of rainfall and tide fd can be expressed by d r t and f d d can be calculated using the following equation 12 f d d s c f r r f t t d s r t s where c f r r f t t is the best fit copula for r and t s is the area bounded by the contour line d r t d and the two axes of rainfall and tide in the schematic diagram fig 3 on the contour line all the r t pairs result in the same fd of d but the contributions of r and t are different through multiple regression the function d r t can be determined from the relationship between the d values simulated by the hydraulic model and the values of r and t for historical events in light of the complexity of the copula and regression functions analytical solutions may not always exist for f d thus the integration in eq 12 can be conducted numerically using monte carlo integration newman and barkema 1999 wang et al 2009 through the following steps 1 sample n random pairs of u 1 and u 2 based on the best fit copula distribution 2 determine the rainfall and tide values for each sample using r f r 1 u 1 and t f t 1 u 2 according to marginal distributions respectively 3 substitute the r and t values into d r t to determine the flood depth for each sample 4 calculate the value of m as the number of samples with a flood depth less than or equal to d 5 f d d m n where n is set as one million and the whole process is repeated for 100 times to obtain the mean value of f d d following the steps above the cumulative flood probability f d d can be determined for any d value and the function of f d can be determined through the fitting of univariate distributions unlike the copula and frequency analyses which uses aic and bic to select the best distribution the best fit cdf for f d is the one with the smallest root mean square error rmse since the population of cumulative flood probability for all d values have been obtained from the monte carlo integration in this study the multivariate copula analysis toolbox mvcat mathworks 2021a in matlab developed by hydroclimate research lab in university of california was adopted to construct the copula models and compute the return periods the statistics and machine learning toolbox mathworks 2021b in matlab was adopted for monte carlo integration to generate random data pairs from the selected copula distributions once the function of f d is determined the exceedance probability for fd resulting from a given r t pair can be expressed as f d d r t and then eq 11 can be modified as 13 p d d r t 1 f d d r t the return periods for and or and fd scenarios are defined as the reciprocals of exceedance probability respectively 14 t and 1 p r r t t 15 t or 1 p r r t t 16 t fd 1 p d d r t t and and t or estimate the joint return period of an r t pair regardless of flooding whereas t fd estimates the return period of fd caused by an r t pair by considering the nonlinearity among rainfall tide and flooding 4 results 4 1 copula analysis table 3 summarizes the goodness of fit for rainfall tide copula and fd distributions having relatively small aic and bic values the lognormal gamma and frank distributions were selected as the most appropriate distributions for rainfall tide and copula respectively fig 4 a and fig 4 b compare the empirical and five theoretical distributions for rainfall and tide respectively fig 5 a shows the cumulative probability for the frank copula and fig 5 b shows the joint probability density related to rainfall and tide with higher concentrations around r 0 2 m and t 1 5 m based on the copula analysis the marginal cumulative probabilities of rainfall and tide f r and f t respectively and the joint return periods for rainfall and tide under and and or scenarios t and and t or defined by eq 14 and 15 respectively were determined for each event as displayed in table 1 it can be seen that the two events in 1996 and 2018 possess the highest values of t and greater than120 year caused by extreme tide levels f t 0 99 and rainfall f r 0 99 respectively compared with t and the annual variation of t or is less sensitive 4 2 flood simulation to estimate fd under different r t pairs the rainfall hyetograph and tide hydrograph for the 27 events in table 1 were introduced into the cos flow model for hydraulic simulation two of the flood simulation results are illustrated in fig 6 a and fig 6 b for the events in 1996 and 2018 with extreme tides and rainfall respectively it is seen that the flood areas resulting from the extreme tides were more concentrated along the coast than those induced by the extreme rainfall to reflect the impacts of flood hazard the maximum water levels in the grids among roads residential industrial and commercial areas were averaged to obtain the fd for each event shown as the values of d in table 1 using nonlinear programming with an objective to minimize the rmse the function d r t can be regressed as below 17 d r t 10 31 r 3 07 0 29 t 2 65 the fds simulated by the hydraulic model and those predicted by eq 17 are in good agreement with r m s e 0 19 m and r 2 0 93 as shown in fig 7 the phenomenon d 0 0 0 indicates that eq 17 is physically reasonable because there is no flooding when both rainfall and tide equal zero when either r or t equals zero fd still increases with the other factor following a power law compared with tide rainfall has a higher influence on fd since the power of r is higher 4 3 flood risk analysis using the boundary contour line defined by eq 17 the monte carlo integration was proceeded on the copula domain to obtain the mean value of cumulative flood probability f d for each historical event with a standard deviation of 0 0001 as listed in table 1 once the f d is determined it can be related to d by fitting univariate distributions in table 3 the lognormal distribution was selected for having the smallest rmse value and the flood cdf can be described as 18 f d d r t 1 2 1 e r f l n d r t μ 2 σ where erf is the error function also called the gauss error function d r t is determined by eq 17 μ 0 16 and σ 0 51 are the coefficients determined by nonlinear programming with an objective to minimize the rmse with r m s e 0 003 m and r 2 1 the cumulative flood probabilities obtained by eq 18 perfectly coincide with those from monte caro integration without accounting for the error from eq 17 as shown in fig 8 unlike conventional distribution functions eq 18 is a hybrid form of cdf because it merges a bivariate function into a univariate cdf affected by hydraulic and topographical conditions the hybrid cdf of eq 18 may have different forms and parameters for different areas introducing eq 18 into eq 13 and eq 16 the value of t fd can be calculated and compared with the t and and t or for each event as listed in table 1 overall the return periods were largest for the and scenario medium for the fd scenario and smallest for the or scenario especially for extreme events taking the event in 2018 as an example the return periods were 127 29 2 10 and 49 02 years for the and or and fd scenarios respectively this means that event based flood risks i e the exceedance probabilities of fd were underestimated by the and scenario and overestimated by the or scenario fig 9 shows the contour lines of the return periods for the and or and fd scenarios in which the cycles represent the observed r t pairs of annual events in the figure each fd contour line is intersected by multiple and and or contour lines showing that the r t pairs resulting in the same t fd may have different t and and t or and vice versa the values of t and t or and t fd are compared in table 4 under different return periods of rainfall t r and tide t t since the frank copula is symmetric the values of t and and t or are symmetric against the diagonal axis when rainfall and tide have the same return period the t fd does not show such a symmetric pattern because rainfall and tide have uneven influences on fd overall t fd is more sensitive to rainfall than to tide at t t 2 year the value of t fd increases by 25 times from 1 86 to 48 88 when t r increases from 2 to 100 years in contrast at t r 2 year the value of t fd only increases by 11 times from 1 86 to 22 73 when t t increases from 2 to 100 years for a given r t pair the values of return period show great discrepancies with an increasing pattern from t or t fd to t and especially at high return periods for example the values of t or t fd and t and are equal to 50 92 445 88 and 2795 40 years at t r t t 100 year respectively this means that great biases happen in applications if the and and or scenarios are used for flood risk estimation 4 4 applications under a given return period the and scenario is often used to select a specific pair of r and t as thresholds for issuing flood warning which may result in errors from the aspect of fd scenario fig 10 compares the contour lines of 10 year return period for and and fd scenarios it is seen that all the r t pairs on the contour line with t and 10 year have t fd values smaller than 10 years if we select an r t pair on the contour line as the thresholds for flood warning the false alarm ratio can be expressed as 19 p t fd t and r r t t p o p and where p and is the occurrence probability in the area bounded by the red dash line p o represents the occurrence probability in the orange area which can be determined by monte carlo integration in contrast for the r t pairs in the green area with t fd 10 only a portion is included by the read dash square and the miss alarm ratio is 20 1 p r r t t t fd t and 1 p and p o p fd where p fd is the occurrence probability in the green area since p fd p and 1 10 eq 20 can be reduced to p o p and which is equivalent to the false alarm ratio in eq 19 this phenomenon is statistically reasonable because when a percentage of the population are incorrectly sampled the same percentage of the population will be missed traditionally the or scenario is used to estimate the failure chance of a flood protection system designed for a specific rainfall or tide fig 11 compares the contour lines of 10 year return period for or and fd scenarios in which the r t pairs on the contour line with t or 10 year have t fd values larger than 10 years if an r t pair on the contour line of t or is selected as the thresholds for hydraulic design the over protection ratio is 21 p t fd t or r r t t p e p or where p or is the occurrence probability in the area bounded by the red dash lines p e represents the occurrence probability in the orange area in the green area with t fd 10 a portion of the r t pairs are not included in the area bounded by the red dash lines which leads to a ratio of under protection 22 1 p r r t t t fd t or 1 p or p e p fd since p fd p or 1 10 eq 22 can also be reduced to p e p or which is equivalent to the over protection ratio fig 12 a and fig 12 b show the ratios of incorrect alarm miss or false alarm and inaccurate protection over or under protection against fd with different r t conditions respectively although all the r t pairs in the figure are selected from the contour lines of 10 year return period under and or or scenario the flood risks are different for having different fd values this results in different levels of incorrect alarm and inaccurate protection for flood warning and hydraulic design respectively in fig 12 a when fd increases to 1 81 m the incorrect alarm ratio slightly decreases from 0 37 to a minimum value of 0 33 at the point with r 0 17 m and t 1 96 m in fig 12 b when fd decreases to 2 9 m the inaccurate protection ratio decreases rapidly to a minimum value of 0 14 at the point with r 0 45 m and t 2 07 m this implies that by selecting the r t pairs with the largest and smallest fds or cumulative flood probabilities under and and or scenarios the errors in flood warning and hydraulic design can be minimized respectively 5 discussions 5 1 novelty traditionally compound flood risk was often estimated by the joint exceedance probability of rainfall and tide under and o or scenario lian et al 2013 zheng et al 2014 zellou and rahali 2019 this results in bias because an event with a higher joint exceedance probability may instead have a lower flood risk and vice versa this phenomenon can be seen from the comparison between events 1994 and 2006 in table 1 in which the former with t and 3 06 and t fd 1 82 has a smaller t and but a larger t fd compared with the latter with t and 6 09 and t fd 1 54 using the fd scenario proposed in this study this kind of bias was systematically analyzed for the first time 5 2 impact in coastal areas flood warning and hydraulic design are often performed under specific r t conditions with an acceptable flood risk if the flood risk for a r t condition is overestimated but selected as a threshold for flood warning and hydraulic design the evacuation expenses and engineering damages will exceed the expectation because of high false alarms and failure chance respectively on the contrary if the flood risk is underestimated flood losses and engineering costs will exceed expectation because of high miss alarms and protection standards respectively although various algorithms were proposed in previous works xu et al 2014 sadegh et al 2018 moftakhari et al 2019 how to select the best r t thresholds has not reached an agreement owing to the limitation of using and and or scenarios in this study we used 10 year return period as a case study showing that incorrect alarms and inaccurate protections are significant and inevitable under the and and or scenarios but it can be minimized using the proposed approach to select the best r t thresholds 5 3 strength the approach proposed in this research can be used to obtain the realistic flood risk with limited data and computation resources the main reason is that all the statistical analysis and hydraulic simulations are performed based on historical events without the need to generate additional r t data through the usage of hydraulic simulation and multiple regression for determining the relationship between r t and d at the first place the flood risk can be directly calculated by monte carlo integration on the copula domain however in traditional monte carlo approaches purvis et al 2008 wang et al 2009 numerous r t samples must be generated for hydraulic simulation prior to flood risk estimation based on hypothetical rain hyetograph tide hydrograph and their phase combination this not only requires a lot of computation time but also results in inconsistency between statistical and hydraulic results due to the inclusion of hypothetical samples 5 4 applicability most of the bivariate flood risk models required the users to have professional knowledge about copula analysis and hydraulic simulation which limited the applicability in this study all information in the analysing phase has been incorporated into a hybrid cdf for estimating the flood risk under any r t condition which can be easily applied by users without relevant knowledge using the general framework proposed in this study localized hybrid cdfs can be established for the cities lian et al 2013 tanim and goharian 2021 estuaries moftakhari et al 2019 zellou and rahal 2019 and catchments zheng et al 2014 saharia et al 2020 in previous works based on their copula and hydraulic models the researchers can update the cdf when variables and parameters change which ensure the applicability and performance of the bivariate flood risk model at the same time 6 conclusions in coastal areas the joint probabilities of rainfall and tide are often used to estimate the risk of compound flooding under and and or scenarios however under the two scenarios there exist many pairs of rainfall and tide that can generate different flood magnitudes for a given return period this is attributed to the nonlinear influences of rainfall and tide on flood magnitudes and thus the flood risk cannot be determined only by the correlation of triggers in this study an innovative approach was proposed to estimate the realistic risk of compound flooding based on the fd scenario through the combination of copula analysis hydraulic simulation multiple regression and monte carlo integration for a coastal area in chiayi county taiwan the results are summarized as follows 1 for a given condition of rainfall and tide the return period estimated by the fd scenario is smaller than that by and scenario and larger than that by or scenario 2 incorrect alarms with equivalent false and miss alarm ratios and inaccurate protections with equivalent over and under protection ratios occur when and and or scenarios are used for flood warning and hydraulic design respectively 3 base on the fd scenario a hybrid cdf is established to determine the cumulative probability for any given flood depth which is expressed as a regression function of rainfall and tide in a nonlinear form 4 for flood warning and hydraulic design the hybrid cdf can be used to determine the best pair of rainfall and tide by maximizing and minimizing cumulative flood probabilities respectively declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by the ministry of science of technology grant number most 110 2625 m 006 006 the authors would like to thank the central weather bureau and the water resources agency for providing the research data 
3667,excessive groundwater pumping exacerbates aquifer depletion and poses a major threat in regions all around the world that already suffer from overuse or climate change in this situation accurate and reliable predictions of long term aquifer water balances are key prerequisites to manage groundwater sustainably compared to spatially explicit numerical models lumped hydrological models are computationally fast lean on data requirement and more accessable for quantifying uncertainty however lumped hydrological models are mainly designed to simulate river discharge only not aquifer storage consequently calibration only includes stream flow data in this study we hypothesize that we can extend a lumped hydrological models here hbv towards a lumped geohydrological model lghm by additional designated terms for water budget and groundwater storage the model building is inspired by the geometry and hydrogeological large scale properties of the catchment s aquifers underground flow routing resembles major groundwater flow paths the model is calibrated and evaluated on both groundwater storage data and surface discharge data we apply our lghm to a modflow based virtual reality describing the unconfined wairau plain aquifer new zealand we consider and discuss specifically river groundwater exchange processes long term forecast of aquifer storage dynamics and groundwater depletion in a hypothetical persistent drought our model evaluation shows very plausible predictive capabilities in 40 year forecasts with synthetic weather time series and several years of groundwater depletion in the extreme drought case keywords water management long term water balance conceptual groundwater model 1 introduction groundwater use covers about one third of the global fresh water demand due to continuously increasing demand e g chen et al 2016 and climate change the risk of groundwater exploitation and depleting aquifers persists putting water resources at risk e g gorelick and zheng 2015 in order to counteract this so called tragedy of commons hardin 1968 sustainable groundwater management needs proper attention hydrologic budgets land use and irrigation require sustainable management strategies e g von gunten et al 2015 in this context model based simulations help to understand and investigate internal hydrosystem responses such as runoff from catchments e g wagener et al 2004 or the total aquifer water budget e g jaani 1996 and hence to make useful predictions about the future under changing conditions e g wagener and gupta 2005 currently many hydrological models exist varying according to temporal and spatial scale as well as complexity as listed in knoben et al 2019 to ensure a sustainable use of water resources decision makers are interested in future states of hydrological systems and specific predictions at different scales the choice of the model depends on the model purpose and also on other factors like data availability and computational power lumped conceptual rainfall runoff models are suitable to efficiently simulate the surface runoff response to rainfall at the catchment scale or at the sub catchment scale yet at the cost of an immense simplification of subsurface flow however we can also estimate subsurface storage from the models of this type examples are vic liang et al 1994 hymod moore 1985 gr4j edijatno et al 1999 hbv bergström 1995 the tank model sugawara and fuyuki 1956 and the sacramento model with soil moisture accounting sac sma buchtele et al 1996 burnash et al 1973 to integrate both surface and subsurface flow distributed hydrologic or spatially explicit integrated physically based flow models are a typical choice one example is modflow harbaugh 2005 which includes surface water routing swr process hughes et al 2012 to perform surface water routing as well as surface water groundwater interaction another example is feflow trefry and muffels 2007 for only sub surface processes but it can be coupled with surface water packages like mike 11 thompson et al 2004 via ifmmike11 monninkhoff 2014 plug in mike she abbott et al 1986 abbott et al 1986 is another coupling option to obtain a fully integrated hydrological modeling system to simulate surface water flow and groundwater flow there are also possibilities for regional to global scale investigations by using 3 dimensional physical based models like parflow ashby and falgout 1996 kollet and maxwell 2006 and hydrogeosphere therrien and sudicky 1996 such models are suitable to account for future water demands in response to socioeconomic development and climate change on very large scales such as in cwatm burek et al 2020 such physically based models are suitable for accurately estimating internal variables and states such as groundwater heads and total aquifer storage compared to lumped conceptual models physically based models consider spatial variability of state variables and represent hydrological processes and their interaction refsgaard and knudsen 1996 however to investigate changes in hydrological systems due to human interaction and climate change these physically based models require large input data related to topography landuse soil and subsurface properties as well as climatic attributes leavesley 1994 goodarzi et al 2014 chen et al 2016 many of these parameters require calibration there are many data scarce regions like in developing countries where operation and maintainance of data aquisition is infeasible due to high costs or lack of personnel and infrastructure the computational effort alone is a major hindrance to solve large scale problems at fine temporal and spatial resolution fatichi et al 2016 and makes long term forecasts with quantified uncertainty computationally very demanding conceptually existing lumped conceptual hydrological models are mostly used to simulate as well to calibrate on catchment runoff processes based on rainfall evaporation and so called slow and fast runoff processes kim et al 2018 azizian and shokoohi 2019 razmkhah 2016 jin et al 2010 rezaeianzadeh et al 2013 bhattacharjya and chaurasia 2013 they are fast and lean on input data requirement representing the hydrological system in a fixed framework of conceptual stores like in gr4j perrin et al 2003 or by more flexible toolbox configurations like in superflex fenicia et al 2011 summa clark et al 2015 and raven craig et al 2020 these more flexible frameworks allow to configure different model structures including sub surface stores in some lumped conceptual models sub surface storage can be further differentiated into a soil and an aquifer storage like the production and the routing store in gr4j all such lumped models and toolboxes are mostly calibrated on river discharge and less attention is given to simulate sub surface dynamics like groundwater storage yet these lumped conceptual models can be calibrated and validated on their slow groundwater components that may resemble groundwater storage seibert 2000 used groundwater heads as additional data along with runoff while calibrating hbv in order to constrain ranges of model parameter values others investigated the decline of model storage in a long term drying climate by using five different lumped conceptual rainfall runoff models fowler et al 2020 used groundwater heads and gravity recovery and climate experiment grace satellite groundwater storage information tapley et al 2004 along with runoff data the problems faced there were the scarcity of piezometric wells unknown specific yield and storage volume of an aquifer and the coarse temporal resolution additionally the grace data with 400 km has very coarse spatial resolution andermann et al 2012 estimated groundwater storage by considering internal model storage states but calibrated gr4j and gr2m mouelhi et al 2006 only on river discharge data of daily and monthly timescale their focus was to determine the role of groundwater storage in the hydrological cycle lecocq et al 2017 calibrated gr4j only on river runoff to estimate groundwater storage and transformed it to pressure head by considering an apparent 3 porosity based on their hosting linestone aquifer the purpose of their study was to demonstrate the ability of ambient seismic noise to determine the changes in near subsurface characteristics however in all these studies aquifer geometry and subsurface properties were not directly used to foster a hydrogeologic interpretation of subsurface properties and aquifer exchange rates or to constrain their calibration also no explicit validation was performed to estimate the potential benefit from adding the used hydrogeologic data during calibration we fill this gap by considering groundwater stores and exchange fluxes together with streamflow throughout the whole modelling process to summarize in previous hydrological modelling studies less attention was given to incorporate the sub surface flow and storage components of catchments the subsurface storage implied by respective slow model components was seldomly validated or even not at all making the use of hydrogeological information for additional calibration of lumped models a largely unexplored field we will deliberately focus on these aspects to estimate both river discharge and groundwater storage within the study domain semi distributed models like topmodel beven and kirby 1979 and swat arnold et al 1998 depict a compromise between lumped and spatially explicit integrated numerical models such models accept both averaged and distributed input parameters and runoff is estimated at each sub catchment however such models are less flexible in integrating additional components for groundwater storage and they are more data intensive and more computationally demanding than lumped conceptual rainfall runoff models considering the features advantages and disadvantages of these model classes the identified research gap is to find a model that has the advantages of lumped conceptual rainfall runoff models but additionally incorporates sub surface properties and catchment behaviour we hypothesize that lumped conceptual hydrological models can be used for long term groundwater predictions under the following conditions if the model is extended by few well selected water budget terms if the model is calibrated by not only using discharge data but also using groundwater storage data if geohydrological information is used in the model to incorporate physical properties of the subsurface if the physical features of the hydrological system are conceptualized in the model e g conceptualization of recharge zones aquifers groundwater flow paths and heads the plausibility of our hypothesis rests on the integration of designated storage terms that are informed by aquifer scale geohydrological properties of course the choice of the model structure depends on individual judgement experience and preference e g addor and melsen 2018 and it is well known that model structural errors introduced during such an upgrade of model complexity could lead to misleading model results höge et al 2018 however the information related to aquifer properties and geometry helps to reduce such errors additionally the volume of groundwater loss is difficult to estimate in case of missing geologic information zaki et al 2019 but one can exploit that hydrological processes are coupled and hence water balance equations can be calibrated on surface and subsurface components together we hypothesise that the long term predictions of internal responses such as groundwater storage are possible without compromising other water budget terms we test our hypothesis by presenting a lumped geohydrological model lghm which is an extension of the existing hbv lumped conceptual model bergström 1995 in this proof of concept to avoid the problem of lack of data when testing validating our new model we use an already existing modflow model for a selected study region wöhling et al 2018 as a virtual reality our real world application is the unconfined wairau aquifer in the blenheim region new zealand our lghm is calibrated and validated against the modflow model of the wairau aquifer which in turn has been calibrated against real data further we test our lghm against modflow by scenario simulation under severe drought conditions and compare both models for plausibility of long term simulations our main contribution is that our new lghm approach includes hydrogeological information of major aquifers dedicated storage boxes and a darcy like subsurface flow routing allowing for calibration on discharge and storage related data to perform long term forecasts of aquifer storage the lumped geohydrological modelling approach presented in this paper will help modelers and decision makers to quantify and predict aquifer water budgets yet the computational and model input data requirement is strongly reduced as compared to physically based hydrogeological models this allows for an increase of hydrologic system coverage as compared to traditional lumped models and it is easier to develop and operate than semi distributed models this paper is organized as follows section 2 contains material and methods adressing lghm modelling philosophy study area the modflow model as synthetic reality model development parameter ranges calibration criteria model performance metrics and our model testing strategy section 3 presents results of model calibration and model tests and their discussion finally in section 4 we conclude on our lghm hypothesis and summarize new research questions to pursue with this model class 2 materials and methods 2 1 lumped geohydrological modelling philosophy the goal of our lumped geohydrological models lghm is to fully account for the processes covered in lumped hydrological models but also for groundwater storage major flow paths and their dynamics as is described in section 2 4 thus given a study area the aquifer is divided into different stores these stores are based on geological information and they interact with each other via major groundwater flow paths from one store to another these flow paths are selected based on their suitability to define total spring discharge and groundwater storage and also justified according to the prevailing geology as a consequence a lghm must be calibrated to and will predict not only outlet discharge but also groundwater storage and therefore can be and has to be validated on both the time periods of calibration and validation in our proof of concept case are described in the next section 2 2 the geological information related to large scale aquifer properties helps the modeler to simulate groundwater storage with more insight to the subsurface conditions in specific hydrogeological properties of subsurface lithological assemblies define the major groundwater storage units and subsurface flow routing mechanisms these properties include total aquifer volume porosity hydraulic conductivity and to some degree spatial arrangement and geometry it is possible to include such models into lumped models with characteristic hydrogeological time scales e g by informing recession coefficients or the hydrograph time base in gr4j as a consequence for building such a lghm geological understanding is important to characterize a hydrological system and to justify the required conceptualization of groundwater storage and flow paths therefore the fundamental approach to build a lghm is to start with a hydrogeological not just hydrological conceptualization of the catchment and its aquifers see section 2 2 this conceptualization for subsurface hydrogeology follows the same principles as for surface hydrology 2 2 site description the study area is part of the wairau river catchment 3430 km 2 in the marlborough district in the northern part of the south island new zealand as depicted in fig 1 the wairau aquifer study domain lies in a flood plain close to the coast of the pacific ocean and has a modelled area of 84 8 km 2 the major land use of the study area is irrigated vineyards and groundwater pumping is the main source of irrigation water the unconfined wairau aquifer is an important resource of drinking water and irrigation water supply in and around blenheim city the average annual precipitation is 650 mm and the mean annual temperature is 12 8 c wöhling et al 2018 this study area has already been extensively investigated by wilson and wöhling 2015 wöhling et al 2018 wöhling 2019 wöhling and burbery 2020 and wöhling et al 2020 the main characteristics of the site are summarized from these studies and we refer to the studies cited above for further details long term daily flow measurements of the wairau river are available at barnetts bank near the sh1 bridge fig 1 the rapaura formation of the wairau aquifer subsequently refered to as wairau aquifer for brevity is mainly recharged by the river thus river recharge is an important variable for groundwater storage the total storage volume v in the wairau plain aquifer is approximately 310 mio m 3 estimated from average porosity aquifer volume from the geological model and highest groundwater heads observed in 2002 wöhling 2019 wöhling et al 2020 recently reviewed groundwater monitoring records and aquifer test data suggest that the aquifer permeablity is highly anisotropic wilson 2016 the gravels of the unconfined aquifer are highly conductive and mean residence times are estimated to be less than 1 year wöhling et al 2018 morgenstern et al 2019 hence the aquifer essentially acts as an extension of the wairau river due to the highly conductive nature of the aquifer river recharge and surface recharge become shallow groundwater with little time delay on the eastern side of the wairau plain the aquifer becomes increasingly confined and at the fringes of the confinement groundwater emerges at the surface as springs in accordance to previous modelling efforts five springs and streams are considered in the model domain wöhling et al 2018 the northern drain nd discharges into the wairau river whereas the spring creek is divided into the eastern sc1 and western sc2 part the southern streams ss are distinguished by the eastern o paoa river or1 and the western o paoa river or2 sc1 is the largest spring with a share of more than half of the flow of all the emerging springs there are four permanently monitored groundwater wells enumerated as 3009 3821 3954 4577 fig 1 and several temporary wells installed and monitored by the marlborough district council previously the lithology of the wairau aquifer has been intensively investigated brown 1981a brown 1981b raiber et al 2012 wilson and wöhling 2015 according to the recent stratigraphy review of the rapaura formation that forms the shallow unconfined wairau aquifer wilson 2016 three lithological layers are identified the base of the unconfined aquifer is considered to be the impermeable speargrass formation the rapaura formation has a maximum thickness of about 30 to 35 m its lowest member contains highly permeable gravels of 9 5 5 m thickness above the speargrass formation above it rest low permeable clay rich gravels with 3 9 m thickness the upper member 8 3 m thickness consists of high permeability gravels towards the coast the aquifer is increasingly confined by the low permeability dillion s point formation the different hydrogeological units were implemented in a spatially explicit modflow model of the unconfined wairau plain aquifer wöhling et al 2018 their fig 5b see also section 2 3 it was found that the hydrological units mentioned above are important to simulate the dynamics of groundwater flow aquifer storage as well as spring flows other hydrogeological features not included in the spatially explicit modflow model are small scale near surface features such as the historical o paoa stream channel within the upper rapaura formation wilson 2016 the data used to drive modflow and our lghm model includes time series of wairau river flow at barnetts bank a site slightly upstream of the old gauging station at the state highway 1 bridge sh1 fig 1 groundwater abstraction land surface recharge and groundwater heads storages the time period between october 31 2013 and may 12 2016 is used for calibration the time period between may 13 2016 and february 20 2017 is used to validate the lghm model concept 2 3 synthetic reality modflow model for proof of concept of our lghm concept and in order to have access to unlimited and gap free data we use the modflow nwt niswonger et al 2011 surface water groundwater model that was already developed wöhling et al 2018 for our study area as a virtual reality the transient spatially explicit numerical modflow model was developed to understand and quantify the river groundwater recharge mechanisms in new zealand s gravel bed rivers the model contains four vertical hydrogeological layers the spatial variability in hydraulic conductivity within the three rapaura formation layers is specified using a pilot point parameterization scheme the computational grid of the modflow domain and the cross section view of geologic layers are shown in fig 2 a b it consists of three geologic layers with 6360 active cells and the size of each cell is 200 200m the simulation time period for this modflow model is between july 01 2013 and february 20 2017 with 123 days as spin up period before model simulations on july 01 2013 for further details on the modflow model the reader is referred to wöhling et al 2018 2 4 model development our model development partially employs the same routines as the orignal hbv model bergström 1995 hbv contains three routines i e snow accumulation and melt soil moisture accounting and the response function and river routine for coupling the hydrologic routines to the subsurface dynamics we use the rushton model rushton et al 2006 to estimate land surface recharge q rec m 3 s 1 and groundwater extractions q well m 3 s 1 for each of the nine major wairau soil types these estimates are taken from a previous study wöhling et al 2018 the rushton model is based on the soil moisture balance concept and contains three main components 1 infiltration to the soil zone and near surface soil storage 2 actual evapotranspiration and 3 soil moisture deficit and recharge the total available water taw values are taken from the new zealand fundamental soil layer database landcare research 2000 the readily available water for vineyard grapes is assumed to be 45 of taw there will only be groundwater recharge when soil moisture is in excess corresponding to the vertical structure of the wairau aquifer our model structure consists of three conceptual stores named as soil box upper store and lower store the latter will be spatially subdivided later below in our modelling framework the soil box resembles the rushton model domain as shown in fig 3 and the upper and lower stores interact with the wairau river first we discuss the interaction with the wairau river groundwater recharge in the study area is dominated by exfiltration from the wairau river the river recharge can be modeled as linear non linear or a combination of both rushton and tomlinson 1979 such lumped approaches have been used in the absence of knowledge about process of parameter detail which is particularly the case in braided rivers such as investigated here there is poor understanding of the small scale details of surface water groundwater exchange mechanisms in braided rivers wöhling et al 2018 wöhling et al 2020 from the relationship between wairau river discharge q riv t m 3 s 1 and modflow river groundwater exchange flux q ex m 3 s 1 we have found that a power law function fits best see fig 15 in appendix a 2 therefore we use a power law relationship between q riv t and q ex t in our lghm note that this is a simplification of the approach used in wöhling and burbery 2020 q ex t is the main driving force in the model and is estimated through calibrating the power law parameters in eq 1 additionally our reasoning for choosing a power law relation is that the exchange flux is related to the wetted area of the river channel and thus to river stage and flow this wetted area follows a typical rating curve which is often modelled as a power law petersen øverleir 2005 this power law equation is further discussed in section 2 5 1 q ex t α 1 q riv t α 2 0 α 2 1 0 α 1 q riv 1 α 2 where t day represents the time coordinate and α 1 and α 2 are the coefficients of the power law equation and q riv million m 3 d 1 is the mean wairau river discharge between between 2000 and 2016 in the model all fluxes e g q ex q riv are in units of million m 3 d 1 but we will report them in units of m 3 s 1 for easier interpretation the parameter α 2 controls the curvature of the power law based on the intuition and relation of rating curves we want q ex to be increasing with increasing q riv yet with a slope that does not increase with river flow q riv thus the lower and upper limits for α 2 are zero and one respectively the other parameter α 1 controls the overall magnitude of the exchange flux as a multiplier the lower limit of zero ensures a net loss of river water into the aquifer for the upper limit we argue that the wairau river can not lose more water than what it has i e q ex q riv when reformulating this for the upper limit of α 1 we obtain that α 1 q riv 1 α 2 the upper store fig 3 is described next the upper store with stored volume s vz t million m 3 resembles shallow groundwater and it takes daily surface recharge q rec t million m 3 d 1 and q ex t from the river it loses percolation q perc t million m 3 d 1 to the lower store and a fast component q vz 1 t million m 3 d 1 and an intermediate component q vz 2 t million m 3 d 1 to spring creek discharge similarly to the orignal hbv q perc t q vz 1 t and q vz 2 t are estimated by using eqs 3 5 in and outflows of the upper store between times t 1 and t are calculated explicitly via 2 s vz t s vz t 1 q rec t q ex t q perc t δ t 3 q perc t s vz t 1 k d 4 q vz 1 t k 1 s vz t 1 uzl 5 q vz 2 t k 2 s vz t 1 here δ t is the time step duration k 1 day 1 is the recession coefficient for the fast runoff component q vz 1 t and uzl million m 3 is the threshold parameter for the upper store as in hbv q vz 1 t is generated only during floods when the storage in s vz t exceeds uzl k 2 day 1 is the recession coefficient for the intermediate runoff component q vz 2 t as in hbv k d day 1 is the coefficient for percolation q perc t to groundwater storage as in hbv in accordance to the conceptual understanding of the wairau aquifer the lghm contains four sequential lower stores with stored volumes s gw 1 t s gw 2 t s gw 3 t and s gw 4 t all in units of million m 3 and their characteristics are shown in table 1 each lower store contains it s own recession coefficient and they are calibrated along with other model parameters as shown in table 3 section 2 6 to conceptualize these four lower stores fig 3 we consider that the groundwater levels decrease from s gw 1 to s gw 4 these four lower stores fig 3 have their individual volume as upper limit and each one has its own water level as each lower store corresponds to a specific section of the aquifer each one has its own values of surface area a km 2 aquifer thickness t m and hydraulic properties like specific yield s y the values of t and s y are spatial averages over the corresponding sections table 2 shows the average thickness t and hydraulic conductivity k h values of three geologic layers corresponding to these four lower stores these properties of an aquifer tables 1 and 2 are obtained from geological investigations in our study area and have already been used in wöhling et al 2018 wöhling 2019 wöhling et al 2020 the lower stores are set up such that their areas add up to the total surface area 84 8 km 2 of the model domain and their volumes to the total aquifer storage volume 310 mio m 3 the storage capacity of each store is estimated by taking the product of average effective water thickness t wa m of the entire aquifer and their surface areas t wa is estimated by dividing the total aquifer storage volume by the total aquifer area now we model the flows into and among these stores the function of each lower store is the same as that of s vz t however there is exchange of groundwater flow between stores depending on the hydrogeologic units q perc t from the upper store is distributed to the first three lower stores s gw 1 s gw 2 s gw 3 depending on the calibrated parameters p 1 p 2 and p 3 as shown in fig 3 according to the geological settings the fourth store s gw 4 is considered confined due to the impervious dillions point formation on top so it receives no recharge in conditions when the storage in a groundwater store reaches its upper storage limit the entire excess volume q exc t m 3 s 1 flows to the next store downstream this q exc between lower stores is only expected in extreme and seldom cases when aquifer is already full and there is excessive groundwater recharge the downstream routing is justified because our study area has sloping terrain with 2 7 wöhling et al 2018 along the wairau river and the aquifer materials are highly conductive for the confined store s gw 4 q exc t is routed directly to the discharge which in our case is the total spring discharge q out million m 3 d 1 the actual daily groundwater abstraction from wells within the model domain is unknown therefore the total groundwater extraction q well for the whole study area was estimated by a distributed version of the rushton model wöhling et al 2018 and is also used in our calculations to extract groundwater from each store q well is divided 4 parts according to the percentage areas of the individual lower stores overall if one desires interpretation of these four lower stores they can be seen as a four cell groundwater flow model that is already simplified to unidirectional flow from each lower store to its downgradient eastern neighbours based on the overall slope of the terrain and based on the regional direction of groundwater flow in summary the equations for the four groundwater stores are beginning with s gw 1 6 s gw 1 t s gw 1 t 1 q gw 1 t q perc t p 1 q well 1 t a 1 qexc s 21 s 22 t δ t where s gw 1 t and s gw 1 t 1 are the storages in the first groundwater store at current and previous time step q gw 1 t is the discharge from s gw 1 to the spring discharge outlet at q gw q perc t is the volume of flow percolating from the upper to the groundwater store p 1 denotes the percentage percolation from s vz into s gw 1 q well 1 t is the groundwater extraction from s gw 1 t through pumping wells a 1 is the percentage of surface area representing s gw 1 t and qexc s 21 s 22 t is the excess volume flow from s gw 1 to s gw 2 correspondingly the equations for s gw 2 s gw 3 s gw 4 are 7 s gw 2 t s gw 2 t 1 q gw 2 t q perc t p 2 q well 2 t a 2 qexc s 21 s 22 t qexc s 22 s 23 t δ t 8 s gw 3 t s gw 3 t 1 q gw 3 t q perc t p 3 q well 3 t a 3 qexc s 22 s 23 t qexc s 23 s 24 t δ t 9 s gw 4 t s gw 4 t 1 q gw 4 t q gw 2 t q gw 3 t q well 4 t a 4 qexc s 23 s 24 t qexc s 24 q out t δ t s gw 4 represents the confined part of the aquifer and there is no direct recharge from the land surface the groundwater components leaving the respective groundwater stores are 10 q gw i t k 3 i s gw i t 1 here q gw i million m 3 d 1 denotes the slow runoff or groundwater flow from groundwater saturated stores i enumerates the four groundwater stores and k 3 i day 1 are the recession coefficients for the corresponding slow runoff components the groundwater flow routing between these groundwater stores and emerging springs as total outlet discharge is inspired by the major flow routes in the model domain the runoff from each groundwater store affects the dynamics of the total spring discharge from the wairau aquifer this leads us to the following routing q gw 1 t emits from s gw 1 t and becomes input to q out q gw 2 t and q gw 3 t become input to s gw 4 t whereas q vz 1 t q vz 2 t and q gw 4 t contribute directly to q out fig 3 provides a conceptual plot of these flow paths overall the total spring discharge q out is the sum of fast and slow components q vz 1 t and q vz 2 t from s vz the selected groundwater flows q gw 1 t and q gw 4 t qexc s 24 q out t from s gw 4 and deep groundwater losses q df m 3 s 1 towards the coast 11 q out q vz 1 t q vz 2 t q gw 1 t q gw 4 t q exc s 24 q out q df where q exc s 24 q out is the excessive flow volume from s gw 4 t into q out q df is the deep groundwater flow as a constant flux boundary condition with a constant value of 0 0604 10 6 m 3 s 1 estimated from spring flows in grovetown lagoon wöhling et al 2018 wöhling et al 2020 with this our model conceptualization is complete the data required by lghm as model inputs and its outputs are summarized in appendix a 1 2 5 model parameter and their ranges the lghm contains eleven calibration parameters out of thirteen free model parameters in total the eliminated parameters are k d day 1 and p 2 which represents the percentage percolation from s vz into s gw 2 the wairau aquifer contains highly conductive gravels and surface recharge is assumed to become groundwater without significant delay thus k d is fixed to k d 1 each calibration parameter with its description unit and lower and upper bounds are summarized in table 3 in the following we describe hydro geo logical reasoning to obtain admissable ranges during calibration as presented in section 2 4 the aquifer is represented by 4 linear reservoirs in which the outlet discharge is controlled by recession coefficients units of day 1 that describe characteristic residence times of water in these stores as in hbv the value of these coefficients must be between 0 and 1 day 1 according to the model physics but can be chosen more narrowly in this study the upper and lower limits of the recession coefficients table 3 are taken from parameter ranges already used in previous studies seibert 2000 abebe et al 2010 seibert and vis 2012 dakhlaoui et al 2012 rusli et al 2015 the range of the upper reservoir threshold uzl is fixed between 0 and 30 million m 3 due to the highly transmissive nature of the aquifer wöhling et al 2018 it is considered that in a case of flood events the maximum storage in the upper reservoir will be 30 million m 3 there are two coefficients α 1 α 2 of the power function to estimate q ex t the reason for taking the upper and lower limits of these coefficients is already explained in section 2 4 the percolation percentages p 1 p 2 and p 3 must individually fall between 0 and 1 and must sum up to one according to the hydrogeological conditions s gw 1 and s gw 2 take large parts of percolation as input s gw 3 takes the least contribution whereas s gw 4 is confined with an impervious layer on top to ensure this distribution of percolation we calibrate p 1 and p 3 subject to the constraints and p 2 is fixed to p 2 1 p 1 p 3 as shown in table 3 this way of calibration helps to reduce one more parameter without compromising over the quality of model results the old o paoa channel as shown in fig 5 of wilson 2016 is starting within the vicinity of the s gw 1 area and its high yielding gravels are also in direct contact with the wairau river at this location therefore we have taken a larger upper limit for p 1 0 75 as compared to p 3 0 25 2 6 parameter calibration the model is calibrated by minimizing the weighted sum of squared errors between given and simulated time series the calibration time period in our lghm is the same as in the calibrated modflow model wöhling et al 2018 that acts as a virtual reality with 917 daily time steps of spring discharge and aquifer storage in this study initial conditions are given to the lghm by spin up simulations between january 01 2000 and june 30 2013 the initial conditions are specified as full storage i e 30 million m 3 for the upper store and a total of 310 million m 3 for the lower stores in our study the model is calibrated on time series of q out and on the change of total groundwater storage δ s although we could extract virtual data on total storage s t from modflow we use δ s as such data types could be available at large scales from gravity recovery and climate experiment grace data products andersen et al 2005 to avoid problems of equifinality that could lead to a rapid decline of groundwater stores in lghm when using only δ s we add a mean estimate of total groundwater storage s as an additional soft information for regularization with hydrogeological information the change in total gw storage δ s is computed as 12 δ s t s t s t 1 where s t is the sum of all 4 groundwater stores 13 s t s gw 1 t s gw 2 t s gw 3 t s gw 4 t the objective function for calibration is 14 θ opt argmin θ θ t 1 n w 1 y sim qout t θ y obs qout 2 w 2 y sim δ s t θ y obs δ s 2 λ y sim s t θ y obs s 2 where the vector θ with eleven elements denotes the paramters to be optimized θ is the parameter space implied by the parameter ranges y sim are the simulated values by lghm q out δ s and s y obs are the modflow simulated data q out δ s and s that serve as virtual reality w 2 and w 1 1 w 2 are adjustable weights to weigh q out and δ s and λ is an adjustable weight to adjust the regularization by s at first the smallest possible weight value λ for the regularisation term is selected to explore the effect of w 1 in finding a compromise solution between the fit to q out and δ s the model is calibrated 100 times by increasing the weight w 2 given to δ s from 0 to 1 in increments of 0 01 correspondingly the weight w 1 given to q out decreases from 1 to 0 in such a way that weights given to both objectives always sum up to 1 the final decisions on λ w 1 and w 2 are discussed in section 3 2 our objective function is differentiable but at the same time could be multi modal thus we use a genetic algorithm ga embedded in the matlab r2018a programming environment after we realized that the calibration problem with gradient methods shows calibration results that depend on the initial parameter guess after globally exploring the solution space with the ga we refine the search locally by using the lsqnonlin least squares optimizer also embedded in the matlab r2018a programming environment in doing so we let lsqnonlin start at the best solution found by the ga we run the ga with a population size of 200 that evolve over 1100 generations for lsqnonlin the stopping criteria is set to a tolerence value of 10 6 2 7 model performance metrics we evaluate the performance of the lghm model in calibration and validation by using the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 15 nse 1 t 1 n y sim t θ opt y obs t 2 t 1 n y sim t θ opt y obs t 2 where θ opt denotes the optimized paramters t enumerates the time steps y sim t is the simulated data of spring discharge q out t and groundwater storage difference δ s t by lghm y obs t is the corresponding modflow simulated data and y obs t is the mean value of the corresponding modflow simulated data over time besides nse as the main performance criterion in this study we also estimate the linear correlation coefficient r between reference and simulated values 16 r t 1 n y sim t θ y sim t θ y obs t y obs t t 1 n y sim t θ y sim t θ 2 t 1 n y obs t y obs t 2 where y sim t θ opt is the mean value per simulation time series to take a global view onto the water balance we estimate the percentage bias means bm of our simulated values of q out q ex and and total groundwater storage s a bm value of zero indicates no error in mean simulated values a positive negative bias represents overestimation underestimation of model simulations respectively 17 bm 1 y sim t y obs t 100 2 8 model testing strategy the concept of lghm is tested in two parts first the lghm is calibrated by considering not only q out but also groundwater storage data δ s and s section 3 1 followed by the final selection of calibration weight section 3 2 subject to geological plausibility criteria section 3 3 after fixing the calibration weight assisted by plausibility checks in section 3 3 the model is now validated with a list of additional checks i against the remaining one third of the given data section 3 4 1 ii then the internal variables are checked section 3 4 2 iii this study claims to follow the natural behaviour of the wairau aquifer therefore it is necessary to test the spatially decreasing groundwater heads section 3 4 3 iv the total groundwater storage s estimated from lghm is compared against modflow section 3 4 4 v the model is compared to modflow under extreme drought conditions which tests the quality of our lghm completely outside the calibration conditions section 3 4 5 vi to test the ability of lghm to give long term predictions it is validated against modflow with synthetic long term weather data section 3 4 6 vii finally the summary of this validation is presented section 3 4 7 3 results and discussion 3 1 calibration fig 4 shows the trade offs among the nse estimates of q out and δ s with increasing weigths w 2 assigned to δ s objective the results of three different cases are compared and discussed here in the first case the lghm with four lower stores lghm 4ls is calibrated only on q out magenta upward pointing triangle and represents the normal practice of calibrating conceptual hydrologcal models in the second case the lghm 4ls is calibrated by considering groundwater storage information δ s s along with q out dual calibration as indicated with blue dots our third case contains dual calibration of lghm with only a single lower store 1ls as shown with gray dots this compares our lghm to the closest possible of a conventional rainfall runoff model furthermore in dual calibration cases two and three the effects on q out δ s q ex and s with increasing weights w 2 assigned to the δ s objective are analysed for clarity the nse values at w 2 1 are not shown in fig 4 note that at this final weight w 2 1 the lghm is calibrated without considering q out at all at first part of dual calibration with 4ls second case we select the weight of our regularisation term λ as discussed in section 2 6 after repeated model runs finally we choose a weight of 0 85 for λ and fixed it for the remainder of this study it is the smallest value at which we consistently avoid cases in which a slight bias in δ s t over time leads to a total depletion of all aquifer storage in short time for lghm with 1ls third case the regularisation term λ is not considered we do this because lghm with 1ls is not a suitable model structure for groundwater storage simulation for that case λ may keep the reservoir full but we found that it influences negatively the dynamics of groundwater storage change δ s in the first case normal practice the nse values of q out and δ s are 0 96 and 0 74 respectively as compared to this the lghm 4ls with dual calibration second case at w 2 0 provides the same nse value of q out but the nse value of δ s increases to 0 92 the lghm 1ls with dual calibration third case at w 2 0 provides the lowest nse values of both q out nse 0 92 and δ s nse 0 64 as compared to first two cases next one can see that the q out objective is more sensitive to a change in weights w 2 and w 1 1 w 2 as compared to δ s it can be seen that the lghm 4ls with dual calibration with increasing weights w 2 assigned to δ s shows a better trade off among the nse values of our two objectives q out and δ s there is a slight exception in this case at w 2 0 9 with a slight increase in q ex as compared to neighbouring points as a result the nse value increases for q out and decreases for δ s but we will pay no further attention to it for a more detailed analysis of the water balance we now discuss the bias of the calibration results fig 5 for the means of q ex q out and total groundwater storage s as described in section 2 7 because these numbers hardly change with weight w 2 we provide for cases two and three their average across all calibration runs with varied values of w 2 the bm for q ex in lghm 4ls with λ 0 normal practice case one and in lghm 4ls with λ 0 85 dual calibration case two for all increasing weights w 2 assigned to δ s are 1 6 and 0 3 however the bm for q ex in lghm 1ls dual calibration case three for the same increasing weights w 2 rises to 7 5 the bm for q out under all cases is equal to 0 however the bm of s in the dualy calibrated lghm 4ls with λ 0 case one is at 59 and in lghm 4ls with λ 0 85 case two is equal to only 0 05 for all weights w 2 however the bm for s in lghm 1ls with λ 0 case three is 95 4 for all w 2 which shows that the aquifer remains completely empty small bm values show good agreement with the benchmark modflow and the high bm values show that the model is completely off for these cases this supports the idea of incorporating information related to groundwater storage i e to use lghm with four lower stores therefore from now onwards in our study only the dual calibration case with 4ls and the corresponding weights w 2 w 1 1 w 2 will be discussed all calibration parameters except uzl and k 1 which are associated with q vz 1 are sensitive to model outputs it is seldom that the s vz exceeds uzl and otherwise q vz 1 remains mostly inactive the other five recession coefficients table 3 play an important role in the model and are senstive towards internal responses q out δ s and s the two parameters α 1 and α 2 related to power law function of q ex are naturally sensitive too as to determine groundwater recharge rates finally p 1 p 3 and hence p 2 1 p 2 p 3 are for percolation of water to lower stores they play an important role to maintain the natural characteristics like decreasing groundwater heads from west to east 3 2 selecting the calibration weight w 2 the previous section showed that the calibration weight w 2 given to δ s has a direct impact on percolation groundwater storage and on the overall dynamics of the internal responses like q out and δ s now we select the final weight w 2 as a compromise solution we do so without compromising over geological and hydrological plausibility criteria in our study area such conditions mainly involve decreasing groundwater heads along the downstream direction of the river sub surface flow paths and aquifer storage depletion one of the criteria to select a weight w 2 for δ s was the fulfillment of all the validation checks as described in the next sections although it is difficult to decide the final weight as most of them fullfill the above mentioned criteria we restricted our choice of weight to the range where the nse for q out is not compromised but for δ s there is already some improvement for the remainder of this study we fix the weight for δ s at w 2 0 03 red plus symbol in fig 4 all results and discussions presented in the remainder of this study are based on this choice λ 0 85 case two w 2 0 03 and hence w 1 0 97 3 3 plausibility checks table 3 shows the optimized parameter values for the selected weighting note that the optimized values of recession coefficients for interflow and base flows are quite small nevertheless these values are very plausible due to simple ratios in the hydrogeological system between two types of values 1 the live aquifer storage of the wairau aquifer is 10 to 15 million m 3 with a total aquifer storage of 310 million m 3 wöhling et al 2018 wöhling et al 2020 2 the average annual flow of the largest spring sc1 is 4 m 3 s 1 wöhling et al 2018 wöhling et al 2020 additionally fig 7c shows that the total spring discharge lies between 5 and 8 m 3 s 1 in which the contribution of sc1 is 54 6 when comparing 1 and 2 the recession coefficients in eqs 5 and 10 have to take on very small values as only a very small fraction of water stored leaves at sc1 per time step the portion of q ex taken by s gw 1 s gw 2 and s gw 3 is p 1 60 4 p 2 25 7 and p 3 13 9 this spatial distribution of gw recharge based on optimised parameters table 3 confirms the hydrogeological conditions associated with aquifer recharge recall that s gw 4 is conceptualized as confined aquifer see section 2 4 so it was defined to receive no percolation the river exchange flow q ex in our lghm is estimated by using the parameters α 1 and α 2 of the power law as described in sections 2 4 and 2 5 note that these parameters are optimized as shown in table 3 along with all other model parameters we compared it with the modflow exchange flow blue dots as shown in fig 6 the resulting function black dots offers a good shape of fit so we see the equation as an appropriate choice the empirical cumulative distribution function ecdf of q ex for both modflow and lghm are shown and compared in appendix a 2 yet there is substantial scatter around our power law the exchange between river and groundwater is a complex phenomenon and varies locally the modflow model wöhling et al 2018 as used in this study incorporates 3 dimensional aquifer heterogeneity which is not possible at the strongly lumped scale of our lghm if further model improvement was desired a multivariate regression including q riv and storage values e g s t could be conducted as the problem is most likely spatially explicit and time variant next we look at the detailed time series of q out and δ s while fig 7a shows q riv as a key model driver fig 7b shows q ex simulated by our lghm and modflow and fig 7c shows the corresponding comparison between modflow blue and simulated black total spring discharges fig 7d shows the comparison between modflow blue and simulated black δ s estimates the simulated results of δ s from lghm show high correlation with the modflow estimates and follow clearly the seasonal behaviour of the wairau aquifer for example from april to september autumn winter the q riv q ex and q out show higher flow rates similarly δ s also shows higher values in this time period the effect of summer river low flows between december and february and the corresponding low groundwater recharge from the wairau river can also be seen this confirms visually the very good nse values reported in section 3 1 and also shown in fig 7 looking at the details there is a slight under estimation and over estimation of q out at upper and lower discharge peaks as compared to modflow similarly δ s also shows the same trend as there is a slight mismatch at positive and negative extremes the main reason for this disagreement is the spatially averaged presentation of q ex eq 1 as discussed above quantile quantile plots of q out and δ s for modflow and lghm are shown in appendix a 3 3 4 model evaluation 3 4 1 model evaluation with independent data the validation data are modflow simulated q out and δ s in the time period from may 13 2016 to february 20 2017 fig 8 shows that the model simulations during the validation period fit well to the modflow results the nse values of q ex and q out fig 8b c decrease from 0 61 and 0 96 at calibration to 0 45 r 0 72 and 0 86 r 0 93 at validation note that q ex is not a part of our objective function the nse of δ s fig 8d has increased from 0 79 to 0 83 r 0 92 the reason for change in these nse values mainly lies in the time period chosen for testing the validation period has only 284 days by chance there are fewer river fluctuations and a lower number of days with high flows compared to the calibration period further fig 8b shows that the power law simplification to q ex mostly matches the pattern of the modflow estimate of the exchange flux but differs in magnitude yet since both q out and δ s in fig 8c and 8d respectively are well reproduced the achieved exchange flux estimates resemble a sufficient linkage representation between river and groundwater within our lghm the coefficient of correlation r in all cases related to our objectives is greater than 0 9 the shape of residuals is the same as already seen during calibration see section 3 3 overall the validation demonstrates a very good fit to the reference model therefore we conclude that the lghm model can predict selected system states to a similar accuracy as the more complex modflow model but in a fraction of time details on computing time are provided in section 3 4 7 3 4 2 internal variables as an additional validation check it is interesting to compare the model results with individual internal responses like sc1 spring discharges modflow spring flows are calibrated to sc1 data and the catchment data indicate that total outflow from all springs is in a relatively fixed proportion to sc1 modflow indicates that sc1 discharges are consistently around 54 6 percent of the total spring discharges to test this proportionality of q out in lghm with sc1 we compare the modflow time series for sc1 with 54 6 percent of the lghm simulated q out fig 9 the lghm doesn t quite catch the lower flows q sc 1 3 m 3 s 1 and the peaks because q out from lghm are lump estimates of all springs nd sc1 sc2 ss or1 and or2 as defined in section 2 2 and we have specified it as a fixed percentage 54 6 to compare with the modflow q sc 1 still this comparison shows a good nse value of 0 91 r 0 97 for this non calibrated quantity this validation check increases our confidence in lghm even though this particular test is not important for the accurate prediction of water balance components 3 4 3 groundwater heads test in the featured model domain observed groundwater levels are decreasing from west to east superimposed by some temporal variability we test this downstream trend in the four zones of our lghm as we calibrated only on δ s values of total storage not zone wise s t or heads this is an additional validation thus we convert time series of lghm storage volumes v within each zone to gw heads by dividing the stored volumes by porosity ϕ and area a other options than comparison of converted heads were not available because the already existing modflow model gives only the information of simulated gw heads at selected monitoring wells the third zone of our lghm does not contain any piezometric well in modflow fig 1 whereas the number of wells in the first second and fourth zone are 2 6 and 2 respectively therefore we represent the head in the third zone dark blue box plot in fig 10 by taking the average between the wells 1685 10426 and 3009 located at the downstream end of the second zone and the two wells 4577 and 3954 located at the beginning of the fourth zone fig 10 shows box plots of the resulting comparison as compared to our lghm the modflow based gw heads in the first second and fourth zone represent dynamic and spatial distribution in a single box plot blue the lghm stores reflect only temporal dynamics of spatially lumped quantities the lghm heads show the largest difference in the first zone as compared to the second third and fourth zone the difference between the median gw levels from modflow and lghm in the first zone is 8 7 m in the second zone it is 2 1 m in the third zone it is 4 4 m and in the fourth zone it is 4 1 m we do not rate this discrepancy as large because the estimation of zone wise heads from the wells in modflow is most likely also inaccurate this holds especially in zones 1 and 4 where large gradients and a sparse spatial distribution of wells exist note that the s gw 4 zone in our lghm is considered confined and water level fluctuations fig 10 in this zone are only due to groundwater abstraction overall fig 10 confirms that the simulated gw heads decrease from west to east with a satisfying fit 3 4 4 total groundwater storage while the existing modflow model was not set up for providing zone wise storage it can easily return the dynamics of total groundwater storage gws within the total model domain the overall time averaged gws in our lghm and in modflow are 285 73 million m 3 and 286 95 million m 3 respectively the discrepancy between them lies within 0 5 and we rate this as a positive validation however fig 8d also showed a good match of δ s between modflow and lghm during validation the reason for this small discrepancy is that the lghm is an explicit consideration of the domain s water balance fig 11 depicts the empirical cumulative distribution function ecdf of groundwater storage anomalies these anomalies are computed by removing the respective mean value the standard deviation of these anomalies for the lghm is 4 14 million m 3 and 2 38 million m 3 for modflow correspondingly the ecdf of the lghm is wider than that of modflow 3 4 5 extreme drought test at spring creek for more extreme scenario testing of the lghm model we investigate an extreme drought scenario where the wairau river is reduced to 5 m 3 s 1 from july 01 2014 up to the end of the simulation time period the same scenario was already used in wöhling et al 2018 results are shown in fig 12 at the start of the simulated extreme drought the groundwater storage in both models lghm and modflow starts decreasing fig 12d the simulated q out from our lghm follows the same trend as modflow up to the first 30 days fig 12c after this over the next about nine months of the simulated drought a significant difference of up to almost 15 builts up between q out predicted by modflow and lghm see fig 12c in lghm the recession coefficients control the emptying of groundwater storage whereas modflow features groundwater flow in a heterogeneous unconfined 3 dimensional aquifer therefore it is expected to get different q out estimates from lghm for this non calibrated quantity however the δ s estimates from both modelling approaches show only slight differences the main reason for this difference is the use of the power law function in lghm while modflow uses the river package as described in section 2 3 this power law function allows only water infiltrating into the aquifer while the modflow exchange flux can go in both directions despite this arguably strong simplification our lghm shows similar temporal dynamics as the modflow for δ s in fig 12d although being slightly biased fig 12b shows that the river exchange flux q ex from modflow drops to zero immediately after the river discharge q riv reduces to 5 m 3 s 1 then it rises again and almost fully agrees with our lghm the reason for this intense decrease of q ex simulated by modflow is that the net river groundwater exchange flow at that particular day becomes zero in contrast our lghm estimates q ex is based on the power law function eq 1 as already explained in section 2 4 and does not show such a large drop in the flux the remaining slight rise and fall in q out and δ s values in both models fig 12 c d during the simulated drought are due to other model forcings like groundwater abstraction for irrigation and land surface recharge considering fig 12 entirely we find that the lghm provides a plausible estimation of a regime shift to the simulated drought condition yet the discrepancies between its predictions and those from modflow require further discussion the reason why lghm estimates q out to be larger september 2014 to early 2015 than modflow lies in the stark simplification of the model structure this simplification might be too strong to capture processes that newly occur such simplification errors might inflate for extreme scenarios such as floods droughts hydrological regimes that have not been observed yet and potential changes in farmers behaviors as a response to changes in climate and or water management regulations moreover many natural and anthropogenic factors like river recharge land surface recharge and groundwater abstraction also influence adaptation strategies for sustainable management of groundwater resources this includes the change in amount and time of groundwater withdrawal by farmers as well as new mitigation measures taken by the authorities none of the two models are equipped to anticipate and predict such management strategies but they can both be coupled with water management models also neither the lghm nor the modflow model parameters are trained for such an extreme conditions since model results depend on the implemented physics and hydro geo logical knowledge from the site to appropriately estimate the change of fluxes and storages it is no surprise that they differ under a drastic regime change therefore although we find the temporal pattern and orders of magnitude of the simulated quantities plausible the application of the lghm just like any other model for long term predictions under unseen conditions should be carried out with caution overall the main benefit of using the lghm for such scenario analyses lies in providing a potential range of plausible predictions for example q ex in modflow fig 12b shows a large drop as compared to lghm at the start of extreme drought scenario this unknown natural behaviour of q ex in modflow may be criticized as overshooting and the lghm prediction here provides a plausible alternative similarly δ s in modflow exhibits a sudden drop at the start of the drought period in comparison the δ s in lghm shows lower values and exhibits some deep drainage during less extreme condition 3 4 6 validation against modflow in synthetic long term simulations finally we test the future long term prediction capability of our lghm by validating it against modflow long term forecasts as a synthetic reality the simulations are conducted for the years 2000 to 2040 with extended synthetic input time series for the years 2017 2040 details on how we generated future input data considering current climate conditions are provided in appendix a 4 the resulting comparison between lghm black and modflow red for q out and δ s are subsequently discussed for a clear representation of comparison between modflow and lghm we split the future time period into two parts the time period between 01 01 2017 and 31 12 2028 is shown in fig 13 whereas fig 14 depicts the time period between 01 01 2029 and 31 12 2040 although the lghm simulated q out and δ s values underestimate upper and lower extremes they agree well with the dynamics of the river flow and reproduce the modflow results reasonably well this is confirmed by nse values of 0 89 r 0 95 fig 13 and 0 9 r 0 96 fig 14a for q out and 0 8 r 0 89 fig 13 and 0 77 r 0 97 fig 14b for δ s the reason for the discrepancy between model results is due to the difference in q ex as already discussed in section 3 1 note that as compared to spatially resolved models like modflow the lghm represents the system by just 4 sequential stores this has an impact on how changes in boundary conditions propagate through the hydrological system this has been tested by simplifying our lghm to just one store in this case the differences in flow amplify results not shown the same applies to groundwater recharge and abstraction where responses to changes of these external forcings are more smoothed out in modflow and the overshooting within our lghm applifies with decreasing number of stores results also not shown however as compared to traditional conceptually lumped models our lghm contains hydrogeological information and instead of calibration only on q out it is also calibrated on δ s such aspects make our modeling approach more plausible to represent the natural system the lghm has shown the same efficiency and performance to reproduce modflow results as it did during calibration see section 3 1 and and evaluation see section 3 4 1 3 4 7 summary of validation overall these validation results indicate that the lghm approach is well suited for long term predictions both modeling approaches lghm and modflow have their strengths and weaknesses model formulation with simplification as in the case of lghm comes at the cost of underestimation or overestimation of internal responses single linear bucket models exhibit exponential hydrographs and therefore come with the tendency to overshoot peaks and lows see section 3 4 6 with more and more buckets in line analytically approaching a nash cascade this peaking becomes smeared out our model has parallel flow componenents and several non linearities hence lghm is not exactly on the continuum between one bucket and the nash cascade yet we find it worthwhile to theoretically allocate lghm with respect to these two extremes we can assume that adding more buckets to our model would buffer extreme peaks and lows more strongly physical based models allow a more detailed description of physical processes but our lghm is simple and easy to apply additionally the computational efficiency is very high as compared to the modflow model the average runtime for a lghm simulation period of 40 years 2000 2040 is 1 5 s on an intel core tm i5 4590 cpu 3 30 ghz using the matlab r2018a programming environment modflow takes 25 min with the same equipment in addition modflow requires input files in a specific format and more spatially explicit data note that we had to break down the modflow simulations into three separate runs for technical reasons our lghm can therefore easily be employed for long term simulations with input data stemming from climate earth system and meso scale catchment models 4 summary and conclusions the goal of this study was to extend lumped conceptual hydrological models towards a lumped geohydrological model lghm with the addition of tailor made groundwater stores the model building is inspired by the geometry and hydrogeological large scale properties of major aquifers in the study area i e attributes that can often be obtained from geological knowledge hence these models require much less computational effort and less expensive site investigation than comparable spatially explicit numerical flow models being lumped lghm cannot describe the spatial variability of natural process but is suitable for large scale quantities such as total groundwater storage the lghm model was calibrated on both groundwater storage data and discharge data our real world application site was the unconfined wairau aquifer in the marlborough region new zealand to avoid the problem of lack of data to validate the lumped conceptual model an already existing modflow model for the study region wöhling et al 2018 served as a virtual reality the prediction capability of lghm is rated based on matching the simulated discharge and groundwater storage of this virtual reality we find that lghm with four lower stores is efficient reliable and fully capable of representing large scale natural processes almost as accurate as the modflow model itself overall we rate the model results with this model structure as highly satisfactory the lghm is about 3 orders of magnitude faster than modflow and can be considered a reasonable alternative for estimating both discharge and groundwater storage there are some discrepancies in model results which can be attributed mainly to river groundwater exchange flux q ex the recharge mechansim from the braided wairau river is complex and still lacks fundamental process understanding the possible limitation of our lghm approach is that it simulates groundwater at an almost fully lumped scale so it cannot be compared directly to groundwater level data instead it has to be calibrated on and only predicts spatially aggregated groundwater storage however the groundwater part in our proposed lghm resembles a minimalistic version of a physically based numerical groundwater flow model with just a few here 4 cells representing darcy type groundwater flow in unconfined and or confined aquifers overall we were able to reproduce the modflow simulations well matching most of the temporal dynamics of the simulated flow and storage in our modelling approach however neither modflow nor lghm consider aspects of a change in water use as a response to a changing climate and or changes in water management regulations especially future spatio temporal changes of the distribution of groundwater abstraction for irrigation and municipal water use as well as water recharge are challenging to be extrapolated lghm is an attractive fast alternative to more computationally demanding models such as modflow and thus can be useful for example for operational forecasting and predictive uncertainty quantification with potentially little loss of accuracy the nse values of total spring discharges q out and gw storage change δ s during calibration are 0 96 and 0 79 respectively during validation the nse value is only slightly smaller at 0 86 for q out and larger at 0 83 for δ s respectively further there is a good agreement between long term simulations of lghm and modflow acting as a synthetic virtual reality in a scenario simulation for 2017 2040 this is confirmed by nse values of 0 89 and 0 9 for q out and 0 8 and 0 77 for δ s respectively our lghm has passed through various additional checks like i hydrological plausibility ii an extreme drought scenario and iii inspecting the river groundwater exchange flux we purely used modflow as a virtual reality for testing the information used to build the lghm model are only hydrogeological information of the site description that modflow modelers have used in greater spatial detail at no point have we extracted information for our lghm model building directly from the modflow model the only simplification we did overall is that we used time series data on total groundwater storage simulated by modflow thus to transfer the lghm idea to other study areas one will indeed need a data product for calibration e g from grace or from interpolated groundwater maps to replace these virtual time series by real data based on the performance of lghm in short and long term predictions and due to its flexible model structure lghm can be adapted easily to other catchments the main conclusions from this study are the lghm reproduces virtual reality data with a high accuracy for different hydrological conditions yet with strongly reduced data requirements the lghm is computationally three orders of magnitude faster than physically based numerical models here modflow is easy to implement and has a flexible model structure this modelling approach was demonstrated to be applicable for long term simulations under current climate conditions our lghm could as well be built inside flexible modelling frameworks like superflex fenicia et al 2011 marmott knoben et al 2019 or raven craig et al 2020 if model refinement is desired in this specific catchment we would recommend to adopt a more complex regression model for river groundwater exchange flux we will explore future climate scenarios in a follow up study where the computational speed is highly important for performing a bayesian uncertainty analysis the accuracy and computational efficiency of our lghm model demonstrates clearly its applicability to replace physically based models here modflow for large scale groundwater storage simulations and forecasts we see this as proof of concept to model other catchments with lghm models as well therefore lghm offers a lean computationally cheap model alternative that also enables stochastic scenario simulation and sampling based uncertainty quantification with methods such as markov chain monte carlo sampling credit authorship contribution statement fahad ejaz conceptualization methodology data curation formal analysis validation writing original draft writing review editing thomas wöhling writing review editing methodology supervision visualization marvin höge visualization investigation writing review editing wolfgang nowak supervision writing review editing methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors received financial support by graduate school scholarship programme gssp 2018 grant no 57395813 from the german academic exchange service daad we acknowledge the support by the stuttgart center for simulation science simtech the german research foundation dfg within the research training group integrated hydrosystem modelling grk 1829 the chair of hydrology at tu dresden and co funding by the new zealand ministry of business innovation and employment mbie contract lvlx1901 further we would like to thank the marlborough district council mdc for providing the data for the wairau case study appendix a a 1 lghm inputs and outputs table 4 shows lghm model inputs their description and source these inputs have already been explained in the manuscript but are summarized here these inputs include wairau river flows q riv at barnetts bank near sh1 bridge groundwater extraction q well surface recharge q rec deep groundwater flow as constant flux boundary condition and aquifer properties our lghm output contains total spring discharges q out groundwater storage change δ s and total groundwater storage s a 2 comparison of river groundwater exchange flux fig 15 shows the fitted power law function orange circles between wairau river flows and modflow simulated q ex for the time period between october 31 2013 and february 20 2017 fig 15 also shows a complete range of q ex simulated by modflow and lghm for the same time period fig 16 shows a comparison of empirical cumulative distribution functions ecdf of river groundwater exchange flux q ex simulated by modflow and our lghm for the simulation period between october 31 2013 and february 20 2017 it can be seen that while there is a mismatch between both models in the occurrence of frequency of higher and lower q ex the overall magnitudes and frequencies are represented in an acceptable magnitude the reason for mismatch lies in the lumping of exchange processes into the univariate power law regression a 3 comparison of total spring discharges and groundwater storage change figs 17 shows quantile quantile plots of total spring discharges q out simulated by modflow and by our lghm for the entire simulation period between july 01 2013 and february 20 2017 dashed in red colour is the 1 1 line representing a perfect fit it can be clearly seen that there is a mismatch among these models at upper and lower extreme values as a consequence there will be slight overestimation of lghm predictions when modflow q out 5 6 m 3 s 1 and likewise some underestimation in lghm predictions when modflow q out 8 2 m 3 s 1 similarly fig 18 presents quantile quantile plots of total groundwater storage change δ s simulated by modflow and by our lghm it can be seen that there is a good match between both models at lower values of δ s up to almost 0 15 million m 3 d 1 and after that the discrepancy grows however at extreme values with δ s greater than 1 12 million m 3 the discrepancy decreases again as a consequence there will some underestimation of lghm predictions when modflow δ s estimates are approximately between 0 15 and 1 12 million m 3 d 1 the main reason for this disagreement is again the lumped presentation of q ex as discussed in the section 3 1 a 4 data generation and river flow simulation to generate synthetic future weather and river flow at first we employ a statistical weather generator vg that is based on vector autoregressive var processes schlabing et al 2014 to generate future time series of rainfall r and temperature t fig 19 depicts the fitting of generated r and t time series on the measured data the time series of measured data is available from the year 2000 to 2016 we found a weibull distribution for r and a normal distribution for t as a suitable functions that give a good fit fig 19 dashed in red colour is the 1 1 line representing a perfect fit of simulated and observed distributions then we estimate the reference evapotranspiration by using the hargreaves samani equation hargreaves and samani 1985 as follows 18 et rc 0 0135 c hs r a λ t max t min 0 5 t a 17 8 where et rc is the reference crop evapotranspiration mm day 1 r a is the extraterrestrial radiation mjm 2 day 1 t max t min and t a are respectively the maximum minimum and average daily air temperatures c c hs is an empirical coefficient modified after samani 2000 19 c hs 0 00185 t max t min 2 0 0433 t max t min 0 4023 t min and t max in eqs 18 and 19 are estimated from the daily averaged temperature values t generated from the weather generator schlabing et al 2014 for this purpose the standard deviation 5 4 of t is subtracted and added tmax min t std dev fig 20 shows t and r variables generated from vg and et rc estimated from the hargreaves samani equation these simulated climate variables r t et rc are then used as an input to an existing rainfall runoff model for the entire wairau catchment this model has been developed with the gr4j model santos et al 2017 as implemented in the marrmot toolbox knoben et al 2019 model parameters were calibrated using markov chain monte carlo methods at tu dresden and this model yields wairau river discharge at the sh1 gauging station the time series of river discharge at rock ferry is then estimated from the predicted discharge at sh1 with the addition of 7 64 m 3 s 1 as determined from the correlation analysis of historical data wöhling et al 2018 the quality of simulated wairau river flows is checked by comparing the basic statistics with the measured data between 2001 and 2016 the spin up period of rainfall runoff model to simulate river flows is 1 year table 5 shows a close match and simulated river flows agree well with the observed flows 
3667,excessive groundwater pumping exacerbates aquifer depletion and poses a major threat in regions all around the world that already suffer from overuse or climate change in this situation accurate and reliable predictions of long term aquifer water balances are key prerequisites to manage groundwater sustainably compared to spatially explicit numerical models lumped hydrological models are computationally fast lean on data requirement and more accessable for quantifying uncertainty however lumped hydrological models are mainly designed to simulate river discharge only not aquifer storage consequently calibration only includes stream flow data in this study we hypothesize that we can extend a lumped hydrological models here hbv towards a lumped geohydrological model lghm by additional designated terms for water budget and groundwater storage the model building is inspired by the geometry and hydrogeological large scale properties of the catchment s aquifers underground flow routing resembles major groundwater flow paths the model is calibrated and evaluated on both groundwater storage data and surface discharge data we apply our lghm to a modflow based virtual reality describing the unconfined wairau plain aquifer new zealand we consider and discuss specifically river groundwater exchange processes long term forecast of aquifer storage dynamics and groundwater depletion in a hypothetical persistent drought our model evaluation shows very plausible predictive capabilities in 40 year forecasts with synthetic weather time series and several years of groundwater depletion in the extreme drought case keywords water management long term water balance conceptual groundwater model 1 introduction groundwater use covers about one third of the global fresh water demand due to continuously increasing demand e g chen et al 2016 and climate change the risk of groundwater exploitation and depleting aquifers persists putting water resources at risk e g gorelick and zheng 2015 in order to counteract this so called tragedy of commons hardin 1968 sustainable groundwater management needs proper attention hydrologic budgets land use and irrigation require sustainable management strategies e g von gunten et al 2015 in this context model based simulations help to understand and investigate internal hydrosystem responses such as runoff from catchments e g wagener et al 2004 or the total aquifer water budget e g jaani 1996 and hence to make useful predictions about the future under changing conditions e g wagener and gupta 2005 currently many hydrological models exist varying according to temporal and spatial scale as well as complexity as listed in knoben et al 2019 to ensure a sustainable use of water resources decision makers are interested in future states of hydrological systems and specific predictions at different scales the choice of the model depends on the model purpose and also on other factors like data availability and computational power lumped conceptual rainfall runoff models are suitable to efficiently simulate the surface runoff response to rainfall at the catchment scale or at the sub catchment scale yet at the cost of an immense simplification of subsurface flow however we can also estimate subsurface storage from the models of this type examples are vic liang et al 1994 hymod moore 1985 gr4j edijatno et al 1999 hbv bergström 1995 the tank model sugawara and fuyuki 1956 and the sacramento model with soil moisture accounting sac sma buchtele et al 1996 burnash et al 1973 to integrate both surface and subsurface flow distributed hydrologic or spatially explicit integrated physically based flow models are a typical choice one example is modflow harbaugh 2005 which includes surface water routing swr process hughes et al 2012 to perform surface water routing as well as surface water groundwater interaction another example is feflow trefry and muffels 2007 for only sub surface processes but it can be coupled with surface water packages like mike 11 thompson et al 2004 via ifmmike11 monninkhoff 2014 plug in mike she abbott et al 1986 abbott et al 1986 is another coupling option to obtain a fully integrated hydrological modeling system to simulate surface water flow and groundwater flow there are also possibilities for regional to global scale investigations by using 3 dimensional physical based models like parflow ashby and falgout 1996 kollet and maxwell 2006 and hydrogeosphere therrien and sudicky 1996 such models are suitable to account for future water demands in response to socioeconomic development and climate change on very large scales such as in cwatm burek et al 2020 such physically based models are suitable for accurately estimating internal variables and states such as groundwater heads and total aquifer storage compared to lumped conceptual models physically based models consider spatial variability of state variables and represent hydrological processes and their interaction refsgaard and knudsen 1996 however to investigate changes in hydrological systems due to human interaction and climate change these physically based models require large input data related to topography landuse soil and subsurface properties as well as climatic attributes leavesley 1994 goodarzi et al 2014 chen et al 2016 many of these parameters require calibration there are many data scarce regions like in developing countries where operation and maintainance of data aquisition is infeasible due to high costs or lack of personnel and infrastructure the computational effort alone is a major hindrance to solve large scale problems at fine temporal and spatial resolution fatichi et al 2016 and makes long term forecasts with quantified uncertainty computationally very demanding conceptually existing lumped conceptual hydrological models are mostly used to simulate as well to calibrate on catchment runoff processes based on rainfall evaporation and so called slow and fast runoff processes kim et al 2018 azizian and shokoohi 2019 razmkhah 2016 jin et al 2010 rezaeianzadeh et al 2013 bhattacharjya and chaurasia 2013 they are fast and lean on input data requirement representing the hydrological system in a fixed framework of conceptual stores like in gr4j perrin et al 2003 or by more flexible toolbox configurations like in superflex fenicia et al 2011 summa clark et al 2015 and raven craig et al 2020 these more flexible frameworks allow to configure different model structures including sub surface stores in some lumped conceptual models sub surface storage can be further differentiated into a soil and an aquifer storage like the production and the routing store in gr4j all such lumped models and toolboxes are mostly calibrated on river discharge and less attention is given to simulate sub surface dynamics like groundwater storage yet these lumped conceptual models can be calibrated and validated on their slow groundwater components that may resemble groundwater storage seibert 2000 used groundwater heads as additional data along with runoff while calibrating hbv in order to constrain ranges of model parameter values others investigated the decline of model storage in a long term drying climate by using five different lumped conceptual rainfall runoff models fowler et al 2020 used groundwater heads and gravity recovery and climate experiment grace satellite groundwater storage information tapley et al 2004 along with runoff data the problems faced there were the scarcity of piezometric wells unknown specific yield and storage volume of an aquifer and the coarse temporal resolution additionally the grace data with 400 km has very coarse spatial resolution andermann et al 2012 estimated groundwater storage by considering internal model storage states but calibrated gr4j and gr2m mouelhi et al 2006 only on river discharge data of daily and monthly timescale their focus was to determine the role of groundwater storage in the hydrological cycle lecocq et al 2017 calibrated gr4j only on river runoff to estimate groundwater storage and transformed it to pressure head by considering an apparent 3 porosity based on their hosting linestone aquifer the purpose of their study was to demonstrate the ability of ambient seismic noise to determine the changes in near subsurface characteristics however in all these studies aquifer geometry and subsurface properties were not directly used to foster a hydrogeologic interpretation of subsurface properties and aquifer exchange rates or to constrain their calibration also no explicit validation was performed to estimate the potential benefit from adding the used hydrogeologic data during calibration we fill this gap by considering groundwater stores and exchange fluxes together with streamflow throughout the whole modelling process to summarize in previous hydrological modelling studies less attention was given to incorporate the sub surface flow and storage components of catchments the subsurface storage implied by respective slow model components was seldomly validated or even not at all making the use of hydrogeological information for additional calibration of lumped models a largely unexplored field we will deliberately focus on these aspects to estimate both river discharge and groundwater storage within the study domain semi distributed models like topmodel beven and kirby 1979 and swat arnold et al 1998 depict a compromise between lumped and spatially explicit integrated numerical models such models accept both averaged and distributed input parameters and runoff is estimated at each sub catchment however such models are less flexible in integrating additional components for groundwater storage and they are more data intensive and more computationally demanding than lumped conceptual rainfall runoff models considering the features advantages and disadvantages of these model classes the identified research gap is to find a model that has the advantages of lumped conceptual rainfall runoff models but additionally incorporates sub surface properties and catchment behaviour we hypothesize that lumped conceptual hydrological models can be used for long term groundwater predictions under the following conditions if the model is extended by few well selected water budget terms if the model is calibrated by not only using discharge data but also using groundwater storage data if geohydrological information is used in the model to incorporate physical properties of the subsurface if the physical features of the hydrological system are conceptualized in the model e g conceptualization of recharge zones aquifers groundwater flow paths and heads the plausibility of our hypothesis rests on the integration of designated storage terms that are informed by aquifer scale geohydrological properties of course the choice of the model structure depends on individual judgement experience and preference e g addor and melsen 2018 and it is well known that model structural errors introduced during such an upgrade of model complexity could lead to misleading model results höge et al 2018 however the information related to aquifer properties and geometry helps to reduce such errors additionally the volume of groundwater loss is difficult to estimate in case of missing geologic information zaki et al 2019 but one can exploit that hydrological processes are coupled and hence water balance equations can be calibrated on surface and subsurface components together we hypothesise that the long term predictions of internal responses such as groundwater storage are possible without compromising other water budget terms we test our hypothesis by presenting a lumped geohydrological model lghm which is an extension of the existing hbv lumped conceptual model bergström 1995 in this proof of concept to avoid the problem of lack of data when testing validating our new model we use an already existing modflow model for a selected study region wöhling et al 2018 as a virtual reality our real world application is the unconfined wairau aquifer in the blenheim region new zealand our lghm is calibrated and validated against the modflow model of the wairau aquifer which in turn has been calibrated against real data further we test our lghm against modflow by scenario simulation under severe drought conditions and compare both models for plausibility of long term simulations our main contribution is that our new lghm approach includes hydrogeological information of major aquifers dedicated storage boxes and a darcy like subsurface flow routing allowing for calibration on discharge and storage related data to perform long term forecasts of aquifer storage the lumped geohydrological modelling approach presented in this paper will help modelers and decision makers to quantify and predict aquifer water budgets yet the computational and model input data requirement is strongly reduced as compared to physically based hydrogeological models this allows for an increase of hydrologic system coverage as compared to traditional lumped models and it is easier to develop and operate than semi distributed models this paper is organized as follows section 2 contains material and methods adressing lghm modelling philosophy study area the modflow model as synthetic reality model development parameter ranges calibration criteria model performance metrics and our model testing strategy section 3 presents results of model calibration and model tests and their discussion finally in section 4 we conclude on our lghm hypothesis and summarize new research questions to pursue with this model class 2 materials and methods 2 1 lumped geohydrological modelling philosophy the goal of our lumped geohydrological models lghm is to fully account for the processes covered in lumped hydrological models but also for groundwater storage major flow paths and their dynamics as is described in section 2 4 thus given a study area the aquifer is divided into different stores these stores are based on geological information and they interact with each other via major groundwater flow paths from one store to another these flow paths are selected based on their suitability to define total spring discharge and groundwater storage and also justified according to the prevailing geology as a consequence a lghm must be calibrated to and will predict not only outlet discharge but also groundwater storage and therefore can be and has to be validated on both the time periods of calibration and validation in our proof of concept case are described in the next section 2 2 the geological information related to large scale aquifer properties helps the modeler to simulate groundwater storage with more insight to the subsurface conditions in specific hydrogeological properties of subsurface lithological assemblies define the major groundwater storage units and subsurface flow routing mechanisms these properties include total aquifer volume porosity hydraulic conductivity and to some degree spatial arrangement and geometry it is possible to include such models into lumped models with characteristic hydrogeological time scales e g by informing recession coefficients or the hydrograph time base in gr4j as a consequence for building such a lghm geological understanding is important to characterize a hydrological system and to justify the required conceptualization of groundwater storage and flow paths therefore the fundamental approach to build a lghm is to start with a hydrogeological not just hydrological conceptualization of the catchment and its aquifers see section 2 2 this conceptualization for subsurface hydrogeology follows the same principles as for surface hydrology 2 2 site description the study area is part of the wairau river catchment 3430 km 2 in the marlborough district in the northern part of the south island new zealand as depicted in fig 1 the wairau aquifer study domain lies in a flood plain close to the coast of the pacific ocean and has a modelled area of 84 8 km 2 the major land use of the study area is irrigated vineyards and groundwater pumping is the main source of irrigation water the unconfined wairau aquifer is an important resource of drinking water and irrigation water supply in and around blenheim city the average annual precipitation is 650 mm and the mean annual temperature is 12 8 c wöhling et al 2018 this study area has already been extensively investigated by wilson and wöhling 2015 wöhling et al 2018 wöhling 2019 wöhling and burbery 2020 and wöhling et al 2020 the main characteristics of the site are summarized from these studies and we refer to the studies cited above for further details long term daily flow measurements of the wairau river are available at barnetts bank near the sh1 bridge fig 1 the rapaura formation of the wairau aquifer subsequently refered to as wairau aquifer for brevity is mainly recharged by the river thus river recharge is an important variable for groundwater storage the total storage volume v in the wairau plain aquifer is approximately 310 mio m 3 estimated from average porosity aquifer volume from the geological model and highest groundwater heads observed in 2002 wöhling 2019 wöhling et al 2020 recently reviewed groundwater monitoring records and aquifer test data suggest that the aquifer permeablity is highly anisotropic wilson 2016 the gravels of the unconfined aquifer are highly conductive and mean residence times are estimated to be less than 1 year wöhling et al 2018 morgenstern et al 2019 hence the aquifer essentially acts as an extension of the wairau river due to the highly conductive nature of the aquifer river recharge and surface recharge become shallow groundwater with little time delay on the eastern side of the wairau plain the aquifer becomes increasingly confined and at the fringes of the confinement groundwater emerges at the surface as springs in accordance to previous modelling efforts five springs and streams are considered in the model domain wöhling et al 2018 the northern drain nd discharges into the wairau river whereas the spring creek is divided into the eastern sc1 and western sc2 part the southern streams ss are distinguished by the eastern o paoa river or1 and the western o paoa river or2 sc1 is the largest spring with a share of more than half of the flow of all the emerging springs there are four permanently monitored groundwater wells enumerated as 3009 3821 3954 4577 fig 1 and several temporary wells installed and monitored by the marlborough district council previously the lithology of the wairau aquifer has been intensively investigated brown 1981a brown 1981b raiber et al 2012 wilson and wöhling 2015 according to the recent stratigraphy review of the rapaura formation that forms the shallow unconfined wairau aquifer wilson 2016 three lithological layers are identified the base of the unconfined aquifer is considered to be the impermeable speargrass formation the rapaura formation has a maximum thickness of about 30 to 35 m its lowest member contains highly permeable gravels of 9 5 5 m thickness above the speargrass formation above it rest low permeable clay rich gravels with 3 9 m thickness the upper member 8 3 m thickness consists of high permeability gravels towards the coast the aquifer is increasingly confined by the low permeability dillion s point formation the different hydrogeological units were implemented in a spatially explicit modflow model of the unconfined wairau plain aquifer wöhling et al 2018 their fig 5b see also section 2 3 it was found that the hydrological units mentioned above are important to simulate the dynamics of groundwater flow aquifer storage as well as spring flows other hydrogeological features not included in the spatially explicit modflow model are small scale near surface features such as the historical o paoa stream channel within the upper rapaura formation wilson 2016 the data used to drive modflow and our lghm model includes time series of wairau river flow at barnetts bank a site slightly upstream of the old gauging station at the state highway 1 bridge sh1 fig 1 groundwater abstraction land surface recharge and groundwater heads storages the time period between october 31 2013 and may 12 2016 is used for calibration the time period between may 13 2016 and february 20 2017 is used to validate the lghm model concept 2 3 synthetic reality modflow model for proof of concept of our lghm concept and in order to have access to unlimited and gap free data we use the modflow nwt niswonger et al 2011 surface water groundwater model that was already developed wöhling et al 2018 for our study area as a virtual reality the transient spatially explicit numerical modflow model was developed to understand and quantify the river groundwater recharge mechanisms in new zealand s gravel bed rivers the model contains four vertical hydrogeological layers the spatial variability in hydraulic conductivity within the three rapaura formation layers is specified using a pilot point parameterization scheme the computational grid of the modflow domain and the cross section view of geologic layers are shown in fig 2 a b it consists of three geologic layers with 6360 active cells and the size of each cell is 200 200m the simulation time period for this modflow model is between july 01 2013 and february 20 2017 with 123 days as spin up period before model simulations on july 01 2013 for further details on the modflow model the reader is referred to wöhling et al 2018 2 4 model development our model development partially employs the same routines as the orignal hbv model bergström 1995 hbv contains three routines i e snow accumulation and melt soil moisture accounting and the response function and river routine for coupling the hydrologic routines to the subsurface dynamics we use the rushton model rushton et al 2006 to estimate land surface recharge q rec m 3 s 1 and groundwater extractions q well m 3 s 1 for each of the nine major wairau soil types these estimates are taken from a previous study wöhling et al 2018 the rushton model is based on the soil moisture balance concept and contains three main components 1 infiltration to the soil zone and near surface soil storage 2 actual evapotranspiration and 3 soil moisture deficit and recharge the total available water taw values are taken from the new zealand fundamental soil layer database landcare research 2000 the readily available water for vineyard grapes is assumed to be 45 of taw there will only be groundwater recharge when soil moisture is in excess corresponding to the vertical structure of the wairau aquifer our model structure consists of three conceptual stores named as soil box upper store and lower store the latter will be spatially subdivided later below in our modelling framework the soil box resembles the rushton model domain as shown in fig 3 and the upper and lower stores interact with the wairau river first we discuss the interaction with the wairau river groundwater recharge in the study area is dominated by exfiltration from the wairau river the river recharge can be modeled as linear non linear or a combination of both rushton and tomlinson 1979 such lumped approaches have been used in the absence of knowledge about process of parameter detail which is particularly the case in braided rivers such as investigated here there is poor understanding of the small scale details of surface water groundwater exchange mechanisms in braided rivers wöhling et al 2018 wöhling et al 2020 from the relationship between wairau river discharge q riv t m 3 s 1 and modflow river groundwater exchange flux q ex m 3 s 1 we have found that a power law function fits best see fig 15 in appendix a 2 therefore we use a power law relationship between q riv t and q ex t in our lghm note that this is a simplification of the approach used in wöhling and burbery 2020 q ex t is the main driving force in the model and is estimated through calibrating the power law parameters in eq 1 additionally our reasoning for choosing a power law relation is that the exchange flux is related to the wetted area of the river channel and thus to river stage and flow this wetted area follows a typical rating curve which is often modelled as a power law petersen øverleir 2005 this power law equation is further discussed in section 2 5 1 q ex t α 1 q riv t α 2 0 α 2 1 0 α 1 q riv 1 α 2 where t day represents the time coordinate and α 1 and α 2 are the coefficients of the power law equation and q riv million m 3 d 1 is the mean wairau river discharge between between 2000 and 2016 in the model all fluxes e g q ex q riv are in units of million m 3 d 1 but we will report them in units of m 3 s 1 for easier interpretation the parameter α 2 controls the curvature of the power law based on the intuition and relation of rating curves we want q ex to be increasing with increasing q riv yet with a slope that does not increase with river flow q riv thus the lower and upper limits for α 2 are zero and one respectively the other parameter α 1 controls the overall magnitude of the exchange flux as a multiplier the lower limit of zero ensures a net loss of river water into the aquifer for the upper limit we argue that the wairau river can not lose more water than what it has i e q ex q riv when reformulating this for the upper limit of α 1 we obtain that α 1 q riv 1 α 2 the upper store fig 3 is described next the upper store with stored volume s vz t million m 3 resembles shallow groundwater and it takes daily surface recharge q rec t million m 3 d 1 and q ex t from the river it loses percolation q perc t million m 3 d 1 to the lower store and a fast component q vz 1 t million m 3 d 1 and an intermediate component q vz 2 t million m 3 d 1 to spring creek discharge similarly to the orignal hbv q perc t q vz 1 t and q vz 2 t are estimated by using eqs 3 5 in and outflows of the upper store between times t 1 and t are calculated explicitly via 2 s vz t s vz t 1 q rec t q ex t q perc t δ t 3 q perc t s vz t 1 k d 4 q vz 1 t k 1 s vz t 1 uzl 5 q vz 2 t k 2 s vz t 1 here δ t is the time step duration k 1 day 1 is the recession coefficient for the fast runoff component q vz 1 t and uzl million m 3 is the threshold parameter for the upper store as in hbv q vz 1 t is generated only during floods when the storage in s vz t exceeds uzl k 2 day 1 is the recession coefficient for the intermediate runoff component q vz 2 t as in hbv k d day 1 is the coefficient for percolation q perc t to groundwater storage as in hbv in accordance to the conceptual understanding of the wairau aquifer the lghm contains four sequential lower stores with stored volumes s gw 1 t s gw 2 t s gw 3 t and s gw 4 t all in units of million m 3 and their characteristics are shown in table 1 each lower store contains it s own recession coefficient and they are calibrated along with other model parameters as shown in table 3 section 2 6 to conceptualize these four lower stores fig 3 we consider that the groundwater levels decrease from s gw 1 to s gw 4 these four lower stores fig 3 have their individual volume as upper limit and each one has its own water level as each lower store corresponds to a specific section of the aquifer each one has its own values of surface area a km 2 aquifer thickness t m and hydraulic properties like specific yield s y the values of t and s y are spatial averages over the corresponding sections table 2 shows the average thickness t and hydraulic conductivity k h values of three geologic layers corresponding to these four lower stores these properties of an aquifer tables 1 and 2 are obtained from geological investigations in our study area and have already been used in wöhling et al 2018 wöhling 2019 wöhling et al 2020 the lower stores are set up such that their areas add up to the total surface area 84 8 km 2 of the model domain and their volumes to the total aquifer storage volume 310 mio m 3 the storage capacity of each store is estimated by taking the product of average effective water thickness t wa m of the entire aquifer and their surface areas t wa is estimated by dividing the total aquifer storage volume by the total aquifer area now we model the flows into and among these stores the function of each lower store is the same as that of s vz t however there is exchange of groundwater flow between stores depending on the hydrogeologic units q perc t from the upper store is distributed to the first three lower stores s gw 1 s gw 2 s gw 3 depending on the calibrated parameters p 1 p 2 and p 3 as shown in fig 3 according to the geological settings the fourth store s gw 4 is considered confined due to the impervious dillions point formation on top so it receives no recharge in conditions when the storage in a groundwater store reaches its upper storage limit the entire excess volume q exc t m 3 s 1 flows to the next store downstream this q exc between lower stores is only expected in extreme and seldom cases when aquifer is already full and there is excessive groundwater recharge the downstream routing is justified because our study area has sloping terrain with 2 7 wöhling et al 2018 along the wairau river and the aquifer materials are highly conductive for the confined store s gw 4 q exc t is routed directly to the discharge which in our case is the total spring discharge q out million m 3 d 1 the actual daily groundwater abstraction from wells within the model domain is unknown therefore the total groundwater extraction q well for the whole study area was estimated by a distributed version of the rushton model wöhling et al 2018 and is also used in our calculations to extract groundwater from each store q well is divided 4 parts according to the percentage areas of the individual lower stores overall if one desires interpretation of these four lower stores they can be seen as a four cell groundwater flow model that is already simplified to unidirectional flow from each lower store to its downgradient eastern neighbours based on the overall slope of the terrain and based on the regional direction of groundwater flow in summary the equations for the four groundwater stores are beginning with s gw 1 6 s gw 1 t s gw 1 t 1 q gw 1 t q perc t p 1 q well 1 t a 1 qexc s 21 s 22 t δ t where s gw 1 t and s gw 1 t 1 are the storages in the first groundwater store at current and previous time step q gw 1 t is the discharge from s gw 1 to the spring discharge outlet at q gw q perc t is the volume of flow percolating from the upper to the groundwater store p 1 denotes the percentage percolation from s vz into s gw 1 q well 1 t is the groundwater extraction from s gw 1 t through pumping wells a 1 is the percentage of surface area representing s gw 1 t and qexc s 21 s 22 t is the excess volume flow from s gw 1 to s gw 2 correspondingly the equations for s gw 2 s gw 3 s gw 4 are 7 s gw 2 t s gw 2 t 1 q gw 2 t q perc t p 2 q well 2 t a 2 qexc s 21 s 22 t qexc s 22 s 23 t δ t 8 s gw 3 t s gw 3 t 1 q gw 3 t q perc t p 3 q well 3 t a 3 qexc s 22 s 23 t qexc s 23 s 24 t δ t 9 s gw 4 t s gw 4 t 1 q gw 4 t q gw 2 t q gw 3 t q well 4 t a 4 qexc s 23 s 24 t qexc s 24 q out t δ t s gw 4 represents the confined part of the aquifer and there is no direct recharge from the land surface the groundwater components leaving the respective groundwater stores are 10 q gw i t k 3 i s gw i t 1 here q gw i million m 3 d 1 denotes the slow runoff or groundwater flow from groundwater saturated stores i enumerates the four groundwater stores and k 3 i day 1 are the recession coefficients for the corresponding slow runoff components the groundwater flow routing between these groundwater stores and emerging springs as total outlet discharge is inspired by the major flow routes in the model domain the runoff from each groundwater store affects the dynamics of the total spring discharge from the wairau aquifer this leads us to the following routing q gw 1 t emits from s gw 1 t and becomes input to q out q gw 2 t and q gw 3 t become input to s gw 4 t whereas q vz 1 t q vz 2 t and q gw 4 t contribute directly to q out fig 3 provides a conceptual plot of these flow paths overall the total spring discharge q out is the sum of fast and slow components q vz 1 t and q vz 2 t from s vz the selected groundwater flows q gw 1 t and q gw 4 t qexc s 24 q out t from s gw 4 and deep groundwater losses q df m 3 s 1 towards the coast 11 q out q vz 1 t q vz 2 t q gw 1 t q gw 4 t q exc s 24 q out q df where q exc s 24 q out is the excessive flow volume from s gw 4 t into q out q df is the deep groundwater flow as a constant flux boundary condition with a constant value of 0 0604 10 6 m 3 s 1 estimated from spring flows in grovetown lagoon wöhling et al 2018 wöhling et al 2020 with this our model conceptualization is complete the data required by lghm as model inputs and its outputs are summarized in appendix a 1 2 5 model parameter and their ranges the lghm contains eleven calibration parameters out of thirteen free model parameters in total the eliminated parameters are k d day 1 and p 2 which represents the percentage percolation from s vz into s gw 2 the wairau aquifer contains highly conductive gravels and surface recharge is assumed to become groundwater without significant delay thus k d is fixed to k d 1 each calibration parameter with its description unit and lower and upper bounds are summarized in table 3 in the following we describe hydro geo logical reasoning to obtain admissable ranges during calibration as presented in section 2 4 the aquifer is represented by 4 linear reservoirs in which the outlet discharge is controlled by recession coefficients units of day 1 that describe characteristic residence times of water in these stores as in hbv the value of these coefficients must be between 0 and 1 day 1 according to the model physics but can be chosen more narrowly in this study the upper and lower limits of the recession coefficients table 3 are taken from parameter ranges already used in previous studies seibert 2000 abebe et al 2010 seibert and vis 2012 dakhlaoui et al 2012 rusli et al 2015 the range of the upper reservoir threshold uzl is fixed between 0 and 30 million m 3 due to the highly transmissive nature of the aquifer wöhling et al 2018 it is considered that in a case of flood events the maximum storage in the upper reservoir will be 30 million m 3 there are two coefficients α 1 α 2 of the power function to estimate q ex t the reason for taking the upper and lower limits of these coefficients is already explained in section 2 4 the percolation percentages p 1 p 2 and p 3 must individually fall between 0 and 1 and must sum up to one according to the hydrogeological conditions s gw 1 and s gw 2 take large parts of percolation as input s gw 3 takes the least contribution whereas s gw 4 is confined with an impervious layer on top to ensure this distribution of percolation we calibrate p 1 and p 3 subject to the constraints and p 2 is fixed to p 2 1 p 1 p 3 as shown in table 3 this way of calibration helps to reduce one more parameter without compromising over the quality of model results the old o paoa channel as shown in fig 5 of wilson 2016 is starting within the vicinity of the s gw 1 area and its high yielding gravels are also in direct contact with the wairau river at this location therefore we have taken a larger upper limit for p 1 0 75 as compared to p 3 0 25 2 6 parameter calibration the model is calibrated by minimizing the weighted sum of squared errors between given and simulated time series the calibration time period in our lghm is the same as in the calibrated modflow model wöhling et al 2018 that acts as a virtual reality with 917 daily time steps of spring discharge and aquifer storage in this study initial conditions are given to the lghm by spin up simulations between january 01 2000 and june 30 2013 the initial conditions are specified as full storage i e 30 million m 3 for the upper store and a total of 310 million m 3 for the lower stores in our study the model is calibrated on time series of q out and on the change of total groundwater storage δ s although we could extract virtual data on total storage s t from modflow we use δ s as such data types could be available at large scales from gravity recovery and climate experiment grace data products andersen et al 2005 to avoid problems of equifinality that could lead to a rapid decline of groundwater stores in lghm when using only δ s we add a mean estimate of total groundwater storage s as an additional soft information for regularization with hydrogeological information the change in total gw storage δ s is computed as 12 δ s t s t s t 1 where s t is the sum of all 4 groundwater stores 13 s t s gw 1 t s gw 2 t s gw 3 t s gw 4 t the objective function for calibration is 14 θ opt argmin θ θ t 1 n w 1 y sim qout t θ y obs qout 2 w 2 y sim δ s t θ y obs δ s 2 λ y sim s t θ y obs s 2 where the vector θ with eleven elements denotes the paramters to be optimized θ is the parameter space implied by the parameter ranges y sim are the simulated values by lghm q out δ s and s y obs are the modflow simulated data q out δ s and s that serve as virtual reality w 2 and w 1 1 w 2 are adjustable weights to weigh q out and δ s and λ is an adjustable weight to adjust the regularization by s at first the smallest possible weight value λ for the regularisation term is selected to explore the effect of w 1 in finding a compromise solution between the fit to q out and δ s the model is calibrated 100 times by increasing the weight w 2 given to δ s from 0 to 1 in increments of 0 01 correspondingly the weight w 1 given to q out decreases from 1 to 0 in such a way that weights given to both objectives always sum up to 1 the final decisions on λ w 1 and w 2 are discussed in section 3 2 our objective function is differentiable but at the same time could be multi modal thus we use a genetic algorithm ga embedded in the matlab r2018a programming environment after we realized that the calibration problem with gradient methods shows calibration results that depend on the initial parameter guess after globally exploring the solution space with the ga we refine the search locally by using the lsqnonlin least squares optimizer also embedded in the matlab r2018a programming environment in doing so we let lsqnonlin start at the best solution found by the ga we run the ga with a population size of 200 that evolve over 1100 generations for lsqnonlin the stopping criteria is set to a tolerence value of 10 6 2 7 model performance metrics we evaluate the performance of the lghm model in calibration and validation by using the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 15 nse 1 t 1 n y sim t θ opt y obs t 2 t 1 n y sim t θ opt y obs t 2 where θ opt denotes the optimized paramters t enumerates the time steps y sim t is the simulated data of spring discharge q out t and groundwater storage difference δ s t by lghm y obs t is the corresponding modflow simulated data and y obs t is the mean value of the corresponding modflow simulated data over time besides nse as the main performance criterion in this study we also estimate the linear correlation coefficient r between reference and simulated values 16 r t 1 n y sim t θ y sim t θ y obs t y obs t t 1 n y sim t θ y sim t θ 2 t 1 n y obs t y obs t 2 where y sim t θ opt is the mean value per simulation time series to take a global view onto the water balance we estimate the percentage bias means bm of our simulated values of q out q ex and and total groundwater storage s a bm value of zero indicates no error in mean simulated values a positive negative bias represents overestimation underestimation of model simulations respectively 17 bm 1 y sim t y obs t 100 2 8 model testing strategy the concept of lghm is tested in two parts first the lghm is calibrated by considering not only q out but also groundwater storage data δ s and s section 3 1 followed by the final selection of calibration weight section 3 2 subject to geological plausibility criteria section 3 3 after fixing the calibration weight assisted by plausibility checks in section 3 3 the model is now validated with a list of additional checks i against the remaining one third of the given data section 3 4 1 ii then the internal variables are checked section 3 4 2 iii this study claims to follow the natural behaviour of the wairau aquifer therefore it is necessary to test the spatially decreasing groundwater heads section 3 4 3 iv the total groundwater storage s estimated from lghm is compared against modflow section 3 4 4 v the model is compared to modflow under extreme drought conditions which tests the quality of our lghm completely outside the calibration conditions section 3 4 5 vi to test the ability of lghm to give long term predictions it is validated against modflow with synthetic long term weather data section 3 4 6 vii finally the summary of this validation is presented section 3 4 7 3 results and discussion 3 1 calibration fig 4 shows the trade offs among the nse estimates of q out and δ s with increasing weigths w 2 assigned to δ s objective the results of three different cases are compared and discussed here in the first case the lghm with four lower stores lghm 4ls is calibrated only on q out magenta upward pointing triangle and represents the normal practice of calibrating conceptual hydrologcal models in the second case the lghm 4ls is calibrated by considering groundwater storage information δ s s along with q out dual calibration as indicated with blue dots our third case contains dual calibration of lghm with only a single lower store 1ls as shown with gray dots this compares our lghm to the closest possible of a conventional rainfall runoff model furthermore in dual calibration cases two and three the effects on q out δ s q ex and s with increasing weights w 2 assigned to the δ s objective are analysed for clarity the nse values at w 2 1 are not shown in fig 4 note that at this final weight w 2 1 the lghm is calibrated without considering q out at all at first part of dual calibration with 4ls second case we select the weight of our regularisation term λ as discussed in section 2 6 after repeated model runs finally we choose a weight of 0 85 for λ and fixed it for the remainder of this study it is the smallest value at which we consistently avoid cases in which a slight bias in δ s t over time leads to a total depletion of all aquifer storage in short time for lghm with 1ls third case the regularisation term λ is not considered we do this because lghm with 1ls is not a suitable model structure for groundwater storage simulation for that case λ may keep the reservoir full but we found that it influences negatively the dynamics of groundwater storage change δ s in the first case normal practice the nse values of q out and δ s are 0 96 and 0 74 respectively as compared to this the lghm 4ls with dual calibration second case at w 2 0 provides the same nse value of q out but the nse value of δ s increases to 0 92 the lghm 1ls with dual calibration third case at w 2 0 provides the lowest nse values of both q out nse 0 92 and δ s nse 0 64 as compared to first two cases next one can see that the q out objective is more sensitive to a change in weights w 2 and w 1 1 w 2 as compared to δ s it can be seen that the lghm 4ls with dual calibration with increasing weights w 2 assigned to δ s shows a better trade off among the nse values of our two objectives q out and δ s there is a slight exception in this case at w 2 0 9 with a slight increase in q ex as compared to neighbouring points as a result the nse value increases for q out and decreases for δ s but we will pay no further attention to it for a more detailed analysis of the water balance we now discuss the bias of the calibration results fig 5 for the means of q ex q out and total groundwater storage s as described in section 2 7 because these numbers hardly change with weight w 2 we provide for cases two and three their average across all calibration runs with varied values of w 2 the bm for q ex in lghm 4ls with λ 0 normal practice case one and in lghm 4ls with λ 0 85 dual calibration case two for all increasing weights w 2 assigned to δ s are 1 6 and 0 3 however the bm for q ex in lghm 1ls dual calibration case three for the same increasing weights w 2 rises to 7 5 the bm for q out under all cases is equal to 0 however the bm of s in the dualy calibrated lghm 4ls with λ 0 case one is at 59 and in lghm 4ls with λ 0 85 case two is equal to only 0 05 for all weights w 2 however the bm for s in lghm 1ls with λ 0 case three is 95 4 for all w 2 which shows that the aquifer remains completely empty small bm values show good agreement with the benchmark modflow and the high bm values show that the model is completely off for these cases this supports the idea of incorporating information related to groundwater storage i e to use lghm with four lower stores therefore from now onwards in our study only the dual calibration case with 4ls and the corresponding weights w 2 w 1 1 w 2 will be discussed all calibration parameters except uzl and k 1 which are associated with q vz 1 are sensitive to model outputs it is seldom that the s vz exceeds uzl and otherwise q vz 1 remains mostly inactive the other five recession coefficients table 3 play an important role in the model and are senstive towards internal responses q out δ s and s the two parameters α 1 and α 2 related to power law function of q ex are naturally sensitive too as to determine groundwater recharge rates finally p 1 p 3 and hence p 2 1 p 2 p 3 are for percolation of water to lower stores they play an important role to maintain the natural characteristics like decreasing groundwater heads from west to east 3 2 selecting the calibration weight w 2 the previous section showed that the calibration weight w 2 given to δ s has a direct impact on percolation groundwater storage and on the overall dynamics of the internal responses like q out and δ s now we select the final weight w 2 as a compromise solution we do so without compromising over geological and hydrological plausibility criteria in our study area such conditions mainly involve decreasing groundwater heads along the downstream direction of the river sub surface flow paths and aquifer storage depletion one of the criteria to select a weight w 2 for δ s was the fulfillment of all the validation checks as described in the next sections although it is difficult to decide the final weight as most of them fullfill the above mentioned criteria we restricted our choice of weight to the range where the nse for q out is not compromised but for δ s there is already some improvement for the remainder of this study we fix the weight for δ s at w 2 0 03 red plus symbol in fig 4 all results and discussions presented in the remainder of this study are based on this choice λ 0 85 case two w 2 0 03 and hence w 1 0 97 3 3 plausibility checks table 3 shows the optimized parameter values for the selected weighting note that the optimized values of recession coefficients for interflow and base flows are quite small nevertheless these values are very plausible due to simple ratios in the hydrogeological system between two types of values 1 the live aquifer storage of the wairau aquifer is 10 to 15 million m 3 with a total aquifer storage of 310 million m 3 wöhling et al 2018 wöhling et al 2020 2 the average annual flow of the largest spring sc1 is 4 m 3 s 1 wöhling et al 2018 wöhling et al 2020 additionally fig 7c shows that the total spring discharge lies between 5 and 8 m 3 s 1 in which the contribution of sc1 is 54 6 when comparing 1 and 2 the recession coefficients in eqs 5 and 10 have to take on very small values as only a very small fraction of water stored leaves at sc1 per time step the portion of q ex taken by s gw 1 s gw 2 and s gw 3 is p 1 60 4 p 2 25 7 and p 3 13 9 this spatial distribution of gw recharge based on optimised parameters table 3 confirms the hydrogeological conditions associated with aquifer recharge recall that s gw 4 is conceptualized as confined aquifer see section 2 4 so it was defined to receive no percolation the river exchange flow q ex in our lghm is estimated by using the parameters α 1 and α 2 of the power law as described in sections 2 4 and 2 5 note that these parameters are optimized as shown in table 3 along with all other model parameters we compared it with the modflow exchange flow blue dots as shown in fig 6 the resulting function black dots offers a good shape of fit so we see the equation as an appropriate choice the empirical cumulative distribution function ecdf of q ex for both modflow and lghm are shown and compared in appendix a 2 yet there is substantial scatter around our power law the exchange between river and groundwater is a complex phenomenon and varies locally the modflow model wöhling et al 2018 as used in this study incorporates 3 dimensional aquifer heterogeneity which is not possible at the strongly lumped scale of our lghm if further model improvement was desired a multivariate regression including q riv and storage values e g s t could be conducted as the problem is most likely spatially explicit and time variant next we look at the detailed time series of q out and δ s while fig 7a shows q riv as a key model driver fig 7b shows q ex simulated by our lghm and modflow and fig 7c shows the corresponding comparison between modflow blue and simulated black total spring discharges fig 7d shows the comparison between modflow blue and simulated black δ s estimates the simulated results of δ s from lghm show high correlation with the modflow estimates and follow clearly the seasonal behaviour of the wairau aquifer for example from april to september autumn winter the q riv q ex and q out show higher flow rates similarly δ s also shows higher values in this time period the effect of summer river low flows between december and february and the corresponding low groundwater recharge from the wairau river can also be seen this confirms visually the very good nse values reported in section 3 1 and also shown in fig 7 looking at the details there is a slight under estimation and over estimation of q out at upper and lower discharge peaks as compared to modflow similarly δ s also shows the same trend as there is a slight mismatch at positive and negative extremes the main reason for this disagreement is the spatially averaged presentation of q ex eq 1 as discussed above quantile quantile plots of q out and δ s for modflow and lghm are shown in appendix a 3 3 4 model evaluation 3 4 1 model evaluation with independent data the validation data are modflow simulated q out and δ s in the time period from may 13 2016 to february 20 2017 fig 8 shows that the model simulations during the validation period fit well to the modflow results the nse values of q ex and q out fig 8b c decrease from 0 61 and 0 96 at calibration to 0 45 r 0 72 and 0 86 r 0 93 at validation note that q ex is not a part of our objective function the nse of δ s fig 8d has increased from 0 79 to 0 83 r 0 92 the reason for change in these nse values mainly lies in the time period chosen for testing the validation period has only 284 days by chance there are fewer river fluctuations and a lower number of days with high flows compared to the calibration period further fig 8b shows that the power law simplification to q ex mostly matches the pattern of the modflow estimate of the exchange flux but differs in magnitude yet since both q out and δ s in fig 8c and 8d respectively are well reproduced the achieved exchange flux estimates resemble a sufficient linkage representation between river and groundwater within our lghm the coefficient of correlation r in all cases related to our objectives is greater than 0 9 the shape of residuals is the same as already seen during calibration see section 3 3 overall the validation demonstrates a very good fit to the reference model therefore we conclude that the lghm model can predict selected system states to a similar accuracy as the more complex modflow model but in a fraction of time details on computing time are provided in section 3 4 7 3 4 2 internal variables as an additional validation check it is interesting to compare the model results with individual internal responses like sc1 spring discharges modflow spring flows are calibrated to sc1 data and the catchment data indicate that total outflow from all springs is in a relatively fixed proportion to sc1 modflow indicates that sc1 discharges are consistently around 54 6 percent of the total spring discharges to test this proportionality of q out in lghm with sc1 we compare the modflow time series for sc1 with 54 6 percent of the lghm simulated q out fig 9 the lghm doesn t quite catch the lower flows q sc 1 3 m 3 s 1 and the peaks because q out from lghm are lump estimates of all springs nd sc1 sc2 ss or1 and or2 as defined in section 2 2 and we have specified it as a fixed percentage 54 6 to compare with the modflow q sc 1 still this comparison shows a good nse value of 0 91 r 0 97 for this non calibrated quantity this validation check increases our confidence in lghm even though this particular test is not important for the accurate prediction of water balance components 3 4 3 groundwater heads test in the featured model domain observed groundwater levels are decreasing from west to east superimposed by some temporal variability we test this downstream trend in the four zones of our lghm as we calibrated only on δ s values of total storage not zone wise s t or heads this is an additional validation thus we convert time series of lghm storage volumes v within each zone to gw heads by dividing the stored volumes by porosity ϕ and area a other options than comparison of converted heads were not available because the already existing modflow model gives only the information of simulated gw heads at selected monitoring wells the third zone of our lghm does not contain any piezometric well in modflow fig 1 whereas the number of wells in the first second and fourth zone are 2 6 and 2 respectively therefore we represent the head in the third zone dark blue box plot in fig 10 by taking the average between the wells 1685 10426 and 3009 located at the downstream end of the second zone and the two wells 4577 and 3954 located at the beginning of the fourth zone fig 10 shows box plots of the resulting comparison as compared to our lghm the modflow based gw heads in the first second and fourth zone represent dynamic and spatial distribution in a single box plot blue the lghm stores reflect only temporal dynamics of spatially lumped quantities the lghm heads show the largest difference in the first zone as compared to the second third and fourth zone the difference between the median gw levels from modflow and lghm in the first zone is 8 7 m in the second zone it is 2 1 m in the third zone it is 4 4 m and in the fourth zone it is 4 1 m we do not rate this discrepancy as large because the estimation of zone wise heads from the wells in modflow is most likely also inaccurate this holds especially in zones 1 and 4 where large gradients and a sparse spatial distribution of wells exist note that the s gw 4 zone in our lghm is considered confined and water level fluctuations fig 10 in this zone are only due to groundwater abstraction overall fig 10 confirms that the simulated gw heads decrease from west to east with a satisfying fit 3 4 4 total groundwater storage while the existing modflow model was not set up for providing zone wise storage it can easily return the dynamics of total groundwater storage gws within the total model domain the overall time averaged gws in our lghm and in modflow are 285 73 million m 3 and 286 95 million m 3 respectively the discrepancy between them lies within 0 5 and we rate this as a positive validation however fig 8d also showed a good match of δ s between modflow and lghm during validation the reason for this small discrepancy is that the lghm is an explicit consideration of the domain s water balance fig 11 depicts the empirical cumulative distribution function ecdf of groundwater storage anomalies these anomalies are computed by removing the respective mean value the standard deviation of these anomalies for the lghm is 4 14 million m 3 and 2 38 million m 3 for modflow correspondingly the ecdf of the lghm is wider than that of modflow 3 4 5 extreme drought test at spring creek for more extreme scenario testing of the lghm model we investigate an extreme drought scenario where the wairau river is reduced to 5 m 3 s 1 from july 01 2014 up to the end of the simulation time period the same scenario was already used in wöhling et al 2018 results are shown in fig 12 at the start of the simulated extreme drought the groundwater storage in both models lghm and modflow starts decreasing fig 12d the simulated q out from our lghm follows the same trend as modflow up to the first 30 days fig 12c after this over the next about nine months of the simulated drought a significant difference of up to almost 15 builts up between q out predicted by modflow and lghm see fig 12c in lghm the recession coefficients control the emptying of groundwater storage whereas modflow features groundwater flow in a heterogeneous unconfined 3 dimensional aquifer therefore it is expected to get different q out estimates from lghm for this non calibrated quantity however the δ s estimates from both modelling approaches show only slight differences the main reason for this difference is the use of the power law function in lghm while modflow uses the river package as described in section 2 3 this power law function allows only water infiltrating into the aquifer while the modflow exchange flux can go in both directions despite this arguably strong simplification our lghm shows similar temporal dynamics as the modflow for δ s in fig 12d although being slightly biased fig 12b shows that the river exchange flux q ex from modflow drops to zero immediately after the river discharge q riv reduces to 5 m 3 s 1 then it rises again and almost fully agrees with our lghm the reason for this intense decrease of q ex simulated by modflow is that the net river groundwater exchange flow at that particular day becomes zero in contrast our lghm estimates q ex is based on the power law function eq 1 as already explained in section 2 4 and does not show such a large drop in the flux the remaining slight rise and fall in q out and δ s values in both models fig 12 c d during the simulated drought are due to other model forcings like groundwater abstraction for irrigation and land surface recharge considering fig 12 entirely we find that the lghm provides a plausible estimation of a regime shift to the simulated drought condition yet the discrepancies between its predictions and those from modflow require further discussion the reason why lghm estimates q out to be larger september 2014 to early 2015 than modflow lies in the stark simplification of the model structure this simplification might be too strong to capture processes that newly occur such simplification errors might inflate for extreme scenarios such as floods droughts hydrological regimes that have not been observed yet and potential changes in farmers behaviors as a response to changes in climate and or water management regulations moreover many natural and anthropogenic factors like river recharge land surface recharge and groundwater abstraction also influence adaptation strategies for sustainable management of groundwater resources this includes the change in amount and time of groundwater withdrawal by farmers as well as new mitigation measures taken by the authorities none of the two models are equipped to anticipate and predict such management strategies but they can both be coupled with water management models also neither the lghm nor the modflow model parameters are trained for such an extreme conditions since model results depend on the implemented physics and hydro geo logical knowledge from the site to appropriately estimate the change of fluxes and storages it is no surprise that they differ under a drastic regime change therefore although we find the temporal pattern and orders of magnitude of the simulated quantities plausible the application of the lghm just like any other model for long term predictions under unseen conditions should be carried out with caution overall the main benefit of using the lghm for such scenario analyses lies in providing a potential range of plausible predictions for example q ex in modflow fig 12b shows a large drop as compared to lghm at the start of extreme drought scenario this unknown natural behaviour of q ex in modflow may be criticized as overshooting and the lghm prediction here provides a plausible alternative similarly δ s in modflow exhibits a sudden drop at the start of the drought period in comparison the δ s in lghm shows lower values and exhibits some deep drainage during less extreme condition 3 4 6 validation against modflow in synthetic long term simulations finally we test the future long term prediction capability of our lghm by validating it against modflow long term forecasts as a synthetic reality the simulations are conducted for the years 2000 to 2040 with extended synthetic input time series for the years 2017 2040 details on how we generated future input data considering current climate conditions are provided in appendix a 4 the resulting comparison between lghm black and modflow red for q out and δ s are subsequently discussed for a clear representation of comparison between modflow and lghm we split the future time period into two parts the time period between 01 01 2017 and 31 12 2028 is shown in fig 13 whereas fig 14 depicts the time period between 01 01 2029 and 31 12 2040 although the lghm simulated q out and δ s values underestimate upper and lower extremes they agree well with the dynamics of the river flow and reproduce the modflow results reasonably well this is confirmed by nse values of 0 89 r 0 95 fig 13 and 0 9 r 0 96 fig 14a for q out and 0 8 r 0 89 fig 13 and 0 77 r 0 97 fig 14b for δ s the reason for the discrepancy between model results is due to the difference in q ex as already discussed in section 3 1 note that as compared to spatially resolved models like modflow the lghm represents the system by just 4 sequential stores this has an impact on how changes in boundary conditions propagate through the hydrological system this has been tested by simplifying our lghm to just one store in this case the differences in flow amplify results not shown the same applies to groundwater recharge and abstraction where responses to changes of these external forcings are more smoothed out in modflow and the overshooting within our lghm applifies with decreasing number of stores results also not shown however as compared to traditional conceptually lumped models our lghm contains hydrogeological information and instead of calibration only on q out it is also calibrated on δ s such aspects make our modeling approach more plausible to represent the natural system the lghm has shown the same efficiency and performance to reproduce modflow results as it did during calibration see section 3 1 and and evaluation see section 3 4 1 3 4 7 summary of validation overall these validation results indicate that the lghm approach is well suited for long term predictions both modeling approaches lghm and modflow have their strengths and weaknesses model formulation with simplification as in the case of lghm comes at the cost of underestimation or overestimation of internal responses single linear bucket models exhibit exponential hydrographs and therefore come with the tendency to overshoot peaks and lows see section 3 4 6 with more and more buckets in line analytically approaching a nash cascade this peaking becomes smeared out our model has parallel flow componenents and several non linearities hence lghm is not exactly on the continuum between one bucket and the nash cascade yet we find it worthwhile to theoretically allocate lghm with respect to these two extremes we can assume that adding more buckets to our model would buffer extreme peaks and lows more strongly physical based models allow a more detailed description of physical processes but our lghm is simple and easy to apply additionally the computational efficiency is very high as compared to the modflow model the average runtime for a lghm simulation period of 40 years 2000 2040 is 1 5 s on an intel core tm i5 4590 cpu 3 30 ghz using the matlab r2018a programming environment modflow takes 25 min with the same equipment in addition modflow requires input files in a specific format and more spatially explicit data note that we had to break down the modflow simulations into three separate runs for technical reasons our lghm can therefore easily be employed for long term simulations with input data stemming from climate earth system and meso scale catchment models 4 summary and conclusions the goal of this study was to extend lumped conceptual hydrological models towards a lumped geohydrological model lghm with the addition of tailor made groundwater stores the model building is inspired by the geometry and hydrogeological large scale properties of major aquifers in the study area i e attributes that can often be obtained from geological knowledge hence these models require much less computational effort and less expensive site investigation than comparable spatially explicit numerical flow models being lumped lghm cannot describe the spatial variability of natural process but is suitable for large scale quantities such as total groundwater storage the lghm model was calibrated on both groundwater storage data and discharge data our real world application site was the unconfined wairau aquifer in the marlborough region new zealand to avoid the problem of lack of data to validate the lumped conceptual model an already existing modflow model for the study region wöhling et al 2018 served as a virtual reality the prediction capability of lghm is rated based on matching the simulated discharge and groundwater storage of this virtual reality we find that lghm with four lower stores is efficient reliable and fully capable of representing large scale natural processes almost as accurate as the modflow model itself overall we rate the model results with this model structure as highly satisfactory the lghm is about 3 orders of magnitude faster than modflow and can be considered a reasonable alternative for estimating both discharge and groundwater storage there are some discrepancies in model results which can be attributed mainly to river groundwater exchange flux q ex the recharge mechansim from the braided wairau river is complex and still lacks fundamental process understanding the possible limitation of our lghm approach is that it simulates groundwater at an almost fully lumped scale so it cannot be compared directly to groundwater level data instead it has to be calibrated on and only predicts spatially aggregated groundwater storage however the groundwater part in our proposed lghm resembles a minimalistic version of a physically based numerical groundwater flow model with just a few here 4 cells representing darcy type groundwater flow in unconfined and or confined aquifers overall we were able to reproduce the modflow simulations well matching most of the temporal dynamics of the simulated flow and storage in our modelling approach however neither modflow nor lghm consider aspects of a change in water use as a response to a changing climate and or changes in water management regulations especially future spatio temporal changes of the distribution of groundwater abstraction for irrigation and municipal water use as well as water recharge are challenging to be extrapolated lghm is an attractive fast alternative to more computationally demanding models such as modflow and thus can be useful for example for operational forecasting and predictive uncertainty quantification with potentially little loss of accuracy the nse values of total spring discharges q out and gw storage change δ s during calibration are 0 96 and 0 79 respectively during validation the nse value is only slightly smaller at 0 86 for q out and larger at 0 83 for δ s respectively further there is a good agreement between long term simulations of lghm and modflow acting as a synthetic virtual reality in a scenario simulation for 2017 2040 this is confirmed by nse values of 0 89 and 0 9 for q out and 0 8 and 0 77 for δ s respectively our lghm has passed through various additional checks like i hydrological plausibility ii an extreme drought scenario and iii inspecting the river groundwater exchange flux we purely used modflow as a virtual reality for testing the information used to build the lghm model are only hydrogeological information of the site description that modflow modelers have used in greater spatial detail at no point have we extracted information for our lghm model building directly from the modflow model the only simplification we did overall is that we used time series data on total groundwater storage simulated by modflow thus to transfer the lghm idea to other study areas one will indeed need a data product for calibration e g from grace or from interpolated groundwater maps to replace these virtual time series by real data based on the performance of lghm in short and long term predictions and due to its flexible model structure lghm can be adapted easily to other catchments the main conclusions from this study are the lghm reproduces virtual reality data with a high accuracy for different hydrological conditions yet with strongly reduced data requirements the lghm is computationally three orders of magnitude faster than physically based numerical models here modflow is easy to implement and has a flexible model structure this modelling approach was demonstrated to be applicable for long term simulations under current climate conditions our lghm could as well be built inside flexible modelling frameworks like superflex fenicia et al 2011 marmott knoben et al 2019 or raven craig et al 2020 if model refinement is desired in this specific catchment we would recommend to adopt a more complex regression model for river groundwater exchange flux we will explore future climate scenarios in a follow up study where the computational speed is highly important for performing a bayesian uncertainty analysis the accuracy and computational efficiency of our lghm model demonstrates clearly its applicability to replace physically based models here modflow for large scale groundwater storage simulations and forecasts we see this as proof of concept to model other catchments with lghm models as well therefore lghm offers a lean computationally cheap model alternative that also enables stochastic scenario simulation and sampling based uncertainty quantification with methods such as markov chain monte carlo sampling credit authorship contribution statement fahad ejaz conceptualization methodology data curation formal analysis validation writing original draft writing review editing thomas wöhling writing review editing methodology supervision visualization marvin höge visualization investigation writing review editing wolfgang nowak supervision writing review editing methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors received financial support by graduate school scholarship programme gssp 2018 grant no 57395813 from the german academic exchange service daad we acknowledge the support by the stuttgart center for simulation science simtech the german research foundation dfg within the research training group integrated hydrosystem modelling grk 1829 the chair of hydrology at tu dresden and co funding by the new zealand ministry of business innovation and employment mbie contract lvlx1901 further we would like to thank the marlborough district council mdc for providing the data for the wairau case study appendix a a 1 lghm inputs and outputs table 4 shows lghm model inputs their description and source these inputs have already been explained in the manuscript but are summarized here these inputs include wairau river flows q riv at barnetts bank near sh1 bridge groundwater extraction q well surface recharge q rec deep groundwater flow as constant flux boundary condition and aquifer properties our lghm output contains total spring discharges q out groundwater storage change δ s and total groundwater storage s a 2 comparison of river groundwater exchange flux fig 15 shows the fitted power law function orange circles between wairau river flows and modflow simulated q ex for the time period between october 31 2013 and february 20 2017 fig 15 also shows a complete range of q ex simulated by modflow and lghm for the same time period fig 16 shows a comparison of empirical cumulative distribution functions ecdf of river groundwater exchange flux q ex simulated by modflow and our lghm for the simulation period between october 31 2013 and february 20 2017 it can be seen that while there is a mismatch between both models in the occurrence of frequency of higher and lower q ex the overall magnitudes and frequencies are represented in an acceptable magnitude the reason for mismatch lies in the lumping of exchange processes into the univariate power law regression a 3 comparison of total spring discharges and groundwater storage change figs 17 shows quantile quantile plots of total spring discharges q out simulated by modflow and by our lghm for the entire simulation period between july 01 2013 and february 20 2017 dashed in red colour is the 1 1 line representing a perfect fit it can be clearly seen that there is a mismatch among these models at upper and lower extreme values as a consequence there will be slight overestimation of lghm predictions when modflow q out 5 6 m 3 s 1 and likewise some underestimation in lghm predictions when modflow q out 8 2 m 3 s 1 similarly fig 18 presents quantile quantile plots of total groundwater storage change δ s simulated by modflow and by our lghm it can be seen that there is a good match between both models at lower values of δ s up to almost 0 15 million m 3 d 1 and after that the discrepancy grows however at extreme values with δ s greater than 1 12 million m 3 the discrepancy decreases again as a consequence there will some underestimation of lghm predictions when modflow δ s estimates are approximately between 0 15 and 1 12 million m 3 d 1 the main reason for this disagreement is again the lumped presentation of q ex as discussed in the section 3 1 a 4 data generation and river flow simulation to generate synthetic future weather and river flow at first we employ a statistical weather generator vg that is based on vector autoregressive var processes schlabing et al 2014 to generate future time series of rainfall r and temperature t fig 19 depicts the fitting of generated r and t time series on the measured data the time series of measured data is available from the year 2000 to 2016 we found a weibull distribution for r and a normal distribution for t as a suitable functions that give a good fit fig 19 dashed in red colour is the 1 1 line representing a perfect fit of simulated and observed distributions then we estimate the reference evapotranspiration by using the hargreaves samani equation hargreaves and samani 1985 as follows 18 et rc 0 0135 c hs r a λ t max t min 0 5 t a 17 8 where et rc is the reference crop evapotranspiration mm day 1 r a is the extraterrestrial radiation mjm 2 day 1 t max t min and t a are respectively the maximum minimum and average daily air temperatures c c hs is an empirical coefficient modified after samani 2000 19 c hs 0 00185 t max t min 2 0 0433 t max t min 0 4023 t min and t max in eqs 18 and 19 are estimated from the daily averaged temperature values t generated from the weather generator schlabing et al 2014 for this purpose the standard deviation 5 4 of t is subtracted and added tmax min t std dev fig 20 shows t and r variables generated from vg and et rc estimated from the hargreaves samani equation these simulated climate variables r t et rc are then used as an input to an existing rainfall runoff model for the entire wairau catchment this model has been developed with the gr4j model santos et al 2017 as implemented in the marrmot toolbox knoben et al 2019 model parameters were calibrated using markov chain monte carlo methods at tu dresden and this model yields wairau river discharge at the sh1 gauging station the time series of river discharge at rock ferry is then estimated from the predicted discharge at sh1 with the addition of 7 64 m 3 s 1 as determined from the correlation analysis of historical data wöhling et al 2018 the quality of simulated wairau river flows is checked by comparing the basic statistics with the measured data between 2001 and 2016 the spin up period of rainfall runoff model to simulate river flows is 1 year table 5 shows a close match and simulated river flows agree well with the observed flows 
3668,freezing and thawing induced variations of groundwater level and the corresponding changes in water storage in the saturated zone have been observed in regions with a shallow water table however the vertical migration of water under the effect of the freezing thawing process on shallow groundwater has not been accurately quantified and the influencing factors of groundwater level dynamics during the freezing thawing period remain unclear reasonable representation of this process on the field scale is very important for improving our understanding of water budgets during the freezing thawing cycle in this study we investigated the main factors controlling groundwater level fluctuations during the freezing thawing period at two sites in northeast china through comparative analyses of long term field observations of air temperature precipitation snow depth liquid soil water content soil water temperature and fluctuations of groundwater level we found that the seasonal variations in groundwater table coincided with the soil frost freezing thawing seasonal cycle which exhibited a v shape freezing induced groundwater decline occurred only when the maximum depth of effect of freezing and thawing overlapped with the maximum height of capillary rise in unconfined groundwater moreover the decline was controlled by air temperature snow cover soil media properties and soil water distribution by comparing the change trends of groundwater level and calculating the water budget the process of the rise of groundwater level could be further divided into three stages during which groundwater was recharged by frost melt water and snowmelt water among them snowmelt water had a limited contribution accounting for less than 20 of the total recharge the results have potential applications in the development of reasonable water management plans for irrigation using which soil salt can be washed out and suitable soil thermal and moisture conditions can be maintained for winter crops or farming in the next year keywords groundwater response freezing thawing period controlling factors frost depth snowmelt 1 introduction in cold climate regions seasonal freezing and thawing of soil control and affect the hydrogeological environment as a result seasonal frozen regions of the world exhibit a distinct groundwater regime different from those of non frozen and permanently frozen regions ireson et al 2013 this difference can be attributed to three factors firstly seasonal frozen soil is a special aquiclude or aquitard whose permeability varies with temperature antecedent soil moisture and soil structure and the infiltration storage and redistribution of water below the ground are likely to be highly dynamic due to phase changes which in turn play a decisive role in the formation and migration of groundwater as well as the distribution pattern and circulation pattern of groundwater dai et al 2019a ireson et al 2013 quinton et al 2005 secondly frozen soil not only directly participates in the hydrothermal cycle but also controls the hydrothermal transfer and exchange process the migration of water heat and salt is strongly coupled with the soil freezing thawing process resulting in the alteration of complex groundwater components sun et al 2021 wang et al 2019 woo 1992 thirdly seasonal frozen soil areas have much higher proportions of farmland forests and mineral resources than permafrost areas and in china most of them are areas with water resources shortage requiring special attention to the utilization and circulation of surface water and groundwater resources dai et al 2012 thus understanding the effects of soil freezing and thawing on subsurface water flow and storage is necessary for better water resources management in seasonal frozen regions xie et al 2021 yu et al 2020 previous studies have suggested that frozen soil affects soil moisture redistribution and infiltration through the following three pathways 1 by decreasing hydraulic conductivity and restricting infiltration of surface water and snowmelt water while the ground is frozen 2 by temporarily increasing hydraulic conductivity thus enhancing infiltration after the thawing of frozen soil and 3 by creating macropores for preferential flow daniel and staricka 2000 iwata et al 2008 iwata et al 2010 under the effect of low soil matric potential induced by soil freezing water migrates from the unfrozen zone to the freezing front cary and mayland 1972 fuchs et al 1978 in fact when the water table is shallow groundwater in the saturated zone can also migrate to the freezing front the loss of water from the groundwater would lower the water table while moisture would simultaneously increase in the frost zone chen et al 2019 cui et al 2020 schneider 1961 stähli et al 1999 willis et al 1964 when the air temperature rises above freezing temperature the water table begins to rise as a result of downward percolation of snowmelt water and frost melt water from the bottom of the frost layer du et al 2019 iwata et al 2008 iwata et al 2010 schneider 1961 however the relationships between the vertical migration of soil moisture shallow groundwater fluctuations and the associated hydrological processes in cold areas have not been fully clarified ireson et al 2013 zhang et al 2019 from the 1950 s to 2000 s several studies have conducted field observations of freezing induced groundwater level decline daniel and staricka 2000 drescher 1955 palkovics et al 1975 schneider 1961 vinnikov et al 1996 willis et al 1964 however no meteorological soil groundwater monitoring system with high monitoring frequency has been established the fluctuation of groundwater level has been described only qualitatively and the influencing factors considered have been relatively singular recent advances in monitoring methods have facilitated fieldwork activities in cold environments but existing relevant research mainly focus on the law of soil water movement flerchinger et al 2006 he et al 2015 iwata et al 2010 nyberg et al 2001 rui et al 2019 or freezing induced water migration from groundwater to the frozen zone by assuming a fixed water table alkhaier et al 2012 chen et al 2019 some scholars attempted to determine the dynamics of groundwater level using multivariate statistical methods or numerical simulation methods cui et al 2020 dai et al 2019a xie et al 2021 zhang et al 2019 but systematic studies on the dynamic law and control factors of the groundwater level under the freezing thawing process are still lacking in general related long term observational data are of importance for understanding these fundamental hydrological processes in this study we investigated the main factors controlling groundwater level fluctuations during freezing thawing periods in seasonal frozen regions using field datasets of major environmental variables soil temperature soil water content and groundwater level gwl from changchun and songyuan of northeast china covering 3 years 2018 2021 and 1 year 2020 2021 respectively the main objectives of this study are as follows 1 determine the main controlling factors and mechanism of groundwater level decline during the freezing period 2 determine the main sources and proportion of groundwater level rise during the thawing period the findings are expected to provide a theoretical basis for developing overwintering irrigation plans by considering the groundwater regime and budget during the freezing thawing period 2 materials 2 1 site description the study was conducted at two sites in changchun city and songyuan city which are located in jilin china fig 1 both sites are characterized by a continental monsoon climate the average annual precipitation and average annual evaporation at the changchun site are 583 8 mm and 1239 mm respectively according to meteorological data the songyuan site experienced lower precipitation and stronger evaporation from 1951 to 2000 reflecting a relatively arid environment at both sites the duration of frozen soil is 6 months from november to april however the frost depth is 1 6 m and 2 0 m respectively at the changchun and songyuan sites which is deeper at songyuan site regarding the soil type the changchun site mainly features loess while the songyuan site mainly features sandy soil the soil of the changchun site is classified as miscellaneous fill with a thickness of approximately 30 cm underlain by silty loess loam up to a depth of 175 cm loess loam with a soil thickness between 175 and 380 cm and loam below 380 cm in contrast the soil of the songyuan site is classified as fine sand with a thickness of approximately 200 cm underlain by clay and sandy clay up to a depth of 400 cm below which it transitions from fine sand to gravel the hydraulic gradient of groundwater at the two sites is small at approximately 5 2 2 data collection daily meteorological data of mean air temperature and precipitation covering the period 2018 2021 were obtained from the china meteorological data service centre snow depth was measured using an ultrasonic snow depth sensor sr50a campbell scientific canada every 30 min at the changchun site soil temperature and water content were measured trime pico32 imko micromodtechnik gmbh germany at depths of 0 10 20 30 40 50 65 80 100 125 150 170 185 200 215 and 230 cm at the songyuan site soil temperature and water content were measured trime pico32 imko micromodtechnik gmbh germany at depths of 0 20 40 60 80 120 140 160 200 310 340 and 360 cm soil water potential was measured teros21 meter group inc usa at depths of 0 20 40 65 100 150 250 and 300 cm only at the changchun site the groundwater table depth was measured using the hobo automatic groundwater level logger hobo u20 001 04 onset computer corporation usa all soil and groundwater levels data were recorded every 30 min 3 results based on the comprehensive analyses of the dynamic changes in air temperature snow cover soil temperature and humidity soil water potential and groundwater level at the songyuan and changchun sites the freezing thawing period could be further divided into the freezing period and thawing period according to the three time nodes of air temperature continuously below 0 c maximum frost depth and complete soil melting therefore the freezing thawing period at both sites was from november to april of the next year and the boundary between the freezing thawing period was generally around february 20 table 1 each index showed the following dynamic characteristics of mutual influence during the freezing thawing period 3 1 air temperature and snow cover air temperature showed a similar overall variation pattern at the changchun and songyuan sites it started to drop below 0 c around november 15 every year and continued to decline with a fluctuating pattern the lowest air temperature generally occurred at the end of december or early january and then began to fluctuate until mid march after which it remained positive the average air temperature during the freezing thawing period was 5 9 c and 8 2 c at the changchun and songyuan sites respectively and the overall air temperature at the songyuan site was relatively lower fig 2 at the changchun site the air temperature fluctuation range of freezing period and thawing period were 23 9 7 5 c and 5 4 20 7 c respectively and the interannual dynamic range was relatively large among them the air temperature in the freezing period from 2020 to 2021 was 3 6 c lower than those in other years table 1 at the changchun site precipitation during the freezing thawing period was 20 5 mm 62 3 mm and 62 1 mm in 2018 2019 2019 2020 and 2020 2021 respectively with significant inter annual dynamic changes precipitation in 2019 2020 was three times that in 2018 2019 resulting in a maximum snow thickness difference of 11 cm between the two years table 1 in addition the change of snow cover was also significantly affected by air temperature dynamics for example although precipitation during the freezing thawing period reached 62 cm in 2020 2021 at both sites the air temperature at the changchun site exceeded 0 c in the middle of the freezing thawing period middle of february resulting in a large amount of snowmelt and the snow cover thickness in the later period was significantly lower than that at the songyuan site fig 2 as the air temperature exceeded 0 c the snow began to melt gradually which was usually completed in late march 3 2 soil freezing as the air temperature dropped below 0 c soil lost heat and gradually froze down from the surface to form frozen soil in the thawing period the air temperature rose and frozen soil melted in both directions from the surface downward and from the maximum frost depth upward the change process of frozen soil thickness was generally synchronized with the dynamic air temperature change fig 2 the interannual dynamic change of soil frost depth at the changchun site was significant taking 2018 2019 and 2019 2020 as examples the evolution process of soil frost depth was quite different although the air temperature was similar during the freezing thawing periods in the two years in 2019 2020 frozen soil did not significantly extend downwards during the freezing period it was less than half of that in the previous year table 1 and the bidirectional melting speed calculated by dividing the maximum freezing depth by the time it takes to complete melting of frozen soil in the thawing period was significantly lower 6 92 cm d 1 48 cm d 3 25 cm d respectively at the changchun site 3 68 cm d at the songyuan site the small range and low speed of the expansion of frozen soil were mainly affected by the heat insulation effect of snow the low thermal conductivity of snow limited the transfer of soil heat and the change of the distribution of frozen soil fig 3 also shows that the amplitude of soil surface temperature below the snow cover in 2018 2019 with thinner snow cover was significantly higher than that in 2019 2020 with thicker snow cover at the same time the time lag between soil temperature and air temperature of each layer in 2019 2020 was significantly larger than that in 2018 2019 on the contrary after the snow melted completely all the soil layers responded quickly to the rise of air temperature even if the maximum soil frost depth differed by 50 cm in different years the corresponding time lag was only 3 days indicating that in addition to air temperature snow cover played an important role in the change of soil frost depth fig 3 the air temperature and snow cover conditions at the songyuan site showed little difference from that at the changchun site but the maximum frost depth 132 6 cm at the songyuan site was twice that at the changchun site in the same year fig 2 since the specific heat capacity of water is about twice that of ice and soil particles and the difference of porosity is not obvious this may be mainly attributable to the distinctly low liquid water content within the maximum freezing depth range of the songyuan site the water content of the changchun site and the songyuan site were 25 32 and 6 30 before the freezing period and 15 26 and 4 12 during the freezing period resulting in higher heat transfer efficiency of the media therefore although both sites experienced similar heat loss the degree of soil temperature reduction was greater at the songyuan site thus leading to greater degree of expansion of frost depth 3 3 soil moisture phase change and migration the vertical distribution of soil moisture content was relatively uniform 24 34 before the freezing thawing period at the changchun site with small differences between the years 26 33 24 34 and 25 32 respectively however at the songyuan site the water content was significantly lower at shallow depth less than 150 cm than that in the deeper soil layer before the freezing thawing period especially in the range of approximately 80 120 cm less than 10 after entering the freezing period the water within the frost depth froze and the liquid water content at the changchun site decreased rapidly to 15 26 and at songyuan site to 4 12 at the same time pore ice reduced the hydraulic conductivity of partially frozen soil compared to the unfrozen soil azmatch et al 2012 during the thawing period the liquid water content at the changchun site gradually recovered with the melting of ice in soil and the liquid water content of the entire soil profile exceeded the level before freezing difference of 0 58 1 26 cm which may be related to the improvement of the hydraulic conductivity of clay after a freeze thaw cycle othman and benson 1994 however at the songyuan site the liquid water content after complete melting was slightly lower than that before freezing difference of 0 82 cm during the entire freezing thawing process areas with significant changes in soil moisture corresponded to the range of the frost depth fig 2 indicating that the phase change of water within the range of frost depth was the key controlling factor for the change of water content nevertheless the soil moisture content below the soil frost depth remained relatively stable during the entire freezing thawing period basically maintaining the field moisture capacity of the media approximately 28 32 and only changed correspondingly near the groundwater level due to the fluctuation of the groundwater level the variation of liquid water content during the freezing thawing period further controlled the distribution of soil water potential and water migration at different depths before the freezing thawing period fig 4 a the soil water potential at all depths was generally between 10 and 45 kpa and the water potential was higher near the surface than at depth thus water migrated downward and the groundwater level rose as the soil froze fig 4b the liquid water content decreased rapidly and the soil water potential in the frost depth decreased significantly to approximately 2000 kpa while the soil water potential below the frost depth remained stable at 20 80 kpa under the action of the water potential gradient water recharge began from bottom to top to the frozen soil layer resulting in a decline in groundwater level and an increase in the total water content of the frozen layer during the thawing period fig 4c as the frozen soil melted from the surface and the maximum frost depth to the middle layer the soil moisture content above and below the frozen soil layer interface increased rapidly and the soil water potential also increased accordingly the soil water potential in the two regions from the ground surface to the upper interface of the frozen soil layer and from the lower interface of the frozen soil layer to the groundwater surface showed a gradual decrease from 400 kpa to 1200 kpa and 25 kpa to 35 kpa respectively inducing downward migration of water under the action of gravitational potential and the groundwater level rose after the frozen soil completely melted fig 4d the range of water potential increased correspondingly because the soil water content level was higher than that before freezing and the overall value was between 10 and 35 kpa similarly water migrated downward and the groundwater level rose 3 4 dynamic change of groundwater table corresponding to the variation process of soil frost depth and water content the groundwater level at the changchun site showed a v shaped trend of decrease during the freezing period and increase during the thawing period and the maximum groundwater table depth and the maximum frost depth appeared in approximately the same time with a lag of only 4 5 days related to the hydraulic conductivity of the soil between the frozen front and the water table zhang et al 2019 however the situation was reversed in 2019 2020 with the maximum frost depth lagging behind the maximum groundwater table depth this was because the air temperature suddenly increased above 0 c on february 11 which induced groundwater recharge consequently the decline of the groundwater level was stopped and the rise was initiated early a similar phenomenon was also reported by schneider 1961 the decrease of groundwater level during the freezing period almost coincided with the increase of groundwater level during the thawing period with a difference of 6 8 cm the decrease of groundwater level caused by freezing in 2018 2019 was greater than the increase caused by thawing but this trend was reversed in 2019 2020 and 2020 2021 the range of inter annual groundwater level variation was quite different and the maximum variation of groundwater level was approximately 1 2 2 3 of the maximum annual frost depth however a very interesting phenomenon was that at the songyuan site with larger frost depth the groundwater table depth fluctuated stably at approximately 3 5 m and the variation range of groundwater level was only 8 10 cm throughout the freezing thawing period 4 discussion 4 1 main controlling factors and control mechanism of groundwater level decline during the freezing period 4 1 1 air temperature and snow cover according to the monitoring results of various indexes during the freezing thawing period at the changchun site over the three years the dynamic changes of air temperature soil frost depth and groundwater level were relatively consistent fig 5 fig 6 among them the correlation between the accumulated negative soil surface temperature and soil frost depth eq 1 and soil frost depth and water table eq 2 could be described by the following expression parameter fitting results are shown in table 2 1 z f a b st s 1 2 2 h c d z f where z f is the soil frost depth h is the groundwater table depth st s is the accumulated negative soil surface temperature a b c and d are empirical coefficients a represents the soil frost depth when the accumulated negative soil surface temperature is 0 b represents the rate of soil freezing under the action of a certain temperature gradient c represents the groundwater table depth when the soil frost depth is 0 which reflects the influence of the initial groundwater table depth and d represents the rate of decrease of groundwater table at a certain freezing speed temperature is undoubtedly the decisive factor among the three dai et al 2019a ge et al 2011 tobita et al 2004 when the air temperature and soil temperature drops below zero degrees celsius the soil begins to freeze and the effective soil porosity of both large and small pores is significantly decreased bense et al 2009 upon freezing the cryogenic suction that is associated with the soil water potential which develops between the ice and the water phases in frozen soils and known as the thermally induced negative pore pressure builds up and rapidly becomes much higher than the liquid pressure arzanfudi and al khoury 2018 it is conceptually similar to the matric suction which develops between the fluid phases i e air and water in unsaturated unfrozen soils while the freezing and thawing processes in nature are relatively slow the cryogenic suction exhibits a sharp increase jump for every degree celsius below zero shastri and sánchez 2012 this phenomenon has also been observed at our site fig 4 consequently pressure in the remaining unfrozen soil decreases where large potential gradients are induced by temperature gradients in the soil water under the effect of the potential gradient groundwater migrates towards the freezing front embleton 1992 eventually leading to a decline in groundwater levels thus the colder the air temperature the deeper the extent of soil freezing the greater the upward migration of soil moisture and the greater the drop in groundwater level it is noteworthy that during the freezing thawing period from 2019 to 2020 the correlation between the three factors was obviously poor the fitting coefficient r of h and z f is 0 4583 which is meaningless and there were no exceptional observations except for the significantly higher snow thickness 18 cm table 1 as shown in fig 7 with the air temperature below 0 c the heat within the frozen layer began to transfer upwards the temperature gradient obtained by dividing the temperature difference at the maximum soil frost depth and the surface by the thickness of the frozen layer is positive and the soil temperature decreased the figure intuitively shows that in 2018 2019 when the snow thickness was relatively small although the accumulated negative air temperature was higher than the accumulated negative soil temperature the difference between the two was significantly smaller than that in the other two years therefore the accumulated negative soil surface temperature was significantly lower this is due to the low thermal conductivity of snow which has a thermal insulation effect and prevents energy transfer between the ground and air consequently the release of heat in the soil layer during the freezing period is limited the freezing of soil is inhibited and the variation range of groundwater level is further affected therefore air temperature determines the direction and magnitude of the temperature gradient heat conduction while the thickness of snow cover affects the process and amount of heat transfer to a certain extent and the two factors collectively control the soil freezing process and the change of groundwater level 4 1 2 soil media property and soil moisture distribution an interesting phenomenon was that during the freezing thawing period from 2020 to 2021 the air temperature was lower 24 0 7 c and the expansion of frozen soil was greater 132 6 cm at the songyuan site than those at the changchun site 23 9 1 2 c and 65 cm respectively however the groundwater level did not show a larger declining rising v shaped dynamic change and the variation range was only within 10 cm throughout the freezing thawing period fig 2 through comprehensive comparison of the weather terrain vadose zone soil media and initial groundwater table depth between the two sites the soil media and initial groundwater table depth were found to be significantly different the soil at the changchun site is silty loess loam while that at the songyuan site is sandy to silty the height of capillary rise at the changchun and songyuan sites ranged from 2 to 3 m and 0 35 to 1 2 m rui 2004 respectively and the initial groundwater levels were 2 700 2 579 and 2 682 at changchun and 3 491 m at songyuan in this study the heights of capillary rise at the changchun and songyuan sites were set as 2 m the lowest value within the range and 1 2 m the highest value within the range and they were superimposed on the groundwater level to obtain the expansion range of the upper limit of the capillary rise in addition according to the coefficient of variation cv the ratio of the standard deviation of the water content to the average value representing the dispersion of data yu et al 2021 and range of soil liquid water content at each depth during the freezing thawing period the critical depth of the influence of freezing thawing was determined the critical depth refers to the depth at which the two parameters begin to stabilize during the freezing thawing period the coefficient of variation below the depth was less than 0 1 reflecting weak variation as shown in fig 8 at the changchun site the upper limit of capillary rise height during the freezing thawing period always overlaps with the critical depth whereas at the songyuan site the upper limit of capillary rise height is always below the critical depth indicating that no complete hydraulic connection formed between frozen soil and groundwater on the other hand during the freezing thawing period in 2020 2021 the water contents below the critical depth were 28 50 32 71 and 30 32 37 31 at the changchun and songyuan sites respectively the water contents were higher than the capillary disrupting moisture 26 29 25 and 20 8 27 3 respectively and field moisture capacity 30 40 and 32 42 respectively indicating that the water contained in the soil layer below the frozen layer could migrate under the action of the water potential gradient therefore the fundamental reason for groundwater level at the songyuan site not responding strongly to the upper soil freezing is that there is no continuous water migration path between groundwater and the frozen layer in general the critical depth of the influence of freezing thawing overlaps with the maximum capillary rise height and the soil water content is greater than the field moisture capacity and capillary disrupting moisture which are the preconditions for the fluctuation of groundwater level during the freezing thawing period on this basis air temperature and snow cover affect the frost depth of soil and then affect the fluctuation range of the groundwater level this relationship can be summarized as the following formula 3 gwd f t vd f t h m a x where gwd f t is the limit depth of groundwater affected by freezing and thawing vd f t is the maximum depth affected by freezing and thawing in the vadose zone and the subscript ft indicated freezing and thawing h max is the maximum capillary rise height of phreatic water 4 2 is the rise of groundwater level mainly recharged by frost melt water or snowmelt water unlike the uniform groundwater level decline during the freezing period the rate of groundwater level rise during the thawing period showed the characteristics of phased changes the thawing period could be further divided into three stages according to the corresponding dynamic laws of air temperature thickness of snow cover soil temperature and moisture at different depths and groundwater level fig 2 fig 9 in the first stage as the average daily air temperature reached above 0 c for the first time 2019 2 23 2020 2 21 2021 2 27 at the changchun site and 2021 2 27 at the songyuan site most of the snow began to melt and day thawing and night freezing phenomena was observed at the soil surface with fluctuations around 0 c the soil temperature at the top and bottom of the frozen soil layer increased and the moisture content increased slowly the phase change occurred at the bottom of the frozen zone first and the soil temperature gradually increased to 0 1 c at the top and bottom toward the center of the frozen layer and continued increasing in addition groundwater level showed a corresponding increase trend in the second stage as the average daily air temperature stabilized above 0 c 2019 3 24 2020 3 17 and 2021 3 17 at the changchun site and 2021 3 22 at the songyuan site the snow on the surface completely melted and the thermal insulation effect disappeared on the whole soil surface temperature and air temperature stabilized at above 0 c and the water content increased suddenly water migrated to other depths of the frozen layer of the soil inducing synchronous sudden changes in the temperature and water content of the soil and the increase of the groundwater level slowed down in the third stage after the frozen soil layer was completely thawed 2019 4 15 2020 4 7 and 2021 4 7 at the changchun site and 2021 4 5 at the songyuan site the moisture content at each depth and groundwater level basically remained stable under the condition of no rainfall in general the rate of groundwater level rise in the vadose zone in the first stage was higher than that in the second stage fig 9 0 0179 vs 0 0122 from 2019 to 2020 and 0 0222 vs 0 0112 from 2020 to 2021 in the first stage except for the melting water of the lower frozen layer groundwater is mainly recharged by snowmelt water and the liquid water content of each layer rises simultaneously which reflects effective recharge by snowmelt water the possibility of such recharge is based on the fact that the soil of changchun site is loess which may have vertical joints and freezing may change the soil structure resulting in surface fissures and macropores with high hydraulic conductivity lu et al 2019 lu et al 2021 therefore the infiltration of soil water can be promoted significantly due to increases in both large and small effective soil pores after the ice melted dai et al 2019b mohammed et al 2018 the second stage is the stage at which each layer of soil begins to thaw groundwater is mainly recharged by frost melt water however the liquid water content of each layer responds slowly to temperature due to which the sudden rise of liquid water content on the profile appears staggered therefore the amount of water recharged by frost melt water in the lower layer is small and stable compared to that in the first stage on the other hand as the amount of snowfall and the corresponding amount of snowmelt are significantly smaller the rate of change of the groundwater level in the two stages showed a reversal from 2018 to 2019 which further proves the impact of snowmelt process on the change of groundwater level nevertheless it should be noted that the recharge effect of snowmelt water on groundwater is still limited similarly in 2018 2019 although the amount of snowmelt was significantly lower than that in the other two years the rate of groundwater level rise in the thawing period was only approximately 10 18 lower than that in the other years moreover due to the long thawing period evaporation discharge during the thawing period made the rise of groundwater level in thawing period smaller than the decrease of it in freezing period making the groundwater level at the end of the thawing period slightly lower than before the freezing period this leads to a very important phenomenon that is the decrease of groundwater level in the freezing period is almost equal to the increase in the thawing period in other words the total amount of water migrating upwards during the freezing period is basically the same as the total amount of water seeping down during the thawing period therefore the key to controlling the rise and fall of the groundwater level lies in the phase change and migration process of soil moisture while the amount of snowmelt water to recharge groundwater is limited from the perspective of water balance the soil moisture content within the vadose zone throughout the freezing thawing period satisfies the following eq 4 ignoring runoff and evaporation 4 w t w 0 μ h 0 h t r snow where w t is the total water storage of the vadose zone after thawing w 0 is the total water storage of the vadose zone before freezing μ is specific yield h t is the groundwater table depth at the end of the thawing period h 0 is the groundwater table depth at the beginning of the freezing period and r snow is the amount of recharge by snowmelt water as the decrease of groundwater level in the freezing period was close to the increase of groundwater level in the thawing period or even larger 2018 2019 most of the snowmelt water can be ascertained to have been converted represented by the change in soil water before and after freezing and thawing the statistical results of measured data over the years also confirmed this assumption table 3 in 2018 2019 2019 2020 and 2020 2021 the variation of soil moisture in the vadose zone before and after the freezing thawing period was 0 773 0 576 and 1 256 cm respectively and the amount of water migration induced by the change of groundwater level was 0 240 0 186 and 0 417 cm respectively in 2019 2020 and 2020 2021 the groundwater level at the end of the thawing period was higher than that before freezing indicating that the amount of water migration from the vadose zone to groundwater during the thawing period was greater than that from groundwater to the vadose zone during the freezing period in the absence of external water supply snowmelt water the water content of the vadose zone should decrease from the perspective of water balance however the actual monitoring results show that the water content of the vadose zone increased which means that snowmelt water effectively recharged the soil media of the vadose zone and groundwater specifically in 2019 2020 and 2020 2021 recharge by snowmelt water accounted for 21 and 12 of the groundwater level rise throughout the thawing period indicating that snowmelt water has a limited contribution to groundwater and the frost melt water is the main contributor to groundwater recovery however in 2018 2019 the amount of water migration induced by the change in groundwater level was 0 240 cm which means that the water that migrated to the vadose zone in the freezing period was not fully returned in the thawing period in other words the change of water content in the vadose zone 0 773 cm includes the amount recharged by groundwater 0 240 cm and recharge by snowmelt water 0 533 cm in 2018 2019 according to the above analysis if there is no upward movement of water and groundwater level drops during the freezing period groundwater level drop 0 there will be no excess water infiltration and recharge in the vadose zone during the thawing period and the groundwater level will not show any distinct rise this also explains the reason for the groundwater level at the songyuan site being relatively stable throughout the freezing thawing period 4 3 conceptual model the dynamic fluctuation of groundwater level during the freezing thawing period is mainly accomplished through mutual transfer between groundwater and water in the vadose zone fig 10 the seasonal dynamic variation of groundwater level is highly correlated with the freezing thawing process of soil the seasonal frozen layer is formed during the freezing period and the groundwater level drops to the maximum depth after the maximum frost depth is reached high water content in the vadose zone before freezing and early snow cover can slow down the soil freezing process when the maximum depth of effect of the freezing and thawing process reaches the maximum capillary rise height of phreatic water and the soil water content exceeds the field moisture capacity capillaries in the soil layer are connected through which water can be continuously transported in this manner a continuous water migration pathway is established between unsaturated and saturated zones at this time groundwater not only migrates in the capillary zone and the intermediate zone but also migrates up to the vadose zone thus inducing a steady decline of the groundwater level the decrease of groundwater level is positively correlated with the maximum frost depth on the contrary if the freezing depth is large but does not intersect with the maximum capillary rise height or the water content is low the water path of groundwater migration to the frozen layer will be discontinuous so that the groundwater level will not fall in the thawing stage the frozen soil melts in two directions with increasing air temperature the amount of meltwater infiltration increases and the water content in the soil increases moreover the thawing period could be further divided into three stages according to the corresponding dynamic laws of air temperature thickness of snow cover soil temperature and moisture at different depths and groundwater level in these three stages the rate of rise of groundwater level in the first stage is higher than that in the second stage the higher rate of rise in the first stage is because the recharge source of groundwater is mainly frost melt water and snowmelt water and that in the second stage is mainly frost melt water after the frozen layer is completely melted the groundwater level rises to a certain height and remains stable without recharge or discharge in the third stage 5 conclusions in this study the response of groundwater level to freezing thawing process was confirmed and the main controlling factors were quantitatively identified through site scale monitoring of different meteorological conditions vadose zone media and hydrogeological conditions the results showed that freezing induced groundwater decline occurred only when the maximum depth of effect of freezing and thawing overlapped with the maximum height of capillary rise in unconfined groundwater the main factors affecting the decline of groundwater level during the freezing period included air temperature snow cover soil medium soil water content before freezing and groundwater table depth before freezing 80 of the recharge source of groundwater level rise during the thawing period was frost melt water and only 20 was snowmelt water the results suggested that freezing thawing and snow cover conditions should be considered when formulating irrigation plans for the winter period to ensure a reasonable groundwater level before freezing or reasonable soil water and heat conditions with appropriate measures saltation of soil and adverse effects on winter and spring crops attributable to excessively high or low groundwater level after the end of the thawing period can be avoided long time series field data or numerical simulations using a calibrated model are required to further determine the critical groundwater table depth affected by freezing thawing and the effective recharge of snowmelt water to groundwater which will play an important role in agricultural water resources management in seasonal frozen regions credit authorship contribution statement hang lyu conceptualization validation formal analysis resources investigation data curation visualization supervision writing review editing tingting wu conceptualization investigation formal analysis data curation visualization writing original draft xiaosi su investigation supervision yongqi wang investigation visualization chao wang investigation visualization zhijiang yuan investigation visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research is supported by the national natural science foundation of china 42172267 u19a20107 and special funds for basic scientific research operating expenses of central universities 
3668,freezing and thawing induced variations of groundwater level and the corresponding changes in water storage in the saturated zone have been observed in regions with a shallow water table however the vertical migration of water under the effect of the freezing thawing process on shallow groundwater has not been accurately quantified and the influencing factors of groundwater level dynamics during the freezing thawing period remain unclear reasonable representation of this process on the field scale is very important for improving our understanding of water budgets during the freezing thawing cycle in this study we investigated the main factors controlling groundwater level fluctuations during the freezing thawing period at two sites in northeast china through comparative analyses of long term field observations of air temperature precipitation snow depth liquid soil water content soil water temperature and fluctuations of groundwater level we found that the seasonal variations in groundwater table coincided with the soil frost freezing thawing seasonal cycle which exhibited a v shape freezing induced groundwater decline occurred only when the maximum depth of effect of freezing and thawing overlapped with the maximum height of capillary rise in unconfined groundwater moreover the decline was controlled by air temperature snow cover soil media properties and soil water distribution by comparing the change trends of groundwater level and calculating the water budget the process of the rise of groundwater level could be further divided into three stages during which groundwater was recharged by frost melt water and snowmelt water among them snowmelt water had a limited contribution accounting for less than 20 of the total recharge the results have potential applications in the development of reasonable water management plans for irrigation using which soil salt can be washed out and suitable soil thermal and moisture conditions can be maintained for winter crops or farming in the next year keywords groundwater response freezing thawing period controlling factors frost depth snowmelt 1 introduction in cold climate regions seasonal freezing and thawing of soil control and affect the hydrogeological environment as a result seasonal frozen regions of the world exhibit a distinct groundwater regime different from those of non frozen and permanently frozen regions ireson et al 2013 this difference can be attributed to three factors firstly seasonal frozen soil is a special aquiclude or aquitard whose permeability varies with temperature antecedent soil moisture and soil structure and the infiltration storage and redistribution of water below the ground are likely to be highly dynamic due to phase changes which in turn play a decisive role in the formation and migration of groundwater as well as the distribution pattern and circulation pattern of groundwater dai et al 2019a ireson et al 2013 quinton et al 2005 secondly frozen soil not only directly participates in the hydrothermal cycle but also controls the hydrothermal transfer and exchange process the migration of water heat and salt is strongly coupled with the soil freezing thawing process resulting in the alteration of complex groundwater components sun et al 2021 wang et al 2019 woo 1992 thirdly seasonal frozen soil areas have much higher proportions of farmland forests and mineral resources than permafrost areas and in china most of them are areas with water resources shortage requiring special attention to the utilization and circulation of surface water and groundwater resources dai et al 2012 thus understanding the effects of soil freezing and thawing on subsurface water flow and storage is necessary for better water resources management in seasonal frozen regions xie et al 2021 yu et al 2020 previous studies have suggested that frozen soil affects soil moisture redistribution and infiltration through the following three pathways 1 by decreasing hydraulic conductivity and restricting infiltration of surface water and snowmelt water while the ground is frozen 2 by temporarily increasing hydraulic conductivity thus enhancing infiltration after the thawing of frozen soil and 3 by creating macropores for preferential flow daniel and staricka 2000 iwata et al 2008 iwata et al 2010 under the effect of low soil matric potential induced by soil freezing water migrates from the unfrozen zone to the freezing front cary and mayland 1972 fuchs et al 1978 in fact when the water table is shallow groundwater in the saturated zone can also migrate to the freezing front the loss of water from the groundwater would lower the water table while moisture would simultaneously increase in the frost zone chen et al 2019 cui et al 2020 schneider 1961 stähli et al 1999 willis et al 1964 when the air temperature rises above freezing temperature the water table begins to rise as a result of downward percolation of snowmelt water and frost melt water from the bottom of the frost layer du et al 2019 iwata et al 2008 iwata et al 2010 schneider 1961 however the relationships between the vertical migration of soil moisture shallow groundwater fluctuations and the associated hydrological processes in cold areas have not been fully clarified ireson et al 2013 zhang et al 2019 from the 1950 s to 2000 s several studies have conducted field observations of freezing induced groundwater level decline daniel and staricka 2000 drescher 1955 palkovics et al 1975 schneider 1961 vinnikov et al 1996 willis et al 1964 however no meteorological soil groundwater monitoring system with high monitoring frequency has been established the fluctuation of groundwater level has been described only qualitatively and the influencing factors considered have been relatively singular recent advances in monitoring methods have facilitated fieldwork activities in cold environments but existing relevant research mainly focus on the law of soil water movement flerchinger et al 2006 he et al 2015 iwata et al 2010 nyberg et al 2001 rui et al 2019 or freezing induced water migration from groundwater to the frozen zone by assuming a fixed water table alkhaier et al 2012 chen et al 2019 some scholars attempted to determine the dynamics of groundwater level using multivariate statistical methods or numerical simulation methods cui et al 2020 dai et al 2019a xie et al 2021 zhang et al 2019 but systematic studies on the dynamic law and control factors of the groundwater level under the freezing thawing process are still lacking in general related long term observational data are of importance for understanding these fundamental hydrological processes in this study we investigated the main factors controlling groundwater level fluctuations during freezing thawing periods in seasonal frozen regions using field datasets of major environmental variables soil temperature soil water content and groundwater level gwl from changchun and songyuan of northeast china covering 3 years 2018 2021 and 1 year 2020 2021 respectively the main objectives of this study are as follows 1 determine the main controlling factors and mechanism of groundwater level decline during the freezing period 2 determine the main sources and proportion of groundwater level rise during the thawing period the findings are expected to provide a theoretical basis for developing overwintering irrigation plans by considering the groundwater regime and budget during the freezing thawing period 2 materials 2 1 site description the study was conducted at two sites in changchun city and songyuan city which are located in jilin china fig 1 both sites are characterized by a continental monsoon climate the average annual precipitation and average annual evaporation at the changchun site are 583 8 mm and 1239 mm respectively according to meteorological data the songyuan site experienced lower precipitation and stronger evaporation from 1951 to 2000 reflecting a relatively arid environment at both sites the duration of frozen soil is 6 months from november to april however the frost depth is 1 6 m and 2 0 m respectively at the changchun and songyuan sites which is deeper at songyuan site regarding the soil type the changchun site mainly features loess while the songyuan site mainly features sandy soil the soil of the changchun site is classified as miscellaneous fill with a thickness of approximately 30 cm underlain by silty loess loam up to a depth of 175 cm loess loam with a soil thickness between 175 and 380 cm and loam below 380 cm in contrast the soil of the songyuan site is classified as fine sand with a thickness of approximately 200 cm underlain by clay and sandy clay up to a depth of 400 cm below which it transitions from fine sand to gravel the hydraulic gradient of groundwater at the two sites is small at approximately 5 2 2 data collection daily meteorological data of mean air temperature and precipitation covering the period 2018 2021 were obtained from the china meteorological data service centre snow depth was measured using an ultrasonic snow depth sensor sr50a campbell scientific canada every 30 min at the changchun site soil temperature and water content were measured trime pico32 imko micromodtechnik gmbh germany at depths of 0 10 20 30 40 50 65 80 100 125 150 170 185 200 215 and 230 cm at the songyuan site soil temperature and water content were measured trime pico32 imko micromodtechnik gmbh germany at depths of 0 20 40 60 80 120 140 160 200 310 340 and 360 cm soil water potential was measured teros21 meter group inc usa at depths of 0 20 40 65 100 150 250 and 300 cm only at the changchun site the groundwater table depth was measured using the hobo automatic groundwater level logger hobo u20 001 04 onset computer corporation usa all soil and groundwater levels data were recorded every 30 min 3 results based on the comprehensive analyses of the dynamic changes in air temperature snow cover soil temperature and humidity soil water potential and groundwater level at the songyuan and changchun sites the freezing thawing period could be further divided into the freezing period and thawing period according to the three time nodes of air temperature continuously below 0 c maximum frost depth and complete soil melting therefore the freezing thawing period at both sites was from november to april of the next year and the boundary between the freezing thawing period was generally around february 20 table 1 each index showed the following dynamic characteristics of mutual influence during the freezing thawing period 3 1 air temperature and snow cover air temperature showed a similar overall variation pattern at the changchun and songyuan sites it started to drop below 0 c around november 15 every year and continued to decline with a fluctuating pattern the lowest air temperature generally occurred at the end of december or early january and then began to fluctuate until mid march after which it remained positive the average air temperature during the freezing thawing period was 5 9 c and 8 2 c at the changchun and songyuan sites respectively and the overall air temperature at the songyuan site was relatively lower fig 2 at the changchun site the air temperature fluctuation range of freezing period and thawing period were 23 9 7 5 c and 5 4 20 7 c respectively and the interannual dynamic range was relatively large among them the air temperature in the freezing period from 2020 to 2021 was 3 6 c lower than those in other years table 1 at the changchun site precipitation during the freezing thawing period was 20 5 mm 62 3 mm and 62 1 mm in 2018 2019 2019 2020 and 2020 2021 respectively with significant inter annual dynamic changes precipitation in 2019 2020 was three times that in 2018 2019 resulting in a maximum snow thickness difference of 11 cm between the two years table 1 in addition the change of snow cover was also significantly affected by air temperature dynamics for example although precipitation during the freezing thawing period reached 62 cm in 2020 2021 at both sites the air temperature at the changchun site exceeded 0 c in the middle of the freezing thawing period middle of february resulting in a large amount of snowmelt and the snow cover thickness in the later period was significantly lower than that at the songyuan site fig 2 as the air temperature exceeded 0 c the snow began to melt gradually which was usually completed in late march 3 2 soil freezing as the air temperature dropped below 0 c soil lost heat and gradually froze down from the surface to form frozen soil in the thawing period the air temperature rose and frozen soil melted in both directions from the surface downward and from the maximum frost depth upward the change process of frozen soil thickness was generally synchronized with the dynamic air temperature change fig 2 the interannual dynamic change of soil frost depth at the changchun site was significant taking 2018 2019 and 2019 2020 as examples the evolution process of soil frost depth was quite different although the air temperature was similar during the freezing thawing periods in the two years in 2019 2020 frozen soil did not significantly extend downwards during the freezing period it was less than half of that in the previous year table 1 and the bidirectional melting speed calculated by dividing the maximum freezing depth by the time it takes to complete melting of frozen soil in the thawing period was significantly lower 6 92 cm d 1 48 cm d 3 25 cm d respectively at the changchun site 3 68 cm d at the songyuan site the small range and low speed of the expansion of frozen soil were mainly affected by the heat insulation effect of snow the low thermal conductivity of snow limited the transfer of soil heat and the change of the distribution of frozen soil fig 3 also shows that the amplitude of soil surface temperature below the snow cover in 2018 2019 with thinner snow cover was significantly higher than that in 2019 2020 with thicker snow cover at the same time the time lag between soil temperature and air temperature of each layer in 2019 2020 was significantly larger than that in 2018 2019 on the contrary after the snow melted completely all the soil layers responded quickly to the rise of air temperature even if the maximum soil frost depth differed by 50 cm in different years the corresponding time lag was only 3 days indicating that in addition to air temperature snow cover played an important role in the change of soil frost depth fig 3 the air temperature and snow cover conditions at the songyuan site showed little difference from that at the changchun site but the maximum frost depth 132 6 cm at the songyuan site was twice that at the changchun site in the same year fig 2 since the specific heat capacity of water is about twice that of ice and soil particles and the difference of porosity is not obvious this may be mainly attributable to the distinctly low liquid water content within the maximum freezing depth range of the songyuan site the water content of the changchun site and the songyuan site were 25 32 and 6 30 before the freezing period and 15 26 and 4 12 during the freezing period resulting in higher heat transfer efficiency of the media therefore although both sites experienced similar heat loss the degree of soil temperature reduction was greater at the songyuan site thus leading to greater degree of expansion of frost depth 3 3 soil moisture phase change and migration the vertical distribution of soil moisture content was relatively uniform 24 34 before the freezing thawing period at the changchun site with small differences between the years 26 33 24 34 and 25 32 respectively however at the songyuan site the water content was significantly lower at shallow depth less than 150 cm than that in the deeper soil layer before the freezing thawing period especially in the range of approximately 80 120 cm less than 10 after entering the freezing period the water within the frost depth froze and the liquid water content at the changchun site decreased rapidly to 15 26 and at songyuan site to 4 12 at the same time pore ice reduced the hydraulic conductivity of partially frozen soil compared to the unfrozen soil azmatch et al 2012 during the thawing period the liquid water content at the changchun site gradually recovered with the melting of ice in soil and the liquid water content of the entire soil profile exceeded the level before freezing difference of 0 58 1 26 cm which may be related to the improvement of the hydraulic conductivity of clay after a freeze thaw cycle othman and benson 1994 however at the songyuan site the liquid water content after complete melting was slightly lower than that before freezing difference of 0 82 cm during the entire freezing thawing process areas with significant changes in soil moisture corresponded to the range of the frost depth fig 2 indicating that the phase change of water within the range of frost depth was the key controlling factor for the change of water content nevertheless the soil moisture content below the soil frost depth remained relatively stable during the entire freezing thawing period basically maintaining the field moisture capacity of the media approximately 28 32 and only changed correspondingly near the groundwater level due to the fluctuation of the groundwater level the variation of liquid water content during the freezing thawing period further controlled the distribution of soil water potential and water migration at different depths before the freezing thawing period fig 4 a the soil water potential at all depths was generally between 10 and 45 kpa and the water potential was higher near the surface than at depth thus water migrated downward and the groundwater level rose as the soil froze fig 4b the liquid water content decreased rapidly and the soil water potential in the frost depth decreased significantly to approximately 2000 kpa while the soil water potential below the frost depth remained stable at 20 80 kpa under the action of the water potential gradient water recharge began from bottom to top to the frozen soil layer resulting in a decline in groundwater level and an increase in the total water content of the frozen layer during the thawing period fig 4c as the frozen soil melted from the surface and the maximum frost depth to the middle layer the soil moisture content above and below the frozen soil layer interface increased rapidly and the soil water potential also increased accordingly the soil water potential in the two regions from the ground surface to the upper interface of the frozen soil layer and from the lower interface of the frozen soil layer to the groundwater surface showed a gradual decrease from 400 kpa to 1200 kpa and 25 kpa to 35 kpa respectively inducing downward migration of water under the action of gravitational potential and the groundwater level rose after the frozen soil completely melted fig 4d the range of water potential increased correspondingly because the soil water content level was higher than that before freezing and the overall value was between 10 and 35 kpa similarly water migrated downward and the groundwater level rose 3 4 dynamic change of groundwater table corresponding to the variation process of soil frost depth and water content the groundwater level at the changchun site showed a v shaped trend of decrease during the freezing period and increase during the thawing period and the maximum groundwater table depth and the maximum frost depth appeared in approximately the same time with a lag of only 4 5 days related to the hydraulic conductivity of the soil between the frozen front and the water table zhang et al 2019 however the situation was reversed in 2019 2020 with the maximum frost depth lagging behind the maximum groundwater table depth this was because the air temperature suddenly increased above 0 c on february 11 which induced groundwater recharge consequently the decline of the groundwater level was stopped and the rise was initiated early a similar phenomenon was also reported by schneider 1961 the decrease of groundwater level during the freezing period almost coincided with the increase of groundwater level during the thawing period with a difference of 6 8 cm the decrease of groundwater level caused by freezing in 2018 2019 was greater than the increase caused by thawing but this trend was reversed in 2019 2020 and 2020 2021 the range of inter annual groundwater level variation was quite different and the maximum variation of groundwater level was approximately 1 2 2 3 of the maximum annual frost depth however a very interesting phenomenon was that at the songyuan site with larger frost depth the groundwater table depth fluctuated stably at approximately 3 5 m and the variation range of groundwater level was only 8 10 cm throughout the freezing thawing period 4 discussion 4 1 main controlling factors and control mechanism of groundwater level decline during the freezing period 4 1 1 air temperature and snow cover according to the monitoring results of various indexes during the freezing thawing period at the changchun site over the three years the dynamic changes of air temperature soil frost depth and groundwater level were relatively consistent fig 5 fig 6 among them the correlation between the accumulated negative soil surface temperature and soil frost depth eq 1 and soil frost depth and water table eq 2 could be described by the following expression parameter fitting results are shown in table 2 1 z f a b st s 1 2 2 h c d z f where z f is the soil frost depth h is the groundwater table depth st s is the accumulated negative soil surface temperature a b c and d are empirical coefficients a represents the soil frost depth when the accumulated negative soil surface temperature is 0 b represents the rate of soil freezing under the action of a certain temperature gradient c represents the groundwater table depth when the soil frost depth is 0 which reflects the influence of the initial groundwater table depth and d represents the rate of decrease of groundwater table at a certain freezing speed temperature is undoubtedly the decisive factor among the three dai et al 2019a ge et al 2011 tobita et al 2004 when the air temperature and soil temperature drops below zero degrees celsius the soil begins to freeze and the effective soil porosity of both large and small pores is significantly decreased bense et al 2009 upon freezing the cryogenic suction that is associated with the soil water potential which develops between the ice and the water phases in frozen soils and known as the thermally induced negative pore pressure builds up and rapidly becomes much higher than the liquid pressure arzanfudi and al khoury 2018 it is conceptually similar to the matric suction which develops between the fluid phases i e air and water in unsaturated unfrozen soils while the freezing and thawing processes in nature are relatively slow the cryogenic suction exhibits a sharp increase jump for every degree celsius below zero shastri and sánchez 2012 this phenomenon has also been observed at our site fig 4 consequently pressure in the remaining unfrozen soil decreases where large potential gradients are induced by temperature gradients in the soil water under the effect of the potential gradient groundwater migrates towards the freezing front embleton 1992 eventually leading to a decline in groundwater levels thus the colder the air temperature the deeper the extent of soil freezing the greater the upward migration of soil moisture and the greater the drop in groundwater level it is noteworthy that during the freezing thawing period from 2019 to 2020 the correlation between the three factors was obviously poor the fitting coefficient r of h and z f is 0 4583 which is meaningless and there were no exceptional observations except for the significantly higher snow thickness 18 cm table 1 as shown in fig 7 with the air temperature below 0 c the heat within the frozen layer began to transfer upwards the temperature gradient obtained by dividing the temperature difference at the maximum soil frost depth and the surface by the thickness of the frozen layer is positive and the soil temperature decreased the figure intuitively shows that in 2018 2019 when the snow thickness was relatively small although the accumulated negative air temperature was higher than the accumulated negative soil temperature the difference between the two was significantly smaller than that in the other two years therefore the accumulated negative soil surface temperature was significantly lower this is due to the low thermal conductivity of snow which has a thermal insulation effect and prevents energy transfer between the ground and air consequently the release of heat in the soil layer during the freezing period is limited the freezing of soil is inhibited and the variation range of groundwater level is further affected therefore air temperature determines the direction and magnitude of the temperature gradient heat conduction while the thickness of snow cover affects the process and amount of heat transfer to a certain extent and the two factors collectively control the soil freezing process and the change of groundwater level 4 1 2 soil media property and soil moisture distribution an interesting phenomenon was that during the freezing thawing period from 2020 to 2021 the air temperature was lower 24 0 7 c and the expansion of frozen soil was greater 132 6 cm at the songyuan site than those at the changchun site 23 9 1 2 c and 65 cm respectively however the groundwater level did not show a larger declining rising v shaped dynamic change and the variation range was only within 10 cm throughout the freezing thawing period fig 2 through comprehensive comparison of the weather terrain vadose zone soil media and initial groundwater table depth between the two sites the soil media and initial groundwater table depth were found to be significantly different the soil at the changchun site is silty loess loam while that at the songyuan site is sandy to silty the height of capillary rise at the changchun and songyuan sites ranged from 2 to 3 m and 0 35 to 1 2 m rui 2004 respectively and the initial groundwater levels were 2 700 2 579 and 2 682 at changchun and 3 491 m at songyuan in this study the heights of capillary rise at the changchun and songyuan sites were set as 2 m the lowest value within the range and 1 2 m the highest value within the range and they were superimposed on the groundwater level to obtain the expansion range of the upper limit of the capillary rise in addition according to the coefficient of variation cv the ratio of the standard deviation of the water content to the average value representing the dispersion of data yu et al 2021 and range of soil liquid water content at each depth during the freezing thawing period the critical depth of the influence of freezing thawing was determined the critical depth refers to the depth at which the two parameters begin to stabilize during the freezing thawing period the coefficient of variation below the depth was less than 0 1 reflecting weak variation as shown in fig 8 at the changchun site the upper limit of capillary rise height during the freezing thawing period always overlaps with the critical depth whereas at the songyuan site the upper limit of capillary rise height is always below the critical depth indicating that no complete hydraulic connection formed between frozen soil and groundwater on the other hand during the freezing thawing period in 2020 2021 the water contents below the critical depth were 28 50 32 71 and 30 32 37 31 at the changchun and songyuan sites respectively the water contents were higher than the capillary disrupting moisture 26 29 25 and 20 8 27 3 respectively and field moisture capacity 30 40 and 32 42 respectively indicating that the water contained in the soil layer below the frozen layer could migrate under the action of the water potential gradient therefore the fundamental reason for groundwater level at the songyuan site not responding strongly to the upper soil freezing is that there is no continuous water migration path between groundwater and the frozen layer in general the critical depth of the influence of freezing thawing overlaps with the maximum capillary rise height and the soil water content is greater than the field moisture capacity and capillary disrupting moisture which are the preconditions for the fluctuation of groundwater level during the freezing thawing period on this basis air temperature and snow cover affect the frost depth of soil and then affect the fluctuation range of the groundwater level this relationship can be summarized as the following formula 3 gwd f t vd f t h m a x where gwd f t is the limit depth of groundwater affected by freezing and thawing vd f t is the maximum depth affected by freezing and thawing in the vadose zone and the subscript ft indicated freezing and thawing h max is the maximum capillary rise height of phreatic water 4 2 is the rise of groundwater level mainly recharged by frost melt water or snowmelt water unlike the uniform groundwater level decline during the freezing period the rate of groundwater level rise during the thawing period showed the characteristics of phased changes the thawing period could be further divided into three stages according to the corresponding dynamic laws of air temperature thickness of snow cover soil temperature and moisture at different depths and groundwater level fig 2 fig 9 in the first stage as the average daily air temperature reached above 0 c for the first time 2019 2 23 2020 2 21 2021 2 27 at the changchun site and 2021 2 27 at the songyuan site most of the snow began to melt and day thawing and night freezing phenomena was observed at the soil surface with fluctuations around 0 c the soil temperature at the top and bottom of the frozen soil layer increased and the moisture content increased slowly the phase change occurred at the bottom of the frozen zone first and the soil temperature gradually increased to 0 1 c at the top and bottom toward the center of the frozen layer and continued increasing in addition groundwater level showed a corresponding increase trend in the second stage as the average daily air temperature stabilized above 0 c 2019 3 24 2020 3 17 and 2021 3 17 at the changchun site and 2021 3 22 at the songyuan site the snow on the surface completely melted and the thermal insulation effect disappeared on the whole soil surface temperature and air temperature stabilized at above 0 c and the water content increased suddenly water migrated to other depths of the frozen layer of the soil inducing synchronous sudden changes in the temperature and water content of the soil and the increase of the groundwater level slowed down in the third stage after the frozen soil layer was completely thawed 2019 4 15 2020 4 7 and 2021 4 7 at the changchun site and 2021 4 5 at the songyuan site the moisture content at each depth and groundwater level basically remained stable under the condition of no rainfall in general the rate of groundwater level rise in the vadose zone in the first stage was higher than that in the second stage fig 9 0 0179 vs 0 0122 from 2019 to 2020 and 0 0222 vs 0 0112 from 2020 to 2021 in the first stage except for the melting water of the lower frozen layer groundwater is mainly recharged by snowmelt water and the liquid water content of each layer rises simultaneously which reflects effective recharge by snowmelt water the possibility of such recharge is based on the fact that the soil of changchun site is loess which may have vertical joints and freezing may change the soil structure resulting in surface fissures and macropores with high hydraulic conductivity lu et al 2019 lu et al 2021 therefore the infiltration of soil water can be promoted significantly due to increases in both large and small effective soil pores after the ice melted dai et al 2019b mohammed et al 2018 the second stage is the stage at which each layer of soil begins to thaw groundwater is mainly recharged by frost melt water however the liquid water content of each layer responds slowly to temperature due to which the sudden rise of liquid water content on the profile appears staggered therefore the amount of water recharged by frost melt water in the lower layer is small and stable compared to that in the first stage on the other hand as the amount of snowfall and the corresponding amount of snowmelt are significantly smaller the rate of change of the groundwater level in the two stages showed a reversal from 2018 to 2019 which further proves the impact of snowmelt process on the change of groundwater level nevertheless it should be noted that the recharge effect of snowmelt water on groundwater is still limited similarly in 2018 2019 although the amount of snowmelt was significantly lower than that in the other two years the rate of groundwater level rise in the thawing period was only approximately 10 18 lower than that in the other years moreover due to the long thawing period evaporation discharge during the thawing period made the rise of groundwater level in thawing period smaller than the decrease of it in freezing period making the groundwater level at the end of the thawing period slightly lower than before the freezing period this leads to a very important phenomenon that is the decrease of groundwater level in the freezing period is almost equal to the increase in the thawing period in other words the total amount of water migrating upwards during the freezing period is basically the same as the total amount of water seeping down during the thawing period therefore the key to controlling the rise and fall of the groundwater level lies in the phase change and migration process of soil moisture while the amount of snowmelt water to recharge groundwater is limited from the perspective of water balance the soil moisture content within the vadose zone throughout the freezing thawing period satisfies the following eq 4 ignoring runoff and evaporation 4 w t w 0 μ h 0 h t r snow where w t is the total water storage of the vadose zone after thawing w 0 is the total water storage of the vadose zone before freezing μ is specific yield h t is the groundwater table depth at the end of the thawing period h 0 is the groundwater table depth at the beginning of the freezing period and r snow is the amount of recharge by snowmelt water as the decrease of groundwater level in the freezing period was close to the increase of groundwater level in the thawing period or even larger 2018 2019 most of the snowmelt water can be ascertained to have been converted represented by the change in soil water before and after freezing and thawing the statistical results of measured data over the years also confirmed this assumption table 3 in 2018 2019 2019 2020 and 2020 2021 the variation of soil moisture in the vadose zone before and after the freezing thawing period was 0 773 0 576 and 1 256 cm respectively and the amount of water migration induced by the change of groundwater level was 0 240 0 186 and 0 417 cm respectively in 2019 2020 and 2020 2021 the groundwater level at the end of the thawing period was higher than that before freezing indicating that the amount of water migration from the vadose zone to groundwater during the thawing period was greater than that from groundwater to the vadose zone during the freezing period in the absence of external water supply snowmelt water the water content of the vadose zone should decrease from the perspective of water balance however the actual monitoring results show that the water content of the vadose zone increased which means that snowmelt water effectively recharged the soil media of the vadose zone and groundwater specifically in 2019 2020 and 2020 2021 recharge by snowmelt water accounted for 21 and 12 of the groundwater level rise throughout the thawing period indicating that snowmelt water has a limited contribution to groundwater and the frost melt water is the main contributor to groundwater recovery however in 2018 2019 the amount of water migration induced by the change in groundwater level was 0 240 cm which means that the water that migrated to the vadose zone in the freezing period was not fully returned in the thawing period in other words the change of water content in the vadose zone 0 773 cm includes the amount recharged by groundwater 0 240 cm and recharge by snowmelt water 0 533 cm in 2018 2019 according to the above analysis if there is no upward movement of water and groundwater level drops during the freezing period groundwater level drop 0 there will be no excess water infiltration and recharge in the vadose zone during the thawing period and the groundwater level will not show any distinct rise this also explains the reason for the groundwater level at the songyuan site being relatively stable throughout the freezing thawing period 4 3 conceptual model the dynamic fluctuation of groundwater level during the freezing thawing period is mainly accomplished through mutual transfer between groundwater and water in the vadose zone fig 10 the seasonal dynamic variation of groundwater level is highly correlated with the freezing thawing process of soil the seasonal frozen layer is formed during the freezing period and the groundwater level drops to the maximum depth after the maximum frost depth is reached high water content in the vadose zone before freezing and early snow cover can slow down the soil freezing process when the maximum depth of effect of the freezing and thawing process reaches the maximum capillary rise height of phreatic water and the soil water content exceeds the field moisture capacity capillaries in the soil layer are connected through which water can be continuously transported in this manner a continuous water migration pathway is established between unsaturated and saturated zones at this time groundwater not only migrates in the capillary zone and the intermediate zone but also migrates up to the vadose zone thus inducing a steady decline of the groundwater level the decrease of groundwater level is positively correlated with the maximum frost depth on the contrary if the freezing depth is large but does not intersect with the maximum capillary rise height or the water content is low the water path of groundwater migration to the frozen layer will be discontinuous so that the groundwater level will not fall in the thawing stage the frozen soil melts in two directions with increasing air temperature the amount of meltwater infiltration increases and the water content in the soil increases moreover the thawing period could be further divided into three stages according to the corresponding dynamic laws of air temperature thickness of snow cover soil temperature and moisture at different depths and groundwater level in these three stages the rate of rise of groundwater level in the first stage is higher than that in the second stage the higher rate of rise in the first stage is because the recharge source of groundwater is mainly frost melt water and snowmelt water and that in the second stage is mainly frost melt water after the frozen layer is completely melted the groundwater level rises to a certain height and remains stable without recharge or discharge in the third stage 5 conclusions in this study the response of groundwater level to freezing thawing process was confirmed and the main controlling factors were quantitatively identified through site scale monitoring of different meteorological conditions vadose zone media and hydrogeological conditions the results showed that freezing induced groundwater decline occurred only when the maximum depth of effect of freezing and thawing overlapped with the maximum height of capillary rise in unconfined groundwater the main factors affecting the decline of groundwater level during the freezing period included air temperature snow cover soil medium soil water content before freezing and groundwater table depth before freezing 80 of the recharge source of groundwater level rise during the thawing period was frost melt water and only 20 was snowmelt water the results suggested that freezing thawing and snow cover conditions should be considered when formulating irrigation plans for the winter period to ensure a reasonable groundwater level before freezing or reasonable soil water and heat conditions with appropriate measures saltation of soil and adverse effects on winter and spring crops attributable to excessively high or low groundwater level after the end of the thawing period can be avoided long time series field data or numerical simulations using a calibrated model are required to further determine the critical groundwater table depth affected by freezing thawing and the effective recharge of snowmelt water to groundwater which will play an important role in agricultural water resources management in seasonal frozen regions credit authorship contribution statement hang lyu conceptualization validation formal analysis resources investigation data curation visualization supervision writing review editing tingting wu conceptualization investigation formal analysis data curation visualization writing original draft xiaosi su investigation supervision yongqi wang investigation visualization chao wang investigation visualization zhijiang yuan investigation visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research is supported by the national natural science foundation of china 42172267 u19a20107 and special funds for basic scientific research operating expenses of central universities 
3669,this paper introduces a new concept for mapping hydraulic transmissivity from temporal concentration data collected in multiple tracer tests based on convolutional neural network the principle uses an encoder decoder architecture with multiple neural layers to establish a relationship between the concentration data and the transmissivity field this relationship is established in two phases with two networks the first network is designated and trained to reconstruct a transmissivity field using data from a single tracer test to improve the reconstruction quality the second network then performs a joint interpretation for multiple tracer tests which reprocesses all the transmissivity resulted from the first network for each individual tracer test both networks are trained by synthetic data where the transmissivity models are generated with a gaussian variogram and its properties are considered as prior information on the aquifer heterogeneity tracer tests are derived numerically by solving the forward problem to obtain the corresponding concentration data that feed the training the trained networks accurately map the transmissivity fields of which the accuracy relies on the volume and nature of the heterogeneities of training models as well as the number of piezometers used to monitor the concentration changes reconstruction quality on the other hand is less influenced by data noise effective training requires a large dataset but the time required for dataset generation is only on the order of the gauss newton algorithm in a conventional inversion while the trained network performs inference instantly keywords inversion method hydraulic tomography cnn neural network architecture deep learning tracer test 1 introduction characterising the spatial variability of aquifer hydraulic properties in hydrogeology remains a complex and critical task for any attempt to understand water dynamics and contaminant transport in aquifers bear and cheng 2010 spatial heterogeneity particularly in hydraulic conductivity drives transport mechanism of water and contaminants in the subsurface such characterization referred as hydraulic tomography is typically performed on a large scale by analysing hydraulic changes due to natural forces such as the hydrological cycle and tidal oscillations bailey baù 2012 jardani et al 2012 on a small scale the task can be similarly achieved through a joint interpretation of hydraulic head variations in a sequential multiple pumping test yeh liu 2000 cardiff et al 2013 as an alternative tracer tests can provide insight into hydraulic properties particularly in high permeability environments by analysing the temporal concentration variations of an injected tracer i e a dye salt or heat jardani et al 2013 lee and kitanidis 2014 sanchez león et al 2016 yeh and zhu 2007 to interpret these hydraulic concentration measurements an inversion solver often involves an iterative algorithm that fits the measurement from adjusting a hydraulic conductivity distribution however this type of inversion approach is ill posed resulting in a non unique solution to overcome this issue constraints and prior information must be included which narrow the possibilities and promote convergence to a physically meaningful model kitanidis 1997 zha et al 2017 this optimization can be performed with an algorithm that belongs to one of three types deterministic stochastic and global carrera et al 2005 reuschen et al 2020 sen et al 1995 soueid ahmed et al 2015 xu and gómez hernández 2018 in deterministic algorithms such as gauss newton and conjugate gradient optimization aims at a local minimum by iteratively computing the gradient of the objective function their computation time and accuracy rely on the selection of initial model and the calibration of jacobian matrix tarantola valette 1982 fahs et al 2014 stochastic algorithms otherwise search for the best model which is based on a random strategy in which many models are generated selected or discarded according to their ability to fit both the water concentration data and the prior information cui et al 2011 this type of algorithm is straightforward to implement and the resulting model is independent of the initial choice however the computation demands an intensive resource as it requires solving several times the forward problem global algorithms such as simulated annealing and genetic also represent an interesting alternative to invert the hydraulic concentration data by iteratively searching for the global optimum datta gupta et al 1995 jha datta 2011 among the applications of these inversion tools on the reconstruction of hydraulic parameters by processing tracer test data which will be the main subject of this paper zhu et al 2009 showed a synthetic case that interpretation of tracer test data with a linear sequence estimator the approach provided useful information about the heterogeneity of the hydraulic conductivity field in a short time especially when the concentration data are expressed with their temporal moments schwede et al 2014 employed the quasi linear geostatistical approach to characterize 3d hydraulic conductivity by jointly inverting hydraulic and thermal data derived from pumping and heat tracing tests conducted on a synthetic aquifer lee and kitanidis 2014 applied principal component geostatistical inversion derived from the classical quasi linear geostatistical algorithm to perform a joint inversion of hydraulic test and tracer data sanchez león et al 2016 examined the effectiveness of the ensemble kalman filter and the kalman ensemble generator in interpreting synthetic pumping and tracer test data jiménez et al 2016 opted for the stochastic reversible jump markov chain monte carlo with the pilot point as a parameterization method to invert tracer data collected on alluvial environment saley et al 2016 used the hamiltonian monte carlo algorithm to reconstruct hydraulic conductivity heterogeneity by inverting heat tracing data collected on sandbox somogyvári bayer 2017 mapped the hydraulic conductivity of a heterogeneous alluvial aquifer by inverting thermal tracer data with the simultaneous iteration reconstruction technique sirt the same algorithm was tested by kittilä et al 2020 in the interpretation of dye tracing test data performed on fractured crystalline rocks to identify preferential groundwater flow paths thus the literature is rich with applications of inversion tools for tracer data processing however an algorithm based on a new generation of deep learning tools has barely been performed for tracer tests the deep learning algorithm is based on the approximation of an inversion function that non linearly relates two parameters the spatio temporal measurement data and the aquifer properties zarita ong 2008 these relationships are determined using networks consists of multiple layers in which a set of linear and nonlinear operations are performed sequentially on the neurons of these layers this process involves the use of multidimensional coefficients known as weights and biases to ensure the connectivity between two successive layers zhang et al 1998 tahmasebi et al 2020 marçais de dreuzy 2017 the identification of the weights and biases is based on the optimization process i e their selection is made according to their ability to connect the input data with their corresponding outputs which are considered to be known and referred to as training dataset hassoun 1995 the accuracy of the predictions provided by the learned network depends strongly on the size of this training dataset zhang et al 1998 jardani et al 2022 in the processing of pumping and tracer test data the first attempts using deep learning algorithms to approximate inversion functions were made with vanilla neural networks where the layers are fully connected zio 1997 balkhair 2002 lin chen 2006 akin 2005 yoon et al 2007 this kind of connectivity implies the use of many parameters which overburdens the learning process and requires a heavy resources and computation time however in recent years a new generation of networks based on convolutional neural networks has emerged allowing to better address the problems of tomography in geosciences lecun et al 1998 lecun and bengio 1998 indeed this type of network permits efficiently linking two images through operating several convolution layers convolution is a linear operation in which small weights called filters are applied to the input image to establish local connectivity between neighbouring pixels indolia et al 2018 each filter is dedicated to extracting a feature in the image by scanning the filter region wise over the entire image the use of these small filters allows the recovery of the main features on the input image and reduces the number of unknown parameters learned during training o shea nash 2015 the number of applications of these new networks in the geosciences continues to grow including liu et al 2020 who used the unet network to train an inversion operator for electrical resistivity tomography that links apparent electrical resistivity data collected at the ground surface to the distribution of electrical resistivity in the subsurface vu jardani 2021 trained a convolutional neural network with encoder decoder architecture to perform 3d inversion of electrical resistivity data apolinario et al 2019 opted for the convolutional neural networks with encoder decoder structure to estimate seismic velocity from acoustic data zhang lin 2020 employed the generative adversarial network to approximate the inversion function to image spatial heterogeneity of seismic velocity for seismogram data in the electromagnetic applications puzyrev swidinsky 2019 used a convolution neural network to perform 1d inversion of electromagnetic data to obtain the vertical profile of electrical conductivity in the hydraulic tomography applications bao et al 2020 combined ensemble smoother with multiple data assimilation with generative adversarial networks to map the geometry of the channels by analysing the hydraulic head and concentration data sun 2018 used the generative adversarial networks to identify the spatial heterogeneity of the synthetic aquifer for the pumping test data laloy et al 2018 also used an inversion of hydraulic data based on the generative adversarial networks to determine spatial distribution of hydraulic conductivity fields in 2d and 3d most of these few initiatives were dedicated to reconstructing the hydraulic conductivity field from hydraulic head observations however there has been little work on the inversion of solute data in this paper we investigate the effectiveness of a network of encoder decoder structures to reconstruct the transmissivity field from temporal concentration data of a salt tracer this network called segnet was originally developed for a segmentation task in which networks are trained to identify pixels of labelled objects animal lane bicycle car on images badrinarayanan et al 2017 however in this paper the network is adapted to perform a regression task to associate concentration data with hydraulic transmissivity fields to our knowledge this is the first time such an advanced network has been performed in a tracer test inversion problem the first part of this paper introduces the theoretical background of the tracer test the forward problem used to generate the training data the principle of inversion is then introduced followed by a brief explanation of the proposed encoder decoder architecture its built in layers and operations for establishing the relationship between the concentration data and hydraulic transmissivity fields in the implementation process the network is tested with 5000 models after being trained with synthetic datasets after that the algorithm accuracy is assessed under a variety of data conditions in a monitoring field including the effects of data size low resolution and observation noise the effect of prior conditions introduced into the generation of training models on accuracy is discussed further in a range of real field contexts finally the deep learning results are compared with those determined with a gauss newton method to illustrate effectiveness of the proposed algorithm 2 theoretical background in this section we first describe the theoretical concept of the forward problem used for the numerical simulation of spatiotemporal concentration data of a tracer injected into an aquifer with a heterogeneous transmissivity field this forward problem is based on a coupling of the steady state groundwater flow equation and the transient transport equation and is employed to build a database in which the concentration data and its corresponding transmissivity field are used in the network training phase in the second section we introduce the concept of inversion problem with the convolutional neural network with an encoder decoder structure 2 1 forward problem numerical simulation of the transfer of a soluble tracer in a saturated heterogeneous medium relies on the sequential solving of the groundwater flow and transport equations first the groundwater flow equation is solved to determine the spatial distribution of the darcy velocity which is subsequently used in the transport equation to compute the convective and dispersive terms in this paper the groundwater flow equation is expressed in the steady state bear 1972 1 t h q 0 δ x x 0 subjected to a boundary condition 2 h h 0 a t γ where t is the heterogeneous transmissivity field m2 s generated geostatistically q0 represents the injection source m2 s at the well position x0 δ is kronecker delta h is the hydraulic head m h0 is a constant hydraulic head imposed at the boundary γ the water velocity is determined by darcy s law 3 u k h where k m s denotes the hydraulic conductivity k t b with b m is thickness of the aquifer taken as constant in this study then the velocity field is used in the transport equation that is expressed in transient mode as following 4 ϕ c t ϕ d c u c 0 subjected to the following initial and boundary conditions 5 c 0 a t t 0 6 n d c c 0 a t x x 0 where ϕ is the dynamic porosity c mol m3 is the solute concentration t s is the time d m2 s represents the hydrodynamic dispersion tensor which can be given by 7 d d m τ α t υ i 3 α l α t υ u u where dm m2 s is molecular diffusion coefficient of tracer υ m s is the magnitude of velocity υ u τ is the tortuosity αl and αt are the longitudinal and transverse dispersivities i 3 is the identify matrix 3 by 3 in this paper the groundwater flow and transport equations are solved numerically using the finite element method with comsol software these equations constitute the direct problem of the tracer test in which the concentration of conservative tracer is connected in a nonlinear manner to the transmissivity field 8 c f m w i t h t 10 m as mentioned earlier the forward problem will be served to create the training dataset by computing concentration data for thousands of geostatistically generated transmissivity fields 2 2 inverse problem with deep learning network in this section we describe the theoretical background of inversion with an encoder decoder structure neural network that is based on the approximation of the highly nonlinear inverse function relating the concentration data input to the transmissivity model output this approximation is derived from a statistical analysis of the provided concentration transmissivity data in which a set of weight and bias parameters are determined by an optimization algorithm to construct a universal relationship between the input and output data thus the inverse operation can be reformulated as following 9 m f 1 c θ where f 1 denotes the inverse operator and θ denotes all parameters used in the network and are determined in the training step c is the temporal measurements of the concentration of tracer collected in the wells m is the negative of logarithm of transmissivity field in the learning phase the inverse operator is built with an optimization process for finding the best weights and biases that connect the concentration and transmissivity of the training data set this operation can be expressed as follows 10 θ argmin 1 n m i f 1 c i θ where m i c i refers to the transmissivity model and its corresponding concentration data determined numerically with the forward problem and n is the size of training data used to train the network the quality of the approximation of the inversion function depends on the amount of data used in the training phase to get an accurate estimate we need to build a large training database from repeated solving of the forward problem making this step the most time consuming in the process the structure of the networks also has a significant impact on the quality of the reconstruction of inversion function in this paper we chose the segnet network which was initially established to deal with the problem of segmentation on images by identifying the objects learned on the images such as car bus road animal since it is difficult to perform a soil classification from the concentration data we adapted this network to handle a regression problem for linking the concentration data to the transmissivity model the segnet network is composed of encoder and decoder blocks presented in a symmetrical manner badrinarayanan et al 2017 on each encoder several operations are performed sequentially to extract the main features of the data using convolution batch normalization and relu convolution is a linear operation in which several small filters are slid to cover the entire image to recover the relevant information called feature maps jogin et al 2018 this operation is followed by a batch normalization as the name indicates is a simple normalization of the feature maps to be of the same order to facilitate learning of the network then the relu function is applied to introduce non linearity in the process at the end of these operations max pooling is used to reduce the size of the maps without losing the main information this loss of resolution will be compensated in the decoder part each decoder starts with an up sampling layer that is used to increase the resolution of the maps extracted in the encoder block this up sampling results from a transfer of the max pooling indices from the encoder block which drastically reduces the computation time compared to other encoder decoder structures such as unet siam et al 2018 as in the encoder convolution batch normalization and relu operations are performed sequentially in the decoder to form the network at the end of all these operations we added a convolution and a regression layer in this study we test two schemes to reconstruct the transmissivity field fig 1 one is designed to process data collected with a single injection net 1 while the other processes data from multiple injections performed separately net 2 the latter uses the transmissivity fields obtained with a single injection as input to the second network to reconstruct a transmissivity model with multiple injections thus the second network performs a joint inversion of the data to improve the prediction accuracy both architectures are built with 3 encoders which relate to 3 decoders and the whole is formed of 45 layers the architectures are trained in the same way but the nature of the input data is totally different the first one uses the concentration data measured in the boreholes at different time steps then these punctual observations are spatially interpolated to bring this data to the same size as the transmissivity field at the end for each time step an image is obtained to construct the spatio temporal concentration data as a matrix with 3d however in the second network the input data are the transmissivity fields obtained with the first network derived from the single injection interpretation thus in the second network the input and output have the same nature this network provides a correction of the transmissivity field obtained by single injection 3 application 3 1 construction of training data this section is dedicated to the construction of the training dataset to train the segnet network to accomplish we use a geostatistical code to generate 25 000 transmissivity fields in which the distribution of log10t is constructed randomly using a gaussian variogram variogram properties vary 0 1 2 5 for sill 3 5 for mean and 3 15 m for range the values of the generated transmissivity models range from 10 6 to 100 m2 s in six orders of magnitude we assign these models to a confined aquifer with dimensions of 20 m 10 m and 5 m for thickness fig 2 on this aquifer we have set up 49 wells 3 of which are dedicated to the injection of the tracer and the others to the monitoring of the evolution in time of the tracer concentration then the set of transmissivity fields is used in the forward problem described in the previous sections to numerically calculate the concentration data associated to the tracer tests conducted sequentially on the three wells the tracer is injected with a constant flow rate of 50 m3 day and a concentration of 50 mol m3 each tracer test lasts 15 days we also impose a hydraulic gradient of 0 1 between the right and left boundaries of the medium to simulate a regional flow for simplicity we assign constant values to the porosity ϕ 0 3 and longitudinal and transverse dispersivities of the aquifer 2 0 m and 0 2 m the concentration data acquired on the 49 boreholes over a period of 15 days with a time step of 0 5 days are transformed with this formulation to avoid strong contrasts between the data 11 c log 10 c 1 then these data are spatially interpolated with nearest method at each time step to make the concentration data the same size as the transmissivity models at the end the input data are assembled as a 3d matrix 32 32 30 the same operation is performed for each hydraulic transmissivity model and each tracer test finally we will try in the training phase to link the concentration data image with multiple channels 32 32 30 to another image of transmissivity with the same resolution 32 32 for the training and testing phases we separated 25 000 transmissivity fields with corresponding concentration data into 3 sets 18 000 models for the training and 2 000 models for the validation the remaining 5000 models are used in the test phase to evaluate the efficiency of the network in handling unseen models all these data are organized according to the number of injections and take in total 2 gb 3 2 learning and validation of the neural network as described in section 2 2 we build two architectures in this study net 1 and net 2 to process the single injection test and the multi injection test respectively for the first network net 1 it will be trained three times one for each injection tests the trainings of both networks are performed with the adam optimization algorithm implemented in matlab on a dell precision tower 5810 single gpu nvidia quadro k2200 for net 1 the training is performed with 60 epochs in 82 min with a learning rate initiated at 0 01 and decreasing by 0 1 for every 30 epochs however the second network net 2 is trained in 35 min using a constant learning rate of 0 01 with 30 epochs the number of epochs in both training is set manually to avoid the overfitting problem the training quality of both networks is reported in fig 3 where we presented the root mean square error between the predicted and true transmissivity models used in the training and validation to quantitatively assess the predictions accuracy of the networks on the unseen data we use the coefficient of determination r2 and the root mean square error rmse as defined below 12 r 2 1 ssr sst 13 rmse 1 n s pred s true 2 n where ssr 1 n s pred s true 2 sst 1 n s true s true 2 with strue and spred denote the true and predicted logarithm of transmissivity s log10t respectively s true is the mean of strue and n is the number of pixels 32 32 in this case to illustrate and discuss the quality of the inversions obtained with both networks we have graphically represented the predictions of three models chosen among the test models these models have different degree of heterogeneity which is very high in model 3 moderate in the second and very low in the first model fig 4 this difference in heterogeneity is due to the parameters of the variogram used in generation which were chosen randomly the present discussion concerns the net 1 trained with single injection data realized at the second well with coordinates 2 5 m 5 m the metric evaluations of the application of net 1 on 5000 models in the test set shows that the accuracy of predictions depends on the complexity of the target model with the averages of determination coefficient and root mean square r2 0 68 and rmse 0 36 respectively this is also confirmed by the prediction reconstructions of three models presented in the fig 4 where the model with simple heterogeneity is better reconstructed exp 1 r2 0 88 compared to the models with moderate exp 2 r2 0 56 and complex exp 3 r2 0 42 heterogeneities we also observe that these reconstructions are better in areas close to the injection well this is normal since in the areas far from the injection wells the concentration decreases and the acquisition time stops at 15 days which makes it difficult to obtain information on the hydraulic properties in order to improve the quality of the predictions we will combine in net 2 all the predictions derived from net 1 with the single injection indeed the assimilation of three transmissivity fields coming from three injections to form the net 2 should allow a better reconstruction of the whole area on the other hand another configuration is also feasible which consists in combining all the data from the three injections to train the network at the same time but this approach obviously requires more memory because the concentration data will be voluminous 32 32 30 3 which makes the training very complex on the other hand by separating the data of each injection we reduce the memory and we can analyze the information brought by each tracer test the training of net 2 is relatively fast compared to the first network because the training data size is reduced to 3 channels 32 32 3 it is also very easy to relate the predicted transmissivity to the real transmissivity fields which have many similarities the performance test of this network was also performed on 5000 unseen test models the prediction results of all these models have an average of r2 0 83 and rmse 0 2 the details of the distribution of r2 and rmse are summarized in fig 10 with a comparison to the previous net 1 results based on this metric evaluation this network seems to correctly reproduce the aquifer heterogeneities this is also confirmed by the analysis of the predictions of the three models which illustrates that with net 2 the reconstructions were well improved for all models compared to the results with first net 1 with single tracer test see fig 5 3 3 effect of the resolution of the observation data in this section we will investigate how changing the quantity of piezometers and the duration of concentration data sampling affects the quality of predictions a number of measurement wells in space in this test we only reduce the number of wells used to track the concentration changes to 25 wells in other words we remove almost half of the wells from the initial configuration used in the previous cases fig 6 however we keep the same sampling duration used in the previous cases then the data acquired with this new configuration is used to train the networks without modifying their structures the trained network net 2 was also used to predict unseen test models and the results obtained have average values of r2 0 70 and rmse 0 33 this metric evaluation illustrates a degradation in the reconstruction accuracy compared to the result of the previous case with a dense distribution of wells however the concentration data are still largely sufficient to provide the main features of the models as confirmed by the predictions of the reference models in which it is found that the reconstructions of the models with simple and moderate heterogeneities remain satisfactory fig 7 however the third model with complex heterogeneity the reconstruction obtained is very smooth as the lack of data did not allow to perfectly identify the heterogeneities of small sizes we then reduced the number of observation wells to 16 arranged in a regular array of 5 0 m 2 5 m analysis of the prediction accuracy with this poor configuration reveals a significant degradation in the quality of the reconstructions with average of r2 0 57 and rmse 0 38 all the information on the metric evaluation of the case is reported in table 1 we conclude that the accuracy of inversion results with deep learning methods like other classical inversions with deterministic gauss newton or stochastic mcmc methods depends strongly on the number of wells used to collect the data thus a configuration with a very limited number of piezometers will not be able to capture all the characteristics of a highly heterogeneous aquifer but will provide a too smooth mapping of the hydraulic transmissivity b number of measurements in time in this section we analyze the impact of reducing the duration of tracer concentration monitoring from 15 days to 5 and 3 days on the predictions in practice we only shortened the number of training data channels used in the construction of net 1 with the first configuration with 49 piezometers thus the data that will be taken in this analysis will have these sizes 32 32 10 and 32 32 6 for the duration of 5 and 3 days respectively we re train the networks with these new data and use them to predict the test models the results obtained for the two acquisition times of 5 and 3 days in table 1 have these averages r2 0 81 rmse 0 30 and r2 0 74 rmse 0 33 respectively from these evaluations there is a net decrease in prediction quality with shortening of the acquisition time the predictions of the reference models confirm this trend but also show that this degradation occurs mainly on the areas far from the injection zone fig 8 indeed the use of a short acquisition time does not allow collecting enough information on the distant areas where the tracer reaches late the accuracy of the reconstruction with the deep learning algorithm depends on the spatial coverage of the piezometer and the temporal acquisition scheme used to track changes in tracer concentration over time dense coverage with a long acquisition time allows for better identification of transmissivity heterogeneities 3 4 effect of observation uncertainty most often in tracer tests the recorded data may carry a noise signal that may affect the inversion result in this section we analyze the noise impact on the result of the deep learning algorithm to do so we contaminate the concentration data used in the test models with a gaussian noise of 15 and 25 and check the result of applying the network already built in the previous section on these contaminated data the result of this application is presented in the table where the averages of the correlation coefficients r2 0 79 for 15 noise and r2 0 76 for 25 noise indicate a slight degradation of the noise quality with the increase of noise magnitude the transmissivity predictions of the reference models also show that the 25 noise does not prevent efficient reconstructions of hydraulic transmissivity fields fig 9 this minimal effect of noise has also been noted in applications of cnn techniques on the inversion of electrical vu jardani 2021 seismic data wu lin 2018 wei chen 2019 this could be explained by the fact that the data in cnn networks are not processed individually but in spatial connection with each other and in this case the noise does not have a significant impact on the alteration of the information carried by the input image to clarify the influence of each interference in the prediction accuracy details of the distribution of r2 and rmse are summarized in table 1 for three examples and the average of 5000 testing models with its histogram illustrated in fig 10 3 5 influence of the features of training models in the inverse problem it is known that the solution is not unique and to reduce the number of solutions it is necessary to include prior information in the optimization procedure in the deep learning algorithms prior information is also included through the choice of the characteristics of generated transmissivity fields of training data to evaluate how the nature of the training models can influence the inversion results we apply the previous network trained with a gaussian variogram on the inversion of the concentration data derived from the non gaussian transmissivity models we generated three models characterized by abrupt changes in transmissivity values that are completely different from the smooth models used in the network training the predictions resulting from these applications have been reported in fig 11 with comparisons between the predicted and true models based on these comparisons we can clearly notice that the network is able to provide the main heterogeneities of the first and second models but in detail these models show many anomalies related to the presence of variabilities in transmissivity on the areas where the values are homogeneous this is related to the influence of the nature of the training models however on the third model with complex heterogeneity the network fails to provide a good reconstruction of the field these results are normal because deep learning algorithms only approximate an inversion operator that is highly dependent on the nature of the training data and thus cannot be used to predict models with unlearned features thus the choice of the feature of the training models is a crucial step in the deep learning algorithm and this choice must be based on the prior information collected on the aquifer under study 3 6 comparison of cnn 2t with conventional gauss newton algorithm we devote this section to comparing the results obtained with our cnn 2t deep learning algorithm and the gauss newton code gauss newton is a popular deterministic algorithm that searches for the best transmissivity model that can fit the concentration data by minimizing an objective function formulated as follows 14 l f m c obs t f m c obs α m m t g 1 m m where m is the logarithm of the transmissivity field to be determined from the minimization of this objective function c obs denotes the measured concentration vector f m is the forward problem used to compute numerically the concentration vector corresponding to the transmissivity model m g is the covariance matrix used with the mean of field m as prior information to constraint the inversion α is a parameter of regularization the minimization of the objective function relies on this iterative formulation 15 m k 1 m k β δ m where 16 δ m j t j α g 1 1 j t c obs f m with coefficient β is a scalar determined from minimizing objective function l using a line search code j is a jacobian matrix computed with finite difference 17 j f m m the calculation of the jacobian matrix requires a very repetitive and heavy computation of the forward problem in this case for each iteration the direct problem is solved 1024 32 32 times the jacobian could be computed with the adjoint state method which is faster than the finite difference method but it is complex to implement vu et al 2019 sun yeh 1990 the process is repeated until a local minimum is reached that minimizes the objective function this algorithm was applied on the three models used as reference in the previous sections and the inversion of each model took 3 days using a cpu intel xeon 3 5 ghz 6 cores 12 threads the results of these inversions faithfully reproduce the main characteristics of the real models with the same degree of accuracy as the cnn 2t algorithm see fig 12 each inference of gauss newton inversion method consumes the same time with building entire process of cnn 2t including time for dataset generation and training network while cnn 2t performs each inference only on few milliseconds as explained in the work of jardani et al 2022 deterministic inversion methods share with the inversion method their strong dependence on the a priori model in deterministic algorithms the a priori model is used as a regularization term of the objective function so it must have a derivable form on the other hand in machine learning the a priori model is used to construct training data without any condition on its derivability it also shares their dependence on the amount of measurement data and that the quality of the prediction improves in both methods when the piezometric information are sufficient to capture all the heterogeneities of the studied aquifer regarding the impact of measurement noise on the results machine learning techniques are slightly less impacted compared to deterministic methods because in machine learning the data processing is performed on the spatial analysis of several information instead of individual data as it is the case in deterministic algorithms the results of the gauss newton inversion are local minima so they depend on the choice of the initial model in contrast machine learning provides a global solution the machine learning method does not require any linearization of the forward problem but it does require a large amount of forward problem computation to construct the training data the time spent generating this training dataset can be the same or less than that needed to find a local minimum with gauss newton code using the finite difference method the reason it will take less time is that training an inversion network with simple and moderate heterogeneities can be done with a very limited data set we recall that in our case we used a variogram with randomly chosen parameters which leads to create a large variability between models which makes the training is done with a large volume of training data 4 conclusion in this work we propose a novel approach that inverts tracer test data to reconstruct the spatial variability of the hydraulic transmissivity field the approach is based on a deep learning neural network to approach the inversion function the proposed neural network architecture segnet uses the concept of convolutional neural networks with encoder decoder structure which have shown significant success in image processing in recent years the segnet network was originally set up for segmentation tasks but in this paper it has been modified to perform a regression task in order to relate the temporal concentration data to the transmissivity field the inversion processing was performed sequentially in two steps and via two connected networks with the same structure the first network was built to link the concentration data recorded with a single tracer test and the transmissivity field then this network is trained with data of each tracer test performed separately the transmissivity fields determined from the individual tracer data are then incorporated into the second network as input data which is linked to the real transmissivity field to improve the reconstructions this second network performs a joint inversion of data from multiple tracer tests and corrects the transmissivity fields determined separately from each individual tracer test the networks were trained from a large synthetic database where the transmissivity fields were generated geostatistically and the concentration data by the coupled numerical solutions of the groundwater flow and transport equations several sensitivity analyses were conducted on these networks to evaluate the prediction accuracy which was also compared with that achieved by a deterministic gauss newton method based on these results we conclude that the network succeeded in accurately reconstructing the heterogeneities of the transmissivity field the reconstruction accuracy though shows a clear dependence on the scale of training datasets whose generation is the hardest task in a deep learning approach however the time needed to generate datasets is of the same magnitude as that required in solving a local minimum in a gauss newton algorithm which computes the jacobian matrix using the finite difference method in addition the size of the training datasets to achieve a perfect approximation of the inverse function depends strongly on the nature of the heterogeneity of the target field learning can be achieved with a small number of training models if the generated models have a low degree of heterogeneity recall that in this work the models are all generated according to a random scheme in which the variogram parameters are also randomly selected to ensure the generality in the generation as a result a large number of training models are required to reconstruct an accurate prediction furthermore the quality of the neural network predictions relies on the size of the concentration data i e the number of wells and the duration chosen for tracer migration monitoring accuracy improves as monitoring data are sufficient to cover the main heterogeneities in the target field this dependence on data coverage is also observed in both classical deterministic and stochastic inversion methods concerning the effect of concentration data noise on forecasts the tests revealed that it had a marginal impact on the network performance this is due to the spatial analysis performed by the convolutional process in which the data are related regionally rather than being handled separately as in classical inversion methods we believe that the new generation of deep learning algorithms based on the concept of convolutional neural networks are effective tools for mapping hydraulic properties from tracing or pumping test data these tools deserve to be explored in hydraulic and geophysical tomography and to show all their aspects we plan in our next work to apply them on a real field data credit authorship contribution statement m t vu conceptualization data curation investigation methodology software visualization a jardani conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
3669,this paper introduces a new concept for mapping hydraulic transmissivity from temporal concentration data collected in multiple tracer tests based on convolutional neural network the principle uses an encoder decoder architecture with multiple neural layers to establish a relationship between the concentration data and the transmissivity field this relationship is established in two phases with two networks the first network is designated and trained to reconstruct a transmissivity field using data from a single tracer test to improve the reconstruction quality the second network then performs a joint interpretation for multiple tracer tests which reprocesses all the transmissivity resulted from the first network for each individual tracer test both networks are trained by synthetic data where the transmissivity models are generated with a gaussian variogram and its properties are considered as prior information on the aquifer heterogeneity tracer tests are derived numerically by solving the forward problem to obtain the corresponding concentration data that feed the training the trained networks accurately map the transmissivity fields of which the accuracy relies on the volume and nature of the heterogeneities of training models as well as the number of piezometers used to monitor the concentration changes reconstruction quality on the other hand is less influenced by data noise effective training requires a large dataset but the time required for dataset generation is only on the order of the gauss newton algorithm in a conventional inversion while the trained network performs inference instantly keywords inversion method hydraulic tomography cnn neural network architecture deep learning tracer test 1 introduction characterising the spatial variability of aquifer hydraulic properties in hydrogeology remains a complex and critical task for any attempt to understand water dynamics and contaminant transport in aquifers bear and cheng 2010 spatial heterogeneity particularly in hydraulic conductivity drives transport mechanism of water and contaminants in the subsurface such characterization referred as hydraulic tomography is typically performed on a large scale by analysing hydraulic changes due to natural forces such as the hydrological cycle and tidal oscillations bailey baù 2012 jardani et al 2012 on a small scale the task can be similarly achieved through a joint interpretation of hydraulic head variations in a sequential multiple pumping test yeh liu 2000 cardiff et al 2013 as an alternative tracer tests can provide insight into hydraulic properties particularly in high permeability environments by analysing the temporal concentration variations of an injected tracer i e a dye salt or heat jardani et al 2013 lee and kitanidis 2014 sanchez león et al 2016 yeh and zhu 2007 to interpret these hydraulic concentration measurements an inversion solver often involves an iterative algorithm that fits the measurement from adjusting a hydraulic conductivity distribution however this type of inversion approach is ill posed resulting in a non unique solution to overcome this issue constraints and prior information must be included which narrow the possibilities and promote convergence to a physically meaningful model kitanidis 1997 zha et al 2017 this optimization can be performed with an algorithm that belongs to one of three types deterministic stochastic and global carrera et al 2005 reuschen et al 2020 sen et al 1995 soueid ahmed et al 2015 xu and gómez hernández 2018 in deterministic algorithms such as gauss newton and conjugate gradient optimization aims at a local minimum by iteratively computing the gradient of the objective function their computation time and accuracy rely on the selection of initial model and the calibration of jacobian matrix tarantola valette 1982 fahs et al 2014 stochastic algorithms otherwise search for the best model which is based on a random strategy in which many models are generated selected or discarded according to their ability to fit both the water concentration data and the prior information cui et al 2011 this type of algorithm is straightforward to implement and the resulting model is independent of the initial choice however the computation demands an intensive resource as it requires solving several times the forward problem global algorithms such as simulated annealing and genetic also represent an interesting alternative to invert the hydraulic concentration data by iteratively searching for the global optimum datta gupta et al 1995 jha datta 2011 among the applications of these inversion tools on the reconstruction of hydraulic parameters by processing tracer test data which will be the main subject of this paper zhu et al 2009 showed a synthetic case that interpretation of tracer test data with a linear sequence estimator the approach provided useful information about the heterogeneity of the hydraulic conductivity field in a short time especially when the concentration data are expressed with their temporal moments schwede et al 2014 employed the quasi linear geostatistical approach to characterize 3d hydraulic conductivity by jointly inverting hydraulic and thermal data derived from pumping and heat tracing tests conducted on a synthetic aquifer lee and kitanidis 2014 applied principal component geostatistical inversion derived from the classical quasi linear geostatistical algorithm to perform a joint inversion of hydraulic test and tracer data sanchez león et al 2016 examined the effectiveness of the ensemble kalman filter and the kalman ensemble generator in interpreting synthetic pumping and tracer test data jiménez et al 2016 opted for the stochastic reversible jump markov chain monte carlo with the pilot point as a parameterization method to invert tracer data collected on alluvial environment saley et al 2016 used the hamiltonian monte carlo algorithm to reconstruct hydraulic conductivity heterogeneity by inverting heat tracing data collected on sandbox somogyvári bayer 2017 mapped the hydraulic conductivity of a heterogeneous alluvial aquifer by inverting thermal tracer data with the simultaneous iteration reconstruction technique sirt the same algorithm was tested by kittilä et al 2020 in the interpretation of dye tracing test data performed on fractured crystalline rocks to identify preferential groundwater flow paths thus the literature is rich with applications of inversion tools for tracer data processing however an algorithm based on a new generation of deep learning tools has barely been performed for tracer tests the deep learning algorithm is based on the approximation of an inversion function that non linearly relates two parameters the spatio temporal measurement data and the aquifer properties zarita ong 2008 these relationships are determined using networks consists of multiple layers in which a set of linear and nonlinear operations are performed sequentially on the neurons of these layers this process involves the use of multidimensional coefficients known as weights and biases to ensure the connectivity between two successive layers zhang et al 1998 tahmasebi et al 2020 marçais de dreuzy 2017 the identification of the weights and biases is based on the optimization process i e their selection is made according to their ability to connect the input data with their corresponding outputs which are considered to be known and referred to as training dataset hassoun 1995 the accuracy of the predictions provided by the learned network depends strongly on the size of this training dataset zhang et al 1998 jardani et al 2022 in the processing of pumping and tracer test data the first attempts using deep learning algorithms to approximate inversion functions were made with vanilla neural networks where the layers are fully connected zio 1997 balkhair 2002 lin chen 2006 akin 2005 yoon et al 2007 this kind of connectivity implies the use of many parameters which overburdens the learning process and requires a heavy resources and computation time however in recent years a new generation of networks based on convolutional neural networks has emerged allowing to better address the problems of tomography in geosciences lecun et al 1998 lecun and bengio 1998 indeed this type of network permits efficiently linking two images through operating several convolution layers convolution is a linear operation in which small weights called filters are applied to the input image to establish local connectivity between neighbouring pixels indolia et al 2018 each filter is dedicated to extracting a feature in the image by scanning the filter region wise over the entire image the use of these small filters allows the recovery of the main features on the input image and reduces the number of unknown parameters learned during training o shea nash 2015 the number of applications of these new networks in the geosciences continues to grow including liu et al 2020 who used the unet network to train an inversion operator for electrical resistivity tomography that links apparent electrical resistivity data collected at the ground surface to the distribution of electrical resistivity in the subsurface vu jardani 2021 trained a convolutional neural network with encoder decoder architecture to perform 3d inversion of electrical resistivity data apolinario et al 2019 opted for the convolutional neural networks with encoder decoder structure to estimate seismic velocity from acoustic data zhang lin 2020 employed the generative adversarial network to approximate the inversion function to image spatial heterogeneity of seismic velocity for seismogram data in the electromagnetic applications puzyrev swidinsky 2019 used a convolution neural network to perform 1d inversion of electromagnetic data to obtain the vertical profile of electrical conductivity in the hydraulic tomography applications bao et al 2020 combined ensemble smoother with multiple data assimilation with generative adversarial networks to map the geometry of the channels by analysing the hydraulic head and concentration data sun 2018 used the generative adversarial networks to identify the spatial heterogeneity of the synthetic aquifer for the pumping test data laloy et al 2018 also used an inversion of hydraulic data based on the generative adversarial networks to determine spatial distribution of hydraulic conductivity fields in 2d and 3d most of these few initiatives were dedicated to reconstructing the hydraulic conductivity field from hydraulic head observations however there has been little work on the inversion of solute data in this paper we investigate the effectiveness of a network of encoder decoder structures to reconstruct the transmissivity field from temporal concentration data of a salt tracer this network called segnet was originally developed for a segmentation task in which networks are trained to identify pixels of labelled objects animal lane bicycle car on images badrinarayanan et al 2017 however in this paper the network is adapted to perform a regression task to associate concentration data with hydraulic transmissivity fields to our knowledge this is the first time such an advanced network has been performed in a tracer test inversion problem the first part of this paper introduces the theoretical background of the tracer test the forward problem used to generate the training data the principle of inversion is then introduced followed by a brief explanation of the proposed encoder decoder architecture its built in layers and operations for establishing the relationship between the concentration data and hydraulic transmissivity fields in the implementation process the network is tested with 5000 models after being trained with synthetic datasets after that the algorithm accuracy is assessed under a variety of data conditions in a monitoring field including the effects of data size low resolution and observation noise the effect of prior conditions introduced into the generation of training models on accuracy is discussed further in a range of real field contexts finally the deep learning results are compared with those determined with a gauss newton method to illustrate effectiveness of the proposed algorithm 2 theoretical background in this section we first describe the theoretical concept of the forward problem used for the numerical simulation of spatiotemporal concentration data of a tracer injected into an aquifer with a heterogeneous transmissivity field this forward problem is based on a coupling of the steady state groundwater flow equation and the transient transport equation and is employed to build a database in which the concentration data and its corresponding transmissivity field are used in the network training phase in the second section we introduce the concept of inversion problem with the convolutional neural network with an encoder decoder structure 2 1 forward problem numerical simulation of the transfer of a soluble tracer in a saturated heterogeneous medium relies on the sequential solving of the groundwater flow and transport equations first the groundwater flow equation is solved to determine the spatial distribution of the darcy velocity which is subsequently used in the transport equation to compute the convective and dispersive terms in this paper the groundwater flow equation is expressed in the steady state bear 1972 1 t h q 0 δ x x 0 subjected to a boundary condition 2 h h 0 a t γ where t is the heterogeneous transmissivity field m2 s generated geostatistically q0 represents the injection source m2 s at the well position x0 δ is kronecker delta h is the hydraulic head m h0 is a constant hydraulic head imposed at the boundary γ the water velocity is determined by darcy s law 3 u k h where k m s denotes the hydraulic conductivity k t b with b m is thickness of the aquifer taken as constant in this study then the velocity field is used in the transport equation that is expressed in transient mode as following 4 ϕ c t ϕ d c u c 0 subjected to the following initial and boundary conditions 5 c 0 a t t 0 6 n d c c 0 a t x x 0 where ϕ is the dynamic porosity c mol m3 is the solute concentration t s is the time d m2 s represents the hydrodynamic dispersion tensor which can be given by 7 d d m τ α t υ i 3 α l α t υ u u where dm m2 s is molecular diffusion coefficient of tracer υ m s is the magnitude of velocity υ u τ is the tortuosity αl and αt are the longitudinal and transverse dispersivities i 3 is the identify matrix 3 by 3 in this paper the groundwater flow and transport equations are solved numerically using the finite element method with comsol software these equations constitute the direct problem of the tracer test in which the concentration of conservative tracer is connected in a nonlinear manner to the transmissivity field 8 c f m w i t h t 10 m as mentioned earlier the forward problem will be served to create the training dataset by computing concentration data for thousands of geostatistically generated transmissivity fields 2 2 inverse problem with deep learning network in this section we describe the theoretical background of inversion with an encoder decoder structure neural network that is based on the approximation of the highly nonlinear inverse function relating the concentration data input to the transmissivity model output this approximation is derived from a statistical analysis of the provided concentration transmissivity data in which a set of weight and bias parameters are determined by an optimization algorithm to construct a universal relationship between the input and output data thus the inverse operation can be reformulated as following 9 m f 1 c θ where f 1 denotes the inverse operator and θ denotes all parameters used in the network and are determined in the training step c is the temporal measurements of the concentration of tracer collected in the wells m is the negative of logarithm of transmissivity field in the learning phase the inverse operator is built with an optimization process for finding the best weights and biases that connect the concentration and transmissivity of the training data set this operation can be expressed as follows 10 θ argmin 1 n m i f 1 c i θ where m i c i refers to the transmissivity model and its corresponding concentration data determined numerically with the forward problem and n is the size of training data used to train the network the quality of the approximation of the inversion function depends on the amount of data used in the training phase to get an accurate estimate we need to build a large training database from repeated solving of the forward problem making this step the most time consuming in the process the structure of the networks also has a significant impact on the quality of the reconstruction of inversion function in this paper we chose the segnet network which was initially established to deal with the problem of segmentation on images by identifying the objects learned on the images such as car bus road animal since it is difficult to perform a soil classification from the concentration data we adapted this network to handle a regression problem for linking the concentration data to the transmissivity model the segnet network is composed of encoder and decoder blocks presented in a symmetrical manner badrinarayanan et al 2017 on each encoder several operations are performed sequentially to extract the main features of the data using convolution batch normalization and relu convolution is a linear operation in which several small filters are slid to cover the entire image to recover the relevant information called feature maps jogin et al 2018 this operation is followed by a batch normalization as the name indicates is a simple normalization of the feature maps to be of the same order to facilitate learning of the network then the relu function is applied to introduce non linearity in the process at the end of these operations max pooling is used to reduce the size of the maps without losing the main information this loss of resolution will be compensated in the decoder part each decoder starts with an up sampling layer that is used to increase the resolution of the maps extracted in the encoder block this up sampling results from a transfer of the max pooling indices from the encoder block which drastically reduces the computation time compared to other encoder decoder structures such as unet siam et al 2018 as in the encoder convolution batch normalization and relu operations are performed sequentially in the decoder to form the network at the end of all these operations we added a convolution and a regression layer in this study we test two schemes to reconstruct the transmissivity field fig 1 one is designed to process data collected with a single injection net 1 while the other processes data from multiple injections performed separately net 2 the latter uses the transmissivity fields obtained with a single injection as input to the second network to reconstruct a transmissivity model with multiple injections thus the second network performs a joint inversion of the data to improve the prediction accuracy both architectures are built with 3 encoders which relate to 3 decoders and the whole is formed of 45 layers the architectures are trained in the same way but the nature of the input data is totally different the first one uses the concentration data measured in the boreholes at different time steps then these punctual observations are spatially interpolated to bring this data to the same size as the transmissivity field at the end for each time step an image is obtained to construct the spatio temporal concentration data as a matrix with 3d however in the second network the input data are the transmissivity fields obtained with the first network derived from the single injection interpretation thus in the second network the input and output have the same nature this network provides a correction of the transmissivity field obtained by single injection 3 application 3 1 construction of training data this section is dedicated to the construction of the training dataset to train the segnet network to accomplish we use a geostatistical code to generate 25 000 transmissivity fields in which the distribution of log10t is constructed randomly using a gaussian variogram variogram properties vary 0 1 2 5 for sill 3 5 for mean and 3 15 m for range the values of the generated transmissivity models range from 10 6 to 100 m2 s in six orders of magnitude we assign these models to a confined aquifer with dimensions of 20 m 10 m and 5 m for thickness fig 2 on this aquifer we have set up 49 wells 3 of which are dedicated to the injection of the tracer and the others to the monitoring of the evolution in time of the tracer concentration then the set of transmissivity fields is used in the forward problem described in the previous sections to numerically calculate the concentration data associated to the tracer tests conducted sequentially on the three wells the tracer is injected with a constant flow rate of 50 m3 day and a concentration of 50 mol m3 each tracer test lasts 15 days we also impose a hydraulic gradient of 0 1 between the right and left boundaries of the medium to simulate a regional flow for simplicity we assign constant values to the porosity ϕ 0 3 and longitudinal and transverse dispersivities of the aquifer 2 0 m and 0 2 m the concentration data acquired on the 49 boreholes over a period of 15 days with a time step of 0 5 days are transformed with this formulation to avoid strong contrasts between the data 11 c log 10 c 1 then these data are spatially interpolated with nearest method at each time step to make the concentration data the same size as the transmissivity models at the end the input data are assembled as a 3d matrix 32 32 30 the same operation is performed for each hydraulic transmissivity model and each tracer test finally we will try in the training phase to link the concentration data image with multiple channels 32 32 30 to another image of transmissivity with the same resolution 32 32 for the training and testing phases we separated 25 000 transmissivity fields with corresponding concentration data into 3 sets 18 000 models for the training and 2 000 models for the validation the remaining 5000 models are used in the test phase to evaluate the efficiency of the network in handling unseen models all these data are organized according to the number of injections and take in total 2 gb 3 2 learning and validation of the neural network as described in section 2 2 we build two architectures in this study net 1 and net 2 to process the single injection test and the multi injection test respectively for the first network net 1 it will be trained three times one for each injection tests the trainings of both networks are performed with the adam optimization algorithm implemented in matlab on a dell precision tower 5810 single gpu nvidia quadro k2200 for net 1 the training is performed with 60 epochs in 82 min with a learning rate initiated at 0 01 and decreasing by 0 1 for every 30 epochs however the second network net 2 is trained in 35 min using a constant learning rate of 0 01 with 30 epochs the number of epochs in both training is set manually to avoid the overfitting problem the training quality of both networks is reported in fig 3 where we presented the root mean square error between the predicted and true transmissivity models used in the training and validation to quantitatively assess the predictions accuracy of the networks on the unseen data we use the coefficient of determination r2 and the root mean square error rmse as defined below 12 r 2 1 ssr sst 13 rmse 1 n s pred s true 2 n where ssr 1 n s pred s true 2 sst 1 n s true s true 2 with strue and spred denote the true and predicted logarithm of transmissivity s log10t respectively s true is the mean of strue and n is the number of pixels 32 32 in this case to illustrate and discuss the quality of the inversions obtained with both networks we have graphically represented the predictions of three models chosen among the test models these models have different degree of heterogeneity which is very high in model 3 moderate in the second and very low in the first model fig 4 this difference in heterogeneity is due to the parameters of the variogram used in generation which were chosen randomly the present discussion concerns the net 1 trained with single injection data realized at the second well with coordinates 2 5 m 5 m the metric evaluations of the application of net 1 on 5000 models in the test set shows that the accuracy of predictions depends on the complexity of the target model with the averages of determination coefficient and root mean square r2 0 68 and rmse 0 36 respectively this is also confirmed by the prediction reconstructions of three models presented in the fig 4 where the model with simple heterogeneity is better reconstructed exp 1 r2 0 88 compared to the models with moderate exp 2 r2 0 56 and complex exp 3 r2 0 42 heterogeneities we also observe that these reconstructions are better in areas close to the injection well this is normal since in the areas far from the injection wells the concentration decreases and the acquisition time stops at 15 days which makes it difficult to obtain information on the hydraulic properties in order to improve the quality of the predictions we will combine in net 2 all the predictions derived from net 1 with the single injection indeed the assimilation of three transmissivity fields coming from three injections to form the net 2 should allow a better reconstruction of the whole area on the other hand another configuration is also feasible which consists in combining all the data from the three injections to train the network at the same time but this approach obviously requires more memory because the concentration data will be voluminous 32 32 30 3 which makes the training very complex on the other hand by separating the data of each injection we reduce the memory and we can analyze the information brought by each tracer test the training of net 2 is relatively fast compared to the first network because the training data size is reduced to 3 channels 32 32 3 it is also very easy to relate the predicted transmissivity to the real transmissivity fields which have many similarities the performance test of this network was also performed on 5000 unseen test models the prediction results of all these models have an average of r2 0 83 and rmse 0 2 the details of the distribution of r2 and rmse are summarized in fig 10 with a comparison to the previous net 1 results based on this metric evaluation this network seems to correctly reproduce the aquifer heterogeneities this is also confirmed by the analysis of the predictions of the three models which illustrates that with net 2 the reconstructions were well improved for all models compared to the results with first net 1 with single tracer test see fig 5 3 3 effect of the resolution of the observation data in this section we will investigate how changing the quantity of piezometers and the duration of concentration data sampling affects the quality of predictions a number of measurement wells in space in this test we only reduce the number of wells used to track the concentration changes to 25 wells in other words we remove almost half of the wells from the initial configuration used in the previous cases fig 6 however we keep the same sampling duration used in the previous cases then the data acquired with this new configuration is used to train the networks without modifying their structures the trained network net 2 was also used to predict unseen test models and the results obtained have average values of r2 0 70 and rmse 0 33 this metric evaluation illustrates a degradation in the reconstruction accuracy compared to the result of the previous case with a dense distribution of wells however the concentration data are still largely sufficient to provide the main features of the models as confirmed by the predictions of the reference models in which it is found that the reconstructions of the models with simple and moderate heterogeneities remain satisfactory fig 7 however the third model with complex heterogeneity the reconstruction obtained is very smooth as the lack of data did not allow to perfectly identify the heterogeneities of small sizes we then reduced the number of observation wells to 16 arranged in a regular array of 5 0 m 2 5 m analysis of the prediction accuracy with this poor configuration reveals a significant degradation in the quality of the reconstructions with average of r2 0 57 and rmse 0 38 all the information on the metric evaluation of the case is reported in table 1 we conclude that the accuracy of inversion results with deep learning methods like other classical inversions with deterministic gauss newton or stochastic mcmc methods depends strongly on the number of wells used to collect the data thus a configuration with a very limited number of piezometers will not be able to capture all the characteristics of a highly heterogeneous aquifer but will provide a too smooth mapping of the hydraulic transmissivity b number of measurements in time in this section we analyze the impact of reducing the duration of tracer concentration monitoring from 15 days to 5 and 3 days on the predictions in practice we only shortened the number of training data channels used in the construction of net 1 with the first configuration with 49 piezometers thus the data that will be taken in this analysis will have these sizes 32 32 10 and 32 32 6 for the duration of 5 and 3 days respectively we re train the networks with these new data and use them to predict the test models the results obtained for the two acquisition times of 5 and 3 days in table 1 have these averages r2 0 81 rmse 0 30 and r2 0 74 rmse 0 33 respectively from these evaluations there is a net decrease in prediction quality with shortening of the acquisition time the predictions of the reference models confirm this trend but also show that this degradation occurs mainly on the areas far from the injection zone fig 8 indeed the use of a short acquisition time does not allow collecting enough information on the distant areas where the tracer reaches late the accuracy of the reconstruction with the deep learning algorithm depends on the spatial coverage of the piezometer and the temporal acquisition scheme used to track changes in tracer concentration over time dense coverage with a long acquisition time allows for better identification of transmissivity heterogeneities 3 4 effect of observation uncertainty most often in tracer tests the recorded data may carry a noise signal that may affect the inversion result in this section we analyze the noise impact on the result of the deep learning algorithm to do so we contaminate the concentration data used in the test models with a gaussian noise of 15 and 25 and check the result of applying the network already built in the previous section on these contaminated data the result of this application is presented in the table where the averages of the correlation coefficients r2 0 79 for 15 noise and r2 0 76 for 25 noise indicate a slight degradation of the noise quality with the increase of noise magnitude the transmissivity predictions of the reference models also show that the 25 noise does not prevent efficient reconstructions of hydraulic transmissivity fields fig 9 this minimal effect of noise has also been noted in applications of cnn techniques on the inversion of electrical vu jardani 2021 seismic data wu lin 2018 wei chen 2019 this could be explained by the fact that the data in cnn networks are not processed individually but in spatial connection with each other and in this case the noise does not have a significant impact on the alteration of the information carried by the input image to clarify the influence of each interference in the prediction accuracy details of the distribution of r2 and rmse are summarized in table 1 for three examples and the average of 5000 testing models with its histogram illustrated in fig 10 3 5 influence of the features of training models in the inverse problem it is known that the solution is not unique and to reduce the number of solutions it is necessary to include prior information in the optimization procedure in the deep learning algorithms prior information is also included through the choice of the characteristics of generated transmissivity fields of training data to evaluate how the nature of the training models can influence the inversion results we apply the previous network trained with a gaussian variogram on the inversion of the concentration data derived from the non gaussian transmissivity models we generated three models characterized by abrupt changes in transmissivity values that are completely different from the smooth models used in the network training the predictions resulting from these applications have been reported in fig 11 with comparisons between the predicted and true models based on these comparisons we can clearly notice that the network is able to provide the main heterogeneities of the first and second models but in detail these models show many anomalies related to the presence of variabilities in transmissivity on the areas where the values are homogeneous this is related to the influence of the nature of the training models however on the third model with complex heterogeneity the network fails to provide a good reconstruction of the field these results are normal because deep learning algorithms only approximate an inversion operator that is highly dependent on the nature of the training data and thus cannot be used to predict models with unlearned features thus the choice of the feature of the training models is a crucial step in the deep learning algorithm and this choice must be based on the prior information collected on the aquifer under study 3 6 comparison of cnn 2t with conventional gauss newton algorithm we devote this section to comparing the results obtained with our cnn 2t deep learning algorithm and the gauss newton code gauss newton is a popular deterministic algorithm that searches for the best transmissivity model that can fit the concentration data by minimizing an objective function formulated as follows 14 l f m c obs t f m c obs α m m t g 1 m m where m is the logarithm of the transmissivity field to be determined from the minimization of this objective function c obs denotes the measured concentration vector f m is the forward problem used to compute numerically the concentration vector corresponding to the transmissivity model m g is the covariance matrix used with the mean of field m as prior information to constraint the inversion α is a parameter of regularization the minimization of the objective function relies on this iterative formulation 15 m k 1 m k β δ m where 16 δ m j t j α g 1 1 j t c obs f m with coefficient β is a scalar determined from minimizing objective function l using a line search code j is a jacobian matrix computed with finite difference 17 j f m m the calculation of the jacobian matrix requires a very repetitive and heavy computation of the forward problem in this case for each iteration the direct problem is solved 1024 32 32 times the jacobian could be computed with the adjoint state method which is faster than the finite difference method but it is complex to implement vu et al 2019 sun yeh 1990 the process is repeated until a local minimum is reached that minimizes the objective function this algorithm was applied on the three models used as reference in the previous sections and the inversion of each model took 3 days using a cpu intel xeon 3 5 ghz 6 cores 12 threads the results of these inversions faithfully reproduce the main characteristics of the real models with the same degree of accuracy as the cnn 2t algorithm see fig 12 each inference of gauss newton inversion method consumes the same time with building entire process of cnn 2t including time for dataset generation and training network while cnn 2t performs each inference only on few milliseconds as explained in the work of jardani et al 2022 deterministic inversion methods share with the inversion method their strong dependence on the a priori model in deterministic algorithms the a priori model is used as a regularization term of the objective function so it must have a derivable form on the other hand in machine learning the a priori model is used to construct training data without any condition on its derivability it also shares their dependence on the amount of measurement data and that the quality of the prediction improves in both methods when the piezometric information are sufficient to capture all the heterogeneities of the studied aquifer regarding the impact of measurement noise on the results machine learning techniques are slightly less impacted compared to deterministic methods because in machine learning the data processing is performed on the spatial analysis of several information instead of individual data as it is the case in deterministic algorithms the results of the gauss newton inversion are local minima so they depend on the choice of the initial model in contrast machine learning provides a global solution the machine learning method does not require any linearization of the forward problem but it does require a large amount of forward problem computation to construct the training data the time spent generating this training dataset can be the same or less than that needed to find a local minimum with gauss newton code using the finite difference method the reason it will take less time is that training an inversion network with simple and moderate heterogeneities can be done with a very limited data set we recall that in our case we used a variogram with randomly chosen parameters which leads to create a large variability between models which makes the training is done with a large volume of training data 4 conclusion in this work we propose a novel approach that inverts tracer test data to reconstruct the spatial variability of the hydraulic transmissivity field the approach is based on a deep learning neural network to approach the inversion function the proposed neural network architecture segnet uses the concept of convolutional neural networks with encoder decoder structure which have shown significant success in image processing in recent years the segnet network was originally set up for segmentation tasks but in this paper it has been modified to perform a regression task in order to relate the temporal concentration data to the transmissivity field the inversion processing was performed sequentially in two steps and via two connected networks with the same structure the first network was built to link the concentration data recorded with a single tracer test and the transmissivity field then this network is trained with data of each tracer test performed separately the transmissivity fields determined from the individual tracer data are then incorporated into the second network as input data which is linked to the real transmissivity field to improve the reconstructions this second network performs a joint inversion of data from multiple tracer tests and corrects the transmissivity fields determined separately from each individual tracer test the networks were trained from a large synthetic database where the transmissivity fields were generated geostatistically and the concentration data by the coupled numerical solutions of the groundwater flow and transport equations several sensitivity analyses were conducted on these networks to evaluate the prediction accuracy which was also compared with that achieved by a deterministic gauss newton method based on these results we conclude that the network succeeded in accurately reconstructing the heterogeneities of the transmissivity field the reconstruction accuracy though shows a clear dependence on the scale of training datasets whose generation is the hardest task in a deep learning approach however the time needed to generate datasets is of the same magnitude as that required in solving a local minimum in a gauss newton algorithm which computes the jacobian matrix using the finite difference method in addition the size of the training datasets to achieve a perfect approximation of the inverse function depends strongly on the nature of the heterogeneity of the target field learning can be achieved with a small number of training models if the generated models have a low degree of heterogeneity recall that in this work the models are all generated according to a random scheme in which the variogram parameters are also randomly selected to ensure the generality in the generation as a result a large number of training models are required to reconstruct an accurate prediction furthermore the quality of the neural network predictions relies on the size of the concentration data i e the number of wells and the duration chosen for tracer migration monitoring accuracy improves as monitoring data are sufficient to cover the main heterogeneities in the target field this dependence on data coverage is also observed in both classical deterministic and stochastic inversion methods concerning the effect of concentration data noise on forecasts the tests revealed that it had a marginal impact on the network performance this is due to the spatial analysis performed by the convolutional process in which the data are related regionally rather than being handled separately as in classical inversion methods we believe that the new generation of deep learning algorithms based on the concept of convolutional neural networks are effective tools for mapping hydraulic properties from tracing or pumping test data these tools deserve to be explored in hydraulic and geophysical tomography and to show all their aspects we plan in our next work to apply them on a real field data credit authorship contribution statement m t vu conceptualization data curation investigation methodology software visualization a jardani conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
