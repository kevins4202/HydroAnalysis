index,text
24005,this article describes a 10 year regional ocean reanalysis of the western coral sea and great barrier reef gbr from 2006 2015 here we use the regional ocean modelling system roms at 4 km resolution and enoi ensemble optimal interpolation data assimilation we also account for river freshwater discharge at the coast using hydrological stream gauge observations the system appears to constrain features of the deep ocean circulation that are important for cross shelf exchanges such as the spatio temporal locations of mesoscale eddies and boundary currents accuracy is evaluated with forecast innovation errors respecting available observations a four dimensional climatological atlas of water mass properties and currents representing 10 years of synthesis between model and data is then presented this illustrates seasonal and climatic processes driving changes in the region such as the el nino southern oscillation enso and its influence on sea temperature and freshwater flux to the shelf from rivers on the shelf where dense observation coverage is limited to satellite sea surface temperature sst we find where sst forecast errors are low and correlations between sst and bottom temperatures are significant and take this as a reliable predictor of bottom temperatures differences and correlations outside these parameters suggest areas where measurement of bottom temperature is likely to be important for a long term and comprehensive monitoring and prediction system the reanalysis provides a realistic physical and dynamic picture of the ocean at its given resolution that may be amenable to a variety of marine and environmental studies keywords assimilation forecasting reefs currents environment marine data availability the reanalysis data is accessible via the following url http dap nci org au thredds remotecatalogservice catalog http dapds00 nci org au thredds catalog rr6 ereefs 4kmreanalyses catalog xml 1 introduction the great barrier reef marine park is an extensive world heritage listed area of shelf sea in the queensland region of australia comprising the world s largest tropical coral reef complex it is characterised by high biodiversity and influenced by meteorological and oceanographic phenomena across a wide range of spatiotemporal scales the boundary currents of the gbr such as the jets of the south equatorial current north queensland current nqc east australian current eac and gulf of papua current gpc play important roles in flushing reef lagoon waters schiller et al 2015 brinkman et al 2002 lambrechts et al 2008 the gbr has been and continues to be subjected to a range of local and global pressures that have deleterious effects these include the influence of land based nutrients and sediments on water quality via river runoff devlin et al 2013 wooldridge 2009 mcculloch et al 2003 coral bleaching eakin et al 2016 ocean warming and acidification due to climate change ainsworth et al 2016 redondo rodriguez et al 2012 hoegh guldberg et al 2007 hughes et al 2007 and damage from development tropical cyclones and fishing dea th et al 2012 done 1992 nutrients pollutants and contaminants introduced through urban industrial and agricultural runoff find their way to the reef via streams and estuaries and influence water quality and ecosystems robson and dourdet 2015 reef decline has been linked to anthropogenic influences on water quality and satellite imagery has shown that after river flooding events materials brought to the seawater from rivers can dramatically deteriorate water quality and reach outer reefs hughes et al 2011 crown of thorns starfish cots infestation is regarded as one of the major threats to the reef and elevated nutrients in the seawater are believed to enhance their proliferation dea th et al 2012 ocean currents are responsible for carrying material away from the rivers and estuaries to reef locations environmental prediction and monitoring of ocean currents and river discharge in this region has significant potential to provide information beneficial for managing and mitigating anthropogenic pressures on the gbr this article describes a reanalysis system aimed at resolving the likely pathways of water borne material and the flushing of the gbr via the boundary currents under a variety of weather and ocean conditions the system is based on a hydrodynamic model a data assimilation system historical ocean observations hydrological river gauge observations atmospheric reanalysis and tidal forcing products realistic analysis and forecasting of the ocean circulation of the gbr region is a complex multi scale challenge that presents numerous limitations these include the relatively sparse ocean observation network and the ability of numerical models to accurately parameterise the complex sub grid scale processes occurring on the reefs whilst the development of the system described here cannot accommodate all these issues it aims to be a step towards quantifying forecast error in terms of the available observations and to provide a reference for potential improvements for other forecasting efforts e g schiller et al 2015 baird et al 2016 oke et al 2015 and wolanski et al 2003 the combination of observations modelling and data assimilation provides a system that can deliver meaningful predictions of the boundary currents of the gbr that vary on time scales of days to years influencing the flushing of the gbr benthuysen et al 2016 schiller et al 2015 brinkman et al 2002 and the dynamics of the shelf and coastal regions that are mainly atmospheric forced and tidally driven at timescales of hours to days the system is used to deliver the first downscaled climatological oceanographic atlas for the gbr through the synthesis of model and observations section 2 describes the system section 3 is devoted to forecast verification with respect to observations and mesoscale features seen in satellite imagery section 4 presents a downscaled climatology of monthly mean mesoscale volume transports and the climatological atlas section 5 provides conclusions 2 system description 2 1 model the regional ocean modelling system roms shchepetkin and mcwilliams 2005 is configured on a curvilinear grid for the great barrier reef and coral sea region at approximately 4 km horizontal resolution with 30 vertical sigma levels vertical resolution increases towards the surface to better accommodate the mixed layer the resolution of the model is insufficient to resolve reef slopes and the reef matrix in general however it is expected to adequately resolving the mesoscale boundary currents of the coral sea ocean currents on the shelf and the imprint of river freshwater input on the region the impact of not resolving the reef matrix is expected to lead to uncertainty in details of flow through the matrix and under estimation of the frictional dissipation and mixing this would show up as a systematic error or bias that the da system would be required to make repeated corrections for the study region and model domain are shown in fig 1 also shown are a 10 year depth averaged currents from the reanalysis that will be focussed on in section 4 2 10 year mean 10 m wind vectors from the ncep climate forecast system reanalysis cfsr saha et al 2010 c bureau of meteorology hydrological river gauge locations and d a schematic of boundary currents adapted from schiller et al 2015 the model bathymetry uses a blend of gbr100m beaman 2010 geoscience australia ga 9 arc second and the ga northward extension daniell 2008 the grid nodes use a mercator projection to unify cell aspect ratio initial conditions for the 1st of january 2006 and open boundary conditions from this date to 31st december 2015 are constructed using bluelink reanalysis bran datasets oke et al 2013 the model is forced with 1 hourly cfsr atmospheric fluxes using standard roms bulk formulae the model uses a combined nudging radation open boundary condition for temperature salinity and the components of the velocity field hereafter denoted as t s u v the chapman condition chapman 1985 is used for the free surface η and the flather condition for 2d momentum flather 1976 horizontal viscosity is increased in a sponge layer in the vicinity of the open boundaries for t s u v horizontal advection of momentum and tracer uses a 3rd order upwind scheme and vertical advection of tracer uses a 4th order centred scheme with an upwind limiter naughten et al 2017 the smagorinsky scheme smagorinsky 1963 is used for spatially dependent horizontal mixing of momentum we use the k profile parameterisation large et al 1994 for vertical mixing mainly for stability and computational efficiency noting that reanalysis experiments using the mellor and yamada 1982 and k epsilon schemes burchard et al 1998 were also carried out without significant changes to performance horizontal tracer diffusion is set to zero bottom drag is parameterised using the quadratic law atmospheric pressure forcing from cfsr is included in the simulations the minimum depth is set to 5 m and the wet dry algorithm enabled tidal forcing for sea surface height and barotropic velocities are derived from the topex poseidon global tidal model tpxo version 7 2 egbert et al 1994 2 2 data assimilation the state vector is taken to be x x η t s u v u v where u v are the components of 2d depth averaged velocity a 10 year hindcast control run is carried out to provide the first estimate of oceanographic conditions and to calculate background error covariances for the da the hindcast is similar to the roms system that wijeratne et al 2018 used to study oceanic variability in the australian region albeit with different size domain atmospheric forcing and open boundary conditions the hindcast inherits potential skill from the reanalysis open boundary conditions and forcing the errors of the hindcast are quantified with respect to the same observations that are used to estimate forecast error from the reanalysis which is a sequence of short forecasts aimed at achieving a dynamical balance between model and observations through frequent assimilation and initialisation steps the data assimilation software enkf c sakov 2018 with ensemble optimal interpolation enoi evensen 2003 oke et al 2005 is used enkf c has been used in a number of realistic ocean reanalyses o kane et al 2019 sandery 2018 sakov and sandery 2015 sandery et al 2014 the analysis equation and enoi background covariances can be written as 1 x a x f b h t h b h t r 1 y h x f 2 b a a t m 1 1 where x a and x f are analysis and forecast state vectors respectively y is an observation vector h is a linear observation operator i e h h x where h is a linear affine observation operator b is background error covariance r is observation error covariance a represents ensemble anomalies m is ensemble size and t denotes matrix transposition x f is taken to be an instantaneous model state whereas x f is a daily mean forecast the assimilation of altimetric sea level anomaly requires the detided background state x d in order to match non tidal altimetric observations with the model a is calculated for 255 ensemble members for x d 7 days apart from the first 6 years of the hindcast using 3 day minus 30 day running means these anomalies effectively filter out both multi week to climatological and sub daily dependencies to represent background error covariances at appropriate spatio temporal scales for the assimilated observations and for the 3 day analysis forecast cycle a graphical depiction of the cycle is shown in fig 2 the innovations are calculated using daily forecast fields at observation time this is known as the first guess at appropriate time fgat approach lee 2005 cummings 2005 the following features of enkf c are used multi grid capability for geo location of state variables to the model arakawa c grid variable dependent localisation radii and r factors and k factor for adaptively limiting the increment to k proportional to ensemble spread r factor defines a multiple of observation error variance and can be used to tune the kalman gain in order to achieve a more balanced observation error ensemble spread relationship k factor is used to avoid large increments in the analysis and improve balance without discarding associated observations that can provide important information to the system sakov and sandery 2017 the system uses no nudging or incremental updating rather the model is directly initialised to the analysis this approach allows the model to run the complete length of each cycle as a dynamical forecast the increment is relatively spatially smooth as b is smooth the use of x f in the innovation vector and x f in the analysis equation allows the increment to be added to the dynamically balanced state the use of x d for η creates an increment based only on mesoscale anomalies this is added to x f that retains the tide in the analysis and initial conditions in order to ensure all calculated errors and increments are based on forecasts of the model and the centred observation window is compared directly with the right observations each forecast is run for an additional 1 5 days past the base date of the next analysis fields are saved as 12 hourly means and the last 6 are averaged into daily means for each background data assimilation tuning experiments showed that the localisation radii and r factors that provided best system performance were 4 and 1 for sea level anomaly sla 1 and 2 for sea surface temperature sst and 4 and 1 for in situ profiles an illustration of low pass filtered variability in the hindcast is shown in fig 3 that presents spread temporal standard deviation for sea surface height ssh sst and sea surface salinity sss derived from the background ensemble ensemble spread is an estimate of model uncertainty the larger the spread the greater the relative impact of the observations with relatively low error on the analysis it can be seen that non tidal ssh uncertainty is large in several areas yet is dominated by the region of mesoscale eddy variability centred on 156 e 26 s where the east australian current is most energetic and chaotic in the domain there is also corresponding sst uncertainty in the eddy field however large spread also manifests along the entire coast due to variability induced by atmospheric forcing spread in sss is also large along the coast and in the gulf of papua with additional variability introduced by river fluxes this indicates that if salinity data were to be assimilated in these areas it would have relatively large impact on the system 2 3 observations super observations are used for assimilation a super observation for a specific variable is made by combining all observations regardless of instrument or platform within a model grid cell weighted by inverse error variance to the average location and time within the cell and observation window assimilated observations include altimetric sla remotely sensed sst and in situ t and s from argo profiles sla is taken from the radar altimeter database system rads schrama et al 2000 using ocean tide and mean dynamic topography corrections the dynamic atmospheric correction that combines a high frequency wind and pressure correction with an inverse barometer correction is used the wind and pressure corrections however are relatively small in the region most of the time being generally 6 of the measurement the model contains sub daily high frequency pressure and wind forcing that is mainly filtered from the observations so we make the analysis backgrounds daily time averaged fields for each of the 3 days within the cycle to improve consistency sea surface temperature sst retrievals from multiple platforms including group for high resolution sea surface temperature ghrsst navoceano may et al 1998 windsat gaiser et al 2004 pathfinder amsr e amsr2 are used when available sst observations are limited to night time only in the region to minimise diurnal warming biases the navoceano advanced very high resolution radiometer avhrr per pixel bias correction is applied in situ temperature and salinity from argo roemmich et al 2009 is used however these observations are sparse and limited to the deep ocean part of the system domain observation error estimates of r for sla and sst are provided by the data product vendors and used in the assimilation except for amsr e where in the absence of vendor supplied error we estimate a constant error of 0 5 k observations errors are assumed uncorrelated so all off diagonal terms in r are zero errors estimates for in situ t and s were fixed at 0 5 k and 0 1 psu respectively fig 4 illustrates observation spatial coverage over a one month period for january 2008 the super observations shown here are time averages over the 30 day window at model grid resolution this demonstrates typical coverage over 10 cycles the maximum sla coverage is illustrated for visual comparison of oceanographic features in the reanalysis we also use two integrated marine observing system imos remote sensing products these are imos australian bureau of meteorology abom ghrsst avhrr l3s night time skin analysis and the imos satellite remote sensing srs ocean colour analysis from the moderate imaging spectrometer modis aqua satellite where these comparisons are made it is ensured that forecast fields from the system are used so that all differences can be seen as errors of a forecast with respect to unassimilated observations rather than analysis errors that include assimilated observations 2 4 rivers attaining a realistic ocean response to river discharge is complex especially when the model does not explicitly resolve rivers or estuaries and the streamflow observations are long distances from the coast herzfeld 2015 direct insertion of freshwater into model coastal cells can develop spurious cyclonic vorticity surface divergence and potential erroneously large upstream deflection of buoyant water yankovsky 2000 herzfeld 2015 introduced a method to parameterise the salinity of estuarine discharge leading to improvements in the modelled response to river forcing we use an alternative and straightforward to implement approach described in further detail in colberg et al 2019 this involves creating channels on the model grid where channel length represents distance of stream gauge from the coast and channel depth is set to represent river volume whilst this method is merely a simple approximation it nonetheless improves the representation of the salinity of the river discharge at the coast and the timing of the discharge compared to direct insertion river discharge data for 25 rivers shown in fig 1 was taken from the bureau of meteorology catchment nowcasting and forecasting system the system generates accurate and reliable predictions of water quantity and quality it was used to provide the reanalysis with river discharge data at gauge locations at sub daily time scale the system is based on the swift short term water information forecasting tools for hourly rainfall runoff modelling and hydrologic routing that includes the effects of storages on river discharge whilst biogeochemistry has not been considered in this reanalysis the catchment model also considers the pathways that exist for constituents solutes and particulates in the streamflow to be transported from the soil in the catchment to the stream the system has the capability to predict seven constituents total suspended solids nitrogen and phosphorous in organic inorganic and particulate forms at thirteen sampling locations in eleven catchments covering about 329 000 km 2 3 verification 3 1 forecast innovation errors fig 5 shows time series of all forecast innovation errors for assimilated variables and the number of observations used in each assimilation cycle it can be seen that there is no systematic trend in bias or mean absolute deviation over the 10 year period for any of the observed variables there are spikes in mean absolute deviation that are highlighted by forecast root mean squared deviation these spikes correspond to either extreme events such as tropical cyclones not captured in either the model or atmospheric forcing or other errors such as misplacement and or timing of synoptic weather patterns and errors associated with the model and or observations this was confirmed in particular for sst by running the system with era interim forcing and also with the bureau of meteorology access r australian community climate and earth system simulator regional numerical weather prediction system nwp over various overlapping periods where we observed a similar proportion of spikes at different times the two prominent spikes in sla were caused by a biased altimeter track these tracks were not discarded from assimilation rather the associated innovation was adaptively moderated by the k factor method described in section 2 2 spikes in in situ forecast errors can be related to model errors in the depth of mixed layers the depth of the thermocline or positional error of oceanic fronts mean and absolute forecast innovation errors for subsurface temperature and salinity as a function of depth are shown in fig 6 the reanalysis has a temperature cool bias positive mean error up to 0 5 k between 10 m to 350 m depth for salinity the bias is slightly salty in the upper 100 m and fresh between 100 m and 350 m some of this bias is likely due to a combination of imperfect parameterisations of surface momentum heat and salt fluxes and vertical mixing the reanalysis is in reasonably good agreement with observations below 1000 m due to lower natural variablility at these depths in the ocean the depth region of largest error 200 700 m corresponds to the permanent thermocline where the reanalysis is biased warm and salty this region has large vertical temperature gradients where any rapid change in water properties exists such as thermoclines or in frontal regions the model only needs to be slightly misplaced for errors to be relatively large nonetheless with limited subsurface observations to constrain the model the error signal at these depths is also influenced by errors in the specification of water properties in the open boundary conditions table 1 summarises the results shown in fig 5 also shown in table 1 are errors for the free running hindcast here we can see that the forecast bias and mean absolute deviation of the reanalysis is significantly lower in all variables compared to the hindcast indicating the data assimilation system is effectively constraining the oceanographic circulation to produce more accurate forecasts 3 2 comparison with satellite imagery assuming insignificant errors in the observations the statistics in fig 5 indicate dis agreement with observations for the salient oceanographic features from day to day in this section we present comparisons of forecast fields with observations for particular days of interest based on satellite sst and modis ocean colour imagery on selected days under clear skies fig 7 shows the oceanography on the 21st may 2009 in terms of sst sla and surface currents as depicted by the reanalysis and hindcast systems panels 6c and d along with an imos abom ghrsst avhrr l3s daily night time analysis and an imos srs ocean colour daily analysis from modis panels 6a and b reanalysis sla and surface current vectors are shown over the satellite derived analyses in this example a cold core eddy exists at about 25 s 156 e with an sst front and elevated chlorophyll on the northern edge the reanalysis and satellite derived analyses are in very good qualitative agreement with this feature that is not present in the hindcast this is similar for the capricorn eddy 24 s 154 e and the north queensland current papua gyre 10 s 147 e note the imos sst l3s is a skin sst that should be approximately 0 17 k cooler than sub skin sst that is closer to model sst the l3s sst product also has errors up to 0 5 k in certain areas that are not shown the errors of the reanalysis and hindcast with respect to sst and sla super observations are annotated in the respective panels indicating the reanalysis has error of 0 23 k with respect to the 16 351 super observations whereas the hindcast has significantly larger sst error 0 48 k sla in the reanalysis is more accurate than the hindcast however there is only 322 sla super observations available this day it may be assumed that for a relatively small region such as this skill in transport of incoming water masses that also involves specification of sla will be inherited from the reanalysis bran open boundary conditions fig 7 illustrates that this is not always a good assumption particularly for chaotic regimes such as where the eac is represented in the domain in some cases such as the southern boundary in this system the distance to the open boundary is not as important as whether the mean flow is into or out from the domain fig 8 presents a qualitative comparison of satellite data and the reanalysis on the 3rd of june 2006 for the southern region of the gbr here we can see cooler surface temperatures in the inner shelf and coastal areas that is typical for this time of year there is interesting agreement between panels 8a b and c for a number of features these include aspects of the southward flowing shelf break current and two cold core eddies one centred on approximately 155 e 24 5 s and one at approximately 156 e 27 s there is a warm core eddy in between these the arrangement of mesoscale features explains the eastward departure of the shelf break current at approximately 23 s the westward return at about 25 s and the relatively wide eac at around 154 e between 26 28 s the corresponding sst and chlorophyll concentration patterns in the satellite derived analyses can be largely explained by the mesoscale eddy field interestingly there are two instrusions of warm water onto the shelf around 154e and between 26 27 s that can be seen in panels 8a b and c that appear to be related to a dynamical baroclinic instability generated along the front between relatively cool shelf waters and warmer oceanward waters fig 9 repeats the analysis for 4th april 2009 this time for the northern area there are a number of interesting features in qualitative agreement such as cooler surface temperatures in the shelf break upper continental slope nqc that appear to be related to tidal upwelling occurring at the shelf break evident in the sstaars climatology wijffels et al 2018 the nqc and circulation of the pg are seen to be relatively coherent and vigorous on this day due to the cyclonic eddy centred around 146 5 e 11 5 s zonally oriented elevated sst and chlorophyll at 12 s between approximately 146 150e appears to be related to the pg nvj and southernward currents emanating from papua new guinea fig 10 shows reanalysis and satellite derived sst for the 17th january 2011 note the change to an expanded range of the colorbar compared to figs 8 and 9 illustrated here is a time when the eac is observed to be a narrow southward jet along the outer shelf break at 154 e between 24 28 s the presence of this jet and the associated sst front is clearly influenced by the large anticyclonic eddy centred around 156 e 27 s whilst this eddy would be referred to as a warm core eddy usually with elevated sst it appears relatively cooler than elsewhere in this image because the image contrasts warmer tropical surface waters with cooler sub tropical waters also notable in fig 10 is a difference between sst in the model and observations in torres strait here model sst is smoother than observations presumably due to unresolved topography and proximity to the open boundary in which strong tidal forcing coupled with temperature information from the global model has a significant impact in the strait the reanalysis sst is shown with super observations in fig 9a where it can be clearly seen that the filament is not exactly in the observed position as has been forecast especially around 154 e 24 5 s it is also worth noting that the filament appears stable in the reanalysis and is not showing the baroclinic instabilities in the observed potentially due to insufficient model resolution or the use of a third rather than fourth order advection scheme there is also low correspondence at the southern end of the eastern boundary where outflow of the model domain is occurring suggesting deficiencies at this time in the open boundary conditions 4 downscaled reanalysis climatology 4 1 mesoscale mean transport in the western coral sea relatively little is understood about the origins of waters passing through the region rousselet et al 2016 that are of great importance for the gbr and eac the analysed 10 year mean depth averaged currents were shown in fig 1 these are in qualitative agreement with those reported in ganachaud et al 2007 kessler and cravatte 2013b a and schiller et al 2015 and references therein the net westward flow in torres strait through the model open boundary that is governed by the mean south east trade winds is in qualitative agreement with the findings of wolanski et al 2013 however the reanalysis has about 8 higher transport due to unresolved topographic features that would otherwise induce greater frictional dissipation climatological monthly mean volume transport from the reanalysis is shown in fig 11 to provide a perspective of changes in variability of the mean mesoscale flow in the western coral sea ridgway et al 2018 emphasise the complex and poorly understood bifurcating transports of the jets of the south equatorial current as it transits the western coral sea the main bifurcation of the nvj and ncj on the continental slope plays an important role in reef flushing lambrechts et al 2008 estimates of the mean position of the main bifurcation vary from around 15 s to 16 s webb 2000 gasparin et al 2014 maes et al 2007 wijeratne et al 2018 fig 1 showed a smoothed representation of this with mean position around 15 5 s and spread between approximately 14 17 s seasonal variation in the main bifurcation has recently been observed by ridgway et al 2018 the reanalysis monthly mean transports shown in fig 11 estimate the position of the main bifurcation to vary between 14 s in december to 17 s in june in the summer months it appears related to a stronger nvj and weaker ncj in winter months the ncj appears to have more coherent flow connecting directly into the nqc and pg one can also see a stronger weaker eac on the shelf break of the outer gbr in summer winter and a stronger weaker nqc and pg in winter summer as observed by ridgway et al 2018 furthermore fig 11 illustrates the complex network of transport pathways guided by topography and provides evidence of differences in amplitude of flow along these pathways at different times of year 4 2 climatological atlas fig 12 shows monthly mean sea surface temperature from the 10 year reanalysis sst is the most reliably observed and accurately predicted variable with an average 10 year mean absolute deviation of 0 346 k and bias of 0 055 k based on a total of 33 302 676 super observations the results in fig 12 can be regarded as the most accurate dynamically consistent relatively high resolution description of sst available for the region with this we calculate monthly climatological mean sst anomalies as shown in fig 13 this highlights seasonal and interannual variability over the period of particular note is the late 2010 early 2011 la nina that produced widespread elevated temperatures associated with this event was increased rainfall and freshwater input from the rivers in the region the large freshwater discharges associated with the la nina event are captured in fig 14 that shows monthly mean surface salinity anomalies these appear to emanate from coast and shelf during the la nina event and persist as fresh anomalies in coastal areas throughout 2011 the years 2013 2015 were an el nino period that is associated with elevated salinity anomalies in the region owing to domination of evaporation over precipitation scanning through the sst monthly anomalies reveals periods when the region is affected by atmospheric forcing and lateral transports from ocean currents in different ways sst is mainly sensitive to atmospheric forcing domain scale anomalies are related to atmospheric climate anomalies there are also many small anomalous mesoscale features in the deep ocean reflecting changes in circulation an example of a climatic shift in the sec can be seen in the anomalous transport of heat through the north eastern open boundary between august and december 2011 the warm anomaly starts as a small jet that intensifies gradually introducing warmer than average ssts to the northern half of the domain february and march 2013 show cooler than average sst across the region however the warm anomaly around 17 s 150 e in february becomes organised into the anomalously warm downstream shelf break current in march 2013 gbr bottom temperatures are not well observed yet can be fundamental to marine ecosystems and determine coral bleaching events to estimate and understand how and where sst relates to bottom temperatures we calculate correlations between monthly mean sst and bottom temperatures fig 15 bottom temperatures are most correlated with sst in winter months that is typical of nearly all australian shelf regions due to relatively stronger atmospheric induced mixing and cooling at any time however the relationship between sst and bottom temperature is also a function of depth typically the shallower the location is the higher the correlation low correlations in summer can be related to intrusive upwelling along the gbr that can be connected to dynamic uplift due to changes in windstress affecting the eac benthuysen et al 2016 the upwelled cold water separates the upper and bottom layers correlation alone does not necessarily indicate how sst can be used as a proxy for bottom temperatures fig 16 shows areas in the monthly mean climatology where correlation between mean sea surface and bottom temperatures are greater than 0 9 and the differences are less than 0 3 k the approximate forecast error for sst in the system this shows the areas where the model indicates that sst will be reliable as a proxy outside these areas the ocean model will provide useful guidance on the types of processes and the likely presence of stratified conditions however absolute bottom temperature will not be reliable given the limited available observations to constrain and verify the model 5 conclusions a 10 year ocean reanalysis of the western coral sea and great barrier reef from 2006 2015 was carried out the system assimilated all satellite and in situ observations typically available for ocean and climate forecasting realistic cfsr atmospheric forcing and river discharges were used to force a 4 km horizontal resolution roms model the system was demonstrated to effectively constrain the mesoscale circulation in the western coral sea that forms the boundary currents of the gbr the accuracy and overall performance of the system was quantified with analysis and forecast innovation errors the reanalysis was shown to be in good agreement with salient synoptic oceanographic features seen on particular days in satellite derived ocean colour and sst a climatological atlas representing 10 years of model data fusion was presented climatological variability of the complex bifurcating transports of the south equatorial current were presented to contribute knowledge to the origins of source waters for the gbr and eac climatological monthly anomalies highlight spatially detailed changes in seasonal to interannual variability over the reanalysis period such as anomalously warm sst and fresh water emanating from coastal discharge during late 2010 2011 la nina and the domination of evaporation over precipitation in the 2012 2013 el nino period the reliability of bottom temperature estimates in the atlas was investigated by calculating climatological correlations between sst and bottom temperatures and where the differences were below the mean sst forecast error this provided an objective assessment of areas where sea bottom temperatures correspond well to satellite sst observations outside these areas suggest where measurement of bottom temperature is likely to be important for monitoring and prediction of thermal stress on coral we have shown that the reanalysis is a viable approach to developing downscaled climatology based on model data synthesis the reanalysis and atlas have potential to be advanced with improvements to the model data assimilation and observing system and through extension to longer periods of time nonetheless the reanalysis provides a realistic physical and dynamical description of the ocean at approximately 4 km model resolution which may be useful for a variety of studies code availability the ocean model is available from https www myroms org the data assimilation code can be found at https github com sakov enkf c these codes are documented within declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was carried out as part of ereefs https ereefs org au ereefs with financial support from the australian bureau of meteorology and the commonwealth scientific and industrial research organisation high performance computing was undertaken at the australian national computational infrastructure nci facility 
24005,this article describes a 10 year regional ocean reanalysis of the western coral sea and great barrier reef gbr from 2006 2015 here we use the regional ocean modelling system roms at 4 km resolution and enoi ensemble optimal interpolation data assimilation we also account for river freshwater discharge at the coast using hydrological stream gauge observations the system appears to constrain features of the deep ocean circulation that are important for cross shelf exchanges such as the spatio temporal locations of mesoscale eddies and boundary currents accuracy is evaluated with forecast innovation errors respecting available observations a four dimensional climatological atlas of water mass properties and currents representing 10 years of synthesis between model and data is then presented this illustrates seasonal and climatic processes driving changes in the region such as the el nino southern oscillation enso and its influence on sea temperature and freshwater flux to the shelf from rivers on the shelf where dense observation coverage is limited to satellite sea surface temperature sst we find where sst forecast errors are low and correlations between sst and bottom temperatures are significant and take this as a reliable predictor of bottom temperatures differences and correlations outside these parameters suggest areas where measurement of bottom temperature is likely to be important for a long term and comprehensive monitoring and prediction system the reanalysis provides a realistic physical and dynamic picture of the ocean at its given resolution that may be amenable to a variety of marine and environmental studies keywords assimilation forecasting reefs currents environment marine data availability the reanalysis data is accessible via the following url http dap nci org au thredds remotecatalogservice catalog http dapds00 nci org au thredds catalog rr6 ereefs 4kmreanalyses catalog xml 1 introduction the great barrier reef marine park is an extensive world heritage listed area of shelf sea in the queensland region of australia comprising the world s largest tropical coral reef complex it is characterised by high biodiversity and influenced by meteorological and oceanographic phenomena across a wide range of spatiotemporal scales the boundary currents of the gbr such as the jets of the south equatorial current north queensland current nqc east australian current eac and gulf of papua current gpc play important roles in flushing reef lagoon waters schiller et al 2015 brinkman et al 2002 lambrechts et al 2008 the gbr has been and continues to be subjected to a range of local and global pressures that have deleterious effects these include the influence of land based nutrients and sediments on water quality via river runoff devlin et al 2013 wooldridge 2009 mcculloch et al 2003 coral bleaching eakin et al 2016 ocean warming and acidification due to climate change ainsworth et al 2016 redondo rodriguez et al 2012 hoegh guldberg et al 2007 hughes et al 2007 and damage from development tropical cyclones and fishing dea th et al 2012 done 1992 nutrients pollutants and contaminants introduced through urban industrial and agricultural runoff find their way to the reef via streams and estuaries and influence water quality and ecosystems robson and dourdet 2015 reef decline has been linked to anthropogenic influences on water quality and satellite imagery has shown that after river flooding events materials brought to the seawater from rivers can dramatically deteriorate water quality and reach outer reefs hughes et al 2011 crown of thorns starfish cots infestation is regarded as one of the major threats to the reef and elevated nutrients in the seawater are believed to enhance their proliferation dea th et al 2012 ocean currents are responsible for carrying material away from the rivers and estuaries to reef locations environmental prediction and monitoring of ocean currents and river discharge in this region has significant potential to provide information beneficial for managing and mitigating anthropogenic pressures on the gbr this article describes a reanalysis system aimed at resolving the likely pathways of water borne material and the flushing of the gbr via the boundary currents under a variety of weather and ocean conditions the system is based on a hydrodynamic model a data assimilation system historical ocean observations hydrological river gauge observations atmospheric reanalysis and tidal forcing products realistic analysis and forecasting of the ocean circulation of the gbr region is a complex multi scale challenge that presents numerous limitations these include the relatively sparse ocean observation network and the ability of numerical models to accurately parameterise the complex sub grid scale processes occurring on the reefs whilst the development of the system described here cannot accommodate all these issues it aims to be a step towards quantifying forecast error in terms of the available observations and to provide a reference for potential improvements for other forecasting efforts e g schiller et al 2015 baird et al 2016 oke et al 2015 and wolanski et al 2003 the combination of observations modelling and data assimilation provides a system that can deliver meaningful predictions of the boundary currents of the gbr that vary on time scales of days to years influencing the flushing of the gbr benthuysen et al 2016 schiller et al 2015 brinkman et al 2002 and the dynamics of the shelf and coastal regions that are mainly atmospheric forced and tidally driven at timescales of hours to days the system is used to deliver the first downscaled climatological oceanographic atlas for the gbr through the synthesis of model and observations section 2 describes the system section 3 is devoted to forecast verification with respect to observations and mesoscale features seen in satellite imagery section 4 presents a downscaled climatology of monthly mean mesoscale volume transports and the climatological atlas section 5 provides conclusions 2 system description 2 1 model the regional ocean modelling system roms shchepetkin and mcwilliams 2005 is configured on a curvilinear grid for the great barrier reef and coral sea region at approximately 4 km horizontal resolution with 30 vertical sigma levels vertical resolution increases towards the surface to better accommodate the mixed layer the resolution of the model is insufficient to resolve reef slopes and the reef matrix in general however it is expected to adequately resolving the mesoscale boundary currents of the coral sea ocean currents on the shelf and the imprint of river freshwater input on the region the impact of not resolving the reef matrix is expected to lead to uncertainty in details of flow through the matrix and under estimation of the frictional dissipation and mixing this would show up as a systematic error or bias that the da system would be required to make repeated corrections for the study region and model domain are shown in fig 1 also shown are a 10 year depth averaged currents from the reanalysis that will be focussed on in section 4 2 10 year mean 10 m wind vectors from the ncep climate forecast system reanalysis cfsr saha et al 2010 c bureau of meteorology hydrological river gauge locations and d a schematic of boundary currents adapted from schiller et al 2015 the model bathymetry uses a blend of gbr100m beaman 2010 geoscience australia ga 9 arc second and the ga northward extension daniell 2008 the grid nodes use a mercator projection to unify cell aspect ratio initial conditions for the 1st of january 2006 and open boundary conditions from this date to 31st december 2015 are constructed using bluelink reanalysis bran datasets oke et al 2013 the model is forced with 1 hourly cfsr atmospheric fluxes using standard roms bulk formulae the model uses a combined nudging radation open boundary condition for temperature salinity and the components of the velocity field hereafter denoted as t s u v the chapman condition chapman 1985 is used for the free surface η and the flather condition for 2d momentum flather 1976 horizontal viscosity is increased in a sponge layer in the vicinity of the open boundaries for t s u v horizontal advection of momentum and tracer uses a 3rd order upwind scheme and vertical advection of tracer uses a 4th order centred scheme with an upwind limiter naughten et al 2017 the smagorinsky scheme smagorinsky 1963 is used for spatially dependent horizontal mixing of momentum we use the k profile parameterisation large et al 1994 for vertical mixing mainly for stability and computational efficiency noting that reanalysis experiments using the mellor and yamada 1982 and k epsilon schemes burchard et al 1998 were also carried out without significant changes to performance horizontal tracer diffusion is set to zero bottom drag is parameterised using the quadratic law atmospheric pressure forcing from cfsr is included in the simulations the minimum depth is set to 5 m and the wet dry algorithm enabled tidal forcing for sea surface height and barotropic velocities are derived from the topex poseidon global tidal model tpxo version 7 2 egbert et al 1994 2 2 data assimilation the state vector is taken to be x x η t s u v u v where u v are the components of 2d depth averaged velocity a 10 year hindcast control run is carried out to provide the first estimate of oceanographic conditions and to calculate background error covariances for the da the hindcast is similar to the roms system that wijeratne et al 2018 used to study oceanic variability in the australian region albeit with different size domain atmospheric forcing and open boundary conditions the hindcast inherits potential skill from the reanalysis open boundary conditions and forcing the errors of the hindcast are quantified with respect to the same observations that are used to estimate forecast error from the reanalysis which is a sequence of short forecasts aimed at achieving a dynamical balance between model and observations through frequent assimilation and initialisation steps the data assimilation software enkf c sakov 2018 with ensemble optimal interpolation enoi evensen 2003 oke et al 2005 is used enkf c has been used in a number of realistic ocean reanalyses o kane et al 2019 sandery 2018 sakov and sandery 2015 sandery et al 2014 the analysis equation and enoi background covariances can be written as 1 x a x f b h t h b h t r 1 y h x f 2 b a a t m 1 1 where x a and x f are analysis and forecast state vectors respectively y is an observation vector h is a linear observation operator i e h h x where h is a linear affine observation operator b is background error covariance r is observation error covariance a represents ensemble anomalies m is ensemble size and t denotes matrix transposition x f is taken to be an instantaneous model state whereas x f is a daily mean forecast the assimilation of altimetric sea level anomaly requires the detided background state x d in order to match non tidal altimetric observations with the model a is calculated for 255 ensemble members for x d 7 days apart from the first 6 years of the hindcast using 3 day minus 30 day running means these anomalies effectively filter out both multi week to climatological and sub daily dependencies to represent background error covariances at appropriate spatio temporal scales for the assimilated observations and for the 3 day analysis forecast cycle a graphical depiction of the cycle is shown in fig 2 the innovations are calculated using daily forecast fields at observation time this is known as the first guess at appropriate time fgat approach lee 2005 cummings 2005 the following features of enkf c are used multi grid capability for geo location of state variables to the model arakawa c grid variable dependent localisation radii and r factors and k factor for adaptively limiting the increment to k proportional to ensemble spread r factor defines a multiple of observation error variance and can be used to tune the kalman gain in order to achieve a more balanced observation error ensemble spread relationship k factor is used to avoid large increments in the analysis and improve balance without discarding associated observations that can provide important information to the system sakov and sandery 2017 the system uses no nudging or incremental updating rather the model is directly initialised to the analysis this approach allows the model to run the complete length of each cycle as a dynamical forecast the increment is relatively spatially smooth as b is smooth the use of x f in the innovation vector and x f in the analysis equation allows the increment to be added to the dynamically balanced state the use of x d for η creates an increment based only on mesoscale anomalies this is added to x f that retains the tide in the analysis and initial conditions in order to ensure all calculated errors and increments are based on forecasts of the model and the centred observation window is compared directly with the right observations each forecast is run for an additional 1 5 days past the base date of the next analysis fields are saved as 12 hourly means and the last 6 are averaged into daily means for each background data assimilation tuning experiments showed that the localisation radii and r factors that provided best system performance were 4 and 1 for sea level anomaly sla 1 and 2 for sea surface temperature sst and 4 and 1 for in situ profiles an illustration of low pass filtered variability in the hindcast is shown in fig 3 that presents spread temporal standard deviation for sea surface height ssh sst and sea surface salinity sss derived from the background ensemble ensemble spread is an estimate of model uncertainty the larger the spread the greater the relative impact of the observations with relatively low error on the analysis it can be seen that non tidal ssh uncertainty is large in several areas yet is dominated by the region of mesoscale eddy variability centred on 156 e 26 s where the east australian current is most energetic and chaotic in the domain there is also corresponding sst uncertainty in the eddy field however large spread also manifests along the entire coast due to variability induced by atmospheric forcing spread in sss is also large along the coast and in the gulf of papua with additional variability introduced by river fluxes this indicates that if salinity data were to be assimilated in these areas it would have relatively large impact on the system 2 3 observations super observations are used for assimilation a super observation for a specific variable is made by combining all observations regardless of instrument or platform within a model grid cell weighted by inverse error variance to the average location and time within the cell and observation window assimilated observations include altimetric sla remotely sensed sst and in situ t and s from argo profiles sla is taken from the radar altimeter database system rads schrama et al 2000 using ocean tide and mean dynamic topography corrections the dynamic atmospheric correction that combines a high frequency wind and pressure correction with an inverse barometer correction is used the wind and pressure corrections however are relatively small in the region most of the time being generally 6 of the measurement the model contains sub daily high frequency pressure and wind forcing that is mainly filtered from the observations so we make the analysis backgrounds daily time averaged fields for each of the 3 days within the cycle to improve consistency sea surface temperature sst retrievals from multiple platforms including group for high resolution sea surface temperature ghrsst navoceano may et al 1998 windsat gaiser et al 2004 pathfinder amsr e amsr2 are used when available sst observations are limited to night time only in the region to minimise diurnal warming biases the navoceano advanced very high resolution radiometer avhrr per pixel bias correction is applied in situ temperature and salinity from argo roemmich et al 2009 is used however these observations are sparse and limited to the deep ocean part of the system domain observation error estimates of r for sla and sst are provided by the data product vendors and used in the assimilation except for amsr e where in the absence of vendor supplied error we estimate a constant error of 0 5 k observations errors are assumed uncorrelated so all off diagonal terms in r are zero errors estimates for in situ t and s were fixed at 0 5 k and 0 1 psu respectively fig 4 illustrates observation spatial coverage over a one month period for january 2008 the super observations shown here are time averages over the 30 day window at model grid resolution this demonstrates typical coverage over 10 cycles the maximum sla coverage is illustrated for visual comparison of oceanographic features in the reanalysis we also use two integrated marine observing system imos remote sensing products these are imos australian bureau of meteorology abom ghrsst avhrr l3s night time skin analysis and the imos satellite remote sensing srs ocean colour analysis from the moderate imaging spectrometer modis aqua satellite where these comparisons are made it is ensured that forecast fields from the system are used so that all differences can be seen as errors of a forecast with respect to unassimilated observations rather than analysis errors that include assimilated observations 2 4 rivers attaining a realistic ocean response to river discharge is complex especially when the model does not explicitly resolve rivers or estuaries and the streamflow observations are long distances from the coast herzfeld 2015 direct insertion of freshwater into model coastal cells can develop spurious cyclonic vorticity surface divergence and potential erroneously large upstream deflection of buoyant water yankovsky 2000 herzfeld 2015 introduced a method to parameterise the salinity of estuarine discharge leading to improvements in the modelled response to river forcing we use an alternative and straightforward to implement approach described in further detail in colberg et al 2019 this involves creating channels on the model grid where channel length represents distance of stream gauge from the coast and channel depth is set to represent river volume whilst this method is merely a simple approximation it nonetheless improves the representation of the salinity of the river discharge at the coast and the timing of the discharge compared to direct insertion river discharge data for 25 rivers shown in fig 1 was taken from the bureau of meteorology catchment nowcasting and forecasting system the system generates accurate and reliable predictions of water quantity and quality it was used to provide the reanalysis with river discharge data at gauge locations at sub daily time scale the system is based on the swift short term water information forecasting tools for hourly rainfall runoff modelling and hydrologic routing that includes the effects of storages on river discharge whilst biogeochemistry has not been considered in this reanalysis the catchment model also considers the pathways that exist for constituents solutes and particulates in the streamflow to be transported from the soil in the catchment to the stream the system has the capability to predict seven constituents total suspended solids nitrogen and phosphorous in organic inorganic and particulate forms at thirteen sampling locations in eleven catchments covering about 329 000 km 2 3 verification 3 1 forecast innovation errors fig 5 shows time series of all forecast innovation errors for assimilated variables and the number of observations used in each assimilation cycle it can be seen that there is no systematic trend in bias or mean absolute deviation over the 10 year period for any of the observed variables there are spikes in mean absolute deviation that are highlighted by forecast root mean squared deviation these spikes correspond to either extreme events such as tropical cyclones not captured in either the model or atmospheric forcing or other errors such as misplacement and or timing of synoptic weather patterns and errors associated with the model and or observations this was confirmed in particular for sst by running the system with era interim forcing and also with the bureau of meteorology access r australian community climate and earth system simulator regional numerical weather prediction system nwp over various overlapping periods where we observed a similar proportion of spikes at different times the two prominent spikes in sla were caused by a biased altimeter track these tracks were not discarded from assimilation rather the associated innovation was adaptively moderated by the k factor method described in section 2 2 spikes in in situ forecast errors can be related to model errors in the depth of mixed layers the depth of the thermocline or positional error of oceanic fronts mean and absolute forecast innovation errors for subsurface temperature and salinity as a function of depth are shown in fig 6 the reanalysis has a temperature cool bias positive mean error up to 0 5 k between 10 m to 350 m depth for salinity the bias is slightly salty in the upper 100 m and fresh between 100 m and 350 m some of this bias is likely due to a combination of imperfect parameterisations of surface momentum heat and salt fluxes and vertical mixing the reanalysis is in reasonably good agreement with observations below 1000 m due to lower natural variablility at these depths in the ocean the depth region of largest error 200 700 m corresponds to the permanent thermocline where the reanalysis is biased warm and salty this region has large vertical temperature gradients where any rapid change in water properties exists such as thermoclines or in frontal regions the model only needs to be slightly misplaced for errors to be relatively large nonetheless with limited subsurface observations to constrain the model the error signal at these depths is also influenced by errors in the specification of water properties in the open boundary conditions table 1 summarises the results shown in fig 5 also shown in table 1 are errors for the free running hindcast here we can see that the forecast bias and mean absolute deviation of the reanalysis is significantly lower in all variables compared to the hindcast indicating the data assimilation system is effectively constraining the oceanographic circulation to produce more accurate forecasts 3 2 comparison with satellite imagery assuming insignificant errors in the observations the statistics in fig 5 indicate dis agreement with observations for the salient oceanographic features from day to day in this section we present comparisons of forecast fields with observations for particular days of interest based on satellite sst and modis ocean colour imagery on selected days under clear skies fig 7 shows the oceanography on the 21st may 2009 in terms of sst sla and surface currents as depicted by the reanalysis and hindcast systems panels 6c and d along with an imos abom ghrsst avhrr l3s daily night time analysis and an imos srs ocean colour daily analysis from modis panels 6a and b reanalysis sla and surface current vectors are shown over the satellite derived analyses in this example a cold core eddy exists at about 25 s 156 e with an sst front and elevated chlorophyll on the northern edge the reanalysis and satellite derived analyses are in very good qualitative agreement with this feature that is not present in the hindcast this is similar for the capricorn eddy 24 s 154 e and the north queensland current papua gyre 10 s 147 e note the imos sst l3s is a skin sst that should be approximately 0 17 k cooler than sub skin sst that is closer to model sst the l3s sst product also has errors up to 0 5 k in certain areas that are not shown the errors of the reanalysis and hindcast with respect to sst and sla super observations are annotated in the respective panels indicating the reanalysis has error of 0 23 k with respect to the 16 351 super observations whereas the hindcast has significantly larger sst error 0 48 k sla in the reanalysis is more accurate than the hindcast however there is only 322 sla super observations available this day it may be assumed that for a relatively small region such as this skill in transport of incoming water masses that also involves specification of sla will be inherited from the reanalysis bran open boundary conditions fig 7 illustrates that this is not always a good assumption particularly for chaotic regimes such as where the eac is represented in the domain in some cases such as the southern boundary in this system the distance to the open boundary is not as important as whether the mean flow is into or out from the domain fig 8 presents a qualitative comparison of satellite data and the reanalysis on the 3rd of june 2006 for the southern region of the gbr here we can see cooler surface temperatures in the inner shelf and coastal areas that is typical for this time of year there is interesting agreement between panels 8a b and c for a number of features these include aspects of the southward flowing shelf break current and two cold core eddies one centred on approximately 155 e 24 5 s and one at approximately 156 e 27 s there is a warm core eddy in between these the arrangement of mesoscale features explains the eastward departure of the shelf break current at approximately 23 s the westward return at about 25 s and the relatively wide eac at around 154 e between 26 28 s the corresponding sst and chlorophyll concentration patterns in the satellite derived analyses can be largely explained by the mesoscale eddy field interestingly there are two instrusions of warm water onto the shelf around 154e and between 26 27 s that can be seen in panels 8a b and c that appear to be related to a dynamical baroclinic instability generated along the front between relatively cool shelf waters and warmer oceanward waters fig 9 repeats the analysis for 4th april 2009 this time for the northern area there are a number of interesting features in qualitative agreement such as cooler surface temperatures in the shelf break upper continental slope nqc that appear to be related to tidal upwelling occurring at the shelf break evident in the sstaars climatology wijffels et al 2018 the nqc and circulation of the pg are seen to be relatively coherent and vigorous on this day due to the cyclonic eddy centred around 146 5 e 11 5 s zonally oriented elevated sst and chlorophyll at 12 s between approximately 146 150e appears to be related to the pg nvj and southernward currents emanating from papua new guinea fig 10 shows reanalysis and satellite derived sst for the 17th january 2011 note the change to an expanded range of the colorbar compared to figs 8 and 9 illustrated here is a time when the eac is observed to be a narrow southward jet along the outer shelf break at 154 e between 24 28 s the presence of this jet and the associated sst front is clearly influenced by the large anticyclonic eddy centred around 156 e 27 s whilst this eddy would be referred to as a warm core eddy usually with elevated sst it appears relatively cooler than elsewhere in this image because the image contrasts warmer tropical surface waters with cooler sub tropical waters also notable in fig 10 is a difference between sst in the model and observations in torres strait here model sst is smoother than observations presumably due to unresolved topography and proximity to the open boundary in which strong tidal forcing coupled with temperature information from the global model has a significant impact in the strait the reanalysis sst is shown with super observations in fig 9a where it can be clearly seen that the filament is not exactly in the observed position as has been forecast especially around 154 e 24 5 s it is also worth noting that the filament appears stable in the reanalysis and is not showing the baroclinic instabilities in the observed potentially due to insufficient model resolution or the use of a third rather than fourth order advection scheme there is also low correspondence at the southern end of the eastern boundary where outflow of the model domain is occurring suggesting deficiencies at this time in the open boundary conditions 4 downscaled reanalysis climatology 4 1 mesoscale mean transport in the western coral sea relatively little is understood about the origins of waters passing through the region rousselet et al 2016 that are of great importance for the gbr and eac the analysed 10 year mean depth averaged currents were shown in fig 1 these are in qualitative agreement with those reported in ganachaud et al 2007 kessler and cravatte 2013b a and schiller et al 2015 and references therein the net westward flow in torres strait through the model open boundary that is governed by the mean south east trade winds is in qualitative agreement with the findings of wolanski et al 2013 however the reanalysis has about 8 higher transport due to unresolved topographic features that would otherwise induce greater frictional dissipation climatological monthly mean volume transport from the reanalysis is shown in fig 11 to provide a perspective of changes in variability of the mean mesoscale flow in the western coral sea ridgway et al 2018 emphasise the complex and poorly understood bifurcating transports of the jets of the south equatorial current as it transits the western coral sea the main bifurcation of the nvj and ncj on the continental slope plays an important role in reef flushing lambrechts et al 2008 estimates of the mean position of the main bifurcation vary from around 15 s to 16 s webb 2000 gasparin et al 2014 maes et al 2007 wijeratne et al 2018 fig 1 showed a smoothed representation of this with mean position around 15 5 s and spread between approximately 14 17 s seasonal variation in the main bifurcation has recently been observed by ridgway et al 2018 the reanalysis monthly mean transports shown in fig 11 estimate the position of the main bifurcation to vary between 14 s in december to 17 s in june in the summer months it appears related to a stronger nvj and weaker ncj in winter months the ncj appears to have more coherent flow connecting directly into the nqc and pg one can also see a stronger weaker eac on the shelf break of the outer gbr in summer winter and a stronger weaker nqc and pg in winter summer as observed by ridgway et al 2018 furthermore fig 11 illustrates the complex network of transport pathways guided by topography and provides evidence of differences in amplitude of flow along these pathways at different times of year 4 2 climatological atlas fig 12 shows monthly mean sea surface temperature from the 10 year reanalysis sst is the most reliably observed and accurately predicted variable with an average 10 year mean absolute deviation of 0 346 k and bias of 0 055 k based on a total of 33 302 676 super observations the results in fig 12 can be regarded as the most accurate dynamically consistent relatively high resolution description of sst available for the region with this we calculate monthly climatological mean sst anomalies as shown in fig 13 this highlights seasonal and interannual variability over the period of particular note is the late 2010 early 2011 la nina that produced widespread elevated temperatures associated with this event was increased rainfall and freshwater input from the rivers in the region the large freshwater discharges associated with the la nina event are captured in fig 14 that shows monthly mean surface salinity anomalies these appear to emanate from coast and shelf during the la nina event and persist as fresh anomalies in coastal areas throughout 2011 the years 2013 2015 were an el nino period that is associated with elevated salinity anomalies in the region owing to domination of evaporation over precipitation scanning through the sst monthly anomalies reveals periods when the region is affected by atmospheric forcing and lateral transports from ocean currents in different ways sst is mainly sensitive to atmospheric forcing domain scale anomalies are related to atmospheric climate anomalies there are also many small anomalous mesoscale features in the deep ocean reflecting changes in circulation an example of a climatic shift in the sec can be seen in the anomalous transport of heat through the north eastern open boundary between august and december 2011 the warm anomaly starts as a small jet that intensifies gradually introducing warmer than average ssts to the northern half of the domain february and march 2013 show cooler than average sst across the region however the warm anomaly around 17 s 150 e in february becomes organised into the anomalously warm downstream shelf break current in march 2013 gbr bottom temperatures are not well observed yet can be fundamental to marine ecosystems and determine coral bleaching events to estimate and understand how and where sst relates to bottom temperatures we calculate correlations between monthly mean sst and bottom temperatures fig 15 bottom temperatures are most correlated with sst in winter months that is typical of nearly all australian shelf regions due to relatively stronger atmospheric induced mixing and cooling at any time however the relationship between sst and bottom temperature is also a function of depth typically the shallower the location is the higher the correlation low correlations in summer can be related to intrusive upwelling along the gbr that can be connected to dynamic uplift due to changes in windstress affecting the eac benthuysen et al 2016 the upwelled cold water separates the upper and bottom layers correlation alone does not necessarily indicate how sst can be used as a proxy for bottom temperatures fig 16 shows areas in the monthly mean climatology where correlation between mean sea surface and bottom temperatures are greater than 0 9 and the differences are less than 0 3 k the approximate forecast error for sst in the system this shows the areas where the model indicates that sst will be reliable as a proxy outside these areas the ocean model will provide useful guidance on the types of processes and the likely presence of stratified conditions however absolute bottom temperature will not be reliable given the limited available observations to constrain and verify the model 5 conclusions a 10 year ocean reanalysis of the western coral sea and great barrier reef from 2006 2015 was carried out the system assimilated all satellite and in situ observations typically available for ocean and climate forecasting realistic cfsr atmospheric forcing and river discharges were used to force a 4 km horizontal resolution roms model the system was demonstrated to effectively constrain the mesoscale circulation in the western coral sea that forms the boundary currents of the gbr the accuracy and overall performance of the system was quantified with analysis and forecast innovation errors the reanalysis was shown to be in good agreement with salient synoptic oceanographic features seen on particular days in satellite derived ocean colour and sst a climatological atlas representing 10 years of model data fusion was presented climatological variability of the complex bifurcating transports of the south equatorial current were presented to contribute knowledge to the origins of source waters for the gbr and eac climatological monthly anomalies highlight spatially detailed changes in seasonal to interannual variability over the reanalysis period such as anomalously warm sst and fresh water emanating from coastal discharge during late 2010 2011 la nina and the domination of evaporation over precipitation in the 2012 2013 el nino period the reliability of bottom temperature estimates in the atlas was investigated by calculating climatological correlations between sst and bottom temperatures and where the differences were below the mean sst forecast error this provided an objective assessment of areas where sea bottom temperatures correspond well to satellite sst observations outside these areas suggest where measurement of bottom temperature is likely to be important for monitoring and prediction of thermal stress on coral we have shown that the reanalysis is a viable approach to developing downscaled climatology based on model data synthesis the reanalysis and atlas have potential to be advanced with improvements to the model data assimilation and observing system and through extension to longer periods of time nonetheless the reanalysis provides a realistic physical and dynamical description of the ocean at approximately 4 km model resolution which may be useful for a variety of studies code availability the ocean model is available from https www myroms org the data assimilation code can be found at https github com sakov enkf c these codes are documented within declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was carried out as part of ereefs https ereefs org au ereefs with financial support from the australian bureau of meteorology and the commonwealth scientific and industrial research organisation high performance computing was undertaken at the australian national computational infrastructure nci facility 
24006,the ocean state off oregon washington u s west coast is highly variable in time under these conditions the assumption made in traditional 4 dimensional variational data assimilation 4dvar that the prior model background error covariance is the same in every data assimilation da window can be limiting a da system based on an ensemble of 4dvars en4dvar has been developed in which the background error covariance is estimated from an ensemble of model runs and is thus time varying this part describes details of the en4dvar method and ensemble statistics verification tests the control run and 39 ensemble members are forced by perturbed wind fields and corrected by da in a series of 3 day windows wind perturbations are represented as a linear combination of empirical orthogonal functions eofs for the larger scales and daubechies wavelets for the smaller scales the variance of the eof expansion coefficients is based on estimates of the wind field error statistics derived using scatterometer observations and a bayesian hierarchical model it is found that the variance of the wind errors relative to the natural wind variability increases as the horizontal spatial scales decrease da corrections to the control run and ensemble members are calculated in parallel by the newly developed cost effective cluster search minimization method for a realistic coastal ocean application this method can generate a 30 wall time reduction compared to the restricted b conjugate gradient rbcg method ensemble statistics are generally found to be consistent with background error statistics in particular ensemble spread is maintained without inflating however sea surface height background errors cannot be fully reproduced by the ensemble perturbations keywords 4dvar coastal ocean data assimilation ensemble numerical modelling usa oregon 1 introduction data assimilation da is a procedure e g used in meteorology and oceanography in which the output of a numerical model is combined with observations to find the most likely estimate for the true state of the system da algorithms require specification of the error statistics for the model and the observations these statistics are often assumed to follow a multidimensional normal distribution with zero mean and a covariance that is static in time i e the same from one assimilation cycle to the next an example of such a da system is the oregon state university coastal ocean forecast system in an area offshore oregon washington or wa at the u s west coast kurapov et al 2011 pasmans et al 2019a yu et al 2012 this system applies the 4dvar algorithm in a series of consecutive 3 day windows initial conditions at the beginning of each window are corrected to yield the nonlinear analysis that fits observations in this window the simulation is then continued for another three days to provide the forecast summer dynamics in this region are dominated by the wind forced upwelling and relaxation and the outflow of the columbia river hickey et al 2005 2010 huyer 1983 liu et al 2009 in such a dynamic environment it is unlikely that the stationarity assumption on the error statistics holds in particular the temperature salinity model error covariance will strongly depend on the presence of the river plume over the past three decades ensemble methods have been developed in meteorology to deal with non stationarity in the error statistics in these methods the forecast background error covariance is estimated from an ensemble of perturbed model runs one of the earliest and most popular examples of such a method is the ensemble kalman filter anderson 2001 bishop et al 2001 evensen 1994 lermusiaux and robinson 1999 more recently in meteorology these ensemble kalman filter systems have been combined with 4dvar systems in which the background error covariance used by the 4dvar system is estimated using the ensemble from the kalman filter system buehner et al 2009 clayton et al 2013 zhang and zhang 2012 in this manuscript we describe our approach to using an ensemble of 4dvars en4dvar to provide a state dependent background error covariance this methodology will be tested with the or wa 4dvar system generalization of the ensemble methodology to ensembles of 4dvars is nontrivial for three reasons first 4dvar is computationally intensive calculation of a da correction requires minimization of a cost function or equivalently solving a linear system with some symmetric and positive definite matrix a this matrix is large and generally not available in explicit form instead only the algorithm for the product of a and a vector is at hand an iterative method e g the restricted b conjugate gradient rbcg algorithm is used to find an approximate solution of this system each iteration requires propagation of the tangent linear tl model over the analysis period forward in time and its adjoint counterpart adj backward in time for practical systems the 4dvar cycle can take 10 100 times as much time as a single forward model run second en4dvar only compounds this problem as it requires running the computationally intensive 4dvar algorithm for each ensemble member third the ensemble has to be initialized and evolved in such a manner that its covariance is representative of the true background error covariance over the last decade much effort has been put into overcoming these challenges several solutions have been found instead of applying full 4dvar to each ensemble member it has become customary to calculate a low rank approximation to a using e g ritz pairs found by the lanczos algorithm trefethen and bau 1997 in the ensemble variational integrated localized data assimilation evil methodology auligné et al 2016 minimization of the cost function is only carried out for the control or deterministic model run from the ritz vectors obtained as a by product from this minimization a low rank approximation of a is constructed the inverse of this approximation is then used to solve the linear system for the ensemble members desroziers and berre 2012 and lorenc et al 2017 followed similar approaches but use the ritz pairs solely to construct a preconditioner advances have also been made to speed up the 4dvar minimization algorithm itself parallelization can be applied to the tl and adj models by assigning the calculations for different parts of the domain to different processor cores as well as to the minimization algorithm the former is currently standard practice while the latter is still an area of active research one popular approach is to use an ensemble of concurrently produced nonlinear model runs to generate approximations of the tl and adj model examples of this approach are 4denvar amezcua et al 2017 desroziers et al 2014 gustafsson and bojarova 2014 liu et al 2008 tian et al 2017 and the ensemble kalman smoother 4dvar eks 4dvar mandel et al 2016 4denvar and eks 4dvar can be used to minimize the same cost function but their implementation differs in two major ways first 4denvar uses all observations within a da window to correct the initial condition while eks 4dvar processes the observations in batches with each batch generating corrections to the model at and prior to the batch time second both in en4dvar and eks 4dvar the propagation of perturbations from the background state to the next time step and into the observation space is carried out by a finite difference scheme involving the nonlinear model and nonlinear sampling operators the finite difference scheme in eks 4dvar uses a smaller step size and thus better approximates the tangent linear model and linearized sampling operators used in classic 4dvar background error localization in these methods is non trivial in absence of a tl model to propagate the localized background error covariance forward in time localization is often assumed to be static in these methods for limited size ensembles with non dense observation networks this can lead to a decrease in forecast performance compared to variational methods that do use tl and adj models poterjoy and zhang 2015 poterjoy et al 2016 a similar problem is encountered when attempting to implement a hybrid background covariance a linear combination of an ensemble and climatological static covariance in these 4denvar systems the use of a hybrid background covariance was found to improve the accuracy of the forecasts produced by traditional 4dvar systems clayton et al 2013 kuhl et al 2013 more specifically it was found that the best fit to the assimilated observations is achieved when the climatological part makes up the major part of the background covariance clayton et al 2013 lorenc and jardak 2018 however without tl and adj models to propagate the covariance back and forth in time hybrid 4denvar failed to provide the same benefits lorenc et al 2015 one different approach to parallelization that does not suffer from these problems is taken by rao and sandu 2016 and fisher and gürol 2017 they make use of the tl and adj models and parallelize the 4dvar minimization algorithm in time this is done by dividing the analysis period into separate time intervals the da correction is found by minimizing a cost function that consists of the sum of the 4dvar cost functions for each interval plus an additional term representing the constraint that the correction should be continuous going from one interval to another another recent approach that circumvents the problems with localization and hybrid covariances encountered in en4dvar is the localized ensemble based tangent linear model letlm in which the matrix for the tangent linear model is not constructed using a linearized version of the extensive nonlinear model but retrieved from a simple regression against the ensemble members allen et al 2017 bishop et al 2017 frolov and bishop 2016 frolov et al 2018 yet another alternative approach explored in this paper is to try to accelerate the linear system solver by using several search directions in parallel the current or wa system uses the restricted b conjugate gradient method rbcg gürol et al 2014 in this method an approximation to the linear system solution is sought in a low dimensional krylov space and the search space dimension is equal to the number of iterations several generic iterative solvers have already been developed in which the search space dimension grows faster than that consequently less iterations are necessary to produce a good approximation to the solution among these are the enlarged krylov space method grigori et al 2016 in which the search space is expanded by multiple directions per iteration simultaneously or the augmented krylov space methods where extra search directions are added to the system coming from an earlier attempt to solve a similar system erhel and guyomarc h 2000 morgan 1995 from the eigenvectors of a preconditioner kharchenko and yeremin 1995 or from an attempt to solve the system with a different initial residual chapman and saad 1996 additional search directions can also lie outside the krylov subspace e g yaremchuk et al 2017 use model based empirical orthogonal functions eofs to create search directions once a general search space is defined the approximation can be defined as the vector in the search space that has the smallest distance to the exact solution in some appropriately chosen norm brezinski 1999 in the en4dvar system proposed in this paper the evil method auligné et al 2016 is parallelized using a new variation of the enlarged and augumented krylov space methods two principal and novel elements of the en4dvar will be described the first is the cluster search method used to enlarge the search space at each iteration at a price of running a relatively small number of tl adj applications in parallel the second is the use of a bayesian hierarchical model to estimate the magnitude of the wind forcing perturbations for the ensemble members part ii of this study pasmans et al submitted will include a a comparison of the ensemble background error covariance produced by the en4dvar system and the static background error covariance based on the balance operator and b comparative tests of en4dvar and traditional 4dvar implemented in the or wa coastal ocean forecast system this paper is organized as follows section 2 describes the experimental setup and the layout of the en4dvar system derivation of the cluster search method is presented in section 3 wind perturbations for the ensemble members are discussed in section 4 in section 5 we check if the en4dvar statistics are representative of the true background error statistics discussion and conclusions are presented in section 6 2 the en4dvar system pasmans et al 2019a describe the or wa coastal ocean forecast system in every detail implemented as standard 4dvar with a static background error covariance a short summary is only provided here the nonlinear model dynamics are described by the regional ocean modelling system roms www myroms org by integrating three dimensional fully nonlinear hydrostatic boussinesq equations featuring advanced numerics shchepetkin and mcwilliams 2003 2005 the model domain is shown in fig 1 the model resolution is approximately 2 km in the horizontal and 40 terrain following layers in the vertical direction the computational grid has 310 522 points non tidal boundary conditions are taken from the global 1 1 2 hycom ncoda analyses coaps 2015 tidal forcing is added along the open boundaries egbert and erofeeva 2002 2010 atmospheric surface forcing is calculated based on the bulk flux algorithm fairall et al 2003 using the 12 km resolution northern american mesoscale nam model analysis fields noaa 2011b the fresh water discharge from the columbia river fraser river and 15 small rivers in puget sound is also included each hour the three dimensional ocean state calculated by the model is saved to disc while standard roms includes tl and adj models these are tightly integrated into the code such that implementing the en4dvar directly into roms was too challenging for us as the users instead we utilize the stand alone tl and adj avrora codes developed in house kurapov et al 2009 2011 yu et al 2012 and integrate these with the nonlinear roms and other components of the en4dvar via linux shell scripts similarly to how it is done in the present or wa operational forecast system the tl and adj runs are performed on a coarser 4 km resolution model grid and their output is interpolated to and from the 2 km model grid all computations have been carried out on the comet cluster with computer allocations made available through the xsede framework towns et al 2014 both the nonlinear roms and tl adj avrora codes are run using message passing interface mpi parallelization the model grid is divided into horizontal tiles and computation in the interior of each tile is performed on a separate processor core owing to a relatively small grid size a small number of n c o r e s 6 tiles are used for each instance of the adj and tl models more nodes are available to us and later in this paper we discuss how these can be used to speed up the iterative minimization algorithm in this paper results from two experiments are compared ens and no da in experiment ens the en4dvar system is used to run m 40 instances of the model forward in time in the discussions below the run with index m 0 is referred to as the control run while instances m 1 2 m 1 are referred to as ensemble members since the dynamics in this region are dominated by the wind forcing we assume that the errors in the wind velocity are the dominant model error source to include this error into the error statistics the nonlinear forecasts for each ensemble member are run with perturbed wind velocities as detailed in section 4 it will be evaluated in section 5 whether the addition of these perturbations alleviates the need for the customary ensemble inflation anderson 2001 anderson and anderson 1999 hamill et al 2001 no wind perturbations are added to the control run in our system the analyses and forecasts from the unperturbed control run are considered to provide the best estimate of the ocean state unless explicitly stated otherwise the control da run is compared with the results from experiment no da in section 5 since no perturbations are added to the control run the probability distributions of the errors in the control run will deviate from that in the ensemble members therefore the control run is not utilized in the calculation of b the ensemble members are all initialized from the same no da model output on 10 march 2011 and propagated forward in time without da using the perturbed winds thus generating an ensemble of perturbed ocean states on 19 april 2011 both ens and no da cases are then run and compared over the period from 19 april 2011 to 1 october 2011 the set of observations for assimilation includes radial surface currents from high frequency radars hfr alongtrack altimetry and satellite sea surface temperature sst although the model includes tides mainly to include their effect on river and ocean water mixing our focus is on correcting subtidal variability surface tidal currents can be dominated by non stationary internal tides e g kurapov et al 2003 osborne et al 2011 that are poorly predictable and poorly constrained by the available data at the same time the daily averaged hfr velocity data present a useful constraint on the 3 day ocean forecasts yu et al 2012 following our practice in the or wa system we assimilate daily averaged hfr observations matching those to the daily averaged model outputs altimetry observations can suffer from large errors in the specification of the geoid to suppress these and the tidal errors in the da we assimilate differences from the mean along track ssh averaged over 24 h details of the procedure can be found in appendix a more details on the data and their associated observational error variances are described in pasmans et al 2019a the only difference here is that the level 2 goes 11 sst maturi et al 2008 is used instead of polar orbiting satellite products the observational error covariance matrix r is diagonal as shown schematically in fig 2 da proceeds in a series of 3 day windows at the beginning of each window the initial conditions for the control run and each ensemble member are corrected then every model starts from the corrected initial conditions and is run forward using the nonlinear roms for the length of the assimilation window 3 days to obtain the analyses and continues for another 3 days to obtain the forecasts the 3 day window length is long enough to let the non tidal dynamics evolve and provide dynamically based space and time interpolation of the data it is still short enough such that the correction to the initial conditions at the beginning of the da window impacts forecasts to explain the da method in more detail we combine the temperature salinity sea surface height and horizontal velocity fields at the beginning of the window and prior to da into a vector of real numbers of length n x b m r n m 0 m 1 the vector containing all observations within the window is denoted as y r d the innovation vector for each ensemble member is defined as d m y h m x b m ϵ m here m x b m is the nonlinear model trajectory started from the initial conditions x b m and h is the collection of data operators a perturbation ϵ m is added to the innovation vector for each ensemble member m 1 m 1 to account for the uncertainty in the analysis introduced by the presence of observational errors burgers et al 1998 houtekamer and mitchell 1998 it is drawn from a normal distribution with zero mean and covariance r an overview of the symbols used is included as appendix b the da correction to the background state x b m is denoted as x m r n it is found by minimizing the following cost function for each m courtier et al 1994 1 j x m 1 2 x m t b 1 x m 1 2 d m h m m x m t r 1 d m h m m x m here m m is the tl model linearized with respect to m x b m m m t is the adj model b is the background error covariance obtained as the sample covariance of the ensemble members with localization as described in pasmans and kurapov 2017 to ensure that b represents dynamics on relatively slow subtidal and subinertial temporal scales each ensemble member is time averaged over the 24 h time interval centred at the beginning of the da window using the last 12 h of the analysis and first 12 h of the forecast from the previous window before it is used in the calculation of b the minimizer of 1 is sought as the solution of a linear symmetric and positive definite system of equations that can take different forms e g depending on whether the solution is sought in a space of size n or d and on how the system is preconditioned rbcg proved to be an efficient solver in the data space of dimension d with good convergence gürol et al 2014 it finds approximations of x m that minimize the cost function in 1 by solving the system 2 i r 1 2 h m m b m m t h t r 1 2 x m d e f a m x m d m where x m b m m t r 1 2 x m and d m r 1 2 d m 3 cost function minimization in this section we discuss several approaches to finding an approximation to x m the solution of 2 and propose the new computationally efficient cluster search algorithm we recognize that some mathematical details can be overwhelming to an educated reader who only wants to grasp the idea for that reason we first provide a high level overview in the beginning of this session this is followed by more formal sections 3 1 3 3 where all the necessary theoretical and algorithmic details are documented in rbcg x i m the i th iteration approximation to x m is sought in the low dimensional krylov subspace k i d m a m where k i z a span z a z a 2 z a i 1 z this search space grows by one dimension per iteration let i be the number of iterations necessary to bring x i m within a certain prescribed error margin of x m then obtaining x i m for each m can require a considerable amount of wall time as well as computational resources indeed every iteration requires the multiplication of a m with a vector this demands that for each m a single implementation of the adj model over the analysis window is run followed by application of b and the tl model to carry this out a total of n c o r e s m processor cores need to be available in parallel as described in more detail in section 3 1 faster convergence to the exact solution x m for each m could be achieved by expanding the space in which x i m is sought with vectors that lie outside k i d m a m such vectors can be generated at no extra computational cost if we similarly to auligné et al 2016 make the assumption that 3 m m m 0 d e f m and consequently a m a 0 d e f a in that case the solution of 2 for different m can be combined into one system of equations for each m the search space will grow by m dimensions per iteration this will allow to approximate x m with the same target accuracy in i i iterations using the block diagonal cg method see section 3 2 this approach will potentially exhibit faster convergence but would still require the same n c o r e s m cores per iteration as an ensemble of regular rbcgs given presently available resources this method would be feasible for our relatively small or wa forecast system but it can become prohibitively expensive for larger forecast systems requiring n c o r e s o 1 0 3 e g kurapov et al 2017 for these systems the new cluster search method is introduced see section 3 3 it also depends on the assumption 3 and involves n s new direction searches at every iteration where 1 n s m these new search directions are generated in parallel requiring n c o r e s n s cores to be available simultaneously it serves as a compromise between rbcg and block diagonal cg 3 1 rbcg using rbcg gürol et al 2014 x i m satisfies 4 x i m k i d m a m x i m x m e w x m e w k i d m a m i e the ith approximation to x m can be found as a linear combination of the vectors spanning the i th krylov space that minimizes the solution error in the e norm w e w t b m a m w 1 2 with b m a m i r 1 2 h m m b m m t h t r 1 2 then x i m is uniquely determined as the e projection of x m on k i d m a m 5 x i m v i v i t b m a m v t 1 v i t b m a m x m v i v i t b m a m v 1 v i t b m d m or alternatively 6 x i m v i t i 1 v i t b v i 1 v i t b m d m where the column space of v i is equal to k i d m a m and t i v i t b m v i 1 v i t b m a m v i here v i and t i depend on m via a m and d m this yields residuals r i m that are by construction b m orthogonal to v i we refer to the column vectors of v i as the search directions as x i m is a projection it is independent of the search directions chosen as long as they span the same space in rbcg i 1 th search direction would be chosen to be e orthogonal i e conjugate to v i here the i 1 th search direction is chosen to be equal to r i m which is b m orthogonal to v i i e v i 1 v i r i m in this case the e orthonormalization is contained in t 1 v i t b m v i 1 in 6 the pseudo code for this method is included in table c 3 3 2 full parallelization block diagonal conjugate gradient method if 3 is assumed then a m a b m b and 2 for the different m can be combined into a single linear system 7 a x d where x x 0 x 1 x m 1 and d d 0 d 1 d m 1 similar to 6 the i th approximation x i can be found as 8 x i v i v i t b a v i 1 v i t b a x v i t i 1 v i t b v i 1 v i t b d where t i v i t b v i 1 v i t b a v i v i d if i 1 and v i v i 1 d a x i if i 1 t v i are independent of m the column space of v i is now k i d a the advantage here compared to rbcg is that the search space for each x i m spanned by v i now has dimension i m instead of i the method results in matrices v i that are no longer b orthogonal but b block orthogonal if v p and v q are two columns of v i then v p t b v q 0 if p q m but might be non zero otherwise the estimates x i retrieved in this way are the same as those found using the block diagonal cg method o leary 1980 with b preconditioning the pseudo code for the block diagonal cg is given in table c 4 3 3 partial parallelization cluster search method in order to expand v i 1 to v i in the block diagonal cg method m applications of a to a vector are necessary this will require n c o r e s m cores and can be prohibitively expensive for large systems here we introduce the cluster search method that requires n s m concurrent applications of a to create the expansion in this case we still look for a solution to 7 with x i still given by 8 but with v i constructed differently in particular we focus on x 0 as it is the control run that will be used to produce the operational forecasts and therefore minimization of the error in x i 0 has top priority to explain how v i is constructed we momentarily assume that the eigendecomposition a u 0 λ 2 u 0 t with u 0 t u 0 i is available and require that i v p t b v q 0 if p q n s similar to block diagonal cg and ii the residual for the control run r i 0 is in the column space of v i 1 as is the case in rbcg for m 0 define v u 0 t r i 0 u 0 t a x ˆ 0 x i 0 v u 0 t d 0 u 0 t a x 0 and u i u 0 a v i t i 1 v i t b v i 1 v i t b u 0 then 9 u 0 v r i 0 r 0 0 a x i 0 r ˆ 0 0 a v i t i 1 v i t b v i 1 v i t b r 0 0 u i v to expand v i to v i 1 we look for n s new search vectors of the form s n u i p n v with n 1 2 n s and p n d d n e d e d t with e d the unit vector in direction d here d n is a subset of 1 2 d such that the union of d 1 d 2 d n s is 1 2 d and d p and d q are disjoint if p q consequently n 1 n s p n v v combined with the equality u 0 v u i v in 9 this then ensures that r i 0 lies within v i 1 thus search vectors of the form s n satisfy requirement ii furthermore 10 v i t b u i v i t b u 0 v i t b a v i t i 1 v i t b v i 1 v i t b u 0 v i t b u 0 v i t b a v i v i t b a v i 1 v i t b u 0 0 this shows that u i is b orthogonal to v i and since the n s new search directions in v i 1 are linear combinations of the column vectors of u i they satisfy requirement i for the following we also need to be able to estimate u 0 t a u i for i 0 u i u 0 and so u 0 t a u 0 λ 2 while for i 0 exact expressions are not directly available instead we observe that the columns of u i are the residuals obtained after trying to find a solution to the linear system a x u 0 in the search space v i this system has the exact solution u 0 λ 2 here we make an ad hoc assumption that these residuals are in good approximation multiples of the columns u 0 i e u i u 0 ξ with ξ diagonal in this case ξ can be estimated as ξ 2 ξ t u 0 t u 0 ξ u i t u i in rbcg x i 0 is defined as the vector in the search space s p a n v i that minimizes the error 4 in the e norm the novel idea behind cluster search is to find a clustering d 1 d 2 d n s and the associated n s new search vectors s n such that the reduction of the expected error x 0 x i 1 0 e is larger than can be achieved using any other clustering using the properties of p n the estimation u i u 0 ξ i and the orthonormality of u 0 we find that the e norm of the expected error for x i 1 0 can be estimated as 11 x 0 x i 0 n 1 n s α n u i p n v e 2 n 1 n s d d n 1 λ d 2 v d 2 2 α n v d λ d 2 1 λ d 2 v d ξ d α n 2 λ d 4 1 λ d 2 v d 2 ξ d 2 where λ d and ξ d are the d th element on the diagonal of λ and ξ correspondingly to find the minimum of this function we set the derivative of 11 as a function of α n to zero and get 12 α n d d n 1 λ d 2 λ d 4 v d 2 ξ d 2 v d v d ξ d λ d 2 d d n 1 λ d 2 λ d 4 v d 2 ξ d 2 1 13 v v ξ d 1 λ d 2 n where n denotes the weighted mean over the cluster d n with weights 1 λ d 2 λ d 4 v d 2 ξ d 2 inserting α n from 13 back into 11 gives that for our guesses of s 1 s n s the error squared obtains a minimum 14 x 0 x i 0 n 1 n s α n u i p n v e 2 n 1 n s d d n 1 λ d 2 v d 2 ξ d 2 λ d 4 v d 2 v d 2 ξ d 2 λ d 4 α n 2 n 1 n s w n var n v d v d ξ d λ d 2 with var n the weighted variance over cluster n and w n d d n 1 λ d 2 λ d 4 v d 2 ξ d 2 the normalization coefficient for the n th cluster the k means clustering algorithm macqueen 1967 can now be used to find a clustering that approximately minimizes 14 once k means produces a clustering s n u i p n v are known and v i 1 v i s 1 s n s in reality the eigenvalue decomposition of a is not available instead it is used that if r and b are true estimates of the observational and background error covariance then a d d t desroziers et al 2005 here denotes the expected value approximations to the eigenvectors and eigenvalues of a are then found by calculating the eigenvalue decomposition of 1 m d 0 d 1 d m 1 d 0 d 1 d m 1 t 1 m d d t d d t the pseudocode for the cluster search method can be found in table c 5 an overview of where the cluster search method enters the cost function minimization algorithm is shown in fig 3 notice that if n s 1 there is only one cluster and requirement i ensures that the new search direction is equal to r i 0 consequently the clustering method reverts to rbcg described in section 3 1 for m 0 if n s m each column vector of u i constitutes its own cluster and hence the new search directions are multiples of the column vectors of u i by construction the column vectors of u i are linear combinations of the i th residuals from the different ensemble members consequently s p a n v i is equal in both the block diagonal cg and cluster search methods in section 5 we will compare convergence rates of rbcg full parallelization and the cluster search methods in the realistic or wa system set up before we can proceed with those we next describe the wind perturbations that will be utilized in the tests of section 5 4 wind perturbations conventionally multiplicative ensemble inflation anderson and anderson 1999 is applied to the ensemble members to compensate for the fact that ensembles generally fail to account for all error sources multiplicative ensemble inflation implicitly assumes that the ensemble underestimates the relative growth of the background errors uniformly throughout the model in the oregon washington region surface currents the strength of the coastal upwelling halpern 1976 huyer 1983 and the location of the fresh water columbia river plume hickey et al 1998 2005 liu et al 2009 all depend on the wind forcing therefore uncertainty in the wind forcing is assumed to be the dominant source of model error in an attempt to better approximate the structure and strength of the background errors we have opted for an approach different from multiplicative ensemble inflation in this approach physically realistic wind perturbations are added to the ensemble members m 1 m 1 and it is left up to the model physics to translate these wind forcing errors into background errors in the ocean state although no comparison with ensemble inflation will be made we will verify later in this manuscript if adding the wind perturbations helps to avoid ensemble variance shrinking alleviating the need for the ensemble inflation hamill and whitaker 2005 li et al 2009 whitaker and hamill 2002 the perturbed wind fields for an ensemble members are generated as 15 w t w n a m t w l t w s t with w n a m t r 2 n w the vector containing the meridional and zonal wind velocity components from the nam model interpolated to the n w roms model surface grid points fields w l t and w s t represent the large scale and small scale wind perturbations respectively for the large scale perturbations we use the empirical orthogonal function eof decomposition of the series w n a m t w n a m t w n a m where the winds are provided every 6 hr from 1 january 2011 00 00 to 31 december 2011 18 00 and w n a m is the mean wind field over this period after the eof decomposition the nam wind field can be written as 16 w n a m t w n a m i 1 n e o f β n a m i t w e o f i w t where w e o f i is the eof mode associated with the i th largest singular value w t t w e o f i 0 for i 1 2 n e o f and β n a m i t are the eof expansion coefficients associated with different eofs and different times here we use 10 eofs n e o f 10 that explain 95 of the variance of w n a m in time similarly to hénaff et al 2009 and vervatis et al 2016 we define the large scale wind perturbation to be 17 w l t i 1 n e o f β l i t w e o f i the expansion coefficients for the large scale wind perturbations β l i with specified standard deviation σ e o f i are generated by an ar1 process 18 β l i t σ e o f i ϵ β i t for t 0 β l i t c β β l i t δ t 1 c β 2 σ e o f i ϵ β i t for t δ t here ϵ β i t is drawn from a standard normal distribution δ t 6 h is the output time step of the nam model and correlation coefficient c β 0 4 milliff et al 2011 the two dominant wind eofs scaled by the standard deviations of their expansion coefficients in the large scale wind errors σ e o f i are shown in fig 4a b the standard deviation of the large scale expansion coefficients β l i is estimated based on the differences between the 6 hourly nam model wind output and the daily 25 km ascat satellite wind product figa saldaa et al 2002 noaa 2011a and ndbc buoy numbers 46089 46015 46050 46029 46041 wind observations noaa 2016 the estimate σ e o f i used is the mode of 19 p σ e o f i 2 w o b s p w s β l ϵ o b s σ e o f 1 2 σ e o f n e o f 2 σ s 2 w o b s d w s d β l d ϵ o b s j 1 j i n e o f d σ e o f j 2 d σ s 2 the conditional probability distribution for σ e o f i 2 given all the scatterometer and buoy wind observations in the model domain in 2011 mapped to the nam model output times vector w o b s for the buoy observations the time mapping is done by selecting the buoy wind measurement closest to the nam model output time while the daily ascat observations are compared with the nam model output time on the same day for which the rmse between ascat observations and nam model output is minimal the conditional probability distribution in 19 is constructed using a bayesian hierarchical model bhm similar to the one used in milliff et al 2011 and wikle et al 2001 the bhm consists of three stages 20 w o b s t j h t j w t r u e t j ϵ o b s t j data stage w t r u e t j w n a m t j w s t j i 1 n e o f w e o f i β l i t j process stage σ o b s 2 σ s 2 σ e o f i 2 parameter stage with the underbar denoting the concatenation of vectors taken at different nam model output times t j into one vector e g w s w s t 1 w s t 2 w s t n t h t j the linear operator that maps the wind velocities at time t j from the model grid to the ascat and buoy observation locations w t r u e t j r 2 n w the unknown true wind field at time t j ϵ o b s t j the measurement error in the ascat ndbc buoy wind observations w s t j r 2 n w the error in the small scale wind field and β l i t j the expansion coefficient for the i th eof mode in the large scale error in the wind field prior distributions of ϵ o b s t j w s t j β l i t j σ s 2 and σ e o f i 2 are assumed to be 21 ϵ o b s t j n ϵ o b s t j 0 σ o b s 2 i w s t j n w s t j 0 σ s 2 i β l i t j n β l i t j 0 σ e o f i 2 σ s 2 i g σ s 2 a s b s σ e o f i 2 i g σ e o f i 2 a e o f i b e o f i where n x μ c is a normal distribution with mean μ and covariance c i g x a b the inverse gamma distribution with parameters a b see appendix d for the details and denotes that a value or vector is randomly drawn from the given distribution any spatial structure in the small scale errors w s t j is neglected based on ascat validation verspeek et al 2013 σ o b s is set to 0 7 m s 1 we pick a e o f i 1 20 n t b e o f i 0 1 a e o f i v a r β n a m i with n t the number of days on which ascat observations are available and v a r β n a m i the variance of the coefficient β i in 16 this gives an a priori distribution for σ e o f i 2 with mode b e o f i 1 a e o f i 0 1 v a r β i these values were chosen such that this mode corresponds to the σ e o f i 2 0 09 v a r β n a m i estimate used by hénaff et al 2009 and vervatis et al 2016 similarly a s and b s are chosen to be a s 2 20 n t n w and b s σ o b s 2 a s given the a priori distribution of σ s 2 with a mode of approximately σ o b s 2 the conditional probability distribution 19 derived using the bhm above is retrieved using a gibbs sampler see appendix d and is shown in fig 5 for the nine dominant eof modes also indicated in fig 5 is the percentage of the variance in the nam wind fields explained by each eof in addition the 9 value of this variance is shown by dashed lines as this value was used in other studies to estimate σ e o f i hénaff et al 2009 vervatis et al 2016 fig 5 shows that the bhm estimate for σ e o f i is higher than the 9 estimate in all modes except mode one the difference between the two estimates increases for increasing eof number for the higher eofs mode 4 and higher which represent smaller spatial scales in the wind field not shown the 9 estimate severely underestimates the contribution of the mode to the error in the wind fields the study of scatterometer wind measurements over the pacific ocean shows that the power spectral density psd of the wind field scales with κ γ where κ is the wave number and γ 2 chin et al 1998 the psd of the meridional nam wind field determined using a hamming window fig 6 solid blue line decreases faster than this for κ 0 3 rad km 1 owing to the limited 12 km nam resolution as the nam model cannot represent the small scale wind field probable small scale wind fields are added to the ensemble members following wikle et al 2001 it is assumed that the small scale wind field in 15 can be decomposed into daubechies 2 wavelets cohen et al 1993 22 w s t γ 0 n 1 9 i γ i n t ψ i n with γ i n t coming from an ar1 process 23 γ i n t c γ γ i n t δ t 1 c γ 2 σ γ n ϵ i n t here n indicates the level of the wavelet with the length scale of the wavelets doubling as the level increases with one and i running over all the wavelets that are available at level n similarly to the large scale wind field we use c γ 0 4 this wavelet approach yields small scale wind perturbations that are local in space and are simultaneously constrained to a limited spectral band by experimentation the standard deviation of σ γ n is chosen such that the dependence of the psd s on the wave number κ of the total ensemble member wind field scales as s κ κ 2 this was achieved by setting σ γ n exp 1 3 n 3 0 5 0 5 tanh 0 4 n 4 and picking γ 0 such that the variance of the wind speed is 0 55 m s 1 2 the psds for the wind fields of the different ensemble members on 8 august 2011 00 00 are shown together with the linear least square log log fit to the ensemble mean psd for κ 0 1 rad km 1 in fig 6 the fit confirms that the psds have indeed the desired p s d κ 2 0 relationship 5 results 5 1 convergence the effectiveness of the cluster search algorithm using a different number of clusters is compared with that of rbcg and block diagonal cg even though the da correction x m is only calculated after the last inner loop iteration i i the cost function 1 can be calculated for each inner loop iteration i if the substitution x i m b m t h t r 1 2 x i m is made in 1 24 j x i m 1 2 x i m t b x i m 1 2 d m b x i m t d m b x i m using 5 we find that b x i m b v i t i 1 v i t b v i 1 v i t b d m which is readily available as b v i is stored using 24 the value of the cost function was calculated prior to each inner loop iteration using the cluster search method with different numbers of clusters 1 n s 40 the cost function normalized by its value at the start of the minimization is shown in fig 7a and b for the windows starting on 31 may and 26 august 2011 respectively increase in the number of clusters n s and correspondingly the number of search directions at each iteration consistently improves the rate at which the cost function decreases as the function of the inner loop iteration number to provide a more quantitative assessment of the advantage of using several search directions in parallel we compute the speed up ratio 25 a n s i 1 i n s where i n s is the number of iterations needed to reach a specific reference level of the cost function j j ref using the cluster method with n s new search directions per iteration i 1 corresponds to rbcg for j ref we choose the value in the case using n s 4 and i 12 iterations as this will be adopted later as the standard setup in the long term system evaluation in part ii of this study pasmans et al submitted the speed up ratios are shown in fig 7c and indicate e g that rbcg n s 1 needs approximately 30 more iterations than cluster search with n s 4 to reach the same level of cost function reduction a fit of a 2nd order polynomial to a dashed black lines in fig 7c shows that the coefficient for the quadratic term is negative and significantly different from zero at a 95 significance level indicating that the additional benefit of adding more clusters diminishes as the number of clusters increases fig 8 compares differences in the initial condition corrections between rbcg n s 1 and the cluster search with n s 4 on 26 august 2011 as the time available to perform da is constrained in operational settings the minimization in both these two cases is terminated after i 12 inner loop iterations the plots on the left show the da correction calculated for sst surface velocity and ssh fields with n s 1 and the plots on the right show the difference between the da corrections in the cases with n s 4 and n s 1 while both methods yield similar large scale corrections they differ in details at the scale of geostrophic eddies for the ensemble members additional dependency on the search space comes from the fact that when cluster search is used the right hand side of 7 is replaced by its b projection on the search space i e on the right hand side of 7 d m is effectively replaced by v i v i t b v i 1 v i t b d m for the control run this is not an issue as by construction d 0 lies in s p a n v 1 but for the ensemble members this could result in the systematic elimination of a part of the errors contained in d m such an elimination would result in da corrections for the ensemble members that are too small and consequently an ensemble spread that will be too large to test whether this is a valid concern the normalized rmse for each observation type i e the rms of the elements of d m associated with one type of observations is calculated and compared with the rmse after taking the b projection of d m on v i with i 12 if d m lies completely in v i as is the case for m 0 the ratio of the latter over the former is one the actual ratio in the experiment is calculated for each ensemble member and each window and the lower bound upper bound and ensemble mean are shown in fig 9 fig 9 shows that as expected using the projection can result in the reduction of the rmse up to 40 however the figure also shows that taking the projection can increase the rmse this paradoxical behaviour emerges because the projection uses the b inner product while in the calculation of the rmse involves the normal euclidean inner product taking the mean of the ratios over all ensemble members shows that increases in the rmses created by the b projection mostly but not completely offset the reductions in rmses and that the net result is a small decrease in the rmse of 1 7 for sst 3 6 for hfr and 2 8 for ssh observations so the projection effect might indeed result in overestimation of the error variances by the ensemble but this effect is small 5 2 error reduction to test whether the system is effective correcting rmse not only for the control run but also for the ensemble members the rmse between the data used in the assimilation and the nonlinear analyses and forecasts is calculated for the ensemble members as shown in fig 10 each line segment represents the rmse in the analysis left point and in the forecast for the subsequent window right point note that the forecast rmse right points is calculated with respect to formally future observations the en4dvar system is effective in reducing the rmse the analysis rmse for the ensemble members exceeds that in experiment no da blue line in less than 4 of the cases forecast rmse for the ensemble members is smaller than no da forecast rmse in 73 of cases the rmses for the ensemble members however are consistently larger than those for the control run green line as they are forced with perturbed wind fields and corrected with perturbed observations however the errors introduced by the perturbations cancel out in the ensemble mean indeed the ensemble mean rmse lies below that of the ensemble members note that in the ensemble kalman filter there is no control run and the ensemble mean is used as the best estimate evensen 1994 we could have used the same approach but the additional communication between the computational nodes required to calculate the mean ocean state would have increased the wall time significantly table 1 shows that the rmse of the control run is on par with that of the ensemble mean with the exception of the rmse in the hfr observations after 14 august 2011 see fig 10b hence our choice to pick the control run over the ensemble mean to produce the forecasts will have only a limited negative impact on the forecast accuracy fig 11 shows the observation model bias in experiment no da the ensemble members the control run and the ensemble mean as the along track mean is removed from both the altimetry observations and their model equivalents prior to assimilation see appendix a the along track mean of both the assimilated altimetry observations and their model equivalents is by construction zero consequently the bias along each track and thus in general is zero and is therefore not included in fig 11 the bias in the hfr observation shows a spread around zero for both the ensemble members as well as the control run forecasts the bias in the forecasts predictions for the sst observations however has a negative tendency with particularly large negative biases during the periods 13 16 may 5 8 june 21 24 july 26 29 august 25 28 september 2011 this results in an overall negative bias over the whole period as shown in table 1 it is indicative of either insufficient surface heating in the model too much mixing in the upper layer or a positive bias in the satellite observations further verification against independent in situ observations is described in part ii 5 3 ensemble reliability if the ensemble statistics are truly representative of the background error statistics the ensemble is said to have high reliability a rank diagram is a diagnostic that can be used to test this hamill 2001 fig 12 shows rank diagrams for the three different types of observations the steps to construct these are as follows a sample each ensemble member forecast at the observation locations and times and add a random observation error b for each observation count the number of ensemble forecasts that are lower than the measured value c by definition this number plus one is the rank of the observation d count the frequency of each rank and divide by the total number of observations to determine the normalized frequency if the ensemble is reliable the rank diagram should be flat hamill 2001 the 95 confidence interval for the normalized frequency of a reliable ensemble is shown as dashed lines in fig 12 the figure shows that the ensemble reliability is different for different fields in the rank diagram for sst fig 12a there is no distinctive peak instead the rank diagram has an upward slope this can be due to the negative bias in the ensemble see fig 11a for the hfr observations mid range ranks are relatively more abundant than the tails see fig 12b this indicates that either the spread in the ensemble is larger than the standard deviation of the hfr background errors or that the observational error magnitude is overestimated the opposite is the case for ssh observations here the u shape fig 12c implies that the forecast ensemble underestimates the magnitude of the background errors finally estimates for the background error and observational covariances used in the da system are compared with estimates obtained from the innovation statistics the relations between innovation statistics and error variances are given by desroziers et al 2005 26 y h m x b 0 d 2 h m b m t h t r d d 27 y h m x b 0 d y h m x b 0 h m x 0 d r d d 28 h m x 0 d y h m x b 0 d h m b m t h t d d where 1 d d is the index of the observation and denotes the expectation value d the d th element of the vector and d d the d th element on the diagonal of a matrix the expectation values on the left hand side of 26 28 are approximated by averaging over all observations of the same type in each window these estimates are shown as blue lines in fig 13 where the top middle and bottom plots are for 26 27 and 28 correspondingly an approximation to the right hand side of 27 is obtained by averaging r d d over all the observations of the same type for the right hand side of 28 an approximation is obtained by doing the same for 29 b e n s d d d e f h m b m t h t d d 1 m 2 m 1 m 1 h m x b m h m x b d 2 h m x b 1 m 1 m 1 m 1 h m x b m error standard deviations based on these estimates are displayed as dashed black lines in fig 13 eqs 26 28 only hold if r and b correctly represent the true observational and background error covariances fig 13 shows to what extent this is the case in our system fig 13g h i show that the ensemble error standard deviation black line grows over time for all three types of observations and hence that the wind perturbations are sufficient to prevent the ensemble spread from collapsing even without ensemble inflation for sst the error standard deviation estimates from the innovation statistics are in agreement with the specified standard deviations see fig 13a d g error standard deviation estimates for hfr observations are consistent up to 1 july 2011 too after 1 july 2011 however the total error standard deviation estimate is too large fig 13b the standard deviations for the observational errors agree fig 13e so the overestimation is due to the fact that after 1 july the ensemble background error standard deviation estimate black line fig 13h is larger than the standard deviation error estimate based on the forecast observation differences blue line in fig 13h this finding is consistent with the shape of the rank histogram in fig 12b indicating overdispersion in the ensemble further investigation not shown here indicates that the difference between the estimates for background error standard deviation can be attributed nearly entirely to the sparse hfr observations taken far offshore depth 2 km closer to the shore depth 1 km where numerous closely spaced hfr observations are available for da to reduce the background error the ensemble estimates for the observational and background error standard deviations and those based on 26 28 show good agreement fig 13b light blue grey initially the total ssh error standard deviation estimate from r and b e n s black line in fig 13c is smaller than the total ssh error standard deviation from the innovations blue line in fig 13c one could put forward the hypothesis that this is due to the fact that the standard deviation from b e n s black line in fig 13i is smaller than the observational error estimate used in the da black line in fig 13f resulting in small ssh da corrections this would be a satisfactory explanation near the shore depth 1 km where ensemble estimates for b and b r remain nearly constant over time fig 13i light blue grey however in general the standard deviation from b e n s keeps increasing over time growing beyond the specified observational error standard deviation of 2 cm and 27 is not satisfied the innovation statistics estimate blue line in fig 13f for the observational error standard deviation continues to lie above the specified standard deviation black line in fig 13f either we have underestimated the observational error standard deviation while specifying r or the structure of the background errors is such that the system cannot remove them effectively 6 conclusions and discussion the development of ensemble based 4dvar systems has been one of the main focus areas in numerical weather prediction similarly there is a rationale to applying ensemble based 4dvar systems for oceanic prediction utility of a static b can be limiting in shelf applications the or wa forecast system used in this study as a test ground for en4dvar is a good example where model error statistics are influenced by high temporal and spatial ocean state variability before en4dvar can be applied successfully to the or wa or any other coastal system many technical details must be worked out as outlined in this manuscript the newly developed en4dvar systems need to go through statistical tests for self consistency using actual observations which help us understand the system behaviour and potential biases in the data critical to a successful implementation of en4dvar for large prediction systems will be the development of time efficient cost function minimization algorithms that take advantage of the massive parallel computer architectures the cluster search method developed and tested in this study explores n s search directions in parallel at each inner loop iteration it was found that using a relatively small number of parallel direction computations n s 4 can reduce the wall clock time by 30 compared to rbcg to achieve the same level of cost function reduction it can be interesting to see in future studies whether combination of this method with saddle point algorithms rao and sandu 2016 fisher and gürol 2017 can deliver an even better 4dvar performance given the same limited number of cores our system did not employ ensemble inflation e g anderson 2001 anderson and anderson 1999 hamill et al 2001 but generated background errors by perturbing the wind fields in the ensemble members in a realistic way although no comparison was made with ensemble inflation and thus it cannot be concluded that wind perturbations are superior to ensemble inflation no collapse of the ensemble spread was observed and therefore wind perturbations alleviated the need for ensemble inflation the common assumption hénaff et al 2009 palmer et al 2009 vervatis et al 2016 that the variance of the wind errors is proportional to the natural time variability was found to be unrealistic this is possibly due to the atmospheric model being less able to represent small scales or due to the inability to represent all possible small scale error modes correctly with a very limited set of eofs instead we found using a bhm that the wind errors increase in proportion to the natural variability as the spatial scale of the wind error decreases based on this we agree with the findings of whitaker and hamill 2012 that additive inflation is more suitable to representing model errors like the errors in wind forcing than multiplicative inflation in which error variances are assumed to be proportional to the temporal variance in the signal even though the en4dvar system was effective in reducing forecast errors compared to the case no da the rank diagram analysis suggests that the ensemble fails to represent the background error statistics perfectly the ensemble overestimates the spread in the surface velocity background errors while it underestimates the spread in the ssh background errors see fig 12 although the rank diagrams in fig 12 are not uniform the bias and the maximum minimum frequency ratio of the diagrams is not exceptionally large compared to the rank diagram analyses in ensemble kalman filter da studies e g cookson hills et al 2017 fujita et al 2007 leeuwenburgh 2007 meng and zhang 2008 this concludes the introduction of the new en4dvar system for the or wa system and evaluation of the error in part ii of this study pasmans et al submitted we will discuss if en4dvar yields better quality predictions than the traditional 4dvar with balance operator background covariance currently used in the operational or wa system declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national oceanic and atmospheric administration noaa united states of america coastal ocean modelling testbed comt grant number na13nos0120139 the noaa quantitative observing system assessment program qosap integrated ocean observing system northwest association of networked ocean observing systems ioos nanoos united states of america grant number na16nos0120019 the national aeronautics and space administration nasa united states of america swot science definition team project grant number nnx13ad89g this work used the extreme science and engineering discovery environment xsede allocation tg oce160001 which is supported by the national science foundation united states of america grant number aci 1548562 the views opinions and findings contained in this paper are those of the authors and should not be construed as an official noaa or u s government position policy or decision we would like to thank the four anonymous reviewers for their very motivating and insightful comments appendix a ssh observations let r be the track number of a set of ssh observations a single pass of a ssh satellite through the domain takes at most several minutes therefore all ssh observations during this pass are assumed to have been made at the same time t here t is chosen to be the mean of the observation times during the pass let x k r t be the location of the k th observation of the ssh along track r at time t define a 1 ζ k r t s s h a x k r t t m d t x k r t l 1 8 t 1 t 0 t 1 a l x k r t cos ω l τ ϕ l x k r t d τ here s s h a x k r t t and m d t x k r t are respectively the detided sea surface height anomaly and mean dynamic topography at location x k r t and time t as provided by the ssh satellite data provider ω l a l x k r t and ϕ l x k r t are the angular frequency amplitude and the phase of the l th tidal component at location x k r t a l and ϕ l are estimated for the m2 s2 n2 k2 k1 o1 p1 q1 tide by regression from the no da model run using t tide pawlowicz et al 2002 t 0 is the maximum of t 12 h and the beginning of the current da window t 1 is the minimum of t 12 h and the end of the current da window and t t 1 t 0 then the ssh observation provided to the da system at time t and location x k r t is a 2 ζ k r t ζ k r t k 1 j ζ j r t with k the total number of ssh observations in track r at time t the innovation corresponding to this observation is then calculated as a 3 d k ζ k r t t 1 t 0 t 1 ζ m o d e l x k r t τ d τ k 1 j t 1 t 0 t 1 ζ m o d e l x j r t τ d τ by applying this procedure we attempt to correct the non tidal ssh slope along each track but not the average level appendix b list of symbols see table b 2 appendix c pseudocode minimization algorithms see tables c 3 c 5 appendix d estimation conditional distribution σ e o f i the integral on the right hand side of the conditional probability distribution σ e o f i 2 19 d 1 p σ e o f i 2 w o b s p s w o b s d w s d β l d ϵ o b s j 1 j i n e o f d σ e o f j 2 d σ s 2 is approximated by drawing 500 samples s w s β l ϵ o b s σ β 1 2 σ β n e o f 2 σ s 2 from the distribution p s w o b s followed by the creation of a normalized histogram of σ e o f i 2 from these samples the sampling is carried out using a gibbs sampler casella and george 1992 and consists of sequentially drawing components of s under the condition that the other components remain constant i e a new sample s w s β l σ e o f 1 2 σ e o f n e o f 2 σ s 2 is constructed from the previous sample s w s β l σ e o f 1 2 σ e o f n e o f 2 σ s 2 by sequentially drawing 1 for each t j d 2 β l t j p β l t j w o b s w s σ e o f 2 σ s 2 p w o b s t j β l t j w s t j σ e o f 2 σ s 2 p β l t j w s t j σ e o f 2 σ s 2 n w o b s t j h t j w n a m t j h t j w β l t j h t j w s t j 0 σ o b s 2 i n β l t j 0 σ e o f 2 n β l t j σ o b s 2 c w t h t j t w o b s t j h t j w n a m t j h t j w s t j c with c 1 σ o b s 2 w t h t j t h t j w σ e o f 2 2 for each t j d 3 w s t j p w s t j w o b s β l σ e o f 2 σ s 2 p w o b s t j w s t j β l t j σ e o f 2 σ s 2 p w s t j β l t j σ e o f 2 σ s 2 n w o b s t j h t j w n a m t j h t j w β l t j h t j w s t j 0 σ o b s 2 i n w s t j 0 σ s 2 i n w s t j σ o b s 2 c h t j t w o b s t j h t j w n a m t j h t j w β l t j c with c 1 σ o b s 2 h t j t h t j σ s 2 i 3 for each i 1 2 n e o f d 4 σ e o f i 2 p σ e o f i 2 w o b s β l w s σ s 2 p β l i σ e o f i 2 p σ e o f i 2 n β l i 0 σ e o f i 2 i g σ e o f i 2 a e o f i b e o f i i g σ e o f i 2 a e o f i 1 2 n t b e o f i 1 2 j β e o f i 2 t j 4 d 5 σ s 2 p σ s 2 w o b s β l w s σ e o f 2 p w s σ s 2 p σ s 2 n w s 0 σ s 2 i i g σ s 2 a s b s i g σ s 2 a s n t n w b s 1 2 j w s 2 t j 2 with w o b s t j the ascat and buoy wind observations at time t j w n a m t j the nam model wind field at time t j interpolated onto the roms model grid h t j the operator that interpolates the wind field to the observation locations at time t j ϵ o b s t j the measurement error in the ascat ndbc buoy wind observations w s t j r 2 n w the error in the small scale wind field β e o f i t j the expansion coefficient of the large scale wind errors at time t j σ the diagonal matrix having σ e o f 1 σ e o f n e o f on its diagonal and w the matrix having w e o f i as its i th column the denotes that a value is randomly drawn from a distribution n x μ c 2 π 1 2 d det c 1 2 exp 1 2 x μ t c 1 x μ is a normal distribution with mean μ and covariance c and i g x a b γ a 1 b a x a 1 exp b x the inverse gamma distribution with scale parameters a b in the second lines of d 2 d 5 bayes theorem has been used in order to insure that the samples generated are uncorrelated 10000 samples are generated with the gibbs sampler but only every 20th sample is retained 
24006,the ocean state off oregon washington u s west coast is highly variable in time under these conditions the assumption made in traditional 4 dimensional variational data assimilation 4dvar that the prior model background error covariance is the same in every data assimilation da window can be limiting a da system based on an ensemble of 4dvars en4dvar has been developed in which the background error covariance is estimated from an ensemble of model runs and is thus time varying this part describes details of the en4dvar method and ensemble statistics verification tests the control run and 39 ensemble members are forced by perturbed wind fields and corrected by da in a series of 3 day windows wind perturbations are represented as a linear combination of empirical orthogonal functions eofs for the larger scales and daubechies wavelets for the smaller scales the variance of the eof expansion coefficients is based on estimates of the wind field error statistics derived using scatterometer observations and a bayesian hierarchical model it is found that the variance of the wind errors relative to the natural wind variability increases as the horizontal spatial scales decrease da corrections to the control run and ensemble members are calculated in parallel by the newly developed cost effective cluster search minimization method for a realistic coastal ocean application this method can generate a 30 wall time reduction compared to the restricted b conjugate gradient rbcg method ensemble statistics are generally found to be consistent with background error statistics in particular ensemble spread is maintained without inflating however sea surface height background errors cannot be fully reproduced by the ensemble perturbations keywords 4dvar coastal ocean data assimilation ensemble numerical modelling usa oregon 1 introduction data assimilation da is a procedure e g used in meteorology and oceanography in which the output of a numerical model is combined with observations to find the most likely estimate for the true state of the system da algorithms require specification of the error statistics for the model and the observations these statistics are often assumed to follow a multidimensional normal distribution with zero mean and a covariance that is static in time i e the same from one assimilation cycle to the next an example of such a da system is the oregon state university coastal ocean forecast system in an area offshore oregon washington or wa at the u s west coast kurapov et al 2011 pasmans et al 2019a yu et al 2012 this system applies the 4dvar algorithm in a series of consecutive 3 day windows initial conditions at the beginning of each window are corrected to yield the nonlinear analysis that fits observations in this window the simulation is then continued for another three days to provide the forecast summer dynamics in this region are dominated by the wind forced upwelling and relaxation and the outflow of the columbia river hickey et al 2005 2010 huyer 1983 liu et al 2009 in such a dynamic environment it is unlikely that the stationarity assumption on the error statistics holds in particular the temperature salinity model error covariance will strongly depend on the presence of the river plume over the past three decades ensemble methods have been developed in meteorology to deal with non stationarity in the error statistics in these methods the forecast background error covariance is estimated from an ensemble of perturbed model runs one of the earliest and most popular examples of such a method is the ensemble kalman filter anderson 2001 bishop et al 2001 evensen 1994 lermusiaux and robinson 1999 more recently in meteorology these ensemble kalman filter systems have been combined with 4dvar systems in which the background error covariance used by the 4dvar system is estimated using the ensemble from the kalman filter system buehner et al 2009 clayton et al 2013 zhang and zhang 2012 in this manuscript we describe our approach to using an ensemble of 4dvars en4dvar to provide a state dependent background error covariance this methodology will be tested with the or wa 4dvar system generalization of the ensemble methodology to ensembles of 4dvars is nontrivial for three reasons first 4dvar is computationally intensive calculation of a da correction requires minimization of a cost function or equivalently solving a linear system with some symmetric and positive definite matrix a this matrix is large and generally not available in explicit form instead only the algorithm for the product of a and a vector is at hand an iterative method e g the restricted b conjugate gradient rbcg algorithm is used to find an approximate solution of this system each iteration requires propagation of the tangent linear tl model over the analysis period forward in time and its adjoint counterpart adj backward in time for practical systems the 4dvar cycle can take 10 100 times as much time as a single forward model run second en4dvar only compounds this problem as it requires running the computationally intensive 4dvar algorithm for each ensemble member third the ensemble has to be initialized and evolved in such a manner that its covariance is representative of the true background error covariance over the last decade much effort has been put into overcoming these challenges several solutions have been found instead of applying full 4dvar to each ensemble member it has become customary to calculate a low rank approximation to a using e g ritz pairs found by the lanczos algorithm trefethen and bau 1997 in the ensemble variational integrated localized data assimilation evil methodology auligné et al 2016 minimization of the cost function is only carried out for the control or deterministic model run from the ritz vectors obtained as a by product from this minimization a low rank approximation of a is constructed the inverse of this approximation is then used to solve the linear system for the ensemble members desroziers and berre 2012 and lorenc et al 2017 followed similar approaches but use the ritz pairs solely to construct a preconditioner advances have also been made to speed up the 4dvar minimization algorithm itself parallelization can be applied to the tl and adj models by assigning the calculations for different parts of the domain to different processor cores as well as to the minimization algorithm the former is currently standard practice while the latter is still an area of active research one popular approach is to use an ensemble of concurrently produced nonlinear model runs to generate approximations of the tl and adj model examples of this approach are 4denvar amezcua et al 2017 desroziers et al 2014 gustafsson and bojarova 2014 liu et al 2008 tian et al 2017 and the ensemble kalman smoother 4dvar eks 4dvar mandel et al 2016 4denvar and eks 4dvar can be used to minimize the same cost function but their implementation differs in two major ways first 4denvar uses all observations within a da window to correct the initial condition while eks 4dvar processes the observations in batches with each batch generating corrections to the model at and prior to the batch time second both in en4dvar and eks 4dvar the propagation of perturbations from the background state to the next time step and into the observation space is carried out by a finite difference scheme involving the nonlinear model and nonlinear sampling operators the finite difference scheme in eks 4dvar uses a smaller step size and thus better approximates the tangent linear model and linearized sampling operators used in classic 4dvar background error localization in these methods is non trivial in absence of a tl model to propagate the localized background error covariance forward in time localization is often assumed to be static in these methods for limited size ensembles with non dense observation networks this can lead to a decrease in forecast performance compared to variational methods that do use tl and adj models poterjoy and zhang 2015 poterjoy et al 2016 a similar problem is encountered when attempting to implement a hybrid background covariance a linear combination of an ensemble and climatological static covariance in these 4denvar systems the use of a hybrid background covariance was found to improve the accuracy of the forecasts produced by traditional 4dvar systems clayton et al 2013 kuhl et al 2013 more specifically it was found that the best fit to the assimilated observations is achieved when the climatological part makes up the major part of the background covariance clayton et al 2013 lorenc and jardak 2018 however without tl and adj models to propagate the covariance back and forth in time hybrid 4denvar failed to provide the same benefits lorenc et al 2015 one different approach to parallelization that does not suffer from these problems is taken by rao and sandu 2016 and fisher and gürol 2017 they make use of the tl and adj models and parallelize the 4dvar minimization algorithm in time this is done by dividing the analysis period into separate time intervals the da correction is found by minimizing a cost function that consists of the sum of the 4dvar cost functions for each interval plus an additional term representing the constraint that the correction should be continuous going from one interval to another another recent approach that circumvents the problems with localization and hybrid covariances encountered in en4dvar is the localized ensemble based tangent linear model letlm in which the matrix for the tangent linear model is not constructed using a linearized version of the extensive nonlinear model but retrieved from a simple regression against the ensemble members allen et al 2017 bishop et al 2017 frolov and bishop 2016 frolov et al 2018 yet another alternative approach explored in this paper is to try to accelerate the linear system solver by using several search directions in parallel the current or wa system uses the restricted b conjugate gradient method rbcg gürol et al 2014 in this method an approximation to the linear system solution is sought in a low dimensional krylov space and the search space dimension is equal to the number of iterations several generic iterative solvers have already been developed in which the search space dimension grows faster than that consequently less iterations are necessary to produce a good approximation to the solution among these are the enlarged krylov space method grigori et al 2016 in which the search space is expanded by multiple directions per iteration simultaneously or the augmented krylov space methods where extra search directions are added to the system coming from an earlier attempt to solve a similar system erhel and guyomarc h 2000 morgan 1995 from the eigenvectors of a preconditioner kharchenko and yeremin 1995 or from an attempt to solve the system with a different initial residual chapman and saad 1996 additional search directions can also lie outside the krylov subspace e g yaremchuk et al 2017 use model based empirical orthogonal functions eofs to create search directions once a general search space is defined the approximation can be defined as the vector in the search space that has the smallest distance to the exact solution in some appropriately chosen norm brezinski 1999 in the en4dvar system proposed in this paper the evil method auligné et al 2016 is parallelized using a new variation of the enlarged and augumented krylov space methods two principal and novel elements of the en4dvar will be described the first is the cluster search method used to enlarge the search space at each iteration at a price of running a relatively small number of tl adj applications in parallel the second is the use of a bayesian hierarchical model to estimate the magnitude of the wind forcing perturbations for the ensemble members part ii of this study pasmans et al submitted will include a a comparison of the ensemble background error covariance produced by the en4dvar system and the static background error covariance based on the balance operator and b comparative tests of en4dvar and traditional 4dvar implemented in the or wa coastal ocean forecast system this paper is organized as follows section 2 describes the experimental setup and the layout of the en4dvar system derivation of the cluster search method is presented in section 3 wind perturbations for the ensemble members are discussed in section 4 in section 5 we check if the en4dvar statistics are representative of the true background error statistics discussion and conclusions are presented in section 6 2 the en4dvar system pasmans et al 2019a describe the or wa coastal ocean forecast system in every detail implemented as standard 4dvar with a static background error covariance a short summary is only provided here the nonlinear model dynamics are described by the regional ocean modelling system roms www myroms org by integrating three dimensional fully nonlinear hydrostatic boussinesq equations featuring advanced numerics shchepetkin and mcwilliams 2003 2005 the model domain is shown in fig 1 the model resolution is approximately 2 km in the horizontal and 40 terrain following layers in the vertical direction the computational grid has 310 522 points non tidal boundary conditions are taken from the global 1 1 2 hycom ncoda analyses coaps 2015 tidal forcing is added along the open boundaries egbert and erofeeva 2002 2010 atmospheric surface forcing is calculated based on the bulk flux algorithm fairall et al 2003 using the 12 km resolution northern american mesoscale nam model analysis fields noaa 2011b the fresh water discharge from the columbia river fraser river and 15 small rivers in puget sound is also included each hour the three dimensional ocean state calculated by the model is saved to disc while standard roms includes tl and adj models these are tightly integrated into the code such that implementing the en4dvar directly into roms was too challenging for us as the users instead we utilize the stand alone tl and adj avrora codes developed in house kurapov et al 2009 2011 yu et al 2012 and integrate these with the nonlinear roms and other components of the en4dvar via linux shell scripts similarly to how it is done in the present or wa operational forecast system the tl and adj runs are performed on a coarser 4 km resolution model grid and their output is interpolated to and from the 2 km model grid all computations have been carried out on the comet cluster with computer allocations made available through the xsede framework towns et al 2014 both the nonlinear roms and tl adj avrora codes are run using message passing interface mpi parallelization the model grid is divided into horizontal tiles and computation in the interior of each tile is performed on a separate processor core owing to a relatively small grid size a small number of n c o r e s 6 tiles are used for each instance of the adj and tl models more nodes are available to us and later in this paper we discuss how these can be used to speed up the iterative minimization algorithm in this paper results from two experiments are compared ens and no da in experiment ens the en4dvar system is used to run m 40 instances of the model forward in time in the discussions below the run with index m 0 is referred to as the control run while instances m 1 2 m 1 are referred to as ensemble members since the dynamics in this region are dominated by the wind forcing we assume that the errors in the wind velocity are the dominant model error source to include this error into the error statistics the nonlinear forecasts for each ensemble member are run with perturbed wind velocities as detailed in section 4 it will be evaluated in section 5 whether the addition of these perturbations alleviates the need for the customary ensemble inflation anderson 2001 anderson and anderson 1999 hamill et al 2001 no wind perturbations are added to the control run in our system the analyses and forecasts from the unperturbed control run are considered to provide the best estimate of the ocean state unless explicitly stated otherwise the control da run is compared with the results from experiment no da in section 5 since no perturbations are added to the control run the probability distributions of the errors in the control run will deviate from that in the ensemble members therefore the control run is not utilized in the calculation of b the ensemble members are all initialized from the same no da model output on 10 march 2011 and propagated forward in time without da using the perturbed winds thus generating an ensemble of perturbed ocean states on 19 april 2011 both ens and no da cases are then run and compared over the period from 19 april 2011 to 1 october 2011 the set of observations for assimilation includes radial surface currents from high frequency radars hfr alongtrack altimetry and satellite sea surface temperature sst although the model includes tides mainly to include their effect on river and ocean water mixing our focus is on correcting subtidal variability surface tidal currents can be dominated by non stationary internal tides e g kurapov et al 2003 osborne et al 2011 that are poorly predictable and poorly constrained by the available data at the same time the daily averaged hfr velocity data present a useful constraint on the 3 day ocean forecasts yu et al 2012 following our practice in the or wa system we assimilate daily averaged hfr observations matching those to the daily averaged model outputs altimetry observations can suffer from large errors in the specification of the geoid to suppress these and the tidal errors in the da we assimilate differences from the mean along track ssh averaged over 24 h details of the procedure can be found in appendix a more details on the data and their associated observational error variances are described in pasmans et al 2019a the only difference here is that the level 2 goes 11 sst maturi et al 2008 is used instead of polar orbiting satellite products the observational error covariance matrix r is diagonal as shown schematically in fig 2 da proceeds in a series of 3 day windows at the beginning of each window the initial conditions for the control run and each ensemble member are corrected then every model starts from the corrected initial conditions and is run forward using the nonlinear roms for the length of the assimilation window 3 days to obtain the analyses and continues for another 3 days to obtain the forecasts the 3 day window length is long enough to let the non tidal dynamics evolve and provide dynamically based space and time interpolation of the data it is still short enough such that the correction to the initial conditions at the beginning of the da window impacts forecasts to explain the da method in more detail we combine the temperature salinity sea surface height and horizontal velocity fields at the beginning of the window and prior to da into a vector of real numbers of length n x b m r n m 0 m 1 the vector containing all observations within the window is denoted as y r d the innovation vector for each ensemble member is defined as d m y h m x b m ϵ m here m x b m is the nonlinear model trajectory started from the initial conditions x b m and h is the collection of data operators a perturbation ϵ m is added to the innovation vector for each ensemble member m 1 m 1 to account for the uncertainty in the analysis introduced by the presence of observational errors burgers et al 1998 houtekamer and mitchell 1998 it is drawn from a normal distribution with zero mean and covariance r an overview of the symbols used is included as appendix b the da correction to the background state x b m is denoted as x m r n it is found by minimizing the following cost function for each m courtier et al 1994 1 j x m 1 2 x m t b 1 x m 1 2 d m h m m x m t r 1 d m h m m x m here m m is the tl model linearized with respect to m x b m m m t is the adj model b is the background error covariance obtained as the sample covariance of the ensemble members with localization as described in pasmans and kurapov 2017 to ensure that b represents dynamics on relatively slow subtidal and subinertial temporal scales each ensemble member is time averaged over the 24 h time interval centred at the beginning of the da window using the last 12 h of the analysis and first 12 h of the forecast from the previous window before it is used in the calculation of b the minimizer of 1 is sought as the solution of a linear symmetric and positive definite system of equations that can take different forms e g depending on whether the solution is sought in a space of size n or d and on how the system is preconditioned rbcg proved to be an efficient solver in the data space of dimension d with good convergence gürol et al 2014 it finds approximations of x m that minimize the cost function in 1 by solving the system 2 i r 1 2 h m m b m m t h t r 1 2 x m d e f a m x m d m where x m b m m t r 1 2 x m and d m r 1 2 d m 3 cost function minimization in this section we discuss several approaches to finding an approximation to x m the solution of 2 and propose the new computationally efficient cluster search algorithm we recognize that some mathematical details can be overwhelming to an educated reader who only wants to grasp the idea for that reason we first provide a high level overview in the beginning of this session this is followed by more formal sections 3 1 3 3 where all the necessary theoretical and algorithmic details are documented in rbcg x i m the i th iteration approximation to x m is sought in the low dimensional krylov subspace k i d m a m where k i z a span z a z a 2 z a i 1 z this search space grows by one dimension per iteration let i be the number of iterations necessary to bring x i m within a certain prescribed error margin of x m then obtaining x i m for each m can require a considerable amount of wall time as well as computational resources indeed every iteration requires the multiplication of a m with a vector this demands that for each m a single implementation of the adj model over the analysis window is run followed by application of b and the tl model to carry this out a total of n c o r e s m processor cores need to be available in parallel as described in more detail in section 3 1 faster convergence to the exact solution x m for each m could be achieved by expanding the space in which x i m is sought with vectors that lie outside k i d m a m such vectors can be generated at no extra computational cost if we similarly to auligné et al 2016 make the assumption that 3 m m m 0 d e f m and consequently a m a 0 d e f a in that case the solution of 2 for different m can be combined into one system of equations for each m the search space will grow by m dimensions per iteration this will allow to approximate x m with the same target accuracy in i i iterations using the block diagonal cg method see section 3 2 this approach will potentially exhibit faster convergence but would still require the same n c o r e s m cores per iteration as an ensemble of regular rbcgs given presently available resources this method would be feasible for our relatively small or wa forecast system but it can become prohibitively expensive for larger forecast systems requiring n c o r e s o 1 0 3 e g kurapov et al 2017 for these systems the new cluster search method is introduced see section 3 3 it also depends on the assumption 3 and involves n s new direction searches at every iteration where 1 n s m these new search directions are generated in parallel requiring n c o r e s n s cores to be available simultaneously it serves as a compromise between rbcg and block diagonal cg 3 1 rbcg using rbcg gürol et al 2014 x i m satisfies 4 x i m k i d m a m x i m x m e w x m e w k i d m a m i e the ith approximation to x m can be found as a linear combination of the vectors spanning the i th krylov space that minimizes the solution error in the e norm w e w t b m a m w 1 2 with b m a m i r 1 2 h m m b m m t h t r 1 2 then x i m is uniquely determined as the e projection of x m on k i d m a m 5 x i m v i v i t b m a m v t 1 v i t b m a m x m v i v i t b m a m v 1 v i t b m d m or alternatively 6 x i m v i t i 1 v i t b v i 1 v i t b m d m where the column space of v i is equal to k i d m a m and t i v i t b m v i 1 v i t b m a m v i here v i and t i depend on m via a m and d m this yields residuals r i m that are by construction b m orthogonal to v i we refer to the column vectors of v i as the search directions as x i m is a projection it is independent of the search directions chosen as long as they span the same space in rbcg i 1 th search direction would be chosen to be e orthogonal i e conjugate to v i here the i 1 th search direction is chosen to be equal to r i m which is b m orthogonal to v i i e v i 1 v i r i m in this case the e orthonormalization is contained in t 1 v i t b m v i 1 in 6 the pseudo code for this method is included in table c 3 3 2 full parallelization block diagonal conjugate gradient method if 3 is assumed then a m a b m b and 2 for the different m can be combined into a single linear system 7 a x d where x x 0 x 1 x m 1 and d d 0 d 1 d m 1 similar to 6 the i th approximation x i can be found as 8 x i v i v i t b a v i 1 v i t b a x v i t i 1 v i t b v i 1 v i t b d where t i v i t b v i 1 v i t b a v i v i d if i 1 and v i v i 1 d a x i if i 1 t v i are independent of m the column space of v i is now k i d a the advantage here compared to rbcg is that the search space for each x i m spanned by v i now has dimension i m instead of i the method results in matrices v i that are no longer b orthogonal but b block orthogonal if v p and v q are two columns of v i then v p t b v q 0 if p q m but might be non zero otherwise the estimates x i retrieved in this way are the same as those found using the block diagonal cg method o leary 1980 with b preconditioning the pseudo code for the block diagonal cg is given in table c 4 3 3 partial parallelization cluster search method in order to expand v i 1 to v i in the block diagonal cg method m applications of a to a vector are necessary this will require n c o r e s m cores and can be prohibitively expensive for large systems here we introduce the cluster search method that requires n s m concurrent applications of a to create the expansion in this case we still look for a solution to 7 with x i still given by 8 but with v i constructed differently in particular we focus on x 0 as it is the control run that will be used to produce the operational forecasts and therefore minimization of the error in x i 0 has top priority to explain how v i is constructed we momentarily assume that the eigendecomposition a u 0 λ 2 u 0 t with u 0 t u 0 i is available and require that i v p t b v q 0 if p q n s similar to block diagonal cg and ii the residual for the control run r i 0 is in the column space of v i 1 as is the case in rbcg for m 0 define v u 0 t r i 0 u 0 t a x ˆ 0 x i 0 v u 0 t d 0 u 0 t a x 0 and u i u 0 a v i t i 1 v i t b v i 1 v i t b u 0 then 9 u 0 v r i 0 r 0 0 a x i 0 r ˆ 0 0 a v i t i 1 v i t b v i 1 v i t b r 0 0 u i v to expand v i to v i 1 we look for n s new search vectors of the form s n u i p n v with n 1 2 n s and p n d d n e d e d t with e d the unit vector in direction d here d n is a subset of 1 2 d such that the union of d 1 d 2 d n s is 1 2 d and d p and d q are disjoint if p q consequently n 1 n s p n v v combined with the equality u 0 v u i v in 9 this then ensures that r i 0 lies within v i 1 thus search vectors of the form s n satisfy requirement ii furthermore 10 v i t b u i v i t b u 0 v i t b a v i t i 1 v i t b v i 1 v i t b u 0 v i t b u 0 v i t b a v i v i t b a v i 1 v i t b u 0 0 this shows that u i is b orthogonal to v i and since the n s new search directions in v i 1 are linear combinations of the column vectors of u i they satisfy requirement i for the following we also need to be able to estimate u 0 t a u i for i 0 u i u 0 and so u 0 t a u 0 λ 2 while for i 0 exact expressions are not directly available instead we observe that the columns of u i are the residuals obtained after trying to find a solution to the linear system a x u 0 in the search space v i this system has the exact solution u 0 λ 2 here we make an ad hoc assumption that these residuals are in good approximation multiples of the columns u 0 i e u i u 0 ξ with ξ diagonal in this case ξ can be estimated as ξ 2 ξ t u 0 t u 0 ξ u i t u i in rbcg x i 0 is defined as the vector in the search space s p a n v i that minimizes the error 4 in the e norm the novel idea behind cluster search is to find a clustering d 1 d 2 d n s and the associated n s new search vectors s n such that the reduction of the expected error x 0 x i 1 0 e is larger than can be achieved using any other clustering using the properties of p n the estimation u i u 0 ξ i and the orthonormality of u 0 we find that the e norm of the expected error for x i 1 0 can be estimated as 11 x 0 x i 0 n 1 n s α n u i p n v e 2 n 1 n s d d n 1 λ d 2 v d 2 2 α n v d λ d 2 1 λ d 2 v d ξ d α n 2 λ d 4 1 λ d 2 v d 2 ξ d 2 where λ d and ξ d are the d th element on the diagonal of λ and ξ correspondingly to find the minimum of this function we set the derivative of 11 as a function of α n to zero and get 12 α n d d n 1 λ d 2 λ d 4 v d 2 ξ d 2 v d v d ξ d λ d 2 d d n 1 λ d 2 λ d 4 v d 2 ξ d 2 1 13 v v ξ d 1 λ d 2 n where n denotes the weighted mean over the cluster d n with weights 1 λ d 2 λ d 4 v d 2 ξ d 2 inserting α n from 13 back into 11 gives that for our guesses of s 1 s n s the error squared obtains a minimum 14 x 0 x i 0 n 1 n s α n u i p n v e 2 n 1 n s d d n 1 λ d 2 v d 2 ξ d 2 λ d 4 v d 2 v d 2 ξ d 2 λ d 4 α n 2 n 1 n s w n var n v d v d ξ d λ d 2 with var n the weighted variance over cluster n and w n d d n 1 λ d 2 λ d 4 v d 2 ξ d 2 the normalization coefficient for the n th cluster the k means clustering algorithm macqueen 1967 can now be used to find a clustering that approximately minimizes 14 once k means produces a clustering s n u i p n v are known and v i 1 v i s 1 s n s in reality the eigenvalue decomposition of a is not available instead it is used that if r and b are true estimates of the observational and background error covariance then a d d t desroziers et al 2005 here denotes the expected value approximations to the eigenvectors and eigenvalues of a are then found by calculating the eigenvalue decomposition of 1 m d 0 d 1 d m 1 d 0 d 1 d m 1 t 1 m d d t d d t the pseudocode for the cluster search method can be found in table c 5 an overview of where the cluster search method enters the cost function minimization algorithm is shown in fig 3 notice that if n s 1 there is only one cluster and requirement i ensures that the new search direction is equal to r i 0 consequently the clustering method reverts to rbcg described in section 3 1 for m 0 if n s m each column vector of u i constitutes its own cluster and hence the new search directions are multiples of the column vectors of u i by construction the column vectors of u i are linear combinations of the i th residuals from the different ensemble members consequently s p a n v i is equal in both the block diagonal cg and cluster search methods in section 5 we will compare convergence rates of rbcg full parallelization and the cluster search methods in the realistic or wa system set up before we can proceed with those we next describe the wind perturbations that will be utilized in the tests of section 5 4 wind perturbations conventionally multiplicative ensemble inflation anderson and anderson 1999 is applied to the ensemble members to compensate for the fact that ensembles generally fail to account for all error sources multiplicative ensemble inflation implicitly assumes that the ensemble underestimates the relative growth of the background errors uniformly throughout the model in the oregon washington region surface currents the strength of the coastal upwelling halpern 1976 huyer 1983 and the location of the fresh water columbia river plume hickey et al 1998 2005 liu et al 2009 all depend on the wind forcing therefore uncertainty in the wind forcing is assumed to be the dominant source of model error in an attempt to better approximate the structure and strength of the background errors we have opted for an approach different from multiplicative ensemble inflation in this approach physically realistic wind perturbations are added to the ensemble members m 1 m 1 and it is left up to the model physics to translate these wind forcing errors into background errors in the ocean state although no comparison with ensemble inflation will be made we will verify later in this manuscript if adding the wind perturbations helps to avoid ensemble variance shrinking alleviating the need for the ensemble inflation hamill and whitaker 2005 li et al 2009 whitaker and hamill 2002 the perturbed wind fields for an ensemble members are generated as 15 w t w n a m t w l t w s t with w n a m t r 2 n w the vector containing the meridional and zonal wind velocity components from the nam model interpolated to the n w roms model surface grid points fields w l t and w s t represent the large scale and small scale wind perturbations respectively for the large scale perturbations we use the empirical orthogonal function eof decomposition of the series w n a m t w n a m t w n a m where the winds are provided every 6 hr from 1 january 2011 00 00 to 31 december 2011 18 00 and w n a m is the mean wind field over this period after the eof decomposition the nam wind field can be written as 16 w n a m t w n a m i 1 n e o f β n a m i t w e o f i w t where w e o f i is the eof mode associated with the i th largest singular value w t t w e o f i 0 for i 1 2 n e o f and β n a m i t are the eof expansion coefficients associated with different eofs and different times here we use 10 eofs n e o f 10 that explain 95 of the variance of w n a m in time similarly to hénaff et al 2009 and vervatis et al 2016 we define the large scale wind perturbation to be 17 w l t i 1 n e o f β l i t w e o f i the expansion coefficients for the large scale wind perturbations β l i with specified standard deviation σ e o f i are generated by an ar1 process 18 β l i t σ e o f i ϵ β i t for t 0 β l i t c β β l i t δ t 1 c β 2 σ e o f i ϵ β i t for t δ t here ϵ β i t is drawn from a standard normal distribution δ t 6 h is the output time step of the nam model and correlation coefficient c β 0 4 milliff et al 2011 the two dominant wind eofs scaled by the standard deviations of their expansion coefficients in the large scale wind errors σ e o f i are shown in fig 4a b the standard deviation of the large scale expansion coefficients β l i is estimated based on the differences between the 6 hourly nam model wind output and the daily 25 km ascat satellite wind product figa saldaa et al 2002 noaa 2011a and ndbc buoy numbers 46089 46015 46050 46029 46041 wind observations noaa 2016 the estimate σ e o f i used is the mode of 19 p σ e o f i 2 w o b s p w s β l ϵ o b s σ e o f 1 2 σ e o f n e o f 2 σ s 2 w o b s d w s d β l d ϵ o b s j 1 j i n e o f d σ e o f j 2 d σ s 2 the conditional probability distribution for σ e o f i 2 given all the scatterometer and buoy wind observations in the model domain in 2011 mapped to the nam model output times vector w o b s for the buoy observations the time mapping is done by selecting the buoy wind measurement closest to the nam model output time while the daily ascat observations are compared with the nam model output time on the same day for which the rmse between ascat observations and nam model output is minimal the conditional probability distribution in 19 is constructed using a bayesian hierarchical model bhm similar to the one used in milliff et al 2011 and wikle et al 2001 the bhm consists of three stages 20 w o b s t j h t j w t r u e t j ϵ o b s t j data stage w t r u e t j w n a m t j w s t j i 1 n e o f w e o f i β l i t j process stage σ o b s 2 σ s 2 σ e o f i 2 parameter stage with the underbar denoting the concatenation of vectors taken at different nam model output times t j into one vector e g w s w s t 1 w s t 2 w s t n t h t j the linear operator that maps the wind velocities at time t j from the model grid to the ascat and buoy observation locations w t r u e t j r 2 n w the unknown true wind field at time t j ϵ o b s t j the measurement error in the ascat ndbc buoy wind observations w s t j r 2 n w the error in the small scale wind field and β l i t j the expansion coefficient for the i th eof mode in the large scale error in the wind field prior distributions of ϵ o b s t j w s t j β l i t j σ s 2 and σ e o f i 2 are assumed to be 21 ϵ o b s t j n ϵ o b s t j 0 σ o b s 2 i w s t j n w s t j 0 σ s 2 i β l i t j n β l i t j 0 σ e o f i 2 σ s 2 i g σ s 2 a s b s σ e o f i 2 i g σ e o f i 2 a e o f i b e o f i where n x μ c is a normal distribution with mean μ and covariance c i g x a b the inverse gamma distribution with parameters a b see appendix d for the details and denotes that a value or vector is randomly drawn from the given distribution any spatial structure in the small scale errors w s t j is neglected based on ascat validation verspeek et al 2013 σ o b s is set to 0 7 m s 1 we pick a e o f i 1 20 n t b e o f i 0 1 a e o f i v a r β n a m i with n t the number of days on which ascat observations are available and v a r β n a m i the variance of the coefficient β i in 16 this gives an a priori distribution for σ e o f i 2 with mode b e o f i 1 a e o f i 0 1 v a r β i these values were chosen such that this mode corresponds to the σ e o f i 2 0 09 v a r β n a m i estimate used by hénaff et al 2009 and vervatis et al 2016 similarly a s and b s are chosen to be a s 2 20 n t n w and b s σ o b s 2 a s given the a priori distribution of σ s 2 with a mode of approximately σ o b s 2 the conditional probability distribution 19 derived using the bhm above is retrieved using a gibbs sampler see appendix d and is shown in fig 5 for the nine dominant eof modes also indicated in fig 5 is the percentage of the variance in the nam wind fields explained by each eof in addition the 9 value of this variance is shown by dashed lines as this value was used in other studies to estimate σ e o f i hénaff et al 2009 vervatis et al 2016 fig 5 shows that the bhm estimate for σ e o f i is higher than the 9 estimate in all modes except mode one the difference between the two estimates increases for increasing eof number for the higher eofs mode 4 and higher which represent smaller spatial scales in the wind field not shown the 9 estimate severely underestimates the contribution of the mode to the error in the wind fields the study of scatterometer wind measurements over the pacific ocean shows that the power spectral density psd of the wind field scales with κ γ where κ is the wave number and γ 2 chin et al 1998 the psd of the meridional nam wind field determined using a hamming window fig 6 solid blue line decreases faster than this for κ 0 3 rad km 1 owing to the limited 12 km nam resolution as the nam model cannot represent the small scale wind field probable small scale wind fields are added to the ensemble members following wikle et al 2001 it is assumed that the small scale wind field in 15 can be decomposed into daubechies 2 wavelets cohen et al 1993 22 w s t γ 0 n 1 9 i γ i n t ψ i n with γ i n t coming from an ar1 process 23 γ i n t c γ γ i n t δ t 1 c γ 2 σ γ n ϵ i n t here n indicates the level of the wavelet with the length scale of the wavelets doubling as the level increases with one and i running over all the wavelets that are available at level n similarly to the large scale wind field we use c γ 0 4 this wavelet approach yields small scale wind perturbations that are local in space and are simultaneously constrained to a limited spectral band by experimentation the standard deviation of σ γ n is chosen such that the dependence of the psd s on the wave number κ of the total ensemble member wind field scales as s κ κ 2 this was achieved by setting σ γ n exp 1 3 n 3 0 5 0 5 tanh 0 4 n 4 and picking γ 0 such that the variance of the wind speed is 0 55 m s 1 2 the psds for the wind fields of the different ensemble members on 8 august 2011 00 00 are shown together with the linear least square log log fit to the ensemble mean psd for κ 0 1 rad km 1 in fig 6 the fit confirms that the psds have indeed the desired p s d κ 2 0 relationship 5 results 5 1 convergence the effectiveness of the cluster search algorithm using a different number of clusters is compared with that of rbcg and block diagonal cg even though the da correction x m is only calculated after the last inner loop iteration i i the cost function 1 can be calculated for each inner loop iteration i if the substitution x i m b m t h t r 1 2 x i m is made in 1 24 j x i m 1 2 x i m t b x i m 1 2 d m b x i m t d m b x i m using 5 we find that b x i m b v i t i 1 v i t b v i 1 v i t b d m which is readily available as b v i is stored using 24 the value of the cost function was calculated prior to each inner loop iteration using the cluster search method with different numbers of clusters 1 n s 40 the cost function normalized by its value at the start of the minimization is shown in fig 7a and b for the windows starting on 31 may and 26 august 2011 respectively increase in the number of clusters n s and correspondingly the number of search directions at each iteration consistently improves the rate at which the cost function decreases as the function of the inner loop iteration number to provide a more quantitative assessment of the advantage of using several search directions in parallel we compute the speed up ratio 25 a n s i 1 i n s where i n s is the number of iterations needed to reach a specific reference level of the cost function j j ref using the cluster method with n s new search directions per iteration i 1 corresponds to rbcg for j ref we choose the value in the case using n s 4 and i 12 iterations as this will be adopted later as the standard setup in the long term system evaluation in part ii of this study pasmans et al submitted the speed up ratios are shown in fig 7c and indicate e g that rbcg n s 1 needs approximately 30 more iterations than cluster search with n s 4 to reach the same level of cost function reduction a fit of a 2nd order polynomial to a dashed black lines in fig 7c shows that the coefficient for the quadratic term is negative and significantly different from zero at a 95 significance level indicating that the additional benefit of adding more clusters diminishes as the number of clusters increases fig 8 compares differences in the initial condition corrections between rbcg n s 1 and the cluster search with n s 4 on 26 august 2011 as the time available to perform da is constrained in operational settings the minimization in both these two cases is terminated after i 12 inner loop iterations the plots on the left show the da correction calculated for sst surface velocity and ssh fields with n s 1 and the plots on the right show the difference between the da corrections in the cases with n s 4 and n s 1 while both methods yield similar large scale corrections they differ in details at the scale of geostrophic eddies for the ensemble members additional dependency on the search space comes from the fact that when cluster search is used the right hand side of 7 is replaced by its b projection on the search space i e on the right hand side of 7 d m is effectively replaced by v i v i t b v i 1 v i t b d m for the control run this is not an issue as by construction d 0 lies in s p a n v 1 but for the ensemble members this could result in the systematic elimination of a part of the errors contained in d m such an elimination would result in da corrections for the ensemble members that are too small and consequently an ensemble spread that will be too large to test whether this is a valid concern the normalized rmse for each observation type i e the rms of the elements of d m associated with one type of observations is calculated and compared with the rmse after taking the b projection of d m on v i with i 12 if d m lies completely in v i as is the case for m 0 the ratio of the latter over the former is one the actual ratio in the experiment is calculated for each ensemble member and each window and the lower bound upper bound and ensemble mean are shown in fig 9 fig 9 shows that as expected using the projection can result in the reduction of the rmse up to 40 however the figure also shows that taking the projection can increase the rmse this paradoxical behaviour emerges because the projection uses the b inner product while in the calculation of the rmse involves the normal euclidean inner product taking the mean of the ratios over all ensemble members shows that increases in the rmses created by the b projection mostly but not completely offset the reductions in rmses and that the net result is a small decrease in the rmse of 1 7 for sst 3 6 for hfr and 2 8 for ssh observations so the projection effect might indeed result in overestimation of the error variances by the ensemble but this effect is small 5 2 error reduction to test whether the system is effective correcting rmse not only for the control run but also for the ensemble members the rmse between the data used in the assimilation and the nonlinear analyses and forecasts is calculated for the ensemble members as shown in fig 10 each line segment represents the rmse in the analysis left point and in the forecast for the subsequent window right point note that the forecast rmse right points is calculated with respect to formally future observations the en4dvar system is effective in reducing the rmse the analysis rmse for the ensemble members exceeds that in experiment no da blue line in less than 4 of the cases forecast rmse for the ensemble members is smaller than no da forecast rmse in 73 of cases the rmses for the ensemble members however are consistently larger than those for the control run green line as they are forced with perturbed wind fields and corrected with perturbed observations however the errors introduced by the perturbations cancel out in the ensemble mean indeed the ensemble mean rmse lies below that of the ensemble members note that in the ensemble kalman filter there is no control run and the ensemble mean is used as the best estimate evensen 1994 we could have used the same approach but the additional communication between the computational nodes required to calculate the mean ocean state would have increased the wall time significantly table 1 shows that the rmse of the control run is on par with that of the ensemble mean with the exception of the rmse in the hfr observations after 14 august 2011 see fig 10b hence our choice to pick the control run over the ensemble mean to produce the forecasts will have only a limited negative impact on the forecast accuracy fig 11 shows the observation model bias in experiment no da the ensemble members the control run and the ensemble mean as the along track mean is removed from both the altimetry observations and their model equivalents prior to assimilation see appendix a the along track mean of both the assimilated altimetry observations and their model equivalents is by construction zero consequently the bias along each track and thus in general is zero and is therefore not included in fig 11 the bias in the hfr observation shows a spread around zero for both the ensemble members as well as the control run forecasts the bias in the forecasts predictions for the sst observations however has a negative tendency with particularly large negative biases during the periods 13 16 may 5 8 june 21 24 july 26 29 august 25 28 september 2011 this results in an overall negative bias over the whole period as shown in table 1 it is indicative of either insufficient surface heating in the model too much mixing in the upper layer or a positive bias in the satellite observations further verification against independent in situ observations is described in part ii 5 3 ensemble reliability if the ensemble statistics are truly representative of the background error statistics the ensemble is said to have high reliability a rank diagram is a diagnostic that can be used to test this hamill 2001 fig 12 shows rank diagrams for the three different types of observations the steps to construct these are as follows a sample each ensemble member forecast at the observation locations and times and add a random observation error b for each observation count the number of ensemble forecasts that are lower than the measured value c by definition this number plus one is the rank of the observation d count the frequency of each rank and divide by the total number of observations to determine the normalized frequency if the ensemble is reliable the rank diagram should be flat hamill 2001 the 95 confidence interval for the normalized frequency of a reliable ensemble is shown as dashed lines in fig 12 the figure shows that the ensemble reliability is different for different fields in the rank diagram for sst fig 12a there is no distinctive peak instead the rank diagram has an upward slope this can be due to the negative bias in the ensemble see fig 11a for the hfr observations mid range ranks are relatively more abundant than the tails see fig 12b this indicates that either the spread in the ensemble is larger than the standard deviation of the hfr background errors or that the observational error magnitude is overestimated the opposite is the case for ssh observations here the u shape fig 12c implies that the forecast ensemble underestimates the magnitude of the background errors finally estimates for the background error and observational covariances used in the da system are compared with estimates obtained from the innovation statistics the relations between innovation statistics and error variances are given by desroziers et al 2005 26 y h m x b 0 d 2 h m b m t h t r d d 27 y h m x b 0 d y h m x b 0 h m x 0 d r d d 28 h m x 0 d y h m x b 0 d h m b m t h t d d where 1 d d is the index of the observation and denotes the expectation value d the d th element of the vector and d d the d th element on the diagonal of a matrix the expectation values on the left hand side of 26 28 are approximated by averaging over all observations of the same type in each window these estimates are shown as blue lines in fig 13 where the top middle and bottom plots are for 26 27 and 28 correspondingly an approximation to the right hand side of 27 is obtained by averaging r d d over all the observations of the same type for the right hand side of 28 an approximation is obtained by doing the same for 29 b e n s d d d e f h m b m t h t d d 1 m 2 m 1 m 1 h m x b m h m x b d 2 h m x b 1 m 1 m 1 m 1 h m x b m error standard deviations based on these estimates are displayed as dashed black lines in fig 13 eqs 26 28 only hold if r and b correctly represent the true observational and background error covariances fig 13 shows to what extent this is the case in our system fig 13g h i show that the ensemble error standard deviation black line grows over time for all three types of observations and hence that the wind perturbations are sufficient to prevent the ensemble spread from collapsing even without ensemble inflation for sst the error standard deviation estimates from the innovation statistics are in agreement with the specified standard deviations see fig 13a d g error standard deviation estimates for hfr observations are consistent up to 1 july 2011 too after 1 july 2011 however the total error standard deviation estimate is too large fig 13b the standard deviations for the observational errors agree fig 13e so the overestimation is due to the fact that after 1 july the ensemble background error standard deviation estimate black line fig 13h is larger than the standard deviation error estimate based on the forecast observation differences blue line in fig 13h this finding is consistent with the shape of the rank histogram in fig 12b indicating overdispersion in the ensemble further investigation not shown here indicates that the difference between the estimates for background error standard deviation can be attributed nearly entirely to the sparse hfr observations taken far offshore depth 2 km closer to the shore depth 1 km where numerous closely spaced hfr observations are available for da to reduce the background error the ensemble estimates for the observational and background error standard deviations and those based on 26 28 show good agreement fig 13b light blue grey initially the total ssh error standard deviation estimate from r and b e n s black line in fig 13c is smaller than the total ssh error standard deviation from the innovations blue line in fig 13c one could put forward the hypothesis that this is due to the fact that the standard deviation from b e n s black line in fig 13i is smaller than the observational error estimate used in the da black line in fig 13f resulting in small ssh da corrections this would be a satisfactory explanation near the shore depth 1 km where ensemble estimates for b and b r remain nearly constant over time fig 13i light blue grey however in general the standard deviation from b e n s keeps increasing over time growing beyond the specified observational error standard deviation of 2 cm and 27 is not satisfied the innovation statistics estimate blue line in fig 13f for the observational error standard deviation continues to lie above the specified standard deviation black line in fig 13f either we have underestimated the observational error standard deviation while specifying r or the structure of the background errors is such that the system cannot remove them effectively 6 conclusions and discussion the development of ensemble based 4dvar systems has been one of the main focus areas in numerical weather prediction similarly there is a rationale to applying ensemble based 4dvar systems for oceanic prediction utility of a static b can be limiting in shelf applications the or wa forecast system used in this study as a test ground for en4dvar is a good example where model error statistics are influenced by high temporal and spatial ocean state variability before en4dvar can be applied successfully to the or wa or any other coastal system many technical details must be worked out as outlined in this manuscript the newly developed en4dvar systems need to go through statistical tests for self consistency using actual observations which help us understand the system behaviour and potential biases in the data critical to a successful implementation of en4dvar for large prediction systems will be the development of time efficient cost function minimization algorithms that take advantage of the massive parallel computer architectures the cluster search method developed and tested in this study explores n s search directions in parallel at each inner loop iteration it was found that using a relatively small number of parallel direction computations n s 4 can reduce the wall clock time by 30 compared to rbcg to achieve the same level of cost function reduction it can be interesting to see in future studies whether combination of this method with saddle point algorithms rao and sandu 2016 fisher and gürol 2017 can deliver an even better 4dvar performance given the same limited number of cores our system did not employ ensemble inflation e g anderson 2001 anderson and anderson 1999 hamill et al 2001 but generated background errors by perturbing the wind fields in the ensemble members in a realistic way although no comparison was made with ensemble inflation and thus it cannot be concluded that wind perturbations are superior to ensemble inflation no collapse of the ensemble spread was observed and therefore wind perturbations alleviated the need for ensemble inflation the common assumption hénaff et al 2009 palmer et al 2009 vervatis et al 2016 that the variance of the wind errors is proportional to the natural time variability was found to be unrealistic this is possibly due to the atmospheric model being less able to represent small scales or due to the inability to represent all possible small scale error modes correctly with a very limited set of eofs instead we found using a bhm that the wind errors increase in proportion to the natural variability as the spatial scale of the wind error decreases based on this we agree with the findings of whitaker and hamill 2012 that additive inflation is more suitable to representing model errors like the errors in wind forcing than multiplicative inflation in which error variances are assumed to be proportional to the temporal variance in the signal even though the en4dvar system was effective in reducing forecast errors compared to the case no da the rank diagram analysis suggests that the ensemble fails to represent the background error statistics perfectly the ensemble overestimates the spread in the surface velocity background errors while it underestimates the spread in the ssh background errors see fig 12 although the rank diagrams in fig 12 are not uniform the bias and the maximum minimum frequency ratio of the diagrams is not exceptionally large compared to the rank diagram analyses in ensemble kalman filter da studies e g cookson hills et al 2017 fujita et al 2007 leeuwenburgh 2007 meng and zhang 2008 this concludes the introduction of the new en4dvar system for the or wa system and evaluation of the error in part ii of this study pasmans et al submitted we will discuss if en4dvar yields better quality predictions than the traditional 4dvar with balance operator background covariance currently used in the operational or wa system declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national oceanic and atmospheric administration noaa united states of america coastal ocean modelling testbed comt grant number na13nos0120139 the noaa quantitative observing system assessment program qosap integrated ocean observing system northwest association of networked ocean observing systems ioos nanoos united states of america grant number na16nos0120019 the national aeronautics and space administration nasa united states of america swot science definition team project grant number nnx13ad89g this work used the extreme science and engineering discovery environment xsede allocation tg oce160001 which is supported by the national science foundation united states of america grant number aci 1548562 the views opinions and findings contained in this paper are those of the authors and should not be construed as an official noaa or u s government position policy or decision we would like to thank the four anonymous reviewers for their very motivating and insightful comments appendix a ssh observations let r be the track number of a set of ssh observations a single pass of a ssh satellite through the domain takes at most several minutes therefore all ssh observations during this pass are assumed to have been made at the same time t here t is chosen to be the mean of the observation times during the pass let x k r t be the location of the k th observation of the ssh along track r at time t define a 1 ζ k r t s s h a x k r t t m d t x k r t l 1 8 t 1 t 0 t 1 a l x k r t cos ω l τ ϕ l x k r t d τ here s s h a x k r t t and m d t x k r t are respectively the detided sea surface height anomaly and mean dynamic topography at location x k r t and time t as provided by the ssh satellite data provider ω l a l x k r t and ϕ l x k r t are the angular frequency amplitude and the phase of the l th tidal component at location x k r t a l and ϕ l are estimated for the m2 s2 n2 k2 k1 o1 p1 q1 tide by regression from the no da model run using t tide pawlowicz et al 2002 t 0 is the maximum of t 12 h and the beginning of the current da window t 1 is the minimum of t 12 h and the end of the current da window and t t 1 t 0 then the ssh observation provided to the da system at time t and location x k r t is a 2 ζ k r t ζ k r t k 1 j ζ j r t with k the total number of ssh observations in track r at time t the innovation corresponding to this observation is then calculated as a 3 d k ζ k r t t 1 t 0 t 1 ζ m o d e l x k r t τ d τ k 1 j t 1 t 0 t 1 ζ m o d e l x j r t τ d τ by applying this procedure we attempt to correct the non tidal ssh slope along each track but not the average level appendix b list of symbols see table b 2 appendix c pseudocode minimization algorithms see tables c 3 c 5 appendix d estimation conditional distribution σ e o f i the integral on the right hand side of the conditional probability distribution σ e o f i 2 19 d 1 p σ e o f i 2 w o b s p s w o b s d w s d β l d ϵ o b s j 1 j i n e o f d σ e o f j 2 d σ s 2 is approximated by drawing 500 samples s w s β l ϵ o b s σ β 1 2 σ β n e o f 2 σ s 2 from the distribution p s w o b s followed by the creation of a normalized histogram of σ e o f i 2 from these samples the sampling is carried out using a gibbs sampler casella and george 1992 and consists of sequentially drawing components of s under the condition that the other components remain constant i e a new sample s w s β l σ e o f 1 2 σ e o f n e o f 2 σ s 2 is constructed from the previous sample s w s β l σ e o f 1 2 σ e o f n e o f 2 σ s 2 by sequentially drawing 1 for each t j d 2 β l t j p β l t j w o b s w s σ e o f 2 σ s 2 p w o b s t j β l t j w s t j σ e o f 2 σ s 2 p β l t j w s t j σ e o f 2 σ s 2 n w o b s t j h t j w n a m t j h t j w β l t j h t j w s t j 0 σ o b s 2 i n β l t j 0 σ e o f 2 n β l t j σ o b s 2 c w t h t j t w o b s t j h t j w n a m t j h t j w s t j c with c 1 σ o b s 2 w t h t j t h t j w σ e o f 2 2 for each t j d 3 w s t j p w s t j w o b s β l σ e o f 2 σ s 2 p w o b s t j w s t j β l t j σ e o f 2 σ s 2 p w s t j β l t j σ e o f 2 σ s 2 n w o b s t j h t j w n a m t j h t j w β l t j h t j w s t j 0 σ o b s 2 i n w s t j 0 σ s 2 i n w s t j σ o b s 2 c h t j t w o b s t j h t j w n a m t j h t j w β l t j c with c 1 σ o b s 2 h t j t h t j σ s 2 i 3 for each i 1 2 n e o f d 4 σ e o f i 2 p σ e o f i 2 w o b s β l w s σ s 2 p β l i σ e o f i 2 p σ e o f i 2 n β l i 0 σ e o f i 2 i g σ e o f i 2 a e o f i b e o f i i g σ e o f i 2 a e o f i 1 2 n t b e o f i 1 2 j β e o f i 2 t j 4 d 5 σ s 2 p σ s 2 w o b s β l w s σ e o f 2 p w s σ s 2 p σ s 2 n w s 0 σ s 2 i i g σ s 2 a s b s i g σ s 2 a s n t n w b s 1 2 j w s 2 t j 2 with w o b s t j the ascat and buoy wind observations at time t j w n a m t j the nam model wind field at time t j interpolated onto the roms model grid h t j the operator that interpolates the wind field to the observation locations at time t j ϵ o b s t j the measurement error in the ascat ndbc buoy wind observations w s t j r 2 n w the error in the small scale wind field β e o f i t j the expansion coefficient of the large scale wind errors at time t j σ the diagonal matrix having σ e o f 1 σ e o f n e o f on its diagonal and w the matrix having w e o f i as its i th column the denotes that a value is randomly drawn from a distribution n x μ c 2 π 1 2 d det c 1 2 exp 1 2 x μ t c 1 x μ is a normal distribution with mean μ and covariance c and i g x a b γ a 1 b a x a 1 exp b x the inverse gamma distribution with scale parameters a b in the second lines of d 2 d 5 bayes theorem has been used in order to insure that the samples generated are uncorrelated 10000 samples are generated with the gibbs sampler but only every 20th sample is retained 
24007,this study investigates the design of unstructured mesh resolution and its impact on the modeling of barotropic tides along the united states east coast and gulf coast ecgc a discrete representation of a computational ocean domain mesh design is necessary due to finite computational resources and an incomplete knowledge of the physical system e g shoreline and seabed topography the selection of mesh resolution impacts both the numerical truncation error and the approximation of the system s physical domain to increase confidence in the design of high resolution coastal ocean meshes and to quantify the efficacy of current mesh design practices an automated mesh generation approach is applied to objectively control resolution placement based on a priori information such as shoreline geometry and seabed topographic features the simulated harmonic tidal elevations for each mesh design are compared to that of a reference solution computed on a 10 8 million vertex mesh of the ecgc region with a minimum shoreline resolution of 50 m our key findings indicate that existing mesh designs that use uniform resolution along the shoreline and slowly varying resolution sizes on the continental shelf inefficiently discretize the computational domain instead a targeted approach that places fine resolution in narrow geometric features along steep topographic gradients and along pronounced submerged estuarine channels while aggressively relaxing resolution elsewhere leads to a mesh with an order of magnitude fewer vertices than the reference solution with comparable accuracy within 3 harmonic elevation amplitudes in 99 of the domain 1 introduction and background two dimensional 2d unstructured triangular meshes are widely used to represent the horizontal domain in the simulation of hydrodynamic processes of ocean shelf and inland coastal water systems in general these variable resolution meshes are used to study a broad spectrum of processes in the coastal ocean from wind waves with periods on the order of seconds to large scale shelf and oceanic circulation with timescales on the order of days to months most commonly barotropically driven long wave processes tides surge and tsunami with periods on the order of minutes to hours are simulated with these meshes this includes the modeling of tidal dynamics blanton et al 2004 chen et al 2011 pringle et al 2018a and the prediction of extreme water levels during high energy events such as tropical and extratropical storms westerink et al 2008 dietrich et al 2010 2011 beardsley et al 2013 chen et al 2013 hope et al 2013 xu et al 2013 zheng et al 2013 xie et al 2016 cyriac et al 2018 critically unstructured triangular meshes facilitate seamless cross scale modeling of the complete long wave spectrum zhang and baptista 2008 zhang et al 2016 pringle et al 2019 unstructured meshes are used to capture the detailed hydrodynamic response driven by the governing physical processes and their interactions with the physical system historically in fluid mechanics approaches to mesh design and adaption have often been based on a posteriori techniques based on the residual of the flow solution on a per element basis e g oden et al 1990 behrens 1998 in coastal modeling an a posteriori analysis has been performed using a formal local truncation error analysis ltea hagen et al 2000 2002 2006 parrish and hagen 2009 with the objective to equalize the truncation error throughout the computational domain in 35 an automatic mesh generation tool was coupled with the ltea method to reduce the total number of vertices in regional scale coastal ocean meshes while maintaining a target solution accuracy however as finer mesh sizes are used to reduce the estimated truncation error it becomes possible to represent new narrower shoreline details that can alter the system s response blanton et al 2004 lynch et al 2004 bacopoulos et al 2011 in fact prior a posteriori approaches have adapted mesh resolution in the interior of the domain and kept the boundary of the domain fixed hagen et al 2006 parrish and hagen 2009 thus while the estimate of the numerical truncation error for a given initial mesh description and shoreline boundary can be minimized the system domain error may persist because critical features i e headlands embayments do not exist in the boundary description and their inclusion may not be detectable by the error indicator furthermore hitherto the generation of this initial mesh description has been often considered a difficult process that could take months to complete hagen et al 2006 depending on user competency experience workflows and technology the aforementioned considerations motivate us to use a feature driven a priori approach in fact for the most part meshes for coastal modeling have been developed using an a priori approach adjusting resolution to match both the physical system s length scale and estimated length scales of the dominant physics e g lyard et al 2006 bunya et al 2010 chen et al 2011 luettich and westerink 2013 kerr et al 2013 chen et al 2016 feature driven a priori approaches have been proposed to automatically design meshes in this manner bilgili et al 2006 conroy et al 2012 roberts et al 2019 nevertheless until now it has been difficult to build a sufficient number of meshes to enable a controlled comparison of the simulated results for realistic coastal ocean hydrodynamic models through the traditional ad hoc and tedious development process however recent advances in automated unstructured mesh generation technology for the ocean remacle and lambrechts 2016 engwirda 2017 candy and pietrzak 2018 avdis et al 2018 roberts et al 2019 now enable well defined repeatable workflows for generating detailed multiscale coastal ocean meshes these approaches alleviate the burden previously associated with the model development steps and ensure that the development process is sufficiently controlled to facilitate inter comparisons between simulation results from a variety of mesh designs with logical perturbations a ubiquitous feature driven a priori meshing criteria for coastal modeling is the wavelength to gridscale heuristic that sizes resolution according to an estimate of depth dependent shallow water wave celerity to maintain constant discretization of the wavelength of the dominant mode westerink et al 1994 lyard et al 2006 greenberg et al 2007 westerink et al 2008 this heuristic produces meshes that contain the finest resolution nearshore element size transitions that vary smoothly and nearly constant resolution across the continental shelf however the wavelength to gridscale heuristic is based on a one dimensional analysis that assumes no bathymetric gradients and thus can neither capture complexity of seabed features like shelf breaks and isolated banks greenberg et al 2007 nor the intricacies of the 2d shoreline further submarine channels that are important to convey flow into the estuarine system can become coarsely discretized with its application while a long legacy of meshes have been built with this heuristic the application of resolution using this approach leads to models with many degrees of freedom if the parameter dictating the number of nodes per wavelength is set to a large value to compensate for inadequately targeting resolution at the aforementioned features consideration of the topographic length scale i e applying finer resolution directly proportional to the seabed depth and inversely proportional to seabed topographic gradient has also been widely conducted lyard et al 2006 chen et al 2016 engwirda 2017 this approach refines the resolution in proximity to the shelf break and submarine ridges and banks which often tend to be co located with large gradients in the solution hannah and wright 1995 in fact the ltea analysis method proposed by hagen et al 2000 2002 2006 demonstrated that the minimization of truncation error tended to produce a distribution of vertices that resembled the application of the topographic length scale representing steep gradients is also useful to capture submarine ridges and rough topography over which internal tides are generated garrett and kunze 2007 this process is often included as a parameterized dissipation process in barotropic tidal models green and nycander 2013 pringle et al 2018a b however a drawback of the topographic length scale is that on the inner shelf the topographic gradient to depth ratio can become large due to topographic irregularities which leads to excessively fine resolution as compared to the length scales of the dominant physics unstructured meshes have a powerful capability to efficiently capture the geometrically complex form of the shoreline and of the complex estuaries and the connected dendritic inland channels but most prior works have not taken full advantage of this capability by applying uniformly fine resolution along shorelines and within inland waterways in regions of interest for instance nomad noaa operational model with adcirc a mesh used for real time predictions of storm surge and tides e g asgs fleming et al 2008 uses uniform coastal resolution of approximately 250 m along all the united states east coast and gulf coasts ecgc technology riverside inc and aecom 2015 other examples of meshes that resolve the shoreline uniformly includes those used in recent long term regional analyses of storm surge and tides in ecgc 1 5 km muis et al 2019 marsooli and lin 2018 and those used for hurricane induced coastal flooding in the northern gulf of mexico 100 m kerr et al 2013 on one hand uniform shoreline resolution ensures that the representation of the inlet back bay system that control coastal inshore hydrodynamics is best represented in the mesh of the specified resolution on the other hand the application of nearly uniform resolution nearshore over resolves many sections of the coastline and inland waters that are straight and geometrically simple leading to a situation where cost constraints then necessitate under resolving narrow and constricted waterways studies in the south atlantic bight have demonstrated that the representation of the estuary system as a whole can alter the morphodynamic feedback between the tides and the shoreline form blanton et al 2004 bacopoulos et al 2011 bacopoulos and hagen 2017 thus beyond applying fine resolution zones nearshore it is often critical to resolve the intricate dendritic inland waters and to quantify the feedback effects from the integrated system these irregular shoreline and inland systems can be efficiently captured using highly variable mesh resolution another consideration for developing unstructured meshes is the rate of element size transitions between zones of variable resolution otherwise referred to as the gradation persson 2006 it is known that element size transitions must be smooth and bounded above by a constant to avoid numerical errors and inaccuracies shewchuk 2002 bilgili et al 2006 in fact the error analysis undertaken by hagen et al 2000 clearly demonstrates that a gradation above 50 will cause odd order error terms to dominate and subsequently degrade a formally second order numerical method to first order while a theoretical upper bound value for the gradation is known the total number of vertices in a coastal ocean discretization can wildly vary depending on the choice of gradation below 50 a large gradation will lead to fewer vertices thus the gradation rate needs to be explored to identify a suggested tighter range of values that efficiently discretizes the physical domain while maintaining accuracy in the simulation of the coastal ocean a common first step in the production of a coastal hydrodynamic model is to assess the simulated accuracy of astronomical tides e g pringle et al 2018a prior to the simulation of extreme sea levels at this initial stage of the model development process the model is calibrated through adjustments to frictional and dissipative parameterizations in order to agree with measured data however when the mesh insufficiently resolves shoreline and seabed features the system s response may become distorted leading to an inability to correctly produce solutions across the entire domain and energy spectrum an example of this would be tuning the model to agree with observations of dominant semi diurnal elevation tidal constituent regionally but this may not lead to a good agreement globally nor for the other tidal constituents instead by gathering knowledge on how tidal solution depends on mesh resolution in realistic coastal modeling problems we can enable efficient and uniformly more accurate mesh designs that can then facilitate more dynamically correct calibrations of friction parameterizations our premise is that the numerical modeling of the circulation and flow of water is largely driven and controlled by the representation of the physical system and the representation of the physical system is integrally related to the mesh sizing functions thus the sizing functions need to be carefully considered for ensuring high fidelity coastal ocean hydrodynamic simulations that have a relatively low associated computational cost this is particularly relevant for operational real time forecast systems in order to be practically computationally feasible many of the previously used a priori mesh size heuristics e g topographic length scale and distance to shoreline have proven useful in practice for producing accurate solutions for tides and storm surges thus we have devised an approach that combines and builds on such mesh size heuristics to variably resolve shoreline geometry seabed topography controlling the geometric expansion of element sizes and capturing submarine channels that convey flow into and out of the estuaries our ultimate goal is to capture the physical system and response with the fewest number of degrees of freedom while preserving the performance of the solution compared to measured data here we apply our approach to the widely studied ecgc region and conduct an in depth analysis of the sensitivity of the barotropic tides to the domain discretization this paper addresses the following two questions a how does the simulation of barotropic tides respond to the representation of shoreline geometry and seabed topography in the ecgc region what are the sources of error and how do these contribute to the measured differences b can we incorporate our results from a to make recommendations for a set of mesh size functions that place resolution according to shoreline geometry and seabed topography to efficiently discretize coastal ocean domains that approximately reproduce simulation results from an extremely well resolved mesh 2 methods data and tools 2 1 ecgc study domain and data the ecgc study domain for this work fig 1 contains a single open ocean boundary along the 60 w meridian which is placed here for geometric simplicity and because it lies in the deep ocean where the tides vary gradually and hence suitable for coupling to global tidal model solutions that are highly accurate in the deep ocean stammer et al 2014 the placement of the open boundary in this way is sufficiently far from the coastal zones to represent tide responses throughout the ecgc domain westerink et al 1994 the domain is classified into four distinct regions as shown in fig 1 along with co tidal and co amplitude lines of the dominant constituents the tides are predominately semi diurnal dominated by the m 2 along the eastern coast of the united states north atlantic na mid atlantic bight mab and south atlantic bight sab in the western half of the gulf of mexico gom the k 1 and o 1 dominate water level variations while the eastern side is mixed diurnal with the m 2 k 1 o 1 and s 2 contributing roughly in equal parts 2 1 1 bathymetric and shoreline datasets the bathymetric data used for this study are primarily based on srtm15 sandwell et al 2014 and supplemented in areas of overlap with the coastal relief model crm amante and eakins 2009 in addition to local 1 3 and 1 9 arc sec ncei topo bathymetric coastal elevation model datasets where available https www ngdc noaa gov mgg coastal coastal html the entire bathymetric dataset was integrated into a final digital elevation model dem that was re sampled on a uniform grid spacing of 3 arc sec 90 m which is equal to the resolution of the crm for srtm15 and the crm the vertical uncertainty in the data is generally larger than the discrepancy between local mean sea level and the navd88 vertical reference datums so no effort was made to rectify the vertical datum for these data however all ncei local and regional datasets were adjusted to local mean sea level using vdatum white and hess 2016 where the transformation was available the horizontal datum of the re sampled dem is in geographic coordinates or wgs84 since the shoreline where land meets the ocean in the temporal mean sense as it exists in nature has a fractal geometry and is constantly evolving due to sedimentation and erosional processes variations in discharge sea level rise and anthropomorphic effects its exact representation may be intractable for the purposes of this work we consider a static version of the shoreline as depicted from the relatively recent 5 10 years old topo bathymetric data used in this study a polyline that approximates the local mean sea level shoreline was extracted using the grass geographical information systems r contour module with a cut parameter of 150 grass development team 2017 while higher quality shoreline vector datasets exist a preference was given to the shoreline extracted from the re sampled dem that was created for this work given that it would produce mesh boundaries that are aligned with the 0 m contour from the data sources in other words this helps to improve the agreement with the location of where the shoreline is when topo bathymetric data is interpolated onto the mesh vertices the discrete shoreline extracted from the dem model can only resolve shoreline length scales down to its horizontal resolution of 3 arc sec approximately 90 m note also that the shoreline is defined at the mean sea level datum hence marsh areas that are flooded during a tidal cycle may not be fully included in the mesh description 2 1 2 tide gauge data harmonic tidal constituent observations at tide gauges in ecgc fig 1 are used in this study to the validate the model simulations on selected meshes the observations are predominantly made up of posted harmonic constituents at 636 national oceanic and atmospheric administration noaa coastal tide gauges https tidesandcurrents noaa gov stations html type harmonic constituents an additional 31 observations located on the continental shelf and in deep water stammer et al 2014 are also included available from ftp ftp legos obs mip fr pub fes2012 project data gauges 2013 12 16 2 2 hydrodynamic model configuration this study uses the advanced circulation model adcirc luettich and westerink 2004 westerink et al 2008 to perform the hydrodynamic simulations of two dimensional 2d barotropic tides adcirc is a continuous galerkin finite element model that solves the primitive continuity equation using the so called generalized wave continuity equation gwce lynch and gray 1979 kinnmark 1988 and a depth averaged momentum equation on an unstructured triangular mesh westerink et al 1992 it is formally a second order solver that discretizes the domain with linear elements we perform all simulations with the following setup the model is forced by astronomical tidal elevation open ocean boundary conditions astronomical tidal equilibrium potential terms and astronomical tidal self attraction and loading sal terms hendershott 1972 in the adcirc solver the time and space advective components of the equations can be excluded from calculations for numerical stability purposes however all terms were included in the calculations further wetting drying was enabled although a minimum depth is enforced on the shoreline of 1 m below sea level to ensure flow through narrow channels on the scale of the minimum resolution note that an implication of forcing the channels depth to minimally 1 m below sea level is that the flux of water into and out the estuary may not be correct as compared to measured data but the small channel will still convey a flux of water and thus not act a barrier wall regardless because the coastline has a fractal form in nature all boundary descriptions will contain this representation error no matter the choice of minimum resolution a constant quadratic bottom friction was used with the standard coefficient of 0 0025 horizontal dissipation was parameterized through a constant lateral eddy viscosity term of 50 m 2 s 1 the gwce mass matrix is solved using an explicit time discretization with mass lumping instead of the consistent implicit method this choice was not found to affect the simulation results at the 2 s simulation time steps we are using here with the courant limited explicit time stepping scheme therefore the explicit method was preferred due to improved computationally efficiency approximately twice as fast tanaka et al 2011 2 3 mesh generation the construction of regional coastal ocean meshes for hydrodynamic simulations in models such as adcirc is an involved process with many degrees of variation in order to analyze how mesh resolution may affect numerical simulations it is vital to have an automated and reproducible workflow to systematically control aspects of the mesh design by reproducible we mean that given the exact same inputs and options the vertex locations of a new instance of the mesh will be approximately the same having vertex elemental densities within a fraction of the target density function and leading to negligible differences between simulation results repeated on various instances of the mesh the approximate similarity of meshes is evidenced in results throughout the manuscript nearly similar mesh designs exhibit the smallest relative differences between their solutions some approaches and tools have been developed recently to make these workflows feasible engwirda 2017 gorman et al 2008 candy and pietrzak 2018 roberts et al 2019 for this work all unstructured meshes were developed with the oceanmesh2d software roberts et al 2019 roberts and pringle 2018 oceanmesh2d is a self contained matlab mesh generation toolkit for the development of 2d unstructured triangular meshes specifically we use version 2 0 of the software which is an extension of v1 0 roberts et al 2019 with support for mesh generation using map projections to ensure that meshes on the sphere conform to earth s curvature and obey user defined resolution requests which are specified in meters any map projection that is featured in the m map mapping package pawlowicz 2018 can be selected a number of meshes are automatically generated in lambert conformal conic projection space using the multiscale meshing approach roberts et al 2019 whereby multiple boxes are used to cover the region roughly indicated by the green and red colored zones in fig 1 a b inside these boxes the minimum resolution l m i n is specified to between 50 m and 250 m depending on the experiment see section 2 4 a larger box covering the whole study region is used to mesh the rest of the domain with a minimum resolution of 1 km that is placed uniformly along the shoreline the result is one seamless unstructured mesh in which the software automatically smooths mesh resolution sizes between regions topo bathymetric data available on a structured grid dem is interpolated onto the mesh vertices using the grid scale averaging approach that is built into the mesh generation software roberts et al 2019 grid scale averaging is used to minimize aliasing of the seabed topography on the mesh vertices that would arise from curve fitting interpolation schemes e g linear interpolation the minimization of sub grid scale topo bathymetric features in the interpolated seabed topography is important in order to study the effect of mesh resolution on the solution 2 4 experimental design in sections 3 1 to 3 4 five experiments are explored to examine the effects of targeted placement of mesh resolution at various seabed and shoreline features according to a mesh size function or constraint table 1 within each experiment three meshes categorized as fine medium and coarse resolution are generated by varying a single mesh size function parameter while holding all other parameters constant note that the variation of mesh sizing parameters is a multi faceted problem and all the parameters interact e g one parameter s value can mask effects of another for example a relatively higher feature size may cause finer resolution in deep offshore features that can be largely influential on the simulation of tides as later shown all meshes require a minimum mesh size and an element to element mesh size gradation rate henceforth referred to as gradation which are set to 50 m uniformly along the shoreline and 15 respectively unless otherwise stated the maximum mesh size is set to 10 km for all meshes the effect of the mesh size functions on the resulting triangulations that are used in the various experiments table 1 are graphically illustrated in fig 2 and described below in the distance function fig 2 a mesh resolution is dictated by the minimum mesh size at the shoreline l m i n and the maximum allowable expansion rate g the variation of l m i n forms experiment 1 the feature size function fig 2 b places mesh resolution according to the width of the geometric feature the width is estimated as two times the sum of the distance from a point in the computational domain to the nearest shoreline point plus the distance from the same point to the nearest medial axis fig 2 c varying the number of elements per geometric feature width forms experiment 2 the gradation function bounds the mesh size transitions on the structured grid that the mesh size function is calculated on which will determine the gradation g on the mesh s triangulation the variation of this parameter only forms experiment 3 the slope function fig 2 e places mesh resolution according to the length of a topographic feature targeting regions of high topographic gradients such as the continental shelf break and slope experiment 4 varies the number of elements per topographic length scale the submarine channel function fig 2 d targets mesh resolution along and near well defined submarine channels such as dredged shipping channels or morphodynamic conveyances within estuaries that are identified through an upslope area calculation using a 1000 dem cell minimum threshold in geographical information systems software experiment 5 varies the number of elements per channel width the channel width is estimated according to the seabed depth near the channel and an assumed slope angle of 30 with the seabed floor see roberts et al 2019 a highly refined reference ref mesh table 1 was generated to act as a proxy for the true solution against which our meshes in the experiments are compared it is stressed here that use of the true solution is strictly limited to the definition that is the solution of the 2d shallow water equations subject to the prescribed boundary conditions ocean depths shoreline boundary bottom friction and open ocean elevations and external forcing it may not however be the true or best solution for tides everywhere in the physical domain as compared to measured data due to uncertainties from the geospatial data open boundary conditions external forcing and the inherent assumptions of the 2d shallow water equations furthermore one of the mesh designs s20 is finer in a local region on the western side of the gom which means that it may be better approximation of the true solution here than the ref in the ref mesh design a set of depth based maximum element size constraints was used and a mesh size gradation of 15 specifically the minimum mesh resolution is 50 m and the maximum resolution was bounded above by 250 m nearshore depth b 50 m 1 km on the continental shelf 50 m b 250 m and 5 km in the deep ocean b 250 m these mesh size constraints are conservative and they represent values that could be accommodated in terms of the total computational cost courant based stability constraint and the resolution of the geospatial data used 90 m the ref mesh contains n 10 746 955 vertices and represents a mesh design that we classify as overly discretized in the sense that as this study will later demonstrate it is possible to substantially reduce the vertex count while maintaining solution accuracy each mesh was used to perform a 122 day tidal simulation to assess the effects on the astronomical tides due to variations in mesh design in these simulations adcirc is forced through the tidal equilibrium potential and sal terms throughout the domain and at the open ocean boundaries with four major semi diurnal m 2 n 2 s 2 k 2 and four major diurnal tidal constituents k 1 o 1 p 1 q 1 open boundary elevations are obtained from tpxo9 1 http volkov oce orst edu tides global html tidal solutions sal terms are obtained from fes2014 tidal loading solutions ftp ftp legos obs mip fr pub fes2012 project data lsa fes2014 in the assessment of the results of these simulations a focus is placed primarily on the variation in the major semi diurnal tide m 2 since this is the predominant tidal constituent along the ecgc the major diurnal tide k 1 is also included where relevant the tidal elevations are decomposed into harmonic constituents using a least squares method at all points within the domain relative errors re in harmonic tidal elevation amplitudes from all sequences of experiments are calculated by linearly interpolating the solution from the ref mesh onto the experiment under consideration subtracting the solutions and then normalizing by ref i e 1 r e a i d a r e f a r e f 100 where a is the harmonic elevation amplitude of the tidal constituent in the experiment id and the ref meshes a focus is placed on the m 2 and k 1 elevation amplitudes as these represent the predominant semi diurnal and diurnal constituents in the ecgc domain section 2 1 the calculation of the re is proceeded in this manner to keep data extrapolation to a minimum so that the same shoreline geometric complexity as depicted in each mesh is present in both solutions under comparison for all differences statistics are only performed on vertices in which the absolute difference from ref exceeds 1 mm or the re between solutions is greater than 0 1 these significance values are considered sufficiently small to ignore for the modeling purposes of barotropic tides along the ecgc which have magnitudes on the order of centimeters to meters the convergence characteristics of the experiments are examined by comparing the cumulative area fraction errors cafe luettich and westerink 1995 hagen et al 2001 of the re statistic along the continental shelf margins of the ecgc region b 250 m where high mesh resolution zones were deployed i e union of the green and red colored zones in fig 1 to be consistent throughout cafe curves only consider errors a i d a r e f that exceed 1 mm or feature a re greater than 0 1 on these cafe plots the y axis value of a point falling on these curves indicates the percent area having a difference greater less than the positive negative value on the x axis a solution that has converged indicates that 99 of the comparison region has a 5 re this definition of convergence may be arbitrary but it represents a statistic that can enable a consistent comparison between solutions and a more stringent accuracy standard than currently set by the u s coastal act 1 1 https www weather gov sti coastalact a challenge with using the cafe plots is that they combine all changes into one curve as a result of this we also identify local changes on spatial maps of re last in section 3 5 we summarize the experiments through the standard deviation of the variation in the re statistics from the ref mesh further the contribution of numerical error versus error in the physical approximation of the domain is illustrated finally based on the results of the five experiments described above we generate mesh designs that combine mesh size functions experiments together to create a mesh with fewer vertices that can approximately mimic the tidal solution accuracy of the ref mesh the following set of statistics are computed to compare the accuracy in terms of error against tide gauge observations section 2 1 2 of the simulated tidal solutions between the ref mesh and the combination mesh designs 2 e 0 5 a o 2 a m 2 2 a o a m cos θ o θ m 1 2 3 b t 1 t e i d e r e f t 1 t e r e f 4 γ 2 v a r e i d e r e f v a r e r e f where e is the complex root mean square error of a tidal constituent for one cycle and account for the amplitude and phase errors a and θ are the amplitudes and phase lags of the tidal constituent respectively the subscripts o and m refer to the observed and modeled values respectively and t in the sum is the total number of tide gauges b is the normalized mean bias and γ 2 is the normalized variance v a r of the discrepancies of e between the ref mesh and a particular mesh combination i d a positive value of b indicates that the mesh combination has on average greater values of e than ref while a negative bias indicates the model is outperforming the ref solution the smaller the value of γ 2 the more similar the mesh s solution is to ref in terms of the distribution of e since a model can be tuned to fit observations locally such as by employing variable bottom friction coefficients in regions where errors arise the main aim here is to minimize γ 2 and b through the effects of mesh resolution on the solution under the assumption that ref is sufficiently resolved for reference the ref solution has a median e for the m 2 of 3 9 cm computed on all 667 tide gauges section 2 1 2 3 results 3 1 resolving the shoreline the representation of the shoreline determines the simulated accuracy in modeling the physical interaction between forcing agents e g tides winds and waves with shoreline geometrical features e g coves headlands back bays and lagoons from a modeling standpoint the shoreline s representation must be simplified to satisfy computational resources by removing fine shoreline details from the mesh s boundary description that are smaller than the minimum mesh resolution however when the shoreline is simplified it alters the approximation of the physical domain and hence possibly the system s tidal response e g molines et al 1989 lynch et al 2004 greenberg et al 2007 this section uses the results from experiments 1 lx and 2 fsx to explore the effects of varying a specified minimum resolution at the shoreline and of varying shoreline resolution according to a feature size estimation respectively a comparative example of the lx and fsx designs along an estuarine region is illustrated in fig 3 as the minimum mesh resolution is coarsened from 50 m to 250 m narrow waterways tributaries and estuaries that are smaller in horizontal length scale than the minimum mesh resolution are automatically removed in the mesh generation process roberts et al 2019 the removal of fine scale shoreline geometry is considered a shoreline approximation error in the sense that the approximate representation of the shoreline departs from its representation in the original shoreline dataset in contrast the feature size approach creates a mesh that represents the physical system accurately by connecting small waterways together in a similar manner to l50 but requiring fewer vertices as resolution can expand in size away from geometric constrictions along the shoreline fig 3 it is important to note that the variation in the minimum element size along the shoreline will impact the sizing of elements near and along adjacent inner and outer shelf seabed topographical features as all the meshes are graded to expand in element size offshore in addition the application of the fs x will lead to finer resolution near more irregular shoreline features considering this more pronounced differences in element sizes will tend to occur between fs x and l x in proximity to shoreline segments that are highly irregular in their form thus besides the obvious impact on the representation of the shoreline via either the l x or fs x design the variations in this experiment also implicitly alter the representation of the inner and outer shelf seabed topographic gradients the shoreline approximation error is quantified by integrating the area enclosed by the polygonal region that defines the mesh boundary s in which the sub script denotes the experiment id 5 a e r r o r s i d s r e f a e r r o r increases geometrically as the minimum shoreline resolution is coarsened from 50 m to 250 m in the lx meshes fig 4 for example a e r r o r 2200 km 2 for l100 increases approximately ten fold to a e r r o r 22 000 km 2 for l250 while the total vertex count reduces from 4 9 million to 0 8 million vertices between l250 and l50 mesh designs in contrast the fsx experiments exhibit no correspondence between total vertex counts and shoreline approximation error and a e r r o r remains small reaching a maximum of approximately 1500 km 2 the fsx design distributes 50 m mesh sizes in narrow waterways and along high curvature shoreline sections while allowing mesh sizes to expand up to 250 m along straighter shoreline segments the predominate variation in vertex counts in the fsx design is the number of vertices per geometric width of the shoreline not the minimum element size thus the fs2 design is capable of preserving a similar amount of shoreline geometry as l50 e g fig 3a c but with approximately two times fewer vertices as is evident in fig 5 the variation in the representation of the shoreline predominately affects the m 2 elevation amplitude in shallow shelf regions 250 m depth range a largely insignificant error 1 mm or 0 1 was observed in the k 1 elevation amplitude not shown the relative m 2 errors re among the lx experiments are greatest for l250 and smallest for l50 fig 5a b demonstrating the improvement of finer resolution large re values are concentrated in estauries in the sab and in the mab around the chesapeake bay and the gulf of maine where large re values of 10 15 are found in the l250 mesh fig 5b in the mab sab and eastern gom shelf zones there is a weak 1 3 deamplification in the m 2 amplitude with the exception of the chesapeake bay estuary which exhibits a pronounced re of 5 10 as the mesh resolution is coarsened from l50 to l250 in general the fsx meshes fig 5c d produce similar relative error patterns to the lx meshes however negative re values are only 1 in the chesapeake and sab for the coarsest lx design fs2 compared to re values in l250 which are approximately 3 here further fs2 reduces the amplification in the gulf of maine by a small amount 1 the western gom shelf region weakly deamplified by 1 3 in the fs8 design but this was not observed in the other lx designs although local differences in re are illustrated in fig 5 the cafe curves demonstrate remarkable similarity in 99 of the comparison zone between the lx and fsx solutions i e above the thick 1 cumulative area line for both the m 2 and k 1 elevation amplitudes fig 6 the cafe curves for the m 2 are asymmetrical and indicate more of the domain has a positive error which is accentuated in the tails below the 1 cumulative area line while all the solutions in this experiment have achieved a converged solution the fs6 and fs8 contain less positive re than the lx designs while the opposite is true for the negative crossing although the difference is marginal 1 2 the relatively coarser l250 4 0 re and fs2 3 9 re mesh designs exhibited only slightly larger positive errors in the m 2 elevation amplitude as compared to l50 and the fs8 design these differences are marginal considering the 4 million total vertex count difference between the fine and coarse mesh designs i e l50 and fs8 vs l250 for the k 1 all meshes have converged solutions to our tolerance and respond far less to alterations in mesh design than the m 2 3 2 mesh size gradation the concept of grading is a key capability of unstructured mesh finite element or finite volume modeling in which coarse elements in the far field grade smoothly into the more finely resolved region of interests where fine resolution is necessary to capture the physical system and or the hydrodynamic response to efficiently discretize regional and global ocean domains this gradation rate between zones of variable resolution can greatly influence the number of vertices in the mesh fig 7 elemental size grading has been based on solution gradients as well as bounding an estimate of the courant number to encourage numerical stability luettich and westerink 1995 however the grade can also be based on geometric criteria by ensuring that neighboring mesh element sizes cannot enlarge too quickly persson 2006 i e the gradation is a bound on the maximum relative increase in edgelength between adjacent elements it is understood from a general modeling point of view that excessive gradation rates lead to triangles with skewed angles containing acute or obtuse angles which can impact the stability and numerical accuracy of the model massey 2015 shewchuk 2002 further the analysis by hagen et al 2000 for one dimensional domains demonstrates that a high gradation value g 0 5 leads to the introduction of odd order truncation error term which lowers the order of the method to first order accurate and or degrades the local global accuracy fundamentally the gradation rate will impact many aspects of the mesh design at once a higher valued mesh size gradation will degrade the approximate representation of the seabed topography by creating comparatively coarser mesh sizes away from the targeted zones of fine resolution as was described in table 1 the meshes that vary the gradation rate utilize a minimum resolution of 50 m along the shoreline l50 note that the mesh generator is bounding the gradation rate above by the user defined parameter value only on the mesh size function and it is assumed that given the convergence of the mesh generator the gradation rate is similarly bounded in the triangulation section 2 4 coarser mesh sizes tend to smooth the interpolation of seabed features onto the mesh vertices and this data interpolation effect can be quantified in the meshes by calculating the overall volume enclosed by the mesh while holding the shoreline boundary fixed i e the surface area of the total mesh is constant thus similar to the shoreline approximation error eq 5 the seabed approximation error is calculated as the absolute difference in total volume from the ref mesh 6 v e r r o r v i d v r e f where v is the total mesh volume for the mesh denoted by id and is calculated as the sum of all the mesh element volumes an element volume is calculated by multiplying the average depth of the element by its area since the ref mesh employs uniform high resolution mesh sizes throughout the nearshore and continental shelf zones cf fig 1 it represents the seabed surface with the smallest approximation error note that the data interpolation approach we are using is a grid scale average section 2 3 and is not a globally conservative interpolation scheme from fig 7 it is apparent that there is a diminishing reduction in the total vertex count of the mesh with increased gradation for the purposes of this study we were not able to explore meshes with gradation greater than 35 due in experiment 3 gx due to the introduction of triangles with very skewed aspect ratios and obtuse and acute angles that created numerical accuracy issues the increase in mesh size gradation from 15 to 35 leads to a highly amplified error pattern in the na region for both m 2 and k 1 constituents as well as along the mab for m 2 fig 8 in the na subdomain gulf of maine the m 2 re is increased from 2 5 for g15 to 10 21 for g35 colors are saturated in fig 8a in which the maximum re is focused on the georges bank in contrast to the response in the m 2 s re the k 1 s re is nearly uniformly degraded from 3 for g15 to 6 for g35 in the na subdomain the m 2 re in the mab sab and eastern gom tends to weakly deamplify by approximately 1 to 5 along the continental shelf zones in contrast to the shoreline approximation experiment a relatively large deamplification of the m 2 re occurs in both the chesapeake bay and delaware bay as the gradation is enlarged to 35 fig 8a b the m 2 re reaches as high as 15 in this region for the g35 experiment colors are saturated in fig 8a as the mesh size gradation grows the tidal elevation amplitudes start to diverge substantially from the ref solution fig 9 in 99 of the comparison zone the g15 mesh has an m 2 error between 1 3 and 3 0 re whereas g35 has between 5 0 and 15 re furthermore the g35 mesh design exhibits between 5 5 and 6 5 k 1 re in the 99 comparison zone which is compared to 3 0 and 0 k 1 re for g15 unlike the shoreline experiment where all meshes converged based on the 5 threshold definition of convergence only the g15 mesh converges for the m 2 constituent and the g15 and g25 meshes converges for k 1 however it is important to note that the tendency of the solution is convergent as the re reduces when the mesh sizes are made finer with lower gradation bounds 3 3 resolution along bathymetric gradients the main motivation for increasing the horizontal resolution in the open ocean is to more accurately represent sharp seabed gradients particularly those that characterize the continental shelf break and slope the representation of these seabed gradients is captured with the topographic length scale sx fig 2 and table 1 the topographic length scale sx is considered a useful mesh heuristic see greenberg et al 2007 for a review to aid in the modeling of shelf break dynamics huthnance 1995 hannah and wright 1995 luettich and westerink 1995 subtidal dynamics loder 1980 chen et al 2016 and internal tide generation processes xing and davies 1998 and their effects on barotropic tides pringle et al 2018a b further hagen et al 2001 have demonstrated that an inadequate prescription of resolution along sharp seabed gradients is a source of numerical truncation error for tidal models however as b 0 the sx meshing criteria fail for some areas as resolution becomes excessively fine in shallow depths and creates element sizes which can lead to numerical instabilities the topographic length scale sx parameter must consider the trade off between the improvement to the solution of barotropic tides and the additional mesh vertex count chen et al 2016 suggested resolution sizes between 3 3 to 6 km to capture the shelf break and 2 km to capture the deep slope in the arctic ocean lyard et al 2006 suggested s15 globally using quadratic finite elements but noted that this value was restricted in its spatial application due to the excessive computational expense it incurred to avoid excessive refinement in our studies we apply a low pass filter to the bathymetry based on the local rossby radius of deformation cf roberts et al 2019 before computing the seabed gradients and bound the courant number to 0 5 for a time step of 2 s furthermore the sx heuristic is only applied where b 50 m to avoid excessive refinement of small scale features in shallow depths these features are instead targeted through the alternative channel function strategy that is presented in section 3 4 from experimentation we have found s20 to be a reasonable upper limit on sx in order to adequately resolve the seabed representation without excessive resolution in experiment 4 sx the vertex count is increased by 4 to 20 over the l50 mesh accompanied by an improvement to the approximation of seabed profile as illustrated along a transect spanning the cross shelf direction in the mab region fig 10 mesh resolution in the vicinity of the shelf break zones is enhanced to approximately 1 2 km and 0 8 km for s5 and s20 respectively a point worth noting is that seabed features exist on the continental shelf break such as the drowned hudson river valley which will otherwise be completely smoothed over without the sx heuristic in comparison without sx resolution is coarser than 8 km close to the maximum resolution size in the vicinity of the shelf break see l50 in fig 10b which tends to shift the break zone shoreward and result in a smoother and more gradual representation of the seabed profile along the transect fig 10c the sx heuristic results in a clear improvement in the depiction of the seabed profile s20 had seabed profile differences of less than 50 m from the ref mesh whereas the seabed profile difference for l50 is as large as 200 m fig 10d the finer resolution along seabed gradients using sx leads to a significant overall reduction in the re pattern associated with the m 2 elevation amplitude in the mab and na subdomains fig 11a c with the m 2 error pattern diminished almost entirely for s20 fig 11c note that although the largest re is co located with the phase convergence zone of the m 2 tidal species in the mab and na domain where the elevation amplitude is zero the re is not confined to solely the amphidromic point and emanates around the entirety of the na subdomain similarly for the k 1 elevation amplitude an approximately 4 re in the na subdomain for the l50 i e s0 mesh is undetectable for any of the sx meshes fig 11d f contrastingly the application of sx in the gom domain tends to introduce differences from the ref mesh rather than reduce them upon inspection the ref is less resolved in parts of the gom bahama banks and the caribbean sea cf fig 1 in comparison to the sx meshes here possibly explaining this result the s20 mesh in particular contains finer resolution than the ref mesh along the shelf break zones of the western gom which is co located with a persistent albeit weak negative re in the m 2 in the s10 and s20 solutions the cafe curves for m 2 and k 1 fig 12 clearly illustrate that increased resolution along seabed gradients leads to a converged solution in 99 of the domain for s5 s10 and s20 according to our definition of convergence 5 the s5 mesh has the largest m 2 error of 2 9 re in 99 of the comparison zone which predominantly corresponds to the errors in the mab and na domains as evident from fig 12 the k 1 was less sensitive to the choice of sx mesh design than m 2 with differences of approximately 3 in 99 of the comparison zone however the s x for the k 1 consistently and substantially by 10 to 15 reduced the spread of the tails in 0 1 of the domain as was illustrated in fig 12 d e f the negative differences for the k 1 in the na and mab domains were consistently reduced with the application of the s x heuristic 3 4 cross sectional representation of estuarine channels estuarine hydrodynamics are controlled by the depth and form together referred to as the morphology of the estuarine seabed dronkers 1986 parker 1991 friedrichs 2010 prandle 2003 thus when designing a model to simulate coastal hydrodynamics it is important to apply sufficient resolution to approximate the nearshore seabed topography in particular coarse mesh resolution in the presence of fine and narrow channelized bed forms will alias the channel s cross sectional profile fig 13 and lead to the inaccurate computation of transports fluxes and frictional resistance molines et al 1989 greenberg et al 2007 in the boarder context of mesh generation techniques for coastal ocean modeling mesh design heuristics that target resolution inversely proportional to seabed s depth e g westerink et al 2008 will also tend to coarsen the resolution in the center of the estuary in the deepest component of the tidal channel thus existing techniques used to build models do not adequately resolve long and narrow channelized bed forms that are critical to conveying water into and throughout inland water systems an automatic mesh size function cx that localizes finer mesh resolution in close proximity to the thalwegs of important estuarine channel morphology was developed as part of the oceanmesh2d meshing software suite roberts et al 2019 an example of a mesh created with the estuarine channel mesh size function cx is illustrated in fig 13 c for the delaware bay estuary located in the mab region with 44 less vertices than ref in this subset of the ecgc the c0 5 mesh represents the cross sectional area of the deepest thalweg in the estuary with the same accuracy in comparison the l50 mesh is only 8 m deep at the thalweg compared to almost 14 m in the ref and c0 5 meshes notice that other less pronounced thalwegs are not captured by c0 5 due to the application of coarser resolution the effects of the estuarine channel mesh size function have been investigated in experiment 5 cx using a mesh size gradation of 35 g35 a higher mesh size gradation motivates the resolution targeting approach because mesh element sizes are relaxed quickly away from the channel thalwegs where finer resolution is applied thus obtaining a mesh with overall fewer vertices than without the targeting approach furthermore a lower mesh size gradation e g 15 would lead to finer resolution in the center of the estuary where the thalweg may be located and may already adequately resolve the channels cross sectional profile the mesh vertex count in the finest cx mesh c1 0 is increased by more than two fold from the g35 mesh to approximately 3 1 million vertices fig 14d f still approximately 60 of the g15 mesh vertex count the refinement of the estuarine channel network primarily impacts the m 2 elevation amplitude solution locally in the estuarine regions of the mab and na subdomains fig 14a c a consistent reduction in m 2 re from the high mesh size gradation solution g35 is observed locally particularly the 5 10 re under prediction error in large estuaries such as the chesapeake bay delaware bay and long island sound the remaining under prediction error in these large estuaries is under 1 2 re for the c1 0 mesh some smaller scale estuarine systems also exhibit reduction to the re for example the large negative error for g35 5 re in barnegat bay cf fig 1 in the mab region is reduced to the point that the error changes sign for c1 0 1 2 re fig 14a c similarly the cafe curves also demonstrate a consistent reduction in m 2 and k 1 re in the comparison zone for the cx meshes and a substantial reduction of re as compared to the solution computed on g35 fig 15 while none of the meshes have converged with the application of resolution along estuarine channels the sequence exhibits convergence despite the approximately 0 7 million vertex count difference between the c0 5 2 4 million vertices in total and c1 0 3 1 million vertices in total meshes their associated solutions perform similarly suggesting diminishing performance gains with finer resolution along estuarine channels in 99 of the comparison zone the c1 0 mesh m 2 error ranges between 1 6 and 5 5 re and 2 8 to 0 re for the k 1 producing non converged solutions for the m 2 but converged solutions for the k 1 nevertheless the narrowing of the error range in 99 of the comparison zone for the cx meshes over that of the g35 mesh 5 0 to 15 for m 2 even though the same 35 gradation is employed is substantial 3 5 summary of experiments 3 5 1 predominant variability a summary of the variation in amplitude errors throughout the ecgc region in response to changes in mesh resolution from all 15 meshes over the five experiments table 1 is summarized by taking the standard deviation σ of re and the dimensional error ae a i d a r e f fig 16 the greatest changes in the m 2 elevation amplitudes are collocated with m 2 phase convergence zones and amphidromic points cf fig 1 and in estuaries such as the chesapeake bay and the delaware bay in the gulf of maine na which is a resonant basin with a large tidal range 2 10 m σ r e is 1 4 and σ a e is well above 2 5 cm for m 2 the k 1 differences in the gulf of maine are also larger than most other regions in the gom which has a small semidiurnal tidal range σ r e is large in the central region around the convergence zone for m 2 but this only corresponds to less than around 2 mm of dimensional variability σ a e is very small in general the k 1 is noticeably less responsive to changes in mesh resolution with σ r e barely exceeding 1 the k 1 exhibits the greatest variation in the na subdomain gulf of maine in large estuaries and throughout most of the gom the relatively small response in the k 1 is to be expected given that it is less energetic and has a longer wavelength than the m 2 and it does not typically exhibit resonance on wide shelves clarke and battisti 1981 3 5 2 numerical error versus physical approximation error an outstanding issue with the results is that the numerical and physical approximation components of error are intertwined both contributing to the re observed in the experiments as the approximation of the bathymetry and shoreline boundary becomes more accurate with the application of finer resolution the study of convergence in the tidal response becomes challenging as new bathymetric and shoreline features emerge from a model design point of view the isolation of the numerical component of the tidal error can provide clarity into how to improve the physical approximation component of error to isolate the numerical error in the tidal harmonics studied here changes in the physical domain approximation were held constant by refining the relatively lightweight l250 mesh so that all triangular edges except for those within 1 of the open ocean boundary were bisected about their midpoints producing four new triangles for every pre existing one following a shape preserving scheme engwirda 2014 the bathymetry from the l250 mesh was linearly interpolated onto this new refined mesh l250r1 ensuring that the approximation of the seabed topography is identical between the two meshes further the bisection of the elements preserves the representation of the shoreline geometrical features between meshes the numerical error was then estimated with richardson extrapolation roache 1994 blain et al 1998 in order to use this approach to estimate numerical truncation error it was first verified that the leading order error terms indeed controlled the numerical convergence i e asymptotic regime spatial errors were found to be much greater than the time discretization errors and the adcirc solver in the current configuration was a second order accurate method in space and time luettich and westerink 2004 the order of convergence was verified to be 2nd order accurate by refining l250r1 once more producing l250r2 the richardson extrapolation base error rebe following roache 1994 is calculated to estimate numerical error with the following formulas 7 r e b e coarse mesh ϵ r n r n 1 r e b e fine mesh ϵ r n 1 n spatial order of adcirc 2 ϵ 100 f l 250 r 1 f l 250 f r e f r x l 250 x l 250 r 1 2 refinement factor where f l 250 and f l 250 r 1 are the solutions computed on the original and refined meshes and f r e f is the solution computed on the reference mesh x l 250 and x l 250 r 1 denote the spatially varying mesh sizes throughout the computational domain the rebe herein the numerical error for the l250 and l250r1 m 2 elevation amplitude is presented in fig 17c d and compared against the total error that was calculated from the ref solution using eq 1 i e re like was performed in the rest of the paper fig 17a b there is a similarity in the numerical and total error estimates particularly in the na subdomain where the magnitude of both errors are 3 5 for the l250 mesh and diminish to 1 2 for the l250r1 mesh however the estimate of the greatest magnitude numerical error is co located with the periphery of the georges bank near sharp seabed topographic gradients while the total error is spread across the entire georges bank in general a weaker reduction in the total error is observed compared to the numerical error in particular the total error is not reduced over the georges bank or along most of the sab and mab coastline fig 17a b however the numerical error is reduced almost everywhere to below the significance threshold for instance the refinement of l250 to l250r1 reduces the numerical error estimate in the chesapeake bay estuary in the mab region markedly however the total error does not diminish in the mab region particularly the chesapeake bay which suggests these regions are more responsive to changes in the physical domain approximation fig 17 overall even though the numerical error has become insignificant 1 2 in magnitude and converged as the mesh has been refined relatively large shoreline and seabed domain approximation errors still remain in the chesapeake bay the long island sound and the georges bank 1 5 thus a method that will reduce the numerical error through an iterative refinement strategy like ltea may still be incapable of improving the accuracy of the solution as compared to observations even if it minimizes the numerical truncation error as it cannot readily incorporate solution responses from unresolved shoreline geometry scales 3 5 3 mesh design combinations the previously described mesh size functions table 1 can be used in combination by taking the minimum of each individual function for each point in a regional or global domain conroy et al 2012 roberts et al 2019 certain combinations of mesh size functions can be regarded as more or less efficient at sufficiently approximating the physical domain for instance if the user were to rely on a low mesh size gradation e g 10 15 the estuarine channel mesh size function becomes far less necessary because elements in proximity to the channel are already close to the resolution at the shoreline based on our resolution targeting approach a sequence of mesh designs with different combinations of mesh size functions all with a high gradation 35 were built with the goal of maintaining the accuracy of tidal solution while significantly reducing the vertex count as compared to the ref mesh combo1 min l 50 s 20 with g 35 employs 50 m resolution everywhere along the shoreline l50 a steep mesh size gradation of 35 g35 and enhanced resolution on seabed gradients s20 a total of 2 3 million vertices combo2 min f s 2 s 20 with g 35 uses feature size function to vary mesh resolution between 50 m and 250 m along the shoreline while maintaining a minimum of two elements across the width of the shoreline fs2 a steep mesh size gradation of 35 g35 and enhanced resolution on seabed gradients s20 a total of 1 1 million vertices combo3 min l 50 s 20 c 0 5 with g 35 uses feature size function to vary mesh resolution between 50 m and 250 m along the shoreline while maintaining a minimum of two elements across the width of the shoreline fs2 a steep mesh size gradation of 35 g35 enhanced resolution on seabed gradients s20 and enhanced resolution along estuarine channel features a total of 1 3 million vertices the idea behind this sequence of mesh combinations combox is to proceed from a more simple design and move towards a more complex design to test the additive effects i e start with uniform shoreline resolution combo1 use variable shoreline resolution combo2 add additional resolution along estuarine channels combo3 combo1 begins with a high gradation rate and a large slope function parameter because of the resolution targeting that we think and which the experimental results support lead to more efficient designs fig 18 highlights this targeting approach by illustrating the resolution distribution for the combo3 mesh similar to the error reduction patterns in experiment 4 using fine resolution 500 1 km along sharp seabed gradients and a 15 gradation cf fig 11 the re in m 2 for all combox meshes is reduced significantly from the g35 mesh primarily in the na and mab subdomains fig 19a c in fact the s20 s cafe curve is largely similar to the combox meshes thus using s20 to resolve high gradient seabed topographic slopes effectively allows for a much higher elemental size expansion rate to conserve computational resources conspicuous positive values of re near the georges bank in proximity to the m 2 s amphidromic point persist but this is reduced from 10 21 for the g35 mesh to under 5 for all combox meshes the improvement to m 2 re for the combox meshes is also reflected in their cafe curves fig 19d which perform similarly to the s20 mesh in 99 of the comparison zone for the negative crossing 1 to 2 re but contain slightly larger re for the positive crossing 3 to 4 re overall the re is substantially reduced from the 16 re positive crossing for the g35 mesh furthermore the resulting pattern of errors against measured harmonic data fig 20 for the combox meshes approaches that of the ref mesh b 0 01 to 0 04 γ 2 0 03 to 0 05 in comparison the positive bias and spread of the errors are significantly greater for the g35 mesh b 0 08 γ 2 0 33 demonstrating substantial improvement in the tidal validation of the mesh with the application of the combinational designs the effect on m 2 re when moving from a uniform shoreline resolution combo1 to variable shoreline resolution combo2 based on the feature size approach in the combination meshes is small fig 19a b differences less than 1 are noticeable in the long island sound delaware estuary and around the georges bank and gulf of maine furthermore the resulting pattern of errors against observations from ref is similar between combo1 and combo2 although the bias has increased to from 0 01 to 0 04 fig 20b c considering that the usage of the fsx shoreline resolution in combo2 leads to 53 fewer vertices than in combo1 a small increase to the bias and variance is expected the effect on m 2 re when additional resolution is placed along important estuarine channels combo3 versus combo2 can be important in localized regions the overall picture as illustrated through the cafe curves fig 19d and the domain wide tide gauge error pattern fig 20 is relatively unaffected as evidenced by the relatively small change in measured statistics predominately the region of positive re over the georges bank and the gulf of maine is increased by approximately 1 when moving to the combo2 and combo3 meshes however re is noticeably reduced in the delaware bay chesapeake bay and long island sound to under 1 re in most areas fig 19b c focusing only on the tide gauges n 108 contained inside the mab estuaries fig 21 the effect of targeting finer resolution along the channels is further highlighted the normalized bias is reduced from a positive bias in combo2 b 0 03 to a negative bias for combo3 b 0 02 inside both estuaries indicating that combo3 performed slightly better than the ref mesh here the normalized spread of the errors γ 2 also reduced but only marginally 4 discussion in coastal ocean modeling applications the shoreline resolution determines the predominate computational expense of the model we explored ways to quantify the effect of simplifying the shoreline s representation in the mesh by coarsening the minimum resolution from 50 m to 250 m and automatically varying the resolution along the shoreline according to the width of shoreline features experiment 2 feature size function coarsening the minimum resolution lx meshes noticeably decreased the total area of the mesh by decimating fine scale shoreline features like embayments headlands and coves leading to a reduction in the total number of vertices up to a factor of five however the associated variation in the tidal elevation amplitudes over most of the domain was comparatively small the relative errors against the ref solution in 99 of the domain did not vary by more than 5 although noticeable differences did occur in the tail of the cafe plots corresponding to highly localized regions experiment 2 demonstrated that the feature size approach fsx preserved the area enclosed by the shoreline of the mesh using the 50 m uniform shoreline resolution see l50 while requiring approximately half the number of vertices further the relative errors from the ref solution for fs2 showed a significant improvement over l250 in the tail comparable to l50 an important point is that the constraints from the sizing functions interact for example the increase in feature size parameter from 2 to 8 improves the representation of nearshore seabed topography by using finer resolution across the width of the shoreline feature but the higher feature size parameter does not improve the ability to resolve the complexity of the shoreline as the minimum element size bound is reached cf fig 4 thus our recommendation is that meshes intended for high resolution tidal modeling to be constructed with a feature size approach also see conroy et al 2012 with maximally two or three vertices across the shoreline s width instead of applying a minimum resolution uniformly along the shoreline bunya et al 2010 kerr et al 2013 note that in the feature size approach a consideration should be taken to make sure that the element sizes along the shoreline cannot become too coarse in this work we applied a five to one ratio upper bound so that the element sizes do not exceed 250 m given that the length scales of the physical processes are still controlled by the proximity to fine scale shoreline geometry here and coarse element sizes nearshore may not be conducive to accurately model other coastal processes that were not considered in this study such as wave setup induced through wave breaking joyce et al 2019 experiment 3 demonstrated how increasing the gradation rate can negatively impact the approximation of seabed topography in the mesh and the simulated accuracy of tidal solutions were highly degraded the mesh with the highest gradation g35 was the worst performing mesh in terms of the m 2 and k 1 relative error values out of all 15 meshes in the five experiments the effect of increasing the gradation is likely to have increased the numerical error hagen et al 2000 in addition to the physical domain approximation error e g representation of seabed topography making the determination of the root cause of the poor performance challenging however experiment 4 clearly demonstrated that placing resolution along seabed gradients 1 km along the continental shelf break and slope improved the accuracy of tidal solutions which is in agreement with prior works luettich and westerink 1995 hagen and parrish 2004 parrish and hagen 2007 chen et al 2016 at the same time increasing the gradation rate coarsened the representation of the continental shelf break as resolution sizes would grow faster from the shoreline thus it is likely that our application of resolution along seabed gradients reduces the numerical error as large gradients in the solution are co located with steep seabed topographic gradients e g hannah and wright 1995 hagen et al 2001 our recommendation is the use of a high value for the slope mesh size function e g s10 s20 in combination with a high gradation rate e g g35 to offset the negative impacts on both error sources while largely reducing the total number of vertices in the mesh experiment 5 demonstrated that the approximation of the seabed topography across estuaries with deep draft channels e g chesapeake bay and delaware bay could be improved by using the estuarine channel mesh size function to place targeted high resolution zones along the submarine channels inside and leading into estuaries in estuaries that are characterized by well defined submarine channels which occupy non trivial portions of the width of the estuary it is important to ensure that adequate resolution is placed along these channels so that the total cross sectional area and local ocean depth minima are preserved indeed progressively placing finer mesh resolution along the estuarine channel network extracted using an upslope area computation on the dem was shown to reduce tidal error metrics as compared to both the reference solution and measured data as inland waterway conveyances are improved and frictional resistance is reduced we remark that other mesh size heuristics such as the slope mesh size function and using finer resolution along the shoreline with a low gradation rate can implicitly but inefficiently capture these submarine channel features thus the application of the estuarine channel mesh size function allows the usage of a higher mesh size gradation so as to focus resolution only on the submarine channels allowing us to more efficiently discretize the estuarine environment we tested the performance of mesh design strategies that involved using a steep mesh size gradation rate g35 in combination with the targeted mesh sizing functions along the shoreline fsx sharp topographic gradients sx and estuarine channel systems cx three combination meshes combox that ranged from 1 1 million to 2 3 million vertices were generated overall all combox meshes performed similarly to the ref mesh both directly and as compared to measured tide gauge data the additive effects of multiple mesh size functions reduced the error metrics largely especially in the comparison to the g35 solution which had a noticeably degraded solution without the usage of other sizing functions in particular the slope function used in the combox sequence echoing our findings from experiment 1 the combo2 mesh utilized a small value of the feature size function parameter fs2 and had approximately half the vertex count of combo1 uniform shoreline resolution with little increase in relative error thus the fs2 is considered an efficient mesh design choice however deep draft channels within estuarine are more likely to be poorly represented with the high gradation g35 and fsx design combination as mesh sizes will become coarser in certain regions depending on the cuspate shape of the shoreline our conclusion is the 15 increase in the total vertex count associated with the addition of the c0 5 component of combo3 to better capture estuarine channels can be considered a good investment particularly since the solution in nearshore estuaries of high importance is improved even to a point beyond the performance of the ref mesh e g fig 21 our results imply that the 250 m bounded blanket resolution applied across the large estuaries in reference solution is coarser and less effective than the targeted resolution that follows the channelized seabed in the c0 5 mesh size function in fact a key drawback of mesh designs that apply uniformly fine zones of resolution throughout regions of similar ocean depths the wavelength to gridscale heuristic e g westerink et al 1994 is that there is less flexibility to more finely capture targeted seabed features and shoreline constrictions due to the baseline expense of the model in many regions the application of targeted refinement can produce more finely resolved solutions in localized areas of importance with far fewer vertices through the combination of the constraints imposed by a set of mesh size functions combox meshes the vertex count was reduced by nearly an order of magnitude from the reference mesh and had a converged solution with tidal error metrics in 99 of the east and gulf coast waters ranging from 2 to 1 for instance combo3 1 3 million vertices had eight times fewer vertices as the reference 10 8 million vertices these results suggest that pre existing operational models may be largely inefficient over discretizing in some areas and under discretizing in others as pre existing models use nearly uniform resolution nearshore and land and following the wavelength to gridscale sizing heuristic offshore for example the hurricane surge operational forecasting system hsofs mesh technology riverside inc and aecom 2015 used in real time predictions employs a minimum shoreline resolution of 250 m and contains 0 75 million underwater vertices which is similar in number to our l250 mesh in contrast the combo3 mesh which spans the same ecgc study region utilizes up to five times finer resolution nearshore 50 m compared to 250 m and up to ten times finer resolution along the continental slope 1 km compared to 10 km with only 1 6 times the total number of underwater vertices than hsofs we highlight that an important first step in the coastal model development procedure is to construct a mesh that minimizes the physical domain approximation error before model tuning occurs vis a vis varying bottom friction other dissipative coefficients viscous models and manually altering ocean depths and shoreline form as was evident in this paper by improving the accuracy of the approximate problem i e the representation of the shoreline and seabed topography as per the available geospatial data used the tidal solutions exhibited convergence towards a reference solution the primary variation in the m 2 cf fig 16 tended to coincide with zones of the ecgc in which the bottom friction coefficient is typically modified szpilka et al 2016 for instance since the chesapeake bay is a long deep non convergent estuary and has a muddy seabed floor the friction coefficient c f is often set to a low value c f 0 001 which is found to improve the tidal solution friedrichs 2010 however our results also indicate that the m 2 tide in the chesapeake estuary is largely sensitive to mesh design with changes around 15 between the mesh design variations explored here cf fig 16 it is thus likely that the bottom friction application procedure may be tuned incorrectly depending on the local mesh design for instance depending on the complexity of the estuarine network in the mesh due to the large spatial scale of this study there are several limitations that have been left to future work for instance riverine inflows have been neglected although it is well understood that river flows can affect tides locally e g bacopoulos et al 2017 however automatic mesh design strategies to incorporate riverine inflows present many new challenges that would otherwise complicate the focus of this manuscript related issues include how to represent high aspect ratio riverine features how to effectively constrain element edges to align with geophysical features and how far to mesh the river above sea level similarly to make the efforts documented in this manuscript computationally feasible a full description of the intertidal zone was not included in the meshes it is possible that for meshing overland the suggested feature size and gradation bounds may become more conservative with a lower gradation rate and more elements across the channel s width as the horizontal length scales often are finer than in the ocean furthermore numerical models are often more prone to instability at wet dry interfaces a remaining impediment to the rapid automatic generation of meshes is the gathering and processing of appropriate and sufficient topo bathymetric datasets and contiguous shoreline segments we stress that the importance of collecting high fidelity geospatial datasets is separate to the main aim of this paper but it is a critically important aspect of developing a high fidelity mesh for coastal ocean circulation modeling as new and hopefully more accurate geospatial datasets become available these meshes can be adapted using the combination of a priori mesh size functions and methodology that was explored in this work ideally if such geospatial datasets require processing to make them useful for automatic mesh generation these will be made openly available for all potential users 5 conclusions a series of controlled unstructured mesh resolution experiments conducted over a broad area of the western atlantic ocean in high resolution 50 m at the ecgc coast and with a physically accurate shoreline boundary has been achieved through an automatic mesh generation approach facilitated by the oceanmesh2d software roberts et al 2019 the sensitivity of the barotropic tidal response to unstructured mesh resolution was investigated by controlling the distribution of mesh sizes according to functions of a priori seabed and shoreline geometry information it is noteworthy to mention that the whole process was scripted and thus automatic using the mesh generator suite all meshes were designed to be numerically stable with a time step of 2 s without requiring post processing hand edits vertex re location element re shaping or bathymetric smoothing or ad hoc limiters 2 2 https wiki adcirc org wiki fort 13 file elemental slope limiter and dissipation attributes this study highlights the need to perform convergence studies to determine the role of mesh resolution on solutions of coastal hydrodynamics we have provided a framework to perform these convergence studies as well as detailing the effect mesh size functions and their parameters have on the solution of surface tides finally we provided suggestions for mesh size function combinations and parameters e g combo3 that efficiently discretize the ecgc domain with minimal mesh resolution errors future work should test these parameters in other real world domains acknowledgments this work was supported by the joseph and nona ahearn endowment at the university of notre dame united states of america and was completed under usdoc noaa award na18oar4590377 oceanmesh2d v2 0 is available from https doi org 10 5281 zenodo 2560555 
24007,this study investigates the design of unstructured mesh resolution and its impact on the modeling of barotropic tides along the united states east coast and gulf coast ecgc a discrete representation of a computational ocean domain mesh design is necessary due to finite computational resources and an incomplete knowledge of the physical system e g shoreline and seabed topography the selection of mesh resolution impacts both the numerical truncation error and the approximation of the system s physical domain to increase confidence in the design of high resolution coastal ocean meshes and to quantify the efficacy of current mesh design practices an automated mesh generation approach is applied to objectively control resolution placement based on a priori information such as shoreline geometry and seabed topographic features the simulated harmonic tidal elevations for each mesh design are compared to that of a reference solution computed on a 10 8 million vertex mesh of the ecgc region with a minimum shoreline resolution of 50 m our key findings indicate that existing mesh designs that use uniform resolution along the shoreline and slowly varying resolution sizes on the continental shelf inefficiently discretize the computational domain instead a targeted approach that places fine resolution in narrow geometric features along steep topographic gradients and along pronounced submerged estuarine channels while aggressively relaxing resolution elsewhere leads to a mesh with an order of magnitude fewer vertices than the reference solution with comparable accuracy within 3 harmonic elevation amplitudes in 99 of the domain 1 introduction and background two dimensional 2d unstructured triangular meshes are widely used to represent the horizontal domain in the simulation of hydrodynamic processes of ocean shelf and inland coastal water systems in general these variable resolution meshes are used to study a broad spectrum of processes in the coastal ocean from wind waves with periods on the order of seconds to large scale shelf and oceanic circulation with timescales on the order of days to months most commonly barotropically driven long wave processes tides surge and tsunami with periods on the order of minutes to hours are simulated with these meshes this includes the modeling of tidal dynamics blanton et al 2004 chen et al 2011 pringle et al 2018a and the prediction of extreme water levels during high energy events such as tropical and extratropical storms westerink et al 2008 dietrich et al 2010 2011 beardsley et al 2013 chen et al 2013 hope et al 2013 xu et al 2013 zheng et al 2013 xie et al 2016 cyriac et al 2018 critically unstructured triangular meshes facilitate seamless cross scale modeling of the complete long wave spectrum zhang and baptista 2008 zhang et al 2016 pringle et al 2019 unstructured meshes are used to capture the detailed hydrodynamic response driven by the governing physical processes and their interactions with the physical system historically in fluid mechanics approaches to mesh design and adaption have often been based on a posteriori techniques based on the residual of the flow solution on a per element basis e g oden et al 1990 behrens 1998 in coastal modeling an a posteriori analysis has been performed using a formal local truncation error analysis ltea hagen et al 2000 2002 2006 parrish and hagen 2009 with the objective to equalize the truncation error throughout the computational domain in 35 an automatic mesh generation tool was coupled with the ltea method to reduce the total number of vertices in regional scale coastal ocean meshes while maintaining a target solution accuracy however as finer mesh sizes are used to reduce the estimated truncation error it becomes possible to represent new narrower shoreline details that can alter the system s response blanton et al 2004 lynch et al 2004 bacopoulos et al 2011 in fact prior a posteriori approaches have adapted mesh resolution in the interior of the domain and kept the boundary of the domain fixed hagen et al 2006 parrish and hagen 2009 thus while the estimate of the numerical truncation error for a given initial mesh description and shoreline boundary can be minimized the system domain error may persist because critical features i e headlands embayments do not exist in the boundary description and their inclusion may not be detectable by the error indicator furthermore hitherto the generation of this initial mesh description has been often considered a difficult process that could take months to complete hagen et al 2006 depending on user competency experience workflows and technology the aforementioned considerations motivate us to use a feature driven a priori approach in fact for the most part meshes for coastal modeling have been developed using an a priori approach adjusting resolution to match both the physical system s length scale and estimated length scales of the dominant physics e g lyard et al 2006 bunya et al 2010 chen et al 2011 luettich and westerink 2013 kerr et al 2013 chen et al 2016 feature driven a priori approaches have been proposed to automatically design meshes in this manner bilgili et al 2006 conroy et al 2012 roberts et al 2019 nevertheless until now it has been difficult to build a sufficient number of meshes to enable a controlled comparison of the simulated results for realistic coastal ocean hydrodynamic models through the traditional ad hoc and tedious development process however recent advances in automated unstructured mesh generation technology for the ocean remacle and lambrechts 2016 engwirda 2017 candy and pietrzak 2018 avdis et al 2018 roberts et al 2019 now enable well defined repeatable workflows for generating detailed multiscale coastal ocean meshes these approaches alleviate the burden previously associated with the model development steps and ensure that the development process is sufficiently controlled to facilitate inter comparisons between simulation results from a variety of mesh designs with logical perturbations a ubiquitous feature driven a priori meshing criteria for coastal modeling is the wavelength to gridscale heuristic that sizes resolution according to an estimate of depth dependent shallow water wave celerity to maintain constant discretization of the wavelength of the dominant mode westerink et al 1994 lyard et al 2006 greenberg et al 2007 westerink et al 2008 this heuristic produces meshes that contain the finest resolution nearshore element size transitions that vary smoothly and nearly constant resolution across the continental shelf however the wavelength to gridscale heuristic is based on a one dimensional analysis that assumes no bathymetric gradients and thus can neither capture complexity of seabed features like shelf breaks and isolated banks greenberg et al 2007 nor the intricacies of the 2d shoreline further submarine channels that are important to convey flow into the estuarine system can become coarsely discretized with its application while a long legacy of meshes have been built with this heuristic the application of resolution using this approach leads to models with many degrees of freedom if the parameter dictating the number of nodes per wavelength is set to a large value to compensate for inadequately targeting resolution at the aforementioned features consideration of the topographic length scale i e applying finer resolution directly proportional to the seabed depth and inversely proportional to seabed topographic gradient has also been widely conducted lyard et al 2006 chen et al 2016 engwirda 2017 this approach refines the resolution in proximity to the shelf break and submarine ridges and banks which often tend to be co located with large gradients in the solution hannah and wright 1995 in fact the ltea analysis method proposed by hagen et al 2000 2002 2006 demonstrated that the minimization of truncation error tended to produce a distribution of vertices that resembled the application of the topographic length scale representing steep gradients is also useful to capture submarine ridges and rough topography over which internal tides are generated garrett and kunze 2007 this process is often included as a parameterized dissipation process in barotropic tidal models green and nycander 2013 pringle et al 2018a b however a drawback of the topographic length scale is that on the inner shelf the topographic gradient to depth ratio can become large due to topographic irregularities which leads to excessively fine resolution as compared to the length scales of the dominant physics unstructured meshes have a powerful capability to efficiently capture the geometrically complex form of the shoreline and of the complex estuaries and the connected dendritic inland channels but most prior works have not taken full advantage of this capability by applying uniformly fine resolution along shorelines and within inland waterways in regions of interest for instance nomad noaa operational model with adcirc a mesh used for real time predictions of storm surge and tides e g asgs fleming et al 2008 uses uniform coastal resolution of approximately 250 m along all the united states east coast and gulf coasts ecgc technology riverside inc and aecom 2015 other examples of meshes that resolve the shoreline uniformly includes those used in recent long term regional analyses of storm surge and tides in ecgc 1 5 km muis et al 2019 marsooli and lin 2018 and those used for hurricane induced coastal flooding in the northern gulf of mexico 100 m kerr et al 2013 on one hand uniform shoreline resolution ensures that the representation of the inlet back bay system that control coastal inshore hydrodynamics is best represented in the mesh of the specified resolution on the other hand the application of nearly uniform resolution nearshore over resolves many sections of the coastline and inland waters that are straight and geometrically simple leading to a situation where cost constraints then necessitate under resolving narrow and constricted waterways studies in the south atlantic bight have demonstrated that the representation of the estuary system as a whole can alter the morphodynamic feedback between the tides and the shoreline form blanton et al 2004 bacopoulos et al 2011 bacopoulos and hagen 2017 thus beyond applying fine resolution zones nearshore it is often critical to resolve the intricate dendritic inland waters and to quantify the feedback effects from the integrated system these irregular shoreline and inland systems can be efficiently captured using highly variable mesh resolution another consideration for developing unstructured meshes is the rate of element size transitions between zones of variable resolution otherwise referred to as the gradation persson 2006 it is known that element size transitions must be smooth and bounded above by a constant to avoid numerical errors and inaccuracies shewchuk 2002 bilgili et al 2006 in fact the error analysis undertaken by hagen et al 2000 clearly demonstrates that a gradation above 50 will cause odd order error terms to dominate and subsequently degrade a formally second order numerical method to first order while a theoretical upper bound value for the gradation is known the total number of vertices in a coastal ocean discretization can wildly vary depending on the choice of gradation below 50 a large gradation will lead to fewer vertices thus the gradation rate needs to be explored to identify a suggested tighter range of values that efficiently discretizes the physical domain while maintaining accuracy in the simulation of the coastal ocean a common first step in the production of a coastal hydrodynamic model is to assess the simulated accuracy of astronomical tides e g pringle et al 2018a prior to the simulation of extreme sea levels at this initial stage of the model development process the model is calibrated through adjustments to frictional and dissipative parameterizations in order to agree with measured data however when the mesh insufficiently resolves shoreline and seabed features the system s response may become distorted leading to an inability to correctly produce solutions across the entire domain and energy spectrum an example of this would be tuning the model to agree with observations of dominant semi diurnal elevation tidal constituent regionally but this may not lead to a good agreement globally nor for the other tidal constituents instead by gathering knowledge on how tidal solution depends on mesh resolution in realistic coastal modeling problems we can enable efficient and uniformly more accurate mesh designs that can then facilitate more dynamically correct calibrations of friction parameterizations our premise is that the numerical modeling of the circulation and flow of water is largely driven and controlled by the representation of the physical system and the representation of the physical system is integrally related to the mesh sizing functions thus the sizing functions need to be carefully considered for ensuring high fidelity coastal ocean hydrodynamic simulations that have a relatively low associated computational cost this is particularly relevant for operational real time forecast systems in order to be practically computationally feasible many of the previously used a priori mesh size heuristics e g topographic length scale and distance to shoreline have proven useful in practice for producing accurate solutions for tides and storm surges thus we have devised an approach that combines and builds on such mesh size heuristics to variably resolve shoreline geometry seabed topography controlling the geometric expansion of element sizes and capturing submarine channels that convey flow into and out of the estuaries our ultimate goal is to capture the physical system and response with the fewest number of degrees of freedom while preserving the performance of the solution compared to measured data here we apply our approach to the widely studied ecgc region and conduct an in depth analysis of the sensitivity of the barotropic tides to the domain discretization this paper addresses the following two questions a how does the simulation of barotropic tides respond to the representation of shoreline geometry and seabed topography in the ecgc region what are the sources of error and how do these contribute to the measured differences b can we incorporate our results from a to make recommendations for a set of mesh size functions that place resolution according to shoreline geometry and seabed topography to efficiently discretize coastal ocean domains that approximately reproduce simulation results from an extremely well resolved mesh 2 methods data and tools 2 1 ecgc study domain and data the ecgc study domain for this work fig 1 contains a single open ocean boundary along the 60 w meridian which is placed here for geometric simplicity and because it lies in the deep ocean where the tides vary gradually and hence suitable for coupling to global tidal model solutions that are highly accurate in the deep ocean stammer et al 2014 the placement of the open boundary in this way is sufficiently far from the coastal zones to represent tide responses throughout the ecgc domain westerink et al 1994 the domain is classified into four distinct regions as shown in fig 1 along with co tidal and co amplitude lines of the dominant constituents the tides are predominately semi diurnal dominated by the m 2 along the eastern coast of the united states north atlantic na mid atlantic bight mab and south atlantic bight sab in the western half of the gulf of mexico gom the k 1 and o 1 dominate water level variations while the eastern side is mixed diurnal with the m 2 k 1 o 1 and s 2 contributing roughly in equal parts 2 1 1 bathymetric and shoreline datasets the bathymetric data used for this study are primarily based on srtm15 sandwell et al 2014 and supplemented in areas of overlap with the coastal relief model crm amante and eakins 2009 in addition to local 1 3 and 1 9 arc sec ncei topo bathymetric coastal elevation model datasets where available https www ngdc noaa gov mgg coastal coastal html the entire bathymetric dataset was integrated into a final digital elevation model dem that was re sampled on a uniform grid spacing of 3 arc sec 90 m which is equal to the resolution of the crm for srtm15 and the crm the vertical uncertainty in the data is generally larger than the discrepancy between local mean sea level and the navd88 vertical reference datums so no effort was made to rectify the vertical datum for these data however all ncei local and regional datasets were adjusted to local mean sea level using vdatum white and hess 2016 where the transformation was available the horizontal datum of the re sampled dem is in geographic coordinates or wgs84 since the shoreline where land meets the ocean in the temporal mean sense as it exists in nature has a fractal geometry and is constantly evolving due to sedimentation and erosional processes variations in discharge sea level rise and anthropomorphic effects its exact representation may be intractable for the purposes of this work we consider a static version of the shoreline as depicted from the relatively recent 5 10 years old topo bathymetric data used in this study a polyline that approximates the local mean sea level shoreline was extracted using the grass geographical information systems r contour module with a cut parameter of 150 grass development team 2017 while higher quality shoreline vector datasets exist a preference was given to the shoreline extracted from the re sampled dem that was created for this work given that it would produce mesh boundaries that are aligned with the 0 m contour from the data sources in other words this helps to improve the agreement with the location of where the shoreline is when topo bathymetric data is interpolated onto the mesh vertices the discrete shoreline extracted from the dem model can only resolve shoreline length scales down to its horizontal resolution of 3 arc sec approximately 90 m note also that the shoreline is defined at the mean sea level datum hence marsh areas that are flooded during a tidal cycle may not be fully included in the mesh description 2 1 2 tide gauge data harmonic tidal constituent observations at tide gauges in ecgc fig 1 are used in this study to the validate the model simulations on selected meshes the observations are predominantly made up of posted harmonic constituents at 636 national oceanic and atmospheric administration noaa coastal tide gauges https tidesandcurrents noaa gov stations html type harmonic constituents an additional 31 observations located on the continental shelf and in deep water stammer et al 2014 are also included available from ftp ftp legos obs mip fr pub fes2012 project data gauges 2013 12 16 2 2 hydrodynamic model configuration this study uses the advanced circulation model adcirc luettich and westerink 2004 westerink et al 2008 to perform the hydrodynamic simulations of two dimensional 2d barotropic tides adcirc is a continuous galerkin finite element model that solves the primitive continuity equation using the so called generalized wave continuity equation gwce lynch and gray 1979 kinnmark 1988 and a depth averaged momentum equation on an unstructured triangular mesh westerink et al 1992 it is formally a second order solver that discretizes the domain with linear elements we perform all simulations with the following setup the model is forced by astronomical tidal elevation open ocean boundary conditions astronomical tidal equilibrium potential terms and astronomical tidal self attraction and loading sal terms hendershott 1972 in the adcirc solver the time and space advective components of the equations can be excluded from calculations for numerical stability purposes however all terms were included in the calculations further wetting drying was enabled although a minimum depth is enforced on the shoreline of 1 m below sea level to ensure flow through narrow channels on the scale of the minimum resolution note that an implication of forcing the channels depth to minimally 1 m below sea level is that the flux of water into and out the estuary may not be correct as compared to measured data but the small channel will still convey a flux of water and thus not act a barrier wall regardless because the coastline has a fractal form in nature all boundary descriptions will contain this representation error no matter the choice of minimum resolution a constant quadratic bottom friction was used with the standard coefficient of 0 0025 horizontal dissipation was parameterized through a constant lateral eddy viscosity term of 50 m 2 s 1 the gwce mass matrix is solved using an explicit time discretization with mass lumping instead of the consistent implicit method this choice was not found to affect the simulation results at the 2 s simulation time steps we are using here with the courant limited explicit time stepping scheme therefore the explicit method was preferred due to improved computationally efficiency approximately twice as fast tanaka et al 2011 2 3 mesh generation the construction of regional coastal ocean meshes for hydrodynamic simulations in models such as adcirc is an involved process with many degrees of variation in order to analyze how mesh resolution may affect numerical simulations it is vital to have an automated and reproducible workflow to systematically control aspects of the mesh design by reproducible we mean that given the exact same inputs and options the vertex locations of a new instance of the mesh will be approximately the same having vertex elemental densities within a fraction of the target density function and leading to negligible differences between simulation results repeated on various instances of the mesh the approximate similarity of meshes is evidenced in results throughout the manuscript nearly similar mesh designs exhibit the smallest relative differences between their solutions some approaches and tools have been developed recently to make these workflows feasible engwirda 2017 gorman et al 2008 candy and pietrzak 2018 roberts et al 2019 for this work all unstructured meshes were developed with the oceanmesh2d software roberts et al 2019 roberts and pringle 2018 oceanmesh2d is a self contained matlab mesh generation toolkit for the development of 2d unstructured triangular meshes specifically we use version 2 0 of the software which is an extension of v1 0 roberts et al 2019 with support for mesh generation using map projections to ensure that meshes on the sphere conform to earth s curvature and obey user defined resolution requests which are specified in meters any map projection that is featured in the m map mapping package pawlowicz 2018 can be selected a number of meshes are automatically generated in lambert conformal conic projection space using the multiscale meshing approach roberts et al 2019 whereby multiple boxes are used to cover the region roughly indicated by the green and red colored zones in fig 1 a b inside these boxes the minimum resolution l m i n is specified to between 50 m and 250 m depending on the experiment see section 2 4 a larger box covering the whole study region is used to mesh the rest of the domain with a minimum resolution of 1 km that is placed uniformly along the shoreline the result is one seamless unstructured mesh in which the software automatically smooths mesh resolution sizes between regions topo bathymetric data available on a structured grid dem is interpolated onto the mesh vertices using the grid scale averaging approach that is built into the mesh generation software roberts et al 2019 grid scale averaging is used to minimize aliasing of the seabed topography on the mesh vertices that would arise from curve fitting interpolation schemes e g linear interpolation the minimization of sub grid scale topo bathymetric features in the interpolated seabed topography is important in order to study the effect of mesh resolution on the solution 2 4 experimental design in sections 3 1 to 3 4 five experiments are explored to examine the effects of targeted placement of mesh resolution at various seabed and shoreline features according to a mesh size function or constraint table 1 within each experiment three meshes categorized as fine medium and coarse resolution are generated by varying a single mesh size function parameter while holding all other parameters constant note that the variation of mesh sizing parameters is a multi faceted problem and all the parameters interact e g one parameter s value can mask effects of another for example a relatively higher feature size may cause finer resolution in deep offshore features that can be largely influential on the simulation of tides as later shown all meshes require a minimum mesh size and an element to element mesh size gradation rate henceforth referred to as gradation which are set to 50 m uniformly along the shoreline and 15 respectively unless otherwise stated the maximum mesh size is set to 10 km for all meshes the effect of the mesh size functions on the resulting triangulations that are used in the various experiments table 1 are graphically illustrated in fig 2 and described below in the distance function fig 2 a mesh resolution is dictated by the minimum mesh size at the shoreline l m i n and the maximum allowable expansion rate g the variation of l m i n forms experiment 1 the feature size function fig 2 b places mesh resolution according to the width of the geometric feature the width is estimated as two times the sum of the distance from a point in the computational domain to the nearest shoreline point plus the distance from the same point to the nearest medial axis fig 2 c varying the number of elements per geometric feature width forms experiment 2 the gradation function bounds the mesh size transitions on the structured grid that the mesh size function is calculated on which will determine the gradation g on the mesh s triangulation the variation of this parameter only forms experiment 3 the slope function fig 2 e places mesh resolution according to the length of a topographic feature targeting regions of high topographic gradients such as the continental shelf break and slope experiment 4 varies the number of elements per topographic length scale the submarine channel function fig 2 d targets mesh resolution along and near well defined submarine channels such as dredged shipping channels or morphodynamic conveyances within estuaries that are identified through an upslope area calculation using a 1000 dem cell minimum threshold in geographical information systems software experiment 5 varies the number of elements per channel width the channel width is estimated according to the seabed depth near the channel and an assumed slope angle of 30 with the seabed floor see roberts et al 2019 a highly refined reference ref mesh table 1 was generated to act as a proxy for the true solution against which our meshes in the experiments are compared it is stressed here that use of the true solution is strictly limited to the definition that is the solution of the 2d shallow water equations subject to the prescribed boundary conditions ocean depths shoreline boundary bottom friction and open ocean elevations and external forcing it may not however be the true or best solution for tides everywhere in the physical domain as compared to measured data due to uncertainties from the geospatial data open boundary conditions external forcing and the inherent assumptions of the 2d shallow water equations furthermore one of the mesh designs s20 is finer in a local region on the western side of the gom which means that it may be better approximation of the true solution here than the ref in the ref mesh design a set of depth based maximum element size constraints was used and a mesh size gradation of 15 specifically the minimum mesh resolution is 50 m and the maximum resolution was bounded above by 250 m nearshore depth b 50 m 1 km on the continental shelf 50 m b 250 m and 5 km in the deep ocean b 250 m these mesh size constraints are conservative and they represent values that could be accommodated in terms of the total computational cost courant based stability constraint and the resolution of the geospatial data used 90 m the ref mesh contains n 10 746 955 vertices and represents a mesh design that we classify as overly discretized in the sense that as this study will later demonstrate it is possible to substantially reduce the vertex count while maintaining solution accuracy each mesh was used to perform a 122 day tidal simulation to assess the effects on the astronomical tides due to variations in mesh design in these simulations adcirc is forced through the tidal equilibrium potential and sal terms throughout the domain and at the open ocean boundaries with four major semi diurnal m 2 n 2 s 2 k 2 and four major diurnal tidal constituents k 1 o 1 p 1 q 1 open boundary elevations are obtained from tpxo9 1 http volkov oce orst edu tides global html tidal solutions sal terms are obtained from fes2014 tidal loading solutions ftp ftp legos obs mip fr pub fes2012 project data lsa fes2014 in the assessment of the results of these simulations a focus is placed primarily on the variation in the major semi diurnal tide m 2 since this is the predominant tidal constituent along the ecgc the major diurnal tide k 1 is also included where relevant the tidal elevations are decomposed into harmonic constituents using a least squares method at all points within the domain relative errors re in harmonic tidal elevation amplitudes from all sequences of experiments are calculated by linearly interpolating the solution from the ref mesh onto the experiment under consideration subtracting the solutions and then normalizing by ref i e 1 r e a i d a r e f a r e f 100 where a is the harmonic elevation amplitude of the tidal constituent in the experiment id and the ref meshes a focus is placed on the m 2 and k 1 elevation amplitudes as these represent the predominant semi diurnal and diurnal constituents in the ecgc domain section 2 1 the calculation of the re is proceeded in this manner to keep data extrapolation to a minimum so that the same shoreline geometric complexity as depicted in each mesh is present in both solutions under comparison for all differences statistics are only performed on vertices in which the absolute difference from ref exceeds 1 mm or the re between solutions is greater than 0 1 these significance values are considered sufficiently small to ignore for the modeling purposes of barotropic tides along the ecgc which have magnitudes on the order of centimeters to meters the convergence characteristics of the experiments are examined by comparing the cumulative area fraction errors cafe luettich and westerink 1995 hagen et al 2001 of the re statistic along the continental shelf margins of the ecgc region b 250 m where high mesh resolution zones were deployed i e union of the green and red colored zones in fig 1 to be consistent throughout cafe curves only consider errors a i d a r e f that exceed 1 mm or feature a re greater than 0 1 on these cafe plots the y axis value of a point falling on these curves indicates the percent area having a difference greater less than the positive negative value on the x axis a solution that has converged indicates that 99 of the comparison region has a 5 re this definition of convergence may be arbitrary but it represents a statistic that can enable a consistent comparison between solutions and a more stringent accuracy standard than currently set by the u s coastal act 1 1 https www weather gov sti coastalact a challenge with using the cafe plots is that they combine all changes into one curve as a result of this we also identify local changes on spatial maps of re last in section 3 5 we summarize the experiments through the standard deviation of the variation in the re statistics from the ref mesh further the contribution of numerical error versus error in the physical approximation of the domain is illustrated finally based on the results of the five experiments described above we generate mesh designs that combine mesh size functions experiments together to create a mesh with fewer vertices that can approximately mimic the tidal solution accuracy of the ref mesh the following set of statistics are computed to compare the accuracy in terms of error against tide gauge observations section 2 1 2 of the simulated tidal solutions between the ref mesh and the combination mesh designs 2 e 0 5 a o 2 a m 2 2 a o a m cos θ o θ m 1 2 3 b t 1 t e i d e r e f t 1 t e r e f 4 γ 2 v a r e i d e r e f v a r e r e f where e is the complex root mean square error of a tidal constituent for one cycle and account for the amplitude and phase errors a and θ are the amplitudes and phase lags of the tidal constituent respectively the subscripts o and m refer to the observed and modeled values respectively and t in the sum is the total number of tide gauges b is the normalized mean bias and γ 2 is the normalized variance v a r of the discrepancies of e between the ref mesh and a particular mesh combination i d a positive value of b indicates that the mesh combination has on average greater values of e than ref while a negative bias indicates the model is outperforming the ref solution the smaller the value of γ 2 the more similar the mesh s solution is to ref in terms of the distribution of e since a model can be tuned to fit observations locally such as by employing variable bottom friction coefficients in regions where errors arise the main aim here is to minimize γ 2 and b through the effects of mesh resolution on the solution under the assumption that ref is sufficiently resolved for reference the ref solution has a median e for the m 2 of 3 9 cm computed on all 667 tide gauges section 2 1 2 3 results 3 1 resolving the shoreline the representation of the shoreline determines the simulated accuracy in modeling the physical interaction between forcing agents e g tides winds and waves with shoreline geometrical features e g coves headlands back bays and lagoons from a modeling standpoint the shoreline s representation must be simplified to satisfy computational resources by removing fine shoreline details from the mesh s boundary description that are smaller than the minimum mesh resolution however when the shoreline is simplified it alters the approximation of the physical domain and hence possibly the system s tidal response e g molines et al 1989 lynch et al 2004 greenberg et al 2007 this section uses the results from experiments 1 lx and 2 fsx to explore the effects of varying a specified minimum resolution at the shoreline and of varying shoreline resolution according to a feature size estimation respectively a comparative example of the lx and fsx designs along an estuarine region is illustrated in fig 3 as the minimum mesh resolution is coarsened from 50 m to 250 m narrow waterways tributaries and estuaries that are smaller in horizontal length scale than the minimum mesh resolution are automatically removed in the mesh generation process roberts et al 2019 the removal of fine scale shoreline geometry is considered a shoreline approximation error in the sense that the approximate representation of the shoreline departs from its representation in the original shoreline dataset in contrast the feature size approach creates a mesh that represents the physical system accurately by connecting small waterways together in a similar manner to l50 but requiring fewer vertices as resolution can expand in size away from geometric constrictions along the shoreline fig 3 it is important to note that the variation in the minimum element size along the shoreline will impact the sizing of elements near and along adjacent inner and outer shelf seabed topographical features as all the meshes are graded to expand in element size offshore in addition the application of the fs x will lead to finer resolution near more irregular shoreline features considering this more pronounced differences in element sizes will tend to occur between fs x and l x in proximity to shoreline segments that are highly irregular in their form thus besides the obvious impact on the representation of the shoreline via either the l x or fs x design the variations in this experiment also implicitly alter the representation of the inner and outer shelf seabed topographic gradients the shoreline approximation error is quantified by integrating the area enclosed by the polygonal region that defines the mesh boundary s in which the sub script denotes the experiment id 5 a e r r o r s i d s r e f a e r r o r increases geometrically as the minimum shoreline resolution is coarsened from 50 m to 250 m in the lx meshes fig 4 for example a e r r o r 2200 km 2 for l100 increases approximately ten fold to a e r r o r 22 000 km 2 for l250 while the total vertex count reduces from 4 9 million to 0 8 million vertices between l250 and l50 mesh designs in contrast the fsx experiments exhibit no correspondence between total vertex counts and shoreline approximation error and a e r r o r remains small reaching a maximum of approximately 1500 km 2 the fsx design distributes 50 m mesh sizes in narrow waterways and along high curvature shoreline sections while allowing mesh sizes to expand up to 250 m along straighter shoreline segments the predominate variation in vertex counts in the fsx design is the number of vertices per geometric width of the shoreline not the minimum element size thus the fs2 design is capable of preserving a similar amount of shoreline geometry as l50 e g fig 3a c but with approximately two times fewer vertices as is evident in fig 5 the variation in the representation of the shoreline predominately affects the m 2 elevation amplitude in shallow shelf regions 250 m depth range a largely insignificant error 1 mm or 0 1 was observed in the k 1 elevation amplitude not shown the relative m 2 errors re among the lx experiments are greatest for l250 and smallest for l50 fig 5a b demonstrating the improvement of finer resolution large re values are concentrated in estauries in the sab and in the mab around the chesapeake bay and the gulf of maine where large re values of 10 15 are found in the l250 mesh fig 5b in the mab sab and eastern gom shelf zones there is a weak 1 3 deamplification in the m 2 amplitude with the exception of the chesapeake bay estuary which exhibits a pronounced re of 5 10 as the mesh resolution is coarsened from l50 to l250 in general the fsx meshes fig 5c d produce similar relative error patterns to the lx meshes however negative re values are only 1 in the chesapeake and sab for the coarsest lx design fs2 compared to re values in l250 which are approximately 3 here further fs2 reduces the amplification in the gulf of maine by a small amount 1 the western gom shelf region weakly deamplified by 1 3 in the fs8 design but this was not observed in the other lx designs although local differences in re are illustrated in fig 5 the cafe curves demonstrate remarkable similarity in 99 of the comparison zone between the lx and fsx solutions i e above the thick 1 cumulative area line for both the m 2 and k 1 elevation amplitudes fig 6 the cafe curves for the m 2 are asymmetrical and indicate more of the domain has a positive error which is accentuated in the tails below the 1 cumulative area line while all the solutions in this experiment have achieved a converged solution the fs6 and fs8 contain less positive re than the lx designs while the opposite is true for the negative crossing although the difference is marginal 1 2 the relatively coarser l250 4 0 re and fs2 3 9 re mesh designs exhibited only slightly larger positive errors in the m 2 elevation amplitude as compared to l50 and the fs8 design these differences are marginal considering the 4 million total vertex count difference between the fine and coarse mesh designs i e l50 and fs8 vs l250 for the k 1 all meshes have converged solutions to our tolerance and respond far less to alterations in mesh design than the m 2 3 2 mesh size gradation the concept of grading is a key capability of unstructured mesh finite element or finite volume modeling in which coarse elements in the far field grade smoothly into the more finely resolved region of interests where fine resolution is necessary to capture the physical system and or the hydrodynamic response to efficiently discretize regional and global ocean domains this gradation rate between zones of variable resolution can greatly influence the number of vertices in the mesh fig 7 elemental size grading has been based on solution gradients as well as bounding an estimate of the courant number to encourage numerical stability luettich and westerink 1995 however the grade can also be based on geometric criteria by ensuring that neighboring mesh element sizes cannot enlarge too quickly persson 2006 i e the gradation is a bound on the maximum relative increase in edgelength between adjacent elements it is understood from a general modeling point of view that excessive gradation rates lead to triangles with skewed angles containing acute or obtuse angles which can impact the stability and numerical accuracy of the model massey 2015 shewchuk 2002 further the analysis by hagen et al 2000 for one dimensional domains demonstrates that a high gradation value g 0 5 leads to the introduction of odd order truncation error term which lowers the order of the method to first order accurate and or degrades the local global accuracy fundamentally the gradation rate will impact many aspects of the mesh design at once a higher valued mesh size gradation will degrade the approximate representation of the seabed topography by creating comparatively coarser mesh sizes away from the targeted zones of fine resolution as was described in table 1 the meshes that vary the gradation rate utilize a minimum resolution of 50 m along the shoreline l50 note that the mesh generator is bounding the gradation rate above by the user defined parameter value only on the mesh size function and it is assumed that given the convergence of the mesh generator the gradation rate is similarly bounded in the triangulation section 2 4 coarser mesh sizes tend to smooth the interpolation of seabed features onto the mesh vertices and this data interpolation effect can be quantified in the meshes by calculating the overall volume enclosed by the mesh while holding the shoreline boundary fixed i e the surface area of the total mesh is constant thus similar to the shoreline approximation error eq 5 the seabed approximation error is calculated as the absolute difference in total volume from the ref mesh 6 v e r r o r v i d v r e f where v is the total mesh volume for the mesh denoted by id and is calculated as the sum of all the mesh element volumes an element volume is calculated by multiplying the average depth of the element by its area since the ref mesh employs uniform high resolution mesh sizes throughout the nearshore and continental shelf zones cf fig 1 it represents the seabed surface with the smallest approximation error note that the data interpolation approach we are using is a grid scale average section 2 3 and is not a globally conservative interpolation scheme from fig 7 it is apparent that there is a diminishing reduction in the total vertex count of the mesh with increased gradation for the purposes of this study we were not able to explore meshes with gradation greater than 35 due in experiment 3 gx due to the introduction of triangles with very skewed aspect ratios and obtuse and acute angles that created numerical accuracy issues the increase in mesh size gradation from 15 to 35 leads to a highly amplified error pattern in the na region for both m 2 and k 1 constituents as well as along the mab for m 2 fig 8 in the na subdomain gulf of maine the m 2 re is increased from 2 5 for g15 to 10 21 for g35 colors are saturated in fig 8a in which the maximum re is focused on the georges bank in contrast to the response in the m 2 s re the k 1 s re is nearly uniformly degraded from 3 for g15 to 6 for g35 in the na subdomain the m 2 re in the mab sab and eastern gom tends to weakly deamplify by approximately 1 to 5 along the continental shelf zones in contrast to the shoreline approximation experiment a relatively large deamplification of the m 2 re occurs in both the chesapeake bay and delaware bay as the gradation is enlarged to 35 fig 8a b the m 2 re reaches as high as 15 in this region for the g35 experiment colors are saturated in fig 8a as the mesh size gradation grows the tidal elevation amplitudes start to diverge substantially from the ref solution fig 9 in 99 of the comparison zone the g15 mesh has an m 2 error between 1 3 and 3 0 re whereas g35 has between 5 0 and 15 re furthermore the g35 mesh design exhibits between 5 5 and 6 5 k 1 re in the 99 comparison zone which is compared to 3 0 and 0 k 1 re for g15 unlike the shoreline experiment where all meshes converged based on the 5 threshold definition of convergence only the g15 mesh converges for the m 2 constituent and the g15 and g25 meshes converges for k 1 however it is important to note that the tendency of the solution is convergent as the re reduces when the mesh sizes are made finer with lower gradation bounds 3 3 resolution along bathymetric gradients the main motivation for increasing the horizontal resolution in the open ocean is to more accurately represent sharp seabed gradients particularly those that characterize the continental shelf break and slope the representation of these seabed gradients is captured with the topographic length scale sx fig 2 and table 1 the topographic length scale sx is considered a useful mesh heuristic see greenberg et al 2007 for a review to aid in the modeling of shelf break dynamics huthnance 1995 hannah and wright 1995 luettich and westerink 1995 subtidal dynamics loder 1980 chen et al 2016 and internal tide generation processes xing and davies 1998 and their effects on barotropic tides pringle et al 2018a b further hagen et al 2001 have demonstrated that an inadequate prescription of resolution along sharp seabed gradients is a source of numerical truncation error for tidal models however as b 0 the sx meshing criteria fail for some areas as resolution becomes excessively fine in shallow depths and creates element sizes which can lead to numerical instabilities the topographic length scale sx parameter must consider the trade off between the improvement to the solution of barotropic tides and the additional mesh vertex count chen et al 2016 suggested resolution sizes between 3 3 to 6 km to capture the shelf break and 2 km to capture the deep slope in the arctic ocean lyard et al 2006 suggested s15 globally using quadratic finite elements but noted that this value was restricted in its spatial application due to the excessive computational expense it incurred to avoid excessive refinement in our studies we apply a low pass filter to the bathymetry based on the local rossby radius of deformation cf roberts et al 2019 before computing the seabed gradients and bound the courant number to 0 5 for a time step of 2 s furthermore the sx heuristic is only applied where b 50 m to avoid excessive refinement of small scale features in shallow depths these features are instead targeted through the alternative channel function strategy that is presented in section 3 4 from experimentation we have found s20 to be a reasonable upper limit on sx in order to adequately resolve the seabed representation without excessive resolution in experiment 4 sx the vertex count is increased by 4 to 20 over the l50 mesh accompanied by an improvement to the approximation of seabed profile as illustrated along a transect spanning the cross shelf direction in the mab region fig 10 mesh resolution in the vicinity of the shelf break zones is enhanced to approximately 1 2 km and 0 8 km for s5 and s20 respectively a point worth noting is that seabed features exist on the continental shelf break such as the drowned hudson river valley which will otherwise be completely smoothed over without the sx heuristic in comparison without sx resolution is coarser than 8 km close to the maximum resolution size in the vicinity of the shelf break see l50 in fig 10b which tends to shift the break zone shoreward and result in a smoother and more gradual representation of the seabed profile along the transect fig 10c the sx heuristic results in a clear improvement in the depiction of the seabed profile s20 had seabed profile differences of less than 50 m from the ref mesh whereas the seabed profile difference for l50 is as large as 200 m fig 10d the finer resolution along seabed gradients using sx leads to a significant overall reduction in the re pattern associated with the m 2 elevation amplitude in the mab and na subdomains fig 11a c with the m 2 error pattern diminished almost entirely for s20 fig 11c note that although the largest re is co located with the phase convergence zone of the m 2 tidal species in the mab and na domain where the elevation amplitude is zero the re is not confined to solely the amphidromic point and emanates around the entirety of the na subdomain similarly for the k 1 elevation amplitude an approximately 4 re in the na subdomain for the l50 i e s0 mesh is undetectable for any of the sx meshes fig 11d f contrastingly the application of sx in the gom domain tends to introduce differences from the ref mesh rather than reduce them upon inspection the ref is less resolved in parts of the gom bahama banks and the caribbean sea cf fig 1 in comparison to the sx meshes here possibly explaining this result the s20 mesh in particular contains finer resolution than the ref mesh along the shelf break zones of the western gom which is co located with a persistent albeit weak negative re in the m 2 in the s10 and s20 solutions the cafe curves for m 2 and k 1 fig 12 clearly illustrate that increased resolution along seabed gradients leads to a converged solution in 99 of the domain for s5 s10 and s20 according to our definition of convergence 5 the s5 mesh has the largest m 2 error of 2 9 re in 99 of the comparison zone which predominantly corresponds to the errors in the mab and na domains as evident from fig 12 the k 1 was less sensitive to the choice of sx mesh design than m 2 with differences of approximately 3 in 99 of the comparison zone however the s x for the k 1 consistently and substantially by 10 to 15 reduced the spread of the tails in 0 1 of the domain as was illustrated in fig 12 d e f the negative differences for the k 1 in the na and mab domains were consistently reduced with the application of the s x heuristic 3 4 cross sectional representation of estuarine channels estuarine hydrodynamics are controlled by the depth and form together referred to as the morphology of the estuarine seabed dronkers 1986 parker 1991 friedrichs 2010 prandle 2003 thus when designing a model to simulate coastal hydrodynamics it is important to apply sufficient resolution to approximate the nearshore seabed topography in particular coarse mesh resolution in the presence of fine and narrow channelized bed forms will alias the channel s cross sectional profile fig 13 and lead to the inaccurate computation of transports fluxes and frictional resistance molines et al 1989 greenberg et al 2007 in the boarder context of mesh generation techniques for coastal ocean modeling mesh design heuristics that target resolution inversely proportional to seabed s depth e g westerink et al 2008 will also tend to coarsen the resolution in the center of the estuary in the deepest component of the tidal channel thus existing techniques used to build models do not adequately resolve long and narrow channelized bed forms that are critical to conveying water into and throughout inland water systems an automatic mesh size function cx that localizes finer mesh resolution in close proximity to the thalwegs of important estuarine channel morphology was developed as part of the oceanmesh2d meshing software suite roberts et al 2019 an example of a mesh created with the estuarine channel mesh size function cx is illustrated in fig 13 c for the delaware bay estuary located in the mab region with 44 less vertices than ref in this subset of the ecgc the c0 5 mesh represents the cross sectional area of the deepest thalweg in the estuary with the same accuracy in comparison the l50 mesh is only 8 m deep at the thalweg compared to almost 14 m in the ref and c0 5 meshes notice that other less pronounced thalwegs are not captured by c0 5 due to the application of coarser resolution the effects of the estuarine channel mesh size function have been investigated in experiment 5 cx using a mesh size gradation of 35 g35 a higher mesh size gradation motivates the resolution targeting approach because mesh element sizes are relaxed quickly away from the channel thalwegs where finer resolution is applied thus obtaining a mesh with overall fewer vertices than without the targeting approach furthermore a lower mesh size gradation e g 15 would lead to finer resolution in the center of the estuary where the thalweg may be located and may already adequately resolve the channels cross sectional profile the mesh vertex count in the finest cx mesh c1 0 is increased by more than two fold from the g35 mesh to approximately 3 1 million vertices fig 14d f still approximately 60 of the g15 mesh vertex count the refinement of the estuarine channel network primarily impacts the m 2 elevation amplitude solution locally in the estuarine regions of the mab and na subdomains fig 14a c a consistent reduction in m 2 re from the high mesh size gradation solution g35 is observed locally particularly the 5 10 re under prediction error in large estuaries such as the chesapeake bay delaware bay and long island sound the remaining under prediction error in these large estuaries is under 1 2 re for the c1 0 mesh some smaller scale estuarine systems also exhibit reduction to the re for example the large negative error for g35 5 re in barnegat bay cf fig 1 in the mab region is reduced to the point that the error changes sign for c1 0 1 2 re fig 14a c similarly the cafe curves also demonstrate a consistent reduction in m 2 and k 1 re in the comparison zone for the cx meshes and a substantial reduction of re as compared to the solution computed on g35 fig 15 while none of the meshes have converged with the application of resolution along estuarine channels the sequence exhibits convergence despite the approximately 0 7 million vertex count difference between the c0 5 2 4 million vertices in total and c1 0 3 1 million vertices in total meshes their associated solutions perform similarly suggesting diminishing performance gains with finer resolution along estuarine channels in 99 of the comparison zone the c1 0 mesh m 2 error ranges between 1 6 and 5 5 re and 2 8 to 0 re for the k 1 producing non converged solutions for the m 2 but converged solutions for the k 1 nevertheless the narrowing of the error range in 99 of the comparison zone for the cx meshes over that of the g35 mesh 5 0 to 15 for m 2 even though the same 35 gradation is employed is substantial 3 5 summary of experiments 3 5 1 predominant variability a summary of the variation in amplitude errors throughout the ecgc region in response to changes in mesh resolution from all 15 meshes over the five experiments table 1 is summarized by taking the standard deviation σ of re and the dimensional error ae a i d a r e f fig 16 the greatest changes in the m 2 elevation amplitudes are collocated with m 2 phase convergence zones and amphidromic points cf fig 1 and in estuaries such as the chesapeake bay and the delaware bay in the gulf of maine na which is a resonant basin with a large tidal range 2 10 m σ r e is 1 4 and σ a e is well above 2 5 cm for m 2 the k 1 differences in the gulf of maine are also larger than most other regions in the gom which has a small semidiurnal tidal range σ r e is large in the central region around the convergence zone for m 2 but this only corresponds to less than around 2 mm of dimensional variability σ a e is very small in general the k 1 is noticeably less responsive to changes in mesh resolution with σ r e barely exceeding 1 the k 1 exhibits the greatest variation in the na subdomain gulf of maine in large estuaries and throughout most of the gom the relatively small response in the k 1 is to be expected given that it is less energetic and has a longer wavelength than the m 2 and it does not typically exhibit resonance on wide shelves clarke and battisti 1981 3 5 2 numerical error versus physical approximation error an outstanding issue with the results is that the numerical and physical approximation components of error are intertwined both contributing to the re observed in the experiments as the approximation of the bathymetry and shoreline boundary becomes more accurate with the application of finer resolution the study of convergence in the tidal response becomes challenging as new bathymetric and shoreline features emerge from a model design point of view the isolation of the numerical component of the tidal error can provide clarity into how to improve the physical approximation component of error to isolate the numerical error in the tidal harmonics studied here changes in the physical domain approximation were held constant by refining the relatively lightweight l250 mesh so that all triangular edges except for those within 1 of the open ocean boundary were bisected about their midpoints producing four new triangles for every pre existing one following a shape preserving scheme engwirda 2014 the bathymetry from the l250 mesh was linearly interpolated onto this new refined mesh l250r1 ensuring that the approximation of the seabed topography is identical between the two meshes further the bisection of the elements preserves the representation of the shoreline geometrical features between meshes the numerical error was then estimated with richardson extrapolation roache 1994 blain et al 1998 in order to use this approach to estimate numerical truncation error it was first verified that the leading order error terms indeed controlled the numerical convergence i e asymptotic regime spatial errors were found to be much greater than the time discretization errors and the adcirc solver in the current configuration was a second order accurate method in space and time luettich and westerink 2004 the order of convergence was verified to be 2nd order accurate by refining l250r1 once more producing l250r2 the richardson extrapolation base error rebe following roache 1994 is calculated to estimate numerical error with the following formulas 7 r e b e coarse mesh ϵ r n r n 1 r e b e fine mesh ϵ r n 1 n spatial order of adcirc 2 ϵ 100 f l 250 r 1 f l 250 f r e f r x l 250 x l 250 r 1 2 refinement factor where f l 250 and f l 250 r 1 are the solutions computed on the original and refined meshes and f r e f is the solution computed on the reference mesh x l 250 and x l 250 r 1 denote the spatially varying mesh sizes throughout the computational domain the rebe herein the numerical error for the l250 and l250r1 m 2 elevation amplitude is presented in fig 17c d and compared against the total error that was calculated from the ref solution using eq 1 i e re like was performed in the rest of the paper fig 17a b there is a similarity in the numerical and total error estimates particularly in the na subdomain where the magnitude of both errors are 3 5 for the l250 mesh and diminish to 1 2 for the l250r1 mesh however the estimate of the greatest magnitude numerical error is co located with the periphery of the georges bank near sharp seabed topographic gradients while the total error is spread across the entire georges bank in general a weaker reduction in the total error is observed compared to the numerical error in particular the total error is not reduced over the georges bank or along most of the sab and mab coastline fig 17a b however the numerical error is reduced almost everywhere to below the significance threshold for instance the refinement of l250 to l250r1 reduces the numerical error estimate in the chesapeake bay estuary in the mab region markedly however the total error does not diminish in the mab region particularly the chesapeake bay which suggests these regions are more responsive to changes in the physical domain approximation fig 17 overall even though the numerical error has become insignificant 1 2 in magnitude and converged as the mesh has been refined relatively large shoreline and seabed domain approximation errors still remain in the chesapeake bay the long island sound and the georges bank 1 5 thus a method that will reduce the numerical error through an iterative refinement strategy like ltea may still be incapable of improving the accuracy of the solution as compared to observations even if it minimizes the numerical truncation error as it cannot readily incorporate solution responses from unresolved shoreline geometry scales 3 5 3 mesh design combinations the previously described mesh size functions table 1 can be used in combination by taking the minimum of each individual function for each point in a regional or global domain conroy et al 2012 roberts et al 2019 certain combinations of mesh size functions can be regarded as more or less efficient at sufficiently approximating the physical domain for instance if the user were to rely on a low mesh size gradation e g 10 15 the estuarine channel mesh size function becomes far less necessary because elements in proximity to the channel are already close to the resolution at the shoreline based on our resolution targeting approach a sequence of mesh designs with different combinations of mesh size functions all with a high gradation 35 were built with the goal of maintaining the accuracy of tidal solution while significantly reducing the vertex count as compared to the ref mesh combo1 min l 50 s 20 with g 35 employs 50 m resolution everywhere along the shoreline l50 a steep mesh size gradation of 35 g35 and enhanced resolution on seabed gradients s20 a total of 2 3 million vertices combo2 min f s 2 s 20 with g 35 uses feature size function to vary mesh resolution between 50 m and 250 m along the shoreline while maintaining a minimum of two elements across the width of the shoreline fs2 a steep mesh size gradation of 35 g35 and enhanced resolution on seabed gradients s20 a total of 1 1 million vertices combo3 min l 50 s 20 c 0 5 with g 35 uses feature size function to vary mesh resolution between 50 m and 250 m along the shoreline while maintaining a minimum of two elements across the width of the shoreline fs2 a steep mesh size gradation of 35 g35 enhanced resolution on seabed gradients s20 and enhanced resolution along estuarine channel features a total of 1 3 million vertices the idea behind this sequence of mesh combinations combox is to proceed from a more simple design and move towards a more complex design to test the additive effects i e start with uniform shoreline resolution combo1 use variable shoreline resolution combo2 add additional resolution along estuarine channels combo3 combo1 begins with a high gradation rate and a large slope function parameter because of the resolution targeting that we think and which the experimental results support lead to more efficient designs fig 18 highlights this targeting approach by illustrating the resolution distribution for the combo3 mesh similar to the error reduction patterns in experiment 4 using fine resolution 500 1 km along sharp seabed gradients and a 15 gradation cf fig 11 the re in m 2 for all combox meshes is reduced significantly from the g35 mesh primarily in the na and mab subdomains fig 19a c in fact the s20 s cafe curve is largely similar to the combox meshes thus using s20 to resolve high gradient seabed topographic slopes effectively allows for a much higher elemental size expansion rate to conserve computational resources conspicuous positive values of re near the georges bank in proximity to the m 2 s amphidromic point persist but this is reduced from 10 21 for the g35 mesh to under 5 for all combox meshes the improvement to m 2 re for the combox meshes is also reflected in their cafe curves fig 19d which perform similarly to the s20 mesh in 99 of the comparison zone for the negative crossing 1 to 2 re but contain slightly larger re for the positive crossing 3 to 4 re overall the re is substantially reduced from the 16 re positive crossing for the g35 mesh furthermore the resulting pattern of errors against measured harmonic data fig 20 for the combox meshes approaches that of the ref mesh b 0 01 to 0 04 γ 2 0 03 to 0 05 in comparison the positive bias and spread of the errors are significantly greater for the g35 mesh b 0 08 γ 2 0 33 demonstrating substantial improvement in the tidal validation of the mesh with the application of the combinational designs the effect on m 2 re when moving from a uniform shoreline resolution combo1 to variable shoreline resolution combo2 based on the feature size approach in the combination meshes is small fig 19a b differences less than 1 are noticeable in the long island sound delaware estuary and around the georges bank and gulf of maine furthermore the resulting pattern of errors against observations from ref is similar between combo1 and combo2 although the bias has increased to from 0 01 to 0 04 fig 20b c considering that the usage of the fsx shoreline resolution in combo2 leads to 53 fewer vertices than in combo1 a small increase to the bias and variance is expected the effect on m 2 re when additional resolution is placed along important estuarine channels combo3 versus combo2 can be important in localized regions the overall picture as illustrated through the cafe curves fig 19d and the domain wide tide gauge error pattern fig 20 is relatively unaffected as evidenced by the relatively small change in measured statistics predominately the region of positive re over the georges bank and the gulf of maine is increased by approximately 1 when moving to the combo2 and combo3 meshes however re is noticeably reduced in the delaware bay chesapeake bay and long island sound to under 1 re in most areas fig 19b c focusing only on the tide gauges n 108 contained inside the mab estuaries fig 21 the effect of targeting finer resolution along the channels is further highlighted the normalized bias is reduced from a positive bias in combo2 b 0 03 to a negative bias for combo3 b 0 02 inside both estuaries indicating that combo3 performed slightly better than the ref mesh here the normalized spread of the errors γ 2 also reduced but only marginally 4 discussion in coastal ocean modeling applications the shoreline resolution determines the predominate computational expense of the model we explored ways to quantify the effect of simplifying the shoreline s representation in the mesh by coarsening the minimum resolution from 50 m to 250 m and automatically varying the resolution along the shoreline according to the width of shoreline features experiment 2 feature size function coarsening the minimum resolution lx meshes noticeably decreased the total area of the mesh by decimating fine scale shoreline features like embayments headlands and coves leading to a reduction in the total number of vertices up to a factor of five however the associated variation in the tidal elevation amplitudes over most of the domain was comparatively small the relative errors against the ref solution in 99 of the domain did not vary by more than 5 although noticeable differences did occur in the tail of the cafe plots corresponding to highly localized regions experiment 2 demonstrated that the feature size approach fsx preserved the area enclosed by the shoreline of the mesh using the 50 m uniform shoreline resolution see l50 while requiring approximately half the number of vertices further the relative errors from the ref solution for fs2 showed a significant improvement over l250 in the tail comparable to l50 an important point is that the constraints from the sizing functions interact for example the increase in feature size parameter from 2 to 8 improves the representation of nearshore seabed topography by using finer resolution across the width of the shoreline feature but the higher feature size parameter does not improve the ability to resolve the complexity of the shoreline as the minimum element size bound is reached cf fig 4 thus our recommendation is that meshes intended for high resolution tidal modeling to be constructed with a feature size approach also see conroy et al 2012 with maximally two or three vertices across the shoreline s width instead of applying a minimum resolution uniformly along the shoreline bunya et al 2010 kerr et al 2013 note that in the feature size approach a consideration should be taken to make sure that the element sizes along the shoreline cannot become too coarse in this work we applied a five to one ratio upper bound so that the element sizes do not exceed 250 m given that the length scales of the physical processes are still controlled by the proximity to fine scale shoreline geometry here and coarse element sizes nearshore may not be conducive to accurately model other coastal processes that were not considered in this study such as wave setup induced through wave breaking joyce et al 2019 experiment 3 demonstrated how increasing the gradation rate can negatively impact the approximation of seabed topography in the mesh and the simulated accuracy of tidal solutions were highly degraded the mesh with the highest gradation g35 was the worst performing mesh in terms of the m 2 and k 1 relative error values out of all 15 meshes in the five experiments the effect of increasing the gradation is likely to have increased the numerical error hagen et al 2000 in addition to the physical domain approximation error e g representation of seabed topography making the determination of the root cause of the poor performance challenging however experiment 4 clearly demonstrated that placing resolution along seabed gradients 1 km along the continental shelf break and slope improved the accuracy of tidal solutions which is in agreement with prior works luettich and westerink 1995 hagen and parrish 2004 parrish and hagen 2007 chen et al 2016 at the same time increasing the gradation rate coarsened the representation of the continental shelf break as resolution sizes would grow faster from the shoreline thus it is likely that our application of resolution along seabed gradients reduces the numerical error as large gradients in the solution are co located with steep seabed topographic gradients e g hannah and wright 1995 hagen et al 2001 our recommendation is the use of a high value for the slope mesh size function e g s10 s20 in combination with a high gradation rate e g g35 to offset the negative impacts on both error sources while largely reducing the total number of vertices in the mesh experiment 5 demonstrated that the approximation of the seabed topography across estuaries with deep draft channels e g chesapeake bay and delaware bay could be improved by using the estuarine channel mesh size function to place targeted high resolution zones along the submarine channels inside and leading into estuaries in estuaries that are characterized by well defined submarine channels which occupy non trivial portions of the width of the estuary it is important to ensure that adequate resolution is placed along these channels so that the total cross sectional area and local ocean depth minima are preserved indeed progressively placing finer mesh resolution along the estuarine channel network extracted using an upslope area computation on the dem was shown to reduce tidal error metrics as compared to both the reference solution and measured data as inland waterway conveyances are improved and frictional resistance is reduced we remark that other mesh size heuristics such as the slope mesh size function and using finer resolution along the shoreline with a low gradation rate can implicitly but inefficiently capture these submarine channel features thus the application of the estuarine channel mesh size function allows the usage of a higher mesh size gradation so as to focus resolution only on the submarine channels allowing us to more efficiently discretize the estuarine environment we tested the performance of mesh design strategies that involved using a steep mesh size gradation rate g35 in combination with the targeted mesh sizing functions along the shoreline fsx sharp topographic gradients sx and estuarine channel systems cx three combination meshes combox that ranged from 1 1 million to 2 3 million vertices were generated overall all combox meshes performed similarly to the ref mesh both directly and as compared to measured tide gauge data the additive effects of multiple mesh size functions reduced the error metrics largely especially in the comparison to the g35 solution which had a noticeably degraded solution without the usage of other sizing functions in particular the slope function used in the combox sequence echoing our findings from experiment 1 the combo2 mesh utilized a small value of the feature size function parameter fs2 and had approximately half the vertex count of combo1 uniform shoreline resolution with little increase in relative error thus the fs2 is considered an efficient mesh design choice however deep draft channels within estuarine are more likely to be poorly represented with the high gradation g35 and fsx design combination as mesh sizes will become coarser in certain regions depending on the cuspate shape of the shoreline our conclusion is the 15 increase in the total vertex count associated with the addition of the c0 5 component of combo3 to better capture estuarine channels can be considered a good investment particularly since the solution in nearshore estuaries of high importance is improved even to a point beyond the performance of the ref mesh e g fig 21 our results imply that the 250 m bounded blanket resolution applied across the large estuaries in reference solution is coarser and less effective than the targeted resolution that follows the channelized seabed in the c0 5 mesh size function in fact a key drawback of mesh designs that apply uniformly fine zones of resolution throughout regions of similar ocean depths the wavelength to gridscale heuristic e g westerink et al 1994 is that there is less flexibility to more finely capture targeted seabed features and shoreline constrictions due to the baseline expense of the model in many regions the application of targeted refinement can produce more finely resolved solutions in localized areas of importance with far fewer vertices through the combination of the constraints imposed by a set of mesh size functions combox meshes the vertex count was reduced by nearly an order of magnitude from the reference mesh and had a converged solution with tidal error metrics in 99 of the east and gulf coast waters ranging from 2 to 1 for instance combo3 1 3 million vertices had eight times fewer vertices as the reference 10 8 million vertices these results suggest that pre existing operational models may be largely inefficient over discretizing in some areas and under discretizing in others as pre existing models use nearly uniform resolution nearshore and land and following the wavelength to gridscale sizing heuristic offshore for example the hurricane surge operational forecasting system hsofs mesh technology riverside inc and aecom 2015 used in real time predictions employs a minimum shoreline resolution of 250 m and contains 0 75 million underwater vertices which is similar in number to our l250 mesh in contrast the combo3 mesh which spans the same ecgc study region utilizes up to five times finer resolution nearshore 50 m compared to 250 m and up to ten times finer resolution along the continental slope 1 km compared to 10 km with only 1 6 times the total number of underwater vertices than hsofs we highlight that an important first step in the coastal model development procedure is to construct a mesh that minimizes the physical domain approximation error before model tuning occurs vis a vis varying bottom friction other dissipative coefficients viscous models and manually altering ocean depths and shoreline form as was evident in this paper by improving the accuracy of the approximate problem i e the representation of the shoreline and seabed topography as per the available geospatial data used the tidal solutions exhibited convergence towards a reference solution the primary variation in the m 2 cf fig 16 tended to coincide with zones of the ecgc in which the bottom friction coefficient is typically modified szpilka et al 2016 for instance since the chesapeake bay is a long deep non convergent estuary and has a muddy seabed floor the friction coefficient c f is often set to a low value c f 0 001 which is found to improve the tidal solution friedrichs 2010 however our results also indicate that the m 2 tide in the chesapeake estuary is largely sensitive to mesh design with changes around 15 between the mesh design variations explored here cf fig 16 it is thus likely that the bottom friction application procedure may be tuned incorrectly depending on the local mesh design for instance depending on the complexity of the estuarine network in the mesh due to the large spatial scale of this study there are several limitations that have been left to future work for instance riverine inflows have been neglected although it is well understood that river flows can affect tides locally e g bacopoulos et al 2017 however automatic mesh design strategies to incorporate riverine inflows present many new challenges that would otherwise complicate the focus of this manuscript related issues include how to represent high aspect ratio riverine features how to effectively constrain element edges to align with geophysical features and how far to mesh the river above sea level similarly to make the efforts documented in this manuscript computationally feasible a full description of the intertidal zone was not included in the meshes it is possible that for meshing overland the suggested feature size and gradation bounds may become more conservative with a lower gradation rate and more elements across the channel s width as the horizontal length scales often are finer than in the ocean furthermore numerical models are often more prone to instability at wet dry interfaces a remaining impediment to the rapid automatic generation of meshes is the gathering and processing of appropriate and sufficient topo bathymetric datasets and contiguous shoreline segments we stress that the importance of collecting high fidelity geospatial datasets is separate to the main aim of this paper but it is a critically important aspect of developing a high fidelity mesh for coastal ocean circulation modeling as new and hopefully more accurate geospatial datasets become available these meshes can be adapted using the combination of a priori mesh size functions and methodology that was explored in this work ideally if such geospatial datasets require processing to make them useful for automatic mesh generation these will be made openly available for all potential users 5 conclusions a series of controlled unstructured mesh resolution experiments conducted over a broad area of the western atlantic ocean in high resolution 50 m at the ecgc coast and with a physically accurate shoreline boundary has been achieved through an automatic mesh generation approach facilitated by the oceanmesh2d software roberts et al 2019 the sensitivity of the barotropic tidal response to unstructured mesh resolution was investigated by controlling the distribution of mesh sizes according to functions of a priori seabed and shoreline geometry information it is noteworthy to mention that the whole process was scripted and thus automatic using the mesh generator suite all meshes were designed to be numerically stable with a time step of 2 s without requiring post processing hand edits vertex re location element re shaping or bathymetric smoothing or ad hoc limiters 2 2 https wiki adcirc org wiki fort 13 file elemental slope limiter and dissipation attributes this study highlights the need to perform convergence studies to determine the role of mesh resolution on solutions of coastal hydrodynamics we have provided a framework to perform these convergence studies as well as detailing the effect mesh size functions and their parameters have on the solution of surface tides finally we provided suggestions for mesh size function combinations and parameters e g combo3 that efficiently discretize the ecgc domain with minimal mesh resolution errors future work should test these parameters in other real world domains acknowledgments this work was supported by the joseph and nona ahearn endowment at the university of notre dame united states of america and was completed under usdoc noaa award na18oar4590377 oceanmesh2d v2 0 is available from https doi org 10 5281 zenodo 2560555 
24008,a coupled ice ocean model with a horizontal resolution of 7 km is developed for the newfoundland and labrador shelves to examine climate trend and variability of ocean and ice conditions over 1979 2010 daily surface atmospheric forcing is applied and monthly open boundary conditions are prescribed the model has reasonable skill in simulating interannual and decadal variability and long term 1979 2010 trend for temperature salinity transport and ice over the newfoundland and labrador shelves at a long term monitoring station both the model and observation show substantial interannual variability in the surface temperature and salinity a warming trend in the surface temperature and no trend in the surface salinity the model sea ice extent south of 55 n shows significant interannual and decadal variability and a declining trend consistent with observations both model and altimetric observation show a declining trend in the transport of the shelf edge labrador current from 1993 to 2010 the total labrador current volume transport is correlated with the north atlantic oscillation with time lags of 0 3 years with the inshore branch having a positive trend while the shelf edge branch having no trend the inshore labrador current shows an increase of the freshwater transport associated with an increase of the volume transport due to large scale baroclinic forcing with the interannual and decadal variability of the freshwater transport dominated by the volume transport while the shelf edge transport shows a decrease of the freshwater transport associated with an increase of salinity with the interannual and decadal variability of the freshwater transport dominated by salinity 1 introduction the newfoundland and labrador shelves are located south and west of the labrador sea fig 1 which features wintertime deep convection potentially important for the atlantic meridional overturning circulation amoc the oceanographic conditions over the newfoundland and labrador shelves are predominantly influenced by the north atlantic subpolar gyre and the arctic outflow through the canadian arctic archipelago as well as by regional atmospheric forcing waters over the newfoundland shelf are also affected by the north atlantic current which is the extension of the gulf stream the combination of the west greenland current the baffin island current and the outflow from hudson strait forms into two branches of the labrador current an inshore branch near the coast and an offshore branch at the shelf edge han et al 2008 a small fraction of the inner labrador current enters the gulf of st lawrence through the strait of belle isle the rest of the labrador current including the shelf edge branch flows onto the newfoundland shelf at around 47 n the inshore branch flows through the avalon channel heading to the southern newfoundland shelf the shelf edge branch separates into two parts at the northeast of the grand banks one following the shelf break through the flemish pass while the other flowing around the flemish cap to the tail of the grand banks most of the shelf edge current turns offshore to join the north atlantic current before reaching the tail of the grand banks therefore the labrador current as part of the subpolar gyre and subject to the influence of the deep convection in the labrador sea and the arctic outflow through the canadian arctic archipelago may have substantial impacts on the amoc e g palter et al 2008 furthermore the temperature salinity and volume transport associated with the labrador current have substantial interannual and decadal variations and long term trends e g drinkwater 1996 han and tang 2001 han et al 2010 which can affect ecosystem and fish recruitment and abundance e g zhao et al 2013 buren et al 2014 nevertheless the present knowledge on the interannual and decadal variations and long term trends is limited there is a clear need for improved knowledge to help address amoc related questions as well as ecosystem and fishery management issues off newfoundland and labrador based on hydrographic observation at station 27 fig 1 petrie et al 1992 discovered that warming period in the late 1960s was followed by a cooling period in the early 1970s and then a warming trend into the early 1980s for water masses at station 27 colbourne and foote 2000 suggested that the advection of labrador current water onto the newfoundland shelf was the main cause of the interannual variability observed in the region petrie et al 1992 also indicated that the sea ice advection over the newfoundland and labrador shelves could significantly change the behaviour of the interannual variability in sea surface temperature sst han and tang 2001 and han et al 2010 2014 found strong interannual and decadal variations of the labrador current transport from satellite altimetry and hydrographic data and the potential linkage with the north atlantic oscillation nao the dominant mode of the atmospheric variability in the north atlantic their findings are consistent with those from direct current observations by dengler et al 2006 it is found that the large scale wind forcing plays important roles in interannual variability of the labrador current volume transport in the 1990s han 2005 inter annual circulation variability on the eastern canadian continental shelf was also simulated by urrego blanco and sheng 2012 studies xu et al 2013 han et al 2014 wang et al 2015 demonstrated that the strong labrador current transport in the 1990s and weak transport in the 1980s and the mid 2000s are due to multi decadal variability however there are few modelling studies that focus on decadal variation and long term 1979 2010 trend on temperature salinity volume transport and freshwater transport in this region in particular the interannual variability and long term trend of the freshwater transport have not been investigated in this study we have developed a high resolution ice ocean model based on the nucleus for european modelling of the ocean nemo madec et al 1998 for the newfoundland and labrador shelves the same model was used to study mean and seasonal circulation as well as ice variability in this region ma et al 2016 in the present study our main objectives are 1 to evaluate the model s skill in simulating interannual and decadal ice ocean variability and long term 1979 2010 trends and 2 to improve our understanding of oceanic variability on interannual and decadal time scales in particular the freshwater transport variability in section 2 we describe the model and its configuration open boundary conditions atmospheric forcing data initial conditions and solution procedure in section 3 we evaluate the skill of model based on observed temperature salinity sea surface current and sea ice data in section 4 we present the interannual variability and trend of the labrador current from both the volume transport and the freshwater transport perspectives we conclude with a brief summary and discussion in section 5 2 model configuration and forcing 2 1 model configuration we use the nemo version 2 3 modelling system madec et al 1998 with the ocean parallelise system opa version 9 and the louvain la neuve ice model lim version 2 nemo opa is a three dimensional primitive equation finite difference ocean circulationmodel the model has a z level coordinate in the vertical the vertical mixing is simulated by the turbulence closure scheme of gaspar et al 1990 nemo lim2 is a two category thermodynamic dynamic sea ice model fichefet and maqueda 1997 bouillon et al 2009 the ice ocean coupling is through the exchange of momentum heat water and salt the model domain extends from the labrador shelf to the newfoundland shelf including the grand banks and covers adjacent deep northwest atlantic ocean and part of the gulf of st lawrence as well fig 1 the model has a rotated curvilinear grid with a resolution of 7 km in the horizontal the vertical grid has a total of 46 levels with a resolution ranging from 6 m at the surface to 250 m at the bottom the bottom topography for the shelf is from the canadian hydrographic service with 7 km resolution and that for the rest of the model domain is from the earth topography 5 min gridded elevation data etopo5 http www ngdc noaa gov mgg gobal etopo5 html 2 2 atmospheric forcing and open boundary conditions we use the atmospheric forcing fields with a horizontal resolution of 32 km from the north american regional reanalysis narr dataset www esrl noaa gov psd mesinger et al 2006 including daily downward shortwave and longwave radiation wind speed air temperature specific humidity and precipitation in the present study we use a constant sea surface albedo value of 0 066 to represent the average cloudy condition according to pegau and paulson 2001 sea levels currents temperature and salinity from the simple ocean data assimilation soda global model carton and giese 2008 were linearly interpolated to the present model grid points along the open boundary the soda 0 5 version 2 2 4 monthly model output was used the interpolated values were prescribed at the open boundary points at each time step we apply a relaxation scheme for sea ice along the northern open boundary the sea ice concentration and thickness were interpolated from hu and myers 2014 their model was validated against observed ice concentration and thickness in the canadian arctic archipelago grivault et al 2017 show the impact of the freshwater input from the greenland ice sheet melt on the baffin bay circulation for our study region the freshwater input from greenland ice sheet melt and canadian arctic glacier melt may also affect regional ocean dynamics the soda version which provides the open boundary condition for our regional model does not have a run with these melt effects accounted for therefore we will leave this aspect to a future study 2 3 solution procedure the model was initialized from the rest state with the initial temperature and salinity from tang s 2007 monthly mean climatology first the model was run with the forcing of 1979 repeated for spin up after the spin up it was run from 1980 to 2010 the model has an external time step of 6 s and an internal time step of 90 s respectively biweekly averaged output was stored for analysis 2 4 statistics used for model evaluation we evaluate the model solutions quantitatively against observations in addition to the root mean square rms difference and the correlation coefficient r we examine the variance ratio γ 2 defined as 1 γ 2 v a r ζ o ζ m v a r ζ o where v a r is the variance ζ indicates a variable temperature salinity transport sea ice extent o and m represent observation and model respectively 2 5 observational data station 27 is located at 47 55 n and 52 59 w with a water depth of 176 m and 8 km offshore fig 1 it is one of the few long term monitoring stations off eastern canada with hydrographic data collected dating back to 1946 since late 1990s temperature and salinity data at station 27 have regularly biweekly except in winter been collected by the northwest atlantic fisheries centre through the atlantic zone monitoring program azmp of fisheries and oceans canada http www meds sdmm dfo mpo gc ca isdm gdsi azmp pmza index eng html we use along track sea surface height anomalies measured by satellite altimeters topex poseidon jason 1 and jason 2 from 1993 to 2010 see fig 1 for a segment crossing newfoundland slope from 200 to 3000 m isobaths the data are from the radar altimeter database system rads http rads tudelft nl rads rads shtml all default rads corrections are applied to account for wet tropospheric dry tropospheric and ionospheric delays sea state bias inverse barometer effect as well as ocean solid and pole tides annual mean sea surface height anomalies are calculated and used to estimate the cross track geostrophic current anomalies and thus the unit depth volume transport anomalies the geostrophic currents based on the multi mission altimeter data are used to evaluate the modelled currents in 1993 and 2005 the dataset is daily with a 0 25 horizontal resolution http marine copernicus eu services portfolio access to products option com csw view details product id sealevel glo phy l4 rep observations 008 047 the en4 2 1 temperature dataset good et al 2013 is used to evaluate the modelled temperature in 1993 and 2005 the dataset is monthly with a 1 horizontal resolution https www metoffice gov uk hadobs en4 download en4 2 1 html sea ice concentration data off labrador and newfoundland are obtained from the digital archive regional dataset prepared by the canadian ice service http iceweb1 cis ec gc ca 30atlas10 lang en the sea ice extent is defined as the total ice covered area south of 55 n with ice concentration above 0 1 2 6 the winter nao index the nao index is defined as the sea level pressure difference between azores high and icelandic low hurrell 1995 and obtained from the national center for atmospheric research https climatedataguide ucar edu climate data hurrell north atlantic oscillation nao index station based the winter january february march nao index is used in this study 2 7 calculation of the freshwater transport a reference salinity s r e f based on the background oceanic salinity is applied in order to determine the freshwater transport across a transect the transport can be estimated as follows 2 v f w s r e f s s r e f v d z d x where s is the salinity v is the current normal to the transect z is the depth and x is the along transect distance we assume s r e f to be 34 8 practical salinity unit psu to be consistent with mertz et al s 1993 calculation the salinity if greater than 34 8 psu is set to 34 8 psu prior to calculation we do not consider the freshwater transport associated with sea ice since its contribution to the annual mean freshwater transport is negligible compared with that associated with the liquid water in the study region 3 model validation and overall ocean ice features 3 1 temperature and salinity at station 27 both modelled and observed temperature and salinity at station 27 are averaged into annual means the annual mean anomalies of temperature and salinity are compared fig 2 near the surface the observed temperature anomalies increased at a rate of 3 7 1 5 10 2 c yr table 1 the model temperature anomalies are highly correlated 0 87 note that the value at the 95 confidence level is 0 34 which is the threshold value applicable throughout the manuscript in terms of statistical significance for correlation coefficients unless specifically indicated with observations have a low variance difference ratio table 1 and show a trend of 2 4 1 3 10 2 c yr that is only two thirds of the observed trend but within the uncertainty of it the bottom temperature anomalies show less variability with time the modelled bottom temperature trend of 1 7 0 9 10 2 c yr though insignificant at the 90 confidence level is in good agreement with the observational estimate of 1 9 1 3 10 2 c yr table 1 the model is able to capture substantial interannual variability in sea surface salinity anomalies fig 2 the modelled sea surface salinity anomalies are highly correlated with observations and have a moderate variance difference ratio table 1 the modelled or observed surface salinity does not have a statistically significant linear trend at the 90 confidence level the bottom salinity anomalies show small variability in observations but the model overestimates it as shown by the large variance difference ratio the model or observed bottom salinity does not show a statistically significant linear trend at the 90 confidence level while it is difficult to find out the exact cause for the overestimation of bottom salinity variability the vertical overmixing in the model might have something to do with the overestimation in summer there is a three layer temperature structure in the vertical with a cold intermediate layer ma et al 2016 there is a sharp vertical gradient in density the present model tends to underestimate the vertical gradient which may degrade the model s accuracy an analysis indicates that the modelled bottom salinity is significantly correlated with the observed one in fall and winter when the vertical density gradient is weak but not in spring and summer when the vertical stratification is strong on the other hand the model bottom salinity is consistent with observations showing moderate correlation significant at the 95 or above confidence levels and no trend over the study period the model observation rms difference is within 0 2 psu for salinity at both the sea surface where variability is strong and the bottom where variability is weak and the model observation difference at the bottom is significantly correlated with that at the surface at the 95 confidence level indicating that the model s accuracy is comparable at the surface and at the bottom independent of the magnitude of signal variability 3 2 unit depth volume transport over the newfoundland slope the annual mean unit depth geostrophic transport anomalies from the 200 to 3000 m isobaths on a segment over the newfoundland slope see fig 1 for location is calculated from both model and altimetry sea surface height anomalies from 1993 to 2010 the model transport variability is generally consistent with the altimetry data fig 3 with a correlation coefficient of 0 86 significant above the 99 confidence level both model and observation show a declining trend in the transport from 1993 to 2010 fig 3 the model trend of 443 108 m2 s yr and the observational rate of 223 68 m2 s yr both are different from zero at the 95 confidence level the model overestimation of the declining trend though substantial is insignificant at the 95 confidence level 3 3 sea ice extent south of 55 n fig 4 shows the winter january march sea ice extent from 1979 2010 for simulated and observed data both suggest decadal variability with high extent from 1983 1985 and 1991 1994 during these two periods the winter air temperature was anomalously cold in labrador fig 4 furthermore the sea ice extent has been declining since 1995 due to warming winter air temperature in labrador the model sea ice extent is negatively correlated r 0 73 with the winter air temperature at cartwright han et al 2015 find strong negative correlation between the winter sea ice extent over the newfoundland and labrador shelf and the wind air temperature at cartwright simulated sea ice extent captures observational variability in both timing and magnitude the correlation coefficient is high and rms difference is relatively small table 2 the model trend of the sea ice extent is 3630 1245 km2 yr consistent with the observational estimate of 3550 1020 km2 yr 3 4 model circulation and ice concentration 1993 vs 2005 here we show annual mean temperature circulation and ice conditions in the entire model domain for 1993 and 2005 respectively the former represents a cold year with persistently strong nao and the latter represents a warm year with weak nao the model annual mean circulation patterns at the 20 m depth fig 5 over the labrador and newfoundland shelves are generally similar between 1993 and 2005 dominated by the equator ward flowing labrador current however there are evident interannual variations in the model temperature and currents the model ocean temperature is colder in 1993 fig 5a than 2005 fig 5b consistent with observations fig 5c d the model shelf edge labrador current is stronger in 1991 0 14 m s on average from the 200 to 3000 m isobaths and from 45 n to 58 n than 2005 0 10 m s while the corresponding values based on altimetric observations are 0 11 m s in 1993 fig 5c and 0 10 m s in 2005 fig 5d the model ice concentration and areal extent also show significant difference between march 1991 and march 2005 fig 6 in march 2005 the model sea ice covers the entire shelf north of 53 n and only the inner shelf south of it with its southernmost location on the northeastern newfoundland coast at 49 n fig 6b in march 1993 the model sea ice covers the entire labrador shelf and the northeastern newfoundland shelf reaching the northern grand bank and flemish pass as south as 46 n fig 6a the model results agree with observations showing that the sea ice has larger extent and thickness in march 1993 fig 6a c than in march 2005 fig 6b d though the discrepancies in the areal extent over the low concentration area are evident in march 2005 4 interannual variations and long term trends in volume and freshwater transports 4 1 volume transport to estimate the labrador current transport positive equatorward we consider three segments at the seal island transect with the inshore current from coast to 250 m and the shelf edge current from the 200 m isobath to 1700 m and the total from coast to the 3000 m isobath see fig 1 for the definition of each segment the same as in han et al 2008 the simulated inshore annual mean transport has significant variations with a range of 1 sv fig 7 the transport is generally low in 1980s and high in early 1990s and middle 2000s there is an increasing trend over the simulation period table 3 significant at the 95 confidence level for the shelf edge current the annual mean transport shows a dome like evolution i e low in early 1980s and late 2000s and high in early and middle 1990s there is a notable fluctuation at a period of 5 years but not a linear trend at the 90 confidence level the model total volume transport from coast to 3000 m shows a similar dome shaped evolution with a range of 17 to 28 sv without a long term trend note that the total includes the inshore current the shelf edge current the flow offshore of the shelf edge current up to 3000 m isobaths and the flow between the inshore and shelf edge currents volume transport at the flemish cap transect is also examined with the inshore current through avalon channel from coast to the 100 m isobath on the offshore side of avalon channel about 100 km from the coast the shelf edge current through the flemish pass from the 150 m isobath on the grand banks side to the 1000 m isobath on the flemish cap side and the total from coast to the 3000 m isobath see fig 1 the inshore labrador current through avalon channel has significant interannual and decadal variability with a range from 0 4 to 1 0 sv fig 8 it has an increasing trend over the simulation period table 3 significant at the 99 confidence level the linear trend is greater than that at the seal island transect which is due to a negative trend in the cross shelf flow positive offshore between the seal island transect and the flemish cap transect fig 9 the shelf edge labrador current through the flemish pass similar to that at the seal island transect has a dome shaped variation with a range of 5 to 9 sv and does not have a linear trend at the 90 confidence level the total volume transport from coast to 3000 m has interannual and decadal variability with a range from 15 to 31 sv at the flemish cap transect without a linear trend at the 90 confidence level the transport variability is larger at the flemish cap transect than at the seal island transect since the offshore end of the flemish cap transect is located in a transitional zone strongly influenced by the north atlantic current the change of the inshore labrador current volume transport at the seal island transect is correlated r 0 34 with that of the volume transport from coast to the 450 m isobath at the northern boundary with both showing an increasing trend fig 7 the change of the shelf edge labrador current volume transport at the seal island transect is correlated r 0 61 with that of the volume transport from the 450 to 2000 m isobaths at the northern boundary han 2005 showed that the regional wind forcing over the newfoundland and labrador shelves has negligible contribution to the interannual variability of the labrador current volume transport in the 1990s while the remote large scale wind forcing has important contribution they found that the large scale wind driven transport increases with the winter nao index for both the inshore and offshore branches of the labrador current in addition to the large scale wind forcing the present study includes the large scale density driven effect through the open boundary conditions the winter nao index is shown in fig 7c since there is little trend in the nao index in the present study period it is not expected for the wind driven transport of the inshore or shelf edge labrador current to have a trend according to han s 2005 modelling study the present model includes both wind and baroclinic forcing and shows an increase in the inshore labrador current transport therefore the increase of inshore labrador current transport can be attributed to baroclinic effect as shown in fig 10 the increase in the total transport can be accounted for 100 50 and 38 by the increase in the local baroclinic transport at the northern boundary the seal island transect and the flemish cap transect respectively therefore the source for the increase of the inshore labrador current transport is the baroclinic effect specified at the northern open boundary the linear trend of the baroclinic transport is similar at the flemish cap transect and the seal island transect while that of the total transport is larger at the flemish cap transect than at the seal island transect as shown earlier the close relationship of the model flow features with the large scale inflows through the northern and eastern boundaries is an indicative that the circulation over the newfoundland and labrador shelf and slope is part of the subpolar gyre of the north atlantic the weakening of the total labrador current happens in 1979 1989 and 2000 2010 consistent with the results from a recent basin scale model for the north atlantic xu et al 2013 and an observational study using satellite altimetry han et al 2014 this variation is likely to be part of the multi decadal variability of the subpolar gyre in relation to the atlantic meridional overturning circulation amoc xu et al 2013 han et al 2014 previous studies have shown that the labrador current transport is correlated with the winter nao index han and tang 2001 han et al 2010 we have calculated the correlation coefficient between the annual mean volume transport and the winter nao index the total volume transport at the seal island transect is positively correlated r 0 56 with the winter nao index at zero lag in contrast the total volume transport at the flemish cap transect lags the winter nao index by 2 3 years zantopp et al 2017 find that the vertical structure of the labrador current at 53 n over the labrador slope is baroclinic and in phase with the nao on a quasi decadal time scale eden and willebrand 2001 from realistic and idealized model experiments showed a fast intraseasonal barotropic response and a delayed 6 8 years baroclinic response of the north atlantic subpolar circulation to the nao zantopp et al 2017 further speculate that the quasi decadal labrador current transport variability is likely generated outside the labrador sea through nao related forcing but with a fast propagation along the western shelf break of the subpolar north atlantic our speculation is that the fast propagation pattern is altered over the newfoundland slope since the region has stronger vertical stratification fig 11 and is subject to stronger influence of the north atlantic current this alteration might explain the phase lag between the volume transport at the flemish cap transect and the nao 4 2 freshwater transport the freshwater transport associated with the labrador current has been calculated based on hydrographic observations mertz et al 1993 petrie and buckley 1996 but its interannual variability or long term trend has not been investigated the freshwater transport on the seal island and flemish cap transects is estimated for the same three segments defined in section 4 1 fig 12 shows the annual mean freshwater transport for the inshore current shelf edge current and the total at the seal island transect the inshore current shows an increasing linear trend table 3 statistically significant at the 95 confidence level there is also decadal variability in freshwater transport small in the 1980s large in the early 1990s and close to the mean state afterwards fig 12a for the shelf edge current the freshwater transport has a declining trend statistically different from zero at the 95 confidence level fig 12b table 3 the decline can mainly be attributed to salinity increase fig 12b during the study period the salinity in the northwestern north atlantic increases at 0 5 0 3 10 2 psu yr at the surface and 0 3 0 1 10 2 psu yr in the 100 700 m han et al 2013 the salinity of the shelf edge current as part of the north atlantic subpolar gyre also increases resulting in the decline of its freshwater transport the freshwater transport across the entire transect has a negative trend statistically significant at the 95 confidence level dominated by that in the shelf edge current fig 12c table 3 overall the inshore freshwater transport variation fig 12a is mainly related to volume transport fig 7a r 0 87 and to a lesser degree to salinity change fig 12a r 0 45 in contrast the shelf edge freshwater transport change fig 12b is mainly related to salinity fig 12b r 0 98 and to a lesser degree to volume transport fig 7b r 0 54 the total freshwater transport variability fig 12c is related to salinity fig 12c r 0 94 and to a lesser degree to volume transport fig 7c r 0 49 fig 13 shows the annual mean freshwater transport for the inshore current shelf edge current and the total at the flemish cap transect the freshwater transport has a positive trend statistically significant at the 95 confidence level for the inshore branch fig 13a table 3 the increase is mainly due to the increase of the volume transport fig 8a table 3 there is also decadal variability in freshwater transport low in the 1980s high in the 1990s and close to average in the 2000s for the shelf edge current the freshwater transport shows a declining trend significant at the 90 confidence level fig 13b table 3 the freshwater transport is higher in the middle 1980s and in the early 1990s the total freshwater transport across the entire transect does not have a linear trend at the 90 confidence level fig 13c table 3 the inshore freshwater transport fig 13a is highly correlated r 0 96 with the volume transport fig 8a but uncorrelated with salinity implying that the volume transport variation is the factor affecting the freshwater transport variation in contrast the shelf edge freshwater transport fig 13b is correlated r 0 80 with salinity but uncorrelated with the volume transport fig 13b implying salinity is the factor affecting the freshwater transport variation the total freshwater transport fig 13c is correlated r 0 89 with salinity fig 13c and the volume transport fig 8c r 0 41 suggesting that the freshwater transport variation is affected mainly by salinity and to a lesser degree by the volume transport in section 3 1 the model validation indicated the model overestimation of the bottom salinity at station 27 where the inshore labrador current is located next we show sensitivity of the relationship of the freshwater transport associated with the inshore labrador current at the flemish cap transect with salinity and volume transport to the model overestimation of the bottom salinity in the sensitivity case we calculate the freshwater transport by using salinity averaged over 1979 2010 for the lower half of the water column the sensitivity case shows that the freshwater transport is highly correlated r 0 99 with the volume transport and uncorrelated with salinity consistent with the conclusion that the volume transport variation is the factor affecting the freshwater transport variation in the inshore labrador current at the flemish cap transect 5 summary we have developed a three dimensional prognostic ice oceanmodel for the newfoundland and labrador shelves the prognostic ice ocean model is based on the nemo opa9 and nemo lim2 for ocean and ice respectively it is forced by narr daily winds and heat flux at the surface and soda monthly sea level and inflows at the lateral open boundaries the model results have been evaluated against temperature salinity ice and current data the model is able to reproduce temperature variability at station 27 the model temperature anomalies show a trend of 2 4 1 3 10 2 c yr one third lower than the observational estimate the model bottom temperature rose at a rate of 1 7 0 9 10 2 c yr consistent with the observational estimate of 1 9 1 3 10 2 c yr the model is able to capture observed sea surface salinity variability at this station the ice model coupled with the circulation model is validated against the observed ice extent south of 55 n the simulated ice extent agrees well with observations in terms of multi decadal variability and a decreasing trend the prognostic model results indicate significant interannual variations in the regional circulation the model transport variability of the shelf edge labrador current per unit depth at the surface is correlated with the altimetric estimate with a correlation coefficient of 0 86 both model and altimetric observation show a declining trend from 1993 to 2010 with the model trend of 443 108 m2 s yr and the observational trend of 223 68 m2 s yr respectively the shelf region is dominated by the equatorward labrador current along the shelf edge and along the labrador and newfoundland coasts the inshore labrador current shows a positive trend in transport from 1979 to 2010 attributable to the large scale baroclinic inflow through the northern boundary the total labrador current transport during the study period is large in the early 1990s and small in the 1980s and 2000s attributable to the large scale inflow through the north and east boundaries and consistent with previous studies xu et al 2013 han et al 2014 it is found that the labrador current is correlated with the winter nao index with time lags of 0 3 years thus the interannual and decadal labrador current variability is likely generated in the subpolar north atlantic with linkage to nao and amoc the inshore branch of the labrador current shows an increase of freshwater transport with its interannual variability dominated by volume transport while the shelf edge branch shows a decrease of freshwater transport with its interannual variability dominated by salinity declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by the aquatic climate change adaptation services program accasp fisheries and oceans canada the research is also supported by the surface water and ocean topography canada swot c program canadian space agency we thank paul myers for providing sea ice conditions on the northern boundary of our model and ingrid peterson for providing the sea ice extent data the narr reanalysis data are provided by the noaa oar esrl psd boulder colorado usa from their web site at http www esrl noaa gov psd the temperature and salinity data at station 27 are from azmp www meds sdmm dfo mpo gc ca isdm gdsi azmp pmza index egn html fisheries and oceans canada altimeter data are from rads http rads tudelft nl rads rads shtml the nao index is obtained from the national center for atmospheric research https climatedataguide ucar edu climate data hurrell north atlantic oscillation nao index station based constructive comments were received from the two anonymous reviewers 
24008,a coupled ice ocean model with a horizontal resolution of 7 km is developed for the newfoundland and labrador shelves to examine climate trend and variability of ocean and ice conditions over 1979 2010 daily surface atmospheric forcing is applied and monthly open boundary conditions are prescribed the model has reasonable skill in simulating interannual and decadal variability and long term 1979 2010 trend for temperature salinity transport and ice over the newfoundland and labrador shelves at a long term monitoring station both the model and observation show substantial interannual variability in the surface temperature and salinity a warming trend in the surface temperature and no trend in the surface salinity the model sea ice extent south of 55 n shows significant interannual and decadal variability and a declining trend consistent with observations both model and altimetric observation show a declining trend in the transport of the shelf edge labrador current from 1993 to 2010 the total labrador current volume transport is correlated with the north atlantic oscillation with time lags of 0 3 years with the inshore branch having a positive trend while the shelf edge branch having no trend the inshore labrador current shows an increase of the freshwater transport associated with an increase of the volume transport due to large scale baroclinic forcing with the interannual and decadal variability of the freshwater transport dominated by the volume transport while the shelf edge transport shows a decrease of the freshwater transport associated with an increase of salinity with the interannual and decadal variability of the freshwater transport dominated by salinity 1 introduction the newfoundland and labrador shelves are located south and west of the labrador sea fig 1 which features wintertime deep convection potentially important for the atlantic meridional overturning circulation amoc the oceanographic conditions over the newfoundland and labrador shelves are predominantly influenced by the north atlantic subpolar gyre and the arctic outflow through the canadian arctic archipelago as well as by regional atmospheric forcing waters over the newfoundland shelf are also affected by the north atlantic current which is the extension of the gulf stream the combination of the west greenland current the baffin island current and the outflow from hudson strait forms into two branches of the labrador current an inshore branch near the coast and an offshore branch at the shelf edge han et al 2008 a small fraction of the inner labrador current enters the gulf of st lawrence through the strait of belle isle the rest of the labrador current including the shelf edge branch flows onto the newfoundland shelf at around 47 n the inshore branch flows through the avalon channel heading to the southern newfoundland shelf the shelf edge branch separates into two parts at the northeast of the grand banks one following the shelf break through the flemish pass while the other flowing around the flemish cap to the tail of the grand banks most of the shelf edge current turns offshore to join the north atlantic current before reaching the tail of the grand banks therefore the labrador current as part of the subpolar gyre and subject to the influence of the deep convection in the labrador sea and the arctic outflow through the canadian arctic archipelago may have substantial impacts on the amoc e g palter et al 2008 furthermore the temperature salinity and volume transport associated with the labrador current have substantial interannual and decadal variations and long term trends e g drinkwater 1996 han and tang 2001 han et al 2010 which can affect ecosystem and fish recruitment and abundance e g zhao et al 2013 buren et al 2014 nevertheless the present knowledge on the interannual and decadal variations and long term trends is limited there is a clear need for improved knowledge to help address amoc related questions as well as ecosystem and fishery management issues off newfoundland and labrador based on hydrographic observation at station 27 fig 1 petrie et al 1992 discovered that warming period in the late 1960s was followed by a cooling period in the early 1970s and then a warming trend into the early 1980s for water masses at station 27 colbourne and foote 2000 suggested that the advection of labrador current water onto the newfoundland shelf was the main cause of the interannual variability observed in the region petrie et al 1992 also indicated that the sea ice advection over the newfoundland and labrador shelves could significantly change the behaviour of the interannual variability in sea surface temperature sst han and tang 2001 and han et al 2010 2014 found strong interannual and decadal variations of the labrador current transport from satellite altimetry and hydrographic data and the potential linkage with the north atlantic oscillation nao the dominant mode of the atmospheric variability in the north atlantic their findings are consistent with those from direct current observations by dengler et al 2006 it is found that the large scale wind forcing plays important roles in interannual variability of the labrador current volume transport in the 1990s han 2005 inter annual circulation variability on the eastern canadian continental shelf was also simulated by urrego blanco and sheng 2012 studies xu et al 2013 han et al 2014 wang et al 2015 demonstrated that the strong labrador current transport in the 1990s and weak transport in the 1980s and the mid 2000s are due to multi decadal variability however there are few modelling studies that focus on decadal variation and long term 1979 2010 trend on temperature salinity volume transport and freshwater transport in this region in particular the interannual variability and long term trend of the freshwater transport have not been investigated in this study we have developed a high resolution ice ocean model based on the nucleus for european modelling of the ocean nemo madec et al 1998 for the newfoundland and labrador shelves the same model was used to study mean and seasonal circulation as well as ice variability in this region ma et al 2016 in the present study our main objectives are 1 to evaluate the model s skill in simulating interannual and decadal ice ocean variability and long term 1979 2010 trends and 2 to improve our understanding of oceanic variability on interannual and decadal time scales in particular the freshwater transport variability in section 2 we describe the model and its configuration open boundary conditions atmospheric forcing data initial conditions and solution procedure in section 3 we evaluate the skill of model based on observed temperature salinity sea surface current and sea ice data in section 4 we present the interannual variability and trend of the labrador current from both the volume transport and the freshwater transport perspectives we conclude with a brief summary and discussion in section 5 2 model configuration and forcing 2 1 model configuration we use the nemo version 2 3 modelling system madec et al 1998 with the ocean parallelise system opa version 9 and the louvain la neuve ice model lim version 2 nemo opa is a three dimensional primitive equation finite difference ocean circulationmodel the model has a z level coordinate in the vertical the vertical mixing is simulated by the turbulence closure scheme of gaspar et al 1990 nemo lim2 is a two category thermodynamic dynamic sea ice model fichefet and maqueda 1997 bouillon et al 2009 the ice ocean coupling is through the exchange of momentum heat water and salt the model domain extends from the labrador shelf to the newfoundland shelf including the grand banks and covers adjacent deep northwest atlantic ocean and part of the gulf of st lawrence as well fig 1 the model has a rotated curvilinear grid with a resolution of 7 km in the horizontal the vertical grid has a total of 46 levels with a resolution ranging from 6 m at the surface to 250 m at the bottom the bottom topography for the shelf is from the canadian hydrographic service with 7 km resolution and that for the rest of the model domain is from the earth topography 5 min gridded elevation data etopo5 http www ngdc noaa gov mgg gobal etopo5 html 2 2 atmospheric forcing and open boundary conditions we use the atmospheric forcing fields with a horizontal resolution of 32 km from the north american regional reanalysis narr dataset www esrl noaa gov psd mesinger et al 2006 including daily downward shortwave and longwave radiation wind speed air temperature specific humidity and precipitation in the present study we use a constant sea surface albedo value of 0 066 to represent the average cloudy condition according to pegau and paulson 2001 sea levels currents temperature and salinity from the simple ocean data assimilation soda global model carton and giese 2008 were linearly interpolated to the present model grid points along the open boundary the soda 0 5 version 2 2 4 monthly model output was used the interpolated values were prescribed at the open boundary points at each time step we apply a relaxation scheme for sea ice along the northern open boundary the sea ice concentration and thickness were interpolated from hu and myers 2014 their model was validated against observed ice concentration and thickness in the canadian arctic archipelago grivault et al 2017 show the impact of the freshwater input from the greenland ice sheet melt on the baffin bay circulation for our study region the freshwater input from greenland ice sheet melt and canadian arctic glacier melt may also affect regional ocean dynamics the soda version which provides the open boundary condition for our regional model does not have a run with these melt effects accounted for therefore we will leave this aspect to a future study 2 3 solution procedure the model was initialized from the rest state with the initial temperature and salinity from tang s 2007 monthly mean climatology first the model was run with the forcing of 1979 repeated for spin up after the spin up it was run from 1980 to 2010 the model has an external time step of 6 s and an internal time step of 90 s respectively biweekly averaged output was stored for analysis 2 4 statistics used for model evaluation we evaluate the model solutions quantitatively against observations in addition to the root mean square rms difference and the correlation coefficient r we examine the variance ratio γ 2 defined as 1 γ 2 v a r ζ o ζ m v a r ζ o where v a r is the variance ζ indicates a variable temperature salinity transport sea ice extent o and m represent observation and model respectively 2 5 observational data station 27 is located at 47 55 n and 52 59 w with a water depth of 176 m and 8 km offshore fig 1 it is one of the few long term monitoring stations off eastern canada with hydrographic data collected dating back to 1946 since late 1990s temperature and salinity data at station 27 have regularly biweekly except in winter been collected by the northwest atlantic fisheries centre through the atlantic zone monitoring program azmp of fisheries and oceans canada http www meds sdmm dfo mpo gc ca isdm gdsi azmp pmza index eng html we use along track sea surface height anomalies measured by satellite altimeters topex poseidon jason 1 and jason 2 from 1993 to 2010 see fig 1 for a segment crossing newfoundland slope from 200 to 3000 m isobaths the data are from the radar altimeter database system rads http rads tudelft nl rads rads shtml all default rads corrections are applied to account for wet tropospheric dry tropospheric and ionospheric delays sea state bias inverse barometer effect as well as ocean solid and pole tides annual mean sea surface height anomalies are calculated and used to estimate the cross track geostrophic current anomalies and thus the unit depth volume transport anomalies the geostrophic currents based on the multi mission altimeter data are used to evaluate the modelled currents in 1993 and 2005 the dataset is daily with a 0 25 horizontal resolution http marine copernicus eu services portfolio access to products option com csw view details product id sealevel glo phy l4 rep observations 008 047 the en4 2 1 temperature dataset good et al 2013 is used to evaluate the modelled temperature in 1993 and 2005 the dataset is monthly with a 1 horizontal resolution https www metoffice gov uk hadobs en4 download en4 2 1 html sea ice concentration data off labrador and newfoundland are obtained from the digital archive regional dataset prepared by the canadian ice service http iceweb1 cis ec gc ca 30atlas10 lang en the sea ice extent is defined as the total ice covered area south of 55 n with ice concentration above 0 1 2 6 the winter nao index the nao index is defined as the sea level pressure difference between azores high and icelandic low hurrell 1995 and obtained from the national center for atmospheric research https climatedataguide ucar edu climate data hurrell north atlantic oscillation nao index station based the winter january february march nao index is used in this study 2 7 calculation of the freshwater transport a reference salinity s r e f based on the background oceanic salinity is applied in order to determine the freshwater transport across a transect the transport can be estimated as follows 2 v f w s r e f s s r e f v d z d x where s is the salinity v is the current normal to the transect z is the depth and x is the along transect distance we assume s r e f to be 34 8 practical salinity unit psu to be consistent with mertz et al s 1993 calculation the salinity if greater than 34 8 psu is set to 34 8 psu prior to calculation we do not consider the freshwater transport associated with sea ice since its contribution to the annual mean freshwater transport is negligible compared with that associated with the liquid water in the study region 3 model validation and overall ocean ice features 3 1 temperature and salinity at station 27 both modelled and observed temperature and salinity at station 27 are averaged into annual means the annual mean anomalies of temperature and salinity are compared fig 2 near the surface the observed temperature anomalies increased at a rate of 3 7 1 5 10 2 c yr table 1 the model temperature anomalies are highly correlated 0 87 note that the value at the 95 confidence level is 0 34 which is the threshold value applicable throughout the manuscript in terms of statistical significance for correlation coefficients unless specifically indicated with observations have a low variance difference ratio table 1 and show a trend of 2 4 1 3 10 2 c yr that is only two thirds of the observed trend but within the uncertainty of it the bottom temperature anomalies show less variability with time the modelled bottom temperature trend of 1 7 0 9 10 2 c yr though insignificant at the 90 confidence level is in good agreement with the observational estimate of 1 9 1 3 10 2 c yr table 1 the model is able to capture substantial interannual variability in sea surface salinity anomalies fig 2 the modelled sea surface salinity anomalies are highly correlated with observations and have a moderate variance difference ratio table 1 the modelled or observed surface salinity does not have a statistically significant linear trend at the 90 confidence level the bottom salinity anomalies show small variability in observations but the model overestimates it as shown by the large variance difference ratio the model or observed bottom salinity does not show a statistically significant linear trend at the 90 confidence level while it is difficult to find out the exact cause for the overestimation of bottom salinity variability the vertical overmixing in the model might have something to do with the overestimation in summer there is a three layer temperature structure in the vertical with a cold intermediate layer ma et al 2016 there is a sharp vertical gradient in density the present model tends to underestimate the vertical gradient which may degrade the model s accuracy an analysis indicates that the modelled bottom salinity is significantly correlated with the observed one in fall and winter when the vertical density gradient is weak but not in spring and summer when the vertical stratification is strong on the other hand the model bottom salinity is consistent with observations showing moderate correlation significant at the 95 or above confidence levels and no trend over the study period the model observation rms difference is within 0 2 psu for salinity at both the sea surface where variability is strong and the bottom where variability is weak and the model observation difference at the bottom is significantly correlated with that at the surface at the 95 confidence level indicating that the model s accuracy is comparable at the surface and at the bottom independent of the magnitude of signal variability 3 2 unit depth volume transport over the newfoundland slope the annual mean unit depth geostrophic transport anomalies from the 200 to 3000 m isobaths on a segment over the newfoundland slope see fig 1 for location is calculated from both model and altimetry sea surface height anomalies from 1993 to 2010 the model transport variability is generally consistent with the altimetry data fig 3 with a correlation coefficient of 0 86 significant above the 99 confidence level both model and observation show a declining trend in the transport from 1993 to 2010 fig 3 the model trend of 443 108 m2 s yr and the observational rate of 223 68 m2 s yr both are different from zero at the 95 confidence level the model overestimation of the declining trend though substantial is insignificant at the 95 confidence level 3 3 sea ice extent south of 55 n fig 4 shows the winter january march sea ice extent from 1979 2010 for simulated and observed data both suggest decadal variability with high extent from 1983 1985 and 1991 1994 during these two periods the winter air temperature was anomalously cold in labrador fig 4 furthermore the sea ice extent has been declining since 1995 due to warming winter air temperature in labrador the model sea ice extent is negatively correlated r 0 73 with the winter air temperature at cartwright han et al 2015 find strong negative correlation between the winter sea ice extent over the newfoundland and labrador shelf and the wind air temperature at cartwright simulated sea ice extent captures observational variability in both timing and magnitude the correlation coefficient is high and rms difference is relatively small table 2 the model trend of the sea ice extent is 3630 1245 km2 yr consistent with the observational estimate of 3550 1020 km2 yr 3 4 model circulation and ice concentration 1993 vs 2005 here we show annual mean temperature circulation and ice conditions in the entire model domain for 1993 and 2005 respectively the former represents a cold year with persistently strong nao and the latter represents a warm year with weak nao the model annual mean circulation patterns at the 20 m depth fig 5 over the labrador and newfoundland shelves are generally similar between 1993 and 2005 dominated by the equator ward flowing labrador current however there are evident interannual variations in the model temperature and currents the model ocean temperature is colder in 1993 fig 5a than 2005 fig 5b consistent with observations fig 5c d the model shelf edge labrador current is stronger in 1991 0 14 m s on average from the 200 to 3000 m isobaths and from 45 n to 58 n than 2005 0 10 m s while the corresponding values based on altimetric observations are 0 11 m s in 1993 fig 5c and 0 10 m s in 2005 fig 5d the model ice concentration and areal extent also show significant difference between march 1991 and march 2005 fig 6 in march 2005 the model sea ice covers the entire shelf north of 53 n and only the inner shelf south of it with its southernmost location on the northeastern newfoundland coast at 49 n fig 6b in march 1993 the model sea ice covers the entire labrador shelf and the northeastern newfoundland shelf reaching the northern grand bank and flemish pass as south as 46 n fig 6a the model results agree with observations showing that the sea ice has larger extent and thickness in march 1993 fig 6a c than in march 2005 fig 6b d though the discrepancies in the areal extent over the low concentration area are evident in march 2005 4 interannual variations and long term trends in volume and freshwater transports 4 1 volume transport to estimate the labrador current transport positive equatorward we consider three segments at the seal island transect with the inshore current from coast to 250 m and the shelf edge current from the 200 m isobath to 1700 m and the total from coast to the 3000 m isobath see fig 1 for the definition of each segment the same as in han et al 2008 the simulated inshore annual mean transport has significant variations with a range of 1 sv fig 7 the transport is generally low in 1980s and high in early 1990s and middle 2000s there is an increasing trend over the simulation period table 3 significant at the 95 confidence level for the shelf edge current the annual mean transport shows a dome like evolution i e low in early 1980s and late 2000s and high in early and middle 1990s there is a notable fluctuation at a period of 5 years but not a linear trend at the 90 confidence level the model total volume transport from coast to 3000 m shows a similar dome shaped evolution with a range of 17 to 28 sv without a long term trend note that the total includes the inshore current the shelf edge current the flow offshore of the shelf edge current up to 3000 m isobaths and the flow between the inshore and shelf edge currents volume transport at the flemish cap transect is also examined with the inshore current through avalon channel from coast to the 100 m isobath on the offshore side of avalon channel about 100 km from the coast the shelf edge current through the flemish pass from the 150 m isobath on the grand banks side to the 1000 m isobath on the flemish cap side and the total from coast to the 3000 m isobath see fig 1 the inshore labrador current through avalon channel has significant interannual and decadal variability with a range from 0 4 to 1 0 sv fig 8 it has an increasing trend over the simulation period table 3 significant at the 99 confidence level the linear trend is greater than that at the seal island transect which is due to a negative trend in the cross shelf flow positive offshore between the seal island transect and the flemish cap transect fig 9 the shelf edge labrador current through the flemish pass similar to that at the seal island transect has a dome shaped variation with a range of 5 to 9 sv and does not have a linear trend at the 90 confidence level the total volume transport from coast to 3000 m has interannual and decadal variability with a range from 15 to 31 sv at the flemish cap transect without a linear trend at the 90 confidence level the transport variability is larger at the flemish cap transect than at the seal island transect since the offshore end of the flemish cap transect is located in a transitional zone strongly influenced by the north atlantic current the change of the inshore labrador current volume transport at the seal island transect is correlated r 0 34 with that of the volume transport from coast to the 450 m isobath at the northern boundary with both showing an increasing trend fig 7 the change of the shelf edge labrador current volume transport at the seal island transect is correlated r 0 61 with that of the volume transport from the 450 to 2000 m isobaths at the northern boundary han 2005 showed that the regional wind forcing over the newfoundland and labrador shelves has negligible contribution to the interannual variability of the labrador current volume transport in the 1990s while the remote large scale wind forcing has important contribution they found that the large scale wind driven transport increases with the winter nao index for both the inshore and offshore branches of the labrador current in addition to the large scale wind forcing the present study includes the large scale density driven effect through the open boundary conditions the winter nao index is shown in fig 7c since there is little trend in the nao index in the present study period it is not expected for the wind driven transport of the inshore or shelf edge labrador current to have a trend according to han s 2005 modelling study the present model includes both wind and baroclinic forcing and shows an increase in the inshore labrador current transport therefore the increase of inshore labrador current transport can be attributed to baroclinic effect as shown in fig 10 the increase in the total transport can be accounted for 100 50 and 38 by the increase in the local baroclinic transport at the northern boundary the seal island transect and the flemish cap transect respectively therefore the source for the increase of the inshore labrador current transport is the baroclinic effect specified at the northern open boundary the linear trend of the baroclinic transport is similar at the flemish cap transect and the seal island transect while that of the total transport is larger at the flemish cap transect than at the seal island transect as shown earlier the close relationship of the model flow features with the large scale inflows through the northern and eastern boundaries is an indicative that the circulation over the newfoundland and labrador shelf and slope is part of the subpolar gyre of the north atlantic the weakening of the total labrador current happens in 1979 1989 and 2000 2010 consistent with the results from a recent basin scale model for the north atlantic xu et al 2013 and an observational study using satellite altimetry han et al 2014 this variation is likely to be part of the multi decadal variability of the subpolar gyre in relation to the atlantic meridional overturning circulation amoc xu et al 2013 han et al 2014 previous studies have shown that the labrador current transport is correlated with the winter nao index han and tang 2001 han et al 2010 we have calculated the correlation coefficient between the annual mean volume transport and the winter nao index the total volume transport at the seal island transect is positively correlated r 0 56 with the winter nao index at zero lag in contrast the total volume transport at the flemish cap transect lags the winter nao index by 2 3 years zantopp et al 2017 find that the vertical structure of the labrador current at 53 n over the labrador slope is baroclinic and in phase with the nao on a quasi decadal time scale eden and willebrand 2001 from realistic and idealized model experiments showed a fast intraseasonal barotropic response and a delayed 6 8 years baroclinic response of the north atlantic subpolar circulation to the nao zantopp et al 2017 further speculate that the quasi decadal labrador current transport variability is likely generated outside the labrador sea through nao related forcing but with a fast propagation along the western shelf break of the subpolar north atlantic our speculation is that the fast propagation pattern is altered over the newfoundland slope since the region has stronger vertical stratification fig 11 and is subject to stronger influence of the north atlantic current this alteration might explain the phase lag between the volume transport at the flemish cap transect and the nao 4 2 freshwater transport the freshwater transport associated with the labrador current has been calculated based on hydrographic observations mertz et al 1993 petrie and buckley 1996 but its interannual variability or long term trend has not been investigated the freshwater transport on the seal island and flemish cap transects is estimated for the same three segments defined in section 4 1 fig 12 shows the annual mean freshwater transport for the inshore current shelf edge current and the total at the seal island transect the inshore current shows an increasing linear trend table 3 statistically significant at the 95 confidence level there is also decadal variability in freshwater transport small in the 1980s large in the early 1990s and close to the mean state afterwards fig 12a for the shelf edge current the freshwater transport has a declining trend statistically different from zero at the 95 confidence level fig 12b table 3 the decline can mainly be attributed to salinity increase fig 12b during the study period the salinity in the northwestern north atlantic increases at 0 5 0 3 10 2 psu yr at the surface and 0 3 0 1 10 2 psu yr in the 100 700 m han et al 2013 the salinity of the shelf edge current as part of the north atlantic subpolar gyre also increases resulting in the decline of its freshwater transport the freshwater transport across the entire transect has a negative trend statistically significant at the 95 confidence level dominated by that in the shelf edge current fig 12c table 3 overall the inshore freshwater transport variation fig 12a is mainly related to volume transport fig 7a r 0 87 and to a lesser degree to salinity change fig 12a r 0 45 in contrast the shelf edge freshwater transport change fig 12b is mainly related to salinity fig 12b r 0 98 and to a lesser degree to volume transport fig 7b r 0 54 the total freshwater transport variability fig 12c is related to salinity fig 12c r 0 94 and to a lesser degree to volume transport fig 7c r 0 49 fig 13 shows the annual mean freshwater transport for the inshore current shelf edge current and the total at the flemish cap transect the freshwater transport has a positive trend statistically significant at the 95 confidence level for the inshore branch fig 13a table 3 the increase is mainly due to the increase of the volume transport fig 8a table 3 there is also decadal variability in freshwater transport low in the 1980s high in the 1990s and close to average in the 2000s for the shelf edge current the freshwater transport shows a declining trend significant at the 90 confidence level fig 13b table 3 the freshwater transport is higher in the middle 1980s and in the early 1990s the total freshwater transport across the entire transect does not have a linear trend at the 90 confidence level fig 13c table 3 the inshore freshwater transport fig 13a is highly correlated r 0 96 with the volume transport fig 8a but uncorrelated with salinity implying that the volume transport variation is the factor affecting the freshwater transport variation in contrast the shelf edge freshwater transport fig 13b is correlated r 0 80 with salinity but uncorrelated with the volume transport fig 13b implying salinity is the factor affecting the freshwater transport variation the total freshwater transport fig 13c is correlated r 0 89 with salinity fig 13c and the volume transport fig 8c r 0 41 suggesting that the freshwater transport variation is affected mainly by salinity and to a lesser degree by the volume transport in section 3 1 the model validation indicated the model overestimation of the bottom salinity at station 27 where the inshore labrador current is located next we show sensitivity of the relationship of the freshwater transport associated with the inshore labrador current at the flemish cap transect with salinity and volume transport to the model overestimation of the bottom salinity in the sensitivity case we calculate the freshwater transport by using salinity averaged over 1979 2010 for the lower half of the water column the sensitivity case shows that the freshwater transport is highly correlated r 0 99 with the volume transport and uncorrelated with salinity consistent with the conclusion that the volume transport variation is the factor affecting the freshwater transport variation in the inshore labrador current at the flemish cap transect 5 summary we have developed a three dimensional prognostic ice oceanmodel for the newfoundland and labrador shelves the prognostic ice ocean model is based on the nemo opa9 and nemo lim2 for ocean and ice respectively it is forced by narr daily winds and heat flux at the surface and soda monthly sea level and inflows at the lateral open boundaries the model results have been evaluated against temperature salinity ice and current data the model is able to reproduce temperature variability at station 27 the model temperature anomalies show a trend of 2 4 1 3 10 2 c yr one third lower than the observational estimate the model bottom temperature rose at a rate of 1 7 0 9 10 2 c yr consistent with the observational estimate of 1 9 1 3 10 2 c yr the model is able to capture observed sea surface salinity variability at this station the ice model coupled with the circulation model is validated against the observed ice extent south of 55 n the simulated ice extent agrees well with observations in terms of multi decadal variability and a decreasing trend the prognostic model results indicate significant interannual variations in the regional circulation the model transport variability of the shelf edge labrador current per unit depth at the surface is correlated with the altimetric estimate with a correlation coefficient of 0 86 both model and altimetric observation show a declining trend from 1993 to 2010 with the model trend of 443 108 m2 s yr and the observational trend of 223 68 m2 s yr respectively the shelf region is dominated by the equatorward labrador current along the shelf edge and along the labrador and newfoundland coasts the inshore labrador current shows a positive trend in transport from 1979 to 2010 attributable to the large scale baroclinic inflow through the northern boundary the total labrador current transport during the study period is large in the early 1990s and small in the 1980s and 2000s attributable to the large scale inflow through the north and east boundaries and consistent with previous studies xu et al 2013 han et al 2014 it is found that the labrador current is correlated with the winter nao index with time lags of 0 3 years thus the interannual and decadal labrador current variability is likely generated in the subpolar north atlantic with linkage to nao and amoc the inshore branch of the labrador current shows an increase of freshwater transport with its interannual variability dominated by volume transport while the shelf edge branch shows a decrease of freshwater transport with its interannual variability dominated by salinity declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by the aquatic climate change adaptation services program accasp fisheries and oceans canada the research is also supported by the surface water and ocean topography canada swot c program canadian space agency we thank paul myers for providing sea ice conditions on the northern boundary of our model and ingrid peterson for providing the sea ice extent data the narr reanalysis data are provided by the noaa oar esrl psd boulder colorado usa from their web site at http www esrl noaa gov psd the temperature and salinity data at station 27 are from azmp www meds sdmm dfo mpo gc ca isdm gdsi azmp pmza index egn html fisheries and oceans canada altimeter data are from rads http rads tudelft nl rads rads shtml the nao index is obtained from the national center for atmospheric research https climatedataguide ucar edu climate data hurrell north atlantic oscillation nao index station based constructive comments were received from the two anonymous reviewers 
24009,we develop asymptotic expressions for wave action density and action flux using an extension of kirby chen 1989 s perturbation solution for weakly sheared currents allowing for a basic flow with froude number f u g h o 1 but with weak vertical shear the accuracy of the expressions for action density and flux is established by comparison to analytic results for a current with constant shear and to numerical results for a field case involving a buoyant ebb tidal plume with strong vertical shear and for a case involving a numerically determined profile for a wind driven current we compare our results to those from recent work of quinn et al 2017 and find unresolved discrepancies in that prior work we provide additional suggestions for efficiently implementing the required extensions in coupled wave circulation models using a taylor series expansion based on conditions at peak frequency and direction these results generalize the previous work of banihashemi et al 2017 to motions in two horizontal dimensions and cover the determination of the wave action keywords wave current interaction wave action conservation ocean models waves over sheared currents 1 introduction significant advances have been made in the numerical modeling of wave current interaction in recent decades an important component in these advances has been the recognition of wave action as the fundamental conserved quantity expressing the wave averaged energy of a slowly varying wave train the simplest description is typically based on the underlying dynamics for monochromatic waves governed by the wave action balance of bretherton and garrett 1968 and given by 1 n t h ℱ 0 where subscripted commas denote partial differentiation for the case of depth uniform mean current u action density n e σ and action flux ℱ n c g a where e is energy density σ ω k u g k tanh k h is intrinsic frequency h and k k are depth and wavenumber and c g a ω k σ k u is the absolute group velocity vector in stationary coordinates phase averaged spectral wave models typically calculate wave properties based on the linear theory for waves superposed on depth uniform currents however currents in the field are occasionallystrongly sheared over the vertical leading to the need for a treatment of the rotationality or shear in the flow field an approximate treatment for the effect of current shear may be based on a perturbation approach that has been developed through a sequence of papers stewart and joy 1974 skop 1987 kirby and chen 1989 ellingsen and li 2017 with kirby and chen 1989 hereafter referred to as kc89 providing a solution to second order for the finite depth case for currents that are assumed to deviate only weakly from depth uniformity the main utility of the approximate solution has been the specification of a depth weighted current u specified by skop 1987 and kc89 and given by 12 as a representative depth uniform current for determining intrinsic frequency and action density in spectral wave models van der westhuysen and lesser 2007 ardhuin et al 2008 as pointed out in the original study of kc89 and recently elaborated on by banihashemi et al 2017 hereafter bkd17 the depth weighted current u does not represent a consistent approximation for the current contribution to the group velocity c g a at leading order bkd17 demonstrate the inappropriateness of the use of the weighted current u as the current speed in the expression for absolute group velocity and establish the accuracy of the alternate value u ˆ which follows naturally from consideration of the dependence of u on wavenumber k when differentiating the dispersion relation to get group velocity the accuracy of this result provides a target for determining appropriate expressions for the group velocity for use in estimating wave action flux models for spectral wave conditions more commonly solve for n x t σ θ using a spectral action balance equation which for cartesian coordinates is given by hasselmann et al 1973 2 n t h n c g a c σ n σ c θ n θ s σ where the third and fourth terms represent transport in spectral space σ θ expressions for these propagation speeds are taken from linear wave theory whitham 1974 dingemans 1997 for waves superimposed on depth uniform currents the right hand side of the equation represents source and sink terms associated with wave generation dissipation and nonlinear wave wave interactions the introduction to each source term included in swan for example can be found in booij et al 1999 in applications using wave models which take as input a single eulerian current vector at each grid point from the circulation model this approach based on a wavenumber dependent current speed is often simplified by using the current value at the peak wave frequency or wavenumber u k p for example elias et al 2012 or at some weighted average wavenumber value bkd17 further examine the effect of using either the correct or incorrect estimate of the current speed evaluated only at the spectral peak frequency the study suggested an alternate strategy involving a taylor series expansion of the depth weighted current about the peak frequency which significantly extends the range of accuracy of current information available to the wave model with minimal additional transfer of data between wave and circulation models in this study the change in the estimate of action density and action flux due to current shear is investigated using asymptotic approximations of the voronovich 1976 action balance equation obtained using a strong current extension of the kc89 perturbation solution in section 2 the problem for a linear wave in a horizontally uniform domain with arbitrary current u z is established in section 3 and appendix a kc89 s perturbation solution for weakly sheared currents is modified to allow for steady currents which are strong and oriented at arbitrary angles to the wave propagation direction approximate expressions for the wave action density and action flux are then developed following a procedure described in appendix b the approach is similar to that of quinn et al 2017 although our results differ significantly in section 4 we evaluate the approximations for the analytic case of a wave on a current with constant vorticity and establish the consistency of the expressions for action and action flux derived from the perturbation solution of kc89 section 5 considers an application to a field case involving a strongly sheared vertical profile measured in the mouth of the columbia river kilcher and nash 2010 in section 6 we extend the proposed taylor series expansion of the expressions for the wavenumber dependent approximations about the reference value at the peak frequency originally presented in bkd17 to include wave directionality and the variation in intrinsic frequency appearing in the denominator of the action density the differences between our results and those of quinn et al 2017 are discussed in section 7 along with suggestions for further work a supplement provides a number of plots comparing action density and flux estimates based on the usual depth uniform current expressions and using the surface or depth averaged currents as the representative values 2 general theory we consider the linearized problem for periodic surface waves in an incompressible inviscid fluid with wave number k and phase velocity c a ω k k ˆ propagating on a stream of velocity u z in finite water depth h here ω denotes the absolute wave frequency in a stationary frame of reference which also fixes the value of u z a unit vector pointing in the direction of wave propagation is defined as k ˆ k k the problem is formulated in terms of the vertical component of the wave orbital velocity written in complex form as 3 w x z t w z 2 e i k x ω t c c where c c denotes the complex conjugate the problem for the vertical structure of plane waves in a spatially uniform domain is then given by an extension of the rayleigh equation to allow for an oblique angle between wave and current direction as well as possible rotation of the current vector over depth 4a σ z w z z k 2 w σ z z z w h z 0 4b σ 2 0 w z 0 g k 2 σ 0 σ z 0 w 0 0 4c w h 0 where g is the gravitational constant the quantity σ z ω k u z represents a depth varying relative frequency we subsequently denote the values of current u 0 and intrinsic frequency σ 0 at the mean surface z 0 by u s and σ s respectively the amplitude of w may be related to surface displacement amplitude a through the kinematic surface boundary condition linearized w r the fluctuating motion given by 5 η t u s h η w 0 with η given by 6 η x t a 2 e i k x ω t c c leading to the relation w 0 i σ s a this result can be extended to cover the full water depth by introducing a dimensionless shape function f z according to 7 w z i σ s a f z f h 0 f 0 1 the form of 4a is intended to indicate that the problem is simply solvable for the case of current profiles without curvature or σ z z 0 the model 4a 4c has been used in a number of studies of arbitrary or idealized velocity distributions see reviews by peregrine 1976 jonsson 1990 and thomas and klopman 1997 for the general case of arbitrary u z voronovich 1976 derived a conservation law in the geometric optics approximation for an adiabatic invariant corresponding to the wave action density with n and ℱ in 1 given by 8a n ρ 4 h 0 1 σ 2 k 2 σ z z w 2 d z ρ g 2 σ 3 1 4 σ 2 k 2 σ z w 2 z 0 8b ℱ ρ 4 h 0 u σ 2 k 2 σ z z 1 σ k 2 u z z 2 k k 2 w 2 d z ρ u g 2 σ 3 1 4 σ 2 k 2 σ z 1 4 σ k 2 u z g k 2 σ 2 k 2 w 2 z 0 these results may be written in more compact form using the substitution 7 giving 9a n e 0 σ s 1 σ s 2 g k 2 σ z 0 σ s 2 h 0 σ 2 σ z z f 2 d z 9b ℱ e 0 σ s u s c r s 1 σ s 2 g h 0 f 2 d z σ s 2 g k 2 a 0 σ s 2 h 0 σ 2 a z f 2 d z where e 0 1 2 ρ g a 2 is the energy density for a wave on a depth uniform current c r s σ s k k ˆ is the wave phase velocity relative to the surface current and 10 a z σ z u z σ z u z the adiabatic invariant n in 8a or 9a is not clearly in the form of wave energy divided by frequency as expected from the work of bretherton and garrett 1968 but takes on this form in cases where analytic results for w are available such as the special case of waves on a current with constant vertical shear jonsson et al 1978 additionally the flux vector ℱ in 8b or 9b is not clearly in the form of action density times group velocity n c g a but can also be shown to be in this form for the constant shear case analytic solutions for progressive waves for the problem 4a 4c are limited to the cases of currents with constant vertical shear including the uniform over depth limit of zero shear for more complex profiles results may be obtained using perturbation solutions due to stewart and joy 1974 for deep water or skop 1987 for finite depth with solutions extended to second order by kc89 shrira 1993 has further demonstrated how series solutions for deep water may be extended to high order ellingsen and li 2017 have extended the basis for perturbation solutions to include currents with constant shear in the leading order solution alternately numerical solutions may be obtained using a variety of methods including shooting methods fenton 1973 dong and kirby 2012 or an iterative approach to the boundary value problem described by li and ellingsen 2019 used below in section 5 3 approximate solution and analysis of action and action flux expressions kc89 considered the propagation of a wave train which was colinear with the mean current and assumed that f u c 1 where f represents a froude number for the mean flow u describes the current magnitude and c is a reference phase speed usually taken to be g h here we consider the case of arbitrary orientation of wave and current and allow for strong currents f o 1 in which case the current enters the wave dispersion relation at leading order this generalization of the results of skop 1987 and kc89 has also been described previously by dong and kirby 2012 and ellingsen and li 2017 the results are repeated here as a basis for discussion of the approximate forms for action density and flux we also modify the treatment of the surface boundary condition for f z from prior studies in order to simplify numerical applications 3 1 scaling framework and series solution an appropriate scaling of the problem and the resulting perturbation solution is described in appendix a and leads to a problem characterized by parameters f describing the strength of the current ϵ characterizing the magnitude of current shear and μ characterizing the ratio of water depth to wavelength here we consider the case of μ f o 1 and ϵ 1 which allows for the development of a formally ordered expansion in powers of ϵ the solution to the resulting problem is carried out to o ϵ in appendix a in particular the intrinsic frequency σ is approximated by 11 σ z ω k u z ω k u ϵ k u 1 z σ ϵ σ 1 z where 12 u 2 k sinh 2 k h h 0 u z cosh 2 k h z d z and u 1 z u z u the vertical velocity w is given to o 1 by 13 w z i σ a f 0 z with 14 f 0 z sinh k h z sinh k h and the dispersion relation 15 σ 2 g k tanh k h the leading order correction to the vertical shape function f is given by 16 f 1 z 1 2 σ i 1 0 i 1 z i 2 0 tanh k h f 0 z i 2 z 2 k σ f 0 z z where in contrast to kc89 or quinn et al 2017 we retain the homogeneous part of the solution for f 1 z in order to specify a boundary condition f 1 0 0 as discussed in appendix a the integrals in 16 are given by i 1 z sinh 1 k h h z k ˆ u ξ ξ ξ sinh 2 k h ξ d ξ 17 i 2 z sinh 1 k h h z k ˆ u ξ ξ ξ cosh 2 k h ξ 1 d ξ the solution for w up to o ϵ is then given by 18 w i σ s a f 0 z f 1 z with σ s σ σ 1 0 σ k u 1 0 σ k u s u for later use the depth dependent intrinsic frequency σ z can also be written as 19 σ z σ s k u z u s 3 2 approximate expressions for action density and flux results presented here favor a framework where quantities are defined primarily in a frame moving with the velocity u with associated intrinsic frequency σ this choice is not unique and is often replaced by representations based on conditions at the water surface a particular example is that of quinn et al 2017 who developed asymptotic expressions for n and ℱ by starting from 8a and 8b and introducing expansions for w σ or phase speed c and for the amplitude of their w relative to surface wave amplitude a here we pursue a different approach starting from 9a and 9b where the original expressions have been simplified using the transformation 7 and the known properties of the problem prior to expansion this transformation and the simplified expressions 9a and 9b are still an exact description of the original problem in order to assess the difference between the two choices of reference frames we develop a generic approximation which specifies neither and then specialize it to the two frames of interest the basic development of the framework is described in appendix b and leads to b 4 and b 18 for action density n 0 and flux ℱ 0 in which a final choice of reference frame velocity and leading order dispersion relation has not been made as in quinn et al 2017 the choice of surface conditions as a reference leads to an expression for action density containing an o ϵ component where ϵ here is basically similar to ϵ 5 in quinn et al the expression is given here by b 19 or 20 n e 0 σ s 1 ϵ σ s σ σ s this expression is similar in form to 4 2 in quinn et al 2017 but the o ϵ components in the two studies do not appear to have a close correspondence this is discussed further in section 7 1 in contrast the approximation resulting from the choice of the depth weighted current reference frame gives the estimate b 20 or 21 n e 0 σ o ϵ 2 this result was suggested by kc89 based on an analysis of the constant shear case of section 4 but was not formally established there as a general result we note that the two formulas 20 and 21 are asymptotically equivalent to within the accuracy of the approximation which can easily be established by substituting between σ s and σ however actual numerical values from the two expressions are seen to diverge in particular examples as will be shown for a linear shear profile in section 4 and for a wind driven current in section 7 1 it is clear from these results that a formulation in terms of σ and u is a more compact version of the approximation similar treatment for the action flux b 18 leads to the expressions 22 ℱ e 0 σ s u ˆ c g r s ϵ u s σ s k ˆ k 1 g σ s σ o ϵ 2 and 23 ℱ e 0 σ u ˆ c g r o ϵ 2 we note the striking result that both versions of the approximate action flux identify u ˆ u k ˆ k u k as the correct current advection velocity the appearance of u ˆ results from the treatment of the integral of the product of the zeroth and first order shape functions f 0 and f 1 see b 13 b 17 the current u ˆ is the vector form of the advection velocity suggested by kc89 and discussed recently by bkd17 this result may be obtained directly from the definition of group velocity 24 c g a ω k σ k u k k ˆ σ k u k ˆ k u k c g r u ˆ unlike the expressions 20 and 21 for n the expressions for ℱ do not appear to be consistent with each other to the order of approximation considered an attempt to rearrange 22 to the form of 23 to within cancellation of o ϵ 2 terms leads to the result 25 ℱ e 0 σ u ˆ c g r ϵ k ˆ k 1 g σ s σ where the remaining term at o ϵ results from the treatment of the i 4 integral in b 11 or the first occurrence of 1 g in b 18 where no o ϵ expansion term occurs in the surface oriented expression whereas the o ϵ expansion term occurring in the u oriented expression cancels the second 1 g term contributed by the integral i 5 in b 17 a similar attempt to work from 23 to 22 also leaves an o ϵ residual which differs from the one in 22 the results 20 and 22 for n and ℱ are expected to be far more accurate representations of action density and flux than simple constructs based on surface or depth averaged currents but the relative accuracy of the two asymptotic approaches remains to be examined we will take up this question again in sections 4 and 7 1 4 waves on currents with constant shear in this section we examine the accuracy of the asymptotic expressions for n and ℱ for the case of waves on a current with constant vertical shear this case has been studied extensively with the basic solution described for collinear propagation in one horizontal dimension thompson 1949 and subsequently extended to two horizontal dimensions for waves oblique to the current craik 1968 ellingsen 2016 among others ellingsen 2016 provides a clear description of the influence of wave orbital motion on the vorticity field for the case of oblique waves jonsson et al 1978 gave expressions for the action density and flux for the 1d case of co linear wave and current the extension to the general case is given below based on the theory of voronovich 1976 in this section we determine the accuracy of the approximate expressions in a space covering variations of k h f θ representing the angle between the wave direction and the surface current and a shear parameter α defined below consider a current profile with constant shear and possible rotation given by 26 u z u s ω z the current shear ω does not have to be collinear with either u s or k fig 1 in this case the bvp 4a 4c simplifies and is given by σ w z z k 2 w 0 h z 0 27 σ s 2 w z 0 g k 2 σ s k ω w 0 0 w h 0 the possibility of σ z taking on a value of zero at a critical level is not typically of interest in surface wave dynamics see also ellingsen and li 2017 the solution to 27 is given by 28 w z i σ s a f z 29 u z σ s a 1 σ k ˆ k ˆ ω ω f z k ˆ k f z z 30 p z ρ σ s a k k ˆ ω f z σ k f z z with vertical shape function 31 f z sinh k h z sinh k h and with dispersion relation 32 σ s 2 g k σ s k ˆ ω tanh k h constant current shear affects the vertical structure of wave orbital velocity and wave pressure by modifying the dispersion relation and twisting wave horizontal velocity in the current shear direction absolute and relative phase speed vectors are related by 33 c a c r s k ˆ k ˆ u s where c a c a k ˆ ω k k ˆ and c r s c r s k ˆ σ s k k ˆ with subscripts s denoting values at the swl z 0 from 32 an expression for c r s is given by 34 c r s 1 2 k 4 g k tanh k h k ˆ ω tanh k h 2 1 2 k ˆ ω tanh k h inserting the wave solutions in 9a and 9b gives exact expressions for the action density and flux given by 35 n e 0 σ s 1 k ˆ ω c r s 2 g and 36 ℱ n c g a c g a u s c g r s the relative group velocity c g r s is given by 37 c g r s σ s k k ˆ g 1 g c r s k ˆ k ˆ ω 1 g ω c r s 2 2 g k ˆ ω c r s turning to the perturbation solution of section 3 we obtain results to o ϵ in the u reference frame and compare them to the full solution to determine their range of validity the weighted current u is given by 38 u u s ω tanh k h 2 k and the corresponding flux advection velocity u ˆ is then given by 39 u ˆ u k ˆ k u k u s tanh k h 2 k ω k ˆ k ˆ ω 1 g with action n and action flux ℱ determined by 21 and 23 the error 100 1 n n for the first order perturbation approximation of the action density 21 compared to the exact result from 35 is shown in fig 2 for 0 1 k h 10 π 2 θ π 2 relative angle β 0 and for different choices of current strength and shear additional results for β π 4 and π 2 are provided as figures c1 and c2 in the supplement appendix c angles θ and β represent the orientation of k and ω relative to the surface current u s as indicated in fig 1 current strength is represented through a froude number based on surface current speed f u s g h while shear is represented by dimensionless parameter α h ω u s the results show a considerably improved accuracy in the predicted action density compared to values constructed using other common approaches such as using the surface velocity u s with n given by n s e 0 σ s figures c3 c5 in supplement or depth averaged velocity u with n given by n e 0 σ σ ω k u figures c6 c8 in supplement opposing currents require a more complex calculation of blocking conditions this limit is not crucial to the development here and deserves it s own treatment in connection with wave propagation near buoyant plumes and other frontal features see bkd17 for examples of the relative magnitudes of errors in those cases an extensive comparison of the correct and approximate action flux velocities for the 1d case has been discussed in bkd17 fig 3 shows the composite error of ℱ as a function of k h and θ for β 0 using the first order perturbation approximation with additional results for β π 4 and π 2 in figures c9 and c10 in the supplement results for the same range of parameters using the surface and depth average current values are shown in figures c11 c16 in the supplement as mentioned is section 3 2 the relative accuracy of the two asymptotic approaches in the frame of reference based on the surface current and the depth weighted current remains to be examined figs 4 and 5 provide a simple comparison of eqs 20 vs 21 and 22 vs 23 the comparison is done for a linear shear profile with variation of α f and k h with θ 0 and β 0 the gain in accuracy provided by the estimates n and ℱ is shown in spite of the two expressions being asymptotically equivalent within the accuracy of the approximation 5 columbia river velocity profile in this section we compare the action densities obtained from different approximations using a measured current profile from the mouth of the columbia river mcr where fresh riverine water meets salty seawater and the current becomes strongly sheared due to stratification and tidal effects here we select a sample velocity profile collected by a pole mounted adcp during the rise project kilcher and nash 2010 the profile shown in fig 6 was also used in bkd17 and represents a maximum ebb condition for the time frame covered by the file the water depth is h 25 m the normalized shear parameter for this current profile is α 8 which indicates a strongly sheared current while the froude number is f 0 15 the current profile is assumed to be unidirectional we consider the case of waves propagating landward against the opposing current we follow a general procedure of fitting polynomials to either measured profiles or profiles taken from gridded model results in order to establish a basis for computing weighted current values expressions below are based on the form 40 u z u s n 0 n a n z h n with current speed referenced to the surface value u s and with dimensionless a n s note that a 0 1 due to the normalization by the surface current velocity while a 1 ω s h u s α where ω s is the current shear at the surface calculations here are carried out using n 6 with the fitted profile for the demonstration case also shown in fig 6 for the given profile the coefficients in 40 are then given by 41 u z 2 28 1 8 22 z h 40 26 z h 2 120 52 z h 3 197 04 z h 4 160 36 z h 5 50 85 z h 6 in the absence of an analytic solution a numerical method is used to solve the rayleigh equation in bkd17 the procedure used by dong and kirby 2012 was considered to solve the boundary value problem the vertical velocity w z was found by solving a riccati equation using a shooting method due to fenton 1973 also discussed in kc89 here we use the direct integration method dim presented by li and ellingsen 2019 which is faster and easier to parallelize than the shooting method the method starts by rewriting 4a 4c with the substitution 7 as 42a f z z k 2 f σ z z z k δ u k c r s f h z 0 42b c r s 2 c r s i c c r s c 0 2 0 where c r s is the relative wave phase speed at the surface and 43a i c c r s k u z 0 tanh k h k 2 c r s h 0 k u z z f z sinh k z h k k δ u k c r s cosh k h d z 43b c 0 2 g k tanh k h 43c f z w z w 0 43d δ u u z u s the dim method treats eqs 42a and 42b as two coupled equations with f and c r s as the unknowns and then obtains the numerical solution to the set of equations the results are used in 8a and 8b to obtain numerical values for wave action density and flux which are taken to be the reference exact solutions the accuracy of the first order perturbation approximation of the wave action density n and wave action flux ℱ relative to the numerical solution obtained from the dim is shown in fig 7 the results are plotted against a parameter k z 0 instead of k h where z 0 is specifically defined assuming a linear profile down from the surface until the current falls to zero at depth z 0 in this case the z 0 would be z 0 u s u s 0 3 m similar to the linear shear case the results show improved accuracy in the estimate of action density compared to the common approaches using depth averaged or surface current values displayed as figures c17 c20 in the supplement 6 taylor series expansion of n k and ℱ k about k p the use of the first order correction to the group velocity u ˆ and the more simplified procedure of using a single value u ˆ k p instead of the frequency dependent form has been investigated in bkd17 for the case of co linear waves and current bkd17 suggested an alternate strategy involving a taylor series expansion about the peak frequency which should significantly extend the range of accuracy of current information available to the wave model with minimal additional data transfer between wave and circulation models writing the components of the effective advection velocity as u ˆ u ˆ i u ˆ j the taylor expansion in component form is given by 44 u ˆ t i k u ˆ i k p k k p u ˆ i k k p o k k p 2 where subscript t denotes the value obtained from the truncated series using the relation between u ˆ and u gives 45 u ˆ i k u i k k k i k k u k k ˆ u i k k i k u k k ˆ k i k k 2 u k 2 the taylor series expansion in component form is then given by 46 u ˆ t i k u i k p k i p k k u k k p k p k k k p u i k k p k i p k k k p u k k p k i p k k p k k k p k p 2 u k 2 k p the same approach is used to calculate the intrinsic frequency relative to the value at the peak wave number as 47 σ t k ω k u k p k p k k k p k u k k p where we take advantage of the fact that the local value of ω is known for each frequency component returning to the case of a current with constant shear we show results for the accuracy of the action density n t for three peak wave numbers corresponding to k p h 1 2 and 3 in figs 8 10 with the peak direction θ p 0 the current non rotational over depth β 0 and a range of directions of π 3 figures c21 c23 in the supplement compare the action flux approximation ℱ p for the same cases corresponding results for action density n for the mcr current profile are provided in fig 11 for k p h 1 2 and the directional spreading of π 5 while the comparison for the action flux ℱ t is shown in figures c24 and c25 in the supplement overall it is seen that the taylor series approach provides a robust estimate for action density and action flux using only information about the depth weighted current velocity at the spectral peak frequency these expressions should be relatively simple to implement in spectral wave models but implementation would require the calculation of u k p u k k p and u k k k p in the circulation model using the 3d velocity field available there and the passage of the three vector quantities at each grid point rather than the passage of as single current velocity vector as presently implemented 7 discussion and conclusions 7 1 comparison to results of quinn et al 2017 despite the similarity in approach to developing approximations for action density and flux in this study and that of quinn et al 2017 the results are significantly different as revealed in a comparison of the two results for the analytic case of a current with constant shear for this case u 0 simplifies the result for action density 4 2 in quinn et al their general result for action density is given by 48 n q 17 e 0 σ s 1 ϵ 5 r 1 r 1 2 i 2 sinh k h 1 c 0 2 sinh 2 k h i 3 c 1 we see from 4 4 in quinn et al that for a constant shear current i 2 0 both terms 2 i 3 0 sinh 2 k h evaluated directly and c 1 in the bracketed expression in r 1 are equivalent to the expression k ˆ u for z 0 it is apparent that the first term in parentheses is the projection of the weighted average velocity k ˆ u which follows directly from the definition 12 here and the expression for i 3 as given in quinn et al s 4 4 the evaluation of c 1 from their c 7 is more ambiguous if i 1 is interpreted as usual as the starting point for the definition of u after two integrations then c 1 also is equal to k ˆ u this would then give an expression for n in our notation as 49 n q 17 e 0 σ s 1 2 k u σ o ϵ 2 on the other hand if the expression is taken literally for the constant shear case under development then c 1 evaluates to c 1 k ˆ u s c 0 2 2 g u z 0 which referring to 38 is again the depth weighted current for this special case giving the expression 49 again it is clear that this expression cannot be correct as n q 17 would have to reduce to e 0 σ s in the limit of a depth uniform current where u u s we are thus not able to explain the discrepancies between our results written in terms of surface values and the expressions provided by quinn et al 2017 in contrast the result obtained in the present study can be written as 50 n e 0 σ s 1 k σ u s u o ϵ 2 quinn et al go on to suggest below their 4 4 that using the surface current in the estimate of action instead of depth averaged current would be a reasonable no cost extension in existing models this suggestion corresponds to the results for n s and ℱ s shown in the supplement appendix c from the results there it is clear that the increase in accuracy afforded by using surface current instead of depth average current is apparent only for relatively short waves whereas the proper use of the perturbation solution or expansions based on that solution is advantageous at all water depths in order to examine the relative predictions of the asymptotic forms 20 22 vs 21 23 and to establish a basis for comparing our error estimates to a case examined by quinn et al 2017 we have repeated their analysis of a current profile given by wu and tsanis 1995 and presented in their section 5 and figs 1 4 the current profile is given by 51 u z a u ln 1 z z s b u ln 1 z z b h in which a q 2 p 1 q 2 q 1 p 2 b q 1 p 1 q 2 q 1 p 2 q 1 1 z s h ln 1 h z s 1 q 2 z s h ln 1 h z b 1 52 p 1 γ z s h p 2 γ z s z b where z b and z s are characteristic viscous sublayer thicknesses at the bottom and surface respectively and γ is a constant to characterize the intensity of the turbulence the origin of the z coordinate is located at the bottom for this velocity profile and the direction is upward a lengthscale δ s is taken to be the depth at which the current velocity falls to zero and is used as the basis for a relative wavelength parameter k δ s used in plots presented below and by quinn et al fig 12 shows errors for action density n and flux ℱ using the asymptotic expressions 21 and 23 with variation of k δ s and froude number u s c 0 the axis has been modified to be in the same format as quinn et al 2017 fig 2 for comparison however our froude number is for a larger range 0 u s c 0 1 while they have only provided results for 0 u s c 0 0 3 profile parameters are given by z s 2 2 1 0 4 h z b 1 4 1 0 4 h γ 0 35 and h 100 m the thickness of the upper layer is δ s 0 34 h in this case comparison between the results and the plots presented in their fig 2 a and d demonstrates the accuracy gain in our approximation corresponding plots for our estimates n and c g a ℱ n based on 20 and 22 are provided in fig 13 and show a marked decrease in accuracy compared to the values n and c g a ℱ n in spite of the demonstrated asymptotic equivalence of n and n with errors based on n and ℱ being up to 100 times smaller we also note that our estimates for n and ℱ in the frame of reference based on the surface current are by far more accurate than the results shown in quinn et al 2017 7 2 conclusions the results here clearly show that leading order asymptotic expressions for action density and flux are both more compact and more accurate numerically when written in terms of a depth weighted current u and corresponding intrinsic frequency σ the asymptotic expressions written in the form of 21 and 23 repeated here as 53 n e 0 σ o ϵ 2 ℱ n u ˆ c g r o ϵ 2 defer the appearance of terms which are not in the standard form for action and flux to second order in the small parameter ϵ characterizing the weak shear in the depth varying current profile they provide a relatively more accurate estimate of the quantities in question than corresponding asymptotic forms 21 and 23 based on surface current u s when compared to exact values obtained analytically or numerically as shown for the analytic example of a current with constant shear in section 4 and for the strongly sheared profile of wu and tsanis 1995 in section 7 1 we have further extended the suggestion of bkd17 to represent current information using a taylor expansion around the peak wavenumber in a modeled spectrum with extensions covering the specification of action flux and intrinsic frequency as well as an extension to a general 2d horizontal setting these results provide an avenue for calculating wave action and action flux in spectral wave models using a compact set of information about the current field evaluated at the spectral peak wavenumber the coupling would require that the wave model accepts the values u u ˆ and u ˆ k at each grid point and corresponding changes would need to be made to the specification of action density and group velocity as a function of frequency and direction within the wave model formulation these are not huge changes and hopefully can be implemented in the near future the corresponding effects on model source terms such as the representation of nonlinear interactions is still an open area for research acknowledgments this work was supported by grants oce 1334325 oce 1435147 and oce 1756355 from the physical oceanography program national science foundation computational resources were provided by instructional technology university of delaware appendix a scaling and perturbation solution for the strong current weak shear case the theoretical development in kc89 and bkd17 is based on a framework that assumes that the steady current is small compared to wave phase speed with current shear and profile curvature comparably small here we provide a scaling analysis and perturbation solution that generalizes the problem to the case of a strong depth uniform current component and arbitrary current orientation in horizontal coordinates but with deviations from depth uniformity assumed to be weak conceptually the approach is to write the mean current vector u z as u 0 u 1 z where the second component carries the information about weak shear and rotation over depth we do not make an a priori choice of how to make this split into two components and as will be seen below the solution itself suggests that u 1 be chosen so as to have a weighted depth average value of 0 when weighted according to the kc89 procedure to develop the non dimensional form of 4a 4c we introduce the scales ω 0 for frequency or inverse time k 0 for wavenumber or inverse horizontal distance and scale vertical coordinate z by uniform depth h vertical velocity is scaled by its value at the free surface determined by the kinematic boundary condition as a 1 w z i σ s a f z where σ s is intrinsic frequency at z 0 a is surface wave amplitude and f z is a dimensionless shape function intrinsic frequency σ is given by a 2 σ z ω k u z ω k u 0 k u 1 z σ 0 σ 1 z we define a reference phase speed c 0 ω 0 k 0 and use c 0 g h which fixes the relationship between ω 0 and k 0 for the monochromatic case studied here we identify ω 0 with ω finally we scale strong depth uniform current u 0 by u and weak current u 1 by h ω where ω represents the strength of current shear or rotation over depth referring to 4a 4c we introduce dimensionless parameters σ σ ω 0 and k k k 0 the resulting dimensionless problem with primes dropped is then given by σ z f z z k 2 μ 2 f ϵ σ 1 z z f 1 z 0 a 3 σ s 2 f z 0 k 2 ϵ σ s σ 1 z 0 f 0 1 f 1 0 with a 4 σ z σ 0 ϵ σ 1 z 1 f k u 0 ϵ k u 1 z dimensionless parameters are μ k 0 h o 1 f u c 0 o 1 and ϵ μ ω ω 0 1 where μ is the usual dispersion parameter resulting from scaling depth by h and horizontal distance by k 0 1 f is a froude number and ϵ 1 is a small parameter characterizing current shear the alternate approach employed by ellingsen and li 2017 where shear is allowed to be strong but curvature weak would employ the regime f ϵ o 1 with a new small parameter required to characterize the weak curvature following kc89 we next solve the system a 3 using a regular perturbation expansion a 5 f z n 0 n ϵ n f n z with f n 1 0 in contrast to kc89 we take f 0 0 1 to satisfy the entire surface boundary condition for f giving homogeneous conditions f n 0 0 for n 0 introducing a 4 and a 5 in a 3 and sorting by powers of ϵ gives the governing equations and surface boundary conditions a 6 σ 0 f n z z k 2 μ 2 f n h n z a 7 σ 0 2 f n z 0 s n at n 0 we have h 0 0 s 0 1 and we get the solution a 8 f 0 z sinh μ k 1 z sinh μ k with a 9 σ 0 2 k tanh μ k μ which is the usual solution for waves on a depth uniform current for higher orders n 1 use of green s law for f 0 and f n leads to a solvability condition a 10 1 0 f 0 h n d z s n at n 1 the leading order at which current shear has an effect we have a 11 h 1 z σ 1 z z σ 0 f 0 z s 1 σ 1 z 0 σ 0 2 k 2 σ 1 0 σ 0 3 using a 11 in a 10 leads after cancellations to the identity a 12 1 0 σ 1 z cosh 2 μ k 1 z d z k 1 0 u 1 z cosh 2 μ k 1 z d z 0 but u 1 u u 0 ϵ which when substituted in a 12 gives the result a 13 u 0 u 2 μ k sinh 2 μ k 1 0 u z cosh 2 μ k 1 z d z where u is the depth weighted current from kc89 extended to allow for f o 1 and arbitrary direction relative to the wave direction we thus have the leading order expression for intrinsic frequency σ 0 σ 1 f k u with leading order dispersion relation a 14 σ 2 k tanh μ k μ the expression for phase speed c a in a fixed frame is given by a 15 c a ω k σ k u o ϵ 2 with no further correction to phase speed at o ϵ eqs a 6 a 7 may then be solved for f 1 z following the procedure in kc89 giving the result a 16 f 1 z a 1 1 μ k 1 z h 1 ξ f 0 ξ ξ d ξ f 0 z b 1 1 μ k 1 z h 1 ξ f 0 ξ d ξ f 0 z z with the coefficients a 1 and b 1 of the homogeneous solution resolved by applying the boundary conditions f 1 0 f 1 1 0 dimensional forms of the results are given in section 3 1 appendix b approximations for weak current shear starting with the expressions 9a and 9b for action density and flux we develop expansions in powers of ϵ consistent with the approach in appendix a in 9a and 9b explicit appearances of σ s and u s occur due to the satisfaction of the surface boundary condition and the transformation 7 we assume these should be common to all versions of the expansion that follows subsequently we express f z as in a 5 and use 14 and 16 we then introduce an arbitrary version of the depth uniform current and resulting intrinsic frequency u 0 and σ 0 as representations of the leading order solution u z u 0 ϵ u 1 z b 1 σ z σ 0 ϵ σ 1 z where σ 0 ω k u 0 and σ 1 k u 1 k u u 0 and with associated dispersion relation b 2 σ 0 2 g k tanh k h after some simplification of the resulting forms of n and ℱ we obtain approximate forms consistent with the present derivation through the choice u 0 u and σ 0 σ we also develop an alternate version based on the choice u 0 u s and σ 0 σ s which leads to expressions for action and flux defined in terms of surface variables as in quinn et al 2017 it was our initial expectation that this procedure should reproduce the results in quinn et al 2017 which are described as being based on the approximate wave current formulation here and in kc89 but we have not been able to reproduce the results given by quinn et al 2017 as discussed in section 7 1 substituting the expressions b 1 and the expansion for f z into the formulas 9a and 9b and retaining terms to o ϵ leads to the generic version of the expansion where any remaining occurrences of frequency or current are expressed in terms of σ 0 and u 0 during this process expressions occurring in terms of o ϵ may be manipulated by choosing σ 0 σ s or σ freely since transformations between these quantities would occur at o ϵ 2 in contrast occurrences of σ 0 in o 1 terms must retain the implied ambiguity as it s resolution would occur within the accuracy of the approximation proceeding with 9a for the action density we note that the integral term is of o ϵ since σ ϵ σ 1 for any choice of reference frame recognizing that σ s σ 0 1 o ϵ for any choice of reference frame making σ 1 small we obtain the approximate expression b 3 n e 0 σ s 1 ϵ σ s 2 g k 2 σ 1 z 0 h 0 σ 1 z z f 0 2 d z o ϵ 2 the expression in the interior parentheses may be integrated immediately and we obtain the approximation b 4 n 0 e 0 σ s 1 ϵ σ s σ 0 2 σ s σ o ϵ 2 where the single appearance of σ 0 results from a resolution of the combination σ 0 2 g k tanh k h turning to the expression for action flux 9b we note that the first integral term involving f 2 occurs at leading order and thus the ambiguity of the value of σ 0 must be retained there we proceed as before by substituting the expansions b 1 the expression a z may be expanded as a a 0 ϵ a 1 o ϵ 2 and we find that a 0 0 and b 5 a 1 z σ 0 u 1 z u 0 σ 1 z so that the integral involving a z is reduced to b 6 σ s 2 h 0 σ 2 a z f 2 d z ϵ σ s 2 σ s 2 o ϵ h 0 a 1 z f 0 2 d z o ϵ 2 the entire bracketed expression involving a in 9b is then evaluated as b 7 ϵ a 1 0 h 0 a 1 z f 0 2 d z ϵ k sinh 2 k h i 3 where b 8 i 3 h 0 a 1 z sinh 2 k h z d z the integral of f 2 is expanded to give b 9 h 0 f 2 d z i 4 2 ϵ i 5 o ϵ 2 with b 10 i 4 h 0 f 0 2 d z i 5 h 0 f 0 f 1 d z and with f 1 given by 16 the resulting expression for the approximation ℱ 0 is then b 11 ℱ 0 e 0 σ s u s c r s 1 σ s 2 g i 4 ϵ e 0 σ s c r s 2 σ s 2 g i 5 σ s σ 0 2 sinh 2 k h i 3 integrals i 3 and i 4 are given to the required order by i 3 sinh 2 k h σ 0 u s u u 0 σ σ s b 12 i 4 g 2 σ 0 2 1 g g 2 k h sinh 2 k h the expression for i 5 is complex and is given after some initial effort by b 13 i 5 1 4 σ sinh 2 k h g cosh 2 k h k i 2 0 i 6 where from 17 b 14 i 2 0 2 sinh 2 k h k ˆ u z 0 2 sinh 2 k h σ s σ and b 15 i 6 h 0 k ˆ u z z z h z sinh 2 k h z d z an expression for i 6 is obtained by first expressing u in terms of u z z using two integrations by parts differentiating the resulting expression with respect to wavenumber k and taking the dot product with the unit wavenumber k ˆ to obtain after rearrangement b 16 i 6 sinh 2 k h k u k h k ˆ u 1 z 0 1 k 1 g 2 g cosh 2 k h σ s σ using b 14 and b 16 in b 13 leads to a relatively compact expression for i 5 given by b 17 i 5 1 2 σ tanh k h k u k 1 k 1 g σ s σ using the results for i 3 i 4 and i 5 in b 11 leads finally to b 18 ℱ 0 e 0 σ s u s c r s 1 1 2 σ s σ 0 2 1 g ϵ e 0 σ s σ s 3 k ˆ σ σ 0 2 k u k 1 k 1 g σ s σ σ s σ 0 2 σ 0 u s u σ σ s u 0 from this point the resolution of the expressions for n 0 and ℱ 0 involves the choice of σ 0 following the procedure of referencing all quantities to surface conditions leads to an expression for n 0 given by b 19 n n 0 σ s e 0 σ s 1 ϵ σ s σ σ s o ϵ 2 this result is similar in form to that in quinn et al 2017 equation 4 2 but there is no clear relation between the residual o ϵ terms in the two results as discussed further in section 7 1 taking the alternate approach of referencing quantities to the frame moving with speed u leads to the expression b 20 n n 0 σ e 0 σ o ϵ 2 where all information about the approximation within the order of accuracy is contained in the simple ratio of e 0 and σ the same process applied to ℱ 0 in b 18 leads to the expressions b 21 ℱ e 0 σ s u ˆ c g r s ϵ u s σ s σ σ s k ˆ k 1 g σ s σ o ϵ 2 and b 22 ℱ e 0 σ u ˆ c g r o ϵ 2 where c g r s and c g r are relative group velocities defined in the usual sense for a depth uniform current relative to the surface and depth weighted velocities respectively appendix c results for errors in wave action density and flux for additional cases supplementary material related to this article can be found online at http dx doi org 10 1016 j ocemod 2019 101460 appendix c results for errors in wave action density and flux for additional cases the following is the supplementary material related to this article mmc s1 
24009,we develop asymptotic expressions for wave action density and action flux using an extension of kirby chen 1989 s perturbation solution for weakly sheared currents allowing for a basic flow with froude number f u g h o 1 but with weak vertical shear the accuracy of the expressions for action density and flux is established by comparison to analytic results for a current with constant shear and to numerical results for a field case involving a buoyant ebb tidal plume with strong vertical shear and for a case involving a numerically determined profile for a wind driven current we compare our results to those from recent work of quinn et al 2017 and find unresolved discrepancies in that prior work we provide additional suggestions for efficiently implementing the required extensions in coupled wave circulation models using a taylor series expansion based on conditions at peak frequency and direction these results generalize the previous work of banihashemi et al 2017 to motions in two horizontal dimensions and cover the determination of the wave action keywords wave current interaction wave action conservation ocean models waves over sheared currents 1 introduction significant advances have been made in the numerical modeling of wave current interaction in recent decades an important component in these advances has been the recognition of wave action as the fundamental conserved quantity expressing the wave averaged energy of a slowly varying wave train the simplest description is typically based on the underlying dynamics for monochromatic waves governed by the wave action balance of bretherton and garrett 1968 and given by 1 n t h ℱ 0 where subscripted commas denote partial differentiation for the case of depth uniform mean current u action density n e σ and action flux ℱ n c g a where e is energy density σ ω k u g k tanh k h is intrinsic frequency h and k k are depth and wavenumber and c g a ω k σ k u is the absolute group velocity vector in stationary coordinates phase averaged spectral wave models typically calculate wave properties based on the linear theory for waves superposed on depth uniform currents however currents in the field are occasionallystrongly sheared over the vertical leading to the need for a treatment of the rotationality or shear in the flow field an approximate treatment for the effect of current shear may be based on a perturbation approach that has been developed through a sequence of papers stewart and joy 1974 skop 1987 kirby and chen 1989 ellingsen and li 2017 with kirby and chen 1989 hereafter referred to as kc89 providing a solution to second order for the finite depth case for currents that are assumed to deviate only weakly from depth uniformity the main utility of the approximate solution has been the specification of a depth weighted current u specified by skop 1987 and kc89 and given by 12 as a representative depth uniform current for determining intrinsic frequency and action density in spectral wave models van der westhuysen and lesser 2007 ardhuin et al 2008 as pointed out in the original study of kc89 and recently elaborated on by banihashemi et al 2017 hereafter bkd17 the depth weighted current u does not represent a consistent approximation for the current contribution to the group velocity c g a at leading order bkd17 demonstrate the inappropriateness of the use of the weighted current u as the current speed in the expression for absolute group velocity and establish the accuracy of the alternate value u ˆ which follows naturally from consideration of the dependence of u on wavenumber k when differentiating the dispersion relation to get group velocity the accuracy of this result provides a target for determining appropriate expressions for the group velocity for use in estimating wave action flux models for spectral wave conditions more commonly solve for n x t σ θ using a spectral action balance equation which for cartesian coordinates is given by hasselmann et al 1973 2 n t h n c g a c σ n σ c θ n θ s σ where the third and fourth terms represent transport in spectral space σ θ expressions for these propagation speeds are taken from linear wave theory whitham 1974 dingemans 1997 for waves superimposed on depth uniform currents the right hand side of the equation represents source and sink terms associated with wave generation dissipation and nonlinear wave wave interactions the introduction to each source term included in swan for example can be found in booij et al 1999 in applications using wave models which take as input a single eulerian current vector at each grid point from the circulation model this approach based on a wavenumber dependent current speed is often simplified by using the current value at the peak wave frequency or wavenumber u k p for example elias et al 2012 or at some weighted average wavenumber value bkd17 further examine the effect of using either the correct or incorrect estimate of the current speed evaluated only at the spectral peak frequency the study suggested an alternate strategy involving a taylor series expansion of the depth weighted current about the peak frequency which significantly extends the range of accuracy of current information available to the wave model with minimal additional transfer of data between wave and circulation models in this study the change in the estimate of action density and action flux due to current shear is investigated using asymptotic approximations of the voronovich 1976 action balance equation obtained using a strong current extension of the kc89 perturbation solution in section 2 the problem for a linear wave in a horizontally uniform domain with arbitrary current u z is established in section 3 and appendix a kc89 s perturbation solution for weakly sheared currents is modified to allow for steady currents which are strong and oriented at arbitrary angles to the wave propagation direction approximate expressions for the wave action density and action flux are then developed following a procedure described in appendix b the approach is similar to that of quinn et al 2017 although our results differ significantly in section 4 we evaluate the approximations for the analytic case of a wave on a current with constant vorticity and establish the consistency of the expressions for action and action flux derived from the perturbation solution of kc89 section 5 considers an application to a field case involving a strongly sheared vertical profile measured in the mouth of the columbia river kilcher and nash 2010 in section 6 we extend the proposed taylor series expansion of the expressions for the wavenumber dependent approximations about the reference value at the peak frequency originally presented in bkd17 to include wave directionality and the variation in intrinsic frequency appearing in the denominator of the action density the differences between our results and those of quinn et al 2017 are discussed in section 7 along with suggestions for further work a supplement provides a number of plots comparing action density and flux estimates based on the usual depth uniform current expressions and using the surface or depth averaged currents as the representative values 2 general theory we consider the linearized problem for periodic surface waves in an incompressible inviscid fluid with wave number k and phase velocity c a ω k k ˆ propagating on a stream of velocity u z in finite water depth h here ω denotes the absolute wave frequency in a stationary frame of reference which also fixes the value of u z a unit vector pointing in the direction of wave propagation is defined as k ˆ k k the problem is formulated in terms of the vertical component of the wave orbital velocity written in complex form as 3 w x z t w z 2 e i k x ω t c c where c c denotes the complex conjugate the problem for the vertical structure of plane waves in a spatially uniform domain is then given by an extension of the rayleigh equation to allow for an oblique angle between wave and current direction as well as possible rotation of the current vector over depth 4a σ z w z z k 2 w σ z z z w h z 0 4b σ 2 0 w z 0 g k 2 σ 0 σ z 0 w 0 0 4c w h 0 where g is the gravitational constant the quantity σ z ω k u z represents a depth varying relative frequency we subsequently denote the values of current u 0 and intrinsic frequency σ 0 at the mean surface z 0 by u s and σ s respectively the amplitude of w may be related to surface displacement amplitude a through the kinematic surface boundary condition linearized w r the fluctuating motion given by 5 η t u s h η w 0 with η given by 6 η x t a 2 e i k x ω t c c leading to the relation w 0 i σ s a this result can be extended to cover the full water depth by introducing a dimensionless shape function f z according to 7 w z i σ s a f z f h 0 f 0 1 the form of 4a is intended to indicate that the problem is simply solvable for the case of current profiles without curvature or σ z z 0 the model 4a 4c has been used in a number of studies of arbitrary or idealized velocity distributions see reviews by peregrine 1976 jonsson 1990 and thomas and klopman 1997 for the general case of arbitrary u z voronovich 1976 derived a conservation law in the geometric optics approximation for an adiabatic invariant corresponding to the wave action density with n and ℱ in 1 given by 8a n ρ 4 h 0 1 σ 2 k 2 σ z z w 2 d z ρ g 2 σ 3 1 4 σ 2 k 2 σ z w 2 z 0 8b ℱ ρ 4 h 0 u σ 2 k 2 σ z z 1 σ k 2 u z z 2 k k 2 w 2 d z ρ u g 2 σ 3 1 4 σ 2 k 2 σ z 1 4 σ k 2 u z g k 2 σ 2 k 2 w 2 z 0 these results may be written in more compact form using the substitution 7 giving 9a n e 0 σ s 1 σ s 2 g k 2 σ z 0 σ s 2 h 0 σ 2 σ z z f 2 d z 9b ℱ e 0 σ s u s c r s 1 σ s 2 g h 0 f 2 d z σ s 2 g k 2 a 0 σ s 2 h 0 σ 2 a z f 2 d z where e 0 1 2 ρ g a 2 is the energy density for a wave on a depth uniform current c r s σ s k k ˆ is the wave phase velocity relative to the surface current and 10 a z σ z u z σ z u z the adiabatic invariant n in 8a or 9a is not clearly in the form of wave energy divided by frequency as expected from the work of bretherton and garrett 1968 but takes on this form in cases where analytic results for w are available such as the special case of waves on a current with constant vertical shear jonsson et al 1978 additionally the flux vector ℱ in 8b or 9b is not clearly in the form of action density times group velocity n c g a but can also be shown to be in this form for the constant shear case analytic solutions for progressive waves for the problem 4a 4c are limited to the cases of currents with constant vertical shear including the uniform over depth limit of zero shear for more complex profiles results may be obtained using perturbation solutions due to stewart and joy 1974 for deep water or skop 1987 for finite depth with solutions extended to second order by kc89 shrira 1993 has further demonstrated how series solutions for deep water may be extended to high order ellingsen and li 2017 have extended the basis for perturbation solutions to include currents with constant shear in the leading order solution alternately numerical solutions may be obtained using a variety of methods including shooting methods fenton 1973 dong and kirby 2012 or an iterative approach to the boundary value problem described by li and ellingsen 2019 used below in section 5 3 approximate solution and analysis of action and action flux expressions kc89 considered the propagation of a wave train which was colinear with the mean current and assumed that f u c 1 where f represents a froude number for the mean flow u describes the current magnitude and c is a reference phase speed usually taken to be g h here we consider the case of arbitrary orientation of wave and current and allow for strong currents f o 1 in which case the current enters the wave dispersion relation at leading order this generalization of the results of skop 1987 and kc89 has also been described previously by dong and kirby 2012 and ellingsen and li 2017 the results are repeated here as a basis for discussion of the approximate forms for action density and flux we also modify the treatment of the surface boundary condition for f z from prior studies in order to simplify numerical applications 3 1 scaling framework and series solution an appropriate scaling of the problem and the resulting perturbation solution is described in appendix a and leads to a problem characterized by parameters f describing the strength of the current ϵ characterizing the magnitude of current shear and μ characterizing the ratio of water depth to wavelength here we consider the case of μ f o 1 and ϵ 1 which allows for the development of a formally ordered expansion in powers of ϵ the solution to the resulting problem is carried out to o ϵ in appendix a in particular the intrinsic frequency σ is approximated by 11 σ z ω k u z ω k u ϵ k u 1 z σ ϵ σ 1 z where 12 u 2 k sinh 2 k h h 0 u z cosh 2 k h z d z and u 1 z u z u the vertical velocity w is given to o 1 by 13 w z i σ a f 0 z with 14 f 0 z sinh k h z sinh k h and the dispersion relation 15 σ 2 g k tanh k h the leading order correction to the vertical shape function f is given by 16 f 1 z 1 2 σ i 1 0 i 1 z i 2 0 tanh k h f 0 z i 2 z 2 k σ f 0 z z where in contrast to kc89 or quinn et al 2017 we retain the homogeneous part of the solution for f 1 z in order to specify a boundary condition f 1 0 0 as discussed in appendix a the integrals in 16 are given by i 1 z sinh 1 k h h z k ˆ u ξ ξ ξ sinh 2 k h ξ d ξ 17 i 2 z sinh 1 k h h z k ˆ u ξ ξ ξ cosh 2 k h ξ 1 d ξ the solution for w up to o ϵ is then given by 18 w i σ s a f 0 z f 1 z with σ s σ σ 1 0 σ k u 1 0 σ k u s u for later use the depth dependent intrinsic frequency σ z can also be written as 19 σ z σ s k u z u s 3 2 approximate expressions for action density and flux results presented here favor a framework where quantities are defined primarily in a frame moving with the velocity u with associated intrinsic frequency σ this choice is not unique and is often replaced by representations based on conditions at the water surface a particular example is that of quinn et al 2017 who developed asymptotic expressions for n and ℱ by starting from 8a and 8b and introducing expansions for w σ or phase speed c and for the amplitude of their w relative to surface wave amplitude a here we pursue a different approach starting from 9a and 9b where the original expressions have been simplified using the transformation 7 and the known properties of the problem prior to expansion this transformation and the simplified expressions 9a and 9b are still an exact description of the original problem in order to assess the difference between the two choices of reference frames we develop a generic approximation which specifies neither and then specialize it to the two frames of interest the basic development of the framework is described in appendix b and leads to b 4 and b 18 for action density n 0 and flux ℱ 0 in which a final choice of reference frame velocity and leading order dispersion relation has not been made as in quinn et al 2017 the choice of surface conditions as a reference leads to an expression for action density containing an o ϵ component where ϵ here is basically similar to ϵ 5 in quinn et al the expression is given here by b 19 or 20 n e 0 σ s 1 ϵ σ s σ σ s this expression is similar in form to 4 2 in quinn et al 2017 but the o ϵ components in the two studies do not appear to have a close correspondence this is discussed further in section 7 1 in contrast the approximation resulting from the choice of the depth weighted current reference frame gives the estimate b 20 or 21 n e 0 σ o ϵ 2 this result was suggested by kc89 based on an analysis of the constant shear case of section 4 but was not formally established there as a general result we note that the two formulas 20 and 21 are asymptotically equivalent to within the accuracy of the approximation which can easily be established by substituting between σ s and σ however actual numerical values from the two expressions are seen to diverge in particular examples as will be shown for a linear shear profile in section 4 and for a wind driven current in section 7 1 it is clear from these results that a formulation in terms of σ and u is a more compact version of the approximation similar treatment for the action flux b 18 leads to the expressions 22 ℱ e 0 σ s u ˆ c g r s ϵ u s σ s k ˆ k 1 g σ s σ o ϵ 2 and 23 ℱ e 0 σ u ˆ c g r o ϵ 2 we note the striking result that both versions of the approximate action flux identify u ˆ u k ˆ k u k as the correct current advection velocity the appearance of u ˆ results from the treatment of the integral of the product of the zeroth and first order shape functions f 0 and f 1 see b 13 b 17 the current u ˆ is the vector form of the advection velocity suggested by kc89 and discussed recently by bkd17 this result may be obtained directly from the definition of group velocity 24 c g a ω k σ k u k k ˆ σ k u k ˆ k u k c g r u ˆ unlike the expressions 20 and 21 for n the expressions for ℱ do not appear to be consistent with each other to the order of approximation considered an attempt to rearrange 22 to the form of 23 to within cancellation of o ϵ 2 terms leads to the result 25 ℱ e 0 σ u ˆ c g r ϵ k ˆ k 1 g σ s σ where the remaining term at o ϵ results from the treatment of the i 4 integral in b 11 or the first occurrence of 1 g in b 18 where no o ϵ expansion term occurs in the surface oriented expression whereas the o ϵ expansion term occurring in the u oriented expression cancels the second 1 g term contributed by the integral i 5 in b 17 a similar attempt to work from 23 to 22 also leaves an o ϵ residual which differs from the one in 22 the results 20 and 22 for n and ℱ are expected to be far more accurate representations of action density and flux than simple constructs based on surface or depth averaged currents but the relative accuracy of the two asymptotic approaches remains to be examined we will take up this question again in sections 4 and 7 1 4 waves on currents with constant shear in this section we examine the accuracy of the asymptotic expressions for n and ℱ for the case of waves on a current with constant vertical shear this case has been studied extensively with the basic solution described for collinear propagation in one horizontal dimension thompson 1949 and subsequently extended to two horizontal dimensions for waves oblique to the current craik 1968 ellingsen 2016 among others ellingsen 2016 provides a clear description of the influence of wave orbital motion on the vorticity field for the case of oblique waves jonsson et al 1978 gave expressions for the action density and flux for the 1d case of co linear wave and current the extension to the general case is given below based on the theory of voronovich 1976 in this section we determine the accuracy of the approximate expressions in a space covering variations of k h f θ representing the angle between the wave direction and the surface current and a shear parameter α defined below consider a current profile with constant shear and possible rotation given by 26 u z u s ω z the current shear ω does not have to be collinear with either u s or k fig 1 in this case the bvp 4a 4c simplifies and is given by σ w z z k 2 w 0 h z 0 27 σ s 2 w z 0 g k 2 σ s k ω w 0 0 w h 0 the possibility of σ z taking on a value of zero at a critical level is not typically of interest in surface wave dynamics see also ellingsen and li 2017 the solution to 27 is given by 28 w z i σ s a f z 29 u z σ s a 1 σ k ˆ k ˆ ω ω f z k ˆ k f z z 30 p z ρ σ s a k k ˆ ω f z σ k f z z with vertical shape function 31 f z sinh k h z sinh k h and with dispersion relation 32 σ s 2 g k σ s k ˆ ω tanh k h constant current shear affects the vertical structure of wave orbital velocity and wave pressure by modifying the dispersion relation and twisting wave horizontal velocity in the current shear direction absolute and relative phase speed vectors are related by 33 c a c r s k ˆ k ˆ u s where c a c a k ˆ ω k k ˆ and c r s c r s k ˆ σ s k k ˆ with subscripts s denoting values at the swl z 0 from 32 an expression for c r s is given by 34 c r s 1 2 k 4 g k tanh k h k ˆ ω tanh k h 2 1 2 k ˆ ω tanh k h inserting the wave solutions in 9a and 9b gives exact expressions for the action density and flux given by 35 n e 0 σ s 1 k ˆ ω c r s 2 g and 36 ℱ n c g a c g a u s c g r s the relative group velocity c g r s is given by 37 c g r s σ s k k ˆ g 1 g c r s k ˆ k ˆ ω 1 g ω c r s 2 2 g k ˆ ω c r s turning to the perturbation solution of section 3 we obtain results to o ϵ in the u reference frame and compare them to the full solution to determine their range of validity the weighted current u is given by 38 u u s ω tanh k h 2 k and the corresponding flux advection velocity u ˆ is then given by 39 u ˆ u k ˆ k u k u s tanh k h 2 k ω k ˆ k ˆ ω 1 g with action n and action flux ℱ determined by 21 and 23 the error 100 1 n n for the first order perturbation approximation of the action density 21 compared to the exact result from 35 is shown in fig 2 for 0 1 k h 10 π 2 θ π 2 relative angle β 0 and for different choices of current strength and shear additional results for β π 4 and π 2 are provided as figures c1 and c2 in the supplement appendix c angles θ and β represent the orientation of k and ω relative to the surface current u s as indicated in fig 1 current strength is represented through a froude number based on surface current speed f u s g h while shear is represented by dimensionless parameter α h ω u s the results show a considerably improved accuracy in the predicted action density compared to values constructed using other common approaches such as using the surface velocity u s with n given by n s e 0 σ s figures c3 c5 in supplement or depth averaged velocity u with n given by n e 0 σ σ ω k u figures c6 c8 in supplement opposing currents require a more complex calculation of blocking conditions this limit is not crucial to the development here and deserves it s own treatment in connection with wave propagation near buoyant plumes and other frontal features see bkd17 for examples of the relative magnitudes of errors in those cases an extensive comparison of the correct and approximate action flux velocities for the 1d case has been discussed in bkd17 fig 3 shows the composite error of ℱ as a function of k h and θ for β 0 using the first order perturbation approximation with additional results for β π 4 and π 2 in figures c9 and c10 in the supplement results for the same range of parameters using the surface and depth average current values are shown in figures c11 c16 in the supplement as mentioned is section 3 2 the relative accuracy of the two asymptotic approaches in the frame of reference based on the surface current and the depth weighted current remains to be examined figs 4 and 5 provide a simple comparison of eqs 20 vs 21 and 22 vs 23 the comparison is done for a linear shear profile with variation of α f and k h with θ 0 and β 0 the gain in accuracy provided by the estimates n and ℱ is shown in spite of the two expressions being asymptotically equivalent within the accuracy of the approximation 5 columbia river velocity profile in this section we compare the action densities obtained from different approximations using a measured current profile from the mouth of the columbia river mcr where fresh riverine water meets salty seawater and the current becomes strongly sheared due to stratification and tidal effects here we select a sample velocity profile collected by a pole mounted adcp during the rise project kilcher and nash 2010 the profile shown in fig 6 was also used in bkd17 and represents a maximum ebb condition for the time frame covered by the file the water depth is h 25 m the normalized shear parameter for this current profile is α 8 which indicates a strongly sheared current while the froude number is f 0 15 the current profile is assumed to be unidirectional we consider the case of waves propagating landward against the opposing current we follow a general procedure of fitting polynomials to either measured profiles or profiles taken from gridded model results in order to establish a basis for computing weighted current values expressions below are based on the form 40 u z u s n 0 n a n z h n with current speed referenced to the surface value u s and with dimensionless a n s note that a 0 1 due to the normalization by the surface current velocity while a 1 ω s h u s α where ω s is the current shear at the surface calculations here are carried out using n 6 with the fitted profile for the demonstration case also shown in fig 6 for the given profile the coefficients in 40 are then given by 41 u z 2 28 1 8 22 z h 40 26 z h 2 120 52 z h 3 197 04 z h 4 160 36 z h 5 50 85 z h 6 in the absence of an analytic solution a numerical method is used to solve the rayleigh equation in bkd17 the procedure used by dong and kirby 2012 was considered to solve the boundary value problem the vertical velocity w z was found by solving a riccati equation using a shooting method due to fenton 1973 also discussed in kc89 here we use the direct integration method dim presented by li and ellingsen 2019 which is faster and easier to parallelize than the shooting method the method starts by rewriting 4a 4c with the substitution 7 as 42a f z z k 2 f σ z z z k δ u k c r s f h z 0 42b c r s 2 c r s i c c r s c 0 2 0 where c r s is the relative wave phase speed at the surface and 43a i c c r s k u z 0 tanh k h k 2 c r s h 0 k u z z f z sinh k z h k k δ u k c r s cosh k h d z 43b c 0 2 g k tanh k h 43c f z w z w 0 43d δ u u z u s the dim method treats eqs 42a and 42b as two coupled equations with f and c r s as the unknowns and then obtains the numerical solution to the set of equations the results are used in 8a and 8b to obtain numerical values for wave action density and flux which are taken to be the reference exact solutions the accuracy of the first order perturbation approximation of the wave action density n and wave action flux ℱ relative to the numerical solution obtained from the dim is shown in fig 7 the results are plotted against a parameter k z 0 instead of k h where z 0 is specifically defined assuming a linear profile down from the surface until the current falls to zero at depth z 0 in this case the z 0 would be z 0 u s u s 0 3 m similar to the linear shear case the results show improved accuracy in the estimate of action density compared to the common approaches using depth averaged or surface current values displayed as figures c17 c20 in the supplement 6 taylor series expansion of n k and ℱ k about k p the use of the first order correction to the group velocity u ˆ and the more simplified procedure of using a single value u ˆ k p instead of the frequency dependent form has been investigated in bkd17 for the case of co linear waves and current bkd17 suggested an alternate strategy involving a taylor series expansion about the peak frequency which should significantly extend the range of accuracy of current information available to the wave model with minimal additional data transfer between wave and circulation models writing the components of the effective advection velocity as u ˆ u ˆ i u ˆ j the taylor expansion in component form is given by 44 u ˆ t i k u ˆ i k p k k p u ˆ i k k p o k k p 2 where subscript t denotes the value obtained from the truncated series using the relation between u ˆ and u gives 45 u ˆ i k u i k k k i k k u k k ˆ u i k k i k u k k ˆ k i k k 2 u k 2 the taylor series expansion in component form is then given by 46 u ˆ t i k u i k p k i p k k u k k p k p k k k p u i k k p k i p k k k p u k k p k i p k k p k k k p k p 2 u k 2 k p the same approach is used to calculate the intrinsic frequency relative to the value at the peak wave number as 47 σ t k ω k u k p k p k k k p k u k k p where we take advantage of the fact that the local value of ω is known for each frequency component returning to the case of a current with constant shear we show results for the accuracy of the action density n t for three peak wave numbers corresponding to k p h 1 2 and 3 in figs 8 10 with the peak direction θ p 0 the current non rotational over depth β 0 and a range of directions of π 3 figures c21 c23 in the supplement compare the action flux approximation ℱ p for the same cases corresponding results for action density n for the mcr current profile are provided in fig 11 for k p h 1 2 and the directional spreading of π 5 while the comparison for the action flux ℱ t is shown in figures c24 and c25 in the supplement overall it is seen that the taylor series approach provides a robust estimate for action density and action flux using only information about the depth weighted current velocity at the spectral peak frequency these expressions should be relatively simple to implement in spectral wave models but implementation would require the calculation of u k p u k k p and u k k k p in the circulation model using the 3d velocity field available there and the passage of the three vector quantities at each grid point rather than the passage of as single current velocity vector as presently implemented 7 discussion and conclusions 7 1 comparison to results of quinn et al 2017 despite the similarity in approach to developing approximations for action density and flux in this study and that of quinn et al 2017 the results are significantly different as revealed in a comparison of the two results for the analytic case of a current with constant shear for this case u 0 simplifies the result for action density 4 2 in quinn et al their general result for action density is given by 48 n q 17 e 0 σ s 1 ϵ 5 r 1 r 1 2 i 2 sinh k h 1 c 0 2 sinh 2 k h i 3 c 1 we see from 4 4 in quinn et al that for a constant shear current i 2 0 both terms 2 i 3 0 sinh 2 k h evaluated directly and c 1 in the bracketed expression in r 1 are equivalent to the expression k ˆ u for z 0 it is apparent that the first term in parentheses is the projection of the weighted average velocity k ˆ u which follows directly from the definition 12 here and the expression for i 3 as given in quinn et al s 4 4 the evaluation of c 1 from their c 7 is more ambiguous if i 1 is interpreted as usual as the starting point for the definition of u after two integrations then c 1 also is equal to k ˆ u this would then give an expression for n in our notation as 49 n q 17 e 0 σ s 1 2 k u σ o ϵ 2 on the other hand if the expression is taken literally for the constant shear case under development then c 1 evaluates to c 1 k ˆ u s c 0 2 2 g u z 0 which referring to 38 is again the depth weighted current for this special case giving the expression 49 again it is clear that this expression cannot be correct as n q 17 would have to reduce to e 0 σ s in the limit of a depth uniform current where u u s we are thus not able to explain the discrepancies between our results written in terms of surface values and the expressions provided by quinn et al 2017 in contrast the result obtained in the present study can be written as 50 n e 0 σ s 1 k σ u s u o ϵ 2 quinn et al go on to suggest below their 4 4 that using the surface current in the estimate of action instead of depth averaged current would be a reasonable no cost extension in existing models this suggestion corresponds to the results for n s and ℱ s shown in the supplement appendix c from the results there it is clear that the increase in accuracy afforded by using surface current instead of depth average current is apparent only for relatively short waves whereas the proper use of the perturbation solution or expansions based on that solution is advantageous at all water depths in order to examine the relative predictions of the asymptotic forms 20 22 vs 21 23 and to establish a basis for comparing our error estimates to a case examined by quinn et al 2017 we have repeated their analysis of a current profile given by wu and tsanis 1995 and presented in their section 5 and figs 1 4 the current profile is given by 51 u z a u ln 1 z z s b u ln 1 z z b h in which a q 2 p 1 q 2 q 1 p 2 b q 1 p 1 q 2 q 1 p 2 q 1 1 z s h ln 1 h z s 1 q 2 z s h ln 1 h z b 1 52 p 1 γ z s h p 2 γ z s z b where z b and z s are characteristic viscous sublayer thicknesses at the bottom and surface respectively and γ is a constant to characterize the intensity of the turbulence the origin of the z coordinate is located at the bottom for this velocity profile and the direction is upward a lengthscale δ s is taken to be the depth at which the current velocity falls to zero and is used as the basis for a relative wavelength parameter k δ s used in plots presented below and by quinn et al fig 12 shows errors for action density n and flux ℱ using the asymptotic expressions 21 and 23 with variation of k δ s and froude number u s c 0 the axis has been modified to be in the same format as quinn et al 2017 fig 2 for comparison however our froude number is for a larger range 0 u s c 0 1 while they have only provided results for 0 u s c 0 0 3 profile parameters are given by z s 2 2 1 0 4 h z b 1 4 1 0 4 h γ 0 35 and h 100 m the thickness of the upper layer is δ s 0 34 h in this case comparison between the results and the plots presented in their fig 2 a and d demonstrates the accuracy gain in our approximation corresponding plots for our estimates n and c g a ℱ n based on 20 and 22 are provided in fig 13 and show a marked decrease in accuracy compared to the values n and c g a ℱ n in spite of the demonstrated asymptotic equivalence of n and n with errors based on n and ℱ being up to 100 times smaller we also note that our estimates for n and ℱ in the frame of reference based on the surface current are by far more accurate than the results shown in quinn et al 2017 7 2 conclusions the results here clearly show that leading order asymptotic expressions for action density and flux are both more compact and more accurate numerically when written in terms of a depth weighted current u and corresponding intrinsic frequency σ the asymptotic expressions written in the form of 21 and 23 repeated here as 53 n e 0 σ o ϵ 2 ℱ n u ˆ c g r o ϵ 2 defer the appearance of terms which are not in the standard form for action and flux to second order in the small parameter ϵ characterizing the weak shear in the depth varying current profile they provide a relatively more accurate estimate of the quantities in question than corresponding asymptotic forms 21 and 23 based on surface current u s when compared to exact values obtained analytically or numerically as shown for the analytic example of a current with constant shear in section 4 and for the strongly sheared profile of wu and tsanis 1995 in section 7 1 we have further extended the suggestion of bkd17 to represent current information using a taylor expansion around the peak wavenumber in a modeled spectrum with extensions covering the specification of action flux and intrinsic frequency as well as an extension to a general 2d horizontal setting these results provide an avenue for calculating wave action and action flux in spectral wave models using a compact set of information about the current field evaluated at the spectral peak wavenumber the coupling would require that the wave model accepts the values u u ˆ and u ˆ k at each grid point and corresponding changes would need to be made to the specification of action density and group velocity as a function of frequency and direction within the wave model formulation these are not huge changes and hopefully can be implemented in the near future the corresponding effects on model source terms such as the representation of nonlinear interactions is still an open area for research acknowledgments this work was supported by grants oce 1334325 oce 1435147 and oce 1756355 from the physical oceanography program national science foundation computational resources were provided by instructional technology university of delaware appendix a scaling and perturbation solution for the strong current weak shear case the theoretical development in kc89 and bkd17 is based on a framework that assumes that the steady current is small compared to wave phase speed with current shear and profile curvature comparably small here we provide a scaling analysis and perturbation solution that generalizes the problem to the case of a strong depth uniform current component and arbitrary current orientation in horizontal coordinates but with deviations from depth uniformity assumed to be weak conceptually the approach is to write the mean current vector u z as u 0 u 1 z where the second component carries the information about weak shear and rotation over depth we do not make an a priori choice of how to make this split into two components and as will be seen below the solution itself suggests that u 1 be chosen so as to have a weighted depth average value of 0 when weighted according to the kc89 procedure to develop the non dimensional form of 4a 4c we introduce the scales ω 0 for frequency or inverse time k 0 for wavenumber or inverse horizontal distance and scale vertical coordinate z by uniform depth h vertical velocity is scaled by its value at the free surface determined by the kinematic boundary condition as a 1 w z i σ s a f z where σ s is intrinsic frequency at z 0 a is surface wave amplitude and f z is a dimensionless shape function intrinsic frequency σ is given by a 2 σ z ω k u z ω k u 0 k u 1 z σ 0 σ 1 z we define a reference phase speed c 0 ω 0 k 0 and use c 0 g h which fixes the relationship between ω 0 and k 0 for the monochromatic case studied here we identify ω 0 with ω finally we scale strong depth uniform current u 0 by u and weak current u 1 by h ω where ω represents the strength of current shear or rotation over depth referring to 4a 4c we introduce dimensionless parameters σ σ ω 0 and k k k 0 the resulting dimensionless problem with primes dropped is then given by σ z f z z k 2 μ 2 f ϵ σ 1 z z f 1 z 0 a 3 σ s 2 f z 0 k 2 ϵ σ s σ 1 z 0 f 0 1 f 1 0 with a 4 σ z σ 0 ϵ σ 1 z 1 f k u 0 ϵ k u 1 z dimensionless parameters are μ k 0 h o 1 f u c 0 o 1 and ϵ μ ω ω 0 1 where μ is the usual dispersion parameter resulting from scaling depth by h and horizontal distance by k 0 1 f is a froude number and ϵ 1 is a small parameter characterizing current shear the alternate approach employed by ellingsen and li 2017 where shear is allowed to be strong but curvature weak would employ the regime f ϵ o 1 with a new small parameter required to characterize the weak curvature following kc89 we next solve the system a 3 using a regular perturbation expansion a 5 f z n 0 n ϵ n f n z with f n 1 0 in contrast to kc89 we take f 0 0 1 to satisfy the entire surface boundary condition for f giving homogeneous conditions f n 0 0 for n 0 introducing a 4 and a 5 in a 3 and sorting by powers of ϵ gives the governing equations and surface boundary conditions a 6 σ 0 f n z z k 2 μ 2 f n h n z a 7 σ 0 2 f n z 0 s n at n 0 we have h 0 0 s 0 1 and we get the solution a 8 f 0 z sinh μ k 1 z sinh μ k with a 9 σ 0 2 k tanh μ k μ which is the usual solution for waves on a depth uniform current for higher orders n 1 use of green s law for f 0 and f n leads to a solvability condition a 10 1 0 f 0 h n d z s n at n 1 the leading order at which current shear has an effect we have a 11 h 1 z σ 1 z z σ 0 f 0 z s 1 σ 1 z 0 σ 0 2 k 2 σ 1 0 σ 0 3 using a 11 in a 10 leads after cancellations to the identity a 12 1 0 σ 1 z cosh 2 μ k 1 z d z k 1 0 u 1 z cosh 2 μ k 1 z d z 0 but u 1 u u 0 ϵ which when substituted in a 12 gives the result a 13 u 0 u 2 μ k sinh 2 μ k 1 0 u z cosh 2 μ k 1 z d z where u is the depth weighted current from kc89 extended to allow for f o 1 and arbitrary direction relative to the wave direction we thus have the leading order expression for intrinsic frequency σ 0 σ 1 f k u with leading order dispersion relation a 14 σ 2 k tanh μ k μ the expression for phase speed c a in a fixed frame is given by a 15 c a ω k σ k u o ϵ 2 with no further correction to phase speed at o ϵ eqs a 6 a 7 may then be solved for f 1 z following the procedure in kc89 giving the result a 16 f 1 z a 1 1 μ k 1 z h 1 ξ f 0 ξ ξ d ξ f 0 z b 1 1 μ k 1 z h 1 ξ f 0 ξ d ξ f 0 z z with the coefficients a 1 and b 1 of the homogeneous solution resolved by applying the boundary conditions f 1 0 f 1 1 0 dimensional forms of the results are given in section 3 1 appendix b approximations for weak current shear starting with the expressions 9a and 9b for action density and flux we develop expansions in powers of ϵ consistent with the approach in appendix a in 9a and 9b explicit appearances of σ s and u s occur due to the satisfaction of the surface boundary condition and the transformation 7 we assume these should be common to all versions of the expansion that follows subsequently we express f z as in a 5 and use 14 and 16 we then introduce an arbitrary version of the depth uniform current and resulting intrinsic frequency u 0 and σ 0 as representations of the leading order solution u z u 0 ϵ u 1 z b 1 σ z σ 0 ϵ σ 1 z where σ 0 ω k u 0 and σ 1 k u 1 k u u 0 and with associated dispersion relation b 2 σ 0 2 g k tanh k h after some simplification of the resulting forms of n and ℱ we obtain approximate forms consistent with the present derivation through the choice u 0 u and σ 0 σ we also develop an alternate version based on the choice u 0 u s and σ 0 σ s which leads to expressions for action and flux defined in terms of surface variables as in quinn et al 2017 it was our initial expectation that this procedure should reproduce the results in quinn et al 2017 which are described as being based on the approximate wave current formulation here and in kc89 but we have not been able to reproduce the results given by quinn et al 2017 as discussed in section 7 1 substituting the expressions b 1 and the expansion for f z into the formulas 9a and 9b and retaining terms to o ϵ leads to the generic version of the expansion where any remaining occurrences of frequency or current are expressed in terms of σ 0 and u 0 during this process expressions occurring in terms of o ϵ may be manipulated by choosing σ 0 σ s or σ freely since transformations between these quantities would occur at o ϵ 2 in contrast occurrences of σ 0 in o 1 terms must retain the implied ambiguity as it s resolution would occur within the accuracy of the approximation proceeding with 9a for the action density we note that the integral term is of o ϵ since σ ϵ σ 1 for any choice of reference frame recognizing that σ s σ 0 1 o ϵ for any choice of reference frame making σ 1 small we obtain the approximate expression b 3 n e 0 σ s 1 ϵ σ s 2 g k 2 σ 1 z 0 h 0 σ 1 z z f 0 2 d z o ϵ 2 the expression in the interior parentheses may be integrated immediately and we obtain the approximation b 4 n 0 e 0 σ s 1 ϵ σ s σ 0 2 σ s σ o ϵ 2 where the single appearance of σ 0 results from a resolution of the combination σ 0 2 g k tanh k h turning to the expression for action flux 9b we note that the first integral term involving f 2 occurs at leading order and thus the ambiguity of the value of σ 0 must be retained there we proceed as before by substituting the expansions b 1 the expression a z may be expanded as a a 0 ϵ a 1 o ϵ 2 and we find that a 0 0 and b 5 a 1 z σ 0 u 1 z u 0 σ 1 z so that the integral involving a z is reduced to b 6 σ s 2 h 0 σ 2 a z f 2 d z ϵ σ s 2 σ s 2 o ϵ h 0 a 1 z f 0 2 d z o ϵ 2 the entire bracketed expression involving a in 9b is then evaluated as b 7 ϵ a 1 0 h 0 a 1 z f 0 2 d z ϵ k sinh 2 k h i 3 where b 8 i 3 h 0 a 1 z sinh 2 k h z d z the integral of f 2 is expanded to give b 9 h 0 f 2 d z i 4 2 ϵ i 5 o ϵ 2 with b 10 i 4 h 0 f 0 2 d z i 5 h 0 f 0 f 1 d z and with f 1 given by 16 the resulting expression for the approximation ℱ 0 is then b 11 ℱ 0 e 0 σ s u s c r s 1 σ s 2 g i 4 ϵ e 0 σ s c r s 2 σ s 2 g i 5 σ s σ 0 2 sinh 2 k h i 3 integrals i 3 and i 4 are given to the required order by i 3 sinh 2 k h σ 0 u s u u 0 σ σ s b 12 i 4 g 2 σ 0 2 1 g g 2 k h sinh 2 k h the expression for i 5 is complex and is given after some initial effort by b 13 i 5 1 4 σ sinh 2 k h g cosh 2 k h k i 2 0 i 6 where from 17 b 14 i 2 0 2 sinh 2 k h k ˆ u z 0 2 sinh 2 k h σ s σ and b 15 i 6 h 0 k ˆ u z z z h z sinh 2 k h z d z an expression for i 6 is obtained by first expressing u in terms of u z z using two integrations by parts differentiating the resulting expression with respect to wavenumber k and taking the dot product with the unit wavenumber k ˆ to obtain after rearrangement b 16 i 6 sinh 2 k h k u k h k ˆ u 1 z 0 1 k 1 g 2 g cosh 2 k h σ s σ using b 14 and b 16 in b 13 leads to a relatively compact expression for i 5 given by b 17 i 5 1 2 σ tanh k h k u k 1 k 1 g σ s σ using the results for i 3 i 4 and i 5 in b 11 leads finally to b 18 ℱ 0 e 0 σ s u s c r s 1 1 2 σ s σ 0 2 1 g ϵ e 0 σ s σ s 3 k ˆ σ σ 0 2 k u k 1 k 1 g σ s σ σ s σ 0 2 σ 0 u s u σ σ s u 0 from this point the resolution of the expressions for n 0 and ℱ 0 involves the choice of σ 0 following the procedure of referencing all quantities to surface conditions leads to an expression for n 0 given by b 19 n n 0 σ s e 0 σ s 1 ϵ σ s σ σ s o ϵ 2 this result is similar in form to that in quinn et al 2017 equation 4 2 but there is no clear relation between the residual o ϵ terms in the two results as discussed further in section 7 1 taking the alternate approach of referencing quantities to the frame moving with speed u leads to the expression b 20 n n 0 σ e 0 σ o ϵ 2 where all information about the approximation within the order of accuracy is contained in the simple ratio of e 0 and σ the same process applied to ℱ 0 in b 18 leads to the expressions b 21 ℱ e 0 σ s u ˆ c g r s ϵ u s σ s σ σ s k ˆ k 1 g σ s σ o ϵ 2 and b 22 ℱ e 0 σ u ˆ c g r o ϵ 2 where c g r s and c g r are relative group velocities defined in the usual sense for a depth uniform current relative to the surface and depth weighted velocities respectively appendix c results for errors in wave action density and flux for additional cases supplementary material related to this article can be found online at http dx doi org 10 1016 j ocemod 2019 101460 appendix c results for errors in wave action density and flux for additional cases the following is the supplementary material related to this article mmc s1 
