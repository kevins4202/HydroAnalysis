index,text
10,enhanced water management systems depend on accurate estimation of subsurface hydraulic properties however geologic formations can vary significantly so information from a single source e g widely spaced boreholes is insufficient in characterizing subsurface aquifer properties therefore multiple sources of information are needed to complement the hydrogeology understanding of a region this study presents a numerical framework in which information from different measurement sources is combined to characterize the 3d random field in a multi fidelity prediction model coupled with the model a bayesian experimental design was used to determine the best future sampling locations the upper sangamon watershed in east central illinois was selected as the case study site where the multi fidelity gaussian process model was used to estimate the hydraulic conductivity in the region of interest multi source observation data were obtained from electrical resistivity and borehole pumping tests the accuracy of the model prediction is dependent on the locations and the distribution of both high and low fidelity data furthermore the multi fidelity model was compared with the single fidelity model the uncertainties and confidence in the measurements and parameter estimates were quantified and used to design future cycles of data collection to further improve the confidence intervals keywords bayesian experiment gaussian process multi fidelity hydraulic conductivity hydro geoinformatics optimization 1 introduction reliable prediction of hydraulic properties of subsurface formations is a crucial step in improving water management systems there are various testing approaches to obtain information from the given area of interest borehole cross pumping test is a traditional reliable method to directly measure subsurface hydro geophysics properties such as hydraulic conductivity reinhart 2006 hamm et al 2007 there are several types of cross pumping tests constant rate pumping test is one of them which directly measures the steady water flow underground by maintaining a constant hydraulic head gradient across the subsurface however although borehole testing can provide relatively high confidence measurement results drilling a borehole to obtain the information at just one specific location is expensive and time consuming on the other hand electrical signal measurement such as earth electrical resistivity eer and electromagnetic induction have been broadly used in hydro geophysics investigations lesmes and friedman 2005 these tests introduce electrical current into the subsurface and measure the resistivity via several receivers along the transect which provides continuous hydro geophysics information in the measured region without intruding into the ground however this type of measurement requires direct or inverse empirical relations between electrical and hydro geophysical properties several studies have examined factors influencing relationships between electrical resistivity and hydraulic properties of aquifers kelly 1977 mazáč et al 1985 niwas and singhal 1985 yadav 1995 sikandar and christen 2012 for example mazáč et al 1990 studied the relationships between hydraulic conductivities and rock resistivities and they examined the role of the distribution of hydraulic conductivity on dynamics of pollution spreading in rock medium these relationships are sometimes case specific and not universal for all locations also soil saturation and temperature can affect these relationships as well khalil and santos 2009 therefore the estimation can cause tremendous errors if not used properly hydraulic conductivity of geologic formations can vary by orders of magnitude over relatively small spatial scales so characterizing subsurface aquifer properties using only the information acquired from a widely spaced single measurement is challenging and potentially inaccurate one method that has been widely employed is to use an integrated exploration approach in which borehole and other geophysical datasets are jointly interpreted lesmes and friedman 2005 numerous studies have used information at different levels of fidelity to estimate hydraulic conductivity for groundwater system models asher et al 2015 zhang et al 2018 these multi fidelity mf models combine low fidelity lf data with high fidelity hf data to approximate the prediction with an accuracy that is better than that offered by a single fidelity sf model peherstorfer et al 2018 fernández godino et al 2016 the terms hf data and lf data refer to different levels of detail and accuracy of the data hf data refers to data that is precise accurate and of high quality with a high level of detail and granularity while lf data on the other hand refers to data that is less accurate less precise and of lower quality with a lower level of detail and granularity forrester et al 2007 first proposed a global optimization strategy using mf surrogate models to include multiple levels of information into the predictions which is called mf kriging in mf kriging models data points obtained from sensors with different fidelity levels are fit with different surrogate models that provide estimation and prediction without the need to obtain a large number of expensive tests or run expensive numerical simulations among the surrogate models the gaussian process i e kriging has been widely used in mf groundwater modeling zaytsev and burnaev 2017 compared to the traditional co kriging method that uses information from correlated variables to improve the accuracy of predictions which involves modeling the correlation between two or more variables mf kriging focuses on using data from multiple levels of fidelity to improve the accuracy of spatial predictions by incorporating information from multiple sources the mf models facilitate the usage of data with different levels of fidelity by combining a hf function a more accurate but expensive representation of a physical phenomenon with a lf function a less accurate but inexpensive representation of a physical phenomenon asher et al 2015 and fernández godino et al 2016 extensively surveyed several data driven methods of combining fidelities with a primary focus on kriging models for mf applications this focus was particularly because such a gaussian process entails an uncertainty structure that readily lends itself to an mf modeling approach fernández godino et al 2016 a more recent study by zheng et al 2018 employed mf gaussian surrogates to propose an adaptive mf ensemble smoother for data assimilation to reduce the high computational cost for characterization of model parameters in ensemble based methods however numerous questions remain unanswered in predicting hydraulic properties of subsurface formations in watersheds for example how many field tests need to be conducted to achieve the desired accuracy of the estimation and what if the existing data points are sparse many studies have confirmed the usage of mf kriging models for predicting the hydro geophysical information in a specific region with abundant hf and lf data but few studies have focused on discussing the effects of hf and lf data location distribution especially in a data sparse situations another subject that has not been fully addressed is to understand how data fidelity associated with different tests would affect future test locations recently menberg et al 2020 used an mf approach along with bayesian parameter estimation in subsurface heat and fluid transport models to include information from a more physically accurate but expensive hf model as well as a large number of evaluations from a less accurate less expensive lf model the study demonstrated that the combined information from sources with different fidelities substantially improved the posterior distribution results which may be important for determining future test locations to optimize the information gained from newly implemented data sources in this study we present a quantitative mf framework to combine information from eer measurements and pumping borehole measurements with different fidelities and accuracies to enhance the understanding of hydro geophysical characteristics for the first time we specifically address the effect of data locations from data with different levels of fidelity under sparse data distributions also we investigated how future test locations with different fidelities should be conducted to optimally enhance our understanding of the geo hydraulic properties of a region according to the new information gained as a sample case study we selected an intensively managed area located in the upper sangamon watershed in east central illinois as the study site traditional high accuracy pumping test data were used with small scale eer measurements to generate 2d maps of hydraulic conductivity over a large scale region with quantified uncertainties in different depth layers according to the mf kriging framework the discussions focused on how the distribution of data with different fidelities would affect the model accuracy especially with sparse data points we further discussed how the mf model can learn from new sensors using probabilistic statistical tools to select the best locations for future data collection the approach was based on the bayesian experimental design which selects the best locations from a set of candidate locations according to the value of information that each location is expected to offer norberg and rosn 2006 by relating the expected value of information from each location to the present levels of uncertainties in the mf kriging model we thus can pick the best location with the most information gain the proposed method can serve as a quantitative decision support framework to optimally conduct tests with different cost and accuracy levels the remainder of this paper is organized as follows in section 2 we provide the theoretical background which includes detailed information about site selection observation data lognormal ordinary kriging lok mf lok and optimal bayesian experimental design in section 3 we show the topography of the upper sangamon watershed and discuss how the eer and pumping test data were obtained and how the multi source data were used in sf kriging with multiple data sources and mf kriging in section 4 we discuss the effect of fidelity on the estimated field and the estimation accuracy followed by the distribution of lf and hf data points the application of optimal bayesian experimental design for obtaining optimal future sampling locations is also presented finally section 5 provides discussions and conclusions 2 method 2 1 study site the sangamon river is a major tributary to the illinois river with the confluence near chandlerville in cass county llinois the watershed spreads across seven counties in east central illinois champaign christian dewitt ford macon mclean and piatt the major urban areas within the watershed are decatur monticello mahomet rantoul and gibson city it is intensively managed for soybean and corn production and is among the five watersheds in illinois that are identified as most in need of attention for water supply planning and management mattia et al 2018 the predominant land use in the watershed is row crop agriculture which comprises nearly 90 of the land area keefer et al 2005 as an intensively managed landscape this region is at risk for deterioration of land and water systems therefore more observations are needed to understand and predict the behavior of natural services ecological hydrological and climatic services that support basic human needs such as water food and energy 2 2 data description based on the geological properties of subsurface formation hydraulic conductivity is spatially correlated but sometimes can vary significantly hence information from a single source is insufficient indicating the need of multiple sources of information to complement the hydrogeology understanding of a region in this study two types of field observation data eer measurement and pumping tests were used as data sources with different fidelities to estimate hydraulic conductivity of the upper sangamon watershed using a mf gaussian process model more details in section 2 4 fig 1 shows the data locations the pumping test involved pumping from a test well at a controlled rate and monitoring the flow rate through the drawdown at different locations along the radial axis from the test well hydraulic conductivity values of aquifer material as determined from pump tests and aquifer tests varies spatially but not as much temporally repeated pump tests may show changes in hydraulic conductivity at the well skin of production wells or within gravel packs immediately surrounding well screens but repeated long duration aquifer tests would provide similar values over time the measured hydraulic conductivity values of aquifer material can provide convincing values therefore pumping test measurements have been well recognized as one of the most reliable ways to measure soil hydraulic conductivity with high fidelity meaning that the data is accurate and precise with high quality and less errors or discrepancies which provides a true and faithful representation of the true value in the real field however because of the high cost of drilling a well limited data can be collected eer measurement has also been widely applied to estimate hydraulic conductivity of the subsurface based on a 2d resistivity model of the relationships between aquifer hydraulic and electrical properties kelly and frohlich 1985 slater 2007 khalil and santos 2009 tizro et al 2010 the measurement relies on testing with a dipole dipole electrode configuration in a vertical 2d plane of the field which is commonly used in 2d electrical resistivity surveys because it provides good resolution of subsurface structures with high sensitivity to lateral changes in resistivity in the array current is injected into the ground using two current electrodes and voltage measurements are made using two pairs of potential electrodes placed at a distance from the current electrodes the distance between the current and potential electrodes is increased systematically to obtain measurements at various depths the dipole dipole array is particularly useful for detecting planar variations vertically and horizontally in subsurface resistivity to infer the hydraulic conductivity however the accuracy depends on the equipment precision hence the measurement has lower cost but also lower fidelity due to its lower accuracy compared with traditional pumping borehole testing in general eer values are known to vary there are many factors that can affect the measured resistivity like soil texture clayey matters pore structure and temperature the greatest variability generally comes from the changes in saturation conditions and temperature khalil and santos 2009 within the upper sangamon watershed the water table is within a few meters of the ground surface except in areas of very steep slopes and very coarse materials these areas are a small percentage of the entire area and thus can be neglected at the scale of this study there is some variation from temperature but we neglected this effect because it is small within the context of this generalized study eer measurement provides a continuous estimation of hydraulic conductivity in a small vertical plane 800 m long and 80 m deep to apply the eer data together with the pumping test data in the mf gaussian process model we need to ensure that two data sources provide the same physical meanings therefore eer has to be converted to hydraulic conductivity since pumping tests directly provide the hydraulic conductivity information a study by lu et al 2019 demonstrated that the relationship between the soil s hydraulic conductivity k and electrical conductivity σ ec follows an exponential function form as k a e b σ e c c where the parameters a b and c can be estimated using the calculated σ ec in soil layers which is the inverse of the resistivity data captured by eer testing according to their experiment results with sands when k is a dependent variable the given best fitted empirical parameters can be obtained by fitting to a comprehensive data set 1 a 299 6 e 0 001147 σ e c 157 b 0 2061 e 0 0001535 σ e c 0 004299 c 7 996 e 0 0001264 σ e c 0 6567 as mentioned previously many factors can affect the empirical relationship between the measured resistivity and k especially the soil pore size within the upper sangamon watershed the dominant soil types found in this area are mollisols and alfisols whose pore sizes can range from 0 1 to 1 0 mm which is similar to the pore size of the typical sands 0 2 to 2 0 mm therefore we assumed that eq 1 by lu et al 2019 is valid within the context of this generalized study in this study as the soil deposition was accumulated layer by layer resulting in a consistent geological composition horizontally after converting the measured resistivity σ ec into hydraulic conductivity k the horizontal mean value of k was set as the representative value in each depth for the lf data input in the mf kriging model borehole pumping tests were conducted at specific locations with different depths unlike eer measurement which provides continuous vertical information pumping tests provide point information on subsurface properties from the measurement of flow velocities within soil pores they offer higher accuracy on hydraulic conductivity which was set as the hf data source in mf kriging we obtained eer data from 15 locations with continuous depth and pumping test data from 68 locations with specific depths for each test compared to the entire horizontal study domain 60km 50km with the relatively sparse distributions of the data points both eer and pumping test can be viewed as point measurements in the model under nearly the same measurement scale in each layer the eer and pumping tests were conducted by the illinois state geological survey and illinois state water survey and the locations of the tests were originally selected to aid in quaternary mapping projects and to develop communities water supply planning and management 2 3 lognormal ordinary kriging lognormal ordinary kriging lok is a commonly used geostatistical procedure that generates an estimated mapping of geo properties from a scattered set of points with scalar values based on a logarithmic transformation of the estimators balaban and dengiz 2018 compared to the traditional ordinary kriging model the lok model can improve the calculation of statistics and weighted averages to avoid negative and extreme estimated values which helps to reduce the impact of outliers on the estimated values roth 1998 also the lok model can be more appropriate when the variable being studied exhibits a positive skewed distribution providing more accurate and realistic estimates since it considers the asymmetry of the distribution as shown in fig 2 the positively skewed distribution of k can be observed in both pumping test data and eer data under a normal scale however after we transformed the data on a log scale the data looks more symmetrical without any extreme data the lok model algorithm follows the structure of gaussian processes 2 l n y f x g p μ k where x xi represents the locations of the data points y yi represents the measured hydraulic conductivity corresponding to the locations x μ is the mean value of ln y within the simulation domain and k kij is a symmetric matrix which is constructed by the kriging function k xi xj θ with exponential variogram through the following equation 3 k i j k x i x j θ n s 1 e x i x j r 3 where θ n s r are the kriging parameters namely nugget n sill s and range r the nugget n is related to the amount of a short range of the initial randomness or noise in the data the range r represents the distance at which data are no longer correlated and the semivariance first flattens out and reaches the sill s the total variance where the empirical variogram appears to level off the kriging parameters can be obtained by fitting the sample variogram to the semivariance γ with the given the observation data x y which can be expressed as 4 γ d i j 1 2 e l n y i l n y j 2 k x i x j θ where dij xi xj and e is the expectation operator that returns the mean value then for the estimations at a set of new locations of points x normal distribution is applied 5 f x f x n μ k x x θ k x x θ k x x θ k according to the resulting conditional distribution estimations at a given point are given by 6 f x x n μ l σ l where 7 μ l μ k x x θ k 1 y μ 8 σ l k x x θ k x x θ k 1 k x x θ since f x is in logarithmic scale to estimate the parameter of interest in this case the hydraulic conductivity we converted the logarithmic values μ l and σ l back to the actual mean and standard deviation values according to 9 μ e x p μ l σ l 2 2 10 σ e x p σ l 2 1 e x p 2 μ l σ l 2 2 4 multi fidelity lognormal ordinary kriging to combine the observation data from eer measurements and pumping testing the mf lok model was used to perform 2d hydraulic conductivity mapping in different depth layers with smooth and continuous fusion of information from two sources with different levels of fidelity precision the mf kriging algorithm follows the structure proposed by kennedy and o hagan 2000 and forrester et al 2007 assuming that 11 u l x g p μ k l x x θ l 12 u h x g p μ k h x x θ h are two independent kriging functions then the lf and hf lok functions can be modeled as fl x ul x and fh x ρul x uh x respectively which can be expressed as a multi output lok 13 f l x f h x g p μ k l l x x θ l k l h x x θ l ρ k h l x x θ l ρ k h h x x θ l θ h ρ where 14 k l l x x θ l k l x x θ l 15 k l h x x θ l ρ k h l x x θ l ρ ρ k l x x θ l 16 k h h x x θ l θ h ρ ρ 2 k l x x θ l k h x x θ h kl and kh are the kriging functions eq 3 for the lf and hf data respectively and ρ is the mf constant which was first proposed by forrester et al 2007 as a scaling factor to approximate the data with a lf contribution to the prediction following the auto regressive model kennedy and o hagan 2000 the idea is to approximate the high fidelity function fh x as the low fidelity gaussian process surrogate ul x multiplied by a scaling factor ρ plus a high fidelity gaussian process surrogate uh x that represents the difference between ρul x and uh x to consider both contributions from the low fidelity and high fidelity data given the observation lf and hf data x l y l and x h y h the kriging parameters θ l and θ h can be fitted by the sample variogram according to the kriging functions of the lf and hf data respectively to obtain the optimized ρ normal distribution is applied 17 f m g p z n μ k where 18 z ln y l ln y h 19 k k l l x l x l θ l k l h x l x h θ l ρ k h l x h x l θ l ρ k h h x h x h θ l θ h ρ and the optimized constant ρ can be trained by minimizing the negative log marginal likelihood nlml 20 n l m l θ l θ h ρ 1 2 y t k 1 y 1 2 l n k n 2 l n 2 π where n is the total number of the data points in this study we used a truncated newton algorithm minimization method nash 1984 to obtain the optimized constant ρ for the estimations at a new set of points x we first constructed the joint distribution 21 f h x z n μ k h h x x θ l θ h ρ q t q k where 22 q t k h l x x l θ l ρ k h h x x h θ l θ h ρ like the sf lok model according to the resulting conditional distribution predictions can be estimated by 23 f h x z n μ m σ m where 24 μ m μ q t k 1 y μ 25 σ m k h h x x q t k 1 q finally we back transform the mean μ m and the standard deviation σ m of the mf model into the normal domain 26 μ e x p μ m σ m 2 2 27 σ e x p σ m 2 1 e x p 2 μ m σ m 2 2 5 optimal bayesian experimental design our experimental design addresses the challenge of identifying the best locations for future tests or data collections these locations are identified based on the value of information that each location is expected to offer norberg and rosn 2006 for instance in the context of hydraulic property estimation for aquifers measurements collected from locations that are closely spaced will provide much less information compared with those obtained from locations that are farther apart in establishing a quantitative framework that captures these facts a bayesian experimental design procedure can be used this begins by quantifying the value of information specifically the value of information is defined as the information gain conditioned on the design variables the information gain is formally defined as the kullback leibler divergence from the posterior distributions of the model parameter to the prior chaloner and verdinelli 1995 the best experiment among the ensemble of candidates is the one that maximizes the information gain taken to be the kullback leibler divergence from posterior to prior solving this optimization problem is numerically complicated because the evaluation of kullback leibler divergence requires samples from the prior and posterior of the parameters here we provide the technical background for this experimental design approach combined with the mf kriging model using bayesian inference the posterior distribution of model parameters p θ d s can be expressed as 28 p θ d s p θ s p d θ s p d s where p θ s is the prior distribution p d θ s is the likelihood and p d s is the evidence which can be considered as a normalizing constant 29 p d s p d θ s p θ s d θ in this study θ is the sampled kriging parameters including n s and r n and s are constant values according to the mf model and r represents the gaussian distributed samples based on the fitted lf and hf range rl and rh with σ l 0 01rl and σ h 0 01rl which were selected to create data samples that are closely clustered around the mean range values rl and rh more specifically we aim to make the data samples to be very precise and consistent with little variations so that the modeled variations of the prior distribution mainly come from d which is the sampled observation data whose probability distribution can be assumed gaussian like with the model estimated μ and σ s represents the designed future sampling location since the prior knowledge of θ is not affected by s the prior distribution 30 p θ s p θ the expected utility in bayesian experimental design can be expressed as lindley 1956 31 u s u s d θ p θ d s d θ d d where u s d θ is the utility function following the algorithm proposed by zhang et al 2015 the relative entropy from the prior to the posterior is chosen as the utility function lindley 1956 which considers the expected gain in shannon information shannon 1948 given by the experiment 32 u s d θ p θ d s ln p θ d s p θ s d θ according to bayes theorem and the monte carlo approach the integral in eq 31 can be approximated by the sum of the discrete values 33 u s 1 n i 1 n l n p d i θ i s l n p d i s where di is each of the sampling data point and n is the total number of the sampling data points from eqs 29 and 30 the evidence p di s can also be approximated by the monte carlo approach 34 p d i s p d i θ s p θ d θ 1 n j 1 n p d i θ j s where the likelihood function p di θ j s uses the gaussian radial basis likelihood function that consists of a exponential decaying function with the mf kriging model g 35 p d i θ j s exp 1 2 d i g θ j s 2 combining eqs 33 34 and 35 the optimal sampling location s can be obtained by maximizing the expected utility u s over the design domain d which can be achieved by minimizing the negative u s 36 s a r g max s d u s a r g min s d u s to avoid being trapped by the local minimum points during optimization process we applied a traditional brutal approach by setting the candidate locations for s every 1 km in x and y directions and then selected the one who had the minimum utility value u s as s the results of the sequential bayesian experimental design application for future sampling locations are demonstrated in section 4 3 3 results 3 1 topography investigation we used lidar data from the us geological survey national elevation dataset for the upper sangamon watershed along with the eer and pumping test data the lidar data are uniformly distributed in the rectangular region of the upper sangamon watershed as shown in fig 1 multi quadratic radial basis function with euclidean distance was used to interpolate the elevation between the lidar data points fig 3 a shows that the topography of the watershed is generally flat which is on average within a range of approximately 210 to 230 m there is only a relatively low region in the southeastern region 180 m the flat topography suggests that a reasonable approach would be to represent the domain in a cartesian coordinate system x y z denoting x coordinate along the latitude y coordinate along the longitude and the z coordinate by depth distance from the surface to ignore the surface variation and set all the locations surface as zero in depth for the z value 3 2 single fidelity results with multiple data sources the upper sangamon watershed is in a typical glaciated midwest river basin which shows characteristic low relief landscapes and reflects glacial deposition patterns except for regions modified by stream processes in valleys therefore soil deposition patterns are expected to have a layer by layer distribution the watershed contains mostly sand and gravel deposits concentrated in different layers which are typically 10 to 15 m thick selkregg and kempton 1958 with an additional sensitivity analysis between the mf kriging results in five layers z 15 m and the results in eight layers z 10 m at similar depth the comparison reconfirms that five layers with 15 m thickness is good enough to show the general geological property such as hydraulic conductivity in different layers in the watershed therefore we divided the 75 m thick domain region into five 15 m thick layers where eer and pumping test data are located in a range between 10 and 85 m deep from the surface as shown in fig 3 b within the same layer soil and hydraulic properties e g hydraulic conductivity are similar and correlate across different locations we constructed a 2d horizontal kriging model in different layers to construct a multilayer mapping of hydraulic conductivity sf kriging with multiple data sources was conducted as the reference to compare with the mf kriging model in the sf kriging model the data sources were treated equally ignoring their different fidelities the exponential model is one of the most commonly used models to characterize cross spatial dependence in geological property data which suggests that data spatial autocorrelation decreases exponentially with increasing distance based on prior knowledge of the phenomenon oliver and webster 2015 we thus used the exponential function based variogram to fit the semivariance of the data eq 4 including eer and pumping test data on the sample variogram oliver and webster 1990 a python based fitting tool using a nonlinear least squares algorithm was applied for curve fitting the fitted kriging parameters of n 0 02 s 0 79 and r 11 39 were used when measurements are done at irregular grid points setting a bandwidth lag tolerance and angle tolerance to account for the directional influence anisotropic effects can be helpful to statistically quantify and analyze sample contributions in different ranges depending on the direction however since there is a limited number of representative observation data from eer and pumping tests we assumed isotropic contribution from all the measurements without setting a bandwidth or tolerance to ensure sufficient data points in the sample variogram in fig 4 the sf kriging result shows a relatively uniform distribution of mapped hydraulic conductivity k in the upper three layers depth 50 m and some peak values can be observed in the lower two layers depth 50 m this result suggests that more varying soil properties exist in the deeper layers of the watershed the uncertainty in the estimated properties is presented by the standard deviations σ however we can see that some regions with high standard deviation around the hf data point shown in fig 4d and 4e it is because when converting the standard deviation σ from the lognormal scale back to normal scale the magnitude of σ is also related to the magnitude of the mean value μ l eq 10 at the region where the estimated mean magnitude of k is high will result in a relatively high deviation however if we look closer to the lower left point inside the blue circle in fig 4e the deviation around the data point remains low blue to yellow due to the unbiased estimate from the model near the data point but quickly becomes higher orange due to the high mean k region red region in the upper panels 3 3 multi fidelity results the sf kriging model did not account for the fact that data are from different sources so they were considered with the same uncertainty however since different data sources typically have different uncertainty error ranges depending on equipment methods and human factors the fidelity of these data sources should also be incorporated into the model incorporation of these factors makes mf kriging models a more accurate approach than sf kriging models when multiple sources of data are available thus not much confidence can be placed in the sf kriging result shown in fig 4 data with different levels of fidelity should also be treated separately in the sample variogram for two sets of fitted kriging parameters in the mf kriging model we treated eer and pumping test data separately where kriging parameters were obtained from each sample variogram the fitted kriging parameters based on the exponential function based variogram are n 0 06 s 0 08 and r 2 91 for eer measurement and n 0 49 s 0 88 and r 21 12 for pumping tests according to the fitted kriging parameters the range r of the high fidelity pumping test dataset r 21 12 which is much higher than the range r of the low fidelity eer dataset r 2 91 indicating that eer data has weaker spatial correlation due to its low fidelity of the data accuracy and quality fig 5 shows the mf kriging result of the hydraulic conductivity and the corresponding standard deviation in the upper sangamon watershed compared with the sf kriging results shown in fig 4 mf kriging puts more weight on the hf data shown by circle markers thus the estimated k and σ distribution patterns generally follow the distribution of the pumping test data furthermore regions near the hf data points blue circles in fig 5 have lower standard deviation this means that the model assesses higher confidence in the estimates in those regions the lf data shown by cross markers however do not help reduce uncertainty levels in a large area but nevertheless provide local hydraulic information in regions far from the hf data locations 4 discussion 4 1 fidelity effect on the predicted field in mf kriging pumping test data were selected as the hf data source because they offer a more reliable measurement method than eer data hence the estimated k and σ values based on mf kriging fig 5 are mostly dominated by the hf data pumping test data to further study the fidelity effect we excluded the lf data and only considered the hf data in the kriging model fig 6 to compare with the mf results fig 5 fig 6 shows that in regions near the hf data the estimated k and σ values are similar to those in fig 5 however in regions far from the hf data points the models provide very different k and σ estimates especially in the upper three layers depth 50 m where hf data points are scarce the higher σ estimations are because of the additional information provided by the lf data however the higher estimated σ does not suggest that the lf data provide incorrect information instead the different estimations of k suggest that the lf data do provide valuable information about the hydraulic conductivity properties for regions where expensive hf tests are not available or economically not feasible 4 2 fidelity effect on the estimation accuracy to evaluate the estimated k values in the mf kriging model we focused on the lower two layers depth 50 m and removed hf data points in each layer from the estimation model since hf data was measured directly by the pumping test with high accuracy we assumed its measured k is the true value and used the removed hf data points as the reference to compare with the model estimated values in fig 7 the red circles show the locations of the removed hf data points in each layer the removed data points were selected based on their locations specifically we preferred hf locations that were close to an lf data location to assess the accuracy of lf data contributions the calculated standard deviation values did not differ significantly between the mf model and the shf model more hf data can increase the confidence levels in both cases however a difference in estimated k values was not observed in this comparison the removed hf data points provide a reference value of k 0 078 cm s fig 7a and 0 026 cm s fig 7d in the fourth layer and k 0 081 cm s fig 7g in the fifth layer at the data locations after the data points were removed the mf model provided a prediction of k 0 081 cm s fig 7b and 0 033 cm s fig 7e in the fourth layer and k 0 107 cm s fig 7h in the fifth layer at the data locations the shf model provided a prediction of k 0 052 cm s fig 7c and 0 032 cm s fig 7f in the fourth layer and k 0 086 cm s fig 7i in the fifth layer at the data locations these results provide an estimated accuracy to obtain a more precise measure of accuracy we defined ak as 37 a k 1 k p r e d k r e f k r e f where kpred is the predicted k from the mf or shf model kref is the reference k i e the removed hf data for the mf model the accuracy is 96 fig 7b and 73 fig 7e in the fourth layer and 68 fig 7h in the fifth layer and for the shf model the accuracy was 67 fig 7c and 77 fig 7f in the fourth layer and 94 fig 7i in the fifth layer the accuracy shows that when the removed points were far from the other hf data points lf data provided important information to enhance the estimation of the kriging model fig 7a b c when the removed points were relatively close to the other hf data points lf data were not necessary and the predictions are dominated by the information provided from the surrounding hf data points with nearly the same accuracy in mf and shf models figure d e f when the removed points were in similar distances from the surrounding hf and lf data points lf data might even provide information with higher variance due to its relatively low accuracy compared with the hf information fig 7g h i thus the accuracy of the mf model depends on the locations and the distribution of both the lf and hf data when hf data points are scarce and far from the lf data points the information provided from lf data becomes important and can enhance model performance and accuracy to further investigate the fidelity effect we choose the deepest fifth layer as the test case and consecutively remove hf data points one by one within or close to the lf data points fig 8 shows the estimated hydraulic conductivity field by mf kriging and shf kriging under four point removal scenarios keep all the hf data remove one point remove two points and remove three points comparing the results of mf kriging versus shf kriging as more data points were removed shf kriging showed a relatively lower and more uniform estimated k field however since lf data still provided the surrounding information in mf kriging they provided estimated k values closer to the original estimates where all the data points were present according to the definition in eq 37 fig 9 shows the accuracy of k estimates at locations pt 1 pt 2 and pt 3 under mf kriging and shf kriging when no data points one data point two data points and three data points were removed when all data points were present the accuracy was 100 at all three locations when one point was removed at location pt 1 the accuracy remained 100 at locations pt 2 and pt 3 but at location pt 1 shf kriging shows a greater accuracy compared with mf kriging because of the far distance between the removed point and the lf data points as discussed in fig 7 when data at two points locations pt 1 and pt 2 were removed mf kriging began to show higher accuracy at locations pt 1 and pt 2 and location pt 3 remained at 100 accuracy when all three data points were removed mf kriging showed obviously higher accuracy at all the locations compared with shf kriging the results again confirm that when hf data become scarcer the information provided by lf data becomes more critical in mf kriging and can lead to better estimation of hydraulic conductivity 4 3 future data collection using bayesian experimental design we applied the bayesian experimental design along with the mf kriging model to determine the future sampling locations for the hf data pumping test measurement we chose the deepest fifth layer which has more uniform distribution of both lf and hf data points five optimal sampling locations for future pumping test data were estimated one by one with the initial guesses of the sampling location uniformly assigned in the simulation domain fig 1 once the current optimal point was obtained the hydraulic conductivity value was then predicted by the mf kriging model at that location the current estimated optimal point with its predicted hydraulic conductivity was then put back in the mf kriging model as one of the synthetic measurement data points to update the model and train the new optimized constant ρ for the next optimal sampling location the final optimal result is shown in fig 10 the optimal locations are denoted by the red triangles with the numbers indicating the sequential order the sampling points were located in the region where σ was high indicating the need of future measurements to enhance the confidence of the prediction and understanding of the region of interest the future sampling points provided more information to the region near the suggested locations where variances were greatly reduced variances were slightly increased in regions far from the suggested locations because of the unbalanced information entered into the model however according to bayesian experimental design those regions were relatively less efficient for future measurements compared with the suggested locations when considering the expected gain in shannon information see section 2 5 the bayesian experimental design model can be carried out for both pumping test data and eer measurement data however because the pumping test data hf data are dominant in the mf kriging model and the pumping test is more expensive and thus more limited the appropriate future optimal locations are more critical than eer test locations from an economical perspective therefore in this study we performed the bayesian experimental design to infer the optimal locations for future pumping tests which can provide more valuable information as suggested by the model this work can be used in future studies on developing a more robust optimization framework that incorporates data cost and fidelity and can reveal their complex interactions 5 discussions and conclusions this work presents a robust approach to exploit multi source data to estimate the 3d random field of hydraulic conductivities we demonstrated how the described framework can use the combination of pumping test data from boreholes which are expensive and highly accurate with observation data from less expensive and less accurate eer measurements this approach offers a cost effective approach to reliably characterize the hydraulic conductivity properties specifically in under sampled sites and can be particularly used in obtaining large scale parameter maps for a region using small scale measurements in an efficient way for the first time we studied the distribution effect of different fidelity data showing that the estimation accuracy of mf kriging depends on the locations of both the lf and hf data when hf data points are sparse and the location is far from the other hf data points the information provided from the lf data becomes crucial and can greatly enhance model accuracy this study suggests that hf data can provide more information to the model compared with lf data however hf data are generally more expensive to obtain mainly because of their more precise testing process for example pumping tests require drilling wells into the ground which costed approximately 11 000 for each 80 m well for each data point in this study however the eer measurements were conducted completely on the surface with no need for drilling this makes the cost of eer testing much lower at approximately only 600 for 80 m deep continuous data since the results also demonstrate that lf data can provide useful information to enhance the model estimation especially in regions where data points are sparsely distributed there is a trade off between deciding on hf versus lf measurements by implementing bayesian experimental design along with the current confidence levels from the kriging model optimal sensor placement locations for future data collection are suggested which were related to the expected value of information from future sensor data to rigorously inform the decision as to what should be the combination of lf and hf measurements future study is needed to develop a more holistic optimization framework that incorporates both data cost and fidelity and evaluates their complex interplay some future works are required according to the limitations of the model and the assumptions made for data usage for example eer measurements can correlate very differently with hydraulic conductivity on different scales and different soil mediums since soil porosity affects the correlation the relationships between eer and hydraulic conductivity used in the study were obtained from an experiment with sand lu et al 2019 which might not be representative of other types of geologic materials this consideration requires additional experiments to obtain a more universal empirical relationship between eer and hydraulic conductivity which is outside the scope of the current study also kriging is limited to the condition of when correlations are non local in a continuous field sometimes in a sparsely sampled area or in cases when the field is discontinuous because of rivers fractures or faults kriging might not be necessarily accurate therefore more measurements are needed to further confirm our approach for this study site however the current study presents a robust framework that reveals important facts about the usage of mf models along with bayesian statistics tools to enhance understanding and future observation design of hydro geology properties based on the existing data once the data provide certain levels of confidence mf kriging models can extract useful information from the data according to different levels of fidelity to make reasonable predictions with corresponding assumptions credit authorship contribution statement chien yung tseng methodology formal analysis investigation software visualization writing original draft writing review editing maryam ghadiri funding acquisition project administration supervision writing original draft writing review editing praveen kumar resources funding acquisition writing review editing hadi meidani conceptualization methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is funded under the provisions of section 104 of the water resources research act annual base grants 104b program made possible and distributed through the illinois water resources center and us geological survey c y t acknowledges support from the illinois water resources center the department of civil and environmental engineering at university of illinois at urbana champaign and the environmental sciences division at oak ridge national laboratory m g acknowledges support from the illinois water resources center and the u s geological survey p k acknowledges support from the national science foundation grant ear1331906 for the critical zone observatory for intensively managed landscapes a multi institutional collaborative effort h m acknowledges support from the department of civil and environmental engineering at university of illinois at urbana champaign instrumentation and technical support were provided by the illinois state geological survey special thanks are given to dr timothy larson and dr andrew stumpf at the illinois state geological survey and daniel r hadley at the illinois state water survey for providing data and supporting this research codes and data presented in this article are available on github through zenodo data repository https zenodo org record 7098032 c y t is an employee of ut battelle llc under contract de ac05 00or22725 with the us doe accordingly the us government retains and the publisher by accepting the article for publication acknowledges that the us government retains a nonexclusive paid up irrevocable worldwide license to publish or reproduce the published form of this manuscript or allow others to do so for us government purposes 
10,enhanced water management systems depend on accurate estimation of subsurface hydraulic properties however geologic formations can vary significantly so information from a single source e g widely spaced boreholes is insufficient in characterizing subsurface aquifer properties therefore multiple sources of information are needed to complement the hydrogeology understanding of a region this study presents a numerical framework in which information from different measurement sources is combined to characterize the 3d random field in a multi fidelity prediction model coupled with the model a bayesian experimental design was used to determine the best future sampling locations the upper sangamon watershed in east central illinois was selected as the case study site where the multi fidelity gaussian process model was used to estimate the hydraulic conductivity in the region of interest multi source observation data were obtained from electrical resistivity and borehole pumping tests the accuracy of the model prediction is dependent on the locations and the distribution of both high and low fidelity data furthermore the multi fidelity model was compared with the single fidelity model the uncertainties and confidence in the measurements and parameter estimates were quantified and used to design future cycles of data collection to further improve the confidence intervals keywords bayesian experiment gaussian process multi fidelity hydraulic conductivity hydro geoinformatics optimization 1 introduction reliable prediction of hydraulic properties of subsurface formations is a crucial step in improving water management systems there are various testing approaches to obtain information from the given area of interest borehole cross pumping test is a traditional reliable method to directly measure subsurface hydro geophysics properties such as hydraulic conductivity reinhart 2006 hamm et al 2007 there are several types of cross pumping tests constant rate pumping test is one of them which directly measures the steady water flow underground by maintaining a constant hydraulic head gradient across the subsurface however although borehole testing can provide relatively high confidence measurement results drilling a borehole to obtain the information at just one specific location is expensive and time consuming on the other hand electrical signal measurement such as earth electrical resistivity eer and electromagnetic induction have been broadly used in hydro geophysics investigations lesmes and friedman 2005 these tests introduce electrical current into the subsurface and measure the resistivity via several receivers along the transect which provides continuous hydro geophysics information in the measured region without intruding into the ground however this type of measurement requires direct or inverse empirical relations between electrical and hydro geophysical properties several studies have examined factors influencing relationships between electrical resistivity and hydraulic properties of aquifers kelly 1977 mazáč et al 1985 niwas and singhal 1985 yadav 1995 sikandar and christen 2012 for example mazáč et al 1990 studied the relationships between hydraulic conductivities and rock resistivities and they examined the role of the distribution of hydraulic conductivity on dynamics of pollution spreading in rock medium these relationships are sometimes case specific and not universal for all locations also soil saturation and temperature can affect these relationships as well khalil and santos 2009 therefore the estimation can cause tremendous errors if not used properly hydraulic conductivity of geologic formations can vary by orders of magnitude over relatively small spatial scales so characterizing subsurface aquifer properties using only the information acquired from a widely spaced single measurement is challenging and potentially inaccurate one method that has been widely employed is to use an integrated exploration approach in which borehole and other geophysical datasets are jointly interpreted lesmes and friedman 2005 numerous studies have used information at different levels of fidelity to estimate hydraulic conductivity for groundwater system models asher et al 2015 zhang et al 2018 these multi fidelity mf models combine low fidelity lf data with high fidelity hf data to approximate the prediction with an accuracy that is better than that offered by a single fidelity sf model peherstorfer et al 2018 fernández godino et al 2016 the terms hf data and lf data refer to different levels of detail and accuracy of the data hf data refers to data that is precise accurate and of high quality with a high level of detail and granularity while lf data on the other hand refers to data that is less accurate less precise and of lower quality with a lower level of detail and granularity forrester et al 2007 first proposed a global optimization strategy using mf surrogate models to include multiple levels of information into the predictions which is called mf kriging in mf kriging models data points obtained from sensors with different fidelity levels are fit with different surrogate models that provide estimation and prediction without the need to obtain a large number of expensive tests or run expensive numerical simulations among the surrogate models the gaussian process i e kriging has been widely used in mf groundwater modeling zaytsev and burnaev 2017 compared to the traditional co kriging method that uses information from correlated variables to improve the accuracy of predictions which involves modeling the correlation between two or more variables mf kriging focuses on using data from multiple levels of fidelity to improve the accuracy of spatial predictions by incorporating information from multiple sources the mf models facilitate the usage of data with different levels of fidelity by combining a hf function a more accurate but expensive representation of a physical phenomenon with a lf function a less accurate but inexpensive representation of a physical phenomenon asher et al 2015 and fernández godino et al 2016 extensively surveyed several data driven methods of combining fidelities with a primary focus on kriging models for mf applications this focus was particularly because such a gaussian process entails an uncertainty structure that readily lends itself to an mf modeling approach fernández godino et al 2016 a more recent study by zheng et al 2018 employed mf gaussian surrogates to propose an adaptive mf ensemble smoother for data assimilation to reduce the high computational cost for characterization of model parameters in ensemble based methods however numerous questions remain unanswered in predicting hydraulic properties of subsurface formations in watersheds for example how many field tests need to be conducted to achieve the desired accuracy of the estimation and what if the existing data points are sparse many studies have confirmed the usage of mf kriging models for predicting the hydro geophysical information in a specific region with abundant hf and lf data but few studies have focused on discussing the effects of hf and lf data location distribution especially in a data sparse situations another subject that has not been fully addressed is to understand how data fidelity associated with different tests would affect future test locations recently menberg et al 2020 used an mf approach along with bayesian parameter estimation in subsurface heat and fluid transport models to include information from a more physically accurate but expensive hf model as well as a large number of evaluations from a less accurate less expensive lf model the study demonstrated that the combined information from sources with different fidelities substantially improved the posterior distribution results which may be important for determining future test locations to optimize the information gained from newly implemented data sources in this study we present a quantitative mf framework to combine information from eer measurements and pumping borehole measurements with different fidelities and accuracies to enhance the understanding of hydro geophysical characteristics for the first time we specifically address the effect of data locations from data with different levels of fidelity under sparse data distributions also we investigated how future test locations with different fidelities should be conducted to optimally enhance our understanding of the geo hydraulic properties of a region according to the new information gained as a sample case study we selected an intensively managed area located in the upper sangamon watershed in east central illinois as the study site traditional high accuracy pumping test data were used with small scale eer measurements to generate 2d maps of hydraulic conductivity over a large scale region with quantified uncertainties in different depth layers according to the mf kriging framework the discussions focused on how the distribution of data with different fidelities would affect the model accuracy especially with sparse data points we further discussed how the mf model can learn from new sensors using probabilistic statistical tools to select the best locations for future data collection the approach was based on the bayesian experimental design which selects the best locations from a set of candidate locations according to the value of information that each location is expected to offer norberg and rosn 2006 by relating the expected value of information from each location to the present levels of uncertainties in the mf kriging model we thus can pick the best location with the most information gain the proposed method can serve as a quantitative decision support framework to optimally conduct tests with different cost and accuracy levels the remainder of this paper is organized as follows in section 2 we provide the theoretical background which includes detailed information about site selection observation data lognormal ordinary kriging lok mf lok and optimal bayesian experimental design in section 3 we show the topography of the upper sangamon watershed and discuss how the eer and pumping test data were obtained and how the multi source data were used in sf kriging with multiple data sources and mf kriging in section 4 we discuss the effect of fidelity on the estimated field and the estimation accuracy followed by the distribution of lf and hf data points the application of optimal bayesian experimental design for obtaining optimal future sampling locations is also presented finally section 5 provides discussions and conclusions 2 method 2 1 study site the sangamon river is a major tributary to the illinois river with the confluence near chandlerville in cass county llinois the watershed spreads across seven counties in east central illinois champaign christian dewitt ford macon mclean and piatt the major urban areas within the watershed are decatur monticello mahomet rantoul and gibson city it is intensively managed for soybean and corn production and is among the five watersheds in illinois that are identified as most in need of attention for water supply planning and management mattia et al 2018 the predominant land use in the watershed is row crop agriculture which comprises nearly 90 of the land area keefer et al 2005 as an intensively managed landscape this region is at risk for deterioration of land and water systems therefore more observations are needed to understand and predict the behavior of natural services ecological hydrological and climatic services that support basic human needs such as water food and energy 2 2 data description based on the geological properties of subsurface formation hydraulic conductivity is spatially correlated but sometimes can vary significantly hence information from a single source is insufficient indicating the need of multiple sources of information to complement the hydrogeology understanding of a region in this study two types of field observation data eer measurement and pumping tests were used as data sources with different fidelities to estimate hydraulic conductivity of the upper sangamon watershed using a mf gaussian process model more details in section 2 4 fig 1 shows the data locations the pumping test involved pumping from a test well at a controlled rate and monitoring the flow rate through the drawdown at different locations along the radial axis from the test well hydraulic conductivity values of aquifer material as determined from pump tests and aquifer tests varies spatially but not as much temporally repeated pump tests may show changes in hydraulic conductivity at the well skin of production wells or within gravel packs immediately surrounding well screens but repeated long duration aquifer tests would provide similar values over time the measured hydraulic conductivity values of aquifer material can provide convincing values therefore pumping test measurements have been well recognized as one of the most reliable ways to measure soil hydraulic conductivity with high fidelity meaning that the data is accurate and precise with high quality and less errors or discrepancies which provides a true and faithful representation of the true value in the real field however because of the high cost of drilling a well limited data can be collected eer measurement has also been widely applied to estimate hydraulic conductivity of the subsurface based on a 2d resistivity model of the relationships between aquifer hydraulic and electrical properties kelly and frohlich 1985 slater 2007 khalil and santos 2009 tizro et al 2010 the measurement relies on testing with a dipole dipole electrode configuration in a vertical 2d plane of the field which is commonly used in 2d electrical resistivity surveys because it provides good resolution of subsurface structures with high sensitivity to lateral changes in resistivity in the array current is injected into the ground using two current electrodes and voltage measurements are made using two pairs of potential electrodes placed at a distance from the current electrodes the distance between the current and potential electrodes is increased systematically to obtain measurements at various depths the dipole dipole array is particularly useful for detecting planar variations vertically and horizontally in subsurface resistivity to infer the hydraulic conductivity however the accuracy depends on the equipment precision hence the measurement has lower cost but also lower fidelity due to its lower accuracy compared with traditional pumping borehole testing in general eer values are known to vary there are many factors that can affect the measured resistivity like soil texture clayey matters pore structure and temperature the greatest variability generally comes from the changes in saturation conditions and temperature khalil and santos 2009 within the upper sangamon watershed the water table is within a few meters of the ground surface except in areas of very steep slopes and very coarse materials these areas are a small percentage of the entire area and thus can be neglected at the scale of this study there is some variation from temperature but we neglected this effect because it is small within the context of this generalized study eer measurement provides a continuous estimation of hydraulic conductivity in a small vertical plane 800 m long and 80 m deep to apply the eer data together with the pumping test data in the mf gaussian process model we need to ensure that two data sources provide the same physical meanings therefore eer has to be converted to hydraulic conductivity since pumping tests directly provide the hydraulic conductivity information a study by lu et al 2019 demonstrated that the relationship between the soil s hydraulic conductivity k and electrical conductivity σ ec follows an exponential function form as k a e b σ e c c where the parameters a b and c can be estimated using the calculated σ ec in soil layers which is the inverse of the resistivity data captured by eer testing according to their experiment results with sands when k is a dependent variable the given best fitted empirical parameters can be obtained by fitting to a comprehensive data set 1 a 299 6 e 0 001147 σ e c 157 b 0 2061 e 0 0001535 σ e c 0 004299 c 7 996 e 0 0001264 σ e c 0 6567 as mentioned previously many factors can affect the empirical relationship between the measured resistivity and k especially the soil pore size within the upper sangamon watershed the dominant soil types found in this area are mollisols and alfisols whose pore sizes can range from 0 1 to 1 0 mm which is similar to the pore size of the typical sands 0 2 to 2 0 mm therefore we assumed that eq 1 by lu et al 2019 is valid within the context of this generalized study in this study as the soil deposition was accumulated layer by layer resulting in a consistent geological composition horizontally after converting the measured resistivity σ ec into hydraulic conductivity k the horizontal mean value of k was set as the representative value in each depth for the lf data input in the mf kriging model borehole pumping tests were conducted at specific locations with different depths unlike eer measurement which provides continuous vertical information pumping tests provide point information on subsurface properties from the measurement of flow velocities within soil pores they offer higher accuracy on hydraulic conductivity which was set as the hf data source in mf kriging we obtained eer data from 15 locations with continuous depth and pumping test data from 68 locations with specific depths for each test compared to the entire horizontal study domain 60km 50km with the relatively sparse distributions of the data points both eer and pumping test can be viewed as point measurements in the model under nearly the same measurement scale in each layer the eer and pumping tests were conducted by the illinois state geological survey and illinois state water survey and the locations of the tests were originally selected to aid in quaternary mapping projects and to develop communities water supply planning and management 2 3 lognormal ordinary kriging lognormal ordinary kriging lok is a commonly used geostatistical procedure that generates an estimated mapping of geo properties from a scattered set of points with scalar values based on a logarithmic transformation of the estimators balaban and dengiz 2018 compared to the traditional ordinary kriging model the lok model can improve the calculation of statistics and weighted averages to avoid negative and extreme estimated values which helps to reduce the impact of outliers on the estimated values roth 1998 also the lok model can be more appropriate when the variable being studied exhibits a positive skewed distribution providing more accurate and realistic estimates since it considers the asymmetry of the distribution as shown in fig 2 the positively skewed distribution of k can be observed in both pumping test data and eer data under a normal scale however after we transformed the data on a log scale the data looks more symmetrical without any extreme data the lok model algorithm follows the structure of gaussian processes 2 l n y f x g p μ k where x xi represents the locations of the data points y yi represents the measured hydraulic conductivity corresponding to the locations x μ is the mean value of ln y within the simulation domain and k kij is a symmetric matrix which is constructed by the kriging function k xi xj θ with exponential variogram through the following equation 3 k i j k x i x j θ n s 1 e x i x j r 3 where θ n s r are the kriging parameters namely nugget n sill s and range r the nugget n is related to the amount of a short range of the initial randomness or noise in the data the range r represents the distance at which data are no longer correlated and the semivariance first flattens out and reaches the sill s the total variance where the empirical variogram appears to level off the kriging parameters can be obtained by fitting the sample variogram to the semivariance γ with the given the observation data x y which can be expressed as 4 γ d i j 1 2 e l n y i l n y j 2 k x i x j θ where dij xi xj and e is the expectation operator that returns the mean value then for the estimations at a set of new locations of points x normal distribution is applied 5 f x f x n μ k x x θ k x x θ k x x θ k according to the resulting conditional distribution estimations at a given point are given by 6 f x x n μ l σ l where 7 μ l μ k x x θ k 1 y μ 8 σ l k x x θ k x x θ k 1 k x x θ since f x is in logarithmic scale to estimate the parameter of interest in this case the hydraulic conductivity we converted the logarithmic values μ l and σ l back to the actual mean and standard deviation values according to 9 μ e x p μ l σ l 2 2 10 σ e x p σ l 2 1 e x p 2 μ l σ l 2 2 4 multi fidelity lognormal ordinary kriging to combine the observation data from eer measurements and pumping testing the mf lok model was used to perform 2d hydraulic conductivity mapping in different depth layers with smooth and continuous fusion of information from two sources with different levels of fidelity precision the mf kriging algorithm follows the structure proposed by kennedy and o hagan 2000 and forrester et al 2007 assuming that 11 u l x g p μ k l x x θ l 12 u h x g p μ k h x x θ h are two independent kriging functions then the lf and hf lok functions can be modeled as fl x ul x and fh x ρul x uh x respectively which can be expressed as a multi output lok 13 f l x f h x g p μ k l l x x θ l k l h x x θ l ρ k h l x x θ l ρ k h h x x θ l θ h ρ where 14 k l l x x θ l k l x x θ l 15 k l h x x θ l ρ k h l x x θ l ρ ρ k l x x θ l 16 k h h x x θ l θ h ρ ρ 2 k l x x θ l k h x x θ h kl and kh are the kriging functions eq 3 for the lf and hf data respectively and ρ is the mf constant which was first proposed by forrester et al 2007 as a scaling factor to approximate the data with a lf contribution to the prediction following the auto regressive model kennedy and o hagan 2000 the idea is to approximate the high fidelity function fh x as the low fidelity gaussian process surrogate ul x multiplied by a scaling factor ρ plus a high fidelity gaussian process surrogate uh x that represents the difference between ρul x and uh x to consider both contributions from the low fidelity and high fidelity data given the observation lf and hf data x l y l and x h y h the kriging parameters θ l and θ h can be fitted by the sample variogram according to the kriging functions of the lf and hf data respectively to obtain the optimized ρ normal distribution is applied 17 f m g p z n μ k where 18 z ln y l ln y h 19 k k l l x l x l θ l k l h x l x h θ l ρ k h l x h x l θ l ρ k h h x h x h θ l θ h ρ and the optimized constant ρ can be trained by minimizing the negative log marginal likelihood nlml 20 n l m l θ l θ h ρ 1 2 y t k 1 y 1 2 l n k n 2 l n 2 π where n is the total number of the data points in this study we used a truncated newton algorithm minimization method nash 1984 to obtain the optimized constant ρ for the estimations at a new set of points x we first constructed the joint distribution 21 f h x z n μ k h h x x θ l θ h ρ q t q k where 22 q t k h l x x l θ l ρ k h h x x h θ l θ h ρ like the sf lok model according to the resulting conditional distribution predictions can be estimated by 23 f h x z n μ m σ m where 24 μ m μ q t k 1 y μ 25 σ m k h h x x q t k 1 q finally we back transform the mean μ m and the standard deviation σ m of the mf model into the normal domain 26 μ e x p μ m σ m 2 2 27 σ e x p σ m 2 1 e x p 2 μ m σ m 2 2 5 optimal bayesian experimental design our experimental design addresses the challenge of identifying the best locations for future tests or data collections these locations are identified based on the value of information that each location is expected to offer norberg and rosn 2006 for instance in the context of hydraulic property estimation for aquifers measurements collected from locations that are closely spaced will provide much less information compared with those obtained from locations that are farther apart in establishing a quantitative framework that captures these facts a bayesian experimental design procedure can be used this begins by quantifying the value of information specifically the value of information is defined as the information gain conditioned on the design variables the information gain is formally defined as the kullback leibler divergence from the posterior distributions of the model parameter to the prior chaloner and verdinelli 1995 the best experiment among the ensemble of candidates is the one that maximizes the information gain taken to be the kullback leibler divergence from posterior to prior solving this optimization problem is numerically complicated because the evaluation of kullback leibler divergence requires samples from the prior and posterior of the parameters here we provide the technical background for this experimental design approach combined with the mf kriging model using bayesian inference the posterior distribution of model parameters p θ d s can be expressed as 28 p θ d s p θ s p d θ s p d s where p θ s is the prior distribution p d θ s is the likelihood and p d s is the evidence which can be considered as a normalizing constant 29 p d s p d θ s p θ s d θ in this study θ is the sampled kriging parameters including n s and r n and s are constant values according to the mf model and r represents the gaussian distributed samples based on the fitted lf and hf range rl and rh with σ l 0 01rl and σ h 0 01rl which were selected to create data samples that are closely clustered around the mean range values rl and rh more specifically we aim to make the data samples to be very precise and consistent with little variations so that the modeled variations of the prior distribution mainly come from d which is the sampled observation data whose probability distribution can be assumed gaussian like with the model estimated μ and σ s represents the designed future sampling location since the prior knowledge of θ is not affected by s the prior distribution 30 p θ s p θ the expected utility in bayesian experimental design can be expressed as lindley 1956 31 u s u s d θ p θ d s d θ d d where u s d θ is the utility function following the algorithm proposed by zhang et al 2015 the relative entropy from the prior to the posterior is chosen as the utility function lindley 1956 which considers the expected gain in shannon information shannon 1948 given by the experiment 32 u s d θ p θ d s ln p θ d s p θ s d θ according to bayes theorem and the monte carlo approach the integral in eq 31 can be approximated by the sum of the discrete values 33 u s 1 n i 1 n l n p d i θ i s l n p d i s where di is each of the sampling data point and n is the total number of the sampling data points from eqs 29 and 30 the evidence p di s can also be approximated by the monte carlo approach 34 p d i s p d i θ s p θ d θ 1 n j 1 n p d i θ j s where the likelihood function p di θ j s uses the gaussian radial basis likelihood function that consists of a exponential decaying function with the mf kriging model g 35 p d i θ j s exp 1 2 d i g θ j s 2 combining eqs 33 34 and 35 the optimal sampling location s can be obtained by maximizing the expected utility u s over the design domain d which can be achieved by minimizing the negative u s 36 s a r g max s d u s a r g min s d u s to avoid being trapped by the local minimum points during optimization process we applied a traditional brutal approach by setting the candidate locations for s every 1 km in x and y directions and then selected the one who had the minimum utility value u s as s the results of the sequential bayesian experimental design application for future sampling locations are demonstrated in section 4 3 3 results 3 1 topography investigation we used lidar data from the us geological survey national elevation dataset for the upper sangamon watershed along with the eer and pumping test data the lidar data are uniformly distributed in the rectangular region of the upper sangamon watershed as shown in fig 1 multi quadratic radial basis function with euclidean distance was used to interpolate the elevation between the lidar data points fig 3 a shows that the topography of the watershed is generally flat which is on average within a range of approximately 210 to 230 m there is only a relatively low region in the southeastern region 180 m the flat topography suggests that a reasonable approach would be to represent the domain in a cartesian coordinate system x y z denoting x coordinate along the latitude y coordinate along the longitude and the z coordinate by depth distance from the surface to ignore the surface variation and set all the locations surface as zero in depth for the z value 3 2 single fidelity results with multiple data sources the upper sangamon watershed is in a typical glaciated midwest river basin which shows characteristic low relief landscapes and reflects glacial deposition patterns except for regions modified by stream processes in valleys therefore soil deposition patterns are expected to have a layer by layer distribution the watershed contains mostly sand and gravel deposits concentrated in different layers which are typically 10 to 15 m thick selkregg and kempton 1958 with an additional sensitivity analysis between the mf kriging results in five layers z 15 m and the results in eight layers z 10 m at similar depth the comparison reconfirms that five layers with 15 m thickness is good enough to show the general geological property such as hydraulic conductivity in different layers in the watershed therefore we divided the 75 m thick domain region into five 15 m thick layers where eer and pumping test data are located in a range between 10 and 85 m deep from the surface as shown in fig 3 b within the same layer soil and hydraulic properties e g hydraulic conductivity are similar and correlate across different locations we constructed a 2d horizontal kriging model in different layers to construct a multilayer mapping of hydraulic conductivity sf kriging with multiple data sources was conducted as the reference to compare with the mf kriging model in the sf kriging model the data sources were treated equally ignoring their different fidelities the exponential model is one of the most commonly used models to characterize cross spatial dependence in geological property data which suggests that data spatial autocorrelation decreases exponentially with increasing distance based on prior knowledge of the phenomenon oliver and webster 2015 we thus used the exponential function based variogram to fit the semivariance of the data eq 4 including eer and pumping test data on the sample variogram oliver and webster 1990 a python based fitting tool using a nonlinear least squares algorithm was applied for curve fitting the fitted kriging parameters of n 0 02 s 0 79 and r 11 39 were used when measurements are done at irregular grid points setting a bandwidth lag tolerance and angle tolerance to account for the directional influence anisotropic effects can be helpful to statistically quantify and analyze sample contributions in different ranges depending on the direction however since there is a limited number of representative observation data from eer and pumping tests we assumed isotropic contribution from all the measurements without setting a bandwidth or tolerance to ensure sufficient data points in the sample variogram in fig 4 the sf kriging result shows a relatively uniform distribution of mapped hydraulic conductivity k in the upper three layers depth 50 m and some peak values can be observed in the lower two layers depth 50 m this result suggests that more varying soil properties exist in the deeper layers of the watershed the uncertainty in the estimated properties is presented by the standard deviations σ however we can see that some regions with high standard deviation around the hf data point shown in fig 4d and 4e it is because when converting the standard deviation σ from the lognormal scale back to normal scale the magnitude of σ is also related to the magnitude of the mean value μ l eq 10 at the region where the estimated mean magnitude of k is high will result in a relatively high deviation however if we look closer to the lower left point inside the blue circle in fig 4e the deviation around the data point remains low blue to yellow due to the unbiased estimate from the model near the data point but quickly becomes higher orange due to the high mean k region red region in the upper panels 3 3 multi fidelity results the sf kriging model did not account for the fact that data are from different sources so they were considered with the same uncertainty however since different data sources typically have different uncertainty error ranges depending on equipment methods and human factors the fidelity of these data sources should also be incorporated into the model incorporation of these factors makes mf kriging models a more accurate approach than sf kriging models when multiple sources of data are available thus not much confidence can be placed in the sf kriging result shown in fig 4 data with different levels of fidelity should also be treated separately in the sample variogram for two sets of fitted kriging parameters in the mf kriging model we treated eer and pumping test data separately where kriging parameters were obtained from each sample variogram the fitted kriging parameters based on the exponential function based variogram are n 0 06 s 0 08 and r 2 91 for eer measurement and n 0 49 s 0 88 and r 21 12 for pumping tests according to the fitted kriging parameters the range r of the high fidelity pumping test dataset r 21 12 which is much higher than the range r of the low fidelity eer dataset r 2 91 indicating that eer data has weaker spatial correlation due to its low fidelity of the data accuracy and quality fig 5 shows the mf kriging result of the hydraulic conductivity and the corresponding standard deviation in the upper sangamon watershed compared with the sf kriging results shown in fig 4 mf kriging puts more weight on the hf data shown by circle markers thus the estimated k and σ distribution patterns generally follow the distribution of the pumping test data furthermore regions near the hf data points blue circles in fig 5 have lower standard deviation this means that the model assesses higher confidence in the estimates in those regions the lf data shown by cross markers however do not help reduce uncertainty levels in a large area but nevertheless provide local hydraulic information in regions far from the hf data locations 4 discussion 4 1 fidelity effect on the predicted field in mf kriging pumping test data were selected as the hf data source because they offer a more reliable measurement method than eer data hence the estimated k and σ values based on mf kriging fig 5 are mostly dominated by the hf data pumping test data to further study the fidelity effect we excluded the lf data and only considered the hf data in the kriging model fig 6 to compare with the mf results fig 5 fig 6 shows that in regions near the hf data the estimated k and σ values are similar to those in fig 5 however in regions far from the hf data points the models provide very different k and σ estimates especially in the upper three layers depth 50 m where hf data points are scarce the higher σ estimations are because of the additional information provided by the lf data however the higher estimated σ does not suggest that the lf data provide incorrect information instead the different estimations of k suggest that the lf data do provide valuable information about the hydraulic conductivity properties for regions where expensive hf tests are not available or economically not feasible 4 2 fidelity effect on the estimation accuracy to evaluate the estimated k values in the mf kriging model we focused on the lower two layers depth 50 m and removed hf data points in each layer from the estimation model since hf data was measured directly by the pumping test with high accuracy we assumed its measured k is the true value and used the removed hf data points as the reference to compare with the model estimated values in fig 7 the red circles show the locations of the removed hf data points in each layer the removed data points were selected based on their locations specifically we preferred hf locations that were close to an lf data location to assess the accuracy of lf data contributions the calculated standard deviation values did not differ significantly between the mf model and the shf model more hf data can increase the confidence levels in both cases however a difference in estimated k values was not observed in this comparison the removed hf data points provide a reference value of k 0 078 cm s fig 7a and 0 026 cm s fig 7d in the fourth layer and k 0 081 cm s fig 7g in the fifth layer at the data locations after the data points were removed the mf model provided a prediction of k 0 081 cm s fig 7b and 0 033 cm s fig 7e in the fourth layer and k 0 107 cm s fig 7h in the fifth layer at the data locations the shf model provided a prediction of k 0 052 cm s fig 7c and 0 032 cm s fig 7f in the fourth layer and k 0 086 cm s fig 7i in the fifth layer at the data locations these results provide an estimated accuracy to obtain a more precise measure of accuracy we defined ak as 37 a k 1 k p r e d k r e f k r e f where kpred is the predicted k from the mf or shf model kref is the reference k i e the removed hf data for the mf model the accuracy is 96 fig 7b and 73 fig 7e in the fourth layer and 68 fig 7h in the fifth layer and for the shf model the accuracy was 67 fig 7c and 77 fig 7f in the fourth layer and 94 fig 7i in the fifth layer the accuracy shows that when the removed points were far from the other hf data points lf data provided important information to enhance the estimation of the kriging model fig 7a b c when the removed points were relatively close to the other hf data points lf data were not necessary and the predictions are dominated by the information provided from the surrounding hf data points with nearly the same accuracy in mf and shf models figure d e f when the removed points were in similar distances from the surrounding hf and lf data points lf data might even provide information with higher variance due to its relatively low accuracy compared with the hf information fig 7g h i thus the accuracy of the mf model depends on the locations and the distribution of both the lf and hf data when hf data points are scarce and far from the lf data points the information provided from lf data becomes important and can enhance model performance and accuracy to further investigate the fidelity effect we choose the deepest fifth layer as the test case and consecutively remove hf data points one by one within or close to the lf data points fig 8 shows the estimated hydraulic conductivity field by mf kriging and shf kriging under four point removal scenarios keep all the hf data remove one point remove two points and remove three points comparing the results of mf kriging versus shf kriging as more data points were removed shf kriging showed a relatively lower and more uniform estimated k field however since lf data still provided the surrounding information in mf kriging they provided estimated k values closer to the original estimates where all the data points were present according to the definition in eq 37 fig 9 shows the accuracy of k estimates at locations pt 1 pt 2 and pt 3 under mf kriging and shf kriging when no data points one data point two data points and three data points were removed when all data points were present the accuracy was 100 at all three locations when one point was removed at location pt 1 the accuracy remained 100 at locations pt 2 and pt 3 but at location pt 1 shf kriging shows a greater accuracy compared with mf kriging because of the far distance between the removed point and the lf data points as discussed in fig 7 when data at two points locations pt 1 and pt 2 were removed mf kriging began to show higher accuracy at locations pt 1 and pt 2 and location pt 3 remained at 100 accuracy when all three data points were removed mf kriging showed obviously higher accuracy at all the locations compared with shf kriging the results again confirm that when hf data become scarcer the information provided by lf data becomes more critical in mf kriging and can lead to better estimation of hydraulic conductivity 4 3 future data collection using bayesian experimental design we applied the bayesian experimental design along with the mf kriging model to determine the future sampling locations for the hf data pumping test measurement we chose the deepest fifth layer which has more uniform distribution of both lf and hf data points five optimal sampling locations for future pumping test data were estimated one by one with the initial guesses of the sampling location uniformly assigned in the simulation domain fig 1 once the current optimal point was obtained the hydraulic conductivity value was then predicted by the mf kriging model at that location the current estimated optimal point with its predicted hydraulic conductivity was then put back in the mf kriging model as one of the synthetic measurement data points to update the model and train the new optimized constant ρ for the next optimal sampling location the final optimal result is shown in fig 10 the optimal locations are denoted by the red triangles with the numbers indicating the sequential order the sampling points were located in the region where σ was high indicating the need of future measurements to enhance the confidence of the prediction and understanding of the region of interest the future sampling points provided more information to the region near the suggested locations where variances were greatly reduced variances were slightly increased in regions far from the suggested locations because of the unbalanced information entered into the model however according to bayesian experimental design those regions were relatively less efficient for future measurements compared with the suggested locations when considering the expected gain in shannon information see section 2 5 the bayesian experimental design model can be carried out for both pumping test data and eer measurement data however because the pumping test data hf data are dominant in the mf kriging model and the pumping test is more expensive and thus more limited the appropriate future optimal locations are more critical than eer test locations from an economical perspective therefore in this study we performed the bayesian experimental design to infer the optimal locations for future pumping tests which can provide more valuable information as suggested by the model this work can be used in future studies on developing a more robust optimization framework that incorporates data cost and fidelity and can reveal their complex interactions 5 discussions and conclusions this work presents a robust approach to exploit multi source data to estimate the 3d random field of hydraulic conductivities we demonstrated how the described framework can use the combination of pumping test data from boreholes which are expensive and highly accurate with observation data from less expensive and less accurate eer measurements this approach offers a cost effective approach to reliably characterize the hydraulic conductivity properties specifically in under sampled sites and can be particularly used in obtaining large scale parameter maps for a region using small scale measurements in an efficient way for the first time we studied the distribution effect of different fidelity data showing that the estimation accuracy of mf kriging depends on the locations of both the lf and hf data when hf data points are sparse and the location is far from the other hf data points the information provided from the lf data becomes crucial and can greatly enhance model accuracy this study suggests that hf data can provide more information to the model compared with lf data however hf data are generally more expensive to obtain mainly because of their more precise testing process for example pumping tests require drilling wells into the ground which costed approximately 11 000 for each 80 m well for each data point in this study however the eer measurements were conducted completely on the surface with no need for drilling this makes the cost of eer testing much lower at approximately only 600 for 80 m deep continuous data since the results also demonstrate that lf data can provide useful information to enhance the model estimation especially in regions where data points are sparsely distributed there is a trade off between deciding on hf versus lf measurements by implementing bayesian experimental design along with the current confidence levels from the kriging model optimal sensor placement locations for future data collection are suggested which were related to the expected value of information from future sensor data to rigorously inform the decision as to what should be the combination of lf and hf measurements future study is needed to develop a more holistic optimization framework that incorporates both data cost and fidelity and evaluates their complex interplay some future works are required according to the limitations of the model and the assumptions made for data usage for example eer measurements can correlate very differently with hydraulic conductivity on different scales and different soil mediums since soil porosity affects the correlation the relationships between eer and hydraulic conductivity used in the study were obtained from an experiment with sand lu et al 2019 which might not be representative of other types of geologic materials this consideration requires additional experiments to obtain a more universal empirical relationship between eer and hydraulic conductivity which is outside the scope of the current study also kriging is limited to the condition of when correlations are non local in a continuous field sometimes in a sparsely sampled area or in cases when the field is discontinuous because of rivers fractures or faults kriging might not be necessarily accurate therefore more measurements are needed to further confirm our approach for this study site however the current study presents a robust framework that reveals important facts about the usage of mf models along with bayesian statistics tools to enhance understanding and future observation design of hydro geology properties based on the existing data once the data provide certain levels of confidence mf kriging models can extract useful information from the data according to different levels of fidelity to make reasonable predictions with corresponding assumptions credit authorship contribution statement chien yung tseng methodology formal analysis investigation software visualization writing original draft writing review editing maryam ghadiri funding acquisition project administration supervision writing original draft writing review editing praveen kumar resources funding acquisition writing review editing hadi meidani conceptualization methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is funded under the provisions of section 104 of the water resources research act annual base grants 104b program made possible and distributed through the illinois water resources center and us geological survey c y t acknowledges support from the illinois water resources center the department of civil and environmental engineering at university of illinois at urbana champaign and the environmental sciences division at oak ridge national laboratory m g acknowledges support from the illinois water resources center and the u s geological survey p k acknowledges support from the national science foundation grant ear1331906 for the critical zone observatory for intensively managed landscapes a multi institutional collaborative effort h m acknowledges support from the department of civil and environmental engineering at university of illinois at urbana champaign instrumentation and technical support were provided by the illinois state geological survey special thanks are given to dr timothy larson and dr andrew stumpf at the illinois state geological survey and daniel r hadley at the illinois state water survey for providing data and supporting this research codes and data presented in this article are available on github through zenodo data repository https zenodo org record 7098032 c y t is an employee of ut battelle llc under contract de ac05 00or22725 with the us doe accordingly the us government retains and the publisher by accepting the article for publication acknowledges that the us government retains a nonexclusive paid up irrevocable worldwide license to publish or reproduce the published form of this manuscript or allow others to do so for us government purposes 
11,recent advances in remote sensing technologies along with the increased availability of topographic data have lately encouraged the development of automatic dem digital elevation model based procedures for floodplain delineation geomorphic methods establishing relationships between flood descriptors and morphologic catchment characteristics appear particularly suitable to be implemented within a gis algorithm in the present work four simplified geomorphic approaches based on flow depth scaling laws fd or flow cross sectional area scaling laws fa with contributing area and two methods employing two different flood descriptors hydro geomorphic method hgm and geomorphic flood index method gfim have been applied for the preliminary evaluation of floodplain extent using high resolution dems i e lidar at 1 and 2 m resolution as the main input taking as a case study six of the largest basins located in southern italy the performances of these methods were evaluated and critically compared using government agency derived flood hazard maps as benchmarks results show that the adoption of fd especially when combined with morphology to formulate the gfim allows to efficiently predict the flood prone areas with low computational costs at the same time performances of the flood mapping procedures based on flow area scaling laws although in principle more appealing seem to be slightly lower overall the proposed approaches can be applied for rough mapping of floodplains in ungauged basins or in data scarce regions where standard flood hazard maps are unavailable keywords floodplain mapping flood descriptors scaling laws digital elevation model 1 introduction identification of flood prone areas has become an urgent challenge in flood risk management representing a key task to reduce flood damages and minimise loss of life during extreme events according to the emergency events database em dat maintained by the centre for research on the epidemiology of disasters cred in the 20 year period between 2000 and 2019 floods have been the most frequently occurring type of natural disaster accounting for 44 of total events affecting 1 6 billion people worldwide and leading to approximately us 651 billion in economic losses cred 2020 furthermore floods intensity and frequency are expected to increase due to climate change over the next decades scientific evidence indicates that these trends are partially attributable to the global temperature rise which according to clausius clapeyron relation leads to a greater moisture holding capacity of the atmosphere thus resulting in an increase of rainfall extremes fowler et al 2021 the severe flooding observed in western germany during july 2021 lehmkuhl et al 2022 which caused nearly 200 fatalities suggests that climate disruption is already revealing its impact on weather patterns making the implementation of effective flood risk mitigation strategies one of the most pressing needs of our time flood inundation maps represent useful tools helping urban planners and stakeholders to identify which areas could potentially be affected by these natural phenomena their effectiveness has been widely recognised to the point that among eu european union member states it has become mandatory to map flood extent since directive 2007 60 ec has entered into force while in the united states such maps are provided by the federal emergency management agency fema to support the national flood insurance program traditional floodplain mapping techniques entail significant data collection as they usually involve both hydrologic and hydraulic analyses when the stream gauge network is sparse and historical rainfall series are the only type of accessible data over a given region hydrological modelling allows the assessment of hydrographs associated with specific return periods rainfall runoff models would normally receive as the main input a hyetograph based on the intensity duration frequency curve idf curve valid for the study area idf curves are typically obtained through complex procedures involving statistical analysis of long term historical rainfall observations deidda et al 2021 their update under the conditions of a changing climate is a modern challenge forestieri et al 2018 by simulating the physical processes involved in the transformation of rainfall into runoff hydrological models provide as output hydrographs of assigned return period which are then used as input of hydraulic models to simulate the flood propagation over complex domains their setup requires accurate topographic information on river features and artificial structures along the reach e g bridges culverts levees evaluation of surface roughness and the assignment of appropriate boundary conditions hydraulic simulations are also time consuming and computationally intensive other than being costly all in all conventional floodplain mapping approaches are difficult to apply especially in those regions where hydrological and morphological data are scarce in recent years the increasing availability of high resolution dems has encouraged the development of alternative cost effective procedures based on river basin geomorphic features to perform preliminary floodplain delineation in ungauged areas these methods rely on the assumption that floodplains are the end product of the accumulated effects of flood events occurred over time and are therefore characterized by unique geomorphic and hydrologic properties that make them distinguishable from adjacent hillslopes nardi et al 2006 various authors successfully experimented hydrogeomorphic approaches based on the application of hydraulic geometry relations leopold and maddock 1953 bhowmik 1984 highlighting their potential capabilities in flood prone areas detection the term hydraulic geometry was first introduced by leopold and maddock 1953 to describe those relationships between stream channel hydraulic characteristics and discharge at any river cross section subsequently bhowmik 1984 supposed that the concept of hydraulic geometry could also be applied to define floodplains characteristics and proved the existence of simple scaling laws relating floodplains hydraulic properties e g width flow area flow depth to the upstream contributing area such relationships have received increasing attention in recent investigations as they allow to easily estimate hydraulic status that conversely would normally be evaluated through hydraulic simulations and moreover they appear particularly suitable to be implemented within gis based procedures for example nardi et al 2006 2013 2019 proposed an algorithm that identifies floodplain extent by comparing river corridors terrain elevation with the absolute elevation of a variable flow depth estimated as a function of contributing area at each stream cell through a stream order averaged scaling law the scaling parameters were initially estimated using water depth values derived from manning equation in conjunction with giuh geomorphologic instantaneous unit hydrograph peak discharge rodríguez iturbe et al 1979 rodriguez iturbe 1993 while in a global scale application nardi et al 2019 proved that optimal parameterization obtained through a simple calibration performed with reference maps provides consistent results while being less computational demanding in a recent study annis et al 2022 investigated the influence of morphologic and climatic river basin characteristics on the parameters of the scaling law between flow depth and drainage area demonstrating that enhanced performances can be achieved considering parameterization for different ranges of slopes and average annual rainfall other researchers implemented linear binary classification procedures and assessed the performance of several classifiers in identifying areas exposed to flood hazard for example degiorgis et al 2012 applied a threshold binary classification technique employing different classifiers derived from single dem based morphological features this approach has been reapplied by manfreda et al 2014 to carry out a comparative analysis with the hydrogeomorphic algorithm nardi et al 2006 and the modified topographic index method manfreda et al 2011 in another work samela et al 2017 compared the performance of eleven classifiers applied at continental scale and investigated the transferability of the corresponding optimal thresholds with varying topography and calibration area extent according to the authors a calibration area at least equal to 2 of the total drainage area of interest allows to determine a threshold value close enough to the optimal one their results also showed that amongst all the tested flood descriptors the geomorphic flood index gfi appeared more transferrable than others in areas with varying topography providing the most reliable and accurate floodplain delineation the aforementioned studies have been carried out utilizing dems with grid resolution ranging from 30 m to 250 m which allow to rapidly produce inundation maps at large scale in a different effort zheng et al 2018 presented a new effective workflow combining the hand height above nearest drainage method rennó et al 2008 nobre et al 2016 with an automatic channel network extraction procedure passalacqua et al 2010 that avails of high resolution topographic data e g 3 m resolution dem without compromising computational efficiency to date similar applications of hydrogeomorphic methodologies employing information obtained from dems at very high resolution are still exiguous the present work aims to investigate the performance of four geomorphic approaches at the basin scale coupling estimations from two simple power laws relating upstream contributing area to cross sectional flow depth and flow area hereafter referred to as flow depth scaling laws fd and flow area scaling laws fa respectively and two mapping methods named hydro geomorphic method hgm and geomorphic flood index method gfim the flood prone areas in hgm methods are identified by comparing a variable flow depth computed along the reach to the relative elevation of those cells hydrologically connected to the stream following the algorithm described by nardi et al 2019 instead the gfim methods avail of the geomorphic flood index samela et al 2017 as a flood descriptor and utilize the threshold binary classification to discern between flooded or not flooded areas the hgm fd and the gfim fd methods take advantage of the straightforward relation between the flow depth and the drainage area flow depth scaling laws fd whilst the hgm fa and the gfim fa make use of the scaling law relating cross sectional flow area to contributing area flow area scaling laws fa while the implementation of floodplain mapping procedures taking advantage of the scaling relation between flow depth and contributing area flow depth scaling laws fd has already been experimented in other studies to our best knowledge flow area scaling laws fa relating cross sectional flow area to drainage area represent an element of novelty of this work that in our opinion deserve to be investigated indeed we should expect in principle a stronger dependence of the flow area rather than the flow depth on the contributing area since the flow depth is more affected by the river cross section shape as will be discussed in the appendix it is worth noticing that the application of hgm fa and the gfim fa methods requires the identification of a flow depth flow area relationship fdfa in each river cross section considered in the analysis or alternatively implies some additional steps which can be synthesized in the implementation of a root finding algorithm that allows to approximately estimate the flow depth associated with a flow area value in any given river cross section of known profile the considered floodplain mapping procedures were implemented in a gis environment using as primary input the information extracted from high resolution dems derived from lidar surveys at 1 m and 2 m resolution in sardinia and sicily italy respectively official flood hazard maps provided by regional agiencies were used to calibrate the four approaches and then as a benchmark to evaluate the performances on three major river basins in sicily and three major rivers in sardinia applying standard indices based on contingency tables and commonly employed for forecast verification this paper is organised as follows section 2 describes the methodology and the implementation of the four approaches with details on flood descriptors and the geomorphic power laws the study area and dataset including terrain data and official flood hazard maps are presented in section 3 in section 4 outcomes form the application of the four approaches are illustrated and then discussed in section 5 along with their strengths and limitations finally section 6 summarizes the main results and suggestions for further studies a flowchart of the four implemented methods used to obtain floodplain mapping based on fd or fa is reported in the supplementary material figure s1 2 methodology 2 1 flood descriptors and geomorphic scaling laws in this section the main assumptions of the four considered geomorphic approaches to map expected flood prone areas in the river basins of interest are introduced and described the core of all the methods relies on the definition of flood descriptors based on an empirically estimated water level flood descriptors can be considered as potential indicators of the susceptibility of an area to be flooded starting from the topographic data contained in dems they can be calculated through proper procedures and then represented in a gridded layer the four considered approaches require a preliminary terrain analysis to assign to each grid cell i j of the dem a flow direction dij and a corresponding flow accumulation fij and subsequently to obtain the river network binary raster in this work these operations were performed with the r watershed module of the grass gis jasiewicz and metz 2011 using the d8 single direction flow algorithm o callaghan and mark 1984 stream network is identified by flagging cells r s with a flow accumulation frs exceeding a constant predefined threshold also the drainage area ars at any stream cell r s can be immediately calculated as the product between the local flow accumulation frs and the cell size once flow accumulation frs and the drainage area ars layers are extracted from the dem as described above we assign to each river network cell r s a variable flood stage hrs above the thalweg derived through simple geomorphic scaling laws as defined below the hgm fd and the gfim fd methods make use of a relation that expresses the flow depth above riverbed h r s f d as a function of the contributing area ars the apex fd indicates the flow depth scaling law as suggested by leopold and maddock 1953 1 h r s f d a a r s b while the hgm fa and gfim fa methods make use of a relation that expresses the cross sectional flow area ω rs as a function of the contributing area ars flow area scaling laws fa as suggested by leopold and maddock 1953 2 ω r s c a r s d consequently the flow depth above riverbed h r s f a is indirectly estimated by a flow depth flow area relationship fdfa 3 h r s f a f d f a ω r s calibration of parameters a b c and d of the scaling laws in eqs 1 and 2 is described later in section 2 2 afterwards availing of the information contained in the flow direction layer we assign to each grid cell i j the flow depth above riverbed hrs obtained by eq 1 or eq 3 in the nearest stream cell r s hydrologically connected to i j 4 h i j f d h r s f d 5 h i j f a h r s f a eqs 1 and 2 are based on the hydraulic geometry concepts developed by leopold and maddock 1953 as they allow to approximately determine stream channel characteristics as functions of a morphological feature namely the upslope contributing area while the main advantage of these scaling laws relies in their straightforward implementation in dem based routines it is important to underline that these relations are not able to describe hydraulic processes as traditional modelling techniques do such as the effects induced by the presence of artificial infrastructures along the stream sudden changes in channel geometry riverbed slope or roughness however despite its simplicity flow depth scaling law fd in eq 1 relating flow depth and contributing area has been proven promising and partially able to reproduce some physical phenomena manfreda et al 2014 samela et al 2017 nardi et al 2019 tavares da costa et al 2020 in addition as discussed in the introduction we were motivated to also investigate the feasibility and performances of methods based on flow area scaling laws fa relating cross sectional flow area and contributing area indeed while the behaviour of the flow depth is subject to great uncertainty when moving from upstream to downstream along the same river especially when the bank full stage is exceeded or in highly irregular cross sections the flow area is expected to regularly increase as the drainage area increases so in principle one should prefer fa approaches such behaviour was also confirmed through numerical simulations of flow propagation on synthetical catchments with constant and varying cross sections along the river see appendix for details supporting the expected advantages of flow area scaling laws fa as opposed to flow depth scaling laws fd as a practical way to the estimation of the flow depth flow area fdfa relationship between hrs and ω rs in eq 3 an automatic procedure based on the bisection method was also developed namely this procedure is aimed to calculate a flow depth hrs associated with the flow area ω rs obtained through eq 2 in any specific river cross section of interest given a cross section profile a flow depth hrs is iteratively assigned until its corresponding flow area value i e the cross section area below hrs see the filled shape in fig 1 a calculated through numerical integration equals the flow area ω rs the accuracy of the estimated flow depth h r s f a is greatly influenced by the resolution of the dem utilized for the extraction of the cross section shape the choice of the optimal resolution of the dem to be used in the application of eq 3 represents a crucial step of the process this is because dem s resolution affect the estimation of flow area associated with a given depth low resolution dems which are free available are expected to lead to biased flow area in this study we carried out a visual comparison between river cross sections extracted from dtms with different resolution while the river channel geometry was correctly represented using the 1 m and 2 m resolution dtms in sardinia and in sicily respectively 10 m resolution dtms provided unreliable results in both cases once the stream network is obtained through the initial terrain analysis as described at the beginning of this section the automatic procedure used to determine the flow depth h r s f a is applied to the selectd river cross sections extracted from the dem to guarantee gradual variations of channel geometry along the river a reasonable spacing between the cross sections must be adopted in our application a maximum distance of 20 meter between consecutive cross sections was considered appropriate in the supplementary materials the location of considered cross sections for one of the case study basins is depicted as an example figure s2 while flow depths h i j f d and h i j f a assessed through eqs 1 5 are directly employed in hgm fd and hgm fa as a flood descriptor for detecting the flood prone areas in a river basin of interest gfim fd and gfim fa make use of the geomorphic flood index gfifd samela et al 2017 and a variation of this composite index hereafter named gfifa 6 g f i i j f d ln h i j f d h i j 7 g f i i j f a ln h i j f a h i j both indices g f i i j f d and g f i i j f a are defined through the ratio of two terms the flow depth h i j f d or h i j f a and the elevation difference hij between the dem elevation zij in the cell i j and dem elevation zrs in the nearest river cell r s hydrologically connected to i j according to the path given by the d8 flow algorithm 8 h i j z i j z r s it is worth noticing that the term hij can also be seen as an indirect measure of the distance between a specified cell and the source of flood hazard that is the watercourse upstream cells located far away from the river centreline are generally characterised by high hij and low gfi values while moving closer to the stream it is expected that hij decreases and consequently gfi increases according to eqs 6 and 7 indicating a greater exposure to flood hazard 2 2 calibration of the geomorphic scaling laws the parameters of eqs 1 and 2 have been calibrated by carrying out a regression analysis on data collected in 56 river basins in sardinia for each basin outlet the river cross section was extracted from a 1 m resolution dtm derived from lidar surveys the upslope contributing area was calculated and the flood discharges associated with return periods of 50 200 500 years were indirectly estimated using regional idf curves and the rational method formula kuichling 1889 hydraulic modelling with hec ras was then performed to calculate flow depth and flow area values for calibration for each cross section one dimensional steady flow hydraulic simulations were carried out under the hypothesis of uniform flow conditions parameters of scaling laws in eqs 1 and 2 with associated return period were obtained by linear regression in log log space of flow depth or flow area versus contributing area see fig 2 a and b under the hypothesis of climatological and hydrological similarities of the two islands sicily and sardinia it has been here assumed that the parameters calibrated in sardinia could be applied also in sicily this hypothesis of transferability was verified by exploiting gauge data recorded in sicily and stored in the italian institute for environmental protection and research database http www bio isprambiente it annalipdf historical streamflow observations at 42 gauging stations were employed to carry out a linear regression in log log space of the highest flow depth recorded in each station and the corresponding contributing area value see fig 2c the constant and the exponent parameters derived from the regression model are very close to the values of the relationships valid for the sardinian river basins i e for 500 years of return period a 0 84 and b 0 30 in sardinia while a 0 87 and b 0 29 in sicily therefore the hypothesis of parameters transferability was considered acceptable by authors 2 3 floodplain delineation the four approaches for the identification of flood prone areas described in previous section were implemented in a python routine following the workflow presented by samela et al 2018 and nardi et al 2019 hgm fd and hgm fa methods make direct use of the two raster grids containing h i j f d and h i j f a flow depth values which represent the flood descriptors used to define the floodplain extent respectively in both methods cells i j where flow depth value h i j f d or h i j f a exceeds or equals the corresponding elevation difference hij identify areas exposed to flood hazard in the resulting floodplain layer conversely flood prone areas delineation in the gfim fd and gfim fa methods require additional steps and relies in a threshold binary classification based on g f i i j f d and g f i i j f a flood descriptors respectively the first step in the gfim fd and gfim fa methods is thus the setting of an optimal threshold on gfifd and gfifa flood descriptors to generate the flood prone area maps that best reproduce the government agency derived flood hazard map used as a benchmark to explore the entire range of possible values both flood descriptors have been rescaled to vary between 1 and 1 the optimal threshold of each index has been calibrated over a limited area of the river basin of interest namely larger than 2 of the total drainage area as suggested by samela et al 2017 since any choice of threshold defines a unique binary flood prone area extent the optimal threshold can be obtained by maximizing specific objective functions that evaluate the degree and matching accuracy of cells labelled as flooded or not with the corresponding cells of the benchmark map the selected objective functions are thus based on 2 2 contingency matrix containing the number of raster cells classified as true positive tp false negative fn false positive fp and true negative tn see table 1 for identifying the optimal thresholds of the gfifd and gfifa the critical success index csi bates and de roo 2000 aronica et al 2002 the measure of fit index mof pappenberger et al 2007 and the true skill statistic tss peirce 1884 have been initially considered and individually used as objective functions to be maximized 9 c s i t p t p f n f p 10 m o f t p f n t p f n f p 11 t s s t p t p f n f p t n f p the csi and the tss vary between 0 and 1 while the mof ranges from 1 to 1 for each index the maximum value is reached when the generated flood map perfectly matches the benchmark while the minimum indicates that there is no agreement with the reference map since this process requires the availability of an official flood hazard map over a portion of the river basin of interest to calibrate an optimal threshold it is expected that the gfim fd and gfim fa are able to provide better mapping performance than the hgm fd and hgm fa which do not apply any binary classification technique 2 4 performance assessment to evaluate the performance of the four considered approaches the csi described by eq 9 was selected together with four metrics provided in the following equations namely the true positive rate tpr the false positive rate fpr the false discovery rate fdr and the error bias i 12 t p r t p t p f n 13 f p r f p f p t n 14 f d r f p t p f p 15 e f p f n the tpr also known as the hit rate represents the probability of correctly detecting cells subject to flood hazard it is helpful for quantifying the tendency to underestimate flood prone areas but it does not provide any information about overestimation conversely the fpr and the fdr assess this type of deficiency as they define respectively the probability of incorrectly classifying cells as flooded and the proportion of the overestimation over the total number of instances labelled as positive these three indices assume values ranging from 0 to 1 the error bias given by the ratio between false positive and false negative instances indicates whether the model presents no bias e 1 or is affected by a general tendency either towards overprediction e 1 or underprediction 0 e 1 overall the critical success index can be considered as the most informative metric since it is able to provide a global measure of the mapping performance in view of the fact that it takes into account both effects of overestimation and underestimation regarding the two methods based on the binary classification gfim fd and gfim fa it is important to remark that the choice of the objective function used to calibrate the optimal threshold for each river basin can significantly affect the resulting flood map among the three indices initially selected for calibration the critical success index csi has been considered the most balanced in penalising overestimation and underestimation hence the most adequate objective function to be maximized in fact the true skill statistic tss tends to favour overprediction as it does not adequately penalise the false alarm instances through the false positive rate pappenberger et al 2007 this inefficiency could be handled by selecting a calibration area with balanced binary classes flooded areas and not flooded areas also the measure of fit mof by additionally penalising underprediction leads to lower optimal threshold values which are subsequently responsible for a tendency towards overestimation of flooded areas see table s1 in the supplementary materials for further details given these considerations results for the methods relying on binary classification are referred to the floodplain maps obtained by applying the optimal thresholds derived through the maximization of the critical success index 3 study area and data source the analysis was conducted as anticipated in the two largest islands in the mediterranean sea sicily and sardinia located in southern italy the two islands show similar hydrological and climatological features typical of mediterranean areas the climate is characterised by a marked seasonality with hot dry summers and mild wet winters precipitations are mainly concentrated during autumn and winter months with strong interannual variations which are occasionally responsible for arid multi year periods and droughts in sardinia the average annual precipitation is about 650 mm ranging between 500 mm in flat regions and 1160 mm observed in the mountainous areas mascaro et al 2018 the average annual rainfall in sicily is about 715 mm ranging between 400 and 1300 mm from south eastern to north eastern regions respectively caracciolo et al 2018 the four considered methods were tested on three of the largest river basins in sardinia namely tirso coghinas and cedrino and three river basins located in sicily that are simeto belice and eleuterio see fig 3 whose main characteristics have been summarised in table 2 these six catchments were chosen with the purpose of considering a wide range of morphological and hydrological characteristics e g drainage area stream order average annual rainfall as well as including the case of rivers affected by the presence of hydraulic infrastructures a simple morphological analysis of the river basins along with the computation of the flood descriptors can be easily performed using the information contained in dems in this work we utilized freely available dtms derived from lidar surveys with 1 m resolution in sardinia and 2 m resolution in sicily respectively in addition 10 m spatial resolution dtms were employed to investigate how floodplain mapping performance vary with resolution it is important to remark that 1 m resolution dtms coverage in sardinia is only extended to the nearest areas along the major rivers in the island and coastal areas while the 10 m resolution dtms are available on the entire regions as a benchmark we used the official flood hazard maps developed in the context of the piano stralcio delle fasce fluviali psff and the piano per l assetto idrogeologico pai by the river basin authorities rbas operating in sardinia and sicily according to the european flood directive 2007 60 ec these two documents provide the necessary information to develop guidelines and measures leading to a safer and more sustainable urban development the psff maps available in sardinia were derived for return periods of 50 200 and 500 years while the pai flood hazard maps available in sicily are associated with return periods of 50 100 and 300 years for the identification of flood prone areas the rbas followed traditional floodplain mapping procedures involving high precision topographic data collection hydrologic analysis and hydraulic modelling in this study the two maps with the highest return periods have been taken as a benchmark to assess the performance of the proposed approaches namely 500 years for sardinia and 300 years for sicily again for sake of clarity due to the limited availability of 1 m resolution dtms in sardinia performance at this resolution were evaluated considering only the reference flood prone areas inside the lidar data coverage 4 results the four proposed geomorphic approaches were applied to delineate the flood prone area extents for each river basin in the study area using high resolution dtms derived from lidar surveys 1 m and 2 m resolution as the main input to explore the variability of the mapping performance at a coarser resolution the hgm fd and the gfim fd have also been implemented making use of 10 m resolution dtms this test was not conducted for the hgm fa and the gfim fa which apply the flow area scaling laws in eq 2 as the river cross section shape extracted from the 10 m resolution dtms have been proved inaccurate in representing the channel geometry especially in complex topography after completing the calibration phase performances of the four considered approaches were evaluated in terms of critical success index csi true positive rate tpr and false discovery rate fdr see eqs 12 15 in section 2 4 evaluations of such metrics on the 1 m and 2 m resolution dtms in each of the six selected basins are displayed in fig 4 a from where some conclusions can be drawn i hydrogeomorphic methods hgm fd and hgm fa are affected by higher dispersion of both the critical success index csi and the true positive rate tpr compared to the gfim fd and gfim fa approaches ii gfim fd and gfim fa approaches performs better in terms of true positive rate tpr but at the expense of larger false discovery rate fdr with respect to hgm fd and hgm fa suggesting an overestimation tendency of floodplain extension for the former approaches for each method and each metric the average values over the six investigated basins are also plotted in fig 4a with larger symbols and reported in the upper part of table 3 hereafter indicated with overbars as c s i t p r f p r f d r and e all the implemented approaches provided moderate to high average of critical success index and true positive rate with c s i values ranging from 0 55 to 0 66 and values of t p r varying between 0 59 and 0 89 and moderate to low f d r values ranging from 0 33 to 0 08 below we will draw some considerations on the average performances of the two scaling laws fd and fa and the two flood descriptors employed in hgm and gfim respectively the hgm fd and gfim fd both employing flow depth scaling law fd are characterized by higher critical success index c s i 0 65 compared to hgm fa and gfim fa making use of the flow area scaling law fa approaches c s i 0 58 similar conclusion applies to the true positive rate t p r 0 80 for fd and average t p r 0 74 for fa whilst averages of the false discovery rate and the error bias of the fd based approaches f d r 0 19 e 7 3 are slightly lower compared with fa based approaches f d r 0 20 e 9 0 in five river basins out of six the method based on fd scaling laws outperformed the others in terms of critical success index in half of the cases it was the gfim fd and in one third of the selected catchments the best performance was attributed to the hgm fd in the remaining river basin the gfim fa obtained the highest value of csi see table s2 in supplementary materials results described above show that the approaches employing fd scaling laws are preferable to fa based approaches in fact parameterization of flow depth scaling laws in eq 1 not only has been proved more efficient by leading to better outcomes in most cases but it is also easier and faster to be implemented in a gis environment looking at the relative performances of the two adopted flood descriptors we can observe from table 3 that the gfim fd and gfim fa display greater true positive rate values t p r 0 89 than the hgm fd and hgm fa t p r 0 64 but at the same time they exhibit higher false discovery rate f d r 0 30 for gfim vs f d r 0 10 for hgm this behaviour is explained by the results in error bias values indicating that both methods based on binary classification overestimate flood prone areas e 15 9 for gfim vs e 0 4 for hgm as expected the hgm fd and hgm fa tend to be less performant in terms of critical success index c s i 0 59 than the gfim fd and gfim fa c s i 0 64 since the optimal thresholds of the two indices are calibrated on limited portions of the study area by taking advantage of benchmark maps derived from hydraulic modelling although it allows to achieve better outcomes the fact that binary classification methods depend on the availability of existing flood hazard maps represents a limitation to their applicability analysing in a deeper detail the performances of the gfim approaches we observe that gfim fd shows lower average fdr and error bias f d r and e equal to 0 27 and 14 4 respectively than gfim fa f d r 0 33 e 17 7 but their average true positive rate tpr values do not significantly differ both close to 0 89 in other words the gfim fa tends to overestimate flood prone areas more than the gfim fd does and this is reflected also on the average critical success index which is in fact higher for the gfim fd than the gfim fa c s i equal to 0 66 and 0 62 respectively looking in details at performances of the hgm approaches we observe that hgm fa presents a slightly lower average fdr than hgm fd f d r 0 08 and 0 11 respectively and the same tendency applies to the average error bias e equal to 0 2 and 0 6 respectively moreover the hgm fd is on average characterized by greater values of true positive rate and critical success index compared to the hgm fa t p r 0 70 and c s i 0 63 as opposed to 0 59 and 0 55 revealing that the hgm fa is the approach that suffers the most from underestimation 5 discussion although hgm fa seems to be the least accurate out of the four analysed geomorphic methods in reproducing the flood hazard areas identified in the benchmark maps it still provides comparable results as its average critical success index is only 10 lower than the highest c s i value obtained from the other approaches the peculiarity of hgm fa approach consists in the use of the flow area scaling laws fa in eq 2 relating cross sectional flow area to drainage area which involves the extraction of the stream cross section for the estimation of flow depth values through the fdfa relationship in eq 3 this process allows to take greater account of river morphology and channel shape changes the gfim fa is also based on the flow area scaling laws fa in eq 2 but the flow depth values provided by the fdfa relationship in eq 3 are used to formulate a composite index the gfifa in eq 7 utilized as a flood descriptor in this latter case the floodplain delineation is obtained through a threshold binary classification that slightly enhances the performance although causing overestimation the gfim fd taking advantage as well of the binary classification technique but applying the flow depth scaling law in eq 1 obtained the highest average critical success index among the four compared methods nevertheless the hgm fd could be considered the most promising in identifying the flood prone areas since it offers the best compromise between accuracy and computational costs using high resolution dems as the main input hgm fd is the simplest method among the four considered approaches since the flow depth is obtained with eq 1 and directly used as a flood descriptor this method does not require any extraction of cross sections along the stream nor the availability of flood hazard maps for threshold calibration purposes as it is the case of methods applying binary classification examples of floodplain delineation obtained with the four methods along with the flood inundated areas of the benchmark map are depicted in fig 5 best case and fig 6 worst case respectively while maps for the remaining four rivers have been reported in supplementary materials figure s3 s6 the visual comparison in fig 5 shows that all methods produced reliable flood prone area extents for the coghinas river basin interestingly three of the four methods provided their best performance on this catchment with critical success index ranging between 0 75 and 0 79 in accordance with previous observations the hgm fa fig 5b tends to slightly underestimate floodplain extensions e 1 while the gfim fd fig 5c and gfim fa fig 5d are affected by a tendency towards overestimation e 1 the hgm fd presents no bias e 1 although stream morphology is taken into greater consideration in the methods applying flow area scaling laws in eq 2 rather than those based on fd scaling laws in eq 1 a paradigmatic case is offered by the lake casteldoria originated by the casteldoria dam erroneously identified as exposed to flood hazard by both methods hgm fa and gfim fa see insets in fig 5b and d this drawback is due to the very steep flow depth flow area relationship in eq 3 corresponding to the narrow shape of the channel at the first cross section downstream the dam as a result the high flow depth corresponding to the estimated flow area exceeded the difference in elevation between the upstream cells included into the reservoir and the stream cell belonging to the cross section causing the false positive instances in the hgm fd and gfim fd this circumstance does not occur as the flow depth is exclusively dependent on the drainage area therefore any effect induced by changes in channel geometry is completely neglected a further investigation of this specific case also revealed a significant underestimation of the flow depth provided by fd scaling laws in eq 1 but since this happens in a deep canyon even a large error in flow depth estimation leads to the same mapping outcome by fd based approaches conversely the erroneous mapping resulting from the fa based approaches seems to be mainly related to an overestimation of the flow area due to the fact that the flow area scaling laws in eq 2 were mainly calibrated on wide cross sections and gentle riverbed profiles fig 6 displays a sample of the flood prone areas identified in the alto tirso river basin where the hgm fd and hgm fa exhibited their poorest performance with critical success index of 0 49 and 0 39 respectively both methods especially the hgm fa tend to strongly underestimate flooded areas e 1 whilst the two approaches based on binary classification suffer once again from overestimation e 1 regarding the sensitivity of the approaches to varying input resolution the outcomes of the hgm fd and gfim fd tested with the 10 m resolution dtms do not significantly differ from the results obtained by the 1 m and 2 m resolution dtms in terms of average success index the percentage difference is below 2 with the hgm fd performing slightly better at coarser resolution in opposition to the gfim fd which is marginally less performant also the metrics dispersion are extremely similar see fig 4b in four river basins out of six the gfim fd produced the highest value of csi nevertheless the average critical success index for both methods is equal to 0 65 the general behaviour identified at finer resolution is maintained the hgm fd tends to underestimate flooded areas e 1 while the gfim fd is still characterised by overestimation bias e 1 overall in this investigation the two methods implementing the flow depth scaling laws did not show significant sensitivity to the dtms resolution change from 1 m and 2 m to 10 m at the same time it is worth mentioning that for fa methods the analyses were not even possible with the 10 m resolution dtms because the cross sectional area estimation turns out to be unreliable only high resolution dem as the ones provided by lidar allow to correctly estimate the cross sectional area and take into account the presence of levees roads and bridges embankments and in general any artificial or natural changes in elevation that are impossible to detect with such accuracy at coarser resolutions considering that fa approach involves terrain analysis and utilizes as a main input the topographic information contained in dtms for its application it would be reasonable to utilize the highest resolution terrain data available 6 conclusions the present study investigated the floodplain mapping performance of four geomorphic approaches based on the coupling of two flood descriptors hgm and gfim and two simple power laws flow depth fd and flow area fa scaling laws relating flow depth and cross sectional flow area to upstream contributing area six river basins located in southern italy were selected as a case study and their flood prone areas were estimated with the four approaches using high resolution dems as the main input and finally compared with official flood hazard benchmark maps derived from hydraulic modelling overall the implemented methods provided average critical success index varying between 0 55 and 0 66 average true positive rate ranging from 0 59 to 0 89 and average false discovery rate ranging between 0 08 and 0 33 the gfim fd and gfim fa based on the threshold binary classification of the gfi to delineate floodplain extents displayed a tendency towards overestimation whilst methods directly employing flood depth as flood descriptor suffer from underestimation especially the hgm fa the two methods employing the relationship between flow depth and contributing area flow depth scaling laws fd eq 1 performed better than the two relating flow area to drainage area flow area scaling laws fa eq 2 despite not being able to take as much into consideration the stream morphology in fact the highest average critical success index was obtained by gfim fd immediately followed by the hgm fd confirming flow depth as a valid flood descriptor to be used in geomorphic approaches it is important to underline that the methodologies proposed in this work being based on simple power laws and taking as the main input the information contained in dtms are not expected to reproduce exactly the floodplain maps obtained through conventional procedures involving hydrologic and hydraulic modelling however they may represent useful tools for approximately delineating flood prone areas in ungauged basins or in data scarce regions where standard flood hazard maps are unavailable with the increasing availability of high resolution topographic data further investigations at regional scale should be carried out to better explore the potentialities of these geomorphic methods incorporating these dtm based approaches into machine learning workflows and also to test the transferability of the scaling laws parameters credit authorship contribution statement claudia deiana methodology software data curation writing original draft roberto deidda visualization investigation writing review editing funding acquisition francesco viola methodology visualization investigation writing review editing declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests roberto deidda reports financial support was provided by european union acknowledgments the authors acknowledge and thank the two reviewer prof salvatore manfreda and the anonymous one for their meticulous work and the precious suggestions this study was carried out within the return extended partnership and received funding from the european union next generation eu national recovery and resilience plan nrrp mission 4 component 2 investment 1 3 d d 1243 2 8 2022 pe0000005 supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2023 104493 appendix b supplementary materials image application 1 appendix regarding the feasibility and performances of methods based on flow area scaling laws fa compared to flow depth scaling laws fd on an empirical basis we initially supposed that the former could potentially have a greater capability of approximately representing what occurs during critical flood events in fact while the flow area is expected to tendentially increase moving from upstream to downstream cross sections of the same river hence as the drainage area increases the behaviour of the flow depth is subject to greater uncertainty especially when the bank full stage is exceeded we formulated this hypothesis on the basis of a synthetic case conducted on a rectangular river basin with discharge increasing linearly with contributing area hydraulic simulations executed with hec ras in one dimensional steady flow under uniform conditions allowed to estimate flow depth and flow area values at the river cross sections the stream channel geometry has been approximated through a triangular shape and two different configurations were tested the former assumed constant riverbanks slope for all the cross sections along the stream the latter considered a progressive decrease in riverbanks slope moving from upstream to downstream cross sections trying to mimic to the natural downstream changes in channel geometry while in the first configuration the flow depth increases downstream with increasing contributing area in the second case it can be observed that after an initial increase the water depth tends to remain constant or slightly decrease see fig 7 a instead the flow area shows an increasing tendency in both configurations see fig 7b which led to the assumptions explained above in addition to these empirically based considerations the fact that flow area has not been employed before as a proxy of a flood descriptor in automatic flood prone area detection techniques has contributed to arouse great interest in investigating the potentialities of eq 3 for this scope 
11,recent advances in remote sensing technologies along with the increased availability of topographic data have lately encouraged the development of automatic dem digital elevation model based procedures for floodplain delineation geomorphic methods establishing relationships between flood descriptors and morphologic catchment characteristics appear particularly suitable to be implemented within a gis algorithm in the present work four simplified geomorphic approaches based on flow depth scaling laws fd or flow cross sectional area scaling laws fa with contributing area and two methods employing two different flood descriptors hydro geomorphic method hgm and geomorphic flood index method gfim have been applied for the preliminary evaluation of floodplain extent using high resolution dems i e lidar at 1 and 2 m resolution as the main input taking as a case study six of the largest basins located in southern italy the performances of these methods were evaluated and critically compared using government agency derived flood hazard maps as benchmarks results show that the adoption of fd especially when combined with morphology to formulate the gfim allows to efficiently predict the flood prone areas with low computational costs at the same time performances of the flood mapping procedures based on flow area scaling laws although in principle more appealing seem to be slightly lower overall the proposed approaches can be applied for rough mapping of floodplains in ungauged basins or in data scarce regions where standard flood hazard maps are unavailable keywords floodplain mapping flood descriptors scaling laws digital elevation model 1 introduction identification of flood prone areas has become an urgent challenge in flood risk management representing a key task to reduce flood damages and minimise loss of life during extreme events according to the emergency events database em dat maintained by the centre for research on the epidemiology of disasters cred in the 20 year period between 2000 and 2019 floods have been the most frequently occurring type of natural disaster accounting for 44 of total events affecting 1 6 billion people worldwide and leading to approximately us 651 billion in economic losses cred 2020 furthermore floods intensity and frequency are expected to increase due to climate change over the next decades scientific evidence indicates that these trends are partially attributable to the global temperature rise which according to clausius clapeyron relation leads to a greater moisture holding capacity of the atmosphere thus resulting in an increase of rainfall extremes fowler et al 2021 the severe flooding observed in western germany during july 2021 lehmkuhl et al 2022 which caused nearly 200 fatalities suggests that climate disruption is already revealing its impact on weather patterns making the implementation of effective flood risk mitigation strategies one of the most pressing needs of our time flood inundation maps represent useful tools helping urban planners and stakeholders to identify which areas could potentially be affected by these natural phenomena their effectiveness has been widely recognised to the point that among eu european union member states it has become mandatory to map flood extent since directive 2007 60 ec has entered into force while in the united states such maps are provided by the federal emergency management agency fema to support the national flood insurance program traditional floodplain mapping techniques entail significant data collection as they usually involve both hydrologic and hydraulic analyses when the stream gauge network is sparse and historical rainfall series are the only type of accessible data over a given region hydrological modelling allows the assessment of hydrographs associated with specific return periods rainfall runoff models would normally receive as the main input a hyetograph based on the intensity duration frequency curve idf curve valid for the study area idf curves are typically obtained through complex procedures involving statistical analysis of long term historical rainfall observations deidda et al 2021 their update under the conditions of a changing climate is a modern challenge forestieri et al 2018 by simulating the physical processes involved in the transformation of rainfall into runoff hydrological models provide as output hydrographs of assigned return period which are then used as input of hydraulic models to simulate the flood propagation over complex domains their setup requires accurate topographic information on river features and artificial structures along the reach e g bridges culverts levees evaluation of surface roughness and the assignment of appropriate boundary conditions hydraulic simulations are also time consuming and computationally intensive other than being costly all in all conventional floodplain mapping approaches are difficult to apply especially in those regions where hydrological and morphological data are scarce in recent years the increasing availability of high resolution dems has encouraged the development of alternative cost effective procedures based on river basin geomorphic features to perform preliminary floodplain delineation in ungauged areas these methods rely on the assumption that floodplains are the end product of the accumulated effects of flood events occurred over time and are therefore characterized by unique geomorphic and hydrologic properties that make them distinguishable from adjacent hillslopes nardi et al 2006 various authors successfully experimented hydrogeomorphic approaches based on the application of hydraulic geometry relations leopold and maddock 1953 bhowmik 1984 highlighting their potential capabilities in flood prone areas detection the term hydraulic geometry was first introduced by leopold and maddock 1953 to describe those relationships between stream channel hydraulic characteristics and discharge at any river cross section subsequently bhowmik 1984 supposed that the concept of hydraulic geometry could also be applied to define floodplains characteristics and proved the existence of simple scaling laws relating floodplains hydraulic properties e g width flow area flow depth to the upstream contributing area such relationships have received increasing attention in recent investigations as they allow to easily estimate hydraulic status that conversely would normally be evaluated through hydraulic simulations and moreover they appear particularly suitable to be implemented within gis based procedures for example nardi et al 2006 2013 2019 proposed an algorithm that identifies floodplain extent by comparing river corridors terrain elevation with the absolute elevation of a variable flow depth estimated as a function of contributing area at each stream cell through a stream order averaged scaling law the scaling parameters were initially estimated using water depth values derived from manning equation in conjunction with giuh geomorphologic instantaneous unit hydrograph peak discharge rodríguez iturbe et al 1979 rodriguez iturbe 1993 while in a global scale application nardi et al 2019 proved that optimal parameterization obtained through a simple calibration performed with reference maps provides consistent results while being less computational demanding in a recent study annis et al 2022 investigated the influence of morphologic and climatic river basin characteristics on the parameters of the scaling law between flow depth and drainage area demonstrating that enhanced performances can be achieved considering parameterization for different ranges of slopes and average annual rainfall other researchers implemented linear binary classification procedures and assessed the performance of several classifiers in identifying areas exposed to flood hazard for example degiorgis et al 2012 applied a threshold binary classification technique employing different classifiers derived from single dem based morphological features this approach has been reapplied by manfreda et al 2014 to carry out a comparative analysis with the hydrogeomorphic algorithm nardi et al 2006 and the modified topographic index method manfreda et al 2011 in another work samela et al 2017 compared the performance of eleven classifiers applied at continental scale and investigated the transferability of the corresponding optimal thresholds with varying topography and calibration area extent according to the authors a calibration area at least equal to 2 of the total drainage area of interest allows to determine a threshold value close enough to the optimal one their results also showed that amongst all the tested flood descriptors the geomorphic flood index gfi appeared more transferrable than others in areas with varying topography providing the most reliable and accurate floodplain delineation the aforementioned studies have been carried out utilizing dems with grid resolution ranging from 30 m to 250 m which allow to rapidly produce inundation maps at large scale in a different effort zheng et al 2018 presented a new effective workflow combining the hand height above nearest drainage method rennó et al 2008 nobre et al 2016 with an automatic channel network extraction procedure passalacqua et al 2010 that avails of high resolution topographic data e g 3 m resolution dem without compromising computational efficiency to date similar applications of hydrogeomorphic methodologies employing information obtained from dems at very high resolution are still exiguous the present work aims to investigate the performance of four geomorphic approaches at the basin scale coupling estimations from two simple power laws relating upstream contributing area to cross sectional flow depth and flow area hereafter referred to as flow depth scaling laws fd and flow area scaling laws fa respectively and two mapping methods named hydro geomorphic method hgm and geomorphic flood index method gfim the flood prone areas in hgm methods are identified by comparing a variable flow depth computed along the reach to the relative elevation of those cells hydrologically connected to the stream following the algorithm described by nardi et al 2019 instead the gfim methods avail of the geomorphic flood index samela et al 2017 as a flood descriptor and utilize the threshold binary classification to discern between flooded or not flooded areas the hgm fd and the gfim fd methods take advantage of the straightforward relation between the flow depth and the drainage area flow depth scaling laws fd whilst the hgm fa and the gfim fa make use of the scaling law relating cross sectional flow area to contributing area flow area scaling laws fa while the implementation of floodplain mapping procedures taking advantage of the scaling relation between flow depth and contributing area flow depth scaling laws fd has already been experimented in other studies to our best knowledge flow area scaling laws fa relating cross sectional flow area to drainage area represent an element of novelty of this work that in our opinion deserve to be investigated indeed we should expect in principle a stronger dependence of the flow area rather than the flow depth on the contributing area since the flow depth is more affected by the river cross section shape as will be discussed in the appendix it is worth noticing that the application of hgm fa and the gfim fa methods requires the identification of a flow depth flow area relationship fdfa in each river cross section considered in the analysis or alternatively implies some additional steps which can be synthesized in the implementation of a root finding algorithm that allows to approximately estimate the flow depth associated with a flow area value in any given river cross section of known profile the considered floodplain mapping procedures were implemented in a gis environment using as primary input the information extracted from high resolution dems derived from lidar surveys at 1 m and 2 m resolution in sardinia and sicily italy respectively official flood hazard maps provided by regional agiencies were used to calibrate the four approaches and then as a benchmark to evaluate the performances on three major river basins in sicily and three major rivers in sardinia applying standard indices based on contingency tables and commonly employed for forecast verification this paper is organised as follows section 2 describes the methodology and the implementation of the four approaches with details on flood descriptors and the geomorphic power laws the study area and dataset including terrain data and official flood hazard maps are presented in section 3 in section 4 outcomes form the application of the four approaches are illustrated and then discussed in section 5 along with their strengths and limitations finally section 6 summarizes the main results and suggestions for further studies a flowchart of the four implemented methods used to obtain floodplain mapping based on fd or fa is reported in the supplementary material figure s1 2 methodology 2 1 flood descriptors and geomorphic scaling laws in this section the main assumptions of the four considered geomorphic approaches to map expected flood prone areas in the river basins of interest are introduced and described the core of all the methods relies on the definition of flood descriptors based on an empirically estimated water level flood descriptors can be considered as potential indicators of the susceptibility of an area to be flooded starting from the topographic data contained in dems they can be calculated through proper procedures and then represented in a gridded layer the four considered approaches require a preliminary terrain analysis to assign to each grid cell i j of the dem a flow direction dij and a corresponding flow accumulation fij and subsequently to obtain the river network binary raster in this work these operations were performed with the r watershed module of the grass gis jasiewicz and metz 2011 using the d8 single direction flow algorithm o callaghan and mark 1984 stream network is identified by flagging cells r s with a flow accumulation frs exceeding a constant predefined threshold also the drainage area ars at any stream cell r s can be immediately calculated as the product between the local flow accumulation frs and the cell size once flow accumulation frs and the drainage area ars layers are extracted from the dem as described above we assign to each river network cell r s a variable flood stage hrs above the thalweg derived through simple geomorphic scaling laws as defined below the hgm fd and the gfim fd methods make use of a relation that expresses the flow depth above riverbed h r s f d as a function of the contributing area ars the apex fd indicates the flow depth scaling law as suggested by leopold and maddock 1953 1 h r s f d a a r s b while the hgm fa and gfim fa methods make use of a relation that expresses the cross sectional flow area ω rs as a function of the contributing area ars flow area scaling laws fa as suggested by leopold and maddock 1953 2 ω r s c a r s d consequently the flow depth above riverbed h r s f a is indirectly estimated by a flow depth flow area relationship fdfa 3 h r s f a f d f a ω r s calibration of parameters a b c and d of the scaling laws in eqs 1 and 2 is described later in section 2 2 afterwards availing of the information contained in the flow direction layer we assign to each grid cell i j the flow depth above riverbed hrs obtained by eq 1 or eq 3 in the nearest stream cell r s hydrologically connected to i j 4 h i j f d h r s f d 5 h i j f a h r s f a eqs 1 and 2 are based on the hydraulic geometry concepts developed by leopold and maddock 1953 as they allow to approximately determine stream channel characteristics as functions of a morphological feature namely the upslope contributing area while the main advantage of these scaling laws relies in their straightforward implementation in dem based routines it is important to underline that these relations are not able to describe hydraulic processes as traditional modelling techniques do such as the effects induced by the presence of artificial infrastructures along the stream sudden changes in channel geometry riverbed slope or roughness however despite its simplicity flow depth scaling law fd in eq 1 relating flow depth and contributing area has been proven promising and partially able to reproduce some physical phenomena manfreda et al 2014 samela et al 2017 nardi et al 2019 tavares da costa et al 2020 in addition as discussed in the introduction we were motivated to also investigate the feasibility and performances of methods based on flow area scaling laws fa relating cross sectional flow area and contributing area indeed while the behaviour of the flow depth is subject to great uncertainty when moving from upstream to downstream along the same river especially when the bank full stage is exceeded or in highly irregular cross sections the flow area is expected to regularly increase as the drainage area increases so in principle one should prefer fa approaches such behaviour was also confirmed through numerical simulations of flow propagation on synthetical catchments with constant and varying cross sections along the river see appendix for details supporting the expected advantages of flow area scaling laws fa as opposed to flow depth scaling laws fd as a practical way to the estimation of the flow depth flow area fdfa relationship between hrs and ω rs in eq 3 an automatic procedure based on the bisection method was also developed namely this procedure is aimed to calculate a flow depth hrs associated with the flow area ω rs obtained through eq 2 in any specific river cross section of interest given a cross section profile a flow depth hrs is iteratively assigned until its corresponding flow area value i e the cross section area below hrs see the filled shape in fig 1 a calculated through numerical integration equals the flow area ω rs the accuracy of the estimated flow depth h r s f a is greatly influenced by the resolution of the dem utilized for the extraction of the cross section shape the choice of the optimal resolution of the dem to be used in the application of eq 3 represents a crucial step of the process this is because dem s resolution affect the estimation of flow area associated with a given depth low resolution dems which are free available are expected to lead to biased flow area in this study we carried out a visual comparison between river cross sections extracted from dtms with different resolution while the river channel geometry was correctly represented using the 1 m and 2 m resolution dtms in sardinia and in sicily respectively 10 m resolution dtms provided unreliable results in both cases once the stream network is obtained through the initial terrain analysis as described at the beginning of this section the automatic procedure used to determine the flow depth h r s f a is applied to the selectd river cross sections extracted from the dem to guarantee gradual variations of channel geometry along the river a reasonable spacing between the cross sections must be adopted in our application a maximum distance of 20 meter between consecutive cross sections was considered appropriate in the supplementary materials the location of considered cross sections for one of the case study basins is depicted as an example figure s2 while flow depths h i j f d and h i j f a assessed through eqs 1 5 are directly employed in hgm fd and hgm fa as a flood descriptor for detecting the flood prone areas in a river basin of interest gfim fd and gfim fa make use of the geomorphic flood index gfifd samela et al 2017 and a variation of this composite index hereafter named gfifa 6 g f i i j f d ln h i j f d h i j 7 g f i i j f a ln h i j f a h i j both indices g f i i j f d and g f i i j f a are defined through the ratio of two terms the flow depth h i j f d or h i j f a and the elevation difference hij between the dem elevation zij in the cell i j and dem elevation zrs in the nearest river cell r s hydrologically connected to i j according to the path given by the d8 flow algorithm 8 h i j z i j z r s it is worth noticing that the term hij can also be seen as an indirect measure of the distance between a specified cell and the source of flood hazard that is the watercourse upstream cells located far away from the river centreline are generally characterised by high hij and low gfi values while moving closer to the stream it is expected that hij decreases and consequently gfi increases according to eqs 6 and 7 indicating a greater exposure to flood hazard 2 2 calibration of the geomorphic scaling laws the parameters of eqs 1 and 2 have been calibrated by carrying out a regression analysis on data collected in 56 river basins in sardinia for each basin outlet the river cross section was extracted from a 1 m resolution dtm derived from lidar surveys the upslope contributing area was calculated and the flood discharges associated with return periods of 50 200 500 years were indirectly estimated using regional idf curves and the rational method formula kuichling 1889 hydraulic modelling with hec ras was then performed to calculate flow depth and flow area values for calibration for each cross section one dimensional steady flow hydraulic simulations were carried out under the hypothesis of uniform flow conditions parameters of scaling laws in eqs 1 and 2 with associated return period were obtained by linear regression in log log space of flow depth or flow area versus contributing area see fig 2 a and b under the hypothesis of climatological and hydrological similarities of the two islands sicily and sardinia it has been here assumed that the parameters calibrated in sardinia could be applied also in sicily this hypothesis of transferability was verified by exploiting gauge data recorded in sicily and stored in the italian institute for environmental protection and research database http www bio isprambiente it annalipdf historical streamflow observations at 42 gauging stations were employed to carry out a linear regression in log log space of the highest flow depth recorded in each station and the corresponding contributing area value see fig 2c the constant and the exponent parameters derived from the regression model are very close to the values of the relationships valid for the sardinian river basins i e for 500 years of return period a 0 84 and b 0 30 in sardinia while a 0 87 and b 0 29 in sicily therefore the hypothesis of parameters transferability was considered acceptable by authors 2 3 floodplain delineation the four approaches for the identification of flood prone areas described in previous section were implemented in a python routine following the workflow presented by samela et al 2018 and nardi et al 2019 hgm fd and hgm fa methods make direct use of the two raster grids containing h i j f d and h i j f a flow depth values which represent the flood descriptors used to define the floodplain extent respectively in both methods cells i j where flow depth value h i j f d or h i j f a exceeds or equals the corresponding elevation difference hij identify areas exposed to flood hazard in the resulting floodplain layer conversely flood prone areas delineation in the gfim fd and gfim fa methods require additional steps and relies in a threshold binary classification based on g f i i j f d and g f i i j f a flood descriptors respectively the first step in the gfim fd and gfim fa methods is thus the setting of an optimal threshold on gfifd and gfifa flood descriptors to generate the flood prone area maps that best reproduce the government agency derived flood hazard map used as a benchmark to explore the entire range of possible values both flood descriptors have been rescaled to vary between 1 and 1 the optimal threshold of each index has been calibrated over a limited area of the river basin of interest namely larger than 2 of the total drainage area as suggested by samela et al 2017 since any choice of threshold defines a unique binary flood prone area extent the optimal threshold can be obtained by maximizing specific objective functions that evaluate the degree and matching accuracy of cells labelled as flooded or not with the corresponding cells of the benchmark map the selected objective functions are thus based on 2 2 contingency matrix containing the number of raster cells classified as true positive tp false negative fn false positive fp and true negative tn see table 1 for identifying the optimal thresholds of the gfifd and gfifa the critical success index csi bates and de roo 2000 aronica et al 2002 the measure of fit index mof pappenberger et al 2007 and the true skill statistic tss peirce 1884 have been initially considered and individually used as objective functions to be maximized 9 c s i t p t p f n f p 10 m o f t p f n t p f n f p 11 t s s t p t p f n f p t n f p the csi and the tss vary between 0 and 1 while the mof ranges from 1 to 1 for each index the maximum value is reached when the generated flood map perfectly matches the benchmark while the minimum indicates that there is no agreement with the reference map since this process requires the availability of an official flood hazard map over a portion of the river basin of interest to calibrate an optimal threshold it is expected that the gfim fd and gfim fa are able to provide better mapping performance than the hgm fd and hgm fa which do not apply any binary classification technique 2 4 performance assessment to evaluate the performance of the four considered approaches the csi described by eq 9 was selected together with four metrics provided in the following equations namely the true positive rate tpr the false positive rate fpr the false discovery rate fdr and the error bias i 12 t p r t p t p f n 13 f p r f p f p t n 14 f d r f p t p f p 15 e f p f n the tpr also known as the hit rate represents the probability of correctly detecting cells subject to flood hazard it is helpful for quantifying the tendency to underestimate flood prone areas but it does not provide any information about overestimation conversely the fpr and the fdr assess this type of deficiency as they define respectively the probability of incorrectly classifying cells as flooded and the proportion of the overestimation over the total number of instances labelled as positive these three indices assume values ranging from 0 to 1 the error bias given by the ratio between false positive and false negative instances indicates whether the model presents no bias e 1 or is affected by a general tendency either towards overprediction e 1 or underprediction 0 e 1 overall the critical success index can be considered as the most informative metric since it is able to provide a global measure of the mapping performance in view of the fact that it takes into account both effects of overestimation and underestimation regarding the two methods based on the binary classification gfim fd and gfim fa it is important to remark that the choice of the objective function used to calibrate the optimal threshold for each river basin can significantly affect the resulting flood map among the three indices initially selected for calibration the critical success index csi has been considered the most balanced in penalising overestimation and underestimation hence the most adequate objective function to be maximized in fact the true skill statistic tss tends to favour overprediction as it does not adequately penalise the false alarm instances through the false positive rate pappenberger et al 2007 this inefficiency could be handled by selecting a calibration area with balanced binary classes flooded areas and not flooded areas also the measure of fit mof by additionally penalising underprediction leads to lower optimal threshold values which are subsequently responsible for a tendency towards overestimation of flooded areas see table s1 in the supplementary materials for further details given these considerations results for the methods relying on binary classification are referred to the floodplain maps obtained by applying the optimal thresholds derived through the maximization of the critical success index 3 study area and data source the analysis was conducted as anticipated in the two largest islands in the mediterranean sea sicily and sardinia located in southern italy the two islands show similar hydrological and climatological features typical of mediterranean areas the climate is characterised by a marked seasonality with hot dry summers and mild wet winters precipitations are mainly concentrated during autumn and winter months with strong interannual variations which are occasionally responsible for arid multi year periods and droughts in sardinia the average annual precipitation is about 650 mm ranging between 500 mm in flat regions and 1160 mm observed in the mountainous areas mascaro et al 2018 the average annual rainfall in sicily is about 715 mm ranging between 400 and 1300 mm from south eastern to north eastern regions respectively caracciolo et al 2018 the four considered methods were tested on three of the largest river basins in sardinia namely tirso coghinas and cedrino and three river basins located in sicily that are simeto belice and eleuterio see fig 3 whose main characteristics have been summarised in table 2 these six catchments were chosen with the purpose of considering a wide range of morphological and hydrological characteristics e g drainage area stream order average annual rainfall as well as including the case of rivers affected by the presence of hydraulic infrastructures a simple morphological analysis of the river basins along with the computation of the flood descriptors can be easily performed using the information contained in dems in this work we utilized freely available dtms derived from lidar surveys with 1 m resolution in sardinia and 2 m resolution in sicily respectively in addition 10 m spatial resolution dtms were employed to investigate how floodplain mapping performance vary with resolution it is important to remark that 1 m resolution dtms coverage in sardinia is only extended to the nearest areas along the major rivers in the island and coastal areas while the 10 m resolution dtms are available on the entire regions as a benchmark we used the official flood hazard maps developed in the context of the piano stralcio delle fasce fluviali psff and the piano per l assetto idrogeologico pai by the river basin authorities rbas operating in sardinia and sicily according to the european flood directive 2007 60 ec these two documents provide the necessary information to develop guidelines and measures leading to a safer and more sustainable urban development the psff maps available in sardinia were derived for return periods of 50 200 and 500 years while the pai flood hazard maps available in sicily are associated with return periods of 50 100 and 300 years for the identification of flood prone areas the rbas followed traditional floodplain mapping procedures involving high precision topographic data collection hydrologic analysis and hydraulic modelling in this study the two maps with the highest return periods have been taken as a benchmark to assess the performance of the proposed approaches namely 500 years for sardinia and 300 years for sicily again for sake of clarity due to the limited availability of 1 m resolution dtms in sardinia performance at this resolution were evaluated considering only the reference flood prone areas inside the lidar data coverage 4 results the four proposed geomorphic approaches were applied to delineate the flood prone area extents for each river basin in the study area using high resolution dtms derived from lidar surveys 1 m and 2 m resolution as the main input to explore the variability of the mapping performance at a coarser resolution the hgm fd and the gfim fd have also been implemented making use of 10 m resolution dtms this test was not conducted for the hgm fa and the gfim fa which apply the flow area scaling laws in eq 2 as the river cross section shape extracted from the 10 m resolution dtms have been proved inaccurate in representing the channel geometry especially in complex topography after completing the calibration phase performances of the four considered approaches were evaluated in terms of critical success index csi true positive rate tpr and false discovery rate fdr see eqs 12 15 in section 2 4 evaluations of such metrics on the 1 m and 2 m resolution dtms in each of the six selected basins are displayed in fig 4 a from where some conclusions can be drawn i hydrogeomorphic methods hgm fd and hgm fa are affected by higher dispersion of both the critical success index csi and the true positive rate tpr compared to the gfim fd and gfim fa approaches ii gfim fd and gfim fa approaches performs better in terms of true positive rate tpr but at the expense of larger false discovery rate fdr with respect to hgm fd and hgm fa suggesting an overestimation tendency of floodplain extension for the former approaches for each method and each metric the average values over the six investigated basins are also plotted in fig 4a with larger symbols and reported in the upper part of table 3 hereafter indicated with overbars as c s i t p r f p r f d r and e all the implemented approaches provided moderate to high average of critical success index and true positive rate with c s i values ranging from 0 55 to 0 66 and values of t p r varying between 0 59 and 0 89 and moderate to low f d r values ranging from 0 33 to 0 08 below we will draw some considerations on the average performances of the two scaling laws fd and fa and the two flood descriptors employed in hgm and gfim respectively the hgm fd and gfim fd both employing flow depth scaling law fd are characterized by higher critical success index c s i 0 65 compared to hgm fa and gfim fa making use of the flow area scaling law fa approaches c s i 0 58 similar conclusion applies to the true positive rate t p r 0 80 for fd and average t p r 0 74 for fa whilst averages of the false discovery rate and the error bias of the fd based approaches f d r 0 19 e 7 3 are slightly lower compared with fa based approaches f d r 0 20 e 9 0 in five river basins out of six the method based on fd scaling laws outperformed the others in terms of critical success index in half of the cases it was the gfim fd and in one third of the selected catchments the best performance was attributed to the hgm fd in the remaining river basin the gfim fa obtained the highest value of csi see table s2 in supplementary materials results described above show that the approaches employing fd scaling laws are preferable to fa based approaches in fact parameterization of flow depth scaling laws in eq 1 not only has been proved more efficient by leading to better outcomes in most cases but it is also easier and faster to be implemented in a gis environment looking at the relative performances of the two adopted flood descriptors we can observe from table 3 that the gfim fd and gfim fa display greater true positive rate values t p r 0 89 than the hgm fd and hgm fa t p r 0 64 but at the same time they exhibit higher false discovery rate f d r 0 30 for gfim vs f d r 0 10 for hgm this behaviour is explained by the results in error bias values indicating that both methods based on binary classification overestimate flood prone areas e 15 9 for gfim vs e 0 4 for hgm as expected the hgm fd and hgm fa tend to be less performant in terms of critical success index c s i 0 59 than the gfim fd and gfim fa c s i 0 64 since the optimal thresholds of the two indices are calibrated on limited portions of the study area by taking advantage of benchmark maps derived from hydraulic modelling although it allows to achieve better outcomes the fact that binary classification methods depend on the availability of existing flood hazard maps represents a limitation to their applicability analysing in a deeper detail the performances of the gfim approaches we observe that gfim fd shows lower average fdr and error bias f d r and e equal to 0 27 and 14 4 respectively than gfim fa f d r 0 33 e 17 7 but their average true positive rate tpr values do not significantly differ both close to 0 89 in other words the gfim fa tends to overestimate flood prone areas more than the gfim fd does and this is reflected also on the average critical success index which is in fact higher for the gfim fd than the gfim fa c s i equal to 0 66 and 0 62 respectively looking in details at performances of the hgm approaches we observe that hgm fa presents a slightly lower average fdr than hgm fd f d r 0 08 and 0 11 respectively and the same tendency applies to the average error bias e equal to 0 2 and 0 6 respectively moreover the hgm fd is on average characterized by greater values of true positive rate and critical success index compared to the hgm fa t p r 0 70 and c s i 0 63 as opposed to 0 59 and 0 55 revealing that the hgm fa is the approach that suffers the most from underestimation 5 discussion although hgm fa seems to be the least accurate out of the four analysed geomorphic methods in reproducing the flood hazard areas identified in the benchmark maps it still provides comparable results as its average critical success index is only 10 lower than the highest c s i value obtained from the other approaches the peculiarity of hgm fa approach consists in the use of the flow area scaling laws fa in eq 2 relating cross sectional flow area to drainage area which involves the extraction of the stream cross section for the estimation of flow depth values through the fdfa relationship in eq 3 this process allows to take greater account of river morphology and channel shape changes the gfim fa is also based on the flow area scaling laws fa in eq 2 but the flow depth values provided by the fdfa relationship in eq 3 are used to formulate a composite index the gfifa in eq 7 utilized as a flood descriptor in this latter case the floodplain delineation is obtained through a threshold binary classification that slightly enhances the performance although causing overestimation the gfim fd taking advantage as well of the binary classification technique but applying the flow depth scaling law in eq 1 obtained the highest average critical success index among the four compared methods nevertheless the hgm fd could be considered the most promising in identifying the flood prone areas since it offers the best compromise between accuracy and computational costs using high resolution dems as the main input hgm fd is the simplest method among the four considered approaches since the flow depth is obtained with eq 1 and directly used as a flood descriptor this method does not require any extraction of cross sections along the stream nor the availability of flood hazard maps for threshold calibration purposes as it is the case of methods applying binary classification examples of floodplain delineation obtained with the four methods along with the flood inundated areas of the benchmark map are depicted in fig 5 best case and fig 6 worst case respectively while maps for the remaining four rivers have been reported in supplementary materials figure s3 s6 the visual comparison in fig 5 shows that all methods produced reliable flood prone area extents for the coghinas river basin interestingly three of the four methods provided their best performance on this catchment with critical success index ranging between 0 75 and 0 79 in accordance with previous observations the hgm fa fig 5b tends to slightly underestimate floodplain extensions e 1 while the gfim fd fig 5c and gfim fa fig 5d are affected by a tendency towards overestimation e 1 the hgm fd presents no bias e 1 although stream morphology is taken into greater consideration in the methods applying flow area scaling laws in eq 2 rather than those based on fd scaling laws in eq 1 a paradigmatic case is offered by the lake casteldoria originated by the casteldoria dam erroneously identified as exposed to flood hazard by both methods hgm fa and gfim fa see insets in fig 5b and d this drawback is due to the very steep flow depth flow area relationship in eq 3 corresponding to the narrow shape of the channel at the first cross section downstream the dam as a result the high flow depth corresponding to the estimated flow area exceeded the difference in elevation between the upstream cells included into the reservoir and the stream cell belonging to the cross section causing the false positive instances in the hgm fd and gfim fd this circumstance does not occur as the flow depth is exclusively dependent on the drainage area therefore any effect induced by changes in channel geometry is completely neglected a further investigation of this specific case also revealed a significant underestimation of the flow depth provided by fd scaling laws in eq 1 but since this happens in a deep canyon even a large error in flow depth estimation leads to the same mapping outcome by fd based approaches conversely the erroneous mapping resulting from the fa based approaches seems to be mainly related to an overestimation of the flow area due to the fact that the flow area scaling laws in eq 2 were mainly calibrated on wide cross sections and gentle riverbed profiles fig 6 displays a sample of the flood prone areas identified in the alto tirso river basin where the hgm fd and hgm fa exhibited their poorest performance with critical success index of 0 49 and 0 39 respectively both methods especially the hgm fa tend to strongly underestimate flooded areas e 1 whilst the two approaches based on binary classification suffer once again from overestimation e 1 regarding the sensitivity of the approaches to varying input resolution the outcomes of the hgm fd and gfim fd tested with the 10 m resolution dtms do not significantly differ from the results obtained by the 1 m and 2 m resolution dtms in terms of average success index the percentage difference is below 2 with the hgm fd performing slightly better at coarser resolution in opposition to the gfim fd which is marginally less performant also the metrics dispersion are extremely similar see fig 4b in four river basins out of six the gfim fd produced the highest value of csi nevertheless the average critical success index for both methods is equal to 0 65 the general behaviour identified at finer resolution is maintained the hgm fd tends to underestimate flooded areas e 1 while the gfim fd is still characterised by overestimation bias e 1 overall in this investigation the two methods implementing the flow depth scaling laws did not show significant sensitivity to the dtms resolution change from 1 m and 2 m to 10 m at the same time it is worth mentioning that for fa methods the analyses were not even possible with the 10 m resolution dtms because the cross sectional area estimation turns out to be unreliable only high resolution dem as the ones provided by lidar allow to correctly estimate the cross sectional area and take into account the presence of levees roads and bridges embankments and in general any artificial or natural changes in elevation that are impossible to detect with such accuracy at coarser resolutions considering that fa approach involves terrain analysis and utilizes as a main input the topographic information contained in dtms for its application it would be reasonable to utilize the highest resolution terrain data available 6 conclusions the present study investigated the floodplain mapping performance of four geomorphic approaches based on the coupling of two flood descriptors hgm and gfim and two simple power laws flow depth fd and flow area fa scaling laws relating flow depth and cross sectional flow area to upstream contributing area six river basins located in southern italy were selected as a case study and their flood prone areas were estimated with the four approaches using high resolution dems as the main input and finally compared with official flood hazard benchmark maps derived from hydraulic modelling overall the implemented methods provided average critical success index varying between 0 55 and 0 66 average true positive rate ranging from 0 59 to 0 89 and average false discovery rate ranging between 0 08 and 0 33 the gfim fd and gfim fa based on the threshold binary classification of the gfi to delineate floodplain extents displayed a tendency towards overestimation whilst methods directly employing flood depth as flood descriptor suffer from underestimation especially the hgm fa the two methods employing the relationship between flow depth and contributing area flow depth scaling laws fd eq 1 performed better than the two relating flow area to drainage area flow area scaling laws fa eq 2 despite not being able to take as much into consideration the stream morphology in fact the highest average critical success index was obtained by gfim fd immediately followed by the hgm fd confirming flow depth as a valid flood descriptor to be used in geomorphic approaches it is important to underline that the methodologies proposed in this work being based on simple power laws and taking as the main input the information contained in dtms are not expected to reproduce exactly the floodplain maps obtained through conventional procedures involving hydrologic and hydraulic modelling however they may represent useful tools for approximately delineating flood prone areas in ungauged basins or in data scarce regions where standard flood hazard maps are unavailable with the increasing availability of high resolution topographic data further investigations at regional scale should be carried out to better explore the potentialities of these geomorphic methods incorporating these dtm based approaches into machine learning workflows and also to test the transferability of the scaling laws parameters credit authorship contribution statement claudia deiana methodology software data curation writing original draft roberto deidda visualization investigation writing review editing funding acquisition francesco viola methodology visualization investigation writing review editing declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests roberto deidda reports financial support was provided by european union acknowledgments the authors acknowledge and thank the two reviewer prof salvatore manfreda and the anonymous one for their meticulous work and the precious suggestions this study was carried out within the return extended partnership and received funding from the european union next generation eu national recovery and resilience plan nrrp mission 4 component 2 investment 1 3 d d 1243 2 8 2022 pe0000005 supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2023 104493 appendix b supplementary materials image application 1 appendix regarding the feasibility and performances of methods based on flow area scaling laws fa compared to flow depth scaling laws fd on an empirical basis we initially supposed that the former could potentially have a greater capability of approximately representing what occurs during critical flood events in fact while the flow area is expected to tendentially increase moving from upstream to downstream cross sections of the same river hence as the drainage area increases the behaviour of the flow depth is subject to greater uncertainty especially when the bank full stage is exceeded we formulated this hypothesis on the basis of a synthetic case conducted on a rectangular river basin with discharge increasing linearly with contributing area hydraulic simulations executed with hec ras in one dimensional steady flow under uniform conditions allowed to estimate flow depth and flow area values at the river cross sections the stream channel geometry has been approximated through a triangular shape and two different configurations were tested the former assumed constant riverbanks slope for all the cross sections along the stream the latter considered a progressive decrease in riverbanks slope moving from upstream to downstream cross sections trying to mimic to the natural downstream changes in channel geometry while in the first configuration the flow depth increases downstream with increasing contributing area in the second case it can be observed that after an initial increase the water depth tends to remain constant or slightly decrease see fig 7 a instead the flow area shows an increasing tendency in both configurations see fig 7b which led to the assumptions explained above in addition to these empirically based considerations the fact that flow area has not been employed before as a proxy of a flood descriptor in automatic flood prone area detection techniques has contributed to arouse great interest in investigating the potentialities of eq 3 for this scope 
12,granular dynamics driven by fluid flow is ubiquitous in many industrial and natural processes such as fluvial and coastal sediment transport yet their complex multiphysics and multi scale nature challenge numerical models accuracy and efficiency here we develop a new multi resolution mesh free particle method based on an enhanced weakly compressible moving particle semi implicit mps method to study the dynamics of rapid fluid driven granular erosion we propose and validate a novel multi resolution multiphase mps formulation for the consistent and conservative form of the governing equations including particle stabilization techniques first we discuss the numerical accuracy and convergence of the proposed approximation operators through two numerical benchmark cases the multi viscosity poiseuille flow and the multi density hydrostatic pressure then coupling the developed model with a generalized rheology equation we investigate the water dam break waves over movable beds the particle convergence study confirms that the proposed multi resolution formulation predicts the analytical solutions with acceptable accuracy and order of convergence validating the multiphase granular flow reveals that the mechanical behavior of this fluid driven problem is highly sensitive to the water sediment density ratio the bed with lighter grains experiences extreme erosion and interface deformations for the bed with a heavier material but different geometrical setups the surge speed and the transport layer thickness remain almost identical away from the gate furthermore while the multi resolution model accurately estimates the global sediment dynamics the single resolution model underestimates the flow evolution overall the qualitative and quantitative analysis of results emphasizes the importance of multi scale multi density interactions in fluid driven modeling graphical abstract keywords multi resolution particle method numerical stability and convergence multiphase flows immersed granular flows dam break erosion data availability data will be made available on request 1 introduction many hydro environmental and geotechnical problems involve the multiphase flow of granular material like sediment immersed in a fluid like water fig 1 a in such multiphysics systems the granular phase demonstrates dynamic solid and fluid like behaviors induced by gravity and the ambient fluid flow e g in the cases of submarine landslides robbe saule et al 2021 pilvar et al 2019 bougouin and lacaze 2018 rondon et al 2011 balmforth and kerswell 2005 and fluvial and coastal sediment transport lobkovsky et al 2008 fraccarollo and capart 2002 brooks and lawrence 1999 particularly rapid shearing flows over granular beds cause large interfacial deformations leading to the erosion suspension and deposition of grains guazzelli and pouliquen 2018 the complex and simultaneous presence of the quasi static dense flow and kinetic suspended regimes jop 2015 makes the accurate prediction of such immersed granular flows challenging over the past decades experimental and theoretical studies have focused on representing physical and mathematical models for multiphase granular flows mechanical behavior in various flow conditions e g stickel and powell 2005 cassar et al 2005 huang et al 2012 li et al 2022 numerical methods have been introduced as an alternative for investigating the underlying physics of immersed granular flow e g chauchat and médale 2010 amarsid et al 2017 baumgarten and kamrin 2019 hu et al 2021 yet their numerical accuracy and stability are subjects of ongoing studies and rely on the constitutive laws mostly developed through experiments and theories e g jop et al 2006 pouliquen and forterre 2009 for dealing with different stress conditions and pore pressure effects of the water sediment interactions baumgarten and kamrin 2019 these issues with numerical methods along with their computational costs affect their applicability to engineering problems and thus further developments and validation of numerical formulations become essential this paper studies fluid driven granular dynamics through a consistent numerical method discrete based and continuum based numerical approaches have been widely developed for simulating immersed granular flows while discrete based methods such as the discrete element method dem cundall and strack 1979 provide an in depth grain scale understanding of the granular behavior they are computationally expensive for practical problems that involve a large volume of materials on the other hand the continuum based numerical methods homogenize the assembly of solid grains or the mixture of solid granules and interstitial fluid into a body of continuum at the macroscopic level fig 1 b thus they are scalable and computationally affordable for large scale modeling such methods employ a rheology model to estimate the mechanical behavior of the granular continuum guazzelli and pouliquen 2018 the continuum based models treat the dense multiphase granular flow system using either single continuum or two continuum models guazzelli and pouliquen 2018 jop 2015 the single continuum models consider the solid grains and interstitial pore fluid as a single uniform dense mixture the mixture interacts with the ambient fluid phase directly through one set of governing equations the two continuum models simulate the relative motion of the interstitial fluid and the solid grains and solve separate sets of governing equations including inter phase forces guazzelli and pouliquen 2018 pailha and pouliquen 2009 unlike the single continuum model the two continuum model considers the effects of volume fraction variations i e the pore water flow into the porous phase in the constitutive formulations baumgarten and kamrin 2019 pailha and pouliquen 2009 in both approaches the numerical element representing the continuum i e the representative elementary volume v in fig 1 b must be large enough to contain a sufficient number of solid grains otherwise the continuum assumption and the constitutive law would become invalid jandaghian et al 2021a guazzelli and pouliquen 2018 rycroft et al 2009 on the other hand the numerical element should be small enough with respect to the characteristic length scale of the problem to mathematically represent its vicinity and minimize the numerical approximation errors jandaghian et al 2021a ghaïtanellis et al 2018 baveye and sposito 1984 the computational model shall respect these two conflicting constraints in determining the spatial resolution of the discretized domain moreover to capture highly dynamic and high reynolds number fluid flows the numerical solution requires a higher spatial resolution for the fluid phase e g v 4 than that of the granular or mixture accordingly one can conceive a multi resolution approach for simulating the fluid driven granular flows fig 1 c d mesh based continuum methods have been developed for various granular simulations rauter 2021 lacaze et al 2021 however due to their mesh dependency they require particular treatments to deal with highly dynamic interfaces selçuk et al 2021 rycroft et al 2020 in contrast mesh free lagrangian continuum methods or simply particle methods discretize the continuum using moving particles without any connectivity fig 1 c this feature of particle methods introduces them as reliable numerical approaches for handling interfacial deformations and hence suitable for highly dynamic granular flows luo et al 2021 feng et al 2021 shakibaeinia and jin 2012a the material point method mpm sulsky et al 1994 the moving particle semi implicit mps method koshizuka and oka 1996 and the smoothed particle hydrodynamics sph method gingold and monaghan 1977 are some of the most widely adopted continuum particle methods we establish the numerical method of this study based on the mps formulation sph and mps have gone through significant developments to improve their accuracy and stability for highly dynamic and multiphase flows antuono et al 2021 jandaghian et al 2022 2021b rezavand et al 2020 duan et al 2017 khayyer et al 2017 shakibaeinia and jin 2012b shakibaeinia and jin 2010 introduced the weakly compressible mps method wc mps jandaghian and shakibaeinia 2020 and jandaghian et al 2021b enhanced the accuracy and stability of the wc mps method by proposing artificial diffusive terms and particle regularization techniques such methods coupled with various constitutive laws in either single or two continuum modeling approaches have simulated immersed granular flows in the single continuum particle methods the adopted rheological models include the bingham plastic formulation nabian and farhadi 2017 khanpour et al 2016 rodriguez paz and bonet 2004 the herschel bulkley model shakibaeinia and jin 2011 rodriguez paz and bonet 2004 the herschel bulkley papanastasiou model fourtakas and rogers 2016 the regularized μ i equation by jop et al 2006 qi et al 2022 jandaghian and shakibaeinia 2019 tajnesaie et al 2018 jafari nodoushan et al 2018 the elastic viscoplastic model ghaïtanellis et al 2018 and the generalized rheology model jandaghian et al 2021a moreover to improve the prediction of the incipient motion of the granular particles some methods employed an additional yielding threshold based on shields erosion criterion zubeldia et al 2018 khanpour et al 2016 manenti et al 2012 as for the two continuum models sph methods have been employed for studying sediment dynamics in the immersed condition e g see bui and nguyen 2017 pahar and dhar 2017 shi et al 2019 although such models can simulate the effects of pore water flow through the continuum solid phase yet empirical equations parameters are used in the system of equations for the inter phase forces and the solid phase stress model shi et al 2021 also the presented two continuum particle methods do not benefit from the recent numerical enhancement techniques like the high order diffusion terms and the particle regularization techniques in their governing equations while the previous particle methods have mostly focused on gravity driven granular flows a few have attempted to simulate fluid driven cases several multi resolution sph and mps methods have been proposed and validated for improving numerical accuracy and capturing more accurate flow solid deformations over a refined computational domain they implement dynamic particle splitting and merging liu and zhang 2021 tanaka et al 2018 vacondio et al 2013 adaptive particle refinement yang et al 2021 chiron et al 2018 barcarolo et al 2014 overlapping methods bellezi et al 2022 yamada et al 2021 shibata et al 2017 and volume adaptive scheme sun et al 2020 such multi resolution methods are employed for various single phase and multiphase flows e g liu and zhang 2021 sun et al 2018 omidvar et al 2013 and fluid structure interactions e g khayyer et al 2021 2019 zhang et al 2020 sun et al 2019 nevertheless no multi resolution particle method has been reported for multiphase granular flows on the development of single continuum wc mps methods for multiphase granular flows shakibaeinia and jin 2011 2012a developed the original form of their multiphase wc mps shakibaeinia and jin 2012b to study immersed granular flows by simulating water dam break over the erodible bed and the sand discharge into still water this method was further validated to two dimensional sub aerial and submerged granular collapse test cases jafari nodoushan et al 2018 tajnesaie et al 2018 jandaghian and shakibaeinia jandaghian et al 2021a developed the multiphase model of their enhanced wc mps method presented by jandaghian and shakibaeinia 2020 for free surface flows to simulate three dimensional gravity driven immersed granular collapse and slide they introduced the regularized form of a visco inertial rheology model including the consistent effective pressure term for rapid granular deformation with non hydrostatic pore water pressure and without shear stress threshold these previous developments have been based on the mps interpolants for single resolution particle interactions in the present study we propose a novel multi resolution particle method based on the enhanced wc mps formulation by jandaghian and shakibaeinia 2020 and jandaghian et al 2021a b to investigate the mechanical behavior of immersed granular dynamics primarily driven by rapid fluid flow to that end here we present the novelties of this work from the numerical and physical perspectives we propose new approximation operators respecting the conservative properties of the multi scale multiphase system the new discretized form of governing equations include multi density multi viscosity interactions of water and mixture particles with different volumes to ensure numerical stability and avoid unphysical pressure oscillations which can largely affect the granular yield behavior we adapt the modified diffusive term jandaghian et al 2021a and the dynamic particle collision dpc technique jandaghian et al 2021b to the newly developed multi resolution framework for the first time we couple a multi resolution particle method with the generalized rheology model jandaghian et al 2021a supplied with a suspension equation for rapid and immersed granular flows thus we extend the validation of the implemented rheology formulations including the consistent effective pressure to fluid driven granular flows through a quantitative and qualitative analysis of numerical results of a benchmark case i e water dam break waves on erodible sediment beds spinewine and zech 2007 spinewine and capart 2013 we provide a comprehensive study on the dynamics of rapid sediment erosion induced by a sudden collapse of a water column we present internal flow properties and the global mechanical behavior of this fluid driven problem we also parameterize the rheology and analyze the phenomenology of sediment dynamics concerning different bed materials and initial configurations of the test case moreover comparing the results of the single and multi resolution mps simulations we evaluate the role of multi scale interactions in capturing the flow evolution we derive the novel multi resolution mps method coupled with the rheology model in section 3 following the equations of motion represented in section 2 first we study the numerical accuracy and convergence of the multi resolution formulation through two multiphase benchmark cases i e the multi viscosity poiseuille flow and the multi density hydrostatic pressure section 4 1 next we investigate water dam break waves on erodible sediment beds in section 4 2 at the end we review the overall results and concluding remarks of this study in section 5 2 equations of motion here the system of granular material and the ambient fluid is considered as a multiphase continuum which in a lagrangian framework is described by the continuity equation 1 d ρ d t ρ v the momentum equation 2 d v d t t ρ f and the advection equation 3 d r d t v calculating the time evolution d d t of the fluid density ρ velocity v and position r respectively panton 2013 the total stress tensor t consists of the pressure scalar value p and the shear stress tensor τ as t p i τ i being the identity matrix and ρ f is the body force per unit volume considering the barotropic fluids the equation of state calculates the pressure i e p f ρ for incompressible fluid flows i e considering v 0 the divergence of the stress tensor reduces to 4 t p η 2 v which is valid for newtonian and non newtonian mechanical behaviors one should note that in the shear force calculation the term η is neglected compared to the magnitude of η 2 v shakibaeinia and jin 2011 constitutive laws determine η as a function of hydrodynamic and material characteristics guazzelli and pouliquen 2018 for water we include a simple turbulence model based on the large eddy simulations in the shear force calculations we treat the mixture phase as a non newtonian fluid through the visco inertial rheology model proposed by baumgarten and kamrin 2019 and then represented in the regularized form by jandaghian et al 2021a 3 a consistent multi resolution multiphase mps method 3 1 integral and summation interpolants in continuum based particle methods the approximation operator transforms the integral representation of functions into the summation interpolant by discretizing the computational domain ω moving calculation points or simply particles carry flow and material properties liu and liu 2003 here we adopt the general integral formulation of the mps method to derive the new summation operator of the multi resolution model mps integral representation of an arbitrary function f r reads koshizuka et al 1998 5 f r ω f r w r r r e d v ω w r r r e d v where d v is a differential volume element the positive non dimensional weighting function w so called the kernel with a compact support smooths f over the influence radius r e mps introduces a normalization factor denoted by n 0 into the equations which corresponds to the reference physical fluid density ρ 0 and the mass of volume element m 0 via 6 n 0 ρ 0 m 0 ω w r r r e d v n 0 only depends on the type of kernel and the ratio of r e to the size of spatial discretization l 0 i e k r e l 0 souto iglesias et al 2013 the original mps formulation uses 6 to rewrite the integral representation 5 as 7 f r 1 n 0 v 0 ω f r w r r r e d v where the reference volume is v 0 m 0 ρ 0 koshizuka and oka 1996 souto iglesias et al 2013 in the mps particle system considering identical spatial resolution and smoothing length over the computational domain i e where l 0 i l 0 j and r e i r e j as l 0 i and r e i stand for the initial particle spacing and the smoothing length of i respectively the summation operator of 7 reads 8 f i 1 n 0 i j n f j w r ij r e i for a target particle i ω surrounded by n number of neighbor particles identified as j ω where r ij r j r i r e i the standard mps method adopts 8 to discretize the fluid flow governing eqs 1 and 2 here we introduce a new form of 8 to take into account the multi resolution particle interactions i e where l 0 i l 0 j and r e i r e j to that end with a constant k for the entire computational domain and v 0 r e k d we employ 6 to rewrite 5 as 9 f r 1 n 0 ω f r w r r r e k d r e d d v where d is the number of space dimensions without any assumption regarding the spatial resolution we derive a new formulation for the kernel identified as w through the general form of approximation operator 10 f i 1 n 0 i j n f j w r ij r e ij v 0 j where the new non dimensional kernel would be 11 w ij w r ij r e ij v 0 j w r ij r e ij v 0 j k d r e ij d in eq 11 v 0 i being the reference volume of particle is equal to l 0 i d for incompressible fluid flows to respect the symmetric feature of the smoothing procedure in the governing equations see section 3 2 and fig 2 we have substituted r e with r e ij r e i r e j 2 similar to the formulations used by sun et al 2017 and tanaka et al 2018 the new definition of particle approximation operator 10 unlike the standard formulation 8 includes the multi resolution particle interactions with different smoothing lengths where v 0 i v 0 j while in the same resolution interactions where v 0 i v 0 j the kernel 11 automatically reduces to its original shape as w ij w r ij r e i by neglecting the kernel truncations at the interfaces and away from boundaries n 0 keeps its standard definition as the summation of kernel at the initial uniform distribution of particles i e n 0 max i j n w r ij r e i at t 0 thus it can be identified as a global constant for all the particle sizes and their interactions as k r e i l 0 i is invariable over ω in this study we set k 3 1 and use the third order polynomial spiky kernel function shakibaeinia and jin 2010 for all the approximation operators 3 2 the discrete system of flow equations in particle methods for immersed granular flows the moving particles are the representative elementary volume of the ambient water phase ω w or the mixture of pore water and solid grains ω m or the solid walls ω s forming the computational domain ω where ω w ω m would be the fluid phase ω f and ω ω f ω s using the summation operator for a target particle i ω f the flow equations read 12 1 n i d n i d t v i d i m d v i d t 1 ρ i p i 1 ρ i η 2 v i f i d r i d t v i in which n i is the non dimensional particle number density given as n 0 ρ i ρ 0 i and independent of the density discontinuity at the interfaces jandaghian et al 2021a in this model the momentum equation considers the density of particle ρ i to be equal to the reference density of the fluid phase respecting the original form of the incompressible mps method i e in the momentum equation ρ i ρ 0 i where for i ω w ρ 0 i ρ 0 w and i ω m ρ 0 i ρ 0 m ρ 0 w 1 ϕ 0 ϕ 0 ρ g as ϕ 0 and ρ g are the reference volume fraction and the true density of the solid grains respectively for the multi resolution multi phase mps model we use the new kernel 11 to discretize the right hand side terms of 12 based on the conservative wc mps formulation jandaghian and shakibaeinia 2020 13 v i d n 0 i j n n j n i v j v i r ij e ij w ij p i d n 0 i j n n i p j n j n j p i n i e ij r ij w ij η 2 v i 2 d n 0 i j n η ij v j v i r ij 2 w ij e ij r ij r ij is the unit direction vector and the harmonic mean of the dynamic effective viscosity of i and j i e η i and η j gives η ij 2 η i η j η i η j with the new kernel function the interaction of particles with various size and density remains anti symmetric within the governing equations thus the conjugate gradient and divergence operators ensure the conservation of the total energy in the absence of shear and external forces see price 2012 and jandaghian and shakibaeinia 2020 fig 2 here similar to other multiphase particle methods developed for granular flows e g ghaïtanellis et al 2018 shakibaeinia and jin 2011 jafari nodoushan et al 2018 we considered η i 0 in the shear force calculation one should note that estimating the viscosity term through the divergence of shear stress tensor i e using τ i instead of η 2 v i may affect the accuracy of the calculations and the anti symmetric feature of the particle interactions depending on the adopted approximation operators discussed by jafari nodoushan et al 2018 considering the barotropic fluid as a weakly compressible phase we employ the equation of state to calculate the pressure by shakibaeinia and jin 2010 14 p i b 0 n i n 0 γ 1 where the bulk modulus b 0 c 0 2 ρ 0 γ and γ 7 are constant for all the fluid phases as ρ 0 and c 0 are the true density and the artificial sound speed of the reference phase respectively here we consider water as the reference phase thus ρ 0 ρ 0 w and c 0 c 0 w to limit the compressibility to less than 1 the reference sound speed should satisfy c 0 10 v max condition by which the mach number is kept less than 0 1 v max being the maximum expected velocity magnitude next we adapt the modified diffusive term by jandaghian et al 2021b to the multi resolution framework with the new kernel 11 as follows 15 d i m δ m p s δ t c 0 2 n 0 2 d n 0 i j n n j n i 1 2 n i c n j c r ij w ij r ij 2 in which n i c is the high order gradient operator of n i estimated by 16 n i c d n 0 i j n n j n i r ij c i e ij w ij and the correction matrix c i is given as 17 c i d n 0 i j n r j r i r ij e ij w ij 1 where stands for the outer product of vectors the non dimensional coefficient 0 δ m p s 1 the calculation time step δ t and c 0 adjust the magnitude of this numerical correction the diffusive term obeys the mass conservation law if i n i v i d i m 0 as v i n 0 v 0 i n i from 6 with i j ω f in 15 17 the diffusive term would be an anti symmetric formulation which conserves the total mass of the multi resolution multiphase system 3 3 dynamic particle collision for multi scale multiphase interactions here we implement the dynamic pair wise particle collision dpc method proposed by jandaghian et al 2021b as the particle regularization technique which ensures the numerical stability by eliminating particle clustering and high frequency pressure noises considering the velocity variation of two particles colliding with different masses and volumes we develop the dpc formulation for the multi resolution multi phase interactions as 18 δ v i i j n κ ij 2 m 0 j m 0 i m 0 j v ij coll δ t ρ 0 i i j n α ij 2 v 0 j v 0 i v 0 j p ij b r ij e ij where i j ω f and m 0 i ρ 0 i v 0 i the collision velocity v i j coll and the binary multiplier α i j are given by 19 v ij coll α ij v ij e ij e ij 0 for v ij e ij 0 0 1 otherwise and the dynamic background pressure p i j b is defined as p ij b p ij χ ij where p ij max min λ p i p j λ p max p min χ i j w r ij l 0 ij w 0 5 l 0 ij l 0 ij 0 5 the non dimensional variable χ ij is a function of the kernel with the smoothing length set to l 0 ij l 0 i l 0 j 2 where for r ij l 0 ij χ ij 0 the preset maximum and minimum pressure of the test case p max and p min respectively and the non dimensional constant λ specify the strength of the repulsive term for the collision term the variable coefficient κ ij dynamically sets the coefficient of restitution as a function of r ij via 20 κ ij χ ij 0 5 l 0 ij r ij l 0 ij 1 r ij 0 5 l 0 ij eventually δ v i from 18 updates the velocity and position of particles within the solution algorithm i e we have v i v i δ v i and r i r i δ v i δ t the proposed dpc through eqs 18 20 conserves the linear momentum of the multi resolution multi phase particle interactions i e with i j ω f then i m 0 i δ v i 0 in this study we use the wendland kernel for χ ij and set λ 0 2 jandaghian et al 2021b 3 4 generalized rheology model we employ the generalized rheology model of jandaghian et al 2021a for calculating the effective viscosity of the water and mixture particles for water as a newtonian fluid with the true viscosity μ w the effective viscosity increases by the presence of solid grains i e with the approximated volume fraction ϕ i defined by 24 and including the turbulence effect 21 i ω w η i μ w 1 5 2 ϕ i ρ 0 w ν t i as the eddy viscosity is given by ν t i c s r e i 2 γ i and the smagorinsky constant coefficient is set to c s 0 12 the pressure imposed rheology treats the mixture of water and solid grains as a non newtonian fluid through the mixture effective viscosity formulated by η i μ i p g i γ i in which p g i is the solid grains normal stress i e the effective pressure μ i is the friction coefficient and γ i is the magnitude of strain rate tensor guazzelli and pouliquen 2018 with the visco inertial model of baumgarten and kamrin 2019 as the friction coefficient and the regularized formulation for avoiding the singularity issue when γ i 0 jandaghian et al 2021a represented the effective viscosity of the mixture particles as i ω m η i τ y i γ i 2 λ r 2 μ 2 μ 1 p g i b p g i d g 2 ρ g 2 μ w γ i λ r γ i 22 5 ϕ i 2 a μ w p g i γ i 2 d g 2 ρ g 2 μ w γ i λ r 2 where a and b are material constants the upper and lower limits of the solid grains friction are denoted as μ 2 and μ 1 tan θ respectively ρ g d g and θ stand for the true density the mean diameter and the internal friction angle of the solid grains respectively the yield stress τ y is given by the drucker prager yield criteria as τ y i 2 3 sin θ p g i 3 sin θ noting that p g i 0 the regularization parameter λ r is set to 0 001 for incompressible fluid flows γ i 4 i i e i as the strain rate tensor e i 0 5 v i c v i c t and its second principal invariant i i e i 0 5 e i e i for the derivation of 22 readers are referred to jandaghian et al 2021a we estimate the gradient of velocity and the volume fraction of the water and mixture particles through 23 v i c d n 0 i j n v j v i r ij c i e ij w ij and 24 ϕ i j n ϕ j w ij j n w ij respectively noting that for j ω w ϕ j 0 and j ω m ϕ j ϕ 0 the non dimensional parameters i e the inertial number i i γ i d g ρ g p g i the viscous number i ν i μ w γ i p g i and the mixed number i m i 2 2 i ν govern the visco inertial rheology model amarsid et al 2017 boyer et al 2011 this model is validated against the experimental data of immersed granular flows where i m 0 6 baumgarten and kamrin 2019 in rapid fluid driven granular erosion mixture particles at the interface are subjected to high shear forces leading to their suspension with low volume concentration in the dilute and semi dilute conditions the dynamic viscosity turns to be a function of the volume fraction and independent of the shear rate magnitude guazzelli and pouliquen 2018 thus to incorporate the role of suspension effects we calculate the effective viscosity of the mixture particles where ϕ i ϕ 0 0 5 or i m i 0 6 through the suspension equation of vand 1948 25 η i μ w exp 2 5 ϕ i 1 39 64 ϕ i coupling the visco inertial formulation with the vand s equation aims at simulating the suspension process of mixture particles previously zubeldia et al 2018 and fourtakas and rogers 2016 used this equation with the herschel bulkley papanastasiou constitutive model for sediment dynamics modeling in sph one should not that our implemented constitutive model treats the different regimes of the immersed granular flow through the failure and post failure terms and the suspension equation without any shear stress threshold e g shield s erosion criterion in zubeldia et al 2018 and khanpour et al 2016 to distinguish the yielded particles from the un yielded ones moreover we implement the consistent effective pressure p eff i proposed by jandaghian et al 2021a to estimate p g i of the immersed granular flow where for i ω m p g i p eff i and 26 p eff i b 0 n i n 0 γ ρ w i ρ 0 w γ in which the density of the pore water ρ w i is updated by its continuity equation derived for the single phase continuum model as follows 27 1 ρ w i d ρ w i d t v i d i m the right hand side of 27 is identical to the right hand side of the continuity equation used for updating n i in 12 overall the dynamic viscosity of the water and mixture particles is calculated through eqs 21 22 and 25 as functions of the material properties the strain rate tensor the volume fraction and the effective granular pressure the multi viscosity particle interactions within the system of eqs 13 are modeled by the harmonic mean of viscosity η ij adopted for the shear force term shakibaeinia and jin 2012b duan et al 2017 3 5 boundary conditions and solution algorithm in the numerical model the fixed boundary particles i ω s simulate the solid walls the fluid particles interact with the solid boundary particles through the governing eqs 13 jandaghian et al 2021a to update the pressure of the wall boundary particles p i we implement the dynamic solid boundary condition by crespo et al 2015 the pressure of the closest wall particle is assigned to the ghost particles the velocity of the solid boundary particles v i is considered to be zero in the continuity equation of fluid particles in the shear force calculations the velocity assigned to the solid boundary particles applies slip or no slip boundary conditions for viscous flow simulations we consider the viscosity of the fluid particle for the boundary particle i e η j ω s η i ω f in η 2 v i for solving the governing equations we implement the second order and explicit symplectic time integration scheme represented by jandaghian et al 2021a the time step of calculation δ t is given based on the courant friedrichs lewy cfl stability condition and the shear force corresponding to the density the spatial resolution and the dynamic viscosity of each phase i e ω w and ω m as follows 28 δ t min c cfl l 0 c 0 c v ρ 0 l 0 2 η max ω w m in which c cfl and c v are non dimensional coefficients of the time steps identical for both phases and η max is the maximum expected dynamic viscosity considering ω w as the reference phase for the bulk module in 14 we set the sound speed of the second phase as c 0 m c 0 w ρ 0 w ρ 0 m 4 results and discussions the reliability of water sediment dynamics modeling depends on the accuracy of the approximated governing equations and their capability in capturing the multiphysics flow properties to investigate the consistency of the proposed multi resolution mps formulation we begin with studying the numerical accuracy and convergence of two benchmark cases i e the multi viscosity poiseuille flow and the hydrostatic pressure of two fluid phases section 4 1 then we investigate and validate rapid fluid driven granular erosion through simulating dam break waves over movable beds section 4 2 a movie containing the numerical simulations and results is provided as the supplementary data of this paper 4 1 numerical accuracy and convergence of the multi resolution mps model here we evaluate the numerical accuracy of the multi resolution operator in estimating the shear force by modeling the multi viscosity poiseuille flow further we simulate the hydrostatic pressure of two fluid phases to investigate the new conservative form of governing equations in the multi resolution configuration fig 3 represents the initial setup of the test cases and their parameters 4 1 1 multi viscosity poiseuille flow this benchmark case has been widely simulated for studying the numerical accuracy and convergence characteristics of particle methods ghaïtanellis et al 2018 duan et al 2015 shakibaeinia and jin 2012b two fluid phases with different viscosity flow between two stationary and parallel plates under a constant body force applied as a gradient of pressure ρ 0 f y p y in the positive y direction shown in fig 3 a the fluid phases denoted as ω 1 and ω 2 fill the channel with identical width equal to l 2 and density i e ρ 1 ρ 2 ρ 0 1000 kg m 3 we set the viscosity ratio m η 2 η 1 to 25 50 and 100 with the dynamic viscosity of the second phase η 2 set to 100 pa s no slip boundary condition determines the velocity of the fixed solid boundary particles interacting with the fluid particles i e v j v i for i ω f ω 2 ω 1 and j ω s periodic boundary condition eliminates kernel truncation at the top and bottom boundaries i e at y l 0 and 1 the particle size of the fluid phase with the greater viscosity i e l 0 2 determines the spatial resolution of the problem by r l l 0 2 the fluid phase with the smaller viscosity value i e ω 1 has the higher spatial resolution where the particle size ratio defined as q l 0 2 l 0 1 is set to 2 and 4 the maximum analytical velocity u max occurs at the midpoint of ω 2 i e at x l 0 75 and the analytical velocity at the interface i e at x l 0 5 is denoted as u 0 the non dimensional time t is given by t u 0 l and eq 28 determines the calculation time steps with c cfl c 0 0 05 s m c v 0 25 and η 2 100 pa s we estimate the normalized root mean square error of the velocity magnitude through l 2 v u max 1 1 n tp i ω f v i v analytical at x i 2 in which n tp is the total number of fluid particles comparing the analytical solution of the velocity field represented by cao et al 2004 with the results of the single and multi resolution simulations we investigate the numerical accuracy of the model solely related to the shear force operator fig 4 illustrates and plots the velocity of the fluid particles for different m and q at t 100 and with r 40 the single and multi resolution simulations predict accurate results as the estimated velocity converges to the analytical velocity profiles with q 4 small incompatibility between the numerical and analytical results appears at the interface i e at x l 0 5 and where the maximum velocity occurs i e at x l 0 75 this discrepancy originates from the adopted assumption that considers the normalization factor i e n 0 to remain valid at the interface even where q 1 also the approximation term has no renormalization matrix for ensuring the first order accuracy of the estimated velocity field next we perform a particle convergence study of the numerical results compared with the analytical velocity profiles we estimate and plot l 2 v over the simulation time t 0 100 and with different spatial resolutions where r 8 10 16 20 40 and 80 fig 5 with both single and multi resolution simulations l 2 v reduces as the spatial resolution increases shown in fig 5 a for m 50 we plot l 2 v against the averaged particle size i e l 0 1 l 0 2 2 in the log log graphs of fig 5 b the plots display that the accuracy of results is independent from the viscosity ratio m e g with q 2 and r 40 l 2 v is 1 15 1 17 and 1 13 for m 25 50 and 100 respectively on the other hand the multi resolution simulations affect the estimation of velocity profiles and the order of convergence by increasing the numerical errors e g for m 100 and r 80 l 2 v for q 1 increases from 0 5 to 0 9 and 1 3 by q 2 and q 4 respectively however adopting higher spatial resolutions decreases the errors with an order of convergence greater than one the numerical accuracy of our multi resolution mps model q 2 and 4 is consistent with the single resolution mps result of duan et al 2017 with r 40 which estimates the error as 1 33 1 31 and 1 32 for m 20 50 and 100 respectively also the order of convergence of our numerical results is compatible with the mps duan et al 2017 and sph yang et al 2022 methods reporting the order of convergence as 0 66 and 1 respectively particularly for m 100 considering that the shear force calculation i e η 2 v used in this study does not benefit from any high order approximation operators overall the order of convergence of the model and the numerical errors by the multi resolution implementations remain in an acceptable range 4 1 2 hydrostatic pressure in this 2d benchmark case two inviscid and immiscible fluids with identical heights fill a steady tank subjected to a constant gravitational force g 0 9 81 m s 2 t jandaghian et al 2021a rezavand et al 2020 the lighter phase ω 1 with the density of ρ 1 1000 kg m 3 is on the top of the heavier phase ω 2 with the density ratio of ρ 2 ρ 1 2 shown in fig 3 b the total fluid height h and the initial particle size of phase 2 l 0 2 determine the spatial resolution as r h l 0 2 we set c 0 ρ 0 and c cfl to 20 m s ρ 1 and 0 5 respectively we activate the diffusive term 15 with δ mps 0 2 while deactivate the dpc technique the fluid particles i ω f ω 1 ω 2 are initially located on a cartesian lattice the particle distribution of each phase is packed separately before starting the main simulations similar to the packing algorithm proposed by colagrossi et al 2012 the model assigns the initial hydrostatic pressure and the corresponding particle number density to the packed fluid particles jandaghian et al 2021a we simulate this test case for 10 s where the non dimensional time t is given by t g h the particle size ratio is denoted by q l 0 2 l 0 1 where q 1 and q 2 4 refer to the single and multi resolution simulations respectively to validate the numerical results compared with the theoretical hydrostatic pressure we extract the local pressure p e linearly averaged over the fluid particles within an influence radius of 1 5 l 0 2 from the extraction points e evenly distributed at x 0 05 0 10 and 0 15 m with δ y e 0 005 m identified as the delta markers in fig 3 b the normalized root mean square error of the pressure is calculated by l 2 p p max 1 1 n e e p e at y e p theoretical at y e 2 in which n e is the total number of extraction points the numerical error is normalized by the maximum theoretical pressure corresponding to each fluid phase i e if y e h 2 then p max 0 5 h ρ 1 g and if y e h 2 then p max 0 5 h ρ 1 ρ 2 g through this benchmark case we investigate the accuracy of the multi density model in predicting hydrostatic pressure fig 6 represents the particle distributions and pressure fields with r 100 and q 1 2 and 4 at t 10 s stable and uniform particle distribution exists at the interface of the multi resolution simulations where q 2 4 the implemented diffusive term ensures smooth pressure fields over the entire fluid domain we plot the local numerical pressures to compare with the hydrostatic pressure profile the graphs show good agreement between the numerical results and the theoretical pressure for all three cases to quantify the accuracy and the convergence order of the results we calculate the normalized root mean square error of the pressure parameter l 2 p for different spatial resolutions i e r 20 50 100 and 200 the numerical error is normalized by the maximum theoretical pressure corresponding to each fluid phase the particle rearrangement due to the assigned pressure field and the initial particle distribution at the interface oscillates the estimated error at the initial time steps until the simulation reaches a stable condition for t 40 fig 7 a the numerical errors of the single and multi resolution simulations reduce as we increase the spatial resolution of each fluid phase we represent l 2 p against l 0 1 l 0 2 2 in a log log plot in fig 7 b thanks to the conservative form of the approximation operators i e v and p and the effective diffusive term 15 the accuracy of numerical results proves to be independent of q where r 100 noting that l 2 p becomes negligible i e l 2 p 0 5 moreover the particle convergence study confirms that the accuracy of multi resolution simulations q 2 4 improves at the expected rate by increasing r as the order of convergence remains equal to 1 one should note that such a multiphase benchmark case has not been previously validated for convergence study of other single or multi resolution particle methods thus the quantitative analysis of this study is limited to validating the numerical results against the theoretical pressure field 4 2 dam break waves on erodible granular beds we simulate the water dam break over movable beds as a benchmark case of rapid fluid driven granular dynamics first we specify the main properties of this problem and the numerical model configurations we conduct a sensitivity analysis concerning the constant material parameters i e μ 2 a and b in the post failure terms of the visco inertial rheology equation and the suspension eq 25 we validate the results of the proposed multi resolution mps model against the available experimental data representing the simulated flow properties and discussing the phenomenology of the sediment erosion also we evaluate the role of multi scale water sediment interactions within the continuum based modeling of such multiphysics problem 4 2 1 problem characteristics and configurations we configure the two dimensional numerical model based on the experimental setup of spinewine and zech 2007 shown in fig 8 in this problem a column of water collapses under the gravitational force g 0 9 81 m s 2 t on sediment beds fully submerged in water the non cohesive sediment material consists of either coarse sand grains or polyvinyl chloride pvc pellets spinewine and zech 2007 table 1 represents their reference material properties assigned in the rheology eqs 22 25 the material constants of water are its reference density ρ 0 w 1000 kg m 3 and true viscosity μ w 0 001 pa s the flume s length is 2 l 6 00 considering different levels of sediment on the left side of the gate δ h b different geometrical configurations exist by δ h b 0 0 0 05 and 0 10 identified as cases a b and c respectively the upstream water level with respect to the downstream sediment level h is equal to 0 35 m and identical for all three experimental setups the gate located at the middle of the flume i e at x 0 0 is being lowered down with the nominal speed of 5 m s in the negative y direction spinewine and zech 2007 in continuum based modeling of granular material the particle size must be large enough to represent a sufficient number of grains so that the continuum assumption and hence the constitutive law remain valid guazzelli and pouliquen 2018 based on the sensitivity analysis conducted by jandaghian et al 2021a and ghaïtanellis et al 2018 for the sediment dynamics problems we fix the initial inter particle distance of mixture particles l 0 m to 0 005 m and 0 01 m for the sand and pvc bed materials respectively which correspond to 2 7 d g see fig 8 we define the particle size ratio q as the ratio of l 0 m to the initial inter particle distance of water particles l 0 w i e q l 0 m l 0 w a packed particle distribution is used for initializing the main simulations hydrostatic pressure determines the initial density and the effective pressure of the fluid particles at t 0 s jandaghian et al 2021a considering the third order polynomial spiky kernel of shakibaeinia and jin 2010 and k 3 1 for the approximation operators the reference normalization factor n 0 2 2414 which is independent of the spatial resolution of each phase to solve the governing equations we set c cfl and c v to 0 5 and 0 125 respectively and the reference sound speed c 0 to 40 m s the diffusive term with δ mps 0 6 and the dpc technique are implemented within all the simulations in this test case the viscous force is dominant thus the maximum viscosity i e η max of the mixture phase determines the time steps of the calculations through eq 28 which we have set to 4000 and 6000 pa s for the sand and pvc cases respectively to simulate the physical gate we implement the virtual gate vg technique proposed by jandaghian et al 2021a we characterize the dynamics of the immersed granular flow by the interface data i e the water free surface the dense sediment transport layer and the bed level the temporal evolution of the eroded area a e the first moment of the eroded area x c a e where x c is the geometric center of a e and the wavefront position x f from the experimental data provided by spinewine and zech 2007 and spinewine and capart 2013 identified on fig 8 b we extract the numerical results at time steps identical to the experimental data before the wave reaching the end of the flume which is at t 0 25 0 5 0 75 1 00 and 1 25 s for the sand case and t 0 25 0 5 0 75 1 00 1 25 and 1 50 s for the pvc case the non dimensional time t is given by t g h we normalize a e and x c a e by their corresponding reference values i e a e exp f and x c a e exp f which refer to the final data from the experiment at t 1 25 s for sand and at t 1 50 s for pvc respectively to detect the simulated eroded area we employ a velocity threshold for both water and mixture particles as v i ω f 0 25 ghaïtanellis et al 2018 and a minimum volume fraction value for water particles in the vicinity of the eroded mixture particles as ϕ i ω w ϕ 0 0 10 0 3 depending on the particle size fluid particles that satisfy the two conditions are identified as the eroded particles i ω ed through validating the simulated flow properties we justify the thresholds set in the detection conditions the numerical error of the sediment erosion parameters at t is given by e r numerical at t experimental at t exp f or l 1 normalized by the corresponding reference value we estimate the global normalized root mean square error i e l 2 by 1 n t 1 n t e r 2 where n t is the number of calculation steps equal to 5 and 6 for sand and pvc respectively 4 2 2 a sensitivity analysis of the rheology parameters the rheology model dynamically estimates the effective viscosity of the fluid particles as functions of the flow and material properties spinewine and zech 2007 reported the reference material parameters of the sand and pvc bed materials table 1 however the constant parameters in the post failure terms of the implemented visco inertial model i e μ 2 a and b remain unknown and should be calibrated here we analysis the sensitivity of the numerical results of case a to the rheology constants considering the suggested values in baumgarten and kamrin 2019 shi et al 2019 and lee et al 2016 also we quantify the role of the suspension eq 25 in the overall mechanical behavior of the sediment erosion to conduct the sensitivity analysis we plot the temporal evolution of a e x c a e and x f simulated by the single resolution mps model q 1 where μ 2 a and b vary as shown in figs 9 and 10 for the sand and pvc cases respectively each parameter changes while the other two parameters are equal to their reference values given in table 1 the graphs show that the bed load evolution with different parameters of the post failure terms remains almost alike tables 2 and 3 represent l 2 of each scenario and compare them with the errors of the reference model given in the first rows of the tables for both bed materials l 2 varies by less than 3 thus the sensitivity analysis confirms that the estimated sediment erosion is almost independent of the variation of the parameters μ 2 a and b in the specified ranges furthermore we simulate case a pvc where q 1 2 4 with and without implementing the suspension eq 25 in the rheology model table 4 shows that l 2 x f is almost identical for both conditions adding the suspension term slightly reduces l 2 a e and l 2 x c a e by 1 4 nevertheless the suspension term does not manipulate the overall sediment dynamics estimated by the single and multi resolution models the considerable incompatibility between the numerical simulations and the experimental measurements shown in the graphs of figs 9 and 10 and quantified in table 4 manifests the incapability of the single resolution model in capturing accurate flow evolution the continuum based numerical model ignores some physical properties of the water sediment mixing process associated with multi scale interactions and volume fraction variations no inter particle mass exchange occurs in the numerical simulations therefore the model neglects the microscopic fluid flow around and between solid grains and the effects of density changes in the rheology model 4 2 3 flow properties and interface data in this section we present and validate the dam break waves over erodible beds simulated by the multi resolution mps method where q 4 by reporting the longitudinal and vertical flow properties we discuss the global flow evolution and the non linear mechanical behavior of this rapid fluid driven problem the velocity magnitude v the effective viscosity as log 10 η the approximated volume fractions i e ϕ normalized by the reference volume fraction of the mixture phase ϕ 0 and the mixed number i m of cases a sand a pvc b sand and c sand at t 0 5 and t 1 0 seconds are illustrated in figs 11 12 13 and 14 respectively the figures include snapshots of the experiments and the interface data plotted over the numerical results except for the close up plots snapshots i e the inset figures with the black dash line boarder the vertical scale of the images is stretched by a factor of 1 5 to ease visualization of the profiles and flow evolution the numerical solution provides in depth details of the water sediment dam break flows as the top edge of the vertical gate reaches the bed level t 0 s the water column collapses on the water saturated sediment bed driving a thin layer of bed load toward the downstream after the sudden vertical collapse the wave propagates horizontally on the movable bed considering that the wavefront position advances a distance of 3 h in the positive x direction in less than 0 5 s the flow velocity increases uniformly from upstream to downstream the dam break surge exceeds a maximum velocity of 2 5 m s forming rapid erosional bores at the interface and the head of the wave as shown in the close up plots for all cases the surge celerity develops similarly independent from the initial configurations and or the sediment materials furthermore the effective viscosity field plotted as log 10 η illustrates the yielded and un yielded regions estimated by the regularized rheology formulation inside the bed high shear forces rapidly reduce the flow velocity toward the bottom of the flume i e in the negative y direction the spatial variation of volume fraction at the interface manifests the mixing of water and mixture particles from upstream to downstream the longitudinal concentration of mixture particles increases over the bed load layer close to the downstream wavefront the suspended mixture particles fill the entire flow depth well observed in case a with the pvc bed material spinewine and capart 2013 in the implemented model the approximated volume fraction is included in the shear force calculations through the effective viscosity terms the mixed number of the rheology model i m as a function of the strain rate magnitude and the effective pressure clearly distinguishes the suspended mixture particles where i m 0 6 for which the suspension eq 25 updates the effective viscosity the overall longitudinal flow evolution including water free surface the sediment transport layer thickness and the bed boundary are in reasonable agreement with the experimental interface data in all cases the high wave velocity causing highly dynamic sediment erosion creates irregular free surface profiles as rotated s like shapes which are particularly visible at t 0 5 s as the wave progresses on the horizontal beds shown at t 1 0 s the free surface curvature reduces and better agreement exists between the numerical and experimental measurements in the flat bed cases a sand and a pvc the sudden vertical surge forms a scour hole at the near dam region i e the gate s location partially captured by the numerical simulations also the calculated wavefront positions of these two cases match quite well with the experimental profiles at t 0 5 and 1 0 s in the case with a forward facing step of the saturated sediment material i e b sand where δ h b 0 05 m the un yielded bed is comparable with the measured bed profile even at the near dam region at x 0 however the bed boundary of the case with the backward facing step i e c sand where δ h b 0 10 m does not match with the experimental profile close to the gate s location this issue also affects the prediction of the free surface with stronger curvatures at x 0 25 0 5 m and underestimates the wavefront position at t 1 00 s also the numerical errors and ignoring the multi directional flow effects result in unphysical voids close to the wavefront the observed discrepancies can be attributed to the complex non linear flow behaviors and turbulence effects at the front of the wave which lead to non monotonous interface profiles and non equilibrium sediment transport fraccarollo and capart 2002 fig 15 shows the smoothness of the pressure fields in the water and mixture phases of case a with sand and pvc at t 1 0 seconds simulated by the multi resolution mps q 4 with the diffusive term 15 yet some local pressure noises exist close to the wavefront with high velocities the continuum based particle method struggles to accurately capture the instantaneous and local flow curvatures especially at t 0 5 s near the wavefront of case b sand and the gate s location of case d sand we should note that the adopted numerical formulation is incapable of directly simulating the dilatation and compaction effects on the immersed granular flows further the virtual gates see jandaghian et al 2021a ignore the gate s physical thickness and therefore the associated initial disturbance of its movement nevertheless the developed model simulates the overall flow evolution wave celerity and sediment erosion processes of the dam break problem comparable with the experimental measurements and snapshots moreover we compare the numerical results of the multi resolution mps model q 4 for case a pvc with the interface data of single resolution mps shakibaeinia and jin 2011 and sph ran et al 2015 models at t 0 25 0 5 and 0 75 s fig 18 considering the reference experimental data from spinewine and zech 2007 the proposed multi resolution mps method predicts a more accurate evolution of the free surface versus the single resolution mps method by shakibaeinia and jin 2011 also the single resolution incompressible sph isph by ran et al 2015 underestimates the wavefront propagation on the movable bed the proposed multi resolution particle method shows improvements in simulating this fluid driven granular flow in comparison with the two numerical results by shakibaeinia and jin 2011 and ran et al 2015 next we validate the internal flow properties of the numerical simulation of case a pvc against the available experimental measurements represented by spinewine and capart 2013 figs 16 and 17 spinewine and capart 2013 used a particle tracking analysis to measure the vertical velocity profiles u exp at 40 cross sections evenly distributed between x 0 95 and 2 95 m with δ x 0 10 m we extract the numerical velocity u num by linearly averaging the velocity magnitude of fluid particles at the vicinity of the extraction points with δ y 0 01 m on the same vertical cross sections fig 16 plots the fluid particles classified as the eroded and not eroded particles i e i ω ed and i ω ed respectively the extracted numerical velocity as x 0 05 u num and the experimental velocity as x 0 05 u exp at t 0 6 1 0 and 1 4 s the numerical model simulates the non linear velocity profiles with smooth variations at the top and base of the sediment transport layer the velocity profiles in the water layer remain uniform with maximum magnitudes at the free surface at t 1 4 s the model slightly underestimates the velocity near the wavefront x 2 5 nevertheless the estimated velocity matches the experimental profiles quite well over the entire fluid domain moreover we extract and compare the local granular concentration c and the sediment transport intensity defined as the product of c and u i e c and c u respectively spinewine and capart 2013 reported the corresponding experimental measurements limited to the granular layer at 13 laser instrumented vertical cross sections between x 0 05 and 1 5 m this data is from several experiments plotted on a single graph which have resulted into multiple values at the same vertical and horizontal positions spinewine and capart 2013 to estimate c num we linearly average the approximated volume fraction of the particles ϕ i ω f at the extraction points one should note that the experimental measurements are missing at x 1 25 m and t 0 6 s unlike the velocity profiles reported by the particle tracking analysis in fig 16 we plot x 0 1 c and x 0 15 c u over the fluid particles in the left and right graphs of fig 17 respectively the granular concentration keeps its maximum value ϕ 0 in the granular layer while reducing across the bed load layer toward the free surface at the top interface of the transport layer the granular concentration drops and further vanishes in the absence of the mixture particles in spite of some minor discrepancies the estimated numerical profiles are in good agreement with the experimental measurements the validation confirms that the numerical model can predict the non linear profiles with smooth variations across the bed load layer we should also highlight that the compatibility between the numerical and experimental profiles justifies conditions we have adopted to detect the eroded area through which we study the phenomenology of sediment erosion and quantify the numerical validations 4 2 4 phenomenology of the sediment erosion a e x c a e and x f to overview the phenomenology of the dam break waves over movable beds we compare the sediment dynamics of the different configurations fig 19 shows the wave propagation of cases a sand a pvc b sand and c sand on the horizontal beds at t 1 25 s the figure contains experimental snapshots and the interface data of the test cases further we plot the temporal evolution of the global erosion variables a e and x c a e and the wavefront position x f in fig 20 and represent the associated numerical errors in table 5 qualitatively the numerical simulations provide comparable flow evolution and predict the thickness of the transport layer at the center of the wave in all four cases the base of the transport layer is well captured however near the gate s location the rapid flow involves complex interface deformations affecting the numerical predictions as discussed earlier this incompatibility is more noticeable for case c sand with the backward facing step comparing case a pvc with the other configurations illustrates the sensitivity of sediment erosion to the density ratio i e ρ m ρ w the thickness of the transport layer increases significantly for case a pvc as the wave can mobilize more mixture particles on the other hand with the sand material i e with the heavier grains but with a smaller fiction angle in cases a b and c the transport layer is thinner thus the wave can progress further on the horizontal bed with less sediment erosion toward the downstream spinewine and capart 2013 fraccarollo and capart 2002 while the wavefront position of case a pvc matches well with the interface data the numerical simulation slightly underestimates the wave propagation speed of cases with the sand beds regardless of their initial configuration to quantitatively study the sediment dynamics fig 20 provides an overall overview of the sediment erosion concerning different configurations and bed materials the graphs of fig 20 show that the multi resolution mps model predicts the global behavior of the sediment erosion and wave prorogation particularly we observe that x c a e and x f of all four cases are in very good agreement with the experimental data for the light pvc material sediment erosion increases significantly as a e of a pvc is almost 2 5 times greater than a e of a sand at t 1 25 s for case c sand the wave interaction with the backward facing step increases the sediment erosion by 30 percents in comparison with cases a sand and b sand with the step like discontinuity of cases b and c the results are less satisfactory considering that the numerical model underestimates the sediment erosion at t 0 5 and 0 75 s table 5 represents the numerical errors of the sediment erosion parameters l 2 l 2 x f and l 2 x c a e remain less than 10 percents manifesting the acceptable accuracy of numerical model in simulating the flow evolution on the movable beds the results show that with the step like discontinuities l 2 a e increases by 10 percents from 8 5 for case a sand to 19 7 and 14 7 percents we attribute the numerical errors to the neglected role of granular dilatation and compaction in the adopted single phase rheology model this issue indirectly ignores the turbulence suspension effects of the microscopic pore water flow between solid grains within the numerical simulations spinewine and capart 2013 nevertheless the multi resolution mps model proves to be capable of predicting the global behavior of the fluid driven granular dynamics with reasonable numerical accuracy 4 2 5 role of multi scale simulations here we discuss the role of multi scale interactions in sediment erosion modeling to do so we compare the interface data of case a simulated by the single and multi resolution models figs 21 and 22 represent the eroded region i ω ed of case a with the sand and pvc bed materials respectively in these figures except for the close up plots the vertical scale is stretched by a factor of 5 0 flow evolution of the water and mixture particles at t 0 75 and 1 25 s shows that the single resolution model q 1 underestimates the wavefront position this discrepancy between the numerical and experimental results is more noticeable for the sand case with a higher density ratio on the other hand the multi resolution models q 2 4 predict more flow deformations at the interface increasing erosion of the mixture particles although the continuum based modeling still misses some physical aspects of sediment erosion i e the pore water flow between the solid grains and the associated changes in the volume fraction of the mixture particles the multi resolution particle interactions allow the numerical model to capture more accurate flow evolution related to the multi scale feature of water sediment dynamics to quantify the numerical validations we plot the temporal evolution of a e x c a e and x f and compare them with the experimental data fig 23 the profiles manifest improvements in estimating the sediment erosion by the multi resolution model with q 4 while the single resolution model underestimates the granular flow evolution the remaining incompatibility between the numerical and experimental profiles especially for the eroded area of case a pvc at t 3 originate from complex water sediment mixing processes at the interface that the continuum based particle method is incapable of simulating table 6 represents the normalized root mean square error l 2 of the sediment erosion parameters the quantified results show a significant reduction in the numerical errors by the multi resolution simulations by a factor of 2 4 with respect to the single resolution results moreover we illustrate the velocity distribution of each resolution q 1 2 and 4 at the interface for case a pvc in fig 24 a and b the velocity fields fig 24 a show that the single resolution model underestimates the wave velocity on the movable bed on the other hand the multi resolution model simulates more flow deformation leading to higher velocity magnitudes over the wavefront fig 24 b compares the extracted velocity profiles with the experimental profiles by spinewine and capart 2013 plotted as the black x markers the velocity profiles estimated by the multi resolution model q 4 are in better agreement with the experimental data compared with the single resolution model q 1 also to evaluate the global mechanical behavior of the sediment flow we plot the global kinetic energy of the mixture particles e k 0 5 ρ 0 i l 0 i 2 v i 2 for i ω m which is independent of the conditions used for detecting the eroded area fig 25 for case a e k of the multi resolution model where q 4 is two to three times greater than e k of the single resolution model where q 1 for both bed materials overall we observe that the developed multi resolution model considerably reduces the errors of the single resolution simulations by estimating more flow and sediment erosion at the interface 5 conclusion in this study we proposed and validated a new form of governing equations based on the enhanced weakly compressible mps method to incorporate multi scale water sediment interactions within the continuum based numerical modeling to do so we presented a novel multi resolution mps formulation supplied with particle enhancement technique to investigate the mechanical behavior of fluid driven granular dynamics first simulating two benchmark cases i e the multi viscosity poiseuille flow and the multi density hydrostatic pressure problems we studied the accuracy and convergence of the numerical results with the single and multi resolution models as for the fluid driven granular erosion we adopted the generalized rheology equation to model the two dimensional dam break waves on erodible sediment beds we presented and discussed the mechanical behavior of this benchmark case for various configurations i e with the flat bed and the step like discontinuities and bed materials i e the sand and pvc granules we analyzed the sensitivity of sediment dynamics to the added suspension equation and the constant material parameters of the rheology model through comprehensive numerical validations we studied the flow evolution and mechanical properties of the sediment erosion induced by the rapid water waves moreover we compared the numerical results of the single and multi resolution simulations to evaluate the role of multi scale interactions in capturing the global behavior of this benchmark case the particle convergence study on the two numerical benchmark cases confirms that the proposed multi resolution formulation predicts the analytical results with acceptable accuracy for the multi viscosity poiseuille flow the multi resolution shear force respects the convergence behavior of the numerical model and keeps the errors of the velocity profiles to less than 2 for the multi density hydrostatic pressure the conservative governing equations ensure the accuracy and stability of the results with errors less than 0 5 in both cases increasing the spatial resolution the numerical results converge to the analytical profiles with the convergence order greater than one for the dam break waves on movable beds the developed numerical model provides in depth details of the water sediment mixing processes and the global behavior of sediment dynamics the nonlinear vertical velocity and granular concentration profiles of the flat bed with pvc are well estimated simulating different geometrical setups with the sand and pvc granules clarifies that the sediment dynamic greatly depends on the mobility of the bed materials i e the density ratio ρ m ρ w supporting the theoretical analysis by spinewine and capart 2013 and fraccarollo and capart 2002 in the flat bed configuration the eroded sediment and the thickness of the transport layer increase with the light pvc material by a factor of 2 5 compared with the case with the sand grains the step like discontinuities lead to complex bed load evolution close to the gate s location and slightly increase the mobility of the bed material at the initial stages of erosion regardless of the initial configuration in cases with sand the wave propagates on the horizontal bed with almost identical bed load layer thickness and speed in general the multi resolution mps method proves to be capable of simulating the sediment erosion at the interface and the wavefront position despite the local discrepancies the interface data and the flow evolution match well with the experimental measurements moreover we observe that the multi resolution model captures more interface deformations in comparison with the single resolution model that underestimates sediment erosion the results presented highlight the importance of multi scale multiphase water sediment interactions in numerical simulations of such a rapid fluid driven problem it is worthwhile to employ the developed particle method for studying multi directional granular flows with applications to industrial and hydro environmental problems further enhancements of the numerical and rheological models should be considered for predicting granular flow regimes in more complex situations than the validation test cases that exists in engineering problems for the three dimensional simulations the neighbor particle search algorithm can be adapted to the multi resolution particle interactions e g by setting different cell domains for each particle size neighbor search to reduce the associated computational costs the proposed multi resolution formulations can be extended to two phase mixture models e g baumgarten and kamrin 2019 shi et al 2019 to investigate the effects of dilatation and compaction on the mechanical behavior of immersed granular flows furthermore the multi resolution mps method can be further validated to high density ratio problems and coupled with dynamic particle merging and splitting techniques to simulate violent free surface flows jandaghian et al 2021b rezavand et al 2020 and fluid structure interactions zhang et al 2020 khayyer et al 2019 credit authorship contribution statement mojtaba jandaghian conceptualization methodology validation formal analysis investigation visualization writing original draft ahmad shakibaeinia conceptualization methodology supervision project administration writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the financial support of the natural sciences and engineering research council of canada nserc and polytechnique montréal canada this study used the high performance computing hpc resources of compute canada and calcul quebec as well as a local server acquired using canada foundation for innovation cfi support appendix a supplementary data movies of the simulations are available online supplementary material related to this article can be found online at https doi org 10 1016 j advwatres 2023 104488 appendix a supplementary data the following is the supplementary material related to this article video s1 a video summarizing the numerical methodology and results 
12,granular dynamics driven by fluid flow is ubiquitous in many industrial and natural processes such as fluvial and coastal sediment transport yet their complex multiphysics and multi scale nature challenge numerical models accuracy and efficiency here we develop a new multi resolution mesh free particle method based on an enhanced weakly compressible moving particle semi implicit mps method to study the dynamics of rapid fluid driven granular erosion we propose and validate a novel multi resolution multiphase mps formulation for the consistent and conservative form of the governing equations including particle stabilization techniques first we discuss the numerical accuracy and convergence of the proposed approximation operators through two numerical benchmark cases the multi viscosity poiseuille flow and the multi density hydrostatic pressure then coupling the developed model with a generalized rheology equation we investigate the water dam break waves over movable beds the particle convergence study confirms that the proposed multi resolution formulation predicts the analytical solutions with acceptable accuracy and order of convergence validating the multiphase granular flow reveals that the mechanical behavior of this fluid driven problem is highly sensitive to the water sediment density ratio the bed with lighter grains experiences extreme erosion and interface deformations for the bed with a heavier material but different geometrical setups the surge speed and the transport layer thickness remain almost identical away from the gate furthermore while the multi resolution model accurately estimates the global sediment dynamics the single resolution model underestimates the flow evolution overall the qualitative and quantitative analysis of results emphasizes the importance of multi scale multi density interactions in fluid driven modeling graphical abstract keywords multi resolution particle method numerical stability and convergence multiphase flows immersed granular flows dam break erosion data availability data will be made available on request 1 introduction many hydro environmental and geotechnical problems involve the multiphase flow of granular material like sediment immersed in a fluid like water fig 1 a in such multiphysics systems the granular phase demonstrates dynamic solid and fluid like behaviors induced by gravity and the ambient fluid flow e g in the cases of submarine landslides robbe saule et al 2021 pilvar et al 2019 bougouin and lacaze 2018 rondon et al 2011 balmforth and kerswell 2005 and fluvial and coastal sediment transport lobkovsky et al 2008 fraccarollo and capart 2002 brooks and lawrence 1999 particularly rapid shearing flows over granular beds cause large interfacial deformations leading to the erosion suspension and deposition of grains guazzelli and pouliquen 2018 the complex and simultaneous presence of the quasi static dense flow and kinetic suspended regimes jop 2015 makes the accurate prediction of such immersed granular flows challenging over the past decades experimental and theoretical studies have focused on representing physical and mathematical models for multiphase granular flows mechanical behavior in various flow conditions e g stickel and powell 2005 cassar et al 2005 huang et al 2012 li et al 2022 numerical methods have been introduced as an alternative for investigating the underlying physics of immersed granular flow e g chauchat and médale 2010 amarsid et al 2017 baumgarten and kamrin 2019 hu et al 2021 yet their numerical accuracy and stability are subjects of ongoing studies and rely on the constitutive laws mostly developed through experiments and theories e g jop et al 2006 pouliquen and forterre 2009 for dealing with different stress conditions and pore pressure effects of the water sediment interactions baumgarten and kamrin 2019 these issues with numerical methods along with their computational costs affect their applicability to engineering problems and thus further developments and validation of numerical formulations become essential this paper studies fluid driven granular dynamics through a consistent numerical method discrete based and continuum based numerical approaches have been widely developed for simulating immersed granular flows while discrete based methods such as the discrete element method dem cundall and strack 1979 provide an in depth grain scale understanding of the granular behavior they are computationally expensive for practical problems that involve a large volume of materials on the other hand the continuum based numerical methods homogenize the assembly of solid grains or the mixture of solid granules and interstitial fluid into a body of continuum at the macroscopic level fig 1 b thus they are scalable and computationally affordable for large scale modeling such methods employ a rheology model to estimate the mechanical behavior of the granular continuum guazzelli and pouliquen 2018 the continuum based models treat the dense multiphase granular flow system using either single continuum or two continuum models guazzelli and pouliquen 2018 jop 2015 the single continuum models consider the solid grains and interstitial pore fluid as a single uniform dense mixture the mixture interacts with the ambient fluid phase directly through one set of governing equations the two continuum models simulate the relative motion of the interstitial fluid and the solid grains and solve separate sets of governing equations including inter phase forces guazzelli and pouliquen 2018 pailha and pouliquen 2009 unlike the single continuum model the two continuum model considers the effects of volume fraction variations i e the pore water flow into the porous phase in the constitutive formulations baumgarten and kamrin 2019 pailha and pouliquen 2009 in both approaches the numerical element representing the continuum i e the representative elementary volume v in fig 1 b must be large enough to contain a sufficient number of solid grains otherwise the continuum assumption and the constitutive law would become invalid jandaghian et al 2021a guazzelli and pouliquen 2018 rycroft et al 2009 on the other hand the numerical element should be small enough with respect to the characteristic length scale of the problem to mathematically represent its vicinity and minimize the numerical approximation errors jandaghian et al 2021a ghaïtanellis et al 2018 baveye and sposito 1984 the computational model shall respect these two conflicting constraints in determining the spatial resolution of the discretized domain moreover to capture highly dynamic and high reynolds number fluid flows the numerical solution requires a higher spatial resolution for the fluid phase e g v 4 than that of the granular or mixture accordingly one can conceive a multi resolution approach for simulating the fluid driven granular flows fig 1 c d mesh based continuum methods have been developed for various granular simulations rauter 2021 lacaze et al 2021 however due to their mesh dependency they require particular treatments to deal with highly dynamic interfaces selçuk et al 2021 rycroft et al 2020 in contrast mesh free lagrangian continuum methods or simply particle methods discretize the continuum using moving particles without any connectivity fig 1 c this feature of particle methods introduces them as reliable numerical approaches for handling interfacial deformations and hence suitable for highly dynamic granular flows luo et al 2021 feng et al 2021 shakibaeinia and jin 2012a the material point method mpm sulsky et al 1994 the moving particle semi implicit mps method koshizuka and oka 1996 and the smoothed particle hydrodynamics sph method gingold and monaghan 1977 are some of the most widely adopted continuum particle methods we establish the numerical method of this study based on the mps formulation sph and mps have gone through significant developments to improve their accuracy and stability for highly dynamic and multiphase flows antuono et al 2021 jandaghian et al 2022 2021b rezavand et al 2020 duan et al 2017 khayyer et al 2017 shakibaeinia and jin 2012b shakibaeinia and jin 2010 introduced the weakly compressible mps method wc mps jandaghian and shakibaeinia 2020 and jandaghian et al 2021b enhanced the accuracy and stability of the wc mps method by proposing artificial diffusive terms and particle regularization techniques such methods coupled with various constitutive laws in either single or two continuum modeling approaches have simulated immersed granular flows in the single continuum particle methods the adopted rheological models include the bingham plastic formulation nabian and farhadi 2017 khanpour et al 2016 rodriguez paz and bonet 2004 the herschel bulkley model shakibaeinia and jin 2011 rodriguez paz and bonet 2004 the herschel bulkley papanastasiou model fourtakas and rogers 2016 the regularized μ i equation by jop et al 2006 qi et al 2022 jandaghian and shakibaeinia 2019 tajnesaie et al 2018 jafari nodoushan et al 2018 the elastic viscoplastic model ghaïtanellis et al 2018 and the generalized rheology model jandaghian et al 2021a moreover to improve the prediction of the incipient motion of the granular particles some methods employed an additional yielding threshold based on shields erosion criterion zubeldia et al 2018 khanpour et al 2016 manenti et al 2012 as for the two continuum models sph methods have been employed for studying sediment dynamics in the immersed condition e g see bui and nguyen 2017 pahar and dhar 2017 shi et al 2019 although such models can simulate the effects of pore water flow through the continuum solid phase yet empirical equations parameters are used in the system of equations for the inter phase forces and the solid phase stress model shi et al 2021 also the presented two continuum particle methods do not benefit from the recent numerical enhancement techniques like the high order diffusion terms and the particle regularization techniques in their governing equations while the previous particle methods have mostly focused on gravity driven granular flows a few have attempted to simulate fluid driven cases several multi resolution sph and mps methods have been proposed and validated for improving numerical accuracy and capturing more accurate flow solid deformations over a refined computational domain they implement dynamic particle splitting and merging liu and zhang 2021 tanaka et al 2018 vacondio et al 2013 adaptive particle refinement yang et al 2021 chiron et al 2018 barcarolo et al 2014 overlapping methods bellezi et al 2022 yamada et al 2021 shibata et al 2017 and volume adaptive scheme sun et al 2020 such multi resolution methods are employed for various single phase and multiphase flows e g liu and zhang 2021 sun et al 2018 omidvar et al 2013 and fluid structure interactions e g khayyer et al 2021 2019 zhang et al 2020 sun et al 2019 nevertheless no multi resolution particle method has been reported for multiphase granular flows on the development of single continuum wc mps methods for multiphase granular flows shakibaeinia and jin 2011 2012a developed the original form of their multiphase wc mps shakibaeinia and jin 2012b to study immersed granular flows by simulating water dam break over the erodible bed and the sand discharge into still water this method was further validated to two dimensional sub aerial and submerged granular collapse test cases jafari nodoushan et al 2018 tajnesaie et al 2018 jandaghian and shakibaeinia jandaghian et al 2021a developed the multiphase model of their enhanced wc mps method presented by jandaghian and shakibaeinia 2020 for free surface flows to simulate three dimensional gravity driven immersed granular collapse and slide they introduced the regularized form of a visco inertial rheology model including the consistent effective pressure term for rapid granular deformation with non hydrostatic pore water pressure and without shear stress threshold these previous developments have been based on the mps interpolants for single resolution particle interactions in the present study we propose a novel multi resolution particle method based on the enhanced wc mps formulation by jandaghian and shakibaeinia 2020 and jandaghian et al 2021a b to investigate the mechanical behavior of immersed granular dynamics primarily driven by rapid fluid flow to that end here we present the novelties of this work from the numerical and physical perspectives we propose new approximation operators respecting the conservative properties of the multi scale multiphase system the new discretized form of governing equations include multi density multi viscosity interactions of water and mixture particles with different volumes to ensure numerical stability and avoid unphysical pressure oscillations which can largely affect the granular yield behavior we adapt the modified diffusive term jandaghian et al 2021a and the dynamic particle collision dpc technique jandaghian et al 2021b to the newly developed multi resolution framework for the first time we couple a multi resolution particle method with the generalized rheology model jandaghian et al 2021a supplied with a suspension equation for rapid and immersed granular flows thus we extend the validation of the implemented rheology formulations including the consistent effective pressure to fluid driven granular flows through a quantitative and qualitative analysis of numerical results of a benchmark case i e water dam break waves on erodible sediment beds spinewine and zech 2007 spinewine and capart 2013 we provide a comprehensive study on the dynamics of rapid sediment erosion induced by a sudden collapse of a water column we present internal flow properties and the global mechanical behavior of this fluid driven problem we also parameterize the rheology and analyze the phenomenology of sediment dynamics concerning different bed materials and initial configurations of the test case moreover comparing the results of the single and multi resolution mps simulations we evaluate the role of multi scale interactions in capturing the flow evolution we derive the novel multi resolution mps method coupled with the rheology model in section 3 following the equations of motion represented in section 2 first we study the numerical accuracy and convergence of the multi resolution formulation through two multiphase benchmark cases i e the multi viscosity poiseuille flow and the multi density hydrostatic pressure section 4 1 next we investigate water dam break waves on erodible sediment beds in section 4 2 at the end we review the overall results and concluding remarks of this study in section 5 2 equations of motion here the system of granular material and the ambient fluid is considered as a multiphase continuum which in a lagrangian framework is described by the continuity equation 1 d ρ d t ρ v the momentum equation 2 d v d t t ρ f and the advection equation 3 d r d t v calculating the time evolution d d t of the fluid density ρ velocity v and position r respectively panton 2013 the total stress tensor t consists of the pressure scalar value p and the shear stress tensor τ as t p i τ i being the identity matrix and ρ f is the body force per unit volume considering the barotropic fluids the equation of state calculates the pressure i e p f ρ for incompressible fluid flows i e considering v 0 the divergence of the stress tensor reduces to 4 t p η 2 v which is valid for newtonian and non newtonian mechanical behaviors one should note that in the shear force calculation the term η is neglected compared to the magnitude of η 2 v shakibaeinia and jin 2011 constitutive laws determine η as a function of hydrodynamic and material characteristics guazzelli and pouliquen 2018 for water we include a simple turbulence model based on the large eddy simulations in the shear force calculations we treat the mixture phase as a non newtonian fluid through the visco inertial rheology model proposed by baumgarten and kamrin 2019 and then represented in the regularized form by jandaghian et al 2021a 3 a consistent multi resolution multiphase mps method 3 1 integral and summation interpolants in continuum based particle methods the approximation operator transforms the integral representation of functions into the summation interpolant by discretizing the computational domain ω moving calculation points or simply particles carry flow and material properties liu and liu 2003 here we adopt the general integral formulation of the mps method to derive the new summation operator of the multi resolution model mps integral representation of an arbitrary function f r reads koshizuka et al 1998 5 f r ω f r w r r r e d v ω w r r r e d v where d v is a differential volume element the positive non dimensional weighting function w so called the kernel with a compact support smooths f over the influence radius r e mps introduces a normalization factor denoted by n 0 into the equations which corresponds to the reference physical fluid density ρ 0 and the mass of volume element m 0 via 6 n 0 ρ 0 m 0 ω w r r r e d v n 0 only depends on the type of kernel and the ratio of r e to the size of spatial discretization l 0 i e k r e l 0 souto iglesias et al 2013 the original mps formulation uses 6 to rewrite the integral representation 5 as 7 f r 1 n 0 v 0 ω f r w r r r e d v where the reference volume is v 0 m 0 ρ 0 koshizuka and oka 1996 souto iglesias et al 2013 in the mps particle system considering identical spatial resolution and smoothing length over the computational domain i e where l 0 i l 0 j and r e i r e j as l 0 i and r e i stand for the initial particle spacing and the smoothing length of i respectively the summation operator of 7 reads 8 f i 1 n 0 i j n f j w r ij r e i for a target particle i ω surrounded by n number of neighbor particles identified as j ω where r ij r j r i r e i the standard mps method adopts 8 to discretize the fluid flow governing eqs 1 and 2 here we introduce a new form of 8 to take into account the multi resolution particle interactions i e where l 0 i l 0 j and r e i r e j to that end with a constant k for the entire computational domain and v 0 r e k d we employ 6 to rewrite 5 as 9 f r 1 n 0 ω f r w r r r e k d r e d d v where d is the number of space dimensions without any assumption regarding the spatial resolution we derive a new formulation for the kernel identified as w through the general form of approximation operator 10 f i 1 n 0 i j n f j w r ij r e ij v 0 j where the new non dimensional kernel would be 11 w ij w r ij r e ij v 0 j w r ij r e ij v 0 j k d r e ij d in eq 11 v 0 i being the reference volume of particle is equal to l 0 i d for incompressible fluid flows to respect the symmetric feature of the smoothing procedure in the governing equations see section 3 2 and fig 2 we have substituted r e with r e ij r e i r e j 2 similar to the formulations used by sun et al 2017 and tanaka et al 2018 the new definition of particle approximation operator 10 unlike the standard formulation 8 includes the multi resolution particle interactions with different smoothing lengths where v 0 i v 0 j while in the same resolution interactions where v 0 i v 0 j the kernel 11 automatically reduces to its original shape as w ij w r ij r e i by neglecting the kernel truncations at the interfaces and away from boundaries n 0 keeps its standard definition as the summation of kernel at the initial uniform distribution of particles i e n 0 max i j n w r ij r e i at t 0 thus it can be identified as a global constant for all the particle sizes and their interactions as k r e i l 0 i is invariable over ω in this study we set k 3 1 and use the third order polynomial spiky kernel function shakibaeinia and jin 2010 for all the approximation operators 3 2 the discrete system of flow equations in particle methods for immersed granular flows the moving particles are the representative elementary volume of the ambient water phase ω w or the mixture of pore water and solid grains ω m or the solid walls ω s forming the computational domain ω where ω w ω m would be the fluid phase ω f and ω ω f ω s using the summation operator for a target particle i ω f the flow equations read 12 1 n i d n i d t v i d i m d v i d t 1 ρ i p i 1 ρ i η 2 v i f i d r i d t v i in which n i is the non dimensional particle number density given as n 0 ρ i ρ 0 i and independent of the density discontinuity at the interfaces jandaghian et al 2021a in this model the momentum equation considers the density of particle ρ i to be equal to the reference density of the fluid phase respecting the original form of the incompressible mps method i e in the momentum equation ρ i ρ 0 i where for i ω w ρ 0 i ρ 0 w and i ω m ρ 0 i ρ 0 m ρ 0 w 1 ϕ 0 ϕ 0 ρ g as ϕ 0 and ρ g are the reference volume fraction and the true density of the solid grains respectively for the multi resolution multi phase mps model we use the new kernel 11 to discretize the right hand side terms of 12 based on the conservative wc mps formulation jandaghian and shakibaeinia 2020 13 v i d n 0 i j n n j n i v j v i r ij e ij w ij p i d n 0 i j n n i p j n j n j p i n i e ij r ij w ij η 2 v i 2 d n 0 i j n η ij v j v i r ij 2 w ij e ij r ij r ij is the unit direction vector and the harmonic mean of the dynamic effective viscosity of i and j i e η i and η j gives η ij 2 η i η j η i η j with the new kernel function the interaction of particles with various size and density remains anti symmetric within the governing equations thus the conjugate gradient and divergence operators ensure the conservation of the total energy in the absence of shear and external forces see price 2012 and jandaghian and shakibaeinia 2020 fig 2 here similar to other multiphase particle methods developed for granular flows e g ghaïtanellis et al 2018 shakibaeinia and jin 2011 jafari nodoushan et al 2018 we considered η i 0 in the shear force calculation one should note that estimating the viscosity term through the divergence of shear stress tensor i e using τ i instead of η 2 v i may affect the accuracy of the calculations and the anti symmetric feature of the particle interactions depending on the adopted approximation operators discussed by jafari nodoushan et al 2018 considering the barotropic fluid as a weakly compressible phase we employ the equation of state to calculate the pressure by shakibaeinia and jin 2010 14 p i b 0 n i n 0 γ 1 where the bulk modulus b 0 c 0 2 ρ 0 γ and γ 7 are constant for all the fluid phases as ρ 0 and c 0 are the true density and the artificial sound speed of the reference phase respectively here we consider water as the reference phase thus ρ 0 ρ 0 w and c 0 c 0 w to limit the compressibility to less than 1 the reference sound speed should satisfy c 0 10 v max condition by which the mach number is kept less than 0 1 v max being the maximum expected velocity magnitude next we adapt the modified diffusive term by jandaghian et al 2021b to the multi resolution framework with the new kernel 11 as follows 15 d i m δ m p s δ t c 0 2 n 0 2 d n 0 i j n n j n i 1 2 n i c n j c r ij w ij r ij 2 in which n i c is the high order gradient operator of n i estimated by 16 n i c d n 0 i j n n j n i r ij c i e ij w ij and the correction matrix c i is given as 17 c i d n 0 i j n r j r i r ij e ij w ij 1 where stands for the outer product of vectors the non dimensional coefficient 0 δ m p s 1 the calculation time step δ t and c 0 adjust the magnitude of this numerical correction the diffusive term obeys the mass conservation law if i n i v i d i m 0 as v i n 0 v 0 i n i from 6 with i j ω f in 15 17 the diffusive term would be an anti symmetric formulation which conserves the total mass of the multi resolution multiphase system 3 3 dynamic particle collision for multi scale multiphase interactions here we implement the dynamic pair wise particle collision dpc method proposed by jandaghian et al 2021b as the particle regularization technique which ensures the numerical stability by eliminating particle clustering and high frequency pressure noises considering the velocity variation of two particles colliding with different masses and volumes we develop the dpc formulation for the multi resolution multi phase interactions as 18 δ v i i j n κ ij 2 m 0 j m 0 i m 0 j v ij coll δ t ρ 0 i i j n α ij 2 v 0 j v 0 i v 0 j p ij b r ij e ij where i j ω f and m 0 i ρ 0 i v 0 i the collision velocity v i j coll and the binary multiplier α i j are given by 19 v ij coll α ij v ij e ij e ij 0 for v ij e ij 0 0 1 otherwise and the dynamic background pressure p i j b is defined as p ij b p ij χ ij where p ij max min λ p i p j λ p max p min χ i j w r ij l 0 ij w 0 5 l 0 ij l 0 ij 0 5 the non dimensional variable χ ij is a function of the kernel with the smoothing length set to l 0 ij l 0 i l 0 j 2 where for r ij l 0 ij χ ij 0 the preset maximum and minimum pressure of the test case p max and p min respectively and the non dimensional constant λ specify the strength of the repulsive term for the collision term the variable coefficient κ ij dynamically sets the coefficient of restitution as a function of r ij via 20 κ ij χ ij 0 5 l 0 ij r ij l 0 ij 1 r ij 0 5 l 0 ij eventually δ v i from 18 updates the velocity and position of particles within the solution algorithm i e we have v i v i δ v i and r i r i δ v i δ t the proposed dpc through eqs 18 20 conserves the linear momentum of the multi resolution multi phase particle interactions i e with i j ω f then i m 0 i δ v i 0 in this study we use the wendland kernel for χ ij and set λ 0 2 jandaghian et al 2021b 3 4 generalized rheology model we employ the generalized rheology model of jandaghian et al 2021a for calculating the effective viscosity of the water and mixture particles for water as a newtonian fluid with the true viscosity μ w the effective viscosity increases by the presence of solid grains i e with the approximated volume fraction ϕ i defined by 24 and including the turbulence effect 21 i ω w η i μ w 1 5 2 ϕ i ρ 0 w ν t i as the eddy viscosity is given by ν t i c s r e i 2 γ i and the smagorinsky constant coefficient is set to c s 0 12 the pressure imposed rheology treats the mixture of water and solid grains as a non newtonian fluid through the mixture effective viscosity formulated by η i μ i p g i γ i in which p g i is the solid grains normal stress i e the effective pressure μ i is the friction coefficient and γ i is the magnitude of strain rate tensor guazzelli and pouliquen 2018 with the visco inertial model of baumgarten and kamrin 2019 as the friction coefficient and the regularized formulation for avoiding the singularity issue when γ i 0 jandaghian et al 2021a represented the effective viscosity of the mixture particles as i ω m η i τ y i γ i 2 λ r 2 μ 2 μ 1 p g i b p g i d g 2 ρ g 2 μ w γ i λ r γ i 22 5 ϕ i 2 a μ w p g i γ i 2 d g 2 ρ g 2 μ w γ i λ r 2 where a and b are material constants the upper and lower limits of the solid grains friction are denoted as μ 2 and μ 1 tan θ respectively ρ g d g and θ stand for the true density the mean diameter and the internal friction angle of the solid grains respectively the yield stress τ y is given by the drucker prager yield criteria as τ y i 2 3 sin θ p g i 3 sin θ noting that p g i 0 the regularization parameter λ r is set to 0 001 for incompressible fluid flows γ i 4 i i e i as the strain rate tensor e i 0 5 v i c v i c t and its second principal invariant i i e i 0 5 e i e i for the derivation of 22 readers are referred to jandaghian et al 2021a we estimate the gradient of velocity and the volume fraction of the water and mixture particles through 23 v i c d n 0 i j n v j v i r ij c i e ij w ij and 24 ϕ i j n ϕ j w ij j n w ij respectively noting that for j ω w ϕ j 0 and j ω m ϕ j ϕ 0 the non dimensional parameters i e the inertial number i i γ i d g ρ g p g i the viscous number i ν i μ w γ i p g i and the mixed number i m i 2 2 i ν govern the visco inertial rheology model amarsid et al 2017 boyer et al 2011 this model is validated against the experimental data of immersed granular flows where i m 0 6 baumgarten and kamrin 2019 in rapid fluid driven granular erosion mixture particles at the interface are subjected to high shear forces leading to their suspension with low volume concentration in the dilute and semi dilute conditions the dynamic viscosity turns to be a function of the volume fraction and independent of the shear rate magnitude guazzelli and pouliquen 2018 thus to incorporate the role of suspension effects we calculate the effective viscosity of the mixture particles where ϕ i ϕ 0 0 5 or i m i 0 6 through the suspension equation of vand 1948 25 η i μ w exp 2 5 ϕ i 1 39 64 ϕ i coupling the visco inertial formulation with the vand s equation aims at simulating the suspension process of mixture particles previously zubeldia et al 2018 and fourtakas and rogers 2016 used this equation with the herschel bulkley papanastasiou constitutive model for sediment dynamics modeling in sph one should not that our implemented constitutive model treats the different regimes of the immersed granular flow through the failure and post failure terms and the suspension equation without any shear stress threshold e g shield s erosion criterion in zubeldia et al 2018 and khanpour et al 2016 to distinguish the yielded particles from the un yielded ones moreover we implement the consistent effective pressure p eff i proposed by jandaghian et al 2021a to estimate p g i of the immersed granular flow where for i ω m p g i p eff i and 26 p eff i b 0 n i n 0 γ ρ w i ρ 0 w γ in which the density of the pore water ρ w i is updated by its continuity equation derived for the single phase continuum model as follows 27 1 ρ w i d ρ w i d t v i d i m the right hand side of 27 is identical to the right hand side of the continuity equation used for updating n i in 12 overall the dynamic viscosity of the water and mixture particles is calculated through eqs 21 22 and 25 as functions of the material properties the strain rate tensor the volume fraction and the effective granular pressure the multi viscosity particle interactions within the system of eqs 13 are modeled by the harmonic mean of viscosity η ij adopted for the shear force term shakibaeinia and jin 2012b duan et al 2017 3 5 boundary conditions and solution algorithm in the numerical model the fixed boundary particles i ω s simulate the solid walls the fluid particles interact with the solid boundary particles through the governing eqs 13 jandaghian et al 2021a to update the pressure of the wall boundary particles p i we implement the dynamic solid boundary condition by crespo et al 2015 the pressure of the closest wall particle is assigned to the ghost particles the velocity of the solid boundary particles v i is considered to be zero in the continuity equation of fluid particles in the shear force calculations the velocity assigned to the solid boundary particles applies slip or no slip boundary conditions for viscous flow simulations we consider the viscosity of the fluid particle for the boundary particle i e η j ω s η i ω f in η 2 v i for solving the governing equations we implement the second order and explicit symplectic time integration scheme represented by jandaghian et al 2021a the time step of calculation δ t is given based on the courant friedrichs lewy cfl stability condition and the shear force corresponding to the density the spatial resolution and the dynamic viscosity of each phase i e ω w and ω m as follows 28 δ t min c cfl l 0 c 0 c v ρ 0 l 0 2 η max ω w m in which c cfl and c v are non dimensional coefficients of the time steps identical for both phases and η max is the maximum expected dynamic viscosity considering ω w as the reference phase for the bulk module in 14 we set the sound speed of the second phase as c 0 m c 0 w ρ 0 w ρ 0 m 4 results and discussions the reliability of water sediment dynamics modeling depends on the accuracy of the approximated governing equations and their capability in capturing the multiphysics flow properties to investigate the consistency of the proposed multi resolution mps formulation we begin with studying the numerical accuracy and convergence of two benchmark cases i e the multi viscosity poiseuille flow and the hydrostatic pressure of two fluid phases section 4 1 then we investigate and validate rapid fluid driven granular erosion through simulating dam break waves over movable beds section 4 2 a movie containing the numerical simulations and results is provided as the supplementary data of this paper 4 1 numerical accuracy and convergence of the multi resolution mps model here we evaluate the numerical accuracy of the multi resolution operator in estimating the shear force by modeling the multi viscosity poiseuille flow further we simulate the hydrostatic pressure of two fluid phases to investigate the new conservative form of governing equations in the multi resolution configuration fig 3 represents the initial setup of the test cases and their parameters 4 1 1 multi viscosity poiseuille flow this benchmark case has been widely simulated for studying the numerical accuracy and convergence characteristics of particle methods ghaïtanellis et al 2018 duan et al 2015 shakibaeinia and jin 2012b two fluid phases with different viscosity flow between two stationary and parallel plates under a constant body force applied as a gradient of pressure ρ 0 f y p y in the positive y direction shown in fig 3 a the fluid phases denoted as ω 1 and ω 2 fill the channel with identical width equal to l 2 and density i e ρ 1 ρ 2 ρ 0 1000 kg m 3 we set the viscosity ratio m η 2 η 1 to 25 50 and 100 with the dynamic viscosity of the second phase η 2 set to 100 pa s no slip boundary condition determines the velocity of the fixed solid boundary particles interacting with the fluid particles i e v j v i for i ω f ω 2 ω 1 and j ω s periodic boundary condition eliminates kernel truncation at the top and bottom boundaries i e at y l 0 and 1 the particle size of the fluid phase with the greater viscosity i e l 0 2 determines the spatial resolution of the problem by r l l 0 2 the fluid phase with the smaller viscosity value i e ω 1 has the higher spatial resolution where the particle size ratio defined as q l 0 2 l 0 1 is set to 2 and 4 the maximum analytical velocity u max occurs at the midpoint of ω 2 i e at x l 0 75 and the analytical velocity at the interface i e at x l 0 5 is denoted as u 0 the non dimensional time t is given by t u 0 l and eq 28 determines the calculation time steps with c cfl c 0 0 05 s m c v 0 25 and η 2 100 pa s we estimate the normalized root mean square error of the velocity magnitude through l 2 v u max 1 1 n tp i ω f v i v analytical at x i 2 in which n tp is the total number of fluid particles comparing the analytical solution of the velocity field represented by cao et al 2004 with the results of the single and multi resolution simulations we investigate the numerical accuracy of the model solely related to the shear force operator fig 4 illustrates and plots the velocity of the fluid particles for different m and q at t 100 and with r 40 the single and multi resolution simulations predict accurate results as the estimated velocity converges to the analytical velocity profiles with q 4 small incompatibility between the numerical and analytical results appears at the interface i e at x l 0 5 and where the maximum velocity occurs i e at x l 0 75 this discrepancy originates from the adopted assumption that considers the normalization factor i e n 0 to remain valid at the interface even where q 1 also the approximation term has no renormalization matrix for ensuring the first order accuracy of the estimated velocity field next we perform a particle convergence study of the numerical results compared with the analytical velocity profiles we estimate and plot l 2 v over the simulation time t 0 100 and with different spatial resolutions where r 8 10 16 20 40 and 80 fig 5 with both single and multi resolution simulations l 2 v reduces as the spatial resolution increases shown in fig 5 a for m 50 we plot l 2 v against the averaged particle size i e l 0 1 l 0 2 2 in the log log graphs of fig 5 b the plots display that the accuracy of results is independent from the viscosity ratio m e g with q 2 and r 40 l 2 v is 1 15 1 17 and 1 13 for m 25 50 and 100 respectively on the other hand the multi resolution simulations affect the estimation of velocity profiles and the order of convergence by increasing the numerical errors e g for m 100 and r 80 l 2 v for q 1 increases from 0 5 to 0 9 and 1 3 by q 2 and q 4 respectively however adopting higher spatial resolutions decreases the errors with an order of convergence greater than one the numerical accuracy of our multi resolution mps model q 2 and 4 is consistent with the single resolution mps result of duan et al 2017 with r 40 which estimates the error as 1 33 1 31 and 1 32 for m 20 50 and 100 respectively also the order of convergence of our numerical results is compatible with the mps duan et al 2017 and sph yang et al 2022 methods reporting the order of convergence as 0 66 and 1 respectively particularly for m 100 considering that the shear force calculation i e η 2 v used in this study does not benefit from any high order approximation operators overall the order of convergence of the model and the numerical errors by the multi resolution implementations remain in an acceptable range 4 1 2 hydrostatic pressure in this 2d benchmark case two inviscid and immiscible fluids with identical heights fill a steady tank subjected to a constant gravitational force g 0 9 81 m s 2 t jandaghian et al 2021a rezavand et al 2020 the lighter phase ω 1 with the density of ρ 1 1000 kg m 3 is on the top of the heavier phase ω 2 with the density ratio of ρ 2 ρ 1 2 shown in fig 3 b the total fluid height h and the initial particle size of phase 2 l 0 2 determine the spatial resolution as r h l 0 2 we set c 0 ρ 0 and c cfl to 20 m s ρ 1 and 0 5 respectively we activate the diffusive term 15 with δ mps 0 2 while deactivate the dpc technique the fluid particles i ω f ω 1 ω 2 are initially located on a cartesian lattice the particle distribution of each phase is packed separately before starting the main simulations similar to the packing algorithm proposed by colagrossi et al 2012 the model assigns the initial hydrostatic pressure and the corresponding particle number density to the packed fluid particles jandaghian et al 2021a we simulate this test case for 10 s where the non dimensional time t is given by t g h the particle size ratio is denoted by q l 0 2 l 0 1 where q 1 and q 2 4 refer to the single and multi resolution simulations respectively to validate the numerical results compared with the theoretical hydrostatic pressure we extract the local pressure p e linearly averaged over the fluid particles within an influence radius of 1 5 l 0 2 from the extraction points e evenly distributed at x 0 05 0 10 and 0 15 m with δ y e 0 005 m identified as the delta markers in fig 3 b the normalized root mean square error of the pressure is calculated by l 2 p p max 1 1 n e e p e at y e p theoretical at y e 2 in which n e is the total number of extraction points the numerical error is normalized by the maximum theoretical pressure corresponding to each fluid phase i e if y e h 2 then p max 0 5 h ρ 1 g and if y e h 2 then p max 0 5 h ρ 1 ρ 2 g through this benchmark case we investigate the accuracy of the multi density model in predicting hydrostatic pressure fig 6 represents the particle distributions and pressure fields with r 100 and q 1 2 and 4 at t 10 s stable and uniform particle distribution exists at the interface of the multi resolution simulations where q 2 4 the implemented diffusive term ensures smooth pressure fields over the entire fluid domain we plot the local numerical pressures to compare with the hydrostatic pressure profile the graphs show good agreement between the numerical results and the theoretical pressure for all three cases to quantify the accuracy and the convergence order of the results we calculate the normalized root mean square error of the pressure parameter l 2 p for different spatial resolutions i e r 20 50 100 and 200 the numerical error is normalized by the maximum theoretical pressure corresponding to each fluid phase the particle rearrangement due to the assigned pressure field and the initial particle distribution at the interface oscillates the estimated error at the initial time steps until the simulation reaches a stable condition for t 40 fig 7 a the numerical errors of the single and multi resolution simulations reduce as we increase the spatial resolution of each fluid phase we represent l 2 p against l 0 1 l 0 2 2 in a log log plot in fig 7 b thanks to the conservative form of the approximation operators i e v and p and the effective diffusive term 15 the accuracy of numerical results proves to be independent of q where r 100 noting that l 2 p becomes negligible i e l 2 p 0 5 moreover the particle convergence study confirms that the accuracy of multi resolution simulations q 2 4 improves at the expected rate by increasing r as the order of convergence remains equal to 1 one should note that such a multiphase benchmark case has not been previously validated for convergence study of other single or multi resolution particle methods thus the quantitative analysis of this study is limited to validating the numerical results against the theoretical pressure field 4 2 dam break waves on erodible granular beds we simulate the water dam break over movable beds as a benchmark case of rapid fluid driven granular dynamics first we specify the main properties of this problem and the numerical model configurations we conduct a sensitivity analysis concerning the constant material parameters i e μ 2 a and b in the post failure terms of the visco inertial rheology equation and the suspension eq 25 we validate the results of the proposed multi resolution mps model against the available experimental data representing the simulated flow properties and discussing the phenomenology of the sediment erosion also we evaluate the role of multi scale water sediment interactions within the continuum based modeling of such multiphysics problem 4 2 1 problem characteristics and configurations we configure the two dimensional numerical model based on the experimental setup of spinewine and zech 2007 shown in fig 8 in this problem a column of water collapses under the gravitational force g 0 9 81 m s 2 t on sediment beds fully submerged in water the non cohesive sediment material consists of either coarse sand grains or polyvinyl chloride pvc pellets spinewine and zech 2007 table 1 represents their reference material properties assigned in the rheology eqs 22 25 the material constants of water are its reference density ρ 0 w 1000 kg m 3 and true viscosity μ w 0 001 pa s the flume s length is 2 l 6 00 considering different levels of sediment on the left side of the gate δ h b different geometrical configurations exist by δ h b 0 0 0 05 and 0 10 identified as cases a b and c respectively the upstream water level with respect to the downstream sediment level h is equal to 0 35 m and identical for all three experimental setups the gate located at the middle of the flume i e at x 0 0 is being lowered down with the nominal speed of 5 m s in the negative y direction spinewine and zech 2007 in continuum based modeling of granular material the particle size must be large enough to represent a sufficient number of grains so that the continuum assumption and hence the constitutive law remain valid guazzelli and pouliquen 2018 based on the sensitivity analysis conducted by jandaghian et al 2021a and ghaïtanellis et al 2018 for the sediment dynamics problems we fix the initial inter particle distance of mixture particles l 0 m to 0 005 m and 0 01 m for the sand and pvc bed materials respectively which correspond to 2 7 d g see fig 8 we define the particle size ratio q as the ratio of l 0 m to the initial inter particle distance of water particles l 0 w i e q l 0 m l 0 w a packed particle distribution is used for initializing the main simulations hydrostatic pressure determines the initial density and the effective pressure of the fluid particles at t 0 s jandaghian et al 2021a considering the third order polynomial spiky kernel of shakibaeinia and jin 2010 and k 3 1 for the approximation operators the reference normalization factor n 0 2 2414 which is independent of the spatial resolution of each phase to solve the governing equations we set c cfl and c v to 0 5 and 0 125 respectively and the reference sound speed c 0 to 40 m s the diffusive term with δ mps 0 6 and the dpc technique are implemented within all the simulations in this test case the viscous force is dominant thus the maximum viscosity i e η max of the mixture phase determines the time steps of the calculations through eq 28 which we have set to 4000 and 6000 pa s for the sand and pvc cases respectively to simulate the physical gate we implement the virtual gate vg technique proposed by jandaghian et al 2021a we characterize the dynamics of the immersed granular flow by the interface data i e the water free surface the dense sediment transport layer and the bed level the temporal evolution of the eroded area a e the first moment of the eroded area x c a e where x c is the geometric center of a e and the wavefront position x f from the experimental data provided by spinewine and zech 2007 and spinewine and capart 2013 identified on fig 8 b we extract the numerical results at time steps identical to the experimental data before the wave reaching the end of the flume which is at t 0 25 0 5 0 75 1 00 and 1 25 s for the sand case and t 0 25 0 5 0 75 1 00 1 25 and 1 50 s for the pvc case the non dimensional time t is given by t g h we normalize a e and x c a e by their corresponding reference values i e a e exp f and x c a e exp f which refer to the final data from the experiment at t 1 25 s for sand and at t 1 50 s for pvc respectively to detect the simulated eroded area we employ a velocity threshold for both water and mixture particles as v i ω f 0 25 ghaïtanellis et al 2018 and a minimum volume fraction value for water particles in the vicinity of the eroded mixture particles as ϕ i ω w ϕ 0 0 10 0 3 depending on the particle size fluid particles that satisfy the two conditions are identified as the eroded particles i ω ed through validating the simulated flow properties we justify the thresholds set in the detection conditions the numerical error of the sediment erosion parameters at t is given by e r numerical at t experimental at t exp f or l 1 normalized by the corresponding reference value we estimate the global normalized root mean square error i e l 2 by 1 n t 1 n t e r 2 where n t is the number of calculation steps equal to 5 and 6 for sand and pvc respectively 4 2 2 a sensitivity analysis of the rheology parameters the rheology model dynamically estimates the effective viscosity of the fluid particles as functions of the flow and material properties spinewine and zech 2007 reported the reference material parameters of the sand and pvc bed materials table 1 however the constant parameters in the post failure terms of the implemented visco inertial model i e μ 2 a and b remain unknown and should be calibrated here we analysis the sensitivity of the numerical results of case a to the rheology constants considering the suggested values in baumgarten and kamrin 2019 shi et al 2019 and lee et al 2016 also we quantify the role of the suspension eq 25 in the overall mechanical behavior of the sediment erosion to conduct the sensitivity analysis we plot the temporal evolution of a e x c a e and x f simulated by the single resolution mps model q 1 where μ 2 a and b vary as shown in figs 9 and 10 for the sand and pvc cases respectively each parameter changes while the other two parameters are equal to their reference values given in table 1 the graphs show that the bed load evolution with different parameters of the post failure terms remains almost alike tables 2 and 3 represent l 2 of each scenario and compare them with the errors of the reference model given in the first rows of the tables for both bed materials l 2 varies by less than 3 thus the sensitivity analysis confirms that the estimated sediment erosion is almost independent of the variation of the parameters μ 2 a and b in the specified ranges furthermore we simulate case a pvc where q 1 2 4 with and without implementing the suspension eq 25 in the rheology model table 4 shows that l 2 x f is almost identical for both conditions adding the suspension term slightly reduces l 2 a e and l 2 x c a e by 1 4 nevertheless the suspension term does not manipulate the overall sediment dynamics estimated by the single and multi resolution models the considerable incompatibility between the numerical simulations and the experimental measurements shown in the graphs of figs 9 and 10 and quantified in table 4 manifests the incapability of the single resolution model in capturing accurate flow evolution the continuum based numerical model ignores some physical properties of the water sediment mixing process associated with multi scale interactions and volume fraction variations no inter particle mass exchange occurs in the numerical simulations therefore the model neglects the microscopic fluid flow around and between solid grains and the effects of density changes in the rheology model 4 2 3 flow properties and interface data in this section we present and validate the dam break waves over erodible beds simulated by the multi resolution mps method where q 4 by reporting the longitudinal and vertical flow properties we discuss the global flow evolution and the non linear mechanical behavior of this rapid fluid driven problem the velocity magnitude v the effective viscosity as log 10 η the approximated volume fractions i e ϕ normalized by the reference volume fraction of the mixture phase ϕ 0 and the mixed number i m of cases a sand a pvc b sand and c sand at t 0 5 and t 1 0 seconds are illustrated in figs 11 12 13 and 14 respectively the figures include snapshots of the experiments and the interface data plotted over the numerical results except for the close up plots snapshots i e the inset figures with the black dash line boarder the vertical scale of the images is stretched by a factor of 1 5 to ease visualization of the profiles and flow evolution the numerical solution provides in depth details of the water sediment dam break flows as the top edge of the vertical gate reaches the bed level t 0 s the water column collapses on the water saturated sediment bed driving a thin layer of bed load toward the downstream after the sudden vertical collapse the wave propagates horizontally on the movable bed considering that the wavefront position advances a distance of 3 h in the positive x direction in less than 0 5 s the flow velocity increases uniformly from upstream to downstream the dam break surge exceeds a maximum velocity of 2 5 m s forming rapid erosional bores at the interface and the head of the wave as shown in the close up plots for all cases the surge celerity develops similarly independent from the initial configurations and or the sediment materials furthermore the effective viscosity field plotted as log 10 η illustrates the yielded and un yielded regions estimated by the regularized rheology formulation inside the bed high shear forces rapidly reduce the flow velocity toward the bottom of the flume i e in the negative y direction the spatial variation of volume fraction at the interface manifests the mixing of water and mixture particles from upstream to downstream the longitudinal concentration of mixture particles increases over the bed load layer close to the downstream wavefront the suspended mixture particles fill the entire flow depth well observed in case a with the pvc bed material spinewine and capart 2013 in the implemented model the approximated volume fraction is included in the shear force calculations through the effective viscosity terms the mixed number of the rheology model i m as a function of the strain rate magnitude and the effective pressure clearly distinguishes the suspended mixture particles where i m 0 6 for which the suspension eq 25 updates the effective viscosity the overall longitudinal flow evolution including water free surface the sediment transport layer thickness and the bed boundary are in reasonable agreement with the experimental interface data in all cases the high wave velocity causing highly dynamic sediment erosion creates irregular free surface profiles as rotated s like shapes which are particularly visible at t 0 5 s as the wave progresses on the horizontal beds shown at t 1 0 s the free surface curvature reduces and better agreement exists between the numerical and experimental measurements in the flat bed cases a sand and a pvc the sudden vertical surge forms a scour hole at the near dam region i e the gate s location partially captured by the numerical simulations also the calculated wavefront positions of these two cases match quite well with the experimental profiles at t 0 5 and 1 0 s in the case with a forward facing step of the saturated sediment material i e b sand where δ h b 0 05 m the un yielded bed is comparable with the measured bed profile even at the near dam region at x 0 however the bed boundary of the case with the backward facing step i e c sand where δ h b 0 10 m does not match with the experimental profile close to the gate s location this issue also affects the prediction of the free surface with stronger curvatures at x 0 25 0 5 m and underestimates the wavefront position at t 1 00 s also the numerical errors and ignoring the multi directional flow effects result in unphysical voids close to the wavefront the observed discrepancies can be attributed to the complex non linear flow behaviors and turbulence effects at the front of the wave which lead to non monotonous interface profiles and non equilibrium sediment transport fraccarollo and capart 2002 fig 15 shows the smoothness of the pressure fields in the water and mixture phases of case a with sand and pvc at t 1 0 seconds simulated by the multi resolution mps q 4 with the diffusive term 15 yet some local pressure noises exist close to the wavefront with high velocities the continuum based particle method struggles to accurately capture the instantaneous and local flow curvatures especially at t 0 5 s near the wavefront of case b sand and the gate s location of case d sand we should note that the adopted numerical formulation is incapable of directly simulating the dilatation and compaction effects on the immersed granular flows further the virtual gates see jandaghian et al 2021a ignore the gate s physical thickness and therefore the associated initial disturbance of its movement nevertheless the developed model simulates the overall flow evolution wave celerity and sediment erosion processes of the dam break problem comparable with the experimental measurements and snapshots moreover we compare the numerical results of the multi resolution mps model q 4 for case a pvc with the interface data of single resolution mps shakibaeinia and jin 2011 and sph ran et al 2015 models at t 0 25 0 5 and 0 75 s fig 18 considering the reference experimental data from spinewine and zech 2007 the proposed multi resolution mps method predicts a more accurate evolution of the free surface versus the single resolution mps method by shakibaeinia and jin 2011 also the single resolution incompressible sph isph by ran et al 2015 underestimates the wavefront propagation on the movable bed the proposed multi resolution particle method shows improvements in simulating this fluid driven granular flow in comparison with the two numerical results by shakibaeinia and jin 2011 and ran et al 2015 next we validate the internal flow properties of the numerical simulation of case a pvc against the available experimental measurements represented by spinewine and capart 2013 figs 16 and 17 spinewine and capart 2013 used a particle tracking analysis to measure the vertical velocity profiles u exp at 40 cross sections evenly distributed between x 0 95 and 2 95 m with δ x 0 10 m we extract the numerical velocity u num by linearly averaging the velocity magnitude of fluid particles at the vicinity of the extraction points with δ y 0 01 m on the same vertical cross sections fig 16 plots the fluid particles classified as the eroded and not eroded particles i e i ω ed and i ω ed respectively the extracted numerical velocity as x 0 05 u num and the experimental velocity as x 0 05 u exp at t 0 6 1 0 and 1 4 s the numerical model simulates the non linear velocity profiles with smooth variations at the top and base of the sediment transport layer the velocity profiles in the water layer remain uniform with maximum magnitudes at the free surface at t 1 4 s the model slightly underestimates the velocity near the wavefront x 2 5 nevertheless the estimated velocity matches the experimental profiles quite well over the entire fluid domain moreover we extract and compare the local granular concentration c and the sediment transport intensity defined as the product of c and u i e c and c u respectively spinewine and capart 2013 reported the corresponding experimental measurements limited to the granular layer at 13 laser instrumented vertical cross sections between x 0 05 and 1 5 m this data is from several experiments plotted on a single graph which have resulted into multiple values at the same vertical and horizontal positions spinewine and capart 2013 to estimate c num we linearly average the approximated volume fraction of the particles ϕ i ω f at the extraction points one should note that the experimental measurements are missing at x 1 25 m and t 0 6 s unlike the velocity profiles reported by the particle tracking analysis in fig 16 we plot x 0 1 c and x 0 15 c u over the fluid particles in the left and right graphs of fig 17 respectively the granular concentration keeps its maximum value ϕ 0 in the granular layer while reducing across the bed load layer toward the free surface at the top interface of the transport layer the granular concentration drops and further vanishes in the absence of the mixture particles in spite of some minor discrepancies the estimated numerical profiles are in good agreement with the experimental measurements the validation confirms that the numerical model can predict the non linear profiles with smooth variations across the bed load layer we should also highlight that the compatibility between the numerical and experimental profiles justifies conditions we have adopted to detect the eroded area through which we study the phenomenology of sediment erosion and quantify the numerical validations 4 2 4 phenomenology of the sediment erosion a e x c a e and x f to overview the phenomenology of the dam break waves over movable beds we compare the sediment dynamics of the different configurations fig 19 shows the wave propagation of cases a sand a pvc b sand and c sand on the horizontal beds at t 1 25 s the figure contains experimental snapshots and the interface data of the test cases further we plot the temporal evolution of the global erosion variables a e and x c a e and the wavefront position x f in fig 20 and represent the associated numerical errors in table 5 qualitatively the numerical simulations provide comparable flow evolution and predict the thickness of the transport layer at the center of the wave in all four cases the base of the transport layer is well captured however near the gate s location the rapid flow involves complex interface deformations affecting the numerical predictions as discussed earlier this incompatibility is more noticeable for case c sand with the backward facing step comparing case a pvc with the other configurations illustrates the sensitivity of sediment erosion to the density ratio i e ρ m ρ w the thickness of the transport layer increases significantly for case a pvc as the wave can mobilize more mixture particles on the other hand with the sand material i e with the heavier grains but with a smaller fiction angle in cases a b and c the transport layer is thinner thus the wave can progress further on the horizontal bed with less sediment erosion toward the downstream spinewine and capart 2013 fraccarollo and capart 2002 while the wavefront position of case a pvc matches well with the interface data the numerical simulation slightly underestimates the wave propagation speed of cases with the sand beds regardless of their initial configuration to quantitatively study the sediment dynamics fig 20 provides an overall overview of the sediment erosion concerning different configurations and bed materials the graphs of fig 20 show that the multi resolution mps model predicts the global behavior of the sediment erosion and wave prorogation particularly we observe that x c a e and x f of all four cases are in very good agreement with the experimental data for the light pvc material sediment erosion increases significantly as a e of a pvc is almost 2 5 times greater than a e of a sand at t 1 25 s for case c sand the wave interaction with the backward facing step increases the sediment erosion by 30 percents in comparison with cases a sand and b sand with the step like discontinuity of cases b and c the results are less satisfactory considering that the numerical model underestimates the sediment erosion at t 0 5 and 0 75 s table 5 represents the numerical errors of the sediment erosion parameters l 2 l 2 x f and l 2 x c a e remain less than 10 percents manifesting the acceptable accuracy of numerical model in simulating the flow evolution on the movable beds the results show that with the step like discontinuities l 2 a e increases by 10 percents from 8 5 for case a sand to 19 7 and 14 7 percents we attribute the numerical errors to the neglected role of granular dilatation and compaction in the adopted single phase rheology model this issue indirectly ignores the turbulence suspension effects of the microscopic pore water flow between solid grains within the numerical simulations spinewine and capart 2013 nevertheless the multi resolution mps model proves to be capable of predicting the global behavior of the fluid driven granular dynamics with reasonable numerical accuracy 4 2 5 role of multi scale simulations here we discuss the role of multi scale interactions in sediment erosion modeling to do so we compare the interface data of case a simulated by the single and multi resolution models figs 21 and 22 represent the eroded region i ω ed of case a with the sand and pvc bed materials respectively in these figures except for the close up plots the vertical scale is stretched by a factor of 5 0 flow evolution of the water and mixture particles at t 0 75 and 1 25 s shows that the single resolution model q 1 underestimates the wavefront position this discrepancy between the numerical and experimental results is more noticeable for the sand case with a higher density ratio on the other hand the multi resolution models q 2 4 predict more flow deformations at the interface increasing erosion of the mixture particles although the continuum based modeling still misses some physical aspects of sediment erosion i e the pore water flow between the solid grains and the associated changes in the volume fraction of the mixture particles the multi resolution particle interactions allow the numerical model to capture more accurate flow evolution related to the multi scale feature of water sediment dynamics to quantify the numerical validations we plot the temporal evolution of a e x c a e and x f and compare them with the experimental data fig 23 the profiles manifest improvements in estimating the sediment erosion by the multi resolution model with q 4 while the single resolution model underestimates the granular flow evolution the remaining incompatibility between the numerical and experimental profiles especially for the eroded area of case a pvc at t 3 originate from complex water sediment mixing processes at the interface that the continuum based particle method is incapable of simulating table 6 represents the normalized root mean square error l 2 of the sediment erosion parameters the quantified results show a significant reduction in the numerical errors by the multi resolution simulations by a factor of 2 4 with respect to the single resolution results moreover we illustrate the velocity distribution of each resolution q 1 2 and 4 at the interface for case a pvc in fig 24 a and b the velocity fields fig 24 a show that the single resolution model underestimates the wave velocity on the movable bed on the other hand the multi resolution model simulates more flow deformation leading to higher velocity magnitudes over the wavefront fig 24 b compares the extracted velocity profiles with the experimental profiles by spinewine and capart 2013 plotted as the black x markers the velocity profiles estimated by the multi resolution model q 4 are in better agreement with the experimental data compared with the single resolution model q 1 also to evaluate the global mechanical behavior of the sediment flow we plot the global kinetic energy of the mixture particles e k 0 5 ρ 0 i l 0 i 2 v i 2 for i ω m which is independent of the conditions used for detecting the eroded area fig 25 for case a e k of the multi resolution model where q 4 is two to three times greater than e k of the single resolution model where q 1 for both bed materials overall we observe that the developed multi resolution model considerably reduces the errors of the single resolution simulations by estimating more flow and sediment erosion at the interface 5 conclusion in this study we proposed and validated a new form of governing equations based on the enhanced weakly compressible mps method to incorporate multi scale water sediment interactions within the continuum based numerical modeling to do so we presented a novel multi resolution mps formulation supplied with particle enhancement technique to investigate the mechanical behavior of fluid driven granular dynamics first simulating two benchmark cases i e the multi viscosity poiseuille flow and the multi density hydrostatic pressure problems we studied the accuracy and convergence of the numerical results with the single and multi resolution models as for the fluid driven granular erosion we adopted the generalized rheology equation to model the two dimensional dam break waves on erodible sediment beds we presented and discussed the mechanical behavior of this benchmark case for various configurations i e with the flat bed and the step like discontinuities and bed materials i e the sand and pvc granules we analyzed the sensitivity of sediment dynamics to the added suspension equation and the constant material parameters of the rheology model through comprehensive numerical validations we studied the flow evolution and mechanical properties of the sediment erosion induced by the rapid water waves moreover we compared the numerical results of the single and multi resolution simulations to evaluate the role of multi scale interactions in capturing the global behavior of this benchmark case the particle convergence study on the two numerical benchmark cases confirms that the proposed multi resolution formulation predicts the analytical results with acceptable accuracy for the multi viscosity poiseuille flow the multi resolution shear force respects the convergence behavior of the numerical model and keeps the errors of the velocity profiles to less than 2 for the multi density hydrostatic pressure the conservative governing equations ensure the accuracy and stability of the results with errors less than 0 5 in both cases increasing the spatial resolution the numerical results converge to the analytical profiles with the convergence order greater than one for the dam break waves on movable beds the developed numerical model provides in depth details of the water sediment mixing processes and the global behavior of sediment dynamics the nonlinear vertical velocity and granular concentration profiles of the flat bed with pvc are well estimated simulating different geometrical setups with the sand and pvc granules clarifies that the sediment dynamic greatly depends on the mobility of the bed materials i e the density ratio ρ m ρ w supporting the theoretical analysis by spinewine and capart 2013 and fraccarollo and capart 2002 in the flat bed configuration the eroded sediment and the thickness of the transport layer increase with the light pvc material by a factor of 2 5 compared with the case with the sand grains the step like discontinuities lead to complex bed load evolution close to the gate s location and slightly increase the mobility of the bed material at the initial stages of erosion regardless of the initial configuration in cases with sand the wave propagates on the horizontal bed with almost identical bed load layer thickness and speed in general the multi resolution mps method proves to be capable of simulating the sediment erosion at the interface and the wavefront position despite the local discrepancies the interface data and the flow evolution match well with the experimental measurements moreover we observe that the multi resolution model captures more interface deformations in comparison with the single resolution model that underestimates sediment erosion the results presented highlight the importance of multi scale multiphase water sediment interactions in numerical simulations of such a rapid fluid driven problem it is worthwhile to employ the developed particle method for studying multi directional granular flows with applications to industrial and hydro environmental problems further enhancements of the numerical and rheological models should be considered for predicting granular flow regimes in more complex situations than the validation test cases that exists in engineering problems for the three dimensional simulations the neighbor particle search algorithm can be adapted to the multi resolution particle interactions e g by setting different cell domains for each particle size neighbor search to reduce the associated computational costs the proposed multi resolution formulations can be extended to two phase mixture models e g baumgarten and kamrin 2019 shi et al 2019 to investigate the effects of dilatation and compaction on the mechanical behavior of immersed granular flows furthermore the multi resolution mps method can be further validated to high density ratio problems and coupled with dynamic particle merging and splitting techniques to simulate violent free surface flows jandaghian et al 2021b rezavand et al 2020 and fluid structure interactions zhang et al 2020 khayyer et al 2019 credit authorship contribution statement mojtaba jandaghian conceptualization methodology validation formal analysis investigation visualization writing original draft ahmad shakibaeinia conceptualization methodology supervision project administration writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the financial support of the natural sciences and engineering research council of canada nserc and polytechnique montréal canada this study used the high performance computing hpc resources of compute canada and calcul quebec as well as a local server acquired using canada foundation for innovation cfi support appendix a supplementary data movies of the simulations are available online supplementary material related to this article can be found online at https doi org 10 1016 j advwatres 2023 104488 appendix a supplementary data the following is the supplementary material related to this article video s1 a video summarizing the numerical methodology and results 
13,the statistical characterization of precipitation p at short durations 24 h is crucial for practical and scientific applications here we advance the knowledge of and ability to model the space time correlation structure stcs and marginal distribution of short duration p using a network of rain gages in central arizona with one of the largest densities and spatial coverages in the world we separately analyze summer and winter p sampled at multiple durations δt from 0 5 to 24 h we first identify an analytical model and a three parameter distribution that robustly capture the empirical stcs and marginal distribution of p respectively across δt s we then conduct monte carlo experiments consisting of multisite stochastic simulations of p time series to explore the spatial and seasonal variability of these properties significant seasonal differences emerge especially at low δt summer winter p exhibits weak strong correlation structure and heavy light tailed distributions resulting from short lived isolated thunderstorms widespread long lasting frontal systems the stcs of p is most likely homogeneous and isotropic except for winter at δt 3 h where anisotropy could be introduced via the motion of frontal storms the spatial variability of the marginal distribution is reproduced by a regional parameterization dependent on elevation in all cases except again for winter at δt 3 h where additional factors are needed to explain the variability of the mean p intensity this work provides insights to improve stochastic p models and validate convection permitting models used to investigate the mechanisms driving changes in short duration p keywords short duration precipitation multisite stochastic rainfall modeling space time rainfall correlation rainfall probability distributions data availability precipitaton data from the fcdmc rain gage network are available at the website https www fcd maricopa gov 625 rainfall data 1 introduction quantifying the spatiotemporal variability of precipitation p at short durations here 24 h is crucial for several practical and scientific goals it is key to generate more realistic design storms for urban stormwater infrastructure gires et al 2014 ichiba et al 2018 peleg et al 2013 improve estimates of areal reduction factors used to convert extreme point p into areal averaged p wright et al 2013 veneziano and langousis 2005 and increase the accuracy and resolution of indirect p estimates from weather radars krajewski et al 2010 and satellite sensors tang et al 2016 the knowledge of short duration p variability is also needed to develop and test stochastic models of temporal spatial and spatiotemporal p fields venugopal et al 1999 schertzer and lovejoy 1987 deidda 2000 bárdossy and pegram 2009 burton et al 2008 papalexiou and serinaldi 2020 papalexiou 2018 papalexiou et al 2021 paschalis et al 2013 peleg et al 2017 kim and onof 2020 rebora et al 2006 among others the high resolution p time series or grids generated by these models have been useful to increase the value of physics based distributed hydrologic models in studies on flood generating mechanisms paschalis et al 2014 mascaro et al 2013b flood frequency wright et al 2014 and climate change impacts piras et al 2014 among other goals moreover outputs of space time p models have the potential to enhance the accuracy of p forecast harris et al 2001 and in turn the skill of flood and flash flood forecasting systems seo et al 2013 alfieri and thielen 2015 particularly in urban regions where watersheds have short response times hjelmstad et al 2021 many studies have provided insights into the spatiotemporal variability of short duration p by investigating the presence of scaling regimes i e time and or space intervals where the p statistical properties are linked via power law relations across a wide range of temporal and spatial scales through spectral multifractal and wavelet based frameworks in most cases a single regime was found from a few days to 0 5 1 h and in some sites where sub hourly measurements were available an additional regime was detected from 0 5 1 h to a few minutes e g fraedrich and larnder 1993 deidda et al 1999 mandapaka et al 2015 verrier et al 2011 mascaro et al 2013a seasonal differences in temporal scaling regimes have also been identified and attributed to different dominant weather systems molnar and burlando 2008 mascaro et al 2014 mascaro 2017 the evidence of p scaling has been also shown in space from 100 200 km to about 1 km and in space time frameworks schertzer and lovejoy 1987 venugopal et al 1999 deidda 2000 deidda et al 2004 mascaro et al 2013b this body of knowledge has significantly advanced our understanding of short duration p and allowed the development of sophisticated stochastic space time p models however the datasets used in previous studies have been largely restricted to p observations collected during short term field experiments or available at a few sites with limited spatial coverage and density this is because rain gage p records at sub daily resolution are still limited and sparse lewis et al 2019 morbidelli et al 2020 while radar and satellite derived p estimates are heavily affected by several sources of errors especially at high temporal resolutions michaelides et al 2009 krajewski et al 2010 as a result further analyses of high quality long term p observations at high temporal and spatial resolutions are needed to confirm the validity of previous findings examine aspects of short duration p variability that have received less attention and support the operational use of space time stochastic p models these needs have become particularly important given recent evidence that short duration p extremes have been intensifying due to global warming fowler et al 2021 prein et al 2017b and urbanization huang et al 2022 moreover new knowledge on the statistics of short duration p would be useful to validate convection permitting atmospheric models that are being increasingly applied to study the mechanisms driving changes in short duration p chen et al 2021 prein et al 2017a two important statistical properties of short duration p that have received relatively less attention are the spatiotemporal correlation structure stcs and the distribution of the intermittent process of zero and nonzero p values previous work has focused on either the spatial correlation of p within short distances 25 km or the temporal serial correlation at single sites ciach and krajewski 2006 habib et al 2001 mascaro 2017 zawadzki 1973 marani 2005 jameson 2021 schleiss et al 2011 among others changes in correlation structure of p for different combinations of space and time lags over large regions have not yet been explored recently new flexible analytical models have been proposed by papalexiou and serinaldi 2020 and papalexiou et al 2021 to characterize the stcs of p but these have not been tested yet against observations at fine temporal scales other recent studies have suggested single and two component parametric distributions that could properly capture the body and tails of the distribution of short duration nonzero p papalexiou and koutsoyiannis 2016 emmanouil et al 2021 naveau et al 2016 while promising the recent methodological advancements on both the stcs and the marginal distribution of short duration p require empirical corroboration and their value should be systematically investigated across different time scales seasons and sites these research needs are addressed in the study which has the main goal of advancing the ability to characterize and model the stcs and marginal distributions of short duration p to robustly investigate these statistical properties we analyze long term 20 years high resolution 30 min p records from a network of rain gages in central arizona which to our knowledge has one of the largest densities and spatial coverages in the world this study region is compelling due to the strong seasonality of the p regime and the effect of orography which lead to marked variability in the statistical properties of p mascaro 2017 2018 2020 we address the following research questions that have both scientific and practical implications and that provide arguably the first systematic characterization of stcs and marginal distribution of p across multiple temporal scales with an extensive and high quality 30 min dataset 1 how does the stcs of p at durations 24 h vary seasonally 2 can the stcs be considered homogenous and isotropic homogeneous means that the function is spatially stationary across the region while isotropic means that the correlation is only affected by the distance between two sites and does not depend on the direction along which the distance is computed 3 is there a parametric distribution that adequately describes the body and tails of the nonzero p marginal distribution across multiple p durations 4 does the presence of serial correlation in short duration p series significantly affect the estimation of the distribution parameters and 5 how do the distribution parameters vary seasonally and spatially and can they be regionalized to answer these research questions we perform a set of monte carlo experiments with the complete stochastic modeling solution cosmos papalexiou 2018 papalexiou and serinaldi 2020 papalexiou et al 2021 papalexiou 2022 which allows for the stochastic simulation of p time series at multiple sites that preserve prescribed marginal distributions and stcs while these research questions are investigated in central arizona our methodological framework provides new insights into the space time p variability at any location and provides key information to increase the reliability of space time simulations of short duration p 2 study area and dataset our study region is in central arizona and includes the phoenix metropolitan area fig 1a where the flood control district of maricopa county fcdmc has deployed a network of rain gages to monitor intense storms the gages were progressively installed since 1980 eventually reaching the current number of 365 in this study we use records of 223 gages with more than 20 years of observations fig 1b the gages cover a region of 29 600 km2 that mainly encompasses the sonoran desert at low elevations from 200 to 700 m above the sea level asl and extends up to the southwestern portion of the mogollon rim at 2325 m asl most gages are in urban areas 2000 km2 with a density of 4 3 gauges per 100 km2 when considering the entire region the density decreases to 1 gauge per 100 km2 the distribution of the inter gage distance is presented in fig 1c demonstrating that this network allows characterizing with unprecedented detail the spatial variability of p statistical properties including correlation structure and marginal distribution the climate in this region of the desert southwestern u s is hot and arid according to the köppen geiger classification the climate is categorized as bwh in most of the region with smaller portions classified as bsh bsk and dsb as the elevation increases fig 1d acronyms defined in its caption the rainfall regime is strongly seasonal summers are dominated by the north american monsoon nam from july to september adams and comrie 1997 during which short lived 1 h spatially localized thunderstorms occur with moderate to high rainfall intensities according to a diurnally modulated cycle winters defined here from november to march are characterized by westerly flow and extended dry periods that are occasionally interrupted by cold fronts that may cause large scale storm systems controlled by dynamical lifting resulting in low to moderate rainfall intensities these storms tend to be widespread and often cover the entire region and last for a few days previous studies mascaro 2017 2018 2020 have investigated several statistical properties of the rainfall regime in the region their findings inform the new research directions pursued in this work 3 methods 3 1 data processing the fcdmc provides p data in a raw format containing the tipping instants in seconds with a resolution of 1 mm for each tip we obtain the rainfall time series at different temporal resolutions δt 0 5 1 2 3 6 12 and 24 h using the method described by mascaro et al 2013 which limits the discretization of the signal caused by the commonly used box counting unfortunately we find that the resolution of the gage bucket of 1 mm is quite coarse and limits the effectiveness of the smoothing procedure therefore the p time series exhibit a considerable fraction of repeated values that are multiples of 1 δt mm h which affect the comparison of the observed p statistics with those of the non discretized synthetic samples generated with cosmos we partially address this issue see results by rounding off the synthetic samples through a procedure based on deidda 2007 that involves 1 estimating the percentage of observed measurements rounded off at multiples of 1 δt mm h and 2 adopting these percentages to round off the corresponding synthetic samples given the different storm generating mechanisms described in section 2 analyses are conducted separately for summer july september and winter november march 3 2 spatiotemporal correlation structure the spatiotemporal correlation structure stcs describes the correlation here linear between two random variables lagged by time τ in hours and placed at a distance δ in km papalexiou and serinaldi 2020 in symbols ρ x τ δ cor x t si x t τ sj with t being any time instant and δ the euclidian distance between locations si and sj here we model the stcs of p using a parametric form emerging from the clayton copula and the weibull survival function papalexiou and serinaldi 2020 the clayton weibull stcs is stationary and isotropic and given by 1 ρ x τ δ θ exp θ δ b s c s exp θ τ b t c t 1 1 θ where θ bs cs bt ct θ is the parameter vector note that the indices s and t stand for space and time respectively to estimate θ we compute 1 the empirical correlation matrixes of the gage records at different time lags r δt k whose generic element r i j δ t k is the pearson correlation coefficient between the p signal at resolution δt at gage i and the p signal at the same resolution lagged by τ k δt at gage j where k is the lag index ranging from 0 to the number of investigated lags p and 2 the distance matrix d whose generic element dij is the euclidian distance between gages i and j we then use these matrixes to solve the least square regression equation 2 θ argmi n θ f i 1 n 1 j i 1 n k 0 p r i j δ t k ρ x k δ t d i j θ 2 where the sum over i and j is used to include the terms in the upper triangle of the symmetric matrixes the calculations are performed in matlab using the function fit 3 3 candidate marginal distributions and parameter estimation when considered at small aggregation times p is an intermittent process that includes zero and nonzero values its distribution is then characterized by a probability mass concentrated at zero p 0 and a continuous part that characterizes nonzero values in symbols if x is the random p variable at a given resolution δt its cumulative distribution function cdf fi x with the subscript i referring to the intermittent process is given by 3 x f i x p 0 1 p 0 f x with f x being the cdf of nonzero p i e valid for x 0 in this study we estimate p 0 as n 0 n with n 0 being the number of time steps where p is zero and n is the total number of time steps for f x we explore the suitability of three parameter distributions that have been shown flexible to capture left and right tails as well as the body of the empirical distribution of positive hydrologic variables papalexiou and koutsoyiannis 2012 papalexiou 2022 these include the generalized gamma g g burr type xii b r xii and generalized exponential type 4 g e 4 distributions their cdfs are 4 f g g x 1 γ γ 1 γ 2 x β γ 2 γ γ 1 γ 2 5 f b r xii x 1 1 γ 2 x β γ 1 1 γ 1 γ 2 6 f g e 4 x 1 exp x β γ 1 1 γ 2 1 1 γ 2 these distributions are defined for x 0 γ 1 0 and γ 2 0 are parameters controlling the shape of the distribution and β 0 is the scale parameter γ and γ denotes the incomplete gamma and gamma functions respectively parameters are estimated using the numerical approach recently proposed by zaghloul et al 2020 based on the method of l moments hosking and wallis 1997 details are provided in appendix a the suitability of the distributions is evaluated graphically with the l moment ratio diagram and further assessed quantitatively via two goodness of fit gof metrics reported in appendix b 3 4 monte carlo experiments with cosmos we design monte carlo experiments based on the version of the complete stochastic modeling solution cosmos for multisite stochastic simulations of p time series that preserve prescribed space time correlation structure and marginal distribution of p papalexiou and serinaldi 2020 this version of cosmos is briefly described in appendix c the experiments are used to investigate 1 the homogeneity and isotropy of the stcs in each season and 2 the spatial variability of the distribution of the intermittent p process for each δt an ensemble of synthetic time series is generated at the 223 gage locations with the same observed record lengths under prescribed stcs and marginal p distributions the statistical properties of the synthetic time series are then compared to the observations an additional monte carlo experiment is carried out to test the effect of serial correlation on parameter estimation for the distribution of nonzero p this involves the generation of long term times series at a single site with prescribed serial correlation i e the stcs with δ 0 and marginal p distribution further details are provided in the next section 4 results 4 1 spatiotemporal correlation structure seasonal differences and effect of time aggregation the clayton weibull stcs is fitted to the empirical pearson correlation coefficients for summer and winter p as an example results for δt 0 5 h are reported in fig 2 visual inspection of the stcs surface and the cross sections for fixed values of τ and δ chosen as examples suggests that the clayton weibull analytical model captures very well the median empirical correlation structure of p in the two seasons this is true for all δt s as an example results for δt 6 h are shown in fig s1 in the supplementary material with the root mean square error between empirical and theoretical stcss ranging from 0 02 to 0 04 across all cases the estimated parameters of the clayton weibull stcs for all δt s are reported in fig s2 given its effect on both the spatial and temporal correlation functions we investigated the role of the θ parameter and found it to depend on the values of the other four parameters and to be overall relatively minor and more significant for the spatial correlation at τ 1 δt additional considerations are provided in figs s3 and s4 given its ability to represent the empirical stcs across all cases we use the clayton weibull model to explore seasonal differences of the p correlation structure as a function of δt to this end we plot in fig 3 the clayton weibull stcs for fixed values of τ and δ for δt 0 5 h which is the characteristic timescale of single convective storms and for δt 3 6 and 24 h which capture the behavior of larger single and multiple storms we first note that for any given δt ρx of all spatial fixed τ and temporal fixed δ correlation functions are higher in winter than in summer this occurs because winter events are longer and more widespread whereas summer monsoonal storms are more localized in time and space and intermittent higher probability of zero p the spatial correlation of p with no temporal lag τ 0 δt shows that ρx increases with δt in both seasons fig 3a top panels this is expected since as the p signal is aggregated over larger time steps multiple storm cells may occur over a bigger spatial domain and there is a higher chance that nonzero p is simultaneously observed at sites located at large distances if we instead consider the spatial correlation of temporally lagged τ 1 δt p series fig 3a bottom panels the role of δt changes dramatically with similar impacts in the two seasons for the largest δt 24 h ρx drops to a very low value that is constant with δ suggesting that in our study region storms rarely last for more than 24 h for δt 0 5 h ρx declines but its values are nonnegligible for δ 50 km especially in winter the behavior of the spatial correlation for δt 3 h and 6 h is intermediate between the largest and smallest δt s discussed above as expected the temporal correlation for δ 0 km i e the serial correlation functions fig 3b top panels for a given dimensionless lag k increases in both seasons as δt is reduced in other words as we consider shorter time steps there is a higher chance that p observations at the same location are similar within a few time steps the temporal correlation evaluated at sites at a distance δ 20 km fig 3b bottom panels is substantially similar to that for δ 0 km except for k 0 where ρx is significantly lower than 1 for all δt s with a more significant drop observed for δt 30 min because of the smaller spatial coverage of single storms in summary the spatial correlation of p for τ 0 δt fig 3a upper panels declines faster as the resolution increases i e lower δt whereas the opposite is true for the temporal correlation of p for δ 0 fig 3b upper panels this behavior is reversed for lagged spatial correlations fig 3a lower panels and fixed distance lagged correlations fig 3b lower panels 4 2 marginal distribution of short duration precipitation 4 2 1 selection of parametric distribution of nonzero precipitation we first focus on the distribution of nonzero p f x and evaluate the suitability of the g g b r xii and g e 4 theoretical models fig 4 presents the l moment ratio diagrams l skewness vs l variation for three representative δt s each panel displays the sample l moments along with surfaces obtained for different combinations of the shape parameters γ 1 and γ 2 for each of the three considered distributions note that distributions with a single shape parameter would instead be represented by a curve in the l skewness l variation space the l moments of p records exhibit seasonal differences with winter p characterized by lower values of both l ratios than summer p the differences are marked at lower δt and tend to be smaller as δt increases the g g is the least flexible distribution and its surface does not fully include the sampling variability of the l ratios on the other hand the b r xii is the most flexible however its shape parameters for low δt in summer γ 2 0 5 lead to distributions with infinite variance which is an undesirable condition for modeling time series stochastically since unrealistically large events could be frequently generated the g e 4 has intermediate flexibility and captures all possible combinations of the sample l moments while having always finite moments the gof of the distributions is further evaluated by plotting in fig 5 the empirical cdfs of nonzero p at different δt s in the two seasons at four representative gages along with the fitted theoretical distributions we first note that despite the presence of several repeated values that are multiples of 1 δt mm h the fitting of the distributions through the method of l moments is quite effective all parametric models capture very well the body of the empirical cdf f x 0 9 shown in insets differences emerge in some cases at the right tail with b r xii exhibiting heavier tails and the largest deviations from the empirical distribution this is quantified by the values of the gof metrics of appendix b w 2 and relmse reported in table 1 for the examples of fig 5 boxplots summarizing the gof metric across all gages are displayed in fig s7 which further indicate that the discrepancies of the b r xii in the right tail measured by relmse are higher for lower δt interestingly even if the region of theoretical l moments for the g g does not capture the sample points for δt 0 5 h see fig 4a the closest pairs of γ 1 and γ 2 to the corresponding sample point returned by the parameter estimation method leads to a fairly good fit to the observed cdf given the overall higher performance in the following analyses the g e 4 is used as the marginal distribution for nonzero p 4 2 2 effect of serial correlation on parameter estimation for low δt the serial correlation of the p time series can be high and the assumption of independent events may not hold from the practical standpoint this implies that the effective sample size is reduced thus increasing uncertainty when estimating the marginal distribution parameters to evaluate this we perform monte carlo experiments where cosmos is used to generate two ensembles of nens 100 long term serially correlated and uncorrelated time series respectively of intermittent p at δt 0 5 h the highest resolution is chosen since it has the strongest serial correlation see fig 3b for these ensembles we use 1 the mean p 0 across the gages 2 the g e 4 distribution for f x with mean values of γ 1 γ 2 and β and 3 the serial correlation provided by the clayton weibull stcs ρ x τ δ 0 this is done separately for summer and winter generating in each case 200 consecutive seasons i e a dataset of 200 years of observations fig 6a shows the theoretical serial correlations and marginal distributions of the intermittent p process fi x used to apply cosmos in the two seasons along with the corresponding empirical functions from one of the synthetic time series the correspondence is remarkable indicating that the cosmos framework reproduces very well these statistical properties of the p signal parameters γ 1 γ 2 and β are then re estimated by fitting the g e 4 to the nonzero p of each synthetic time series for the number of seasons m ranging from 10 to 200 results are presented in fig 6b which shows the 90 confidence intervals of the estimated parameters in all cases and for all m s the estimates are unbiased and the uncertainty of correlated and uncorrelated series is the same even for low m the only exception is the case of γ 1 in winter where the uncertainty of the correlated series is slightly larger likely because of the stronger serial correlation overall these experiments suggest that the considered samples are long enough that the presence of serial correlation does not significantly affect parameter estimation therefore there is no practical need to apply techniques to identify statistically independent events as in principle required by the assumption of independent and identically distributed i i d variables this result was verified for all δt s not shown if in future applications this turns out not be the case due to stronger serial correlations smaller samples or the use of a different probability distribution the proposed monte carlo framework could be used to identify strategies to extract an independent sample from the original time series or bias correct the parameter estimates 4 2 3 seasonal variability of the marginal distribution as a function of time aggregation fig 7a presents the boxplots of p 0 and the g e 4 parameter estimates at the 223 gages for all δt s seasonal differences emerge for all parameters the probability of zero p p 0 is slightly higher in summer than winter when the signal is aggregated up to δt 6 h the opposite is true for longer time aggregations moreover the relation between p 0 and δt is linear r2 0 95 not detectable in the semilogarithmic plot of fig 7a with a mean slope of 4 3 10 3 3 3 10 3 h 1 in summer winter the scale parameter β is 1 relatively larger for summer p at smaller δt s 2 similar in the two seasons at intermediate δt 6 h and 3 higher for winter p at larger aggregation times in addition β exhibits a scaling relationship with δt highlighted through the log log plot with a slope of 0 68 0 57 in summer winter focusing on the shape parameters γ 1 is larger for winter than summer p while the opposite is true for γ 2 but with less notable differences as expected by the location of the l moments estimates see fig 4 neither parameter exhibits significant variations with δt when considering summer p except for slightly higher values of γ 2 for δt 1 h larger variations of the shape parameters with δt are instead observed for winter p particularly for γ 1 that decreases between δt 0 5 h to δt 6 h we further investigate the relationship between the shape parameters as a function of the time aggregation in each season by plotting in fig 7b the scatterplots between γ 1 and γ 2 for all δt s the two g e 4 parameters are inversely related in a nonlinear fashion in summer a single relation encapsulates the estimates for all δt s with slightly higher lower values of γ 1 γ 2 found for δt 6 h in contrast distinct relationships between the two parameters emerge in winter for each δt to visualize how these outcomes affect the shape of f x fig 7c e display the g e 4 cdfs with the median parameter values for δt 0 5 6 and 24 h in the two seasons which are also depicted with arrows in fig 7b the distribution of summer p is always heavy tailed with very limited changes of its shape across δt s winter p is instead characterized by a distribution with much lighter tails than summer and whose heaviness gradually increases with δt our sensitivity tests and the visual inspection of fig 7b indicate that 1 γ 1 exerts the largest control on the right tail and 2 differences in β mainly affect the body of the distribution f x 0 9 4 2 4 spatial variability of the marginal distribution as a next step we investigate whether the inter gage variability of p 0 and g e 4 parameters results from sampling variability or is related to local physical factors we find that p 0 has a rather constant value for elevation z lower than 400 m asl and decreases linearly with z with a slope that is larger in absolute value i e stronger orographic control as δt increases this is shown in fig 8a b for three δt s while maps are reported in fig s8 the pearson correlation coefficient cc with z is 0 81 across seasons and δt s the scale parameter β is moderately related to z in a nonlinear fashion as presented in the examples of fig 8c d for three δt s and quantified by spearman cc between 0 21 and 0 51 across all cases for the shape parameters γ 1 and γ 2 no significant relations are found with z or gage coordinates examples of maps of the three g e 4 parameters are reported in figs s5 s6 4 3 insights into the correlation structure and physical controls on short duration precipitation through stochastic simulations with cosmos the insights gained in the previous sections allow designing monte carlo experiments with cosmos to investigate the following two hypotheses 1 the stcs of short duration p in the region could be considered spatially homogeneous and isotropic in each season and 2 the spatial variability of the parameters of the marginal distribution fi x is explained by a few regional relations the latter ones are identified based on the empirical evidence presented in section 4 2 4 which suggests that for a given δt and season the shape of the nonzero p distribution controlled γ 1 and γ 2 can be considered constant while the scale parameter β and p 0 are related to the elevation this translates into the following relations for each δt 9a p 0 p 0 m a x z z p 0 m a x m z z z z 9b γ 1 γ 1 9c γ 2 γ 2 9d β β β β 0 e q z where p 0 max and m are intercept and slopes of the linear relation respectively and z 400 m asl γ 1 and γ 2 are the g e 4 shape parameters corresponding to the sample mean l variation and l skewness across all gages see fig 4g i and β β 0 and q are coefficients of a decreasing exponential relationship linking the g e 4 scale parameter with z see fig 8c d the latter one is the same analytical relation that was found by mascaro 2018 to well capture the relation between z and the scale parameter of the generalized pareto distribution used as a theoretical model of daily extreme p in this region the values of the estimated coefficients and parameters of equations 9 in each season and δt are reported in table 2 to evaluate these hypotheses for each δt we perform two sets of simulations with cosmos each consisting of the generation of 100 spatially and temporally correlated synthetic time series at the 223 gages with the same duration of the observed records in the first set parameters of fi x are specified using the at site estimates labeled at site while in the second set parameters are obtained through the regional equations 9a d labeled regional in both cases the clayton weibull model of eq 1 with parameters reported in fig s2 is used to estimate the stcs the at site simulations are expected to provide the best possible performance of this version of cosmos with a homogeneous and isotropic stcs our first hypothesis is then addressed by quantifying the discrepancies between the observed inter gage correlations and those computed from the at site synthetic time series the second hypothesis is assessed by measuring the degree to which the performance of regional in simulating the observed l moments and empirical marginal p distributions degrades compared to at site fig 9 shows for three δt s and both seasons the correlation coefficients between the observed p signals at all gage pairs for two temporal lags τ as a function of the inter gage distance δ along with the 90 confidence interval ci derived from the 100 at site simulations with cosmos note that results are the same for regional since the same analytical stcs is used in both experiments in summer a single analytical model for the stcs captures remarkably well the empirical values for all δ τ and δt performances slightly degrade in winter i e more cases have 10 of the observed correlations outside the cis especially for δt 3 h but they are still satisfactory in most cases these findings suggest that in summer the stcs of subdaily and daily p could be considered with high confidence homogeneous and isotropic while a certain degree of nonhomogeneity and or anisotropy exists in winter to investigate the second hypothesis we first compare the l moments ratio diagrams of the observed samples same as fig 4 and one ensemble member of the regional experiment as shown in fig 10 the l moments of the synthetic p signals exhibit a slightly larger spread than the observed estimates and similar averages indicating that the observed variability of these two statistics is within the sampling variability of the g e 4 distribution with a single set of regional shape parameters the larger spread of the synthetic l moments might result from the observed p records having slightly smaller l kurtosis than the synthetic ones note that the l kurtosis is not used in the estimation of the g e 4 parameters however this issue should be further investigated through e g ad hoc monte carlo simulations we then compare the observed cdfs of nonzero p with the 90 cis of the synthetic samples results for the same gages of fig 5 chosen as examples are displayed in fig 11 which shows that 1 the 90 cis of at site gray lines capture very well the observed cdfs across δt s and seasons confirming the suitability of the g e 4 distribution and 2 the regional simulations black lines exhibit somewhat degraded performance that is worse in some cases in winter e g fig 11b d f moreover there are a few cases where the visual assessment suggests that the simulation performance is good but the percent of observations outside the 90 cis labeled as out is 10 this occurs because the discretized measurements at low p values affect the shape of the cdf in a way that leads to several observed values being very close to but outside the 90 cis of the simulations see insets in fig 11 even after the latter ones have been rounded off at multiples of 1 δt mm h as described in the methods these outcomes are confirmed and summarized in fig 12 where the mean across all gages of out is reported for the entire cdf and for f x 0 5 to eliminate the effect of the discretized measurements on this performance metric the at site simulations capture very well the observed cdfs in summer as shown by the mean of out always being 10 for certain δt s in winter the averaged out is 10 for the entire cdf but is dramatically reduced well below the 10 threshold for f x 0 5 as expected the performance of regional lowers compared to at site but is still accurate for f x 0 5 except for δt 3 h in winter importantly the extreme rain rates f x 0 95 are practically always included within the 90 cis not shown overall these findings suggest that the elevation dependent regional model of equations 9 allows capturing the variability of short duration p across all δt s in summer and for most δt s in winter results also indicate that additional factors might be needed to fully explain the variability of winter p for δt 3 h 5 discussion 5 1 summary of results in central arizona our characterization of stcss and marginal distributions reveal that important differences exist in the study region between the statistical properties of short duration p in the two seasons the distinct physical mechanisms driving summer and winter p lead to significant differences for the smallest δt 0 5 h which progressively decrease as p is aggregated over larger δt s summer p is dominated by convective monsoonal thunderstorms whose typical time scale is close to δt 0 5 h these storms are isolated in space and time as revealed by the sharp drop of the spatial correlation at δt 0 5 h for δ 50 km fig 3a top and the lag 1 serial correlation for δt 0 5 h fig 3b top summer p sampled at δt 0 5 h is characterized by high rain rates with intense extremes as shown by the high scale parameter β and the heavy tail of the distribution low γ 1 fig 7 the aggregation of short lived thunderstorms at larger δt s impacts the statistical properties of the p signal in three different ways first it leads to increasingly higher spatial correlation because there are more chances that nonzero p is simultaneously observed at separate locations resulting from storm cells occurring at different times fig 3a top second it causes a further drop in the serial correlation suggesting that multiple cells occur only within 1 2 h fig 3b top third it leads to distributions that have gradually lower magnitudes of the more frequent events compared to winter p at the same δt but still intense extremes heavy tail which are likely controlled by a single storm with very high intensity occurring within δt this is shown by the fact that β decays faster with δt for summer than winter fig 7a while γ 1 does not change significantly fig 7b winter p is dominated by frontal systems that occupy larger areas and last longer than monsoonal thunderstorms this is quantified by 1 the spatial correlation being non negligible at δ 200 km even for the smallest δt fig 3a top and 2 the lag 1 serial correlation being similar for δt 6 h fig 3b top frontal systems lead to relatively low rain rates with little variance when p is sampled at δt 2 h as shown by smaller β than summer and the light tail of the distributions i e high γ 1 fig 7 as p is accumulated over larger δt s the magnitude of both more and less frequent events increases as quantified by 1 β decaying slower with δt compared to summer and becoming comparatively higher for δt 6 h and 2 the tail of the distributions becoming heavier i e γ 1 slightly decreasing the monte carlo simulations with cosmos under prescribed stcs and parameterizations of the marginal distribution provide further insights into the spatial variability of short duration p the hypothesis that the stcs of summer p is homogeneous and isotropic fig 9a cannot be rejected likely because monsoonal thunderstorms are localized and rather stationary and do not exhibit dominant directions the shape of the marginal distribution of p controlled by γ 1 and γ 2 could be considered constant across the region fig 10 similar to the growth curve used in regional frequency analysis of extreme p hosking and wallis 1997 p occurrence related to p 0 and magnitude linked to β are instead highly and moderately affected by elevation respectively figs 8 11 12 these features of stcs and controls on the marginal distribution are also found for winter p when δt 3 h for larger time aggregations the hypothesis of homogeneous and isotropic stcs is instead less sustained fig 9b confirming the preliminary analyses of mascaro 2017 their fig 12 who found that directional correlograms of winter p exhibit anisotropic behavior with higher correlations along the northeast southwest axis this could be explained by the combined effect of storm anisotropy the preferential motion of large scale frontal storms as also suggested by sungmin and foelsche 2019 and the orographic barrier of the mogollon rim fig 1 the shape of the marginal distribution of p sampled at δt 3 h could still be considered constant fig 9 while elevation is not sufficient to fully explain the spatial variability of p magnitude figs 11 12 5 2 generalization of the results and transferability of the approach the results of this work are consistent with and expand the findings of previous studies several efforts krajewski et al 2003 ciach and krajewski 2006 villarini et al 2008 sungmin and foelsche 2019 peleg et al 2013 showed that the spatial correlation of high resolution p could decrease significantly within short distances δ 25 km as p is aggregated at smaller δt s and that the rate of these changes varies with the climatic regimes and seasons our findings confirm these outcomes and further expand them by considering larger δt s and δ s thanks to the large spatial coverage and high density of the rain gage network our results are also in line with molnar and burlando 2008 who showed that winter p in switzerland dominated by frontal systems is more structured i e has higher serial correlation than summer p resulting from convective storms this indicates that qualitatively the considerations reported in the previous section have general validity at sites with a precipitation regime dominated by convective and frontal systems this work provides an effective methodological framework to gain new insights into the space time p variability at any location provided that p observations are available with sufficient density and spatial coverage as known the most accurate p products are ground observations of dense rain gage networks which are becoming increasingly available as part of flood warning systems for example in the u s the counties of harris clark and los angeles as well as the santa clara valley water district operate dense rain gage networks to monitor flooding in the metropolitan areas of houston las vegas los angeles and san jose respectively dense rain gage networks are also available in europe de vos et al 2017 o and foelsche 2019 when rain gages are not available spatially seamless quantitative precipitation estimates from weather radars lin 2011 zhang et al 2016 satellite sensors e g hou et al 2014 and gridded interpolated products e g noaa 2021 kim and villarini 2022 could be very valuable after their ability to capture marginal distributions and stcs and their overall biases are assessed in regions where dense gage networks are available this is one of the subjects of our future work as shown in fig 4 the three parameter distributions cover several combinations of l moments and thus they should be able to capture a large variety of p distribution shapes across climatic regimes other parametric forms have been proposed by naveau et al 2016 and papalexiou 2022 the clayton copula stcs was found to be a flexible homogeneous and isotropic model that well captures the empirical stcs in our study region specifically the clayton copula stcs has the minimum number of parameters that allow adequate control of the scale and shape of the spatial and temporal correlations bs cs bt ct as well as of their interactions θ if the clayton copula is not considered adequate at other sites papalexiou and serinaldi 2020 and papalexiou et al 2021 proposed alternative analytical forms of stcs and provided suggestions to design new analytical models that might be needed to account for anisotropy and or spatial heterogeneity once marginal distribution and stcs have been parameterized the cosmos framework could then be used to validate hypotheses on their variability as done here 6 conclusions this study advances the knowledge of and ability to model the stcs and marginal distribution of short duration 24 h p two properties that have received relatively little attention in the literature due to the lack of adequate reliable observations a systematic analysis of the seasonal and spatial variability of these properties is conducted in a large region in central arizona using a high density network of gages with long term high resolution p records the empirical stcss are captured well by the clayton weibull parametric stcs while three parametric distributions namely the g g b r xii and g e 4 describe well the empirical distribution of nonzero p for all δt s with the g e 4 providing the best results these parametric models show that summer p dominated by short lived convective thunderstorms exhibits weaker correlation structure and heavier tails of the distribution than winter p which is instead controlled by longer and widespread frontal systems monte carlo experiments relying on stochastic simulations with the cosmos space time p model show that in most cases the stcs of p could be considered homogeneous and isotropic the marginal distribution has constant shape across the region and the spatial variability of p occurrence and mean intensity is controlled by elevation the only exception is winter p at δt 3 h that shows possible non homogeneity and anisotropy in the stcs and requires additional factors to explain the spatial variability of the mean p intensity the methodological framework of this work could be applied at other sites and is then useful for parameterizing testing and improving p models and weather generators sørup et al 2016 paschalis et al 2013 peleg et al 2017 grimaldi et al 2022 kim and onof 2020 as well as for validating in a statistical sense numerical p simulations from convection permitting atmospheric models i e verifying the degree to which the probability distributions and space time correlation structures of their simulated p time series are consistent with the parametric forms presented here we identify several future research avenues to further support these goals the description of the stcs should be improved by accounting for storm advection and anisotropy jameson 2021 the potential existence of nonlinear dependencies between the p signals at different time lags should be better quantified and modeled using e g copulas as recently suggested by papalexiou 2022 analyses should also target the characterization of the stcs of the binary signal of rain no rain as well as the assessment of the ability of the proposed marginal distributions to capture p extremes and develop strategies to regionalize their parameters finally while the findings of this study did not indicate the existence of significant differences between the stcs and marginal distributions of all nonzero p in urban and non urban regions of the study area not shown additional efforts should be devoted to further investigating the presence of differences by focusing on the extremes as suggested by the recent study of huang et al 2022 credit authorship contribution statement giuseppe mascaro conceptualization methodology software validation formal analysis investigation data curation writing original draft visualization supervision funding acquisition simon michael papalexiou conceptualization methodology software writing original draft visualization daniel b wright conceptualization writing original draft declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests giuseppe mascaro reports financial support was provided by the national institute of standards and technology and the national science foundation acknowledgments we thank three anonymous reviewers for their comments that helped to improve the quality of the paper this work has been supported by the national science foundation nsf award 1831475 scc community based automated information for urban flooding and the national institute of standards and technology nist award 70nanb22h056 assessing the utility of safe to fail design to improve climate hazards resilience of interdependent infrastructure systems the authors thank stephen d waters from the flood control district of maricopa county for providing the rainfall data of the network appendix a estimation of distribution parameters using l moments parameters of the g g b r xii and g e 4 were estimated using the numerical procedure proposed by zaghloul et al 2020 which is based on the method of l moments for distributions with one scale parameter and two shape parameters the l variation τ 2 and l skewness τ 3 depend only on the shape parameters γ 1 and γ 2 following hosking 1990 the integral forms of τ 2 and τ 3 are a1 τ 2 γ 1 γ 2 λ 2 λ 1 0 1 q u 1 γ 1 γ 2 2 u 1 d u 0 1 q u 1 γ 1 γ 2 d u a2 τ 3 γ 1 γ 2 λ 3 λ 2 0 1 q u 1 γ 1 γ 2 6 u 2 6 u 1 d u 0 1 q u 1 γ 1 γ 2 2 u 1 d u where λq q 1 2 3 is the q order l moment and q u 1 γ1 γ2 is the quantile function of any of the three distributions with scale parameter β 1 for each record the sample values of the l moments τ 2 and τ 3 are calculated and parameters γ 1 and γ 2 are estimated by minimizing the squared difference between the sample and theoretical l moments in symbols a3 γ 1 γ 2 argmi n γ 1 γ 2 q 2 3 τ q γ 1 γ 2 τ q 2 eq a3 is solved numerically by substituting eqs a1 and a2 after estimating γ 1 and γ 2 the scale parameter β is calculated by minimizing the function a4 β argmi n β λ 1 β λ 1 2 where λ 1 β 0 1 q u β γ 1 γ 2 d u and λ 1 is the sample estimate of the first order l moment appendix b metrics quantifying goodness of fit of the parametric distributions the goodness of fit gof of the parametric distributions is quantitatively assessed through the cramer von mises statistic w 2 deidda and puliga 2006 laio 2004 and the mean relative mean square error relmse papalexiou et al 2013 defined as a5 w 2 1 12 n i 1 n f t h e o r x i f e m p x i 2 a6 relmse i 1 n f t h e o r x i f e m p x i 1 f e m p x i 2 where xi is the i th ascending order statistic n is the sample size ftheor xi is the theoretical cdfs one of the three parametric distributions mentioned above and f e m p x i i 0 5 n is the empirical cdf estimated through the hazen plotting position formula both metrics provide a measure of the correspondence between theoretical and parametric cdfs with w2 giving the same weight to all order statistics and relmse assigning larger weights to the differences in the right tail of the distribution appendix c overview of the complete stochastic modeling solution cosmos we provide here a brief description of the version of cosmos used here referring the reader to papalexiou 2018 and papalexiou and serinaldi 2020 for additional details and to papalexiou et al 2021 and papalexiou 2022 for further developments of this modeling framework let x si t be a stationary stochastic process describing the time series of p at temporal aggregation δt at s locations si with i 1 s cosmos assumes that the process x si t can be simulated by transforming a parent standard gaussian process z si t with an appropriate stcs ρ z τ δ related to the stcs of x the method is applied through the following steps a stcs for x ρ x τ δ is identified preferably through an analytical model as done in section 3 2 a suitable marginal distribution of p fi x for x is specified at each gage location the stcs for the parent gaussian process z ρ z τ δ is obtained by inflating ρ x τ δ through the correlation transformation function a7 ρ x τ δ r ρ z τ δ c ρ z τ δ μ x 2 σ x where μx and σx are the mean and standard deviation of x computed from the parametric form of fi x and c ρ z τ δ e x i x j is the expectation of the product between x at two locations i and j the latter term involves an integral that is solved numerically for a given value of ρz therefore one applies eq a7 to calculate ρx for a set of fixed values of ρz e g 0 0 05 0 10 0 95 1 and then fits an analytical relation to the computed ρz ρx pairs to map ρz ρx here the following empirical equation suggested by papalexiou and serinaldi 2020 is found to capture well this relation a8 ρ z 1 b ρ x 1 c 1 1 b 1 c 1 where b and c are coefficients it is worth noting that while μx and σx may vary in space for this step they could assumed to be constant to simplify the numerical application of cosmos with minimal impact of its performance to simulate time series of t time steps at s sites a multivariate autoregressive model mar p of order p with stcs ρ z τ δ is used to generate s t standard gaussian variates z si t these are transformed into x variates x si t through the marginal back transformation x s i t f i 1 φ z s i t where φ is the standard gaussian cdf here the order p was chosen as the time lag where the serial correlation decays to a negligible value i e 0 05 
13,the statistical characterization of precipitation p at short durations 24 h is crucial for practical and scientific applications here we advance the knowledge of and ability to model the space time correlation structure stcs and marginal distribution of short duration p using a network of rain gages in central arizona with one of the largest densities and spatial coverages in the world we separately analyze summer and winter p sampled at multiple durations δt from 0 5 to 24 h we first identify an analytical model and a three parameter distribution that robustly capture the empirical stcs and marginal distribution of p respectively across δt s we then conduct monte carlo experiments consisting of multisite stochastic simulations of p time series to explore the spatial and seasonal variability of these properties significant seasonal differences emerge especially at low δt summer winter p exhibits weak strong correlation structure and heavy light tailed distributions resulting from short lived isolated thunderstorms widespread long lasting frontal systems the stcs of p is most likely homogeneous and isotropic except for winter at δt 3 h where anisotropy could be introduced via the motion of frontal storms the spatial variability of the marginal distribution is reproduced by a regional parameterization dependent on elevation in all cases except again for winter at δt 3 h where additional factors are needed to explain the variability of the mean p intensity this work provides insights to improve stochastic p models and validate convection permitting models used to investigate the mechanisms driving changes in short duration p keywords short duration precipitation multisite stochastic rainfall modeling space time rainfall correlation rainfall probability distributions data availability precipitaton data from the fcdmc rain gage network are available at the website https www fcd maricopa gov 625 rainfall data 1 introduction quantifying the spatiotemporal variability of precipitation p at short durations here 24 h is crucial for several practical and scientific goals it is key to generate more realistic design storms for urban stormwater infrastructure gires et al 2014 ichiba et al 2018 peleg et al 2013 improve estimates of areal reduction factors used to convert extreme point p into areal averaged p wright et al 2013 veneziano and langousis 2005 and increase the accuracy and resolution of indirect p estimates from weather radars krajewski et al 2010 and satellite sensors tang et al 2016 the knowledge of short duration p variability is also needed to develop and test stochastic models of temporal spatial and spatiotemporal p fields venugopal et al 1999 schertzer and lovejoy 1987 deidda 2000 bárdossy and pegram 2009 burton et al 2008 papalexiou and serinaldi 2020 papalexiou 2018 papalexiou et al 2021 paschalis et al 2013 peleg et al 2017 kim and onof 2020 rebora et al 2006 among others the high resolution p time series or grids generated by these models have been useful to increase the value of physics based distributed hydrologic models in studies on flood generating mechanisms paschalis et al 2014 mascaro et al 2013b flood frequency wright et al 2014 and climate change impacts piras et al 2014 among other goals moreover outputs of space time p models have the potential to enhance the accuracy of p forecast harris et al 2001 and in turn the skill of flood and flash flood forecasting systems seo et al 2013 alfieri and thielen 2015 particularly in urban regions where watersheds have short response times hjelmstad et al 2021 many studies have provided insights into the spatiotemporal variability of short duration p by investigating the presence of scaling regimes i e time and or space intervals where the p statistical properties are linked via power law relations across a wide range of temporal and spatial scales through spectral multifractal and wavelet based frameworks in most cases a single regime was found from a few days to 0 5 1 h and in some sites where sub hourly measurements were available an additional regime was detected from 0 5 1 h to a few minutes e g fraedrich and larnder 1993 deidda et al 1999 mandapaka et al 2015 verrier et al 2011 mascaro et al 2013a seasonal differences in temporal scaling regimes have also been identified and attributed to different dominant weather systems molnar and burlando 2008 mascaro et al 2014 mascaro 2017 the evidence of p scaling has been also shown in space from 100 200 km to about 1 km and in space time frameworks schertzer and lovejoy 1987 venugopal et al 1999 deidda 2000 deidda et al 2004 mascaro et al 2013b this body of knowledge has significantly advanced our understanding of short duration p and allowed the development of sophisticated stochastic space time p models however the datasets used in previous studies have been largely restricted to p observations collected during short term field experiments or available at a few sites with limited spatial coverage and density this is because rain gage p records at sub daily resolution are still limited and sparse lewis et al 2019 morbidelli et al 2020 while radar and satellite derived p estimates are heavily affected by several sources of errors especially at high temporal resolutions michaelides et al 2009 krajewski et al 2010 as a result further analyses of high quality long term p observations at high temporal and spatial resolutions are needed to confirm the validity of previous findings examine aspects of short duration p variability that have received less attention and support the operational use of space time stochastic p models these needs have become particularly important given recent evidence that short duration p extremes have been intensifying due to global warming fowler et al 2021 prein et al 2017b and urbanization huang et al 2022 moreover new knowledge on the statistics of short duration p would be useful to validate convection permitting atmospheric models that are being increasingly applied to study the mechanisms driving changes in short duration p chen et al 2021 prein et al 2017a two important statistical properties of short duration p that have received relatively less attention are the spatiotemporal correlation structure stcs and the distribution of the intermittent process of zero and nonzero p values previous work has focused on either the spatial correlation of p within short distances 25 km or the temporal serial correlation at single sites ciach and krajewski 2006 habib et al 2001 mascaro 2017 zawadzki 1973 marani 2005 jameson 2021 schleiss et al 2011 among others changes in correlation structure of p for different combinations of space and time lags over large regions have not yet been explored recently new flexible analytical models have been proposed by papalexiou and serinaldi 2020 and papalexiou et al 2021 to characterize the stcs of p but these have not been tested yet against observations at fine temporal scales other recent studies have suggested single and two component parametric distributions that could properly capture the body and tails of the distribution of short duration nonzero p papalexiou and koutsoyiannis 2016 emmanouil et al 2021 naveau et al 2016 while promising the recent methodological advancements on both the stcs and the marginal distribution of short duration p require empirical corroboration and their value should be systematically investigated across different time scales seasons and sites these research needs are addressed in the study which has the main goal of advancing the ability to characterize and model the stcs and marginal distributions of short duration p to robustly investigate these statistical properties we analyze long term 20 years high resolution 30 min p records from a network of rain gages in central arizona which to our knowledge has one of the largest densities and spatial coverages in the world this study region is compelling due to the strong seasonality of the p regime and the effect of orography which lead to marked variability in the statistical properties of p mascaro 2017 2018 2020 we address the following research questions that have both scientific and practical implications and that provide arguably the first systematic characterization of stcs and marginal distribution of p across multiple temporal scales with an extensive and high quality 30 min dataset 1 how does the stcs of p at durations 24 h vary seasonally 2 can the stcs be considered homogenous and isotropic homogeneous means that the function is spatially stationary across the region while isotropic means that the correlation is only affected by the distance between two sites and does not depend on the direction along which the distance is computed 3 is there a parametric distribution that adequately describes the body and tails of the nonzero p marginal distribution across multiple p durations 4 does the presence of serial correlation in short duration p series significantly affect the estimation of the distribution parameters and 5 how do the distribution parameters vary seasonally and spatially and can they be regionalized to answer these research questions we perform a set of monte carlo experiments with the complete stochastic modeling solution cosmos papalexiou 2018 papalexiou and serinaldi 2020 papalexiou et al 2021 papalexiou 2022 which allows for the stochastic simulation of p time series at multiple sites that preserve prescribed marginal distributions and stcs while these research questions are investigated in central arizona our methodological framework provides new insights into the space time p variability at any location and provides key information to increase the reliability of space time simulations of short duration p 2 study area and dataset our study region is in central arizona and includes the phoenix metropolitan area fig 1a where the flood control district of maricopa county fcdmc has deployed a network of rain gages to monitor intense storms the gages were progressively installed since 1980 eventually reaching the current number of 365 in this study we use records of 223 gages with more than 20 years of observations fig 1b the gages cover a region of 29 600 km2 that mainly encompasses the sonoran desert at low elevations from 200 to 700 m above the sea level asl and extends up to the southwestern portion of the mogollon rim at 2325 m asl most gages are in urban areas 2000 km2 with a density of 4 3 gauges per 100 km2 when considering the entire region the density decreases to 1 gauge per 100 km2 the distribution of the inter gage distance is presented in fig 1c demonstrating that this network allows characterizing with unprecedented detail the spatial variability of p statistical properties including correlation structure and marginal distribution the climate in this region of the desert southwestern u s is hot and arid according to the köppen geiger classification the climate is categorized as bwh in most of the region with smaller portions classified as bsh bsk and dsb as the elevation increases fig 1d acronyms defined in its caption the rainfall regime is strongly seasonal summers are dominated by the north american monsoon nam from july to september adams and comrie 1997 during which short lived 1 h spatially localized thunderstorms occur with moderate to high rainfall intensities according to a diurnally modulated cycle winters defined here from november to march are characterized by westerly flow and extended dry periods that are occasionally interrupted by cold fronts that may cause large scale storm systems controlled by dynamical lifting resulting in low to moderate rainfall intensities these storms tend to be widespread and often cover the entire region and last for a few days previous studies mascaro 2017 2018 2020 have investigated several statistical properties of the rainfall regime in the region their findings inform the new research directions pursued in this work 3 methods 3 1 data processing the fcdmc provides p data in a raw format containing the tipping instants in seconds with a resolution of 1 mm for each tip we obtain the rainfall time series at different temporal resolutions δt 0 5 1 2 3 6 12 and 24 h using the method described by mascaro et al 2013 which limits the discretization of the signal caused by the commonly used box counting unfortunately we find that the resolution of the gage bucket of 1 mm is quite coarse and limits the effectiveness of the smoothing procedure therefore the p time series exhibit a considerable fraction of repeated values that are multiples of 1 δt mm h which affect the comparison of the observed p statistics with those of the non discretized synthetic samples generated with cosmos we partially address this issue see results by rounding off the synthetic samples through a procedure based on deidda 2007 that involves 1 estimating the percentage of observed measurements rounded off at multiples of 1 δt mm h and 2 adopting these percentages to round off the corresponding synthetic samples given the different storm generating mechanisms described in section 2 analyses are conducted separately for summer july september and winter november march 3 2 spatiotemporal correlation structure the spatiotemporal correlation structure stcs describes the correlation here linear between two random variables lagged by time τ in hours and placed at a distance δ in km papalexiou and serinaldi 2020 in symbols ρ x τ δ cor x t si x t τ sj with t being any time instant and δ the euclidian distance between locations si and sj here we model the stcs of p using a parametric form emerging from the clayton copula and the weibull survival function papalexiou and serinaldi 2020 the clayton weibull stcs is stationary and isotropic and given by 1 ρ x τ δ θ exp θ δ b s c s exp θ τ b t c t 1 1 θ where θ bs cs bt ct θ is the parameter vector note that the indices s and t stand for space and time respectively to estimate θ we compute 1 the empirical correlation matrixes of the gage records at different time lags r δt k whose generic element r i j δ t k is the pearson correlation coefficient between the p signal at resolution δt at gage i and the p signal at the same resolution lagged by τ k δt at gage j where k is the lag index ranging from 0 to the number of investigated lags p and 2 the distance matrix d whose generic element dij is the euclidian distance between gages i and j we then use these matrixes to solve the least square regression equation 2 θ argmi n θ f i 1 n 1 j i 1 n k 0 p r i j δ t k ρ x k δ t d i j θ 2 where the sum over i and j is used to include the terms in the upper triangle of the symmetric matrixes the calculations are performed in matlab using the function fit 3 3 candidate marginal distributions and parameter estimation when considered at small aggregation times p is an intermittent process that includes zero and nonzero values its distribution is then characterized by a probability mass concentrated at zero p 0 and a continuous part that characterizes nonzero values in symbols if x is the random p variable at a given resolution δt its cumulative distribution function cdf fi x with the subscript i referring to the intermittent process is given by 3 x f i x p 0 1 p 0 f x with f x being the cdf of nonzero p i e valid for x 0 in this study we estimate p 0 as n 0 n with n 0 being the number of time steps where p is zero and n is the total number of time steps for f x we explore the suitability of three parameter distributions that have been shown flexible to capture left and right tails as well as the body of the empirical distribution of positive hydrologic variables papalexiou and koutsoyiannis 2012 papalexiou 2022 these include the generalized gamma g g burr type xii b r xii and generalized exponential type 4 g e 4 distributions their cdfs are 4 f g g x 1 γ γ 1 γ 2 x β γ 2 γ γ 1 γ 2 5 f b r xii x 1 1 γ 2 x β γ 1 1 γ 1 γ 2 6 f g e 4 x 1 exp x β γ 1 1 γ 2 1 1 γ 2 these distributions are defined for x 0 γ 1 0 and γ 2 0 are parameters controlling the shape of the distribution and β 0 is the scale parameter γ and γ denotes the incomplete gamma and gamma functions respectively parameters are estimated using the numerical approach recently proposed by zaghloul et al 2020 based on the method of l moments hosking and wallis 1997 details are provided in appendix a the suitability of the distributions is evaluated graphically with the l moment ratio diagram and further assessed quantitatively via two goodness of fit gof metrics reported in appendix b 3 4 monte carlo experiments with cosmos we design monte carlo experiments based on the version of the complete stochastic modeling solution cosmos for multisite stochastic simulations of p time series that preserve prescribed space time correlation structure and marginal distribution of p papalexiou and serinaldi 2020 this version of cosmos is briefly described in appendix c the experiments are used to investigate 1 the homogeneity and isotropy of the stcs in each season and 2 the spatial variability of the distribution of the intermittent p process for each δt an ensemble of synthetic time series is generated at the 223 gage locations with the same observed record lengths under prescribed stcs and marginal p distributions the statistical properties of the synthetic time series are then compared to the observations an additional monte carlo experiment is carried out to test the effect of serial correlation on parameter estimation for the distribution of nonzero p this involves the generation of long term times series at a single site with prescribed serial correlation i e the stcs with δ 0 and marginal p distribution further details are provided in the next section 4 results 4 1 spatiotemporal correlation structure seasonal differences and effect of time aggregation the clayton weibull stcs is fitted to the empirical pearson correlation coefficients for summer and winter p as an example results for δt 0 5 h are reported in fig 2 visual inspection of the stcs surface and the cross sections for fixed values of τ and δ chosen as examples suggests that the clayton weibull analytical model captures very well the median empirical correlation structure of p in the two seasons this is true for all δt s as an example results for δt 6 h are shown in fig s1 in the supplementary material with the root mean square error between empirical and theoretical stcss ranging from 0 02 to 0 04 across all cases the estimated parameters of the clayton weibull stcs for all δt s are reported in fig s2 given its effect on both the spatial and temporal correlation functions we investigated the role of the θ parameter and found it to depend on the values of the other four parameters and to be overall relatively minor and more significant for the spatial correlation at τ 1 δt additional considerations are provided in figs s3 and s4 given its ability to represent the empirical stcs across all cases we use the clayton weibull model to explore seasonal differences of the p correlation structure as a function of δt to this end we plot in fig 3 the clayton weibull stcs for fixed values of τ and δ for δt 0 5 h which is the characteristic timescale of single convective storms and for δt 3 6 and 24 h which capture the behavior of larger single and multiple storms we first note that for any given δt ρx of all spatial fixed τ and temporal fixed δ correlation functions are higher in winter than in summer this occurs because winter events are longer and more widespread whereas summer monsoonal storms are more localized in time and space and intermittent higher probability of zero p the spatial correlation of p with no temporal lag τ 0 δt shows that ρx increases with δt in both seasons fig 3a top panels this is expected since as the p signal is aggregated over larger time steps multiple storm cells may occur over a bigger spatial domain and there is a higher chance that nonzero p is simultaneously observed at sites located at large distances if we instead consider the spatial correlation of temporally lagged τ 1 δt p series fig 3a bottom panels the role of δt changes dramatically with similar impacts in the two seasons for the largest δt 24 h ρx drops to a very low value that is constant with δ suggesting that in our study region storms rarely last for more than 24 h for δt 0 5 h ρx declines but its values are nonnegligible for δ 50 km especially in winter the behavior of the spatial correlation for δt 3 h and 6 h is intermediate between the largest and smallest δt s discussed above as expected the temporal correlation for δ 0 km i e the serial correlation functions fig 3b top panels for a given dimensionless lag k increases in both seasons as δt is reduced in other words as we consider shorter time steps there is a higher chance that p observations at the same location are similar within a few time steps the temporal correlation evaluated at sites at a distance δ 20 km fig 3b bottom panels is substantially similar to that for δ 0 km except for k 0 where ρx is significantly lower than 1 for all δt s with a more significant drop observed for δt 30 min because of the smaller spatial coverage of single storms in summary the spatial correlation of p for τ 0 δt fig 3a upper panels declines faster as the resolution increases i e lower δt whereas the opposite is true for the temporal correlation of p for δ 0 fig 3b upper panels this behavior is reversed for lagged spatial correlations fig 3a lower panels and fixed distance lagged correlations fig 3b lower panels 4 2 marginal distribution of short duration precipitation 4 2 1 selection of parametric distribution of nonzero precipitation we first focus on the distribution of nonzero p f x and evaluate the suitability of the g g b r xii and g e 4 theoretical models fig 4 presents the l moment ratio diagrams l skewness vs l variation for three representative δt s each panel displays the sample l moments along with surfaces obtained for different combinations of the shape parameters γ 1 and γ 2 for each of the three considered distributions note that distributions with a single shape parameter would instead be represented by a curve in the l skewness l variation space the l moments of p records exhibit seasonal differences with winter p characterized by lower values of both l ratios than summer p the differences are marked at lower δt and tend to be smaller as δt increases the g g is the least flexible distribution and its surface does not fully include the sampling variability of the l ratios on the other hand the b r xii is the most flexible however its shape parameters for low δt in summer γ 2 0 5 lead to distributions with infinite variance which is an undesirable condition for modeling time series stochastically since unrealistically large events could be frequently generated the g e 4 has intermediate flexibility and captures all possible combinations of the sample l moments while having always finite moments the gof of the distributions is further evaluated by plotting in fig 5 the empirical cdfs of nonzero p at different δt s in the two seasons at four representative gages along with the fitted theoretical distributions we first note that despite the presence of several repeated values that are multiples of 1 δt mm h the fitting of the distributions through the method of l moments is quite effective all parametric models capture very well the body of the empirical cdf f x 0 9 shown in insets differences emerge in some cases at the right tail with b r xii exhibiting heavier tails and the largest deviations from the empirical distribution this is quantified by the values of the gof metrics of appendix b w 2 and relmse reported in table 1 for the examples of fig 5 boxplots summarizing the gof metric across all gages are displayed in fig s7 which further indicate that the discrepancies of the b r xii in the right tail measured by relmse are higher for lower δt interestingly even if the region of theoretical l moments for the g g does not capture the sample points for δt 0 5 h see fig 4a the closest pairs of γ 1 and γ 2 to the corresponding sample point returned by the parameter estimation method leads to a fairly good fit to the observed cdf given the overall higher performance in the following analyses the g e 4 is used as the marginal distribution for nonzero p 4 2 2 effect of serial correlation on parameter estimation for low δt the serial correlation of the p time series can be high and the assumption of independent events may not hold from the practical standpoint this implies that the effective sample size is reduced thus increasing uncertainty when estimating the marginal distribution parameters to evaluate this we perform monte carlo experiments where cosmos is used to generate two ensembles of nens 100 long term serially correlated and uncorrelated time series respectively of intermittent p at δt 0 5 h the highest resolution is chosen since it has the strongest serial correlation see fig 3b for these ensembles we use 1 the mean p 0 across the gages 2 the g e 4 distribution for f x with mean values of γ 1 γ 2 and β and 3 the serial correlation provided by the clayton weibull stcs ρ x τ δ 0 this is done separately for summer and winter generating in each case 200 consecutive seasons i e a dataset of 200 years of observations fig 6a shows the theoretical serial correlations and marginal distributions of the intermittent p process fi x used to apply cosmos in the two seasons along with the corresponding empirical functions from one of the synthetic time series the correspondence is remarkable indicating that the cosmos framework reproduces very well these statistical properties of the p signal parameters γ 1 γ 2 and β are then re estimated by fitting the g e 4 to the nonzero p of each synthetic time series for the number of seasons m ranging from 10 to 200 results are presented in fig 6b which shows the 90 confidence intervals of the estimated parameters in all cases and for all m s the estimates are unbiased and the uncertainty of correlated and uncorrelated series is the same even for low m the only exception is the case of γ 1 in winter where the uncertainty of the correlated series is slightly larger likely because of the stronger serial correlation overall these experiments suggest that the considered samples are long enough that the presence of serial correlation does not significantly affect parameter estimation therefore there is no practical need to apply techniques to identify statistically independent events as in principle required by the assumption of independent and identically distributed i i d variables this result was verified for all δt s not shown if in future applications this turns out not be the case due to stronger serial correlations smaller samples or the use of a different probability distribution the proposed monte carlo framework could be used to identify strategies to extract an independent sample from the original time series or bias correct the parameter estimates 4 2 3 seasonal variability of the marginal distribution as a function of time aggregation fig 7a presents the boxplots of p 0 and the g e 4 parameter estimates at the 223 gages for all δt s seasonal differences emerge for all parameters the probability of zero p p 0 is slightly higher in summer than winter when the signal is aggregated up to δt 6 h the opposite is true for longer time aggregations moreover the relation between p 0 and δt is linear r2 0 95 not detectable in the semilogarithmic plot of fig 7a with a mean slope of 4 3 10 3 3 3 10 3 h 1 in summer winter the scale parameter β is 1 relatively larger for summer p at smaller δt s 2 similar in the two seasons at intermediate δt 6 h and 3 higher for winter p at larger aggregation times in addition β exhibits a scaling relationship with δt highlighted through the log log plot with a slope of 0 68 0 57 in summer winter focusing on the shape parameters γ 1 is larger for winter than summer p while the opposite is true for γ 2 but with less notable differences as expected by the location of the l moments estimates see fig 4 neither parameter exhibits significant variations with δt when considering summer p except for slightly higher values of γ 2 for δt 1 h larger variations of the shape parameters with δt are instead observed for winter p particularly for γ 1 that decreases between δt 0 5 h to δt 6 h we further investigate the relationship between the shape parameters as a function of the time aggregation in each season by plotting in fig 7b the scatterplots between γ 1 and γ 2 for all δt s the two g e 4 parameters are inversely related in a nonlinear fashion in summer a single relation encapsulates the estimates for all δt s with slightly higher lower values of γ 1 γ 2 found for δt 6 h in contrast distinct relationships between the two parameters emerge in winter for each δt to visualize how these outcomes affect the shape of f x fig 7c e display the g e 4 cdfs with the median parameter values for δt 0 5 6 and 24 h in the two seasons which are also depicted with arrows in fig 7b the distribution of summer p is always heavy tailed with very limited changes of its shape across δt s winter p is instead characterized by a distribution with much lighter tails than summer and whose heaviness gradually increases with δt our sensitivity tests and the visual inspection of fig 7b indicate that 1 γ 1 exerts the largest control on the right tail and 2 differences in β mainly affect the body of the distribution f x 0 9 4 2 4 spatial variability of the marginal distribution as a next step we investigate whether the inter gage variability of p 0 and g e 4 parameters results from sampling variability or is related to local physical factors we find that p 0 has a rather constant value for elevation z lower than 400 m asl and decreases linearly with z with a slope that is larger in absolute value i e stronger orographic control as δt increases this is shown in fig 8a b for three δt s while maps are reported in fig s8 the pearson correlation coefficient cc with z is 0 81 across seasons and δt s the scale parameter β is moderately related to z in a nonlinear fashion as presented in the examples of fig 8c d for three δt s and quantified by spearman cc between 0 21 and 0 51 across all cases for the shape parameters γ 1 and γ 2 no significant relations are found with z or gage coordinates examples of maps of the three g e 4 parameters are reported in figs s5 s6 4 3 insights into the correlation structure and physical controls on short duration precipitation through stochastic simulations with cosmos the insights gained in the previous sections allow designing monte carlo experiments with cosmos to investigate the following two hypotheses 1 the stcs of short duration p in the region could be considered spatially homogeneous and isotropic in each season and 2 the spatial variability of the parameters of the marginal distribution fi x is explained by a few regional relations the latter ones are identified based on the empirical evidence presented in section 4 2 4 which suggests that for a given δt and season the shape of the nonzero p distribution controlled γ 1 and γ 2 can be considered constant while the scale parameter β and p 0 are related to the elevation this translates into the following relations for each δt 9a p 0 p 0 m a x z z p 0 m a x m z z z z 9b γ 1 γ 1 9c γ 2 γ 2 9d β β β β 0 e q z where p 0 max and m are intercept and slopes of the linear relation respectively and z 400 m asl γ 1 and γ 2 are the g e 4 shape parameters corresponding to the sample mean l variation and l skewness across all gages see fig 4g i and β β 0 and q are coefficients of a decreasing exponential relationship linking the g e 4 scale parameter with z see fig 8c d the latter one is the same analytical relation that was found by mascaro 2018 to well capture the relation between z and the scale parameter of the generalized pareto distribution used as a theoretical model of daily extreme p in this region the values of the estimated coefficients and parameters of equations 9 in each season and δt are reported in table 2 to evaluate these hypotheses for each δt we perform two sets of simulations with cosmos each consisting of the generation of 100 spatially and temporally correlated synthetic time series at the 223 gages with the same duration of the observed records in the first set parameters of fi x are specified using the at site estimates labeled at site while in the second set parameters are obtained through the regional equations 9a d labeled regional in both cases the clayton weibull model of eq 1 with parameters reported in fig s2 is used to estimate the stcs the at site simulations are expected to provide the best possible performance of this version of cosmos with a homogeneous and isotropic stcs our first hypothesis is then addressed by quantifying the discrepancies between the observed inter gage correlations and those computed from the at site synthetic time series the second hypothesis is assessed by measuring the degree to which the performance of regional in simulating the observed l moments and empirical marginal p distributions degrades compared to at site fig 9 shows for three δt s and both seasons the correlation coefficients between the observed p signals at all gage pairs for two temporal lags τ as a function of the inter gage distance δ along with the 90 confidence interval ci derived from the 100 at site simulations with cosmos note that results are the same for regional since the same analytical stcs is used in both experiments in summer a single analytical model for the stcs captures remarkably well the empirical values for all δ τ and δt performances slightly degrade in winter i e more cases have 10 of the observed correlations outside the cis especially for δt 3 h but they are still satisfactory in most cases these findings suggest that in summer the stcs of subdaily and daily p could be considered with high confidence homogeneous and isotropic while a certain degree of nonhomogeneity and or anisotropy exists in winter to investigate the second hypothesis we first compare the l moments ratio diagrams of the observed samples same as fig 4 and one ensemble member of the regional experiment as shown in fig 10 the l moments of the synthetic p signals exhibit a slightly larger spread than the observed estimates and similar averages indicating that the observed variability of these two statistics is within the sampling variability of the g e 4 distribution with a single set of regional shape parameters the larger spread of the synthetic l moments might result from the observed p records having slightly smaller l kurtosis than the synthetic ones note that the l kurtosis is not used in the estimation of the g e 4 parameters however this issue should be further investigated through e g ad hoc monte carlo simulations we then compare the observed cdfs of nonzero p with the 90 cis of the synthetic samples results for the same gages of fig 5 chosen as examples are displayed in fig 11 which shows that 1 the 90 cis of at site gray lines capture very well the observed cdfs across δt s and seasons confirming the suitability of the g e 4 distribution and 2 the regional simulations black lines exhibit somewhat degraded performance that is worse in some cases in winter e g fig 11b d f moreover there are a few cases where the visual assessment suggests that the simulation performance is good but the percent of observations outside the 90 cis labeled as out is 10 this occurs because the discretized measurements at low p values affect the shape of the cdf in a way that leads to several observed values being very close to but outside the 90 cis of the simulations see insets in fig 11 even after the latter ones have been rounded off at multiples of 1 δt mm h as described in the methods these outcomes are confirmed and summarized in fig 12 where the mean across all gages of out is reported for the entire cdf and for f x 0 5 to eliminate the effect of the discretized measurements on this performance metric the at site simulations capture very well the observed cdfs in summer as shown by the mean of out always being 10 for certain δt s in winter the averaged out is 10 for the entire cdf but is dramatically reduced well below the 10 threshold for f x 0 5 as expected the performance of regional lowers compared to at site but is still accurate for f x 0 5 except for δt 3 h in winter importantly the extreme rain rates f x 0 95 are practically always included within the 90 cis not shown overall these findings suggest that the elevation dependent regional model of equations 9 allows capturing the variability of short duration p across all δt s in summer and for most δt s in winter results also indicate that additional factors might be needed to fully explain the variability of winter p for δt 3 h 5 discussion 5 1 summary of results in central arizona our characterization of stcss and marginal distributions reveal that important differences exist in the study region between the statistical properties of short duration p in the two seasons the distinct physical mechanisms driving summer and winter p lead to significant differences for the smallest δt 0 5 h which progressively decrease as p is aggregated over larger δt s summer p is dominated by convective monsoonal thunderstorms whose typical time scale is close to δt 0 5 h these storms are isolated in space and time as revealed by the sharp drop of the spatial correlation at δt 0 5 h for δ 50 km fig 3a top and the lag 1 serial correlation for δt 0 5 h fig 3b top summer p sampled at δt 0 5 h is characterized by high rain rates with intense extremes as shown by the high scale parameter β and the heavy tail of the distribution low γ 1 fig 7 the aggregation of short lived thunderstorms at larger δt s impacts the statistical properties of the p signal in three different ways first it leads to increasingly higher spatial correlation because there are more chances that nonzero p is simultaneously observed at separate locations resulting from storm cells occurring at different times fig 3a top second it causes a further drop in the serial correlation suggesting that multiple cells occur only within 1 2 h fig 3b top third it leads to distributions that have gradually lower magnitudes of the more frequent events compared to winter p at the same δt but still intense extremes heavy tail which are likely controlled by a single storm with very high intensity occurring within δt this is shown by the fact that β decays faster with δt for summer than winter fig 7a while γ 1 does not change significantly fig 7b winter p is dominated by frontal systems that occupy larger areas and last longer than monsoonal thunderstorms this is quantified by 1 the spatial correlation being non negligible at δ 200 km even for the smallest δt fig 3a top and 2 the lag 1 serial correlation being similar for δt 6 h fig 3b top frontal systems lead to relatively low rain rates with little variance when p is sampled at δt 2 h as shown by smaller β than summer and the light tail of the distributions i e high γ 1 fig 7 as p is accumulated over larger δt s the magnitude of both more and less frequent events increases as quantified by 1 β decaying slower with δt compared to summer and becoming comparatively higher for δt 6 h and 2 the tail of the distributions becoming heavier i e γ 1 slightly decreasing the monte carlo simulations with cosmos under prescribed stcs and parameterizations of the marginal distribution provide further insights into the spatial variability of short duration p the hypothesis that the stcs of summer p is homogeneous and isotropic fig 9a cannot be rejected likely because monsoonal thunderstorms are localized and rather stationary and do not exhibit dominant directions the shape of the marginal distribution of p controlled by γ 1 and γ 2 could be considered constant across the region fig 10 similar to the growth curve used in regional frequency analysis of extreme p hosking and wallis 1997 p occurrence related to p 0 and magnitude linked to β are instead highly and moderately affected by elevation respectively figs 8 11 12 these features of stcs and controls on the marginal distribution are also found for winter p when δt 3 h for larger time aggregations the hypothesis of homogeneous and isotropic stcs is instead less sustained fig 9b confirming the preliminary analyses of mascaro 2017 their fig 12 who found that directional correlograms of winter p exhibit anisotropic behavior with higher correlations along the northeast southwest axis this could be explained by the combined effect of storm anisotropy the preferential motion of large scale frontal storms as also suggested by sungmin and foelsche 2019 and the orographic barrier of the mogollon rim fig 1 the shape of the marginal distribution of p sampled at δt 3 h could still be considered constant fig 9 while elevation is not sufficient to fully explain the spatial variability of p magnitude figs 11 12 5 2 generalization of the results and transferability of the approach the results of this work are consistent with and expand the findings of previous studies several efforts krajewski et al 2003 ciach and krajewski 2006 villarini et al 2008 sungmin and foelsche 2019 peleg et al 2013 showed that the spatial correlation of high resolution p could decrease significantly within short distances δ 25 km as p is aggregated at smaller δt s and that the rate of these changes varies with the climatic regimes and seasons our findings confirm these outcomes and further expand them by considering larger δt s and δ s thanks to the large spatial coverage and high density of the rain gage network our results are also in line with molnar and burlando 2008 who showed that winter p in switzerland dominated by frontal systems is more structured i e has higher serial correlation than summer p resulting from convective storms this indicates that qualitatively the considerations reported in the previous section have general validity at sites with a precipitation regime dominated by convective and frontal systems this work provides an effective methodological framework to gain new insights into the space time p variability at any location provided that p observations are available with sufficient density and spatial coverage as known the most accurate p products are ground observations of dense rain gage networks which are becoming increasingly available as part of flood warning systems for example in the u s the counties of harris clark and los angeles as well as the santa clara valley water district operate dense rain gage networks to monitor flooding in the metropolitan areas of houston las vegas los angeles and san jose respectively dense rain gage networks are also available in europe de vos et al 2017 o and foelsche 2019 when rain gages are not available spatially seamless quantitative precipitation estimates from weather radars lin 2011 zhang et al 2016 satellite sensors e g hou et al 2014 and gridded interpolated products e g noaa 2021 kim and villarini 2022 could be very valuable after their ability to capture marginal distributions and stcs and their overall biases are assessed in regions where dense gage networks are available this is one of the subjects of our future work as shown in fig 4 the three parameter distributions cover several combinations of l moments and thus they should be able to capture a large variety of p distribution shapes across climatic regimes other parametric forms have been proposed by naveau et al 2016 and papalexiou 2022 the clayton copula stcs was found to be a flexible homogeneous and isotropic model that well captures the empirical stcs in our study region specifically the clayton copula stcs has the minimum number of parameters that allow adequate control of the scale and shape of the spatial and temporal correlations bs cs bt ct as well as of their interactions θ if the clayton copula is not considered adequate at other sites papalexiou and serinaldi 2020 and papalexiou et al 2021 proposed alternative analytical forms of stcs and provided suggestions to design new analytical models that might be needed to account for anisotropy and or spatial heterogeneity once marginal distribution and stcs have been parameterized the cosmos framework could then be used to validate hypotheses on their variability as done here 6 conclusions this study advances the knowledge of and ability to model the stcs and marginal distribution of short duration 24 h p two properties that have received relatively little attention in the literature due to the lack of adequate reliable observations a systematic analysis of the seasonal and spatial variability of these properties is conducted in a large region in central arizona using a high density network of gages with long term high resolution p records the empirical stcss are captured well by the clayton weibull parametric stcs while three parametric distributions namely the g g b r xii and g e 4 describe well the empirical distribution of nonzero p for all δt s with the g e 4 providing the best results these parametric models show that summer p dominated by short lived convective thunderstorms exhibits weaker correlation structure and heavier tails of the distribution than winter p which is instead controlled by longer and widespread frontal systems monte carlo experiments relying on stochastic simulations with the cosmos space time p model show that in most cases the stcs of p could be considered homogeneous and isotropic the marginal distribution has constant shape across the region and the spatial variability of p occurrence and mean intensity is controlled by elevation the only exception is winter p at δt 3 h that shows possible non homogeneity and anisotropy in the stcs and requires additional factors to explain the spatial variability of the mean p intensity the methodological framework of this work could be applied at other sites and is then useful for parameterizing testing and improving p models and weather generators sørup et al 2016 paschalis et al 2013 peleg et al 2017 grimaldi et al 2022 kim and onof 2020 as well as for validating in a statistical sense numerical p simulations from convection permitting atmospheric models i e verifying the degree to which the probability distributions and space time correlation structures of their simulated p time series are consistent with the parametric forms presented here we identify several future research avenues to further support these goals the description of the stcs should be improved by accounting for storm advection and anisotropy jameson 2021 the potential existence of nonlinear dependencies between the p signals at different time lags should be better quantified and modeled using e g copulas as recently suggested by papalexiou 2022 analyses should also target the characterization of the stcs of the binary signal of rain no rain as well as the assessment of the ability of the proposed marginal distributions to capture p extremes and develop strategies to regionalize their parameters finally while the findings of this study did not indicate the existence of significant differences between the stcs and marginal distributions of all nonzero p in urban and non urban regions of the study area not shown additional efforts should be devoted to further investigating the presence of differences by focusing on the extremes as suggested by the recent study of huang et al 2022 credit authorship contribution statement giuseppe mascaro conceptualization methodology software validation formal analysis investigation data curation writing original draft visualization supervision funding acquisition simon michael papalexiou conceptualization methodology software writing original draft visualization daniel b wright conceptualization writing original draft declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests giuseppe mascaro reports financial support was provided by the national institute of standards and technology and the national science foundation acknowledgments we thank three anonymous reviewers for their comments that helped to improve the quality of the paper this work has been supported by the national science foundation nsf award 1831475 scc community based automated information for urban flooding and the national institute of standards and technology nist award 70nanb22h056 assessing the utility of safe to fail design to improve climate hazards resilience of interdependent infrastructure systems the authors thank stephen d waters from the flood control district of maricopa county for providing the rainfall data of the network appendix a estimation of distribution parameters using l moments parameters of the g g b r xii and g e 4 were estimated using the numerical procedure proposed by zaghloul et al 2020 which is based on the method of l moments for distributions with one scale parameter and two shape parameters the l variation τ 2 and l skewness τ 3 depend only on the shape parameters γ 1 and γ 2 following hosking 1990 the integral forms of τ 2 and τ 3 are a1 τ 2 γ 1 γ 2 λ 2 λ 1 0 1 q u 1 γ 1 γ 2 2 u 1 d u 0 1 q u 1 γ 1 γ 2 d u a2 τ 3 γ 1 γ 2 λ 3 λ 2 0 1 q u 1 γ 1 γ 2 6 u 2 6 u 1 d u 0 1 q u 1 γ 1 γ 2 2 u 1 d u where λq q 1 2 3 is the q order l moment and q u 1 γ1 γ2 is the quantile function of any of the three distributions with scale parameter β 1 for each record the sample values of the l moments τ 2 and τ 3 are calculated and parameters γ 1 and γ 2 are estimated by minimizing the squared difference between the sample and theoretical l moments in symbols a3 γ 1 γ 2 argmi n γ 1 γ 2 q 2 3 τ q γ 1 γ 2 τ q 2 eq a3 is solved numerically by substituting eqs a1 and a2 after estimating γ 1 and γ 2 the scale parameter β is calculated by minimizing the function a4 β argmi n β λ 1 β λ 1 2 where λ 1 β 0 1 q u β γ 1 γ 2 d u and λ 1 is the sample estimate of the first order l moment appendix b metrics quantifying goodness of fit of the parametric distributions the goodness of fit gof of the parametric distributions is quantitatively assessed through the cramer von mises statistic w 2 deidda and puliga 2006 laio 2004 and the mean relative mean square error relmse papalexiou et al 2013 defined as a5 w 2 1 12 n i 1 n f t h e o r x i f e m p x i 2 a6 relmse i 1 n f t h e o r x i f e m p x i 1 f e m p x i 2 where xi is the i th ascending order statistic n is the sample size ftheor xi is the theoretical cdfs one of the three parametric distributions mentioned above and f e m p x i i 0 5 n is the empirical cdf estimated through the hazen plotting position formula both metrics provide a measure of the correspondence between theoretical and parametric cdfs with w2 giving the same weight to all order statistics and relmse assigning larger weights to the differences in the right tail of the distribution appendix c overview of the complete stochastic modeling solution cosmos we provide here a brief description of the version of cosmos used here referring the reader to papalexiou 2018 and papalexiou and serinaldi 2020 for additional details and to papalexiou et al 2021 and papalexiou 2022 for further developments of this modeling framework let x si t be a stationary stochastic process describing the time series of p at temporal aggregation δt at s locations si with i 1 s cosmos assumes that the process x si t can be simulated by transforming a parent standard gaussian process z si t with an appropriate stcs ρ z τ δ related to the stcs of x the method is applied through the following steps a stcs for x ρ x τ δ is identified preferably through an analytical model as done in section 3 2 a suitable marginal distribution of p fi x for x is specified at each gage location the stcs for the parent gaussian process z ρ z τ δ is obtained by inflating ρ x τ δ through the correlation transformation function a7 ρ x τ δ r ρ z τ δ c ρ z τ δ μ x 2 σ x where μx and σx are the mean and standard deviation of x computed from the parametric form of fi x and c ρ z τ δ e x i x j is the expectation of the product between x at two locations i and j the latter term involves an integral that is solved numerically for a given value of ρz therefore one applies eq a7 to calculate ρx for a set of fixed values of ρz e g 0 0 05 0 10 0 95 1 and then fits an analytical relation to the computed ρz ρx pairs to map ρz ρx here the following empirical equation suggested by papalexiou and serinaldi 2020 is found to capture well this relation a8 ρ z 1 b ρ x 1 c 1 1 b 1 c 1 where b and c are coefficients it is worth noting that while μx and σx may vary in space for this step they could assumed to be constant to simplify the numerical application of cosmos with minimal impact of its performance to simulate time series of t time steps at s sites a multivariate autoregressive model mar p of order p with stcs ρ z τ δ is used to generate s t standard gaussian variates z si t these are transformed into x variates x si t through the marginal back transformation x s i t f i 1 φ z s i t where φ is the standard gaussian cdf here the order p was chosen as the time lag where the serial correlation decays to a negligible value i e 0 05 
14,numerical models based on the two dimensional 2d shallow water equations swe are commonly used for flood hazard assessment although the basic assumption of small bottom slopes is not always strictly satisfied such as in mountain areas when terrain slopes are large the steep slope shallow water equations ssswe are theoretically more suitable because the restrictive hypothesis of small bottom slopes is not introduced in deriving these equations a new formulation of the 2d ssswe in which the water depth is measured in the vertical direction and the flow velocity is assumed parallel to the bottom surface is proposed in the companion paper part i the pressure distribution on the vertical is assumed linear yet non hydrostatic and the effect of flow curvature is neglected in this paper the new ssswe are solved with an explicit muscl type second order accurate finite volume scheme using the centered force method for flux evaluation the ssswe model is validated against existing experimental data of one dimensional 1d dam break flows on sloping channels with fixed slopes the numerical results of the ssswe and swe models are compared both in this benchmark test case and in other numerical tests including a 1d dam break flow moving on an adverse slope a 2d dam break flow spreading on an inclined plane and a 2d dam break flow propagating in a sloping parabolic channel finally the two models are applied to the real field test case of the cancano dam adda river northern italy which is characterized by very steep and irregular topography especially in the upper portion of the valley the results show that on the whole the ssswe are more accurate in describing dam break flows over steep topographies than the conventional swe and predict less severe flooding with slower wave propagation the two models are practically equivalent when bottom slopes are relatively small keywords finite volume method free surface flow numerical model shallow water equations steep bottom slopes two dimensional depth averaged model data availability data will be made available on request 1 introduction the depth averaged shallow water equations swe are widely used to model a variety of geophysical fluid flows and wave propagation phenomena e g toro 2001 fent et al 2018 in the classic formulation these equations hold under a set of restrictive hypotheses including that of small bottom slopes e g chow 1959 toro 2001 castro orgaz and hager 2017 however often free surface flows develop on very steep and irregular topography at least locally especially in mountain regions or near geometric singularities despite the swe are not strictly valid in this context e g van emelen et al 2014 they are yet used for flood hazard assessment assuming that solution s accuracy remains acceptable for engineering purposes e g han and wang 1996 valiani et al 2002 begnudelli and sanders 2007 aureli et al 2008c pilotti et al 2011 singh et al 2011 wang et al 2011 pilotti et al 2014 the steep slope shallow water equations ssswe are in principle of more general application not requiring the assumption of small bottom slopes however if a univocal formulation of the one dimensional 1d ssswe is available in the literature e g berger 1994 fernandez feria 2006 ancey et al 2008 different formulations of the ssswe have been proposed in the two dimensional 2d framework based on different global or local coordinate systems e g chaudhry 1993 laigle 1997 nakagawa and takahashi 1997 denlinger and iverson 2004 rickenmann et al 2006 denlinger and o connel 2008 medina et al 2008 juez et al 2013 xia and liang 2018 ni et al 2019 a review of existing 2d formulations has been performed in part i of this work maranzoni and tomirotti 2022 to overcome some critical issues of the available formulations in the companion paper the writers have proposed a new formulation of the depth averaged 2d ssswe based on the assumptions that the water depth is measured in the vertical direction the flow velocity is parallel to the bottom the vertical pressure distribution is linear yet non hydrostatic and the effect of flow curvature is negligible the resulting equations are hyperbolic for wet bed and reduce to the conventional swe for small bottom slopes therefore the variety of numerical methods proposed in the literature to solve nonlinear hyperbolic systems of conservation laws e g toro 1997 leveque 2002 toro and garcia navarro 2007 can be applied also to the new set of equations solving the governing equations with robust and accurate numerical models is crucial in order to correctly simulate the flow dynamics and calculate the flow variables involved in quantifying and classifying flood hazard e g kim and sanders 2016 d oria et al 2019 in this paper the new 2d ssswe written in conservative form are solved by an explicit muscl type second order accurate finite volume scheme in which the force first order centered method is used for the evaluation of the numerical fluxes toro 2001 and a hybrid weighted depth surface gradient method wsdgm is used to estimate the conserved variables at intercell boundaries aureli et al 2008a based on the idea of the finite volume method the computational domain is subdivided into areal elements with planar inclined bottom and rectangular horizontal projection and the flowing water mass is interpreted as composed by a set of prismatic vertical water columns where cell averaged values of the conserved variables are defined the vertical alignment of such control volumes which is a direct consequence of the assumption of measuring the water depth along the vertical prevents their superimposition or gross distortions mancarella and hungr 2010 allowing the lateral faces of adjacent control volumes to match denlinger and iverson 2004 conversely models in which the water depths are assumed normal to the bottom e g iverson and denlinger 2001 fent et al 2018 are potentially subject to these numerical problems especially on very irregular topographies maranzoni and tomirotti 2022 figs 1 and 2 and require laborious pre and post processing of terrain elevation data in general numerical methods must address challenging difficulties in real applications e g zhou et al 2001 leveque et al 2011 such as dealing with irregular topographies and wet dry interfaces or reproducing bores and transcritical flows as well as static or steady states which requires a well balanced numerical scheme the robustness and effectiveness of the scheme used in this study in facing these numerical challenges were extensively tested in aureli et al 2008a in the case of swe the adjustments required to effectively handle the peculiarities of the new system of equations are discussed here the ssswe model is first validated against existing experimental data concerning the propagation of a dam break wave in a sloping channel lauber and hager 1998b some schematic numerical tests are then performed for 1d and 2d dam break flows over a sloping bottom including dam break flows moving on an adverse slope spreading on an inclined plane and propagating in a sloping parabolic channel characterized by large bottom slopes both in the longitudinal and transverse directions finally the model is applied to the real field test case of the hypothetical total collapse of the cancano dam adda river northern italy for which experimental flooded areas and discharge hydrographs at selected cross sections measured in a historical small scale physical model are available de marchi 1945 pilotti et al 2014 pilotti et al 2020 aureli et al 2021 this test case is particularly suitable for validating the ssswe because long stretches of the upper portion of the valley downstream of the dam are very steep as well as the valley sides for all the test cases considered the numerical results of the ssswe are compared with those obtained by the conventional swe using the same finite volume numerical scheme this paper is organized as follows the governing equations are recalled in section 2 and the numerical model is described in section 3 the validation of the model is performed in section 4 along with the analysis of its performance in 1d and 2d schematic numerical tests the real field application is presented in section 5 conclusions are drawn in section 6 2 mathematical model the new 2d ssswe were derived in part i of this work maranzoni and tomirotti 2022 by adopting a global horizontal oriented xyz coordinate system with vertical z axis and a local bottom oriented coordinate system with two axes ξ and η in general non orthogonal locally parallel to the bottom with inclination angles θx and θy with respect to horizontal orthogonal directions x and y and the third axis ζ locally perpendicular to the fixed bottom surface the global fixed reference frame is used to define the spatial variables water depth and horizontal spatial coordinates while the local reference frame is used to define the vertically averaged flow velocity assumed locally parallel to the bottom surface the equations representing the mass conservation and the linear momentum balance along the ξ and η directions can be expressed in conservative vector form as 1 u t f x g y s with 2 u h u h v h f u h cos θ x u u h 1 2 k g h 2 cos θ x u v h cos θ x g v h cos θ y u v h cos θ y v v h 1 2 k g h 2 cos θ y s 0 g h s 0 ξ s f ξ g h s 0 η s f η where u is the vector of the conserved variables f and g are the vectors of the physical fluxes along the ξ and η directions respectively s is the source term which includes the effects of bottom slope s 0 and friction sf in the definitions of eq 2 h is the water depth measured along the vertical direction u v ξ and v v η are the orthogonal projections of flow velocity v in the ξ and η directions identified by the unit vectors ξ and η respectively and u and v are the scalar components of the velocity vector along the ξ and η directions respectively i e v u ξ v η accordingly u and v can be expressed as a function of u and v as 3 u u v sin θ x sin θ y 1 sin 2 θ x sin 2 θ y v v u sin θ x sin θ y 1 sin 2 θ x sin 2 θ y again in eqs 1 and 2 t is time g is the acceleration due to gravity and k is a pressure correction factor 0 k 1 which reflects the effect of bottom slope on pressure distribution assumed to be linear along any vertical reducing the pressure with respect to the hydrostatic one in dynamic conditions neglecting the effect of bottom curvature and in analogy to the case of 1d parallel flow chow 1959 p 33 k is set equal to the square cosine of the angle between the direction locally normal to the bottom and the vertical in dynamic conditions juez et al 2013 xia and liang 2018 ni et al 2019 and equal to unity in static conditions 4 k 1 if v 0 1 1 tan 2 θ x tan 2 θ y otherwise finally in eq 2 the bottom slopes read 5 s 0 ξ sin θ x and s 0 η sin θ y and extending the manning formula to the 2d framework e g molls et al 1998 the friction slopes are 6 s f ξ n 2 u v h 4 3 1 ta n 2 θ x ta n 2 θ y and s f η n 2 v v h 4 3 1 ta n 2 θ x ta n 2 θ y where n is the manning roughness coefficient the new set of equations is strictly hyperbolic for wet bed and reduces to the conventional 2d shallow water equations when bottom slopes are small maranzoni and tomirotti 2022 3 numerical model due to the hyperbolicity of the new equations and their structural similarity with the classic 2d depth averaged swe the variety of existing numerical methods designed to solve the swe can also be used for the ssswe in this paper the 2d non linear differential system of eqs 1 and 2 is numerically solved by the finite volume scheme described in aureli et al 2008a successfully used to simulate unsteady free surface flows in various applications maranzoni and mignosa 2018 2019 including flooding due to dam break aureli et al 2008a 2008c and levee breach aureli et al 2006a 2006b the horizontal projection of the computational domain is discretized by a uniform structured cartesian grid with size δx δy and the bottom basis of each computational cell is assumed to be an inclined quadrilateral fig 1a with area 7 a δ x δ y 1 ta n 2 θ x ta n 2 θ y following the basic idea of the cell centered finite volume methods leveque 2002 cell averaged values u i j of the conserved variables are defined for each computational i j cell identified by the rectangular interval xi 1 2 xi 1 2 yj 1 2 yj 1 2 on the horizontal xy plane and stored in the corresponding cell center fig 1b the piecewise linear approximation of the bottom surface implies that the bottom inclination angles θx and θy are constant over each cell and defined at the cell centers with discontinuities at the cell boundaries if the bottom surface is non planar this causes a computational difficulty in the calculation of the numerical fluxes since they depend on the local bottom inclination according to eq 2 to overcome this problem the strategy adopted by maranzoni and mignosa 2018 of fictitiously splitting a cell interface into two distinct mutually parallel interfaces each belonging to one of the adjoining cells is used in this paper for example the i 1 2 j intercell is assumed to be split into the two distinct intercells forward i 1 2 j and backward i 1 2 j belonging to cells i 1 j and i j respectively accordingly different numerical fluxes can be computed at split interfaces i 1 2 j and i 1 2 j by using the bottom slopes of cells i 1 j and i j respectively fig 1c this strategy also allows dealing with bottom discontinuities which occur for example in step poll streams stepped channels or at check dams zhou et al 2002 starting from cell average state u i j n at time tn updated cell average flow state u i j n 1 at next time tn 1 tn δt is obtained through the following explicit dimensionally unsplit three step algorithm based on the second order accurate strang splitting decomposition of the friction source term toro 2001 p 232 8a u i j u i j n δ t 2 s f i j n 8b u i j u i j δ t δ x f i 1 2 j f i 1 2 j δ t δ y g i j 1 2 g i j 1 2 δ t s 0 i j 8c u i j n 1 u i j δ t 2 s f i j in this algorithm eqs 8a c u i j and u i j denote two successive intermediate updates of u i j in the computational time step δt f i 1 2 j f i 1 2 j g i j 1 2 and g i j 1 2 are numerical fluxes across intercells i 1 2 j i 1 2 j i j 1 2 and i j 1 2 of the i j cell respectively fig 1c s 0 i j and s f i j are the cell averaged bottom and friction source terms respectively in the first step of the algorithm eq 8a the contribution of the friction source term is calculated in a pointwise way on the basis of the previous discretized solution u i j n over a halved time step δt 2 whereas in the third step eq 8c the update is based on the intermediate solution u i j in the second step of the algorithm eq 8b the intermediate solution u i j is updated to the new intermediate solution u i j over the entire time step δt by applying simultaneously both advection and bottom slope terms both calculated for u i j the numerical fluxes are evaluated using a second order accurate muscl hancock scheme e g hirsch 1990 toro 2001 according to the steps described in appendix a owing to the quasi conservative structure of eq 8b the numerical scheme does not satisfy the telescopic property toro 2001 p 144 if the terrain is uneven i e non planar because f i 1 2 j f i 1 2 j and g i j 1 2 g i j 1 2 this occurs for the momentum flux components since the basic assumption that the flow velocity is locally parallel to the bottom implies that velocity components u and v of adjacent computational cells refer in general to different directions however this apparent inconsistency does not exclude that the momentum vector is conserved as physically required by the linear momentum principle the telescopic property of momentum fluxes is restored by supposing that fictitious cells are present between the split boundaries of adjacent actual cells zhou et al 2002 maranzoni and mignosa 2018 again in the case of uneven terrain the telescopic property is not satisfied even for mass fluxes since the first components of physical fluxes f and g depend on local bottom inclinations θx and θy which can be different between two neighboring cells the numerical strategies to overcome this problem are described in appendix a 4 numerical tests and validation in this section the performance of the ssswe is assessed on the basis of 1d and 2d test cases of dam break flows on sloping bottom and compared with that of the conventional swe 4 1 dam break in a rectangular sloping channel a systematic analysis of the effect of bottom slope on dam break flows was performed by lauber and hager who carried out a series of laboratory experiments considering the cases of horizontal lauber and hager 1998a and sloping bottom lauber and hager 1998b the experimental data presented in the latter paper were obtained for two channel slopes s 0 0 1 and s 0 0 5 s 0 tanθx corresponding to channel inclination angles of approximately 6 and 27 respectively they are particularly useful to assess models capability to reproduce dam break waves on inclined bottoms even considering large slopes tan and chu 2009 the experiments were conducted in a rectangular flume 14 m long and 0 5 m wide with smooth surfaces made of pvc and glass lauber and hager 1998a the vertical sluice gate used to simulate the dam was located 3 5 m downstream of the upper channel end and was suddenly opened to release the water stored behind the initial water depth at the gate was h 0 0 3 m and the flume was initially dry downstream experimental data include profiles of water depth average cross sectional velocity and discharge at selected times trajectories and velocities of positive wetting negative and drying fronts time histories of water depth measured perpendicularly to the bottom average cross sectional velocity and discharge at selected locations lauber and hager 1998b similar experimental investigations were carried out by iverson et al 1992 in the sloping usgs channel with clear water or debris logan et al 2018 and by ancey and cochard 2009 with viscoplastic fluids in the numerical simulations a uniform cartesian mesh is used and the manning roughness coefficient is set to 0 01 m 1 3s which is a suitable value for smooth surfaces of a laboratory flume chow 1959 table 5 6 p 110 the ssswe code is verified in appendix b through a grid refinement study based on free surface profiles at various times calculated with uniform grids of different sizes this study shows that spatial convergence is practically attained with the grid size δx 2 10 3 m fig 2 compares experimental and numerical trajectories calculated with the new ssswe and the conventional swe of wetting and drying fronts for s 0 0 1 and s 0 0 5 fig 2a shows that for the smaller bottom slope s 0 0 1 the numerical fronts both wetting and drying are substantially overlapping and the numerical wetting fronts agree very well with the experimental data conversely the predicted drying fronts differ significantly from the measured one however the numerical trajectory of the drying front is considerably influenced by the threshold water depth used for the numerical simulation of the wetting drying process aureli et al 2008a fig 4 p 968 in the simulations this threshold was set to 5 10 4 m fig 2b shows appreciable differences between the numerical wetting fronts predicted by the two shallow water models for s 0 0 5 in this case the ssswe model reproduces well the experimental wetting front apart from an initial slight overestimation of the front celerity whereas the swe model predicts a faster front propagation than observed in the experiments as regards the drying front instead the two numerical models return similar results although the swe one tends to predict a faster front propagation for increasing time differently from the previous case s 0 0 1 fig 2a the numerical drying fronts agree well with the experimental one mainly because the wetting drying threshold is less critical in determining the position of the numerical drying front for higher bottom slopes the intersection of the numerical drying fronts is due to the effect of friction which strongly influences the flow dynamics at the head of the reservoir where water depths are small horizontal sections of the plots in fig 2 identify the channel stretch spanned by the water profile at a given time and vertical sections correspond to the time interval spanned by the wave history at a given location accordingly for the higher channel slope s 0 0 5 fig 2b the swe model predicts longer stretches spanned by wave profiles at fixed times mainly due to a significant overestimation of the wetting front celerity and shorter wave arrival times at fixed locations compared to the experimental observations the ability of the two numerical models to capture the wave profile in the tip region is verified in appendix c against the analytical solutions of the dynamic equation of uniformly progressive flow in a wide rectangular channel this ability is critical for dam break numerical codes e g bohorquez and fernandez feria 2008 especially for waves propagating down a steeply inclined bottom the previous remarks concerning free surface profiles are confirmed by figs 3 and 4 which compare experimental and numerical water surface profiles at selected times for s 0 0 1 and s 0 0 5 respectively for the former case fig 3 the ssswe and swe numerical profiles are substantially identical as the bottom slope is low enough less than 6 according to chow 1959 p 33 for the ssswe to practically reduce to the conventional swe moreover both numerical models slightly overpredict the celerity of the wetting front in the first stages of dam break flow after the gate removal fig 3a c for the higher slope case fig 4 this overprediction is more significant for the swe model while it is much less pronounced in the ssswe profiles and attenuates over time finally it is worth noting that shallow water models cannot reproduce the inflection point of the experimental profiles at the initial stages of motion when the effect of flow curvature is significant the accuracy in the numerical reproduction of the experimental water surface profiles shown in figs 3 and 4 is assessed by calculating the mean absolute percentage error mape e g hyndman and koehler 2006 9 mape 1 n k 1 n h z b num k h z b exp k h z b exp k 100 where zb is the bottom elevation n is the number of available experimental points and subscripts num and exp refer to numerical predictions and experimental data respectively the 1 norm is indeed appropriate for conservation laws according to leveque 2002 p 140 numerical predictions are linearly interpolated at the longitudinal coordinates where water surface elevations were measured in the physical model and the mape calculation based on eq 9 is limited to the channel stretch common to the profiles compared the mape computed with the ssswe and swe predictions are compared in tables 1 and 2 for s 0 0 1 and s 0 0 5 respectively the ssswe errors are always less than the swe ones and the differences are more significant for the case with the higher bottom slope moreover errors decrease with time for both models as the dam break wave propagation proceeds figs 5 and 6 show flow depth hydrographs at selected cross sections located downstream of the gate these time series refer to flow depth h measured perpendicularly to the channel bottom which is calculated from the vertical water depth h computed by the numerical models through the trigonometric transformation 10 h h for the swe model h cos θ x 1 1 s 0 s wse for the ssswe model where s 0 tanθx zb x x is the slope of the channel and s wse zb h x is the local slope of the water surface in the streamwise direction the condition for the swe model derives from the substantial equivalence between vertical and normal depths due to the assumption of small bottom slopes as for the water surface profiles the numerical water depth hydrographs are practically identical for s 0 0 1 fig 5 and reproduce fairly well the experimental ones except for a slight underestimation of the peak value at the most upstream observation section fig 5a and a general steeper rise of the hydrographs resulting in a systematic slight anticipation of the peak conversely considerable differences between the hydrographs predicted by the two numerical models occur for s 0 0 5 fig 6 in this case despite the more complex two peak pattern of the measured hydrographs the ssswe perform better than the swe showing an overall satisfactory agreement with the experimental data except for a slight underestimation of the wave arrival time at the three most upstream observation points fig 6a c on the other hand the swe overestimate the peak value at the two most upstream observation points fig 6a b and underestimate the wave front arrival time more significantly at the cross sections furthest from the dam similar conclusions can be drawn from the analysis of the discharge per unit width hydrographs reported in figs 7 and 8 the two shallow water models provide practically identical numerical results in the lower slope case s 0 0 1 fig 7 instead the ssswe perform better than the conventional swe in reproducing the experimental discharge hydrographs in the larger slope case s 0 0 5 fig 8 indeed in this case the swe return a greater overestimation of the peak discharge especially in the observation cross sections closest to the dam in fig 8 it is again evident that the swe predict a faster wave front the accuracy in the numerical prediction of the water depth and unit discharges time series shown in figs 5 8 is assessed in tables 3 6 by the normalized nash sutcliffe efficiency coefficient nnse nossent and bauwens 2012 11 n n s e 1 2 n s e where nse is the usual nash sutcliffe model efficiency coefficient nash and sutcliffe 1970 12 n s e 1 k 1 n θ num k θ exp k 2 k 1 n θ exp k θ exp 2 where θ denotes the hydraulic variable of interest water depth or unit discharge and θ exp is the average value of the set of experimental data the nash sutcliffe model efficiency coefficient is commonly used in various hydraulic and hydrologic applications e g echeverribar et al 2019 and its normalized version ranges between 0 and 1 the latter being the optimal value moreover this performance coefficient does not incur division by zero and the numerical difficulties related to the temporal shifts of the hydrographs compared as would occur for mape numerical predictions are linearly interpolated at the times of the experimental data to calculate nse based on eq 12 the results confirm the superiority of the ssswe in predicting the time series of both water depth and unit discharge since the nnse values are higher than for the swe model the difference between the nnse coefficients calculated from the two models is higher for the steeper channel the agreement between numerical predictions and experimental data is overall better for the milder slope since the nnse values get closer to 1 the greater accuracy of the ssswe model is obtained at the cost of a slight reduction in computational efficiency for example the ratio of the execution times of the swe and ssswe codes is equal to 0 866 on an intel xeon cpu e5 1620 v4 3 50 ghz workstation for 3 s simulation of lauber and hager s test case s 0 0 5 on a 2 10 3 m grid with a courant number of 0 9 wave profiles and time series presented in figs 3 8 show a regular behaviour however it is well known that the free surface of a supercritical flow in a channel with a very steep slope can break into a train of travelling pulses named roll waves chow 1959 p 580 this phenomenon can also occur in the propagation of a dam break wave if the channel is long enough denlinger and o connell 2008 bohorquez 2011 appendix d shows that both shallow water models are able to catch the formation of roll waves near the wavefront of a dam break flow in a steep channel 4 2 run up of a dam break flow on an adverse slope the test case presented in this section concerns a 1d dam break wave which first propagates on a horizontal channel and then runs up a steep adverse slope despite its simplicity this problem is of practical interest for example in modeling flow in the coastal swash zone antuono and hogg 2009 and the motion of rapid geophysical flows on adverse inclined topographies iverson et al 2016 or against obstacles and protective structures mancarella and hungr 2010 the depth averaged swe are classically used to simulate such flow phenomena e g aureli et al 2000 in this test the adverse ramp is assumed to be very steep so that the performance of the new ssswe can be effectively compared with the conventional swe the 2d numerical solution on the vertical plane obtained simulating the planar flow on the xz plane via the vof volume of fluid model with the cfd computational fluid dynamics software ansys fluent 18 0 2017 is used as a reference for comparison purposes the vof model is indeed widely used in cfd to study dam break flows especially in the initial stages e g ozmen cagatay and kocaman 2010 larocque et al 2013 yang et al 2022 and the propagation of tsunami bores in the swash zone e g tar et al 2017 showing better predictive capabilities than the depth averaged shallow water models ozmen cagatay and kocaman 2010 kocaman et al 2021 the test case is similar to the dam break problem on an adverse sloping plane theoretically analyzed by antuono and hogg 2009 the main difference is that the adverse slope inclined by θx 45 with respect to the horizontal s 0 1 is preceded by a horizontal propagation channel as in o donoghue et al 2010 or lu and liu 2018 the bottom is described by 13 z b x 0 for 0 x 6 m x 6 for 6 m x 7 m where zb is the bottom elevation and x denotes the horizontal coordinate fig 9 the sharp change in bottom slope implies that bottom curvature is different from zero tending to infinity only locally at x 6 m the resistance is assumed to be negligible the ideal dam is located at x 5 m and the initial condition is 14 h x t 0 0 2 m for 0 x 5 m 0 otherwise the unsteady flow generated by the sudden removal of the dam is a frictionless dam break flow on a horizontal dry bed until the wave tip reaches the section x 6 m at which the adverse ramp starts the run up of the wave on the adverse slope induces flow deceleration and inversion with the formation of a backwash bore a cartesian grid with square cells sized 2 10 3 m was used in the numerical simulations performed with the depth averaged shallow water models the manning coefficient was set to zero in the cfd model the vof method was applied to the inviscid euler equations the 2d computational domain on the x z vertical plane was discretized with a fixed unstructured mesh of non uniform quadrilateral cells the characteristic cell size is 10 3 m in the region involved by the water flow moreover solid walls were assumed at the boundary of the computational domain except for the upper boundary where the gage pressure was imposed equal to zero the numerical solution was advanced in time using a fixed global time step of 5 10 3 s fig 9 shows the numerical profiles of water surface and depth averaged velocity at selected times in the cfd solution the 0 5 volume fraction isosurface represents the water air interface which includes the free surface since the vof method models a free surface flow as a two phase flow of an air water mixture with the water volume fraction ranging between 0 and 1 at t 0 5 s after the dam removal the waves computed by the depth averaged models are already climbing up the adverse ramp while the wetting front of the wave simulated by the cfd model is just at the toe of the slope fig 9a at this time the water surface and velocity profiles calculated by the two depth averaged models are identical in the approaching channel and exhibit the typical features of the depression wave of ritter s solution on the other hand the free surface profile computed by the cfd model shows the shape with change in profile curvature experimentally observed in several studies e g lauber and hager 1998a stansby et al 1998 ozmen cagatay and kocaman 2010 after passing the bottom slope change the dam break wave climbs up the adverse ramp fig 9a b decelerating until the maximum run up height is attained in this run up phase the wave is tapered and thin see also fig 10a hence the assumption of flow velocity parallel to the bottom is perfectly plausible thereafter flow inversion occurs and a backwash bore appears inducing the increase of the water depth at the toe of the adverse ramp fig 9c for t 1 2 s in these circumstances the motion is fully 2d in the vertical plane and the classic shallow water models are inaccurate fig 10b after its formation the bore moves backward t 1 2 s separating the downstream flow influenced by the presence of the adverse slope from the upstream incoming flow the shallow water models predict a standard moving jump its celerity and height are practically equal in the two depth averaged models instead the cfd model predicts the development of a plunging bore with complex splash phenomena and air entrainment fig 9d e these phenomena cannot be reproduced by a depth averaged shallow water model fig 11a which plots the wave front position as a function of time shows that the new ssswe model estimates a lower maximum run up height than the other two models the conventional swe model and the 2d vof model predict maximum run up heights that are in good agreement even if the maximum run up occurs earlier in the swe model the maximum run up height is reached at approximately t 0 7 s for both depth averaged models and later approximately at t 1 s for the 2d vof model indeed the wave front computed by the 2d vof model is slower than the one calculated by the two depth averaged models when the dam break wave propagates on the horizontal stretch incidentally the wave front celerities predicted by the two depth averaged models are identical as long as the dam break wave moves on a horizontal bottom once the maximum run up height is reached the flow reverses over the ramp and subsequent flow inversions occur accordingly the wave front oscillates and quickly becomes quasi stationary this oscillating behavior is not so evident in the ssswe model the quasi stationary position of the wave front on the inclined ramp returned by the ssswe model agrees very well with the one provided by the reference 2d vof model while the swe model predicts a slightly higher long term wave front elevation in any case it is worth noting that the water front trajectory calculated by the shallow water models is rather sensitive to the value of the water depth threshold introduced to deal with wetting and drying fig 11b shows the numerical time series of flow discharge per unit width at the dam location x 5 m and at the vertical section where the bottom slope changes discontinuously x 6 m the three discharge hydrographs are in good agreement and show comparable features in both control cross sections the outflow discharge at the dam location remains constant equal to the value provided by the ritter analytical solution for all three numerical models until the backwash bore reaches this section however the outflow hydrograph calculated by the 2d vof model exhibits an initial peak induced by flow curvature which has significant effects at the initial stages of a dam break flow cantero chinchilla et al 2020 the two depth averaged shallow water models slightly overestimate the arrival time of the backwash bore at the dam location compared with the 2d vof model although the bore reaches the section of change in bottom slope earlier in the depth averaged models than in the 2d vof model all the numerical models predict comparable peak flow discharges at x 6 m and indicate local inversion of the flow at the passage of the backwash bore at this control section at both cross sections the arrival time of the backwash bore is slightly shorter in the ssswe model than in the swe one which is consistent with the lower run up height predicted by the former 4 3 spreading of a dam break flow on a sloping plane several experimental investigations of partial dam break flow on a plane can be found in the literature e g fraccarollo and toro 1995 aureli et al 2008b kocaman et al 2021 however they have been typically conducted on horizontal bottom dam break flow spreading on a sloping plane is most frequently considered in the context of debris and mud flow analysis e g laigle 1997 iverson et al 2004 cochard and ancey 2009 in particular laigle s experiments were conducted on an inclined platform 6 m long and 2 1 m wide with an adjustable slope the set up of test a16 laigle 1997 table 1 p 129 characterized by a slope of 0 2 θx 11 31 being θx the inclination of the platform with reference to the horizontal plane is considered here in this test the bottom slope is the maximum realized in the experimental investigation the planar shape of the reservoir is assumed rectangular making it more schematic than the original one laigle 1997 fig 1 p 128 a gate placed symmetrically between two lateral walls separates the reservoir from a short rectangular channel 0 75 m long and 0 5 m wide connected downstream with a 3 9 m long floodable area fig 12 shows a sketch of the test conditions the gate was arranged orthogonally to the bottom in the experimental set up however it is assumed vertical in the numerical modeling according to the basic hypothesis of measuring water depths in the vertical direction quiescent water initially stored in the reservoir has a depth h 0 0 22 m at the gate fig 12 the marked 2d character of the spreading shallow flow resulting from the sudden opening of the gate is the peculiar feature of this test compared to those presented in the previous sections the computational domain was discretized by means of a cartesian uniform mesh with size δx 0 01 m δy 0 01 m and manning s roughness coefficient n was set to 0 01 m 1 3s the numerical simulation was stopped when the dam break wave reached the downstream end of the plane fig 13 compares the numerical results obtained from the new ssswe and the conventional swe in terms of water surface profiles along the centerline longitudinal axis and of contour line maps of water surface elevation and velocity magnitude at t 0 7 s fig 13a and t 1 5 s fig 13b the ssswe predict slower propagation of the nose of the wave front in accordance with the results of 1d dam break flows on large bottom slopes presented in section 4 1 and wider lateral spreading differences in flooding width increase over time fig 14a compares the hydrographs of inflow discharge in the floodable plain computed by the ssswe and swe models similarly fig 14b compares the numerical time series of vertical flow depth at a control point located on the plane centerline 2 70 m from the upper end this control point corresponds to gage point no 11 reported by laigle 1997 fig 2 p 129 the differences in the numerical hydrographs shown in fig 14 are very slight because the bottom slope of this test s 0 0 2 is only slightly higher than the limit slope under which the conventional swe are strictly valid s 0 0 1 according to chow 1959 p 33 differences become more significant if the plane slope increases to 0 5 maintaining the same initial water depth at the gate section h 0 0 22 m the water volume stored in the reservoir reduces to 40 5 of that of the previous case fig 15 shows the numerical water surfaces and the velocity magnitude contours at t 0 6 s fig 15a and t 1 1 s fig 15b calculated with the same computational grid δx δy 0 01 m dam break wave propagation is significantly faster in the swe simulation than in the ssswe one whereas predicted flooding widths are comparable fig 16 compares numerical discharge hydrographs at the end of the short channel fig 16a and vertical water depth time series at the selected gage point fig 16b the peak discharge predicted by the ssswe at the control section is slightly lower than that computed by the swe the opposite occurs for the peak value of the vertical water depth at the gage point 4 4 dam break flow in a parabolic sloping channel dam break flow in a prismatic sloping channel of parabolic cross section is considered in this subsection the channel bed is a parabolic cylindrical surface described by the equation 15 z b x y s 0 l x 0 03 y 20 2 for 0 x 200 m 0 y 40 m where zb is the bottom elevation x and y are the longitudinal and transverse horizontal coordinates respectively s 0 tanθx 0 577 θx 30 is the longitudinal slope of the channel l 200 m is the length of its horizontal projection accordingly axis y 20 m is the projection of the thalweg on the horizontal xy plane the thalweg elevation is equal to 115 47 m at the upstream vertical section x 0 and is equal to zero at the downstream end x l the top width of each vertical cross section 12 m above the thalweg is 40 m the transverse bottom slope ranges from 0 at the channel centerline to 1 2 θy 50 at the top of the channel sides the channel is partitioned by a vertical dam located at x 20 m which retains a still water volume of approximately 1687 m3 when the water depth at the dam is equal to 10 m the channel is dry downstream of the dam this numerical test is challenging because both longitudinal and transverse bottom slopes are different from zero attaining relatively high values typical of sloping natural streams and transverse bottom slope is variable in the channel cross section therefore despite the prismatic shape of the channel 2d features are expected to characterize the dam break flow generated by the sudden and total collapse of the dam in the numerical simulations the manning coefficient was set to 0 04 m 1 3s which is a feasible value in natural streams chow 1959 the numerical solution was calculated on a 0 1 m 0 1 m cartesian mesh fig 17 compares water surface elevation and velocity magnitude contour lines computed by the ssswe and swe models at two selected times t 2 s and t 5 s it shows that the dam break wave stretches and spreads rapidly converging towards the channel centerline in the first phase of the motion fig 17a and then spreading laterally fig 17b the wave predicted by the ssswe is slower than that predicted by the swe ni et al 2019 and shows wider lateral spreading on the channel sides consistently the celerity of the wetting front along the channel centerline is higher in the swe simulation than in the ssswe one as also highlighted by the numerical longitudinal water surface profiles plotted in fig 18 this figure also shows transverse water surface profiles at selected vertical cross sections for t 2 s and t 5 s the curved shape of the numerical transverse water surface profiles confirms the 2d character of the flow and that the transverse component of flow velocity is non zero due to the sloping sides of the channel fig 19 compares the flow discharge hydrographs predicted by the two shallow water models at the dam section x 20 m and at two cross sections located 10 m and 80 m downstream x 30 m and x 100 m at the dam section the ssswe discharge hydrograph is flatter than the swe one and the peak discharge is approximately 20 lower fig 19a the difference in peak discharge reduces significantly at the section located 10 m downstream of the dam x 30 m where the peak discharge computed by the ssswe is only 1 5 lower than that predicted by the swe fig 19b in this cross section the wave arrival time is slightly higher and the rising limb of the hydrograph is gentler in the ssswe model than in the swe one the difference in the wave front arrival times is more pronounced at x 100 m where the peak discharge predicted by the swe is again higher fig 19b it is worth noting that at the dam location x 20 m the ssswe discharge hydrograph attains the peak value approximately 1 s after the dam collapse and at x 30 m the ssswe predict a peak discharge slightly higher than at the dam location however at the initial stages of the dam break flow water depths are not shallow near the dam at the dam location the ratio of the water depth to the top width at the free surface is approximately equal to 0 27 in the initial condition in addition the assumption of flow velocities parallel to the bottom is not strictly valid the same occurs in a large portion of the channel stretch upstream of the dam during the reservoir emptying 5 application to a real field dam break test case in this section the ssswe and swe models are applied to the real field test case of the hypothetical cancano dam break described in pilotti et al 2014 and pilotti et al 2020 this test is particularly suitable to verify the performance of the new ssswe because the valley stretch immediately downstream of the dam is very narrow and steep with bottom slopes along the thalweg greater than 20 the predictions of the two numerical models are compared with each other and with the experimental data of a historical physical model investigation de marchi 1945 the cancano i dam was a concrete arched gravity dam built in 1924 1929 on the upper reach of the adda river valtellina northern italy the dam was 57 5 m high with reference to the downstream thalweg and approximately 265 m long at the crest the maximum reservoir capacity was about 24 106 m3 anidel 1953 the cancano i dam is now submerged by the water volume impounded by the new cancano ii dam which was built downstream in 1953 to increase the reservoir capacity the cancano i dam was considered a war target during world war ii the dam failure could cause flooding of urban areas the most important being the town of bormio which counted approximately 2500 inhabitants at that time prof de marchi was then commissioned to study the catastrophic flood resulting from the potential breaching of this dam he simulated the dam break flood in the approximately 15 km long valley stretch from the dam up to the village of cepina in a 1 500 scale physical model fig 20a assuming a hypothetical partial dam break scenario and the total collapse scenario only the latter is considered herein de marchi measured flood extents in the lower portion of the physical model and the discharge hydrographs at the three cross sections indicated in fig 20a 1 just downstream of the dam 2 at section 23 located approximately 8 km downstream of the dam 3 at the town of cepina unfortunately detailed information on the topography reproduced in the physical model is missing therefore pilotti et al 2020 reconstructed the altimetry of the valley using a recent digital terrain model dtm with a 5 m resolution having verified that substantial morphological changes have not occurred in the meantime in the present study numerical simulations are performed on a 20 m cartesian grid extracted from this dtm pilotti et al 2020 and pilotti et al 2014 did not include the reservoir in the computational domain and used the discharge time series measured at the dam as an inflow boundary condition instead in this paper the reservoir is included in order to model its emptying and utilize the experimental discharge hydrograph at the dam section for comparison and model validation however the reconstruction of the geometric shape of the reservoir reproduced in the physical model is affected by several uncertainties due to the limited information available in his paper de marchi claimed that the physical model reproduced the bottom of the reservoir except for the upstream end of which the volume only was reproduced not the exact configuration translated from de marchi 1945 based on the plan sketch of the physical model fig 20a a prismatic reservoir is assumed here with vertical walls and a horizontal rectangular basis approximately 1060 m long and 650 m wide accordingly to correctly reproduce the volume impounded at the maximum water level of 1857 m a s l the horizontal bottom of this schematic reservoir is placed at the fictitious elevation of 1821 m a s l although the resulting water depth behind the dam is lower than the actual one equal to approximately 55 m to accurately reproduce the actual topographic situation the rock mass protruding into the reservoir on the left hand side of the dam fig 20b is included in the numerical model by inserting non floodable computational cells even if this geometrical detail seems not to have been reproduced in the physical model given the particular plan shape of the reservoir the total collapse of the dam substantially determines a partial dam break scenario because the width of the reservoir behind the dam is greater than the dam length fig 20b following pilotti et al 2020 and pilotti et al 2014 the numerical simulations were carried out in real scale thus neglecting scale effects that most likely influenced the experimental data due to the small geometric scale ratio of the physical model henderson 1966 p 491 the manning roughness coefficient was set to 0 050 m 1 3s in the steep and rugged upper portion of the valley from the dam to section 23 and 0 041 m 1 3s in the downstream stretch from section 23 to the outlet according to the range of values considered by pilotti et al 2014 2020 in their sensitivity analysis on the roughness effect dam failure was assumed to be instantaneous on an initially dry bottom and the transmissive boundary condition was imposed at the downstream outlet located approximately 1 5 km downstream of the cepina section fig 21 shows the computational domain with indicated the zones where the terrain inclination angle is higher than 30 cos30 0 866 cos230 0 75 large areas are characterized by high bottom slopes especially in the upper reach of the valley where the maximum value of the terrain inclination angle is approximately 70 limited to the portion of the valley that can reasonably be reached by flooding fig 21 also compares the flood extents predicted by the ssswe and swe models with the observed one the two numerical flood inundation maps are very similar showing slight local differences mainly concerning slightly larger flooded areas predicted by the swe model in some zones on the whole measured and computed flooded areas are in good agreement with the observed ones the most significant discrepancies occur in the downstream stretch of the valley namely in the floodplain of bormio on the left hand side of the adda river just downstream of the town of bormio there is a large area where the flooding observed in the physical model is not reproduced by the two numerical models conversely on the opposite side of the river predicted flooded areas are wider than the measured ones in several zones accuracy in flood extent prediction is assessed through the following metrics commonly used in flood model performance analysis fit rate h horritt and bates 2002 cook and merwade 2009 missing flooding ratio m kim and sanders 2016 false alarm ratio f and error bias b sampson et al 2015 defined as 16a h a sim a obs a sim a obs 16b m a obs a sim a obs 16c f a sim a obs a sim 16d b a sim a obs a obs a sim where a sim and a obs denote the simulated and observed inundated areas respectively h is a hit rate 0 h 1 which assesses the agreement between the observed and predicted inundated areas m is an index ranging from 0 to 1 that quantifies model underpredition i e inundated areas that are not predicted by the model f 0 f 1 quantifies model overprediction i e areas where the model predicts flooding that actually does not occur and b measures the model s tendency to underpredict 0 b 1 or overpredict b 1 flooded areas table 7 reports the values of these performance metrics for the two numerical models in the cancano dam break test case the values of hit rate h confirm the good global performance of both numerical models which are substantially equivalent in reproducing the inundation extent moreover the results concerning indexes m and f indicate a moderate tendency of the numerical models to both underprediction and overprediction the underestimation of the flooded areas is higher for the ssswe model than for the conventional swe one while it is the opposite for overprediction finally the calculated values of index b 1 indicate a global tendency of both models to underpredict flooded areas more pronounced for the ssswe one fig 22 shows the spatial distribution of the differences between the maximum vertical water depths computed with the ssswe and the swe i e δh max h max ssswe h max swe the ssswe predict globally lower maximum water depths than the swe indeed negative values of δh max occur in approximately 85 of the computed flooded area and the median value of δh max is 0 4 m in particular the ssswe predict lower maximum water depths with differences lower than 3 m in several zones of the floodplain of bormio near the boundaries of the inundation area and in a large area downstream of cepina zones with the absolute difference δh max lower than 0 5 m are not filled in fig 22 and occupy most of the computed flooded area in the floodplain of bormio their extent is approximately 46 of the total extent of the predicted flooded areas the 75th percentile of δh max is equal to 1 3 m the highest values of δh max occur in the upper portion of the valley where the valley is very narrow and irregular fig 23 compares numerical and experimental discharge hydrographs at the three measuring cross sections the top and right axes indicate time and flow discharge in the physical model scale according to the froude similitude table 8 compares numerical and experimental peak discharges at the measuring cross sections in the experimental investigation by de marchi 1945 discharge measurements were performed using a calibrated tank that collected the water falling through bottom slots opened in turn at the selected measuring sections to reproduce more accurately these experimental measuring conditions additional simulations on a reduced computational domain were performed including only the upper portion of the valley up to section 23 where a transmissive boundary condition was imposed no significant differences were observed in the numerical discharge hydrographs at section 23 therefore the results of the simulations performed on the complete computational domain are used here for comparison and are shown in fig 23 the numerical models reproduce fairly well the experimental discharge hydrograph at the section just downstream of the dam site despite the strong uncertainties in the numerical description of the reservoir geometry however both numerical models underestimate the peak value in this section with a higher underestimation by the ssswe one about 11 moreover both models predict the peak discharge shortly approximately 1 min after the instantaneous collapse of the dam which is perfectly compatible with an essentially partial dam break as regards the comparison between numerical and experimental discharge hydrographs at section 23 the swe overestimate the peak value by 12 6 and the ssswe by 3 3 table 8 the dam break wave front predicted by the ssswe reaches section 23 shortly before that calculated by the swe but in perfect timing with the arrival of the experimental wave which occurs about 7 min after the dam collapse the swe overestimate the wave front arrival time at this cross section by approximately 1 min both numerical models predict a concentration limb steeper than the experimental one the comparison between numerical and experimental hydrographs at cepina leads to similar remarks however in this last section the flooding arrival times predicted by both numerical models are slightly overestimated the swe overestimate the experimental peak discharge by 18 6 whereas the ssswe by only 6 9 table 8 6 conclusions free surface flows on very steep and irregular terrains such as mountain areas could not be modeled in theory with the conventional 2d depth averaged swe because the basic hypothesis of small bottom slopes is not strictly valid in this context a new formulation of the 2d ssswe has been proposed in the companion paper to overcome this limitation defining the water depth along the vertical direction and assuming the flow velocity locally parallel to the bottom surface the vertical pressure distribution is assumed linear albeit non hydrostatic in this paper the new equations are numerically solved with an explicit muscl type second order accurate finite volume scheme which uses the force method to estimate the numerical fluxes when bottom slopes are large the bottom surface cannot be approximated with its horizontal projection accordingly a piecewise linear discretization of the bottom surface is applied based on a quadrilateral non uniform computational grid constructed on the terrain which maps in a uniform cartesian grid on the horizontal plane control volumes with vertical boundaries prevent distortions or possible intersections as well as the problem of handling cell boundaries with variable inclinations on non flat terrains the piecewise linear discretization of the bottom surface induces discontinuities in the bottom slope at cell boundaries unless the bottom surface is planar consequently the finite volume scheme would be intrinsically non conservative due to the presence of the bottom inclination angles in the definition of the physical fluxes numerical adjustments are presented to restore the conservative property of the scheme even on irregular terrains model s accuracy in simulating dam break flows over a sloping bottom is analyzed through split 1d and fully 2d test cases the results of the new ssswe and the conventional swe are compared in all tests to assess the differences the validation against experimental data of 1d dam break flow in a rectangular sloping channel demonstrates that the ssswe are more accurate than the swe in reproducing the wave propagation and the flow discharge at fixed cross sections the two numerical models are practically equivalent when bottom slopes are small the 1d test case concerning the run up of a dam break flow on an adverse slope shows that the ssswe predict a lower run up than the swe in this case the comparison with the numerical results of a 2d inviscid model in the vertical plane indicates that the ssswe model can be inaccurate where the hypothesis of flow velocity parallel to the bottom fails the numerical tests of partial dam break flow on a sloping plane and dam break flow in a parabolic channel demonstrate the model s capability in 2d frameworks in the presence of steep bottom slopes in the parabolic channel test steep bottom slopes occur in both longitudinal and transverse directions the numerical results show that the ssswe predict slower and less severe flood waves than the conventional swe this effect decreases progressively as the bottom slopes decrease the cancano test case shows the capability of the ssswe to cope with the propagation of a dam break flood wave on real topography namely in mountain valleys with high slopes in this test case the two shallow water models are substantially equivalent in predicting flooded areas and satisfactorily reproduce the experimental ones the analysis of the discharge hydrographs at two selected cross sections located in the valley downstream of the dam shows that both numerical models tend to overestimate the peak discharge and the wave arrival time however the percentage error in peak discharge prediction is lower for the ssswe model than for the swe one on the whole the results show that the ssswe are more accurate in describing dam break flows over steep topographies than the conventional swe and predict less severe flooding with slower wave propagation both shallow water models return discharge hydrographs with steeper concentration limbs than the experimental ones ultimately the new 2d ssswe can be used with confidence to predict the main flow features of unsteady shallow free surface flows on sloping terrain provided that the assumption that flow velocity is parallel to the bottom surface is globally acceptable compared with the conventional 2d swe the new equations do not require computationally much more expensive numerical methods the ssswe prove to be on the whole more accurate than the conventional swe in dam break flood modeling on steep terrain slopes when the basic hypotheses are valid in addition they can be adopted in a wider range of applications in any case the swe provide conservative predictions which can be safely used in flood hazard assessment author statement all persons who meet authorship criteria are listed as authors and all authors certify that they have participated sufficiently in the work to take public responsibility for the content including participation in the concept design analysis writing or revision of the manuscript furthermore each author certifies that this material or similar material has not been and will not be submitted to or published in any other publication before its appearance in advances in water resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements prof marco pilotti university of brescia italy is kindly acknowledged for suggesting the research topic of this paper and for his valuable advice and support appendix a details on the numerical model numerical fluxes are computed according to the classic muscl hancock approach through the slic slope limiter centered scheme toro 2001 p 211 based on the following three steps a variable extrapolation boundary extrapolated variables u l and u r are estimated at the two sides of the boundaries of each computational cell fig 1b through a piecewise linear extrapolation toro 2001 p 206 which in the x direction reads a1 q i 1 2 j l q i 1 2 j l q i j n 1 2 ψ i 1 2 j q i j n q i 1 j n q i 1 2 j r q i 1 2 j r q i 1 j n 1 2 ψ i 3 2 j q i 2 j n q i 1 j n where q denotes a conserved variable of the vector u and ψ is a slope limiter function which avoids non physical oscillations at steep gradients of the solution ψ depends on the solution gradients as a2 ψ i 1 2 j ψ r i 1 2 j ψ i 3 2 j ψ r i 3 2 j where r is a ratio of consecutive variations of the conserved variables hirsch 1990 p 537 defined as a3 r i 1 2 j q i 1 j n q i j n q i j n q i 1 j n r i 3 2 j q i 1 j n q i j n q i 2 j n q i 1 j n the van leer limiter function hirsch 1990 p 542 a4 ψ r r r 1 r is adopted in this paper intercell water depths are reconstructed using the weighted surface gradient method wsdgm proposed by aureli et al 2008a p 965 given the excellent performance of this technique in the presence of non flat topography and wetting drying fronts b evolution in time of extrapolated variables the boundary extrapolated variables u l and u r are evolved in time over a half computational time step toro 2001 p 207 through a conservative formula like eq 8b to compute updated boundary extrapolated variables u l and u r aureli et al 2008a eq 16 p 964 a5 u i 1 2 j l u i 1 2 j l δ t 2 δ x f u i 1 2 j l f u i 1 2 j r δ t 2 δ y g u i j 1 2 l g u i j 1 2 r δ t 2 s 0 i j u i 1 2 j r u i 1 2 j r δ t 2 δ x f u i 1 2 j l f u i 1 2 j r δ t 2 δ y g u i j 1 2 l g u i j 1 2 r δ t 2 s 0 i j updated velocity components u and v are also estimated at the left and right hand sides of the cell interfaces through eq 3 in this calculation the bottom inclination angles are set to the values of the computational cell on which the intercell side is facing i e cell i j for the left hand side of intercell i 1 2 j cell i 1 j for the right hand side of intercell i 1 2 j and so on c evaluation of numerical fluxes the intercell numerical fluxes along the ξ and η directions are calculated through the force first order centered scheme toro 2001 p 164 as a6a f i 1 2 j 1 2 f i 1 2 j l f u i 1 2 j l u i 1 2 j r f i 1 2 j r i u i 1 2 j l u i 1 2 j r a6b g i j 1 2 1 2 g i j 1 2 l f u i j 1 2 l u i j 1 2 r g i j 1 2 r i u i j 1 2 l u i j 1 2 r where superscripts and refer again to the forward and backward split interfaces and labels lf and ri refer to the lax friedrichs and richtmyer fluxes respectively lf fluxes are computed according to the 2d lax friedrichs centered scheme hirsch 1990 p 230 a7a f i 1 2 j l f u i 1 2 j l u i 1 2 j r 1 2 f u i 1 2 j l f u i 1 2 j r 1 4 δ x δ t u i 1 2 j l u i 1 2 j r a7b g i j 1 2 l f u i j 1 2 l u i j 1 2 r 1 2 g u i j 1 2 l g u i j 1 2 r 1 4 δ y δ t u i j 1 2 l u i j 1 2 r while ri fluxes are computed according to the two step lax wendroff scheme toro 2001 p 164 a8a f i 1 2 j r i u i 1 2 j l u i 1 2 j r f u i 1 2 j r i with u i 1 2 j r i 1 2 u i 1 2 j l u i 1 2 j r 1 2 δ t δ x f u i 1 2 j r f u i 1 2 j l a8b g i j 1 2 r i u i j 1 2 l u i 1 2 j r f u i j 1 2 r i with u i j 1 2 r i 1 2 u i j 1 2 l u i j 1 2 r 1 2 δ t δ y g u i j 1 2 r g u i j 1 2 l a cell centered estimate of the pressure correction factor defined in eq 4 is used in eqs a7a a7b a8a and a8b according to the rule of selecting the computational cell to which the split intercell belongs average values of bottom inclination functions cosθx and cosθy calculated as a9 cos θ x i 1 2 j cos θ x i j cos θ x i 1 j 2 cos θ y i j 1 2 cos θ y i j cos θ y i j 1 2 are used at i 1 2 j and i j 1 2 interfaces in assessing mass fluxes to ensure that the numerical scheme is conservative with respect to the mass at each cell interface both forward and backward intercell u r i and v r i velocities are set equal to the arithmetic mean of the updated left and right hand side boundary extrapolated values to prevent the richtmyer component of the force flux from producing mass unbalance when the bottom surface is uneven the iterative flux correction procedure described in aureli et al 2008a p 965 is applied to avoid the numerical instabilities typically induced by small water depths at wetting and drying fronts especially over irregular topography and to reduce the mass error since pressure correction coefficient k is discontinuous for v 0 eq 4 the numerical scheme must be well balanced i e it must preserve exactly a stationary condition this property is obtained by including the bottom slope term in the time evolution of the boundary extrapolated variables step b eq a5 and calculating it according to the centered approximation aureli et al 2008a eq 17 p 964 a10 s 0 i j 0 g h i 1 2 j l h i 1 2 j r 2 z b i 1 2 j z b i 1 2 j δ x g h i j 1 2 l h i j 1 2 r 2 z b i j 1 2 z b i j 1 2 δ y where zb is the bottom elevation the present numerical scheme as any other explicit one is potentially stable under the courant friedrichs lewy stability condition for 2d unsplit schemes this condition identifies a reduced stability range toro 2001 p 240 and can be expressed as aureli et al 2008b maranzoni et al 2015 a11 δ t c r 2 min δ x max i j λ 3 f i j δ y max i j λ 3 g i j where λ 3 f and λ 3 g are the maximum absolute celerities provided by eqs c4 and c5 in maranzoni and tomirotti 2022 and cr is the courant number 0 cr 1 appendix b grid convergence analysis grid convergence analysis is usually performed in cfd computational fluid dynamics calculations to assess the grid discretization error stern et al 2001 three grid sizes are considered here to this end δx 1 2 10 3 m δx 2 3 33 10 3 m and δx 3 1 10 2 m with refinement factors r 21 δx 2 δx 1 1 667 and r 32 δx 3 δx 2 3 both greater than 1 3 according to the refinement criterion by celik et al 2008 p 1 this choice for the grid sizes allows comparison of numerical predictions at common cell center locations without requiring interpolations which can result in the introduction of interpolation errors fig b1 compares numerical profiles of flow depth and velocity calculated with the ssswe at selected times for the three grid sizes considered it shows that numerical results have practically reached convergence with respect to the grid size parameter fig b2 shows the profiles of the absolute differences between the numerical solutions in terms of flow depth and velocity calculated at the cell centers of the coarser mesh for two selected times denoting θ a hydraulic variable of interest e g h or u ε θ 32 θ3 θ2 is the absolute difference between the solution θ3 of the coarser grid and the solution θ2 of the medium one and ε θ 21 θ2 θ1 is the absolute difference between the solution of the medium grid and the solution θ1 of the finer one deviations ε θ 21 are on average smaller than ε θ 32 except at the wave fronts deviations are very close to zero indicating that numerical convergence has practically been attained with the finer grid δx 1 2 10 3 m mean absolute deviations b1 ε θ 32 1 n k 1 n θ 3 θ 2 k ε θ 21 1 n k 1 n θ 2 θ 1 k and ε θ 31 1 n k 1 n θ 3 θ 1 k are calculated for flow depth table b1 and velocity table b2 profiles at the times considered in fig b1 in eq b1 n is the number of non zero deviations in the numerical profiles an average global apparent order of accuracy can be calculated for each profile as b2 p ln ε θ 31 ε θ 21 ln r 32 using the numerical results of the finer grid as a reference solution an estimate of the exact solution can then be obtained through the richardson extrapolation celik et al 2008 eq 4 b3 θ 0 r 21 p θ 1 θ 2 r 21 p 1 and a global numerical uncertainty associated with the finer grid solution can be estimated as b4 ε θ 10 1 n k 1 n θ 1 θ 0 k or in relative terms with reference to the average value θ 0 of the estimated exact θ profile as ε θ 10 θ 0 note that the usual procedures for estimating the discretization error such as the grid convergence method gci do not work if either ε θ 32 and ε θ 21 are very close to zero celik et al 2008 p 2 tables b1 and b2 provide an example of the calculation of discretization errors for flow depth and velocity profiles respectively maximum global relative uncertainties in the numerical solutions obtained with the finer grid δx 1 2 10 3 m are in the order of 1 for both flow depth and velocity profiles appendix c wave tip region the tip region of the dam break wave is dominated by friction and characterized by significant variations in flow depth and velocity chanson 2009 the profile of a dam break wave propagating on a steep slope is substantially unchanging in this region once the wave has become very thin hence it can be considered the wave profile of a uniformly progressive flow chow 1959 p 535 in the ssswe framework starting from the equations of the 1d x split problem maranzoni and tomirotti 2022 eq 21 c1 h t u h cos θ x x 0 u h t x u 2 h 1 2 k g h 2 cos θ x g h sin θ x n 2 u 2 h 4 3 1 ta n 2 θ x the following dynamic equation can be obtained for uniformly progressive flow in a sloping wide rectangular channel of fixed slope θx c2 h x tan θ x cos 2 θ x 1 h n h 4 3 where hn is the normal depth at the upper limit of the wave tip region where the flow is practically uniform expressed via the manning formula solving for dx and integrating assuming x 0 at the wave front where h 0 the analytical flow profile in the tip region is c3 x tan θ x cos 2 θ x h 3 2 h n arctan h h n 1 3 3 2 h n arctanh h h n 1 3 similarly using the swe this analytical profile becomes c4 x tan θ x h 3 2 h n arctan h h n 1 3 3 2 h n arctanh h h n 1 3 fig c1 compares the numerical and analytical wave profiles in the tip region at a selected time t 1 207 s for lauber and hager s case study with s 0 0 5 the value of hn was determined from the numerical profiles as the average flow depth at the wavefront crest where the profile appears unchanging fig c1 shows the capability of the numerical model to correctly reproduce the analytical solution of the wave profile near the wetting front for a dam break wave moving on a prismatic channel with a steep bottom at the instant considered the ssswe wavefront is behind the swe one and the normal depth hn of the ssswe profile is slightly higher 2 65 10 2 m against 2 38 10 2 m for the swe profile appendix d formation of roll waves the capability to describe the formation of roll waves in a dam break wave propagating on an inclined channel is desirable for a shallow water model zanuttigh and lamberti 2002 bohorquez and fernandez feria 2008 bohorquez 2011 this property is verified in this appendix for the ssswe and swe models presented in this paper the geometry of the steeper channel of lauber and hager s experiments s 0 0 5 θx 26 56 was considered to this end however the initial water depth at the dam h 0 was reduced to 0 075 m to ensure that the channel was long enough to allow the development of roll waves fig d1 shows that the ssswe and swe models can reproduce the formation of roll waves near the wave front at sufficiently large times when the froude number fr u ghcos2 θx 1 2 is much greater than 2 bohorquez and fernandez feria 2006 indeed approximately 1 s after the dam removal instabilities appear near the front where fr reaches values close to 10 according to bohorquez and fernandez feria 2006 p 511 such instabilities develop from just the numerical round off noise at high froude numbers the train of travelling roll waves becomes evident at t 2 s when the ssswe model predicts a maximum crest height higher than the swe one the swe simulate a faster advance of the dam break wave even in the presence of roll waves 
14,numerical models based on the two dimensional 2d shallow water equations swe are commonly used for flood hazard assessment although the basic assumption of small bottom slopes is not always strictly satisfied such as in mountain areas when terrain slopes are large the steep slope shallow water equations ssswe are theoretically more suitable because the restrictive hypothesis of small bottom slopes is not introduced in deriving these equations a new formulation of the 2d ssswe in which the water depth is measured in the vertical direction and the flow velocity is assumed parallel to the bottom surface is proposed in the companion paper part i the pressure distribution on the vertical is assumed linear yet non hydrostatic and the effect of flow curvature is neglected in this paper the new ssswe are solved with an explicit muscl type second order accurate finite volume scheme using the centered force method for flux evaluation the ssswe model is validated against existing experimental data of one dimensional 1d dam break flows on sloping channels with fixed slopes the numerical results of the ssswe and swe models are compared both in this benchmark test case and in other numerical tests including a 1d dam break flow moving on an adverse slope a 2d dam break flow spreading on an inclined plane and a 2d dam break flow propagating in a sloping parabolic channel finally the two models are applied to the real field test case of the cancano dam adda river northern italy which is characterized by very steep and irregular topography especially in the upper portion of the valley the results show that on the whole the ssswe are more accurate in describing dam break flows over steep topographies than the conventional swe and predict less severe flooding with slower wave propagation the two models are practically equivalent when bottom slopes are relatively small keywords finite volume method free surface flow numerical model shallow water equations steep bottom slopes two dimensional depth averaged model data availability data will be made available on request 1 introduction the depth averaged shallow water equations swe are widely used to model a variety of geophysical fluid flows and wave propagation phenomena e g toro 2001 fent et al 2018 in the classic formulation these equations hold under a set of restrictive hypotheses including that of small bottom slopes e g chow 1959 toro 2001 castro orgaz and hager 2017 however often free surface flows develop on very steep and irregular topography at least locally especially in mountain regions or near geometric singularities despite the swe are not strictly valid in this context e g van emelen et al 2014 they are yet used for flood hazard assessment assuming that solution s accuracy remains acceptable for engineering purposes e g han and wang 1996 valiani et al 2002 begnudelli and sanders 2007 aureli et al 2008c pilotti et al 2011 singh et al 2011 wang et al 2011 pilotti et al 2014 the steep slope shallow water equations ssswe are in principle of more general application not requiring the assumption of small bottom slopes however if a univocal formulation of the one dimensional 1d ssswe is available in the literature e g berger 1994 fernandez feria 2006 ancey et al 2008 different formulations of the ssswe have been proposed in the two dimensional 2d framework based on different global or local coordinate systems e g chaudhry 1993 laigle 1997 nakagawa and takahashi 1997 denlinger and iverson 2004 rickenmann et al 2006 denlinger and o connel 2008 medina et al 2008 juez et al 2013 xia and liang 2018 ni et al 2019 a review of existing 2d formulations has been performed in part i of this work maranzoni and tomirotti 2022 to overcome some critical issues of the available formulations in the companion paper the writers have proposed a new formulation of the depth averaged 2d ssswe based on the assumptions that the water depth is measured in the vertical direction the flow velocity is parallel to the bottom the vertical pressure distribution is linear yet non hydrostatic and the effect of flow curvature is negligible the resulting equations are hyperbolic for wet bed and reduce to the conventional swe for small bottom slopes therefore the variety of numerical methods proposed in the literature to solve nonlinear hyperbolic systems of conservation laws e g toro 1997 leveque 2002 toro and garcia navarro 2007 can be applied also to the new set of equations solving the governing equations with robust and accurate numerical models is crucial in order to correctly simulate the flow dynamics and calculate the flow variables involved in quantifying and classifying flood hazard e g kim and sanders 2016 d oria et al 2019 in this paper the new 2d ssswe written in conservative form are solved by an explicit muscl type second order accurate finite volume scheme in which the force first order centered method is used for the evaluation of the numerical fluxes toro 2001 and a hybrid weighted depth surface gradient method wsdgm is used to estimate the conserved variables at intercell boundaries aureli et al 2008a based on the idea of the finite volume method the computational domain is subdivided into areal elements with planar inclined bottom and rectangular horizontal projection and the flowing water mass is interpreted as composed by a set of prismatic vertical water columns where cell averaged values of the conserved variables are defined the vertical alignment of such control volumes which is a direct consequence of the assumption of measuring the water depth along the vertical prevents their superimposition or gross distortions mancarella and hungr 2010 allowing the lateral faces of adjacent control volumes to match denlinger and iverson 2004 conversely models in which the water depths are assumed normal to the bottom e g iverson and denlinger 2001 fent et al 2018 are potentially subject to these numerical problems especially on very irregular topographies maranzoni and tomirotti 2022 figs 1 and 2 and require laborious pre and post processing of terrain elevation data in general numerical methods must address challenging difficulties in real applications e g zhou et al 2001 leveque et al 2011 such as dealing with irregular topographies and wet dry interfaces or reproducing bores and transcritical flows as well as static or steady states which requires a well balanced numerical scheme the robustness and effectiveness of the scheme used in this study in facing these numerical challenges were extensively tested in aureli et al 2008a in the case of swe the adjustments required to effectively handle the peculiarities of the new system of equations are discussed here the ssswe model is first validated against existing experimental data concerning the propagation of a dam break wave in a sloping channel lauber and hager 1998b some schematic numerical tests are then performed for 1d and 2d dam break flows over a sloping bottom including dam break flows moving on an adverse slope spreading on an inclined plane and propagating in a sloping parabolic channel characterized by large bottom slopes both in the longitudinal and transverse directions finally the model is applied to the real field test case of the hypothetical total collapse of the cancano dam adda river northern italy for which experimental flooded areas and discharge hydrographs at selected cross sections measured in a historical small scale physical model are available de marchi 1945 pilotti et al 2014 pilotti et al 2020 aureli et al 2021 this test case is particularly suitable for validating the ssswe because long stretches of the upper portion of the valley downstream of the dam are very steep as well as the valley sides for all the test cases considered the numerical results of the ssswe are compared with those obtained by the conventional swe using the same finite volume numerical scheme this paper is organized as follows the governing equations are recalled in section 2 and the numerical model is described in section 3 the validation of the model is performed in section 4 along with the analysis of its performance in 1d and 2d schematic numerical tests the real field application is presented in section 5 conclusions are drawn in section 6 2 mathematical model the new 2d ssswe were derived in part i of this work maranzoni and tomirotti 2022 by adopting a global horizontal oriented xyz coordinate system with vertical z axis and a local bottom oriented coordinate system with two axes ξ and η in general non orthogonal locally parallel to the bottom with inclination angles θx and θy with respect to horizontal orthogonal directions x and y and the third axis ζ locally perpendicular to the fixed bottom surface the global fixed reference frame is used to define the spatial variables water depth and horizontal spatial coordinates while the local reference frame is used to define the vertically averaged flow velocity assumed locally parallel to the bottom surface the equations representing the mass conservation and the linear momentum balance along the ξ and η directions can be expressed in conservative vector form as 1 u t f x g y s with 2 u h u h v h f u h cos θ x u u h 1 2 k g h 2 cos θ x u v h cos θ x g v h cos θ y u v h cos θ y v v h 1 2 k g h 2 cos θ y s 0 g h s 0 ξ s f ξ g h s 0 η s f η where u is the vector of the conserved variables f and g are the vectors of the physical fluxes along the ξ and η directions respectively s is the source term which includes the effects of bottom slope s 0 and friction sf in the definitions of eq 2 h is the water depth measured along the vertical direction u v ξ and v v η are the orthogonal projections of flow velocity v in the ξ and η directions identified by the unit vectors ξ and η respectively and u and v are the scalar components of the velocity vector along the ξ and η directions respectively i e v u ξ v η accordingly u and v can be expressed as a function of u and v as 3 u u v sin θ x sin θ y 1 sin 2 θ x sin 2 θ y v v u sin θ x sin θ y 1 sin 2 θ x sin 2 θ y again in eqs 1 and 2 t is time g is the acceleration due to gravity and k is a pressure correction factor 0 k 1 which reflects the effect of bottom slope on pressure distribution assumed to be linear along any vertical reducing the pressure with respect to the hydrostatic one in dynamic conditions neglecting the effect of bottom curvature and in analogy to the case of 1d parallel flow chow 1959 p 33 k is set equal to the square cosine of the angle between the direction locally normal to the bottom and the vertical in dynamic conditions juez et al 2013 xia and liang 2018 ni et al 2019 and equal to unity in static conditions 4 k 1 if v 0 1 1 tan 2 θ x tan 2 θ y otherwise finally in eq 2 the bottom slopes read 5 s 0 ξ sin θ x and s 0 η sin θ y and extending the manning formula to the 2d framework e g molls et al 1998 the friction slopes are 6 s f ξ n 2 u v h 4 3 1 ta n 2 θ x ta n 2 θ y and s f η n 2 v v h 4 3 1 ta n 2 θ x ta n 2 θ y where n is the manning roughness coefficient the new set of equations is strictly hyperbolic for wet bed and reduces to the conventional 2d shallow water equations when bottom slopes are small maranzoni and tomirotti 2022 3 numerical model due to the hyperbolicity of the new equations and their structural similarity with the classic 2d depth averaged swe the variety of existing numerical methods designed to solve the swe can also be used for the ssswe in this paper the 2d non linear differential system of eqs 1 and 2 is numerically solved by the finite volume scheme described in aureli et al 2008a successfully used to simulate unsteady free surface flows in various applications maranzoni and mignosa 2018 2019 including flooding due to dam break aureli et al 2008a 2008c and levee breach aureli et al 2006a 2006b the horizontal projection of the computational domain is discretized by a uniform structured cartesian grid with size δx δy and the bottom basis of each computational cell is assumed to be an inclined quadrilateral fig 1a with area 7 a δ x δ y 1 ta n 2 θ x ta n 2 θ y following the basic idea of the cell centered finite volume methods leveque 2002 cell averaged values u i j of the conserved variables are defined for each computational i j cell identified by the rectangular interval xi 1 2 xi 1 2 yj 1 2 yj 1 2 on the horizontal xy plane and stored in the corresponding cell center fig 1b the piecewise linear approximation of the bottom surface implies that the bottom inclination angles θx and θy are constant over each cell and defined at the cell centers with discontinuities at the cell boundaries if the bottom surface is non planar this causes a computational difficulty in the calculation of the numerical fluxes since they depend on the local bottom inclination according to eq 2 to overcome this problem the strategy adopted by maranzoni and mignosa 2018 of fictitiously splitting a cell interface into two distinct mutually parallel interfaces each belonging to one of the adjoining cells is used in this paper for example the i 1 2 j intercell is assumed to be split into the two distinct intercells forward i 1 2 j and backward i 1 2 j belonging to cells i 1 j and i j respectively accordingly different numerical fluxes can be computed at split interfaces i 1 2 j and i 1 2 j by using the bottom slopes of cells i 1 j and i j respectively fig 1c this strategy also allows dealing with bottom discontinuities which occur for example in step poll streams stepped channels or at check dams zhou et al 2002 starting from cell average state u i j n at time tn updated cell average flow state u i j n 1 at next time tn 1 tn δt is obtained through the following explicit dimensionally unsplit three step algorithm based on the second order accurate strang splitting decomposition of the friction source term toro 2001 p 232 8a u i j u i j n δ t 2 s f i j n 8b u i j u i j δ t δ x f i 1 2 j f i 1 2 j δ t δ y g i j 1 2 g i j 1 2 δ t s 0 i j 8c u i j n 1 u i j δ t 2 s f i j in this algorithm eqs 8a c u i j and u i j denote two successive intermediate updates of u i j in the computational time step δt f i 1 2 j f i 1 2 j g i j 1 2 and g i j 1 2 are numerical fluxes across intercells i 1 2 j i 1 2 j i j 1 2 and i j 1 2 of the i j cell respectively fig 1c s 0 i j and s f i j are the cell averaged bottom and friction source terms respectively in the first step of the algorithm eq 8a the contribution of the friction source term is calculated in a pointwise way on the basis of the previous discretized solution u i j n over a halved time step δt 2 whereas in the third step eq 8c the update is based on the intermediate solution u i j in the second step of the algorithm eq 8b the intermediate solution u i j is updated to the new intermediate solution u i j over the entire time step δt by applying simultaneously both advection and bottom slope terms both calculated for u i j the numerical fluxes are evaluated using a second order accurate muscl hancock scheme e g hirsch 1990 toro 2001 according to the steps described in appendix a owing to the quasi conservative structure of eq 8b the numerical scheme does not satisfy the telescopic property toro 2001 p 144 if the terrain is uneven i e non planar because f i 1 2 j f i 1 2 j and g i j 1 2 g i j 1 2 this occurs for the momentum flux components since the basic assumption that the flow velocity is locally parallel to the bottom implies that velocity components u and v of adjacent computational cells refer in general to different directions however this apparent inconsistency does not exclude that the momentum vector is conserved as physically required by the linear momentum principle the telescopic property of momentum fluxes is restored by supposing that fictitious cells are present between the split boundaries of adjacent actual cells zhou et al 2002 maranzoni and mignosa 2018 again in the case of uneven terrain the telescopic property is not satisfied even for mass fluxes since the first components of physical fluxes f and g depend on local bottom inclinations θx and θy which can be different between two neighboring cells the numerical strategies to overcome this problem are described in appendix a 4 numerical tests and validation in this section the performance of the ssswe is assessed on the basis of 1d and 2d test cases of dam break flows on sloping bottom and compared with that of the conventional swe 4 1 dam break in a rectangular sloping channel a systematic analysis of the effect of bottom slope on dam break flows was performed by lauber and hager who carried out a series of laboratory experiments considering the cases of horizontal lauber and hager 1998a and sloping bottom lauber and hager 1998b the experimental data presented in the latter paper were obtained for two channel slopes s 0 0 1 and s 0 0 5 s 0 tanθx corresponding to channel inclination angles of approximately 6 and 27 respectively they are particularly useful to assess models capability to reproduce dam break waves on inclined bottoms even considering large slopes tan and chu 2009 the experiments were conducted in a rectangular flume 14 m long and 0 5 m wide with smooth surfaces made of pvc and glass lauber and hager 1998a the vertical sluice gate used to simulate the dam was located 3 5 m downstream of the upper channel end and was suddenly opened to release the water stored behind the initial water depth at the gate was h 0 0 3 m and the flume was initially dry downstream experimental data include profiles of water depth average cross sectional velocity and discharge at selected times trajectories and velocities of positive wetting negative and drying fronts time histories of water depth measured perpendicularly to the bottom average cross sectional velocity and discharge at selected locations lauber and hager 1998b similar experimental investigations were carried out by iverson et al 1992 in the sloping usgs channel with clear water or debris logan et al 2018 and by ancey and cochard 2009 with viscoplastic fluids in the numerical simulations a uniform cartesian mesh is used and the manning roughness coefficient is set to 0 01 m 1 3s which is a suitable value for smooth surfaces of a laboratory flume chow 1959 table 5 6 p 110 the ssswe code is verified in appendix b through a grid refinement study based on free surface profiles at various times calculated with uniform grids of different sizes this study shows that spatial convergence is practically attained with the grid size δx 2 10 3 m fig 2 compares experimental and numerical trajectories calculated with the new ssswe and the conventional swe of wetting and drying fronts for s 0 0 1 and s 0 0 5 fig 2a shows that for the smaller bottom slope s 0 0 1 the numerical fronts both wetting and drying are substantially overlapping and the numerical wetting fronts agree very well with the experimental data conversely the predicted drying fronts differ significantly from the measured one however the numerical trajectory of the drying front is considerably influenced by the threshold water depth used for the numerical simulation of the wetting drying process aureli et al 2008a fig 4 p 968 in the simulations this threshold was set to 5 10 4 m fig 2b shows appreciable differences between the numerical wetting fronts predicted by the two shallow water models for s 0 0 5 in this case the ssswe model reproduces well the experimental wetting front apart from an initial slight overestimation of the front celerity whereas the swe model predicts a faster front propagation than observed in the experiments as regards the drying front instead the two numerical models return similar results although the swe one tends to predict a faster front propagation for increasing time differently from the previous case s 0 0 1 fig 2a the numerical drying fronts agree well with the experimental one mainly because the wetting drying threshold is less critical in determining the position of the numerical drying front for higher bottom slopes the intersection of the numerical drying fronts is due to the effect of friction which strongly influences the flow dynamics at the head of the reservoir where water depths are small horizontal sections of the plots in fig 2 identify the channel stretch spanned by the water profile at a given time and vertical sections correspond to the time interval spanned by the wave history at a given location accordingly for the higher channel slope s 0 0 5 fig 2b the swe model predicts longer stretches spanned by wave profiles at fixed times mainly due to a significant overestimation of the wetting front celerity and shorter wave arrival times at fixed locations compared to the experimental observations the ability of the two numerical models to capture the wave profile in the tip region is verified in appendix c against the analytical solutions of the dynamic equation of uniformly progressive flow in a wide rectangular channel this ability is critical for dam break numerical codes e g bohorquez and fernandez feria 2008 especially for waves propagating down a steeply inclined bottom the previous remarks concerning free surface profiles are confirmed by figs 3 and 4 which compare experimental and numerical water surface profiles at selected times for s 0 0 1 and s 0 0 5 respectively for the former case fig 3 the ssswe and swe numerical profiles are substantially identical as the bottom slope is low enough less than 6 according to chow 1959 p 33 for the ssswe to practically reduce to the conventional swe moreover both numerical models slightly overpredict the celerity of the wetting front in the first stages of dam break flow after the gate removal fig 3a c for the higher slope case fig 4 this overprediction is more significant for the swe model while it is much less pronounced in the ssswe profiles and attenuates over time finally it is worth noting that shallow water models cannot reproduce the inflection point of the experimental profiles at the initial stages of motion when the effect of flow curvature is significant the accuracy in the numerical reproduction of the experimental water surface profiles shown in figs 3 and 4 is assessed by calculating the mean absolute percentage error mape e g hyndman and koehler 2006 9 mape 1 n k 1 n h z b num k h z b exp k h z b exp k 100 where zb is the bottom elevation n is the number of available experimental points and subscripts num and exp refer to numerical predictions and experimental data respectively the 1 norm is indeed appropriate for conservation laws according to leveque 2002 p 140 numerical predictions are linearly interpolated at the longitudinal coordinates where water surface elevations were measured in the physical model and the mape calculation based on eq 9 is limited to the channel stretch common to the profiles compared the mape computed with the ssswe and swe predictions are compared in tables 1 and 2 for s 0 0 1 and s 0 0 5 respectively the ssswe errors are always less than the swe ones and the differences are more significant for the case with the higher bottom slope moreover errors decrease with time for both models as the dam break wave propagation proceeds figs 5 and 6 show flow depth hydrographs at selected cross sections located downstream of the gate these time series refer to flow depth h measured perpendicularly to the channel bottom which is calculated from the vertical water depth h computed by the numerical models through the trigonometric transformation 10 h h for the swe model h cos θ x 1 1 s 0 s wse for the ssswe model where s 0 tanθx zb x x is the slope of the channel and s wse zb h x is the local slope of the water surface in the streamwise direction the condition for the swe model derives from the substantial equivalence between vertical and normal depths due to the assumption of small bottom slopes as for the water surface profiles the numerical water depth hydrographs are practically identical for s 0 0 1 fig 5 and reproduce fairly well the experimental ones except for a slight underestimation of the peak value at the most upstream observation section fig 5a and a general steeper rise of the hydrographs resulting in a systematic slight anticipation of the peak conversely considerable differences between the hydrographs predicted by the two numerical models occur for s 0 0 5 fig 6 in this case despite the more complex two peak pattern of the measured hydrographs the ssswe perform better than the swe showing an overall satisfactory agreement with the experimental data except for a slight underestimation of the wave arrival time at the three most upstream observation points fig 6a c on the other hand the swe overestimate the peak value at the two most upstream observation points fig 6a b and underestimate the wave front arrival time more significantly at the cross sections furthest from the dam similar conclusions can be drawn from the analysis of the discharge per unit width hydrographs reported in figs 7 and 8 the two shallow water models provide practically identical numerical results in the lower slope case s 0 0 1 fig 7 instead the ssswe perform better than the conventional swe in reproducing the experimental discharge hydrographs in the larger slope case s 0 0 5 fig 8 indeed in this case the swe return a greater overestimation of the peak discharge especially in the observation cross sections closest to the dam in fig 8 it is again evident that the swe predict a faster wave front the accuracy in the numerical prediction of the water depth and unit discharges time series shown in figs 5 8 is assessed in tables 3 6 by the normalized nash sutcliffe efficiency coefficient nnse nossent and bauwens 2012 11 n n s e 1 2 n s e where nse is the usual nash sutcliffe model efficiency coefficient nash and sutcliffe 1970 12 n s e 1 k 1 n θ num k θ exp k 2 k 1 n θ exp k θ exp 2 where θ denotes the hydraulic variable of interest water depth or unit discharge and θ exp is the average value of the set of experimental data the nash sutcliffe model efficiency coefficient is commonly used in various hydraulic and hydrologic applications e g echeverribar et al 2019 and its normalized version ranges between 0 and 1 the latter being the optimal value moreover this performance coefficient does not incur division by zero and the numerical difficulties related to the temporal shifts of the hydrographs compared as would occur for mape numerical predictions are linearly interpolated at the times of the experimental data to calculate nse based on eq 12 the results confirm the superiority of the ssswe in predicting the time series of both water depth and unit discharge since the nnse values are higher than for the swe model the difference between the nnse coefficients calculated from the two models is higher for the steeper channel the agreement between numerical predictions and experimental data is overall better for the milder slope since the nnse values get closer to 1 the greater accuracy of the ssswe model is obtained at the cost of a slight reduction in computational efficiency for example the ratio of the execution times of the swe and ssswe codes is equal to 0 866 on an intel xeon cpu e5 1620 v4 3 50 ghz workstation for 3 s simulation of lauber and hager s test case s 0 0 5 on a 2 10 3 m grid with a courant number of 0 9 wave profiles and time series presented in figs 3 8 show a regular behaviour however it is well known that the free surface of a supercritical flow in a channel with a very steep slope can break into a train of travelling pulses named roll waves chow 1959 p 580 this phenomenon can also occur in the propagation of a dam break wave if the channel is long enough denlinger and o connell 2008 bohorquez 2011 appendix d shows that both shallow water models are able to catch the formation of roll waves near the wavefront of a dam break flow in a steep channel 4 2 run up of a dam break flow on an adverse slope the test case presented in this section concerns a 1d dam break wave which first propagates on a horizontal channel and then runs up a steep adverse slope despite its simplicity this problem is of practical interest for example in modeling flow in the coastal swash zone antuono and hogg 2009 and the motion of rapid geophysical flows on adverse inclined topographies iverson et al 2016 or against obstacles and protective structures mancarella and hungr 2010 the depth averaged swe are classically used to simulate such flow phenomena e g aureli et al 2000 in this test the adverse ramp is assumed to be very steep so that the performance of the new ssswe can be effectively compared with the conventional swe the 2d numerical solution on the vertical plane obtained simulating the planar flow on the xz plane via the vof volume of fluid model with the cfd computational fluid dynamics software ansys fluent 18 0 2017 is used as a reference for comparison purposes the vof model is indeed widely used in cfd to study dam break flows especially in the initial stages e g ozmen cagatay and kocaman 2010 larocque et al 2013 yang et al 2022 and the propagation of tsunami bores in the swash zone e g tar et al 2017 showing better predictive capabilities than the depth averaged shallow water models ozmen cagatay and kocaman 2010 kocaman et al 2021 the test case is similar to the dam break problem on an adverse sloping plane theoretically analyzed by antuono and hogg 2009 the main difference is that the adverse slope inclined by θx 45 with respect to the horizontal s 0 1 is preceded by a horizontal propagation channel as in o donoghue et al 2010 or lu and liu 2018 the bottom is described by 13 z b x 0 for 0 x 6 m x 6 for 6 m x 7 m where zb is the bottom elevation and x denotes the horizontal coordinate fig 9 the sharp change in bottom slope implies that bottom curvature is different from zero tending to infinity only locally at x 6 m the resistance is assumed to be negligible the ideal dam is located at x 5 m and the initial condition is 14 h x t 0 0 2 m for 0 x 5 m 0 otherwise the unsteady flow generated by the sudden removal of the dam is a frictionless dam break flow on a horizontal dry bed until the wave tip reaches the section x 6 m at which the adverse ramp starts the run up of the wave on the adverse slope induces flow deceleration and inversion with the formation of a backwash bore a cartesian grid with square cells sized 2 10 3 m was used in the numerical simulations performed with the depth averaged shallow water models the manning coefficient was set to zero in the cfd model the vof method was applied to the inviscid euler equations the 2d computational domain on the x z vertical plane was discretized with a fixed unstructured mesh of non uniform quadrilateral cells the characteristic cell size is 10 3 m in the region involved by the water flow moreover solid walls were assumed at the boundary of the computational domain except for the upper boundary where the gage pressure was imposed equal to zero the numerical solution was advanced in time using a fixed global time step of 5 10 3 s fig 9 shows the numerical profiles of water surface and depth averaged velocity at selected times in the cfd solution the 0 5 volume fraction isosurface represents the water air interface which includes the free surface since the vof method models a free surface flow as a two phase flow of an air water mixture with the water volume fraction ranging between 0 and 1 at t 0 5 s after the dam removal the waves computed by the depth averaged models are already climbing up the adverse ramp while the wetting front of the wave simulated by the cfd model is just at the toe of the slope fig 9a at this time the water surface and velocity profiles calculated by the two depth averaged models are identical in the approaching channel and exhibit the typical features of the depression wave of ritter s solution on the other hand the free surface profile computed by the cfd model shows the shape with change in profile curvature experimentally observed in several studies e g lauber and hager 1998a stansby et al 1998 ozmen cagatay and kocaman 2010 after passing the bottom slope change the dam break wave climbs up the adverse ramp fig 9a b decelerating until the maximum run up height is attained in this run up phase the wave is tapered and thin see also fig 10a hence the assumption of flow velocity parallel to the bottom is perfectly plausible thereafter flow inversion occurs and a backwash bore appears inducing the increase of the water depth at the toe of the adverse ramp fig 9c for t 1 2 s in these circumstances the motion is fully 2d in the vertical plane and the classic shallow water models are inaccurate fig 10b after its formation the bore moves backward t 1 2 s separating the downstream flow influenced by the presence of the adverse slope from the upstream incoming flow the shallow water models predict a standard moving jump its celerity and height are practically equal in the two depth averaged models instead the cfd model predicts the development of a plunging bore with complex splash phenomena and air entrainment fig 9d e these phenomena cannot be reproduced by a depth averaged shallow water model fig 11a which plots the wave front position as a function of time shows that the new ssswe model estimates a lower maximum run up height than the other two models the conventional swe model and the 2d vof model predict maximum run up heights that are in good agreement even if the maximum run up occurs earlier in the swe model the maximum run up height is reached at approximately t 0 7 s for both depth averaged models and later approximately at t 1 s for the 2d vof model indeed the wave front computed by the 2d vof model is slower than the one calculated by the two depth averaged models when the dam break wave propagates on the horizontal stretch incidentally the wave front celerities predicted by the two depth averaged models are identical as long as the dam break wave moves on a horizontal bottom once the maximum run up height is reached the flow reverses over the ramp and subsequent flow inversions occur accordingly the wave front oscillates and quickly becomes quasi stationary this oscillating behavior is not so evident in the ssswe model the quasi stationary position of the wave front on the inclined ramp returned by the ssswe model agrees very well with the one provided by the reference 2d vof model while the swe model predicts a slightly higher long term wave front elevation in any case it is worth noting that the water front trajectory calculated by the shallow water models is rather sensitive to the value of the water depth threshold introduced to deal with wetting and drying fig 11b shows the numerical time series of flow discharge per unit width at the dam location x 5 m and at the vertical section where the bottom slope changes discontinuously x 6 m the three discharge hydrographs are in good agreement and show comparable features in both control cross sections the outflow discharge at the dam location remains constant equal to the value provided by the ritter analytical solution for all three numerical models until the backwash bore reaches this section however the outflow hydrograph calculated by the 2d vof model exhibits an initial peak induced by flow curvature which has significant effects at the initial stages of a dam break flow cantero chinchilla et al 2020 the two depth averaged shallow water models slightly overestimate the arrival time of the backwash bore at the dam location compared with the 2d vof model although the bore reaches the section of change in bottom slope earlier in the depth averaged models than in the 2d vof model all the numerical models predict comparable peak flow discharges at x 6 m and indicate local inversion of the flow at the passage of the backwash bore at this control section at both cross sections the arrival time of the backwash bore is slightly shorter in the ssswe model than in the swe one which is consistent with the lower run up height predicted by the former 4 3 spreading of a dam break flow on a sloping plane several experimental investigations of partial dam break flow on a plane can be found in the literature e g fraccarollo and toro 1995 aureli et al 2008b kocaman et al 2021 however they have been typically conducted on horizontal bottom dam break flow spreading on a sloping plane is most frequently considered in the context of debris and mud flow analysis e g laigle 1997 iverson et al 2004 cochard and ancey 2009 in particular laigle s experiments were conducted on an inclined platform 6 m long and 2 1 m wide with an adjustable slope the set up of test a16 laigle 1997 table 1 p 129 characterized by a slope of 0 2 θx 11 31 being θx the inclination of the platform with reference to the horizontal plane is considered here in this test the bottom slope is the maximum realized in the experimental investigation the planar shape of the reservoir is assumed rectangular making it more schematic than the original one laigle 1997 fig 1 p 128 a gate placed symmetrically between two lateral walls separates the reservoir from a short rectangular channel 0 75 m long and 0 5 m wide connected downstream with a 3 9 m long floodable area fig 12 shows a sketch of the test conditions the gate was arranged orthogonally to the bottom in the experimental set up however it is assumed vertical in the numerical modeling according to the basic hypothesis of measuring water depths in the vertical direction quiescent water initially stored in the reservoir has a depth h 0 0 22 m at the gate fig 12 the marked 2d character of the spreading shallow flow resulting from the sudden opening of the gate is the peculiar feature of this test compared to those presented in the previous sections the computational domain was discretized by means of a cartesian uniform mesh with size δx 0 01 m δy 0 01 m and manning s roughness coefficient n was set to 0 01 m 1 3s the numerical simulation was stopped when the dam break wave reached the downstream end of the plane fig 13 compares the numerical results obtained from the new ssswe and the conventional swe in terms of water surface profiles along the centerline longitudinal axis and of contour line maps of water surface elevation and velocity magnitude at t 0 7 s fig 13a and t 1 5 s fig 13b the ssswe predict slower propagation of the nose of the wave front in accordance with the results of 1d dam break flows on large bottom slopes presented in section 4 1 and wider lateral spreading differences in flooding width increase over time fig 14a compares the hydrographs of inflow discharge in the floodable plain computed by the ssswe and swe models similarly fig 14b compares the numerical time series of vertical flow depth at a control point located on the plane centerline 2 70 m from the upper end this control point corresponds to gage point no 11 reported by laigle 1997 fig 2 p 129 the differences in the numerical hydrographs shown in fig 14 are very slight because the bottom slope of this test s 0 0 2 is only slightly higher than the limit slope under which the conventional swe are strictly valid s 0 0 1 according to chow 1959 p 33 differences become more significant if the plane slope increases to 0 5 maintaining the same initial water depth at the gate section h 0 0 22 m the water volume stored in the reservoir reduces to 40 5 of that of the previous case fig 15 shows the numerical water surfaces and the velocity magnitude contours at t 0 6 s fig 15a and t 1 1 s fig 15b calculated with the same computational grid δx δy 0 01 m dam break wave propagation is significantly faster in the swe simulation than in the ssswe one whereas predicted flooding widths are comparable fig 16 compares numerical discharge hydrographs at the end of the short channel fig 16a and vertical water depth time series at the selected gage point fig 16b the peak discharge predicted by the ssswe at the control section is slightly lower than that computed by the swe the opposite occurs for the peak value of the vertical water depth at the gage point 4 4 dam break flow in a parabolic sloping channel dam break flow in a prismatic sloping channel of parabolic cross section is considered in this subsection the channel bed is a parabolic cylindrical surface described by the equation 15 z b x y s 0 l x 0 03 y 20 2 for 0 x 200 m 0 y 40 m where zb is the bottom elevation x and y are the longitudinal and transverse horizontal coordinates respectively s 0 tanθx 0 577 θx 30 is the longitudinal slope of the channel l 200 m is the length of its horizontal projection accordingly axis y 20 m is the projection of the thalweg on the horizontal xy plane the thalweg elevation is equal to 115 47 m at the upstream vertical section x 0 and is equal to zero at the downstream end x l the top width of each vertical cross section 12 m above the thalweg is 40 m the transverse bottom slope ranges from 0 at the channel centerline to 1 2 θy 50 at the top of the channel sides the channel is partitioned by a vertical dam located at x 20 m which retains a still water volume of approximately 1687 m3 when the water depth at the dam is equal to 10 m the channel is dry downstream of the dam this numerical test is challenging because both longitudinal and transverse bottom slopes are different from zero attaining relatively high values typical of sloping natural streams and transverse bottom slope is variable in the channel cross section therefore despite the prismatic shape of the channel 2d features are expected to characterize the dam break flow generated by the sudden and total collapse of the dam in the numerical simulations the manning coefficient was set to 0 04 m 1 3s which is a feasible value in natural streams chow 1959 the numerical solution was calculated on a 0 1 m 0 1 m cartesian mesh fig 17 compares water surface elevation and velocity magnitude contour lines computed by the ssswe and swe models at two selected times t 2 s and t 5 s it shows that the dam break wave stretches and spreads rapidly converging towards the channel centerline in the first phase of the motion fig 17a and then spreading laterally fig 17b the wave predicted by the ssswe is slower than that predicted by the swe ni et al 2019 and shows wider lateral spreading on the channel sides consistently the celerity of the wetting front along the channel centerline is higher in the swe simulation than in the ssswe one as also highlighted by the numerical longitudinal water surface profiles plotted in fig 18 this figure also shows transverse water surface profiles at selected vertical cross sections for t 2 s and t 5 s the curved shape of the numerical transverse water surface profiles confirms the 2d character of the flow and that the transverse component of flow velocity is non zero due to the sloping sides of the channel fig 19 compares the flow discharge hydrographs predicted by the two shallow water models at the dam section x 20 m and at two cross sections located 10 m and 80 m downstream x 30 m and x 100 m at the dam section the ssswe discharge hydrograph is flatter than the swe one and the peak discharge is approximately 20 lower fig 19a the difference in peak discharge reduces significantly at the section located 10 m downstream of the dam x 30 m where the peak discharge computed by the ssswe is only 1 5 lower than that predicted by the swe fig 19b in this cross section the wave arrival time is slightly higher and the rising limb of the hydrograph is gentler in the ssswe model than in the swe one the difference in the wave front arrival times is more pronounced at x 100 m where the peak discharge predicted by the swe is again higher fig 19b it is worth noting that at the dam location x 20 m the ssswe discharge hydrograph attains the peak value approximately 1 s after the dam collapse and at x 30 m the ssswe predict a peak discharge slightly higher than at the dam location however at the initial stages of the dam break flow water depths are not shallow near the dam at the dam location the ratio of the water depth to the top width at the free surface is approximately equal to 0 27 in the initial condition in addition the assumption of flow velocities parallel to the bottom is not strictly valid the same occurs in a large portion of the channel stretch upstream of the dam during the reservoir emptying 5 application to a real field dam break test case in this section the ssswe and swe models are applied to the real field test case of the hypothetical cancano dam break described in pilotti et al 2014 and pilotti et al 2020 this test is particularly suitable to verify the performance of the new ssswe because the valley stretch immediately downstream of the dam is very narrow and steep with bottom slopes along the thalweg greater than 20 the predictions of the two numerical models are compared with each other and with the experimental data of a historical physical model investigation de marchi 1945 the cancano i dam was a concrete arched gravity dam built in 1924 1929 on the upper reach of the adda river valtellina northern italy the dam was 57 5 m high with reference to the downstream thalweg and approximately 265 m long at the crest the maximum reservoir capacity was about 24 106 m3 anidel 1953 the cancano i dam is now submerged by the water volume impounded by the new cancano ii dam which was built downstream in 1953 to increase the reservoir capacity the cancano i dam was considered a war target during world war ii the dam failure could cause flooding of urban areas the most important being the town of bormio which counted approximately 2500 inhabitants at that time prof de marchi was then commissioned to study the catastrophic flood resulting from the potential breaching of this dam he simulated the dam break flood in the approximately 15 km long valley stretch from the dam up to the village of cepina in a 1 500 scale physical model fig 20a assuming a hypothetical partial dam break scenario and the total collapse scenario only the latter is considered herein de marchi measured flood extents in the lower portion of the physical model and the discharge hydrographs at the three cross sections indicated in fig 20a 1 just downstream of the dam 2 at section 23 located approximately 8 km downstream of the dam 3 at the town of cepina unfortunately detailed information on the topography reproduced in the physical model is missing therefore pilotti et al 2020 reconstructed the altimetry of the valley using a recent digital terrain model dtm with a 5 m resolution having verified that substantial morphological changes have not occurred in the meantime in the present study numerical simulations are performed on a 20 m cartesian grid extracted from this dtm pilotti et al 2020 and pilotti et al 2014 did not include the reservoir in the computational domain and used the discharge time series measured at the dam as an inflow boundary condition instead in this paper the reservoir is included in order to model its emptying and utilize the experimental discharge hydrograph at the dam section for comparison and model validation however the reconstruction of the geometric shape of the reservoir reproduced in the physical model is affected by several uncertainties due to the limited information available in his paper de marchi claimed that the physical model reproduced the bottom of the reservoir except for the upstream end of which the volume only was reproduced not the exact configuration translated from de marchi 1945 based on the plan sketch of the physical model fig 20a a prismatic reservoir is assumed here with vertical walls and a horizontal rectangular basis approximately 1060 m long and 650 m wide accordingly to correctly reproduce the volume impounded at the maximum water level of 1857 m a s l the horizontal bottom of this schematic reservoir is placed at the fictitious elevation of 1821 m a s l although the resulting water depth behind the dam is lower than the actual one equal to approximately 55 m to accurately reproduce the actual topographic situation the rock mass protruding into the reservoir on the left hand side of the dam fig 20b is included in the numerical model by inserting non floodable computational cells even if this geometrical detail seems not to have been reproduced in the physical model given the particular plan shape of the reservoir the total collapse of the dam substantially determines a partial dam break scenario because the width of the reservoir behind the dam is greater than the dam length fig 20b following pilotti et al 2020 and pilotti et al 2014 the numerical simulations were carried out in real scale thus neglecting scale effects that most likely influenced the experimental data due to the small geometric scale ratio of the physical model henderson 1966 p 491 the manning roughness coefficient was set to 0 050 m 1 3s in the steep and rugged upper portion of the valley from the dam to section 23 and 0 041 m 1 3s in the downstream stretch from section 23 to the outlet according to the range of values considered by pilotti et al 2014 2020 in their sensitivity analysis on the roughness effect dam failure was assumed to be instantaneous on an initially dry bottom and the transmissive boundary condition was imposed at the downstream outlet located approximately 1 5 km downstream of the cepina section fig 21 shows the computational domain with indicated the zones where the terrain inclination angle is higher than 30 cos30 0 866 cos230 0 75 large areas are characterized by high bottom slopes especially in the upper reach of the valley where the maximum value of the terrain inclination angle is approximately 70 limited to the portion of the valley that can reasonably be reached by flooding fig 21 also compares the flood extents predicted by the ssswe and swe models with the observed one the two numerical flood inundation maps are very similar showing slight local differences mainly concerning slightly larger flooded areas predicted by the swe model in some zones on the whole measured and computed flooded areas are in good agreement with the observed ones the most significant discrepancies occur in the downstream stretch of the valley namely in the floodplain of bormio on the left hand side of the adda river just downstream of the town of bormio there is a large area where the flooding observed in the physical model is not reproduced by the two numerical models conversely on the opposite side of the river predicted flooded areas are wider than the measured ones in several zones accuracy in flood extent prediction is assessed through the following metrics commonly used in flood model performance analysis fit rate h horritt and bates 2002 cook and merwade 2009 missing flooding ratio m kim and sanders 2016 false alarm ratio f and error bias b sampson et al 2015 defined as 16a h a sim a obs a sim a obs 16b m a obs a sim a obs 16c f a sim a obs a sim 16d b a sim a obs a obs a sim where a sim and a obs denote the simulated and observed inundated areas respectively h is a hit rate 0 h 1 which assesses the agreement between the observed and predicted inundated areas m is an index ranging from 0 to 1 that quantifies model underpredition i e inundated areas that are not predicted by the model f 0 f 1 quantifies model overprediction i e areas where the model predicts flooding that actually does not occur and b measures the model s tendency to underpredict 0 b 1 or overpredict b 1 flooded areas table 7 reports the values of these performance metrics for the two numerical models in the cancano dam break test case the values of hit rate h confirm the good global performance of both numerical models which are substantially equivalent in reproducing the inundation extent moreover the results concerning indexes m and f indicate a moderate tendency of the numerical models to both underprediction and overprediction the underestimation of the flooded areas is higher for the ssswe model than for the conventional swe one while it is the opposite for overprediction finally the calculated values of index b 1 indicate a global tendency of both models to underpredict flooded areas more pronounced for the ssswe one fig 22 shows the spatial distribution of the differences between the maximum vertical water depths computed with the ssswe and the swe i e δh max h max ssswe h max swe the ssswe predict globally lower maximum water depths than the swe indeed negative values of δh max occur in approximately 85 of the computed flooded area and the median value of δh max is 0 4 m in particular the ssswe predict lower maximum water depths with differences lower than 3 m in several zones of the floodplain of bormio near the boundaries of the inundation area and in a large area downstream of cepina zones with the absolute difference δh max lower than 0 5 m are not filled in fig 22 and occupy most of the computed flooded area in the floodplain of bormio their extent is approximately 46 of the total extent of the predicted flooded areas the 75th percentile of δh max is equal to 1 3 m the highest values of δh max occur in the upper portion of the valley where the valley is very narrow and irregular fig 23 compares numerical and experimental discharge hydrographs at the three measuring cross sections the top and right axes indicate time and flow discharge in the physical model scale according to the froude similitude table 8 compares numerical and experimental peak discharges at the measuring cross sections in the experimental investigation by de marchi 1945 discharge measurements were performed using a calibrated tank that collected the water falling through bottom slots opened in turn at the selected measuring sections to reproduce more accurately these experimental measuring conditions additional simulations on a reduced computational domain were performed including only the upper portion of the valley up to section 23 where a transmissive boundary condition was imposed no significant differences were observed in the numerical discharge hydrographs at section 23 therefore the results of the simulations performed on the complete computational domain are used here for comparison and are shown in fig 23 the numerical models reproduce fairly well the experimental discharge hydrograph at the section just downstream of the dam site despite the strong uncertainties in the numerical description of the reservoir geometry however both numerical models underestimate the peak value in this section with a higher underestimation by the ssswe one about 11 moreover both models predict the peak discharge shortly approximately 1 min after the instantaneous collapse of the dam which is perfectly compatible with an essentially partial dam break as regards the comparison between numerical and experimental discharge hydrographs at section 23 the swe overestimate the peak value by 12 6 and the ssswe by 3 3 table 8 the dam break wave front predicted by the ssswe reaches section 23 shortly before that calculated by the swe but in perfect timing with the arrival of the experimental wave which occurs about 7 min after the dam collapse the swe overestimate the wave front arrival time at this cross section by approximately 1 min both numerical models predict a concentration limb steeper than the experimental one the comparison between numerical and experimental hydrographs at cepina leads to similar remarks however in this last section the flooding arrival times predicted by both numerical models are slightly overestimated the swe overestimate the experimental peak discharge by 18 6 whereas the ssswe by only 6 9 table 8 6 conclusions free surface flows on very steep and irregular terrains such as mountain areas could not be modeled in theory with the conventional 2d depth averaged swe because the basic hypothesis of small bottom slopes is not strictly valid in this context a new formulation of the 2d ssswe has been proposed in the companion paper to overcome this limitation defining the water depth along the vertical direction and assuming the flow velocity locally parallel to the bottom surface the vertical pressure distribution is assumed linear albeit non hydrostatic in this paper the new equations are numerically solved with an explicit muscl type second order accurate finite volume scheme which uses the force method to estimate the numerical fluxes when bottom slopes are large the bottom surface cannot be approximated with its horizontal projection accordingly a piecewise linear discretization of the bottom surface is applied based on a quadrilateral non uniform computational grid constructed on the terrain which maps in a uniform cartesian grid on the horizontal plane control volumes with vertical boundaries prevent distortions or possible intersections as well as the problem of handling cell boundaries with variable inclinations on non flat terrains the piecewise linear discretization of the bottom surface induces discontinuities in the bottom slope at cell boundaries unless the bottom surface is planar consequently the finite volume scheme would be intrinsically non conservative due to the presence of the bottom inclination angles in the definition of the physical fluxes numerical adjustments are presented to restore the conservative property of the scheme even on irregular terrains model s accuracy in simulating dam break flows over a sloping bottom is analyzed through split 1d and fully 2d test cases the results of the new ssswe and the conventional swe are compared in all tests to assess the differences the validation against experimental data of 1d dam break flow in a rectangular sloping channel demonstrates that the ssswe are more accurate than the swe in reproducing the wave propagation and the flow discharge at fixed cross sections the two numerical models are practically equivalent when bottom slopes are small the 1d test case concerning the run up of a dam break flow on an adverse slope shows that the ssswe predict a lower run up than the swe in this case the comparison with the numerical results of a 2d inviscid model in the vertical plane indicates that the ssswe model can be inaccurate where the hypothesis of flow velocity parallel to the bottom fails the numerical tests of partial dam break flow on a sloping plane and dam break flow in a parabolic channel demonstrate the model s capability in 2d frameworks in the presence of steep bottom slopes in the parabolic channel test steep bottom slopes occur in both longitudinal and transverse directions the numerical results show that the ssswe predict slower and less severe flood waves than the conventional swe this effect decreases progressively as the bottom slopes decrease the cancano test case shows the capability of the ssswe to cope with the propagation of a dam break flood wave on real topography namely in mountain valleys with high slopes in this test case the two shallow water models are substantially equivalent in predicting flooded areas and satisfactorily reproduce the experimental ones the analysis of the discharge hydrographs at two selected cross sections located in the valley downstream of the dam shows that both numerical models tend to overestimate the peak discharge and the wave arrival time however the percentage error in peak discharge prediction is lower for the ssswe model than for the swe one on the whole the results show that the ssswe are more accurate in describing dam break flows over steep topographies than the conventional swe and predict less severe flooding with slower wave propagation both shallow water models return discharge hydrographs with steeper concentration limbs than the experimental ones ultimately the new 2d ssswe can be used with confidence to predict the main flow features of unsteady shallow free surface flows on sloping terrain provided that the assumption that flow velocity is parallel to the bottom surface is globally acceptable compared with the conventional 2d swe the new equations do not require computationally much more expensive numerical methods the ssswe prove to be on the whole more accurate than the conventional swe in dam break flood modeling on steep terrain slopes when the basic hypotheses are valid in addition they can be adopted in a wider range of applications in any case the swe provide conservative predictions which can be safely used in flood hazard assessment author statement all persons who meet authorship criteria are listed as authors and all authors certify that they have participated sufficiently in the work to take public responsibility for the content including participation in the concept design analysis writing or revision of the manuscript furthermore each author certifies that this material or similar material has not been and will not be submitted to or published in any other publication before its appearance in advances in water resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements prof marco pilotti university of brescia italy is kindly acknowledged for suggesting the research topic of this paper and for his valuable advice and support appendix a details on the numerical model numerical fluxes are computed according to the classic muscl hancock approach through the slic slope limiter centered scheme toro 2001 p 211 based on the following three steps a variable extrapolation boundary extrapolated variables u l and u r are estimated at the two sides of the boundaries of each computational cell fig 1b through a piecewise linear extrapolation toro 2001 p 206 which in the x direction reads a1 q i 1 2 j l q i 1 2 j l q i j n 1 2 ψ i 1 2 j q i j n q i 1 j n q i 1 2 j r q i 1 2 j r q i 1 j n 1 2 ψ i 3 2 j q i 2 j n q i 1 j n where q denotes a conserved variable of the vector u and ψ is a slope limiter function which avoids non physical oscillations at steep gradients of the solution ψ depends on the solution gradients as a2 ψ i 1 2 j ψ r i 1 2 j ψ i 3 2 j ψ r i 3 2 j where r is a ratio of consecutive variations of the conserved variables hirsch 1990 p 537 defined as a3 r i 1 2 j q i 1 j n q i j n q i j n q i 1 j n r i 3 2 j q i 1 j n q i j n q i 2 j n q i 1 j n the van leer limiter function hirsch 1990 p 542 a4 ψ r r r 1 r is adopted in this paper intercell water depths are reconstructed using the weighted surface gradient method wsdgm proposed by aureli et al 2008a p 965 given the excellent performance of this technique in the presence of non flat topography and wetting drying fronts b evolution in time of extrapolated variables the boundary extrapolated variables u l and u r are evolved in time over a half computational time step toro 2001 p 207 through a conservative formula like eq 8b to compute updated boundary extrapolated variables u l and u r aureli et al 2008a eq 16 p 964 a5 u i 1 2 j l u i 1 2 j l δ t 2 δ x f u i 1 2 j l f u i 1 2 j r δ t 2 δ y g u i j 1 2 l g u i j 1 2 r δ t 2 s 0 i j u i 1 2 j r u i 1 2 j r δ t 2 δ x f u i 1 2 j l f u i 1 2 j r δ t 2 δ y g u i j 1 2 l g u i j 1 2 r δ t 2 s 0 i j updated velocity components u and v are also estimated at the left and right hand sides of the cell interfaces through eq 3 in this calculation the bottom inclination angles are set to the values of the computational cell on which the intercell side is facing i e cell i j for the left hand side of intercell i 1 2 j cell i 1 j for the right hand side of intercell i 1 2 j and so on c evaluation of numerical fluxes the intercell numerical fluxes along the ξ and η directions are calculated through the force first order centered scheme toro 2001 p 164 as a6a f i 1 2 j 1 2 f i 1 2 j l f u i 1 2 j l u i 1 2 j r f i 1 2 j r i u i 1 2 j l u i 1 2 j r a6b g i j 1 2 1 2 g i j 1 2 l f u i j 1 2 l u i j 1 2 r g i j 1 2 r i u i j 1 2 l u i j 1 2 r where superscripts and refer again to the forward and backward split interfaces and labels lf and ri refer to the lax friedrichs and richtmyer fluxes respectively lf fluxes are computed according to the 2d lax friedrichs centered scheme hirsch 1990 p 230 a7a f i 1 2 j l f u i 1 2 j l u i 1 2 j r 1 2 f u i 1 2 j l f u i 1 2 j r 1 4 δ x δ t u i 1 2 j l u i 1 2 j r a7b g i j 1 2 l f u i j 1 2 l u i j 1 2 r 1 2 g u i j 1 2 l g u i j 1 2 r 1 4 δ y δ t u i j 1 2 l u i j 1 2 r while ri fluxes are computed according to the two step lax wendroff scheme toro 2001 p 164 a8a f i 1 2 j r i u i 1 2 j l u i 1 2 j r f u i 1 2 j r i with u i 1 2 j r i 1 2 u i 1 2 j l u i 1 2 j r 1 2 δ t δ x f u i 1 2 j r f u i 1 2 j l a8b g i j 1 2 r i u i j 1 2 l u i 1 2 j r f u i j 1 2 r i with u i j 1 2 r i 1 2 u i j 1 2 l u i j 1 2 r 1 2 δ t δ y g u i j 1 2 r g u i j 1 2 l a cell centered estimate of the pressure correction factor defined in eq 4 is used in eqs a7a a7b a8a and a8b according to the rule of selecting the computational cell to which the split intercell belongs average values of bottom inclination functions cosθx and cosθy calculated as a9 cos θ x i 1 2 j cos θ x i j cos θ x i 1 j 2 cos θ y i j 1 2 cos θ y i j cos θ y i j 1 2 are used at i 1 2 j and i j 1 2 interfaces in assessing mass fluxes to ensure that the numerical scheme is conservative with respect to the mass at each cell interface both forward and backward intercell u r i and v r i velocities are set equal to the arithmetic mean of the updated left and right hand side boundary extrapolated values to prevent the richtmyer component of the force flux from producing mass unbalance when the bottom surface is uneven the iterative flux correction procedure described in aureli et al 2008a p 965 is applied to avoid the numerical instabilities typically induced by small water depths at wetting and drying fronts especially over irregular topography and to reduce the mass error since pressure correction coefficient k is discontinuous for v 0 eq 4 the numerical scheme must be well balanced i e it must preserve exactly a stationary condition this property is obtained by including the bottom slope term in the time evolution of the boundary extrapolated variables step b eq a5 and calculating it according to the centered approximation aureli et al 2008a eq 17 p 964 a10 s 0 i j 0 g h i 1 2 j l h i 1 2 j r 2 z b i 1 2 j z b i 1 2 j δ x g h i j 1 2 l h i j 1 2 r 2 z b i j 1 2 z b i j 1 2 δ y where zb is the bottom elevation the present numerical scheme as any other explicit one is potentially stable under the courant friedrichs lewy stability condition for 2d unsplit schemes this condition identifies a reduced stability range toro 2001 p 240 and can be expressed as aureli et al 2008b maranzoni et al 2015 a11 δ t c r 2 min δ x max i j λ 3 f i j δ y max i j λ 3 g i j where λ 3 f and λ 3 g are the maximum absolute celerities provided by eqs c4 and c5 in maranzoni and tomirotti 2022 and cr is the courant number 0 cr 1 appendix b grid convergence analysis grid convergence analysis is usually performed in cfd computational fluid dynamics calculations to assess the grid discretization error stern et al 2001 three grid sizes are considered here to this end δx 1 2 10 3 m δx 2 3 33 10 3 m and δx 3 1 10 2 m with refinement factors r 21 δx 2 δx 1 1 667 and r 32 δx 3 δx 2 3 both greater than 1 3 according to the refinement criterion by celik et al 2008 p 1 this choice for the grid sizes allows comparison of numerical predictions at common cell center locations without requiring interpolations which can result in the introduction of interpolation errors fig b1 compares numerical profiles of flow depth and velocity calculated with the ssswe at selected times for the three grid sizes considered it shows that numerical results have practically reached convergence with respect to the grid size parameter fig b2 shows the profiles of the absolute differences between the numerical solutions in terms of flow depth and velocity calculated at the cell centers of the coarser mesh for two selected times denoting θ a hydraulic variable of interest e g h or u ε θ 32 θ3 θ2 is the absolute difference between the solution θ3 of the coarser grid and the solution θ2 of the medium one and ε θ 21 θ2 θ1 is the absolute difference between the solution of the medium grid and the solution θ1 of the finer one deviations ε θ 21 are on average smaller than ε θ 32 except at the wave fronts deviations are very close to zero indicating that numerical convergence has practically been attained with the finer grid δx 1 2 10 3 m mean absolute deviations b1 ε θ 32 1 n k 1 n θ 3 θ 2 k ε θ 21 1 n k 1 n θ 2 θ 1 k and ε θ 31 1 n k 1 n θ 3 θ 1 k are calculated for flow depth table b1 and velocity table b2 profiles at the times considered in fig b1 in eq b1 n is the number of non zero deviations in the numerical profiles an average global apparent order of accuracy can be calculated for each profile as b2 p ln ε θ 31 ε θ 21 ln r 32 using the numerical results of the finer grid as a reference solution an estimate of the exact solution can then be obtained through the richardson extrapolation celik et al 2008 eq 4 b3 θ 0 r 21 p θ 1 θ 2 r 21 p 1 and a global numerical uncertainty associated with the finer grid solution can be estimated as b4 ε θ 10 1 n k 1 n θ 1 θ 0 k or in relative terms with reference to the average value θ 0 of the estimated exact θ profile as ε θ 10 θ 0 note that the usual procedures for estimating the discretization error such as the grid convergence method gci do not work if either ε θ 32 and ε θ 21 are very close to zero celik et al 2008 p 2 tables b1 and b2 provide an example of the calculation of discretization errors for flow depth and velocity profiles respectively maximum global relative uncertainties in the numerical solutions obtained with the finer grid δx 1 2 10 3 m are in the order of 1 for both flow depth and velocity profiles appendix c wave tip region the tip region of the dam break wave is dominated by friction and characterized by significant variations in flow depth and velocity chanson 2009 the profile of a dam break wave propagating on a steep slope is substantially unchanging in this region once the wave has become very thin hence it can be considered the wave profile of a uniformly progressive flow chow 1959 p 535 in the ssswe framework starting from the equations of the 1d x split problem maranzoni and tomirotti 2022 eq 21 c1 h t u h cos θ x x 0 u h t x u 2 h 1 2 k g h 2 cos θ x g h sin θ x n 2 u 2 h 4 3 1 ta n 2 θ x the following dynamic equation can be obtained for uniformly progressive flow in a sloping wide rectangular channel of fixed slope θx c2 h x tan θ x cos 2 θ x 1 h n h 4 3 where hn is the normal depth at the upper limit of the wave tip region where the flow is practically uniform expressed via the manning formula solving for dx and integrating assuming x 0 at the wave front where h 0 the analytical flow profile in the tip region is c3 x tan θ x cos 2 θ x h 3 2 h n arctan h h n 1 3 3 2 h n arctanh h h n 1 3 similarly using the swe this analytical profile becomes c4 x tan θ x h 3 2 h n arctan h h n 1 3 3 2 h n arctanh h h n 1 3 fig c1 compares the numerical and analytical wave profiles in the tip region at a selected time t 1 207 s for lauber and hager s case study with s 0 0 5 the value of hn was determined from the numerical profiles as the average flow depth at the wavefront crest where the profile appears unchanging fig c1 shows the capability of the numerical model to correctly reproduce the analytical solution of the wave profile near the wetting front for a dam break wave moving on a prismatic channel with a steep bottom at the instant considered the ssswe wavefront is behind the swe one and the normal depth hn of the ssswe profile is slightly higher 2 65 10 2 m against 2 38 10 2 m for the swe profile appendix d formation of roll waves the capability to describe the formation of roll waves in a dam break wave propagating on an inclined channel is desirable for a shallow water model zanuttigh and lamberti 2002 bohorquez and fernandez feria 2008 bohorquez 2011 this property is verified in this appendix for the ssswe and swe models presented in this paper the geometry of the steeper channel of lauber and hager s experiments s 0 0 5 θx 26 56 was considered to this end however the initial water depth at the dam h 0 was reduced to 0 075 m to ensure that the channel was long enough to allow the development of roll waves fig d1 shows that the ssswe and swe models can reproduce the formation of roll waves near the wave front at sufficiently large times when the froude number fr u ghcos2 θx 1 2 is much greater than 2 bohorquez and fernandez feria 2006 indeed approximately 1 s after the dam removal instabilities appear near the front where fr reaches values close to 10 according to bohorquez and fernandez feria 2006 p 511 such instabilities develop from just the numerical round off noise at high froude numbers the train of travelling roll waves becomes evident at t 2 s when the ssswe model predicts a maximum crest height higher than the swe one the swe simulate a faster advance of the dam break wave even in the presence of roll waves 
