index,text
25560,sediment connectivity is the capability of a system to regulate the exchange of sediment in catchments the index of connectivity ic has become a widely used tool offering a practical way to assess sediment connectivity from hillslopes to downstream channels we present a novel implementation of ic in r environment to expand the audience of users and encourage alternative applications of the index the r ic is an open source and freely available tool composed by three codes standard r ic runs the ic and it represents the core of the other variants custom r ic offers a more flexible script allowing the computation of alternative weighting factors and the possibility of running a further profile ic analysis batch r ic performs batch processing of the index for each code variant a geomorphological application is presented to illustrate how the r ic could be used in watershed management and practical issues related to sediment dynamics keywords sediment connectivity geomorphometry r ic open source software availability r ic was developed jointly by the three authors baggio tommaso martini lorenzo and torresani loris and is available at https github com tommbagg r ic releases tag r ic v1 0 baggio et al 2022 at no cost it is distributed under the gnu general public license v4 0 the r ic code is written in r language and it requires the packages raster hijmans 2020 shapefiles stabler 2013 rgdal bivand et al 2021 and ggplot2 wickham 2016 together with the executable files of taudem version 5 3 7 https hydrology usu edu taudem taudem5 the size of the code is 63 kb while the example scripts together with inputs and outputs is 10 mb r ic is tested on a windows computer equipped with intel r core tm i7 8700 cpu 3 20 ghz with 16 gb of memory ram using r version 4 0 3 to process a large raster 4 85 gb we used a windows server virtual machine equipped with intel r xeon r e5 2695 2 30 ghz with 100 gb of memory ram and r version 4 1 1 contact information department of land environment agriculture and forestry university of padova viale dell università 16 legnaro 35020 pd italy email tommaso baggio unipd it 1 introduction in the field of geomorphology assessment of sediment availability and transfer dynamics is important to understand landscape evolution and the consequences of human impacts on geomorphic systems seminal works by brunsden and thornes 1979 caine and swanson 1989 and harvey 2001 first placed attention towards the role of geomorphic coupling in the sediment delivery and sediment yield assessment issues more recently the interest in the regulation of sediment transfer between geomorphic system compartments has increased remarkably the dis connectivity between such compartments e g hillslopes channels floodplains wetlands plays a fundamental role in influencing the efficiency of sediment transfer in drainage basins merritt et al 2003 brierley et al 2006 fryirs et al 2007a 2007b bracken et al 2015 in the sediment cascade framework sediment connectivity is intended as an intrinsic property of any basin wohl 2017 and it defines the degree to which the basin area and stream network system promote the exchange of sediment based on its spatial configuration i e structural connectivity and its processes i e functional connectivity wainwright et al 2011 heckmann et al 2018 turnbull et al 2018 as result in mountain catchments sediment connectivity underlies the potential sediment transfer between an area of sediment production i e sediment source and downstream sink areas hooke 2003 together with the development of several frameworks and definitions the assessment of sediment connectivity has become a major concern for geomorphologists being able to represent and quantify the linkages responsible for sediment transfer will increase awareness of the trajectories of geomorphic systems in stationary conditions and after natural and anthropic disturbances as consequence this will prevent potential negative impacts on environmental and or socio economical assets poeppl et al 2017 fuchs et al 2019 such as loss of fish biodiversity due to reduction of longitudinal connectivity by dam constructions poeppl et al 2017 or the alluvial flooding of entire villages triggered by volcanic eruptions pierson et al 2013 after a disturbance the degree of connectivity can help predict the sensitivity of the catchment as it facilitates the propagation of the disturbance cienciala 2021 therefore sediment connectivity is becoming a useful concept for decision making assessments in river and catchment management wohl et al 2019 a semi quantitative measure of sediment connectivity is provided by the geomorphometric index of connectivity hereinafter ic which determines the potential routing of sediment from hillslope to the stream system borselli et al 2008 ic relies on topographical indices of a catchment as major source of input and it offers a straightforward way to describe the existing structural relationships among sediment sources and downstream sink areas from the original formulation by borselli et al 2008 different variants have been proposed to enhance it and to spread its usage over different environments e g geological climate and vegetation settings among those the most prominent was introduced by cavalli et al 2013 and has become a reference point for investigating sediment sources in mountain catchments cavalli et al 2017 cucchiaro et al 2019 zanandrea et al 2020 martini et al 2022 moreover in the analysis of catchment s sensitivity to large and infrequent disturbances ic can be adapted successfully by modifying the parameter representing the impedance to sediment fluxes the so called weighting factor in this sense many authors assessed sediment connectivity after different events wildfires fernández et al 2020 lópez vicente et al 2020 martini et al 2020 volcanic eruption ortíz rodríguez et al 2017 martini et al 2019 windstorms and forest disturbances jautzy et al 2021 pellegrini et al 2021 rainato et al 2021 and land use changes lizaga et al 2017 with the increasing number of applications the availability of tools for deriving ic and its variants has become pivotal in this sense easy to use flexible and parsimonious tools can efficiently support a large number of works carried out by both researchers and land management authorities tangi et al 2019 the reproducibility of the analyses is indeed a fundamental issue if we seek to introduce the sediment connectivity based tools into decision making processes and catchment management strategies however it is fundamental to highlight here that the ic given its simplified nature is mainly intended as a lateral i e hillslope to channel connectivity index and its application along the channels where more complex processes as bedload transport operate should be carefully addressed taking into account all the intrinsic limitations of the approach heckmann and schwanghart 2013 on the same line in this work we present a novel open source code to compute ic in r environment named r ic starting from the already available implementations we developed r ic to provide an additional and alternative solution to carry out sediment connectivity analysis based on the geomorphometric approach proposed by cavalli et al 2013 the r ic is intended as an easy open source tool with high flexibility and reproducibility thanks to three variants of the code specifically designed for enhancing the use of ic under different needs the ultimate goal of such implementation is to make ic even more accessible promoting the integration of deeper analysis directly in r and offering a new environment to prepare input data and or further process and analyse the outputs accordingly in this work we present potential useful applications related to real case studies 2 background and implementation 2 1 index of connectivity the basic formulation of the index of connectivity represented in fig 1 is the following 1 i c log 10 d u p d d n where the base 10 logarithm is calculated over the ratio between an upslope factor dup and a downslope factor ddn the ic value expressed in logarithmic scale is dimensionless the dup eq 2 expresses the main topographic features of the area potentially prodividing the sediment 2 d u p w s a where w is the average weighting factor indicating the average impedance to sediment fluxes of the upslope drainage area s is the average slope m m of the upslope drainage area and a is the contributing area draining to the raster cell under investigation within the computational domain the ddn eq 3 instead expresses the characteristics of the sediment pathway from the raster cell under investigation to a specific target e g channel network outlet sink 3 d d n d i w i s i where di is the length m of each ith cell along the flow path wi is the weighting factor and si the slope referred to the ith cell the logarithmic ratio between dup and ddn forming the ic can range from infinite representing low connection with the target area to infinite high connection in the present work the refined version of ic made by cavalli et al 2013 is used over the previous formulation made by borselli et al 2008 hence three major adaptations are considered the slope gradient is calculated according to the steepest downslope direction and trimmed by a lower and upper value ii the contributing area is computed employing the d infinity approach tarboton 1997 and iii to calculate the w factor the roughness index ri is adopted following the formulation of cavalli and marchi 2008 equal to the standard deviation of the residual topography difference between the original dem and the smoothed one within a moving window these refinements have been implemented to enhance the use of the ic in steep alpine areas in the case of high resolution dtms available commonly defined as cell size lower than 5 m 2 2 available implementations of ic ic implementations have always been characterized by particular attention devoted to the applicability of the proposed approach from the first proposal by borselli et al 2008 the authors provided arcmap code listing within the appendix of the manuscript the work carried out by the hydrogeomorphology research group hrg of cnr irpi during the years led to the availability of an arcgis toolbox cavalli et al 2014 and an open source stand alone application named sedinconnect crema and cavalli 2018 developed to facilitate ic computation moreover sedinconnect provides a framework not bound by the use of commercial software or any gis or scripting environment at all and drastically simplified input parameters computation needed by the arcgis toolbox furthermore both the arcgis toolbox and sedinconnect have the embedded option of computing surface roughness from an input dtm to be used as impedance to sediment fluxes proxy in ic computation finally worthy of note is the recent availability of python scripts crema et al 2021 for computing ic and surface roughness within a wider python framework or for custom or batch processing 2 3 r ic the algorithms developed in this study aim to improve the computation and the analysis of ic the main advantages of r ic are i the flexibility of the code in the pre and post processing phase ii the possibility to compute ic at a regional scale the computational limit is the computer performance and iii to batch process of different study areas the ic algorithm has been implemented in r r core team 2020 environment version used 4 0 3 through raster operations in particular the packages used are raster hijmans 2020 shapefiles stabler 2013 rgdal bivand et al 2021 and ggplot2 wickham 2016 for hydrologic analysis of the dtm similarly to the arcgis toolbox and sedinconnect implementations we used the functions implemented in taudem https hydrology usu edu taudem taudem5 the functions are directly recalled in the r script via the use of the terminal that run the executable scripts writing the output raster files in the working directory taudem algorithms take advantage of parallel processing by partitioning the computational domain into stripes using message passing interface mpi therefore the types of input formats for r ic are those acceptable in the listed r packages consequently the user has potentially no limit in raster size and can use alternatively different raster gis file formats instead the raster outputs of r ic are written in tiff format and located in the same folder of the input data the standard r ic fig 2 a code offers a simple and straightforward computation of the ic as refined by cavalli et al 2013 the procedure for running the code can be summarized in a flowchart showing the main steps concerning required inputs computational processes conditional blocks and outputs fig 2a three main inputs are needed to run the standard r ic first the main input is the dtm in raster format which needs to be hydrologically corrected in order to avoid local depressions acting as spurious sinks filling the sinks in the dtm is up to the user who chooses the method one considers most appropriate moreover the raster grid must be regular with uniform cell sizes expressed as length measure second a moving window size is required to define the number of neighbouring cells to compute the surface roughness following the formulation of cavalli and marchi 2008 third it is asked to provide polygon features shapefile format to be used as the user defined target of the ic the shapefile represents areas of interest to which the degree of linkage i e connectivity is calculated the target area is chosen by the user according to the objective of the study and it needs to be represented in the same coordinate system of the dtm and provided only by polygon features lines and points are not accepted computational processes regard in sequence the roughness index ri computation weighting factor w computation and the ic computation the ri is calculated according to the formula first proposed in cavalli and marchi 2008 and it requires the choice of a moving window size the ri is consequently computed as the standard deviation of the residual topography in a n x n cells moving window eq 4 4 r i i 1 n 2 x i x m 2 n 2 where n is the number of processing cells within a user defined moving window xi is a value of the dtm xm is the mean value of the cells in the n x n moving window the ri is used to compute the w eq 5 which is trimmed to the range 0 001 and 1 cavalli et al 2013 representing high and low impedance to the sediment fluxes respectively 5 w 1 r i r i m a x finally ic is calculated according to eq 1 and a user defined flag allows the saving of either all outputs main and intermediate outputs or just the main outputs index of connectivity roughness index upslope component downslope component a particular advantage of standard r ic is the potential unlimited size of the input raster file to be elaborated differently from the previous implementations of ic limited to the geotiff raster format the algorithms used in r ic have not constraints regarding the file format and dimensions the restrictions are only associated to available hardware and especially to the ram memory engaged to temporarily store matrix and raster data for computation purposes within the global environment of r based on the standard r ic two additional scripts were developed in order to achieve more flexibility than previos implementations of ic so that further applications can be carried out custom r ic differs for the use of a w map provided by the user and by the possibility flag to perform a further analysis of topographic parameters and ic along a user defined profile fig 2b the workflow starts with user defined inputs target dtm and w factor particularly in the custom r ic code the computation of ri is not already set as default hence no moving window needs to be defined on the contrary the user decides the w raster map that mostly represents the impedance to sediment fluxes the input w is a raster file that has to match the same characteristics of the dtm cell size extension coordinate system ic is computed as in the standard r ic but a further optional analysis is then implemented the profile analysis of ic is introduced following the approach presented on the relative open source code torresani and piton 2022 which unravels ic and its main components along a longitudinal profile if the profile ic analysis is chosen flag for activation the code requires as a further input a user defined point shapefile along which the analysis is going to be performed using the r ic outputs the optional input profile is requested at the beginning of the script leaving the possibility of not assigning any file in the case the analysis is not performed the outputs of the profile ic analysis are tables and graphical results charts and boxplots the longitudinal approach here proposed should be mainly applied in steep small medium size catchments where sediment concentration of the flow is important since debris flows or debris floods dominate it is important to underline that this alternative code does not limit to the mere decomposition of the ic components but it offers the opportunity to incorporate other kind of analysis e g dem of difference dod for comparisons and further investigations in the end the custom r ic code offers a flexible solution to compute ic at the catchment scale paving the way for deeper geostatistical analyses directly in r environment in the case the user wants to run the standard r ic reiteratively varying the input data the batch r ic is the best option the batch r ic fig 2c exploits the standard r ic as core function to compute ic according to multiple targets and multiple dtms retrieved in a single folder in the same way the user can vary the moving window size for each dtm the input s constraints are the same as those outlined for the standard r ic concerning the outputs in this code variant only the main ic outputs are kept in the working location additionally after the whole loop a summary table is derived csv format summarizing the main statistics min max median sd of the multiple ic computed for each dtm the batch processing can help the final user in the computation of ic for different study areas for instance to identify the most critical one in terms of sediment connectivity for a region of interest and as result enhancing the reproducibility of the geomorphometric approach in order to test the accuracy in computing ic the standard code r ic has been tested against sedinconnect 2 3 crema and cavalli 2018 providing a difference of ic in the order of 10 5 test performed on the val de le noghere catchment section 3 1 mean difference 1 9 10 5 standard deviation 3 5 10 3 regarding the maximum size of the input rasters we ran r ic in the isarco catchment section 3 2 using a 2 5 m dtm with a raster size equal to 4 85 gb the code is expected to work even with bigger rasters only limited by the available hardware differently from the sedinconnect 2 3 crema and cavalli 2018 for which the input dtm is limited by the characteristics of the geotiff raster file 3 examples of application 3 1 computing ic in a small catchment affected by multiple disturbances we decided to test the custom r ic in a small alpine catchment to investigate sediment dynamics and to carry out a deeper characterization of longitudinal connectivity according to the morphological characteristics of the main channel the study area is the val de le noghere or longhere a subcatchment of the liera stream located in the north eastern italian alps veneto region the val de le noghere subcatchment 1 20 km2 is characterized by steep slopes mean slope of 48 with elevation ranging from 1195 m a s l to 2502 m a s l the area was affected by multiple disturbances in 2016 a rock slope failure deposited a large amount of sediment in the upper part of the catchment and in october 2018 the area was hit by an exceptional storm named vaia which triggered widespread instabilities and a large debris flow in the main channel the response of the catchment to the vaia storm is under investigation by the interreg ita aut project sedinout boretto et al 2021 a lidar derived dtm and dsm at 1 m resolution obtained in 2019 were used for the sediment connectivity analysis which consisted in the computation of ic detection of spatial patterns and further analysis of ic along the main stream the computation of ic was carried out with the custom r ic using the outlet as target to compute w we adopted the vector ruggedness measure sappington et al 2007 applied to the 1 m dsm associated with a moving window of 49 m2 7 7 m the derived w integrates also the effect of above ground features such as shrubs sparse dense and disturbed forests brožová et al 2021 that may potentially interact in different ways with sediment fluxes on slopes notably in this example of application rather than investigating the optimum w factor the goal is to show the versatility and flexibility of the code by including an alternative roughness to the standard roughness index cavalli and marchi 2008 after the computation ic was automatically extracted along the longitudinal profile of the val de le noghere stream and the main variables analyzed through the approach proposed in torresani and piton 2022 which has been added to the custom r ic code straightforwardly the ic map shows the distribution of the values into four classes fig 3 the downstream part and the channel network are areas of high ic as represented by the hot colors branching out in the catchment medium high ic areas are very limited in extension and mainly visible close to the high ic areas on the contrary medium low ic and low ic areas are organized in patterns partially following the topographic characteristics of the catchment medium low ic values are concentrated along the western tributary showing steep slopes and an incised channel instead low ic characterizes the central part of the basin where it is possible to observe large deposits of sediment related to the 2016 rockfall hence an overall lower slope and consequently lower sediment connectivity depict this area acting as a buffer for the sediment the longitudinal profile 1397 m was divided into two distinct domains defined by the user in accordance with the channel bed width fig 3 the upstream a domain red showing narrow and incised channel width range 4 7 m the downstream b domain blue showing wider channel width range 8 13 m the former ranges from 1195 to 1525 m a s l while the latter from 1525 to 1863 m a s l fig 4 a as reported by whole fig 4 in fact the main variables and components of ic are unraveled along the profile and divided into the two domains the slope chart fig 4b shows that the channel can reach high steepness with peaks of 14 2 m m in domain a and 8 6 m m in domain b that are also visible as two steps in the longitudinal profile presented in fig 4a as expected the slope increases moving upstream concave pattern hence the domain a generally shows higher values fig 4bb the contributing area instead decreases going further to the outlet and the major jumps are associated to the junctions of major tributaries fig 4c for instance the first evident jump in domain b corresponds to the cut off of the western tributary showing medium low ic values in the sediment connectivity map fig 3 concerning the w factor variation first it is possible to observe greater variability along the domain a than domain b thanks to the strong sensitivity of the proposed roughness to the surface morphology and vegetation cover fig 4dd the roughness is much more subject to variations in the upper domain a characterized by a narrower channel with high steps and steep banks than in downstream domain b characterized by a wider channel and large availability of sediment the boxplots highlight this difference of w between the upstream and downstream domains with the former having a wider distribution and a lower median than the latter fig 4dd the difference may be also influenced by the adopted combination of moving window and dsm resolution for which the derived roughness suitable to identify different features on slopes may considered also features outside from the identified channel bed especially when it is narrow the two lowest values 0 3 are examples of how the proposed roughness is affected by morphological variations in the first case the lowest value in domain b corresponds to a point of the channel affected by wood jams formed by windthrows and standing trees which enhances the nearby roughness in the second case a vertical step along the upper domain a causes an abrupt increase of roughness which consequently lowered w the trends of the upslope fig 4e and downslope fig 4f components along the profile reflect the variations of their main factors specifically the contributing area and the distance respectively the lower the contributing area the lower the dup the longer the distance the higher the ddn moreover the ic components are also subjected to the variations of slope and w as demonstrated by the frequent alterations along the profiles the ic along the profile is shown in fig 4g and as expected the major trend is the decrease of ic with the increase of the distance from the target notably in domain b the value drops in the first 200 m decreasing from 1 to 1 from 200 to 1000 m the ic decreases slowly and only at the end of domain a it starts again to decrease considerably therefore ic is highly sensitive to the distance factor especially very close to the target this behavior is confirmed by the high r2 determination coefficient 0 886 obtained by fitting a third order polynomial function a clear distinction can be observed between the two domains by looking at the ic distributions fig 4gg with the downstream one domain b having higher ic values than the upstream one domain a the integration of an alternative weighting factor into r ic helped detect spatial patterns in ic values in an alpine catchment with high variability in terms of land cover and morphological changes nevertheless the choice of the proper w depends on the characteristics of the study area and on the effects of the disturbance i e wildfires land use changes forest windthrowns shallow lanslides to be represented for instance to integrate vegetation dynamics in the w factor after wildfires martini et al 2020 exploited a combination of vegetation spectral indices and hydraulic coefficients while after multi temporal forest disturbances jautzy et al 2021 implemented an hydrological recovery factor for forest stands 3 2 multiple catchments in this application example a set of multiple catchments has been analyzed and their ic values distributions presented the computation of ic for multiple catchments was carried out using the batch r ic code implemented for reiterative operations the selected catchments are located in north east of italy val dei mocheni in trentino alto adige region agordino area in the veneto region carnia area in friuli venezia giulia therefore they differ in the typology of the dominant process in accordance with the definitions of church and jakob 2020 table 1 and therefore they are divided in two groups freely available dtms downloaded from the webportals of the trentino province veneto region and friuli venezia giulia region provided by the civil protection were used for ic computation with resolution 1 m the results are presented in fig s1 the six small catchments group a fig s1 are characterized by different patterns a1 a4 and a5 present high ic exclusively along the main channel and lower values gradually moving far from the target in a3 high ic is also evident in the uppermost areas a6 has high ic concentrated along the hilly slopes of the main valley finally in a2 there is a distinction between upstream and downstream with the former almost completely disconnected and the latter highly connected comparing the maps within group b it is possible to detect differences first of all in the fvg region b1 b4 and b5 catchments display a common pattern the presence of a disconnected sector in each area is evident b4 and b5 show low ic sectors in the south whereas b1 shows low ic areas on the eastern slopes in comparison b2 shows much more larger areas of low ic this result is ascribed to i an upper plateau on the east disconnected from the main angheraz valley on the west and more gentle slopes if compared to the fvg areas finally b3 shows highly connected areas located along the two tributaries and downstream the channel merging to further visualize the similarities and differences within the groups ic frequency curves for each catchment have been computed fig 5 a presents the cumulative curve of ic frequency for group a first in accordance to the maps fig s1 a6 shows the larger frequency of high ic values with a median value equal to 2 5 second in a4 an abrupt inflection point is evident in the third quartile and in the ic range of 3 2 and 2 7 indicating a net distinction between low and high values as supported also from the ic map lastly the other catchments point out similar patterns since their frequency curves are overlapped fig 5b instead highlights the cumulative curve of ic frequency for group b as visible b2 has the largest frequency of low ic values with a median equal to 4 as confirmed by the ic map previously discussed the other curves mainly differ in the first and second quartiles for ic values lower than 3 7 finally even though the two groups are hard to be compared because of their differences in geographic context and dominant process group a shows overall higher values than those of group b the analysis carried out using both maps and frequency curves could help in the definition of best management practices in mountain watersheds from these tools it is possible to determine which catchment shows higher connectivity and which sector needs priority of intervention indeed additional data are needed to achieve a more reliable plan of intervention like for instance landslides debris flow susceptibility maps sediment source inventories land use maps outcomes of hydrological simulations the use of batch r ic allowed the reiterative computation of different ic maps in various catchments of the north east of italy differently from previous ic implementations this version of the r ic code can easily and quickly process a batch of dtms avoiding the repetitive upload of the data into a gui however running the r ic code requires a basic level of expertise in r and higher attention in data entry as well as in general usage 3 3 regional scale another main advantage of using r ic is the possibility to process large input dtms since the computational limit is given by computer performances therefore the following study case provides an example of the potential use of r ic for regional scale investigations intending to identify the most critical spots in terms of sediment connectivity the ic map of the isarco catchment was obtained using the standard r ic script hence with ri window size 3x3 cells to derive w and the channel network as target for the computation of ic a 2 5 m dtm obtained free of charge from the regional geoportal was used accounting for a total file size of 4 85 gb given the input file size ic was computed on a windows virtual machine located in the server of the tesaf department university of padova and equipped with intel r xeon r e5 2695 2 30 ghz and 100 gb of memory ram the isarco river is one of the largest tributaries of the adige river with 4200 km2 and it flows entirely in the autonomous province of bozen bolzano trentino alto adige region to highlight the potential use of ic regional maps we show two examples of how human infrastructures interacting with sediment connectivity and how the ic patterns might be altered by the presence of such elements which are forestry roads and check dams the information related to the forestry roads and check dams were downloaded again from the provincial geoportal the resulting regional map shows a heterogeneous mosaic of ic values primarily following the configuration of the isarco channel network fig 6 along the main channel it is possible to observe an alternation of high and low ic areas suggesting that lateral connectivity hillslope channel is frequently interrupted by the wide valley floor and by the presence of large and recurrent human infrastructures roads railroads embankments etc conversely in most of the sub catchments the steep slopes and narrow valleys increase lateral sediment connectivity hence high ic areas are detectable along the tributaries moreover using the ic map of the isarco river we advise a potential application related to the impact of forestry roads and or hydraulic structures on sediment connectivity and two examples are reported fig 7 a shows the alteration of the potential sediment fluxes caused by the presence of a forestry road it is evident how different sections of the road intercept concentrate and deviate the potential fluxes into other routes this means that the normal trajectory might be highly affected during an event changing the dynamic of the sediment flux in the second example a series of check dams is built to reduce the slope and stabilise a reach supplied by active sediment sources fig 7b the ic map depicts a red pathway suggesting longitudinal connectivity along the channel however the construction of check dams decreased the local connectivity as indicated by local green spots of lower ic around the hydraulic structures more downstream the lack of structures does not affect the natural geomorphic condition therefore in the two examples provided the ic results reported the role of human interventions and it represents a starting point for deeper analyses addressing specific problems of the territory roads have been already documented to re route sediment and water fluxes tarolli and sofia 2016 mauri et al 2021 and to enhance upstream sediment fluxes and erosion rates ramos scharrón 2021 on the contrary the primary role of the check dam is to regulate the sediment transfer decreasing the lateral sediment connectivity marchi et al 2019 it is important to highlight that the dtm grid resolution was found compatible with the dimension of the infrastructures and associated impacts which otherwise would have not been properly represented in conclusion even if the ic spatial patterns for the whole isarco catchment can be influenced by different factors due to the large differences among the sub catchments sediment dynamics morphology geology etc the regional scale maps could be useful to identify macro processes and to detect macro patterns caused by large disturbances i e landslides wildfires windthrowns however we advised important advantages of working with regional scales especially for regional or national agencies that can use ic maps at the regional scale maps for management purposes or to support risk assessment models mazzorana and fuchs 2010 in this sense ic can be regarded as an approach to support decision making strategies aimed at solving issue at a vast scale 4 final remarks considering the increasing number of studies dealing with sediment connectivity supported by the use of index of connectivity ic and the ongoing tendency of exploiting ic for deeper investigation of sediment transfer processes the implementation of a flexible tool to compute ic can meet the needs of the scientific community and of the local civil authorities this study proposes a new way to integrate the ic within the r environment called r ic thanks to the three code variants the derivation of ic results is flexible and easily accessible in particular the custom r ic gives the possibility to define ad hoc input data and to carry out a deeper analysis of the outputs in this way the user can adapt a sediment connectivity analysis to different environmental conditions and exploit the ic components to identify the process along the longitudinal profile the batch r ic provides the possibility to batch process different dtms and or to accurately evaluate the influence of the moving window size on ic differently from previous ic implementations large rasters are now processable limited only by the computational speed which will be the focus of future development maybe involving a multi processor scheme the proposed open source code integrated within a widespread programming language like r encourages potential users to perform further analysis consequently improving the investigations related to the sediment connectivity the examples of application presented in this study showed the r ic users how to face real geomorphological case studies at the same time it is important to underline that the ic is only a proxy of potential sediment transfer mostly based on topographic variables and therefore it can not be used indiscriminately as an empirical or physical model although recently it has been proved to represent structural sediment connectivity martini et al 2022 still critical thinking needs to be pursued when deciding to use ic for watershed management interventions solid justifications regarding the choice of ic input parameters e g dtm cell size moving window w factor as well as supportive use of traditional field surveys are recommended author contributions m l b t and l t designed the research and coded the scripts m l and b t analyzed the data and wrote the original draft c s and c m provided programming support reviewed the manuscript and supervised the study declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 5 acknowledgments this research received funding as a part of the project bridging the mass flow modelling with the reality from the cariparo foundation 2724 2018 and partially from the interreg v a italy austria 2014 2020 itat3032 sedinout project moreover it was partially developed within the project financed with bird 2021 funds dept tesaf università degli studi di padova appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105446 
25560,sediment connectivity is the capability of a system to regulate the exchange of sediment in catchments the index of connectivity ic has become a widely used tool offering a practical way to assess sediment connectivity from hillslopes to downstream channels we present a novel implementation of ic in r environment to expand the audience of users and encourage alternative applications of the index the r ic is an open source and freely available tool composed by three codes standard r ic runs the ic and it represents the core of the other variants custom r ic offers a more flexible script allowing the computation of alternative weighting factors and the possibility of running a further profile ic analysis batch r ic performs batch processing of the index for each code variant a geomorphological application is presented to illustrate how the r ic could be used in watershed management and practical issues related to sediment dynamics keywords sediment connectivity geomorphometry r ic open source software availability r ic was developed jointly by the three authors baggio tommaso martini lorenzo and torresani loris and is available at https github com tommbagg r ic releases tag r ic v1 0 baggio et al 2022 at no cost it is distributed under the gnu general public license v4 0 the r ic code is written in r language and it requires the packages raster hijmans 2020 shapefiles stabler 2013 rgdal bivand et al 2021 and ggplot2 wickham 2016 together with the executable files of taudem version 5 3 7 https hydrology usu edu taudem taudem5 the size of the code is 63 kb while the example scripts together with inputs and outputs is 10 mb r ic is tested on a windows computer equipped with intel r core tm i7 8700 cpu 3 20 ghz with 16 gb of memory ram using r version 4 0 3 to process a large raster 4 85 gb we used a windows server virtual machine equipped with intel r xeon r e5 2695 2 30 ghz with 100 gb of memory ram and r version 4 1 1 contact information department of land environment agriculture and forestry university of padova viale dell università 16 legnaro 35020 pd italy email tommaso baggio unipd it 1 introduction in the field of geomorphology assessment of sediment availability and transfer dynamics is important to understand landscape evolution and the consequences of human impacts on geomorphic systems seminal works by brunsden and thornes 1979 caine and swanson 1989 and harvey 2001 first placed attention towards the role of geomorphic coupling in the sediment delivery and sediment yield assessment issues more recently the interest in the regulation of sediment transfer between geomorphic system compartments has increased remarkably the dis connectivity between such compartments e g hillslopes channels floodplains wetlands plays a fundamental role in influencing the efficiency of sediment transfer in drainage basins merritt et al 2003 brierley et al 2006 fryirs et al 2007a 2007b bracken et al 2015 in the sediment cascade framework sediment connectivity is intended as an intrinsic property of any basin wohl 2017 and it defines the degree to which the basin area and stream network system promote the exchange of sediment based on its spatial configuration i e structural connectivity and its processes i e functional connectivity wainwright et al 2011 heckmann et al 2018 turnbull et al 2018 as result in mountain catchments sediment connectivity underlies the potential sediment transfer between an area of sediment production i e sediment source and downstream sink areas hooke 2003 together with the development of several frameworks and definitions the assessment of sediment connectivity has become a major concern for geomorphologists being able to represent and quantify the linkages responsible for sediment transfer will increase awareness of the trajectories of geomorphic systems in stationary conditions and after natural and anthropic disturbances as consequence this will prevent potential negative impacts on environmental and or socio economical assets poeppl et al 2017 fuchs et al 2019 such as loss of fish biodiversity due to reduction of longitudinal connectivity by dam constructions poeppl et al 2017 or the alluvial flooding of entire villages triggered by volcanic eruptions pierson et al 2013 after a disturbance the degree of connectivity can help predict the sensitivity of the catchment as it facilitates the propagation of the disturbance cienciala 2021 therefore sediment connectivity is becoming a useful concept for decision making assessments in river and catchment management wohl et al 2019 a semi quantitative measure of sediment connectivity is provided by the geomorphometric index of connectivity hereinafter ic which determines the potential routing of sediment from hillslope to the stream system borselli et al 2008 ic relies on topographical indices of a catchment as major source of input and it offers a straightforward way to describe the existing structural relationships among sediment sources and downstream sink areas from the original formulation by borselli et al 2008 different variants have been proposed to enhance it and to spread its usage over different environments e g geological climate and vegetation settings among those the most prominent was introduced by cavalli et al 2013 and has become a reference point for investigating sediment sources in mountain catchments cavalli et al 2017 cucchiaro et al 2019 zanandrea et al 2020 martini et al 2022 moreover in the analysis of catchment s sensitivity to large and infrequent disturbances ic can be adapted successfully by modifying the parameter representing the impedance to sediment fluxes the so called weighting factor in this sense many authors assessed sediment connectivity after different events wildfires fernández et al 2020 lópez vicente et al 2020 martini et al 2020 volcanic eruption ortíz rodríguez et al 2017 martini et al 2019 windstorms and forest disturbances jautzy et al 2021 pellegrini et al 2021 rainato et al 2021 and land use changes lizaga et al 2017 with the increasing number of applications the availability of tools for deriving ic and its variants has become pivotal in this sense easy to use flexible and parsimonious tools can efficiently support a large number of works carried out by both researchers and land management authorities tangi et al 2019 the reproducibility of the analyses is indeed a fundamental issue if we seek to introduce the sediment connectivity based tools into decision making processes and catchment management strategies however it is fundamental to highlight here that the ic given its simplified nature is mainly intended as a lateral i e hillslope to channel connectivity index and its application along the channels where more complex processes as bedload transport operate should be carefully addressed taking into account all the intrinsic limitations of the approach heckmann and schwanghart 2013 on the same line in this work we present a novel open source code to compute ic in r environment named r ic starting from the already available implementations we developed r ic to provide an additional and alternative solution to carry out sediment connectivity analysis based on the geomorphometric approach proposed by cavalli et al 2013 the r ic is intended as an easy open source tool with high flexibility and reproducibility thanks to three variants of the code specifically designed for enhancing the use of ic under different needs the ultimate goal of such implementation is to make ic even more accessible promoting the integration of deeper analysis directly in r and offering a new environment to prepare input data and or further process and analyse the outputs accordingly in this work we present potential useful applications related to real case studies 2 background and implementation 2 1 index of connectivity the basic formulation of the index of connectivity represented in fig 1 is the following 1 i c log 10 d u p d d n where the base 10 logarithm is calculated over the ratio between an upslope factor dup and a downslope factor ddn the ic value expressed in logarithmic scale is dimensionless the dup eq 2 expresses the main topographic features of the area potentially prodividing the sediment 2 d u p w s a where w is the average weighting factor indicating the average impedance to sediment fluxes of the upslope drainage area s is the average slope m m of the upslope drainage area and a is the contributing area draining to the raster cell under investigation within the computational domain the ddn eq 3 instead expresses the characteristics of the sediment pathway from the raster cell under investigation to a specific target e g channel network outlet sink 3 d d n d i w i s i where di is the length m of each ith cell along the flow path wi is the weighting factor and si the slope referred to the ith cell the logarithmic ratio between dup and ddn forming the ic can range from infinite representing low connection with the target area to infinite high connection in the present work the refined version of ic made by cavalli et al 2013 is used over the previous formulation made by borselli et al 2008 hence three major adaptations are considered the slope gradient is calculated according to the steepest downslope direction and trimmed by a lower and upper value ii the contributing area is computed employing the d infinity approach tarboton 1997 and iii to calculate the w factor the roughness index ri is adopted following the formulation of cavalli and marchi 2008 equal to the standard deviation of the residual topography difference between the original dem and the smoothed one within a moving window these refinements have been implemented to enhance the use of the ic in steep alpine areas in the case of high resolution dtms available commonly defined as cell size lower than 5 m 2 2 available implementations of ic ic implementations have always been characterized by particular attention devoted to the applicability of the proposed approach from the first proposal by borselli et al 2008 the authors provided arcmap code listing within the appendix of the manuscript the work carried out by the hydrogeomorphology research group hrg of cnr irpi during the years led to the availability of an arcgis toolbox cavalli et al 2014 and an open source stand alone application named sedinconnect crema and cavalli 2018 developed to facilitate ic computation moreover sedinconnect provides a framework not bound by the use of commercial software or any gis or scripting environment at all and drastically simplified input parameters computation needed by the arcgis toolbox furthermore both the arcgis toolbox and sedinconnect have the embedded option of computing surface roughness from an input dtm to be used as impedance to sediment fluxes proxy in ic computation finally worthy of note is the recent availability of python scripts crema et al 2021 for computing ic and surface roughness within a wider python framework or for custom or batch processing 2 3 r ic the algorithms developed in this study aim to improve the computation and the analysis of ic the main advantages of r ic are i the flexibility of the code in the pre and post processing phase ii the possibility to compute ic at a regional scale the computational limit is the computer performance and iii to batch process of different study areas the ic algorithm has been implemented in r r core team 2020 environment version used 4 0 3 through raster operations in particular the packages used are raster hijmans 2020 shapefiles stabler 2013 rgdal bivand et al 2021 and ggplot2 wickham 2016 for hydrologic analysis of the dtm similarly to the arcgis toolbox and sedinconnect implementations we used the functions implemented in taudem https hydrology usu edu taudem taudem5 the functions are directly recalled in the r script via the use of the terminal that run the executable scripts writing the output raster files in the working directory taudem algorithms take advantage of parallel processing by partitioning the computational domain into stripes using message passing interface mpi therefore the types of input formats for r ic are those acceptable in the listed r packages consequently the user has potentially no limit in raster size and can use alternatively different raster gis file formats instead the raster outputs of r ic are written in tiff format and located in the same folder of the input data the standard r ic fig 2 a code offers a simple and straightforward computation of the ic as refined by cavalli et al 2013 the procedure for running the code can be summarized in a flowchart showing the main steps concerning required inputs computational processes conditional blocks and outputs fig 2a three main inputs are needed to run the standard r ic first the main input is the dtm in raster format which needs to be hydrologically corrected in order to avoid local depressions acting as spurious sinks filling the sinks in the dtm is up to the user who chooses the method one considers most appropriate moreover the raster grid must be regular with uniform cell sizes expressed as length measure second a moving window size is required to define the number of neighbouring cells to compute the surface roughness following the formulation of cavalli and marchi 2008 third it is asked to provide polygon features shapefile format to be used as the user defined target of the ic the shapefile represents areas of interest to which the degree of linkage i e connectivity is calculated the target area is chosen by the user according to the objective of the study and it needs to be represented in the same coordinate system of the dtm and provided only by polygon features lines and points are not accepted computational processes regard in sequence the roughness index ri computation weighting factor w computation and the ic computation the ri is calculated according to the formula first proposed in cavalli and marchi 2008 and it requires the choice of a moving window size the ri is consequently computed as the standard deviation of the residual topography in a n x n cells moving window eq 4 4 r i i 1 n 2 x i x m 2 n 2 where n is the number of processing cells within a user defined moving window xi is a value of the dtm xm is the mean value of the cells in the n x n moving window the ri is used to compute the w eq 5 which is trimmed to the range 0 001 and 1 cavalli et al 2013 representing high and low impedance to the sediment fluxes respectively 5 w 1 r i r i m a x finally ic is calculated according to eq 1 and a user defined flag allows the saving of either all outputs main and intermediate outputs or just the main outputs index of connectivity roughness index upslope component downslope component a particular advantage of standard r ic is the potential unlimited size of the input raster file to be elaborated differently from the previous implementations of ic limited to the geotiff raster format the algorithms used in r ic have not constraints regarding the file format and dimensions the restrictions are only associated to available hardware and especially to the ram memory engaged to temporarily store matrix and raster data for computation purposes within the global environment of r based on the standard r ic two additional scripts were developed in order to achieve more flexibility than previos implementations of ic so that further applications can be carried out custom r ic differs for the use of a w map provided by the user and by the possibility flag to perform a further analysis of topographic parameters and ic along a user defined profile fig 2b the workflow starts with user defined inputs target dtm and w factor particularly in the custom r ic code the computation of ri is not already set as default hence no moving window needs to be defined on the contrary the user decides the w raster map that mostly represents the impedance to sediment fluxes the input w is a raster file that has to match the same characteristics of the dtm cell size extension coordinate system ic is computed as in the standard r ic but a further optional analysis is then implemented the profile analysis of ic is introduced following the approach presented on the relative open source code torresani and piton 2022 which unravels ic and its main components along a longitudinal profile if the profile ic analysis is chosen flag for activation the code requires as a further input a user defined point shapefile along which the analysis is going to be performed using the r ic outputs the optional input profile is requested at the beginning of the script leaving the possibility of not assigning any file in the case the analysis is not performed the outputs of the profile ic analysis are tables and graphical results charts and boxplots the longitudinal approach here proposed should be mainly applied in steep small medium size catchments where sediment concentration of the flow is important since debris flows or debris floods dominate it is important to underline that this alternative code does not limit to the mere decomposition of the ic components but it offers the opportunity to incorporate other kind of analysis e g dem of difference dod for comparisons and further investigations in the end the custom r ic code offers a flexible solution to compute ic at the catchment scale paving the way for deeper geostatistical analyses directly in r environment in the case the user wants to run the standard r ic reiteratively varying the input data the batch r ic is the best option the batch r ic fig 2c exploits the standard r ic as core function to compute ic according to multiple targets and multiple dtms retrieved in a single folder in the same way the user can vary the moving window size for each dtm the input s constraints are the same as those outlined for the standard r ic concerning the outputs in this code variant only the main ic outputs are kept in the working location additionally after the whole loop a summary table is derived csv format summarizing the main statistics min max median sd of the multiple ic computed for each dtm the batch processing can help the final user in the computation of ic for different study areas for instance to identify the most critical one in terms of sediment connectivity for a region of interest and as result enhancing the reproducibility of the geomorphometric approach in order to test the accuracy in computing ic the standard code r ic has been tested against sedinconnect 2 3 crema and cavalli 2018 providing a difference of ic in the order of 10 5 test performed on the val de le noghere catchment section 3 1 mean difference 1 9 10 5 standard deviation 3 5 10 3 regarding the maximum size of the input rasters we ran r ic in the isarco catchment section 3 2 using a 2 5 m dtm with a raster size equal to 4 85 gb the code is expected to work even with bigger rasters only limited by the available hardware differently from the sedinconnect 2 3 crema and cavalli 2018 for which the input dtm is limited by the characteristics of the geotiff raster file 3 examples of application 3 1 computing ic in a small catchment affected by multiple disturbances we decided to test the custom r ic in a small alpine catchment to investigate sediment dynamics and to carry out a deeper characterization of longitudinal connectivity according to the morphological characteristics of the main channel the study area is the val de le noghere or longhere a subcatchment of the liera stream located in the north eastern italian alps veneto region the val de le noghere subcatchment 1 20 km2 is characterized by steep slopes mean slope of 48 with elevation ranging from 1195 m a s l to 2502 m a s l the area was affected by multiple disturbances in 2016 a rock slope failure deposited a large amount of sediment in the upper part of the catchment and in october 2018 the area was hit by an exceptional storm named vaia which triggered widespread instabilities and a large debris flow in the main channel the response of the catchment to the vaia storm is under investigation by the interreg ita aut project sedinout boretto et al 2021 a lidar derived dtm and dsm at 1 m resolution obtained in 2019 were used for the sediment connectivity analysis which consisted in the computation of ic detection of spatial patterns and further analysis of ic along the main stream the computation of ic was carried out with the custom r ic using the outlet as target to compute w we adopted the vector ruggedness measure sappington et al 2007 applied to the 1 m dsm associated with a moving window of 49 m2 7 7 m the derived w integrates also the effect of above ground features such as shrubs sparse dense and disturbed forests brožová et al 2021 that may potentially interact in different ways with sediment fluxes on slopes notably in this example of application rather than investigating the optimum w factor the goal is to show the versatility and flexibility of the code by including an alternative roughness to the standard roughness index cavalli and marchi 2008 after the computation ic was automatically extracted along the longitudinal profile of the val de le noghere stream and the main variables analyzed through the approach proposed in torresani and piton 2022 which has been added to the custom r ic code straightforwardly the ic map shows the distribution of the values into four classes fig 3 the downstream part and the channel network are areas of high ic as represented by the hot colors branching out in the catchment medium high ic areas are very limited in extension and mainly visible close to the high ic areas on the contrary medium low ic and low ic areas are organized in patterns partially following the topographic characteristics of the catchment medium low ic values are concentrated along the western tributary showing steep slopes and an incised channel instead low ic characterizes the central part of the basin where it is possible to observe large deposits of sediment related to the 2016 rockfall hence an overall lower slope and consequently lower sediment connectivity depict this area acting as a buffer for the sediment the longitudinal profile 1397 m was divided into two distinct domains defined by the user in accordance with the channel bed width fig 3 the upstream a domain red showing narrow and incised channel width range 4 7 m the downstream b domain blue showing wider channel width range 8 13 m the former ranges from 1195 to 1525 m a s l while the latter from 1525 to 1863 m a s l fig 4 a as reported by whole fig 4 in fact the main variables and components of ic are unraveled along the profile and divided into the two domains the slope chart fig 4b shows that the channel can reach high steepness with peaks of 14 2 m m in domain a and 8 6 m m in domain b that are also visible as two steps in the longitudinal profile presented in fig 4a as expected the slope increases moving upstream concave pattern hence the domain a generally shows higher values fig 4bb the contributing area instead decreases going further to the outlet and the major jumps are associated to the junctions of major tributaries fig 4c for instance the first evident jump in domain b corresponds to the cut off of the western tributary showing medium low ic values in the sediment connectivity map fig 3 concerning the w factor variation first it is possible to observe greater variability along the domain a than domain b thanks to the strong sensitivity of the proposed roughness to the surface morphology and vegetation cover fig 4dd the roughness is much more subject to variations in the upper domain a characterized by a narrower channel with high steps and steep banks than in downstream domain b characterized by a wider channel and large availability of sediment the boxplots highlight this difference of w between the upstream and downstream domains with the former having a wider distribution and a lower median than the latter fig 4dd the difference may be also influenced by the adopted combination of moving window and dsm resolution for which the derived roughness suitable to identify different features on slopes may considered also features outside from the identified channel bed especially when it is narrow the two lowest values 0 3 are examples of how the proposed roughness is affected by morphological variations in the first case the lowest value in domain b corresponds to a point of the channel affected by wood jams formed by windthrows and standing trees which enhances the nearby roughness in the second case a vertical step along the upper domain a causes an abrupt increase of roughness which consequently lowered w the trends of the upslope fig 4e and downslope fig 4f components along the profile reflect the variations of their main factors specifically the contributing area and the distance respectively the lower the contributing area the lower the dup the longer the distance the higher the ddn moreover the ic components are also subjected to the variations of slope and w as demonstrated by the frequent alterations along the profiles the ic along the profile is shown in fig 4g and as expected the major trend is the decrease of ic with the increase of the distance from the target notably in domain b the value drops in the first 200 m decreasing from 1 to 1 from 200 to 1000 m the ic decreases slowly and only at the end of domain a it starts again to decrease considerably therefore ic is highly sensitive to the distance factor especially very close to the target this behavior is confirmed by the high r2 determination coefficient 0 886 obtained by fitting a third order polynomial function a clear distinction can be observed between the two domains by looking at the ic distributions fig 4gg with the downstream one domain b having higher ic values than the upstream one domain a the integration of an alternative weighting factor into r ic helped detect spatial patterns in ic values in an alpine catchment with high variability in terms of land cover and morphological changes nevertheless the choice of the proper w depends on the characteristics of the study area and on the effects of the disturbance i e wildfires land use changes forest windthrowns shallow lanslides to be represented for instance to integrate vegetation dynamics in the w factor after wildfires martini et al 2020 exploited a combination of vegetation spectral indices and hydraulic coefficients while after multi temporal forest disturbances jautzy et al 2021 implemented an hydrological recovery factor for forest stands 3 2 multiple catchments in this application example a set of multiple catchments has been analyzed and their ic values distributions presented the computation of ic for multiple catchments was carried out using the batch r ic code implemented for reiterative operations the selected catchments are located in north east of italy val dei mocheni in trentino alto adige region agordino area in the veneto region carnia area in friuli venezia giulia therefore they differ in the typology of the dominant process in accordance with the definitions of church and jakob 2020 table 1 and therefore they are divided in two groups freely available dtms downloaded from the webportals of the trentino province veneto region and friuli venezia giulia region provided by the civil protection were used for ic computation with resolution 1 m the results are presented in fig s1 the six small catchments group a fig s1 are characterized by different patterns a1 a4 and a5 present high ic exclusively along the main channel and lower values gradually moving far from the target in a3 high ic is also evident in the uppermost areas a6 has high ic concentrated along the hilly slopes of the main valley finally in a2 there is a distinction between upstream and downstream with the former almost completely disconnected and the latter highly connected comparing the maps within group b it is possible to detect differences first of all in the fvg region b1 b4 and b5 catchments display a common pattern the presence of a disconnected sector in each area is evident b4 and b5 show low ic sectors in the south whereas b1 shows low ic areas on the eastern slopes in comparison b2 shows much more larger areas of low ic this result is ascribed to i an upper plateau on the east disconnected from the main angheraz valley on the west and more gentle slopes if compared to the fvg areas finally b3 shows highly connected areas located along the two tributaries and downstream the channel merging to further visualize the similarities and differences within the groups ic frequency curves for each catchment have been computed fig 5 a presents the cumulative curve of ic frequency for group a first in accordance to the maps fig s1 a6 shows the larger frequency of high ic values with a median value equal to 2 5 second in a4 an abrupt inflection point is evident in the third quartile and in the ic range of 3 2 and 2 7 indicating a net distinction between low and high values as supported also from the ic map lastly the other catchments point out similar patterns since their frequency curves are overlapped fig 5b instead highlights the cumulative curve of ic frequency for group b as visible b2 has the largest frequency of low ic values with a median equal to 4 as confirmed by the ic map previously discussed the other curves mainly differ in the first and second quartiles for ic values lower than 3 7 finally even though the two groups are hard to be compared because of their differences in geographic context and dominant process group a shows overall higher values than those of group b the analysis carried out using both maps and frequency curves could help in the definition of best management practices in mountain watersheds from these tools it is possible to determine which catchment shows higher connectivity and which sector needs priority of intervention indeed additional data are needed to achieve a more reliable plan of intervention like for instance landslides debris flow susceptibility maps sediment source inventories land use maps outcomes of hydrological simulations the use of batch r ic allowed the reiterative computation of different ic maps in various catchments of the north east of italy differently from previous ic implementations this version of the r ic code can easily and quickly process a batch of dtms avoiding the repetitive upload of the data into a gui however running the r ic code requires a basic level of expertise in r and higher attention in data entry as well as in general usage 3 3 regional scale another main advantage of using r ic is the possibility to process large input dtms since the computational limit is given by computer performances therefore the following study case provides an example of the potential use of r ic for regional scale investigations intending to identify the most critical spots in terms of sediment connectivity the ic map of the isarco catchment was obtained using the standard r ic script hence with ri window size 3x3 cells to derive w and the channel network as target for the computation of ic a 2 5 m dtm obtained free of charge from the regional geoportal was used accounting for a total file size of 4 85 gb given the input file size ic was computed on a windows virtual machine located in the server of the tesaf department university of padova and equipped with intel r xeon r e5 2695 2 30 ghz and 100 gb of memory ram the isarco river is one of the largest tributaries of the adige river with 4200 km2 and it flows entirely in the autonomous province of bozen bolzano trentino alto adige region to highlight the potential use of ic regional maps we show two examples of how human infrastructures interacting with sediment connectivity and how the ic patterns might be altered by the presence of such elements which are forestry roads and check dams the information related to the forestry roads and check dams were downloaded again from the provincial geoportal the resulting regional map shows a heterogeneous mosaic of ic values primarily following the configuration of the isarco channel network fig 6 along the main channel it is possible to observe an alternation of high and low ic areas suggesting that lateral connectivity hillslope channel is frequently interrupted by the wide valley floor and by the presence of large and recurrent human infrastructures roads railroads embankments etc conversely in most of the sub catchments the steep slopes and narrow valleys increase lateral sediment connectivity hence high ic areas are detectable along the tributaries moreover using the ic map of the isarco river we advise a potential application related to the impact of forestry roads and or hydraulic structures on sediment connectivity and two examples are reported fig 7 a shows the alteration of the potential sediment fluxes caused by the presence of a forestry road it is evident how different sections of the road intercept concentrate and deviate the potential fluxes into other routes this means that the normal trajectory might be highly affected during an event changing the dynamic of the sediment flux in the second example a series of check dams is built to reduce the slope and stabilise a reach supplied by active sediment sources fig 7b the ic map depicts a red pathway suggesting longitudinal connectivity along the channel however the construction of check dams decreased the local connectivity as indicated by local green spots of lower ic around the hydraulic structures more downstream the lack of structures does not affect the natural geomorphic condition therefore in the two examples provided the ic results reported the role of human interventions and it represents a starting point for deeper analyses addressing specific problems of the territory roads have been already documented to re route sediment and water fluxes tarolli and sofia 2016 mauri et al 2021 and to enhance upstream sediment fluxes and erosion rates ramos scharrón 2021 on the contrary the primary role of the check dam is to regulate the sediment transfer decreasing the lateral sediment connectivity marchi et al 2019 it is important to highlight that the dtm grid resolution was found compatible with the dimension of the infrastructures and associated impacts which otherwise would have not been properly represented in conclusion even if the ic spatial patterns for the whole isarco catchment can be influenced by different factors due to the large differences among the sub catchments sediment dynamics morphology geology etc the regional scale maps could be useful to identify macro processes and to detect macro patterns caused by large disturbances i e landslides wildfires windthrowns however we advised important advantages of working with regional scales especially for regional or national agencies that can use ic maps at the regional scale maps for management purposes or to support risk assessment models mazzorana and fuchs 2010 in this sense ic can be regarded as an approach to support decision making strategies aimed at solving issue at a vast scale 4 final remarks considering the increasing number of studies dealing with sediment connectivity supported by the use of index of connectivity ic and the ongoing tendency of exploiting ic for deeper investigation of sediment transfer processes the implementation of a flexible tool to compute ic can meet the needs of the scientific community and of the local civil authorities this study proposes a new way to integrate the ic within the r environment called r ic thanks to the three code variants the derivation of ic results is flexible and easily accessible in particular the custom r ic gives the possibility to define ad hoc input data and to carry out a deeper analysis of the outputs in this way the user can adapt a sediment connectivity analysis to different environmental conditions and exploit the ic components to identify the process along the longitudinal profile the batch r ic provides the possibility to batch process different dtms and or to accurately evaluate the influence of the moving window size on ic differently from previous ic implementations large rasters are now processable limited only by the computational speed which will be the focus of future development maybe involving a multi processor scheme the proposed open source code integrated within a widespread programming language like r encourages potential users to perform further analysis consequently improving the investigations related to the sediment connectivity the examples of application presented in this study showed the r ic users how to face real geomorphological case studies at the same time it is important to underline that the ic is only a proxy of potential sediment transfer mostly based on topographic variables and therefore it can not be used indiscriminately as an empirical or physical model although recently it has been proved to represent structural sediment connectivity martini et al 2022 still critical thinking needs to be pursued when deciding to use ic for watershed management interventions solid justifications regarding the choice of ic input parameters e g dtm cell size moving window w factor as well as supportive use of traditional field surveys are recommended author contributions m l b t and l t designed the research and coded the scripts m l and b t analyzed the data and wrote the original draft c s and c m provided programming support reviewed the manuscript and supervised the study declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 5 acknowledgments this research received funding as a part of the project bridging the mass flow modelling with the reality from the cariparo foundation 2724 2018 and partially from the interreg v a italy austria 2014 2020 itat3032 sedinout project moreover it was partially developed within the project financed with bird 2021 funds dept tesaf università degli studi di padova appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105446 
25561,the goal of this study is to develop geospatial hydrology models incorporating design rainfall intensities and land morphologic features to identify erosion hazards and vulnerability risks to road culverts stream crossings in three watersheds at usda forest service long term experimental forests i coweeta hydrologic laboratory nc ii santee experimental forest sc and iii alum creek experimental forest ar these models developed in an arcgis modelbuilder platform were i streambank erosion vulnerability assessment sbeva and ii modified revised universal soil loss equation modified rusle for potential erosion and streambank vulnerability estimation the sbeva model developed using a delphi based weighted probability scale and modified rusle were integrated to identify locations of culverts stream crossings morphologically vulnerable to erosion and scouring which were ground truthed for the sc site only as the modified rusle model does not assess streambank erosion its integration with the sbeva helps to develop a better decision support tool for relevant agencies for safeguarding these road culverts stream crossings keywords streambank erosion spatial vulnerability assessment sbeva model modified revised universal soil loss equation modified rusle model extreme precipitation events automated geospatial hydrology model stream crossings delphi weighting factors 1 introduction climate change is expected to lead to more frequent extreme precipitation events kundzewicz et al 2014 flooding and landslides potentially enhancing the probability of road closures and other incidents such as roads being washed away due to culverts or bridge failures as a worst case scenario kalantari and folkeson 2013 usdot 2018 identified heavy precipitation and flooding as the vulnerability most closely related to the road culvert systems among four different climate change related vulnerabilities of forest transportation networks filosa et al 2017 projected increases in the intensity and frequency of precipitation events due to climate change easterling et al 2017 may further exacerbate flooding increasing risks of road drainage and culvert failures due to their limited carrying capacities usdot 2002 therefore stronger demands will be placed on the functionality of road drainage systems in such extreme events rees et al 2018 urban drainage systems can be quickly assessed while road crossing drainage structures and stream crossings in remote forest lands will need proactive management to prevent the occurrence of such casualties due to their inaccessibility the u s department of agriculture usda forest service fs manages a road system consisting of approximately 600 000 km of roads and at least 40 000 stream crossings i e road leadoff structures fords culverts and bridges heredia et al 2016 these structures most of which are located in forested headwater watersheds with small drainage areas catchments need an accurate estimation of peak storm discharge rates from watersheds for the design of drainage works along roadways and related infrastructure mannering and kilareski 1998 according to the u s department of transportation usdot 2018 most road crossings in the united states including the ones in forested watersheds are currently considered undersized for accommodating bankfull flow conditions that could occur about 1 or 2 years climate change induced extreme precipitation jalowska and spero 2019 and corresponding peak discharge events including their methods of estimation could have major consequences for improperly sized stream crossing infrastructure amatya et al 2021 located in headwater forested watersheds with small drainage areas other than the extreme discharge the inherent scientific reasoning for such structural failures is precarious the amount of rainfall does influence the moisture content in soil dawson 2009 but the time delay between the precipitation event and the consequent subgrade moisture content increase can vary from an almost immediate effect to a delay of up to a month fifer bizjak et al 2014 this is because the soil road surface drainage and surrounding conditions can all strongly affect the response of the road to rainfall and most importantly road scouring will increase due to this microclimatic effect fifer bizjak et al 2014 when rainfall water reaches the unbound subgrade destabilization can take place if the drainage system is not able to remove it quickly especially in cohesive soil drainage clogging would occur with subsequent structural failure fifer bizjak et al 2014 this structural failure would cause significant challenges associated with increased runoff soil erosion and sediment yields economic losses and disruption of stream connectivity thereby creating barriers to aquatic organisms heredia et al 2016 the fs developed an ecological stream simulation approach for designing and building road stream crossings intended to permit free and unrestricted movements of any aquatic species usda 2008 the approach applies to crossing structures on any transportation network including roads trails and railroads at the same time safe and cost effective hydraulic design with minimum maintenance is critically important to accommodate extreme flow that may occur during the useful life of these structures novak et al 2007 that could minimize siltation and scouring with regard to soil erosion based vulnerability stream bank erosion is expected to cause more infrastructure failures as forest roads are established in high gradient watersheds and in areas receiving higher precipitation amounts than average watersheds according to the u s environmental protection agency epa 2020 sediment from streambank erosion that contributes 80 cancienne et al 2008 langendoen and simon 2008 wilson et al 2008 of the sediment yield has been listed as one of the major and common causes of stream impairment in forested watersheds high precipitation on steep terrains could cause hillslope failures or landslides exacerbated by elevated antecedent soil moisture and debris flows that would be detrimental to the safety of road infrastructure soil scientists have analyzed gentle slopes and found that gully erosion which is a form of hillslope failure can be a significant source of stream sediment a staggering 44 of the total soil erosion worldwide poesen et al 2003 and 35 of the total soil loss in the united states nrcs 2020 were due to gully erosion historically the emphasis of erosion research has been on sheet and rill erosion and gully erosion with a hydrologic focus on surface flow processes nrcs 2020 thus the universal soil loss equation usle revised usle rusle modified usle musle and the recent version rusle2 are often used to assess surface flow induced soil erosion losses however due to the lack of experimental observations and insufficient understanding of processes governing total runoff generation consideration of subsurface flow contributions to such erosion processes leading to landslides and streambank erosion has largely been neglected in assessments and prediction technologies fox and wilson 2010 emphasized by laniak et al 2013 in their comprehensive review article in environmental modeling and software complex environmental issues need integrated environmental modeling iem approach iem is inspired by contemporary environmental problems like the one under study here which warrant higher order systems thinking and holistic solutions epa us environmental protection agency 2008 jakeman and letcher 2003 parker et al 2002 an iem approach to the holistic geospatial study of the dynamic and interdependent nature of forest topography soil characteristics antecedent soil moisture vegetation dynamics the extent of climate change induced extreme precipitation and many other environmental features that contribute to the study of physical engineering distress is needed more than ever laniak et al 2013 correctly underscored that iem concepts and early models are now more than 30 years old bailey et al 1985 cohen 1986 mackay 1991 walters 1986 with the emergence of issues related to regional scale spatial land use management climate change and ecosystem services laniak et al 2013 similar to our study there is a critical need for a different approach to combining geospatial watershed management models such as archydro rusle2 and the innovative streambank erosion spatial vulnerability assessment sbeva etc to develop a practical management decision support system this is explained by david et al 2013 through their review article on the object modeling system in environmental modeling and software accordingly the main goal of this research is to develop a comprehensive geospatial hydrology model incorporating extreme precipitation and spatial land morphologic features as an iem approach to identify erosion hazards and vulnerability of the road culverts and stream crossings employing data from three different watersheds at fs experimental forests efs in the southeastern united states the objectives of the study are to i determine spatial locations of road culverts and stream crossings using high resolution stream networks defined by conducting hydrologic analysis of the watersheds in arc hydro model platform maidment and morehouse 2002 ii conduct on site verifications of the geospatially determined locations of culverts using data from the fs iii spatially locate identify road culverts and stream crossings with erosion vulnerability in low moderate and high scales using the rusle2 model foster et al 2003 modified further as modified rusle and the sbeva model developed in this study both in the arcgis modelbuilder platform and iv determine the resultant scale based vulnerable culverts and stream crossings in each of the study watersheds by combining results from both the models modified rusle and sbeva 2 materials and methods 2 1 study area this study was conducted in three fs experimental forest watersheds in the southeastern united states varying in size soils topography forest vegetation and climate and representing i high relief mountains in north carolina nc ii moderate relief mountains in arkansas ar and iii low relief coastal plain in south carolina sc fig 1 the study watersheds in nc 35 03 n 83 25 w are located at the coweeta hydrologic laboratory chl in the appalachian mountain range within the blue ridge physiographic province fig 1 the coweeta basin 1626 ha has a humid temperate climate with a long term average annual precipitation ranging from 1794 mm at lower elevations to 2368 mm at high elevations laseter et al 2012 soils are moderately well drained on moderate to steep slopes two reference watersheds low elevation ws14 and high elevation ws27 were selected for this study due to the large elevation induced climate gradient between the two locations amatya et al 2021 the mean annual precipitation in ws27 39 ha and ws14 61 ha varies widely with 2316 mm yr and 1842 mm yr respectively the ws27 and ws14 watersheds with mean elevations of 1254 m and 878 m respectively have mean slopes of 57 and 50 respectively the vegetation cover in both watersheds is mixed hardwood the second study site ac04 in alum creek ar is located within the 1885 ha alum creek experimental forest 34 48 n 93 3 w within the upper lake winona basin of the ouachita national forest fig 1 the ac04 watershed studied in this research has a drainage area of 13 ha with a mean elevation of 300 m and a mean slope of 15 amatya et al 2021 the ac04 watershed is characterized by a humid subtropical climate with mean annual precipitation of 1321 mm yr soils are generally less than 1 m deep with high infiltration rates the vegetation cover in the watershed is pine hardwood a detailed description of the watershed is provided by adams and loughry 2008 the third study site is the turkey creek watershed ws78 draining a third order stream with an area of 5240 ha fig 1 at santee experimental forest 33 08 n 79 47 w within the francis marion national forest fmnf amatya et al 2015 ws78 is adjacent to the ws80 watershed studied together with the two above watersheds by amatya et al 2021 the watershed is the headwaters of east cooper river a major tributary of the cooper river which drains to the charleston harbor the topographic elevation of the watershed varies from 3 6 m at the outlet to 14 m above mean sea level this coastal site has a subtropical climate with hot and humid summers characterized by high intensity short duration storm events and moderate wet winters generally with low intensity long duration rain events seasonally the summer is characterized by tropical depression storms that are not uncommon the average annual daily temperature and average annual precipitations are 18 4 c and 1370 mm respectively amatya et al 2015 vegetation cover within the watershed is mostly comprised of pine forest it is instrumented with a real time stream gauge sensor and a rain gauge http waterdata usgs gov sc nwis uv site no 02172035 operated and managed by the u s geological survey usgs 2 2 data and software the following data were used in the development of the three automated geospatial hydrology models watershed characterization using archydro tool modified rusle model based road infrastructure related watershed erosion distribution and sbeva model based streambank erosion vulnerability analysis the sources of the data collected for the three ef watersheds are provided in parentheses precipitation parameter elevation regressions on independent slopes model prism 900 m data usda natural resources conservation service nrcs geospatial data gateway https datagateway nrcs usda gov 100 yr 30 min rain intensity data noaa precipitation frequency data server pfds https hdsc nws noaa gov hdsc pfds gssurgo 10 m data nrcs geospatial data gateway https datagateway nrcs usda gov lidar elevation data 1 5 m for ws80 sc department of natural resources https www dnr sc gov 3 m digital elevation model dem for alum creek and coweeta watersheds nrcs geospatial data gateway https datagateway nrcs usda gov tiger road 2010 data u s census bureau www census gov national agricultural imagery program naip 1 m land use data usda farm service agency https www fsa usda gov programs and services aerial photography imagery programs naip imagery arcgis 10 3 esri redlands ca arc hydro esri redlands ca arcmap modelbuilder esri redlands ca other spatial data such as forest road and digitized culverts trail network low resolution stream network watershed boundaries etc were obtained from the fs ef geospatial database amatya and trettin 2021 caldwell 2019 marion 2019 in addition we conducted detailed field verification of all possible road culverts and their locations using a gps unit and mapped them for our analyses 2 3 procedure this iem approach based study was completed with a synchronous integration of two advanced automatic geospatial models modified rusle and sbeva with archydro tool through professional expert knowledge assimilation using delphi based weighted matrices arc hydro model helped provide detailed stream networks all possible road drainage structures and stream crossing locations and the associated catchments for each location using the lidar based high resolution dem reconditioning and step by step hydrologic analyses the arc hydro procedure eased the task of locating coordinates which otherwise would have been cumbersome and time consuming to do manually fig 2 provides a comprehensive approach schematic of the entire study to achieve our research goal the rusle2 model a modified form of a current usda agricultural research service ars model provided detailed pixel based soil loss and total annual sediment load estimates at the locations of interest using climate change associated and historic data based precipitation data noaa atlas 14 https hdsc nws noaa gov hdsc pfds pfds map cont html and detailed high resolution land use and soil spatial data of the studied watersheds sbeva model analysis provided information about streambanks that may be vulnerable due to their susceptibility to bank erosion which could easily clog stream crossing pathways and cause subsequent scouring and ultimate failure of the road culverts 2 3 1 arc hydro supported geospatial model development for stream road crossing structures inventory development as pointed by usda forest service usfs and federal highway authority fhwa field engineers the detailed and total number of stream road crossing structures like culverts and bridges in the forested watersheds are absent we developed an automated geospatial model aided by archydro to develop an accurate inventory an available geospatial database for each of the ef study sites was updated using the latest remote sensing data including lidar aerial photography and localized field soil sample testing unpublished data for soil database development arc hydro model as an add in to arcgis 10 3 was used to delineate high resolution stream networks which differed from national hydrography dataset nhd created stream networks along with other digitized streams using the high resolution 1 5 m lidar based dem for the ws80 watershed photo science 2007 and the 3 m dem downloaded from the nrcs geospatial data gateway for other watersheds to reflect actual conditions arc hydro is capable of terrain preprocessing like dem reconditioning fill sinks fill pits terrain morphology watershed processing attribute tools and network tools for both vector and raster processing strager et al 2010 and works efficiently for forested watersheds simões 2013 the fill sinks tool was used to fill the depressions within the lidar elevation data this was to ensure that the flow and accumulation of the stream is accurate the flow direction tool was then run to create a raster flow direction from each cell to its steepest downslope neighbor this creates the actual flow path of the channels the flow accumulation tool was then run to create a flow accumulation grid from the flow direction grid the stream definition tool was then used to create a stream grid with cells from the flow accumulation grid that exceeded our user defined threshold a threshold of 5000 cells was used to obtain a very detailed stream network configuration finally the watershed delineation tool created the subwatersheds in the watershed however it was observed that the arc hydro delineated subwatersheds with a defined threshold of 5000 cells did not properly represent each of the road drainage structures culverts mapped for the watersheds together with our limited information based on an initial field visit for ground truthing we also developed a unique approach to identify locations of all possible culverts in each of the studied watersheds similar to the one by amatya et al 2013 analyzing detailed stream channel networks developed using the arc hydro modeling updated digitized road trail network and relevant gps locations we rasterized both layers and reclassified each pixel as a value of 1 then the arcgis plus tool provided us with pixel cell values of 2 which is an overlapped pixel combination of both stream and road this analysis suggested that these pixels are road crossing pixels later our ground truthing in the field confirmed our resultant road crossing structure locations providing a complete updated culvert location spatial file for all the watersheds as a next step instead of using automatically generated subwatersheds we used the arc hydro batch processing tool to delineate subwatersheds that represented each culvert location as its exit point and was present in the field the efficacy of arc hydro performance was examined later when erosion based models were developed fig 3 represents the workflow process of digitizing subwatersheds for each possible culvert location in the studied watersheds 2 3 2 modified rusle model development the rusle2 model is supported by six environmental factors renard et al 1994 as model parameters shown in eq 1 below 1 a r x k x l x s x c x p where a pixel based soil erosion rate t ha 1 yr 1 r rainfall erosivity factor developed separately using noaa pfds i30 raster k soil erodibility factor obtained from gssurgo l slope length factor usle obtained from gssurgo s slope gradient factor usle obtained from gssurgo c crop management factor developed with land use map reclassification and p conservation practice factor a constant value for a managed watershed the modified form of the rusle2 modified rusle model was developed for the watersheds with the uniquely developed r factor using noaa pfds i30 raster of the study area panda et al 2021 using the ars algorithm shown in eqs 2 and 3 the c factor was developed using a normalized difference vegetation index ndvi based formula eq 4 reeves et al 2021 and the p factor raster was generated using the reclassified naip land use classified rasters for the studied watersheds reeves et al 2021 the k l and s factor rasters were developed from the gssurgo data downloaded from nrcs geospatial data gateway fig 4 represents the schematic of the automated flow diagram for the modified rusle 2 r ke i30 where ke total kinetic energy of the rainstorm i30 30 min rainfall intensity for a 100 yr storm and e was calculated using eq 3 shown below 3 e 916 331 log10 i30 4 c 0 1 n d v i 1 2 2 3 3 sbeva geospatial model development though stream bank erosion is a natural process often occurring as a result of changes in flow regime and sediment supply of streams and rivers it is very detrimental to forested watersheds for example even a small amount of stream bank erosion can clog forest road drainage outlets and stream crossings allowing overtopping of runoff and consequently damaging the structures climate change induced extreme precipitation and or natural catchment disturbances like soil erosion also enhance the impact of streambank erosion on the structures it is to be noted according to hughes 2016 that streambank erosion rates increase with natural land cover changes potentially due to climate change induced flashy regimes changes to natural riparian vegetation channel modification and introduction of livestock e g cattle sheep deer to catchments and their unrestricted access to streams however most of those scenarios are not expected in forested watersheds though streambank erosion potential is still high due to steep terrain wildlife access to streams and erodible soil characteristics we developed the sbeva model to identify areas vulnerable to erosion at road culvert outlets stream crossings and stream banks of each study watershed using the prism precipitation raster 900 m gssurgo soil raster 10 m classified naip imagery raster 1 m and lidar based dem raster 1 5 m as shown in section 2 2 above it is to be noted and as pointed by usfs and fhwa field engineers upon their review of this research s practicality regarding the real time precipitation data availability we used the local weather stations up to date precipitation data to develop the precipitation intensity duration frequency pidf data amatya et al 2021 and embedded that with noaa created pidf raster https hdsc nws noaa gov hdsc pfds available for the study areas at a spatial resolution of 900 m each raster was pan sharpened to a similar spatial resolution of 1 m in arcgis software these 1 m spatial resolution rasters were then reclassified based on their streambank erosion vulnerability potential the study area precipitation distribution raster was reclassified by rating the amount of precipitation in millimeters that occurred in an area of interest using a 1 9 scale with 1 being the lowest and 9 being the highest higher precipitation was rated as a higher vulnerability for streambank erosion potential through jenks natural breaks algorithm based raster classification similarly land use was reclassified by its potential for streambank erosion with a scale of 1 9 i e dense forest along the streambank has a lower erosion potential and was assigned the lowest score 1 while bare soil along the stream bank was assigned the highest score 9 the dem raster was converted to a slope raster and again classified using the jenks algorithm with nine classes the lowest slope degree range was assigned the lowest streambank erosion vulnerability scale of 1 and vice versa the gssurgo raster was also reclassified to create several streambank erosion vulnerability rasters with five contributing soil characteristics including k factor soil hydrologic group soil texture slope length usle and drainage each of the characteristics was classified with a rating of 9 1 a rating of 9 was assigned to the soil with the highest potential for erosion vulnerability and a rating of 1 was assigned to the soil with the lowest potential for erosion vulnerability it is to be noted that the sbeva analyses were conducted within the 50 m buffer of the entire stream network of each ef from which each road culvert on the watershed was identified for its vulnerability using the arcgis zonal statistics tool the streambank erosion vulnerability scale 1 9 was assigned for land use and soil characteristics based rasters using the widely used delphi method weight assignment process section 2 3 3 1 once all the spatial factors contributing to the streambank erosion process were reclassified they were assimilated through a weighted sum tool available in arcgis the same delphi method based weight assignment process was used to assign percentile weights to each environmental factor during the weighted sum application it is also to be noted that land use along the stream banks influences streambank erosion more than soil drainage type the reclassified data were given weights that determined their potential for influencing erosion vulnerability each of the soil characteristics was assigned a weighted score of 10 while land use slope gradient and precipitation were assigned scores of 20 15 and 15 respectively the result of the weighted sum rated the areas of spatial erosion vulnerability on a scale of 1 9 lowest to highest the entire process was carried out for the whole stream network fig 5 denotes the sbeva model schematic as created in the arcgis modelbuilder platform 2 3 3 1 delphi method of vulnerability weight assignment the delphi method developed by the rand corporation in the 1950s aimed to reduce the range of group responses and to strive for expert consensus essential in environmental modeling where vulnerability susceptibility probability weight assignment is crucial the process as described in the method is accomplished by the feedback of individual contributions of information and knowledge as well as responses with a degree of anonymity to assign weights of vulnerability as is applied in determining spatial probability adler and ziglio 1996 angus et al 1996 linstone and turoff 1975 rowe et al 1991 along with environmental impact assessments the delphi method is effective in various fields such as information systems planning social policy public health water resource use and management and water quality assessment angus et al 1996 linstone and turoff 1975 kim and chung 2013 lee et al 2013 macmillan and marshall 2006 okoli and pawlowski 2004 we used the delphi method for developing a weighted index for individual layers that are associated with our streambank erosion vulnerability model development as discussed above the authors of this manuscript along with professional experts from usgs atlanta office city of gainesville ga and institute for environmental and spatial analysis and biology and engineering programs of the university of north georgia were asked to provide their opinion on vulnerability weight scales for all eight layers used in the model development their weighted scale was compiled and a statistically derived weight scale for each layer was used in the analysis 2 3 4 model integration the arc hydro model provided the locations of all culverts and stream crossings in each ef including the study watersheds within them the modified rusle provided pixel based estimated erosion amounts and total summed soil erosion amounts from all pixels within a subwatershed discharged to its outlet structure culvert or stream crossing each structure located in the individual ef was classified into three low moderate and high vulnerability classes based on the probable estimated erosion accumulated at that location similarly the sbeva model provided the information on a 1 9 erosion vulnerability scale for the entire stream network within each ef the sbeva model separated each subwatershed outlet using the arcgis select tool and classified it into three low moderate and high vulnerability scales finally both the modified rusle and sbeva based scales were overlain together spatially in arcgis and each structure location was assigned a resultant scale of low 1 moderate 2 and high 3 classes based on their probable vulnerability to risks of failure due to the climate change induced extreme precipitation events and associated soil erosion 3 results and discussion fig 6 shows the arc hydro and modified rusle model based delineated detailed stream network and the road culvert locations along with the estimated pixel based soil erosion analysis of the turkey creek watershed ws78 at santee ef fig 1 similar results were obtained for the other two ef watersheds at coweeta and alum creek fs personnel assisted students from the university of north georgia ung in 2010 2011 and the college of charleston cofc in 2007 in surveying each of those locations and confirmed about some of their existences as shown in fig 6 legend as aoi culverts fssurveyed for the ws78 it is to be noted that the nhd based stream network in 1 24 000 scale does not show the detailed stream network as generated with the arc hydro model and presented in fig 6 soil erosion was estimated on a pixel basis kg ha yr and grouped into three classes green yellow and red being low high and moderate erosion amounts respectively later they were summed together for individual subwatershed outlets with locations of each structure using the zonal statistics tool the summed values were classified into three classes low moderate and high based on the watershed soil erosion vulnerability as discussed in section 2 3 4 fig 7 provides r k combined ls and c factor rasters developed using an innovative approach that ultimately were combined in arcgis using the raster calculator tool it should be noted that although l and s factor rasters fig 8 were individually created from gssurgo reclassification we found more than 70 of the area of interest having no data or provided as unclassified this paucity of data is attributed to the fact that the turkey creek watershed is on low gradient forested wetlands on the lower coastal plain where soil mapping and data were obtained from scs 1980 in which many soil characteristics were broadly defined or were not completed ramcharan et al 2017 therefore another ars algorithm eq 5 supported approach was followed to create the combined ls factor raster that uses the flow accumulation and slope rasters of the watershed which were developed with the arc hydro model the studied forested watersheds are within fs national forests and are well managed sites therefore we used a value of 0 9 for all the three watersheds 5 ls factor raster pow fac 28 36 22 13 0 4 pow sin slope 0 0896 1 3 fig 9 shows streambank erosion vulnerability along with the streams crossings and road culvert locations in the turkey creek watershed ws78 classified into three vulnerability classes low moderate and high as described in section 2 3 4 as the next step the sbeva and modified rusle based vulnerability classes were combined and or overlain together the culvert locations at the intersection of these two layers were classified into three final categories low 1 moderate 2 and high 3 vulnerability based on scouring clogging of culvert openings and flood runoff overtopping that was partially ground truthed accordingly fig 10 provides these three categories for culverts bridges along with other stream crossings with low vulnerability due to their locations at the headwaters of the entire watershed the arcgis select tool was used to separate such locations belonging to each vulnerability category and separate databases were created for individual categories with the locational coordinate information shown on the right side of fig 10 as examples the culvert bridge structures with scaled vulnerability are presented on the turkey creek watershed with point variation format fig 10 culverts and their on site condition information on the ws78 reported by the c of c and ung students with assistance from the santee ef personnel were used for ground truthing of the geospatial model based vulnerability assessment results appendix a even with our previous ground truthing we observed 80 accuracy on the vulnerability results obtained from our study with sampled sites verified our earlier assessments on the ws78 could not follow a detailed protocol on the culvert inventory and assessment prepared by the center for aquatic technology transfer team only in 2011 catt 2011 in a separate related streambank erosion vulnerability model study detailed ground truthing found 100 accuracy on nine sampled locations panda et al 2017 which are provided in appendix b based on on site ground truthing it was observed that out of more than 100 culverts only 11 and three culverts in the turkey creek watershed ws78 were found to be in the high and moderate vulnerability scales respectively with the rest of the structures either in the low or zero vulnerability categories this is attributed to the topographic condition of the watershed mostly a flat to low gradient one with minimal soil erosion losses appelboom et al 2002 noted that low slope along the road length and coarser textured soils in the coastal plain forest lands result in less erosion and sedimentation potential forestry best management practices manual 1989 however it was found that a higher percentage 30 of the forest road culverts bridges stream crossings in the coweeta and alum creek watersheds were under the high vulnerability category not shown both of these watersheds are on highly undulated and moderate to high gradient topography in addition the coweeta watershed is within the highest precipitation zone of the united states on the other hand the alum creek watershed has soils that are more vulnerable to erosion compared to the other two watersheds 3 1 uncertainty and limitations in general error propagation is the persistence of an error in new datasets calculated or created using datasets that originally contained errors during geospatial data analysis and model development goodchild 2018 2020 wechsler et al 2019 cumulative error propagation is certainly a big concern throughout a series of data processing operations such as those conducted in this geospatial modeling study that used aerial imageries lidar data supported dem on site surveys and gis analyzed gssurgo data in addition to instrumentation for measurements of noaa pfds supported precipitation data naip aerial images used in this study were downloaded directly from the nrcs geospatial data gateway which may contain radiometric errors although we have corrected them for geometrical errors lidar data collected a few meters above the ground were not corrected for atmospheric interference which may potentially lead to some elevation errors similarly gssurgo data may contain human induced errors and other geospatial data development process errors precipitation raster data obtained from the noaa pfds was not corrected either for any human or satellite radar based errors all these spatial and temporal data with such potential errors were used in the modeling process and automated model building therefore both error propagation and accumulation are inherent and should be acknowledged however these errors are minimal and in environmental modeling such small errors can easily be ignored goodchild 2018 therefore we believe results from this study with a more subjective approach should be acceptable for a vulnerability assessment based decision support system we could not include any culverts bridges structural vulnerability analysis based on serious structural failure due to debris flow to the structure opening and clogging it boulders and tree debris can make the erosion based clogging process faster and thus subsequent overtopping off and scour could happen we will update our vulnerability analyses modeling approach in future works as suggested by usfs and fhwa engineers to include the debris flow modeling based analysis into the model to make it more comprehensive and efficient 3 2 software and models with this study three automated geospatial models archydro based stream crossing watershed development model modified rusle model to determine eroded soil amount at stream crossings and sbeva model to determine stream crossing location scouring potential were developed they are available at ung institute for environmental spatial analysis iesa program s esri portal https iesa ung maps arcgis com home gallery html view grid sortorder desc sortfield relevance focus applications dashboards it is password protected and will be available to readers users at request however as explained the schematic of the models shown in figs 3 5 can be replicated with knowledge in esri modelbuilder application we also have developed basic python scripts for each model as supported by esri modelbuilder and the codes would be available for public use in the github site https github com drsudhanshupanda software appendix c contains an example of the arcgis modelbuilder created python script that can be replicated on modification by other researchers 4 summary and conclusions this study provides an initial assessment of the vulnerability of forest road culverts and stream crossings due to climate change induced extreme precipitation events which can result in their complete failure due to flooding undersized siltation scouring and even washout the study described a step by step methodology of developing geospatial technology based hydrology models incorporating design rainfall intensities to identify erosion hazards and vulnerability risks of forest road culverts and stream crossings in one of three study watersheds with varying areas topography soils and land use the modeling approach used the arc hydro model in creating detailed stream networks with the lidar based high resolution dem combined with digitized forest road networks culverts and stream crossings a modified rusle utilizing design precipitation intensity and sbeva geospatial hydrology models were developed and integrated to obtain erosion vulnerability on a scale of high moderate and low using the delphi method the combined vulnerability estimates from both the sbeva and modified rusle models established the most vulnerable locations of the structures which were ground truthed based on 2007 photos appendix a to be 80 accurate for culvert and streambank erosion conditions in the turkey creek watershed it is to be noted that the rusle2 model alone does not assess streambank erosion so integration of the sbeva model helps develop a more reliable decision support tool for assessing the vulnerability of these forest road culvert and stream crossing structures finally this study and associated geospatial models provide decision support tools for forest managers engineers and hydrologists to identify analyze and prioritize culvert design restoration and adaptation options substantively informing their management decisions on road infrastructure planning this can serve as a rapid assessment tool for the vulnerability of road culverts at these pilot efs in nc sc and ar with a possibility of its extension to other efs and federal lands e g national forests national parks lands managed by the bureau of land management blm under current and future climatic conditions for example an earlier version of this geospatial modeling assessment was shared with the transportation engineer at fs region 8 in tallahassee fl and the fmnf staff sc for their initial assessment of the culverts to support their timely management and on ground restoration work if needed similar geospatial modeling analyses were conducted in two other efs in nc and ar as well fig 1 it is expected that this study will also facilitate forest managers and landowners in locating inaccessible and not easily traceable road culverts and stream crossings that require repair restoration and upgrades finally this geospatial modeling study can be replicated in other forested or non forested watersheds as it is an integration of automated environmental models hydrology and morphology based to provide forest structure management decision support future studies should explore multiple on site data for enhancing the scaling factors of the delphi based weighted approach in addition future work also should explore the fs water erosion prediction program wepp model as an alternative to rusle for evaluating the erosion potential of small catchments within the watersheds the sbeva model should also consider adding an antecedent soil moisture parameter among the existing parameters as it plays a critical role in affecting peak discharges as well as sediment export in that context there is great potential to explore the use of nasa s recently available soil moisture active passive smap based soil moisture data ayres et al 2021 colliander et al 2020 in future we would update our vulnerability analyses including a debris flow model based on borga et al 2014 suggested parameters and others such as pidf 24 h duration geologic data rock type 1 and 2 and smap ecostress satellites supported soil moisture data declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to acknowledge robert gubernick watershed restoration geologist and team lead at us forest service national stream and aquatic ecology center for reviewing the manuscript and providing constructive suggestions that helped improve the quality of the manuscript in addition we are thankful to elizabeth haley former graduate student and her advisor dr timothy callahan both at the college of charleston and jose martin former undergraduate student of university of north georgia for helping conduct extensive survey of road culverts at the turkey creek study site and stephanie worley firley and shawna reid both at forest service southern research station for edits and gis map respectively the authors would like to acknowledge the usda forest service southern research station srs and region 8 for funding this study furthermore the authors extend thanks to the reviewers and editorial board members for this manuscript s review and publication appendix a photographs figure a1 below provides spatial location reference of each photograph to show their condition taken in the turkey creek during the stream survey during 2007 as an example of stream crossings damaged that corroborates to our recent geospatial hydrology integrated model based results fig a1 stream crossings culverts bridges surveyed in the year 2007 by e b haley as part of her postgraduate research photographs below shows the condition of few culverts that are found to be moderately or highly vulnerable to extreme precipitation based erosion scouring fig a1 photographs credit beth haley college of charleston sc 2007 image 2 image 3 photo a 1 photograph taken january 11 2007 of a tributary emerging from a metal culvert at point 13 on map in figure a1 photo a 2 photograph taken january 12 2007 of a floodplain in one of the tributaries at point 19 on map in figure a1 image 4 image 5 photo a 3 photograph taken january 31 2007 of a tributary flowing through a concrete culvert under a gravel road at point 40 on map in figure a1 photo a 4 photograph taken january 31 2007 of metal culverts in poor condition at point 38 on map in figure a1 image 6 image 7 photo a 5 photograph taken february 16 2007 of a metal culvert at point 54 on map in figure a1 photo a 6 photograph taken february 16 2007 of metal culvert at point 50 on map in figure a1 image 8 image 9 photo a 7 photograph taken february 16 2007 of metal culvert beginning to collapse at point 48 on map in figure a1 photo a 8 photograph taken march 7 2007 of three concrete culverts in turkey creek watershed at point 65 on map in figure a1 image 10 photo a 9 photograph taken of a second beaver dam also near whittley bridge on the main channel of turkey creek near point 67 on map in figure a1 appendix b fig b1 turkey creek watershed sbeva model result showing the ground truthed locations with 100 accuracy obtained note field photographs confirming the ground truthed locations actual field conditions are shown below fig b1 image 12 photograph location 1 image 13 photograph location 2 image 14 photograph location 4 image 15 photograph location 7 image 16 photograph location 9 appendix c python script sample example of sbeva model created with data stored in local folder as generated by arcgis modelbuilder and can be replicated by researchers with modification image 17 
25561,the goal of this study is to develop geospatial hydrology models incorporating design rainfall intensities and land morphologic features to identify erosion hazards and vulnerability risks to road culverts stream crossings in three watersheds at usda forest service long term experimental forests i coweeta hydrologic laboratory nc ii santee experimental forest sc and iii alum creek experimental forest ar these models developed in an arcgis modelbuilder platform were i streambank erosion vulnerability assessment sbeva and ii modified revised universal soil loss equation modified rusle for potential erosion and streambank vulnerability estimation the sbeva model developed using a delphi based weighted probability scale and modified rusle were integrated to identify locations of culverts stream crossings morphologically vulnerable to erosion and scouring which were ground truthed for the sc site only as the modified rusle model does not assess streambank erosion its integration with the sbeva helps to develop a better decision support tool for relevant agencies for safeguarding these road culverts stream crossings keywords streambank erosion spatial vulnerability assessment sbeva model modified revised universal soil loss equation modified rusle model extreme precipitation events automated geospatial hydrology model stream crossings delphi weighting factors 1 introduction climate change is expected to lead to more frequent extreme precipitation events kundzewicz et al 2014 flooding and landslides potentially enhancing the probability of road closures and other incidents such as roads being washed away due to culverts or bridge failures as a worst case scenario kalantari and folkeson 2013 usdot 2018 identified heavy precipitation and flooding as the vulnerability most closely related to the road culvert systems among four different climate change related vulnerabilities of forest transportation networks filosa et al 2017 projected increases in the intensity and frequency of precipitation events due to climate change easterling et al 2017 may further exacerbate flooding increasing risks of road drainage and culvert failures due to their limited carrying capacities usdot 2002 therefore stronger demands will be placed on the functionality of road drainage systems in such extreme events rees et al 2018 urban drainage systems can be quickly assessed while road crossing drainage structures and stream crossings in remote forest lands will need proactive management to prevent the occurrence of such casualties due to their inaccessibility the u s department of agriculture usda forest service fs manages a road system consisting of approximately 600 000 km of roads and at least 40 000 stream crossings i e road leadoff structures fords culverts and bridges heredia et al 2016 these structures most of which are located in forested headwater watersheds with small drainage areas catchments need an accurate estimation of peak storm discharge rates from watersheds for the design of drainage works along roadways and related infrastructure mannering and kilareski 1998 according to the u s department of transportation usdot 2018 most road crossings in the united states including the ones in forested watersheds are currently considered undersized for accommodating bankfull flow conditions that could occur about 1 or 2 years climate change induced extreme precipitation jalowska and spero 2019 and corresponding peak discharge events including their methods of estimation could have major consequences for improperly sized stream crossing infrastructure amatya et al 2021 located in headwater forested watersheds with small drainage areas other than the extreme discharge the inherent scientific reasoning for such structural failures is precarious the amount of rainfall does influence the moisture content in soil dawson 2009 but the time delay between the precipitation event and the consequent subgrade moisture content increase can vary from an almost immediate effect to a delay of up to a month fifer bizjak et al 2014 this is because the soil road surface drainage and surrounding conditions can all strongly affect the response of the road to rainfall and most importantly road scouring will increase due to this microclimatic effect fifer bizjak et al 2014 when rainfall water reaches the unbound subgrade destabilization can take place if the drainage system is not able to remove it quickly especially in cohesive soil drainage clogging would occur with subsequent structural failure fifer bizjak et al 2014 this structural failure would cause significant challenges associated with increased runoff soil erosion and sediment yields economic losses and disruption of stream connectivity thereby creating barriers to aquatic organisms heredia et al 2016 the fs developed an ecological stream simulation approach for designing and building road stream crossings intended to permit free and unrestricted movements of any aquatic species usda 2008 the approach applies to crossing structures on any transportation network including roads trails and railroads at the same time safe and cost effective hydraulic design with minimum maintenance is critically important to accommodate extreme flow that may occur during the useful life of these structures novak et al 2007 that could minimize siltation and scouring with regard to soil erosion based vulnerability stream bank erosion is expected to cause more infrastructure failures as forest roads are established in high gradient watersheds and in areas receiving higher precipitation amounts than average watersheds according to the u s environmental protection agency epa 2020 sediment from streambank erosion that contributes 80 cancienne et al 2008 langendoen and simon 2008 wilson et al 2008 of the sediment yield has been listed as one of the major and common causes of stream impairment in forested watersheds high precipitation on steep terrains could cause hillslope failures or landslides exacerbated by elevated antecedent soil moisture and debris flows that would be detrimental to the safety of road infrastructure soil scientists have analyzed gentle slopes and found that gully erosion which is a form of hillslope failure can be a significant source of stream sediment a staggering 44 of the total soil erosion worldwide poesen et al 2003 and 35 of the total soil loss in the united states nrcs 2020 were due to gully erosion historically the emphasis of erosion research has been on sheet and rill erosion and gully erosion with a hydrologic focus on surface flow processes nrcs 2020 thus the universal soil loss equation usle revised usle rusle modified usle musle and the recent version rusle2 are often used to assess surface flow induced soil erosion losses however due to the lack of experimental observations and insufficient understanding of processes governing total runoff generation consideration of subsurface flow contributions to such erosion processes leading to landslides and streambank erosion has largely been neglected in assessments and prediction technologies fox and wilson 2010 emphasized by laniak et al 2013 in their comprehensive review article in environmental modeling and software complex environmental issues need integrated environmental modeling iem approach iem is inspired by contemporary environmental problems like the one under study here which warrant higher order systems thinking and holistic solutions epa us environmental protection agency 2008 jakeman and letcher 2003 parker et al 2002 an iem approach to the holistic geospatial study of the dynamic and interdependent nature of forest topography soil characteristics antecedent soil moisture vegetation dynamics the extent of climate change induced extreme precipitation and many other environmental features that contribute to the study of physical engineering distress is needed more than ever laniak et al 2013 correctly underscored that iem concepts and early models are now more than 30 years old bailey et al 1985 cohen 1986 mackay 1991 walters 1986 with the emergence of issues related to regional scale spatial land use management climate change and ecosystem services laniak et al 2013 similar to our study there is a critical need for a different approach to combining geospatial watershed management models such as archydro rusle2 and the innovative streambank erosion spatial vulnerability assessment sbeva etc to develop a practical management decision support system this is explained by david et al 2013 through their review article on the object modeling system in environmental modeling and software accordingly the main goal of this research is to develop a comprehensive geospatial hydrology model incorporating extreme precipitation and spatial land morphologic features as an iem approach to identify erosion hazards and vulnerability of the road culverts and stream crossings employing data from three different watersheds at fs experimental forests efs in the southeastern united states the objectives of the study are to i determine spatial locations of road culverts and stream crossings using high resolution stream networks defined by conducting hydrologic analysis of the watersheds in arc hydro model platform maidment and morehouse 2002 ii conduct on site verifications of the geospatially determined locations of culverts using data from the fs iii spatially locate identify road culverts and stream crossings with erosion vulnerability in low moderate and high scales using the rusle2 model foster et al 2003 modified further as modified rusle and the sbeva model developed in this study both in the arcgis modelbuilder platform and iv determine the resultant scale based vulnerable culverts and stream crossings in each of the study watersheds by combining results from both the models modified rusle and sbeva 2 materials and methods 2 1 study area this study was conducted in three fs experimental forest watersheds in the southeastern united states varying in size soils topography forest vegetation and climate and representing i high relief mountains in north carolina nc ii moderate relief mountains in arkansas ar and iii low relief coastal plain in south carolina sc fig 1 the study watersheds in nc 35 03 n 83 25 w are located at the coweeta hydrologic laboratory chl in the appalachian mountain range within the blue ridge physiographic province fig 1 the coweeta basin 1626 ha has a humid temperate climate with a long term average annual precipitation ranging from 1794 mm at lower elevations to 2368 mm at high elevations laseter et al 2012 soils are moderately well drained on moderate to steep slopes two reference watersheds low elevation ws14 and high elevation ws27 were selected for this study due to the large elevation induced climate gradient between the two locations amatya et al 2021 the mean annual precipitation in ws27 39 ha and ws14 61 ha varies widely with 2316 mm yr and 1842 mm yr respectively the ws27 and ws14 watersheds with mean elevations of 1254 m and 878 m respectively have mean slopes of 57 and 50 respectively the vegetation cover in both watersheds is mixed hardwood the second study site ac04 in alum creek ar is located within the 1885 ha alum creek experimental forest 34 48 n 93 3 w within the upper lake winona basin of the ouachita national forest fig 1 the ac04 watershed studied in this research has a drainage area of 13 ha with a mean elevation of 300 m and a mean slope of 15 amatya et al 2021 the ac04 watershed is characterized by a humid subtropical climate with mean annual precipitation of 1321 mm yr soils are generally less than 1 m deep with high infiltration rates the vegetation cover in the watershed is pine hardwood a detailed description of the watershed is provided by adams and loughry 2008 the third study site is the turkey creek watershed ws78 draining a third order stream with an area of 5240 ha fig 1 at santee experimental forest 33 08 n 79 47 w within the francis marion national forest fmnf amatya et al 2015 ws78 is adjacent to the ws80 watershed studied together with the two above watersheds by amatya et al 2021 the watershed is the headwaters of east cooper river a major tributary of the cooper river which drains to the charleston harbor the topographic elevation of the watershed varies from 3 6 m at the outlet to 14 m above mean sea level this coastal site has a subtropical climate with hot and humid summers characterized by high intensity short duration storm events and moderate wet winters generally with low intensity long duration rain events seasonally the summer is characterized by tropical depression storms that are not uncommon the average annual daily temperature and average annual precipitations are 18 4 c and 1370 mm respectively amatya et al 2015 vegetation cover within the watershed is mostly comprised of pine forest it is instrumented with a real time stream gauge sensor and a rain gauge http waterdata usgs gov sc nwis uv site no 02172035 operated and managed by the u s geological survey usgs 2 2 data and software the following data were used in the development of the three automated geospatial hydrology models watershed characterization using archydro tool modified rusle model based road infrastructure related watershed erosion distribution and sbeva model based streambank erosion vulnerability analysis the sources of the data collected for the three ef watersheds are provided in parentheses precipitation parameter elevation regressions on independent slopes model prism 900 m data usda natural resources conservation service nrcs geospatial data gateway https datagateway nrcs usda gov 100 yr 30 min rain intensity data noaa precipitation frequency data server pfds https hdsc nws noaa gov hdsc pfds gssurgo 10 m data nrcs geospatial data gateway https datagateway nrcs usda gov lidar elevation data 1 5 m for ws80 sc department of natural resources https www dnr sc gov 3 m digital elevation model dem for alum creek and coweeta watersheds nrcs geospatial data gateway https datagateway nrcs usda gov tiger road 2010 data u s census bureau www census gov national agricultural imagery program naip 1 m land use data usda farm service agency https www fsa usda gov programs and services aerial photography imagery programs naip imagery arcgis 10 3 esri redlands ca arc hydro esri redlands ca arcmap modelbuilder esri redlands ca other spatial data such as forest road and digitized culverts trail network low resolution stream network watershed boundaries etc were obtained from the fs ef geospatial database amatya and trettin 2021 caldwell 2019 marion 2019 in addition we conducted detailed field verification of all possible road culverts and their locations using a gps unit and mapped them for our analyses 2 3 procedure this iem approach based study was completed with a synchronous integration of two advanced automatic geospatial models modified rusle and sbeva with archydro tool through professional expert knowledge assimilation using delphi based weighted matrices arc hydro model helped provide detailed stream networks all possible road drainage structures and stream crossing locations and the associated catchments for each location using the lidar based high resolution dem reconditioning and step by step hydrologic analyses the arc hydro procedure eased the task of locating coordinates which otherwise would have been cumbersome and time consuming to do manually fig 2 provides a comprehensive approach schematic of the entire study to achieve our research goal the rusle2 model a modified form of a current usda agricultural research service ars model provided detailed pixel based soil loss and total annual sediment load estimates at the locations of interest using climate change associated and historic data based precipitation data noaa atlas 14 https hdsc nws noaa gov hdsc pfds pfds map cont html and detailed high resolution land use and soil spatial data of the studied watersheds sbeva model analysis provided information about streambanks that may be vulnerable due to their susceptibility to bank erosion which could easily clog stream crossing pathways and cause subsequent scouring and ultimate failure of the road culverts 2 3 1 arc hydro supported geospatial model development for stream road crossing structures inventory development as pointed by usda forest service usfs and federal highway authority fhwa field engineers the detailed and total number of stream road crossing structures like culverts and bridges in the forested watersheds are absent we developed an automated geospatial model aided by archydro to develop an accurate inventory an available geospatial database for each of the ef study sites was updated using the latest remote sensing data including lidar aerial photography and localized field soil sample testing unpublished data for soil database development arc hydro model as an add in to arcgis 10 3 was used to delineate high resolution stream networks which differed from national hydrography dataset nhd created stream networks along with other digitized streams using the high resolution 1 5 m lidar based dem for the ws80 watershed photo science 2007 and the 3 m dem downloaded from the nrcs geospatial data gateway for other watersheds to reflect actual conditions arc hydro is capable of terrain preprocessing like dem reconditioning fill sinks fill pits terrain morphology watershed processing attribute tools and network tools for both vector and raster processing strager et al 2010 and works efficiently for forested watersheds simões 2013 the fill sinks tool was used to fill the depressions within the lidar elevation data this was to ensure that the flow and accumulation of the stream is accurate the flow direction tool was then run to create a raster flow direction from each cell to its steepest downslope neighbor this creates the actual flow path of the channels the flow accumulation tool was then run to create a flow accumulation grid from the flow direction grid the stream definition tool was then used to create a stream grid with cells from the flow accumulation grid that exceeded our user defined threshold a threshold of 5000 cells was used to obtain a very detailed stream network configuration finally the watershed delineation tool created the subwatersheds in the watershed however it was observed that the arc hydro delineated subwatersheds with a defined threshold of 5000 cells did not properly represent each of the road drainage structures culverts mapped for the watersheds together with our limited information based on an initial field visit for ground truthing we also developed a unique approach to identify locations of all possible culverts in each of the studied watersheds similar to the one by amatya et al 2013 analyzing detailed stream channel networks developed using the arc hydro modeling updated digitized road trail network and relevant gps locations we rasterized both layers and reclassified each pixel as a value of 1 then the arcgis plus tool provided us with pixel cell values of 2 which is an overlapped pixel combination of both stream and road this analysis suggested that these pixels are road crossing pixels later our ground truthing in the field confirmed our resultant road crossing structure locations providing a complete updated culvert location spatial file for all the watersheds as a next step instead of using automatically generated subwatersheds we used the arc hydro batch processing tool to delineate subwatersheds that represented each culvert location as its exit point and was present in the field the efficacy of arc hydro performance was examined later when erosion based models were developed fig 3 represents the workflow process of digitizing subwatersheds for each possible culvert location in the studied watersheds 2 3 2 modified rusle model development the rusle2 model is supported by six environmental factors renard et al 1994 as model parameters shown in eq 1 below 1 a r x k x l x s x c x p where a pixel based soil erosion rate t ha 1 yr 1 r rainfall erosivity factor developed separately using noaa pfds i30 raster k soil erodibility factor obtained from gssurgo l slope length factor usle obtained from gssurgo s slope gradient factor usle obtained from gssurgo c crop management factor developed with land use map reclassification and p conservation practice factor a constant value for a managed watershed the modified form of the rusle2 modified rusle model was developed for the watersheds with the uniquely developed r factor using noaa pfds i30 raster of the study area panda et al 2021 using the ars algorithm shown in eqs 2 and 3 the c factor was developed using a normalized difference vegetation index ndvi based formula eq 4 reeves et al 2021 and the p factor raster was generated using the reclassified naip land use classified rasters for the studied watersheds reeves et al 2021 the k l and s factor rasters were developed from the gssurgo data downloaded from nrcs geospatial data gateway fig 4 represents the schematic of the automated flow diagram for the modified rusle 2 r ke i30 where ke total kinetic energy of the rainstorm i30 30 min rainfall intensity for a 100 yr storm and e was calculated using eq 3 shown below 3 e 916 331 log10 i30 4 c 0 1 n d v i 1 2 2 3 3 sbeva geospatial model development though stream bank erosion is a natural process often occurring as a result of changes in flow regime and sediment supply of streams and rivers it is very detrimental to forested watersheds for example even a small amount of stream bank erosion can clog forest road drainage outlets and stream crossings allowing overtopping of runoff and consequently damaging the structures climate change induced extreme precipitation and or natural catchment disturbances like soil erosion also enhance the impact of streambank erosion on the structures it is to be noted according to hughes 2016 that streambank erosion rates increase with natural land cover changes potentially due to climate change induced flashy regimes changes to natural riparian vegetation channel modification and introduction of livestock e g cattle sheep deer to catchments and their unrestricted access to streams however most of those scenarios are not expected in forested watersheds though streambank erosion potential is still high due to steep terrain wildlife access to streams and erodible soil characteristics we developed the sbeva model to identify areas vulnerable to erosion at road culvert outlets stream crossings and stream banks of each study watershed using the prism precipitation raster 900 m gssurgo soil raster 10 m classified naip imagery raster 1 m and lidar based dem raster 1 5 m as shown in section 2 2 above it is to be noted and as pointed by usfs and fhwa field engineers upon their review of this research s practicality regarding the real time precipitation data availability we used the local weather stations up to date precipitation data to develop the precipitation intensity duration frequency pidf data amatya et al 2021 and embedded that with noaa created pidf raster https hdsc nws noaa gov hdsc pfds available for the study areas at a spatial resolution of 900 m each raster was pan sharpened to a similar spatial resolution of 1 m in arcgis software these 1 m spatial resolution rasters were then reclassified based on their streambank erosion vulnerability potential the study area precipitation distribution raster was reclassified by rating the amount of precipitation in millimeters that occurred in an area of interest using a 1 9 scale with 1 being the lowest and 9 being the highest higher precipitation was rated as a higher vulnerability for streambank erosion potential through jenks natural breaks algorithm based raster classification similarly land use was reclassified by its potential for streambank erosion with a scale of 1 9 i e dense forest along the streambank has a lower erosion potential and was assigned the lowest score 1 while bare soil along the stream bank was assigned the highest score 9 the dem raster was converted to a slope raster and again classified using the jenks algorithm with nine classes the lowest slope degree range was assigned the lowest streambank erosion vulnerability scale of 1 and vice versa the gssurgo raster was also reclassified to create several streambank erosion vulnerability rasters with five contributing soil characteristics including k factor soil hydrologic group soil texture slope length usle and drainage each of the characteristics was classified with a rating of 9 1 a rating of 9 was assigned to the soil with the highest potential for erosion vulnerability and a rating of 1 was assigned to the soil with the lowest potential for erosion vulnerability it is to be noted that the sbeva analyses were conducted within the 50 m buffer of the entire stream network of each ef from which each road culvert on the watershed was identified for its vulnerability using the arcgis zonal statistics tool the streambank erosion vulnerability scale 1 9 was assigned for land use and soil characteristics based rasters using the widely used delphi method weight assignment process section 2 3 3 1 once all the spatial factors contributing to the streambank erosion process were reclassified they were assimilated through a weighted sum tool available in arcgis the same delphi method based weight assignment process was used to assign percentile weights to each environmental factor during the weighted sum application it is also to be noted that land use along the stream banks influences streambank erosion more than soil drainage type the reclassified data were given weights that determined their potential for influencing erosion vulnerability each of the soil characteristics was assigned a weighted score of 10 while land use slope gradient and precipitation were assigned scores of 20 15 and 15 respectively the result of the weighted sum rated the areas of spatial erosion vulnerability on a scale of 1 9 lowest to highest the entire process was carried out for the whole stream network fig 5 denotes the sbeva model schematic as created in the arcgis modelbuilder platform 2 3 3 1 delphi method of vulnerability weight assignment the delphi method developed by the rand corporation in the 1950s aimed to reduce the range of group responses and to strive for expert consensus essential in environmental modeling where vulnerability susceptibility probability weight assignment is crucial the process as described in the method is accomplished by the feedback of individual contributions of information and knowledge as well as responses with a degree of anonymity to assign weights of vulnerability as is applied in determining spatial probability adler and ziglio 1996 angus et al 1996 linstone and turoff 1975 rowe et al 1991 along with environmental impact assessments the delphi method is effective in various fields such as information systems planning social policy public health water resource use and management and water quality assessment angus et al 1996 linstone and turoff 1975 kim and chung 2013 lee et al 2013 macmillan and marshall 2006 okoli and pawlowski 2004 we used the delphi method for developing a weighted index for individual layers that are associated with our streambank erosion vulnerability model development as discussed above the authors of this manuscript along with professional experts from usgs atlanta office city of gainesville ga and institute for environmental and spatial analysis and biology and engineering programs of the university of north georgia were asked to provide their opinion on vulnerability weight scales for all eight layers used in the model development their weighted scale was compiled and a statistically derived weight scale for each layer was used in the analysis 2 3 4 model integration the arc hydro model provided the locations of all culverts and stream crossings in each ef including the study watersheds within them the modified rusle provided pixel based estimated erosion amounts and total summed soil erosion amounts from all pixels within a subwatershed discharged to its outlet structure culvert or stream crossing each structure located in the individual ef was classified into three low moderate and high vulnerability classes based on the probable estimated erosion accumulated at that location similarly the sbeva model provided the information on a 1 9 erosion vulnerability scale for the entire stream network within each ef the sbeva model separated each subwatershed outlet using the arcgis select tool and classified it into three low moderate and high vulnerability scales finally both the modified rusle and sbeva based scales were overlain together spatially in arcgis and each structure location was assigned a resultant scale of low 1 moderate 2 and high 3 classes based on their probable vulnerability to risks of failure due to the climate change induced extreme precipitation events and associated soil erosion 3 results and discussion fig 6 shows the arc hydro and modified rusle model based delineated detailed stream network and the road culvert locations along with the estimated pixel based soil erosion analysis of the turkey creek watershed ws78 at santee ef fig 1 similar results were obtained for the other two ef watersheds at coweeta and alum creek fs personnel assisted students from the university of north georgia ung in 2010 2011 and the college of charleston cofc in 2007 in surveying each of those locations and confirmed about some of their existences as shown in fig 6 legend as aoi culverts fssurveyed for the ws78 it is to be noted that the nhd based stream network in 1 24 000 scale does not show the detailed stream network as generated with the arc hydro model and presented in fig 6 soil erosion was estimated on a pixel basis kg ha yr and grouped into three classes green yellow and red being low high and moderate erosion amounts respectively later they were summed together for individual subwatershed outlets with locations of each structure using the zonal statistics tool the summed values were classified into three classes low moderate and high based on the watershed soil erosion vulnerability as discussed in section 2 3 4 fig 7 provides r k combined ls and c factor rasters developed using an innovative approach that ultimately were combined in arcgis using the raster calculator tool it should be noted that although l and s factor rasters fig 8 were individually created from gssurgo reclassification we found more than 70 of the area of interest having no data or provided as unclassified this paucity of data is attributed to the fact that the turkey creek watershed is on low gradient forested wetlands on the lower coastal plain where soil mapping and data were obtained from scs 1980 in which many soil characteristics were broadly defined or were not completed ramcharan et al 2017 therefore another ars algorithm eq 5 supported approach was followed to create the combined ls factor raster that uses the flow accumulation and slope rasters of the watershed which were developed with the arc hydro model the studied forested watersheds are within fs national forests and are well managed sites therefore we used a value of 0 9 for all the three watersheds 5 ls factor raster pow fac 28 36 22 13 0 4 pow sin slope 0 0896 1 3 fig 9 shows streambank erosion vulnerability along with the streams crossings and road culvert locations in the turkey creek watershed ws78 classified into three vulnerability classes low moderate and high as described in section 2 3 4 as the next step the sbeva and modified rusle based vulnerability classes were combined and or overlain together the culvert locations at the intersection of these two layers were classified into three final categories low 1 moderate 2 and high 3 vulnerability based on scouring clogging of culvert openings and flood runoff overtopping that was partially ground truthed accordingly fig 10 provides these three categories for culverts bridges along with other stream crossings with low vulnerability due to their locations at the headwaters of the entire watershed the arcgis select tool was used to separate such locations belonging to each vulnerability category and separate databases were created for individual categories with the locational coordinate information shown on the right side of fig 10 as examples the culvert bridge structures with scaled vulnerability are presented on the turkey creek watershed with point variation format fig 10 culverts and their on site condition information on the ws78 reported by the c of c and ung students with assistance from the santee ef personnel were used for ground truthing of the geospatial model based vulnerability assessment results appendix a even with our previous ground truthing we observed 80 accuracy on the vulnerability results obtained from our study with sampled sites verified our earlier assessments on the ws78 could not follow a detailed protocol on the culvert inventory and assessment prepared by the center for aquatic technology transfer team only in 2011 catt 2011 in a separate related streambank erosion vulnerability model study detailed ground truthing found 100 accuracy on nine sampled locations panda et al 2017 which are provided in appendix b based on on site ground truthing it was observed that out of more than 100 culverts only 11 and three culverts in the turkey creek watershed ws78 were found to be in the high and moderate vulnerability scales respectively with the rest of the structures either in the low or zero vulnerability categories this is attributed to the topographic condition of the watershed mostly a flat to low gradient one with minimal soil erosion losses appelboom et al 2002 noted that low slope along the road length and coarser textured soils in the coastal plain forest lands result in less erosion and sedimentation potential forestry best management practices manual 1989 however it was found that a higher percentage 30 of the forest road culverts bridges stream crossings in the coweeta and alum creek watersheds were under the high vulnerability category not shown both of these watersheds are on highly undulated and moderate to high gradient topography in addition the coweeta watershed is within the highest precipitation zone of the united states on the other hand the alum creek watershed has soils that are more vulnerable to erosion compared to the other two watersheds 3 1 uncertainty and limitations in general error propagation is the persistence of an error in new datasets calculated or created using datasets that originally contained errors during geospatial data analysis and model development goodchild 2018 2020 wechsler et al 2019 cumulative error propagation is certainly a big concern throughout a series of data processing operations such as those conducted in this geospatial modeling study that used aerial imageries lidar data supported dem on site surveys and gis analyzed gssurgo data in addition to instrumentation for measurements of noaa pfds supported precipitation data naip aerial images used in this study were downloaded directly from the nrcs geospatial data gateway which may contain radiometric errors although we have corrected them for geometrical errors lidar data collected a few meters above the ground were not corrected for atmospheric interference which may potentially lead to some elevation errors similarly gssurgo data may contain human induced errors and other geospatial data development process errors precipitation raster data obtained from the noaa pfds was not corrected either for any human or satellite radar based errors all these spatial and temporal data with such potential errors were used in the modeling process and automated model building therefore both error propagation and accumulation are inherent and should be acknowledged however these errors are minimal and in environmental modeling such small errors can easily be ignored goodchild 2018 therefore we believe results from this study with a more subjective approach should be acceptable for a vulnerability assessment based decision support system we could not include any culverts bridges structural vulnerability analysis based on serious structural failure due to debris flow to the structure opening and clogging it boulders and tree debris can make the erosion based clogging process faster and thus subsequent overtopping off and scour could happen we will update our vulnerability analyses modeling approach in future works as suggested by usfs and fhwa engineers to include the debris flow modeling based analysis into the model to make it more comprehensive and efficient 3 2 software and models with this study three automated geospatial models archydro based stream crossing watershed development model modified rusle model to determine eroded soil amount at stream crossings and sbeva model to determine stream crossing location scouring potential were developed they are available at ung institute for environmental spatial analysis iesa program s esri portal https iesa ung maps arcgis com home gallery html view grid sortorder desc sortfield relevance focus applications dashboards it is password protected and will be available to readers users at request however as explained the schematic of the models shown in figs 3 5 can be replicated with knowledge in esri modelbuilder application we also have developed basic python scripts for each model as supported by esri modelbuilder and the codes would be available for public use in the github site https github com drsudhanshupanda software appendix c contains an example of the arcgis modelbuilder created python script that can be replicated on modification by other researchers 4 summary and conclusions this study provides an initial assessment of the vulnerability of forest road culverts and stream crossings due to climate change induced extreme precipitation events which can result in their complete failure due to flooding undersized siltation scouring and even washout the study described a step by step methodology of developing geospatial technology based hydrology models incorporating design rainfall intensities to identify erosion hazards and vulnerability risks of forest road culverts and stream crossings in one of three study watersheds with varying areas topography soils and land use the modeling approach used the arc hydro model in creating detailed stream networks with the lidar based high resolution dem combined with digitized forest road networks culverts and stream crossings a modified rusle utilizing design precipitation intensity and sbeva geospatial hydrology models were developed and integrated to obtain erosion vulnerability on a scale of high moderate and low using the delphi method the combined vulnerability estimates from both the sbeva and modified rusle models established the most vulnerable locations of the structures which were ground truthed based on 2007 photos appendix a to be 80 accurate for culvert and streambank erosion conditions in the turkey creek watershed it is to be noted that the rusle2 model alone does not assess streambank erosion so integration of the sbeva model helps develop a more reliable decision support tool for assessing the vulnerability of these forest road culvert and stream crossing structures finally this study and associated geospatial models provide decision support tools for forest managers engineers and hydrologists to identify analyze and prioritize culvert design restoration and adaptation options substantively informing their management decisions on road infrastructure planning this can serve as a rapid assessment tool for the vulnerability of road culverts at these pilot efs in nc sc and ar with a possibility of its extension to other efs and federal lands e g national forests national parks lands managed by the bureau of land management blm under current and future climatic conditions for example an earlier version of this geospatial modeling assessment was shared with the transportation engineer at fs region 8 in tallahassee fl and the fmnf staff sc for their initial assessment of the culverts to support their timely management and on ground restoration work if needed similar geospatial modeling analyses were conducted in two other efs in nc and ar as well fig 1 it is expected that this study will also facilitate forest managers and landowners in locating inaccessible and not easily traceable road culverts and stream crossings that require repair restoration and upgrades finally this geospatial modeling study can be replicated in other forested or non forested watersheds as it is an integration of automated environmental models hydrology and morphology based to provide forest structure management decision support future studies should explore multiple on site data for enhancing the scaling factors of the delphi based weighted approach in addition future work also should explore the fs water erosion prediction program wepp model as an alternative to rusle for evaluating the erosion potential of small catchments within the watersheds the sbeva model should also consider adding an antecedent soil moisture parameter among the existing parameters as it plays a critical role in affecting peak discharges as well as sediment export in that context there is great potential to explore the use of nasa s recently available soil moisture active passive smap based soil moisture data ayres et al 2021 colliander et al 2020 in future we would update our vulnerability analyses including a debris flow model based on borga et al 2014 suggested parameters and others such as pidf 24 h duration geologic data rock type 1 and 2 and smap ecostress satellites supported soil moisture data declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to acknowledge robert gubernick watershed restoration geologist and team lead at us forest service national stream and aquatic ecology center for reviewing the manuscript and providing constructive suggestions that helped improve the quality of the manuscript in addition we are thankful to elizabeth haley former graduate student and her advisor dr timothy callahan both at the college of charleston and jose martin former undergraduate student of university of north georgia for helping conduct extensive survey of road culverts at the turkey creek study site and stephanie worley firley and shawna reid both at forest service southern research station for edits and gis map respectively the authors would like to acknowledge the usda forest service southern research station srs and region 8 for funding this study furthermore the authors extend thanks to the reviewers and editorial board members for this manuscript s review and publication appendix a photographs figure a1 below provides spatial location reference of each photograph to show their condition taken in the turkey creek during the stream survey during 2007 as an example of stream crossings damaged that corroborates to our recent geospatial hydrology integrated model based results fig a1 stream crossings culverts bridges surveyed in the year 2007 by e b haley as part of her postgraduate research photographs below shows the condition of few culverts that are found to be moderately or highly vulnerable to extreme precipitation based erosion scouring fig a1 photographs credit beth haley college of charleston sc 2007 image 2 image 3 photo a 1 photograph taken january 11 2007 of a tributary emerging from a metal culvert at point 13 on map in figure a1 photo a 2 photograph taken january 12 2007 of a floodplain in one of the tributaries at point 19 on map in figure a1 image 4 image 5 photo a 3 photograph taken january 31 2007 of a tributary flowing through a concrete culvert under a gravel road at point 40 on map in figure a1 photo a 4 photograph taken january 31 2007 of metal culverts in poor condition at point 38 on map in figure a1 image 6 image 7 photo a 5 photograph taken february 16 2007 of a metal culvert at point 54 on map in figure a1 photo a 6 photograph taken february 16 2007 of metal culvert at point 50 on map in figure a1 image 8 image 9 photo a 7 photograph taken february 16 2007 of metal culvert beginning to collapse at point 48 on map in figure a1 photo a 8 photograph taken march 7 2007 of three concrete culverts in turkey creek watershed at point 65 on map in figure a1 image 10 photo a 9 photograph taken of a second beaver dam also near whittley bridge on the main channel of turkey creek near point 67 on map in figure a1 appendix b fig b1 turkey creek watershed sbeva model result showing the ground truthed locations with 100 accuracy obtained note field photographs confirming the ground truthed locations actual field conditions are shown below fig b1 image 12 photograph location 1 image 13 photograph location 2 image 14 photograph location 4 image 15 photograph location 7 image 16 photograph location 9 appendix c python script sample example of sbeva model created with data stored in local folder as generated by arcgis modelbuilder and can be replicated by researchers with modification image 17 
25562,this study incorporates light gradient boosting machine lightgbm to a land use regression lur model for estimating no2 and pm2 5 levels the predictions were compared with lur based machine learnings models of extreme gradient boosting xgboost and random forests rf weather research and forecasting wrf model simulated meteorological parameters community multiscale air quality modeling system cmaq simulated no2 pm2 5 concentrations land use variables and population data were used as predictor variables the model performances were evaluated through spatial and temporal cross validations cv the cv results indicated that the lightgbm model was moderately superior in no2 and pm2 5 predictions compared to the rf and xgboost models moreover the lightgbm model had high performance in no2 and pm2 5 predictions at high concentrations which is essential for risk assessment our findings demonstrate that lightgbm can greatly improve the accuracy of no2 and pm2 5 estimates keywords light gradient boosting machine extreme gradient boosting random forests community multiscale air quality model land use regression air quality forecasting model abbreviations adaboost adaptive boosting ctm chemical transport model cv cross validation r2 coefficient of determination cmaq community multiscale air quality modeling system dnn deep neural network dart dropouts meet multiple additive regression trees xgboost extreme gradient boosting pm2 5 fine particulate matter gbdt gradient boosting decision tree lur land use regression lightgbm light gradient boosting machine ml machine learning me mean error mae mean absolute error mse mean square error no2 nitrogen dioxide pbl planetary boundary layer rf random forests rmse root mean square error wrf weather research forecasting model 1 introduction exposure to air pollutants has been associated with adverse health effects in several epidemiological studies faiz et al 2012 ha et al 2018 hart et al 2013 king et al 2019 in particular nitrogen dioxide no2 and fine particulate matter pm2 5 are classified as air pollutants with potentially adverse effects on human health who 2000 accurate and precise estimates of air pollutant concentrations are essential for appropriate exposure assessments to prevent misclassification and biased risk evaluation land use regression lur models have generally been used to fulfill this necessity hoek et al 2008 in general the lur model is developed using a multiple linear regression technique incorporating monitored concentrations as the objective variable and predictor variables that may be associated with the concentrations hoek et al 2008 the obtained lur model is then applied to predict air pollutant concentrations at non monitored point locations for example it has been used for estimating ambient no2 nox pm10 and pm2 5 concentrations beelen et al 2013 henderson et al 2007 ross et al 2006 vienneau et al 2013 however the conventional method of lur model has limitations due to its difficulty in capturing nonlinearity and handling complexity among variables araki et al 2018 to overcome this limitation machine learning ml was introduced to the lur framework as it can efficiently handle nonlinearity and deal with complex interactions among the predictor variables gupta and christopher 2009 ml algorithms such as neural networks araki et al 2020 di et al 2016 and random forests rf araki et al 2018 huang et al 2018 have been successfully applied to the lur based ml model for estimating no2 and pm2 5 in particular gradient boosting decision tree gbdt is preferred for big data mining because of its accuracy efficiency and interpretability zhang and jung 2020 gbdt exhibits high robustness and generalization ability when handling complex correlated variables friedman 2001 a widely used gbdt is the extreme gradient boosting xgboost algorithm proposed by chen and guestrin 2016 several studies have applied the xgboost algorithm to the lur based ml models for estimating air pollutant concentrations their findings revealed that xgboost outperforms other ml methods including random forests rf when predicting air pollution and has higher accuracy and precision wong et al 2021 wong et al 2021 deep neural network dnn ren et al 2020 wong et al 2021 wong et al 2021 in 2017 a new gbdt based algorithm called light gradient boosting machine lightgbm was introduced by ke et al 2017 and the microsoft corporation lightgbm was developed to increase the speed of model training reduce memory usages and enhance predictability performances ke et al 2017 lightgbm constructs a model by implementing the left wise tree growth method ke et al 2017 which selects the leaf with max delta loss to grow this building approach achieves a lower penalty for a bad prediction loss ke et al 2017 besides lightgbm can limit its tree depth to efficiently avoid over fitting ke et al 2017 lightgbm shows more robust performance in highly accurate forecasts compared to rf and support vector machine sun et al 2020 in a study of time series air quality forecasting in beijing lightgbm showed superior performance in estimating pm2 5 concentration compared to other ml methods including adaptive boosting adaboost xgboost gbdt and dnn zhang et al 2019 this study suggests that lightgbm effectively handles high dimensional large scale data and missing values in the dataset therefore the application of the lightgbm algorithm to the lur based ml model to estimate air pollutant levels for higher predictive accuracy needs to be explored however it has not been yet studied in this study an innovative lur based ml model scheme by incorporating the lightgbm algorithm is proposed for estimating daily no2 and pm2 5 concentrations the overall objective is to evaluate the no2 and pm2 5 estimation performances of the lur based ml model developed from lightgbm algorithm predictor variables such as land use and community multiscale air quality modeling system cmaq simulated air pollutants are used to build the lur based ml model second the no2 and pm2 5 predictabilities made by lightgbm model were compared to those by the xgboost and rf models to determine the improvement in prediction accuracy xgboost and rf algorithms are chosen for a comparison benchmark since these algorithms are also decision tree based ml algorithms and have been used in lur based ml studies araki et al 2018 huang et al 2018 stafoggia et al 2020 zhang et al 2021 the model performances were investigated through the outcomes from the spatial and temporal cross validations cv finally the implications of the lightgbm model are outlined 2 methods 2 1 study area the study area is the kansai region which is in the central to western areas of honshu japan s main island and includes the second largest metropolitan area with osaka kobe and kyoto fig 1 the study domain is 300 300 km the study region was selected because it was affected by both long range transport from mainland asia and local pollution wakamatsu et al 2013 and shimadera et al 2016 thus the relationship between predictors and air pollutants is expected to be complicated which is suitable for model comparison 2 2 air quality measurement the daily no2 and pm2 5 observations were obtained from daily average concentrations in the year 2014 from the database of japan s regulatory monitoring network the data access websites are presented in table s1 the data from this monitoring network are collected and stored in a database by the ministry of environment japan the locations of the air quality monitoring stations that measure no2 and pm2 5 concentrations are shown in fig 1 data quality is controlled according to a uniform national standard which is made by the japanese ministry of environment the national standard covers sampling methods monitoring methods calibrations for monitoring devices maintenance for monitoring devices and data screening ministry of the environment 2010 this study utilized the observations from the general ambient air quality monitoring stations as they are positioned to prevent the direct effects of the hotspot or specific emission sources the selected air monitoring stations could represent the concentrations in our study area covering not only the urban areas but also areas where the concentrations are influenced by traffic the data from air quality monitoring stations with a temporal daily coverage of more than 80 a year was only used to ensure that it was sufficiently representative therefore a total of 360 and 204 monitoring stations were considered for no2 and pm2 5 measurements respectively the plots of the spatiotemporal variation of daily average no2 and pm2 5 concentrations in our study domain are shown in fig s1 2 3 dataset the predictor variables were selected by considering potential factors that could affect the air pollutant behaviors the prediction grids with a 1 25 km resolution were used in this study the data sources and their original spatial resolution are presented in table s1 the detail of the predictor variables is presented in table s2 2 3 1 wrf cmaq simulated predictor variables the weather research and forecasting model wrf v3 8 is used for simulating meteorological features skamarock and klemp 2008 the wrf simulation was conducted using the same physics options and objective analysis data that were used by uranishi et al 2019 three nested domains for wrf cmaq simulation cover east asia western japan and the kansai region with the horizontal resolution of 45 15 and 5 km respectively fig s2 the wrf simulated hourly meteorological fields in the innermost domain which is identical to the study area fig 1 were processed to prepare for the predictor variables for the year 2014 including planetary boundary layer pbl height wind speed air temperature relative humidity and precipitation the chemical transport model ctm was applied as a predictor variable to our prediction models because it improves the air pollutant predictability of lur models by providing spatially and temporally resolved estimates of air pollutant concentrations di et al 2019 2020 gariazzo et al 2020 ma et al 2020 ctm works by simulating the dynamics of ambient air pollutants that have high temporal variance patterns by cooperatively explaining meteorological conditions emission patterns and chemical reactions balk et al 2011 menut and bessagnet 2010 zhang et al 2012 in this study cmaq v5 2 1 was used as the ctm to simulate no2 pm2 5 concentrations with meteorological fields produced by the wrf the cmaq simulation was conducted using the same chemistry modules and air pollutant emission inventories as those used in the baseline simulation by uranishi et al 2019 except that anthropogenic emissions in china were corrected based on interannual emission trends estimated by zheng et al 2018 the cmaq simulated hourly air quality fields in the innermost domain were processed to prepare the predictor variables the correlation between the cmaq simulated no2 pm2 5 and the observed no2 pm2 5 concentrations are shown in fig s3 the wrf cmaq simulated predictor variables originally featuring a 5 km resolution were resampled to 1 25 km grids via bilinear interpolation kirkland 2010 liu et al 2018 and vienneau et al 2013 in a similar way as previous studies thongthammachart et al 2021a 2021b the wrf cmaq simulated predictor variables were not directly simulated at 1 25 km grids because of high computation cost 2 3 2 land use population and road network the built up area ratio and the agriculture area ratio in the grid cells were calculated from the national land numeric information data of japan the green area ratio was computed by summing the ratio from agricultural fields rice fields and forests provided in the land use data the population data were obtained from the japanese national census the original spatial resolution of the land use and population data is 1 km the road network dataset obtained from global map classified roads as highway primary or secondary the road area ratio was computed from the road network dataset the road length in a cell was calculated for each classification using road network data the shortest distances were calculated from a grid cell centroid to each road type and coast these values were employed as predictors distance to highway secondary road primary road and a coast the distance decay effect was introduced to the lur model framework by vienneau et al 2009 they applied the focal sum approach to the potential predictors and effectively modeled no2 in their study in this study the focal sum method with squared inverse distance as a weighting factor was applied to land use and road length variables with the objective of considering the distance decay effect araki et al 2018 these predictors were prepared to be identical with the prediction grids with a 1 25 km resolution 2 4 land use regression based machine learning models the observed no2 and pm2 5 concentrations from air quality measurement were applied as the predicted feature of the prediction models all selected predictor variables table s2 were input to build the lur based ml models because the boosting and bagging decision tree based ml has less impact from multicollinearity and robust against noise variables dormann et al 2013 ghosh et al 2016 xgboost 2022 and microsoft 2022 a feature important assessment was conducted to investigate and detect influenced features which contribute to model performance 2 4 1 light gradient boosting machine lightgbm lightgbm is one of the newest and most powerful ml techniques which uses a gradient boosting based algorithm ke et al 2017 the important hyperparameters for model tunning are learning rate learning rate number of trees num iterations number of leaves num leaves bagging fraction bagging fraction a subset of features on each iteration feature fraction learning task and maximum tree depth max depth the number of trees was set to 500 next the other hyperparameters were optimized using a grid search optimization zamani joharestani et al 2019 as summarized in table s3 in addition the lightgbm model was trained using dropouts meet multiple additive regression trees dart booster to increase the model accuracy and deal with over fitting rashmi and gilad bachrach 2015 2 4 2 random forests rf the rf technique proposed by breiman 2001 is nonparametric statistical method that can effectively handle nonlinearity of variables rf is a decision tree based ml technique which can be used for solving regression and classification problems breiman 2001 it constructs individual decision trees using a bootstrap sample of the data and splits each point in the tree based on the best of a subset of randomly chosen predictors at each point the number of variables in the subset at each node m try was set to 2p 3 where p is the number of predictor variables in the entire data set the number of trees n tree was regularly set to 500 as the default of the ranger package the other parameters used in this study were set to the default values of the ranger package wright and ziegler 2017 2 4 3 extreme gradient boosting xgboost extreme gradient boosting or xgboost is one of the successful ml techniques with a gradient boosting decision tree based algorithm apart from solving regression and classification problems it proficiently deals with missing values in the dataset xgboost produces a prediction model in the form of an ensemble of a weak prediction model in a stage wise fashion it can construct a model with parallel processing to increase speed the important hyperparameters in this method are the maximum depth of a tree max depth number of trees n estimators boosting learning rate learning rate minimum loss reduction required gamma subsample ratio of the training instances subsample subsampling of the column colsample bytree learning task and corresponding learning objective objective for a fair comparison the number of trees was set to 500 the other hyperparameters were then optimized using a grid search optimization zamani joharestani et al 2019 furthermore the xgboost models was trained with dart booster rashmi and gilad bachrach 2015 2 5 evaluation the performances of the lur based ml models were evaluated via model fitting and model cv for model fitting the lur based ml models were constructed with whole datasets then the correlation of determination r2 mean error me mean absolute error mae and root mean square error rmse were calculated between the predicted and the observed pollutant concentrations the mae and rmse values were anticipated to be as small as possible the processing time of model training was calculated from the start of lightgbm ranger and xgboost functions running to the completion of the training process of these algorithms for the lightgbm and xgboost models the trained models were used to calculate model r2 me mae and rmse values in contrast the r2 value of the rf model was calculated as eq 1 eq 1 r 2 1 m s e v a r y where y is the observed values and mse is the mean squared errors of out of bag predictions brokamp et al 2017 the predicted values from the rf model were obtained by ranger function following which the me mae and rmse were calculated from these predicted values for the cv the performances were evaluated through spatial and temporal cvs in the spatial cv five fold spatial cv de hoogh et al 2018 chen et al 2019 araki et al 2020 2021 with 50 repetitions were conducted the monitoring locations were randomly split into five groups the observations from one group of the location were removed then the remaining four groups were trained to build the lur model thereafter the constructed lur model predicted the concentrations of the removed groups this process was repeated for the remaining groups the five fold spatial cv was repeated 50 times with different random number seeds to eliminate the random effect of split data finally the cv predictions were obtained by averaging the 50 outputs and were compared with the observed values in the temporal cv the five fold dates based temporal cv with 50 repetitions was conducted for consistency with the extent of the spatial cv the dataset labelled by date were randomly split into five groups therefore all same day data stay in one group the observations from one group were removed then the remaining four groups were trained to build the lur model thereafter the procedure of temporal cv was conducted as the same with spatial cv the predicting accuracy from the cvs were investigated using the r2 values between the predicted and the observed values the me mae and rmse values were calculated through these cvs to evaluate predicting precision bias and average error magnitude respectively to determine if there was a significant improvement in the predictions made by the lightgbm model the error between the observed and predicted values predicting residuals made by the lightgbm model was statistically compared with those by xgboost and rf models the statistical methods for these comparisons were paired t and f tests hengl et al 2015 the paired t test evaluates whether the two models have the same me while the f test evaluates whether the two models have the same variance i e the same rmse assuming that the mes are the same to investigate model predicting ability at high concentrations the observed no2 and pm2 5 concentrations at the 95th percentile were selected from the spatial and temporal cvs results then the me and rmse values were calculated between the observation and prediction and compared the predicting residuals via paired t and f tests in addition spatial distributions of no2 and pm2 5 levels were illustrated the prediction maps made by lightgbm model were compared with those by rf and xgboost models 2 6 software and computation r statistical software version 4 0 5 was used for building the lightgbm xgboost and rf models r core team 2017 the raster package was used for the integration and construction of the potential predictor variables hijmans et al 2014 the lightgbm ke et al 2020 ranger wright and ziegler 2017 and xgboost chen et al 2021 packages were used for the implementation of lightgbm rf and xgboost respectively the lightgbm xgboost and rf algorithms were run on a personal computer with intel core i7 8700 3 2 ghz processor with 64 gb memory 3 results 3 1 feature importance assessment the variables importance bar plots fig 2 show the importance ordered features under lightgbm rf and xgboost models for model training of no2 and pm2 5 predictions cmaq was detected as the most influential features at all models moreover we conducted spearman s rank correlation between the observed no2 pm2 5 concentrations and the predictor variables fig s4 the results indicate that cmaq has a strong positive relation to observed no2 and pm2 5 concentrations with correlated values of 0 80 and 0 71 respectively fig s4 therefore cmaq detected by variable importance measurement is consistent with spearman s rank correlation in addition the orders of the other predictor variables are similar between the three lur based ml models in the feature importance assessment as well as the spearman s rank correlation 3 2 model performances in table 1 the model fitting results show that the lightgbm model reveals a higher r2 lower rmse and lower mae values than the rf and xgboost models in contrast the lightgbm and the xgboost models show a lower magnitude of me than those of rf model with regard to processing time for running models lightgbm requires 35 and 26 s for the running lightgbm function to train the no2 and pm2 5 models respectively moreover the rf requires 98 and 38 s for the running ranger function to train the no2 and pm2 5 models respectively the xgboost requires 719 and 392 s for running the xgboost function to train the no2 and pm2 5 models respectively therefore the lightgbm model is faster than the rf and xgboost models table 2 the model performances were evaluated through the spatial and temporal cvs and their results are displayed in table 1 fig 3 and fig 4 for the no2 model the lightgbm model had a higher cv r2 a lower rmse and a lower mae in spatial cv than the rf and xgboost models in the temporal cv the lightgbm had slightly higher cv r2 values than the rf and xgboost models however the lightgbm showed similar rmse and mae values to the rf and xgboost models in addition the lightgbm model showed similar me values to xgboost but lower me magnitude than the rf model for pm2 5 the lightgbm and rf models showed higher cv r2 values than the xgboost model in spatial cv and the three models exhibited similar r2 values in temporal cv furthermore the lightgbm model had lower rmse and mae values than the xgboost model from spatial cv similarly the lightgbm model had lower rmse value than the rf model in temporal cv and had a smaller magnitude of cv me values than the rf model at both cv aspects therefore overall the lightgbm model had higher performance than the rf and xgboost models in most of the cv results for predicting ability at high concentration 95 percentiles the lightgbm model had a smaller magnitude of me and a smaller rmse than the rf and xgboost models in most spatial and temporal cv results table s4 except for temporal cv of no2 the lightgbm had similar rmse values to the rf model 3 3 statistical analysis to investigate whether the lightgbm model improves no2 and pm2 5 predictions see in table 3 the prediction residuals from the lightgbm model were statistically compared to those from the rf and xgboost models on comparing the lightgbm and rf models the paired t test results show that the me differences are statistically significant p 0 05 in all cases this difference indicates that the residual error of the rf model me 0 1 ppb is significantly smaller than that of the lightgbm model me 0 0 ppb in other words the me of lightgbm is closer to zero than that of the rf model therefore the lightgbm model is less biased than the rf model both for pm2 5 and no2 the f test results show that the rmse differences are statistically significant p 0 05 except the temporal cv of no2 this indicates that the residual variance of the rf model is significantly larger than that of the lightgbm model therefore the lightgbm reduces bias and variance compared to the rf model for no2 and pm2 5 predictions for the comparison between lightgbm and xgboost the paired t test results show that the me differences were not statistically significant the f test results show that the variance differences are statistically significant p 0 05 except for temporal cv of no2 the results indicate that the rmse of the xgboost model is significantly larger than that of the lightgbm model except the temporal cv of pm2 5 therefore the lightgbm significantly reduced variance from the xgboost model for the three cases from the statistical comparison it can be determined that the lightgbm model has improved no2 and pm2 5 predictions compared to the rf and xgboost models furthermore δ rmse indicated that the lightgbm model improved precision compared to the rf and xgboost models by 4 5 7 2 for no2 and by 1 2 8 3 for pm2 5 predictions respectively in the statistical analysis of the high concentrations 95 percentile the paired t test indicated that the me of the lightgbm model was significantly smaller than those of the rf and xgboost models p 0 05 table s5 the f test results showed that the rmse of the lightgbm model was significantly smaller than that of rf model in the case spatial cv of no2 p 0 05 table s5 however lightgbm had significantly smaller rmse than xgboost in spatial cv for both no2 and pm2 5 p 0 05 table s5 therefore the lightgbm model has higher predictive ability for no2 and pm2 5 at high concentrations especially in term of bias correction 3 4 mapping fig 5 and fig 6 show the prediction maps generated using the lightgbm rf and xgboost models to illustrate the spatial distribution of no2 and pm2 5 concentrations respectively the daily no2 and pm2 5 concentration were the highest on january 30 and february 26 2014 respectively therefore these days were selected to illustrate the spatial distribution of these air pollutants as a worse case scenario the mappings among these three models are similar in predicting no2 and pm2 5 levels the spatial distribution of no2 is associated with the built up area ratio distribution which is representative of urban and commercial areas fig 1 in contrast the pm2 5 pattern is distributed consistently over all the kansai region although the concentration is slightly higher at areas with a high built up ratio area according to the characteristics of air pollution in japan no2 is typically from local sources meaning that higher concentrations are found in urban areas wakamatsu et al 2013 whereas pm2 5 is from long range transport of pollution from mainland asia which is more evenly dispersed over the region shimadera et al 2016 4 discussion an innovative lur based ml model which integrated the lightgbm algorithm was developed to accurately estimate daily no2 and pm2 5 levels in the kansai region of japan the lur based ml models were trained with daily one year no2 and pm2 5 datasets and then investigated model performance by model fitting and model validations the results showed that the lightgbm model had higher performance in model fitting than the rf and xgboost models table 1 furthermore the lightgbm model required less processing time than xgboost and rf models table 2 because the lightgbm is a histogram based algorithm which supports parallel learning it has better ability to process high dimensional big data compared with the other boost algorithms showing a faster training rate and higher accuracy ke et al 2017 in model validation the lightgbm model had relatively higher performance than the xgboost and rf models for no2 and pm2 5 predictions in most of the validation cases furthermore statistical analysis revealed that the lightgbm model reduced prediction bias significantly more than the rf model and reduced prediction variance significantly compared to both the rf and xgboost models this is expected as lightgbm and xgboost are boosting algorithms which can decrease both bias and variance in the dataset while the rf technique is a bagging algorithm which is better suited to reducing variance than bias lópez de prado 2020 therefore application of the lightgbm algorithm can effectively reduce both predicting bias and variance compared to rf as the lightgbm and xgboost algorithms were developed with the boosting decision tree based ml the model performance in terms of bias reduction are similar although there are small differences in some portions between the mappings in figs 5 and 6 no consistent difference was found between the maps produced by the three algorithms however the lightgbm model has several advantages such as faster processing higher predicting accuracy and reduction of both predicting bias and variance which emphasizes that lightgbm is preferable for lur models for air quality prediction the spatial cvs of three models exhibited higher r2 lower rmse and lower mae values than those of the temporal cvs in pm2 5 models the characteristics of no2 in japan revealed that no2 originated from local sources wakamatsu et al 2013 in which the spatial site to site and temporal day to day variations are assumed to be large in contrast pm2 5 is associated with long range transport shimadera et al 2016 and probably has larger temporal day to day than spatial site to site variation hence we investigated the spatially averaged temporal variation and temporally averaged spatial variation of daily no2 and pm2 5 by calculating the coefficient of variation the spatially averaged temporal variation of no2 had a slightly higher coefficient of variation than the temporally averaged spatial variation hence the no2 viability is consistent between temporal and spatial variation in contrast the spatially averaged temporal variation of pm2 5 clearly had a higher coefficient of variation value than the temporally averaged spatial variation thus pm2 5 has a larger temporal than spatial variation fig s1 therefore in terms of spatial cv day to day variation patterns at excluded sites can be inferred from those at other sites and in terms of temporal cv day to day variation patterns during excluded periods can be inferred however with lower accuracy these findings support that spatial cv is superior to temporal cv especially for pm2 5 modeling furthermore we demonstrated the advantage of the lur based ml models over the cmaq model alone in terms of no2 and pm2 5 forecasting ability the performance from the model fitting and cv outcomes figs 3 and 4 of our lur based ml models were superior to the cmaq model alone as indicated by the higher r2 and lower rmse values fig s3 moreover the lur based ml models can obviously correct overestimation of pm2 5 concentration from the cmaq model hence the lur based ml models serve as a bias correction approach to improve the predicting precision additionally the lur based ml models effectively reduce bias and variance compared to the cmaq model alone in addition our lightgbm model achieved high cv r2 between the observed and predicted concentrations of no2 and pm2 5 the performance of our model is comparable to other studies of daily no2 and pm2 5 lur based ml models incorporating rf and xgboost algorithms the cv r2 of the other no2 lur based ml model studies were 0 79 for the united states di et al 2020 and 0 74 for sweden stafoggia et al 2020 the cv r2 of the other pm2 5 lur based ml model studies were 0 86 for the united states di et al 2019 0 80 for iran zamani joharestani et al 2019 0 81 for mainland china zhang et al 2021 and 0 72 for taiwan wong et al 2017 this study makes valuable contributions as evidenced from its outcomes first this is an innovative study that incorporates the lightgbm algorithm to develop lur based ml model for accurately estimating daily ambient air pollutant levels the application of the lightgbm to lur based ml model demonstrates outstanding no2 and pm2 5 predictions this means that lightgbm can be confidently implemented in future studies of lur based ml models second the lightgbm model showed high performance in no2 and pm2 5 predictions at high concentrations which is important for the field of health and ecological risk assessment third our study successfully forecasted no2 and pm2 5 concentrations over a medium large geographical area the lur based ml model from lightgbm algorithm is applicable for air quality assessment at large geographical and long temporal scale since its advantage is accurately predicting air pollution levels with high speed computation although our evaluations of the lightgbm model revealed some advantages this study had some limitations first we did not include the feature selection approach for selecting important predictor variables however the decision tree based ml algorithms including lightgbm rf and xgboost are robust against noise variable ghosh et al 2016 xgboost 2022 and microsoft 2022 in addition there are not a large number of potential predictors in this study thus it was not essential to reduce the number of predictors nevertheless it will be better to examine the feature selection approach if there are numerous potential predictor variables in the future study because numerous variables consume high computation costs such as time and computer memory therefore this approach could be advantageous to reduce computation costs for a large dataset which contains numerous predictor variables second the daily average no2 and pm2 5 concentrations were only used for one year 2014 which is insufficient for a comprehensive investigation of long term trends of air pollution third a single ml algorithm was incorporated to the lur based model since the objective of the study was to evaluate the predicting performance of the lightgbm algorithm an implementation of an ensemble approach combining more than two algorithms to the lur based ml model would be worth examining di et al 2019 2020 this approach might result in a better performance of the lur based ml model despite these limitations an innovative lur based ml model incorporating the lightgbm algorithm was successfully developed to accurately estimate ambient no2 and pm2 5 concentrations in the kansai region of japan the lightgbm algorithm is an innovative approach to developing an effective lur based ml model for air quality prediction and epidemiological studies 5 conclusion in this study an innovative lur based ml model for air quality forecasting was developed by incorporating the lightgbm algorithm to accurately estimate daily no2 and pm2 5 levels in the kansai region of japan the lightgbm model processed faster and achieved more accurate no2 and pm2 5 predictions than the rf and xgboost models hence the lightgbm model can advantageously and accurately estimate no2 and pm2 5 concentrations in future studies we intend to apply the lur based ml model of the lightgbm algorithm to a more extensive region a longer period a multi model fusion and an epidemiological study for more comprehensive air pollutant investigations declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this study was supported by the environment research and technology development fund jpmeerf20195055 and jpmeerf20185002 of the environmental restoration and conservation agency of japan and jsps kakenhi grant number 19k12370 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105447 
25562,this study incorporates light gradient boosting machine lightgbm to a land use regression lur model for estimating no2 and pm2 5 levels the predictions were compared with lur based machine learnings models of extreme gradient boosting xgboost and random forests rf weather research and forecasting wrf model simulated meteorological parameters community multiscale air quality modeling system cmaq simulated no2 pm2 5 concentrations land use variables and population data were used as predictor variables the model performances were evaluated through spatial and temporal cross validations cv the cv results indicated that the lightgbm model was moderately superior in no2 and pm2 5 predictions compared to the rf and xgboost models moreover the lightgbm model had high performance in no2 and pm2 5 predictions at high concentrations which is essential for risk assessment our findings demonstrate that lightgbm can greatly improve the accuracy of no2 and pm2 5 estimates keywords light gradient boosting machine extreme gradient boosting random forests community multiscale air quality model land use regression air quality forecasting model abbreviations adaboost adaptive boosting ctm chemical transport model cv cross validation r2 coefficient of determination cmaq community multiscale air quality modeling system dnn deep neural network dart dropouts meet multiple additive regression trees xgboost extreme gradient boosting pm2 5 fine particulate matter gbdt gradient boosting decision tree lur land use regression lightgbm light gradient boosting machine ml machine learning me mean error mae mean absolute error mse mean square error no2 nitrogen dioxide pbl planetary boundary layer rf random forests rmse root mean square error wrf weather research forecasting model 1 introduction exposure to air pollutants has been associated with adverse health effects in several epidemiological studies faiz et al 2012 ha et al 2018 hart et al 2013 king et al 2019 in particular nitrogen dioxide no2 and fine particulate matter pm2 5 are classified as air pollutants with potentially adverse effects on human health who 2000 accurate and precise estimates of air pollutant concentrations are essential for appropriate exposure assessments to prevent misclassification and biased risk evaluation land use regression lur models have generally been used to fulfill this necessity hoek et al 2008 in general the lur model is developed using a multiple linear regression technique incorporating monitored concentrations as the objective variable and predictor variables that may be associated with the concentrations hoek et al 2008 the obtained lur model is then applied to predict air pollutant concentrations at non monitored point locations for example it has been used for estimating ambient no2 nox pm10 and pm2 5 concentrations beelen et al 2013 henderson et al 2007 ross et al 2006 vienneau et al 2013 however the conventional method of lur model has limitations due to its difficulty in capturing nonlinearity and handling complexity among variables araki et al 2018 to overcome this limitation machine learning ml was introduced to the lur framework as it can efficiently handle nonlinearity and deal with complex interactions among the predictor variables gupta and christopher 2009 ml algorithms such as neural networks araki et al 2020 di et al 2016 and random forests rf araki et al 2018 huang et al 2018 have been successfully applied to the lur based ml model for estimating no2 and pm2 5 in particular gradient boosting decision tree gbdt is preferred for big data mining because of its accuracy efficiency and interpretability zhang and jung 2020 gbdt exhibits high robustness and generalization ability when handling complex correlated variables friedman 2001 a widely used gbdt is the extreme gradient boosting xgboost algorithm proposed by chen and guestrin 2016 several studies have applied the xgboost algorithm to the lur based ml models for estimating air pollutant concentrations their findings revealed that xgboost outperforms other ml methods including random forests rf when predicting air pollution and has higher accuracy and precision wong et al 2021 wong et al 2021 deep neural network dnn ren et al 2020 wong et al 2021 wong et al 2021 in 2017 a new gbdt based algorithm called light gradient boosting machine lightgbm was introduced by ke et al 2017 and the microsoft corporation lightgbm was developed to increase the speed of model training reduce memory usages and enhance predictability performances ke et al 2017 lightgbm constructs a model by implementing the left wise tree growth method ke et al 2017 which selects the leaf with max delta loss to grow this building approach achieves a lower penalty for a bad prediction loss ke et al 2017 besides lightgbm can limit its tree depth to efficiently avoid over fitting ke et al 2017 lightgbm shows more robust performance in highly accurate forecasts compared to rf and support vector machine sun et al 2020 in a study of time series air quality forecasting in beijing lightgbm showed superior performance in estimating pm2 5 concentration compared to other ml methods including adaptive boosting adaboost xgboost gbdt and dnn zhang et al 2019 this study suggests that lightgbm effectively handles high dimensional large scale data and missing values in the dataset therefore the application of the lightgbm algorithm to the lur based ml model to estimate air pollutant levels for higher predictive accuracy needs to be explored however it has not been yet studied in this study an innovative lur based ml model scheme by incorporating the lightgbm algorithm is proposed for estimating daily no2 and pm2 5 concentrations the overall objective is to evaluate the no2 and pm2 5 estimation performances of the lur based ml model developed from lightgbm algorithm predictor variables such as land use and community multiscale air quality modeling system cmaq simulated air pollutants are used to build the lur based ml model second the no2 and pm2 5 predictabilities made by lightgbm model were compared to those by the xgboost and rf models to determine the improvement in prediction accuracy xgboost and rf algorithms are chosen for a comparison benchmark since these algorithms are also decision tree based ml algorithms and have been used in lur based ml studies araki et al 2018 huang et al 2018 stafoggia et al 2020 zhang et al 2021 the model performances were investigated through the outcomes from the spatial and temporal cross validations cv finally the implications of the lightgbm model are outlined 2 methods 2 1 study area the study area is the kansai region which is in the central to western areas of honshu japan s main island and includes the second largest metropolitan area with osaka kobe and kyoto fig 1 the study domain is 300 300 km the study region was selected because it was affected by both long range transport from mainland asia and local pollution wakamatsu et al 2013 and shimadera et al 2016 thus the relationship between predictors and air pollutants is expected to be complicated which is suitable for model comparison 2 2 air quality measurement the daily no2 and pm2 5 observations were obtained from daily average concentrations in the year 2014 from the database of japan s regulatory monitoring network the data access websites are presented in table s1 the data from this monitoring network are collected and stored in a database by the ministry of environment japan the locations of the air quality monitoring stations that measure no2 and pm2 5 concentrations are shown in fig 1 data quality is controlled according to a uniform national standard which is made by the japanese ministry of environment the national standard covers sampling methods monitoring methods calibrations for monitoring devices maintenance for monitoring devices and data screening ministry of the environment 2010 this study utilized the observations from the general ambient air quality monitoring stations as they are positioned to prevent the direct effects of the hotspot or specific emission sources the selected air monitoring stations could represent the concentrations in our study area covering not only the urban areas but also areas where the concentrations are influenced by traffic the data from air quality monitoring stations with a temporal daily coverage of more than 80 a year was only used to ensure that it was sufficiently representative therefore a total of 360 and 204 monitoring stations were considered for no2 and pm2 5 measurements respectively the plots of the spatiotemporal variation of daily average no2 and pm2 5 concentrations in our study domain are shown in fig s1 2 3 dataset the predictor variables were selected by considering potential factors that could affect the air pollutant behaviors the prediction grids with a 1 25 km resolution were used in this study the data sources and their original spatial resolution are presented in table s1 the detail of the predictor variables is presented in table s2 2 3 1 wrf cmaq simulated predictor variables the weather research and forecasting model wrf v3 8 is used for simulating meteorological features skamarock and klemp 2008 the wrf simulation was conducted using the same physics options and objective analysis data that were used by uranishi et al 2019 three nested domains for wrf cmaq simulation cover east asia western japan and the kansai region with the horizontal resolution of 45 15 and 5 km respectively fig s2 the wrf simulated hourly meteorological fields in the innermost domain which is identical to the study area fig 1 were processed to prepare for the predictor variables for the year 2014 including planetary boundary layer pbl height wind speed air temperature relative humidity and precipitation the chemical transport model ctm was applied as a predictor variable to our prediction models because it improves the air pollutant predictability of lur models by providing spatially and temporally resolved estimates of air pollutant concentrations di et al 2019 2020 gariazzo et al 2020 ma et al 2020 ctm works by simulating the dynamics of ambient air pollutants that have high temporal variance patterns by cooperatively explaining meteorological conditions emission patterns and chemical reactions balk et al 2011 menut and bessagnet 2010 zhang et al 2012 in this study cmaq v5 2 1 was used as the ctm to simulate no2 pm2 5 concentrations with meteorological fields produced by the wrf the cmaq simulation was conducted using the same chemistry modules and air pollutant emission inventories as those used in the baseline simulation by uranishi et al 2019 except that anthropogenic emissions in china were corrected based on interannual emission trends estimated by zheng et al 2018 the cmaq simulated hourly air quality fields in the innermost domain were processed to prepare the predictor variables the correlation between the cmaq simulated no2 pm2 5 and the observed no2 pm2 5 concentrations are shown in fig s3 the wrf cmaq simulated predictor variables originally featuring a 5 km resolution were resampled to 1 25 km grids via bilinear interpolation kirkland 2010 liu et al 2018 and vienneau et al 2013 in a similar way as previous studies thongthammachart et al 2021a 2021b the wrf cmaq simulated predictor variables were not directly simulated at 1 25 km grids because of high computation cost 2 3 2 land use population and road network the built up area ratio and the agriculture area ratio in the grid cells were calculated from the national land numeric information data of japan the green area ratio was computed by summing the ratio from agricultural fields rice fields and forests provided in the land use data the population data were obtained from the japanese national census the original spatial resolution of the land use and population data is 1 km the road network dataset obtained from global map classified roads as highway primary or secondary the road area ratio was computed from the road network dataset the road length in a cell was calculated for each classification using road network data the shortest distances were calculated from a grid cell centroid to each road type and coast these values were employed as predictors distance to highway secondary road primary road and a coast the distance decay effect was introduced to the lur model framework by vienneau et al 2009 they applied the focal sum approach to the potential predictors and effectively modeled no2 in their study in this study the focal sum method with squared inverse distance as a weighting factor was applied to land use and road length variables with the objective of considering the distance decay effect araki et al 2018 these predictors were prepared to be identical with the prediction grids with a 1 25 km resolution 2 4 land use regression based machine learning models the observed no2 and pm2 5 concentrations from air quality measurement were applied as the predicted feature of the prediction models all selected predictor variables table s2 were input to build the lur based ml models because the boosting and bagging decision tree based ml has less impact from multicollinearity and robust against noise variables dormann et al 2013 ghosh et al 2016 xgboost 2022 and microsoft 2022 a feature important assessment was conducted to investigate and detect influenced features which contribute to model performance 2 4 1 light gradient boosting machine lightgbm lightgbm is one of the newest and most powerful ml techniques which uses a gradient boosting based algorithm ke et al 2017 the important hyperparameters for model tunning are learning rate learning rate number of trees num iterations number of leaves num leaves bagging fraction bagging fraction a subset of features on each iteration feature fraction learning task and maximum tree depth max depth the number of trees was set to 500 next the other hyperparameters were optimized using a grid search optimization zamani joharestani et al 2019 as summarized in table s3 in addition the lightgbm model was trained using dropouts meet multiple additive regression trees dart booster to increase the model accuracy and deal with over fitting rashmi and gilad bachrach 2015 2 4 2 random forests rf the rf technique proposed by breiman 2001 is nonparametric statistical method that can effectively handle nonlinearity of variables rf is a decision tree based ml technique which can be used for solving regression and classification problems breiman 2001 it constructs individual decision trees using a bootstrap sample of the data and splits each point in the tree based on the best of a subset of randomly chosen predictors at each point the number of variables in the subset at each node m try was set to 2p 3 where p is the number of predictor variables in the entire data set the number of trees n tree was regularly set to 500 as the default of the ranger package the other parameters used in this study were set to the default values of the ranger package wright and ziegler 2017 2 4 3 extreme gradient boosting xgboost extreme gradient boosting or xgboost is one of the successful ml techniques with a gradient boosting decision tree based algorithm apart from solving regression and classification problems it proficiently deals with missing values in the dataset xgboost produces a prediction model in the form of an ensemble of a weak prediction model in a stage wise fashion it can construct a model with parallel processing to increase speed the important hyperparameters in this method are the maximum depth of a tree max depth number of trees n estimators boosting learning rate learning rate minimum loss reduction required gamma subsample ratio of the training instances subsample subsampling of the column colsample bytree learning task and corresponding learning objective objective for a fair comparison the number of trees was set to 500 the other hyperparameters were then optimized using a grid search optimization zamani joharestani et al 2019 furthermore the xgboost models was trained with dart booster rashmi and gilad bachrach 2015 2 5 evaluation the performances of the lur based ml models were evaluated via model fitting and model cv for model fitting the lur based ml models were constructed with whole datasets then the correlation of determination r2 mean error me mean absolute error mae and root mean square error rmse were calculated between the predicted and the observed pollutant concentrations the mae and rmse values were anticipated to be as small as possible the processing time of model training was calculated from the start of lightgbm ranger and xgboost functions running to the completion of the training process of these algorithms for the lightgbm and xgboost models the trained models were used to calculate model r2 me mae and rmse values in contrast the r2 value of the rf model was calculated as eq 1 eq 1 r 2 1 m s e v a r y where y is the observed values and mse is the mean squared errors of out of bag predictions brokamp et al 2017 the predicted values from the rf model were obtained by ranger function following which the me mae and rmse were calculated from these predicted values for the cv the performances were evaluated through spatial and temporal cvs in the spatial cv five fold spatial cv de hoogh et al 2018 chen et al 2019 araki et al 2020 2021 with 50 repetitions were conducted the monitoring locations were randomly split into five groups the observations from one group of the location were removed then the remaining four groups were trained to build the lur model thereafter the constructed lur model predicted the concentrations of the removed groups this process was repeated for the remaining groups the five fold spatial cv was repeated 50 times with different random number seeds to eliminate the random effect of split data finally the cv predictions were obtained by averaging the 50 outputs and were compared with the observed values in the temporal cv the five fold dates based temporal cv with 50 repetitions was conducted for consistency with the extent of the spatial cv the dataset labelled by date were randomly split into five groups therefore all same day data stay in one group the observations from one group were removed then the remaining four groups were trained to build the lur model thereafter the procedure of temporal cv was conducted as the same with spatial cv the predicting accuracy from the cvs were investigated using the r2 values between the predicted and the observed values the me mae and rmse values were calculated through these cvs to evaluate predicting precision bias and average error magnitude respectively to determine if there was a significant improvement in the predictions made by the lightgbm model the error between the observed and predicted values predicting residuals made by the lightgbm model was statistically compared with those by xgboost and rf models the statistical methods for these comparisons were paired t and f tests hengl et al 2015 the paired t test evaluates whether the two models have the same me while the f test evaluates whether the two models have the same variance i e the same rmse assuming that the mes are the same to investigate model predicting ability at high concentrations the observed no2 and pm2 5 concentrations at the 95th percentile were selected from the spatial and temporal cvs results then the me and rmse values were calculated between the observation and prediction and compared the predicting residuals via paired t and f tests in addition spatial distributions of no2 and pm2 5 levels were illustrated the prediction maps made by lightgbm model were compared with those by rf and xgboost models 2 6 software and computation r statistical software version 4 0 5 was used for building the lightgbm xgboost and rf models r core team 2017 the raster package was used for the integration and construction of the potential predictor variables hijmans et al 2014 the lightgbm ke et al 2020 ranger wright and ziegler 2017 and xgboost chen et al 2021 packages were used for the implementation of lightgbm rf and xgboost respectively the lightgbm xgboost and rf algorithms were run on a personal computer with intel core i7 8700 3 2 ghz processor with 64 gb memory 3 results 3 1 feature importance assessment the variables importance bar plots fig 2 show the importance ordered features under lightgbm rf and xgboost models for model training of no2 and pm2 5 predictions cmaq was detected as the most influential features at all models moreover we conducted spearman s rank correlation between the observed no2 pm2 5 concentrations and the predictor variables fig s4 the results indicate that cmaq has a strong positive relation to observed no2 and pm2 5 concentrations with correlated values of 0 80 and 0 71 respectively fig s4 therefore cmaq detected by variable importance measurement is consistent with spearman s rank correlation in addition the orders of the other predictor variables are similar between the three lur based ml models in the feature importance assessment as well as the spearman s rank correlation 3 2 model performances in table 1 the model fitting results show that the lightgbm model reveals a higher r2 lower rmse and lower mae values than the rf and xgboost models in contrast the lightgbm and the xgboost models show a lower magnitude of me than those of rf model with regard to processing time for running models lightgbm requires 35 and 26 s for the running lightgbm function to train the no2 and pm2 5 models respectively moreover the rf requires 98 and 38 s for the running ranger function to train the no2 and pm2 5 models respectively the xgboost requires 719 and 392 s for running the xgboost function to train the no2 and pm2 5 models respectively therefore the lightgbm model is faster than the rf and xgboost models table 2 the model performances were evaluated through the spatial and temporal cvs and their results are displayed in table 1 fig 3 and fig 4 for the no2 model the lightgbm model had a higher cv r2 a lower rmse and a lower mae in spatial cv than the rf and xgboost models in the temporal cv the lightgbm had slightly higher cv r2 values than the rf and xgboost models however the lightgbm showed similar rmse and mae values to the rf and xgboost models in addition the lightgbm model showed similar me values to xgboost but lower me magnitude than the rf model for pm2 5 the lightgbm and rf models showed higher cv r2 values than the xgboost model in spatial cv and the three models exhibited similar r2 values in temporal cv furthermore the lightgbm model had lower rmse and mae values than the xgboost model from spatial cv similarly the lightgbm model had lower rmse value than the rf model in temporal cv and had a smaller magnitude of cv me values than the rf model at both cv aspects therefore overall the lightgbm model had higher performance than the rf and xgboost models in most of the cv results for predicting ability at high concentration 95 percentiles the lightgbm model had a smaller magnitude of me and a smaller rmse than the rf and xgboost models in most spatial and temporal cv results table s4 except for temporal cv of no2 the lightgbm had similar rmse values to the rf model 3 3 statistical analysis to investigate whether the lightgbm model improves no2 and pm2 5 predictions see in table 3 the prediction residuals from the lightgbm model were statistically compared to those from the rf and xgboost models on comparing the lightgbm and rf models the paired t test results show that the me differences are statistically significant p 0 05 in all cases this difference indicates that the residual error of the rf model me 0 1 ppb is significantly smaller than that of the lightgbm model me 0 0 ppb in other words the me of lightgbm is closer to zero than that of the rf model therefore the lightgbm model is less biased than the rf model both for pm2 5 and no2 the f test results show that the rmse differences are statistically significant p 0 05 except the temporal cv of no2 this indicates that the residual variance of the rf model is significantly larger than that of the lightgbm model therefore the lightgbm reduces bias and variance compared to the rf model for no2 and pm2 5 predictions for the comparison between lightgbm and xgboost the paired t test results show that the me differences were not statistically significant the f test results show that the variance differences are statistically significant p 0 05 except for temporal cv of no2 the results indicate that the rmse of the xgboost model is significantly larger than that of the lightgbm model except the temporal cv of pm2 5 therefore the lightgbm significantly reduced variance from the xgboost model for the three cases from the statistical comparison it can be determined that the lightgbm model has improved no2 and pm2 5 predictions compared to the rf and xgboost models furthermore δ rmse indicated that the lightgbm model improved precision compared to the rf and xgboost models by 4 5 7 2 for no2 and by 1 2 8 3 for pm2 5 predictions respectively in the statistical analysis of the high concentrations 95 percentile the paired t test indicated that the me of the lightgbm model was significantly smaller than those of the rf and xgboost models p 0 05 table s5 the f test results showed that the rmse of the lightgbm model was significantly smaller than that of rf model in the case spatial cv of no2 p 0 05 table s5 however lightgbm had significantly smaller rmse than xgboost in spatial cv for both no2 and pm2 5 p 0 05 table s5 therefore the lightgbm model has higher predictive ability for no2 and pm2 5 at high concentrations especially in term of bias correction 3 4 mapping fig 5 and fig 6 show the prediction maps generated using the lightgbm rf and xgboost models to illustrate the spatial distribution of no2 and pm2 5 concentrations respectively the daily no2 and pm2 5 concentration were the highest on january 30 and february 26 2014 respectively therefore these days were selected to illustrate the spatial distribution of these air pollutants as a worse case scenario the mappings among these three models are similar in predicting no2 and pm2 5 levels the spatial distribution of no2 is associated with the built up area ratio distribution which is representative of urban and commercial areas fig 1 in contrast the pm2 5 pattern is distributed consistently over all the kansai region although the concentration is slightly higher at areas with a high built up ratio area according to the characteristics of air pollution in japan no2 is typically from local sources meaning that higher concentrations are found in urban areas wakamatsu et al 2013 whereas pm2 5 is from long range transport of pollution from mainland asia which is more evenly dispersed over the region shimadera et al 2016 4 discussion an innovative lur based ml model which integrated the lightgbm algorithm was developed to accurately estimate daily no2 and pm2 5 levels in the kansai region of japan the lur based ml models were trained with daily one year no2 and pm2 5 datasets and then investigated model performance by model fitting and model validations the results showed that the lightgbm model had higher performance in model fitting than the rf and xgboost models table 1 furthermore the lightgbm model required less processing time than xgboost and rf models table 2 because the lightgbm is a histogram based algorithm which supports parallel learning it has better ability to process high dimensional big data compared with the other boost algorithms showing a faster training rate and higher accuracy ke et al 2017 in model validation the lightgbm model had relatively higher performance than the xgboost and rf models for no2 and pm2 5 predictions in most of the validation cases furthermore statistical analysis revealed that the lightgbm model reduced prediction bias significantly more than the rf model and reduced prediction variance significantly compared to both the rf and xgboost models this is expected as lightgbm and xgboost are boosting algorithms which can decrease both bias and variance in the dataset while the rf technique is a bagging algorithm which is better suited to reducing variance than bias lópez de prado 2020 therefore application of the lightgbm algorithm can effectively reduce both predicting bias and variance compared to rf as the lightgbm and xgboost algorithms were developed with the boosting decision tree based ml the model performance in terms of bias reduction are similar although there are small differences in some portions between the mappings in figs 5 and 6 no consistent difference was found between the maps produced by the three algorithms however the lightgbm model has several advantages such as faster processing higher predicting accuracy and reduction of both predicting bias and variance which emphasizes that lightgbm is preferable for lur models for air quality prediction the spatial cvs of three models exhibited higher r2 lower rmse and lower mae values than those of the temporal cvs in pm2 5 models the characteristics of no2 in japan revealed that no2 originated from local sources wakamatsu et al 2013 in which the spatial site to site and temporal day to day variations are assumed to be large in contrast pm2 5 is associated with long range transport shimadera et al 2016 and probably has larger temporal day to day than spatial site to site variation hence we investigated the spatially averaged temporal variation and temporally averaged spatial variation of daily no2 and pm2 5 by calculating the coefficient of variation the spatially averaged temporal variation of no2 had a slightly higher coefficient of variation than the temporally averaged spatial variation hence the no2 viability is consistent between temporal and spatial variation in contrast the spatially averaged temporal variation of pm2 5 clearly had a higher coefficient of variation value than the temporally averaged spatial variation thus pm2 5 has a larger temporal than spatial variation fig s1 therefore in terms of spatial cv day to day variation patterns at excluded sites can be inferred from those at other sites and in terms of temporal cv day to day variation patterns during excluded periods can be inferred however with lower accuracy these findings support that spatial cv is superior to temporal cv especially for pm2 5 modeling furthermore we demonstrated the advantage of the lur based ml models over the cmaq model alone in terms of no2 and pm2 5 forecasting ability the performance from the model fitting and cv outcomes figs 3 and 4 of our lur based ml models were superior to the cmaq model alone as indicated by the higher r2 and lower rmse values fig s3 moreover the lur based ml models can obviously correct overestimation of pm2 5 concentration from the cmaq model hence the lur based ml models serve as a bias correction approach to improve the predicting precision additionally the lur based ml models effectively reduce bias and variance compared to the cmaq model alone in addition our lightgbm model achieved high cv r2 between the observed and predicted concentrations of no2 and pm2 5 the performance of our model is comparable to other studies of daily no2 and pm2 5 lur based ml models incorporating rf and xgboost algorithms the cv r2 of the other no2 lur based ml model studies were 0 79 for the united states di et al 2020 and 0 74 for sweden stafoggia et al 2020 the cv r2 of the other pm2 5 lur based ml model studies were 0 86 for the united states di et al 2019 0 80 for iran zamani joharestani et al 2019 0 81 for mainland china zhang et al 2021 and 0 72 for taiwan wong et al 2017 this study makes valuable contributions as evidenced from its outcomes first this is an innovative study that incorporates the lightgbm algorithm to develop lur based ml model for accurately estimating daily ambient air pollutant levels the application of the lightgbm to lur based ml model demonstrates outstanding no2 and pm2 5 predictions this means that lightgbm can be confidently implemented in future studies of lur based ml models second the lightgbm model showed high performance in no2 and pm2 5 predictions at high concentrations which is important for the field of health and ecological risk assessment third our study successfully forecasted no2 and pm2 5 concentrations over a medium large geographical area the lur based ml model from lightgbm algorithm is applicable for air quality assessment at large geographical and long temporal scale since its advantage is accurately predicting air pollution levels with high speed computation although our evaluations of the lightgbm model revealed some advantages this study had some limitations first we did not include the feature selection approach for selecting important predictor variables however the decision tree based ml algorithms including lightgbm rf and xgboost are robust against noise variable ghosh et al 2016 xgboost 2022 and microsoft 2022 in addition there are not a large number of potential predictors in this study thus it was not essential to reduce the number of predictors nevertheless it will be better to examine the feature selection approach if there are numerous potential predictor variables in the future study because numerous variables consume high computation costs such as time and computer memory therefore this approach could be advantageous to reduce computation costs for a large dataset which contains numerous predictor variables second the daily average no2 and pm2 5 concentrations were only used for one year 2014 which is insufficient for a comprehensive investigation of long term trends of air pollution third a single ml algorithm was incorporated to the lur based model since the objective of the study was to evaluate the predicting performance of the lightgbm algorithm an implementation of an ensemble approach combining more than two algorithms to the lur based ml model would be worth examining di et al 2019 2020 this approach might result in a better performance of the lur based ml model despite these limitations an innovative lur based ml model incorporating the lightgbm algorithm was successfully developed to accurately estimate ambient no2 and pm2 5 concentrations in the kansai region of japan the lightgbm algorithm is an innovative approach to developing an effective lur based ml model for air quality prediction and epidemiological studies 5 conclusion in this study an innovative lur based ml model for air quality forecasting was developed by incorporating the lightgbm algorithm to accurately estimate daily no2 and pm2 5 levels in the kansai region of japan the lightgbm model processed faster and achieved more accurate no2 and pm2 5 predictions than the rf and xgboost models hence the lightgbm model can advantageously and accurately estimate no2 and pm2 5 concentrations in future studies we intend to apply the lur based ml model of the lightgbm algorithm to a more extensive region a longer period a multi model fusion and an epidemiological study for more comprehensive air pollutant investigations declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this study was supported by the environment research and technology development fund jpmeerf20195055 and jpmeerf20185002 of the environmental restoration and conservation agency of japan and jsps kakenhi grant number 19k12370 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105447 
25563,to illustrate the power and utility of macro level decomposition tools this article presents a structured comparison of two all sector global modeling exercises that assess emissions reductions compatible with climate stabilization at roughly 1 5c above pre industrial levels it uses an expanded kaya identity combined with the lmdi logarithmic mean divisia index method to decompose the effects of key drivers of changes in emissions over time in these scenarios the most important drivers of emissions reductions include final energy intensity of economic activity the fraction of primary energy delivered by fossil fuels and emissions from non co2 warming agents land use change and the carbon intensity of fossil energy are also important the article suggests additional data modelers should release to allow more rapid analysis of results and ways to facilitate cross study comparisons such as adopting best of breed sectoral models instead of relying solely on in house expertise for model development topics global change climate change emissions reduction modeling model comparisons energy resources environmental policy environmental technology energy policy keywords greenhouse gas emissions reduction scenarios integrated assessment models climate change mitigation decomposition methods 1 5c warming scenarios energy efficiency 1 introduction to illustrate the kinds of insights available from the use of recently developed macro level decomposition tools this article compares the results from two high profile all sector global climate mitigation modeling exercises the intervention cases for many such scenarios rely heavily on carbon capture don t include changes in projected end use service demands and are not aggressive enough to achieve climate stabilization as embodied in the paris accord of well below 2 celsius above pre industrial levels ipcc 2022 we chose to explore two edge cases that assess the potential for emissions reductions compatible with climate stabilization at roughly 1 5c above pre industrial levels with modest or no deployments of carbon capture and storage ccs and some changes in service demands there are comparatively few studies of such edge cases but the ones we chose use two widely cited models created by top tier analytical teams we also chose scenarios for which the public data were detailed enough for us to apply our macro decomposition tools as described below the lack of availability of key data for many such analyses is a constraint on applying these methods more widely although data availability is gradually improving over time ipcc 2022 we apply our systematic analytical framework to raise follow on questions highlight key issues and propose areas for future research and practice previous comparative analyses have yielded real insights ipcc 2022 ipcc 2018 sognnaes et al 2021 but we are convinced that a more detailed and systematic decomposition approach will be even more advantageous to improving modeling practice for example such comparisons almost universally rely on the traditional four factor kaya identity to decompose energy sector trends but as shown in previous work koomey et al 2019 and in the analysis below that convention masks important effects and can create confusion for policy makers the tools and indicators on which we rely enable consistent comparisons with historical trends as well as allowing rapid visual discovery of differences in scenario outputs this article first presents methods reviewing the kaya identity and its offspring it then shows results digging into detail on key drivers for the two scenarios the article then turns to potential future work and ends with a summary of conclusions the supplemental information gives more detail on technical methods and results 2 methods to assess high level drivers of change in the energy sector we apply a well established convention in emissions scenario analysis known as the kaya identity kaya 1989 in our comparison of modeling studies there are other decomposition methods commonly applied to assess sectoral change for example as used in chen et al 2022 but just examining high level macro drivers can also yield important lessons and we hope that climate solutions modelers will bring such decomposition methods into their workflows to support diagnostics analysis interpretive insights and better scenario story telling de meyer et al 2020 guivarch et al 2022 as many researchers have realized over the years the kaya identity as it was originally introduced is incomplete this section presents the original kaya identity then presents an expanded version of that identity and a more comprehensive fully expanded decomposition including terms characterizing emissions outside the energy sector laid out in detail in koomey et al 2019 and expanded further in koomey et al 2022 2 1 overview of the kaya identity and its offspring the kaya identity illustrates the key drivers for fossil carbon dioxide emissions from the energy sector this identity decomposes carbon emissions as a product of aggregate economic activity per year energy intensity of economic activity and carbon intensity of energy supplied professor kaya presented this equation to help understand the implications of history and future scenarios in a simple back of the envelope way we show the familiar four factor kaya identity in equation 1 1 c a r b o n d i o x i d e e m i s s i o n s p g n p p p e g n p c pe where p is population in any year gnp is gross national product per year a measure of economic activity pe is primary energy consumed per year including conversion and energy transmission losses c is total net carbon dioxide emitted per year from the primary energy resource mix gnp p is the average income per person per year pe gnp is the primary energy intensity of the economy and c pe is the net carbon dioxide intensity of supplying primary energy the kaya identity reflects a more general identity that expresses impact i as a product of human population p affluence a and technology t ehrlich and holdren 1971 1972 population is the same in both the kaya and ipat identities gnp person represents affluence and the other two terms characterize technology this formulation implies that a larger number of people with a higher income and more extensive use of certain technologies will have a greater impact on the environment the effect of technology can be ambiguous technologies that produce and combust fossil fuels are the primary anthropogenic source of carbon dioxide while technologies for harnessing renewable energy and nuclear power sequestering carbon and improving efficiency can reduce or eliminate net anthropogenic carbon emissions in analyzing these studies we relied on methods developed for previous work koomey et al 2019 enhanced and updated for this project as explored in a recent white paper koomey et al 2022 we use graphics that summarize key drivers of emissions scenarios in the energy sector expressed in the form of an expanded kaya identity in which we disaggregate key terms to address energy supply losses the fraction of primary energy delivered by fossil fuels and fuel switching among fossil fuels this disaggregation is explained in more detail in the supplemental information part si 1 and in koomey et al 2019 we supplement the expanded kaya identity with additional graphs that tell the complete high level emissions story for each scenario the expanded kaya identity as described in koomey et al 2019 reads as shown in equation 2 2 c f o s s i l f u e l s p g n p p f e g n p p e f e pe ff p e t f c pe ff n f c t f c where c f o s s i l f u e l s represents carbon dioxide co2 emissions per year from fossil fuels combusted in the energy sector p is population in any year gnp is gross national product per year measured consistently using purchasing power parity or market exchange rates fe is final energy consumed per year pe is total primary energy consumed per year calculated using the direct equivalent deq method as discussed in koomey et al 2019 pe ff is primary energy consumed per year associated with fossil fuels tfc is total fossil energy co2 emitted per year by the primary energy resource mix nfc is net fossil co2 emitted to the atmosphere per year after accounting for fossil sequestration the ratio gnp p represents annual economic activity per person the ratio fe gnp represents final energy intensity of economic activity the ratio pe fe represents the energy system loss factor eslf which is a measure of total losses throughout the energy system supply chain the ratio peff pe we call the fossil fuel fraction which is the fraction of primary energy supplied by fossil fuels the ratio tfc peff we call the emissions intensity of fossil fuel production changes in which measure fuel switching among fossil fuels like switching power plants from being fired by coal to being fired by fossil gas or switching from oils with higher life cycle emissions to those with lower life cycle emissions as described in gordon et al 2015 koomey et al 2016 and brandt et al 2018 the ratio nfc tfc is an index characterizing the fraction of energy sector emissions that reach the atmosphere which is a measure of how much energy sector fossil sequestration a scenario contains this identity allows us to disentangle key drivers affecting scenario results in the energy sector and to show graphically which of these drivers are most important because we care about all emissions that cause warming we also need the more comprehensive relationship summarized in equation 3 which includes all emissions in terms of carbon dioxide equivalent 3 c total eq c f o s s i l f u e l s c i n d u s t r y c l a n d u s e c n o n c o 2 g a s e s e q c s b i o m a s s where c f o s s i l f u e l s is defined in equation 2 c i n d u s t r y represents carbon dioxide emissions per year from industrial processes non energy uses of fossil fuels that result in emissions such as cement steel and aluminum production some models combine these emissions with fossil fuel combustion emissions but they should be split out for clarity and internal consistency checks c l a n d u s e represents net carbon dioxide emissions per year from changes in agriculture and land use that are not associated with emissions reductions from biomass ccs this term can be negative if there is significant reforestation or afforestation c n o n c o 2 g a s e s e q represents emissions per year of other greenhouse gases converted to co2 equivalent using relative factors of global warming potential gwp 1 1 we convert emissions of the two major non co2 greenhouse gases methane and nitrous oxides to co2 equivalents using 100 year global warming potentials including climate feedbacks from the ipcc s sixth assessment report ipcc 2021 table 7 sm 7 for both models we calculate total f gas emissions in co2 equivalent using gwps from the same source using the three major categories of such gases reported by the models pfcs hfcs and sf6 c s b i o m a s s represents net negative emissions per year from sequestering carbon emissions associated with biomass combustion in effect such sequestration removes carbon from the biosphere although the timing of biomass regrowth can vary greatly introducing uncertainty into these negative emissions estimates the emissions reductions from this source must also be carefully distinguished from other land use changes if direct air capture of co2 is present in future scenarios as seems likely an additional term would be needed in equation 3 substituting equation 2 into equation 3 we get equation 4 which we refer to as our fully expanded decomposition 4 c total eq p g n p p f e g n p p e f e pe ff p e t f c pe ff n f c t f c c i n d u s t r y c l a n d u s e c n o n c o 2 g a s e s e q c s b i o m a s s equation 4 allows us to compare emissions savings in every sector from scenario modeling runs assuming that those modeling exercises release sufficient data to calculate all terms in our fully expanded decomposition 2 2 the studies we identified two modeling studies that are recent cover all sectors and analyze similarly rapid emissions reductions 1 van vuuren et al 2018 the reference scenario for this study is consonant with shared socioeconomic pathway 2 ssp 2 bauer et al 2017 fricko et al 2017 riahi et al 2017 and we use van vuuren s most aggressive intervention 2 we prefer the term intervention to describe scenarios that diverge from the reference case because it is more general than mitigation and can in principle cover intervention scenarios that result in higher emissions although such scenarios would be special cases 2 scenario that includes carbon taxes changes in service demand and non price policies sufficient to keep radiative forcing at 1 9 w m2 roughly equivalent to 1 5 c above pre industrial times 2 grübler et al 2018 this study can also be compared to the ssp 2 reference case bauer et al 2017 fricko et al 2017 riahi et al 2017 and its intervention case achieves 1 5 c it focuses on technical institutional and social changes to enable a future world with vastly lower energy intensities than in more traditional scenarios lower energy use reveals possibilities for structural change on the supply side as well as aggressive climate action not dependent on carbon capture and much less dependent on high carbon taxes both scenarios were included in the ipcc s latest working group iii report ipcc 2022 these scenarios could be considered edge cases in that they describe scenario storylines that involve aggressive emissions reductions rely in part on changes in service demands and have minimal or no ccs but use different modeling constraints and assumptions in the following section we summarize results of applying our decomposition tools to these studies in the supplemental information we give a more detailed exposition of the decomposition results for readers who want to dig deeper 3 results we begin at the highest level examining drivers of changes in emissions in the reference cases and cumulative emissions savings in the intervention cases we then discuss lessons revealed by the detailed dashboards for the two studies 3 1 reference case trends we begin by decomposing the underlying drivers of emissions growth in the reference scenarios for the two studies applying the logarithmic mean divisia index lmdi method ang 2004 to the kaya identity in the energy sector 3 details can be found in supplemental information part 1 si 1 technical methods 3 fig 1 shows the change in emissions attributable to each driver to 2100 relative to a 2020 base year expressed in gigatonnes of co2 equivalent emissions calculated component by component we focus on the cumulative change in emissions because it is directly related to changes in global temperatures to first order lahn 2020 2021 although there are complexities when summing co2 equivalent emissions of different warming agents so these results should be considered approximate this graph shows the sum of changes relative to the 2020 value in each year for each sector driver we apply the lmdi 4 ang 2004 shows lmdi methods 1 and 2 we choose method 1 because it is simpler and method 2 has no advantages for our analysis 4 approach to the energy sector kaya identity for the reference case minus 2020 energy sector emissions to conduct the decomposition in the ten year intervals the data allow we then interpolate linearly between decadal values to get annual numbers and sum the difference for each component in every year to 2100 for the additive factors other gases land use and industrial process emissions we take the difference between the reference case for each factor in each year and its value in 2020 then sum those differences to 2100 this method gives an indication of the relative importance of each driver sector over the analysis period drivers shown above the zero line push emissions up while those below the zero line push emissions down the net changes in cumulative emissions for the scenarios are indicated by the black circles which fall at about 1500 gt co2e for van vuuren and about 2100 gt co2e for grübler both scenarios represent ssp 2 but there are always differences in the underlying drivers depending on modeling practice the single biggest driver of emissions growth is increasing economic activity per person which is about five times more important than the next largest category of emissions growth population increased economic activity is mainly the result of improving economic conditions in developing countries which is a consequence of societal development and an appropriate outcome given historical inequities in income growth the third largest driver of emissions growth is other gases which is one reason why just focusing on the energy sector for emissions reductions doesn t give the full picture the carbon intensity of fossil energy which characterizes fuel switching among fossil fuels also contributes to emissions growth in the grübler reference case indicating a modest shift towards more carbon intensive fossil fuels over time reductions in energy intensity of the economy are the dominant source of reductions in emissions over time in both reference case scenarios the second most important source of emissions reductions for grübler and the third most important for van vuuren are changes in land use indicating that even in the reference case there are big changes in this source of emissions fossil fuel fraction also contributes modestly to emissions reductions over time in both cases 3 2 drivers of emissions reductions we next summarize emissions reductions in the intervention scenario compared to the reference scenario fig 2 shows the attribution of cumulative emissions savings relative to the reference case to categories as per the previous graphs and equations the same caveat about these results being approximate applies for the 2020 to 2050 and 2050 to 2100 periods we ve normalized savings to 100 of cumulative net emissions savings and those absolute savings totals are shown at the top of each bar when factors change in a way that drives net emissions up relative to the reference case like for van vuuren then the bar exceeds 100 on the positive side and shows a corresponding bar below the zero line for the factor increasing emissions instead of decreasing it the grübler intervention case shows improvements in the final energy intensity of the economy to be more important than for van vuuren to 2050 but shows this component to be less important than for van vuuren from 2050 to 2100 because of slowing improvements in emissions intensity in the later period see further discussion below efficiency improvements also slow in the later period for van vuuren but the effect is not as dramatic for grübler the fossil fuel fraction is by far the most important driver of emissions reductions accounting for about 30 of the total to 2050 and about 50 from 2050 to 2100 the contribution of fossil fuel fraction to total emission reductions also grows for van vuuren the van vuuren scenario also trades off emissions reductions from changes in fossil fuel fraction against fossil ccs and greater emissions reductions from the carbon intensity of fossil energy than in the grübler scenario the contribution of other gases to total emissions reductions is about one quarter for van vuuren and slightly less than one fifth for grübler and those percentage contributions remain roughly constant over the two analysis periods emissions reductions associated with changes in land use are front loaded in both scenarios with significantly greater reductions in the first period five emissions reduction drivers comprise about 90 of cumulative reductions final energy intensity of the economy fossil fuel fraction other gases land use and the carbon intensity of fossil energy the savings from other gases depends strongly on the assumption about global warming potentials smith and wigley 2000a 2000b in fig 2 we used the standard assumption of gwps based on a 100 year lifetime but a strong case can be made for also considering gwps integrated over a 20 year period especially for 1 5 c scenarios that reach net zero emissions in the next few decades fig 3 shows the results of altering the gwp for methane n2o and f gases to a 20 year time period the gwp of carbon dioxide equals 1 0 by definition for any time period because gwp is measured relative to co2 methane is the most important of the other gases and its 20 year gwp is two and a half times bigger than the 100 year value for n2o the 20 year gwp is the same as the 100 year gwp while for f gases some have 20 year gwps that are lower than their 100 year gwps and some show the opposite taken together these changes push savings from other gases to comprise thirty to forty percent of total cumulative emissions savings up from twenty to twenty five percent when using 100 year gwps this result does not mean we can delay reductions in carbon dioxide which take on increasing importance as time passes it does mean that focusing on the other gases particularly methane and other shorter lived warming agents is a critical element of slowing climate change in the near term interestingly van vuuren also shows emissions savings from a reduction in population growth previous research has documented that population growth affects emissions but that changes in population growth are affected by many complex ethical and human factors related more broadly to societal development o neill et al 2010 cautions that the fact that a particular phenomenon is a quantitatively significant driver of emissions does not mean that it is also an important policy lever choices that affect societal development can also affect population and thus emissions but most scenarios avoid discussing such choices as explicitly driven by the goal of emissions reductions bongaarts and o neill 2018 van vuuren states that the lower population estimates in this scenario are the result of aggressive policies promoting education referencing samir and lutz 2017 the van vuuren scenario also indicates a small increase in emissions associated with improved economic activity per person indicated by a small grey bar below the zero line grübler also shows this effect but it s much smaller 10 20 of what s shown in the van vuuren scenario these effects appear to be related to economic benefits and co benefits of various non price policies as distinct from implementation of the global carbon price 3 3 digging into the ratios dashboards we show the results in the energy sector of our fully expanded decomposition for van vuuren et al and grübler et al in figs 4 and 5 respectively each pane in the dashboard characterizes one of the ratios in the expanded kaya identity from equation 2 the green dotted lines show the path of the relevant ratio if it followed average historical growth rates for that ratio from 1900 to 2014 while the blue dotted lines show the path if it followed average historical growth rates from 1995 to 2014 the black lines indicate the path of the reference case while the red line indicates the path of the intervention or mitigation case 3 3 1 population and economic activity population and economic welfare per person look roughly similar in both scenarios population growth diverges from historical trends as expected from demographic studies in recent years samir and lutz 2017 economic activity in the reference cases is assumed not to be significantly affected by associated changes in temperature which is not necessarily a good assumption but it s a common assumption for scenarios like these ipcc 2022 bastien olvera 2019 christensen et al 2018 mann 2022 the reduction in population and increase in economic activity in the van vuuren et al intervention case show up clearly in the first two dashboard panes 3 3 2 final energy intensity of economic activity fig 6 shows expanded panes for final energy intensity of economic activity for van vuuren s and grübler s scenarios from 2010 to 2030 van vuuren s intervention scenario shows a rapid decline in the final energy intensity of economic activity fe gnp substantially exceeding historical trends as well as that of the reference scenario from 2030 to 2040 the slope of the intervention scenario curve matches the historical rate of decline from 1995 to 2014 and flattens out further as the scenario progresses grübler s scenario shows the same pattern with an even steeper decline from 2010 to 2040 the rate of decline from 2040 to 2050 roughly matching that of the 1995 to 2014 period with the curve then flattening just like for van vuuren if grübler s estimates for final energy intensity are correct it would indicate the possibility of additional emissions reductions possible for the van vuuren scenario through reduced energy intensities in the intervention scenario declines in energy intensity driven by improvements in energy efficiency electrification and changes in service demands accelerate for the first few decades of the scenario and then slow down as also shown in figs 4 and 5 above the reasons for this pattern are not entirely clear but as a general rule demand side technologies and practices like energy efficiency and changes in activity levels are represented in a much less detailed fashion in global energy models than are supply side technologies and bottom up analyses of end use efficiency tend to run out of efficiency later in these analyses because predicting technological change at a disaggregated level becomes increasingly difficult for later years wilson et al 2012 pye et al 2020 hardt et al 2019 napp et al 2019 it is also possible that there are aggregate assumptions of physical limits buried in the models that curtail energy intensity improvements as each scenario progresses whether such assumptions represent real physical limits based on the 2nd law of thermodynamics or simply modeling practice is not known but we believe the importance of this issue warrants a much deeper dive into why climate mitigation scenarios exhibit this structural similarity in final energy intensity of economic activity a deeper question is whether changes in the structure of economic growth away from increases in physical consumption and toward increases in knowledge based goods and higher quality physical goods can allow society to continue improvements in final energy intensity of economic activity far beyond what conventional models would indicate mcafee 2019 answers to this question will vary greatly country by country as demonstrated by both scenarios end use energy intensity declines can make it possible to achieve emissions reductions with less widespread deployment of carbon capture and other supply side technologies hummel 2006 called this a reduction in mitigation pressure that allows for deeper emissions reductions than would be possible with accelerated supply side options alone grübler et al 2018 also allude to intensity reductions as an enabler of more rapid and more profound supply side changes 3 3 3 energy supply system losses as shown in figs 4 and 5 above energy supply losses to 2050 in both intervention cases are lower than in both reference cases which is expected as more direct equivalent non combustion energy sources enter the supply mix koomey et al 2019 nakicenovic et al 2000 energy supply losses in both intervention cases rise in the second half of the twenty first century with losses in the van vuuren scenario exceeding those in the reference case as fossil ccs which has higher system losses than conventional technologies enters the supply mix the grübler scenario also shows rising supply losses in the intervention case over time but these losses remain lower than those in the reference case for the entire analysis period 3 3 4 fossil fuel fraction of primary energy fig 7 shows expanded versions of the dashboard panes devoted to the fossil fuel fraction of primary energy both intervention scenarios show declines in this fraction with van vuuren approaching about one third of 2010 levels by 2100 and grübler showing total fossil phaseout by about 2070 or so this difference is primarily attributable to the use of fossil ccs in the van vuuren scenario under strict emissions reduction goals scenarios with ccs continue to use fossil fuels while those without do not which is one reason why fossil ccs is technology often favored by the fossil fuel industry 3 3 5 carbon intensity of fossil energy fig 8 shows expanded panes from the dashboard characterizing the carbon intensity of fossil energy supply this factor increases in both reference cases indicating slightly more emissions intensive use of fossil fuels over time both intervention cases trend towards the asymptote of natural gas emissions but van vuuren s scenario approaches that goal much more quickly additional emissions savings could thus be realized in the grübler intervention scenario if the shift to natural gas happened as quickly as shown in the van vuuren scenario why the carbon intensity of fossil fuel supply increases slightly towards the end of the analysis period for van vuuren is a question worthy of further exploration 3 3 6 graphs of primary energy that summarize major trends in key drivers one way to answer some of the queries raised above is by graphing primary energy over time by source as shown in fig 9 a and fig 9 b for the van vuuren and grübler intervention cases respectively graphs like these show trends in total primary energy they also implicitly show trends in final energy because the energy supply loss factor is close to 1 0 throughout the analysis period for both scenarios in addition they implicitly show the fossil fuel fraction as well as the mix of fossil fuels contributing to meeting service demands in any year fig 9a for van vuuren shows that total primary energy drops rapidly to 2040 in part because of rapid improvements in the final energy intensity of economic activity and in part because of the rapid displacement of fossil combustion with direct equivalent sources which avoids combustion losses as improvements in final energy intensity slow down mid century and carbon capture technologies with high system losses become more widely used total primary energy starts rising reaching 2020 levels by 2100 fossil gas consumption stays roughly constant to 2040 and then rises modestly to 2070 then falls to 2100 petroleum use falls to mid century then remains roughly flat while coal use falls to mid century and then rises to 2100 this latter finding explains why the carbon intensity of fossil fuel supply goes up in the last couple of decades of the 21st century for this scenario fig 9b shows the same graph for grübler illustrating big differences with the van vuuren intervention scenario primary and final energy decline substantially by mid century and then remain roughly flat to 2100 coal is almost completely gone by 2050 petroleum by 2070 and fossil gas by 2090 fossil gas represents a higher percentage of primary fossil energy supplied from 2020 to 2050 in the van vuuren intervention case than in the grübler intervention case with this gap growing over time these data explain why the carbon intensity of fossil energy supplied falls more rapidly early in the van vuuren intervention case 3 4 digging into the additive factors dashboard now we turn to insights from our additive factors dashboards which show emissions changes over the analysis period by each factor identified in equation 4 above expressed in gt co2 equivalent per year figs 10 and 11 show that the energy sector is the largest contributor to emissions reductions but other non co2 warming agents and land use changes are also important there are relatively small savings from industrial process emissions and none from biomass ccs in either scenario 3 4 1 land use change fig 12 shows expanded versions of the dashboard panes for carbon dioxide emissions from land use changes to make them easier to see some obvious questions emerge from casual examination of these graphs what drives emissions in both references cases to decline over time in the van vuuren case after rising to 2030 why do net emissions in the van vuuren intervention case become less negative after mid century what drives the rapid emissions reductions in the grübler intervention scenario to 2030 and why then do emissions reductions proceed less rapidly after 2030 3 4 2 industrial processes fig 13 shows expanded versions of the dashboard panes for carbon dioxide emissions from industrial processes mainly cement the reference cases are identical taken from van vuuren because the ssp2 reference case used by grübler doesn t split industrial process emissions from energy sector emissions the van vuuren intervention case comes directly from that study s outputs but we infer the intervention case for grübler using fossil energy combustion and related emissions factors then subtracting out inferred energy sector emissions from the sum of energy sector plus industrial process emissions both intervention cases reflect changes in emissions from industrial processes but it s not entirely clear whether such changes are consistent with the trajectory of energy infrastructure construction in these scenarios this issue is a more general one that needs further attention from the modeling community additional transparency is needed with data related to industrial process emissions separate from energy sector emissions to ensure internal consistency of the scenarios the van vuuren intervention case also has unexplained oscillations that clearly warrant futher investigation 3 4 3 non co2 warming agents fig 14 shows expanded versions of the dashboard panes for carbon dioxide emissions from non co2 warming agents like methane nitrous oxide and other pollutants using 100 year gwps the reference cases appear to be comparable but the intervention cases show much more rapid and effective mitigation of non co2 pollutants in the van vuuren scenario if the van vuuren assessment is correct there is clearly room for more reductions in other warming agents in the grübler scenario 4 recommendations for future work we are hopeful that these decomposition tools can support and strengthen the next iteration of the ipcc s working group iii report due out in the mid to late 2020s but that will depend on modelers integrating these tools into their workflows and and using them to generate insights wh which should also speed up the process of developing scenarios and evaluating results 4 1 more studies of aggressive emissions reduction scenarios are needed in our view there are too few scenarios with aggressive emissions reductions and such emissions reductions are less well studied than they should be these edge cases are the most likely to teach us something useful about what ultimate emissions reductions will be possible because they push the boundaries of our imagination the most comprehensive summaries of such scenarios are found in ipcc 2022 and ipcc 2018 but as with all fast changing research areas findings become obsolete quickly as suggested by three of the comparisons above improvements in the intensity of final energy use the emissions intensity of fossil fuels and emissions from non co2 warming agents analytical focus on combining the best parts of the most aggressive scenarios from best of breed analyses can help policy makers map the true limits of what society can achieve we are also convinced that comparing analyses that are quite different in their underlying assumptions and drivers can yield important insights sognnaes et al 2021 the two scenarios presented above are of a similar type but comparing scenarios like these to others that have different core assumptions about drivers and available technologies should be an important part of scenario decomposition efforts going forward 4 2 addressing unanswered questions use of the analytical tools highlighted above can help identify and diagnose unexplained trends and discontinuities an example is the common pattern of accelerated energy intensity reductions in the first two or three decades of intervention cases but a sudden slowing of those reductions around the mid twenty first century identifying and researching puzzles like these can lead to more rapid improvements in modeling practice as well as increased understanding of the true constraints holding back rapid climate action 4 3 we need more data we need more data from global energy models to do full decompositions to more fully understand the implications of individual studies and of the body of literature as a whole the modeling community must routinely release more comprehensive data beyond what is now standard practice policy makers and funders can and should encourage more complete disclosure our experience indicates that more comprehensive better defined and more accurate data are needed in at least four areas 1 more disaggregated data to facilitate analysis and scenario comparisons it is critical that data be disaggregated sufficiently for example industrial process carbon dioxide emissions should be reported separately from energy sector emissions methane and nitrous oxide emissions should at a minimum be split between those associated with fossil fuel production and those non fossil emissions associated with industrial processes agriculture and other human activities finally f gases should be split and reported by species not reported only as a total otherwise it is hard to adjust for different global warming potentials and assess policy effects on different f gases 2 endogenous treatment of industrial sector process emissions industrial process emissions most of which are associated with construction materials like cement steel aluminum and glass should be modeled as a function of the numbers and types of new energy production facilities because the material requirements of future pathways can differ substantially pauliuk et al 2017 simultaneously modeling materials flows process emissions and the economic factors affecting expansion of certain industries as in for example cao et al 2019 and iea 2019 is an approach more analysts should consider similarly ccs for industrial sector process emissions should be tracked separately from energy sector ccs 3 electricity sector more detail on inputs and outputs to the electricity sector are also important as electrification is a key component of many recent modeling exercises with significant electricity generation being allocated to hydrogen production and power to gas in future scenarios precise tracking is complicated but necessary care will be needed to ensure correct accounting and accurate characterization of energy supply losses for these technologies 4 interactions between related sectors scenario decomposition tools allow for more accurate characterization of iterations between linked sectors and technologies like land use biofuels biomass ccs and agriculture but consistent system boundaries and accurate data collection are essential to creating meaningful comparisons decomposition tools can serve important diagnostic and research functions but the results they produce are only as good as their input data understanding the inputs needed for comprehensive decomposition analyses can help researchers to organize and structure their models to produce the most useful results 4 4 integrating decomposition analysis into the modeling process we built our decomposition tools in microsoft excel because they grew out of earlier work that used that platform hummel 2006 as our work has progressed we ve come to realize that only tools that can be run by the modeling teams themselves and fully integrated into their workflows will gain wide acceptance and use and that precludes an excel model run by third parties for this reason we are turning our attention to creating an open source python library that will allow modelers to generate the decomposition results as part of their modeling process integrated with tools now under active development by iiasa and other modeling groups huppmann et al 2021 we hope that this effort will result in much more widespread use of these diagnostic analytical tools and speed up the process of scenario design creation and implementation 5 conclusions stabilizing global temperatures at well below 2 c will require immediate and sustained emission reductions as well as retirement of fossil capital before it reaches its accounting lifetime ipcc 2022 the two scenarios we examine while each aggressive in its own ways contains only a subset of the possibilities modeling is a human process scenario analyses reflect the strengths weaknesses and knowledge of the modeling teams that create them articles summarizing analyses contain different views of their results but because each modeling team chooses what to emphasize it is difficult to compare results across studies in a consistent fashion developing standardized comparison tools and integrating them into modeling workflows is one way to enable more rapid cross study comparisons the modeling community should consider and implement ways to speed up comparisons and harmonization among modeling efforts and funders should support this vital work because it will allow us to identify more potentially promising pathways than we would be able to do in the absence of such efforts consistent comparisons of scenario drivers using systematic analytical tools can enable harmonization of resource potentials technology costs and deployment rates with improved analytical tools we are hopeful that scenario comparison exercises like the ones our decomposition tools enable will help inform development of rapid emissions reduction policies in the future declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests jonathan koomey koomey analytics reports financial support was provided by world resources institute acknowledgements we are grateful for the financial support of world resources institute for this work many colleagues contributed comments insights and or data along the way including four anonymous reviewers tim duane oliver fricko arnulf grübler mathijs harmsen nate hultman holmes hummel daniel huppman dan kammen florentin krause volker krey amory lovins glen peters keywan riahi joeri rogelj simon de stercke sven teske detlef van vuuren david victor and john weyant any errors are the responsibility of the authors appendix a supplementary data the following is the supplementary data related to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2022 105426 
25563,to illustrate the power and utility of macro level decomposition tools this article presents a structured comparison of two all sector global modeling exercises that assess emissions reductions compatible with climate stabilization at roughly 1 5c above pre industrial levels it uses an expanded kaya identity combined with the lmdi logarithmic mean divisia index method to decompose the effects of key drivers of changes in emissions over time in these scenarios the most important drivers of emissions reductions include final energy intensity of economic activity the fraction of primary energy delivered by fossil fuels and emissions from non co2 warming agents land use change and the carbon intensity of fossil energy are also important the article suggests additional data modelers should release to allow more rapid analysis of results and ways to facilitate cross study comparisons such as adopting best of breed sectoral models instead of relying solely on in house expertise for model development topics global change climate change emissions reduction modeling model comparisons energy resources environmental policy environmental technology energy policy keywords greenhouse gas emissions reduction scenarios integrated assessment models climate change mitigation decomposition methods 1 5c warming scenarios energy efficiency 1 introduction to illustrate the kinds of insights available from the use of recently developed macro level decomposition tools this article compares the results from two high profile all sector global climate mitigation modeling exercises the intervention cases for many such scenarios rely heavily on carbon capture don t include changes in projected end use service demands and are not aggressive enough to achieve climate stabilization as embodied in the paris accord of well below 2 celsius above pre industrial levels ipcc 2022 we chose to explore two edge cases that assess the potential for emissions reductions compatible with climate stabilization at roughly 1 5c above pre industrial levels with modest or no deployments of carbon capture and storage ccs and some changes in service demands there are comparatively few studies of such edge cases but the ones we chose use two widely cited models created by top tier analytical teams we also chose scenarios for which the public data were detailed enough for us to apply our macro decomposition tools as described below the lack of availability of key data for many such analyses is a constraint on applying these methods more widely although data availability is gradually improving over time ipcc 2022 we apply our systematic analytical framework to raise follow on questions highlight key issues and propose areas for future research and practice previous comparative analyses have yielded real insights ipcc 2022 ipcc 2018 sognnaes et al 2021 but we are convinced that a more detailed and systematic decomposition approach will be even more advantageous to improving modeling practice for example such comparisons almost universally rely on the traditional four factor kaya identity to decompose energy sector trends but as shown in previous work koomey et al 2019 and in the analysis below that convention masks important effects and can create confusion for policy makers the tools and indicators on which we rely enable consistent comparisons with historical trends as well as allowing rapid visual discovery of differences in scenario outputs this article first presents methods reviewing the kaya identity and its offspring it then shows results digging into detail on key drivers for the two scenarios the article then turns to potential future work and ends with a summary of conclusions the supplemental information gives more detail on technical methods and results 2 methods to assess high level drivers of change in the energy sector we apply a well established convention in emissions scenario analysis known as the kaya identity kaya 1989 in our comparison of modeling studies there are other decomposition methods commonly applied to assess sectoral change for example as used in chen et al 2022 but just examining high level macro drivers can also yield important lessons and we hope that climate solutions modelers will bring such decomposition methods into their workflows to support diagnostics analysis interpretive insights and better scenario story telling de meyer et al 2020 guivarch et al 2022 as many researchers have realized over the years the kaya identity as it was originally introduced is incomplete this section presents the original kaya identity then presents an expanded version of that identity and a more comprehensive fully expanded decomposition including terms characterizing emissions outside the energy sector laid out in detail in koomey et al 2019 and expanded further in koomey et al 2022 2 1 overview of the kaya identity and its offspring the kaya identity illustrates the key drivers for fossil carbon dioxide emissions from the energy sector this identity decomposes carbon emissions as a product of aggregate economic activity per year energy intensity of economic activity and carbon intensity of energy supplied professor kaya presented this equation to help understand the implications of history and future scenarios in a simple back of the envelope way we show the familiar four factor kaya identity in equation 1 1 c a r b o n d i o x i d e e m i s s i o n s p g n p p p e g n p c pe where p is population in any year gnp is gross national product per year a measure of economic activity pe is primary energy consumed per year including conversion and energy transmission losses c is total net carbon dioxide emitted per year from the primary energy resource mix gnp p is the average income per person per year pe gnp is the primary energy intensity of the economy and c pe is the net carbon dioxide intensity of supplying primary energy the kaya identity reflects a more general identity that expresses impact i as a product of human population p affluence a and technology t ehrlich and holdren 1971 1972 population is the same in both the kaya and ipat identities gnp person represents affluence and the other two terms characterize technology this formulation implies that a larger number of people with a higher income and more extensive use of certain technologies will have a greater impact on the environment the effect of technology can be ambiguous technologies that produce and combust fossil fuels are the primary anthropogenic source of carbon dioxide while technologies for harnessing renewable energy and nuclear power sequestering carbon and improving efficiency can reduce or eliminate net anthropogenic carbon emissions in analyzing these studies we relied on methods developed for previous work koomey et al 2019 enhanced and updated for this project as explored in a recent white paper koomey et al 2022 we use graphics that summarize key drivers of emissions scenarios in the energy sector expressed in the form of an expanded kaya identity in which we disaggregate key terms to address energy supply losses the fraction of primary energy delivered by fossil fuels and fuel switching among fossil fuels this disaggregation is explained in more detail in the supplemental information part si 1 and in koomey et al 2019 we supplement the expanded kaya identity with additional graphs that tell the complete high level emissions story for each scenario the expanded kaya identity as described in koomey et al 2019 reads as shown in equation 2 2 c f o s s i l f u e l s p g n p p f e g n p p e f e pe ff p e t f c pe ff n f c t f c where c f o s s i l f u e l s represents carbon dioxide co2 emissions per year from fossil fuels combusted in the energy sector p is population in any year gnp is gross national product per year measured consistently using purchasing power parity or market exchange rates fe is final energy consumed per year pe is total primary energy consumed per year calculated using the direct equivalent deq method as discussed in koomey et al 2019 pe ff is primary energy consumed per year associated with fossil fuels tfc is total fossil energy co2 emitted per year by the primary energy resource mix nfc is net fossil co2 emitted to the atmosphere per year after accounting for fossil sequestration the ratio gnp p represents annual economic activity per person the ratio fe gnp represents final energy intensity of economic activity the ratio pe fe represents the energy system loss factor eslf which is a measure of total losses throughout the energy system supply chain the ratio peff pe we call the fossil fuel fraction which is the fraction of primary energy supplied by fossil fuels the ratio tfc peff we call the emissions intensity of fossil fuel production changes in which measure fuel switching among fossil fuels like switching power plants from being fired by coal to being fired by fossil gas or switching from oils with higher life cycle emissions to those with lower life cycle emissions as described in gordon et al 2015 koomey et al 2016 and brandt et al 2018 the ratio nfc tfc is an index characterizing the fraction of energy sector emissions that reach the atmosphere which is a measure of how much energy sector fossil sequestration a scenario contains this identity allows us to disentangle key drivers affecting scenario results in the energy sector and to show graphically which of these drivers are most important because we care about all emissions that cause warming we also need the more comprehensive relationship summarized in equation 3 which includes all emissions in terms of carbon dioxide equivalent 3 c total eq c f o s s i l f u e l s c i n d u s t r y c l a n d u s e c n o n c o 2 g a s e s e q c s b i o m a s s where c f o s s i l f u e l s is defined in equation 2 c i n d u s t r y represents carbon dioxide emissions per year from industrial processes non energy uses of fossil fuels that result in emissions such as cement steel and aluminum production some models combine these emissions with fossil fuel combustion emissions but they should be split out for clarity and internal consistency checks c l a n d u s e represents net carbon dioxide emissions per year from changes in agriculture and land use that are not associated with emissions reductions from biomass ccs this term can be negative if there is significant reforestation or afforestation c n o n c o 2 g a s e s e q represents emissions per year of other greenhouse gases converted to co2 equivalent using relative factors of global warming potential gwp 1 1 we convert emissions of the two major non co2 greenhouse gases methane and nitrous oxides to co2 equivalents using 100 year global warming potentials including climate feedbacks from the ipcc s sixth assessment report ipcc 2021 table 7 sm 7 for both models we calculate total f gas emissions in co2 equivalent using gwps from the same source using the three major categories of such gases reported by the models pfcs hfcs and sf6 c s b i o m a s s represents net negative emissions per year from sequestering carbon emissions associated with biomass combustion in effect such sequestration removes carbon from the biosphere although the timing of biomass regrowth can vary greatly introducing uncertainty into these negative emissions estimates the emissions reductions from this source must also be carefully distinguished from other land use changes if direct air capture of co2 is present in future scenarios as seems likely an additional term would be needed in equation 3 substituting equation 2 into equation 3 we get equation 4 which we refer to as our fully expanded decomposition 4 c total eq p g n p p f e g n p p e f e pe ff p e t f c pe ff n f c t f c c i n d u s t r y c l a n d u s e c n o n c o 2 g a s e s e q c s b i o m a s s equation 4 allows us to compare emissions savings in every sector from scenario modeling runs assuming that those modeling exercises release sufficient data to calculate all terms in our fully expanded decomposition 2 2 the studies we identified two modeling studies that are recent cover all sectors and analyze similarly rapid emissions reductions 1 van vuuren et al 2018 the reference scenario for this study is consonant with shared socioeconomic pathway 2 ssp 2 bauer et al 2017 fricko et al 2017 riahi et al 2017 and we use van vuuren s most aggressive intervention 2 we prefer the term intervention to describe scenarios that diverge from the reference case because it is more general than mitigation and can in principle cover intervention scenarios that result in higher emissions although such scenarios would be special cases 2 scenario that includes carbon taxes changes in service demand and non price policies sufficient to keep radiative forcing at 1 9 w m2 roughly equivalent to 1 5 c above pre industrial times 2 grübler et al 2018 this study can also be compared to the ssp 2 reference case bauer et al 2017 fricko et al 2017 riahi et al 2017 and its intervention case achieves 1 5 c it focuses on technical institutional and social changes to enable a future world with vastly lower energy intensities than in more traditional scenarios lower energy use reveals possibilities for structural change on the supply side as well as aggressive climate action not dependent on carbon capture and much less dependent on high carbon taxes both scenarios were included in the ipcc s latest working group iii report ipcc 2022 these scenarios could be considered edge cases in that they describe scenario storylines that involve aggressive emissions reductions rely in part on changes in service demands and have minimal or no ccs but use different modeling constraints and assumptions in the following section we summarize results of applying our decomposition tools to these studies in the supplemental information we give a more detailed exposition of the decomposition results for readers who want to dig deeper 3 results we begin at the highest level examining drivers of changes in emissions in the reference cases and cumulative emissions savings in the intervention cases we then discuss lessons revealed by the detailed dashboards for the two studies 3 1 reference case trends we begin by decomposing the underlying drivers of emissions growth in the reference scenarios for the two studies applying the logarithmic mean divisia index lmdi method ang 2004 to the kaya identity in the energy sector 3 details can be found in supplemental information part 1 si 1 technical methods 3 fig 1 shows the change in emissions attributable to each driver to 2100 relative to a 2020 base year expressed in gigatonnes of co2 equivalent emissions calculated component by component we focus on the cumulative change in emissions because it is directly related to changes in global temperatures to first order lahn 2020 2021 although there are complexities when summing co2 equivalent emissions of different warming agents so these results should be considered approximate this graph shows the sum of changes relative to the 2020 value in each year for each sector driver we apply the lmdi 4 ang 2004 shows lmdi methods 1 and 2 we choose method 1 because it is simpler and method 2 has no advantages for our analysis 4 approach to the energy sector kaya identity for the reference case minus 2020 energy sector emissions to conduct the decomposition in the ten year intervals the data allow we then interpolate linearly between decadal values to get annual numbers and sum the difference for each component in every year to 2100 for the additive factors other gases land use and industrial process emissions we take the difference between the reference case for each factor in each year and its value in 2020 then sum those differences to 2100 this method gives an indication of the relative importance of each driver sector over the analysis period drivers shown above the zero line push emissions up while those below the zero line push emissions down the net changes in cumulative emissions for the scenarios are indicated by the black circles which fall at about 1500 gt co2e for van vuuren and about 2100 gt co2e for grübler both scenarios represent ssp 2 but there are always differences in the underlying drivers depending on modeling practice the single biggest driver of emissions growth is increasing economic activity per person which is about five times more important than the next largest category of emissions growth population increased economic activity is mainly the result of improving economic conditions in developing countries which is a consequence of societal development and an appropriate outcome given historical inequities in income growth the third largest driver of emissions growth is other gases which is one reason why just focusing on the energy sector for emissions reductions doesn t give the full picture the carbon intensity of fossil energy which characterizes fuel switching among fossil fuels also contributes to emissions growth in the grübler reference case indicating a modest shift towards more carbon intensive fossil fuels over time reductions in energy intensity of the economy are the dominant source of reductions in emissions over time in both reference case scenarios the second most important source of emissions reductions for grübler and the third most important for van vuuren are changes in land use indicating that even in the reference case there are big changes in this source of emissions fossil fuel fraction also contributes modestly to emissions reductions over time in both cases 3 2 drivers of emissions reductions we next summarize emissions reductions in the intervention scenario compared to the reference scenario fig 2 shows the attribution of cumulative emissions savings relative to the reference case to categories as per the previous graphs and equations the same caveat about these results being approximate applies for the 2020 to 2050 and 2050 to 2100 periods we ve normalized savings to 100 of cumulative net emissions savings and those absolute savings totals are shown at the top of each bar when factors change in a way that drives net emissions up relative to the reference case like for van vuuren then the bar exceeds 100 on the positive side and shows a corresponding bar below the zero line for the factor increasing emissions instead of decreasing it the grübler intervention case shows improvements in the final energy intensity of the economy to be more important than for van vuuren to 2050 but shows this component to be less important than for van vuuren from 2050 to 2100 because of slowing improvements in emissions intensity in the later period see further discussion below efficiency improvements also slow in the later period for van vuuren but the effect is not as dramatic for grübler the fossil fuel fraction is by far the most important driver of emissions reductions accounting for about 30 of the total to 2050 and about 50 from 2050 to 2100 the contribution of fossil fuel fraction to total emission reductions also grows for van vuuren the van vuuren scenario also trades off emissions reductions from changes in fossil fuel fraction against fossil ccs and greater emissions reductions from the carbon intensity of fossil energy than in the grübler scenario the contribution of other gases to total emissions reductions is about one quarter for van vuuren and slightly less than one fifth for grübler and those percentage contributions remain roughly constant over the two analysis periods emissions reductions associated with changes in land use are front loaded in both scenarios with significantly greater reductions in the first period five emissions reduction drivers comprise about 90 of cumulative reductions final energy intensity of the economy fossil fuel fraction other gases land use and the carbon intensity of fossil energy the savings from other gases depends strongly on the assumption about global warming potentials smith and wigley 2000a 2000b in fig 2 we used the standard assumption of gwps based on a 100 year lifetime but a strong case can be made for also considering gwps integrated over a 20 year period especially for 1 5 c scenarios that reach net zero emissions in the next few decades fig 3 shows the results of altering the gwp for methane n2o and f gases to a 20 year time period the gwp of carbon dioxide equals 1 0 by definition for any time period because gwp is measured relative to co2 methane is the most important of the other gases and its 20 year gwp is two and a half times bigger than the 100 year value for n2o the 20 year gwp is the same as the 100 year gwp while for f gases some have 20 year gwps that are lower than their 100 year gwps and some show the opposite taken together these changes push savings from other gases to comprise thirty to forty percent of total cumulative emissions savings up from twenty to twenty five percent when using 100 year gwps this result does not mean we can delay reductions in carbon dioxide which take on increasing importance as time passes it does mean that focusing on the other gases particularly methane and other shorter lived warming agents is a critical element of slowing climate change in the near term interestingly van vuuren also shows emissions savings from a reduction in population growth previous research has documented that population growth affects emissions but that changes in population growth are affected by many complex ethical and human factors related more broadly to societal development o neill et al 2010 cautions that the fact that a particular phenomenon is a quantitatively significant driver of emissions does not mean that it is also an important policy lever choices that affect societal development can also affect population and thus emissions but most scenarios avoid discussing such choices as explicitly driven by the goal of emissions reductions bongaarts and o neill 2018 van vuuren states that the lower population estimates in this scenario are the result of aggressive policies promoting education referencing samir and lutz 2017 the van vuuren scenario also indicates a small increase in emissions associated with improved economic activity per person indicated by a small grey bar below the zero line grübler also shows this effect but it s much smaller 10 20 of what s shown in the van vuuren scenario these effects appear to be related to economic benefits and co benefits of various non price policies as distinct from implementation of the global carbon price 3 3 digging into the ratios dashboards we show the results in the energy sector of our fully expanded decomposition for van vuuren et al and grübler et al in figs 4 and 5 respectively each pane in the dashboard characterizes one of the ratios in the expanded kaya identity from equation 2 the green dotted lines show the path of the relevant ratio if it followed average historical growth rates for that ratio from 1900 to 2014 while the blue dotted lines show the path if it followed average historical growth rates from 1995 to 2014 the black lines indicate the path of the reference case while the red line indicates the path of the intervention or mitigation case 3 3 1 population and economic activity population and economic welfare per person look roughly similar in both scenarios population growth diverges from historical trends as expected from demographic studies in recent years samir and lutz 2017 economic activity in the reference cases is assumed not to be significantly affected by associated changes in temperature which is not necessarily a good assumption but it s a common assumption for scenarios like these ipcc 2022 bastien olvera 2019 christensen et al 2018 mann 2022 the reduction in population and increase in economic activity in the van vuuren et al intervention case show up clearly in the first two dashboard panes 3 3 2 final energy intensity of economic activity fig 6 shows expanded panes for final energy intensity of economic activity for van vuuren s and grübler s scenarios from 2010 to 2030 van vuuren s intervention scenario shows a rapid decline in the final energy intensity of economic activity fe gnp substantially exceeding historical trends as well as that of the reference scenario from 2030 to 2040 the slope of the intervention scenario curve matches the historical rate of decline from 1995 to 2014 and flattens out further as the scenario progresses grübler s scenario shows the same pattern with an even steeper decline from 2010 to 2040 the rate of decline from 2040 to 2050 roughly matching that of the 1995 to 2014 period with the curve then flattening just like for van vuuren if grübler s estimates for final energy intensity are correct it would indicate the possibility of additional emissions reductions possible for the van vuuren scenario through reduced energy intensities in the intervention scenario declines in energy intensity driven by improvements in energy efficiency electrification and changes in service demands accelerate for the first few decades of the scenario and then slow down as also shown in figs 4 and 5 above the reasons for this pattern are not entirely clear but as a general rule demand side technologies and practices like energy efficiency and changes in activity levels are represented in a much less detailed fashion in global energy models than are supply side technologies and bottom up analyses of end use efficiency tend to run out of efficiency later in these analyses because predicting technological change at a disaggregated level becomes increasingly difficult for later years wilson et al 2012 pye et al 2020 hardt et al 2019 napp et al 2019 it is also possible that there are aggregate assumptions of physical limits buried in the models that curtail energy intensity improvements as each scenario progresses whether such assumptions represent real physical limits based on the 2nd law of thermodynamics or simply modeling practice is not known but we believe the importance of this issue warrants a much deeper dive into why climate mitigation scenarios exhibit this structural similarity in final energy intensity of economic activity a deeper question is whether changes in the structure of economic growth away from increases in physical consumption and toward increases in knowledge based goods and higher quality physical goods can allow society to continue improvements in final energy intensity of economic activity far beyond what conventional models would indicate mcafee 2019 answers to this question will vary greatly country by country as demonstrated by both scenarios end use energy intensity declines can make it possible to achieve emissions reductions with less widespread deployment of carbon capture and other supply side technologies hummel 2006 called this a reduction in mitigation pressure that allows for deeper emissions reductions than would be possible with accelerated supply side options alone grübler et al 2018 also allude to intensity reductions as an enabler of more rapid and more profound supply side changes 3 3 3 energy supply system losses as shown in figs 4 and 5 above energy supply losses to 2050 in both intervention cases are lower than in both reference cases which is expected as more direct equivalent non combustion energy sources enter the supply mix koomey et al 2019 nakicenovic et al 2000 energy supply losses in both intervention cases rise in the second half of the twenty first century with losses in the van vuuren scenario exceeding those in the reference case as fossil ccs which has higher system losses than conventional technologies enters the supply mix the grübler scenario also shows rising supply losses in the intervention case over time but these losses remain lower than those in the reference case for the entire analysis period 3 3 4 fossil fuel fraction of primary energy fig 7 shows expanded versions of the dashboard panes devoted to the fossil fuel fraction of primary energy both intervention scenarios show declines in this fraction with van vuuren approaching about one third of 2010 levels by 2100 and grübler showing total fossil phaseout by about 2070 or so this difference is primarily attributable to the use of fossil ccs in the van vuuren scenario under strict emissions reduction goals scenarios with ccs continue to use fossil fuels while those without do not which is one reason why fossil ccs is technology often favored by the fossil fuel industry 3 3 5 carbon intensity of fossil energy fig 8 shows expanded panes from the dashboard characterizing the carbon intensity of fossil energy supply this factor increases in both reference cases indicating slightly more emissions intensive use of fossil fuels over time both intervention cases trend towards the asymptote of natural gas emissions but van vuuren s scenario approaches that goal much more quickly additional emissions savings could thus be realized in the grübler intervention scenario if the shift to natural gas happened as quickly as shown in the van vuuren scenario why the carbon intensity of fossil fuel supply increases slightly towards the end of the analysis period for van vuuren is a question worthy of further exploration 3 3 6 graphs of primary energy that summarize major trends in key drivers one way to answer some of the queries raised above is by graphing primary energy over time by source as shown in fig 9 a and fig 9 b for the van vuuren and grübler intervention cases respectively graphs like these show trends in total primary energy they also implicitly show trends in final energy because the energy supply loss factor is close to 1 0 throughout the analysis period for both scenarios in addition they implicitly show the fossil fuel fraction as well as the mix of fossil fuels contributing to meeting service demands in any year fig 9a for van vuuren shows that total primary energy drops rapidly to 2040 in part because of rapid improvements in the final energy intensity of economic activity and in part because of the rapid displacement of fossil combustion with direct equivalent sources which avoids combustion losses as improvements in final energy intensity slow down mid century and carbon capture technologies with high system losses become more widely used total primary energy starts rising reaching 2020 levels by 2100 fossil gas consumption stays roughly constant to 2040 and then rises modestly to 2070 then falls to 2100 petroleum use falls to mid century then remains roughly flat while coal use falls to mid century and then rises to 2100 this latter finding explains why the carbon intensity of fossil fuel supply goes up in the last couple of decades of the 21st century for this scenario fig 9b shows the same graph for grübler illustrating big differences with the van vuuren intervention scenario primary and final energy decline substantially by mid century and then remain roughly flat to 2100 coal is almost completely gone by 2050 petroleum by 2070 and fossil gas by 2090 fossil gas represents a higher percentage of primary fossil energy supplied from 2020 to 2050 in the van vuuren intervention case than in the grübler intervention case with this gap growing over time these data explain why the carbon intensity of fossil energy supplied falls more rapidly early in the van vuuren intervention case 3 4 digging into the additive factors dashboard now we turn to insights from our additive factors dashboards which show emissions changes over the analysis period by each factor identified in equation 4 above expressed in gt co2 equivalent per year figs 10 and 11 show that the energy sector is the largest contributor to emissions reductions but other non co2 warming agents and land use changes are also important there are relatively small savings from industrial process emissions and none from biomass ccs in either scenario 3 4 1 land use change fig 12 shows expanded versions of the dashboard panes for carbon dioxide emissions from land use changes to make them easier to see some obvious questions emerge from casual examination of these graphs what drives emissions in both references cases to decline over time in the van vuuren case after rising to 2030 why do net emissions in the van vuuren intervention case become less negative after mid century what drives the rapid emissions reductions in the grübler intervention scenario to 2030 and why then do emissions reductions proceed less rapidly after 2030 3 4 2 industrial processes fig 13 shows expanded versions of the dashboard panes for carbon dioxide emissions from industrial processes mainly cement the reference cases are identical taken from van vuuren because the ssp2 reference case used by grübler doesn t split industrial process emissions from energy sector emissions the van vuuren intervention case comes directly from that study s outputs but we infer the intervention case for grübler using fossil energy combustion and related emissions factors then subtracting out inferred energy sector emissions from the sum of energy sector plus industrial process emissions both intervention cases reflect changes in emissions from industrial processes but it s not entirely clear whether such changes are consistent with the trajectory of energy infrastructure construction in these scenarios this issue is a more general one that needs further attention from the modeling community additional transparency is needed with data related to industrial process emissions separate from energy sector emissions to ensure internal consistency of the scenarios the van vuuren intervention case also has unexplained oscillations that clearly warrant futher investigation 3 4 3 non co2 warming agents fig 14 shows expanded versions of the dashboard panes for carbon dioxide emissions from non co2 warming agents like methane nitrous oxide and other pollutants using 100 year gwps the reference cases appear to be comparable but the intervention cases show much more rapid and effective mitigation of non co2 pollutants in the van vuuren scenario if the van vuuren assessment is correct there is clearly room for more reductions in other warming agents in the grübler scenario 4 recommendations for future work we are hopeful that these decomposition tools can support and strengthen the next iteration of the ipcc s working group iii report due out in the mid to late 2020s but that will depend on modelers integrating these tools into their workflows and and using them to generate insights wh which should also speed up the process of developing scenarios and evaluating results 4 1 more studies of aggressive emissions reduction scenarios are needed in our view there are too few scenarios with aggressive emissions reductions and such emissions reductions are less well studied than they should be these edge cases are the most likely to teach us something useful about what ultimate emissions reductions will be possible because they push the boundaries of our imagination the most comprehensive summaries of such scenarios are found in ipcc 2022 and ipcc 2018 but as with all fast changing research areas findings become obsolete quickly as suggested by three of the comparisons above improvements in the intensity of final energy use the emissions intensity of fossil fuels and emissions from non co2 warming agents analytical focus on combining the best parts of the most aggressive scenarios from best of breed analyses can help policy makers map the true limits of what society can achieve we are also convinced that comparing analyses that are quite different in their underlying assumptions and drivers can yield important insights sognnaes et al 2021 the two scenarios presented above are of a similar type but comparing scenarios like these to others that have different core assumptions about drivers and available technologies should be an important part of scenario decomposition efforts going forward 4 2 addressing unanswered questions use of the analytical tools highlighted above can help identify and diagnose unexplained trends and discontinuities an example is the common pattern of accelerated energy intensity reductions in the first two or three decades of intervention cases but a sudden slowing of those reductions around the mid twenty first century identifying and researching puzzles like these can lead to more rapid improvements in modeling practice as well as increased understanding of the true constraints holding back rapid climate action 4 3 we need more data we need more data from global energy models to do full decompositions to more fully understand the implications of individual studies and of the body of literature as a whole the modeling community must routinely release more comprehensive data beyond what is now standard practice policy makers and funders can and should encourage more complete disclosure our experience indicates that more comprehensive better defined and more accurate data are needed in at least four areas 1 more disaggregated data to facilitate analysis and scenario comparisons it is critical that data be disaggregated sufficiently for example industrial process carbon dioxide emissions should be reported separately from energy sector emissions methane and nitrous oxide emissions should at a minimum be split between those associated with fossil fuel production and those non fossil emissions associated with industrial processes agriculture and other human activities finally f gases should be split and reported by species not reported only as a total otherwise it is hard to adjust for different global warming potentials and assess policy effects on different f gases 2 endogenous treatment of industrial sector process emissions industrial process emissions most of which are associated with construction materials like cement steel aluminum and glass should be modeled as a function of the numbers and types of new energy production facilities because the material requirements of future pathways can differ substantially pauliuk et al 2017 simultaneously modeling materials flows process emissions and the economic factors affecting expansion of certain industries as in for example cao et al 2019 and iea 2019 is an approach more analysts should consider similarly ccs for industrial sector process emissions should be tracked separately from energy sector ccs 3 electricity sector more detail on inputs and outputs to the electricity sector are also important as electrification is a key component of many recent modeling exercises with significant electricity generation being allocated to hydrogen production and power to gas in future scenarios precise tracking is complicated but necessary care will be needed to ensure correct accounting and accurate characterization of energy supply losses for these technologies 4 interactions between related sectors scenario decomposition tools allow for more accurate characterization of iterations between linked sectors and technologies like land use biofuels biomass ccs and agriculture but consistent system boundaries and accurate data collection are essential to creating meaningful comparisons decomposition tools can serve important diagnostic and research functions but the results they produce are only as good as their input data understanding the inputs needed for comprehensive decomposition analyses can help researchers to organize and structure their models to produce the most useful results 4 4 integrating decomposition analysis into the modeling process we built our decomposition tools in microsoft excel because they grew out of earlier work that used that platform hummel 2006 as our work has progressed we ve come to realize that only tools that can be run by the modeling teams themselves and fully integrated into their workflows will gain wide acceptance and use and that precludes an excel model run by third parties for this reason we are turning our attention to creating an open source python library that will allow modelers to generate the decomposition results as part of their modeling process integrated with tools now under active development by iiasa and other modeling groups huppmann et al 2021 we hope that this effort will result in much more widespread use of these diagnostic analytical tools and speed up the process of scenario design creation and implementation 5 conclusions stabilizing global temperatures at well below 2 c will require immediate and sustained emission reductions as well as retirement of fossil capital before it reaches its accounting lifetime ipcc 2022 the two scenarios we examine while each aggressive in its own ways contains only a subset of the possibilities modeling is a human process scenario analyses reflect the strengths weaknesses and knowledge of the modeling teams that create them articles summarizing analyses contain different views of their results but because each modeling team chooses what to emphasize it is difficult to compare results across studies in a consistent fashion developing standardized comparison tools and integrating them into modeling workflows is one way to enable more rapid cross study comparisons the modeling community should consider and implement ways to speed up comparisons and harmonization among modeling efforts and funders should support this vital work because it will allow us to identify more potentially promising pathways than we would be able to do in the absence of such efforts consistent comparisons of scenario drivers using systematic analytical tools can enable harmonization of resource potentials technology costs and deployment rates with improved analytical tools we are hopeful that scenario comparison exercises like the ones our decomposition tools enable will help inform development of rapid emissions reduction policies in the future declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests jonathan koomey koomey analytics reports financial support was provided by world resources institute acknowledgements we are grateful for the financial support of world resources institute for this work many colleagues contributed comments insights and or data along the way including four anonymous reviewers tim duane oliver fricko arnulf grübler mathijs harmsen nate hultman holmes hummel daniel huppman dan kammen florentin krause volker krey amory lovins glen peters keywan riahi joeri rogelj simon de stercke sven teske detlef van vuuren david victor and john weyant any errors are the responsibility of the authors appendix a supplementary data the following is the supplementary data related to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2022 105426 
25564,a coupled modelling framework consisting of the storm surge model and the european regional seas ecosystem model ersem has been established to examine hydrodynamics process during typhoon hagupit and its role on nutrient and salinity dynamics in the pearl river estuary pre the accuracy of modelling framework was reasonably validated against measured typhoon wind storm tide and water quality data further analysis suggests hagupit significantly increases water levels in the pre meanwhile the seaward residual currents apparently and chaotically change the phosphate and dissolved inorganic nitrogen concentrations decrease by 0 2 1 8 and 20 88 6 μmol l in the most area from the downstream of narrow river channels to offshore region due to the variations of hydrodynamics while small difference was detected in upstream narrow channels and open sea by contrast salinity distribution showed opposite variation statistically the typhoon winds alleviated the averaged nutrient pollution in the whole pre while causing serious saltwater intrusion keywords nutrient pollution saltwater intrusion storm surge residual current coupled modelling 1 introduction globally many estuarine deltas are densely populated and economically developed areas meanwhile various environmental problems from increased agricultural activities fish dike farming urban and industrial sewage effluents put enormous pressure on the local estuarine environment and dramatically threaten the sustainable development of economy and society shen et al 2002 yang and liang 2020 excess nutrient loading especially nitrogen from human activities e g wastewater input and land use change management and natural processes e g atmospheric deposition and precipitation can result in eutrophication and facilitate rapid phytoplankton growth thereby leading to potentially noxious and toxic algal blooms chen et al 2020 ren et al 2009 high turbidity from increased sediment runoff can increase light attenuation thus limiting the blooms of phytoplankton e g chao et al 2008 liu and huang 2009 wang et al 2019 as salt intrusion affects the estuarine density gradient mixing and circulation processes it changes the transport processes of nutrients and contaminants sun et al 2020 the flocculation re suspension as well as trapping of fine sediments ren and wu 2014 and phytoplankton dynamics lu and gan 2015 in estuaries enhanced salt intrusion even causes significant threat to the survival of some aquatic species in estuaries and the status of estuarine ecosystems huang et al 2015 moreover the estuarine ecosystem is always a fragile system which is particularly vulnerable to the impacts of external forcing like climate change human activities extreme weather and marine disasters e g tsunami storm surge and earthquake thus it is crucial to analyze the impacts of these environmental drivers and understand the mechanism that underlies the dynamic process of water quality factors in estuaries the pearl river estuary pre is one of the largest river systems and the most developed regions in china covering several major cities e g guangzhou shenzhen zhuhai hongkong and macao fig 1 a variety of economic development activities are conducted in the estuary including port construction industrial development tourism and aquaculture the rapid economic growth of this region has become a great cause for concern in terms of the scale of pollution in particular a large amount of incomplete treatment wastewater with high concentration of anthropogenic nutrients discharged into the pre through the eight major tributaries humen jiaomen hongqili hengmen modaomen jitimen hutiaomen and yamen and ultimately transported to the south china sea scs the water quality in the pre and its adjacent areas met the grade v according to china national sea water quality standard failing to reach the requirements of the class v chen et al 2007 several extensive field surveys have been conducted to investigate water quality in the estuary and the results showed that nutrients and organic pollutants are two of the major nutrient indicators especially excess nitrogen over enrichment xu et al 2008 yin and harrison 2008 due to the continuous decrease of freshwater and the dramatic change of river course saltwater intrusion has significantly intensified and it become another typical environment issue in the pre zhang et al 2010 saltwater intrusion occurs if seawater from the oceanic continental shelf of the estuary enters the river section along the main channel with tide and increases the salinity value in this region the river discharge in the pre is significantly affected by the monsoonal climate and characterized by distinct changes between dry from november to march and wet from may to october seasons with approximately 80 water being discharged during the wet season ren et al 2014 the saltwater from open sea is largely suppressed by a large amount of freshwater discharge which does not cause serious salinity intrusion nevertheless the 5 psu isohaline can extend 80 km landward from the estuary s mouth with the significant decrease of freshwater discharge during the dry season which poses a great threat to the drinking water supply in the area and to the habitat of many fish and invertebrate species there is a common consensus that the continuous in situ observation and monitoring of the water quality factors e g temperature salinity and pollutant concentrations those highly correlated with the estuarine environment are time consuming labour intensive and costly especially involving large scale processes the measurement of water quality will be more difficult to conduct during the extreme weather and marine disasters e g tsunami storm surge and earthquake with significant advancement in computing techniques and power water quality modelling has become an effective way to study the polluted characteristics there has been substantial growth of publications focusing on improvements of existing models and techniques and case studies fu et al 2020 jakeman et al 2006 and blocken and gualtieri 2012 set out ten iterative steps for the development and evaluation of models which provides a comprehensive framework that encompasses and extends the existing best practice guidelines over the last few decades the numerical study of the water quality in the pre has been widely conducted chau and jiang 2002 developed a three dimensional numerical pollutant transport model to simulate the transport and distribution of chemical oxygen demand in the pre and the numerical results illustrated that the inter boundary effects of pollutants between the guangdong province and the hong kong special administrative region are quite strong due to the wastewater discharged from the pearl river delta region hu and li 2009 analyzed the flux and transformation of nutrients in the pearl river network and delta by combining a one dimensional model and a three dimensional estuary model wei et al 2016 developed a coupled three dimensional hydrodynamic biological model for the pre to investigate the effects of river discharges and winds on hypoxia during the summer sun et al 2020 built a three dimensional water age wa model base on delft3d flow numerical model to predict the vertical wa distribution in the pre and further quantitatively investigate the effects of vertical water renewal on water quality by linking the wa and dissolved oxygen levels gong et al 2018 examined the effects of winds and waves on salt intrusion in the pre using the coupled ocean atmosphere wave sediment transport coawst modeling system the pre adjacent to the main development region of western pacific typhoons suffers the most frequent typhoons among all the global typhoon active oceans causing severe storm surges in coastal regions of pre according to the statistical data from the china meteorological observatory fifty two typhoons made landfall on the coastal area of pre from 2008 to 2018 fourteen typhoons causing high storm surges over 1 m were observed in hong kong from 1999 to 2018 h k o 2017 jian et al 2021 demonstrated that the mean surge heights along the pre coastline are in the range of 1 5 3 2 m and 2 0 3 5 m under 100 year and 200 year return periods respectively using a steady state surge model tang et al 2012 demonstrated that large surface elevations and intense surface currents are generated over the pre due to the storm surge effects during super typhoon koryn yin et al 2017 revealed that typhoon intensification has a greater impact on storm surge slr has a greater impact on wave heights in the estuary and the combination of those two factors also increases peak surge height and wave height during typhoons hagupit and dujuan zhang et al 2021 pointed out that storm surges and waves weaken estuarine water circulation and water renewal ability during typhoon hagupit passing through the pre previous studies have widely and separately studied the water quality and storm surge process in the pre with various conditions nevertheless short term dynamic processes of nutrients and salinity especially those influenced by typhoons in and near the pre have yet to be fully elucidated authors surmise that typhoon induced storm surge may significantly influence the dynamic processes of nutrients and salinity by changing hydrodynamic characteristics and water circulations as the important water quality parameters triggering a series of environmental problems e g eutrophication algae bloom and species death in the pre studying the response of nutrients and salinity during extreme typhoons is essential to understand the key factors that control estuarine dynamics and coastal ecosystems and provide scientific supports for estuarine environmental management in the present study we aim to establish a coupled storm surge water quality model to further analyze and discuss the effects of typhoon wind on storm surge nutrient and salinity transport processes during a typhoon process 2 numerical models in order to investigate the key physical biochemical processes of water quality parameters and their response to hydrodynamic processes caused by typhoons the schematic diagram of the coupled storm surge water quality model framework is conducted in this study as shown in fig 2 the storm surge model within fvcom framework describes the storm surge process of the study region and provides the background physical forcing e g flow velocity water depth temperature and shortwave radiation to the water quality model the water quality model is based on the european regional seas ecosystem model ersem baretta et al 1995 and it describes the biogeochemical processes in the study region the fortran based framework for aquatic biogeochemical models fabm is a domain independent programming framework with support for any number of processes prognostic variables diagnostic variables and advanced features e g sea ice biota benthos and sediment in surface and bottom layers and multiple feedbacks to physics thus it is applied to achieve the coupling between storm surge model and water quality model 2 1 storm surge model 2 1 1 momentum and continuity equation the fvcom originally developed by chen et al 2003 is a prognostic free surface three dimensional ocean circulation model based on the unstructured finite volume method the unstructured triangular mesh used in fvcom is capable of resolving complex geometry and bathymetry and fvcom has been widely applied to the simulation of hydrodynamics and pollutant transport process in many estuarine and coastal regions guo et al 2009 zhang et al 2021 the 3d equations of momentum and continuity in σ coordinate are presented as follows 1 u d t u 2 d x v u v d y u ω σ f v d g d ζ x d ρ 0 p a x g d ρ 0 σ 0 d ρ x d σ d x σ 0 σ ρ σ d σ 1 d σ k m u σ d f u 2 v d t u v d x v v 2 d y v ω σ f u d g d ζ x d ρ 0 p a x g d ρ 0 σ 0 d ρ y d σ d y σ 0 σ ρ σ d σ 1 d σ k m v σ d f v 3 ζ t d u x d v y ω σ 0 where u v and ω are the velocity components in horizontal x y and vertical σ directions respectively d is the total water depth f is the coriolis parameter ζ is the water surface elevation p a is the atmospheric pressure g is the gravitational acceleration ρ 0 is the reference density ρ is in situ density k m is the vertical viscosity coefficient f u and f v represent the diffusion terms in x and y directions respectively 2 1 2 typhoon wind model wind stress and atmospheric pressure are responsible for generating storm surge on sea surface the accuracy of typhoon model restricts the accurate degree of modeling storm surge characteristics which further affects the transport and distribution of water quality factors hence it is critical precondition for storm surge and water quality simulations to reasonably predict wind and pressure fields during a typhoon in the past few decades numerous wind models and dataset have been applied to simulate the pressure and wind fields jelesnianski 1965 holland 1980 wang et al 1991 wang and shen 2012 in this study the nested model of fujita formula and takahashi formula was considered to simulate pressure field because of its successful applications in many coastal and estuarine waters yin et al 2018 the formulas can be written as follows 4 p r p p p 0 1 2 r r 2 0 r 2 r 5 p r p p p 0 1 r r 2 r r where r is the distance from the station to the center of the typhoon in the computed region p r is the pressure at a distance r from the typhoon center p is the ambient or environmental pressure 1013 25 hpa p 0 is the typhoon center pressure r represents the radius of maximum wind speed from the typhoon center and it is proposed as 6 r 28 52 tanh 0 0873 φ 28 12 22 exp p 0 1013 25 33 86 0 2 c m where φ is the typhoon center latitude c is the speed at the typhoon center m is initial radius in addition ueno formula was considered to simulate wind field in the pre during a typhoon process and it can be defined as follows when 0 r 2r 7 w x c 1 v x e x p π 4 r r r c 2 f 2 f 2 4 10 3 2 δ p ρ a r 2 1 2 r r 2 3 2 x x 0 sin θ y y 0 cos θ 8 w y c 1 v y e x p π 4 r r r c 2 f 2 f 2 4 10 3 2 δ p ρ a r 2 1 2 r r 2 3 2 x x 0 cos θ y y 0 sin θ when 2r r 9 w x c 1 v x e x p π 4 r r r c 2 f 2 f 2 4 10 3 δ p ρ a r r 1 r r 2 x x 0 sin θ y y 0 cos θ 10 w y c 1 v y e x p π 4 r r r c 2 f 2 f 2 4 10 3 δ p ρ a r r 1 r r 2 x x 0 c o s θ y y 0 sin θ where w x and w y the surface wind stresses in x and y directions respectively c 1 and c 2 are empirical constants v x and v y are typhoon forward velocities in x and y directions respectively ρ a is the air density and it is given by 1 2929 kg m3 θ is the inflow angle 20 δp is pressure deficit at surface boundary the effect of wind stress on water body is expressed as 11 k m u σ v σ 1 ρ τ s x τ s y ω ζ t ζ x ζ y where τ s x τ s y c d s ρ a w x 2 w y 2 w x w y are the x and y components of surface wind stress c d s is the drag coefficient of wind and it is calculated by 12 c d s 0 0012 if u 11 m s 0 001 0 49 0 0065 u if 11 m s u 25 m s 0 001 0 49 0 0065 25 if 25 m s u where u w x 2 w y 2 is the wind velocity base on above parametric typhoon model the calculated pressure and winds fields were provided to fvcom model to generate storm surges in the pre during a typhoon period then the storm surge model provides the background physical forcing e g flow velocity water depth temperature and shortwave radiation to control the transport of water quality factors 2 1 3 solving method the momentum equations are solved numerically applying a combined explicit and implicit scheme in which the local change of the currents is integrated using a second order accurate upwind scheme in time the advection terms are computed explicitly by a second order accurate upwind scheme and the vertical diffusion is solved implicitly the calculations of velocity components in x and y directions are both conducted in two steps for example the x component of the transition velocity u i k at the midpoint between the k and k 1 σ levels in triangular cell i is firstly calculated using all the terms except the vertical diffusion term r u i k n in the momentum equations 13 u i k u i k n δ t i ω i δ σ d i r u i k n where δ σ σ k σ k 1 n is the indicator of the nth time step ω i is the area of the ith triangle mesh δ t i is the time step for the internal mode then the true velocity is determined implicitly applying a balance between the local change of the transition velocity and the vertical diffusion term 14 a i k u k 1 n 1 b i k u k n 1 c i k u k 1 n 1 u where 15 a i k 2 k m k 1 δ t d n 1 2 σ k σ k 1 σ k σ k 2 c i k 2 k m k δ t d n 1 2 σ k σ k 1 σ k 1 σ k 1 b i k 1 a i k c i k the solution of u k is calculated by 16 u k a i k b i k c i k v h k 1 u k 1 u c i k v p h k 1 b i k c i k v h k 1 where 17 v h k a i k b i k c i k v h k 1 p h k u c i k v p h k 1 b i k c i k v h k 1 the vertical velocity ω is calculated by 18 ω j k 1 ω j k δ σ k δ t i ζ j n 1 ζ j n δ σ k ω j t c e l v n k n d d l where j is the indicator of the jth node point ω j tce means the area of the jth tracer control element tce and it is defined in the reference of chen et al 2003 n means an indicator of the velocity component normal to the boundary of a tce with a length of l 2 2 water quality model the water quality model based on ersem is applied to describe the biogeochemical processes of nutrients in the pre ersem is a high complexity lower trophic food web model including both pelagic and benthic systems fig 3 it uses a functional group approach e g trait and size to form four phytoplankton groups three zooplankton groups and one bacteria group within the pelagic model the biogeochemical cycling of inorganic dissolved nutrients nitrogen phosphorus and silicon was represented by modulating the cycling between producers consumers and decomposers using variable stoichiometric ratios within the pelagic model 2 2 1 transportation equation the biogeochemical variables as passive tracers are subjected to advection and diffusion therefore the rate of variation for the concentration c pel of a pelagic biogeochemical variable can be expressed as 19 c pel t u c pel x v c pel y ω c pel σ x a h c pel x y a h c pel y σ k h c pel σ b f where u v and ω are the velocity components in horizontal x y and vertical z directions respectively a h is the horizontal eddy diffusion coefficient and k h is the vertical eddy diffusion coefficient b f represents the total biochemical flux and it is calculated by ersem a correct estimation of horizontal and vertical eddy diffusion coefficients is very important as they greatly affect final results about concentration of water quality parameters in this study horizontal diffusion coefficient is estimated by the smagorinsky eddy parameterization method smagorinsky 1963 20 a h 0 5 c t ω t c e p r u x 2 0 5 v x u y v y 2 where c t is a constant parameter and p r is the prandtl number the vertical thermal diffusion coefficient k h is estimated by the mellor yamada level 2 5 turbulence closure scheme mellor and yamada 1982 in the boundary layer approximation the shear production of turbulent kinetic energy is produced by the vertical shear of the horizontal flow near the boundary the equations for q 2 and q 2 l can be simplified as 21 q 2 t u q 2 x v q 2 y ω q 2 σ 2 p s p b ε σ k q q 2 σ f q 22 q 2 l t u q 2 l x v q 2 l y ω q 2 l σ 2 e 1 p s p b w e 1 ε σ k q q 2 l σ f l where q 2 is the turbulent kinetic energy l is the turbulent macroscale k q is the vertical eddy diffusion coefficient of the turbulent kinetic energy f q and f l mean the horizontal diffusion of the turbulent kinetic energy and macroscale p s and p b are the shear and buoyancy production terms of turbulent kinetic energy ε is the turbulent kinetic energy dissipation rate w 1 e 2 l 2 κ l 2 is a wall proximity function where l 1 ζ σ 1 h σ 1 and κ 0 4 is the von karman constant e 1 and e 2 are close constants of the model the turbulent kinetic energy and macroscale equations are closed by defining 23 k m l q 0 4275 3 354 g h 1 34 676 g h 1 6 127 g h k h l q 0 494 1 34 676 g h k q 0 2 l q where g h l 2 q q 2 ρ 0 ρ has an upper bound of 0 023 for the case of unstable stratification and a lower bound of 0 28 for the case of stable stratification 2 2 2 biogeochemical process in order to obtain a better understanding of main pollutant in the pre caused by excessive nutrients the biogeochemical cycling of dissolved inorganic nutrients oxidized nitrogen ammonium phosphorus and silicate is presented in this section 24 c ox n t bgc c ox n t nitr c ox n t upt 25 c amm n t bgc c amm n t remin c amm n t rel c amm n t upt c amm n t nitr 26 c p t bgc c p t remin c p t rel c p t upt 27 c s t bgc c s t rel c s t upt where c ox n c amm n c p and c s represent the oxidized nitrogen ammonium phosphorus and silicate concentrations in pelagic layer respectively the oxidized nitrogen may be regenerated exclusively and ammonium may be further reduced by nitrification 28 c ox n t nitr r nitr b l t b l o nitr l n nitr l ph c amm n 29 c amm n t nitr r nitr b l t b l o nitr l n nitr l ph c amm n where c means the nutrient concentration in the water body excluding background concentration r nitr b is the maximum ammonium mass specific nitrification rate at reference temperature l t b l o nitr l n nitr and l ph is the regulation and limitation factor of temperature oxygen nitrogen and ph respectively and they have been given by butenschön et al 2015 in pelagic layer oxidized nitrogen ammonium and phosphorus are taken up by phytoplankton and bacteria 30 c ox n t upt ψ r aff ox ψ c ox n r aff ox ψ c ox n r aff amm ψ c amm n p n ψ t upt 31 c amm n t upt ψ r aff ox ψ c amm n r aff ox ψ c ox n r aff amm ψ c amm n p n ψ t upt b n t upt 32 c p t upt ψ p p ψ t upt b p t upt where ψ is the indicator of the ψth phytoplankton r aff ox and r aff amm is the affinity of oxidized nitrogen and ammonium p n p is the phytoplankton nitrogen or phosphorus b n p is the bacteria nitrogen or phosphorus the uptake of nitrogen and phosphorus by phytoplankton group is regulated by their nutrient demand f demand p n p ψ c n p and limited by the external availability f avail p n p ψ c n p 33 p n p ψ t upt min f demand p n p ψ c n p f avail p n p ψ c n p if f demand p n p ψ c n p 0 0 if f demand p n p ψ c n p 0 where 34 f demand p n p ψ c n p s gpp ψ 1 δ excr ψ 1 q aresp ψ q maxn p c ψ p c ψ r nlux q maxn p c ψ p c ψ p n p ψ r rsep ψ p n p ψ 35 f avail p n ψ c n r aff ox ψ c ox n r aff amm ψ c amm n p c ψ 36 f avail p p ψ c p r aff p ψ c p p c ψ s gpp is the mass specific gross primary production of phytoplankton δ excr is the excretion fraction of gross primary production q aresp is the fraction of the assimilated amount of biomass per time unit after excretion q maxn p c is the maximum nitrogen or phosphorus to carbon quota r nlux is the rate of nutrient luxury uptake towards the maximum quota r resp is the specific rate of rest respiration at reference temperature p c is the phytoplankton carbon concentration including background carbon concentration p c n p is the phytoplankton carbon nitrogen or phosphorus concentration excluding background concentration r aff p is the affinity of phosphorus the uptake up of bacteria on nitrogen and phosphorus is expressed as 37 b n p t upt r rel b q n p c b q maxn p c b b c c amm n p c amm n p h n p b if q n p c b q maxn p c b 0 if q n p c b q maxn p c b where r rel b is the mass specific release rate q n p c is the nitrogen or phosphorus to carbon quota h n p b means the half saturation constant for phosphorus or nitrogen limitation silicate is taken up by diatoms 38 c s t upt max q ref s c dia s growth dia 0 where q ref s c dia is the reference silicate to carbon quota of diatoms s growth dia is the substrate mass specific uptake of diatoms the remineralization process of ammonium and phosphorus can be evaluated as 39 c amm n t remin r rem n r lab n 40 c p t remin r rem p r lab p where r rem n and r rem p are the mass specific remineralization rates of nitrogen and phosphorus r lab n and r lab p mean the labile dissolved organic matter dom nitrogen and phosphorus concentrations excluding background concentrations the release processes of nutrients are evaluated as 41 c amm n t rel ψ p n ψ t rel k z n k t rel b n t rel 42 c p t rel ψ p p ψ t rel k z p k t rel b p t rel 43 c s t rel p s dia q ref s c dia p c dia where 44 p n p ψ t rel 0 if f demand p n p ψ c n p 0 f demand p n p ψ c n p if f demand p n p ψ c n p 0 45 z n p k t rel min 0 z n p k q n p c k z c k r reln p k 46 b n p t rel 0 if q n p c b q maxn p c b r rel b q n p c b q maxn p c b b c if q n p c b q maxn p c b z c n p is the zooplankton nitrogen phosphorus or carbon concentration including background concentration z c n p is the zooplankton carbon nitrogen or phosphorus concentration excluding background concentration b c is the bacteria carbon concentration excluding background concentration r reln p means the relaxation rate of release into dissolved inorganic form 2 2 3 coupling of benthic model and pelagic model a simple benthic return model was applied instead of the standard dynamical benthic model baretta bekker et al 1997 which considered the settling of organic matter and phytoplankton into the benthos and diffusional inorganic nutrient fluxes from the sediment layer deposition fluxes of organic matter and phytoplankton from pelagic layer into benthic layer are expressed as 47 f ben c pel ω depo c pel c pel where ω depo c pel max 1 τ bed τ crit 0 ω sed c pel is the deposition velocity ω sed c pel is the velocity of gravitational sinking τ bed is the seabed shear stress and τ crit is the critical seabed shear stress the absorption of deposited nitrogen and phosphorus components into the sediments then results in separation of the organic material into dissolved degradable and refractory matter according to 48 f pel q n p degr ψ 1 q ddepo ψ p cyto n p lab q rdepo ψ p cyto n p part f p n p ψ ben χ 1 q rdepo part f r n p χ ben 49 f pel q n p refr ψ q rdepo ψ p cyto n p part f p n p ψ ben q rdepo part f r n p χ ben 50 f pel q n p dis ψ q ddepo ψ p cyto n p lab f p n p ψ ben where q n p degr q n p refr and q n p dis represent the degradable organic nitrogen and phosphorus dissolved organic nitrogen and phosphorus and refractory nitrogen and phosphorus in benthic layer respectively q ddepo ψ and q rdepo ψ are the dissolved and refractory fractions of ψth phytoplankton r n p χ is the ᵡth organic matter nitrogen or phosphorus and q rdepo part is its particle fractions p cyto n p lab reflects the relative nitrogen or phosphorus content of cytoplasm of labile dissolved organic matter with respect to the structural components and p cyto n p part reflects the relative nitrogen or phosphorus content of cytoplasm of particulate organic matter pom the silicate component is entirely directed to degradable matter 51 f q s degr pel f ben p s dia f ben r s med f ben r s large where q s degr is the degradable organic matter silicate in benthic layer r s med and r s large mean the medium and large size pom the variables in the benthic layer are returned into the pelagic layer during resuspension and remineralization processes 52 f n p s resusp r med q des r err max τ bed t crit 1 0 q n p s des 53 f p s remin c p s q p s λ r remin λ q p s λ 54 f n remin c ox n q n λ q remin ox n r remin λ q n λ 55 f n remin c amm n q n λ 1 q remin ox n r remin λ q n λ where λ represents the indicator of the λth benthic organic matter r err represents erosion rate q n p s is the benthic organic nitrogen phosphorus or silicate concentration excluding background concentration r remin is the remineralization rate q remin ox n is the nitrate fraction of remineralised nitrogen 3 model configuration and verification 3 1 model configuration since the typhoon winds and storm surges affect the area of interest over a relatively large region during a typhoon process and the hydrodynamic as well as water quality characteristics at the open boundary of the model mesh are tough to be accurately simulated the mesh boundaries should be sufficiently far away from the area of interest so as to guarantee that the boundary disturbances do not affect its hydrodynamic and water quality process however it may decrease the degree of computed resolution or increase computational cost due to the use of different grid sizes and numbers consequently a two nested mesh system was performed to achieve the feature that may predict the hydrodynamics and water quality parameters over the area of interest efficiently and accurately fig 4 the domain of outer model covered not only the whole pre but also a main part of the south china sea 105 7 119 9 e 13 6 23 1 n in the outer domain the total number of mesh element and node was set as 39729 and 21079 respectively the mesh resolution changed from about 25 km on the open boundary of the outer model to about 300 m in the area of the interest jakeman et al 2006 expressed that even some crude error estimates based on output sensitivity to the most important variables is useful during uncertainty analysis process in inner model two resolution high resolution hr and low resolution lr meshes were considered to estimate their effects on model output fig 4b and c fig 4d and e plot the enlarged view of the two resolution meshes in lingdingyang bay the information of mesh element and node is shown in table 1 a global topography database etop1 https ngdc noaa gov mgg globalglobal html was extracted for bathymetry interpolation in the most of study region except for the pre where the bathymetry data was obtained from higher resolution field measurement fig 1b along the open sea boundary of outer model the time series water levels induced by astronomical tide were specified by the four main tidal constituents m2 s2 k1 and o1 and four minor constituents n2 k2 q2 and p1 the temperature salinity nutrient and chlorophyll a values were extracted from the global reanalysis data of the cmems database for the conditions of open sea boundary e g water level flow velocity salinity and water quality factors in inner model which were calculated and provided by the outer model the eight major tributaries humen jiaomen hongqili hengmen modaomen jitimen hutiaomen and yamen are set as river discharge open boundary and the river discharge was confirmed based on historical flow data from river outlets in pre the nutrient loads at the river boundaries were obtained from the field surveys liu 2006 jos et al 2007 as for the sea surface boundary the data was obtained from ecmwf database including atmospheric pressure wind relative humidity clearness coefficient temperature evaporation precipitation and shortwave radiation etc in this study the parameters used in the water quality model were derived from observation in the pre and from scientific literatures jos et al 2007 blackford and burkill 2002 petihakis et al 2002 based on the above parameter values the key model parameters were further calibrated to comprehensively understand the performance of key parameters that affect the model results and accurately predict water quality process and their values are listed in table 2 the entire simulation time includes the process required by hydrodynamics and water quality to achieve dynamically steady state and the process of development and movement of hagupit in the scs from 00 00 on 1 june to 24 00 on 30 september 2008 utc in hydrodynamics model the mode splitting method is used the free water surface is integrated by solving vertically averaged equations in external mode and the 3d momentum equations are integrated in internal mode the fixed time steps of 5 s and 30 s have been used for the external and internal modes as for water quality model the time step was set as 30 s 3 2 sensitivity analysis of mesh resolution in this section sensitivity analysis has been performed using two types of inner meshes with hr and lr table 3 presents a quantitative comparison of hydrodynamics and water quality parameters tide level salinity and dissolved inorganic nitrogen din at twenty selected stations although the ratio of two mesh resolution is about 2 times in the pre the difference of tide level salinity and din at most selected stations is very close the maximum change rates of tide level salinity and din are 0 878 2 529 and 3 679 and they appears at stations 4 18 and 9 respectively all of above results confirm that even the mesh resolution of 50 4800 m is able to reasonably simulate hydrodynamics and water quality processes and the simulation results do not obviously change with the further improvement of mesh resolution therefore a lr inner mesh was used for further verification and application in order to improve the calculation efficiency 3 3 model verification 3 3 1 typhoon wind and storm surge hagupit 0814 initially developed as a tropical storm in the northwestern pacific on sept 19 2008 see fig 5 for track it was strengthened into a typhoon on sept 21 and further upgraded into a severe typhoon on sept 22 the typhoon then advanced west northwestwards and further intensified in the scs with maximum wind speeds of 50 m s and a minimum pressure of 935 hpa at 22 45 utc time on sept 23 it made landfall over the coastal region of maoming county guangdong province after landfall hagupit gradually weakened and eventually disappeared during the typhoon many tidal gauge stations in the pre reached or broke the 100 year annual maximum water level record the highest water level was 3 5 m and it appeared at beijingang station see fig 5 for location the government statistics showed that 22 people died and direct economic losses amounted to us 1 742 280 000 during this typhoon as a representative of the severe typhoon to make landfall in the pre hagupit was used to validate the typhoon and storm surge models and further investigate typhoon wind effects on hydrodynamics nutrient and salinity dynamics the detail hagupit information e g hourly typhoon central location pressure and maximum wind speed was obtained from the chinese typhoon weather web site http typhoon nmc cn web html to verify the accuracy of typhoon and storm surge models in the pre three gauge stations fuliu mountaion hengmen and huangjin see fig 6 for location were chosen to compare the wind speeds and storm tides between measurements and simulations during hagupit fig 7 the performance of numerical model was assessed by calculating the four widely used metrics including mean absolute error mae root mean square error rmse relative mean square error msre and pearson product moment correlation ppmc these metrics were systematically discussed by bennett et al 2013 as shown in table 4 in this table y i and y ˆ i are the ith simulated value and observed value respectively y and y are the mean values of the simulated and observed results as it can be seen from the typhoon wind process at fuliu mountaion station the nested typhoon model is capable of simulating wind field for the hydrodynamic model with a mae value of 2 27 m s a rmse value of 2 84 m s and a msre value of 0 29 m s respectively table 5 the value of ppmc is 0 93 showing the good consistency between the measured wind speeds and simulated results the errors in the wind modelling are generally reasonable and acceptable in comparison to those given in peer reviewed literature for example the average rmse value presented by yin et al 2018 for their typhoon modelling of pre is 3 05 m s with a correlation coefficient of 0 89 the measured data collected at stations hengmen and huangjin were utilized to validate the simulation accuracy of the storm tide it can be seen that the simulated range and phase of the storm tide were in reasonable agreement with the measurements at hengmen station the mae rmse msre and ppmc values of the simulated storm tide from the measured values are 0 27 m 0 32 m 0 01 m and 0 93 respectively and these values are 0 18 m 0 31 m 0 01 m and 0 94 at huangjin station the above validation results indicated that the storm surge model can reasonably predict the variation of storm surge process during hagupit the spatial distribution of simulated wind speeds in the scs at 6 h intervals from 12 00 utc on september 23 2008 to 06 00 utc on september 24 2008 was shown in fig 8 the wind fields in the scs presented a counterclockwise circulation structure under the influence of hagupit the maximum wind speed reached 47 m s at the location being the maximum typhoon radius away from typhoon center when typhoon center was located in the south of the pre 108 9 e 21 9 n strong offshore winds appeared in the extensive region between the beibu gulf and the pre which were opposite with those in the east region of the pre fig 8a the wind speeds in the pre ranged from 14 m s to 26 m s with the typhoon center moving toward the pre 111 6 e 21 3 n the wind field in the pre was more significantly determined by the typhoon and the range of wind speeds was 16 35 m s their direction turned landward at this time moreover the maximum wind speed with tiny change in the value appeared in the southwest of the pre fig 8b when typhoon center made landfall in the coastal region of maoming county the wind directions turned southerly and the wind speeds decreased to 14 6 m s in the pre fig 8c eventually they decreased to 7 m s after typhoon center making landfall fig 8d 3 3 2 water quality given the difficulty of in situ water quality measurement during typhoon hagupit there is no relevant measured water quality data at this time therefore the in situ water quality data from twelve stations see fig 6 for location before the typhoon was used to validate the water quality model and the results are plotted in fig 9 including salinity temperature phosphate din and silicate the simulated water quality values match well with the measurement data at the most monitoring stations of the pre while relatively large errors appear at the several stations near offshore region due to the limited accuracy of water quality data specified at the open sea boundary table 6 shows that the averaged values of mae rmse and msre between the simulated salinity and measured results are 1 97 2 47 and 0 02 psu respectively with an averaged ppmc value of 0 84 a smaller averaged value of ppmc 0 65 appears between simulated and measured temperature which can be explained by that variation of the temperature in the spatial distribution is slight and it is very difficult to be accurately captured by water quality model nevertheless the water quality model can reasonably reproduce the amplitude of measured temperature with an averaged mae value of 1 79 c an averaged rmse value of 1 96 c and an averaged rmse value of 0 06 c as for phosphate din and silicate the averaged values of ppmc are all larger than 0 95 showing the good consistency between the simulated values and measured results in general the overall agreement in terms of the water quality factors is less satisfactory although still being acceptable it laid a solid foundation for further discussion about the effect of typhoon process on nutrient and salinity dynamics 4 results and discussion based on the model configuration and validation mentioned above the established model was utilized to test the effects of hagupit on hydrodynamics nutrient and salinity simulations in the pre in the numerical simulations two scenarios without and with typhoon wind effects were performed while the other model conditions and parameters kept fixed a comparison was then conducted between the results obtained in the variable typhoon wind scenarios to find out how storm surges and water quality simulations are impacted by the typhoon winds in the pre 4 1 impacts of typhoon winds on hydrodynamics to characterize the impacts of hagupit on hydrodynamics process in the study region the time series of storm surges and flow velocities at three selected points e1 e2 and e3 the representative of the sub regions lingdingyang bay maodaomen huangmaohai bay in the pre respectively see fig 6 were analyzed with and without the wind conditions as showed in fig 10 the height of storm surge was obtained by the surge tide in the case with typhoon winds minus the astronomical tide in the case without typhoon winds it can be seen that the storm surges are characterized by single peak shape at all selected points and the whole durations of the storm surges are around 1 day when the typhoon was far away from the selected points the storm surges slowly decreased due to the effects of typhoon winds with seaward direction with the arrival of the typhoon they rose sharply and formed a distinct peak with a maximum value of 1 12 1 08 1 36 m at e1 e2 and e3 points respectively the storm surges decreased faster after the peak and then there were severe small amplitude oscillations meanwhile the seaward flow currents at three selected points were first slowly increased by the typhoon wind forcing from the similar direction before the typhoon center arrived here then they were significantly weakened by the typhoon winds from the opposite direction and their directions even reversed landward when the typhoon passed through the selected points fig 11 presents the distribution of the maximum storm surges caused by hagupit and the surface residual currents without and with wind conditions during a typhoon period at the upstream of the huangmaohai bay and the lingdingyang bay the heights of maximum storm surges are more than 2 0 m and they gradually decreases toward open sea the maximum storm surge heights are generally lower than 0 4 in open sea under the influence of typhoon winds the surface residual currents significantly increase in the huangmaohai bay the upstream of the lingdingyang bay and the southwest of the pre in the huangmaohai bay the maximum surface residual current increases from 0 3 m s to 0 6 m s the surface residual currents averagely increase from 0 08 to 0 19 m s in the upstream of the lingdingyang bay in the southwest of the pre the variation is from 0 26 to 0 6 m s nevertheless the results of the scenario with typhoon winds in the main channel of the jitimen show lower seaward residual currents the biggest residual current decreases from 0 58 m s to 0 29 m s due to typhoon wind effects along the main channel in the mouth of the lingdingyang bay the residual currents are mainly lower than 0 3 m s and this value increases to 0 4 m s in the scenario without typhoon winds the typhoon winds apparently increase the area with larger residual velocity of 0 5 m s meanwhile the flow directions deflect westward in the whole pre with the effects of typhoon winds and the seaward currents in some regions even reverse landward which significantly contributes to weaken seaward residual currents and make the structure of residual currents more chaotically 4 2 impacts of typhoon winds on nutrient and salinity dynamics previous studies show that the environmental status and variations in estuaries are mainly controlled by the complex interplay between physical chemical and biological processes ren et al 2014 chi et al 2020 as illustrated in the previous section different typhoon wind scenarios result in obvious variations of hydrodynamics process in study region to further improve the understanding of wind forcing contribution during a typhoon period the nutrient and salinity processes with and without typhoon winds were also investigated by the validated hydrodynamic water quality model fig 12 compares the time series of computed din and salinity concentrations at three selected points with variable typhoon wind scenarios before hagupit arrived the pre and its adjacent region the local winds were dominant and they slightly affected the amplitude and variation of din concentrations at the selected points due to small wind stress then the din concentrations were most dramatically decreased with significantly weakened seaward residual currents and increased storm surges since the landward typhoon winds approached here statistically the din concentration differences between two scenarios the scenario with winds minus the scenario without winds at the e1 e2 and e3 points are in the range of 46 28 9 54 μmol l 48 51 25 09 μmol l and 54 09 25 78 μmol l indicating the non ignorable affects of the wind forcing on nutrient dynamics especially during the typhoon on the contrary salinity values apparently increased at the three selected points with the landward typhoon winds promoting the intensification of salinity intrusion in pre statistically the salinity concentration differences between the two scenarios the scenario with winds minus the scenario without winds at e1 e2 and e3 points are in the range of 0 95 8 41 psu 5 10 8 56 psu and 3 40 9 64 psu indicating the serious threat in saltwater intrusion during the typhoon fig 13 a d shows the spatial distribution of simulated phosphate and din concentrations in the scenarios without and with typhoon winds respectively from the simulation results it can be seen that the simulated phosphate concentration decreases from 2 μmol l in the river source to 0 4 μmol l in offshore plume water and the din concentration decreases from 120 to 20 μmol l in the pre compared with the scenario with typhoon winds both the din and phosphate concentrations are transported to further distances in the scenario without typhoon winds to facilitate comparison the phosphate and din concentrations in the scenario without typhoon winds were subtracted from those in the scenario with typhoon winds to obtain the spatial distribution of concentration differences as is shown in fig 13 e and f examination of the spatial distribution of nutrient differences between these two typhoon scenarios revealed that the impacts of typhoon winds on nutrient distributions are significant the typhoon winds mainly decrease the phosphate concentrations more than 0 2 μmol l in the most area from the downstream of narrow river channels to offshore region with a maximum decrease value of 1 8 μmol l around the mouth of the lingdingyang bay the plume front of 0 2 μmol l is mainly determined by the difference of surface residual currents in the two scenarios with and with typhoon winds in upstream narrow channels and open sea away from the pre the differences of phosphate concentrations between the two scenarios are basically lower 0 04 μmol l as for the small areas on the southeastern huangmaohai bay near the mouth of the modaomen and around the qi ao island the typhoon winds increase phosphate concentrations by 0 15 μmol l there are also considerable differences in din concentrations between the two typhoon wind scenarios and the effects of typhoon winds on din dynamics are gradually consistent with those of phosphate the difference value of din concentrations is between 20 μmol l and 88 6 μmol l in the most area from the downstream of upstream narrow channels to offshore region while this value decreases to 1 μmol l in upstream narrow channels and open sea away from the pre these spatial patterns can be explained by the residual current and storm surge differences between the two scenarios as shown in fig 11 the typhoon winds deflect the flow directions more landward weaken the seaward residual currents and make the structure of residual currents more chaotically in the large area from the downstream of upstream narrow channels to offshore region thus hindering the spread of nutrients from river sources to this area and causing lower nutrient concentrations beside a large amount of water with low nutrient concentration moved into the pre from open sea during the storm surge which also contributes to the dilution of nutrients in local area fig 14 illustrates the salinity distributions under the two typhoon wind scenarios and their differences in the scenario with typhoon wind effects salt intrusion is more dramatically intensified compared with that in the scenario without wind thereby causing the increase of the salinity values in the pre in the most area from the downstream of narrow river channels to offshore region the typhoon wind scenario increases the salinity 4 19 2 psu as for the east of hebao island the entrance of modaomen and the area around qi ao island the typhoon wind scenario causes the decrease of salinity values with the maximum difference of 1 0 psu in upstream narrow channels and open sea away from the pre the variation is lower 0 2 psu such a variation pattern is also related to the comprehensive influences of the increased storm surges and changed residual currents during the typhoon process statistically the averaged phosphate din and silicate concentrations of the whole computational domain decrease from 0 78 μg l 42 13 μg l and 74 72 μmol l to 0 51 μmol l 27 61 μmol l and 47 44 μmol l under the effects of the typhoon winds respectively the corresponding decrease rates are 34 62 34 46 and 36 51 which means that the typhoon wind process partly alleviates nutrient pollution nevertheless the averaged salinity concentration increases from 25 08 psu to 28 92 psu with the increase rate of 15 31 resulting in the serious threat of salinity intrusion in the pre 5 conclusions a coupled storm surge water quality model over the pre was established based on a parametric typhoon model fvcom circulation model and ersem to evaluate the storm surge process and its influence on nutrient and salinity dynamics using typhoon hagupit as a case study the measured typhoon winds storm surges and water quality factors at different stations were collected and used for coupled storm surge water quality model calibration and validation generally the simulation results of coupled model reasonably reproduced the measured data the comparative analysis of hydrodynamic process in the scenarios with and without typhoon winds shows that the typhoon winds can lead to the variation of water levels and flow velocities during a typhoon period under the influence of typhoon winds the maximum storm surges are larger than 2 0 m at the upstream of the huangmaohai bay and the lingdingyang bay and they gradually decrease to 0 4 m in open sea typhoon winds also weaken seaward residual currents and cause chaotic residual current structure the phosphate and din concentrations mainly decreases by 0 2 and 20 μmol l in the most area from the downstream of narrow river channels to offshore region while the variations are small in upstream narrow channels and open sea away from the pre as for salinity distribution during the typhoon passing through the pre it appears almost opposite variation compared with that of nutrients the salinity values increase by 4 19 2 psu in the most area from the downstream of narrow river channels to offshore region statistically the averaged phosphate din and silicate concentrations decrease by 34 62 34 46 and 36 51 while the averaged salinity concentration increases by 15 31 in the whole computational domain with the effects of typhoon winds in general strong typhoon winds bring about significant storm surges and notable distinct residual currents such hydrodynamics differences eventually lead to the obvious dilution of nutrient concentrations and serious salinity intrusion in the pre the results provided in this paper improve our understanding of the performance of typhoon wind in hydrodynamics process nutrient and salinity dynamics which may contribute to more accurately evaluate storm surge hazards and concomitant water quality issues during typhoon processes software availability software name and available the coupled modelling framework cmster consisting of the storm surge model and the european regional seas ecosystem model ersem is freely available from https github com hxzhangdlut cmster git fabm is applied to achieve the coupling between the two sub models and is freely available from https github com fabm model fabm developers yongming shen and hongxing zhang year first available 2022 hardware and software required matlab linux program language fortran language c program scale 17 mb contract information yongming shen state key laboratory of coastal and offshore engineering dalian university of technology dalian 116024 p r china e mail ymshen dlut edu cn fax international 86 411 84708526 tel international 86 411 84708514 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was funded by the program for guangdong introducing innovative and entrepreneurial teams grant no 2019zt08l213 the key special project for introduced talents team of southern marine science and engineering guangdong laboratory guangzhou grant no gml2019zd0403 and guangdong provincial key laboratory project grant no 2019b121203011 
25564,a coupled modelling framework consisting of the storm surge model and the european regional seas ecosystem model ersem has been established to examine hydrodynamics process during typhoon hagupit and its role on nutrient and salinity dynamics in the pearl river estuary pre the accuracy of modelling framework was reasonably validated against measured typhoon wind storm tide and water quality data further analysis suggests hagupit significantly increases water levels in the pre meanwhile the seaward residual currents apparently and chaotically change the phosphate and dissolved inorganic nitrogen concentrations decrease by 0 2 1 8 and 20 88 6 μmol l in the most area from the downstream of narrow river channels to offshore region due to the variations of hydrodynamics while small difference was detected in upstream narrow channels and open sea by contrast salinity distribution showed opposite variation statistically the typhoon winds alleviated the averaged nutrient pollution in the whole pre while causing serious saltwater intrusion keywords nutrient pollution saltwater intrusion storm surge residual current coupled modelling 1 introduction globally many estuarine deltas are densely populated and economically developed areas meanwhile various environmental problems from increased agricultural activities fish dike farming urban and industrial sewage effluents put enormous pressure on the local estuarine environment and dramatically threaten the sustainable development of economy and society shen et al 2002 yang and liang 2020 excess nutrient loading especially nitrogen from human activities e g wastewater input and land use change management and natural processes e g atmospheric deposition and precipitation can result in eutrophication and facilitate rapid phytoplankton growth thereby leading to potentially noxious and toxic algal blooms chen et al 2020 ren et al 2009 high turbidity from increased sediment runoff can increase light attenuation thus limiting the blooms of phytoplankton e g chao et al 2008 liu and huang 2009 wang et al 2019 as salt intrusion affects the estuarine density gradient mixing and circulation processes it changes the transport processes of nutrients and contaminants sun et al 2020 the flocculation re suspension as well as trapping of fine sediments ren and wu 2014 and phytoplankton dynamics lu and gan 2015 in estuaries enhanced salt intrusion even causes significant threat to the survival of some aquatic species in estuaries and the status of estuarine ecosystems huang et al 2015 moreover the estuarine ecosystem is always a fragile system which is particularly vulnerable to the impacts of external forcing like climate change human activities extreme weather and marine disasters e g tsunami storm surge and earthquake thus it is crucial to analyze the impacts of these environmental drivers and understand the mechanism that underlies the dynamic process of water quality factors in estuaries the pearl river estuary pre is one of the largest river systems and the most developed regions in china covering several major cities e g guangzhou shenzhen zhuhai hongkong and macao fig 1 a variety of economic development activities are conducted in the estuary including port construction industrial development tourism and aquaculture the rapid economic growth of this region has become a great cause for concern in terms of the scale of pollution in particular a large amount of incomplete treatment wastewater with high concentration of anthropogenic nutrients discharged into the pre through the eight major tributaries humen jiaomen hongqili hengmen modaomen jitimen hutiaomen and yamen and ultimately transported to the south china sea scs the water quality in the pre and its adjacent areas met the grade v according to china national sea water quality standard failing to reach the requirements of the class v chen et al 2007 several extensive field surveys have been conducted to investigate water quality in the estuary and the results showed that nutrients and organic pollutants are two of the major nutrient indicators especially excess nitrogen over enrichment xu et al 2008 yin and harrison 2008 due to the continuous decrease of freshwater and the dramatic change of river course saltwater intrusion has significantly intensified and it become another typical environment issue in the pre zhang et al 2010 saltwater intrusion occurs if seawater from the oceanic continental shelf of the estuary enters the river section along the main channel with tide and increases the salinity value in this region the river discharge in the pre is significantly affected by the monsoonal climate and characterized by distinct changes between dry from november to march and wet from may to october seasons with approximately 80 water being discharged during the wet season ren et al 2014 the saltwater from open sea is largely suppressed by a large amount of freshwater discharge which does not cause serious salinity intrusion nevertheless the 5 psu isohaline can extend 80 km landward from the estuary s mouth with the significant decrease of freshwater discharge during the dry season which poses a great threat to the drinking water supply in the area and to the habitat of many fish and invertebrate species there is a common consensus that the continuous in situ observation and monitoring of the water quality factors e g temperature salinity and pollutant concentrations those highly correlated with the estuarine environment are time consuming labour intensive and costly especially involving large scale processes the measurement of water quality will be more difficult to conduct during the extreme weather and marine disasters e g tsunami storm surge and earthquake with significant advancement in computing techniques and power water quality modelling has become an effective way to study the polluted characteristics there has been substantial growth of publications focusing on improvements of existing models and techniques and case studies fu et al 2020 jakeman et al 2006 and blocken and gualtieri 2012 set out ten iterative steps for the development and evaluation of models which provides a comprehensive framework that encompasses and extends the existing best practice guidelines over the last few decades the numerical study of the water quality in the pre has been widely conducted chau and jiang 2002 developed a three dimensional numerical pollutant transport model to simulate the transport and distribution of chemical oxygen demand in the pre and the numerical results illustrated that the inter boundary effects of pollutants between the guangdong province and the hong kong special administrative region are quite strong due to the wastewater discharged from the pearl river delta region hu and li 2009 analyzed the flux and transformation of nutrients in the pearl river network and delta by combining a one dimensional model and a three dimensional estuary model wei et al 2016 developed a coupled three dimensional hydrodynamic biological model for the pre to investigate the effects of river discharges and winds on hypoxia during the summer sun et al 2020 built a three dimensional water age wa model base on delft3d flow numerical model to predict the vertical wa distribution in the pre and further quantitatively investigate the effects of vertical water renewal on water quality by linking the wa and dissolved oxygen levels gong et al 2018 examined the effects of winds and waves on salt intrusion in the pre using the coupled ocean atmosphere wave sediment transport coawst modeling system the pre adjacent to the main development region of western pacific typhoons suffers the most frequent typhoons among all the global typhoon active oceans causing severe storm surges in coastal regions of pre according to the statistical data from the china meteorological observatory fifty two typhoons made landfall on the coastal area of pre from 2008 to 2018 fourteen typhoons causing high storm surges over 1 m were observed in hong kong from 1999 to 2018 h k o 2017 jian et al 2021 demonstrated that the mean surge heights along the pre coastline are in the range of 1 5 3 2 m and 2 0 3 5 m under 100 year and 200 year return periods respectively using a steady state surge model tang et al 2012 demonstrated that large surface elevations and intense surface currents are generated over the pre due to the storm surge effects during super typhoon koryn yin et al 2017 revealed that typhoon intensification has a greater impact on storm surge slr has a greater impact on wave heights in the estuary and the combination of those two factors also increases peak surge height and wave height during typhoons hagupit and dujuan zhang et al 2021 pointed out that storm surges and waves weaken estuarine water circulation and water renewal ability during typhoon hagupit passing through the pre previous studies have widely and separately studied the water quality and storm surge process in the pre with various conditions nevertheless short term dynamic processes of nutrients and salinity especially those influenced by typhoons in and near the pre have yet to be fully elucidated authors surmise that typhoon induced storm surge may significantly influence the dynamic processes of nutrients and salinity by changing hydrodynamic characteristics and water circulations as the important water quality parameters triggering a series of environmental problems e g eutrophication algae bloom and species death in the pre studying the response of nutrients and salinity during extreme typhoons is essential to understand the key factors that control estuarine dynamics and coastal ecosystems and provide scientific supports for estuarine environmental management in the present study we aim to establish a coupled storm surge water quality model to further analyze and discuss the effects of typhoon wind on storm surge nutrient and salinity transport processes during a typhoon process 2 numerical models in order to investigate the key physical biochemical processes of water quality parameters and their response to hydrodynamic processes caused by typhoons the schematic diagram of the coupled storm surge water quality model framework is conducted in this study as shown in fig 2 the storm surge model within fvcom framework describes the storm surge process of the study region and provides the background physical forcing e g flow velocity water depth temperature and shortwave radiation to the water quality model the water quality model is based on the european regional seas ecosystem model ersem baretta et al 1995 and it describes the biogeochemical processes in the study region the fortran based framework for aquatic biogeochemical models fabm is a domain independent programming framework with support for any number of processes prognostic variables diagnostic variables and advanced features e g sea ice biota benthos and sediment in surface and bottom layers and multiple feedbacks to physics thus it is applied to achieve the coupling between storm surge model and water quality model 2 1 storm surge model 2 1 1 momentum and continuity equation the fvcom originally developed by chen et al 2003 is a prognostic free surface three dimensional ocean circulation model based on the unstructured finite volume method the unstructured triangular mesh used in fvcom is capable of resolving complex geometry and bathymetry and fvcom has been widely applied to the simulation of hydrodynamics and pollutant transport process in many estuarine and coastal regions guo et al 2009 zhang et al 2021 the 3d equations of momentum and continuity in σ coordinate are presented as follows 1 u d t u 2 d x v u v d y u ω σ f v d g d ζ x d ρ 0 p a x g d ρ 0 σ 0 d ρ x d σ d x σ 0 σ ρ σ d σ 1 d σ k m u σ d f u 2 v d t u v d x v v 2 d y v ω σ f u d g d ζ x d ρ 0 p a x g d ρ 0 σ 0 d ρ y d σ d y σ 0 σ ρ σ d σ 1 d σ k m v σ d f v 3 ζ t d u x d v y ω σ 0 where u v and ω are the velocity components in horizontal x y and vertical σ directions respectively d is the total water depth f is the coriolis parameter ζ is the water surface elevation p a is the atmospheric pressure g is the gravitational acceleration ρ 0 is the reference density ρ is in situ density k m is the vertical viscosity coefficient f u and f v represent the diffusion terms in x and y directions respectively 2 1 2 typhoon wind model wind stress and atmospheric pressure are responsible for generating storm surge on sea surface the accuracy of typhoon model restricts the accurate degree of modeling storm surge characteristics which further affects the transport and distribution of water quality factors hence it is critical precondition for storm surge and water quality simulations to reasonably predict wind and pressure fields during a typhoon in the past few decades numerous wind models and dataset have been applied to simulate the pressure and wind fields jelesnianski 1965 holland 1980 wang et al 1991 wang and shen 2012 in this study the nested model of fujita formula and takahashi formula was considered to simulate pressure field because of its successful applications in many coastal and estuarine waters yin et al 2018 the formulas can be written as follows 4 p r p p p 0 1 2 r r 2 0 r 2 r 5 p r p p p 0 1 r r 2 r r where r is the distance from the station to the center of the typhoon in the computed region p r is the pressure at a distance r from the typhoon center p is the ambient or environmental pressure 1013 25 hpa p 0 is the typhoon center pressure r represents the radius of maximum wind speed from the typhoon center and it is proposed as 6 r 28 52 tanh 0 0873 φ 28 12 22 exp p 0 1013 25 33 86 0 2 c m where φ is the typhoon center latitude c is the speed at the typhoon center m is initial radius in addition ueno formula was considered to simulate wind field in the pre during a typhoon process and it can be defined as follows when 0 r 2r 7 w x c 1 v x e x p π 4 r r r c 2 f 2 f 2 4 10 3 2 δ p ρ a r 2 1 2 r r 2 3 2 x x 0 sin θ y y 0 cos θ 8 w y c 1 v y e x p π 4 r r r c 2 f 2 f 2 4 10 3 2 δ p ρ a r 2 1 2 r r 2 3 2 x x 0 cos θ y y 0 sin θ when 2r r 9 w x c 1 v x e x p π 4 r r r c 2 f 2 f 2 4 10 3 δ p ρ a r r 1 r r 2 x x 0 sin θ y y 0 cos θ 10 w y c 1 v y e x p π 4 r r r c 2 f 2 f 2 4 10 3 δ p ρ a r r 1 r r 2 x x 0 c o s θ y y 0 sin θ where w x and w y the surface wind stresses in x and y directions respectively c 1 and c 2 are empirical constants v x and v y are typhoon forward velocities in x and y directions respectively ρ a is the air density and it is given by 1 2929 kg m3 θ is the inflow angle 20 δp is pressure deficit at surface boundary the effect of wind stress on water body is expressed as 11 k m u σ v σ 1 ρ τ s x τ s y ω ζ t ζ x ζ y where τ s x τ s y c d s ρ a w x 2 w y 2 w x w y are the x and y components of surface wind stress c d s is the drag coefficient of wind and it is calculated by 12 c d s 0 0012 if u 11 m s 0 001 0 49 0 0065 u if 11 m s u 25 m s 0 001 0 49 0 0065 25 if 25 m s u where u w x 2 w y 2 is the wind velocity base on above parametric typhoon model the calculated pressure and winds fields were provided to fvcom model to generate storm surges in the pre during a typhoon period then the storm surge model provides the background physical forcing e g flow velocity water depth temperature and shortwave radiation to control the transport of water quality factors 2 1 3 solving method the momentum equations are solved numerically applying a combined explicit and implicit scheme in which the local change of the currents is integrated using a second order accurate upwind scheme in time the advection terms are computed explicitly by a second order accurate upwind scheme and the vertical diffusion is solved implicitly the calculations of velocity components in x and y directions are both conducted in two steps for example the x component of the transition velocity u i k at the midpoint between the k and k 1 σ levels in triangular cell i is firstly calculated using all the terms except the vertical diffusion term r u i k n in the momentum equations 13 u i k u i k n δ t i ω i δ σ d i r u i k n where δ σ σ k σ k 1 n is the indicator of the nth time step ω i is the area of the ith triangle mesh δ t i is the time step for the internal mode then the true velocity is determined implicitly applying a balance between the local change of the transition velocity and the vertical diffusion term 14 a i k u k 1 n 1 b i k u k n 1 c i k u k 1 n 1 u where 15 a i k 2 k m k 1 δ t d n 1 2 σ k σ k 1 σ k σ k 2 c i k 2 k m k δ t d n 1 2 σ k σ k 1 σ k 1 σ k 1 b i k 1 a i k c i k the solution of u k is calculated by 16 u k a i k b i k c i k v h k 1 u k 1 u c i k v p h k 1 b i k c i k v h k 1 where 17 v h k a i k b i k c i k v h k 1 p h k u c i k v p h k 1 b i k c i k v h k 1 the vertical velocity ω is calculated by 18 ω j k 1 ω j k δ σ k δ t i ζ j n 1 ζ j n δ σ k ω j t c e l v n k n d d l where j is the indicator of the jth node point ω j tce means the area of the jth tracer control element tce and it is defined in the reference of chen et al 2003 n means an indicator of the velocity component normal to the boundary of a tce with a length of l 2 2 water quality model the water quality model based on ersem is applied to describe the biogeochemical processes of nutrients in the pre ersem is a high complexity lower trophic food web model including both pelagic and benthic systems fig 3 it uses a functional group approach e g trait and size to form four phytoplankton groups three zooplankton groups and one bacteria group within the pelagic model the biogeochemical cycling of inorganic dissolved nutrients nitrogen phosphorus and silicon was represented by modulating the cycling between producers consumers and decomposers using variable stoichiometric ratios within the pelagic model 2 2 1 transportation equation the biogeochemical variables as passive tracers are subjected to advection and diffusion therefore the rate of variation for the concentration c pel of a pelagic biogeochemical variable can be expressed as 19 c pel t u c pel x v c pel y ω c pel σ x a h c pel x y a h c pel y σ k h c pel σ b f where u v and ω are the velocity components in horizontal x y and vertical z directions respectively a h is the horizontal eddy diffusion coefficient and k h is the vertical eddy diffusion coefficient b f represents the total biochemical flux and it is calculated by ersem a correct estimation of horizontal and vertical eddy diffusion coefficients is very important as they greatly affect final results about concentration of water quality parameters in this study horizontal diffusion coefficient is estimated by the smagorinsky eddy parameterization method smagorinsky 1963 20 a h 0 5 c t ω t c e p r u x 2 0 5 v x u y v y 2 where c t is a constant parameter and p r is the prandtl number the vertical thermal diffusion coefficient k h is estimated by the mellor yamada level 2 5 turbulence closure scheme mellor and yamada 1982 in the boundary layer approximation the shear production of turbulent kinetic energy is produced by the vertical shear of the horizontal flow near the boundary the equations for q 2 and q 2 l can be simplified as 21 q 2 t u q 2 x v q 2 y ω q 2 σ 2 p s p b ε σ k q q 2 σ f q 22 q 2 l t u q 2 l x v q 2 l y ω q 2 l σ 2 e 1 p s p b w e 1 ε σ k q q 2 l σ f l where q 2 is the turbulent kinetic energy l is the turbulent macroscale k q is the vertical eddy diffusion coefficient of the turbulent kinetic energy f q and f l mean the horizontal diffusion of the turbulent kinetic energy and macroscale p s and p b are the shear and buoyancy production terms of turbulent kinetic energy ε is the turbulent kinetic energy dissipation rate w 1 e 2 l 2 κ l 2 is a wall proximity function where l 1 ζ σ 1 h σ 1 and κ 0 4 is the von karman constant e 1 and e 2 are close constants of the model the turbulent kinetic energy and macroscale equations are closed by defining 23 k m l q 0 4275 3 354 g h 1 34 676 g h 1 6 127 g h k h l q 0 494 1 34 676 g h k q 0 2 l q where g h l 2 q q 2 ρ 0 ρ has an upper bound of 0 023 for the case of unstable stratification and a lower bound of 0 28 for the case of stable stratification 2 2 2 biogeochemical process in order to obtain a better understanding of main pollutant in the pre caused by excessive nutrients the biogeochemical cycling of dissolved inorganic nutrients oxidized nitrogen ammonium phosphorus and silicate is presented in this section 24 c ox n t bgc c ox n t nitr c ox n t upt 25 c amm n t bgc c amm n t remin c amm n t rel c amm n t upt c amm n t nitr 26 c p t bgc c p t remin c p t rel c p t upt 27 c s t bgc c s t rel c s t upt where c ox n c amm n c p and c s represent the oxidized nitrogen ammonium phosphorus and silicate concentrations in pelagic layer respectively the oxidized nitrogen may be regenerated exclusively and ammonium may be further reduced by nitrification 28 c ox n t nitr r nitr b l t b l o nitr l n nitr l ph c amm n 29 c amm n t nitr r nitr b l t b l o nitr l n nitr l ph c amm n where c means the nutrient concentration in the water body excluding background concentration r nitr b is the maximum ammonium mass specific nitrification rate at reference temperature l t b l o nitr l n nitr and l ph is the regulation and limitation factor of temperature oxygen nitrogen and ph respectively and they have been given by butenschön et al 2015 in pelagic layer oxidized nitrogen ammonium and phosphorus are taken up by phytoplankton and bacteria 30 c ox n t upt ψ r aff ox ψ c ox n r aff ox ψ c ox n r aff amm ψ c amm n p n ψ t upt 31 c amm n t upt ψ r aff ox ψ c amm n r aff ox ψ c ox n r aff amm ψ c amm n p n ψ t upt b n t upt 32 c p t upt ψ p p ψ t upt b p t upt where ψ is the indicator of the ψth phytoplankton r aff ox and r aff amm is the affinity of oxidized nitrogen and ammonium p n p is the phytoplankton nitrogen or phosphorus b n p is the bacteria nitrogen or phosphorus the uptake of nitrogen and phosphorus by phytoplankton group is regulated by their nutrient demand f demand p n p ψ c n p and limited by the external availability f avail p n p ψ c n p 33 p n p ψ t upt min f demand p n p ψ c n p f avail p n p ψ c n p if f demand p n p ψ c n p 0 0 if f demand p n p ψ c n p 0 where 34 f demand p n p ψ c n p s gpp ψ 1 δ excr ψ 1 q aresp ψ q maxn p c ψ p c ψ r nlux q maxn p c ψ p c ψ p n p ψ r rsep ψ p n p ψ 35 f avail p n ψ c n r aff ox ψ c ox n r aff amm ψ c amm n p c ψ 36 f avail p p ψ c p r aff p ψ c p p c ψ s gpp is the mass specific gross primary production of phytoplankton δ excr is the excretion fraction of gross primary production q aresp is the fraction of the assimilated amount of biomass per time unit after excretion q maxn p c is the maximum nitrogen or phosphorus to carbon quota r nlux is the rate of nutrient luxury uptake towards the maximum quota r resp is the specific rate of rest respiration at reference temperature p c is the phytoplankton carbon concentration including background carbon concentration p c n p is the phytoplankton carbon nitrogen or phosphorus concentration excluding background concentration r aff p is the affinity of phosphorus the uptake up of bacteria on nitrogen and phosphorus is expressed as 37 b n p t upt r rel b q n p c b q maxn p c b b c c amm n p c amm n p h n p b if q n p c b q maxn p c b 0 if q n p c b q maxn p c b where r rel b is the mass specific release rate q n p c is the nitrogen or phosphorus to carbon quota h n p b means the half saturation constant for phosphorus or nitrogen limitation silicate is taken up by diatoms 38 c s t upt max q ref s c dia s growth dia 0 where q ref s c dia is the reference silicate to carbon quota of diatoms s growth dia is the substrate mass specific uptake of diatoms the remineralization process of ammonium and phosphorus can be evaluated as 39 c amm n t remin r rem n r lab n 40 c p t remin r rem p r lab p where r rem n and r rem p are the mass specific remineralization rates of nitrogen and phosphorus r lab n and r lab p mean the labile dissolved organic matter dom nitrogen and phosphorus concentrations excluding background concentrations the release processes of nutrients are evaluated as 41 c amm n t rel ψ p n ψ t rel k z n k t rel b n t rel 42 c p t rel ψ p p ψ t rel k z p k t rel b p t rel 43 c s t rel p s dia q ref s c dia p c dia where 44 p n p ψ t rel 0 if f demand p n p ψ c n p 0 f demand p n p ψ c n p if f demand p n p ψ c n p 0 45 z n p k t rel min 0 z n p k q n p c k z c k r reln p k 46 b n p t rel 0 if q n p c b q maxn p c b r rel b q n p c b q maxn p c b b c if q n p c b q maxn p c b z c n p is the zooplankton nitrogen phosphorus or carbon concentration including background concentration z c n p is the zooplankton carbon nitrogen or phosphorus concentration excluding background concentration b c is the bacteria carbon concentration excluding background concentration r reln p means the relaxation rate of release into dissolved inorganic form 2 2 3 coupling of benthic model and pelagic model a simple benthic return model was applied instead of the standard dynamical benthic model baretta bekker et al 1997 which considered the settling of organic matter and phytoplankton into the benthos and diffusional inorganic nutrient fluxes from the sediment layer deposition fluxes of organic matter and phytoplankton from pelagic layer into benthic layer are expressed as 47 f ben c pel ω depo c pel c pel where ω depo c pel max 1 τ bed τ crit 0 ω sed c pel is the deposition velocity ω sed c pel is the velocity of gravitational sinking τ bed is the seabed shear stress and τ crit is the critical seabed shear stress the absorption of deposited nitrogen and phosphorus components into the sediments then results in separation of the organic material into dissolved degradable and refractory matter according to 48 f pel q n p degr ψ 1 q ddepo ψ p cyto n p lab q rdepo ψ p cyto n p part f p n p ψ ben χ 1 q rdepo part f r n p χ ben 49 f pel q n p refr ψ q rdepo ψ p cyto n p part f p n p ψ ben q rdepo part f r n p χ ben 50 f pel q n p dis ψ q ddepo ψ p cyto n p lab f p n p ψ ben where q n p degr q n p refr and q n p dis represent the degradable organic nitrogen and phosphorus dissolved organic nitrogen and phosphorus and refractory nitrogen and phosphorus in benthic layer respectively q ddepo ψ and q rdepo ψ are the dissolved and refractory fractions of ψth phytoplankton r n p χ is the ᵡth organic matter nitrogen or phosphorus and q rdepo part is its particle fractions p cyto n p lab reflects the relative nitrogen or phosphorus content of cytoplasm of labile dissolved organic matter with respect to the structural components and p cyto n p part reflects the relative nitrogen or phosphorus content of cytoplasm of particulate organic matter pom the silicate component is entirely directed to degradable matter 51 f q s degr pel f ben p s dia f ben r s med f ben r s large where q s degr is the degradable organic matter silicate in benthic layer r s med and r s large mean the medium and large size pom the variables in the benthic layer are returned into the pelagic layer during resuspension and remineralization processes 52 f n p s resusp r med q des r err max τ bed t crit 1 0 q n p s des 53 f p s remin c p s q p s λ r remin λ q p s λ 54 f n remin c ox n q n λ q remin ox n r remin λ q n λ 55 f n remin c amm n q n λ 1 q remin ox n r remin λ q n λ where λ represents the indicator of the λth benthic organic matter r err represents erosion rate q n p s is the benthic organic nitrogen phosphorus or silicate concentration excluding background concentration r remin is the remineralization rate q remin ox n is the nitrate fraction of remineralised nitrogen 3 model configuration and verification 3 1 model configuration since the typhoon winds and storm surges affect the area of interest over a relatively large region during a typhoon process and the hydrodynamic as well as water quality characteristics at the open boundary of the model mesh are tough to be accurately simulated the mesh boundaries should be sufficiently far away from the area of interest so as to guarantee that the boundary disturbances do not affect its hydrodynamic and water quality process however it may decrease the degree of computed resolution or increase computational cost due to the use of different grid sizes and numbers consequently a two nested mesh system was performed to achieve the feature that may predict the hydrodynamics and water quality parameters over the area of interest efficiently and accurately fig 4 the domain of outer model covered not only the whole pre but also a main part of the south china sea 105 7 119 9 e 13 6 23 1 n in the outer domain the total number of mesh element and node was set as 39729 and 21079 respectively the mesh resolution changed from about 25 km on the open boundary of the outer model to about 300 m in the area of the interest jakeman et al 2006 expressed that even some crude error estimates based on output sensitivity to the most important variables is useful during uncertainty analysis process in inner model two resolution high resolution hr and low resolution lr meshes were considered to estimate their effects on model output fig 4b and c fig 4d and e plot the enlarged view of the two resolution meshes in lingdingyang bay the information of mesh element and node is shown in table 1 a global topography database etop1 https ngdc noaa gov mgg globalglobal html was extracted for bathymetry interpolation in the most of study region except for the pre where the bathymetry data was obtained from higher resolution field measurement fig 1b along the open sea boundary of outer model the time series water levels induced by astronomical tide were specified by the four main tidal constituents m2 s2 k1 and o1 and four minor constituents n2 k2 q2 and p1 the temperature salinity nutrient and chlorophyll a values were extracted from the global reanalysis data of the cmems database for the conditions of open sea boundary e g water level flow velocity salinity and water quality factors in inner model which were calculated and provided by the outer model the eight major tributaries humen jiaomen hongqili hengmen modaomen jitimen hutiaomen and yamen are set as river discharge open boundary and the river discharge was confirmed based on historical flow data from river outlets in pre the nutrient loads at the river boundaries were obtained from the field surveys liu 2006 jos et al 2007 as for the sea surface boundary the data was obtained from ecmwf database including atmospheric pressure wind relative humidity clearness coefficient temperature evaporation precipitation and shortwave radiation etc in this study the parameters used in the water quality model were derived from observation in the pre and from scientific literatures jos et al 2007 blackford and burkill 2002 petihakis et al 2002 based on the above parameter values the key model parameters were further calibrated to comprehensively understand the performance of key parameters that affect the model results and accurately predict water quality process and their values are listed in table 2 the entire simulation time includes the process required by hydrodynamics and water quality to achieve dynamically steady state and the process of development and movement of hagupit in the scs from 00 00 on 1 june to 24 00 on 30 september 2008 utc in hydrodynamics model the mode splitting method is used the free water surface is integrated by solving vertically averaged equations in external mode and the 3d momentum equations are integrated in internal mode the fixed time steps of 5 s and 30 s have been used for the external and internal modes as for water quality model the time step was set as 30 s 3 2 sensitivity analysis of mesh resolution in this section sensitivity analysis has been performed using two types of inner meshes with hr and lr table 3 presents a quantitative comparison of hydrodynamics and water quality parameters tide level salinity and dissolved inorganic nitrogen din at twenty selected stations although the ratio of two mesh resolution is about 2 times in the pre the difference of tide level salinity and din at most selected stations is very close the maximum change rates of tide level salinity and din are 0 878 2 529 and 3 679 and they appears at stations 4 18 and 9 respectively all of above results confirm that even the mesh resolution of 50 4800 m is able to reasonably simulate hydrodynamics and water quality processes and the simulation results do not obviously change with the further improvement of mesh resolution therefore a lr inner mesh was used for further verification and application in order to improve the calculation efficiency 3 3 model verification 3 3 1 typhoon wind and storm surge hagupit 0814 initially developed as a tropical storm in the northwestern pacific on sept 19 2008 see fig 5 for track it was strengthened into a typhoon on sept 21 and further upgraded into a severe typhoon on sept 22 the typhoon then advanced west northwestwards and further intensified in the scs with maximum wind speeds of 50 m s and a minimum pressure of 935 hpa at 22 45 utc time on sept 23 it made landfall over the coastal region of maoming county guangdong province after landfall hagupit gradually weakened and eventually disappeared during the typhoon many tidal gauge stations in the pre reached or broke the 100 year annual maximum water level record the highest water level was 3 5 m and it appeared at beijingang station see fig 5 for location the government statistics showed that 22 people died and direct economic losses amounted to us 1 742 280 000 during this typhoon as a representative of the severe typhoon to make landfall in the pre hagupit was used to validate the typhoon and storm surge models and further investigate typhoon wind effects on hydrodynamics nutrient and salinity dynamics the detail hagupit information e g hourly typhoon central location pressure and maximum wind speed was obtained from the chinese typhoon weather web site http typhoon nmc cn web html to verify the accuracy of typhoon and storm surge models in the pre three gauge stations fuliu mountaion hengmen and huangjin see fig 6 for location were chosen to compare the wind speeds and storm tides between measurements and simulations during hagupit fig 7 the performance of numerical model was assessed by calculating the four widely used metrics including mean absolute error mae root mean square error rmse relative mean square error msre and pearson product moment correlation ppmc these metrics were systematically discussed by bennett et al 2013 as shown in table 4 in this table y i and y ˆ i are the ith simulated value and observed value respectively y and y are the mean values of the simulated and observed results as it can be seen from the typhoon wind process at fuliu mountaion station the nested typhoon model is capable of simulating wind field for the hydrodynamic model with a mae value of 2 27 m s a rmse value of 2 84 m s and a msre value of 0 29 m s respectively table 5 the value of ppmc is 0 93 showing the good consistency between the measured wind speeds and simulated results the errors in the wind modelling are generally reasonable and acceptable in comparison to those given in peer reviewed literature for example the average rmse value presented by yin et al 2018 for their typhoon modelling of pre is 3 05 m s with a correlation coefficient of 0 89 the measured data collected at stations hengmen and huangjin were utilized to validate the simulation accuracy of the storm tide it can be seen that the simulated range and phase of the storm tide were in reasonable agreement with the measurements at hengmen station the mae rmse msre and ppmc values of the simulated storm tide from the measured values are 0 27 m 0 32 m 0 01 m and 0 93 respectively and these values are 0 18 m 0 31 m 0 01 m and 0 94 at huangjin station the above validation results indicated that the storm surge model can reasonably predict the variation of storm surge process during hagupit the spatial distribution of simulated wind speeds in the scs at 6 h intervals from 12 00 utc on september 23 2008 to 06 00 utc on september 24 2008 was shown in fig 8 the wind fields in the scs presented a counterclockwise circulation structure under the influence of hagupit the maximum wind speed reached 47 m s at the location being the maximum typhoon radius away from typhoon center when typhoon center was located in the south of the pre 108 9 e 21 9 n strong offshore winds appeared in the extensive region between the beibu gulf and the pre which were opposite with those in the east region of the pre fig 8a the wind speeds in the pre ranged from 14 m s to 26 m s with the typhoon center moving toward the pre 111 6 e 21 3 n the wind field in the pre was more significantly determined by the typhoon and the range of wind speeds was 16 35 m s their direction turned landward at this time moreover the maximum wind speed with tiny change in the value appeared in the southwest of the pre fig 8b when typhoon center made landfall in the coastal region of maoming county the wind directions turned southerly and the wind speeds decreased to 14 6 m s in the pre fig 8c eventually they decreased to 7 m s after typhoon center making landfall fig 8d 3 3 2 water quality given the difficulty of in situ water quality measurement during typhoon hagupit there is no relevant measured water quality data at this time therefore the in situ water quality data from twelve stations see fig 6 for location before the typhoon was used to validate the water quality model and the results are plotted in fig 9 including salinity temperature phosphate din and silicate the simulated water quality values match well with the measurement data at the most monitoring stations of the pre while relatively large errors appear at the several stations near offshore region due to the limited accuracy of water quality data specified at the open sea boundary table 6 shows that the averaged values of mae rmse and msre between the simulated salinity and measured results are 1 97 2 47 and 0 02 psu respectively with an averaged ppmc value of 0 84 a smaller averaged value of ppmc 0 65 appears between simulated and measured temperature which can be explained by that variation of the temperature in the spatial distribution is slight and it is very difficult to be accurately captured by water quality model nevertheless the water quality model can reasonably reproduce the amplitude of measured temperature with an averaged mae value of 1 79 c an averaged rmse value of 1 96 c and an averaged rmse value of 0 06 c as for phosphate din and silicate the averaged values of ppmc are all larger than 0 95 showing the good consistency between the simulated values and measured results in general the overall agreement in terms of the water quality factors is less satisfactory although still being acceptable it laid a solid foundation for further discussion about the effect of typhoon process on nutrient and salinity dynamics 4 results and discussion based on the model configuration and validation mentioned above the established model was utilized to test the effects of hagupit on hydrodynamics nutrient and salinity simulations in the pre in the numerical simulations two scenarios without and with typhoon wind effects were performed while the other model conditions and parameters kept fixed a comparison was then conducted between the results obtained in the variable typhoon wind scenarios to find out how storm surges and water quality simulations are impacted by the typhoon winds in the pre 4 1 impacts of typhoon winds on hydrodynamics to characterize the impacts of hagupit on hydrodynamics process in the study region the time series of storm surges and flow velocities at three selected points e1 e2 and e3 the representative of the sub regions lingdingyang bay maodaomen huangmaohai bay in the pre respectively see fig 6 were analyzed with and without the wind conditions as showed in fig 10 the height of storm surge was obtained by the surge tide in the case with typhoon winds minus the astronomical tide in the case without typhoon winds it can be seen that the storm surges are characterized by single peak shape at all selected points and the whole durations of the storm surges are around 1 day when the typhoon was far away from the selected points the storm surges slowly decreased due to the effects of typhoon winds with seaward direction with the arrival of the typhoon they rose sharply and formed a distinct peak with a maximum value of 1 12 1 08 1 36 m at e1 e2 and e3 points respectively the storm surges decreased faster after the peak and then there were severe small amplitude oscillations meanwhile the seaward flow currents at three selected points were first slowly increased by the typhoon wind forcing from the similar direction before the typhoon center arrived here then they were significantly weakened by the typhoon winds from the opposite direction and their directions even reversed landward when the typhoon passed through the selected points fig 11 presents the distribution of the maximum storm surges caused by hagupit and the surface residual currents without and with wind conditions during a typhoon period at the upstream of the huangmaohai bay and the lingdingyang bay the heights of maximum storm surges are more than 2 0 m and they gradually decreases toward open sea the maximum storm surge heights are generally lower than 0 4 in open sea under the influence of typhoon winds the surface residual currents significantly increase in the huangmaohai bay the upstream of the lingdingyang bay and the southwest of the pre in the huangmaohai bay the maximum surface residual current increases from 0 3 m s to 0 6 m s the surface residual currents averagely increase from 0 08 to 0 19 m s in the upstream of the lingdingyang bay in the southwest of the pre the variation is from 0 26 to 0 6 m s nevertheless the results of the scenario with typhoon winds in the main channel of the jitimen show lower seaward residual currents the biggest residual current decreases from 0 58 m s to 0 29 m s due to typhoon wind effects along the main channel in the mouth of the lingdingyang bay the residual currents are mainly lower than 0 3 m s and this value increases to 0 4 m s in the scenario without typhoon winds the typhoon winds apparently increase the area with larger residual velocity of 0 5 m s meanwhile the flow directions deflect westward in the whole pre with the effects of typhoon winds and the seaward currents in some regions even reverse landward which significantly contributes to weaken seaward residual currents and make the structure of residual currents more chaotically 4 2 impacts of typhoon winds on nutrient and salinity dynamics previous studies show that the environmental status and variations in estuaries are mainly controlled by the complex interplay between physical chemical and biological processes ren et al 2014 chi et al 2020 as illustrated in the previous section different typhoon wind scenarios result in obvious variations of hydrodynamics process in study region to further improve the understanding of wind forcing contribution during a typhoon period the nutrient and salinity processes with and without typhoon winds were also investigated by the validated hydrodynamic water quality model fig 12 compares the time series of computed din and salinity concentrations at three selected points with variable typhoon wind scenarios before hagupit arrived the pre and its adjacent region the local winds were dominant and they slightly affected the amplitude and variation of din concentrations at the selected points due to small wind stress then the din concentrations were most dramatically decreased with significantly weakened seaward residual currents and increased storm surges since the landward typhoon winds approached here statistically the din concentration differences between two scenarios the scenario with winds minus the scenario without winds at the e1 e2 and e3 points are in the range of 46 28 9 54 μmol l 48 51 25 09 μmol l and 54 09 25 78 μmol l indicating the non ignorable affects of the wind forcing on nutrient dynamics especially during the typhoon on the contrary salinity values apparently increased at the three selected points with the landward typhoon winds promoting the intensification of salinity intrusion in pre statistically the salinity concentration differences between the two scenarios the scenario with winds minus the scenario without winds at e1 e2 and e3 points are in the range of 0 95 8 41 psu 5 10 8 56 psu and 3 40 9 64 psu indicating the serious threat in saltwater intrusion during the typhoon fig 13 a d shows the spatial distribution of simulated phosphate and din concentrations in the scenarios without and with typhoon winds respectively from the simulation results it can be seen that the simulated phosphate concentration decreases from 2 μmol l in the river source to 0 4 μmol l in offshore plume water and the din concentration decreases from 120 to 20 μmol l in the pre compared with the scenario with typhoon winds both the din and phosphate concentrations are transported to further distances in the scenario without typhoon winds to facilitate comparison the phosphate and din concentrations in the scenario without typhoon winds were subtracted from those in the scenario with typhoon winds to obtain the spatial distribution of concentration differences as is shown in fig 13 e and f examination of the spatial distribution of nutrient differences between these two typhoon scenarios revealed that the impacts of typhoon winds on nutrient distributions are significant the typhoon winds mainly decrease the phosphate concentrations more than 0 2 μmol l in the most area from the downstream of narrow river channels to offshore region with a maximum decrease value of 1 8 μmol l around the mouth of the lingdingyang bay the plume front of 0 2 μmol l is mainly determined by the difference of surface residual currents in the two scenarios with and with typhoon winds in upstream narrow channels and open sea away from the pre the differences of phosphate concentrations between the two scenarios are basically lower 0 04 μmol l as for the small areas on the southeastern huangmaohai bay near the mouth of the modaomen and around the qi ao island the typhoon winds increase phosphate concentrations by 0 15 μmol l there are also considerable differences in din concentrations between the two typhoon wind scenarios and the effects of typhoon winds on din dynamics are gradually consistent with those of phosphate the difference value of din concentrations is between 20 μmol l and 88 6 μmol l in the most area from the downstream of upstream narrow channels to offshore region while this value decreases to 1 μmol l in upstream narrow channels and open sea away from the pre these spatial patterns can be explained by the residual current and storm surge differences between the two scenarios as shown in fig 11 the typhoon winds deflect the flow directions more landward weaken the seaward residual currents and make the structure of residual currents more chaotically in the large area from the downstream of upstream narrow channels to offshore region thus hindering the spread of nutrients from river sources to this area and causing lower nutrient concentrations beside a large amount of water with low nutrient concentration moved into the pre from open sea during the storm surge which also contributes to the dilution of nutrients in local area fig 14 illustrates the salinity distributions under the two typhoon wind scenarios and their differences in the scenario with typhoon wind effects salt intrusion is more dramatically intensified compared with that in the scenario without wind thereby causing the increase of the salinity values in the pre in the most area from the downstream of narrow river channels to offshore region the typhoon wind scenario increases the salinity 4 19 2 psu as for the east of hebao island the entrance of modaomen and the area around qi ao island the typhoon wind scenario causes the decrease of salinity values with the maximum difference of 1 0 psu in upstream narrow channels and open sea away from the pre the variation is lower 0 2 psu such a variation pattern is also related to the comprehensive influences of the increased storm surges and changed residual currents during the typhoon process statistically the averaged phosphate din and silicate concentrations of the whole computational domain decrease from 0 78 μg l 42 13 μg l and 74 72 μmol l to 0 51 μmol l 27 61 μmol l and 47 44 μmol l under the effects of the typhoon winds respectively the corresponding decrease rates are 34 62 34 46 and 36 51 which means that the typhoon wind process partly alleviates nutrient pollution nevertheless the averaged salinity concentration increases from 25 08 psu to 28 92 psu with the increase rate of 15 31 resulting in the serious threat of salinity intrusion in the pre 5 conclusions a coupled storm surge water quality model over the pre was established based on a parametric typhoon model fvcom circulation model and ersem to evaluate the storm surge process and its influence on nutrient and salinity dynamics using typhoon hagupit as a case study the measured typhoon winds storm surges and water quality factors at different stations were collected and used for coupled storm surge water quality model calibration and validation generally the simulation results of coupled model reasonably reproduced the measured data the comparative analysis of hydrodynamic process in the scenarios with and without typhoon winds shows that the typhoon winds can lead to the variation of water levels and flow velocities during a typhoon period under the influence of typhoon winds the maximum storm surges are larger than 2 0 m at the upstream of the huangmaohai bay and the lingdingyang bay and they gradually decrease to 0 4 m in open sea typhoon winds also weaken seaward residual currents and cause chaotic residual current structure the phosphate and din concentrations mainly decreases by 0 2 and 20 μmol l in the most area from the downstream of narrow river channels to offshore region while the variations are small in upstream narrow channels and open sea away from the pre as for salinity distribution during the typhoon passing through the pre it appears almost opposite variation compared with that of nutrients the salinity values increase by 4 19 2 psu in the most area from the downstream of narrow river channels to offshore region statistically the averaged phosphate din and silicate concentrations decrease by 34 62 34 46 and 36 51 while the averaged salinity concentration increases by 15 31 in the whole computational domain with the effects of typhoon winds in general strong typhoon winds bring about significant storm surges and notable distinct residual currents such hydrodynamics differences eventually lead to the obvious dilution of nutrient concentrations and serious salinity intrusion in the pre the results provided in this paper improve our understanding of the performance of typhoon wind in hydrodynamics process nutrient and salinity dynamics which may contribute to more accurately evaluate storm surge hazards and concomitant water quality issues during typhoon processes software availability software name and available the coupled modelling framework cmster consisting of the storm surge model and the european regional seas ecosystem model ersem is freely available from https github com hxzhangdlut cmster git fabm is applied to achieve the coupling between the two sub models and is freely available from https github com fabm model fabm developers yongming shen and hongxing zhang year first available 2022 hardware and software required matlab linux program language fortran language c program scale 17 mb contract information yongming shen state key laboratory of coastal and offshore engineering dalian university of technology dalian 116024 p r china e mail ymshen dlut edu cn fax international 86 411 84708526 tel international 86 411 84708514 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was funded by the program for guangdong introducing innovative and entrepreneurial teams grant no 2019zt08l213 the key special project for introduced talents team of southern marine science and engineering guangdong laboratory guangzhou grant no gml2019zd0403 and guangdong provincial key laboratory project grant no 2019b121203011 
