index,text
3800,shale and tight gas developments in the beetaloo 28 000 km2 and cooper 139 000 km2 basins of australia are subject to stringent state and federal government controls and assessments several scientific investigations are ongoing to improve the scientific basis of the risks from unconventional gas developments to water and the environment in this study a framework was developed to derive estimates of chemical dilution associated with leakage to groundwater from accidental release of chemicals used for shale and tight gas extraction in australia the quantitative assessment accounted for key landscape parameters that determine natural attenuation soil type depth to groundwater and groundwater velocity both basins were discretised into 1000 1000 m2 grids for which the unsaturated zone and groundwater dilution factors were derived migration of chemicals through deep unsaturated zones was calculated with the hydrus 1d simulator taking account of best available hydraulic properties from a digital soil database a three dimensional analytical solution of the advection dispersion equation provided estimates of dilution in groundwater after solutes travelled 500 m from the centre source location to the edge of every grid cell the combined vadose zone groundwater dilution factors were used to determine under which conditions concentrations of hydraulic fracturing chemicals or flowback water accidentally released into the environment would decrease to levels that are no longer considered harmful to the environment when the method was applied to 39 hydraulic fracturing chemicals scheduled for stimulation of a shale gas well ecotoxicological risk quotients rq were calculated to indicate which chemicals were of no environmental concern this work contributes to increasing the efficiency of quantitative impact assessments and provides a framework to develop dedicated monitoring and management practices to support regulation and management of the gas industry in australia keywords shale gas chemical spills risk assessment soil and groundwater attenuation vadose zone and groundwater hydrology hydrus 1d 1 introduction expansion of shale and tight gas developments across the globe have triggered numerous scientific investigations to address concerns over potential environmental contamination by hydraulic fracturing fluids during surface handling and injection brantley et al 2014 engelder et al 2014 kissinger et al 2013 hydrocarbon and formation fluid leakage into beneficial aquifers dusseault and jackson 2014 jackson et al 2013 warner et al 2012 and fugitive emissions of gases such as methane allen et al 2013 brandt et al 2014 o sullivan and paltsev 2012 scientific reviews in the us us epa 2016 europe trsrae 2012 lechtenb√∂hmer et al 2011 and australia mallants et al 2018 have shown that the greatest risks associated with unconventional gas developments are linked to the accidental release of hydraulic fracturing fluids during surface operations typically leakage of water holding ponds and spills linked truck rollover potentially causing contamination of soil aquifers and surface water a review of compliance related events from coal seam gas coal bed methane extraction in australia between 2009 and 2013 revealed most spills involved the accidental release of flowback and or produced water from coal seam gas extraction most incidents occurred while gas is extracted with the co produced water requiring proper management such as treatment in a desalination facility using reverse osmosis mallants et al 2018 quantitative impact assessments for such surface spills demonstrated that chemical dilution alone i e disregarding sorption and degradation processes in soil and groundwater was large enough to decrease concentrations of 17 out of 19 chemicals used in hydraulic fracturing below their no effect concentration values for the protection of aquatic ecosystems mallants et al 2020 further groundwater flow and chemical transport modelling studies have been undertaken in australia to inform contamination risk from unconventional gas developments examples include transport modelling of potential water quality changes during large scale re injection of treated coal seam gas produced water prommer et al 2016 sreekanth and moore 2018 following the discoveries of large shale and tight gas resources in the beetaloo basin northern territory australia and cooper basin south australia and queensland australia exploration drilling has now commenced under a strict regulatory guidance nt government 2018 this includes the need for collecting baseline hydrogeochemical data deslandes et al 2019 wilkes et al 2019 and terrestrial and aquatic biodiversity distribution frery et al 2020 holland et al 2020 against which assessments of water quality or ecological change over time can be made these initiatives are part of the australian government s geological and bioregional assessment program to assess the potential impacts of shale and tight gas development on water and the environment these scientific investigations will provide independent scientific advice to governments industry landowners and the community hall et al 2018 previous approaches to calculate large scale subsurface fate and transport of chemicals released at the soil surface either use stochastic approaches to account for variations in soil and hydrogeological conditions or are gis based examples of the former category include the epa composite model for leachate migration with transformation products epacmtp us epa 1993 and the consim simulator used by the uk environment agency environment agency 2006 gis based approaches to soil and groundwater risk assessment are reported in strassberg et al 2003 and sinkevich et al 2005 other risk assessment methods are more tailored to individual contaminated sites locatelli et al 2019 although applying them in a continuous grid by grid fashion as we show in the current paper across large areas would seem feasible all these methods use simplified conceptualisations of the unsaturated zone e g homogeneous soil profile and simplified expressions for water flow and solute transport e g steady state analytical and semi analytical solutions analytical solutions have several advantages over numerical models their use is simple and implementation is straightforward they are computationally fast and require less input data by virtue of the simplified system conceptualisation e g uniform soil profile steady state flow conditions however for deep unsaturated zones hydraulic properties are typically non uniform with depth requiring numerical simulators that accommodate vertical heterogeneity also whether or not a steady state approach is appropriate for solute migration across deep unsaturated zones requires first transient simulations with time dependent climatic boundary conditions from which appropriate steady conditions can potentially be derived the objective of this paper is to develop and apply a risk assessment framework to derive estimates of chemical dilution in soil and groundwater across large scale regions tens to hundreds of thousands km2 associated with surface spills of chemicals used for shale and tight gas exploration in australia unlike most previous risk assessment tools a numerical mechanistic simulation model is used to calculate variably saturated water flow and solute transport across the unsaturated zone in doing so stratigraphic heterogeneity is accounted for and effects of transient climatic boundary conditions are incorporated in the methodology coupling is provided with a 3d analytical model of advective dispersive transport in groundwater considering a fixed transport distance of 500 m the quantitative assessment accounts for key landscape parameters that determine natural attenuation such as soil type depth to groundwater and groundwater velocity these parameters will be evaluated at every grid cell in the basins using a 1000 1000 m2 grid size the degree of attenuation is used to evaluate if hydraulic fracturing chemicals or flowback water accidentally released into the environment would decrease to levels that are no longer considered harmful to the environment the assessment represents a worst case scenario as we consider pre mitigation conditions that is spills have not been cleaned up the framework is implemented in the beetaloo and cooper basins australia and involves the derivation of simple attenuation or dilution factor relationships that can be used with any gis capability to generate continuous maps of dilution factors with high spatial granularity in a companion paper the mapping across the landscape is implemented doble et al 2021 by means of this framework areas with lower dilution potential can be identified which would trigger appropriate mitigation and management approaches this risk assessment framework can be applied to many other sources of chemical contamination such as from agrochemicals pfas and organic compounds e g chlorinated solvents 2 materials and methods 2 1 assessment framework overview developing the risk assessment framework involved three main steps fig 1 in the first step contaminant leaching through the unsaturated zone is calculated from which the dilution at the bottom of the unsaturated zone is derived df uz subsequently the dilution factor at a receptor e g well is calculated based on contaminant migration in groundwater df gw both dilution factors are combined to derive the overall dilution from migration through the unsaturated and saturated zones df t df uz df gw all dilution factors are derived from the maximum plume concentration these calculations are done for each landscape class major soil groups depth to groundwater and groundwater velocities across the basins this delivers a large set of dilution factors that capture the variability of influential factors across the landscape in step 2 these dilution factors are used to derive for each landscape class mathematical relationships between dilution factor depth of the unsaturated zone and groundwater pore velocity fig 1 step 3 then applies these relationships to a 1000 1000 m2 gridded landscape map where the attributes of each grid are landscape class depth to groundwater and groundwater pore velocity fig 1 a gis operation returns a spatially variable dilution factor map ready for use for risk assessment of specific chemicals these steps are explained herein 2 2 chemical fate and transport modelling 2 2 1 unsaturated zone natural attenuation is the result of several processes that occur in soil and groundwater without human intervention that result in decreasing the amount volume concentration toxicity or mobility of chemicals such processes may include dilution dispersion biotransformation radioactive decay adsorption or volatilisation us epa 1998 in this study only dilution and dispersion are accounted for as the purpose of this assessment framework is primarily to assist with a conservative screening of a large number of chemicals across very large potential gas development areas when site specific risk assessments have to be carried out because chemicals are found to be of potential concern kirby et al 2020 additional attenuation processes such as chemical and or biological degradation and adsorption can be considered as well mallants et al 2017 mallants et al 2022 solute transport through the unsaturated zone will provide estimates of chemical concentrations at any depth including at the bottom of the unsaturated zone which coincides with the groundwater table it is convenient to define the reduction in concentration dilution at the groundwater table that has occurred from the solute travelling through the entire unsaturated zone likewise a reduction in concentration can be defined as solutes travel in groundwater from their source i e the interface with the unsaturated zone towards a well or any other receiving environment for example us epa 1996 defined a dilution attenuation factor daf to account for processes such as dilution and attenuation sorption and or biodegradation the daf is calculated as the ratio of the original source concentration c 0 to the predicted environment concentration pec daf c0 pec the lowest possible value of daf is therefore 1 i e there is no dilution or attenuation at all high daf values on the other hand correspond to a high degree of dilution and attenuation the term dilution factor df is more appropriate in the context of this study when sorption and biodegradation processes are not accounted for e g in a high end impact assessment such as the current one in the current calculations the source concentration is given an arbitrary value of 1 c 0 1 two source dimensions are considered a 360 m2 area for the beetaloo sub basin and a 1500 m2 area for the cooper basin further details of the source areas are discussed in section 2 6 migration of chemicals in the unsaturated or vadose zone is primarily by advection and hydrodynamic dispersion ignoring gaseous transport mallants et al 2011 simulations of chemical transport during steady state or transient water flow were undertaken using the one dimensional hydrus 1d code for details of the model and input data see supplementary material ≈°im≈Ønek et al 2013 2016 the use of one dimensional models is acceptable because chemical migration processes in soils with deep groundwater levels in relatively flat areas where near horizontal subsurface flows are negligible can be conveniently approximated as one dimensional van dam et al 2004 2 2 2 saturated zone solute migration across the unsaturated zone and further into the saturated zone i e groundwater are two coupled processes fig 1 however in deep unsaturated zones with low groundwater recharge and therefore limited groundwater level fluctuations the coupled processes can be safely approximated by uncoupling them i e into a separate unsaturated zone pathway and a saturated zone pathway the combined effect of both pathways on solute dilution can then be obtained by combining the dilution calculated for the separate pathways mallants et al 2020 the chemical attenuation due to dilution and dispersion in groundwater is based here on the analytical solutions of leij et al 1991 and leij and bradford 1994 to the three dimensional advection dispersion solute transport differential equation see fig s1 and supplementary material for further details of the model and input parameters 2 3 unsaturated zone data 2 3 1 beetaloo basin the beetaloo sub basin in the northern territory australia covers an area of 28 000 km2 and is a major shale and tight gas exploration area frery et al 2020 the soils of the basin are grouped in landscape classes of which the four largest occupy 28 131 km2 or 98 of the basin table s1 and fig s2 the dominant landscape classes are the loamy and sandy plains 70 followed by clay plains 17 floodplain and alluvium 6 and undulating country 5 frery et al 2020 the presence of very deep unsaturated zones within of the four classes is evident from the depth to groundwater data table s1 derived from interpolation of water table depths observed in water bores in the beetaloo sub basin for each of the landscape classes soil hydraulic parameters of the van genuchten mualem models supplementary material eq 3 and 4 were derived using a set of pedo transfer functions details of the derivation of the parameters are available from mallants et al 2021 we here provide a summary of the hydraulic parameters and their depth distribution six stratigraphic layers have been considered for the unsaturated zone profiles within each landscape class detailed soil physical properties are available for the top 200 cm of the soil profile based on the asris digital map of australian soil properties including soil texture sand silt clay and bulk density mckenzie et al 2012 the asris data is available at 90 90 m2 spatial grids across australia for depths of 0 5 cm 5 15 cm 15 30 cm 30 60 cm 60 100 cm and 100 200 cm the original six layers were simplified to four 0 15 15 30 30 60 and 60 200 cm based on similarity in soil texture for depths 200 600 cm the same data as for the 60 200 cm is used consistent with the approach in australian water resources assessment landscape model awra l vaze et al 2018 for the remainder of the soil profile i e from 600 cm to the groundwater table two additional materials are defined based on an analysis of drilling logs claystone 6 22 m and siltstone 22 50 m santos 2019 owing to the paucity of data the hydraulic properties of the claystone and siltstone are based on the usda class transfer functions from carsel and parrish 1988 clay loam is used for claystone and silty clay is used for siltstone average water retention curves for each of the six stratigraphic layers for the four landscape classes together with the deeper claystone and siltstone layers are shown in fig s3 depth dependency of saturated hydraulic conductivity k s for all six layers is available from fig s4 there is a general trend for k s to decrease with depth with the deepest layer siltstone displaying a ten times lower k s than the next deepest layer claystone and up to a 25 to 100 times lower k s than the shallowest layers 2 3 2 cooper basin the cooper basin covers an area of 139 000 km2 across north east south australia and south west queensland australia holland et al 2020 conventional gas production has been ongoing for more than 50 years with the basin continuing to report new shale and tight gas discoveries there are five major landscape classes soils that occupy the entire 130 000 km2 of the basin table s2 and fig s5 the dominant landscape classes are floodplain and alluvium 32 and inland dunefields 30 followed by undulating country 20 tablelands and duricrusts 9 and loamy and sandy plains 9 as in the beetaloo sub basin there are very deep unsaturated zones within each of the five classes with depths to groundwater up to nearly 100 m table s2 depth to groundwater was derived from interpolation of water table depths observed in water bores compared to the depth of the beetaloo unsaturated zones those in the cooper landscape classes are on average about two to three times less deep soil hydraulic parameters of the van genuchten mualem models supplementary material eq 3 and 4 derived from pedo transfer functions are available from mallants et al 2021 because the asris digital map of australian soil properties has the same data types everywhere again six stratigraphic layers were originally considered for the unsaturated zone profiles within each landscape class of the cooper basin these original six layers were again simplified to four 0 15 15 30 30 60 and 60 200 cm based on similarity in soil texture for depths 200 600 cm the same data as for the 60 200 cm is used consistent with the approach in awra l vaze et al 2018 for the remainder of the soil profile i e from 600 cm to the groundwater table sandstone is defined as a single material based on an analysis of stratigraphic logs from well completion reports the minimum horizontal hydraulic conductivity for one of the most important surficial aquifers the winton mackunda aquifer is 0 1 m d evans et al 2020 which is close to the 0 062 m d from carsel and parrish for clay loam therefore the hydraulic properties for the sandstone are based on the clay loam usda class transfer functions from carsel and parrish 1988 average water retention curves for each of the six layers for the five landscape classes together with the deeper sandstone layer are shown in fig s6 depth variations of saturated hydraulic conductivity k s for all five landscape classes are available from fig s7 there is a general trend for k s to decrease with depth with the deepest layer sandstone displaying a three to six times lower k s than that of the shallowest layers 2 4 saturated zone data 2 4 1 beetaloo sub basin the surficial groundwater of the cambrian limestone aquifer cla that directly underlies most of the unsaturated zones within the beetaloo sub basin is composed of the upper cla anthony lagoon siltstone and dolostone and underlying low cla gum ridge limestone and dolostone formations frery et al 2020 the three parameters to derive groundwater pore velocity v see eq 6 supplementary material will be briefly described on the basis of detailed parameter maps derived for the entire sub basin doble et al 2021 the hydraulic conductivity k for the anthony lagoon and underlying gum ridge formations range from 1 to over 200 m d the latter value is assumed representative for karst features the hydraulic gradient i is approximately 0 0001 to 0 003 m m tickell 2003 an effective porosity value of 0 1 was used based on an environmental tracer study undertaken by deslandes et al 2019 the paucity of data did not allow to derive a range for effective porosity additional solute transport parameters are the longitudinal dispersion d x assumed to be 5 m2 y and the horizontal d y and vertical d z transverse dispersion assumed to be 0 5 and 0 05 m2 y these values are based on a groundwater pore velocity of 1 m y the range in the cla being 0 4 to 11 m y using non karstic velocities and longitudinal horizontal and vertical transverse dispersivity of 5 0 5 and 0 05 m the longitudinal dispersivity a l of 5 m value is consistent with the average dispersivity for a transport distance between 100 and 1000 m gelhar et al 1992 the transport distance 100 1000 m is relevant for this study with its main observation point at 500 m the maximum transport distance at which the environmental concentration is predicted this distance was chosen as it corresponds to the maximum travel distance in x and y direction for each of the 1000 1000 m2 grid cells for which all relevant landscape and groundwater data was made available for application of the calculation framework shown in fig 1 a travel distance of 500 m also corresponds to half the recommended minimum default offset distance between shale gas well pads and stock and domestic bores pepper et al 2018 for the horizontal a th and vertical a tv transverse dispersivity the value of a l was divided by 10 and 100 respectively consistent with anderson and cherry 1979 knowing the representative screen length of groundwater bores that would pump potentially contaminated groundwater is important to derive realistic solute concentrations with the 3d analytical model therefore the screen length was based on a sample of bores obtained from the groundwater explorer database bureau of meteorology 2019 there are 159 bores listed within a 50 km radius of the town of daly waters one of the most populated settlements in the centre of the basin of those 25 are listed as being functional all stock and domestic bores out those 25 only 17 had data on the screen depth average screen depth was 9 6 m the minimum was 6 m and the maximum was 18 m a rounded value for screen length of 10 m will be used here for vertically averaging the solute concentrations across the simulated profile 2 4 2 cooper basin surficial groundwater in the cooper basin is predominantly from the sub artesian winton mackunda aquifer and mostly unconfined aquifers in the cenozoic lake eyre basin holland et al 2020 hydraulic conductivity ranges from 0 1 to 5 m day with hydraulic gradients from 1 3 10 5 to 2 10 3 effective porosity was estimated to be around 0 1 doble et al 2021 given that the same groundwater transport distance of 500 m was used for both basins dispersion parameters were considered the same as those for the beetaloo sub basin the same screen length of 10 m below groundwater table was considered for vertically averaging of calculated solute concentrations 2 4 3 climate data with its hot semi arid steppe climate k√∂ppen climate classification subtype bsh the beetaloo gba region has distinct wet seasons november to march and dry seasons april to october hot summers and warm winters total annual rainfall is 665 mm in daly waters and 518 mm in newcastle waters pan evaporation is about 2800 mm year fulton and knapton 2015 a time series of 10 year rainfall and evaporation from the daly waters bureau of meteorology bureau of meteorology meteorological station 14618 in the northern territory was used to generate a continuous timeseries of the atmospheric boundary condition for the unsaturated zone flow and transport simulations no transpiration was considered in the calculations this increases groundwater recharge which is a conservative assumption when leaching of chemicals is of concern the climate of the cooper basin is hot and dry with summer dominated december to february rainfall and high inter annual variability within the cooper gba region the mean annual rainfall was 217 mm year with a maximum in the north east of 378 mm year and a minimum of 127 mm year in the south west mean annual potential evapotranspiration pet for the period 1976 to 2005 is 1702 mm year across the cooper gba region holland et al 2020 the rainfall and evaporation data from the windorah bureau of meteorology meteorological station 38024 was used here for the unsaturated zone simulations using again a 10 year time series of daily data as a basis 2 4 4 leak and spill scenarios make up water for drilling and stimulation fluid and flowback water from unconventional gas developments in the beetalo and cooper basins is stored in above ground double lined tanks with leak detection although the likelihood for a leak from an above ground tank is small it can never be completely eliminated mallants et al 2018 two types of leak spill scenarios are considered an off site spill from a truck roll over and an on site leak from a storage tank the on site leak scenario for the beetaloo sub basin considered that a relatively small volume of 100 000 l infiltrates the soil nearby the water holding tanks following a catastrophic breach of the tanks mitigation measures are in place to keep any leaks within a bunded area surrounding the tanks with the leaking fluids being collected in a sump with a permeable bottom dug 3 m deep into the soil santos 2019 the leak could be either drilling or fracturing fluid or flowback water for consistency and to allow comparison between gas development sites the same volume was used for the leak scenarios across the entire beetaloo sub basin a truck roll over was considered to have the highest likelihood of any gas development related incident whereby fluids could be released into the environment considering a maximum truck load of approximately 22 000 l per tanker korfmacher et al 2015 with a trailer of maximum three tankers carrying a total of 66 000 l the maximum volume of fluid that could be released was conservatively set at 100 000 l 0 1 ml this scenario assumed the entire 100 000 l will infiltrate the soil over a surface area identical to the surface area used for the on site leak in the beetaloo sub basin 360 m2 the same scenario with identical parameters will be applied across both beetaloo sub basin and the cooper basin given its higher likelihood compared to the on site leak the focus of the discussion will be on truck roll over scenario in the cooper basin the on site leak scenario considered the same 100 000 l but used a slightly larger surface area of 1500 m2 through which the fluid would infiltrate the soil this surface area corresponds to the size of the water holding ponds 30 50 m2 that are slightly different in design compared to those in the beetaloo sub basin sapex 2018 the difference between the on site leak and off site spill in the beetaloo sub basin is the assumption that fluids from the leak accumulate in a sump dug within the bunded area surrounding the main water holding tanks the features of the sump are taken from those described in santos 2019 and consider a 3 m deep rectangular hole dug into the soil with a permeable base through which the water will slowly infiltrate the underlying unsaturated zone for the given sump geometry total surface area of 360 m2 the maximum water depth for a 0 1 ml leak is approximately 0 28 m because of the 3 m deep sump the total effective depth of the unsaturated zone for the on site leak is assumed to be 3 m less compared to that for the off site spill where fluid is supposedly spilled into a shallow ditch in the cooper basin the difference between the off site spill and on site leak is more subtle for the on site leak the ponding depth defined by the 100 000 l leak volume and the 1500 m2 infiltration area becomes 0 067 m this is 4 2 times smaller than the 0 28 m ponding depth for the off site spill no sumps are used in the cooper basin hence the total effective soil depth for off site spill and on site leak are the same the framework to derive estimates of chemical dilution across large scale regions will be illustrated primarily based on the off site spill scenario 3 results and discussion 3 1 spill infiltration 3 1 1 beetaloo sub basin following a 20 year initialisation period during which the unsaturated zone profile was put in a quasi steady state condition with respect to pressure head and water content in response to the climatic boundary conditions the spill scenario was initiated by allowing 100 000 l of fluid to infiltrate a 360 m2 surface the initial ponding depth of 0 28 m quickly decreased as fluid infiltrated the soil surface fig s8 for floodplains and alluvium infiltration took less than a day whereas for clay plains and undulating country nearly three days were required to infiltrate the entire spill as time progressed soil pressure heads for the different landscape classes further diverged a result of their different hydraulic properties fig s3 s4 floodplain and alluvium soils have the overall highest hydraulic conductivity at the soil surface allowing faster water infiltration compared to the other soils fig s8 undulating country on the other hand has the lowest hydraulic conductivity therefore requires more time to infiltrate fig s8 cumulative infiltration displays the same pattern as the pressure head with floodplain and alluvium reaching its total cumulative infiltration 0 28 m or 100 000 l sooner than the other classes fig s8 loamy and sandy plains reach complete infiltration after two days while the remaining two classes take about three days to infiltrate the entire spill volume these differences in infiltration rate will have a noticeable effect on solute redistribution throughout the deep unsaturated zone see further once the spill has infiltrated the scenario assumes the same atmospheric boundary conditions as prior to the spill this results in cycles of water losses from the soil surface through evapotranspiration and gains in soil water via precipitation these highly transient processes were approximated by assuming a quasi steady state condition with a fixed water content and pressure head distribution across the entire unsaturated zone profile fig 2 the depth distribution of water content and pressure head are the result of the imposed fluxes at the soil surface and the groundwater table at the bottom of the domain in combination with the hydraulic properties that are unique to each landscape class note that although the depth of the unsaturated zone varies across the landscape for each class see table s1 calculations were done only for the maximum depth i e 95th percentile results i e peak concentrations for shallower depths were derived from the simulations with the deepest depths by collecting simulation results peak concentrations across the entire profile regardless of the landscape class moisture content displays a characteristic pattern with increasing values i e wetter towards the bottom of the deepest soil layer at 6 m depth fig 2 at that depth the less permeable claystone formation occurs causing a local build up of water and pore pressure near the interface of both layers at the first node within the top of the claystone formation water content is minimal in accordance with the low hydraulic conductivity the pressure build up above the interface is required to overcome the hydraulic resistance of the poorly permeable claystone within the claystone water content again increases with depth as the underlying siltstone at 22 m depth has again a considerably lower hydraulic conductivity fig s4 a similar phenomenon occurs as discussed for the top of the claystone pressure build up is required to force water into the less permeable siltstone formation which is accompanied by a higher water content based on the Œ∏ h relationship of the landscape class within the siltstone formation both water content and pressure head are nearly constant the result of the assumed homogenous hydraulic properties and the great depth to the lower boundary condition groundwater table at the bottom of the simulation domain a small increase in water content and pressure head less negative is observed due to the presence of the groundwater table where h 0 the water flux q h follows the same pattern as the unsaturated hydraulic conductivity k h there is an increasing trend with depth from the surface to the interface with the claystone where higher pressure head and water content increase values for q fig 2 a sharp drop in flux occurs just beneath the top of the claystone as the water enters a much less permeable formation from then onwards the flux increases again as it approaches the next interface i e that with the siltstone within the top of the siltstone the flux is much smaller again due to the smaller hydraulic conductivity owing to the fairly uniform water content and pressure head within the siltstone water flux and hydraulic conductivity are fairly uniform too there is a small increase towards the bottom of the profile due to the presence of the groundwater table the pore water velocity v q h Œ∏ displays a similar depth distribution as the water flux rescaled with the water content at each depth fig 2 for the majority of the profile i e from 22 m to the bottom of the profile pore water velocity is fairly constant with an average value of 0 023 cm day or 8 4 cm y average values for q h and Œ∏ in this calculation are 3 03 cm y and 0 355 cm3 cm3 these small velocities are determined by the low water flux and the low conductivity of the siltstone such very low water fluxes and pore water velocities are common for deep unsaturated zones in arid and semi arid climates at the hanford site washington state us with its cool desert type climate average rainfall of 180 mm y and its 70 m thick vadose zone the average recharge water content and pore water velocity estimated from sr and u isotopes are 0 5 cm y 0 09 cm3 cm3 and 5 5 cm y respectively maher et al 2006 for the deep unsaturated zones up to 100 m of china s loess plateau under semi arid climate 450 623 mm y rainfall huang et al 2013 derived pore water velocities from 13 2 to 20 8 cm y further note that the pore water velocities within the siltstone formation are virtually the same for all four landscape classes there are still differences though in velocities within the top 22 m of the profile these differences together with the difference in infiltration rate and volume of fluid that actually migrates downward are the main cause for the difference in solute arrival time and peak concentration and thus the level of attenuation that is obtained see further another hydrologic difference between the landscape classes is the depth to the zero flux plane zfp the zfp is the soil depth that separates upward movement of soil water to evapotranspiration from downward leaching to groundwater cooper et al 1990 sharma et al 1991 indeed for all classes but most so for floodplains an important upward flux exists in response to the evaporative demand of the soil as a result a larger portion of the infiltrated fluid in case of floodplains is kept above the zfp near the soil surface and does not migrate deeper this means that the effective volume for deep migration is smallest for the floodplains and largest for the loamy and sandy plains the steady state zfp for floodplains and alluvium is situated at 4 m which is nearly twice as deep as for clay plains approximately 2 m undulating country and loamy and sandy plains have the shallowest zfp respectively 1 5 and 1 1 m fig 2 by comparison depths of zfp measured in western australia under mediterranean climate 800 mm yr rainfall and 1800 mm yr pan evaporation on a coarse sandy varied between close to the surface at the start of the rainy season and near 10 m depth during summer sharma et al 1991 the next step in the simulations is to use the quasi steady state velocity profiles from fig 2 and calculate solute migration with the solute plume that entered the soil surface following the spill incident fig s8 3 1 2 cooper basin landscape classes in the cooper basin have steady state moisture and pressure head profiles that are slightly more uniform compared to those in the beetaloo sub basin fig s9 beneath the soil layers there now is only a single sediment i e sandstone within the sandstone moisture content and pressure head are rather uniform with depth with steady state values representing the equilibrium response to the imposed water flux the water flux displays some oscillations with depth a result of the atmospheric boundary condition with alternating wet and dry periods these oscillations will have an impact on the solute transport and dilution factors see further average water flux moisture content and pore water velocity across the sandstone are 5 84 cm y 0 313 cm3 cm3 and 18 6 cm y respectively compared to the beetaloo sub basin water flux and pore water velocity are on average 1 9 and 2 2 times higher in the cooper the higher saturated hydraulic conductivity of the coarser cooper top soils fig s7 compared to the beetaloo except for the undulating country in beetaloo fig s4 result in higher infiltration rates another result of the difference in soil hydraulic properties between the two basins is the shallower depths of the zfp in the cooper in between 1 and 1 5 m fig s9 compared to zfp as deep as 4 m in the beetaloo sub basin fig 2 this leads to a greater fraction of the spill volume percolating into the deeper sediments and for all five cooper basin landscape classes to higher solute concentrations compared to those beetaloo sub basin landscape classes with much deeper zfp see further 3 2 soil attenuation 3 2 1 beetaloo sub basin migration of chemicals through the generally deep unsaturated zones of the case study area is a very slow process irrespective of landscape class fig 3 the difference in solute migration profiles between different landscape classes is also noticeable differences exist in the rate at which the chemicals are transported through the unsaturated zone fig 3 and in the magnitude of the concentration peak concentrations used to calculate the dilution factors are reached slightly sooner for the undulating country and loamy and sandy plains compared to clay plains solute migration is slowest in the floodplains and alluvium landscape class there are also noticeable differences in the peak concentrations between the landscape classes with loamy and sand plains having slightly higher values than undulating country at similar depths fig 3 clay plains display nearly ten times lower concentrations compared to the two previous classes while floodplains and alluvium produce the overall smallest concentrations the solute breakthrough curves for the different landscape classes start to diverge very early on in the profile fig s10 already at 5 m depth there is a considerable difference in solute peak concentration with loamy and sandy plains displaying the largest concentration and undulating country the next largest values still smaller values are then seen for clay plains with floodplains showing the overall smallest concentrations these rankings in terms of peak concentration are consistent with those seen for the solute depth profiles fig 3 the reason for these large difference in concentration especially for the floodplain class is to be found in the different depths of the zero flux plain fig 2 where the zfp is closest to the soil surface the largest volume of water from a spill or leak will infiltrate to the deeper layers for those conditions the solute concentration will be larger compared to soils with a deeper zfp that cause smaller volumes of water to contribute to leaching to groundwater these concentration differences between landscape classes therefore result in different attenuation or dilution at the bottom of the unsaturated zone across the landscape also within one and the same landscape class attenuation varies depending on the depth to the groundwater table for instance at approximately 10 m depth in the undulating country class the peak concentration is about 0 02 or one fiftieth of the source concentration assumed unity at about 70 m deep into the profile the peak concentration has further reduced to 0 007 or 142 times smaller than the source concentration finally at the bottom of the profile the peak concentration is only 0 004 or 250 times smaller than the source concentration a similar decrease in peak concentration with increasing depth in the profile is observed for the loamy and sandy plains fig 3 note that at t 200 y the peak concentration is slightly higher than at the previous time step this is the result of an increase in solute concentration in the soil pore water as a result of a change in soil hydraulic properties at 22 m depth transition from claystone to siltstone with a 13 fold decrease in saturated hydraulic conductivity that causes a sharp decrease in pore water velocity a compression of the solute plume and therefore a local increase in solute concentration see further note that the compression of the solute plume due to the sudden decrease in hydraulic conductivity is also visible in clay plains and floodplains and alluvium when the plume reaches 22 m clay plains display a nearly ten times smaller peak concentration at the same depths compared to undulating country and loamy and sandy plains fig 3 this is the result of the smaller solute plume that passes the first few meters of the soil profile a result of a larger proportion of the infiltrating solute plume remaining close to the soil surface due to a strong soil evaporation the floodplain and alluvium landscape class produces the overall lowest concentrations and compared to all three previous classes regardless of depth the volume of solute that infiltrates past the top few meters is again smaller than that of the clay plains owing to most of the solute remaining in the top layer owing to evaporative forces 3 2 2 cooper basin solute migration through the vadose zone of the cooper basin landscape classes is about two times faster compared to that in the beetaloo sub basin fig 4 this faster migration is mainly due to a higher saturated hydraulic conductivity for the majority of the profile based on a clay loam sediment assumed for the sandstone from 6 m down to the groundwater table another difference with most of the beetaloo sub basin classes is the large decrease in peak concentration until approximately 20 m deep from which depth onwards the peak solute concentrations decrease only slightly an example of the increasing dilution factor with increasing soil depth is shown for the undulating country landscape class fig 4f similar to the beetaloo sub basin the compression of the solute plume at around 40 m has produced locally increased concentrations and hence a decrease in dilution factor this behaviour is caused by the decrease in water flux and thus in solute velocity at the depth of 37 40 m fig s9 such decrease is related to the transient atmospheric boundary condition causing a non uniform water flux profile from 40 m onwards solute concentrations decrease again with depth although somewhat erratically producing again increasing dilution factors with increasing depth this behaviour resulted in two separate dilution depth models with a stepwise transition at 37 m a similar stepwise dilution depth behaviour was observed for the other landscape classes except for floodplain and alluvium whose maximum depth was less than the depth where the solute plume compression occurred results not shown for the most abundant cooper basin landscape classes 32 for floodplain and alluvium and 30 for inland dunefields the dilution factor at the maximum depth of the unsaturated zone 39 m for floodplain and alluvium and 62 m inland dunefields is 400 and 100 respectively despite its shallower depth floodplain and alluvium have a higher dilution due to their deeper zfp linked to the overall lowest saturated hydraulic conductivity of the top soil fig s7 in comparison the most abundant landscape class in the beetaloo sub basin loamy and sandy plains covering 70 of the area has a dilution factor of 140 at the maximum depth of 115 m 3 3 groundwater attenuation once the solute plume has traversed the unsaturated zone it will seep into the surficial groundwater where it continues its migration path based on the predominant direction of groundwater flow assuming three dimensional groundwater flow that drives the advective dispersive transport of the solute plume solute concentrations were calculated at increasing travel distances here we report concentrations and associated dilution factors for a travel distance of 500 m this is to be consistent with the 1000 1000 m2 grid across the entire basin 500 m then corresponds to the distance from the centre of each grid cell also the location of the chemical source to the boundary of the grid cell doble et al 2021 groundwater advection or groundwater pore water velocity was calculated separately for each grid cell of the basin using a gis approach where input parameters were the aquifer hydraulic conductivity hydraulic gradient and effective porosity advective dispersive transport calculations were undertaken for the velocity range thus obtained to produce dilution factors in function of velocity the resulting range in groundwater dilution factors was then combined i e multiplied with the soil dilution factors to produce a combined soil groundwater dilution factor fig 5 for each landscape class dilution factors are derived as function of soil depth and groundwater pore velocity the relationships from fig 5 were then used to generate a continuous map of groundwater pore velocities that were used to generate basin scale maps of soil groundwater dilution factors for examples see fig 6 f and doble et al 2021 the general trend of the dilution factors is to increase with increasing soil depth for a given pore water velocity i e parallel to the y axis in fig 5 and for a given soil depth to increase with decreasing velocity i e ascending along the curves in fig 5 indeed a higher groundwater velocity results in a faster arrival time and less lateral and transverse dispersion compared to smaller velocities combined dilution factors in the beetaloo sub basin are largest for surficial groundwater overlain by floodplain and alluvium 6 of the basin and smallest for groundwater overlain by loamy and sandy plains this landscape class represents 70 of the basin chemical attenuation across the cooper basin displays a similar behaviour as for the beetaloo sub basin i e increasing dilution with increasing depth of the unsaturated zone and decreasing groundwater pore water velocity fig 6 one noticeable difference is in the smaller groundwater velocities approximately one order of magnitude less than in beetaloo the smaller velocities result in a somewhat larger groundwater dilution with all five landscape classes displaying combined soil groundwater dilution factors larger than 106 for the greatest soil depth for soil depths as shallow as 5 m and the smallest groundwater velocity of 0 1 m year the dilution factors are still in excess of 105 for all landscape classes 4 discussion and outlook this framework for deriving dilution factors across vast areas of land has flexibility to account for many parameters that determine the degree to which chemicals released at the soil surface see their concentrations decrease owing to physical attenuation processes dilution and hydrodynamic dispersion by gridding of soil hydraulic properties depth of the unsaturated zone and groundwater velocity based on gridded values of hydraulic conductivity hydraulic gradient and effective porosity spatially varying dilution factors were derived for both basins example maps of unsaturated zone depth groundwater velocity and combined dilution factor are available in doble et al 2021 data sets for both basins were used to derive cumulative distribution functions cdf of dilution factors fig 7 a cdf represents the probability of non exceedance i e prob x x there are two important reasons why cdfs are useful in showing the results of risk assessments first of all cdfs address the question how likely is an outcome to be this small or smaller which is a key question in any risk assessment next cdfs depict small probabilities associated with large consequences or small dilution factors fig 7 shows cdfs for the complete data sets for both basins with data pooled across all landscape classes and depths of the unsaturated zone for each probability value the minimum and maximum dilution factors represent the smallest respectively largest values across the entire depth range clearly for each cdf value the beetaloo displays the largest variation in dilution factors this is due in part to a greater depth dependency of the dilution factor in the beetaloo owing to the more heterogeneous stratigraphy compare fig 2 and fig s9 causing smaller dilution factors at shallower depths compared to the cooper basin fig 7 a breakdown of dilution factors per unsaturated zone depth class is provided in table 1 using 20 m depth intervals together with the median value 50th percentile the lower quartile q1 25th percentile and upper quartile q3 75th percentile are listed from which the interquartile range iqr q3 q1 can be derived the iqr quantifies the spread of a dataset which is resistant to the presence of outliers outliers in dilution factors exist due to extreme parameters generated by interpolation from a small number of data points the pooled data accounts for the surface area of each depth class and is therefore an area weighted value note that for beetaloo the 20 40 m depth class has lower dilution factors owing to the compression of the solute plume generating an increase in concentration and a decrease in dilution factor at the transition of the claystone to the siltstone see previous discussion a similar phenomenon is present in the cooper basin owing to a decrease in solute velocity at the depth of nearly 40 m see previous discussion travel times through the unsaturated zones are based on the governing steady state water flux calculated for the different landscape classes for beetaloo depth averaged water flux across the siltstone formation is 30 3 mm y based on the chloride mass balance method recharge rates across the beetaloo sub basin were estimated to vary between 25 mm y and less than 1 mm y a result of the karst nature of this basin deslandes et al 2019 a higher recharge of 66 mm y was derived from analysis of tritium data collected from shallow bores deslandes et al 2019 in a recent reassessment of the cambrian limestone aquifer recharge the chloride mass balance recharge estimates were constrained using baseflow and remotely sensed evapotranspiration data for the western part of the beetaloo sub basin broadly corresponding to our study area the 50th percentile and the 5th 95th percentile range were 48 and 27 92 mm y respectively crosbie and rachakonda 2021 our calculated values therefore are consistent with these estimates based on tracer measurements giving confidence to the calculated long travel times through the unsaturated zone note that the water content of the deep sediments is an equally important factor in determining chemical velocity confirming the calculated values about 0 355 cm3 cm3 for the siltstone however was beyond the scope of this study the current assessment only considers dilution and hydrodynamic dispersion in deriving dilution factors for both metals and organic compounds found in fracturing chemicals or flowback waters there is ample of literature data demonstrating weak to strong sorption onto various geo media and for organics the ability to degrade chen et al 2017 kahrilas et al 2015 labrecque and blanford 2021 scow and johnson 1997 stringfellow et al 2014 these processes are expected to further decrease chemical concentrations both in soil and in groundwater for instance transport of the biocide bronopol was found to be retarded on average 187 times relative to an inert tracer based on sorption onto soil organic carbon aerobic degradation half lives were on average 87 days mallants et al 2017 using those parameters bronopol was calculated to be removed from the soil solution within several centimeters of the surface demonstrating significant natural attenuation capacity of soils as a result of sorption and biodegradation mallants et al 2017 the risk classification based on the rq for each chemical evaluated is determined in accordance with the principles outlined by the environmental risk assessment guidance manual for industrial chemicals ephc 2009 and the australia and new zealand conservation council and agriculture resources management council of australia and new zealand anzecc and armcanz 2000 guidelines as an illustration of how the dilution factors can used to assess risks from specific chemicals ecotoxicological risk quotients rq are derived from the ratio of predicted environmental concentration pec at a receptor to predicted no effect concentrations pnec rq pec pnec for chemicals of low concern i e rq is less than 1 compounds with rq larger than 1 and less than 10 are considered to have the potential to cause adverse environmental effects if they are released into the environment dedicated risk management measures may be required to ensure that chemicals of potential concern do not cause harm to the environment doee 2017 chemicals with rq larger than 10 are likely to cause adverse environmental effects if released into the environment dedicated risk management measures are likely required to ensure that chemicals of potentially high concern do not cause harm to the environment doee 2017 rqs are calculated for 39 chemicals to be used in the stimulation fluid at a typical deep shale gas well located in the beetaloo sub basin santos 2019 for a limited number of chemicals pnec values were sourced from the australian water quality guidelines anzecc armcanz 2000 for the remaining chemicals pnecs were derived by kirby et al 2021 fig 8 displays the rqs calculated from the calculated pec values using the median 50th percentile dilution factor at a hypothetical well at 500 m from where the spill occurred the pecs were also calculated for the 25th and 75th percentile dilution factor derived from a subregion of the relevant exploration permit that is within the beetaloo sub basin total area of 1527 km2 these percentiles account for variation in landscape class depth to groundwater and groundwater velocities across the lease area similar to data from table 1 fig 8 demonstrates that for all but two chemicals hydrochloric acid rq 1 37 and tributyl tetradecylphosphonium chloride rq 6 01 the ecotoxicity endpoint are not exceeded i e rq less than 1 at a hypothetical receptor point 500 m downstream from the area where the spill occurs in other words except for two all other chemicals are of low concern the environmental fate of hydrochloric acid and tributyl tetradecylphosphonium chloride is further influenced by additional natural attenuation processes hydrochloric acid is expected to dissociate in water to hydrogen h and chloride cl ions while additional natural attenuation processes will further reduce exposure concentration and organism effects as the acid plume moves through the soil several geochemical processes can be expected bea et al 2013 hyun et al 2020 proton sorption on sediments e g goethite and kaolinite dissolution of existing minerals and precipitation of secondary minerals e g al and fe oxides all of which will contribute to acid neutralization given the long transport times through soil of several hundred years fig 3 and the relatively fast rate of mineral dissolution and precipitation in the presence of h full acid neutralisation can be expected before the plume reaches the groundwater tributyl tetradecylphosphonium chloride is a biocide expected to be readily biodegradable 60 in 28 days kirby et al 2021 also natural attenuation processes will further reduce exposure concentrations and organisms effects e g adsorption kahrilas et al 2015 complexation and transformations as can be seen from fig 3 the estimated transport time from the source of the spill soil surface to the groundwater table is at least several hundred years sufficient to completely biodegrade compounds like tributyl tetradecylphosphonium chloride we note again that the source concentrations used here are not the actual ones but those considered in the planning stage these results are very robust given that the rqs for most chemicals are several orders of magnitude smaller than one while there are several factors that could increase the pec values including increased local recharge larger spill volumes or higher source concentrations these are not likely to increase the rqs above one given the current results while soil and or groundwater monitoring of specific chemical e g the hydrochloric acid and tributyl tetradecylphosphonium chloride discussed above is one of several potential mitigation measures to prevent contamination it would be more effective to monitor leaks and spills in a staged approach whereby the most mobile water quality parameters such as salinity chloride or ph are analysed first as they would be precursors of the more slow moving organic compounds pepper et al 2018 such water quality parameters are also easy and relatively cheap to measure while some can be tracked using permanently installed in situ monitoring devices including geoelectric systems e g aaltonen and olofsson 2002 binley and daily 2003 daily et al 2004 spectroscopy based sensors e g hartzler et al 2019 and fiber optics e g shanafield et al 2018 once a trigger value of the most mobile parameters has been exceeded measurement of the organic compounds can be considered note that trigger values should be sufficiently conservative to provide an early warning of potential risks to groundwater to allow for sufficient time for remedial actions to be undertaken before groundwater pollution occurs early monitoring of contaminants should focus on the unsaturated zone to detect pollutant fluxes before they reach the groundwater table vrba and adams 2008 table s3 lists the groundwater pecs and pnecs for 39 chemicals scheduled to be used in the stimulation fluid santos 2019 we note that these are not actual concentrations used but rather estimated concentrations as reported in the environmental management plan emp note that our environmental risk assessment ignores attenuation by sorption and degradation hence is still conservative as a potential next step a site specific risk assessment accounting for additional attenuation processes can be undertaken focussing on those few chemicals that were not identified to be of low risk large scale impact assessments on the scale of several tens of thousands of km2 28 000 km2 for beetaloo sub basin and 139 000 km2 for cooper basin in data poor areas will necessarily be limited by the amount of information on critical process required for modelling we argue that similarly data poor areas exist elsewhere and that the methodology developed has broader applicability then just regional this is especially true if one considers the tiered approach for risk assessments recommended by the us epa 2014 furthermore large scale risk assessments are most cost effective and fit for purpose when a tiered approach is adopted us epa 2014 at the lowest level tier 1 the assessment uses generic properties and conservative assumptions qualitative assessment at the next level tier 2 deterministic approaches it incorporates site specific data knowledge and exposure scenarios while advanced analysis using probabilistic exposure scenario analysis techniques including quantitative assessment of variability and uncertainty are typical of the highest level tier 3 probabilistic approaches our approach is at tier 2 where a deterministic assessment is undertaken with spatially variable site specific data at 1 km2 grid cells commensurate with the scale of the assessment where the risk is possibly higher than acceptable more detailed site specific studies can be undertaken consistent with tier 3 of the tiered risk assessment approach in such case site specific transport kinetic parameters can be collected together with more detailed soil hydrologic and groundwater flow and transport parameters the argument of method transferability or not to other hydroclimate scenarios is addressed next our study has shown that it is applicable across different climates as the two case study areas have a distinctly different climate the beetaloo sub basin climate has a hot semi arid steppe climate k√∂ppen climate classification subtype bsh with a total annual rainfall is 665 mm the cooper basin is much more aridic persistently dry desert bwh with a mean annual rainfall was 217 mm when a mechanistic soil hydrological code like hydrus is used with proper use of hydroclimatic boundary conditions as input then the method is transferability to other hydroclimates as any transient flow and transport condition that will exist will be a reflection of the combined effect of hydroclimate and soil properties both of which should be available at a tier 2 and 3 assessment level 5 conclusions the unintentional release of chemicals during surface handling associated with shale and tight gas exploration and production drilling hydraulic fracturing flowback water can lead to limited spreading into unsaturated soil and sediments with further migration to surficial groundwater detailed numerical simulations of chemical fate and transport with the state of the art hydrus 1d code showed very long transfer times across deep unsaturated zones up to 100 m and more in the order of several hundreds of years in the beetaloo sub basin such slow chemical migration is due to the very slow pore water velocity 8 4 m century owing to the low hydraulic conductivity of the claystone and siltstone rock formations that make up more than 90 of the total unsaturated zone thickness in combination with the low rainfall and high evapotranspiration rates of the region cooper basin sediments produced a nearly two times faster pore water velocity while also being two to three time less deep compared to the beetaloo as a result transit times in the cooper are several times faster than in the beetaloo to account for spatial heterogeneity in soil characteristics critical to chemical fate and transport major landscape classes or soil types were used to summarise the dilution factors considerable differences in transport behaviour were observed between classes primarily driven by different hydraulic properties that produced different depths of the zero flux plane between 1 and 4 m depth in the beetaloo sub basin causing different amounts of chemicals being retained close to the soil surface and therefore not contributing to deep leaching the use of a three dimensional analytical model of the advection dispersion equation delivered dilution factors on a spatial resolution of 1000 1000 m2 across both basins the combined pooled unsaturated zone groundwater dilution factor for the beetaloo sub basin was found to be 4 230 50th percentile with lower and upper quartiles of 778 and 15 400 respectively for the cooper basin the 50th percentile dilution factor was 7 970 for pooled data with upper and lower quartile values of 3 830 and 21 100 high resolution spatial maps of combined dilution factors have been produced based on the dilution factor relationships developed here doble et al 2021 such maps are practical tools to inform effective monitoring and management practices to support regulation and management of the gas industry in australia an example environmental risk assessment application based on 39 hydraulic fracturing chemicals scheduled for stimulation of a shale gas well demonstrated ecotoxicological risk quotients rqs for most chemicals to be low enough i e less than 1 to indicate negligible environmental impact this result was based on assuming only dilution and dispersion contribute to attenuation for chemicals that had their rq above 1 additional attenuation processes such as biodegradation mineral dissolution and precipitation are expected to further decrease chemical concentrations to levels that cause no environmental harm credit authorship contribution statement dirk mallants conceptualization methodology writing original draft writing review editing rebecca doble data curation visualization yousef beiraghdar data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank dr luk peeters dr david rassam and mitchell bouma for useful discussions the feedback from two anonymous reviewers improved the manuscript this work was produced under the geological and bioregional assessments program funded by the commonwealth department of agriculture water and environment https www bioregionalassessments gov au geological and bioregional assessment program the datasets from this paper are available at data gov au appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127271 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3800,shale and tight gas developments in the beetaloo 28 000 km2 and cooper 139 000 km2 basins of australia are subject to stringent state and federal government controls and assessments several scientific investigations are ongoing to improve the scientific basis of the risks from unconventional gas developments to water and the environment in this study a framework was developed to derive estimates of chemical dilution associated with leakage to groundwater from accidental release of chemicals used for shale and tight gas extraction in australia the quantitative assessment accounted for key landscape parameters that determine natural attenuation soil type depth to groundwater and groundwater velocity both basins were discretised into 1000 1000 m2 grids for which the unsaturated zone and groundwater dilution factors were derived migration of chemicals through deep unsaturated zones was calculated with the hydrus 1d simulator taking account of best available hydraulic properties from a digital soil database a three dimensional analytical solution of the advection dispersion equation provided estimates of dilution in groundwater after solutes travelled 500 m from the centre source location to the edge of every grid cell the combined vadose zone groundwater dilution factors were used to determine under which conditions concentrations of hydraulic fracturing chemicals or flowback water accidentally released into the environment would decrease to levels that are no longer considered harmful to the environment when the method was applied to 39 hydraulic fracturing chemicals scheduled for stimulation of a shale gas well ecotoxicological risk quotients rq were calculated to indicate which chemicals were of no environmental concern this work contributes to increasing the efficiency of quantitative impact assessments and provides a framework to develop dedicated monitoring and management practices to support regulation and management of the gas industry in australia keywords shale gas chemical spills risk assessment soil and groundwater attenuation vadose zone and groundwater hydrology hydrus 1d 1 introduction expansion of shale and tight gas developments across the globe have triggered numerous scientific investigations to address concerns over potential environmental contamination by hydraulic fracturing fluids during surface handling and injection brantley et al 2014 engelder et al 2014 kissinger et al 2013 hydrocarbon and formation fluid leakage into beneficial aquifers dusseault and jackson 2014 jackson et al 2013 warner et al 2012 and fugitive emissions of gases such as methane allen et al 2013 brandt et al 2014 o sullivan and paltsev 2012 scientific reviews in the us us epa 2016 europe trsrae 2012 lechtenb√∂hmer et al 2011 and australia mallants et al 2018 have shown that the greatest risks associated with unconventional gas developments are linked to the accidental release of hydraulic fracturing fluids during surface operations typically leakage of water holding ponds and spills linked truck rollover potentially causing contamination of soil aquifers and surface water a review of compliance related events from coal seam gas coal bed methane extraction in australia between 2009 and 2013 revealed most spills involved the accidental release of flowback and or produced water from coal seam gas extraction most incidents occurred while gas is extracted with the co produced water requiring proper management such as treatment in a desalination facility using reverse osmosis mallants et al 2018 quantitative impact assessments for such surface spills demonstrated that chemical dilution alone i e disregarding sorption and degradation processes in soil and groundwater was large enough to decrease concentrations of 17 out of 19 chemicals used in hydraulic fracturing below their no effect concentration values for the protection of aquatic ecosystems mallants et al 2020 further groundwater flow and chemical transport modelling studies have been undertaken in australia to inform contamination risk from unconventional gas developments examples include transport modelling of potential water quality changes during large scale re injection of treated coal seam gas produced water prommer et al 2016 sreekanth and moore 2018 following the discoveries of large shale and tight gas resources in the beetaloo basin northern territory australia and cooper basin south australia and queensland australia exploration drilling has now commenced under a strict regulatory guidance nt government 2018 this includes the need for collecting baseline hydrogeochemical data deslandes et al 2019 wilkes et al 2019 and terrestrial and aquatic biodiversity distribution frery et al 2020 holland et al 2020 against which assessments of water quality or ecological change over time can be made these initiatives are part of the australian government s geological and bioregional assessment program to assess the potential impacts of shale and tight gas development on water and the environment these scientific investigations will provide independent scientific advice to governments industry landowners and the community hall et al 2018 previous approaches to calculate large scale subsurface fate and transport of chemicals released at the soil surface either use stochastic approaches to account for variations in soil and hydrogeological conditions or are gis based examples of the former category include the epa composite model for leachate migration with transformation products epacmtp us epa 1993 and the consim simulator used by the uk environment agency environment agency 2006 gis based approaches to soil and groundwater risk assessment are reported in strassberg et al 2003 and sinkevich et al 2005 other risk assessment methods are more tailored to individual contaminated sites locatelli et al 2019 although applying them in a continuous grid by grid fashion as we show in the current paper across large areas would seem feasible all these methods use simplified conceptualisations of the unsaturated zone e g homogeneous soil profile and simplified expressions for water flow and solute transport e g steady state analytical and semi analytical solutions analytical solutions have several advantages over numerical models their use is simple and implementation is straightforward they are computationally fast and require less input data by virtue of the simplified system conceptualisation e g uniform soil profile steady state flow conditions however for deep unsaturated zones hydraulic properties are typically non uniform with depth requiring numerical simulators that accommodate vertical heterogeneity also whether or not a steady state approach is appropriate for solute migration across deep unsaturated zones requires first transient simulations with time dependent climatic boundary conditions from which appropriate steady conditions can potentially be derived the objective of this paper is to develop and apply a risk assessment framework to derive estimates of chemical dilution in soil and groundwater across large scale regions tens to hundreds of thousands km2 associated with surface spills of chemicals used for shale and tight gas exploration in australia unlike most previous risk assessment tools a numerical mechanistic simulation model is used to calculate variably saturated water flow and solute transport across the unsaturated zone in doing so stratigraphic heterogeneity is accounted for and effects of transient climatic boundary conditions are incorporated in the methodology coupling is provided with a 3d analytical model of advective dispersive transport in groundwater considering a fixed transport distance of 500 m the quantitative assessment accounts for key landscape parameters that determine natural attenuation such as soil type depth to groundwater and groundwater velocity these parameters will be evaluated at every grid cell in the basins using a 1000 1000 m2 grid size the degree of attenuation is used to evaluate if hydraulic fracturing chemicals or flowback water accidentally released into the environment would decrease to levels that are no longer considered harmful to the environment the assessment represents a worst case scenario as we consider pre mitigation conditions that is spills have not been cleaned up the framework is implemented in the beetaloo and cooper basins australia and involves the derivation of simple attenuation or dilution factor relationships that can be used with any gis capability to generate continuous maps of dilution factors with high spatial granularity in a companion paper the mapping across the landscape is implemented doble et al 2021 by means of this framework areas with lower dilution potential can be identified which would trigger appropriate mitigation and management approaches this risk assessment framework can be applied to many other sources of chemical contamination such as from agrochemicals pfas and organic compounds e g chlorinated solvents 2 materials and methods 2 1 assessment framework overview developing the risk assessment framework involved three main steps fig 1 in the first step contaminant leaching through the unsaturated zone is calculated from which the dilution at the bottom of the unsaturated zone is derived df uz subsequently the dilution factor at a receptor e g well is calculated based on contaminant migration in groundwater df gw both dilution factors are combined to derive the overall dilution from migration through the unsaturated and saturated zones df t df uz df gw all dilution factors are derived from the maximum plume concentration these calculations are done for each landscape class major soil groups depth to groundwater and groundwater velocities across the basins this delivers a large set of dilution factors that capture the variability of influential factors across the landscape in step 2 these dilution factors are used to derive for each landscape class mathematical relationships between dilution factor depth of the unsaturated zone and groundwater pore velocity fig 1 step 3 then applies these relationships to a 1000 1000 m2 gridded landscape map where the attributes of each grid are landscape class depth to groundwater and groundwater pore velocity fig 1 a gis operation returns a spatially variable dilution factor map ready for use for risk assessment of specific chemicals these steps are explained herein 2 2 chemical fate and transport modelling 2 2 1 unsaturated zone natural attenuation is the result of several processes that occur in soil and groundwater without human intervention that result in decreasing the amount volume concentration toxicity or mobility of chemicals such processes may include dilution dispersion biotransformation radioactive decay adsorption or volatilisation us epa 1998 in this study only dilution and dispersion are accounted for as the purpose of this assessment framework is primarily to assist with a conservative screening of a large number of chemicals across very large potential gas development areas when site specific risk assessments have to be carried out because chemicals are found to be of potential concern kirby et al 2020 additional attenuation processes such as chemical and or biological degradation and adsorption can be considered as well mallants et al 2017 mallants et al 2022 solute transport through the unsaturated zone will provide estimates of chemical concentrations at any depth including at the bottom of the unsaturated zone which coincides with the groundwater table it is convenient to define the reduction in concentration dilution at the groundwater table that has occurred from the solute travelling through the entire unsaturated zone likewise a reduction in concentration can be defined as solutes travel in groundwater from their source i e the interface with the unsaturated zone towards a well or any other receiving environment for example us epa 1996 defined a dilution attenuation factor daf to account for processes such as dilution and attenuation sorption and or biodegradation the daf is calculated as the ratio of the original source concentration c 0 to the predicted environment concentration pec daf c0 pec the lowest possible value of daf is therefore 1 i e there is no dilution or attenuation at all high daf values on the other hand correspond to a high degree of dilution and attenuation the term dilution factor df is more appropriate in the context of this study when sorption and biodegradation processes are not accounted for e g in a high end impact assessment such as the current one in the current calculations the source concentration is given an arbitrary value of 1 c 0 1 two source dimensions are considered a 360 m2 area for the beetaloo sub basin and a 1500 m2 area for the cooper basin further details of the source areas are discussed in section 2 6 migration of chemicals in the unsaturated or vadose zone is primarily by advection and hydrodynamic dispersion ignoring gaseous transport mallants et al 2011 simulations of chemical transport during steady state or transient water flow were undertaken using the one dimensional hydrus 1d code for details of the model and input data see supplementary material ≈°im≈Ønek et al 2013 2016 the use of one dimensional models is acceptable because chemical migration processes in soils with deep groundwater levels in relatively flat areas where near horizontal subsurface flows are negligible can be conveniently approximated as one dimensional van dam et al 2004 2 2 2 saturated zone solute migration across the unsaturated zone and further into the saturated zone i e groundwater are two coupled processes fig 1 however in deep unsaturated zones with low groundwater recharge and therefore limited groundwater level fluctuations the coupled processes can be safely approximated by uncoupling them i e into a separate unsaturated zone pathway and a saturated zone pathway the combined effect of both pathways on solute dilution can then be obtained by combining the dilution calculated for the separate pathways mallants et al 2020 the chemical attenuation due to dilution and dispersion in groundwater is based here on the analytical solutions of leij et al 1991 and leij and bradford 1994 to the three dimensional advection dispersion solute transport differential equation see fig s1 and supplementary material for further details of the model and input parameters 2 3 unsaturated zone data 2 3 1 beetaloo basin the beetaloo sub basin in the northern territory australia covers an area of 28 000 km2 and is a major shale and tight gas exploration area frery et al 2020 the soils of the basin are grouped in landscape classes of which the four largest occupy 28 131 km2 or 98 of the basin table s1 and fig s2 the dominant landscape classes are the loamy and sandy plains 70 followed by clay plains 17 floodplain and alluvium 6 and undulating country 5 frery et al 2020 the presence of very deep unsaturated zones within of the four classes is evident from the depth to groundwater data table s1 derived from interpolation of water table depths observed in water bores in the beetaloo sub basin for each of the landscape classes soil hydraulic parameters of the van genuchten mualem models supplementary material eq 3 and 4 were derived using a set of pedo transfer functions details of the derivation of the parameters are available from mallants et al 2021 we here provide a summary of the hydraulic parameters and their depth distribution six stratigraphic layers have been considered for the unsaturated zone profiles within each landscape class detailed soil physical properties are available for the top 200 cm of the soil profile based on the asris digital map of australian soil properties including soil texture sand silt clay and bulk density mckenzie et al 2012 the asris data is available at 90 90 m2 spatial grids across australia for depths of 0 5 cm 5 15 cm 15 30 cm 30 60 cm 60 100 cm and 100 200 cm the original six layers were simplified to four 0 15 15 30 30 60 and 60 200 cm based on similarity in soil texture for depths 200 600 cm the same data as for the 60 200 cm is used consistent with the approach in australian water resources assessment landscape model awra l vaze et al 2018 for the remainder of the soil profile i e from 600 cm to the groundwater table two additional materials are defined based on an analysis of drilling logs claystone 6 22 m and siltstone 22 50 m santos 2019 owing to the paucity of data the hydraulic properties of the claystone and siltstone are based on the usda class transfer functions from carsel and parrish 1988 clay loam is used for claystone and silty clay is used for siltstone average water retention curves for each of the six stratigraphic layers for the four landscape classes together with the deeper claystone and siltstone layers are shown in fig s3 depth dependency of saturated hydraulic conductivity k s for all six layers is available from fig s4 there is a general trend for k s to decrease with depth with the deepest layer siltstone displaying a ten times lower k s than the next deepest layer claystone and up to a 25 to 100 times lower k s than the shallowest layers 2 3 2 cooper basin the cooper basin covers an area of 139 000 km2 across north east south australia and south west queensland australia holland et al 2020 conventional gas production has been ongoing for more than 50 years with the basin continuing to report new shale and tight gas discoveries there are five major landscape classes soils that occupy the entire 130 000 km2 of the basin table s2 and fig s5 the dominant landscape classes are floodplain and alluvium 32 and inland dunefields 30 followed by undulating country 20 tablelands and duricrusts 9 and loamy and sandy plains 9 as in the beetaloo sub basin there are very deep unsaturated zones within each of the five classes with depths to groundwater up to nearly 100 m table s2 depth to groundwater was derived from interpolation of water table depths observed in water bores compared to the depth of the beetaloo unsaturated zones those in the cooper landscape classes are on average about two to three times less deep soil hydraulic parameters of the van genuchten mualem models supplementary material eq 3 and 4 derived from pedo transfer functions are available from mallants et al 2021 because the asris digital map of australian soil properties has the same data types everywhere again six stratigraphic layers were originally considered for the unsaturated zone profiles within each landscape class of the cooper basin these original six layers were again simplified to four 0 15 15 30 30 60 and 60 200 cm based on similarity in soil texture for depths 200 600 cm the same data as for the 60 200 cm is used consistent with the approach in awra l vaze et al 2018 for the remainder of the soil profile i e from 600 cm to the groundwater table sandstone is defined as a single material based on an analysis of stratigraphic logs from well completion reports the minimum horizontal hydraulic conductivity for one of the most important surficial aquifers the winton mackunda aquifer is 0 1 m d evans et al 2020 which is close to the 0 062 m d from carsel and parrish for clay loam therefore the hydraulic properties for the sandstone are based on the clay loam usda class transfer functions from carsel and parrish 1988 average water retention curves for each of the six layers for the five landscape classes together with the deeper sandstone layer are shown in fig s6 depth variations of saturated hydraulic conductivity k s for all five landscape classes are available from fig s7 there is a general trend for k s to decrease with depth with the deepest layer sandstone displaying a three to six times lower k s than that of the shallowest layers 2 4 saturated zone data 2 4 1 beetaloo sub basin the surficial groundwater of the cambrian limestone aquifer cla that directly underlies most of the unsaturated zones within the beetaloo sub basin is composed of the upper cla anthony lagoon siltstone and dolostone and underlying low cla gum ridge limestone and dolostone formations frery et al 2020 the three parameters to derive groundwater pore velocity v see eq 6 supplementary material will be briefly described on the basis of detailed parameter maps derived for the entire sub basin doble et al 2021 the hydraulic conductivity k for the anthony lagoon and underlying gum ridge formations range from 1 to over 200 m d the latter value is assumed representative for karst features the hydraulic gradient i is approximately 0 0001 to 0 003 m m tickell 2003 an effective porosity value of 0 1 was used based on an environmental tracer study undertaken by deslandes et al 2019 the paucity of data did not allow to derive a range for effective porosity additional solute transport parameters are the longitudinal dispersion d x assumed to be 5 m2 y and the horizontal d y and vertical d z transverse dispersion assumed to be 0 5 and 0 05 m2 y these values are based on a groundwater pore velocity of 1 m y the range in the cla being 0 4 to 11 m y using non karstic velocities and longitudinal horizontal and vertical transverse dispersivity of 5 0 5 and 0 05 m the longitudinal dispersivity a l of 5 m value is consistent with the average dispersivity for a transport distance between 100 and 1000 m gelhar et al 1992 the transport distance 100 1000 m is relevant for this study with its main observation point at 500 m the maximum transport distance at which the environmental concentration is predicted this distance was chosen as it corresponds to the maximum travel distance in x and y direction for each of the 1000 1000 m2 grid cells for which all relevant landscape and groundwater data was made available for application of the calculation framework shown in fig 1 a travel distance of 500 m also corresponds to half the recommended minimum default offset distance between shale gas well pads and stock and domestic bores pepper et al 2018 for the horizontal a th and vertical a tv transverse dispersivity the value of a l was divided by 10 and 100 respectively consistent with anderson and cherry 1979 knowing the representative screen length of groundwater bores that would pump potentially contaminated groundwater is important to derive realistic solute concentrations with the 3d analytical model therefore the screen length was based on a sample of bores obtained from the groundwater explorer database bureau of meteorology 2019 there are 159 bores listed within a 50 km radius of the town of daly waters one of the most populated settlements in the centre of the basin of those 25 are listed as being functional all stock and domestic bores out those 25 only 17 had data on the screen depth average screen depth was 9 6 m the minimum was 6 m and the maximum was 18 m a rounded value for screen length of 10 m will be used here for vertically averaging the solute concentrations across the simulated profile 2 4 2 cooper basin surficial groundwater in the cooper basin is predominantly from the sub artesian winton mackunda aquifer and mostly unconfined aquifers in the cenozoic lake eyre basin holland et al 2020 hydraulic conductivity ranges from 0 1 to 5 m day with hydraulic gradients from 1 3 10 5 to 2 10 3 effective porosity was estimated to be around 0 1 doble et al 2021 given that the same groundwater transport distance of 500 m was used for both basins dispersion parameters were considered the same as those for the beetaloo sub basin the same screen length of 10 m below groundwater table was considered for vertically averaging of calculated solute concentrations 2 4 3 climate data with its hot semi arid steppe climate k√∂ppen climate classification subtype bsh the beetaloo gba region has distinct wet seasons november to march and dry seasons april to october hot summers and warm winters total annual rainfall is 665 mm in daly waters and 518 mm in newcastle waters pan evaporation is about 2800 mm year fulton and knapton 2015 a time series of 10 year rainfall and evaporation from the daly waters bureau of meteorology bureau of meteorology meteorological station 14618 in the northern territory was used to generate a continuous timeseries of the atmospheric boundary condition for the unsaturated zone flow and transport simulations no transpiration was considered in the calculations this increases groundwater recharge which is a conservative assumption when leaching of chemicals is of concern the climate of the cooper basin is hot and dry with summer dominated december to february rainfall and high inter annual variability within the cooper gba region the mean annual rainfall was 217 mm year with a maximum in the north east of 378 mm year and a minimum of 127 mm year in the south west mean annual potential evapotranspiration pet for the period 1976 to 2005 is 1702 mm year across the cooper gba region holland et al 2020 the rainfall and evaporation data from the windorah bureau of meteorology meteorological station 38024 was used here for the unsaturated zone simulations using again a 10 year time series of daily data as a basis 2 4 4 leak and spill scenarios make up water for drilling and stimulation fluid and flowback water from unconventional gas developments in the beetalo and cooper basins is stored in above ground double lined tanks with leak detection although the likelihood for a leak from an above ground tank is small it can never be completely eliminated mallants et al 2018 two types of leak spill scenarios are considered an off site spill from a truck roll over and an on site leak from a storage tank the on site leak scenario for the beetaloo sub basin considered that a relatively small volume of 100 000 l infiltrates the soil nearby the water holding tanks following a catastrophic breach of the tanks mitigation measures are in place to keep any leaks within a bunded area surrounding the tanks with the leaking fluids being collected in a sump with a permeable bottom dug 3 m deep into the soil santos 2019 the leak could be either drilling or fracturing fluid or flowback water for consistency and to allow comparison between gas development sites the same volume was used for the leak scenarios across the entire beetaloo sub basin a truck roll over was considered to have the highest likelihood of any gas development related incident whereby fluids could be released into the environment considering a maximum truck load of approximately 22 000 l per tanker korfmacher et al 2015 with a trailer of maximum three tankers carrying a total of 66 000 l the maximum volume of fluid that could be released was conservatively set at 100 000 l 0 1 ml this scenario assumed the entire 100 000 l will infiltrate the soil over a surface area identical to the surface area used for the on site leak in the beetaloo sub basin 360 m2 the same scenario with identical parameters will be applied across both beetaloo sub basin and the cooper basin given its higher likelihood compared to the on site leak the focus of the discussion will be on truck roll over scenario in the cooper basin the on site leak scenario considered the same 100 000 l but used a slightly larger surface area of 1500 m2 through which the fluid would infiltrate the soil this surface area corresponds to the size of the water holding ponds 30 50 m2 that are slightly different in design compared to those in the beetaloo sub basin sapex 2018 the difference between the on site leak and off site spill in the beetaloo sub basin is the assumption that fluids from the leak accumulate in a sump dug within the bunded area surrounding the main water holding tanks the features of the sump are taken from those described in santos 2019 and consider a 3 m deep rectangular hole dug into the soil with a permeable base through which the water will slowly infiltrate the underlying unsaturated zone for the given sump geometry total surface area of 360 m2 the maximum water depth for a 0 1 ml leak is approximately 0 28 m because of the 3 m deep sump the total effective depth of the unsaturated zone for the on site leak is assumed to be 3 m less compared to that for the off site spill where fluid is supposedly spilled into a shallow ditch in the cooper basin the difference between the off site spill and on site leak is more subtle for the on site leak the ponding depth defined by the 100 000 l leak volume and the 1500 m2 infiltration area becomes 0 067 m this is 4 2 times smaller than the 0 28 m ponding depth for the off site spill no sumps are used in the cooper basin hence the total effective soil depth for off site spill and on site leak are the same the framework to derive estimates of chemical dilution across large scale regions will be illustrated primarily based on the off site spill scenario 3 results and discussion 3 1 spill infiltration 3 1 1 beetaloo sub basin following a 20 year initialisation period during which the unsaturated zone profile was put in a quasi steady state condition with respect to pressure head and water content in response to the climatic boundary conditions the spill scenario was initiated by allowing 100 000 l of fluid to infiltrate a 360 m2 surface the initial ponding depth of 0 28 m quickly decreased as fluid infiltrated the soil surface fig s8 for floodplains and alluvium infiltration took less than a day whereas for clay plains and undulating country nearly three days were required to infiltrate the entire spill as time progressed soil pressure heads for the different landscape classes further diverged a result of their different hydraulic properties fig s3 s4 floodplain and alluvium soils have the overall highest hydraulic conductivity at the soil surface allowing faster water infiltration compared to the other soils fig s8 undulating country on the other hand has the lowest hydraulic conductivity therefore requires more time to infiltrate fig s8 cumulative infiltration displays the same pattern as the pressure head with floodplain and alluvium reaching its total cumulative infiltration 0 28 m or 100 000 l sooner than the other classes fig s8 loamy and sandy plains reach complete infiltration after two days while the remaining two classes take about three days to infiltrate the entire spill volume these differences in infiltration rate will have a noticeable effect on solute redistribution throughout the deep unsaturated zone see further once the spill has infiltrated the scenario assumes the same atmospheric boundary conditions as prior to the spill this results in cycles of water losses from the soil surface through evapotranspiration and gains in soil water via precipitation these highly transient processes were approximated by assuming a quasi steady state condition with a fixed water content and pressure head distribution across the entire unsaturated zone profile fig 2 the depth distribution of water content and pressure head are the result of the imposed fluxes at the soil surface and the groundwater table at the bottom of the domain in combination with the hydraulic properties that are unique to each landscape class note that although the depth of the unsaturated zone varies across the landscape for each class see table s1 calculations were done only for the maximum depth i e 95th percentile results i e peak concentrations for shallower depths were derived from the simulations with the deepest depths by collecting simulation results peak concentrations across the entire profile regardless of the landscape class moisture content displays a characteristic pattern with increasing values i e wetter towards the bottom of the deepest soil layer at 6 m depth fig 2 at that depth the less permeable claystone formation occurs causing a local build up of water and pore pressure near the interface of both layers at the first node within the top of the claystone formation water content is minimal in accordance with the low hydraulic conductivity the pressure build up above the interface is required to overcome the hydraulic resistance of the poorly permeable claystone within the claystone water content again increases with depth as the underlying siltstone at 22 m depth has again a considerably lower hydraulic conductivity fig s4 a similar phenomenon occurs as discussed for the top of the claystone pressure build up is required to force water into the less permeable siltstone formation which is accompanied by a higher water content based on the Œ∏ h relationship of the landscape class within the siltstone formation both water content and pressure head are nearly constant the result of the assumed homogenous hydraulic properties and the great depth to the lower boundary condition groundwater table at the bottom of the simulation domain a small increase in water content and pressure head less negative is observed due to the presence of the groundwater table where h 0 the water flux q h follows the same pattern as the unsaturated hydraulic conductivity k h there is an increasing trend with depth from the surface to the interface with the claystone where higher pressure head and water content increase values for q fig 2 a sharp drop in flux occurs just beneath the top of the claystone as the water enters a much less permeable formation from then onwards the flux increases again as it approaches the next interface i e that with the siltstone within the top of the siltstone the flux is much smaller again due to the smaller hydraulic conductivity owing to the fairly uniform water content and pressure head within the siltstone water flux and hydraulic conductivity are fairly uniform too there is a small increase towards the bottom of the profile due to the presence of the groundwater table the pore water velocity v q h Œ∏ displays a similar depth distribution as the water flux rescaled with the water content at each depth fig 2 for the majority of the profile i e from 22 m to the bottom of the profile pore water velocity is fairly constant with an average value of 0 023 cm day or 8 4 cm y average values for q h and Œ∏ in this calculation are 3 03 cm y and 0 355 cm3 cm3 these small velocities are determined by the low water flux and the low conductivity of the siltstone such very low water fluxes and pore water velocities are common for deep unsaturated zones in arid and semi arid climates at the hanford site washington state us with its cool desert type climate average rainfall of 180 mm y and its 70 m thick vadose zone the average recharge water content and pore water velocity estimated from sr and u isotopes are 0 5 cm y 0 09 cm3 cm3 and 5 5 cm y respectively maher et al 2006 for the deep unsaturated zones up to 100 m of china s loess plateau under semi arid climate 450 623 mm y rainfall huang et al 2013 derived pore water velocities from 13 2 to 20 8 cm y further note that the pore water velocities within the siltstone formation are virtually the same for all four landscape classes there are still differences though in velocities within the top 22 m of the profile these differences together with the difference in infiltration rate and volume of fluid that actually migrates downward are the main cause for the difference in solute arrival time and peak concentration and thus the level of attenuation that is obtained see further another hydrologic difference between the landscape classes is the depth to the zero flux plane zfp the zfp is the soil depth that separates upward movement of soil water to evapotranspiration from downward leaching to groundwater cooper et al 1990 sharma et al 1991 indeed for all classes but most so for floodplains an important upward flux exists in response to the evaporative demand of the soil as a result a larger portion of the infiltrated fluid in case of floodplains is kept above the zfp near the soil surface and does not migrate deeper this means that the effective volume for deep migration is smallest for the floodplains and largest for the loamy and sandy plains the steady state zfp for floodplains and alluvium is situated at 4 m which is nearly twice as deep as for clay plains approximately 2 m undulating country and loamy and sandy plains have the shallowest zfp respectively 1 5 and 1 1 m fig 2 by comparison depths of zfp measured in western australia under mediterranean climate 800 mm yr rainfall and 1800 mm yr pan evaporation on a coarse sandy varied between close to the surface at the start of the rainy season and near 10 m depth during summer sharma et al 1991 the next step in the simulations is to use the quasi steady state velocity profiles from fig 2 and calculate solute migration with the solute plume that entered the soil surface following the spill incident fig s8 3 1 2 cooper basin landscape classes in the cooper basin have steady state moisture and pressure head profiles that are slightly more uniform compared to those in the beetaloo sub basin fig s9 beneath the soil layers there now is only a single sediment i e sandstone within the sandstone moisture content and pressure head are rather uniform with depth with steady state values representing the equilibrium response to the imposed water flux the water flux displays some oscillations with depth a result of the atmospheric boundary condition with alternating wet and dry periods these oscillations will have an impact on the solute transport and dilution factors see further average water flux moisture content and pore water velocity across the sandstone are 5 84 cm y 0 313 cm3 cm3 and 18 6 cm y respectively compared to the beetaloo sub basin water flux and pore water velocity are on average 1 9 and 2 2 times higher in the cooper the higher saturated hydraulic conductivity of the coarser cooper top soils fig s7 compared to the beetaloo except for the undulating country in beetaloo fig s4 result in higher infiltration rates another result of the difference in soil hydraulic properties between the two basins is the shallower depths of the zfp in the cooper in between 1 and 1 5 m fig s9 compared to zfp as deep as 4 m in the beetaloo sub basin fig 2 this leads to a greater fraction of the spill volume percolating into the deeper sediments and for all five cooper basin landscape classes to higher solute concentrations compared to those beetaloo sub basin landscape classes with much deeper zfp see further 3 2 soil attenuation 3 2 1 beetaloo sub basin migration of chemicals through the generally deep unsaturated zones of the case study area is a very slow process irrespective of landscape class fig 3 the difference in solute migration profiles between different landscape classes is also noticeable differences exist in the rate at which the chemicals are transported through the unsaturated zone fig 3 and in the magnitude of the concentration peak concentrations used to calculate the dilution factors are reached slightly sooner for the undulating country and loamy and sandy plains compared to clay plains solute migration is slowest in the floodplains and alluvium landscape class there are also noticeable differences in the peak concentrations between the landscape classes with loamy and sand plains having slightly higher values than undulating country at similar depths fig 3 clay plains display nearly ten times lower concentrations compared to the two previous classes while floodplains and alluvium produce the overall smallest concentrations the solute breakthrough curves for the different landscape classes start to diverge very early on in the profile fig s10 already at 5 m depth there is a considerable difference in solute peak concentration with loamy and sandy plains displaying the largest concentration and undulating country the next largest values still smaller values are then seen for clay plains with floodplains showing the overall smallest concentrations these rankings in terms of peak concentration are consistent with those seen for the solute depth profiles fig 3 the reason for these large difference in concentration especially for the floodplain class is to be found in the different depths of the zero flux plain fig 2 where the zfp is closest to the soil surface the largest volume of water from a spill or leak will infiltrate to the deeper layers for those conditions the solute concentration will be larger compared to soils with a deeper zfp that cause smaller volumes of water to contribute to leaching to groundwater these concentration differences between landscape classes therefore result in different attenuation or dilution at the bottom of the unsaturated zone across the landscape also within one and the same landscape class attenuation varies depending on the depth to the groundwater table for instance at approximately 10 m depth in the undulating country class the peak concentration is about 0 02 or one fiftieth of the source concentration assumed unity at about 70 m deep into the profile the peak concentration has further reduced to 0 007 or 142 times smaller than the source concentration finally at the bottom of the profile the peak concentration is only 0 004 or 250 times smaller than the source concentration a similar decrease in peak concentration with increasing depth in the profile is observed for the loamy and sandy plains fig 3 note that at t 200 y the peak concentration is slightly higher than at the previous time step this is the result of an increase in solute concentration in the soil pore water as a result of a change in soil hydraulic properties at 22 m depth transition from claystone to siltstone with a 13 fold decrease in saturated hydraulic conductivity that causes a sharp decrease in pore water velocity a compression of the solute plume and therefore a local increase in solute concentration see further note that the compression of the solute plume due to the sudden decrease in hydraulic conductivity is also visible in clay plains and floodplains and alluvium when the plume reaches 22 m clay plains display a nearly ten times smaller peak concentration at the same depths compared to undulating country and loamy and sandy plains fig 3 this is the result of the smaller solute plume that passes the first few meters of the soil profile a result of a larger proportion of the infiltrating solute plume remaining close to the soil surface due to a strong soil evaporation the floodplain and alluvium landscape class produces the overall lowest concentrations and compared to all three previous classes regardless of depth the volume of solute that infiltrates past the top few meters is again smaller than that of the clay plains owing to most of the solute remaining in the top layer owing to evaporative forces 3 2 2 cooper basin solute migration through the vadose zone of the cooper basin landscape classes is about two times faster compared to that in the beetaloo sub basin fig 4 this faster migration is mainly due to a higher saturated hydraulic conductivity for the majority of the profile based on a clay loam sediment assumed for the sandstone from 6 m down to the groundwater table another difference with most of the beetaloo sub basin classes is the large decrease in peak concentration until approximately 20 m deep from which depth onwards the peak solute concentrations decrease only slightly an example of the increasing dilution factor with increasing soil depth is shown for the undulating country landscape class fig 4f similar to the beetaloo sub basin the compression of the solute plume at around 40 m has produced locally increased concentrations and hence a decrease in dilution factor this behaviour is caused by the decrease in water flux and thus in solute velocity at the depth of 37 40 m fig s9 such decrease is related to the transient atmospheric boundary condition causing a non uniform water flux profile from 40 m onwards solute concentrations decrease again with depth although somewhat erratically producing again increasing dilution factors with increasing depth this behaviour resulted in two separate dilution depth models with a stepwise transition at 37 m a similar stepwise dilution depth behaviour was observed for the other landscape classes except for floodplain and alluvium whose maximum depth was less than the depth where the solute plume compression occurred results not shown for the most abundant cooper basin landscape classes 32 for floodplain and alluvium and 30 for inland dunefields the dilution factor at the maximum depth of the unsaturated zone 39 m for floodplain and alluvium and 62 m inland dunefields is 400 and 100 respectively despite its shallower depth floodplain and alluvium have a higher dilution due to their deeper zfp linked to the overall lowest saturated hydraulic conductivity of the top soil fig s7 in comparison the most abundant landscape class in the beetaloo sub basin loamy and sandy plains covering 70 of the area has a dilution factor of 140 at the maximum depth of 115 m 3 3 groundwater attenuation once the solute plume has traversed the unsaturated zone it will seep into the surficial groundwater where it continues its migration path based on the predominant direction of groundwater flow assuming three dimensional groundwater flow that drives the advective dispersive transport of the solute plume solute concentrations were calculated at increasing travel distances here we report concentrations and associated dilution factors for a travel distance of 500 m this is to be consistent with the 1000 1000 m2 grid across the entire basin 500 m then corresponds to the distance from the centre of each grid cell also the location of the chemical source to the boundary of the grid cell doble et al 2021 groundwater advection or groundwater pore water velocity was calculated separately for each grid cell of the basin using a gis approach where input parameters were the aquifer hydraulic conductivity hydraulic gradient and effective porosity advective dispersive transport calculations were undertaken for the velocity range thus obtained to produce dilution factors in function of velocity the resulting range in groundwater dilution factors was then combined i e multiplied with the soil dilution factors to produce a combined soil groundwater dilution factor fig 5 for each landscape class dilution factors are derived as function of soil depth and groundwater pore velocity the relationships from fig 5 were then used to generate a continuous map of groundwater pore velocities that were used to generate basin scale maps of soil groundwater dilution factors for examples see fig 6 f and doble et al 2021 the general trend of the dilution factors is to increase with increasing soil depth for a given pore water velocity i e parallel to the y axis in fig 5 and for a given soil depth to increase with decreasing velocity i e ascending along the curves in fig 5 indeed a higher groundwater velocity results in a faster arrival time and less lateral and transverse dispersion compared to smaller velocities combined dilution factors in the beetaloo sub basin are largest for surficial groundwater overlain by floodplain and alluvium 6 of the basin and smallest for groundwater overlain by loamy and sandy plains this landscape class represents 70 of the basin chemical attenuation across the cooper basin displays a similar behaviour as for the beetaloo sub basin i e increasing dilution with increasing depth of the unsaturated zone and decreasing groundwater pore water velocity fig 6 one noticeable difference is in the smaller groundwater velocities approximately one order of magnitude less than in beetaloo the smaller velocities result in a somewhat larger groundwater dilution with all five landscape classes displaying combined soil groundwater dilution factors larger than 106 for the greatest soil depth for soil depths as shallow as 5 m and the smallest groundwater velocity of 0 1 m year the dilution factors are still in excess of 105 for all landscape classes 4 discussion and outlook this framework for deriving dilution factors across vast areas of land has flexibility to account for many parameters that determine the degree to which chemicals released at the soil surface see their concentrations decrease owing to physical attenuation processes dilution and hydrodynamic dispersion by gridding of soil hydraulic properties depth of the unsaturated zone and groundwater velocity based on gridded values of hydraulic conductivity hydraulic gradient and effective porosity spatially varying dilution factors were derived for both basins example maps of unsaturated zone depth groundwater velocity and combined dilution factor are available in doble et al 2021 data sets for both basins were used to derive cumulative distribution functions cdf of dilution factors fig 7 a cdf represents the probability of non exceedance i e prob x x there are two important reasons why cdfs are useful in showing the results of risk assessments first of all cdfs address the question how likely is an outcome to be this small or smaller which is a key question in any risk assessment next cdfs depict small probabilities associated with large consequences or small dilution factors fig 7 shows cdfs for the complete data sets for both basins with data pooled across all landscape classes and depths of the unsaturated zone for each probability value the minimum and maximum dilution factors represent the smallest respectively largest values across the entire depth range clearly for each cdf value the beetaloo displays the largest variation in dilution factors this is due in part to a greater depth dependency of the dilution factor in the beetaloo owing to the more heterogeneous stratigraphy compare fig 2 and fig s9 causing smaller dilution factors at shallower depths compared to the cooper basin fig 7 a breakdown of dilution factors per unsaturated zone depth class is provided in table 1 using 20 m depth intervals together with the median value 50th percentile the lower quartile q1 25th percentile and upper quartile q3 75th percentile are listed from which the interquartile range iqr q3 q1 can be derived the iqr quantifies the spread of a dataset which is resistant to the presence of outliers outliers in dilution factors exist due to extreme parameters generated by interpolation from a small number of data points the pooled data accounts for the surface area of each depth class and is therefore an area weighted value note that for beetaloo the 20 40 m depth class has lower dilution factors owing to the compression of the solute plume generating an increase in concentration and a decrease in dilution factor at the transition of the claystone to the siltstone see previous discussion a similar phenomenon is present in the cooper basin owing to a decrease in solute velocity at the depth of nearly 40 m see previous discussion travel times through the unsaturated zones are based on the governing steady state water flux calculated for the different landscape classes for beetaloo depth averaged water flux across the siltstone formation is 30 3 mm y based on the chloride mass balance method recharge rates across the beetaloo sub basin were estimated to vary between 25 mm y and less than 1 mm y a result of the karst nature of this basin deslandes et al 2019 a higher recharge of 66 mm y was derived from analysis of tritium data collected from shallow bores deslandes et al 2019 in a recent reassessment of the cambrian limestone aquifer recharge the chloride mass balance recharge estimates were constrained using baseflow and remotely sensed evapotranspiration data for the western part of the beetaloo sub basin broadly corresponding to our study area the 50th percentile and the 5th 95th percentile range were 48 and 27 92 mm y respectively crosbie and rachakonda 2021 our calculated values therefore are consistent with these estimates based on tracer measurements giving confidence to the calculated long travel times through the unsaturated zone note that the water content of the deep sediments is an equally important factor in determining chemical velocity confirming the calculated values about 0 355 cm3 cm3 for the siltstone however was beyond the scope of this study the current assessment only considers dilution and hydrodynamic dispersion in deriving dilution factors for both metals and organic compounds found in fracturing chemicals or flowback waters there is ample of literature data demonstrating weak to strong sorption onto various geo media and for organics the ability to degrade chen et al 2017 kahrilas et al 2015 labrecque and blanford 2021 scow and johnson 1997 stringfellow et al 2014 these processes are expected to further decrease chemical concentrations both in soil and in groundwater for instance transport of the biocide bronopol was found to be retarded on average 187 times relative to an inert tracer based on sorption onto soil organic carbon aerobic degradation half lives were on average 87 days mallants et al 2017 using those parameters bronopol was calculated to be removed from the soil solution within several centimeters of the surface demonstrating significant natural attenuation capacity of soils as a result of sorption and biodegradation mallants et al 2017 the risk classification based on the rq for each chemical evaluated is determined in accordance with the principles outlined by the environmental risk assessment guidance manual for industrial chemicals ephc 2009 and the australia and new zealand conservation council and agriculture resources management council of australia and new zealand anzecc and armcanz 2000 guidelines as an illustration of how the dilution factors can used to assess risks from specific chemicals ecotoxicological risk quotients rq are derived from the ratio of predicted environmental concentration pec at a receptor to predicted no effect concentrations pnec rq pec pnec for chemicals of low concern i e rq is less than 1 compounds with rq larger than 1 and less than 10 are considered to have the potential to cause adverse environmental effects if they are released into the environment dedicated risk management measures may be required to ensure that chemicals of potential concern do not cause harm to the environment doee 2017 chemicals with rq larger than 10 are likely to cause adverse environmental effects if released into the environment dedicated risk management measures are likely required to ensure that chemicals of potentially high concern do not cause harm to the environment doee 2017 rqs are calculated for 39 chemicals to be used in the stimulation fluid at a typical deep shale gas well located in the beetaloo sub basin santos 2019 for a limited number of chemicals pnec values were sourced from the australian water quality guidelines anzecc armcanz 2000 for the remaining chemicals pnecs were derived by kirby et al 2021 fig 8 displays the rqs calculated from the calculated pec values using the median 50th percentile dilution factor at a hypothetical well at 500 m from where the spill occurred the pecs were also calculated for the 25th and 75th percentile dilution factor derived from a subregion of the relevant exploration permit that is within the beetaloo sub basin total area of 1527 km2 these percentiles account for variation in landscape class depth to groundwater and groundwater velocities across the lease area similar to data from table 1 fig 8 demonstrates that for all but two chemicals hydrochloric acid rq 1 37 and tributyl tetradecylphosphonium chloride rq 6 01 the ecotoxicity endpoint are not exceeded i e rq less than 1 at a hypothetical receptor point 500 m downstream from the area where the spill occurs in other words except for two all other chemicals are of low concern the environmental fate of hydrochloric acid and tributyl tetradecylphosphonium chloride is further influenced by additional natural attenuation processes hydrochloric acid is expected to dissociate in water to hydrogen h and chloride cl ions while additional natural attenuation processes will further reduce exposure concentration and organism effects as the acid plume moves through the soil several geochemical processes can be expected bea et al 2013 hyun et al 2020 proton sorption on sediments e g goethite and kaolinite dissolution of existing minerals and precipitation of secondary minerals e g al and fe oxides all of which will contribute to acid neutralization given the long transport times through soil of several hundred years fig 3 and the relatively fast rate of mineral dissolution and precipitation in the presence of h full acid neutralisation can be expected before the plume reaches the groundwater tributyl tetradecylphosphonium chloride is a biocide expected to be readily biodegradable 60 in 28 days kirby et al 2021 also natural attenuation processes will further reduce exposure concentrations and organisms effects e g adsorption kahrilas et al 2015 complexation and transformations as can be seen from fig 3 the estimated transport time from the source of the spill soil surface to the groundwater table is at least several hundred years sufficient to completely biodegrade compounds like tributyl tetradecylphosphonium chloride we note again that the source concentrations used here are not the actual ones but those considered in the planning stage these results are very robust given that the rqs for most chemicals are several orders of magnitude smaller than one while there are several factors that could increase the pec values including increased local recharge larger spill volumes or higher source concentrations these are not likely to increase the rqs above one given the current results while soil and or groundwater monitoring of specific chemical e g the hydrochloric acid and tributyl tetradecylphosphonium chloride discussed above is one of several potential mitigation measures to prevent contamination it would be more effective to monitor leaks and spills in a staged approach whereby the most mobile water quality parameters such as salinity chloride or ph are analysed first as they would be precursors of the more slow moving organic compounds pepper et al 2018 such water quality parameters are also easy and relatively cheap to measure while some can be tracked using permanently installed in situ monitoring devices including geoelectric systems e g aaltonen and olofsson 2002 binley and daily 2003 daily et al 2004 spectroscopy based sensors e g hartzler et al 2019 and fiber optics e g shanafield et al 2018 once a trigger value of the most mobile parameters has been exceeded measurement of the organic compounds can be considered note that trigger values should be sufficiently conservative to provide an early warning of potential risks to groundwater to allow for sufficient time for remedial actions to be undertaken before groundwater pollution occurs early monitoring of contaminants should focus on the unsaturated zone to detect pollutant fluxes before they reach the groundwater table vrba and adams 2008 table s3 lists the groundwater pecs and pnecs for 39 chemicals scheduled to be used in the stimulation fluid santos 2019 we note that these are not actual concentrations used but rather estimated concentrations as reported in the environmental management plan emp note that our environmental risk assessment ignores attenuation by sorption and degradation hence is still conservative as a potential next step a site specific risk assessment accounting for additional attenuation processes can be undertaken focussing on those few chemicals that were not identified to be of low risk large scale impact assessments on the scale of several tens of thousands of km2 28 000 km2 for beetaloo sub basin and 139 000 km2 for cooper basin in data poor areas will necessarily be limited by the amount of information on critical process required for modelling we argue that similarly data poor areas exist elsewhere and that the methodology developed has broader applicability then just regional this is especially true if one considers the tiered approach for risk assessments recommended by the us epa 2014 furthermore large scale risk assessments are most cost effective and fit for purpose when a tiered approach is adopted us epa 2014 at the lowest level tier 1 the assessment uses generic properties and conservative assumptions qualitative assessment at the next level tier 2 deterministic approaches it incorporates site specific data knowledge and exposure scenarios while advanced analysis using probabilistic exposure scenario analysis techniques including quantitative assessment of variability and uncertainty are typical of the highest level tier 3 probabilistic approaches our approach is at tier 2 where a deterministic assessment is undertaken with spatially variable site specific data at 1 km2 grid cells commensurate with the scale of the assessment where the risk is possibly higher than acceptable more detailed site specific studies can be undertaken consistent with tier 3 of the tiered risk assessment approach in such case site specific transport kinetic parameters can be collected together with more detailed soil hydrologic and groundwater flow and transport parameters the argument of method transferability or not to other hydroclimate scenarios is addressed next our study has shown that it is applicable across different climates as the two case study areas have a distinctly different climate the beetaloo sub basin climate has a hot semi arid steppe climate k√∂ppen climate classification subtype bsh with a total annual rainfall is 665 mm the cooper basin is much more aridic persistently dry desert bwh with a mean annual rainfall was 217 mm when a mechanistic soil hydrological code like hydrus is used with proper use of hydroclimatic boundary conditions as input then the method is transferability to other hydroclimates as any transient flow and transport condition that will exist will be a reflection of the combined effect of hydroclimate and soil properties both of which should be available at a tier 2 and 3 assessment level 5 conclusions the unintentional release of chemicals during surface handling associated with shale and tight gas exploration and production drilling hydraulic fracturing flowback water can lead to limited spreading into unsaturated soil and sediments with further migration to surficial groundwater detailed numerical simulations of chemical fate and transport with the state of the art hydrus 1d code showed very long transfer times across deep unsaturated zones up to 100 m and more in the order of several hundreds of years in the beetaloo sub basin such slow chemical migration is due to the very slow pore water velocity 8 4 m century owing to the low hydraulic conductivity of the claystone and siltstone rock formations that make up more than 90 of the total unsaturated zone thickness in combination with the low rainfall and high evapotranspiration rates of the region cooper basin sediments produced a nearly two times faster pore water velocity while also being two to three time less deep compared to the beetaloo as a result transit times in the cooper are several times faster than in the beetaloo to account for spatial heterogeneity in soil characteristics critical to chemical fate and transport major landscape classes or soil types were used to summarise the dilution factors considerable differences in transport behaviour were observed between classes primarily driven by different hydraulic properties that produced different depths of the zero flux plane between 1 and 4 m depth in the beetaloo sub basin causing different amounts of chemicals being retained close to the soil surface and therefore not contributing to deep leaching the use of a three dimensional analytical model of the advection dispersion equation delivered dilution factors on a spatial resolution of 1000 1000 m2 across both basins the combined pooled unsaturated zone groundwater dilution factor for the beetaloo sub basin was found to be 4 230 50th percentile with lower and upper quartiles of 778 and 15 400 respectively for the cooper basin the 50th percentile dilution factor was 7 970 for pooled data with upper and lower quartile values of 3 830 and 21 100 high resolution spatial maps of combined dilution factors have been produced based on the dilution factor relationships developed here doble et al 2021 such maps are practical tools to inform effective monitoring and management practices to support regulation and management of the gas industry in australia an example environmental risk assessment application based on 39 hydraulic fracturing chemicals scheduled for stimulation of a shale gas well demonstrated ecotoxicological risk quotients rqs for most chemicals to be low enough i e less than 1 to indicate negligible environmental impact this result was based on assuming only dilution and dispersion contribute to attenuation for chemicals that had their rq above 1 additional attenuation processes such as biodegradation mineral dissolution and precipitation are expected to further decrease chemical concentrations to levels that cause no environmental harm credit authorship contribution statement dirk mallants conceptualization methodology writing original draft writing review editing rebecca doble data curation visualization yousef beiraghdar data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we thank dr luk peeters dr david rassam and mitchell bouma for useful discussions the feedback from two anonymous reviewers improved the manuscript this work was produced under the geological and bioregional assessments program funded by the commonwealth department of agriculture water and environment https www bioregionalassessments gov au geological and bioregional assessment program the datasets from this paper are available at data gov au appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127271 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3801,the long term spatiotemporal assessment of groundwater resources through robust clustering techniques can be used to promote remediation measures for groundwater depletion and contamination to fully understand the variability of groundwater quantity and quality due to anthropogenic activities and climate changes a new ensemble clustering framework based on the combining multiple clusters via similarity graph comusa method was developed this new approach was applied and evaluated in the context of groundwater well systems on the ghorveh dehgolan plain gdp which is located in western iran for groundwater level gwl and 13 physicochemical parameters during four periods the average of data from 1988 1990 1997 1999 2006 2008 and 2015 2017 the classification was confirmed by using the cluster validity index of the silhouette coefficient sc which indicated that the cluster ensemble method could improve the performance of individual clustering methods for groundwater quantity and quality by up to 12 and 20 respectively piper plots us salinity laboratory staff ussl diagrams and the pollution index of groundwater pig were assessed for all clusters of physicochemical variables to analyse groundwater suitability for drinking and irrigation purposes the results of the cluster ensemble showed that a critical pattern of groundwater depletion occurred in the western half of the gdp while the eastern part was recognized as the most polluted zone on the plain it could be concluded that the decline in gwl was not the only reason for the increase in groundwater quality variables but other factors such as noticeable cropland expansion and the overuse of chemical fertilizers and pesticides were also influential factors related to these patterns taken together the results of this study contribute to better recognizing the spatiotemporal changes in groundwater quantity and quality under the intense pressure of anthropogenic activities keywords groundwater pollution index of groundwater pig cluster ensemble ghorveh dehgolan plain gdp 1 introduction sustainable groundwater management is one of the significant issues in environmental engineering while freshwater scarcity affects human life there is also ample evidence suggesting that the quality of groundwater the largest freshwater resource is threatened due to the combination of industrial development inadequate sanitation systems chemical fertilizers and pesticides and groundwater depletion groundwater depletion and contamination of aquifers affect human health costs of water supplies and future civilization hence recognizing changes in groundwater quantity and quality is an essential part of informed water resource protection groundwater quality depends on changes in various variables and spatiotemporal assessment of each variable is a complicated and time consuming procedure to simplify assessments of groundwater quality decreasing the large dimension of water quality variables and representing data in a simpler way various water quality indices have been proposed which provide a simple value to identify the quality of water for instance the relative effect of each chemical variable on the general chemical quality of groundwater may be assessed using the pollution index of groundwater pig this index quantifies the concentration status of water quality measures related to their standards for drinking water quality e g see subba rao and chaudhary 2019 egbueri 2020 considering the importance of groundwater protection finding efficient methods to recognize complex relationships between various variables is an essential step in extracting the most homogeneous patterns additionally spatiotemporal assessments of these homogeneous patterns can effectively find and trace the time and place of changes in groundwater variables in this regard one of the robust multivariate analyses is clustering which is widely used to classify multidimensional inputs into homogeneous groups clustering can extract features from an unlabelled input to form clusters having maximum within group object similarity and between group object dissimilarity nourani and kalantari 2010 in general all members of each cluster may be regarded to have almost the same pattern that can simplify evaluation and accelerate decision making processes for instance i a designed water resource management strategy for a member e g watershed or piezometer may also be applied to the other cluster members which have similar conditions ii variables of a hydrological model for a cluster member may further be verified for other members of that cluster iii the available data of a cluster may be used to fill in missing data of other members within the same cluster the powerful applications of clustering methods have encouraged researchers to take advantage of various clustering algorithms in groundwater assessment for specific purposes table 1 as a practical linear type of clustering the k means algorithm has been applied to several hydrology fields due to the simple linear structure that can classify unlabelled inputs into separate k clusters e g fabbrocino et al 2019 sharif et al 2015 hierarchical cluster analysis hca is another successful clustering approach developed as a powerful partitioning tool that seeks to build a hierarchy of clusters different hca types single linkage complete linkage average linkage and ward method have yielded valuable results in groundwater assessment research e g see bhakar and singh 2019 some clustering algorithms utilize competitive learning concepts to classify data automatically and one of the best known examples is the self organizing map som in the standard version of som the number of neurons should be set based on the expected number of clusters previous studies have revealed that som is a powerful tool to visualize different groups of groundwater quality and quantity variables see wu et al 2021 baghanam et al 2020 nourani et al 2016 although som has been widely applied for clustering purposes the inefficiency in topology recognition is a major limiting factor of the som method another limitation of utilizing the som clustering method on large scale structures of inputs is the time consuming process of som to diminish the impacts of these limiting factors other alternative methods have been suggested on the basis of som growing neural gas gng is an som based algorithm that learns complex relationships without prior knowledge gng uses competitive hebbian learning chl to form topology without being restricted in k dimensional structures this method has gained considerable attention due to its flexibility in complex pattern recognition and has been successfully utilized as a multipurpose tool in various fields of engineering such as robotics viejo et al 2014 medicine aljobouri et al 2018 the clothing industry jimeno morenila et al 2016 hydrology abdi et al 2017 and computer science e g shi et al 2014 garc√≠a rodr√≠guez et al 2012 santos and nascimento 2016 but there is a gap in the use of gng for the clustering and assessment of groundwater quality and quantity variables on the other hand since every individual clustering method can extract particular features from a dataset and there is no agreement among researchers about the superiority of a specific method table1 finding an appropriate clustering method is a challenging task additionally the homogeneous formation of clusters is a sensitive process in which the cluster ensemble can effectively perform and benefit from the advantages of different clustering methods simultaneously e g see mohammadi et al 2008 azimi et al 2009 mimaroglu and erdil 2011 mimaroglu and erdil 2013 combining multiple clustering via similarity graph comusa is a flexible cluster ensemble method that creates a similarity graph by utilizing the evidence accumulated from the different clustering methods comusa can find arbitrarily shaped clusters and is not affected by cluster size noise or outliers leading to more homogeneous clusters mimaroglu and erdil 2011 there are still no studies that have applied the comusa algorithm in the general fields of hydrology and water resources the present study attempted to identify spatiotemporal groundwater quantity and quality changes using ensemble clustering based on the similarity graph method for the ghorveh dehgolan plain gdp located in western iran where overpumping and overuse of fertilizers and pesticides for irrigational purposes have placed significant pressures on groundwater resources of the gdp this method was applied to combine the results of three practical clustering algorithms commonly used k means method agglomerative hierarchical method of ward and gng as an unsupervised ann based method to extract the most homogeneous structures of clusters from groundwater variables of the gdp after recognizing existing groundwater quality and quantity patterns the piper plot us salinity laboratory staff ussl diagrams and pig evaluated the quality of patterns to investigate groundwater suitability for drinking and irrigation purposes 2 in situ experimental investigation on the study area and data analysis the gdp is located in western iran within the longitude from 47 38 52 to 48 06 03 east and latitude from 35 02 22 to 35 30 54 north the climate of the examined area is semiarid while during winter the average minimum temperature is 5 5 c and the region experiences a daily maximum temperature of 36 c in the summer moreover the average annual precipitation in this area is 345 mm this paper used data of 49 groundwater level monitoring wells in the plain for monitoring monthly gwl and 41 groundwater quality monitoring wells measured twice a year for monitoring geochemical variables provided by the kurdestan regional water authority krwa 2017 the location map and positions of wells of the gdp are shown in fig 1 a the main recharge sources of groundwater of gdp are precipitation and subsurface flow from surrounding highlands and rivers fig 1b while the semiarid climate with low precipitation and surface water potential limit the recharge process of the aquifer in addition irrigation water infiltrates back to the groundwater system the northwestern parts of the plain have experienced extreme subsidence due to the high amounts of groundwater depletion fig 1c besides anthropogenic activities have impacted the plain which drained a large part of surface water resources such as the dehgolan river fig 1d groundwater samples of the gdp were tested in a laboratory to examine the physicochemical variables to study the water quality fig 1e the plain also has hygienic problems because there is no sanitary landfill in the region fig 1f resulting in leachate penetration into groundwater there are several observation wells in the plain to explore and collect water samples for studying the groundwater quantity and quality fig 1g in this study four time steps with ten year intervals were selected to investigate long term trends of data sets due to the possibility of extreme values in a 1 year dataset the average of three year datasets for each time step was selected to avoid possible bias and anomalies a statistical summary of the groundwater parameters is presented in table 2 the unconfined alluvial aquifer of gdp covers an area of approximately 1270 km2 in kurdistan province based on pumping tests carried out in the plain the transmissivity of the gdp aquifer varies between 50 and 1492 m2 d the range of hydraulic conductivity of the aquifer is from 34 to 90 m day the average value of the gdp aquifer storage coefficient is about 1 7 gwls vary from 1740 m to 1961 m above the mean sea level the gdp is located in the sanandaj sirjan structural zone of iran the sanandaj sirjan is identified as a region of polyphase deformation the latest reflecting the collision of arabia and eurasia and the subsequent southward propagation of the fold thrust belt therefore the geology of the study area is characterized by geologic structures and fracture systems geological examinations have shown that this area primarily contains limestone dolomite rocks and quaternary units the most common of which include alluvial plain deposits alluvial terraces alluvial fan deposits calcareous sandstone and travertine notably small areas with dolomite and limestone were discovered in the central and western parts of the plain which are susceptible to pollution caused by transportation on land surfaces which flow into the aquifer karst system to a large extent rahmati et al 2015 fig 2 also contains geological cross sections indicating possible structures in the gdp fine grained and coarse grained units are repeated alternately over the plain and do not follow a specific order regarding the condition of borehole logs of exploratory wells in gdp fig 3 shows some samples of borehole logs in the western part l1 l2 and l3 central part l4 l5 and l6 and eastern part l7 l8 and l9 of the gdp illustrating the direct relationship between the increase in depth and the coarse grained units hydrogeological properties of the aquifer layers and their thickness were estimated through 340 geoelectrical soundings and 15 geoelectrical profiles provided by krwa krwa 2017 see fig 4 representing three of them fig 4a illustrates the western section i i including four layers the first layer shows the surface layer with a thickness of 15 40 m containing alluvial deposits consisting of silt clay sand and gravel the samples of boreholes show the soil textures of the first layers of the i i section fig 3b the second layer thickness varies from 25 to 50 m forming from the alternation of medium grained alluvial at the top and coarse grained alluvial deposits at the deeper depth the main texture of the third layer is fine grained alluvial deposits with an average depth of 50 m the third layer with a lower potential of discharge contains groundwater the fourth layer is the bedrock of this profile referring to the terissic jurassic period and contains dark grey crystalline limestone with interbedded metavolcanic rocks slate phyllite conglomerate and crystalline limestone geophysical investigations divided the central profile ii ii into three layers fig 4b the first layer with a thickness range of 5 30 m is an alternation of surface alluvial deposits with high percents of gravel the second layer thickness reaches 200 m in which the alluvial deposits with high percents of gravel were recognized the last layer as bedrock contains granite amphibole granite diorite marble and crystalline dolomite in some areas of the ii ii cross section the bedrock is not detected due to the existence of a fault creating a significant disturbance in the lower alluvium of the aquifer the first layers of the eastern cross section iii iii fig 4c consist of alternations of fine grained alluvial deposits with high percents of silt clay and gravel see borehole logs of fig 3d the bedrock of the eastern part of the gdp s aquifer has low resistivity representing layers such as argillaceous marl and sandy marl it is worth mentioning that the low groundwater quality of the eastern part of gdp could affect and disturb the results of geophysical investigations in order to define groundwater flow directions and rates through the aquifer the interpolation map of gwl was created regarding the permeability of the aquifer materials the kriging algorithm was utilized to create an interpolation map and generate contour maps fig 5 each contour or equipotential represents a line of equal hydraulic head it is clear from fig 5 that the general groundwater flow direction is from the west and southwestern regions of the plain to the east and southeastern regions also the southern parts of the aquifer have greater hydraulic gradients and the location of equipotential lines represent a lower groundwater hydraulic gradient in the eastern part of gdp 3 methodology utilizing the proposed methodology of this study see fig 6 groundwater quantity and quality variables of the gdp were first patterned using three individual clustering methods k means ward and gng then the cluster ensemble technique was used as a postprocessing method to form the most homogeneous clusters additionally before assessing the conditions of clusters cropland expansion was visualized by using the normalized difference vegetation index ndvi data of all time steps to show its impacts on groundwater on the gdp finally spatiotemporal analyses of the patterns obtained were conducted by comparing groundwater level gwl pig piper and ussl diagrams 3 1 k means clustering method k means is one of the clustering methods that has shown decent performance in hydrological research k means classifies inputs into clusters in which the distance between the members and the centroid of clusters is at a minimum degree macqueen 1967 finally this algorithm aims at minimizing an objective function given by 1 j i 1 n j 1 k r nk x i v j 2 where n is the number of data points k is the number of clusters x i v j is the euclidean distance between x i and v j r nk 0 1 is indicator variable where k describing the data point x i is assigned to which of the k clusters x is the set of data points and v is the set of centres 3 2 ward s hierarchical clustering method hierarchical cluster analysis has been developed as a flexible data grouping application in scientific fields this method first forms clusters with a single member then these clusters are merged to create clusters containing two members and this process continues until it forms a final cluster consisting of all members new clusters are created based on the minimum variance of each step for more details about the hierarchical clustering method see subba rao and chaudhary 2019 egbueri 2020 3 3 growing neural gas gng network gng is one of the som based algorithms that as an unsupervised learning method further utilizes a growing mechanism for gradual adaptation to create a network topology without being restricted in a k dimensional structure gng utilizes the chl growth approach fritzke 1995 linking neurons form the neighbourhood network which structures in each iteration by first and second winner neurons at random positions and associated reference vectors then gng generates a random input related to a density function and finding the nearest neurons winner neurons continues to increase the age of all edges the insertion of connections between the two closest neurons to the randomly generated input patterns establishes an induced delaunay triangulation in the input space the elimination of connections diminishes the edges that no longer comprise the triangulation this is performed by eliminating the connections between neurons that are no longer close or that have nearer neurons finally the accumulated error allows the identification of those zones in the input space where it is necessary to increase the number of neurons to improve the mapping jimeno morenilla et al 2013 the gng learning algorithm steps are as follows fig 7 i start with neuron a and neuron b at random positions in which w a and w b are their associated reference vectors ii generate a random input time series related to a density function p Œæ iii find the nearest neuron s1 winner neuron and the second nearest neuron s2 iv increase the age of all edges emanating from s1 to its neighbours v increase the local error of s1 by using the euclidean distance between two vectors as Œ¥ e r r o r s 1 w s 1 Œæ 2 2 vi relocate s1 and its topological neighbours towards Œæ by Œµw and Œµn learning rates respectively of the total distance n shows all direct neighbours of s1 3 Œ¥ w s 1 Œµ w Œæ w s 1 4 Œ¥ w s n Œµ n Œæ w s n vii if there exists an edge between s1 and s2 then set zero as their age viii remove the edges larger than a max if this results in isolated neurons without emanating edges remove them as well ix for every certain number of inputs generated insert a new neuron x decrease all error variables by multiplying them with a constant Œ≤ xi delete outliers based on the network edge length average xii if the stopping criterion is not yet achieved proceed to step 2 xiii reorder network neurons using neighbourhood structure unlike classical clustering algorithms gng has a flexible and adaptable algorithm that makes it practical for learning the topology of high dimensional datasets the gng algorithm was written and implemented in matlab r2018b 3 4 combining multiple clusterings via similarity graph comusa cluster ensemble methods aim to combine multiple clustering algorithm results to produce a better clustering outcome than those from individual clustering methods in terms of consistency and quality combining multiple clustering methods requires reusing pre existing knowledge employing distributed data mining methods and producing a final clustering with better overall quality various solutions for combining multiple clustering methods have been presented such as genetic hybrid bipartite graph formulation hypergraph partitioning and meta clustering algorithms alqurashi and wang 2019 there is no single algorithm that is universally used and there are no generally agreed upon criteria for selecting the most suitable ones in this case it is better to apply the one with the most simplicity and efficiency with this aim the present study attempted to combine the three clustering methods in groundwater assessment using the similarity graph method via the following steps mimaroglu and erdil 2011 where d is a dataset œÄ d c 1 c 2 c œÄ d is an individual clustering of d c i is a cluster of œÄ d œÄ d œÄ 1 d œÄ 2 d œÄ m d is a set of the best results of different clustering methods the following function forms a co association similarity matrix sm 5 c o a s s o c i j votes i j where votes i j is the number of times that members i and j were in the same clusters this information of members produces the sm the similarity graph is an undirected and weighted graph that displays the sm in a similarity graph sg d e and each edge d i d j has a mark associated with the smij in the co association matrix df d i is the degrees of freedom and sw d i is the sum of weights of edges incident to di the attachment index eq 6 is for initiating new clusters a member with the highest attachment index is selected as an initial member pivot 6 a t t a c h m e n t d i s w d i d f d i initially each cluster is a singleton and the pivot object expands the cluster by considering all immediate neighbours a neighbour is included in a pivot s cluster if it is most similar to the pivot once a neighbour is included it is marked and then acts like a pivot by considering its immediate neighbours for further expansion each cluster is expanded by its neighbours as explained previously extension of a cluster comes to an end if pivots of a cluster cannot add any other objects into the cluster comusa starts a new cluster by choosing a new pivot if there are unmarked objects in a dataset comusa halts when all objects are marked for more details see mimaroglu and erdil 2011 note that the comusa algorithm was written and implemented in matlab r2018b 3 5 cluster validity index the silhouette coefficient sc is measured to assess and compare the performance of clustering methods to calculate the sc for clustering structures first the s i for all members is calculated as a silhouette index rousseeuw 1987 7 s i b i a i m a x a i b i a i is the average euclidean distance between member i and all members of cluster a and b i is the least average dissimilarity of member i to the members within a cluster distinct from cluster a based on this formula it infers that 1 s i 1 therefore if s i is adjacent to 1 it may be concluded that the sith feature vector has been allocated to a proper cluster conversely when s i is adjacent to 1 it may be inferred that the s i th feature vector has been classified incorrectly when s i is almost zero it indicates that the s i th feature vector is located similarly far away from two clusters while n is the number of members and k is the number of clusters the overall quality of a clustering method and the optimal number of clusters can be validated using the average silhouette width of the entire dataset for each number of clusters as 8 sc max k 1 n 1 n s i when average silhouette values were calculated for desired numbers of clusters k 2 3 n the maximum average silhouette is sc representing the optimal number of clusters a higher sc illustrates better discrimination among the clusters 3 6 pollution index of groundwater pig subba rao 2012 proposed the pig to quantify pollution activity originating from anthropogenic and geogenic sources in which the relative effect of single chemical variables on the general chemical quality of groundwater can be identified by using only a simple value subba rao 2012 suitability assessment of drinking water quality by using the pig is taken in five steps i estimation of the relative weight rw on a scale of 1 5 of the analyzed variables based on their significance in the water quality assessment and relative impact on human health table 3 ii calculation of the weight parameter wp to assess its relative association with the groundwater quality table 3 is as follows 9 w p r w r w iii the status of concentration sc is measured by dividing each of the water quality variable contents c by its respective drinking water quality standard limits ds as 10 sc c d s table 3 presents the status of the relative influence of individual physicochemical variables on overall groundwater quality by using rw wp and ds iv the overall groundwater quality ow is calculated by multiplying the wp by the sc 11 ow w p s c v the summation of all ow values per sample gives the pig as 12 pig o w the pig values reveal the contributions of all analyzed hydrochemical variables of each groundwater sample it is noteworthy that in this study in addition to the variables in table 3 the sodium absorption ratio sar and electrical conductivity ec parameters also contributed to the evaluation of groundwater suitability for irrigational purposes 4 results and discussion assessment of hydrological phenomena has complicated procedures where analysis requires powerful applications of enhanced methods and to that end in this study first to explore and assess the spatiotemporal changes of groundwater quantity and quality on the gdp the study was conducted over four time steps the first second third and fourth time steps are the averages of the datasets for the 1988 to 1990 1997 to 1999 2006 to 2008 and 2015 to 2017 limits respectively the averages of three years as representative of the time steps were selected to avoid possible bias and anomalies that may occur in a one year dataset the groundwater quantity and quality datasets of these four time steps were first clustered separately by individual clustering methods and the optimal results were selected based on the sc with the aim of enhancing the structure of clusters the results of individual clustering methods were then combined through a cluster ensemble algorithm as a postprocessing step finally the spatiotemporal changes of clusters were evaluated via the assessment of the sc gwl pig and groundwater quality diagrams 4 1 results of individual clustering methods individual clustering algorithms including linear k means hierarchical ward and self organizing neural network gng clustering methods were applied to the four time step datasets and the optimal number of clusters nc was chosen by comparing the sc from 2 to 10 clusters after the training process the results of individual clustering methods are shown in table 4 for gwl and physicochemical variables using normalized data as shown in table 4 in all time steps the sc indicates better performance for the gng clustering method compared with the other individual clustering methods the main reason for the superiority of gng against ward and k means is the way that this flexible method can drive its nodes through the topology of inputs in contrast the rigid structure of the other methods k means and ward limits their applicability in dealing with complex datasets additionally the adaptation ability and optimized growth of gng lead to a desired resolution of the clustered networks based on the sc results higher than 0 5 show well structured clusters and those lower than 0 5 show that samples are structured poorly a comparison of sc values in table 4 indicates the satisfactory performance of all clustering methods in gwl clustering in contrast the sc values of qualitative clustering via k means and ward methods illustrate inadequate structures in some time steps these differences between the sc of quantitative and qualitative clustering might be related to the number of input variables for gwl clustering only spatial parameters utm and groundwater level were imposed on clustering algorithms while in qualitative clustering in addition to gwl variables 13 physicochemical variables of groundwater samples were utilized the high dimensional dataset of qualitative variables and the existence of nonlinear and complex relationships among variables caused unsatisfactory results in the k means and ward methods under the same conditions the gng method obtained acceptable results in all time steps because of its ability to recognize complex relationships after applying individual clustering techniques a cluster ensemble method was applied to improve the clustering performance as a postprocessing step 4 2 results of the cluster ensemble regarding the fact that there is no agreement regarding the superiority of specific clustering methods and the optimal number of clusters in this study the best results of individual clustering methods were combined via the similarity graph comusa method which can efficiently find the natural number of clusters mimaroglu and erdil 2011 with the similarity matrix formation for all time steps the attachment index for all members was calculated the highest amount was randomly selected based on the preliminary nodes of the clustering operation then the correlation coefficient of other members related to the preliminary nodes was measured to form new clusters this practice was continued until all members were settled in their clusters comusa can find shapes of clusters and can assign members to a cluster if they are most similar to a pivot high attachment values in that cluster the growth of clusters is based on immediate neighbours of pivots if a member enters a cluster it receives a label as a new pivot to continue the expansion process of the cluster until all members are labelled then comusa halts information on the quantitative and qualitative patterns of the cluster ensemble is presented in tables 5 and 6 additionally as an example of generating a cluster ensemble using comusa the final gwl clusters of the fourth time step are shown in fig 8 the red dotes in fig 8 highlight the preliminary pivot objects of all clusters which indicate high attachment values high sum of weights and low degrees of freedom that indicate they are strongly connected somewhere after estimating the pivot object the expansion of each cluster is continued by considering all their immediate neighbours shown with black circles fig 8 furthermore the euclidean distance criterion was then calculated to determine the prominent centroid well of each cluster as the best representation of the groundwater quantity and quality clusters the determined central wells of clusters are highlighted in the third column in tables 5 and 6 after recognizing the new patterns of gwl and physicochemical variables the sc was computed for all time steps a comparison of results in table 4 with results in tables 5 and 6 indicates that the application of the cluster ensemble could successfully enhance the performance of individual clustering methods for groundwater quality and quantity up to 12 and 20 respectively it is worth mentioning that an increase in the sc even in small amounts can be very effective in evaluating groundwater conditions in areas where the number of observation wells is low belonging to an appropriate cluster is crucial in making the decision about a member according to tables 5 and 6 the centroid wells were almost the same until the number of clusters changed it is noteworthy that the centres of the preliminary clusters have continued to maintain their position in later time steps which indicates the suitability of the centroid wells to consider their quantitative and qualitative conditions as the best representative of clusters to provide a broader perspective on the impacts of anthropogenic activities on groundwater patterns the areas of cropland expansion were assessed for all time steps additionally the ndvi dataset of each time step was sketched to see the spatiotemporal changes in cropland and their impacts on the groundwater conditions on the gdp 4 3 assessment of cropland areas it is noteworthy that people living on the gdp depend on commodities produced by irrigated agriculture and the gdp is one of iran s potato production bases where farmers apply large amounts of water fertilizers and pesticides to agricultural soil to achieve a high production therefore before assessing the quantitative and qualitative conditions of groundwater having a broader perspective on cropland areas on the gdp is a valuable step in understanding the relationship between groundwater problems and cropland expansion on the gdp considering that the primary groundwater consumption on the gdp is for irrigational purposes there can be a significant relationship between cropland expansion and groundwater problems which also has been reported for other regions in previous studies e g foroumandi et al 2022 to this end remote sensing rs can help visualize cropland area changes ground covers have a defined spectral signature spectral reflectance patterns compressed into spectral vegetation indices because of their ability to distinguish different vegetated surfaces the ndvi is one of the most well known vegetation indices and involves the ratio of the difference and the sum between near infrared and red bands this index can distinguish vegetation from other soil coverings nourani et al 2021 foroumandi et al 2021 to take into account the contribution of agricultural prosperity and its impacts on the quantitative and qualitative conditions of groundwater the landsat derived ndvi maps related to july 1989 1998 2007 and 2016 the spatial resolution size of 30 m for each pixel of landsat 5 and landsat 8 images were sketched on the google earth engine gee cloud computing platform the ndvi maps for all four time steps in which the darker green colours in pixels express the higher values of the ndvi and the centroid wells of gwl and groundwater quality clusters are shown in fig 9 according to reports from the agricultural organization of kurdistan province table 7 an incremental increase in irrigated cropland areas has occurred over time which has almost more than doubled in the last time step additionally in the western half of the gdp the irrigated cropland area increased over 90 percent between the second and third time steps these changes are clearly discernible among the maps in fig 9 the difference in the area of irrigated cropland from 1988 to 2017 was 24 675 ha table 7 the most significant increase in irrigated cropland area occurred between the second and third time steps approximately 11194 ha in comparison the rainfed cropland area decreased by 10 958 ha during this time which shows an increasing tendency among local farmers to cultivate irrigated crops this crop pattern has shifted to cultivating water intensive crops such as potato and forage crops which is another influential factor affecting groundwater conditions on the gdp the comprehensive assessment of cropland area changes and their impacts on groundwater status is performed simultaneously with trend analysis of clusters in the following subsections 4 4 trend analysis of gwl the cluster ensemble of the gwl could recognize three patterns for both the first and second time steps and could extract five and seven patterns for the third and fourth time steps respectively the increase in the number of clusters indicates that over time initial strong relationships among members have diminished and has resulted in splitting large clusters into smaller clusters to maintain the quality of the clusters fig 10 shows the spatial distributions of the gwl clusters in the first and last time steps as shown in fig 10a gwl shows three patterns on the gdp in the first time step among which cluster 3 with the lowest gwl average 1805 m was located in the eastern and northwestern parts of the plain in the second time step the total gwl average of the plain increased by approximately 1 m which could have been a consequence of the longest wet period on the gdp which occurred from march 1994 to april 1996 and could have compensated groundwater overextraction comparison of the first two time steps indicates that clusters of gwl did not experience a significant change in the structure of clusters during this period fig 10a and 10b in the third time step fig 10c the highest amounts of groundwater depletion approximately 24 m occurred in the western part of the gdp where cluster 3 was split into two clusters between the second and third time steps the area of cropland increased significantly fig 9 which could have changed the groundwater consumption pattern the number of clusters rose to five during this time in combination with climate change and population growth recognizing and forming new patterns from a cluster in the following years could have resulted from heterogeneous changes between members understanding these changes among the cluster members is one of the valuable outcomes of spatiotemporal cluster analysis this application makes the time and place of uncommon events approximately recognizable in the last time step the number of recognized patterns was increased to seven and the total distribution of members among clusters was changed as shown in fig 10d this relocation of members between clusters indicates the existence of inconsistent changes in the zones of these clusters and one of the main factors was extensive groundwater withdrawal on the other hand crop patterns changed in which more water intensive crops were cultivated which could have significantly increased groundwater withdrawals the most noticeable groundwater depletion almost 24 m during this time step is in cluster 7 located in the western part of the gdp it is worth mentioning that from 1988 to 2017 the centroid well of cluster 7 w18 experienced an almost 33 m decline on average eventually the spatiotemporal comparison of gwl reveals that the zone of clusters with high amounts of groundwater depletion has expanded from the west and east to the centre of the gdp since the wells that lie in the same cluster may have a similar pattern the behaviour of wells in a cluster may be determined from an assessment of the central well utilized as the representative for groundwater conditions in the cluster nourani et al 2016 to visualize the trend of cluster changes over time and to investigate the relationship between the sc and the quantitative status of gwl clusters the temporal changes of these factors are plotted for centroid wells selected as the best representatives in their respective clusters using the euclidean distance criterion thus wells 18 30 33 and 48 were chosen to have prominent representations of groundwater in the entire gdp fig 11 shows the temporal changes in the gwl and sc of the centroid wells to show the impacts of agricultural prosperity on gwl in each pattern the values of the variables were normalized before plotting it can be seen from all plots in fig 11 that the inverse relationship between the sc and gwl was maintained during the study period which indicates that gwl depletion trends led to improved structures in these clusters increase in the sc these improvements resulted from the formation of clusters with higher within group object similarity and between group object dissimilarity based on the sharp decrease in gwl in most members their similarities increased and consequently led to an increase in the sc it could be concluded that with the increase in anthropogenic activities e g excessive withdrawal of groundwater for irrigation purposes which is a major consumer on the gdp the natural diversity of gwl distribution on the gdp has been gradually decreasing which can cause irreversible consequences such as permanent subsidence and related ground failures if the decline continues for a long period of time well 18 was selected as a cluster representative for the western part of the gdp as shown in fig 11a the highest decrease in gwl 19 m occurred between the third and fourth time steps over the period between the second and third time steps despite the high increase in cropland areas there was no large water level drop because during this period the longest wet period of the region occurred and partially offset groundwater overpumping for agricultural activities in contrast after the second time step this region underwent the most critical cluster with a decreasing trend in gwl well 30 represents the cluster that was first located in the southwestern and centre parts of the gdp fig 11b shows that the gwl of well 30 slightly increased between the first and second time steps the occurrence of the longest wet period from march 1994 to april 1996 could have been a reason for the gwl increase during this time period increasing the gwl reduced the sc values which indicates that the natural diversity of the gwl distribution has increased across the plain the comparison of the first and last time steps shows that the gwl of well 30 has decreased by approximately 33 m well 33 with a 1 8 m depletion in gwl between the first and last time steps is the representative member of a small cluster located in the southern part of the gdp in terms of gwl this member had the smallest fluctuations compared with other centroid wells fig 11c clearly shows that the inverse relationship between the gwl and sc remained even during small fluctuations in gwl well 48 is the centroid member of the first eastern cluster with a 26 m depletion in which the gwl had a decreasing trend during all time steps as shown in fig 11d it is clear from fig 9 that the eastern part of the gdp between the first and last time steps underwent a noticeable increase in cropland area that caused further intensification in the competition for groundwater resources overall the plots in fig 11 indicate that some factors such as significant irrigated cropland expansion lack of surface water resources and gwl decline might lead to a loss of natural diversity of gwl distribution on the gdp after the second time step 1999 4 5 trend analysis of groundwater quality piper diagrams have been widely utilized to recognize the dominant hydrochemical facies by plotting major cation and anion concentrations piper 1994 in the piper diagram major ions are plotted in two base triangles as major cations ca 2 mg 2 and na k and major anions cl so 4 2 and co 3 2 hco 3 in milliequivalent percentages and the diamond part shows the dominant water chemistry type based on the statistics of physicochemical variables in this study table 2 the order of dominant cations and anions are ranked as ca2 mg2 na k and hco3 so4 2 no3 cl respectively fig 12 shows piper diagrams plotted for all cluster members in the first and last time steps in which the dominant facies of clusters are ca mg hco3 and the dominance of weak acidic anions over strong acidic anions and alkaline earths over alkali anions are shown the members that belong to the mixed type zone can be recognized as neither cation nor anion dominant comparing the piper plots related to the first and last time steps fig 12 shows the increase in hco3 in some clusters that could have been a consequence of soil co2 leakage to the groundwater organic matter decay and root respiration increase the soil co2 leakage rate and the combination of co2 with groundwater recharge forms hco3 leading to mineral dissolution additionally it is clear from fig 12 that the na of some members increased over time steps which could represent anthropogenic pollution footprints such as a consequence of cropland expansion on the gdp cluster ensemble of physicochemical variables could recognize three patterns for both the first and fourth time steps and could extract two patterns for the second and third time steps to evaluate the water quality of clusters used specifically for drinking purposes the pig was calculated for each cluster by calculating the average pig for the centroid wells in the clusters see table 8 the ranges of drinking water pollution have been categorized into five groups pig values below 1 0 indicate insignificant pollution ip 1 0 1 5 indicate low pollution lp 1 5 2 0 indicate moderate pollution mp 2 0 2 5 indicate high pollution hp and pig 2 5 indicate very high pollution vhp subba rao 2012 the results show that until 2008 third time step all clusters had an insignificant pollution level hence their qualities were suitable for drinking consumption despite increasing pig values table 8 in the last time step the pig values significantly increased in wells 12 and 28 eastern part of the plain fig 13 and their categories changed to low and high pollution the assessment of the pig for the last time step indicates that the proposed method in this study could find exclusively distinguishable clusters and could visualize the spatiotemporal changes in the pig to classify irrigation water the ussl suggested a practical diagram that describes the combined effects of sodium hazards and salinity hazards on the ussl diagram s and c are the abbreviations for sar and ec in micromhos per centimeter balasubramanian et al 2015 in this step the ussl diagram categorizes the clusters for irrigation purposes using sar and ec values the ussl plots of groundwater samples illustrate all members in the limits of c2s1 medium salinity and low sodium water and c3s1 high salinity and low sodium water suggesting that the groundwater samples were satisfactory for irrigational use in all time steps fig 14 comparing the ussl diagrams fig 14 revealed that members of cluster 2 of the second time step experienced a noticeable increase in associated variables ec and sar in the next time steps consequently some of the members entered the c3s1 status due to their movements in the ussl diagrams eventually cluster 3 with only one member is bound to fall into the c4s1 very high salinity with low sodium zone in the fourth time step overall the ussl diagrams of all time steps illustrated that most parts of the gdp had a satisfactory quality for irrigation while the continuous increases in physicochemical variables in the eastern part of the plain decreased the suitability of groundwater for irrigational purposes to gain a broader perspective regarding temporal changes in physicochemical variables the pig sar ec gwl and sc values of centroid wells are plotted in fig 15 as representatives of groundwater quality in various regions of the plain due to the different units of variables they were normalized before plotting regarding fig 15b well 24 was selected as the representative of the western cluster for groundwater quality and this monitoring well experienced unusual changes over time as shown in fig 15b all variables reached their maximum in the second time step despite this increase it was still in the category of insignificant pollution and excellent water according to the pig and ussl diagrams after the second time step despite the sharp decrease in gwl the trend of quality variables gradually decreased consequently water quality conditions improved in the western part of the gdp based on the pig and ussl diagrams the trend of the sc in this quality monitoring well indicates that the increase in the quality variables disturbed the homogeneous structure of the members in the second time step however with the beginning of the decreasing trend of the variables the sc subsequently began to increase after the third time step for well 28 the maximum increase in quality variables occurred between the third and fourth time steps which caused a low pollution high salinity and low sodium status for drinking purposes and irrigational use fig 15c also indicates that the decrease in gwl had an influential role in increasing the concentration of quality variables in this area investigating the increasing trend of the sc for well 28 during the time steps illustrates that the increase in quality variables in the second and third steps formed more homogeneous clusters that reveal spreading pollution in groundwater in the eastern part of the gdp the highest concentration of qualitative variables could be observed in the eastern part of the gdp and well 12 was the centroid member of the most critical clusters in all time steps which has undergone sharp increases in physicochemical variables see fig 15a due to this escalation during the fourth time step this well could not be placed with any of the other clusters and thus formed a single member cluster during the last time step experiencing an 83 increase in sar and a 130 increase in ec this well was bound to fall into the c4s1 zone indicating very high salinity which represents an alarming condition for this type of water that is used for irrigation purposes the pig of well 12 did not experience considerable fluctuations in the first three time steps but with an increase of 150 it was categorized as highly polluted for drinking purposes in the fourth period finally the eastern part of the plain with a noticeable increase in quality variables was recognized as the area undergoing the most changes in groundwater quality variables while the highest groundwater depletion rate occurred in the western part of the gdp 4 6 scenarios for the groundwater quality in the eastern part of gdp different scenarios are considered to explore the significant reasons for the detected critical clusters in eastern gdp based on the outcomes of statistical approaches in this study in the first scenario to investigate the effects of the aquifer s essence geological explorations in the structure of the aquifer were performed the sediment cementing materials different minerals and lithostratigraphy units have particular properties to erosion and weathering according to the kind of petrology of each formation water may dissolve different cations and anions which finally changes the quality of water evaporated deposits such as gypsum anhydrite marl and salts are sensitive to erosion and weathering so toxic ions such as cl so4 2 and na can separate from them easily and decrease the quality of water the results of hydrogeological investigations section 2 indicated that the eastern part of gdp consists of fine grained alluvial deposits with high percents of silt clay and gravel at the first layers fig 3d and its bedrock is an alternation of marl rocks which may have an influential rule in decreasing the groundwater quality which is consistent with previous studies e g rahmati et al 2015 also other studies indicated that the ground slope is an influential factor affecting the groundwater quality because in slow slopes surface water pollution has enough time to penetrate into the underground e g nadiri et al 2017 chen et al 2019 fig 3a shows the digital elevation model of gdp that indicates the eastern part of gdp has slow slopes compared with other parts of the plain which may affect groundwater quality by penetrating the agricultural pollution into the ground another scenario is the effects of the groundwater flow path alluvial deposits of a plain can be an important source of groundwater the geology of gdp figs 2 and 3 has a great potential for precipitation and irrigation return flow infiltration also the existence of limestone and dolomite in some parts of the plain show karst systems that are characterized as regions with high pollution vulnerability the dominant groundwater flow direction of gdp is from the west and southwestern parts of the plain to the east and southeastern regions fig 5 the direction of groundwater flow can explain the spatial distribution of quality clusters figs 5 and 13 illustrate that the polluted clusters of the aquifer have spread in the direction of the groundwater flow path of the eastern part of gdp also a lower hydraulic gradient in the eastern part of the plain can be a reason for high concentrations of groundwater quality variables according to the chebotarev sequence chebotarev 1955 as water moves in the direction of the flow path the chemical composition experiences normal changes changes in water quality composition also occur with increasing depth of travel as bicarbonate anions which dominate in many shallow groundwaters give way to sulfate and then chloride anions and calcium is exchanged for sodium in this study the groundwater flow path may result in more ec values in the eastern parts regarding the chebotarev sequence anthropogenic activities can be another cause that forced groundwater quality of gdp with significant problems the results of section 4 3 showed that gdp experienced a sharp increase in the area of irrigated croplands that require large amounts of water fertilizers and pesticides to achieve high production there can be a significant relationship between cropland expansion and groundwater quality of gdp which was also presented by other studies e g rahmati et al 2015 the effect of changes in the groundwater depletion on values of ec might be considered as another scenario therefore the correlation coefficient between the changes of ec and groundwater depletion was estimated the results showed a low negative correlation 0 21 indicating that changes in groundwater depletion and ec values did not contain considerable linkage see fig 16 in another scenario the moving average method was utilized to study annual precipitation data in the meteorological station p5 in fig 1a located in the eastern gdp see fig 17 the results denoted that this part of the plain experienced dry periods from 1999 to 2009 and from 2012 to 2015 which can affect the groundwater quality finally the eastern part of the plain with a noticeable increase in physicochemical variables such as ec was recognized as the area undergoing the most changes in groundwater quality variables while the highest groundwater depletion rate occurred in the western part of the gdp taken together aquifer materials low rate of recharge slow slope groundwater flow path the increasing trends of groundwater depletion occurring multiple dry periods cropland area expansion overuse of chemical fertilizers and pesticides in the eastern part of gdp are the influential factors that affect the groundwater quality 5 conclusions in the present study long term spatiotemporal assessment of groundwater quantity and quality on the gdp was conducted using a combination of results from three different types of clustering methods furthermore to fulfill the aim of extracting the most homogeneous clusters a cluster ensemble method was applied ensemble clustering enhanced the final validity index in quantitative and qualitative groundwater clustering up to 12 and 20 respectively the significant increase in irrigated cropland area and the changes of crop patterns relating to the cultivation of water intensive crops such as potatoes and forage in the eastern part of the gdp caused large declines in gwl almost 26 m and an increase in groundwater quality variables in clusters that represents a shift from insignificant pollution to low and high pollution in the last time step furthermore the patterns of gwl revealed that the most noticeable groundwater depletion almost 33 m occurred in cluster 7 which is located in the western part of the gdp which has had a considerable increase in cropland area between the first and last time steps the final results revealed that simultaneous analysis of the cluster ensemble with the ussl diagram piper plot and pig is a flexible and scientifically justified approach to recognize and display the changing patterns of groundwater quantity and quality the results of this study provide insight into the spatiotemporal changes in groundwater conditions on the gdp that can be utilized for long term policies and effective implementation of mitigation measures for future studies combining the cluster ensemble method with artificial intelligence approaches to forecast groundwater quantity and quality variables is proposed due to the lack of monthly physicochemical data for the study area groundwater quality clustering was performed using 6 monthly data and it would be more efficient to apply the proposed methodology to other study areas with monthly physicochemical datasets if available furthermore the spatiotemporal cluster ensemble method of hydroclimatological variables is also suggested to recognize the impacts of climate change credit authorship contribution statement vahid nourani conceptualization supervision methodology writing review editing parnian ghaneei project administration methodology sameh a kantoush validation formal analysis writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was funded by apn asia pacific network for global change research under project reference number crrp2020 09my kantoush funder id https doi org 10 13039 100005536 
3801,the long term spatiotemporal assessment of groundwater resources through robust clustering techniques can be used to promote remediation measures for groundwater depletion and contamination to fully understand the variability of groundwater quantity and quality due to anthropogenic activities and climate changes a new ensemble clustering framework based on the combining multiple clusters via similarity graph comusa method was developed this new approach was applied and evaluated in the context of groundwater well systems on the ghorveh dehgolan plain gdp which is located in western iran for groundwater level gwl and 13 physicochemical parameters during four periods the average of data from 1988 1990 1997 1999 2006 2008 and 2015 2017 the classification was confirmed by using the cluster validity index of the silhouette coefficient sc which indicated that the cluster ensemble method could improve the performance of individual clustering methods for groundwater quantity and quality by up to 12 and 20 respectively piper plots us salinity laboratory staff ussl diagrams and the pollution index of groundwater pig were assessed for all clusters of physicochemical variables to analyse groundwater suitability for drinking and irrigation purposes the results of the cluster ensemble showed that a critical pattern of groundwater depletion occurred in the western half of the gdp while the eastern part was recognized as the most polluted zone on the plain it could be concluded that the decline in gwl was not the only reason for the increase in groundwater quality variables but other factors such as noticeable cropland expansion and the overuse of chemical fertilizers and pesticides were also influential factors related to these patterns taken together the results of this study contribute to better recognizing the spatiotemporal changes in groundwater quantity and quality under the intense pressure of anthropogenic activities keywords groundwater pollution index of groundwater pig cluster ensemble ghorveh dehgolan plain gdp 1 introduction sustainable groundwater management is one of the significant issues in environmental engineering while freshwater scarcity affects human life there is also ample evidence suggesting that the quality of groundwater the largest freshwater resource is threatened due to the combination of industrial development inadequate sanitation systems chemical fertilizers and pesticides and groundwater depletion groundwater depletion and contamination of aquifers affect human health costs of water supplies and future civilization hence recognizing changes in groundwater quantity and quality is an essential part of informed water resource protection groundwater quality depends on changes in various variables and spatiotemporal assessment of each variable is a complicated and time consuming procedure to simplify assessments of groundwater quality decreasing the large dimension of water quality variables and representing data in a simpler way various water quality indices have been proposed which provide a simple value to identify the quality of water for instance the relative effect of each chemical variable on the general chemical quality of groundwater may be assessed using the pollution index of groundwater pig this index quantifies the concentration status of water quality measures related to their standards for drinking water quality e g see subba rao and chaudhary 2019 egbueri 2020 considering the importance of groundwater protection finding efficient methods to recognize complex relationships between various variables is an essential step in extracting the most homogeneous patterns additionally spatiotemporal assessments of these homogeneous patterns can effectively find and trace the time and place of changes in groundwater variables in this regard one of the robust multivariate analyses is clustering which is widely used to classify multidimensional inputs into homogeneous groups clustering can extract features from an unlabelled input to form clusters having maximum within group object similarity and between group object dissimilarity nourani and kalantari 2010 in general all members of each cluster may be regarded to have almost the same pattern that can simplify evaluation and accelerate decision making processes for instance i a designed water resource management strategy for a member e g watershed or piezometer may also be applied to the other cluster members which have similar conditions ii variables of a hydrological model for a cluster member may further be verified for other members of that cluster iii the available data of a cluster may be used to fill in missing data of other members within the same cluster the powerful applications of clustering methods have encouraged researchers to take advantage of various clustering algorithms in groundwater assessment for specific purposes table 1 as a practical linear type of clustering the k means algorithm has been applied to several hydrology fields due to the simple linear structure that can classify unlabelled inputs into separate k clusters e g fabbrocino et al 2019 sharif et al 2015 hierarchical cluster analysis hca is another successful clustering approach developed as a powerful partitioning tool that seeks to build a hierarchy of clusters different hca types single linkage complete linkage average linkage and ward method have yielded valuable results in groundwater assessment research e g see bhakar and singh 2019 some clustering algorithms utilize competitive learning concepts to classify data automatically and one of the best known examples is the self organizing map som in the standard version of som the number of neurons should be set based on the expected number of clusters previous studies have revealed that som is a powerful tool to visualize different groups of groundwater quality and quantity variables see wu et al 2021 baghanam et al 2020 nourani et al 2016 although som has been widely applied for clustering purposes the inefficiency in topology recognition is a major limiting factor of the som method another limitation of utilizing the som clustering method on large scale structures of inputs is the time consuming process of som to diminish the impacts of these limiting factors other alternative methods have been suggested on the basis of som growing neural gas gng is an som based algorithm that learns complex relationships without prior knowledge gng uses competitive hebbian learning chl to form topology without being restricted in k dimensional structures this method has gained considerable attention due to its flexibility in complex pattern recognition and has been successfully utilized as a multipurpose tool in various fields of engineering such as robotics viejo et al 2014 medicine aljobouri et al 2018 the clothing industry jimeno morenila et al 2016 hydrology abdi et al 2017 and computer science e g shi et al 2014 garc√≠a rodr√≠guez et al 2012 santos and nascimento 2016 but there is a gap in the use of gng for the clustering and assessment of groundwater quality and quantity variables on the other hand since every individual clustering method can extract particular features from a dataset and there is no agreement among researchers about the superiority of a specific method table1 finding an appropriate clustering method is a challenging task additionally the homogeneous formation of clusters is a sensitive process in which the cluster ensemble can effectively perform and benefit from the advantages of different clustering methods simultaneously e g see mohammadi et al 2008 azimi et al 2009 mimaroglu and erdil 2011 mimaroglu and erdil 2013 combining multiple clustering via similarity graph comusa is a flexible cluster ensemble method that creates a similarity graph by utilizing the evidence accumulated from the different clustering methods comusa can find arbitrarily shaped clusters and is not affected by cluster size noise or outliers leading to more homogeneous clusters mimaroglu and erdil 2011 there are still no studies that have applied the comusa algorithm in the general fields of hydrology and water resources the present study attempted to identify spatiotemporal groundwater quantity and quality changes using ensemble clustering based on the similarity graph method for the ghorveh dehgolan plain gdp located in western iran where overpumping and overuse of fertilizers and pesticides for irrigational purposes have placed significant pressures on groundwater resources of the gdp this method was applied to combine the results of three practical clustering algorithms commonly used k means method agglomerative hierarchical method of ward and gng as an unsupervised ann based method to extract the most homogeneous structures of clusters from groundwater variables of the gdp after recognizing existing groundwater quality and quantity patterns the piper plot us salinity laboratory staff ussl diagrams and pig evaluated the quality of patterns to investigate groundwater suitability for drinking and irrigation purposes 2 in situ experimental investigation on the study area and data analysis the gdp is located in western iran within the longitude from 47 38 52 to 48 06 03 east and latitude from 35 02 22 to 35 30 54 north the climate of the examined area is semiarid while during winter the average minimum temperature is 5 5 c and the region experiences a daily maximum temperature of 36 c in the summer moreover the average annual precipitation in this area is 345 mm this paper used data of 49 groundwater level monitoring wells in the plain for monitoring monthly gwl and 41 groundwater quality monitoring wells measured twice a year for monitoring geochemical variables provided by the kurdestan regional water authority krwa 2017 the location map and positions of wells of the gdp are shown in fig 1 a the main recharge sources of groundwater of gdp are precipitation and subsurface flow from surrounding highlands and rivers fig 1b while the semiarid climate with low precipitation and surface water potential limit the recharge process of the aquifer in addition irrigation water infiltrates back to the groundwater system the northwestern parts of the plain have experienced extreme subsidence due to the high amounts of groundwater depletion fig 1c besides anthropogenic activities have impacted the plain which drained a large part of surface water resources such as the dehgolan river fig 1d groundwater samples of the gdp were tested in a laboratory to examine the physicochemical variables to study the water quality fig 1e the plain also has hygienic problems because there is no sanitary landfill in the region fig 1f resulting in leachate penetration into groundwater there are several observation wells in the plain to explore and collect water samples for studying the groundwater quantity and quality fig 1g in this study four time steps with ten year intervals were selected to investigate long term trends of data sets due to the possibility of extreme values in a 1 year dataset the average of three year datasets for each time step was selected to avoid possible bias and anomalies a statistical summary of the groundwater parameters is presented in table 2 the unconfined alluvial aquifer of gdp covers an area of approximately 1270 km2 in kurdistan province based on pumping tests carried out in the plain the transmissivity of the gdp aquifer varies between 50 and 1492 m2 d the range of hydraulic conductivity of the aquifer is from 34 to 90 m day the average value of the gdp aquifer storage coefficient is about 1 7 gwls vary from 1740 m to 1961 m above the mean sea level the gdp is located in the sanandaj sirjan structural zone of iran the sanandaj sirjan is identified as a region of polyphase deformation the latest reflecting the collision of arabia and eurasia and the subsequent southward propagation of the fold thrust belt therefore the geology of the study area is characterized by geologic structures and fracture systems geological examinations have shown that this area primarily contains limestone dolomite rocks and quaternary units the most common of which include alluvial plain deposits alluvial terraces alluvial fan deposits calcareous sandstone and travertine notably small areas with dolomite and limestone were discovered in the central and western parts of the plain which are susceptible to pollution caused by transportation on land surfaces which flow into the aquifer karst system to a large extent rahmati et al 2015 fig 2 also contains geological cross sections indicating possible structures in the gdp fine grained and coarse grained units are repeated alternately over the plain and do not follow a specific order regarding the condition of borehole logs of exploratory wells in gdp fig 3 shows some samples of borehole logs in the western part l1 l2 and l3 central part l4 l5 and l6 and eastern part l7 l8 and l9 of the gdp illustrating the direct relationship between the increase in depth and the coarse grained units hydrogeological properties of the aquifer layers and their thickness were estimated through 340 geoelectrical soundings and 15 geoelectrical profiles provided by krwa krwa 2017 see fig 4 representing three of them fig 4a illustrates the western section i i including four layers the first layer shows the surface layer with a thickness of 15 40 m containing alluvial deposits consisting of silt clay sand and gravel the samples of boreholes show the soil textures of the first layers of the i i section fig 3b the second layer thickness varies from 25 to 50 m forming from the alternation of medium grained alluvial at the top and coarse grained alluvial deposits at the deeper depth the main texture of the third layer is fine grained alluvial deposits with an average depth of 50 m the third layer with a lower potential of discharge contains groundwater the fourth layer is the bedrock of this profile referring to the terissic jurassic period and contains dark grey crystalline limestone with interbedded metavolcanic rocks slate phyllite conglomerate and crystalline limestone geophysical investigations divided the central profile ii ii into three layers fig 4b the first layer with a thickness range of 5 30 m is an alternation of surface alluvial deposits with high percents of gravel the second layer thickness reaches 200 m in which the alluvial deposits with high percents of gravel were recognized the last layer as bedrock contains granite amphibole granite diorite marble and crystalline dolomite in some areas of the ii ii cross section the bedrock is not detected due to the existence of a fault creating a significant disturbance in the lower alluvium of the aquifer the first layers of the eastern cross section iii iii fig 4c consist of alternations of fine grained alluvial deposits with high percents of silt clay and gravel see borehole logs of fig 3d the bedrock of the eastern part of the gdp s aquifer has low resistivity representing layers such as argillaceous marl and sandy marl it is worth mentioning that the low groundwater quality of the eastern part of gdp could affect and disturb the results of geophysical investigations in order to define groundwater flow directions and rates through the aquifer the interpolation map of gwl was created regarding the permeability of the aquifer materials the kriging algorithm was utilized to create an interpolation map and generate contour maps fig 5 each contour or equipotential represents a line of equal hydraulic head it is clear from fig 5 that the general groundwater flow direction is from the west and southwestern regions of the plain to the east and southeastern regions also the southern parts of the aquifer have greater hydraulic gradients and the location of equipotential lines represent a lower groundwater hydraulic gradient in the eastern part of gdp 3 methodology utilizing the proposed methodology of this study see fig 6 groundwater quantity and quality variables of the gdp were first patterned using three individual clustering methods k means ward and gng then the cluster ensemble technique was used as a postprocessing method to form the most homogeneous clusters additionally before assessing the conditions of clusters cropland expansion was visualized by using the normalized difference vegetation index ndvi data of all time steps to show its impacts on groundwater on the gdp finally spatiotemporal analyses of the patterns obtained were conducted by comparing groundwater level gwl pig piper and ussl diagrams 3 1 k means clustering method k means is one of the clustering methods that has shown decent performance in hydrological research k means classifies inputs into clusters in which the distance between the members and the centroid of clusters is at a minimum degree macqueen 1967 finally this algorithm aims at minimizing an objective function given by 1 j i 1 n j 1 k r nk x i v j 2 where n is the number of data points k is the number of clusters x i v j is the euclidean distance between x i and v j r nk 0 1 is indicator variable where k describing the data point x i is assigned to which of the k clusters x is the set of data points and v is the set of centres 3 2 ward s hierarchical clustering method hierarchical cluster analysis has been developed as a flexible data grouping application in scientific fields this method first forms clusters with a single member then these clusters are merged to create clusters containing two members and this process continues until it forms a final cluster consisting of all members new clusters are created based on the minimum variance of each step for more details about the hierarchical clustering method see subba rao and chaudhary 2019 egbueri 2020 3 3 growing neural gas gng network gng is one of the som based algorithms that as an unsupervised learning method further utilizes a growing mechanism for gradual adaptation to create a network topology without being restricted in a k dimensional structure gng utilizes the chl growth approach fritzke 1995 linking neurons form the neighbourhood network which structures in each iteration by first and second winner neurons at random positions and associated reference vectors then gng generates a random input related to a density function and finding the nearest neurons winner neurons continues to increase the age of all edges the insertion of connections between the two closest neurons to the randomly generated input patterns establishes an induced delaunay triangulation in the input space the elimination of connections diminishes the edges that no longer comprise the triangulation this is performed by eliminating the connections between neurons that are no longer close or that have nearer neurons finally the accumulated error allows the identification of those zones in the input space where it is necessary to increase the number of neurons to improve the mapping jimeno morenilla et al 2013 the gng learning algorithm steps are as follows fig 7 i start with neuron a and neuron b at random positions in which w a and w b are their associated reference vectors ii generate a random input time series related to a density function p Œæ iii find the nearest neuron s1 winner neuron and the second nearest neuron s2 iv increase the age of all edges emanating from s1 to its neighbours v increase the local error of s1 by using the euclidean distance between two vectors as Œ¥ e r r o r s 1 w s 1 Œæ 2 2 vi relocate s1 and its topological neighbours towards Œæ by Œµw and Œµn learning rates respectively of the total distance n shows all direct neighbours of s1 3 Œ¥ w s 1 Œµ w Œæ w s 1 4 Œ¥ w s n Œµ n Œæ w s n vii if there exists an edge between s1 and s2 then set zero as their age viii remove the edges larger than a max if this results in isolated neurons without emanating edges remove them as well ix for every certain number of inputs generated insert a new neuron x decrease all error variables by multiplying them with a constant Œ≤ xi delete outliers based on the network edge length average xii if the stopping criterion is not yet achieved proceed to step 2 xiii reorder network neurons using neighbourhood structure unlike classical clustering algorithms gng has a flexible and adaptable algorithm that makes it practical for learning the topology of high dimensional datasets the gng algorithm was written and implemented in matlab r2018b 3 4 combining multiple clusterings via similarity graph comusa cluster ensemble methods aim to combine multiple clustering algorithm results to produce a better clustering outcome than those from individual clustering methods in terms of consistency and quality combining multiple clustering methods requires reusing pre existing knowledge employing distributed data mining methods and producing a final clustering with better overall quality various solutions for combining multiple clustering methods have been presented such as genetic hybrid bipartite graph formulation hypergraph partitioning and meta clustering algorithms alqurashi and wang 2019 there is no single algorithm that is universally used and there are no generally agreed upon criteria for selecting the most suitable ones in this case it is better to apply the one with the most simplicity and efficiency with this aim the present study attempted to combine the three clustering methods in groundwater assessment using the similarity graph method via the following steps mimaroglu and erdil 2011 where d is a dataset œÄ d c 1 c 2 c œÄ d is an individual clustering of d c i is a cluster of œÄ d œÄ d œÄ 1 d œÄ 2 d œÄ m d is a set of the best results of different clustering methods the following function forms a co association similarity matrix sm 5 c o a s s o c i j votes i j where votes i j is the number of times that members i and j were in the same clusters this information of members produces the sm the similarity graph is an undirected and weighted graph that displays the sm in a similarity graph sg d e and each edge d i d j has a mark associated with the smij in the co association matrix df d i is the degrees of freedom and sw d i is the sum of weights of edges incident to di the attachment index eq 6 is for initiating new clusters a member with the highest attachment index is selected as an initial member pivot 6 a t t a c h m e n t d i s w d i d f d i initially each cluster is a singleton and the pivot object expands the cluster by considering all immediate neighbours a neighbour is included in a pivot s cluster if it is most similar to the pivot once a neighbour is included it is marked and then acts like a pivot by considering its immediate neighbours for further expansion each cluster is expanded by its neighbours as explained previously extension of a cluster comes to an end if pivots of a cluster cannot add any other objects into the cluster comusa starts a new cluster by choosing a new pivot if there are unmarked objects in a dataset comusa halts when all objects are marked for more details see mimaroglu and erdil 2011 note that the comusa algorithm was written and implemented in matlab r2018b 3 5 cluster validity index the silhouette coefficient sc is measured to assess and compare the performance of clustering methods to calculate the sc for clustering structures first the s i for all members is calculated as a silhouette index rousseeuw 1987 7 s i b i a i m a x a i b i a i is the average euclidean distance between member i and all members of cluster a and b i is the least average dissimilarity of member i to the members within a cluster distinct from cluster a based on this formula it infers that 1 s i 1 therefore if s i is adjacent to 1 it may be concluded that the sith feature vector has been allocated to a proper cluster conversely when s i is adjacent to 1 it may be inferred that the s i th feature vector has been classified incorrectly when s i is almost zero it indicates that the s i th feature vector is located similarly far away from two clusters while n is the number of members and k is the number of clusters the overall quality of a clustering method and the optimal number of clusters can be validated using the average silhouette width of the entire dataset for each number of clusters as 8 sc max k 1 n 1 n s i when average silhouette values were calculated for desired numbers of clusters k 2 3 n the maximum average silhouette is sc representing the optimal number of clusters a higher sc illustrates better discrimination among the clusters 3 6 pollution index of groundwater pig subba rao 2012 proposed the pig to quantify pollution activity originating from anthropogenic and geogenic sources in which the relative effect of single chemical variables on the general chemical quality of groundwater can be identified by using only a simple value subba rao 2012 suitability assessment of drinking water quality by using the pig is taken in five steps i estimation of the relative weight rw on a scale of 1 5 of the analyzed variables based on their significance in the water quality assessment and relative impact on human health table 3 ii calculation of the weight parameter wp to assess its relative association with the groundwater quality table 3 is as follows 9 w p r w r w iii the status of concentration sc is measured by dividing each of the water quality variable contents c by its respective drinking water quality standard limits ds as 10 sc c d s table 3 presents the status of the relative influence of individual physicochemical variables on overall groundwater quality by using rw wp and ds iv the overall groundwater quality ow is calculated by multiplying the wp by the sc 11 ow w p s c v the summation of all ow values per sample gives the pig as 12 pig o w the pig values reveal the contributions of all analyzed hydrochemical variables of each groundwater sample it is noteworthy that in this study in addition to the variables in table 3 the sodium absorption ratio sar and electrical conductivity ec parameters also contributed to the evaluation of groundwater suitability for irrigational purposes 4 results and discussion assessment of hydrological phenomena has complicated procedures where analysis requires powerful applications of enhanced methods and to that end in this study first to explore and assess the spatiotemporal changes of groundwater quantity and quality on the gdp the study was conducted over four time steps the first second third and fourth time steps are the averages of the datasets for the 1988 to 1990 1997 to 1999 2006 to 2008 and 2015 to 2017 limits respectively the averages of three years as representative of the time steps were selected to avoid possible bias and anomalies that may occur in a one year dataset the groundwater quantity and quality datasets of these four time steps were first clustered separately by individual clustering methods and the optimal results were selected based on the sc with the aim of enhancing the structure of clusters the results of individual clustering methods were then combined through a cluster ensemble algorithm as a postprocessing step finally the spatiotemporal changes of clusters were evaluated via the assessment of the sc gwl pig and groundwater quality diagrams 4 1 results of individual clustering methods individual clustering algorithms including linear k means hierarchical ward and self organizing neural network gng clustering methods were applied to the four time step datasets and the optimal number of clusters nc was chosen by comparing the sc from 2 to 10 clusters after the training process the results of individual clustering methods are shown in table 4 for gwl and physicochemical variables using normalized data as shown in table 4 in all time steps the sc indicates better performance for the gng clustering method compared with the other individual clustering methods the main reason for the superiority of gng against ward and k means is the way that this flexible method can drive its nodes through the topology of inputs in contrast the rigid structure of the other methods k means and ward limits their applicability in dealing with complex datasets additionally the adaptation ability and optimized growth of gng lead to a desired resolution of the clustered networks based on the sc results higher than 0 5 show well structured clusters and those lower than 0 5 show that samples are structured poorly a comparison of sc values in table 4 indicates the satisfactory performance of all clustering methods in gwl clustering in contrast the sc values of qualitative clustering via k means and ward methods illustrate inadequate structures in some time steps these differences between the sc of quantitative and qualitative clustering might be related to the number of input variables for gwl clustering only spatial parameters utm and groundwater level were imposed on clustering algorithms while in qualitative clustering in addition to gwl variables 13 physicochemical variables of groundwater samples were utilized the high dimensional dataset of qualitative variables and the existence of nonlinear and complex relationships among variables caused unsatisfactory results in the k means and ward methods under the same conditions the gng method obtained acceptable results in all time steps because of its ability to recognize complex relationships after applying individual clustering techniques a cluster ensemble method was applied to improve the clustering performance as a postprocessing step 4 2 results of the cluster ensemble regarding the fact that there is no agreement regarding the superiority of specific clustering methods and the optimal number of clusters in this study the best results of individual clustering methods were combined via the similarity graph comusa method which can efficiently find the natural number of clusters mimaroglu and erdil 2011 with the similarity matrix formation for all time steps the attachment index for all members was calculated the highest amount was randomly selected based on the preliminary nodes of the clustering operation then the correlation coefficient of other members related to the preliminary nodes was measured to form new clusters this practice was continued until all members were settled in their clusters comusa can find shapes of clusters and can assign members to a cluster if they are most similar to a pivot high attachment values in that cluster the growth of clusters is based on immediate neighbours of pivots if a member enters a cluster it receives a label as a new pivot to continue the expansion process of the cluster until all members are labelled then comusa halts information on the quantitative and qualitative patterns of the cluster ensemble is presented in tables 5 and 6 additionally as an example of generating a cluster ensemble using comusa the final gwl clusters of the fourth time step are shown in fig 8 the red dotes in fig 8 highlight the preliminary pivot objects of all clusters which indicate high attachment values high sum of weights and low degrees of freedom that indicate they are strongly connected somewhere after estimating the pivot object the expansion of each cluster is continued by considering all their immediate neighbours shown with black circles fig 8 furthermore the euclidean distance criterion was then calculated to determine the prominent centroid well of each cluster as the best representation of the groundwater quantity and quality clusters the determined central wells of clusters are highlighted in the third column in tables 5 and 6 after recognizing the new patterns of gwl and physicochemical variables the sc was computed for all time steps a comparison of results in table 4 with results in tables 5 and 6 indicates that the application of the cluster ensemble could successfully enhance the performance of individual clustering methods for groundwater quality and quantity up to 12 and 20 respectively it is worth mentioning that an increase in the sc even in small amounts can be very effective in evaluating groundwater conditions in areas where the number of observation wells is low belonging to an appropriate cluster is crucial in making the decision about a member according to tables 5 and 6 the centroid wells were almost the same until the number of clusters changed it is noteworthy that the centres of the preliminary clusters have continued to maintain their position in later time steps which indicates the suitability of the centroid wells to consider their quantitative and qualitative conditions as the best representative of clusters to provide a broader perspective on the impacts of anthropogenic activities on groundwater patterns the areas of cropland expansion were assessed for all time steps additionally the ndvi dataset of each time step was sketched to see the spatiotemporal changes in cropland and their impacts on the groundwater conditions on the gdp 4 3 assessment of cropland areas it is noteworthy that people living on the gdp depend on commodities produced by irrigated agriculture and the gdp is one of iran s potato production bases where farmers apply large amounts of water fertilizers and pesticides to agricultural soil to achieve a high production therefore before assessing the quantitative and qualitative conditions of groundwater having a broader perspective on cropland areas on the gdp is a valuable step in understanding the relationship between groundwater problems and cropland expansion on the gdp considering that the primary groundwater consumption on the gdp is for irrigational purposes there can be a significant relationship between cropland expansion and groundwater problems which also has been reported for other regions in previous studies e g foroumandi et al 2022 to this end remote sensing rs can help visualize cropland area changes ground covers have a defined spectral signature spectral reflectance patterns compressed into spectral vegetation indices because of their ability to distinguish different vegetated surfaces the ndvi is one of the most well known vegetation indices and involves the ratio of the difference and the sum between near infrared and red bands this index can distinguish vegetation from other soil coverings nourani et al 2021 foroumandi et al 2021 to take into account the contribution of agricultural prosperity and its impacts on the quantitative and qualitative conditions of groundwater the landsat derived ndvi maps related to july 1989 1998 2007 and 2016 the spatial resolution size of 30 m for each pixel of landsat 5 and landsat 8 images were sketched on the google earth engine gee cloud computing platform the ndvi maps for all four time steps in which the darker green colours in pixels express the higher values of the ndvi and the centroid wells of gwl and groundwater quality clusters are shown in fig 9 according to reports from the agricultural organization of kurdistan province table 7 an incremental increase in irrigated cropland areas has occurred over time which has almost more than doubled in the last time step additionally in the western half of the gdp the irrigated cropland area increased over 90 percent between the second and third time steps these changes are clearly discernible among the maps in fig 9 the difference in the area of irrigated cropland from 1988 to 2017 was 24 675 ha table 7 the most significant increase in irrigated cropland area occurred between the second and third time steps approximately 11194 ha in comparison the rainfed cropland area decreased by 10 958 ha during this time which shows an increasing tendency among local farmers to cultivate irrigated crops this crop pattern has shifted to cultivating water intensive crops such as potato and forage crops which is another influential factor affecting groundwater conditions on the gdp the comprehensive assessment of cropland area changes and their impacts on groundwater status is performed simultaneously with trend analysis of clusters in the following subsections 4 4 trend analysis of gwl the cluster ensemble of the gwl could recognize three patterns for both the first and second time steps and could extract five and seven patterns for the third and fourth time steps respectively the increase in the number of clusters indicates that over time initial strong relationships among members have diminished and has resulted in splitting large clusters into smaller clusters to maintain the quality of the clusters fig 10 shows the spatial distributions of the gwl clusters in the first and last time steps as shown in fig 10a gwl shows three patterns on the gdp in the first time step among which cluster 3 with the lowest gwl average 1805 m was located in the eastern and northwestern parts of the plain in the second time step the total gwl average of the plain increased by approximately 1 m which could have been a consequence of the longest wet period on the gdp which occurred from march 1994 to april 1996 and could have compensated groundwater overextraction comparison of the first two time steps indicates that clusters of gwl did not experience a significant change in the structure of clusters during this period fig 10a and 10b in the third time step fig 10c the highest amounts of groundwater depletion approximately 24 m occurred in the western part of the gdp where cluster 3 was split into two clusters between the second and third time steps the area of cropland increased significantly fig 9 which could have changed the groundwater consumption pattern the number of clusters rose to five during this time in combination with climate change and population growth recognizing and forming new patterns from a cluster in the following years could have resulted from heterogeneous changes between members understanding these changes among the cluster members is one of the valuable outcomes of spatiotemporal cluster analysis this application makes the time and place of uncommon events approximately recognizable in the last time step the number of recognized patterns was increased to seven and the total distribution of members among clusters was changed as shown in fig 10d this relocation of members between clusters indicates the existence of inconsistent changes in the zones of these clusters and one of the main factors was extensive groundwater withdrawal on the other hand crop patterns changed in which more water intensive crops were cultivated which could have significantly increased groundwater withdrawals the most noticeable groundwater depletion almost 24 m during this time step is in cluster 7 located in the western part of the gdp it is worth mentioning that from 1988 to 2017 the centroid well of cluster 7 w18 experienced an almost 33 m decline on average eventually the spatiotemporal comparison of gwl reveals that the zone of clusters with high amounts of groundwater depletion has expanded from the west and east to the centre of the gdp since the wells that lie in the same cluster may have a similar pattern the behaviour of wells in a cluster may be determined from an assessment of the central well utilized as the representative for groundwater conditions in the cluster nourani et al 2016 to visualize the trend of cluster changes over time and to investigate the relationship between the sc and the quantitative status of gwl clusters the temporal changes of these factors are plotted for centroid wells selected as the best representatives in their respective clusters using the euclidean distance criterion thus wells 18 30 33 and 48 were chosen to have prominent representations of groundwater in the entire gdp fig 11 shows the temporal changes in the gwl and sc of the centroid wells to show the impacts of agricultural prosperity on gwl in each pattern the values of the variables were normalized before plotting it can be seen from all plots in fig 11 that the inverse relationship between the sc and gwl was maintained during the study period which indicates that gwl depletion trends led to improved structures in these clusters increase in the sc these improvements resulted from the formation of clusters with higher within group object similarity and between group object dissimilarity based on the sharp decrease in gwl in most members their similarities increased and consequently led to an increase in the sc it could be concluded that with the increase in anthropogenic activities e g excessive withdrawal of groundwater for irrigation purposes which is a major consumer on the gdp the natural diversity of gwl distribution on the gdp has been gradually decreasing which can cause irreversible consequences such as permanent subsidence and related ground failures if the decline continues for a long period of time well 18 was selected as a cluster representative for the western part of the gdp as shown in fig 11a the highest decrease in gwl 19 m occurred between the third and fourth time steps over the period between the second and third time steps despite the high increase in cropland areas there was no large water level drop because during this period the longest wet period of the region occurred and partially offset groundwater overpumping for agricultural activities in contrast after the second time step this region underwent the most critical cluster with a decreasing trend in gwl well 30 represents the cluster that was first located in the southwestern and centre parts of the gdp fig 11b shows that the gwl of well 30 slightly increased between the first and second time steps the occurrence of the longest wet period from march 1994 to april 1996 could have been a reason for the gwl increase during this time period increasing the gwl reduced the sc values which indicates that the natural diversity of the gwl distribution has increased across the plain the comparison of the first and last time steps shows that the gwl of well 30 has decreased by approximately 33 m well 33 with a 1 8 m depletion in gwl between the first and last time steps is the representative member of a small cluster located in the southern part of the gdp in terms of gwl this member had the smallest fluctuations compared with other centroid wells fig 11c clearly shows that the inverse relationship between the gwl and sc remained even during small fluctuations in gwl well 48 is the centroid member of the first eastern cluster with a 26 m depletion in which the gwl had a decreasing trend during all time steps as shown in fig 11d it is clear from fig 9 that the eastern part of the gdp between the first and last time steps underwent a noticeable increase in cropland area that caused further intensification in the competition for groundwater resources overall the plots in fig 11 indicate that some factors such as significant irrigated cropland expansion lack of surface water resources and gwl decline might lead to a loss of natural diversity of gwl distribution on the gdp after the second time step 1999 4 5 trend analysis of groundwater quality piper diagrams have been widely utilized to recognize the dominant hydrochemical facies by plotting major cation and anion concentrations piper 1994 in the piper diagram major ions are plotted in two base triangles as major cations ca 2 mg 2 and na k and major anions cl so 4 2 and co 3 2 hco 3 in milliequivalent percentages and the diamond part shows the dominant water chemistry type based on the statistics of physicochemical variables in this study table 2 the order of dominant cations and anions are ranked as ca2 mg2 na k and hco3 so4 2 no3 cl respectively fig 12 shows piper diagrams plotted for all cluster members in the first and last time steps in which the dominant facies of clusters are ca mg hco3 and the dominance of weak acidic anions over strong acidic anions and alkaline earths over alkali anions are shown the members that belong to the mixed type zone can be recognized as neither cation nor anion dominant comparing the piper plots related to the first and last time steps fig 12 shows the increase in hco3 in some clusters that could have been a consequence of soil co2 leakage to the groundwater organic matter decay and root respiration increase the soil co2 leakage rate and the combination of co2 with groundwater recharge forms hco3 leading to mineral dissolution additionally it is clear from fig 12 that the na of some members increased over time steps which could represent anthropogenic pollution footprints such as a consequence of cropland expansion on the gdp cluster ensemble of physicochemical variables could recognize three patterns for both the first and fourth time steps and could extract two patterns for the second and third time steps to evaluate the water quality of clusters used specifically for drinking purposes the pig was calculated for each cluster by calculating the average pig for the centroid wells in the clusters see table 8 the ranges of drinking water pollution have been categorized into five groups pig values below 1 0 indicate insignificant pollution ip 1 0 1 5 indicate low pollution lp 1 5 2 0 indicate moderate pollution mp 2 0 2 5 indicate high pollution hp and pig 2 5 indicate very high pollution vhp subba rao 2012 the results show that until 2008 third time step all clusters had an insignificant pollution level hence their qualities were suitable for drinking consumption despite increasing pig values table 8 in the last time step the pig values significantly increased in wells 12 and 28 eastern part of the plain fig 13 and their categories changed to low and high pollution the assessment of the pig for the last time step indicates that the proposed method in this study could find exclusively distinguishable clusters and could visualize the spatiotemporal changes in the pig to classify irrigation water the ussl suggested a practical diagram that describes the combined effects of sodium hazards and salinity hazards on the ussl diagram s and c are the abbreviations for sar and ec in micromhos per centimeter balasubramanian et al 2015 in this step the ussl diagram categorizes the clusters for irrigation purposes using sar and ec values the ussl plots of groundwater samples illustrate all members in the limits of c2s1 medium salinity and low sodium water and c3s1 high salinity and low sodium water suggesting that the groundwater samples were satisfactory for irrigational use in all time steps fig 14 comparing the ussl diagrams fig 14 revealed that members of cluster 2 of the second time step experienced a noticeable increase in associated variables ec and sar in the next time steps consequently some of the members entered the c3s1 status due to their movements in the ussl diagrams eventually cluster 3 with only one member is bound to fall into the c4s1 very high salinity with low sodium zone in the fourth time step overall the ussl diagrams of all time steps illustrated that most parts of the gdp had a satisfactory quality for irrigation while the continuous increases in physicochemical variables in the eastern part of the plain decreased the suitability of groundwater for irrigational purposes to gain a broader perspective regarding temporal changes in physicochemical variables the pig sar ec gwl and sc values of centroid wells are plotted in fig 15 as representatives of groundwater quality in various regions of the plain due to the different units of variables they were normalized before plotting regarding fig 15b well 24 was selected as the representative of the western cluster for groundwater quality and this monitoring well experienced unusual changes over time as shown in fig 15b all variables reached their maximum in the second time step despite this increase it was still in the category of insignificant pollution and excellent water according to the pig and ussl diagrams after the second time step despite the sharp decrease in gwl the trend of quality variables gradually decreased consequently water quality conditions improved in the western part of the gdp based on the pig and ussl diagrams the trend of the sc in this quality monitoring well indicates that the increase in the quality variables disturbed the homogeneous structure of the members in the second time step however with the beginning of the decreasing trend of the variables the sc subsequently began to increase after the third time step for well 28 the maximum increase in quality variables occurred between the third and fourth time steps which caused a low pollution high salinity and low sodium status for drinking purposes and irrigational use fig 15c also indicates that the decrease in gwl had an influential role in increasing the concentration of quality variables in this area investigating the increasing trend of the sc for well 28 during the time steps illustrates that the increase in quality variables in the second and third steps formed more homogeneous clusters that reveal spreading pollution in groundwater in the eastern part of the gdp the highest concentration of qualitative variables could be observed in the eastern part of the gdp and well 12 was the centroid member of the most critical clusters in all time steps which has undergone sharp increases in physicochemical variables see fig 15a due to this escalation during the fourth time step this well could not be placed with any of the other clusters and thus formed a single member cluster during the last time step experiencing an 83 increase in sar and a 130 increase in ec this well was bound to fall into the c4s1 zone indicating very high salinity which represents an alarming condition for this type of water that is used for irrigation purposes the pig of well 12 did not experience considerable fluctuations in the first three time steps but with an increase of 150 it was categorized as highly polluted for drinking purposes in the fourth period finally the eastern part of the plain with a noticeable increase in quality variables was recognized as the area undergoing the most changes in groundwater quality variables while the highest groundwater depletion rate occurred in the western part of the gdp 4 6 scenarios for the groundwater quality in the eastern part of gdp different scenarios are considered to explore the significant reasons for the detected critical clusters in eastern gdp based on the outcomes of statistical approaches in this study in the first scenario to investigate the effects of the aquifer s essence geological explorations in the structure of the aquifer were performed the sediment cementing materials different minerals and lithostratigraphy units have particular properties to erosion and weathering according to the kind of petrology of each formation water may dissolve different cations and anions which finally changes the quality of water evaporated deposits such as gypsum anhydrite marl and salts are sensitive to erosion and weathering so toxic ions such as cl so4 2 and na can separate from them easily and decrease the quality of water the results of hydrogeological investigations section 2 indicated that the eastern part of gdp consists of fine grained alluvial deposits with high percents of silt clay and gravel at the first layers fig 3d and its bedrock is an alternation of marl rocks which may have an influential rule in decreasing the groundwater quality which is consistent with previous studies e g rahmati et al 2015 also other studies indicated that the ground slope is an influential factor affecting the groundwater quality because in slow slopes surface water pollution has enough time to penetrate into the underground e g nadiri et al 2017 chen et al 2019 fig 3a shows the digital elevation model of gdp that indicates the eastern part of gdp has slow slopes compared with other parts of the plain which may affect groundwater quality by penetrating the agricultural pollution into the ground another scenario is the effects of the groundwater flow path alluvial deposits of a plain can be an important source of groundwater the geology of gdp figs 2 and 3 has a great potential for precipitation and irrigation return flow infiltration also the existence of limestone and dolomite in some parts of the plain show karst systems that are characterized as regions with high pollution vulnerability the dominant groundwater flow direction of gdp is from the west and southwestern parts of the plain to the east and southeastern regions fig 5 the direction of groundwater flow can explain the spatial distribution of quality clusters figs 5 and 13 illustrate that the polluted clusters of the aquifer have spread in the direction of the groundwater flow path of the eastern part of gdp also a lower hydraulic gradient in the eastern part of the plain can be a reason for high concentrations of groundwater quality variables according to the chebotarev sequence chebotarev 1955 as water moves in the direction of the flow path the chemical composition experiences normal changes changes in water quality composition also occur with increasing depth of travel as bicarbonate anions which dominate in many shallow groundwaters give way to sulfate and then chloride anions and calcium is exchanged for sodium in this study the groundwater flow path may result in more ec values in the eastern parts regarding the chebotarev sequence anthropogenic activities can be another cause that forced groundwater quality of gdp with significant problems the results of section 4 3 showed that gdp experienced a sharp increase in the area of irrigated croplands that require large amounts of water fertilizers and pesticides to achieve high production there can be a significant relationship between cropland expansion and groundwater quality of gdp which was also presented by other studies e g rahmati et al 2015 the effect of changes in the groundwater depletion on values of ec might be considered as another scenario therefore the correlation coefficient between the changes of ec and groundwater depletion was estimated the results showed a low negative correlation 0 21 indicating that changes in groundwater depletion and ec values did not contain considerable linkage see fig 16 in another scenario the moving average method was utilized to study annual precipitation data in the meteorological station p5 in fig 1a located in the eastern gdp see fig 17 the results denoted that this part of the plain experienced dry periods from 1999 to 2009 and from 2012 to 2015 which can affect the groundwater quality finally the eastern part of the plain with a noticeable increase in physicochemical variables such as ec was recognized as the area undergoing the most changes in groundwater quality variables while the highest groundwater depletion rate occurred in the western part of the gdp taken together aquifer materials low rate of recharge slow slope groundwater flow path the increasing trends of groundwater depletion occurring multiple dry periods cropland area expansion overuse of chemical fertilizers and pesticides in the eastern part of gdp are the influential factors that affect the groundwater quality 5 conclusions in the present study long term spatiotemporal assessment of groundwater quantity and quality on the gdp was conducted using a combination of results from three different types of clustering methods furthermore to fulfill the aim of extracting the most homogeneous clusters a cluster ensemble method was applied ensemble clustering enhanced the final validity index in quantitative and qualitative groundwater clustering up to 12 and 20 respectively the significant increase in irrigated cropland area and the changes of crop patterns relating to the cultivation of water intensive crops such as potatoes and forage in the eastern part of the gdp caused large declines in gwl almost 26 m and an increase in groundwater quality variables in clusters that represents a shift from insignificant pollution to low and high pollution in the last time step furthermore the patterns of gwl revealed that the most noticeable groundwater depletion almost 33 m occurred in cluster 7 which is located in the western part of the gdp which has had a considerable increase in cropland area between the first and last time steps the final results revealed that simultaneous analysis of the cluster ensemble with the ussl diagram piper plot and pig is a flexible and scientifically justified approach to recognize and display the changing patterns of groundwater quantity and quality the results of this study provide insight into the spatiotemporal changes in groundwater conditions on the gdp that can be utilized for long term policies and effective implementation of mitigation measures for future studies combining the cluster ensemble method with artificial intelligence approaches to forecast groundwater quantity and quality variables is proposed due to the lack of monthly physicochemical data for the study area groundwater quality clustering was performed using 6 monthly data and it would be more efficient to apply the proposed methodology to other study areas with monthly physicochemical datasets if available furthermore the spatiotemporal cluster ensemble method of hydroclimatological variables is also suggested to recognize the impacts of climate change credit authorship contribution statement vahid nourani conceptualization supervision methodology writing review editing parnian ghaneei project administration methodology sameh a kantoush validation formal analysis writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was funded by apn asia pacific network for global change research under project reference number crrp2020 09my kantoush funder id https doi org 10 13039 100005536 
3802,the typical framework of the climate change impact assessment on water resources relies on plausible scenarios obtained from global climate models gcms and hydrological models hms although regional climate models rcms can better simulate local climate at a high resolution grid the direct use of model outputs from rcms is not recommended as inputs for hms due to systematic error existing studies have focused on the bias correction bc of climate model outputs without considering uncertainties biases in hydrological modeling in this regard this study proposed an integrated framework that combines the bc of rcm precipitation and the simulated flow from the rainfall runoff model considering the underlying uncertainty in the parameters of the distribution function the regional climate model hadrm3 and the conceptual rainfall runoff model hymod are employed observed daily precipitation evapotranspiration and discharge time series over the thorverton catchment are compiled from the uk meteorological office to examine the effectiveness of the combined strategy four different bc approaches have been explored to reduce systematic biases in the flow simulated through the hms using the rcm precipitation as input here bcs of rcm and hm outputs have been applied under the condition that the bias corrected ensembles should be within the range of the observed climate variability the four bc models are considered aathe rcm precipitation and flow are corrected by preserving their natural variabilities case 4 from a hydrological perspective the case 4 model showed the best performance among the four cases in terms of correcting the bias and the spread of the flow ensemble keywords natural climate variability bias correction spread of flow ensemble 1 introduction climate change impacts on water resources are of increasing concern since changes in water resources can be associated with many other aspects of water related sectors including agriculture ecosystem health water quality and water quantity management arnell and liv 2001 bates et al 2008 in recent years an increasing number of studies particularly in the area of hydro meteorology have explored climate model ensembles chegwidden et al 2019 gosling et al 2017 guo et al 2018 hattermann et al 2017 jackson et al 2011 sexton et al 2019 although regional climate models rcms provide more detailed climate information particularly for hydrological applications spatial scale mismatches can lead to increased uncertainty in the output of the hydrological model muerth et al 2013b therefore bias adjustment of both global and regional climate model derived hydrometeorological variables is often required to correct systematic biases kim et al 2015 piani and haerter 2012 su et al 2020 several studies have shown that typical systematic biases in rcms include over or under estimation of hydrometeorological components e g precipitation and temperature inaccurate seasonal representation of large scale climate patterns and overestimation of the wet day frequency ines and hansen 2006 various bias correction bc approaches have been explored by teutschbein and seibert 2012 1 parametric local adjustment and power transformation fang et al 2015 leander et al 2008 smitha et al 2018 and 2 parametric quantile mapping cannon 2018 cannon et al 2015 guo et al 2019 kim et al 2016 maraun 2013 piani et al 2010 switanek et al 2017 bc remains a debatable issue ehret et al 2012b muerth et al 2013a since a applying bias correction may narrow the uncertainty range ensemble spreads of climate simulations b bias is assumed to be constant or stationary i e a set of parameters associated with bias correction under current climate conditions will still be effective under future climate however the bc approach to climate information including precipitation and temperature has been widely applied to assess the impact of climate change on water resources chen et al 2018 ghimire et al 2019 meyer et al 2019 rainfall runoff modeling systems are indispensable for representing the hydrologic processes that offer guidance for water system design and water resource planning and management madsen 2000 wagener et al 2003 apart from the biases in climate model outputs hydrological models hms are an imperfect representation of the real world hydrological processes as well which are affected by input uncertainty e g measurement error sampling error model uncertainty parametric uncertainty inadequate descriptions of initial and boundary conditions etc several studies have investigated the advantages and disadvantages of using bias corrected rcm outputs to estimate runoff for instance muerth et al 2013a evaluated the effect of bc on runoff projections under climate change and showed that there was a limited influence on the relative changes in other words both bias corrected and bias uncorrected climate model data demonstrated a similar representation of the changes in runoff through the hydrological modeling process meanwhile willkofer et al 2018 emphasized that different bc schemes can lead to differences in future runoff changes especially for high flows although bc of the climate model outputs remains controversial with regard to hydrological impact studies hagemann et al 2011 most recent studies have used bias corrected climate model outputs as inputs for hydrological impact assessments akhtar et al 2009 chen et al 2018 fiseha et al 2014 olsson et al 2015 su et al 2020 teutschbein and seibert 2012 various studies have concentrated separately on either the bc process of climate model outputs or the statistical post processing of outputs obtained from hydrological models recent studies however have evaluated the impact of bias correction on both the input variables and streamflow considering the uncertainty in hydrologic modeling chen et al 2021 li et al 2019 tiwari et al 2021 chen et al 2021 compared the performance of the pre processing and post processing of hms they found that bias correction of climate model outputs was more efficient than post process hydrological model analysis li et al 2019 concluded that the bias correction procedure could be applied to either precipitation or streamflow simulation for improving hydrological predictions tiwari et al 2021 investigated the effects of bias correction of meteorological and streamflow forecast on hydrological predictions in india they suggested that the combination of the bias correction of climate model outputs and simulated streamflow could significantly enhance the predictability of streamflow several previous studies have not paid attention to the sampling uncertainty in the case of ensemble forecasts the bias correction is often applied to adjust the statistical properties of each of the individual ensemble members to those of one observation this process does not properly take advantage of ensemble spreads representing model uncertainty in climate change impact studies in this study the natural variability of the observations is first estimated and then the spread i e variance of the ensemble is adjusted to the range of natural variability observed over the past three decades by incorporating sampling uncertainty this study proposes an integrated approach that can combine the bc of rcm precipitation and the flow simulated from the rainfall runoff model considering the distributional parametric uncertainty underlying the observations in other words in this process the ensemble spread is preserved to a certain degree after bias correction which corresponds to the observation sampling uncertainty specifically four different bc models were introduced to reduce systematic biases in the simulated streamflow the suggested bc schemes were assessed with a conceptual rainfall runoff model the underlying assumption in this study is that the flow observations for bias correction are also available this coupling strategy is expected to better represent the rainfall runoff relationship a brief summary of the bc models taken into account in this study is described below case 1 uses raw rcm precipitation data for simulation of the hydrological model and it is used as a reference case the biases of the climate model and hydrological model outputs are not corrected case 2 uses bias corrected simulated flow data obtained from the hydrological model and raw rcm precipitation data as inputs case 3 uses bias corrected rcm precipitation data as the input for the hydrological model the bias of the simulated flow from the hydrological model is not corrected case 4 uses corrected model outputs for both rcm and hydrological models we compared the performance of the four bc models with the observed discharge from the calibration period 1961 1990 and the validation period 1991 2014 to address the following questions 1 can the bc models applied in this study minimize systematic errors in rcm and hydrological model outputs for the baseline and future periods 2 how does the correction of the bias i e systematic errors in the rcm precipitation affect the output of the hydrological model is it better to use the bias corrected rcm precipitation as an input for the rainfall runoff model instead of the uncorrected rcm rainfall 3 should bc apply only to the precipitation in climate models or to the simulated flow in hydrological models is the combined bc model more effective in reproducing the observed flow research backgrounds and objectives are introduced in this section the hydrometeorological data and study area are provided in section 2 in section 3 the conventional bc method is presented next we demonstrate the importance of preserving the observed natural variability in the bc process the hydrological model and simulation design used to explore the impact of bc is presented in section 4 we also discuss the results of this study finally we offer a summary and conclusions 2 watershed and climate data observed daily hydrologic variables including catchment average precipitation data evapotranspiration and flow time series over the thorverton basin from 1961 to 1990 are compiled from the camels gb catchment attributes and meteorology for large sample studies coxon et al 2020 its catchment averaged daily rainfall data have been derived from ceh gear data tanguy et al 2016 a 1 km gridded rainfall estimates interpolated from daily observed rainfall data from the met office the rainfall grids were achieved using the natural neighbor interpolation method including a normalization step based on average annual rainfall 1961 1990 its potential evapotranspiration pet data were retrieved from the 1 km gridded chess pe dataset robinson et al 2017 which are based on the penman monteith equation monteith 1965 recommended by the fao guidelines on the reference pet allen et al 1998 here the simulated hydrological variables are obtained from the met office hadley centre regional model perturbed physics ensemble simulations for the 21st century for the uk domain hadrm3 ppe uk these regional climate change scenarios are dynamically downscaled from the hadcm3 gcm murphy et al 2009 the hadcm3 consists of an 11 member ensemble one unperturbed member and 10 perturbed members for the perturbed model selected parameters are perturbed from the unperturbed model by considering uncertainties in the model parameters for rcm collins et al 2011 the climate simulations at daily time steps for historical and future periods ranging from 1950 to 2100 are provided with a horizontal resolution of 0 22 degree approximately 25 km this study used the daily precipitation data constructed from all ensemble members to explore the integrated bc approach for the reference precipitation during 1961 1990 the thorverton basin is highlighted by the red grid box as represented in fig 1 right panel 3 methodology 3 1 quantile mapping approach for bias correction the quantile mapping qm approach has been widely applied to calibrate the gcm or rcm outputs e g temperature precipitation and evapotranspiration at different time scales e g from seasonal to daily scales a seasonally varying qm model is usually adopted for bc of the climate model outputs to effectively consider seasonal phases with different degrees of bias by considering strong seasonality and variability in precipitation more importantly an increase in wet day frequency with low precipitation intensity namely drizzle effect has been a well known issue in climate models posing a challenge for effective analysis in this regard systematic bias in the rainfall occurrence process obtained from the climate models is adjusted by applying a threshold based cut off approach in advance before applying bc in other words the wet day frequency is first forced to match with that of the observed precipitation data by eliminating the drizzle effect qm is then performed based on probability distribution functions constructed from observed and simulated daily precipitation the precipitation is assumed to be represented by a gamma distribution as follows 1 f r 1 Œ∏ k Œ≥ k r k 1 e r Œ∏ r 0 k Œ∏ 0 here k and Œ∏ represent the shape and scale parameters respectively and Œ≥ indicates the gamma function in this study the gamma distribution based qm approach is applied for the bc of the daily rcm precipitation gamma distribution is applied to daily data on a monthly basis and the associated parameters are estimated for each of the 11 rcm ensemble members using the maximum likelihood method a conceptual representation of the typical qm based bc scheme is illustrated in fig a1 to be more specific the cumulative distribution functions cdfs for both rcm simulations and observations are built for the same period fig a1 a and the cdf of rcm simulations is then mapped to the cdf of the observed precipitation similarly qm can also be demonstrated in terms of the parameters of probability density functions pdfs i e transfer functions as presented in fig a1 b here a set of distribution parameters of the rcm simulations are transferred to those of the observed data via qm the bias corrected rcm precipitation can be obtained from the transfer function or quantile function as given in eq 2 2 r c f 1 f r m Œ± m Œ≤ m Œ± obs Œ≤ obs here r c denotes the bias corrected daily precipitation from the modeled precipitation r m while f and f 1 are the cumulative density function and quantile function of the gamma distribution respectively with shape Œ± and scale Œ≤ parameters the subscripts m and obs in these parameters Œ± and Œ≤ represent the model and observed precipitation here bc is done for precipitation and simulated flow data it should be noted that bc for the simulated flow is done in the same way as it is done for the simulated precipitation 3 2 natural variability of precipitation and discharge in bc the main drawback of existing bc approaches is that the distribution parameters obtained from all the ensemble members are mapped to a point in the parameter space as illustrated in fig 2 more importantly this may banish model spread from a single model or multi model which represents the uncertainty during the bc process moreover assigning a set of parameters for the bc can be problematic if the sampling error is taken into account and the obtained parameters from the observed precipitation may only represent one case out of many alternatives this study adopted the bc approach for the rcm ensemble proposed by kim et al 2016 which considers both observational uncertainties or sampling errors and natural variability for details the reader is referred to kim et al 2016 first to assess the natural variability of the observed flow daily flow data were randomly selected 30 times on a yearly basis from 30 years of observed daily flow second sampling was repeatedly performed 1000 times to obtain 1000 sets of 30 year daily flow data third gamma distribution parameters were estimated for each series of the simulated flow i e 30 year daily flow simulation the bc for the flow series was done on an annual basis i e 360 days 30 years 10 800 data points similarly the natural variation in precipitation was evaluated it should be noted that seasonally varying transfer functions tfs for each month were built from 1961 to 1990 fig 2 represents a schematic view of the bc considered in this study which reflects the natural variability of observed hydrological variables the main idea of the bc adopted in this study is to maintain the relative distance over the ensemble members seen in rcm simulations after bc this was done so that variations in the bias corrected values are able to reproduce those of the population as if all individuals are equally likely drawn from the population that can be regarded as the observed natural variability it was found that the biases in the 11 member ensemble are effectively removed while maintaining the ensemble spread as seen in fig 2e for more details about the modeling procedure refer to kim et al 2016 3 3 hydrological model this study used the conceptual rainfall runoff model hymod moore 1985 which has five parameters to explore the impact of bc schemes on modeling flow a brief description of model parameters is summarized in table 1 and the schematic representation of the model is given in fig 3 the runoff generation process is described by a parsimonious precipitation runoff model represented through the probability distributed theory and it has been widely used in hydrologic researches boyle 2001 de vos et al 2010 gharari et al 2013 kollat et al 2012 remesan et al 2014 vrugt et al 2003 wagener et al 2001 the spatial variability of the water storage capacity c can be defined as follows 3 f c 1 1 c t c max b exp 0 c t c max here c max and b exp represent the maximum soil moisture sm storage capacity and the degree of spatial variability of the sm capacity in the basin based on the weighting factor Œ± the effective or excess rainfall is converted into a quick flow and a slow flow the discharge is then sequentially routed via parallelly linked three reservoirs representing quick flow simulation in the upper layer and a reservoir for slow flow simulation in the lower layer the hydrographs are finally synthesized by applying the recession parameters for the fast r q and slow r s flow components at the catchment scale the hymod was calibrated at a daily time step over the first available 30 year period 1961 1990 to obtain the optimized parameters and further validated over the remaining period 1991 2014 the calibration was done to minimize the difference between the observed and simulated flow through an objective function based on the nash sutcliffe efficiency nse nash and sutcliffe 1970 4 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 i 1 n day where q sim q obs q obs are the simulated flow the observed flow and the mean of the observed flow respectively in the calibration period we used a dynamically dimensioned search dds tolson and shoemaker 2007 a heuristic global optimization algorithm the values of nse were found to be 0 83 and 0 82 for the calibration and validation periods respectively which appear to be effective for rainfall runoff modeling according to the given criteria n s e 0 75 motovilov et al 1999 3 4 experimental design used to examine the effectiveness of bias correction the four experimental design cases are presented as follows the bc is applied to 11 members of rcm precipitation and the simulated flow from the hydrological model a rigorous inter comparison between the four cases is provided as illustrated in fig 4 case 1 the uncorrected 11 member ensemble of rcm precipitation is used as an input for the hm and the uncorrected flow from hm is obtained i e neither the bias of rcm precipitation nor the bias of the simulated flow are corrected case 2 the uncorrected 11 member ensemble of rcm precipitation is used for the hm as an input and the bias of the simulated flow from hm is then adjusted i e the bias of rcm precipitation is not corrected while the bias of the simulated flow is corrected case 3 the bias of the 11 member ensemble of rcm precipitation is corrected which is then used for the hm as an input i e the bias of rcm precipitation is corrected while the bias of the simulated flow is not corrected case 4 the bias of the 11 member ensemble of rcm precipitation is corrected which is then used for the hm as an input the bias of the simulated flow from hm is also adjusted i e both the biases of rcm precipitation and the simulated flow are corrected fig 5 provides a conceptual diagram of the four different proposed bc approaches for the rcm ensemble of rcm precipitation and simulated flow from a distribution parameter estimation point of view different transfer functions tfs are used to correct each ensemble member however the distribution parameters range for the tfs is restricted to the natural variability in the observed precipitation and flow since both the precipitation from the rcm and the simulated flow from a rainfall runoff model are often affected by systematic errors the spread of model outputs for case 1 are significantly biased by the natural variability of the hydrologic variables e g precipitation and flow as illustrated in fig 5 a for case 2 the bias uncorrected rcm precipitation ensemble is used as an input for hm and the uncertainty range of the simulated flow ensemble is corrected by mapping the tfs based on the natural variability of the observed flow therefore the spread of the simulated flow obtained from the rcm ensemble after bc blue dotted ellipse is expected to match well with the spread of the observation data red ellipse fig 5 b for case 3 the spread of the rcm precipitation ensemble is corrected blue dotted ellipse by mapping the tfs based on the observed natural variability in precipitation red ellipse then the bias corrected precipitation ensemble is used as an input for hm whereas the bias of the outputs from hm is not corrected in this case fig 5 c for case 4 the spread of the rcm precipitation ensemble is corrected blue dotted ellipse by mapping the tfs based on the climate variation in the observation red ellipse and the bias corrected precipitation ensemble is used as an input for hm furthermore the bias of the outputs from hm is corrected in this case fig 5 d 3 5 validation of proposed bias correction schemes to evaluate the tfs for the bc the hydrological data i e precipitation and flow are divided into calibration 1961 1990 and validation 1991 2014 periods representing the unseen data in a cross validation context both the precipitation and the flow ranging from 1961 to 1990 were used to construct the tfs for bc the tfs were then applied to the independent data from 1991 to 2008 note that the climate model outputs have no direct link to the data corresponding to the individual years of observation i e they are not synchronous for example rcm precipitations in the year 1961 have no direct relationship with the observed precipitations in the same year a set of aggregated statistics estimated from both observations and model outputs can be comparable in this regard therefore to explore the effectiveness of bc in both the calibration and validation periods monthly mean flows were compared for the four cases a schematic representation of applying the tf to the validation period is presented in fig 6 the tf is built under the assumption that it is still effective for future climate conditions i e the stationarity assumption with the tf albeit the climate is changed in the future which is commonly adopted in climate bias corrections so that the tf is constructed based on the calibration period data blue and red ellipses given the stationarity assumption the magnitude direction and spread of the tf are preserved while being applied to the validation period data blue dotted ellipse the bc results black dotted ellipse are compared with the natural variability of the observation during the validation period red dotted ellipse which is assumed to be the future unseen data 4 results 4 1 calibration period 4 1 1 bias correction of the rcm precipitation ensemble fig 7 shows the performance of bc for correcting the mean simulated precipitation although the seasonality is largely reproduced the uncorrected monthly average rainfalls of 11 members of hadrm3 for the calibration phase 1961 1990 significantly deviate from those of the observed left panel of fig 7 the ensemble means were generally well simulated in april and june on the other hand overestimation is seen in may and underestimation is largely observed from july to march after bc the bias corrected precipitation of each ensemble member is comparable with that of the observation data on a monthly basis a comparison of percentage errors of the monthly precipitation between before and after bias correction is presented in fig 8 overall the systematic bias in the mean was well corrected and the spread associated with the natural variability was also reasonably well preserved right panel of fig 7 and fig 8 in terms of the model spread the uncorrected model outputs were somewhat overestimated compared with the spread seen in the bias corrected rcm precipitation as shown in figs 7 and 8 4 1 2 comparison of the simulated flows we compared the monthly mean flows between the observed data and four different model cases the shaded area representing the model spread is obtained from the precipitation ensemble for the period from 1961 to 1990 the model spread is then compared with the boxplots showing the natural variability of the observed flow fig 9 overall the monthly flows simulated from the bias uncorrected 11 member rcm precipitation fig 9 a produces a large bias mostly underestimated compared with those of the bias corrected one fig 9 b c d in addition the spread of flows simulated from the bias uncorrected rcm precipitation fig 9 a is larger than those of simulated flow from bias corrected rcm fig 9 c and post processed flows fig 9 b d therefore it is apparent that the simulations without bias correction and post processing are not able to accurately represent both the climate and the hydrological processes fig 9 a case 1 the bias corrected flow ensemble fig 9 b case 2 is the output of the hymod model which is simulated using bias uncorrected rcm precipitation followed by correcting the bias of simulated flows the result showed a narrower range of uncertainty than case 1 in other words both the mean and variance of the flow ensemble have been improved because the systematic bias of the flow has been directly corrected although the overall model spread and bias of the flow ensemble have been improved after correcting the bias of hm outputs further improvements are needed to match the natural variability of the observed flow for example the spread of hm outputs is larger than those of the observations from december to march and the flow is underestimated from august to november in case 3 the flow simulations ensembles were obtained by using the bias corrected precipitation as an input as shown in fig 9 c the performance of case 3 is better than that of the approach used in case 1 in terms of reducing the bias the ensemble range is well reproduced after bc which is comparable with the observed natural variation although the bias of the flow needs to be further improved the spread of the simulated flow ensemble is more similar to that of the observation compared with case 2 this might be due to the use of bias corrected rcm precipitation as inputs to hm thus one can conclude that bc of the rcm precipitation plays a critical role in achieving objectives that reduce the bias and reproduce the natural variability of the flow to explore the role of bc in the simulated flow ensemble the biases of the rcm precipitation and flow were corrected in case 4 fig 9 d as expected the bias and the spread of the simulated flow ensemble are noticeably smaller than those of case 2 and case 3 the spread of bias corrected flow ensemble mostly fell inside the natural variability of the observed flow from this result the case 4 model which corrects the biases of both precipitation and flow shows the best performance among the four cases in terms of correcting the bias and the spread of the flow ensemble we further evaluated the model performance with different percentiles to explore the proposed effectiveness of the bc schemes at different flow regimes here 11 member ensembles for the four cases were used to obtain flow distribution information at various percentiles as shown in fig 10 since 1000 sets of random long term precipitation sequences i e 30 year 365 days 1000 were sampled to reproduce the natural variability over the past 30 year precipitation 1000 sets of flow duration curves fdcs were constructed in most percentiles the flow ensembles i e case 1 and case 3 are generally underestimated their median values differ from the observed flows with extended ranges of the simulated flow at most flow regimes overall the findings are in line with the results as illustrated in fig 9 in contrast the medians and the ranges of the bias corrected flows case 2 and case 4 were comparable to the observed flow at most flow regimes fig 11 presents the performance of different cases for the relationship of distribution parameters of the flow data the red dots represent the estimated parameters associated with the natural variability of the observed flow which are resampled from the observation data details of estimating the natural variability of the observed flow are presented in section 3 2 in fig 11 a the unfilled blue dots are the gamma distribution parameters of the simulated flow from the uncorrected 11 member rcm precipitation case 1 and the filled blue triangles are those of the bias corrected flow with the uncorrected 11 member precipitation sets obtained from the rcm case 2 in fig 11 b the unfilled blue dots are the relationship of two parameters of the bias uncorrected flow simulated from the corrected 11 member rcm precipitation case 3 and the filled blue triangles are the relationship between gamma distribution parameters of the bias corrected flow simulated from the corrected 11 member rcm precipitation case 4 the gamma distribution parameters of the fixed flow members case 2 and case 4 are all inside the range of the observed natural variability which indicates that the spread of the 11 members parameters after bc are reasonably well reproduced in contrast the bias uncorrected flow cases case 1 and case 3 generally deviate from the parameter space shown in the observed flow again these results confirm that using bc for the simulated flow is important in reducing the bias and reproducing the natural variability of the flow 4 2 validation period 4 2 1 bias correction of the rcm precipitation ensemble fig 12 represents the bias correction results during the validation period 1991 2014 here the observed monthly mean precipitation during the validation period is assumed to be the future precipitation as done in the climate change study the difference between the uncorrected precipitation of hadrm3 and the observation data was found for the validation period from 1991 to 2014 left panel of fig 12 more specifically the precipitation ensemble means were generally overestimated in march and may whereas an underestimation of the precipitation was observed for the rest of the month the results are generally consistent with the differences identified in the calibration period even considering that the tfs were built during the calibration period the results demonstrated that the simulated monthly precipitation was reasonably well corrected a comparison of percentage errors of the monthly precipitation between before and after bias correction during the validation period 1991 2014 is presented in fig 13 the overall reduction in the ensemble spread representing the natural variability was also confirmed except for march april and september right panel of figs 12 and 13 the overestimation of the model spread that exceeded the observed natural variability in precipitation is in line with the calibration results during 1961 1990 compared to the calibration results during 1961 1990 the proposed approach could be applied for bias correction of unseen data representing the future climate although there is a slight difference from the observed precipitation the effectiveness of the proposed bc model can be confirmed overall 4 2 2 comparison of the simulated flows to further explore the proposed bc schemes the monthly mean flows of the observed data and four different model cases during the validation period 1991 2014 were compared the shaded area representing the model spread is obtained from the precipitation ensemble for the period from 1991 to 2014 the model spread is then compared with the boxplots showing the natural variability of the observed flow as illustrated in fig 14 overall regardless of applying the bc for the rcm precipitation the flow ensemble simulated from the rcm precipitation case 1 and case 3 was shown to be systematically biased when the simulated flows were not corrected more specifically the monthly flows simulated from the bias uncorrected 11 member rcm precipitation fig 14 a produce a large bias mostly underestimated compared with those of the bias corrected flows fig 14 b d in case 2 the flow simulations ensembles were obtained by using the bias uncorrected precipitation as an input followed by correcting the bias of simulated flows the systematic bias is largely corrected however the higher mean value of the flow ensemble than the observed is seen during the first half of the year and vice versa during the rest of the year the spread of the simulated flows is not clearly reduced compared with case 1 which implies that the bc process for hm outputs has a limited effect on improving the uncertainty of the simulated flow during the validation period although case 3 during the calibration period fig 9 c showed an improvement in terms of reducing the bias of simulated flows when the bias corrected rcm precipitations are used as inputs to hm this is not the case for the validation period fig 14 c on the other hand when both the rcm precipitation and flow biases are corrected fig 14 d case 4 it can be seen that the biases of the simulated flow ensemble are noticeably reduced than those observed in case 3 in summary case 4 which corrected the bias of rcm precipitation and simulated flow showed the best performance among the four cases in terms of correcting the bias of the flow ensemble theoverall model spread of the flow ensemble after correcting the bias of hm outputs was largely similar to the natural variability of the observation data and mostly fell inside the observed natural variability of the flow as similarly found in the calibration period one can conclude that bc of the simulated flow played a crucial role in achieving objectives that reduce the bias of the flow it should be noted that the overall efficacy of the proposed bias correction approach largely relies on the calibration of the rainfall runoff model more specifically if the rainfall runoff model is not adequately calibrated the differences in performance across cases cannot be attributed solely to the bias correction approaches proposed in this study here we did not evaluate the sensitivity of the overall results according to the model performance in the calibration and validation processes however we confirmed that the calibration process appears to be effective for rainfall runoff modeling since the values of nse were found to be over 0 80 for both the calibration and validation periods model performances at different flow regimes are illustrated in fig 15 as done in the calibration period in section 4 1 2 as seen in the calibration period the bias uncorrected flows i e case 1 and case 3 generally underestimated the observed flow their underlying distributions slightly deviated from that of the observed data with an extended range of the natural variability at most flow regimes overall the findings are in line with the calibration results whereas the distributions of the bias corrected flows case 2 and case 4 are largely comparable to the observed flow at most flow regimes a comparison of model validation results during 1991 2014 when correcting the parameter space of the flow data over four different schemes is presented in fig 16 as expected the parameter space of the corrected flow ensemble case 2 and case 4 was comparable to that of the observed data and much closer than the uncorrected flows simulated from the rcm precipitation irrespective of correcting the bias of precipitation i e case 1 and case 3 however the estimated parameters from the bias corrected flow ensemble do not always fall in the range seen in the observed flow finally the results obtained during the validation period reemphasize the relative importance for the bc of the simulated flow 5 summary and conclusions existing studies have independently focused on either the bc process of climate model outputs e g precipitation and temperature or the post processing of hydrological model outputs e g simulated flow several recent studies have evaluated the impact of bias correction on both the input variables and streamflow considering the uncertainty in the hydrologic model simulations however these studies neglected the advantage of quantifying uncertainty through the use of ensemble spread in climate change impact studies in this context this study is an extended work of these existing studies combining the bias correction processes of rcm precipitation and the flow simulated from the rainfall runoff model in an integrated framework considering the underlying uncertainty in the parameters of the distribution function to examine the effectiveness of the combined strategy four different bc approaches have been explored to reduce systematic biases in the streamflow simulated from a conceptual hydrological model the basic assumption in this study was that both the observed precipitation and the flow data for bias correction were available moreover the proposed bc approaches have been applied under the presumption that the corrected rcm members and the simulated flow with the rcm precipitation should come from within the range of the variation observed in the precipitation and flow data the four bc models we considered are described as follows in case 1 the biases of both the climate model and hydrological model outputs are not corrected in case 2 the bias of the flow is only corrected with the use of the uncorrected rcm precipitation in case 3 the bias of rcm precipitation is solely corrected without bc of the simulated flow in case 4 both the rcm precipitation and flow are corrected by preserving their natural variabilities the performance of these four different cases of combined bc models was compared with the observed flow during both the calibration period 1961 1990 and the validation period 1991 2014 the main summary and key findings from this study are described as follows 1 in case 1 the uncorrected precipitation for the calibration phase differs from the observations the flow simulated from the uncorrected rcm precipitation was shown to be systematically biased and the model spread was largely overestimated compared to that in the observations in case 2 the bias corrected flow using the bias uncorrected precipitation ensemble demonstrated a narrower range of uncertainty than case 1 the bias corrected flow ensemble has been improved since the systematic bias of the flow has been directly corrected although the overall model spread of the flow ensemble after correcting the bias of the simulated flow was similar to the natural variability of the observed flow further improvement is needed to match the natural variability of the observed flow 2 in case 3 the corrected precipitation was almost identical to that of the observation data the systematic biases in the precipitation ensemble were well corrected and the spread associated with the natural variability was also reasonably well preserved although the bias of the simulated flow needs to be further improved the spread of the simulated flow ensemble is more similar to that of the observation compared with case 1 this might be due to the use of bias corrected rcm precipitation as inputs to hm in case 4 both the rcm precipitation and flow biases were corrected as expected the bias and the spread of the simulated flow ensemble were noticeably smaller than those in case 2 and case 3 the case 4 model which corrects the biases of both the precipitation and the flow showed the best performance among the four cases in terms of correcting the bias and the spread of the flow ensemble the improved results in terms of bias correction in case 4 have some interesting implications about the important role of bc for both the rcm precipitation and the simulated flow in reducing the bias and reproducing the natural variability of the flow 3 we further explored model performance at different flow regimes in most percentiles the flow ensembles obtained from case 1 and case 3 were generally underestimated their median values differ from the observed flows with an extended range of the simulated flow at most flow regimes in contrast the medians and the ranges of the bias corrected flows obtained from case 2 and case 4 were comparable to the observed flow at most flow regimes finally the model performance of different cases in terms of the parameter space of the flow ensemble was evaluated the gamma distribution parameters of the corrected flow members obtained from case 2 and case 4 were all inside the range of the observed natural variability it should be noted that the bc of the simulated flow demonstrated the relative importance of reducing the bias and reproducing the natural variability of the flow during the validation period the model performances were further evaluated the case 4 model was the best in correcting the bias of simulated flows which are in line with the calibration results however from an ensemble uncertainty perspective the spread of simulated models is not identical to those of the observations which implies that bc of the model outputs does not play a crucial role in reproducing the spread of the observed flow during the validation period the difference in the ensemble uncertainty seems to be due to nonstationarity in the flow leading to a difference in the transfer function for the bias correction 4 bc of the rcm precipitation is often criticized due to several aspects dosio et al 2012 ehret et al 2012a hagemann et al 2011 maraun 2012 maraun et al 2010 teutschbein and seibert 2012 such as 1 a physical justification is missing since the model errors induced by physical causes are not considered 2 the relationship and spatio temporal consistency between climate variables are modified after bc 3 it may not be plausible to correct climate change trends and 4 the stationarity assumption might not be met under changing climate conditions however from a hydrological perspective we would like to point out that the use of the bias corrected climate model precipitations as inputs to the hydrological model followed by the bc of the simulated flow from hm is recommended 6 data availability the camels gb dataset used in this study is available via the uk centre for ecology hydrology environmental information data centre credit authorship contribution statement kue bum kim conceptualization data curation methodology software validation formal analysis writing original draft hyun han kwon conceptualization methodology investigation supervision writing review editing funding acquisition dawei han supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was funded by the korea meteorological administration research and development program under grant kmi 2018 07010 this work was partially supported by the national research foundation of korea nrf grant funded by the korea government msit no 2019r1a2c2087944 
3802,the typical framework of the climate change impact assessment on water resources relies on plausible scenarios obtained from global climate models gcms and hydrological models hms although regional climate models rcms can better simulate local climate at a high resolution grid the direct use of model outputs from rcms is not recommended as inputs for hms due to systematic error existing studies have focused on the bias correction bc of climate model outputs without considering uncertainties biases in hydrological modeling in this regard this study proposed an integrated framework that combines the bc of rcm precipitation and the simulated flow from the rainfall runoff model considering the underlying uncertainty in the parameters of the distribution function the regional climate model hadrm3 and the conceptual rainfall runoff model hymod are employed observed daily precipitation evapotranspiration and discharge time series over the thorverton catchment are compiled from the uk meteorological office to examine the effectiveness of the combined strategy four different bc approaches have been explored to reduce systematic biases in the flow simulated through the hms using the rcm precipitation as input here bcs of rcm and hm outputs have been applied under the condition that the bias corrected ensembles should be within the range of the observed climate variability the four bc models are considered aathe rcm precipitation and flow are corrected by preserving their natural variabilities case 4 from a hydrological perspective the case 4 model showed the best performance among the four cases in terms of correcting the bias and the spread of the flow ensemble keywords natural climate variability bias correction spread of flow ensemble 1 introduction climate change impacts on water resources are of increasing concern since changes in water resources can be associated with many other aspects of water related sectors including agriculture ecosystem health water quality and water quantity management arnell and liv 2001 bates et al 2008 in recent years an increasing number of studies particularly in the area of hydro meteorology have explored climate model ensembles chegwidden et al 2019 gosling et al 2017 guo et al 2018 hattermann et al 2017 jackson et al 2011 sexton et al 2019 although regional climate models rcms provide more detailed climate information particularly for hydrological applications spatial scale mismatches can lead to increased uncertainty in the output of the hydrological model muerth et al 2013b therefore bias adjustment of both global and regional climate model derived hydrometeorological variables is often required to correct systematic biases kim et al 2015 piani and haerter 2012 su et al 2020 several studies have shown that typical systematic biases in rcms include over or under estimation of hydrometeorological components e g precipitation and temperature inaccurate seasonal representation of large scale climate patterns and overestimation of the wet day frequency ines and hansen 2006 various bias correction bc approaches have been explored by teutschbein and seibert 2012 1 parametric local adjustment and power transformation fang et al 2015 leander et al 2008 smitha et al 2018 and 2 parametric quantile mapping cannon 2018 cannon et al 2015 guo et al 2019 kim et al 2016 maraun 2013 piani et al 2010 switanek et al 2017 bc remains a debatable issue ehret et al 2012b muerth et al 2013a since a applying bias correction may narrow the uncertainty range ensemble spreads of climate simulations b bias is assumed to be constant or stationary i e a set of parameters associated with bias correction under current climate conditions will still be effective under future climate however the bc approach to climate information including precipitation and temperature has been widely applied to assess the impact of climate change on water resources chen et al 2018 ghimire et al 2019 meyer et al 2019 rainfall runoff modeling systems are indispensable for representing the hydrologic processes that offer guidance for water system design and water resource planning and management madsen 2000 wagener et al 2003 apart from the biases in climate model outputs hydrological models hms are an imperfect representation of the real world hydrological processes as well which are affected by input uncertainty e g measurement error sampling error model uncertainty parametric uncertainty inadequate descriptions of initial and boundary conditions etc several studies have investigated the advantages and disadvantages of using bias corrected rcm outputs to estimate runoff for instance muerth et al 2013a evaluated the effect of bc on runoff projections under climate change and showed that there was a limited influence on the relative changes in other words both bias corrected and bias uncorrected climate model data demonstrated a similar representation of the changes in runoff through the hydrological modeling process meanwhile willkofer et al 2018 emphasized that different bc schemes can lead to differences in future runoff changes especially for high flows although bc of the climate model outputs remains controversial with regard to hydrological impact studies hagemann et al 2011 most recent studies have used bias corrected climate model outputs as inputs for hydrological impact assessments akhtar et al 2009 chen et al 2018 fiseha et al 2014 olsson et al 2015 su et al 2020 teutschbein and seibert 2012 various studies have concentrated separately on either the bc process of climate model outputs or the statistical post processing of outputs obtained from hydrological models recent studies however have evaluated the impact of bias correction on both the input variables and streamflow considering the uncertainty in hydrologic modeling chen et al 2021 li et al 2019 tiwari et al 2021 chen et al 2021 compared the performance of the pre processing and post processing of hms they found that bias correction of climate model outputs was more efficient than post process hydrological model analysis li et al 2019 concluded that the bias correction procedure could be applied to either precipitation or streamflow simulation for improving hydrological predictions tiwari et al 2021 investigated the effects of bias correction of meteorological and streamflow forecast on hydrological predictions in india they suggested that the combination of the bias correction of climate model outputs and simulated streamflow could significantly enhance the predictability of streamflow several previous studies have not paid attention to the sampling uncertainty in the case of ensemble forecasts the bias correction is often applied to adjust the statistical properties of each of the individual ensemble members to those of one observation this process does not properly take advantage of ensemble spreads representing model uncertainty in climate change impact studies in this study the natural variability of the observations is first estimated and then the spread i e variance of the ensemble is adjusted to the range of natural variability observed over the past three decades by incorporating sampling uncertainty this study proposes an integrated approach that can combine the bc of rcm precipitation and the flow simulated from the rainfall runoff model considering the distributional parametric uncertainty underlying the observations in other words in this process the ensemble spread is preserved to a certain degree after bias correction which corresponds to the observation sampling uncertainty specifically four different bc models were introduced to reduce systematic biases in the simulated streamflow the suggested bc schemes were assessed with a conceptual rainfall runoff model the underlying assumption in this study is that the flow observations for bias correction are also available this coupling strategy is expected to better represent the rainfall runoff relationship a brief summary of the bc models taken into account in this study is described below case 1 uses raw rcm precipitation data for simulation of the hydrological model and it is used as a reference case the biases of the climate model and hydrological model outputs are not corrected case 2 uses bias corrected simulated flow data obtained from the hydrological model and raw rcm precipitation data as inputs case 3 uses bias corrected rcm precipitation data as the input for the hydrological model the bias of the simulated flow from the hydrological model is not corrected case 4 uses corrected model outputs for both rcm and hydrological models we compared the performance of the four bc models with the observed discharge from the calibration period 1961 1990 and the validation period 1991 2014 to address the following questions 1 can the bc models applied in this study minimize systematic errors in rcm and hydrological model outputs for the baseline and future periods 2 how does the correction of the bias i e systematic errors in the rcm precipitation affect the output of the hydrological model is it better to use the bias corrected rcm precipitation as an input for the rainfall runoff model instead of the uncorrected rcm rainfall 3 should bc apply only to the precipitation in climate models or to the simulated flow in hydrological models is the combined bc model more effective in reproducing the observed flow research backgrounds and objectives are introduced in this section the hydrometeorological data and study area are provided in section 2 in section 3 the conventional bc method is presented next we demonstrate the importance of preserving the observed natural variability in the bc process the hydrological model and simulation design used to explore the impact of bc is presented in section 4 we also discuss the results of this study finally we offer a summary and conclusions 2 watershed and climate data observed daily hydrologic variables including catchment average precipitation data evapotranspiration and flow time series over the thorverton basin from 1961 to 1990 are compiled from the camels gb catchment attributes and meteorology for large sample studies coxon et al 2020 its catchment averaged daily rainfall data have been derived from ceh gear data tanguy et al 2016 a 1 km gridded rainfall estimates interpolated from daily observed rainfall data from the met office the rainfall grids were achieved using the natural neighbor interpolation method including a normalization step based on average annual rainfall 1961 1990 its potential evapotranspiration pet data were retrieved from the 1 km gridded chess pe dataset robinson et al 2017 which are based on the penman monteith equation monteith 1965 recommended by the fao guidelines on the reference pet allen et al 1998 here the simulated hydrological variables are obtained from the met office hadley centre regional model perturbed physics ensemble simulations for the 21st century for the uk domain hadrm3 ppe uk these regional climate change scenarios are dynamically downscaled from the hadcm3 gcm murphy et al 2009 the hadcm3 consists of an 11 member ensemble one unperturbed member and 10 perturbed members for the perturbed model selected parameters are perturbed from the unperturbed model by considering uncertainties in the model parameters for rcm collins et al 2011 the climate simulations at daily time steps for historical and future periods ranging from 1950 to 2100 are provided with a horizontal resolution of 0 22 degree approximately 25 km this study used the daily precipitation data constructed from all ensemble members to explore the integrated bc approach for the reference precipitation during 1961 1990 the thorverton basin is highlighted by the red grid box as represented in fig 1 right panel 3 methodology 3 1 quantile mapping approach for bias correction the quantile mapping qm approach has been widely applied to calibrate the gcm or rcm outputs e g temperature precipitation and evapotranspiration at different time scales e g from seasonal to daily scales a seasonally varying qm model is usually adopted for bc of the climate model outputs to effectively consider seasonal phases with different degrees of bias by considering strong seasonality and variability in precipitation more importantly an increase in wet day frequency with low precipitation intensity namely drizzle effect has been a well known issue in climate models posing a challenge for effective analysis in this regard systematic bias in the rainfall occurrence process obtained from the climate models is adjusted by applying a threshold based cut off approach in advance before applying bc in other words the wet day frequency is first forced to match with that of the observed precipitation data by eliminating the drizzle effect qm is then performed based on probability distribution functions constructed from observed and simulated daily precipitation the precipitation is assumed to be represented by a gamma distribution as follows 1 f r 1 Œ∏ k Œ≥ k r k 1 e r Œ∏ r 0 k Œ∏ 0 here k and Œ∏ represent the shape and scale parameters respectively and Œ≥ indicates the gamma function in this study the gamma distribution based qm approach is applied for the bc of the daily rcm precipitation gamma distribution is applied to daily data on a monthly basis and the associated parameters are estimated for each of the 11 rcm ensemble members using the maximum likelihood method a conceptual representation of the typical qm based bc scheme is illustrated in fig a1 to be more specific the cumulative distribution functions cdfs for both rcm simulations and observations are built for the same period fig a1 a and the cdf of rcm simulations is then mapped to the cdf of the observed precipitation similarly qm can also be demonstrated in terms of the parameters of probability density functions pdfs i e transfer functions as presented in fig a1 b here a set of distribution parameters of the rcm simulations are transferred to those of the observed data via qm the bias corrected rcm precipitation can be obtained from the transfer function or quantile function as given in eq 2 2 r c f 1 f r m Œ± m Œ≤ m Œ± obs Œ≤ obs here r c denotes the bias corrected daily precipitation from the modeled precipitation r m while f and f 1 are the cumulative density function and quantile function of the gamma distribution respectively with shape Œ± and scale Œ≤ parameters the subscripts m and obs in these parameters Œ± and Œ≤ represent the model and observed precipitation here bc is done for precipitation and simulated flow data it should be noted that bc for the simulated flow is done in the same way as it is done for the simulated precipitation 3 2 natural variability of precipitation and discharge in bc the main drawback of existing bc approaches is that the distribution parameters obtained from all the ensemble members are mapped to a point in the parameter space as illustrated in fig 2 more importantly this may banish model spread from a single model or multi model which represents the uncertainty during the bc process moreover assigning a set of parameters for the bc can be problematic if the sampling error is taken into account and the obtained parameters from the observed precipitation may only represent one case out of many alternatives this study adopted the bc approach for the rcm ensemble proposed by kim et al 2016 which considers both observational uncertainties or sampling errors and natural variability for details the reader is referred to kim et al 2016 first to assess the natural variability of the observed flow daily flow data were randomly selected 30 times on a yearly basis from 30 years of observed daily flow second sampling was repeatedly performed 1000 times to obtain 1000 sets of 30 year daily flow data third gamma distribution parameters were estimated for each series of the simulated flow i e 30 year daily flow simulation the bc for the flow series was done on an annual basis i e 360 days 30 years 10 800 data points similarly the natural variation in precipitation was evaluated it should be noted that seasonally varying transfer functions tfs for each month were built from 1961 to 1990 fig 2 represents a schematic view of the bc considered in this study which reflects the natural variability of observed hydrological variables the main idea of the bc adopted in this study is to maintain the relative distance over the ensemble members seen in rcm simulations after bc this was done so that variations in the bias corrected values are able to reproduce those of the population as if all individuals are equally likely drawn from the population that can be regarded as the observed natural variability it was found that the biases in the 11 member ensemble are effectively removed while maintaining the ensemble spread as seen in fig 2e for more details about the modeling procedure refer to kim et al 2016 3 3 hydrological model this study used the conceptual rainfall runoff model hymod moore 1985 which has five parameters to explore the impact of bc schemes on modeling flow a brief description of model parameters is summarized in table 1 and the schematic representation of the model is given in fig 3 the runoff generation process is described by a parsimonious precipitation runoff model represented through the probability distributed theory and it has been widely used in hydrologic researches boyle 2001 de vos et al 2010 gharari et al 2013 kollat et al 2012 remesan et al 2014 vrugt et al 2003 wagener et al 2001 the spatial variability of the water storage capacity c can be defined as follows 3 f c 1 1 c t c max b exp 0 c t c max here c max and b exp represent the maximum soil moisture sm storage capacity and the degree of spatial variability of the sm capacity in the basin based on the weighting factor Œ± the effective or excess rainfall is converted into a quick flow and a slow flow the discharge is then sequentially routed via parallelly linked three reservoirs representing quick flow simulation in the upper layer and a reservoir for slow flow simulation in the lower layer the hydrographs are finally synthesized by applying the recession parameters for the fast r q and slow r s flow components at the catchment scale the hymod was calibrated at a daily time step over the first available 30 year period 1961 1990 to obtain the optimized parameters and further validated over the remaining period 1991 2014 the calibration was done to minimize the difference between the observed and simulated flow through an objective function based on the nash sutcliffe efficiency nse nash and sutcliffe 1970 4 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 i 1 n day where q sim q obs q obs are the simulated flow the observed flow and the mean of the observed flow respectively in the calibration period we used a dynamically dimensioned search dds tolson and shoemaker 2007 a heuristic global optimization algorithm the values of nse were found to be 0 83 and 0 82 for the calibration and validation periods respectively which appear to be effective for rainfall runoff modeling according to the given criteria n s e 0 75 motovilov et al 1999 3 4 experimental design used to examine the effectiveness of bias correction the four experimental design cases are presented as follows the bc is applied to 11 members of rcm precipitation and the simulated flow from the hydrological model a rigorous inter comparison between the four cases is provided as illustrated in fig 4 case 1 the uncorrected 11 member ensemble of rcm precipitation is used as an input for the hm and the uncorrected flow from hm is obtained i e neither the bias of rcm precipitation nor the bias of the simulated flow are corrected case 2 the uncorrected 11 member ensemble of rcm precipitation is used for the hm as an input and the bias of the simulated flow from hm is then adjusted i e the bias of rcm precipitation is not corrected while the bias of the simulated flow is corrected case 3 the bias of the 11 member ensemble of rcm precipitation is corrected which is then used for the hm as an input i e the bias of rcm precipitation is corrected while the bias of the simulated flow is not corrected case 4 the bias of the 11 member ensemble of rcm precipitation is corrected which is then used for the hm as an input the bias of the simulated flow from hm is also adjusted i e both the biases of rcm precipitation and the simulated flow are corrected fig 5 provides a conceptual diagram of the four different proposed bc approaches for the rcm ensemble of rcm precipitation and simulated flow from a distribution parameter estimation point of view different transfer functions tfs are used to correct each ensemble member however the distribution parameters range for the tfs is restricted to the natural variability in the observed precipitation and flow since both the precipitation from the rcm and the simulated flow from a rainfall runoff model are often affected by systematic errors the spread of model outputs for case 1 are significantly biased by the natural variability of the hydrologic variables e g precipitation and flow as illustrated in fig 5 a for case 2 the bias uncorrected rcm precipitation ensemble is used as an input for hm and the uncertainty range of the simulated flow ensemble is corrected by mapping the tfs based on the natural variability of the observed flow therefore the spread of the simulated flow obtained from the rcm ensemble after bc blue dotted ellipse is expected to match well with the spread of the observation data red ellipse fig 5 b for case 3 the spread of the rcm precipitation ensemble is corrected blue dotted ellipse by mapping the tfs based on the observed natural variability in precipitation red ellipse then the bias corrected precipitation ensemble is used as an input for hm whereas the bias of the outputs from hm is not corrected in this case fig 5 c for case 4 the spread of the rcm precipitation ensemble is corrected blue dotted ellipse by mapping the tfs based on the climate variation in the observation red ellipse and the bias corrected precipitation ensemble is used as an input for hm furthermore the bias of the outputs from hm is corrected in this case fig 5 d 3 5 validation of proposed bias correction schemes to evaluate the tfs for the bc the hydrological data i e precipitation and flow are divided into calibration 1961 1990 and validation 1991 2014 periods representing the unseen data in a cross validation context both the precipitation and the flow ranging from 1961 to 1990 were used to construct the tfs for bc the tfs were then applied to the independent data from 1991 to 2008 note that the climate model outputs have no direct link to the data corresponding to the individual years of observation i e they are not synchronous for example rcm precipitations in the year 1961 have no direct relationship with the observed precipitations in the same year a set of aggregated statistics estimated from both observations and model outputs can be comparable in this regard therefore to explore the effectiveness of bc in both the calibration and validation periods monthly mean flows were compared for the four cases a schematic representation of applying the tf to the validation period is presented in fig 6 the tf is built under the assumption that it is still effective for future climate conditions i e the stationarity assumption with the tf albeit the climate is changed in the future which is commonly adopted in climate bias corrections so that the tf is constructed based on the calibration period data blue and red ellipses given the stationarity assumption the magnitude direction and spread of the tf are preserved while being applied to the validation period data blue dotted ellipse the bc results black dotted ellipse are compared with the natural variability of the observation during the validation period red dotted ellipse which is assumed to be the future unseen data 4 results 4 1 calibration period 4 1 1 bias correction of the rcm precipitation ensemble fig 7 shows the performance of bc for correcting the mean simulated precipitation although the seasonality is largely reproduced the uncorrected monthly average rainfalls of 11 members of hadrm3 for the calibration phase 1961 1990 significantly deviate from those of the observed left panel of fig 7 the ensemble means were generally well simulated in april and june on the other hand overestimation is seen in may and underestimation is largely observed from july to march after bc the bias corrected precipitation of each ensemble member is comparable with that of the observation data on a monthly basis a comparison of percentage errors of the monthly precipitation between before and after bias correction is presented in fig 8 overall the systematic bias in the mean was well corrected and the spread associated with the natural variability was also reasonably well preserved right panel of fig 7 and fig 8 in terms of the model spread the uncorrected model outputs were somewhat overestimated compared with the spread seen in the bias corrected rcm precipitation as shown in figs 7 and 8 4 1 2 comparison of the simulated flows we compared the monthly mean flows between the observed data and four different model cases the shaded area representing the model spread is obtained from the precipitation ensemble for the period from 1961 to 1990 the model spread is then compared with the boxplots showing the natural variability of the observed flow fig 9 overall the monthly flows simulated from the bias uncorrected 11 member rcm precipitation fig 9 a produces a large bias mostly underestimated compared with those of the bias corrected one fig 9 b c d in addition the spread of flows simulated from the bias uncorrected rcm precipitation fig 9 a is larger than those of simulated flow from bias corrected rcm fig 9 c and post processed flows fig 9 b d therefore it is apparent that the simulations without bias correction and post processing are not able to accurately represent both the climate and the hydrological processes fig 9 a case 1 the bias corrected flow ensemble fig 9 b case 2 is the output of the hymod model which is simulated using bias uncorrected rcm precipitation followed by correcting the bias of simulated flows the result showed a narrower range of uncertainty than case 1 in other words both the mean and variance of the flow ensemble have been improved because the systematic bias of the flow has been directly corrected although the overall model spread and bias of the flow ensemble have been improved after correcting the bias of hm outputs further improvements are needed to match the natural variability of the observed flow for example the spread of hm outputs is larger than those of the observations from december to march and the flow is underestimated from august to november in case 3 the flow simulations ensembles were obtained by using the bias corrected precipitation as an input as shown in fig 9 c the performance of case 3 is better than that of the approach used in case 1 in terms of reducing the bias the ensemble range is well reproduced after bc which is comparable with the observed natural variation although the bias of the flow needs to be further improved the spread of the simulated flow ensemble is more similar to that of the observation compared with case 2 this might be due to the use of bias corrected rcm precipitation as inputs to hm thus one can conclude that bc of the rcm precipitation plays a critical role in achieving objectives that reduce the bias and reproduce the natural variability of the flow to explore the role of bc in the simulated flow ensemble the biases of the rcm precipitation and flow were corrected in case 4 fig 9 d as expected the bias and the spread of the simulated flow ensemble are noticeably smaller than those of case 2 and case 3 the spread of bias corrected flow ensemble mostly fell inside the natural variability of the observed flow from this result the case 4 model which corrects the biases of both precipitation and flow shows the best performance among the four cases in terms of correcting the bias and the spread of the flow ensemble we further evaluated the model performance with different percentiles to explore the proposed effectiveness of the bc schemes at different flow regimes here 11 member ensembles for the four cases were used to obtain flow distribution information at various percentiles as shown in fig 10 since 1000 sets of random long term precipitation sequences i e 30 year 365 days 1000 were sampled to reproduce the natural variability over the past 30 year precipitation 1000 sets of flow duration curves fdcs were constructed in most percentiles the flow ensembles i e case 1 and case 3 are generally underestimated their median values differ from the observed flows with extended ranges of the simulated flow at most flow regimes overall the findings are in line with the results as illustrated in fig 9 in contrast the medians and the ranges of the bias corrected flows case 2 and case 4 were comparable to the observed flow at most flow regimes fig 11 presents the performance of different cases for the relationship of distribution parameters of the flow data the red dots represent the estimated parameters associated with the natural variability of the observed flow which are resampled from the observation data details of estimating the natural variability of the observed flow are presented in section 3 2 in fig 11 a the unfilled blue dots are the gamma distribution parameters of the simulated flow from the uncorrected 11 member rcm precipitation case 1 and the filled blue triangles are those of the bias corrected flow with the uncorrected 11 member precipitation sets obtained from the rcm case 2 in fig 11 b the unfilled blue dots are the relationship of two parameters of the bias uncorrected flow simulated from the corrected 11 member rcm precipitation case 3 and the filled blue triangles are the relationship between gamma distribution parameters of the bias corrected flow simulated from the corrected 11 member rcm precipitation case 4 the gamma distribution parameters of the fixed flow members case 2 and case 4 are all inside the range of the observed natural variability which indicates that the spread of the 11 members parameters after bc are reasonably well reproduced in contrast the bias uncorrected flow cases case 1 and case 3 generally deviate from the parameter space shown in the observed flow again these results confirm that using bc for the simulated flow is important in reducing the bias and reproducing the natural variability of the flow 4 2 validation period 4 2 1 bias correction of the rcm precipitation ensemble fig 12 represents the bias correction results during the validation period 1991 2014 here the observed monthly mean precipitation during the validation period is assumed to be the future precipitation as done in the climate change study the difference between the uncorrected precipitation of hadrm3 and the observation data was found for the validation period from 1991 to 2014 left panel of fig 12 more specifically the precipitation ensemble means were generally overestimated in march and may whereas an underestimation of the precipitation was observed for the rest of the month the results are generally consistent with the differences identified in the calibration period even considering that the tfs were built during the calibration period the results demonstrated that the simulated monthly precipitation was reasonably well corrected a comparison of percentage errors of the monthly precipitation between before and after bias correction during the validation period 1991 2014 is presented in fig 13 the overall reduction in the ensemble spread representing the natural variability was also confirmed except for march april and september right panel of figs 12 and 13 the overestimation of the model spread that exceeded the observed natural variability in precipitation is in line with the calibration results during 1961 1990 compared to the calibration results during 1961 1990 the proposed approach could be applied for bias correction of unseen data representing the future climate although there is a slight difference from the observed precipitation the effectiveness of the proposed bc model can be confirmed overall 4 2 2 comparison of the simulated flows to further explore the proposed bc schemes the monthly mean flows of the observed data and four different model cases during the validation period 1991 2014 were compared the shaded area representing the model spread is obtained from the precipitation ensemble for the period from 1991 to 2014 the model spread is then compared with the boxplots showing the natural variability of the observed flow as illustrated in fig 14 overall regardless of applying the bc for the rcm precipitation the flow ensemble simulated from the rcm precipitation case 1 and case 3 was shown to be systematically biased when the simulated flows were not corrected more specifically the monthly flows simulated from the bias uncorrected 11 member rcm precipitation fig 14 a produce a large bias mostly underestimated compared with those of the bias corrected flows fig 14 b d in case 2 the flow simulations ensembles were obtained by using the bias uncorrected precipitation as an input followed by correcting the bias of simulated flows the systematic bias is largely corrected however the higher mean value of the flow ensemble than the observed is seen during the first half of the year and vice versa during the rest of the year the spread of the simulated flows is not clearly reduced compared with case 1 which implies that the bc process for hm outputs has a limited effect on improving the uncertainty of the simulated flow during the validation period although case 3 during the calibration period fig 9 c showed an improvement in terms of reducing the bias of simulated flows when the bias corrected rcm precipitations are used as inputs to hm this is not the case for the validation period fig 14 c on the other hand when both the rcm precipitation and flow biases are corrected fig 14 d case 4 it can be seen that the biases of the simulated flow ensemble are noticeably reduced than those observed in case 3 in summary case 4 which corrected the bias of rcm precipitation and simulated flow showed the best performance among the four cases in terms of correcting the bias of the flow ensemble theoverall model spread of the flow ensemble after correcting the bias of hm outputs was largely similar to the natural variability of the observation data and mostly fell inside the observed natural variability of the flow as similarly found in the calibration period one can conclude that bc of the simulated flow played a crucial role in achieving objectives that reduce the bias of the flow it should be noted that the overall efficacy of the proposed bias correction approach largely relies on the calibration of the rainfall runoff model more specifically if the rainfall runoff model is not adequately calibrated the differences in performance across cases cannot be attributed solely to the bias correction approaches proposed in this study here we did not evaluate the sensitivity of the overall results according to the model performance in the calibration and validation processes however we confirmed that the calibration process appears to be effective for rainfall runoff modeling since the values of nse were found to be over 0 80 for both the calibration and validation periods model performances at different flow regimes are illustrated in fig 15 as done in the calibration period in section 4 1 2 as seen in the calibration period the bias uncorrected flows i e case 1 and case 3 generally underestimated the observed flow their underlying distributions slightly deviated from that of the observed data with an extended range of the natural variability at most flow regimes overall the findings are in line with the calibration results whereas the distributions of the bias corrected flows case 2 and case 4 are largely comparable to the observed flow at most flow regimes a comparison of model validation results during 1991 2014 when correcting the parameter space of the flow data over four different schemes is presented in fig 16 as expected the parameter space of the corrected flow ensemble case 2 and case 4 was comparable to that of the observed data and much closer than the uncorrected flows simulated from the rcm precipitation irrespective of correcting the bias of precipitation i e case 1 and case 3 however the estimated parameters from the bias corrected flow ensemble do not always fall in the range seen in the observed flow finally the results obtained during the validation period reemphasize the relative importance for the bc of the simulated flow 5 summary and conclusions existing studies have independently focused on either the bc process of climate model outputs e g precipitation and temperature or the post processing of hydrological model outputs e g simulated flow several recent studies have evaluated the impact of bias correction on both the input variables and streamflow considering the uncertainty in the hydrologic model simulations however these studies neglected the advantage of quantifying uncertainty through the use of ensemble spread in climate change impact studies in this context this study is an extended work of these existing studies combining the bias correction processes of rcm precipitation and the flow simulated from the rainfall runoff model in an integrated framework considering the underlying uncertainty in the parameters of the distribution function to examine the effectiveness of the combined strategy four different bc approaches have been explored to reduce systematic biases in the streamflow simulated from a conceptual hydrological model the basic assumption in this study was that both the observed precipitation and the flow data for bias correction were available moreover the proposed bc approaches have been applied under the presumption that the corrected rcm members and the simulated flow with the rcm precipitation should come from within the range of the variation observed in the precipitation and flow data the four bc models we considered are described as follows in case 1 the biases of both the climate model and hydrological model outputs are not corrected in case 2 the bias of the flow is only corrected with the use of the uncorrected rcm precipitation in case 3 the bias of rcm precipitation is solely corrected without bc of the simulated flow in case 4 both the rcm precipitation and flow are corrected by preserving their natural variabilities the performance of these four different cases of combined bc models was compared with the observed flow during both the calibration period 1961 1990 and the validation period 1991 2014 the main summary and key findings from this study are described as follows 1 in case 1 the uncorrected precipitation for the calibration phase differs from the observations the flow simulated from the uncorrected rcm precipitation was shown to be systematically biased and the model spread was largely overestimated compared to that in the observations in case 2 the bias corrected flow using the bias uncorrected precipitation ensemble demonstrated a narrower range of uncertainty than case 1 the bias corrected flow ensemble has been improved since the systematic bias of the flow has been directly corrected although the overall model spread of the flow ensemble after correcting the bias of the simulated flow was similar to the natural variability of the observed flow further improvement is needed to match the natural variability of the observed flow 2 in case 3 the corrected precipitation was almost identical to that of the observation data the systematic biases in the precipitation ensemble were well corrected and the spread associated with the natural variability was also reasonably well preserved although the bias of the simulated flow needs to be further improved the spread of the simulated flow ensemble is more similar to that of the observation compared with case 1 this might be due to the use of bias corrected rcm precipitation as inputs to hm in case 4 both the rcm precipitation and flow biases were corrected as expected the bias and the spread of the simulated flow ensemble were noticeably smaller than those in case 2 and case 3 the case 4 model which corrects the biases of both the precipitation and the flow showed the best performance among the four cases in terms of correcting the bias and the spread of the flow ensemble the improved results in terms of bias correction in case 4 have some interesting implications about the important role of bc for both the rcm precipitation and the simulated flow in reducing the bias and reproducing the natural variability of the flow 3 we further explored model performance at different flow regimes in most percentiles the flow ensembles obtained from case 1 and case 3 were generally underestimated their median values differ from the observed flows with an extended range of the simulated flow at most flow regimes in contrast the medians and the ranges of the bias corrected flows obtained from case 2 and case 4 were comparable to the observed flow at most flow regimes finally the model performance of different cases in terms of the parameter space of the flow ensemble was evaluated the gamma distribution parameters of the corrected flow members obtained from case 2 and case 4 were all inside the range of the observed natural variability it should be noted that the bc of the simulated flow demonstrated the relative importance of reducing the bias and reproducing the natural variability of the flow during the validation period the model performances were further evaluated the case 4 model was the best in correcting the bias of simulated flows which are in line with the calibration results however from an ensemble uncertainty perspective the spread of simulated models is not identical to those of the observations which implies that bc of the model outputs does not play a crucial role in reproducing the spread of the observed flow during the validation period the difference in the ensemble uncertainty seems to be due to nonstationarity in the flow leading to a difference in the transfer function for the bias correction 4 bc of the rcm precipitation is often criticized due to several aspects dosio et al 2012 ehret et al 2012a hagemann et al 2011 maraun 2012 maraun et al 2010 teutschbein and seibert 2012 such as 1 a physical justification is missing since the model errors induced by physical causes are not considered 2 the relationship and spatio temporal consistency between climate variables are modified after bc 3 it may not be plausible to correct climate change trends and 4 the stationarity assumption might not be met under changing climate conditions however from a hydrological perspective we would like to point out that the use of the bias corrected climate model precipitations as inputs to the hydrological model followed by the bc of the simulated flow from hm is recommended 6 data availability the camels gb dataset used in this study is available via the uk centre for ecology hydrology environmental information data centre credit authorship contribution statement kue bum kim conceptualization data curation methodology software validation formal analysis writing original draft hyun han kwon conceptualization methodology investigation supervision writing review editing funding acquisition dawei han supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was funded by the korea meteorological administration research and development program under grant kmi 2018 07010 this work was partially supported by the national research foundation of korea nrf grant funded by the korea government msit no 2019r1a2c2087944 
3803,the bayesian method has been increasingly applied to the inversion of seepage parameters owing to its superiority of considering the uncertainty in the inversion process however most of the current bayesian inversion studies only focus on parameter uncertainty ignoring the model structure error in addition existing research has mostly adopted a single machine learning algorithm or an ensemble of surrogates based on a single prediction performance indicator as a substitute for the seepage forward model and has not considered the interactions between multiple prediction performance indicators thereby leading to poor accuracy to address these issues this study proposed an efficient bayesian inversion method for seepage parameters using a data driven error model and an ensemble of surrogates considering the interactions between prediction performance indicators a data driven error model based on gaussian process regression was integrated into the bayesian inversion model to modify the likelihood function for dealing with the model structure error for determining the weight coefficients of the ensemble surrogates the improved dempster shafer d s evidence theory based on the hellinger distance and deng entropy was proposed to fuse multiple prediction performance indicators and consider their interactions further an ensemble of surrogates in conjunction with support vector regression kriging and multivariate adaptive regression splines was constructed through weighted summation the validity and accuracy of the proposed method were verified by applying it to a real hydropower station in china the results showed that the proposed method can significantly improve the accuracy and efficiency of bayesian inversion of seepage parameters the proposed method therefore serves as a new basis for the inversion of seepage parameters and can be applied to parameter inversion in other related fields keywords bayesian inversion data driven error model surrogate model dempster shafer evidence theory prediction performance indicator seepage parameter 1 introduction seepage problems have received significant attention in several engineering fields including groundwater remediation water pollution treatment hydropower station operation and fossil energy exploitation numerical simulation is an effective tool for understanding the complex seepage phenomena involved in these fields in a seepage numerical model determination of the seepage parameters e g hydraulic conductivities of aquifers is of great significance for obtaining accurate seepage simulation results one favoured method to determine the seepage parameters involves conducting inversion analysis according to the monitoring data such as the water head of the piezometer and the seepage flow among the existing parameter inversion methods the bayesian inversion method is a formal approach for parameter inversion and uncertainty assessment and has become increasingly popular in the fields of hydrology and geophysics han and zheng 2018 hassanzadeh et al 2019 jiang and ou 2017 ju et al 2020 liu et al 2017 rajabi and ataie ashtiani 2016 yan and zhou 2019 zhang et al 2016 although these studies have achieved promising results two key issues remain to be resolved first most studies have only concentrated on parameter uncertainty while ignoring model structure error which is often quite difficult to address liu et al 2019 another issue is the computational burden which is caused by the considerable number of repeated forward model calls for a posterior distribution to reach convergence chen et al 2018 currently some efforts have been made to solve the problem of model structure error in parameter inversion in general the approaches that have been presented so far can be divided into three categories the first category of approaches is multi model method which accounts for model structure uncertainty by recognizing and combining multiple competing model representations tasdighi et al 2018 xu et al 2017 however the multi model methods are related to the subjective choice of the independent model structures and model weights which may induce additional uncertainty in the inversion process xu and valocchi 2015a in the second category researchers simply treat the model structure error by adding a stochastic perturbation term to the model simulated states rather than designing a sophisticated method choi et al 2017 zhang and fu 2018 2019 however some researchers believe that this method may lead to an underestimation of the model structure error zhang et al 2019 data driven approaches based on machine learning algorithms for example gaussian process regression are the third category of approaches presented to address model structure error data driven approaches can learn complex functional relationships between output i e model structural error and inputs selected from historical data xu et al 2017 kennedy and o hagan 2001 first proposed a bayesian framework integrated with the gaussian progress regression to jointly infer the uncertain input parameters in a physically based model together with the model structure error their seminal work is known as the koh framework choi et al 2018 and has been applied and developed in several research fields including groundwater modelling xu and valocchi 2015b zhang et al 2019 pan et al 2020 thermal problems liu et al 2019 choi et al 2017 2018 and material models rappel et al 2019 in the abovementioned studies data driven approaches have demonstrated their effectiveness in dealing with model structure error inspired by previous studies this study also adopts a data driven approach based on gaussian progress regression to deal with the structure error in seepage parameter inversion in the bayesian inversion process hundreds of thousands of forward model calls are required for posterior distribution to reach convergence the computational expense for complex forward models may be prohibitively high in addition the joint inference of uncertain input parameters and model structure error may further increase the computational cost because of the increased dimension of the sampling space and the decreased convergence rate xu et al 2017 to address this problem surrogate models based on machine learning methods such as the response surface model rsm li et al 2019 radial basis function wu et al 2021 polynomial chaos expansion mohammadi et al 2021 kriging jiang et al 2020 svr xu et al 2017 and multivariate adaptive regression splines mars chen et al 2017b can be used to substitute computationally intensive forward models in many previous studies surrogate models were generally constructed based on an individual machine learning method however the performance of the individual machine learning method varies with the specific problem wang et al 2021 it is therefore difficult for an individual machine learning method to achieve optimal fitting of all simulation models this problem can be addressed by using an ensemble of surrogates which can be constructed by combining different machine learning methods via a weighted summation strategy determining the weight of each surrogate model is the most critical step when constructing an ensemble of surrogates to date various weight determination methods have been proposed for example the optimal weighted surrogate owsdiag proposed by viana et al 2009 is a commonly used weight determination method for constructing an ensemble of surrogates christelis et al 2019 dhamotharan et al 2018 ouyang et al 2017 yang et al 2018 in addition the set pair analysis hou et al 2017 yin and tsai 2020 bagging method chen et al 2017b 2018 gradient boosting approach queipo and nava 2019 adaptive metropolis markov chain monte carlo xing et al 2019 differential evolution tabu search de ts hybrid algorithm wang et al 2021 bayesian model averaging yin et al 2021 and minimization of local mean square error ye et al 2020 have all been proposed to construct the ensemble of surrogates however most previous studies have only determined the weights based on a certain prediction performance indicator for example correlation coefficient r or root mean squared error rmse and have ignored the interactions between multiple prediction performance indicators it must be noted that a particular surrogate model may have conflicting characteristics in terms of prediction performance indicators such as the correlation coefficient r root mean squared error rmse mean absolute error mae and median absolute deviation mad different weight coefficients can be obtained according to different performance indicators it is of great significance to determine more reliable weight coefficients by considering the interactions between multiple prediction performance indicators the dempster shafer d s evidence theory offers a method of integrating conflicting vague and uncertain information from diverse sources muller and piche 2011 roy and datta 2019 a variety of prediction performance indicators can therefore be integrated based on the d s evidence theory to obtain the weight coefficient of each single model muller and piche 2011 proposed an ensemble of surrogates based on the d s evidence theory for global optimization problems roy and datta 2019 2020 further extended the d s evidence theory to study seawater intrusion in coastal aquifers however in the abovementioned studies each evidence that is each prediction performance indicator is regarded as independent of each other without considering their similarity and uncertainty this can lead to information redundancy and an adverse impact on the calculation results of the weight coefficients similarity measures include the jensen shannon divergence xie et al 2020 jousselme distance fan et al 2020 cosine similarity dong et al 2018 minkowski distance chen et al 2017a and matusita distance ye et al 2018 the hellinger distance is a measure of the probability distribution similarity that can reflect the similarity of data distribution in contrast to other distance measurement methods the hellinger distance is more stable and reliable and can effectively measure the difference between probability distributions of random variables deng and wang 2020 in addition the uncertainty of the evidence itself is a very important property deng proposed the deng entropy as an extension of the shannon entropy deng 2016 the combination of deng entropy and the d s evidence theory can be used to effectively measure the uncertainty of the evidence thus realizing the credibility analysis and making the fusion result of the evidences more reasonable in view of the abovementioned research this study introduces the hellinger distance and deng entropy to improve the traditional d s evidence theory to consider the interactions between multiple prediction performance indicators and obtain more reasonable weight coefficients furthermore the ensemble of surrogates is constructed based on the improved d s evidence theory the main objective of this study was to invert the seepage parameters accurately and efficiently using the bayesian inversion method the main contributions of this study can be summarized as follows 1 a data driven error model based on gaussian process regression was adopted and integrated into bayesian inference to invert the seepage parameters and address the model structure error in the progress of seepage parameter inversion 2 an ensemble of surrogates that can combine the advantages of different machine learning algorithms was proposed to improve the computational efficiency of bayesian inversion 3 an improved d s evidence theory based on the hellinger distance and deng entropy was proposed to determine the weights of the surrogate models which could fuse multiple prediction performance indicators and consider their interactions thereby improving the accuracy of the ensemble of surrogates the remainder of this paper is organized as follows section 2 presents a brief introduction of the research framework of this study the ensemble of surrogates considering the interactions between prediction performance indicators and the bayesian inversion method with a data driven error model in section 3 the method proposed in this study is applied to a hydropower station in southwest china the prediction performance of the proposed ensemble of surrogates and the results of the seepage parameter inversion are discussed in section 4 finally the conclusions are drawn in section 5 2 methodology 2 1 research framework fig 1 shows the basic flowchart of the proposed method it comprises three main steps 1 dataset generation 2 construction of the ensemble of surrogates and 3 bayesian inversion using the data driven error model a detailed description of each step is provided below step 1 dataset generation the sample points of the seepage parameters were obtained through latin hypercube sampling lhs and then these sample points were input into the seepage model to obtain the simulated values at the monitoring locations the sample points of the seepage parameters and the simulated values of the monitoring locations constitute the dataset of the ensemble of surrogates from which the training and testing sets were divided step 2 construction of the ensemble of surrogates to make full use of the prediction advantages of different machine learning algorithms and improve the prediction accuracy three machine learning algorithms namely svr kriging and mars were trained according to the training set to build the ensemble of surrogates determining the weight coefficient of each model is a key step in constructing an ensemble of surrogates to comprehensively consider the interactions between various performance indicators namely r rmse mae and mad an improved d s evidence theory based on the hellinger distance and deng entropy was proposed to determine the weight coefficients furthermore the ensemble of surrogates was established by weighted summation step 3 bayesian inversion using the data driven error model before bayesian inversion the prior distribution of the parameters and monitoring values were set to obtain more reliable inversion results a data driven error model based on gaussian process regression was adopted to deal with the model structure error because it is difficult to directly solve the bayesian formula of the parameter posterior distribution the markov chain monte carlo sampling method dreamzs algorithm was selected in this study was used to solve the posterior distribution of parameters to improve the efficiency of the inversion calculation the ensemble of surrogates established in step 2 was used to replace the computation time consuming seepage forward model 2 2 seepage simulation model the seepage simulation model is the basis of the ensemble surrogate models and bayesian inversion model the governing partial differential equation for the steady state seepage can be expressed as follows 1 x k x h x y k y h y z k z h z 0 where h is the hydraulic head kx ky and kz are the hydraulic conductivity in x y and z directions respectively in this study the finite volume method in the software star ccm 10 02 was used to obtain the numerical solution of equation 1 for the computation of the free surface flow determining the saturated surface is the key step since the volume of fluid vof method proposed by hirt and nichols 1981 can quickly capture the sharp fluid interface and reduce numerical diffusion and complicated geometrical reconstruction near the interface cheng et al 2018 this method was adopted in this study to obtain the saturated surface the basic principle of the vof method is to determine the position and shape of the saturated surface through solving the function f which is defined as the ratio of fluid volume over the total volume in a computational cell zhong et al 2013 in the vof method the saturated surface can be captured by solving the following equation 2 f t u f 0 where t is the time u is the superficial velocity vector of the computational cell which can be calculated as follows 3 u œÅ u where u is the real seepage velocity vector in the pores œÅ is the porosity of the porous media 2 3 ensemble of surrogates considering the interactions between prediction performance indicators 2 3 1 ensemble of surrogates in this study three widely used surrogate models namely svr kriging and mars were adopted to construct an ensemble of surrogates svr was selected because of its ability to efficiently capture the complex relationship between the input and output from small sample data kriging has beneficial interpolating capabilities in approximating deterministic computer simulations christelis et al 2019 mars is a rapid flexible adaptive and nonparametric approach for developing regression models roy and datta 2019 the ensemble of surrogates can be expressed as follows 4 f en x i 1 3 w i f i x 5 i 1 3 w i 1 where fen x is the predicted value of the ensemble of surrogates fi x i 1 2 3 are the predicted values of the three surrogate models in the ensemble x is the vector of design variables and wi i 1 2 3 are the weight coefficients of svr kriging and mars respectively detailed descriptions of svr kriging and mars can be found in the work of cheng et al 2017 toal and keane 2013 and chen et al 2018 therefore these descriptions are not repeated herein in this study the improved dempster shafer d s evidence theory based on the hellinger distance and deng entropy was proposed as a weight determination method to construct ensembles of surrogates considering the interactions between prediction performance indicators 2 3 2 dempster shafer evidence theory in the dempster shafer d s evidence theory the basic probability assignment bpa function m a is the fundamental method of expressing uncertainty roy and datta 2019 for each subset a of frame Œ∏ a 1 a 2 a n the bpa function m a is defined as the mapping m 2Œ∏ 0 1 similar to the probability theory the sum of bpa equals one in this study the frame can be represented as Œ∏ svr kriging mars a 1 a 2 a 3 four performance indicators of surrogate models based on the training dataset namely the correlation coefficient r root mean squared error rmse mean absolute error mae and median absolute deviation mad were adopted as four pieces of evidence for the d s evidence theory then the basic probability assignments bpas in the frame can be expressed as follows 6 m r m r a 1 m r a 2 m r a 3 m rmse m rmse a 1 m rmse a 2 m rmse a 3 m mae m mae a 1 m mae a 2 m mae a 3 m mad m mad a 1 m mad a 2 m mad a 3 ideally the best surrogate model should have higher values of r and lower values of rmse mae and mad roy and datta 2019 these performance indicators then need to be normalized to satisfy the condition that the sum of bpa values over the frame Œ∏ must be equal one namely k 1 3 m r a k 1 k 1 3 m rmse a k 1 k 1 3 m mae a k 1 and k 1 3 m mad a k 1 the calculation formulae for the normalization can be expressed as follows 7 m r a k r k k 1 3 r k m rmse a k 1 rmse k k 1 3 1 rmse k m mae a k 1 mae k k 1 3 1 mae k m mad a k 1 mad k k 1 3 1 mad k where rk rmsek maek and madk represent the four prediction performance indicators of the kth individual surrogate model the bpa functions can be combined using dempster s rule of combination which can be expressed as follows 8 m a a k a i 1 n m i a k 1 t a 0 a 9 t a k i 1 n m i a k where represents the null set t is the conflict coefficient that measures the degree of the conflict between pieces of evidence and n represents the number of pieces of evidence which is taken as four in this study 2 3 3 improved dempster shafer evidence theory based on the hellinger distance and deng entropy in order to consider the interactions between multiple prediction performance indicators and obtain more reasonable weight coefficients this study introduced the hellinger distance and deng entropy to measure the similarity between evidences and the uncertainty of the evidences to realize an improvement of the traditional d s evidence theory the specific steps of the improved d s evidence theory based on the hellinger distance and deng entropy proposed in this study are as follows 1 establish bpa four prediction performance indicators of the three surrogate models namely r rmse mae and mad were obtained based on the training set and normalized treatment was conducted according to equation 7 to establish the bpa of the d s evidence theory 2 calculate the similarity measure among the evidences based on the hellinger distance for the two random variables p p 1 p 2 pk and q q 1 q 2 qk the hellinger distance is expressed as follows 10 h p q 1 2 i 1 k p i q i 2 where k represents the sample size of the random variables the hellinger distance satisfies the following characteristics 1 the value range of h p q is 0 1 2 h p q is symmetric and non negative that is h p q h q p 0 the smaller the hellinger distance between the evidences the higher the similarity between the evidences and the greater the degree of mutual support the hellinger distance between each piece of evidence can be calculated according to eq 10 and the hellinger distance matrix in this study can be expressed as follows 11 h 0 h m 1 m 2 h m 1 m 3 h m 1 m 4 h m 2 m 1 0 h m 2 m 3 h m 2 m 4 h m 3 m 1 h m 3 m 2 0 h m 3 m 4 h m 4 m 1 h m 4 m 2 h m 4 m 3 0 the similarity measure between two pieces of evidence mi and mj can be defined as follows 12 s ij m i m j 1 h m i m j i j 1 2 3 4 then the similarity measure matrix in this study can be expressed as follows 13 s 1 1 h m 1 m 2 1 h m 1 m 3 1 h m 1 m 4 1 h m 2 m 1 1 1 h m 2 m 3 1 h m 2 m 4 1 h m 3 m 1 1 h m 3 m 2 1 1 h m 3 m 4 1 h m 4 m 1 1 h m 4 m 2 1 h m 4 m 3 1 3 calculate the support degree and credibility of the evidence the support degree reflects the degree to which evidence is supported by other evidences the greater the similarity between evidences the higher the support degree of the evidences therefore the support degree sup mi can be obtained through the similarity measure as follows 14 s u p m i j 1 j i 4 s ij m i m j i j 1 2 3 4 the credibility crdi can then be obtained by normalizing the support degree as follows 15 crd i sup m i i 1 4 s u p m i 1 i 4 4 adjust the credibility of evidence based on deng entropy deng entropy is an extension of shannon entropy which can effectively measure the uncertainty of information deng entropy is defined as follows 16 e di k 1 3 m i a k l o g m i a k 2 a k 1 1 i 4 where ak is the cardinality of set ak when evidence has a high deng entropy it indicates that the evidence contains more information and can be better supported by other evidences therefore the evidence with a high deng entropy plays an important role in the final combination and carries a large weight the credibility of the evidence can be adjusted according to the deng entropy of each evidence as follows 17 acrd i crd i e di 1 i 4 5 modify the evidences based on the weights of evidences the weight of each evidence can be obtained according to the adjusted credibility as follows 18 w i acrd i i 1 4 acrd i 1 i 4 then the initial evidence is modified through the weighted average the weighted average evidence w a e m a k can be obtained as follows 19 w a e m a k i 1 4 w i m i a k 6 evidence fusion calculations the modified evidence is combined n 1 n is the number of the pieces of evidence which is taken as four in this study times according to dempster s combination rule to obtain the fusion results the fusion results are the weight coefficients of the surrogate models which can be introduced into equation 4 to establish the ensemble of surrogates 2 4 bayesian inversion method with data driven error model based on bayes theorem the posterior distribution p Œ∏ y of the model parameter Œ∏ can be expressed as follows 20 p Œ∏ y p y Œ∏ p Œ∏ p y Œ∏ p Œ∏ d Œ∏ where p Œ∏ is the prior distribution of parameter Œ∏ y is the monitoring value and p y Œ∏ is the likelihood function obtaining an analytical expression of the posterior distribution p Œ∏ y is difficult an effective method is to construct a posterior distribution using markov chain monte carlo mcmc sampling the dreamzs algorithm laloy and vrugt 2012 vrugt 2016 was adopted in this study existing bayesian methods can deal with the measurement error and parameter uncertainty by assuming the error structure of residuals and bayesian inference respectively in mcmc pan et al 2020 however most existing bayesian methods ignore the model structure error because it is usually more difficult to address than parameter uncertainty to quantify the model structure error the relationship between the monitoring value y and the simulated value of model m Œ∏ can be expressed as follows 21 y m Œ∏ Œ¥ z œÜ Œµ where Œ¥ z œÜ represents the model structure error z represents the input of the model which consists of the physically based model outputs and the locations of the monitoring points in this study œÜ represents the tuning parameters and Œµ represents the measurement error Œµ is a random vector that follows an independent and identical gaussian distribution Œµ n 0 œÉ Œµ 2 œÉ Œµ 2 can be determined according to the error of the monitoring instrument in this study a data driven error model based on gaussian process regression is adopted to characterize the model structure error more details on the introduction of gaussian process regression can be found in xu and valocchi 2015a without loss of generality this study provides only a brief introduction the prior distribution of the model structure error Œ¥ z œÜ is usually assumed to obey a multivariate gaussian distribution n Œº c the gaussian process regression is specified by a mean function Œº m e Œ¥ z and a covariance function c k z z e Œ¥ z Œº z Œ¥ z Œº z in this study the mean function is set to a constant zero and the squared exponential covariance function is adopted 22 k z i z j œÉ 2 e x p z i z j t z i z j Œª 2 œÉ Œµ 2 œà i j 1 2 n where Œª is the characteristic length scale œÉ 2 represents the marginal variance of Œ¥ z œÜ œÉ Œµ 2 describes the measurement error and œà represents the indicator function that equals one if i j and zero otherwise the model parameter Œ∏ and hyper parameters œÜ Œª œÉ 2 œÉ Œµ 2 can be jointly inferred using bayes theorem the prior probability is specified as p Œ∏ œÜ p Œ∏ p œÜ and the prior distributions of Œ∏ and œÜ are assumed to be independent the posterior probability can then be expressed as 23 p Œ∏ œÜ y p y Œ∏ œÜ p Œ∏ p œÜ the likelihood function p y Œ∏ œÜ can be described by the logarithmic form 24 log p y Œ∏ œÜ 1 2 y m Œ∏ Œº t c 1 y m Œ∏ Œº 1 2 l o g c n 2 l o g 2 œÄ as mentioned earlier this study adopted the dreamzs algorithm to calculate the posterior distribution of the model parameter Œ∏ and hyper parameters œÜ Œª œÉ 2 œÉ Œµ 2 to improve the computational efficiency of the dreamzs algorithm the ensemble of surrogates established in section 2 3 was used to replace the time consuming seepage forward model 3 case study to illustrate the validity and accuracy of the proposed method the d hydropower station in southwest china was selected as a case study for application 3 1 description of the study area the d hydropower station is a cascade hydropower station on the mainstream of the dadu river its predominant use is to generate electricity the hydropower station has a clay core wall dam with a dam crest elevation of 1385 50 m a maximum dam height of 79 50 m and a dam crest length of 526 7 m the hierarchical structure of the foundation rock is complex and mainly composed of diorite weakly weathered layer no unloading layer weak unloading layer strong unloading layer gravel layer 1 gravel layer 2 gravel layer 3 gravel layer 4 gravel layer 5 and gravel layer 6 the groundwater is mainly bedrock fissure water and pore water pore water occurs in the quaternary loose accumulation layer and local confined water appears near the boundary between the bedrock and overburden owing to the inhomogeneity of the overburden structure the bedrock fissure water mainly occurs in the weathered and unloaded fissure media along the banks of the river the groundwater level on both sides of the dam site is deep and the hydraulic slope of the groundwater is gentle the geological model of the study area is shown in fig 2 3 2 dataset generation and ensemble of surrogates construction in this study the hydraulic conductivities of the six gravel layers were inverted and analyzed as shown in fig 2 eight head monitoring locations are arranged downstream of the dam which are respectively denoted as m1 m2 m3 m4 m5 m6 m7 and m8 among them m1 m2 m6 and m7 monitor the head value of gravel layer 3 while m3 m4 m5 and m8 monitor the head value of gravel layer 1 in this case study each monitoring location will obtain one head monitoring value every day the head monitoring values of m1 m2 m3 m4 m5 and m6 on august 9 2018 were used as model calibration data while the head monitoring values of m7 and m8 on august 9 2018 were used as model validation data it was assumed that the hydraulic conductivities of the six gravel layers were homogeneous and their prior distributions follow a uniform random distribution the hydraulic conductivities of the foundation rock mass dam body and grouting curtains were obtained based on on site geological exploration data and laboratory test data as summarized in table 1 the steady state seepage numerical simulation was carried out under the water level condition on august 9 2018 that is the upstream and downstream water levels were 1368 92 m and 1306 01 m respectively in this study one forward run of the steady state seepage simulation model takes more than 4 h on a workstation 14 core w 2257 cpu 3 30 ghz processors for this large and complex model the latin hypercube sampling was used to sample 100 times within the range of the prior distributions as presented in table 1 thereby generating 100 sets of hydraulic conductivities the hydraulic conductivities of the six gravel layers were input into the seepage simulation model to obtain the corresponding head values of the eight monitoring locations the input hydraulic conductivities and corresponding head values of 100 model simulations had formed the dataset of the ensemble surrogate models the dataset was then randomly divided into a training dataset of 80 samples 80 of the samples and a testing dataset of 20 samples 20 of the samples based on the training dataset svr kriging and mars were trained to construct the ensemble of surrogates the improved d s evidence theory proposed in this study and the d s theory adopted by muller and piche 2011 were used to calculate the weights of svr kriging and mars respectively the specific calculation process of the weights is provide in appendix and the weight calculation results are presented in fig 3 it can be clearly seen that the weights of svr in fig 3 a and fig 3 b both are greater than those of kriging and mars indicating that the predicted value of svr fits best with the simulated values moreover compared with d s theory the improved d s theory gives greater weights to svr in fig 3 a the weight of kriging at m1 m2 m3 and m4 is higher than that of mars while the weight of kriging at m5 m6 m7 and m8 is lower than that of mars however in fig 3 b the weights of kriging at all measuring locations are lower than those of mars the weights obtained above were then adopted to establish the ensemble of surrogates 3 3 bayesian inversion of seepage parameters 3 3 1 setup of the bayesian inversion method in the process of bayesian inversion the prior distributions of the hydraulic conductivities of the six gravel layers were assumed to be uniformly distributed in the parameter space and the ranges of these uniform distributions were determined based on the values suggested in table 1 the prior distribution of the hyper parameter Œª was specified as a uniform distribution on 0 001 1 following the similar practice in xu et al 2017 according to the residual analysis results the prior distribution of the hyper parameter œÉ was assumed to be an exponential distribution with a mean of 15 and the range was set to 0 001 30 considering the measurement error of the water head measuring instrument in this case study a normal distribution with a mean of 0 and a standard deviation of 2 was defined as the prior distribution of the hyper parameter œÉŒµ and the range was set to 0 001 10 after defining the priors the dreamzs algorithm was adopted to evaluate the posterior probability distribution the number of parallel chains was set to four and the number of iterations was set to 10 000 the parallel search iterative process converged at around 6 000 iterations and the first 6 000 iterations were abandoned as burn in the last 4000 iterations were taken as samples of the posterior distributions of nine variables and each variable was statistically analysed based on these samples 3 3 2 inversion results of seepage parameters fig 4 shows the inversion results the posterior distributions of hydraulic conductivities k1 k3 and k4 have obvious peaks indicating that the uncertainties of gravel layers 1 3 and 4 are significantly reduced with the data support the posterior distributions of hydraulic conductivities k2 k5 and k6 are flat and the peaks are not obvious indicating that the identification of these parameters is poor and the uncertainties of these parameters are large this may be due to the lack of water head monitoring points in the distribution range of the gravel layers 2 5 and 6 and the water head monitoring data at other locations has no obvious effect on reducing the uncertainty of k2 k5 and k6 the hyper parameters œÜ Œª œÉ 2 œÉ Œµ 2 can also be jointly inverted with the hydraulic conductivities of the six gravel layers and their peak values are relatively obvious indicating that the uncertainties of these parameters are small 4 discussion 4 1 performance assessment of the surrogate models to evaluate the prediction performance of the individual surrogate models and the ensemble of surrogates the four performance indicators over the training dataset and testing dataset at eight monitoring locations were calculated as presented in tables 2 and 3 normally a model can be considered accurate if its r indicator is higher than 0 8 xing et al 2019 during the training period except for the r of mars at m3 which was less than 0 8 all the other r values were more than 0 8 further when the performance of the individual surrogate models was desirable the r values were more than 0 98 as mentioned earlier a particular surrogate model may have conflicting characteristics in terms of predictive performance indicators for example in terms of the rmse indicator at m2 mars had better prediction performance than kriging however the prediction performance of kriging was better than that of mars in terms of other indicators similar phenomena were observed at m2 m3 m4 m5 m6 m7 and m8 therefore it may not be reasonable to determine the weights of the surrogate models only based on a particular indicator to more accurately determine the weights of the surrogate models this study proposed an improved d s evidence theory based on the hellinger distance and deng entropy to fuse multiple prediction performance indicators and consider their interactions the performance indicators of the ensemble of surrogates are also listed in table 2 according to further comparisons and analyses the performances of the ensemble of surrogates es1 and es2 were closer to the best individual surrogate models at all monitoring locations during the testing period except for the r of kriging or mars at m1 m2 m4 and m7 which were less than 0 9 all the other r values were above 0 9 from the r indicator presented in table 3 the predicted results of the surrogate models were satisfactory in a more detailed comparison the svr models performed better than the kriging and mars models according to further comparisons and analyses the performances of es1 and es2 were closer to the best individual surrogate models at all monitoring locations moreover the r of es1 performed better than the best individual surrogate model except at m1 the rmse of es1 performed better than the other three individual surrogate models except for m1 and m2 the mae of es1 performed better than the other three individual surrogate models and es2 in addition at m2 the mad of es1 and es2 were superior to those of the individual models fig 5 shows the surrogate errors of the three individual surrogates and the two ensemble of surrogates on test samples the absolute error is adopted to quantify the surrogate error in this study as can be seen from fig 5 the median and mean of the absolute error of svr are the smallest among the three individual surrogate models which indicates that the predictive performance of svr is the best among the three models compared with kriging and mars the median and mean of the absolute error of es2 are closer to svr which indicates that the ensemble of surrogates improves the prediction accuracy of the individual models through further comparison and analysis it can be found that the median and mean of the absolute error of es1 are lower than those of es2 and closer to svr which indicates that the improved d s evidence theory proposed in this study can effectively improve the prediction accuracy of the ensemble of surrogates based on the traditional d s evidence theory to further verify the prediction advantage of es1 compared with es2 fig 6 shows the prediction performance improvement of es1 compared with es2 at each monitoring location during the testing period overall es1 has no obvious improvement in r but the improvements in rmse mae and mad are significant by further calculation compared with es2 the average improvements of es1 in r rmse mae and mad are 0 35 8 88 16 97 and 26 48 respectively thus es1 has a superior prediction performance compared to es2 overall the ensemble of surrogates performed better than the individual surrogate models therefore the ensemble of surrogates can substitute for the time consuming seepage simulation model in bayesian inversion in this study 4 2 discussion on inversion results of seepage parameters 4 2 1 computational efficiency compared with the seepage simulation model that runs for more than 4 h on a workstation the ensemble of surrogates takes only seconds to run at a time which makes bayesian invasion more efficient if the time cost of running the ensemble of surrogates and the associated bayesian inversion is neglected the main time cost is spent on 100 seepage model simulations to generate the training and testing dataset in this study the number of iterations of the dreamzs sampling procedure was set to 10 000 times which means that the ensemble of surrogates was called 10 000 times the ensemble of surrogates based bayesian inversion improved the inverse efficiency by 10 000 100 100 times compared to the traditional bayesian approach in this study hence the proposed ensemble of surrogates based bayesian inversion constitutes an invaluable means of saving time in the parameter inversion and the power of the proposed method can be more significant for more realistic and complicated seepage simulations 4 2 2 validation of inversion results to evaluate the accuracy of water head predictions the inferred posterior distributions of the water heads at eight monitoring locations were compared with their observations vertical black dashed dotted line the blue lines in fig 7 show the predictions of the water heads at eight monitoring locations without the consideration of the model structure error it can be seen that only the predicted water head distribution at m5 has a high probability density that is only the predicted water head at m5 has a high prediction accuracy and the predicted water head values at the other seven monitoring locations have significant deviations from their observations compared with the blue lines in fig 7 the red lines in fig 7 present the water head predictions inferred with the consideration of the model structure error it can be observed that all the water head predictions of the monitoring locations have a high probability density therefore it can be concluded that it is necessary to consider the model structure error during parameter inversion to significantly improve the accuracy of water head prediction at each monitoring location fig 8 presents the mean absolute deviation between the observations and predicted heads at eight monitoring locations based on the inversion results of the ensemble of surrogates and individual surrogate models at m1 m3 m5 and m8 the mean absolute deviations of the inversion results based on es1 are all smaller than those of the inversion results based on svr kriging and mars at m2 m4 m6 and m7 the mean absolute deviation of the es1 based inversion was also smaller than those of the kriging based inversion and the mars based inversion on the whole the inversion results based on the proposed ensemble of surrogates have a higher accuracy than the inversion results based on individual surrogate models moreover the mean absolute deviation of the inversion result based on es1 is smaller than that based on es2 at each measurement location which once again proves that the ensemble of surrogates based on the improved d s evidence theory proposed in this study is more accurate than the ensemble of surrogates based on the traditional d s evidence theory 5 conclusion accurate inversion of seepage parameters is of great significance for improving the accuracy of seepage numerical simulation to invert the seepage parameters accurately and efficiently an efficient bayesian inversion method for seepage parameters using a data driven error model and an ensemble of surrogates considering the interactions between prediction performance indicators was proposed in this study the major conclusions are as follows 1 a data driven error model based on gaussian process regression was adopted and integrated into bayesian inference to invert the seepage parameters and address the model structure error and at the same time the parameter uncertainty and measurement error were effectively considered 2 an ensemble of surrogates considering the interactions between prediction performance indicators was constructed to improve the computational efficiency of bayesian inversion in particular the weights of the surrogate models were determined by the improved d s evidence theory based on the hellinger distance and deng entropy which play a key role in fusing multiple prediction performance indicators while considering their interactions compared with the individual surrogate models the proposed ensemble of surrogates was found to be more accurate 3 the inversion study of a real engineering example further verified the accuracy and efficiency of the proposed method the inversion results of the proposed method demonstrated the necessity of addressing the model structure error and constructing an ensemble of surrogates considering the interactions between prediction performance indicators in the inversion process it is also important to recognize the limitations of the method proposed in this study first the number of water head monitoring points in this case study is limited in the future more monitoring points can be arranged in the real engineering and the arrangement of monitoring points can also be optimized according to the inversion results second the water head monitoring data of the monitoring locations on august 9 2018 were used to invert the hydraulic conductivities of the six gravel layers in this study however the head monitoring data obtained by most monitoring instruments is usually belong to time series data therefore how to effectively use these time series data to conduct inversion analysis of the hydraulic conductivity is a key issue to be addressed in our future research third this study assumes that the seepage parameters are homogeneous and future research can consider the spatial variability of the seepage parameters to obtain more realistic inversion results finally the inversion of seepage parameters in this study is based on the steady state seepage model the future research can also be combined with the transient seepage model under the condition of reservoir water level rising or falling to give full play to the potential of the proposed method credit authorship contribution statement hongling yu conceptualization methodology writing original draft writing review editing xiaoling wang supervision project administration project administration bingyu ren methodology software tuocheng zeng investigation data curation mingming lv formal analysis formal analysis cheng wang visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the yalong river joint funds of the national natural science foundation of china grant no u1865204 u1765205 appendix a brief illustrative example for the weight calculation based on the improved d s evidence theory here m1 is taken as an example to illustrate the weight calculation process of the ensemble of surrogates proposed in this study 1 establish bpa four prediction performance indicators of the three surrogate models namely r rmse mae and mad are obtained based on the training set as shown in table a1 the normalized treatment is conducted according to equation 7 to establish the bpa over the frame Œ∏ svr kriging mars a 1 a 2 a 3 m r m r a 1 0 3433 m r a 2 0 3393 m r a 3 0 3174 m rmse m rmse a 1 0 4822 m rmse a 2 0 2659 m rmse a 3 0 2519 m mae m mae a 1 0 4949 m mae a 2 0 2551 m mae a 3 0 2500 m mad m mad a 1 0 5631 m mad a 2 0 2399 m mad a 3 0 1970 2 calculate the similarity measure among the evidences based on the hellinger distance the hellinger distance matrix can be calculated as follows h 0 0 1000 0 1092 0 1581 0 1000 0 0 0100 0 0599 0 1092 0 0100 0 0 0529 0 1581 0 0599 0 0529 0 then the similarity measure matrix can be calculated as follows s 1 h 1 0 9000 0 8908 0 8419 0 9000 1 0 9900 0 9401 0 8908 0 9900 1 0 9471 0 8419 0 9401 0 9471 1 3 calculate the support degree and credibility of the evidence the support degree sup mi can be obtained through the similarity measure as follows s u p m r 1 0 9000 0 8908 0 8419 3 6327 s u p m rmse 0 9000 1 0 9900 0 9401 3 8301 s u p m mae 0 8908 0 9900 1 0 9471 3 8280 s u p m mad 0 8419 0 9401 0 9471 1 3 7291 the credibility crdi can then be obtained by normalizing the support degree as follows c r d m r 3 6327 3 6327 3 8301 3 8280 3 7280 0 2419 c r d m rmse 3 8301 3 6327 3 8301 3 8280 3 7280 0 2550 c r d m mae 3 8280 3 6327 3 8301 3 8280 3 7280 0 2549 c r d m mad 3 7280 3 6327 3 8301 3 8280 3 7280 0 2483 4 adjust the credibility of evidence based on deng entropy the deng entropy of each piece of evidence can be calculated as follows e d m r 0 3433 log 2 0 3433 2 1 0 3393 log 2 0 3393 2 1 0 3174 log 2 0 3174 2 1 1 5841 e d m rmse 0 4822 log 2 0 4822 2 1 0 2659 log 2 0 2659 2 1 0 2519 log 2 0 2519 2 1 1 5166 e d m mae 0 4949 log 2 0 4949 2 1 0 2551 log 2 0 2551 2 1 0 2500 log 2 0 2500 2 1 1 5050 e d m mad 0 5631 log 2 0 5631 2 1 0 2399 log 2 0 2399 2 1 0 1970 log 2 0 1970 2 1 1 4223 the credibility of the evidence can be adjusted according to the deng entropy of each piece of evidence as follows a c r d m r 0 2419 1 5841 0 3831 a c r d m rmse 0 2550 1 5166 0 3867 a c r d m mae 0 2549 1 5050 0 3836 a c r d m mad 0 2483 1 4223 0 3531 5 modify the evidences based on the weights of evidences the weight of each evidence can be obtained according to the adjusted credibility as follows w r 0 3831 0 3831 0 3867 0 3836 0 3531 0 2543 w rmse 0 3867 0 3831 0 3867 0 3836 0 3531 0 2567 w mae 0 3836 0 3831 0 3867 0 3836 0 3531 0 2546 w mad 0 3531 0 3831 0 3867 0 3836 0 3531 0 2344 then the initial evidence is modified through the weighted average m a 1 0 2543 0 3433 0 2567 0 4822 0 2546 0 4949 0 2344 0 5631 0 4691 m a 2 0 2543 0 3393 0 2567 0 2659 0 2546 0 2551 0 2344 0 2399 0 2757 m a 2 0 2543 0 3174 0 2567 0 2519 0 2546 0 2500 0 2344 0 1970 0 2552 6 evidence fusion calculations the modified evidence is combined 3 times according to dempster s combination rule and the fusion results are shown in table a2 the fusion results are the weight coefficients of the surrogate models which can be adopted to establish the ensemble of surrogates therefore for the ensemble of surrogates at m1 the weight coefficients of svr kriging and mars are 0 8285 0 0989 and 0 0726 respectively 
3803,the bayesian method has been increasingly applied to the inversion of seepage parameters owing to its superiority of considering the uncertainty in the inversion process however most of the current bayesian inversion studies only focus on parameter uncertainty ignoring the model structure error in addition existing research has mostly adopted a single machine learning algorithm or an ensemble of surrogates based on a single prediction performance indicator as a substitute for the seepage forward model and has not considered the interactions between multiple prediction performance indicators thereby leading to poor accuracy to address these issues this study proposed an efficient bayesian inversion method for seepage parameters using a data driven error model and an ensemble of surrogates considering the interactions between prediction performance indicators a data driven error model based on gaussian process regression was integrated into the bayesian inversion model to modify the likelihood function for dealing with the model structure error for determining the weight coefficients of the ensemble surrogates the improved dempster shafer d s evidence theory based on the hellinger distance and deng entropy was proposed to fuse multiple prediction performance indicators and consider their interactions further an ensemble of surrogates in conjunction with support vector regression kriging and multivariate adaptive regression splines was constructed through weighted summation the validity and accuracy of the proposed method were verified by applying it to a real hydropower station in china the results showed that the proposed method can significantly improve the accuracy and efficiency of bayesian inversion of seepage parameters the proposed method therefore serves as a new basis for the inversion of seepage parameters and can be applied to parameter inversion in other related fields keywords bayesian inversion data driven error model surrogate model dempster shafer evidence theory prediction performance indicator seepage parameter 1 introduction seepage problems have received significant attention in several engineering fields including groundwater remediation water pollution treatment hydropower station operation and fossil energy exploitation numerical simulation is an effective tool for understanding the complex seepage phenomena involved in these fields in a seepage numerical model determination of the seepage parameters e g hydraulic conductivities of aquifers is of great significance for obtaining accurate seepage simulation results one favoured method to determine the seepage parameters involves conducting inversion analysis according to the monitoring data such as the water head of the piezometer and the seepage flow among the existing parameter inversion methods the bayesian inversion method is a formal approach for parameter inversion and uncertainty assessment and has become increasingly popular in the fields of hydrology and geophysics han and zheng 2018 hassanzadeh et al 2019 jiang and ou 2017 ju et al 2020 liu et al 2017 rajabi and ataie ashtiani 2016 yan and zhou 2019 zhang et al 2016 although these studies have achieved promising results two key issues remain to be resolved first most studies have only concentrated on parameter uncertainty while ignoring model structure error which is often quite difficult to address liu et al 2019 another issue is the computational burden which is caused by the considerable number of repeated forward model calls for a posterior distribution to reach convergence chen et al 2018 currently some efforts have been made to solve the problem of model structure error in parameter inversion in general the approaches that have been presented so far can be divided into three categories the first category of approaches is multi model method which accounts for model structure uncertainty by recognizing and combining multiple competing model representations tasdighi et al 2018 xu et al 2017 however the multi model methods are related to the subjective choice of the independent model structures and model weights which may induce additional uncertainty in the inversion process xu and valocchi 2015a in the second category researchers simply treat the model structure error by adding a stochastic perturbation term to the model simulated states rather than designing a sophisticated method choi et al 2017 zhang and fu 2018 2019 however some researchers believe that this method may lead to an underestimation of the model structure error zhang et al 2019 data driven approaches based on machine learning algorithms for example gaussian process regression are the third category of approaches presented to address model structure error data driven approaches can learn complex functional relationships between output i e model structural error and inputs selected from historical data xu et al 2017 kennedy and o hagan 2001 first proposed a bayesian framework integrated with the gaussian progress regression to jointly infer the uncertain input parameters in a physically based model together with the model structure error their seminal work is known as the koh framework choi et al 2018 and has been applied and developed in several research fields including groundwater modelling xu and valocchi 2015b zhang et al 2019 pan et al 2020 thermal problems liu et al 2019 choi et al 2017 2018 and material models rappel et al 2019 in the abovementioned studies data driven approaches have demonstrated their effectiveness in dealing with model structure error inspired by previous studies this study also adopts a data driven approach based on gaussian progress regression to deal with the structure error in seepage parameter inversion in the bayesian inversion process hundreds of thousands of forward model calls are required for posterior distribution to reach convergence the computational expense for complex forward models may be prohibitively high in addition the joint inference of uncertain input parameters and model structure error may further increase the computational cost because of the increased dimension of the sampling space and the decreased convergence rate xu et al 2017 to address this problem surrogate models based on machine learning methods such as the response surface model rsm li et al 2019 radial basis function wu et al 2021 polynomial chaos expansion mohammadi et al 2021 kriging jiang et al 2020 svr xu et al 2017 and multivariate adaptive regression splines mars chen et al 2017b can be used to substitute computationally intensive forward models in many previous studies surrogate models were generally constructed based on an individual machine learning method however the performance of the individual machine learning method varies with the specific problem wang et al 2021 it is therefore difficult for an individual machine learning method to achieve optimal fitting of all simulation models this problem can be addressed by using an ensemble of surrogates which can be constructed by combining different machine learning methods via a weighted summation strategy determining the weight of each surrogate model is the most critical step when constructing an ensemble of surrogates to date various weight determination methods have been proposed for example the optimal weighted surrogate owsdiag proposed by viana et al 2009 is a commonly used weight determination method for constructing an ensemble of surrogates christelis et al 2019 dhamotharan et al 2018 ouyang et al 2017 yang et al 2018 in addition the set pair analysis hou et al 2017 yin and tsai 2020 bagging method chen et al 2017b 2018 gradient boosting approach queipo and nava 2019 adaptive metropolis markov chain monte carlo xing et al 2019 differential evolution tabu search de ts hybrid algorithm wang et al 2021 bayesian model averaging yin et al 2021 and minimization of local mean square error ye et al 2020 have all been proposed to construct the ensemble of surrogates however most previous studies have only determined the weights based on a certain prediction performance indicator for example correlation coefficient r or root mean squared error rmse and have ignored the interactions between multiple prediction performance indicators it must be noted that a particular surrogate model may have conflicting characteristics in terms of prediction performance indicators such as the correlation coefficient r root mean squared error rmse mean absolute error mae and median absolute deviation mad different weight coefficients can be obtained according to different performance indicators it is of great significance to determine more reliable weight coefficients by considering the interactions between multiple prediction performance indicators the dempster shafer d s evidence theory offers a method of integrating conflicting vague and uncertain information from diverse sources muller and piche 2011 roy and datta 2019 a variety of prediction performance indicators can therefore be integrated based on the d s evidence theory to obtain the weight coefficient of each single model muller and piche 2011 proposed an ensemble of surrogates based on the d s evidence theory for global optimization problems roy and datta 2019 2020 further extended the d s evidence theory to study seawater intrusion in coastal aquifers however in the abovementioned studies each evidence that is each prediction performance indicator is regarded as independent of each other without considering their similarity and uncertainty this can lead to information redundancy and an adverse impact on the calculation results of the weight coefficients similarity measures include the jensen shannon divergence xie et al 2020 jousselme distance fan et al 2020 cosine similarity dong et al 2018 minkowski distance chen et al 2017a and matusita distance ye et al 2018 the hellinger distance is a measure of the probability distribution similarity that can reflect the similarity of data distribution in contrast to other distance measurement methods the hellinger distance is more stable and reliable and can effectively measure the difference between probability distributions of random variables deng and wang 2020 in addition the uncertainty of the evidence itself is a very important property deng proposed the deng entropy as an extension of the shannon entropy deng 2016 the combination of deng entropy and the d s evidence theory can be used to effectively measure the uncertainty of the evidence thus realizing the credibility analysis and making the fusion result of the evidences more reasonable in view of the abovementioned research this study introduces the hellinger distance and deng entropy to improve the traditional d s evidence theory to consider the interactions between multiple prediction performance indicators and obtain more reasonable weight coefficients furthermore the ensemble of surrogates is constructed based on the improved d s evidence theory the main objective of this study was to invert the seepage parameters accurately and efficiently using the bayesian inversion method the main contributions of this study can be summarized as follows 1 a data driven error model based on gaussian process regression was adopted and integrated into bayesian inference to invert the seepage parameters and address the model structure error in the progress of seepage parameter inversion 2 an ensemble of surrogates that can combine the advantages of different machine learning algorithms was proposed to improve the computational efficiency of bayesian inversion 3 an improved d s evidence theory based on the hellinger distance and deng entropy was proposed to determine the weights of the surrogate models which could fuse multiple prediction performance indicators and consider their interactions thereby improving the accuracy of the ensemble of surrogates the remainder of this paper is organized as follows section 2 presents a brief introduction of the research framework of this study the ensemble of surrogates considering the interactions between prediction performance indicators and the bayesian inversion method with a data driven error model in section 3 the method proposed in this study is applied to a hydropower station in southwest china the prediction performance of the proposed ensemble of surrogates and the results of the seepage parameter inversion are discussed in section 4 finally the conclusions are drawn in section 5 2 methodology 2 1 research framework fig 1 shows the basic flowchart of the proposed method it comprises three main steps 1 dataset generation 2 construction of the ensemble of surrogates and 3 bayesian inversion using the data driven error model a detailed description of each step is provided below step 1 dataset generation the sample points of the seepage parameters were obtained through latin hypercube sampling lhs and then these sample points were input into the seepage model to obtain the simulated values at the monitoring locations the sample points of the seepage parameters and the simulated values of the monitoring locations constitute the dataset of the ensemble of surrogates from which the training and testing sets were divided step 2 construction of the ensemble of surrogates to make full use of the prediction advantages of different machine learning algorithms and improve the prediction accuracy three machine learning algorithms namely svr kriging and mars were trained according to the training set to build the ensemble of surrogates determining the weight coefficient of each model is a key step in constructing an ensemble of surrogates to comprehensively consider the interactions between various performance indicators namely r rmse mae and mad an improved d s evidence theory based on the hellinger distance and deng entropy was proposed to determine the weight coefficients furthermore the ensemble of surrogates was established by weighted summation step 3 bayesian inversion using the data driven error model before bayesian inversion the prior distribution of the parameters and monitoring values were set to obtain more reliable inversion results a data driven error model based on gaussian process regression was adopted to deal with the model structure error because it is difficult to directly solve the bayesian formula of the parameter posterior distribution the markov chain monte carlo sampling method dreamzs algorithm was selected in this study was used to solve the posterior distribution of parameters to improve the efficiency of the inversion calculation the ensemble of surrogates established in step 2 was used to replace the computation time consuming seepage forward model 2 2 seepage simulation model the seepage simulation model is the basis of the ensemble surrogate models and bayesian inversion model the governing partial differential equation for the steady state seepage can be expressed as follows 1 x k x h x y k y h y z k z h z 0 where h is the hydraulic head kx ky and kz are the hydraulic conductivity in x y and z directions respectively in this study the finite volume method in the software star ccm 10 02 was used to obtain the numerical solution of equation 1 for the computation of the free surface flow determining the saturated surface is the key step since the volume of fluid vof method proposed by hirt and nichols 1981 can quickly capture the sharp fluid interface and reduce numerical diffusion and complicated geometrical reconstruction near the interface cheng et al 2018 this method was adopted in this study to obtain the saturated surface the basic principle of the vof method is to determine the position and shape of the saturated surface through solving the function f which is defined as the ratio of fluid volume over the total volume in a computational cell zhong et al 2013 in the vof method the saturated surface can be captured by solving the following equation 2 f t u f 0 where t is the time u is the superficial velocity vector of the computational cell which can be calculated as follows 3 u œÅ u where u is the real seepage velocity vector in the pores œÅ is the porosity of the porous media 2 3 ensemble of surrogates considering the interactions between prediction performance indicators 2 3 1 ensemble of surrogates in this study three widely used surrogate models namely svr kriging and mars were adopted to construct an ensemble of surrogates svr was selected because of its ability to efficiently capture the complex relationship between the input and output from small sample data kriging has beneficial interpolating capabilities in approximating deterministic computer simulations christelis et al 2019 mars is a rapid flexible adaptive and nonparametric approach for developing regression models roy and datta 2019 the ensemble of surrogates can be expressed as follows 4 f en x i 1 3 w i f i x 5 i 1 3 w i 1 where fen x is the predicted value of the ensemble of surrogates fi x i 1 2 3 are the predicted values of the three surrogate models in the ensemble x is the vector of design variables and wi i 1 2 3 are the weight coefficients of svr kriging and mars respectively detailed descriptions of svr kriging and mars can be found in the work of cheng et al 2017 toal and keane 2013 and chen et al 2018 therefore these descriptions are not repeated herein in this study the improved dempster shafer d s evidence theory based on the hellinger distance and deng entropy was proposed as a weight determination method to construct ensembles of surrogates considering the interactions between prediction performance indicators 2 3 2 dempster shafer evidence theory in the dempster shafer d s evidence theory the basic probability assignment bpa function m a is the fundamental method of expressing uncertainty roy and datta 2019 for each subset a of frame Œ∏ a 1 a 2 a n the bpa function m a is defined as the mapping m 2Œ∏ 0 1 similar to the probability theory the sum of bpa equals one in this study the frame can be represented as Œ∏ svr kriging mars a 1 a 2 a 3 four performance indicators of surrogate models based on the training dataset namely the correlation coefficient r root mean squared error rmse mean absolute error mae and median absolute deviation mad were adopted as four pieces of evidence for the d s evidence theory then the basic probability assignments bpas in the frame can be expressed as follows 6 m r m r a 1 m r a 2 m r a 3 m rmse m rmse a 1 m rmse a 2 m rmse a 3 m mae m mae a 1 m mae a 2 m mae a 3 m mad m mad a 1 m mad a 2 m mad a 3 ideally the best surrogate model should have higher values of r and lower values of rmse mae and mad roy and datta 2019 these performance indicators then need to be normalized to satisfy the condition that the sum of bpa values over the frame Œ∏ must be equal one namely k 1 3 m r a k 1 k 1 3 m rmse a k 1 k 1 3 m mae a k 1 and k 1 3 m mad a k 1 the calculation formulae for the normalization can be expressed as follows 7 m r a k r k k 1 3 r k m rmse a k 1 rmse k k 1 3 1 rmse k m mae a k 1 mae k k 1 3 1 mae k m mad a k 1 mad k k 1 3 1 mad k where rk rmsek maek and madk represent the four prediction performance indicators of the kth individual surrogate model the bpa functions can be combined using dempster s rule of combination which can be expressed as follows 8 m a a k a i 1 n m i a k 1 t a 0 a 9 t a k i 1 n m i a k where represents the null set t is the conflict coefficient that measures the degree of the conflict between pieces of evidence and n represents the number of pieces of evidence which is taken as four in this study 2 3 3 improved dempster shafer evidence theory based on the hellinger distance and deng entropy in order to consider the interactions between multiple prediction performance indicators and obtain more reasonable weight coefficients this study introduced the hellinger distance and deng entropy to measure the similarity between evidences and the uncertainty of the evidences to realize an improvement of the traditional d s evidence theory the specific steps of the improved d s evidence theory based on the hellinger distance and deng entropy proposed in this study are as follows 1 establish bpa four prediction performance indicators of the three surrogate models namely r rmse mae and mad were obtained based on the training set and normalized treatment was conducted according to equation 7 to establish the bpa of the d s evidence theory 2 calculate the similarity measure among the evidences based on the hellinger distance for the two random variables p p 1 p 2 pk and q q 1 q 2 qk the hellinger distance is expressed as follows 10 h p q 1 2 i 1 k p i q i 2 where k represents the sample size of the random variables the hellinger distance satisfies the following characteristics 1 the value range of h p q is 0 1 2 h p q is symmetric and non negative that is h p q h q p 0 the smaller the hellinger distance between the evidences the higher the similarity between the evidences and the greater the degree of mutual support the hellinger distance between each piece of evidence can be calculated according to eq 10 and the hellinger distance matrix in this study can be expressed as follows 11 h 0 h m 1 m 2 h m 1 m 3 h m 1 m 4 h m 2 m 1 0 h m 2 m 3 h m 2 m 4 h m 3 m 1 h m 3 m 2 0 h m 3 m 4 h m 4 m 1 h m 4 m 2 h m 4 m 3 0 the similarity measure between two pieces of evidence mi and mj can be defined as follows 12 s ij m i m j 1 h m i m j i j 1 2 3 4 then the similarity measure matrix in this study can be expressed as follows 13 s 1 1 h m 1 m 2 1 h m 1 m 3 1 h m 1 m 4 1 h m 2 m 1 1 1 h m 2 m 3 1 h m 2 m 4 1 h m 3 m 1 1 h m 3 m 2 1 1 h m 3 m 4 1 h m 4 m 1 1 h m 4 m 2 1 h m 4 m 3 1 3 calculate the support degree and credibility of the evidence the support degree reflects the degree to which evidence is supported by other evidences the greater the similarity between evidences the higher the support degree of the evidences therefore the support degree sup mi can be obtained through the similarity measure as follows 14 s u p m i j 1 j i 4 s ij m i m j i j 1 2 3 4 the credibility crdi can then be obtained by normalizing the support degree as follows 15 crd i sup m i i 1 4 s u p m i 1 i 4 4 adjust the credibility of evidence based on deng entropy deng entropy is an extension of shannon entropy which can effectively measure the uncertainty of information deng entropy is defined as follows 16 e di k 1 3 m i a k l o g m i a k 2 a k 1 1 i 4 where ak is the cardinality of set ak when evidence has a high deng entropy it indicates that the evidence contains more information and can be better supported by other evidences therefore the evidence with a high deng entropy plays an important role in the final combination and carries a large weight the credibility of the evidence can be adjusted according to the deng entropy of each evidence as follows 17 acrd i crd i e di 1 i 4 5 modify the evidences based on the weights of evidences the weight of each evidence can be obtained according to the adjusted credibility as follows 18 w i acrd i i 1 4 acrd i 1 i 4 then the initial evidence is modified through the weighted average the weighted average evidence w a e m a k can be obtained as follows 19 w a e m a k i 1 4 w i m i a k 6 evidence fusion calculations the modified evidence is combined n 1 n is the number of the pieces of evidence which is taken as four in this study times according to dempster s combination rule to obtain the fusion results the fusion results are the weight coefficients of the surrogate models which can be introduced into equation 4 to establish the ensemble of surrogates 2 4 bayesian inversion method with data driven error model based on bayes theorem the posterior distribution p Œ∏ y of the model parameter Œ∏ can be expressed as follows 20 p Œ∏ y p y Œ∏ p Œ∏ p y Œ∏ p Œ∏ d Œ∏ where p Œ∏ is the prior distribution of parameter Œ∏ y is the monitoring value and p y Œ∏ is the likelihood function obtaining an analytical expression of the posterior distribution p Œ∏ y is difficult an effective method is to construct a posterior distribution using markov chain monte carlo mcmc sampling the dreamzs algorithm laloy and vrugt 2012 vrugt 2016 was adopted in this study existing bayesian methods can deal with the measurement error and parameter uncertainty by assuming the error structure of residuals and bayesian inference respectively in mcmc pan et al 2020 however most existing bayesian methods ignore the model structure error because it is usually more difficult to address than parameter uncertainty to quantify the model structure error the relationship between the monitoring value y and the simulated value of model m Œ∏ can be expressed as follows 21 y m Œ∏ Œ¥ z œÜ Œµ where Œ¥ z œÜ represents the model structure error z represents the input of the model which consists of the physically based model outputs and the locations of the monitoring points in this study œÜ represents the tuning parameters and Œµ represents the measurement error Œµ is a random vector that follows an independent and identical gaussian distribution Œµ n 0 œÉ Œµ 2 œÉ Œµ 2 can be determined according to the error of the monitoring instrument in this study a data driven error model based on gaussian process regression is adopted to characterize the model structure error more details on the introduction of gaussian process regression can be found in xu and valocchi 2015a without loss of generality this study provides only a brief introduction the prior distribution of the model structure error Œ¥ z œÜ is usually assumed to obey a multivariate gaussian distribution n Œº c the gaussian process regression is specified by a mean function Œº m e Œ¥ z and a covariance function c k z z e Œ¥ z Œº z Œ¥ z Œº z in this study the mean function is set to a constant zero and the squared exponential covariance function is adopted 22 k z i z j œÉ 2 e x p z i z j t z i z j Œª 2 œÉ Œµ 2 œà i j 1 2 n where Œª is the characteristic length scale œÉ 2 represents the marginal variance of Œ¥ z œÜ œÉ Œµ 2 describes the measurement error and œà represents the indicator function that equals one if i j and zero otherwise the model parameter Œ∏ and hyper parameters œÜ Œª œÉ 2 œÉ Œµ 2 can be jointly inferred using bayes theorem the prior probability is specified as p Œ∏ œÜ p Œ∏ p œÜ and the prior distributions of Œ∏ and œÜ are assumed to be independent the posterior probability can then be expressed as 23 p Œ∏ œÜ y p y Œ∏ œÜ p Œ∏ p œÜ the likelihood function p y Œ∏ œÜ can be described by the logarithmic form 24 log p y Œ∏ œÜ 1 2 y m Œ∏ Œº t c 1 y m Œ∏ Œº 1 2 l o g c n 2 l o g 2 œÄ as mentioned earlier this study adopted the dreamzs algorithm to calculate the posterior distribution of the model parameter Œ∏ and hyper parameters œÜ Œª œÉ 2 œÉ Œµ 2 to improve the computational efficiency of the dreamzs algorithm the ensemble of surrogates established in section 2 3 was used to replace the time consuming seepage forward model 3 case study to illustrate the validity and accuracy of the proposed method the d hydropower station in southwest china was selected as a case study for application 3 1 description of the study area the d hydropower station is a cascade hydropower station on the mainstream of the dadu river its predominant use is to generate electricity the hydropower station has a clay core wall dam with a dam crest elevation of 1385 50 m a maximum dam height of 79 50 m and a dam crest length of 526 7 m the hierarchical structure of the foundation rock is complex and mainly composed of diorite weakly weathered layer no unloading layer weak unloading layer strong unloading layer gravel layer 1 gravel layer 2 gravel layer 3 gravel layer 4 gravel layer 5 and gravel layer 6 the groundwater is mainly bedrock fissure water and pore water pore water occurs in the quaternary loose accumulation layer and local confined water appears near the boundary between the bedrock and overburden owing to the inhomogeneity of the overburden structure the bedrock fissure water mainly occurs in the weathered and unloaded fissure media along the banks of the river the groundwater level on both sides of the dam site is deep and the hydraulic slope of the groundwater is gentle the geological model of the study area is shown in fig 2 3 2 dataset generation and ensemble of surrogates construction in this study the hydraulic conductivities of the six gravel layers were inverted and analyzed as shown in fig 2 eight head monitoring locations are arranged downstream of the dam which are respectively denoted as m1 m2 m3 m4 m5 m6 m7 and m8 among them m1 m2 m6 and m7 monitor the head value of gravel layer 3 while m3 m4 m5 and m8 monitor the head value of gravel layer 1 in this case study each monitoring location will obtain one head monitoring value every day the head monitoring values of m1 m2 m3 m4 m5 and m6 on august 9 2018 were used as model calibration data while the head monitoring values of m7 and m8 on august 9 2018 were used as model validation data it was assumed that the hydraulic conductivities of the six gravel layers were homogeneous and their prior distributions follow a uniform random distribution the hydraulic conductivities of the foundation rock mass dam body and grouting curtains were obtained based on on site geological exploration data and laboratory test data as summarized in table 1 the steady state seepage numerical simulation was carried out under the water level condition on august 9 2018 that is the upstream and downstream water levels were 1368 92 m and 1306 01 m respectively in this study one forward run of the steady state seepage simulation model takes more than 4 h on a workstation 14 core w 2257 cpu 3 30 ghz processors for this large and complex model the latin hypercube sampling was used to sample 100 times within the range of the prior distributions as presented in table 1 thereby generating 100 sets of hydraulic conductivities the hydraulic conductivities of the six gravel layers were input into the seepage simulation model to obtain the corresponding head values of the eight monitoring locations the input hydraulic conductivities and corresponding head values of 100 model simulations had formed the dataset of the ensemble surrogate models the dataset was then randomly divided into a training dataset of 80 samples 80 of the samples and a testing dataset of 20 samples 20 of the samples based on the training dataset svr kriging and mars were trained to construct the ensemble of surrogates the improved d s evidence theory proposed in this study and the d s theory adopted by muller and piche 2011 were used to calculate the weights of svr kriging and mars respectively the specific calculation process of the weights is provide in appendix and the weight calculation results are presented in fig 3 it can be clearly seen that the weights of svr in fig 3 a and fig 3 b both are greater than those of kriging and mars indicating that the predicted value of svr fits best with the simulated values moreover compared with d s theory the improved d s theory gives greater weights to svr in fig 3 a the weight of kriging at m1 m2 m3 and m4 is higher than that of mars while the weight of kriging at m5 m6 m7 and m8 is lower than that of mars however in fig 3 b the weights of kriging at all measuring locations are lower than those of mars the weights obtained above were then adopted to establish the ensemble of surrogates 3 3 bayesian inversion of seepage parameters 3 3 1 setup of the bayesian inversion method in the process of bayesian inversion the prior distributions of the hydraulic conductivities of the six gravel layers were assumed to be uniformly distributed in the parameter space and the ranges of these uniform distributions were determined based on the values suggested in table 1 the prior distribution of the hyper parameter Œª was specified as a uniform distribution on 0 001 1 following the similar practice in xu et al 2017 according to the residual analysis results the prior distribution of the hyper parameter œÉ was assumed to be an exponential distribution with a mean of 15 and the range was set to 0 001 30 considering the measurement error of the water head measuring instrument in this case study a normal distribution with a mean of 0 and a standard deviation of 2 was defined as the prior distribution of the hyper parameter œÉŒµ and the range was set to 0 001 10 after defining the priors the dreamzs algorithm was adopted to evaluate the posterior probability distribution the number of parallel chains was set to four and the number of iterations was set to 10 000 the parallel search iterative process converged at around 6 000 iterations and the first 6 000 iterations were abandoned as burn in the last 4000 iterations were taken as samples of the posterior distributions of nine variables and each variable was statistically analysed based on these samples 3 3 2 inversion results of seepage parameters fig 4 shows the inversion results the posterior distributions of hydraulic conductivities k1 k3 and k4 have obvious peaks indicating that the uncertainties of gravel layers 1 3 and 4 are significantly reduced with the data support the posterior distributions of hydraulic conductivities k2 k5 and k6 are flat and the peaks are not obvious indicating that the identification of these parameters is poor and the uncertainties of these parameters are large this may be due to the lack of water head monitoring points in the distribution range of the gravel layers 2 5 and 6 and the water head monitoring data at other locations has no obvious effect on reducing the uncertainty of k2 k5 and k6 the hyper parameters œÜ Œª œÉ 2 œÉ Œµ 2 can also be jointly inverted with the hydraulic conductivities of the six gravel layers and their peak values are relatively obvious indicating that the uncertainties of these parameters are small 4 discussion 4 1 performance assessment of the surrogate models to evaluate the prediction performance of the individual surrogate models and the ensemble of surrogates the four performance indicators over the training dataset and testing dataset at eight monitoring locations were calculated as presented in tables 2 and 3 normally a model can be considered accurate if its r indicator is higher than 0 8 xing et al 2019 during the training period except for the r of mars at m3 which was less than 0 8 all the other r values were more than 0 8 further when the performance of the individual surrogate models was desirable the r values were more than 0 98 as mentioned earlier a particular surrogate model may have conflicting characteristics in terms of predictive performance indicators for example in terms of the rmse indicator at m2 mars had better prediction performance than kriging however the prediction performance of kriging was better than that of mars in terms of other indicators similar phenomena were observed at m2 m3 m4 m5 m6 m7 and m8 therefore it may not be reasonable to determine the weights of the surrogate models only based on a particular indicator to more accurately determine the weights of the surrogate models this study proposed an improved d s evidence theory based on the hellinger distance and deng entropy to fuse multiple prediction performance indicators and consider their interactions the performance indicators of the ensemble of surrogates are also listed in table 2 according to further comparisons and analyses the performances of the ensemble of surrogates es1 and es2 were closer to the best individual surrogate models at all monitoring locations during the testing period except for the r of kriging or mars at m1 m2 m4 and m7 which were less than 0 9 all the other r values were above 0 9 from the r indicator presented in table 3 the predicted results of the surrogate models were satisfactory in a more detailed comparison the svr models performed better than the kriging and mars models according to further comparisons and analyses the performances of es1 and es2 were closer to the best individual surrogate models at all monitoring locations moreover the r of es1 performed better than the best individual surrogate model except at m1 the rmse of es1 performed better than the other three individual surrogate models except for m1 and m2 the mae of es1 performed better than the other three individual surrogate models and es2 in addition at m2 the mad of es1 and es2 were superior to those of the individual models fig 5 shows the surrogate errors of the three individual surrogates and the two ensemble of surrogates on test samples the absolute error is adopted to quantify the surrogate error in this study as can be seen from fig 5 the median and mean of the absolute error of svr are the smallest among the three individual surrogate models which indicates that the predictive performance of svr is the best among the three models compared with kriging and mars the median and mean of the absolute error of es2 are closer to svr which indicates that the ensemble of surrogates improves the prediction accuracy of the individual models through further comparison and analysis it can be found that the median and mean of the absolute error of es1 are lower than those of es2 and closer to svr which indicates that the improved d s evidence theory proposed in this study can effectively improve the prediction accuracy of the ensemble of surrogates based on the traditional d s evidence theory to further verify the prediction advantage of es1 compared with es2 fig 6 shows the prediction performance improvement of es1 compared with es2 at each monitoring location during the testing period overall es1 has no obvious improvement in r but the improvements in rmse mae and mad are significant by further calculation compared with es2 the average improvements of es1 in r rmse mae and mad are 0 35 8 88 16 97 and 26 48 respectively thus es1 has a superior prediction performance compared to es2 overall the ensemble of surrogates performed better than the individual surrogate models therefore the ensemble of surrogates can substitute for the time consuming seepage simulation model in bayesian inversion in this study 4 2 discussion on inversion results of seepage parameters 4 2 1 computational efficiency compared with the seepage simulation model that runs for more than 4 h on a workstation the ensemble of surrogates takes only seconds to run at a time which makes bayesian invasion more efficient if the time cost of running the ensemble of surrogates and the associated bayesian inversion is neglected the main time cost is spent on 100 seepage model simulations to generate the training and testing dataset in this study the number of iterations of the dreamzs sampling procedure was set to 10 000 times which means that the ensemble of surrogates was called 10 000 times the ensemble of surrogates based bayesian inversion improved the inverse efficiency by 10 000 100 100 times compared to the traditional bayesian approach in this study hence the proposed ensemble of surrogates based bayesian inversion constitutes an invaluable means of saving time in the parameter inversion and the power of the proposed method can be more significant for more realistic and complicated seepage simulations 4 2 2 validation of inversion results to evaluate the accuracy of water head predictions the inferred posterior distributions of the water heads at eight monitoring locations were compared with their observations vertical black dashed dotted line the blue lines in fig 7 show the predictions of the water heads at eight monitoring locations without the consideration of the model structure error it can be seen that only the predicted water head distribution at m5 has a high probability density that is only the predicted water head at m5 has a high prediction accuracy and the predicted water head values at the other seven monitoring locations have significant deviations from their observations compared with the blue lines in fig 7 the red lines in fig 7 present the water head predictions inferred with the consideration of the model structure error it can be observed that all the water head predictions of the monitoring locations have a high probability density therefore it can be concluded that it is necessary to consider the model structure error during parameter inversion to significantly improve the accuracy of water head prediction at each monitoring location fig 8 presents the mean absolute deviation between the observations and predicted heads at eight monitoring locations based on the inversion results of the ensemble of surrogates and individual surrogate models at m1 m3 m5 and m8 the mean absolute deviations of the inversion results based on es1 are all smaller than those of the inversion results based on svr kriging and mars at m2 m4 m6 and m7 the mean absolute deviation of the es1 based inversion was also smaller than those of the kriging based inversion and the mars based inversion on the whole the inversion results based on the proposed ensemble of surrogates have a higher accuracy than the inversion results based on individual surrogate models moreover the mean absolute deviation of the inversion result based on es1 is smaller than that based on es2 at each measurement location which once again proves that the ensemble of surrogates based on the improved d s evidence theory proposed in this study is more accurate than the ensemble of surrogates based on the traditional d s evidence theory 5 conclusion accurate inversion of seepage parameters is of great significance for improving the accuracy of seepage numerical simulation to invert the seepage parameters accurately and efficiently an efficient bayesian inversion method for seepage parameters using a data driven error model and an ensemble of surrogates considering the interactions between prediction performance indicators was proposed in this study the major conclusions are as follows 1 a data driven error model based on gaussian process regression was adopted and integrated into bayesian inference to invert the seepage parameters and address the model structure error and at the same time the parameter uncertainty and measurement error were effectively considered 2 an ensemble of surrogates considering the interactions between prediction performance indicators was constructed to improve the computational efficiency of bayesian inversion in particular the weights of the surrogate models were determined by the improved d s evidence theory based on the hellinger distance and deng entropy which play a key role in fusing multiple prediction performance indicators while considering their interactions compared with the individual surrogate models the proposed ensemble of surrogates was found to be more accurate 3 the inversion study of a real engineering example further verified the accuracy and efficiency of the proposed method the inversion results of the proposed method demonstrated the necessity of addressing the model structure error and constructing an ensemble of surrogates considering the interactions between prediction performance indicators in the inversion process it is also important to recognize the limitations of the method proposed in this study first the number of water head monitoring points in this case study is limited in the future more monitoring points can be arranged in the real engineering and the arrangement of monitoring points can also be optimized according to the inversion results second the water head monitoring data of the monitoring locations on august 9 2018 were used to invert the hydraulic conductivities of the six gravel layers in this study however the head monitoring data obtained by most monitoring instruments is usually belong to time series data therefore how to effectively use these time series data to conduct inversion analysis of the hydraulic conductivity is a key issue to be addressed in our future research third this study assumes that the seepage parameters are homogeneous and future research can consider the spatial variability of the seepage parameters to obtain more realistic inversion results finally the inversion of seepage parameters in this study is based on the steady state seepage model the future research can also be combined with the transient seepage model under the condition of reservoir water level rising or falling to give full play to the potential of the proposed method credit authorship contribution statement hongling yu conceptualization methodology writing original draft writing review editing xiaoling wang supervision project administration project administration bingyu ren methodology software tuocheng zeng investigation data curation mingming lv formal analysis formal analysis cheng wang visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the yalong river joint funds of the national natural science foundation of china grant no u1865204 u1765205 appendix a brief illustrative example for the weight calculation based on the improved d s evidence theory here m1 is taken as an example to illustrate the weight calculation process of the ensemble of surrogates proposed in this study 1 establish bpa four prediction performance indicators of the three surrogate models namely r rmse mae and mad are obtained based on the training set as shown in table a1 the normalized treatment is conducted according to equation 7 to establish the bpa over the frame Œ∏ svr kriging mars a 1 a 2 a 3 m r m r a 1 0 3433 m r a 2 0 3393 m r a 3 0 3174 m rmse m rmse a 1 0 4822 m rmse a 2 0 2659 m rmse a 3 0 2519 m mae m mae a 1 0 4949 m mae a 2 0 2551 m mae a 3 0 2500 m mad m mad a 1 0 5631 m mad a 2 0 2399 m mad a 3 0 1970 2 calculate the similarity measure among the evidences based on the hellinger distance the hellinger distance matrix can be calculated as follows h 0 0 1000 0 1092 0 1581 0 1000 0 0 0100 0 0599 0 1092 0 0100 0 0 0529 0 1581 0 0599 0 0529 0 then the similarity measure matrix can be calculated as follows s 1 h 1 0 9000 0 8908 0 8419 0 9000 1 0 9900 0 9401 0 8908 0 9900 1 0 9471 0 8419 0 9401 0 9471 1 3 calculate the support degree and credibility of the evidence the support degree sup mi can be obtained through the similarity measure as follows s u p m r 1 0 9000 0 8908 0 8419 3 6327 s u p m rmse 0 9000 1 0 9900 0 9401 3 8301 s u p m mae 0 8908 0 9900 1 0 9471 3 8280 s u p m mad 0 8419 0 9401 0 9471 1 3 7291 the credibility crdi can then be obtained by normalizing the support degree as follows c r d m r 3 6327 3 6327 3 8301 3 8280 3 7280 0 2419 c r d m rmse 3 8301 3 6327 3 8301 3 8280 3 7280 0 2550 c r d m mae 3 8280 3 6327 3 8301 3 8280 3 7280 0 2549 c r d m mad 3 7280 3 6327 3 8301 3 8280 3 7280 0 2483 4 adjust the credibility of evidence based on deng entropy the deng entropy of each piece of evidence can be calculated as follows e d m r 0 3433 log 2 0 3433 2 1 0 3393 log 2 0 3393 2 1 0 3174 log 2 0 3174 2 1 1 5841 e d m rmse 0 4822 log 2 0 4822 2 1 0 2659 log 2 0 2659 2 1 0 2519 log 2 0 2519 2 1 1 5166 e d m mae 0 4949 log 2 0 4949 2 1 0 2551 log 2 0 2551 2 1 0 2500 log 2 0 2500 2 1 1 5050 e d m mad 0 5631 log 2 0 5631 2 1 0 2399 log 2 0 2399 2 1 0 1970 log 2 0 1970 2 1 1 4223 the credibility of the evidence can be adjusted according to the deng entropy of each piece of evidence as follows a c r d m r 0 2419 1 5841 0 3831 a c r d m rmse 0 2550 1 5166 0 3867 a c r d m mae 0 2549 1 5050 0 3836 a c r d m mad 0 2483 1 4223 0 3531 5 modify the evidences based on the weights of evidences the weight of each evidence can be obtained according to the adjusted credibility as follows w r 0 3831 0 3831 0 3867 0 3836 0 3531 0 2543 w rmse 0 3867 0 3831 0 3867 0 3836 0 3531 0 2567 w mae 0 3836 0 3831 0 3867 0 3836 0 3531 0 2546 w mad 0 3531 0 3831 0 3867 0 3836 0 3531 0 2344 then the initial evidence is modified through the weighted average m a 1 0 2543 0 3433 0 2567 0 4822 0 2546 0 4949 0 2344 0 5631 0 4691 m a 2 0 2543 0 3393 0 2567 0 2659 0 2546 0 2551 0 2344 0 2399 0 2757 m a 2 0 2543 0 3174 0 2567 0 2519 0 2546 0 2500 0 2344 0 1970 0 2552 6 evidence fusion calculations the modified evidence is combined 3 times according to dempster s combination rule and the fusion results are shown in table a2 the fusion results are the weight coefficients of the surrogate models which can be adopted to establish the ensemble of surrogates therefore for the ensemble of surrogates at m1 the weight coefficients of svr kriging and mars are 0 8285 0 0989 and 0 0726 respectively 
3804,the overwhelming increase and variations in the extreme rainfall events demand the use of a nonstationary intensity duration frequency idf curve for the design and management of water resource infrastructure generally nonstationary idf curves are developed by incorporating the trend in the distribution parameter using generalized extreme value distribution gev with time as a covariate the physical processes influencing the variations in a hydrologic variable can be captured by utilizing relevant climatic variables climate informed as covariates since time alone cannot be the best covariate hence this study investigates the potential climate informed covariates influencing the extreme rainfall and incorporates the best covariates to develop a realistic nonstationary idf relationship unlike previous studies a time sliding window tsw approach is employed to detect the changing distribution parameters before performing nonstationary modeling nsm the proposed covariate based tsw nsm is effectively used to construct idf curves for seven major metropolitan cities of india several models are generated based on the detected changing parameters and combinations of covariates then bayesian differential evolutionary monte carlo de mc algorithm is employed to estimate the uncertainty bound of the nonstationary parameters and the best model is chosen using the deviance information criterion dic the results reveal that the best covariate combinations for short duration events are dominated by local processes i e local temperature changes and diurnal temperature changes whereas the same for longer duration events are dominated by the global processes global warming enso modoki cycle and iod however the acceptable nonstationary models reveal that all the temperature based covariates are capable of capturing the dynamic behavior it is also observed that the local processes carry the signature of global processes finally the return levels computed through the best nonstationary model show that the return periods are decreasing and the short duration events have undergone drastic changes than the longer duration events thus the results suggest that employing climate informed covariates based nonstationary idf curves is indispensable for devising long term strategies to address the changing climate keywords non stationarity bayesian inference climate informed covariates return level 1 introduction the design and construction of engineering infrastructure often need information about the behavior of the natural climate system especially of its extremes it has been established that the characteristics of these extremes majorly of two dominant hydrologic variables precipitation and temperature have considerably changed in the past century alexander et al 2006 goswami et al 2006 according to the intergovernmental panel on climate change assessment report 5 ipcc 2012 the rise in the global surface temperature is likely to exceed 2 c by the end of the 21st century the rising temperature increases the atmosphere s water holding capacity by about 7 per 1 c thereby influencing the precipitation directly cheng and aghakouchak 2015 trenberth 2011 and rising its intensity giorgi et al 2011 detailed investigations of historical regional precipitation around different parts of the globe revealed a higher rate of increase in extreme precipitation when compared to that of average precipitation in the recent decades alexander et al 2006 ganguli and coulibaly 2017 vinnarasi and dhanya 2016 vittal et al 2013 because of this altered scenario high intensity short duration rainfall events have become more prevalent and hence pose a severe threat to both infrastructure and crops leading to substantial social and economic loss worldwide these facts raise significant concerns on the endurance of the existing planned urban infrastructures and water resources systems to the variations anticipated in the extreme events conventionally engineering design operation of structures like municipal stormwater network and various water resources projects are based on intensity duration frequency idf curve to ensure the serviceability cheng and aghakouchak 2015 yilmaz and perera 2014 idf curve is a standard tool derived from historical rainfall series to estimate the design rainfall intensity for a given duration and provides information about regional rainfall extremes idf curves are mathematical relationship among the rainfall intensity duration and frequency koutsoyiannis et al 1998 which can be constructed either through empirical relationship babu et al 1979 kothyari and garde 1993 sherman 1931 or frequency analysis chow et al 1988 hershfield 1961 linsley et al 1975 in the case of empirical formula the constants vary spatially singh and zhang 2007 however the validity of these constants under a changing climate is questionable on the other hand in frequency analysis the idf curves are constructed by fitting the block or partial maximum rainfall intensities for specific durations e g 1 hr 2 hr 3 hr 6 hr etc into the theoretical probabilistic distribution roshan et al 2014 further koutsoyiannis et al 1998 developed a semi empirical approach which is a mathematical framework based on probability distribution for regionalization of idf relationships in general the probabilistic distributions are assumed to be stationary i e the distribution parameters do not change with respect to time nevertheless as mentioned before it has been observed that the characteristics of extreme precipitation have altered significantly over time and the stationarity based idf curve approach often underestimates the return level cheng and aghakouchak 2015 sugahara et al 2009 this questions the reliability of stationary assumption for such applications and demands the incorporation of dynamic behavior into the distribution parameters cheng et al 2014 coles 2001 sarhadi and soulis 2017 in general non stationarity in extreme event modeling is addressed by expressing the distribution parameters as a linear or non linear function of covariates cheng et al 2014 kwon and lall 2016 sarhadi et al 2016 the covariates can be either time or physical processes like hydro meteorological variables or low frequency climatological signals coles 2001 katz et al 2002 while time is the frequently employed covariate sugahara et al 2009 yilmaz and perera 2014 this approach is further enhanced to assess the uncertainty in the nonstationary parameters through bayesian inference cheng and aghakouchak 2015 sarhadi and soulis 2017 some studies argue that the incorporation of non stationarity in extreme event modeling koutsoyiannis 2011 koutsoyiannis and montanari 2014 adds to the uncertainty since the nonstationary modeling includes the changes merely based on the trend in the hydrologic variable these changes may also be due to physical processes ragno et al 2019 serinaldi and kilsby 2015 and hence incorporating the relevant physical processes in extreme event modeling is beneficial montanari and koutsoyiannis 2014 ragno et al 2019 numerous studies have established the relationship between various physical processes and extreme rainfall events mondal and mujumdar mondal and mujumdar 2015 showed that the changes in extreme rainfall over india are due to local temperature changes global warming and the el ni√±o southern oscillation enso cycle local temperature changes are analysed using the local temperature anomaly which is based on surface air temperature however recent studies observed a strong influence of diurnal temperature range integrated water vapour and dew point temperature on extreme precipitation changes rather than the surface air temperature which questions the reliability of clausius clayepron relation ali and mishra 2017 he et al 2015 roderick et al 2020 zhang et al 2019 besides these processes urbanization and various teleconnections like southern oscillation index soi enso cycle el ni√±o southern oscillation modoki enso modoki indian ocean dipole iod etc are found to have impact on the extreme precipitation ashok et al 2007 2001 vittal et al 2013 hence these climatic variables when used as covariates are termed as climate informed covariates thus far nonstationary modeling using climate informed covariates is explored only by few studies bracken et al 2018 li et al 2015 ragno et al 2019 risser and wehner 2017 steirou et al 2018 zhang et al 2015 especially in the case idf curves agilan and umamahesh 2017a 2017b sarhadi and soulis 2017 sarhadi and soulis sarhadi and soulis 2017 used time and soi as covariates for 911 stations over the great lakes and found time as the best covariate for a majority of stations and soi as the best covariate for a few stations however they did not conduct a detailed analysis involving other physical processes affecting precipitation as covariates agilan and umamahesh agilan and umamahesh 2017a used five different covariates for developing idf curves for a single location and found that the dominant covariates for short duration rainfall intensity are local processes such as urbanization and local temperature changes whereas the same for long duration rainfall intensities are global processes like the enso cycle iod and global warming they addressed the non stationarity based on the trend in the extreme rainfall series by incorporating change in either location or combination of location and scale parameter which produced 62 combination of models while in another study agilan and umamahesh 2017b for the same location they addressed non stationarity only in location parameter using 27 covariates and reported that the best covariate for longer duration rainfall is the local process total precipitation one of the reasons for variation in the results of these studies is the lack of knowledge about the nonstationary distribution parameters as to which parameter location scale both should be modeled as nonstationary hence in order to bring realism into covariate based nonstationary modeling this study adopts a robust time sliding window tsw approach to model extreme rainfall intensity proposed by vinnarasi and dhanya vinnarasi and dhanya 2019 tsw nonstationary modeling tsw nsm is capable of detecting the signature of non stationarity in the distribution parameter and reduces the complexity involved in the traditional approach vinnarasi and dhanya 2019 moreover the relation between the local and global processes on the impact of changing extreme precipitation characteristics are yet to be explored it should also be noted that increasing the number of covariates necessarily increases the uncertainty and the computation effort by increasing the number of combinations therefore the potential covariates should be chosen utmost carefully before the modeling in this study we investigate the best climate informed covariate from the basket of potential covariates that influence extreme rainfall intensity and are expected to comprehend the physical phenomenon behind the changing characteristics of extreme precipitation the potential covariates are selected based on thorough literature review finally the best climate informed covariate is used to develop the nonstationary univariate idf relationship utilizing a robust bayesian inference based tsw nsm the proposed framework is demonstrated for seven major cities in india which are chosen based on the availability of data and the need of nonstationary idf relationship for proper water resource planning and infrastructure design 2 study area and data description the proposed nonstationary idf curve framework is implemented over seven major metropolitan cities in india namely bengaluru formerly bangalore mumbai formerly bombay kolkata formerly calcutta chennai formerly madras hyderabad pune and nagpur according to the koppen geiger classification all these cities belong to warm humid regions except hyderabad and pune which falls under semi arid regions peel et al 2007 among all these cities bombay receives the highest annual average rainfall of 2167 mm whereas bangalore calcutta madras hyderabad pune nagpur receive an annual average rainfall of 865 mm 1603 mm and 1355 mm respectively bombay pune nagpur hyderabad and calcutta receive a significant part of rainfall during the southwest monsoon june to september while madras receives heavy rainfall during the northeast monsoon october to december on the other hand bangalore receives rainfall from both northeast and southwest monsoons rapid urbanization accompanied by the exponential population growth in these cities necessitates the design and construction of new state of the art infrastructure to meet the increasing demands in addition to this the impact of the recent flood events in bombay 2005 and madras 2015 evidently reveals the inadequacy of the existing water resource planning and infrastructure the autographic hourly rainfall data procured from the indian meteorological department imd is used in this study the station number duration of the data available information about missing data and the geographic locations of the stations are given in table 1 from the hourly rainfall series the annual maximum rainfall series corresponding to different durations i e 1 hr 2 hr 6 hr 12 hr 18 hr 24 hr and 48 hr are extracted for each station a set of appropriate covariates is then selected for developing nonstationary idf curves initially temperature based covariates are selected since they are generally attributed to the rise of extreme precipitation events allan and soden 2008 soden et al 2005 trenberth 2011 recently agilan and umamahesh agilan and umamahesh 2017a and mondal and mujumdar mondal and mujumdar 2015 inferred that local temperature anomaly lta which expresses the local surface temperature changes and global temperature anomaly gta which expresses the global warming are the best temperature based covariates to develop nonstationary idf curves apart from these two covariates the present study includes diurnal temperature range dtr which is the difference between daily maximum and minimum temperature any changes in dtr are known to have a direct impact on the precipitation he et al 2015 zhou et al 2009 since dtr incorporates urbanization changes in soil moisture dew point temperature wind speed and humidity effects and dtr is found to be significantly influenced by the regional climate over indian sub continent vinnarasi et al 2017 the daily 1 1 gridded mean maximum and minimum temperature data prepared by the national climatic centre ncc imd for the period of 1951 2013 is used to extract lta and dtr the spatial domain of this gridded data set is 7 5 n to 37 5 n and 67 5 e to 97 5 e covering the mainland region of india this data is interpolated to the respective location of each station to extract the respective daily mean minimum and maximum temperature further to represent global warming hadcrut4 yearly observed global temperature anomaly gta is used which is available at https www metoffice gov uk hadobs hadcrut4 recently many studies observed that the influence of enso on indian monsoon is reducing annamalai et al 2007 kumar 1999 while the influence of iod and enso modoki on extreme indian monsoon rainfall is increasing ashok et al 2007 ashok and yamagata 2009 ratnam et al 2010 and the indian summer monsoon rainfall ismr is intensified weakened by the positive negative dipole index ashok et al 2001 further it is observed that iod has strongly modulated the extreme rainfall characteristics over india ajayamohan and a rao 2008 due to greenhouse warming the frequency of extreme iod events are increasing cai et al 2014 which in turn alters the frequency of extreme rainfall recently agilan and umamahesh agilan and umamahesh 2017a have used iod as one of the covariates to construct nonstationary idf curves likewise enso modoki a recently identified phenomenon different from enso is associated with the strong anomalous warming in central tropical pacific and cooling in the eastern and western tropical pacific ashok et al 2007 it causes subsidence over the indian subcontinent due to the modification in the walker circulation over the tropical and subtropical pacific ratnam et al 2010 recent studies show that the frequency of enso modoki is increasing seow 2018 and has a strong correlation to extreme rainfall over india dandi et al 2020 hence enso modoki and iod are considered as covariates in addition to lta gta and dtr iod is quantified through dipole mode index dmi which is the difference of area averaged sea surface temperature anomaly ssta between the tropical western indian ocean 50 e 70 e 10 s 10 n and the tropical southeastern indian ocean 90 e 110 e 10 s equator saji et al 1999 in this study gisst dataset is used to derive the monthly dmi which is downloaded from http www jamstec go jp frcgc research d1 iod iod observations s html en yearly dmi is computed by averaging the monthly dmi from june to november agilan and umamahesh 2017a enso modoki index emi is extracted using sea surface temperature sst using eq 1 1 emi ssta a 0 5 ssta b 0 5 ssta c where ssta a s s t a b and s s t a c are derived from the area averaged sst over each of the regions a 165 e 140 w 10 s 10 n b 110 w 70 w 15 s 5 n and c 125 e 145 e 10 s 20 n respectively ashok et al 2007 the monthly emi data is directly downloaded from http www jamstec go jp frsgc research d1 iod data emi monthly txt overall five physical processes namely local temperature changes global warming diurnal temperature changes enso modoki cycle iod and their combinations are used as covariates additionally time is considered as a covariate to develop the nonstationary idf curves 3 methodology initially the annual maximum rainfall intensity series x t x 1 x 2 x t is formed using the annual maximum rainfall extracted for different durations which are independent and identically distributed random variables generalized extreme value gev distribution which comprises of three extreme value distributions gumbel fr√©chet and weibull coles 2001 are the best to model annual maximum series based on the extreme value theory the major steps involved in constructing the climate informed covariate based nonstationary idf curve are outlined below 1 time sliding window approach is used to detect the non stationarity in each distribution parameter of the series for each duration 2 different nonstationary extreme event models are developed using different combinations of five physical processes local temperature changes global warming enso modoki index iod and dtr as covariates for the distribution parameter 3 the nonstationary idf curve is constructed after identifying the best extreme event model best covariate the overall procedure is depicted in fig 1 each major step mentioned above is briefly described below 3 1 detection of non stationarity after extraction of the extreme rainfall intensity series for different durations the non stationarity in the distribution parameter of each series is detected using tsw approach proposed by vinnarasi and dhanya 2019 the detailed procedure of tsw is described below 1 the extreme rainfall intensity series for each duration is reconstructed into many realizations using a pre defined time sliding window of length m for example extreme rainfall intensity series of 1 hour duration x d 1 t x 1 x 2 x t is divided into many realizations r 1 r 2 r t m as follows r 1 x 1 x 2 x m r 2 x 2 x 3 x m 1 r t m x t m x t m 1 x t 2 each realization is fitted into the gev distribution and the distribution parameters are computed using the maximum likelihood estimate the cumulative distribution function is given as 2 f gev r 1 Œº r 1 œÉ r 1 Œæ r 1 e x p 1 Œæ r 1 Œº œÉ 1 Œæ where Œº œÉ Œæ are the location scale and shape parameters respectively the distribution is defined on the set x 1 Œæ x Œº œÉ 0 and the parameters should satisfy the following criterion Œº œÉ 0 Œæ the log likelihood for the gev distribution is 3 log l Œº r 1 œÉ r 1 Œæ r 1 r 1 n log œÉ 1 1 Œæ i 1 n log 1 Œæ x i Œº œÉ i 1 n 1 Œæ x i Œº œÉ 1 Œæ the maximum likelihood can be estimated by maximizing the equation 3 with respect to the parameter vector 4 a new parameter series is constructed using the parameters obtained from each realization as Œº Œº r 1 Œº r 2 Œº rn m 5 using a non parametric moving block bootstrap mann kendall test the significant trend of each parameter series is computed 5 if any parameter shows a significant trend it is considered as changing parameter Œº t and is modeled using a linear trend Œº t Œº 1 Œº 2 c whereas the remaining parameters are considered as time invariant kept as constant 3 2 nonstationary extreme event model as mentioned earlier gev distribution is chosen to model the extreme rainfall intensities traditionally the parameters Œº œÉ Œæ of the gev distributions are assumed to be stationary i e the parameters are kept constant however under nonstationary conditions the parameters are time dependent based on this a time varying extreme event model is developed in which the parameters are expressed as a linear function of a covariate the cumulative distribution of gev distribution for the nonstationary case is given as 4 f x t x t Œº t œÉ t Œæ t e x p 1 Œæ t x t Œº t œÉ t 1 Œæ as discussed earlier in section 3 1 only those parameters which show significant trend are modeled as nonstationary linearly related to covariate while the other parameters are considered as constant however the shape parameter is kept as constant for all the cases since it requires long term observations to model it accurately cheng et al 2014 ganguli and coulibaly 2017 five physical processes and time are used as the covariates to define a linear function of the changing distribution parameters the changing location and scale parameters with time as a covariate is expressed as Œº t Œº t 1 Œº t 2 t and œÉ i t e œÉ i 1 t œÉ i 2 t the same can be expressed in terms of other covariates instead of time thus different combinations of nonstationary models are developed in terms of the detected changing parameter as listed in table s1 of the supplementary information here we restrict the nonstationary distribution parameters to a simple linear model to avoid the complexity and uncertainty due to the additional parameters luke et al 2017 serinaldi and kilsby 2015 further to estimate the parameters with uncertainty bound a robust bayesian inference framework is used renard et al 2013 which is a preferred method to analyse sparse data chandra et al 2015 coles et al 2003 huard et al 2010 and is widely used to model dynamic behavior agilan and umamahesh 2017b cheng et al 2014 cheng and aghakouchak 2015 kwon and lall 2016 sarhadi et al 2016 sarhadi and soulis 2017 bayesian inference combines the knowledge carried by the likelihood function of the annual maximum series and prior distribution through bayes theorem the posterior distribution using bayesian inference is given as 5 p œÜ x p œÜ l œÜ x the likelihood function is computed using 6 l œÜ x i 1 n p x i œÜ where p œÜ is the prior distribution of the parameter l œÜ x is the likelihood function i e œÜ is the parameter of the gev distribution in this study weak informative normal distribution i e a normal distribution with large variance n 0 1000 is chosen for location and scale parameters which uses the knowledge from the observations cheng et al 2014 gelman et al 2014 for the shape parameter the informative normal distribution with 0 3 standard deviation is used renard et al 2013 for instance the posterior distribution of extreme rainfall intensity for 1 hr duration considering significant dynamic behavior in location parameter expressed as a function of five covariates is given as 7 Œº t Œº 1 Œº 2 c 1 Œº 3 c 2 Œº 4 c 3 Œº 5 c 4 Œº 6 c 5 8 p œÜ d 1 x d 1 p œÜ d 1 i 1 n p x d 1 œÜ d 1 where œÜ d 1 Œº 1 Œº 2 Œº 3 Œº 4 Œº 5 Œº 6 œÉ Œ∫ to estimate the distribution parameters bayesian inference is implemented through differential evolution markov chain de mc algorithm which integrates differential evolution de learning strategy and monte carlo markov chain mcmc simulation employing metropolis hastings algorithm for sampling cheng and aghakouchak 2015 ter braak 2006 ter braak and vrugt 2008 vrugt et al 2009 additionally the convergence of the posterior distribution is estimated using a statistical criterion known as r gelman and shirley 2011 the value of r is checked whether it is 1 1 otherwise the sampling is done again by running a new set of initial values the best model is selected using deviance information criterion dic which is specially designed for model selection and comparison with respective to bayesian inference the model corresponding to the minimum dic is considered as the best model 3 3 construction of nonstationary idf curves after identifying the best nonstationary model the nonstationary return level is computed using the parameters of the best nonstationary model the estimation of return level in a nonstationary context is a crucial step since the distribution parameters change over time in this study we employ design exceedance probability to estimate the return level for developing the idf curve where the return level is computed using a selected percentile value of the changing parameter as suggested by cheng et al cheng et al 2014 the 95th percentile of the changing parameter which is considered as low risk more conservative is chosen for instance the 95th percentile of the changing location parameter Œº is expressed as Œº 95 q 95 Œº 1 Œº 2 Œº t further the nonstationary return level of maximum intensity associated with a t year return period for different storm durations is estimated by inverting the cumulative distribution function of gev distribution i e extreme quantiles as given below 9 x p Œº 95 œÉ 95 Œæ 1 log 1 p Œæ f o r Œæ 0 Œº 95 œÉ 95 log log 1 p f o r Œæ 0 where p is the exceedance probability of occurrence the return level x p for particular t year return period refers to the annual maximum rainfall for particular intensity and duration having a probability of exceedance 1 t hence the return level is computed as a function of return period t where t 1 p 4 results and discussion 4 1 nonstationary extreme event model annual maximum rainfall intensity series are generated for eight different storm durations i e 1 hr 2 hr 3 hr 6 hr 12 hr 18 hr 24 hr and 48 hr the statistics of each series for each station are shown in fig s1 bombay receives the highest average 1 hr rainfall with a maximum intensity of 55 85 mm hr among all other stations since the trend in the extreme intensity series may not reveal the actual trend in the distribution parameters the trend in the time series is not evaluated the detection of nonstationary parameters and the selection of the best nonstationary extreme event model is discussed below 4 1 1 detecting and estimating nonstationary parameters the signature of non stationarity is detected in the distribution parameter series instead of the annual maximum rainfall series as mentioned in section 3 1 for this purpose tsw is employed to capture the nonstationary behavior in the extreme rainfall intensity series of eight different durations for the seven stations total 56 cases each series is segmented into many realizations using a 20 year time sliding window since the data is not available for a longer duration and a minimum of 20 years parameter series is required to perform trend analysis 30 year window can be used if longer duration data is available the distribution parameters i e location scale and shape parameter of each realization is computed by fitting it into the gev distribution then the parameter series for a specific case duration and location is constructed by arranging the respective parameter of each realization non parametric moving block bootstrap mann kendall test is used to test the significance of the trend in the parameter series at various significance levels as shown in table 2 any change in the location parameter has more impact on the mean of the time series though the change in all these three parameters contributes to the change in the mean likewise change in scale or shape parameter has more impact on the variance the change in the mean or variance will intensify the tail of the distribution the results show that all the seven stations have undergone changes which clearly questions the reliability of stationary assumption in case of bangalore and bombay both location and scale parameters exhibit an increasing trend which can be inferred as the positive shift in the mean i e increase in high rainfall intensity and longer spread of the events increase in the probability of both extreme tails of the distribution the observed changes in the distribution parameters of these cities may be attributed to rapid urbanization nagendra et al 2014 and the closeness to the arabian sea which is reportedly getting warmer in recent decades kothawale et al 2008 likewise the probabilistic characteristics of longer duration rainfall intensities of madras and nagpur are strengthened as reflected from the increasing trend in the location and scale parameters the short duration rainfall intensity in madras has undergone changes only in the scale parameter whereas nagpur shows a negative change in location parameter and positive change in scale parameter it is worthy to note that the changes in the scale parameter is expected to alter the spread of the extreme events moreover the observed negative trends in the location parameter of 2 hr 3 hr and 6 hr durations for madras will result in the shortening of the spread of events also the observed positive trend in the scale parameter of 1 hr duration may indicate an increase in the spread of the events interestingly no changes are observed in 1hr and 3hr durations in hyderabad 2 hr and 3 hr durations in calcutta to avoid the ambiguity in the results we have kept 1 to 3 hr duration of calcutta and hyderabad as stationary and it is also noted that the changes observed in 2 hr of hyderabad and 1 hr of calcutta is weakly significant for longer duration hyderabad exhibits a negative positive change in location scale parameter on the contrary decreasing trends in the distribution parameters are observed in calcutta and pune in case of calcutta the negative changes are more predominant in scale parameter however no changes are observed for 2 hr and 3 hr durations whereas pune exhibit negative trend in both scale and location parameter the observed decreasing trend in the distribution parameters of calcutta and pune is expected to shrink the spread of the extreme events which in turn will reduce the extreme rainfall though the global factor for all the stations remain the same the contradictory pattern in the local parameters among the stations clearly indicates that local processes work in tandem with the global processes at regional scale highlighting that the covariates are region specific overall it can be inferred that the scale parameter has undergone more changes than the location parameter which clearly reveal that the spread distribution of the events has undergone more alteration than the total amount of rainfall goswami et al 2006 vinnarasi and dhanya 2016 vittal et al 2013 after detecting the changing distribution parameters it is necessary to model the nonstationary parameter as a function of covariate s as shown in table s1 32 different combinations of nonstationary linear regression models are developed based on five physical processes and time as a covariate to compare the nonstationary model with the stationary model a separate model with a constant parameter is developed i e a total of 33 models are developed for each duration of each station the distribution parameter of each model is estimated along with their uncertainty bound using bayesian inference employing the demc metropolis hastings algorithm in this study five markov chains are generated with five thousand samples in each chain the first 1000 samples are discarded as the burn in period the remaining samples are used to compute the distribution parameters only if the samples converge hence the convergence statistics r are monitored and assured to be less than 1 1 the convergence of the posterior sample is further ensured by observing the trace plot and the posterior distribution as an illustration the trace plot and posterior distribution of extreme rainfall intensity for 1 hr duration for bangalore station are shown in fig 2 which shows no upward or downward trend in the posterior sample and the distribution is also not centered at zero for brevity the remaining cases are not shown in this article 4 1 2 selection of best covariate once the nonstationary parameters are detected the nonstationary model with the best combination of covariates is assessed using dic before constructing the idf curve the model having the least dic value i e Œ¥ d i c 0 is considered as the best while Œ¥ d i c i e the difference in the dic value of any model with that of the best model lesser than 2 is also considered as a reasonable choice spiegelhalter et al 2002 the dic value and Œ¥ d i c of each model for 1 hr duration of all seven stations are summarized in table 3 all acceptable models reasonable choices and the best model are highlighted in italics and boldface respectively m26 is found to be the best model for 1 hr duration in bangalore madras and nagpur whereas m24 and m8 are the best for bombay and pune respectively interestingly except pune the best model for 1 hr duration for other stations are the combination of lta and dtr with some global processes i e lta dtr emi for bangalore madras and nagpur and lta dtr gta for bombay whereas for pune the best nonstationary model is based emi and gta it can be noted that the other acceptable models for 1 hr duration are also a combination of both local and global processes these results clearly indicate that the temperature based local process covariates like lta and dtr have more influence on 1 hr duration in consistent with the previous studies agilan and umamahesh 2017a kishtawal et al 2010 mondal and mujumdar 2015 vittal et al 2013 which highlights that the short duration high intensity rainfall is chiefly due to the change in the regional temperature the nonstationary extreme event models for other durations are summarized in table s2 s8 of the supplementary material results reveal that the influence of the global processes gradually increases with the increase in duration for instance the best covariate model of 24 hr and 48 hr for bangalore is m8 and m30 respectively which are entirely based on global processes whereas in the other stations local processes along with global processes forms best covariate especially most predominant covariate is gta however some of the acceptable models are entirely based on local processes underlining that the local processes cannot be overlooked indicating that the local processes carry the signature of global processes the increase in the number of acceptable models increases the uncertainty range in the estimation of return level the cumulative distribution function cdf plots for all acceptable models along with parameter uncertainty bounds of best model for 24 hr duration of all the stations fig 3 shows that the covariate uncertainty in all the cases are within the parameter uncertainty in other words the uncertainty due to parameters is more than that of the covariate therefore the best nonstationary model is considered for the remaining analysis the same deduction is made for the remaining durations as shown in figs s2 to s8 of the supplementary information the best nonstationary model for each station and each duration is shown in fig 4 among the 32 cases time based nonstationary model qualifies as the best only for 2 hr duration of bombay best model 24 hr duration of madras acceptable model and 1 and 2 hr duration of pune acceptable model overall it can be inferred that temperature based covariates i e lta dtr and gta as separate or as combinations have more influence on the trend of the changing parameter than the teleconnections and are indispensable in modeling the dynamic behavior of extreme rainfall intensities this suggests that in the absence of investigation for best covariates temperature based indices can be reasonably employed as covariates for modelling since they are in the acceptable models this also confirms the clausius clapeyron relation which states that the increase in temperature increases the moisture holding capacity of the atmosphere which further influences the intensity of precipitation giorgi et al 2011 however the observed results also highlight that the model based on lta alone is not good to model temporal changes of extreme rainfall which again supports that the surface air temperature alone is not a good covariate to project the extreme rainfall changes roderick et al 2020 further the goodness of fit for the best nonstationary model is examined through pp probability probability and qq quantile quantile plots these plots for 24 hr duration rainfall are shown in fig 5 and fig 6 respectively the same for other durations are given in figs s9 s22 of supplementary information from these plots it is observed that the best nonstationary model is able to capture the extreme rainfall intensities besides the pdf plots of best nonstationary and stationary model shown in fig 7 for 6 hr duration the nonstationary model clearly reveal the positive negative shift in the mean and lengthening shortening in the spread of events the efficiency of the tsw approach is demonstrated in the fact that it requires only 33 models to be developed to capture the appropriate changing parameter whereas the traditional nonstationary model requires 97 models to be developed this is achieved in the present approach by circumventing the nonstationary modeling of insignificant distribution parameters thereby reducing the complexity and improving the computational efficiency it further emphasizes that neglecting nonstationary model based on the physical process like meteorological variables or low frequency signals will under overestimate the risk of extreme events agilan and umamahesh 2017b sarhadi and soulis 2017 4 2 nonstationary idf curves the nonstationary idf curves for 2 year 5 year 20 year 25 year 50 year and 100 year return periods are constructed using the best nonstationary models the nonstationary idf curve for bombay clearly reveals that the stationary idf curves underestimate extreme events as shown in fig 8 for instance the return level of 1 hr duration event with 2 year return period for the nonstationary model is 60 83 mm hr whereas the same for the stationary model is 55 83 mm hr with a difference of about 5 081 mm hr 12 similarly for a 1 hr event with a 10 year return period the difference between nonstationary 101 89 mm hr and stationary 90 46 mm hr model is 11 51 mm hr 13 it should be noted that a difference of 11 51 mm hr would result in a significant increase in the flood it can also be observed that stationary return level of 1 hr duration for 10 year return period is roughly equal to the nonstationary return level 84 89 mm hr of 1 hr duration with 5 year return period which clearly indicates that the return period is decreasing while the return level is increasing therefore the existing infrastructure designed based on the stationary return level in bombay will suffer underestimation of the actual flood risk and hence especially the present storm drainage system in bombay may not be able to handle the expected frequent flood events gupta 2007 the difference between the nonstationary and stationary return levels for different return periods for bombay is shown in fig 9 which shows that this difference decreases as the duration increases which further demonstrates that short duration high intensity rainfall has increased in recent decades this can be attributed to the clausius clapeyron dependence which implies that increasing temperature causes convective rainfall with high intensity and short duration giorgi et al 2011 similarly idf curves are developed for other stations and shown in figs s23 to s34 since the intensification is more for 1 hr duration the return level for various return periods of 1 hr duration for bangalore bombay madras nagpur and pune are shown in fig 10 bangalore madras and nagpur also exhibit similar behavior to bombay increase in the nonstationary return level than the stationary return level i e the median and quantiles of the nonstationary return level are above zero except for short duration intensities in madras on the contrary pune shows a decrease in the nonstationary return level i e the quantiles are below zero fig 10e as reported in the previous studies sen roy 2009 though remarkable changes were not observed in the short duration rainfall events of calcutta there is a decrease in the nonstationary return level for higher duration rainfall events fig s30 this may be due to the cooling reduced warming of surface air temperature in calcutta ross et al 2018 overall it is inferred that the nature of extremes is dynamic due to the warming climate the observed changes in the return level of each station exactly correlate with the temperature variations over the region which highlights that temperature based indices are the best covariates to model nonstationary idf curves to validate this the study area is further extended to entire india using 0 25 0 25 gridded daily rainfall data provided by imd due to the unavailability of data longer than 30 years the analysis is carried out for 24 hr duration only the results observed over entire india corroborates with the observations for higher duration in the seven cities considered in this study refer to the supporting information text s1 however the choice of covariate cannot be concluded merely based on information criteria but requires numerical model which will aid understanding the physical phenomena behind these changes and reduce the covariate uncertainty further the reliability of stationary extreme event modeling is questionable which either underestimates or overestimates the risk of extreme events and should not be recommended for infrastructure planning and design though the proposed approach is superior to the traditional approaches by capturing the temporal dynamics and effectively incorporating them in the modelling a mathematical framework for idf curve cannot be developed based on only seven locations therefore the analysis of the spatial distribution of best covariate and developing a mathematical relation would be a possible future work that allows the extrapolation of the time varying idf beyond the observed durations 5 conclusions the increase in the frequency of the short duration high intensity rainfall events in the recent decades and the influence of climatic processes on the extreme precipitation have motivated the authors to develop the climate informed covariate based nonstationary intensity duration frequency idf curves for seven metropolitan cities of india bombay bangalore calcutta hyderabad madras nagpur and pune the influence of climatic variables on the distribution of precipitation extremes is investigated using a site specific nonstationary model nsm which utilizes a time sliding window tsw approach to detect non stationarity and bayesian inference to model the parameter uncertainty only the distribution parameters that have a signature of significant non stationarity are modeled as a linear function of the covariate while the other parameters are kept constant a total of 32 nonstationary gev models are developed for each storm duration and for each station with all possible combinations of five climatic variables local temperature changes lta diurnal extremes changes dtr global warming gta enso modoki cycle emi and indian ocean dipole iod then the best climate informed nonstationary model is selected based on deviance information criteria dic this study reveals that all four cities exhibit significant non stationarity in the distribution parameters it is found that temperature based covariates like lta dtr and gta have more influence on the rainfall intensities except calcutta and pune where teleconnections especially iod and emi respectively play a significant role however in both calcutta and pune temperature based covariate models are also acceptable while time did not qualify as the best covariate for any of the cases except for 12 hr duration in bombay the stationary model underestimates the return level for bangalore bombay hyderabad madras and nagpur whereas in calcutta and pune it overestimates it can also be noted that the rate of increase in temperature is high in all the cities except calcutta which could also be a reason for the contrast behavior of calcutta when compared to other stations the following conclusions are derived based on this study 1 the non stationarity in the scale parameter spread of the events of extreme rainfall intensity was detected and modeled which would have been overlooked by traditional nsm 2 the precipitation extremes are strongly influenced by the warming climate even if a suitable teleconnection is not known temperature based covariates can be used to develop appropriate idf curves 3 it is evident that the nonstationary model based on climate variables as covariates will improve the accuracy of nonstationary idf curves 4 ignoring the non stationarity in the return level will underestimate the risk of extreme events especially that of short durations and lead to the failure of water resources systems and infrastructure 5 design and construction practices for water resource infrastructures should be updated by adopting non stationarity based idf curves in order to mitigate the expected flood events in the future credit authorship contribution statement r vinnarasi conceptualization methodology formal analysis visualization writing original draft c t dhanya conceptualization investigation visualization supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127178 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3804,the overwhelming increase and variations in the extreme rainfall events demand the use of a nonstationary intensity duration frequency idf curve for the design and management of water resource infrastructure generally nonstationary idf curves are developed by incorporating the trend in the distribution parameter using generalized extreme value distribution gev with time as a covariate the physical processes influencing the variations in a hydrologic variable can be captured by utilizing relevant climatic variables climate informed as covariates since time alone cannot be the best covariate hence this study investigates the potential climate informed covariates influencing the extreme rainfall and incorporates the best covariates to develop a realistic nonstationary idf relationship unlike previous studies a time sliding window tsw approach is employed to detect the changing distribution parameters before performing nonstationary modeling nsm the proposed covariate based tsw nsm is effectively used to construct idf curves for seven major metropolitan cities of india several models are generated based on the detected changing parameters and combinations of covariates then bayesian differential evolutionary monte carlo de mc algorithm is employed to estimate the uncertainty bound of the nonstationary parameters and the best model is chosen using the deviance information criterion dic the results reveal that the best covariate combinations for short duration events are dominated by local processes i e local temperature changes and diurnal temperature changes whereas the same for longer duration events are dominated by the global processes global warming enso modoki cycle and iod however the acceptable nonstationary models reveal that all the temperature based covariates are capable of capturing the dynamic behavior it is also observed that the local processes carry the signature of global processes finally the return levels computed through the best nonstationary model show that the return periods are decreasing and the short duration events have undergone drastic changes than the longer duration events thus the results suggest that employing climate informed covariates based nonstationary idf curves is indispensable for devising long term strategies to address the changing climate keywords non stationarity bayesian inference climate informed covariates return level 1 introduction the design and construction of engineering infrastructure often need information about the behavior of the natural climate system especially of its extremes it has been established that the characteristics of these extremes majorly of two dominant hydrologic variables precipitation and temperature have considerably changed in the past century alexander et al 2006 goswami et al 2006 according to the intergovernmental panel on climate change assessment report 5 ipcc 2012 the rise in the global surface temperature is likely to exceed 2 c by the end of the 21st century the rising temperature increases the atmosphere s water holding capacity by about 7 per 1 c thereby influencing the precipitation directly cheng and aghakouchak 2015 trenberth 2011 and rising its intensity giorgi et al 2011 detailed investigations of historical regional precipitation around different parts of the globe revealed a higher rate of increase in extreme precipitation when compared to that of average precipitation in the recent decades alexander et al 2006 ganguli and coulibaly 2017 vinnarasi and dhanya 2016 vittal et al 2013 because of this altered scenario high intensity short duration rainfall events have become more prevalent and hence pose a severe threat to both infrastructure and crops leading to substantial social and economic loss worldwide these facts raise significant concerns on the endurance of the existing planned urban infrastructures and water resources systems to the variations anticipated in the extreme events conventionally engineering design operation of structures like municipal stormwater network and various water resources projects are based on intensity duration frequency idf curve to ensure the serviceability cheng and aghakouchak 2015 yilmaz and perera 2014 idf curve is a standard tool derived from historical rainfall series to estimate the design rainfall intensity for a given duration and provides information about regional rainfall extremes idf curves are mathematical relationship among the rainfall intensity duration and frequency koutsoyiannis et al 1998 which can be constructed either through empirical relationship babu et al 1979 kothyari and garde 1993 sherman 1931 or frequency analysis chow et al 1988 hershfield 1961 linsley et al 1975 in the case of empirical formula the constants vary spatially singh and zhang 2007 however the validity of these constants under a changing climate is questionable on the other hand in frequency analysis the idf curves are constructed by fitting the block or partial maximum rainfall intensities for specific durations e g 1 hr 2 hr 3 hr 6 hr etc into the theoretical probabilistic distribution roshan et al 2014 further koutsoyiannis et al 1998 developed a semi empirical approach which is a mathematical framework based on probability distribution for regionalization of idf relationships in general the probabilistic distributions are assumed to be stationary i e the distribution parameters do not change with respect to time nevertheless as mentioned before it has been observed that the characteristics of extreme precipitation have altered significantly over time and the stationarity based idf curve approach often underestimates the return level cheng and aghakouchak 2015 sugahara et al 2009 this questions the reliability of stationary assumption for such applications and demands the incorporation of dynamic behavior into the distribution parameters cheng et al 2014 coles 2001 sarhadi and soulis 2017 in general non stationarity in extreme event modeling is addressed by expressing the distribution parameters as a linear or non linear function of covariates cheng et al 2014 kwon and lall 2016 sarhadi et al 2016 the covariates can be either time or physical processes like hydro meteorological variables or low frequency climatological signals coles 2001 katz et al 2002 while time is the frequently employed covariate sugahara et al 2009 yilmaz and perera 2014 this approach is further enhanced to assess the uncertainty in the nonstationary parameters through bayesian inference cheng and aghakouchak 2015 sarhadi and soulis 2017 some studies argue that the incorporation of non stationarity in extreme event modeling koutsoyiannis 2011 koutsoyiannis and montanari 2014 adds to the uncertainty since the nonstationary modeling includes the changes merely based on the trend in the hydrologic variable these changes may also be due to physical processes ragno et al 2019 serinaldi and kilsby 2015 and hence incorporating the relevant physical processes in extreme event modeling is beneficial montanari and koutsoyiannis 2014 ragno et al 2019 numerous studies have established the relationship between various physical processes and extreme rainfall events mondal and mujumdar mondal and mujumdar 2015 showed that the changes in extreme rainfall over india are due to local temperature changes global warming and the el ni√±o southern oscillation enso cycle local temperature changes are analysed using the local temperature anomaly which is based on surface air temperature however recent studies observed a strong influence of diurnal temperature range integrated water vapour and dew point temperature on extreme precipitation changes rather than the surface air temperature which questions the reliability of clausius clayepron relation ali and mishra 2017 he et al 2015 roderick et al 2020 zhang et al 2019 besides these processes urbanization and various teleconnections like southern oscillation index soi enso cycle el ni√±o southern oscillation modoki enso modoki indian ocean dipole iod etc are found to have impact on the extreme precipitation ashok et al 2007 2001 vittal et al 2013 hence these climatic variables when used as covariates are termed as climate informed covariates thus far nonstationary modeling using climate informed covariates is explored only by few studies bracken et al 2018 li et al 2015 ragno et al 2019 risser and wehner 2017 steirou et al 2018 zhang et al 2015 especially in the case idf curves agilan and umamahesh 2017a 2017b sarhadi and soulis 2017 sarhadi and soulis sarhadi and soulis 2017 used time and soi as covariates for 911 stations over the great lakes and found time as the best covariate for a majority of stations and soi as the best covariate for a few stations however they did not conduct a detailed analysis involving other physical processes affecting precipitation as covariates agilan and umamahesh agilan and umamahesh 2017a used five different covariates for developing idf curves for a single location and found that the dominant covariates for short duration rainfall intensity are local processes such as urbanization and local temperature changes whereas the same for long duration rainfall intensities are global processes like the enso cycle iod and global warming they addressed the non stationarity based on the trend in the extreme rainfall series by incorporating change in either location or combination of location and scale parameter which produced 62 combination of models while in another study agilan and umamahesh 2017b for the same location they addressed non stationarity only in location parameter using 27 covariates and reported that the best covariate for longer duration rainfall is the local process total precipitation one of the reasons for variation in the results of these studies is the lack of knowledge about the nonstationary distribution parameters as to which parameter location scale both should be modeled as nonstationary hence in order to bring realism into covariate based nonstationary modeling this study adopts a robust time sliding window tsw approach to model extreme rainfall intensity proposed by vinnarasi and dhanya vinnarasi and dhanya 2019 tsw nonstationary modeling tsw nsm is capable of detecting the signature of non stationarity in the distribution parameter and reduces the complexity involved in the traditional approach vinnarasi and dhanya 2019 moreover the relation between the local and global processes on the impact of changing extreme precipitation characteristics are yet to be explored it should also be noted that increasing the number of covariates necessarily increases the uncertainty and the computation effort by increasing the number of combinations therefore the potential covariates should be chosen utmost carefully before the modeling in this study we investigate the best climate informed covariate from the basket of potential covariates that influence extreme rainfall intensity and are expected to comprehend the physical phenomenon behind the changing characteristics of extreme precipitation the potential covariates are selected based on thorough literature review finally the best climate informed covariate is used to develop the nonstationary univariate idf relationship utilizing a robust bayesian inference based tsw nsm the proposed framework is demonstrated for seven major cities in india which are chosen based on the availability of data and the need of nonstationary idf relationship for proper water resource planning and infrastructure design 2 study area and data description the proposed nonstationary idf curve framework is implemented over seven major metropolitan cities in india namely bengaluru formerly bangalore mumbai formerly bombay kolkata formerly calcutta chennai formerly madras hyderabad pune and nagpur according to the koppen geiger classification all these cities belong to warm humid regions except hyderabad and pune which falls under semi arid regions peel et al 2007 among all these cities bombay receives the highest annual average rainfall of 2167 mm whereas bangalore calcutta madras hyderabad pune nagpur receive an annual average rainfall of 865 mm 1603 mm and 1355 mm respectively bombay pune nagpur hyderabad and calcutta receive a significant part of rainfall during the southwest monsoon june to september while madras receives heavy rainfall during the northeast monsoon october to december on the other hand bangalore receives rainfall from both northeast and southwest monsoons rapid urbanization accompanied by the exponential population growth in these cities necessitates the design and construction of new state of the art infrastructure to meet the increasing demands in addition to this the impact of the recent flood events in bombay 2005 and madras 2015 evidently reveals the inadequacy of the existing water resource planning and infrastructure the autographic hourly rainfall data procured from the indian meteorological department imd is used in this study the station number duration of the data available information about missing data and the geographic locations of the stations are given in table 1 from the hourly rainfall series the annual maximum rainfall series corresponding to different durations i e 1 hr 2 hr 6 hr 12 hr 18 hr 24 hr and 48 hr are extracted for each station a set of appropriate covariates is then selected for developing nonstationary idf curves initially temperature based covariates are selected since they are generally attributed to the rise of extreme precipitation events allan and soden 2008 soden et al 2005 trenberth 2011 recently agilan and umamahesh agilan and umamahesh 2017a and mondal and mujumdar mondal and mujumdar 2015 inferred that local temperature anomaly lta which expresses the local surface temperature changes and global temperature anomaly gta which expresses the global warming are the best temperature based covariates to develop nonstationary idf curves apart from these two covariates the present study includes diurnal temperature range dtr which is the difference between daily maximum and minimum temperature any changes in dtr are known to have a direct impact on the precipitation he et al 2015 zhou et al 2009 since dtr incorporates urbanization changes in soil moisture dew point temperature wind speed and humidity effects and dtr is found to be significantly influenced by the regional climate over indian sub continent vinnarasi et al 2017 the daily 1 1 gridded mean maximum and minimum temperature data prepared by the national climatic centre ncc imd for the period of 1951 2013 is used to extract lta and dtr the spatial domain of this gridded data set is 7 5 n to 37 5 n and 67 5 e to 97 5 e covering the mainland region of india this data is interpolated to the respective location of each station to extract the respective daily mean minimum and maximum temperature further to represent global warming hadcrut4 yearly observed global temperature anomaly gta is used which is available at https www metoffice gov uk hadobs hadcrut4 recently many studies observed that the influence of enso on indian monsoon is reducing annamalai et al 2007 kumar 1999 while the influence of iod and enso modoki on extreme indian monsoon rainfall is increasing ashok et al 2007 ashok and yamagata 2009 ratnam et al 2010 and the indian summer monsoon rainfall ismr is intensified weakened by the positive negative dipole index ashok et al 2001 further it is observed that iod has strongly modulated the extreme rainfall characteristics over india ajayamohan and a rao 2008 due to greenhouse warming the frequency of extreme iod events are increasing cai et al 2014 which in turn alters the frequency of extreme rainfall recently agilan and umamahesh agilan and umamahesh 2017a have used iod as one of the covariates to construct nonstationary idf curves likewise enso modoki a recently identified phenomenon different from enso is associated with the strong anomalous warming in central tropical pacific and cooling in the eastern and western tropical pacific ashok et al 2007 it causes subsidence over the indian subcontinent due to the modification in the walker circulation over the tropical and subtropical pacific ratnam et al 2010 recent studies show that the frequency of enso modoki is increasing seow 2018 and has a strong correlation to extreme rainfall over india dandi et al 2020 hence enso modoki and iod are considered as covariates in addition to lta gta and dtr iod is quantified through dipole mode index dmi which is the difference of area averaged sea surface temperature anomaly ssta between the tropical western indian ocean 50 e 70 e 10 s 10 n and the tropical southeastern indian ocean 90 e 110 e 10 s equator saji et al 1999 in this study gisst dataset is used to derive the monthly dmi which is downloaded from http www jamstec go jp frcgc research d1 iod iod observations s html en yearly dmi is computed by averaging the monthly dmi from june to november agilan and umamahesh 2017a enso modoki index emi is extracted using sea surface temperature sst using eq 1 1 emi ssta a 0 5 ssta b 0 5 ssta c where ssta a s s t a b and s s t a c are derived from the area averaged sst over each of the regions a 165 e 140 w 10 s 10 n b 110 w 70 w 15 s 5 n and c 125 e 145 e 10 s 20 n respectively ashok et al 2007 the monthly emi data is directly downloaded from http www jamstec go jp frsgc research d1 iod data emi monthly txt overall five physical processes namely local temperature changes global warming diurnal temperature changes enso modoki cycle iod and their combinations are used as covariates additionally time is considered as a covariate to develop the nonstationary idf curves 3 methodology initially the annual maximum rainfall intensity series x t x 1 x 2 x t is formed using the annual maximum rainfall extracted for different durations which are independent and identically distributed random variables generalized extreme value gev distribution which comprises of three extreme value distributions gumbel fr√©chet and weibull coles 2001 are the best to model annual maximum series based on the extreme value theory the major steps involved in constructing the climate informed covariate based nonstationary idf curve are outlined below 1 time sliding window approach is used to detect the non stationarity in each distribution parameter of the series for each duration 2 different nonstationary extreme event models are developed using different combinations of five physical processes local temperature changes global warming enso modoki index iod and dtr as covariates for the distribution parameter 3 the nonstationary idf curve is constructed after identifying the best extreme event model best covariate the overall procedure is depicted in fig 1 each major step mentioned above is briefly described below 3 1 detection of non stationarity after extraction of the extreme rainfall intensity series for different durations the non stationarity in the distribution parameter of each series is detected using tsw approach proposed by vinnarasi and dhanya 2019 the detailed procedure of tsw is described below 1 the extreme rainfall intensity series for each duration is reconstructed into many realizations using a pre defined time sliding window of length m for example extreme rainfall intensity series of 1 hour duration x d 1 t x 1 x 2 x t is divided into many realizations r 1 r 2 r t m as follows r 1 x 1 x 2 x m r 2 x 2 x 3 x m 1 r t m x t m x t m 1 x t 2 each realization is fitted into the gev distribution and the distribution parameters are computed using the maximum likelihood estimate the cumulative distribution function is given as 2 f gev r 1 Œº r 1 œÉ r 1 Œæ r 1 e x p 1 Œæ r 1 Œº œÉ 1 Œæ where Œº œÉ Œæ are the location scale and shape parameters respectively the distribution is defined on the set x 1 Œæ x Œº œÉ 0 and the parameters should satisfy the following criterion Œº œÉ 0 Œæ the log likelihood for the gev distribution is 3 log l Œº r 1 œÉ r 1 Œæ r 1 r 1 n log œÉ 1 1 Œæ i 1 n log 1 Œæ x i Œº œÉ i 1 n 1 Œæ x i Œº œÉ 1 Œæ the maximum likelihood can be estimated by maximizing the equation 3 with respect to the parameter vector 4 a new parameter series is constructed using the parameters obtained from each realization as Œº Œº r 1 Œº r 2 Œº rn m 5 using a non parametric moving block bootstrap mann kendall test the significant trend of each parameter series is computed 5 if any parameter shows a significant trend it is considered as changing parameter Œº t and is modeled using a linear trend Œº t Œº 1 Œº 2 c whereas the remaining parameters are considered as time invariant kept as constant 3 2 nonstationary extreme event model as mentioned earlier gev distribution is chosen to model the extreme rainfall intensities traditionally the parameters Œº œÉ Œæ of the gev distributions are assumed to be stationary i e the parameters are kept constant however under nonstationary conditions the parameters are time dependent based on this a time varying extreme event model is developed in which the parameters are expressed as a linear function of a covariate the cumulative distribution of gev distribution for the nonstationary case is given as 4 f x t x t Œº t œÉ t Œæ t e x p 1 Œæ t x t Œº t œÉ t 1 Œæ as discussed earlier in section 3 1 only those parameters which show significant trend are modeled as nonstationary linearly related to covariate while the other parameters are considered as constant however the shape parameter is kept as constant for all the cases since it requires long term observations to model it accurately cheng et al 2014 ganguli and coulibaly 2017 five physical processes and time are used as the covariates to define a linear function of the changing distribution parameters the changing location and scale parameters with time as a covariate is expressed as Œº t Œº t 1 Œº t 2 t and œÉ i t e œÉ i 1 t œÉ i 2 t the same can be expressed in terms of other covariates instead of time thus different combinations of nonstationary models are developed in terms of the detected changing parameter as listed in table s1 of the supplementary information here we restrict the nonstationary distribution parameters to a simple linear model to avoid the complexity and uncertainty due to the additional parameters luke et al 2017 serinaldi and kilsby 2015 further to estimate the parameters with uncertainty bound a robust bayesian inference framework is used renard et al 2013 which is a preferred method to analyse sparse data chandra et al 2015 coles et al 2003 huard et al 2010 and is widely used to model dynamic behavior agilan and umamahesh 2017b cheng et al 2014 cheng and aghakouchak 2015 kwon and lall 2016 sarhadi et al 2016 sarhadi and soulis 2017 bayesian inference combines the knowledge carried by the likelihood function of the annual maximum series and prior distribution through bayes theorem the posterior distribution using bayesian inference is given as 5 p œÜ x p œÜ l œÜ x the likelihood function is computed using 6 l œÜ x i 1 n p x i œÜ where p œÜ is the prior distribution of the parameter l œÜ x is the likelihood function i e œÜ is the parameter of the gev distribution in this study weak informative normal distribution i e a normal distribution with large variance n 0 1000 is chosen for location and scale parameters which uses the knowledge from the observations cheng et al 2014 gelman et al 2014 for the shape parameter the informative normal distribution with 0 3 standard deviation is used renard et al 2013 for instance the posterior distribution of extreme rainfall intensity for 1 hr duration considering significant dynamic behavior in location parameter expressed as a function of five covariates is given as 7 Œº t Œº 1 Œº 2 c 1 Œº 3 c 2 Œº 4 c 3 Œº 5 c 4 Œº 6 c 5 8 p œÜ d 1 x d 1 p œÜ d 1 i 1 n p x d 1 œÜ d 1 where œÜ d 1 Œº 1 Œº 2 Œº 3 Œº 4 Œº 5 Œº 6 œÉ Œ∫ to estimate the distribution parameters bayesian inference is implemented through differential evolution markov chain de mc algorithm which integrates differential evolution de learning strategy and monte carlo markov chain mcmc simulation employing metropolis hastings algorithm for sampling cheng and aghakouchak 2015 ter braak 2006 ter braak and vrugt 2008 vrugt et al 2009 additionally the convergence of the posterior distribution is estimated using a statistical criterion known as r gelman and shirley 2011 the value of r is checked whether it is 1 1 otherwise the sampling is done again by running a new set of initial values the best model is selected using deviance information criterion dic which is specially designed for model selection and comparison with respective to bayesian inference the model corresponding to the minimum dic is considered as the best model 3 3 construction of nonstationary idf curves after identifying the best nonstationary model the nonstationary return level is computed using the parameters of the best nonstationary model the estimation of return level in a nonstationary context is a crucial step since the distribution parameters change over time in this study we employ design exceedance probability to estimate the return level for developing the idf curve where the return level is computed using a selected percentile value of the changing parameter as suggested by cheng et al cheng et al 2014 the 95th percentile of the changing parameter which is considered as low risk more conservative is chosen for instance the 95th percentile of the changing location parameter Œº is expressed as Œº 95 q 95 Œº 1 Œº 2 Œº t further the nonstationary return level of maximum intensity associated with a t year return period for different storm durations is estimated by inverting the cumulative distribution function of gev distribution i e extreme quantiles as given below 9 x p Œº 95 œÉ 95 Œæ 1 log 1 p Œæ f o r Œæ 0 Œº 95 œÉ 95 log log 1 p f o r Œæ 0 where p is the exceedance probability of occurrence the return level x p for particular t year return period refers to the annual maximum rainfall for particular intensity and duration having a probability of exceedance 1 t hence the return level is computed as a function of return period t where t 1 p 4 results and discussion 4 1 nonstationary extreme event model annual maximum rainfall intensity series are generated for eight different storm durations i e 1 hr 2 hr 3 hr 6 hr 12 hr 18 hr 24 hr and 48 hr the statistics of each series for each station are shown in fig s1 bombay receives the highest average 1 hr rainfall with a maximum intensity of 55 85 mm hr among all other stations since the trend in the extreme intensity series may not reveal the actual trend in the distribution parameters the trend in the time series is not evaluated the detection of nonstationary parameters and the selection of the best nonstationary extreme event model is discussed below 4 1 1 detecting and estimating nonstationary parameters the signature of non stationarity is detected in the distribution parameter series instead of the annual maximum rainfall series as mentioned in section 3 1 for this purpose tsw is employed to capture the nonstationary behavior in the extreme rainfall intensity series of eight different durations for the seven stations total 56 cases each series is segmented into many realizations using a 20 year time sliding window since the data is not available for a longer duration and a minimum of 20 years parameter series is required to perform trend analysis 30 year window can be used if longer duration data is available the distribution parameters i e location scale and shape parameter of each realization is computed by fitting it into the gev distribution then the parameter series for a specific case duration and location is constructed by arranging the respective parameter of each realization non parametric moving block bootstrap mann kendall test is used to test the significance of the trend in the parameter series at various significance levels as shown in table 2 any change in the location parameter has more impact on the mean of the time series though the change in all these three parameters contributes to the change in the mean likewise change in scale or shape parameter has more impact on the variance the change in the mean or variance will intensify the tail of the distribution the results show that all the seven stations have undergone changes which clearly questions the reliability of stationary assumption in case of bangalore and bombay both location and scale parameters exhibit an increasing trend which can be inferred as the positive shift in the mean i e increase in high rainfall intensity and longer spread of the events increase in the probability of both extreme tails of the distribution the observed changes in the distribution parameters of these cities may be attributed to rapid urbanization nagendra et al 2014 and the closeness to the arabian sea which is reportedly getting warmer in recent decades kothawale et al 2008 likewise the probabilistic characteristics of longer duration rainfall intensities of madras and nagpur are strengthened as reflected from the increasing trend in the location and scale parameters the short duration rainfall intensity in madras has undergone changes only in the scale parameter whereas nagpur shows a negative change in location parameter and positive change in scale parameter it is worthy to note that the changes in the scale parameter is expected to alter the spread of the extreme events moreover the observed negative trends in the location parameter of 2 hr 3 hr and 6 hr durations for madras will result in the shortening of the spread of events also the observed positive trend in the scale parameter of 1 hr duration may indicate an increase in the spread of the events interestingly no changes are observed in 1hr and 3hr durations in hyderabad 2 hr and 3 hr durations in calcutta to avoid the ambiguity in the results we have kept 1 to 3 hr duration of calcutta and hyderabad as stationary and it is also noted that the changes observed in 2 hr of hyderabad and 1 hr of calcutta is weakly significant for longer duration hyderabad exhibits a negative positive change in location scale parameter on the contrary decreasing trends in the distribution parameters are observed in calcutta and pune in case of calcutta the negative changes are more predominant in scale parameter however no changes are observed for 2 hr and 3 hr durations whereas pune exhibit negative trend in both scale and location parameter the observed decreasing trend in the distribution parameters of calcutta and pune is expected to shrink the spread of the extreme events which in turn will reduce the extreme rainfall though the global factor for all the stations remain the same the contradictory pattern in the local parameters among the stations clearly indicates that local processes work in tandem with the global processes at regional scale highlighting that the covariates are region specific overall it can be inferred that the scale parameter has undergone more changes than the location parameter which clearly reveal that the spread distribution of the events has undergone more alteration than the total amount of rainfall goswami et al 2006 vinnarasi and dhanya 2016 vittal et al 2013 after detecting the changing distribution parameters it is necessary to model the nonstationary parameter as a function of covariate s as shown in table s1 32 different combinations of nonstationary linear regression models are developed based on five physical processes and time as a covariate to compare the nonstationary model with the stationary model a separate model with a constant parameter is developed i e a total of 33 models are developed for each duration of each station the distribution parameter of each model is estimated along with their uncertainty bound using bayesian inference employing the demc metropolis hastings algorithm in this study five markov chains are generated with five thousand samples in each chain the first 1000 samples are discarded as the burn in period the remaining samples are used to compute the distribution parameters only if the samples converge hence the convergence statistics r are monitored and assured to be less than 1 1 the convergence of the posterior sample is further ensured by observing the trace plot and the posterior distribution as an illustration the trace plot and posterior distribution of extreme rainfall intensity for 1 hr duration for bangalore station are shown in fig 2 which shows no upward or downward trend in the posterior sample and the distribution is also not centered at zero for brevity the remaining cases are not shown in this article 4 1 2 selection of best covariate once the nonstationary parameters are detected the nonstationary model with the best combination of covariates is assessed using dic before constructing the idf curve the model having the least dic value i e Œ¥ d i c 0 is considered as the best while Œ¥ d i c i e the difference in the dic value of any model with that of the best model lesser than 2 is also considered as a reasonable choice spiegelhalter et al 2002 the dic value and Œ¥ d i c of each model for 1 hr duration of all seven stations are summarized in table 3 all acceptable models reasonable choices and the best model are highlighted in italics and boldface respectively m26 is found to be the best model for 1 hr duration in bangalore madras and nagpur whereas m24 and m8 are the best for bombay and pune respectively interestingly except pune the best model for 1 hr duration for other stations are the combination of lta and dtr with some global processes i e lta dtr emi for bangalore madras and nagpur and lta dtr gta for bombay whereas for pune the best nonstationary model is based emi and gta it can be noted that the other acceptable models for 1 hr duration are also a combination of both local and global processes these results clearly indicate that the temperature based local process covariates like lta and dtr have more influence on 1 hr duration in consistent with the previous studies agilan and umamahesh 2017a kishtawal et al 2010 mondal and mujumdar 2015 vittal et al 2013 which highlights that the short duration high intensity rainfall is chiefly due to the change in the regional temperature the nonstationary extreme event models for other durations are summarized in table s2 s8 of the supplementary material results reveal that the influence of the global processes gradually increases with the increase in duration for instance the best covariate model of 24 hr and 48 hr for bangalore is m8 and m30 respectively which are entirely based on global processes whereas in the other stations local processes along with global processes forms best covariate especially most predominant covariate is gta however some of the acceptable models are entirely based on local processes underlining that the local processes cannot be overlooked indicating that the local processes carry the signature of global processes the increase in the number of acceptable models increases the uncertainty range in the estimation of return level the cumulative distribution function cdf plots for all acceptable models along with parameter uncertainty bounds of best model for 24 hr duration of all the stations fig 3 shows that the covariate uncertainty in all the cases are within the parameter uncertainty in other words the uncertainty due to parameters is more than that of the covariate therefore the best nonstationary model is considered for the remaining analysis the same deduction is made for the remaining durations as shown in figs s2 to s8 of the supplementary information the best nonstationary model for each station and each duration is shown in fig 4 among the 32 cases time based nonstationary model qualifies as the best only for 2 hr duration of bombay best model 24 hr duration of madras acceptable model and 1 and 2 hr duration of pune acceptable model overall it can be inferred that temperature based covariates i e lta dtr and gta as separate or as combinations have more influence on the trend of the changing parameter than the teleconnections and are indispensable in modeling the dynamic behavior of extreme rainfall intensities this suggests that in the absence of investigation for best covariates temperature based indices can be reasonably employed as covariates for modelling since they are in the acceptable models this also confirms the clausius clapeyron relation which states that the increase in temperature increases the moisture holding capacity of the atmosphere which further influences the intensity of precipitation giorgi et al 2011 however the observed results also highlight that the model based on lta alone is not good to model temporal changes of extreme rainfall which again supports that the surface air temperature alone is not a good covariate to project the extreme rainfall changes roderick et al 2020 further the goodness of fit for the best nonstationary model is examined through pp probability probability and qq quantile quantile plots these plots for 24 hr duration rainfall are shown in fig 5 and fig 6 respectively the same for other durations are given in figs s9 s22 of supplementary information from these plots it is observed that the best nonstationary model is able to capture the extreme rainfall intensities besides the pdf plots of best nonstationary and stationary model shown in fig 7 for 6 hr duration the nonstationary model clearly reveal the positive negative shift in the mean and lengthening shortening in the spread of events the efficiency of the tsw approach is demonstrated in the fact that it requires only 33 models to be developed to capture the appropriate changing parameter whereas the traditional nonstationary model requires 97 models to be developed this is achieved in the present approach by circumventing the nonstationary modeling of insignificant distribution parameters thereby reducing the complexity and improving the computational efficiency it further emphasizes that neglecting nonstationary model based on the physical process like meteorological variables or low frequency signals will under overestimate the risk of extreme events agilan and umamahesh 2017b sarhadi and soulis 2017 4 2 nonstationary idf curves the nonstationary idf curves for 2 year 5 year 20 year 25 year 50 year and 100 year return periods are constructed using the best nonstationary models the nonstationary idf curve for bombay clearly reveals that the stationary idf curves underestimate extreme events as shown in fig 8 for instance the return level of 1 hr duration event with 2 year return period for the nonstationary model is 60 83 mm hr whereas the same for the stationary model is 55 83 mm hr with a difference of about 5 081 mm hr 12 similarly for a 1 hr event with a 10 year return period the difference between nonstationary 101 89 mm hr and stationary 90 46 mm hr model is 11 51 mm hr 13 it should be noted that a difference of 11 51 mm hr would result in a significant increase in the flood it can also be observed that stationary return level of 1 hr duration for 10 year return period is roughly equal to the nonstationary return level 84 89 mm hr of 1 hr duration with 5 year return period which clearly indicates that the return period is decreasing while the return level is increasing therefore the existing infrastructure designed based on the stationary return level in bombay will suffer underestimation of the actual flood risk and hence especially the present storm drainage system in bombay may not be able to handle the expected frequent flood events gupta 2007 the difference between the nonstationary and stationary return levels for different return periods for bombay is shown in fig 9 which shows that this difference decreases as the duration increases which further demonstrates that short duration high intensity rainfall has increased in recent decades this can be attributed to the clausius clapeyron dependence which implies that increasing temperature causes convective rainfall with high intensity and short duration giorgi et al 2011 similarly idf curves are developed for other stations and shown in figs s23 to s34 since the intensification is more for 1 hr duration the return level for various return periods of 1 hr duration for bangalore bombay madras nagpur and pune are shown in fig 10 bangalore madras and nagpur also exhibit similar behavior to bombay increase in the nonstationary return level than the stationary return level i e the median and quantiles of the nonstationary return level are above zero except for short duration intensities in madras on the contrary pune shows a decrease in the nonstationary return level i e the quantiles are below zero fig 10e as reported in the previous studies sen roy 2009 though remarkable changes were not observed in the short duration rainfall events of calcutta there is a decrease in the nonstationary return level for higher duration rainfall events fig s30 this may be due to the cooling reduced warming of surface air temperature in calcutta ross et al 2018 overall it is inferred that the nature of extremes is dynamic due to the warming climate the observed changes in the return level of each station exactly correlate with the temperature variations over the region which highlights that temperature based indices are the best covariates to model nonstationary idf curves to validate this the study area is further extended to entire india using 0 25 0 25 gridded daily rainfall data provided by imd due to the unavailability of data longer than 30 years the analysis is carried out for 24 hr duration only the results observed over entire india corroborates with the observations for higher duration in the seven cities considered in this study refer to the supporting information text s1 however the choice of covariate cannot be concluded merely based on information criteria but requires numerical model which will aid understanding the physical phenomena behind these changes and reduce the covariate uncertainty further the reliability of stationary extreme event modeling is questionable which either underestimates or overestimates the risk of extreme events and should not be recommended for infrastructure planning and design though the proposed approach is superior to the traditional approaches by capturing the temporal dynamics and effectively incorporating them in the modelling a mathematical framework for idf curve cannot be developed based on only seven locations therefore the analysis of the spatial distribution of best covariate and developing a mathematical relation would be a possible future work that allows the extrapolation of the time varying idf beyond the observed durations 5 conclusions the increase in the frequency of the short duration high intensity rainfall events in the recent decades and the influence of climatic processes on the extreme precipitation have motivated the authors to develop the climate informed covariate based nonstationary intensity duration frequency idf curves for seven metropolitan cities of india bombay bangalore calcutta hyderabad madras nagpur and pune the influence of climatic variables on the distribution of precipitation extremes is investigated using a site specific nonstationary model nsm which utilizes a time sliding window tsw approach to detect non stationarity and bayesian inference to model the parameter uncertainty only the distribution parameters that have a signature of significant non stationarity are modeled as a linear function of the covariate while the other parameters are kept constant a total of 32 nonstationary gev models are developed for each storm duration and for each station with all possible combinations of five climatic variables local temperature changes lta diurnal extremes changes dtr global warming gta enso modoki cycle emi and indian ocean dipole iod then the best climate informed nonstationary model is selected based on deviance information criteria dic this study reveals that all four cities exhibit significant non stationarity in the distribution parameters it is found that temperature based covariates like lta dtr and gta have more influence on the rainfall intensities except calcutta and pune where teleconnections especially iod and emi respectively play a significant role however in both calcutta and pune temperature based covariate models are also acceptable while time did not qualify as the best covariate for any of the cases except for 12 hr duration in bombay the stationary model underestimates the return level for bangalore bombay hyderabad madras and nagpur whereas in calcutta and pune it overestimates it can also be noted that the rate of increase in temperature is high in all the cities except calcutta which could also be a reason for the contrast behavior of calcutta when compared to other stations the following conclusions are derived based on this study 1 the non stationarity in the scale parameter spread of the events of extreme rainfall intensity was detected and modeled which would have been overlooked by traditional nsm 2 the precipitation extremes are strongly influenced by the warming climate even if a suitable teleconnection is not known temperature based covariates can be used to develop appropriate idf curves 3 it is evident that the nonstationary model based on climate variables as covariates will improve the accuracy of nonstationary idf curves 4 ignoring the non stationarity in the return level will underestimate the risk of extreme events especially that of short durations and lead to the failure of water resources systems and infrastructure 5 design and construction practices for water resource infrastructures should be updated by adopting non stationarity based idf curves in order to mitigate the expected flood events in the future credit authorship contribution statement r vinnarasi conceptualization methodology formal analysis visualization writing original draft c t dhanya conceptualization investigation visualization supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127178 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
