index,text
25580,the pairwiseiha is an open source toolkit written in python that enables the user to quickly obtain the indicators of hydrologic alteration iha from inflow and outflow time series for headwater reservoirs specifically the iha metrics obtained from inflows outflows are considered as natural regulated and the differences are used to indicate how the magnitude frequency duration timing and rate of change are altered by reservoir operation it extends the functionality of the popular iha software for analyzing concurrent inflows and outflows the results of three case study reservoirs in california highlight that reservoir operation leads to considerable alterations in the five components of the flow regime the findings on flow regime alteration are consistent across wet normal and dry years overall the pairwiseiha can serve as an effective tool to investigate alterations in flow regime induced by human activities for water managers scientists natural resource agencies and water users keywords flow regime reservoir operation natural inflow regulated outflow indicators of hydrologic alteration range of variability approach 1 introduction the natural flow regime plays a critical role in creating the dynamics of in channel and floodplain conditions that are critical for maintaining ecological integrity in riverine ecosystems poff et al 1997 grill et al 2019 from an evolutionary perspective aquatic and riparian organisms have adapted to the natural hydrological variations including floods and droughts lytle and poff 2004 on the other hand human activities such as reservoir operation have substantially altered the flow regime across more than half of large river systems around the world cheng et al 2018 wang et al 2018 grill et al 2019 the alterations prompt a range of ecological responses that threaten the biodiversity of riverine ecosystems zuo et al 2015 zhang et al 2017 wang et al 2018 therefore enhanced knowledge of flow regime alterations induced by reservoir operation is critical for policy makers and water managers to support environmental flow management zhao et al 2015 horne et al 2017 nayeb yazdi et al 2019 barton et al 2020 zhou et al 2020 the indicators of hydrologic alteration iha have been proposed to assess alterations in flow regime by examining the characteristics of streamflow before and after a particular human activity richter et al 1996 specifically five components of iha metrics i e the magnitude frequency duration timing and rate of change are calculated from streamflow time series by water year then they are examined across water years to illustrate any trends and step alterations in flow regime richter et al 1996 gao et al 2009 li et al 2018 the range of variability approach rva uses the iha metrics to quantify the degree of flow regime alteration and to identify management targets for regulated rivers richter et al 1997 cui et al 2020 investigated flow regime alteration due to climate change and dam construction on the upper yellow river basin and analyzed potential impacts of flow regime alterations on riverine ecosystems and chalise et al 2021 quantified the degree of flow regime alteration across the conterminous united state and illustrated its importance for protection of the ecological environment iha software which was developed by the nature conservancy https www conservationgateway org presents an effective and efficient way to derive the 33 iha metrics from daily streamflow time series richter et al 1996 1997 mathews and richter 2007 the software provides tabular summaries and graphical outputs for the analysis of hydrologic impacts of human activities in an iha application users only need to supply daily streamflow time series and specify a few parameters then the software automatically presents the time series of iha metrics by year mathews and richter 2007 the iha metrics and rva results derived by the iha software have been widely used to aid ecological protection and river management butchart kuhlmann et al 2018 gebremicael et al 2019 tian et al 2019 cui et al 2020 hernandez suarez et al 2021 this paper details a new open source toolkit called pairwiseiha to illustrate the specific impact of reservoir operation on flow regime by contrasting the outflows with the inflows for headwater reservoirs there is an obstacle to the direct application of the popular iha software for the analysis of concurrent inflows and outflows of headwater reservoirs this is because the iha software focuses on one time series by examining the iha metrics before and after a certain human activity whereas inflows and outflows are two concurrent time series tian et al 2019 cui et al 2020 gunawardana et al 2021 the pairwiseiha bridges this gap by directly contrasting the iha metrics of inflows and outflows to show how the flow regime has been altered as will be demonstrated through the results of three case study reservoirs in california the pairwiseiha toolkit is effective in quantifying the alterations in flow regime induced by the operation of headwater reservoirs 2 toolkit capabilities 2 1 overview of pairwiseiha the pairwiseiha is a toolkit written in python to investigate the effects of reservoir operation on the flow regime for a target headwater reservoir the iha metrics are used to indicate the flow regime alterations the 33 iha metrics can be divided into five groups specifically there are 12 metrics of magnitude of monthly water conditions 12 metrics of magnitude and duration of annual extreme water conditions 2 metrics of timing of annual extreme water conditions 4 metrics of frequency and duration of high and low pulses and 3 metrics of rate and frequency of water condition changes richter et al 1996 mathews and richter 2007 the rva targets are determined by the range of each of the iha metrics richter et al 1997 zolezzi et al 2009 there are four steps of the pairwiseiha to analyze the flow regime alterations as shown in fig 1 the first step is to prepare the time series of inflow and outflow the second step is to interpolate missing data using monthly mean values the third step is to calculate the iha metrics of the inflows and of the outflows for the third step there are three sub steps defining the local water year setting high and low pulse thresholds and calculating iha metrics the reason three sub steps are used is that hydrologic statistics of the iha metrics of inflows and outflows are calculated by the local water year which is a 12 month period beginning in the month of the lowest average monthly inflow for headwater reservoirs wasko et al 2020 the default definition of high pulse is those periods where the daily streamflow within a year rises above the 75th percentile of inflows and the low pulse is those periods that drop below the 25th percentile of inflows richter et al 1996 the iha metrics are derived from both inflows and outflows using the high and low pulse thresholds the fourth step is to measure the degree of hydrologic alteration which uses the rva to evaluate the flow regime alterations for headwater reservoirs the hydrologic alteration can be analyzed across wet normal and dry years the pairwiseiha outputs the iha metrics by using the comma separated values csv file that can be easily used by other software 2 2 mathematical formulations the times series of daily inflow and outflow are indexed by subscripts yyyy mm and dd which represent year month and day respectively in the meantime the time series of daily inflow are denoted by i and i and the time series of daily outflow by o and o 1 i i y y y y m m d d o o y y y y m m d d in which i o is the set of inflow outflow and i o represents individual values of inflow outflow the iha metrics are calculated from i and o the first group is comprised of the iha metrics of magnitude of monthly water conditions 2 i m m i y y y y m m o m m o y y y y m m in which i m m o m m is the set of monthly inflow outflow indexed by mm i e january february december i y y y y m m o y y y y m m is the average of daily inflow outflow in month mm year yyyy the second group is comprised of the iha metrics of magnitude and duration of annual extreme water conditions 3 i x d m n i y y y y x d m n o x d m n o y y y y x d m n and 4 i x d m x i y y y y x d m x o x d m x o y y y y x d m x the x day xd minimum mn and maximum mx flows are derived by year from the daily time series of inflow outflow the value of x is set as 1 3 7 30 and 90 following the standard setting of the iha software mathews and richter 2007 in addition the number of zero flow days and base flow index are derived the third group is comprised of the iha metrics of timing of annual extreme water conditions 5 i d o y m n i y y y y d o y m n o d o y m n o y y y y d o y m n and 6 i d o y m x i y y y y d o y m x o d o y m x o y y y y d o y m x in which the day of year doy of minimum mn flow and maximum mx flow are derived by year from the daily time series of inflow outflow which follows the user manual of the iha software mathews and richter 2007 then the doy of both minimum flow and maximum flow are converted into the circular date li et al 2017 7 φ 360 d o y 366 the fourth group is comprised of the iha metrics of frequency and duration of high and low pulses 8 i l p f r e i y y y y l p f r e o l p f r e o y y y y l p f r e and 9 i l p d u r i y y y y l p d u r o l p d u r o y y y y l p d u r the frequency fre and duration dur of low pulse lp are derived by year from the low pulse of inflow outflow i y y y y l p f r e o y y y y l p f r e is the count of low pulse of inflow outflow in year yyyy i y y y y l p d u r o y y y y l p d u r is the average of low pulse duration of inflow outflow in year yyyy in addition the frequency and duration of high pulse are derived with the same method the fifth group is comprised of the iha metrics of rate and frequency of water condition changes 10 i r r i y y y y r r o r r o y y y y r r and 11 i f r i y y y y f r o f r o y y y y f r the rise rate rr and the fall rate fr are derived by year from the daily time series of inflow outflow i y y y y r r o y y y y r r is the average of rise rate of inflow outflow in year yyyy i y y y y f r o y y y y f r is the average of fall rate of inflow outflow in year yyyy in addition the number of reversals is derived the rva makes use of the iha metrics to evaluate the alterations in flow regime between inflows and outflows the rva target of each iha metric is generally defined as the 25th percentile to 75th percentile range of the iha metric of inflow richter et al 1997 the degree of hydrologic alteration developed by richter et al 1998 is evaluated with rva target ranges 12 d m n o m n e n e 100 in which d m is the degree of hydrologic alteration of the m th iha metric n o m is the number of observed years of the m th iha metrics of outflow locating in rva target range n e is the number of expected years locating in rva target range n e r n t r is the ratio of iha metric of inflow within the rva target and n t is the sample size of inflow or outflow with the unit of year d m below 33 indicates low degree change from inflows to outflows d m between 33 and 67 moderate degree change and d m above 67 high degree change 2 3 analysis for wet normal and dry years as per water balance there is a close relationship between the magnitude and temporal distribution of inflows and outflows yin et al 2011 he et al 2020 therefore the alterations in flow regime in different inflow conditions may exhibit different patterns to compare the differences in flow regime alterations across wet normal and dry years the annual average inflows were used to define three types of the inflow condition using the standardized runoff index sri approach shukla and wood 2008 the sri was set by the inverse standard normal transformation 13 s r i φ 1 f r r in which r is annual average inflow f r is the cumulative distribution function cdf of the annual average inflow and φ 1 is inverse cumulative standard normal distribution the definitions of the wet normal and dry years are as follows 14 y w e t y s r i 0 5 y n o r m a l y 0 5 s r i 0 5 y d r y y s r i 0 5 in which y w e t y n o r m a l and y d r y is the set of wet years normal years and dry years the values of sri greater than 0 5 are defined as the wet years the values of sri between 0 5 and 0 5 are defined as the normal years and the values of sri less than 0 5 are defined as the dry years following shiau and wu 2007 the cumulative probabilities corresponding to the dry years are less than 31 the cumulative probabilities corresponding to the wet years are larger than 69 the other values are for the normal years 3 case study three headwater reservoirs in california which are lake oroville folsom lake and pine flat lake were selected to demonstrate the use of the pairwiseiha the location map of the reservoirs was shown in fig 2 1 the oroville dam on the feather river primarily provides flood control water supply and hydropower generation anghileri et al 2016 the impoundment of lake oroville has a volume of about 4 36 km3 notably lake oroville is the largest reservoir in the california state water project swp the quantity and timing of snowmelt show inter annual differences due to the large inter annual variability in temperature and precipitation of lake oroville 2 the folsom dam on the american river primarily serves for flood control hydropower generation and water supply for irrigation adams et al 2017 the impoundment of folsom lake has a volume of about 1 19 km3 releases by folsom lake largely influence the downstream environmental conditions 3 the pine flat dam on the kings river primarily provides flood control water supply and hydropower generation maurer 2007 the impoundment of pine flat lake has a volume of about 1 23 km3 and it is one of the largest reservoirs in california the time series of inflow and outflow of lake oroville folsom lake and pine flat lake were mainly collected from the sacramento district s water control data system wcds https www spk wc usace army mil due to the lack of data in the wcds the inflow and outflow data from california data exchange center cdec https cdec water ca gov was used as a supplement the wcds and cdec provide valuable hydrologic datasets for environmental management in california for about 200 reservoirs in california they provide the storage inflow and outflow at hourly daily and monthly timescales it is found that 0 02 of the inflow values are missing for pine flat lake and that there is no missing data for lake oroville and folsom lake it is also noted that 0 28 1 61 of the values of inflow outflow are negative for lake oroville which may be due to reservoir evaporation at the annual timescale the inflows generally match the outflows indicating limited effects of negative values on the water balance fig s1 in the supplementary material to facilitate the analysis the missing values were replaced by the monthly mean values and the negative values were replaced with zeros the analysis mainly focused on the results of lake oroville the similar results at the other two reservoirs were presented in the supplementary material 4 results 4 1 alterations in flow regime the reservoir inflows and outflows were presented in fig 3 by different colors corresponding to the values substantial differences were observed between the inflows and the outflows which can be attributed to reservoir operation the inflows in the feather river are largely snow dominated which resulted in high inflow in spring and low inflow in autumn on the other hand the outflows tended to be high in summer due to high human water demands during the dry season and they were low during the wet season zhu et al 2005 thus the seasonality of inflow had been substantially changed this outcome is attributed to the fact that lake oroville primarily serves urban and agricultural water demands during the dry season for the san francisco bay area anghileri et al 2016 similarly the outflows of folsom lake and pine flat lake see figs s2 and s8 also tended to be high in summer the time series of iha metrics except for the timing of annual extreme water conditions were plotted in fig 4 where the dash lines represented the rva range of each iha metric the monthly mean outflows in july august september and october largely deviated from those of inflows suggesting that the monthly mean flows in these months had been substantially changed due to the reservoir operation there were substantial differences between annual maximum outflows and annual maximum inflows since lake oroville serves flood control water supply during the wet dry season anghileri et al 2016 as the number of days increases the annual maximum inflows and outflows became more similar to each other implying the substantial regulation of reservoir operation on maximum flow in the short run and the reduced impact in the long run the durations of high pulse and low pulse of outflows were similar to those of inflows the annual changes in rise and fall rates of outflow were consistent with those of inflow which showed that the outflows were considerably affected by the inflows in addition the number of reversals of outflow was less than that of inflow the results indicated that the operation of headwater reservoir tended to smoothen the inflow variability the timing of annual extreme water conditions of iha metrics was presented in fig 5 as expected the dates of maximum and minimum flow were different for the inflows and the outflows the maximum inflows mainly occurred from february to march which is the wet season the maximum outflows were substantially later than those of inflows the minimum inflows mainly occurred from september to october while the minimum outflows mainly occurred from january to june which is the wet season these results were generally attributable to flood control during the wet season which stored excessive flood water for water supply during the dry season the degrees of hydrologic alteration of 33 iha metrics were shown in fig 6 by rectangular bars with different colors it was observed that the degrees of hydrologic alteration were different in the magnitude frequency duration timing and rate of change for lake oroville among the 33 iha metrics 10 metrics exhibited high degree changes and 14 metrics showed moderate degree changes most of the high degree changes were the magnitude of monthly water conditions i e six metrics of monthly flow the degrees of hydrologic alteration of monthly mean flow during the dry season were higher than those during the wet season most of the degrees of hydrologic alteration were negative indicating that most of the iha metrics were out of the rva range 4 2 analysis for wet normal and dry years the empirical cumulative distribution function ecdf was used to compute the sri to investigate the flow regime alterations in wet normal and dry years mckee et al 1993 the iha metrics except for the timing of annual extreme water conditions in wet normal and dry years were visualized by boxplots in fig 7 the monthly mean outflows during wet years were generally higher than those during dry years for annual maximum and minimum flows variations in the minimum outflows were generally larger than the maximum outflows during normal and dry years for high and low pulses the variations in the frequency of high and low pulses of outflow were generally larger than those of inflow during wet normal and dry years indicating that the outflows in extremely wet years tended to be more unevenly distributed the variations in rise and fall rates of outflow were larger than those of inflow during normal and dry years in addition the number of reversals of outflow was generally less than that of inflow during wet normal and dry years which showed that the alterations in number of reversals were generally similar during wet normal and dry years the timing of annual extreme water conditions of iha metrics in wet normal and dry years was presented in fig 8 the maximum and minimum inflows mainly occurred within the same season across wet normal and dry years for lake oroville combining the actual storage of reservoirs of california state water project the water release of lake oroville is dynamically adjusted based on downstream water needs and streamflow forecasts anghileri et al 2016 the maximum outflows were slightly later than those of inflows during wet years and were largely different during dry years the results indicated that the timing of extreme water conditions was altered to different extents during wet normal and dry years 5 discussion the pairwiseiha was developed to investigate the hydrological regime subject to reservoir operation this toolkit can supplement the iha software that assesses iha metrics before and after a particular human activity mathews and richter 2007 it is noted that there are other iha toolkits including the eflowstats in r and the matlab hydrological index tool thompson et al 2013 abouali et al 2016 the open source eflowstats provides flexible functions to calculate hydrological metrics indicating ecologically relevant streamflow variability thompson et al 2013 and the matlab hydrological index tool can derive hydrological metrics from big data sets abouali et al 2016 these toolkits can efficiently calculate up to 171 hydrological metrics including iha metrics the pairwiseiha in python offers a novel perspective on flow regime analysis by contrasting the iha metrics of reservoir outflows with those of the inflows to illustrate how the magnitude frequency duration timing and rate of change are altered by reservoir operation the flow regime restoration is critical for ecological protection and river management given that dams affect more than half of large river systems around the world wang et al 2018 palmer and ruhi 2019 tonkin et al 2021 previous studies have found that reservoir operation has a great influence on downstream flow regimes in rivers by using the iha metrics magilligan and nislow 2005 cheng et al 2018 zhou et al 2020 the restoration of flow regime has attracted growing attention in water resources management for instance kiernan et al 2012 proposed that the high springtime flows regulated by dams facilitate the expansion of native fishes in lower putah creek in california of which the catchment area is 1650 km2 chen and olden 2017 found that the large water releases of navajo dam in late winter are beneficial to native species in the san juan river with a catchment area of 63840 km2 and suggested dams can serve as tools to provide the design flows and nakamura et al 2020 found that the artificial floods released by the satsunai river dam contributed to flow regime restoration by creating some suitable habitats for regeneration of riparian species in the satsunai river where the catchment area is 725 km2 in the future the pairwiseiha can be integrated into environmental models to account for flow regime objectives in ecological reservoir operation lloyd et al 2011 david et al 2013 6 conclusions this paper has built upon the popular iha software an open source pairwiseiha toolkit that offers a new perspective by focusing on the differences between reservoir inflows and outflows the four steps i e data inputs pre processing processing and analysis of results can easily be used for the assessment of environmental flow of headwater reservoirs the pairwiseiha toolkit has been applied to three case study reservoirs namely lake oroville folsom lake and pine flat lake in california to analyze the effects of reservoir operation on flow regime the results overall showed that the iha metrics of reservoir outflows were considerably different from the iha metrics of inflows and that the flow regime alterations were consistent across wet normal and dry years in the future more efforts can be devoted to integrating the pairwiseiha into environmental models to comprehensively consider flow regime objectives in ecological protection and river management credit author statement zexin chen visualization investigation writing original draft tongtiegang zhao conceptualization methodology writing review editing tongbi tu validation writing review editing xinjun tu data curation xiaohong chen validation supervision software and data availability software name pairwiseiha developer zexin chen and tongtiegang zhao year first available 2022 hardware requirements pc system requirements windows linux mac program language python program size about 200 kb availability the python scripts of pairwiseiha is submitted as the e component of the paper data sets sacramento district s water control data system wcds https www spk wc usace army mil and california data exchange center cdec https cdec water ca gov declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is jointly supported by the ministry of science and technology of the people s republic of china 2021yfc3001000 the natural science foundation of china 51979295 51861125203 u1911204 52109046 and 518790288 the guangdong provincial department of science and technology 2019zt08g090 and the water science and technology innovation project of guangdong province 2020 27 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105427 
25580,the pairwiseiha is an open source toolkit written in python that enables the user to quickly obtain the indicators of hydrologic alteration iha from inflow and outflow time series for headwater reservoirs specifically the iha metrics obtained from inflows outflows are considered as natural regulated and the differences are used to indicate how the magnitude frequency duration timing and rate of change are altered by reservoir operation it extends the functionality of the popular iha software for analyzing concurrent inflows and outflows the results of three case study reservoirs in california highlight that reservoir operation leads to considerable alterations in the five components of the flow regime the findings on flow regime alteration are consistent across wet normal and dry years overall the pairwiseiha can serve as an effective tool to investigate alterations in flow regime induced by human activities for water managers scientists natural resource agencies and water users keywords flow regime reservoir operation natural inflow regulated outflow indicators of hydrologic alteration range of variability approach 1 introduction the natural flow regime plays a critical role in creating the dynamics of in channel and floodplain conditions that are critical for maintaining ecological integrity in riverine ecosystems poff et al 1997 grill et al 2019 from an evolutionary perspective aquatic and riparian organisms have adapted to the natural hydrological variations including floods and droughts lytle and poff 2004 on the other hand human activities such as reservoir operation have substantially altered the flow regime across more than half of large river systems around the world cheng et al 2018 wang et al 2018 grill et al 2019 the alterations prompt a range of ecological responses that threaten the biodiversity of riverine ecosystems zuo et al 2015 zhang et al 2017 wang et al 2018 therefore enhanced knowledge of flow regime alterations induced by reservoir operation is critical for policy makers and water managers to support environmental flow management zhao et al 2015 horne et al 2017 nayeb yazdi et al 2019 barton et al 2020 zhou et al 2020 the indicators of hydrologic alteration iha have been proposed to assess alterations in flow regime by examining the characteristics of streamflow before and after a particular human activity richter et al 1996 specifically five components of iha metrics i e the magnitude frequency duration timing and rate of change are calculated from streamflow time series by water year then they are examined across water years to illustrate any trends and step alterations in flow regime richter et al 1996 gao et al 2009 li et al 2018 the range of variability approach rva uses the iha metrics to quantify the degree of flow regime alteration and to identify management targets for regulated rivers richter et al 1997 cui et al 2020 investigated flow regime alteration due to climate change and dam construction on the upper yellow river basin and analyzed potential impacts of flow regime alterations on riverine ecosystems and chalise et al 2021 quantified the degree of flow regime alteration across the conterminous united state and illustrated its importance for protection of the ecological environment iha software which was developed by the nature conservancy https www conservationgateway org presents an effective and efficient way to derive the 33 iha metrics from daily streamflow time series richter et al 1996 1997 mathews and richter 2007 the software provides tabular summaries and graphical outputs for the analysis of hydrologic impacts of human activities in an iha application users only need to supply daily streamflow time series and specify a few parameters then the software automatically presents the time series of iha metrics by year mathews and richter 2007 the iha metrics and rva results derived by the iha software have been widely used to aid ecological protection and river management butchart kuhlmann et al 2018 gebremicael et al 2019 tian et al 2019 cui et al 2020 hernandez suarez et al 2021 this paper details a new open source toolkit called pairwiseiha to illustrate the specific impact of reservoir operation on flow regime by contrasting the outflows with the inflows for headwater reservoirs there is an obstacle to the direct application of the popular iha software for the analysis of concurrent inflows and outflows of headwater reservoirs this is because the iha software focuses on one time series by examining the iha metrics before and after a certain human activity whereas inflows and outflows are two concurrent time series tian et al 2019 cui et al 2020 gunawardana et al 2021 the pairwiseiha bridges this gap by directly contrasting the iha metrics of inflows and outflows to show how the flow regime has been altered as will be demonstrated through the results of three case study reservoirs in california the pairwiseiha toolkit is effective in quantifying the alterations in flow regime induced by the operation of headwater reservoirs 2 toolkit capabilities 2 1 overview of pairwiseiha the pairwiseiha is a toolkit written in python to investigate the effects of reservoir operation on the flow regime for a target headwater reservoir the iha metrics are used to indicate the flow regime alterations the 33 iha metrics can be divided into five groups specifically there are 12 metrics of magnitude of monthly water conditions 12 metrics of magnitude and duration of annual extreme water conditions 2 metrics of timing of annual extreme water conditions 4 metrics of frequency and duration of high and low pulses and 3 metrics of rate and frequency of water condition changes richter et al 1996 mathews and richter 2007 the rva targets are determined by the range of each of the iha metrics richter et al 1997 zolezzi et al 2009 there are four steps of the pairwiseiha to analyze the flow regime alterations as shown in fig 1 the first step is to prepare the time series of inflow and outflow the second step is to interpolate missing data using monthly mean values the third step is to calculate the iha metrics of the inflows and of the outflows for the third step there are three sub steps defining the local water year setting high and low pulse thresholds and calculating iha metrics the reason three sub steps are used is that hydrologic statistics of the iha metrics of inflows and outflows are calculated by the local water year which is a 12 month period beginning in the month of the lowest average monthly inflow for headwater reservoirs wasko et al 2020 the default definition of high pulse is those periods where the daily streamflow within a year rises above the 75th percentile of inflows and the low pulse is those periods that drop below the 25th percentile of inflows richter et al 1996 the iha metrics are derived from both inflows and outflows using the high and low pulse thresholds the fourth step is to measure the degree of hydrologic alteration which uses the rva to evaluate the flow regime alterations for headwater reservoirs the hydrologic alteration can be analyzed across wet normal and dry years the pairwiseiha outputs the iha metrics by using the comma separated values csv file that can be easily used by other software 2 2 mathematical formulations the times series of daily inflow and outflow are indexed by subscripts yyyy mm and dd which represent year month and day respectively in the meantime the time series of daily inflow are denoted by i and i and the time series of daily outflow by o and o 1 i i y y y y m m d d o o y y y y m m d d in which i o is the set of inflow outflow and i o represents individual values of inflow outflow the iha metrics are calculated from i and o the first group is comprised of the iha metrics of magnitude of monthly water conditions 2 i m m i y y y y m m o m m o y y y y m m in which i m m o m m is the set of monthly inflow outflow indexed by mm i e january february december i y y y y m m o y y y y m m is the average of daily inflow outflow in month mm year yyyy the second group is comprised of the iha metrics of magnitude and duration of annual extreme water conditions 3 i x d m n i y y y y x d m n o x d m n o y y y y x d m n and 4 i x d m x i y y y y x d m x o x d m x o y y y y x d m x the x day xd minimum mn and maximum mx flows are derived by year from the daily time series of inflow outflow the value of x is set as 1 3 7 30 and 90 following the standard setting of the iha software mathews and richter 2007 in addition the number of zero flow days and base flow index are derived the third group is comprised of the iha metrics of timing of annual extreme water conditions 5 i d o y m n i y y y y d o y m n o d o y m n o y y y y d o y m n and 6 i d o y m x i y y y y d o y m x o d o y m x o y y y y d o y m x in which the day of year doy of minimum mn flow and maximum mx flow are derived by year from the daily time series of inflow outflow which follows the user manual of the iha software mathews and richter 2007 then the doy of both minimum flow and maximum flow are converted into the circular date li et al 2017 7 φ 360 d o y 366 the fourth group is comprised of the iha metrics of frequency and duration of high and low pulses 8 i l p f r e i y y y y l p f r e o l p f r e o y y y y l p f r e and 9 i l p d u r i y y y y l p d u r o l p d u r o y y y y l p d u r the frequency fre and duration dur of low pulse lp are derived by year from the low pulse of inflow outflow i y y y y l p f r e o y y y y l p f r e is the count of low pulse of inflow outflow in year yyyy i y y y y l p d u r o y y y y l p d u r is the average of low pulse duration of inflow outflow in year yyyy in addition the frequency and duration of high pulse are derived with the same method the fifth group is comprised of the iha metrics of rate and frequency of water condition changes 10 i r r i y y y y r r o r r o y y y y r r and 11 i f r i y y y y f r o f r o y y y y f r the rise rate rr and the fall rate fr are derived by year from the daily time series of inflow outflow i y y y y r r o y y y y r r is the average of rise rate of inflow outflow in year yyyy i y y y y f r o y y y y f r is the average of fall rate of inflow outflow in year yyyy in addition the number of reversals is derived the rva makes use of the iha metrics to evaluate the alterations in flow regime between inflows and outflows the rva target of each iha metric is generally defined as the 25th percentile to 75th percentile range of the iha metric of inflow richter et al 1997 the degree of hydrologic alteration developed by richter et al 1998 is evaluated with rva target ranges 12 d m n o m n e n e 100 in which d m is the degree of hydrologic alteration of the m th iha metric n o m is the number of observed years of the m th iha metrics of outflow locating in rva target range n e is the number of expected years locating in rva target range n e r n t r is the ratio of iha metric of inflow within the rva target and n t is the sample size of inflow or outflow with the unit of year d m below 33 indicates low degree change from inflows to outflows d m between 33 and 67 moderate degree change and d m above 67 high degree change 2 3 analysis for wet normal and dry years as per water balance there is a close relationship between the magnitude and temporal distribution of inflows and outflows yin et al 2011 he et al 2020 therefore the alterations in flow regime in different inflow conditions may exhibit different patterns to compare the differences in flow regime alterations across wet normal and dry years the annual average inflows were used to define three types of the inflow condition using the standardized runoff index sri approach shukla and wood 2008 the sri was set by the inverse standard normal transformation 13 s r i φ 1 f r r in which r is annual average inflow f r is the cumulative distribution function cdf of the annual average inflow and φ 1 is inverse cumulative standard normal distribution the definitions of the wet normal and dry years are as follows 14 y w e t y s r i 0 5 y n o r m a l y 0 5 s r i 0 5 y d r y y s r i 0 5 in which y w e t y n o r m a l and y d r y is the set of wet years normal years and dry years the values of sri greater than 0 5 are defined as the wet years the values of sri between 0 5 and 0 5 are defined as the normal years and the values of sri less than 0 5 are defined as the dry years following shiau and wu 2007 the cumulative probabilities corresponding to the dry years are less than 31 the cumulative probabilities corresponding to the wet years are larger than 69 the other values are for the normal years 3 case study three headwater reservoirs in california which are lake oroville folsom lake and pine flat lake were selected to demonstrate the use of the pairwiseiha the location map of the reservoirs was shown in fig 2 1 the oroville dam on the feather river primarily provides flood control water supply and hydropower generation anghileri et al 2016 the impoundment of lake oroville has a volume of about 4 36 km3 notably lake oroville is the largest reservoir in the california state water project swp the quantity and timing of snowmelt show inter annual differences due to the large inter annual variability in temperature and precipitation of lake oroville 2 the folsom dam on the american river primarily serves for flood control hydropower generation and water supply for irrigation adams et al 2017 the impoundment of folsom lake has a volume of about 1 19 km3 releases by folsom lake largely influence the downstream environmental conditions 3 the pine flat dam on the kings river primarily provides flood control water supply and hydropower generation maurer 2007 the impoundment of pine flat lake has a volume of about 1 23 km3 and it is one of the largest reservoirs in california the time series of inflow and outflow of lake oroville folsom lake and pine flat lake were mainly collected from the sacramento district s water control data system wcds https www spk wc usace army mil due to the lack of data in the wcds the inflow and outflow data from california data exchange center cdec https cdec water ca gov was used as a supplement the wcds and cdec provide valuable hydrologic datasets for environmental management in california for about 200 reservoirs in california they provide the storage inflow and outflow at hourly daily and monthly timescales it is found that 0 02 of the inflow values are missing for pine flat lake and that there is no missing data for lake oroville and folsom lake it is also noted that 0 28 1 61 of the values of inflow outflow are negative for lake oroville which may be due to reservoir evaporation at the annual timescale the inflows generally match the outflows indicating limited effects of negative values on the water balance fig s1 in the supplementary material to facilitate the analysis the missing values were replaced by the monthly mean values and the negative values were replaced with zeros the analysis mainly focused on the results of lake oroville the similar results at the other two reservoirs were presented in the supplementary material 4 results 4 1 alterations in flow regime the reservoir inflows and outflows were presented in fig 3 by different colors corresponding to the values substantial differences were observed between the inflows and the outflows which can be attributed to reservoir operation the inflows in the feather river are largely snow dominated which resulted in high inflow in spring and low inflow in autumn on the other hand the outflows tended to be high in summer due to high human water demands during the dry season and they were low during the wet season zhu et al 2005 thus the seasonality of inflow had been substantially changed this outcome is attributed to the fact that lake oroville primarily serves urban and agricultural water demands during the dry season for the san francisco bay area anghileri et al 2016 similarly the outflows of folsom lake and pine flat lake see figs s2 and s8 also tended to be high in summer the time series of iha metrics except for the timing of annual extreme water conditions were plotted in fig 4 where the dash lines represented the rva range of each iha metric the monthly mean outflows in july august september and october largely deviated from those of inflows suggesting that the monthly mean flows in these months had been substantially changed due to the reservoir operation there were substantial differences between annual maximum outflows and annual maximum inflows since lake oroville serves flood control water supply during the wet dry season anghileri et al 2016 as the number of days increases the annual maximum inflows and outflows became more similar to each other implying the substantial regulation of reservoir operation on maximum flow in the short run and the reduced impact in the long run the durations of high pulse and low pulse of outflows were similar to those of inflows the annual changes in rise and fall rates of outflow were consistent with those of inflow which showed that the outflows were considerably affected by the inflows in addition the number of reversals of outflow was less than that of inflow the results indicated that the operation of headwater reservoir tended to smoothen the inflow variability the timing of annual extreme water conditions of iha metrics was presented in fig 5 as expected the dates of maximum and minimum flow were different for the inflows and the outflows the maximum inflows mainly occurred from february to march which is the wet season the maximum outflows were substantially later than those of inflows the minimum inflows mainly occurred from september to october while the minimum outflows mainly occurred from january to june which is the wet season these results were generally attributable to flood control during the wet season which stored excessive flood water for water supply during the dry season the degrees of hydrologic alteration of 33 iha metrics were shown in fig 6 by rectangular bars with different colors it was observed that the degrees of hydrologic alteration were different in the magnitude frequency duration timing and rate of change for lake oroville among the 33 iha metrics 10 metrics exhibited high degree changes and 14 metrics showed moderate degree changes most of the high degree changes were the magnitude of monthly water conditions i e six metrics of monthly flow the degrees of hydrologic alteration of monthly mean flow during the dry season were higher than those during the wet season most of the degrees of hydrologic alteration were negative indicating that most of the iha metrics were out of the rva range 4 2 analysis for wet normal and dry years the empirical cumulative distribution function ecdf was used to compute the sri to investigate the flow regime alterations in wet normal and dry years mckee et al 1993 the iha metrics except for the timing of annual extreme water conditions in wet normal and dry years were visualized by boxplots in fig 7 the monthly mean outflows during wet years were generally higher than those during dry years for annual maximum and minimum flows variations in the minimum outflows were generally larger than the maximum outflows during normal and dry years for high and low pulses the variations in the frequency of high and low pulses of outflow were generally larger than those of inflow during wet normal and dry years indicating that the outflows in extremely wet years tended to be more unevenly distributed the variations in rise and fall rates of outflow were larger than those of inflow during normal and dry years in addition the number of reversals of outflow was generally less than that of inflow during wet normal and dry years which showed that the alterations in number of reversals were generally similar during wet normal and dry years the timing of annual extreme water conditions of iha metrics in wet normal and dry years was presented in fig 8 the maximum and minimum inflows mainly occurred within the same season across wet normal and dry years for lake oroville combining the actual storage of reservoirs of california state water project the water release of lake oroville is dynamically adjusted based on downstream water needs and streamflow forecasts anghileri et al 2016 the maximum outflows were slightly later than those of inflows during wet years and were largely different during dry years the results indicated that the timing of extreme water conditions was altered to different extents during wet normal and dry years 5 discussion the pairwiseiha was developed to investigate the hydrological regime subject to reservoir operation this toolkit can supplement the iha software that assesses iha metrics before and after a particular human activity mathews and richter 2007 it is noted that there are other iha toolkits including the eflowstats in r and the matlab hydrological index tool thompson et al 2013 abouali et al 2016 the open source eflowstats provides flexible functions to calculate hydrological metrics indicating ecologically relevant streamflow variability thompson et al 2013 and the matlab hydrological index tool can derive hydrological metrics from big data sets abouali et al 2016 these toolkits can efficiently calculate up to 171 hydrological metrics including iha metrics the pairwiseiha in python offers a novel perspective on flow regime analysis by contrasting the iha metrics of reservoir outflows with those of the inflows to illustrate how the magnitude frequency duration timing and rate of change are altered by reservoir operation the flow regime restoration is critical for ecological protection and river management given that dams affect more than half of large river systems around the world wang et al 2018 palmer and ruhi 2019 tonkin et al 2021 previous studies have found that reservoir operation has a great influence on downstream flow regimes in rivers by using the iha metrics magilligan and nislow 2005 cheng et al 2018 zhou et al 2020 the restoration of flow regime has attracted growing attention in water resources management for instance kiernan et al 2012 proposed that the high springtime flows regulated by dams facilitate the expansion of native fishes in lower putah creek in california of which the catchment area is 1650 km2 chen and olden 2017 found that the large water releases of navajo dam in late winter are beneficial to native species in the san juan river with a catchment area of 63840 km2 and suggested dams can serve as tools to provide the design flows and nakamura et al 2020 found that the artificial floods released by the satsunai river dam contributed to flow regime restoration by creating some suitable habitats for regeneration of riparian species in the satsunai river where the catchment area is 725 km2 in the future the pairwiseiha can be integrated into environmental models to account for flow regime objectives in ecological reservoir operation lloyd et al 2011 david et al 2013 6 conclusions this paper has built upon the popular iha software an open source pairwiseiha toolkit that offers a new perspective by focusing on the differences between reservoir inflows and outflows the four steps i e data inputs pre processing processing and analysis of results can easily be used for the assessment of environmental flow of headwater reservoirs the pairwiseiha toolkit has been applied to three case study reservoirs namely lake oroville folsom lake and pine flat lake in california to analyze the effects of reservoir operation on flow regime the results overall showed that the iha metrics of reservoir outflows were considerably different from the iha metrics of inflows and that the flow regime alterations were consistent across wet normal and dry years in the future more efforts can be devoted to integrating the pairwiseiha into environmental models to comprehensively consider flow regime objectives in ecological protection and river management credit author statement zexin chen visualization investigation writing original draft tongtiegang zhao conceptualization methodology writing review editing tongbi tu validation writing review editing xinjun tu data curation xiaohong chen validation supervision software and data availability software name pairwiseiha developer zexin chen and tongtiegang zhao year first available 2022 hardware requirements pc system requirements windows linux mac program language python program size about 200 kb availability the python scripts of pairwiseiha is submitted as the e component of the paper data sets sacramento district s water control data system wcds https www spk wc usace army mil and california data exchange center cdec https cdec water ca gov declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is jointly supported by the ministry of science and technology of the people s republic of china 2021yfc3001000 the natural science foundation of china 51979295 51861125203 u1911204 52109046 and 518790288 the guangdong provincial department of science and technology 2019zt08g090 and the water science and technology innovation project of guangdong province 2020 27 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105427 
25581,recent advances in information communication and environmental monitoring technologies have increased the availability spatiotemporal resolution and quality of water related data thereby leading to the emergence of many innovative big data applications among these applications visualization and visual analytics also known as the visual computing techniques empower the synergy of computational methods e g machine learning and statistical models with human reasoning to improve the understanding and solution toward complex science and engineering problems these approaches are frequently integrated with geographic information systems and cyberinfrastructure to provide new opportunities and methods for enhancing water resources management in this paper we present a comprehensive review of recent hydroinformatics applications that employ visual computing techniques to 1 support complex data driven research problems and 2 support the communication and decision makings in the water resources management sector then we conduct a technical review of the state of the art web based visualization technologies and libraries to share our experiences on developing shareable adaptive and interactive visualizations and visual interfaces for water resources management applications we close with a vision that applies the emerging visual computing technologies and paradigms to develop the next generation of hydroinformatics applications keywords big data hydroinformatics visual analytics visualization human computer interaction 1 introduction to date the water sciences discipline like many other scientific domains has been driven into the big data era with the advancement of next generation information and communication technologies researchers are confronted with rapidly growing amounts and variety of water related data which arise in many areas of water resources research and management and challenge the capabilities of current data analytics guo et al 2015 adamala 2017 despite many computational methods e g statistics numerical simulation machine learning ml are developed to address the avalanche of big data through intelligent and automated data analytics their implicit nature honegger 2018 has limited their ability to conduct exploratory analyses for information and pattern extraction or to support complex decision making for which human intelligence collaboration and justification are indispensable for decades the visual computing discipline has played an important role in exploring analyzing and presenting scientific data kehrer 2011 earnshaw et al 2019 it enables direct human interactions with computational methods to provide an effective integration of human reasoning into computational intelligence within the visualization community the research is separated into information visualization scientific visualization and visual analytics andrienko et al 2011 information visualization presents abstract data in visual formats e g charts graphs lists maps to facilitate human cognition for insight and pattern extractions burley and ashburn 2010 scientific visualization on the other hand focuses on rendering raw scientific data as often 3d graphics to enable a better depiction and interpretation of real world scientific phenomena and processes visual analytics emerges as an applied research discipline from computer graphics design and cognitive science to enable more advanced analytical reasoning capability on large information workloads by combining the strength of computational resources and human intelligence through sophisticated visual interfaces and dashboards thomas and cook 2006 these visual interfaces and dashboards often have more sophisticated analytical workflows that involve advanced user interaction techniques data transformation and coordinated views to enable users to explore different facets and perspectives of complex data simultaneously and logically 1 1 visual computing for scientific research in recent decades visual computing techniques have been applied in many disciplines few and edge 2007 koylu 2019 including social sciences wu et al 2016 climate science nocke et al 2015 wong et al 2014 urban science zheng et al 2016 transportation planning and mobility management andrienko et al 2017 berres et al 2021 and biomedical informatics wu et al 2019 to improve the knowledge building hypothesis generation and decision support of complex problems kohlhammer et al 2011 andrienko et al 2007 visual computing techniques bring unique value to big data analysis in which information overload and data complexity hinder effective dissemination communication and perception of data and research output as a particular example the us department of homeland security dhs has established the national visualization and analytics center to promote the development and application of advanced visual analytics technologies to provide a strategic advantage in emergency response and counter terrorism operations thomas and cook 2006 councilet al 2003 wong 2007 as a joint research effort of the national science foundation and dhs the foundations on data analysis and visual analytics fodava initiative was created to cultivate next generation visual computing techniques for scientific research dill et al 2012 kielman et al 2009 compared with other scientific disciplines visual computing applications are relatively limited in the water science sector we compared the research trends of visualization and visual analytics in different domains using search results from scopus https www scopus com we only identified 127 water resources management related documents from scopus when searching article titles keywords and abstracts for information visualization scientific visualization visual analytics visual analysis visual computing or visualization our search was conducted on 02 27 2022 for the time being we discovered that visual computing applications in the water resources management sector are not as well developed as they are for other science domains e g social science climate science transportation planning for which 1 000 4 000 visual computing related research documents can be discovered using the same search terms review and vision articles in other science disciplines often systematically incorporate visualization and visual analytics techniques into their domain specific approaches to create a well defined interdisciplinary research area whereas such articles do not exist for water resources management applications we also conducted an exhaustive search for hydrologic and water resources research applications defined as subject areas through the search terms published in the top tier visualization venues e g ieee vis and ieee transactions on visualization and computer graphics using scopus and could not identify any articles related to water resources management as many recent articles have presented fragmented visions to describe how certain types of data visualization and visual analytics techniques could practically benefit specific water related research and management applications tague and frew 2021 grainger et al 2016 we believe that more advanced and system based visual computing techniques can be applied to improve the water resources management repertoire from many different perspectives as the water science discipline enters the big data age more attention is given to the emerging computation techniques that enable ai through deep learning and hybrid models allen dumas et al 2021 adamala 2017 mar ç ais and de dreuzy 2017 lange and sippel 2020 past reviews that focus on the visualization of environmental data were limited to particular research applications as an example grainger et al 2016 provided a detailed review of environmental data visualization for non scientific contexts nevertheless the value of visual computing techniques as a critical investigative approach to support broad water resources research and management applications is often overlooked and rarely discussed in the literature review articles that focus on visualization and visual analytics applications in the water resources management sector are rare this situation limits the public awareness of the visual computing approaches and their potential for playing more important roles in water resources research and management applications to fill this gap we conduct a comprehensive review of recent visual computing applications in the water resource management domain first we focus on the methodological aspects of the visual computing techniques by reviewing a selection of successful research applications during the review we discuss the benefits and potential opportunities related to different visualization and visual analytics techniques for enhancing both the data driven research and the communication and decision making processes in various water resources management applications second we discuss the contemporary visualization technologies used for implementing advanced visual computing techniques we describe a strategy that integrates the emerging visual computing techniques into water resource management applications for amore holistic approach to smart city management of water resources we aim to share our experience and provide advice to lower the technical burden of development and allow non computer science domain experts researchers to develop useful visualization and visual analytics dashboards within shareable and accessible web applications 1 2 paper structure and organization our review is structured in the following way section 2 describes the motivation of this work section 3 focuses on the visual computing applications that support data driven research in water resources management section 4 dives into the communication and decision support aspects of visual computing applications for supporting collaborative and integrated water resources management with an emphasis on the social dimension of water resources both sections are outlined based on detailed research and application areas summarized in sections 2 3 1 and 2 3 2 section 5 describes the technical advancement in web based visualization technologies and their potential for benefiting hydroinformatics applications before going into detail on the visualization technologies some basic notations for computer graphics rendering in a web environment are clarified the remainder of the section summarizes popular web visualization libraries for creating charts plots web maps and 3d geospatial environments many libraries provide intuitive and well defined application programming interfaces apis we believe using these technologies can remarkably lower the technical burden of web development and allow both professional software developers and non computer science domain experts to develop useful visualization and visual analytics dash boards to support their research and water resources management applications finally section 6 presents our vision to integrate the emerging visual computing technologies and paradigms to create next generation hydroinformatics applications to support water resources management 2 motivation in this section we first review the current state of visual computing applications in the water resources management sector then we discuss the unique strengths and benefits of visual computing for supporting research and decision support applications through a dynamic human computer feedback loop finally we briefly discuss some application areas of visual computing techniques in the water resources research and management sectors these areas are summarized through the review of selected studies 2 1 current state over a long period of time data visualization tools have been developed for specific water management or hydroinformatics applications as marginal and supplementary components to support the production presentation and dissemination of analytical results from simulations and statistical models a similar bottleneck also exists in many other science domains for which visualization tools are considered the end product or side product of scientific research they are not deemed a pivotal research tool or major approach that can be adaptively and systematically applied to lead the scientific investigations themselves fox and hendler 2011 developed in the early 1990s the original concept of hydroinformatics stemmed from computational hydraulics abbott et al 1991 waldrop 1979 in which research efforts are primarily driven by the numerical simulation of water flows and related processes abbott and vojinovic 2013 during that time period data modeling and visualization techniques were complementary to the mainstream hydrologic and environmental modeling approaches in the past two decades however the emergence of data intensive science and increasing awareness of the social dimension of water management have expanded the scope of hydroinformatics and generated numerous opportunities for data driven and collaborative water research applications vojinovic 2012 adamala 2017 abbott 1996 subsequently these opportunities have triggered demands for effective analytical reasoning capabilities that require the involvement of multiple sectors e g research institutes management authorities policy makers including the public carson et al 2018 to this end these opportunities require a new hydroinformatics paradigm that can support the quantitative and qualitative analysis of big environmental data and address social needs and related concerns for water management manyika et al 2011 vojinovic and abbott 2017 the new paradigm could also benefit many emerging research efforts such as social hydrology which focuses on the exploration of the dynamic interactions and feedback between hydrologic and human processes sivapalan 2015 brelsford et al 2020 these efforts often require public participation and the use of complex multidomain urban hydro datasets with the emergence of the open government initiative ginsberg 2011 and open watre data initiative blodgett et al 2016 and the formation of collaborative hydrologic research communities such as the consortium of universities for the advancement of hydrologic science inc cuahsi and the national water center a tremendous amount of hydrologic data and data driven tools have become freely available and can be accessed through a variety of web platforms examples of these platforms include the usgs s national water information system and cuahsi s hydroshare tarboton et al 2014 maidment 2016 the new hydroinformatics paradigm has generated demands and opportunities for researchers to integrate more visual computing techniques into the water management sector for now most studies in the water science sector only employ basic forms of visualization e g graphs charts maps data viewers in their water management and hydroinformatics applications they primarily use visualizations to facilitate the presentation and dissemination of hydrologic data simulation results and research output advanced visual computing and human computer interaction techniques are often missing from these applications these techniques include 1 visual analytical reasoning 2 visual representations and interaction and 3 data representation and transformation thomas and cook 2006 given the current state of the water science sector we believe there are many opportunities to use visual computing techniques in a more systematic way and combine them with traditional investigative methods such as environmental modeling and experimental methods in section 2 2 we detail a systematic use of visual computing techniques by developing a dynamic human computer feedback loop endert et al 2014 2 2 benefits of visual computing techniques we believe the major benefit and strength of visualization and visual analytics in big data analytics is their capability to create cycles of feedback between humans and computers we refer to these cycles as the feedback loops which are important parts of a visual analytical pipeline fig 1 these loops have a significant advantage in facilitating human perception and reasoning during the analysis of massive and complex environmental datasets 2 2 1 feedback between humans and computers within the feedback loop visual computing techniques can address challenges that are difficult to solve using computational methods these challenges are often related to the complexity of water related data which are becoming increasingly multifaceted i e multivariate spatiotemporal multirun multivalued ensemble kehrer 2011 furthermore many environmental and hydrologic variables often exhibit a high degree of spatial and temporal variability asce task committee on application 2000 and their underlying environmental processes often interconnect with other riverine processes e g ecological biological stream morphological at a conceptual level the feedback loop is designed to place domain experts into the analytical pipeline to supervise the data analysis by applying human experiences justification and domain knowledge keim et al 2008 within the first iteration of the loop visual computing techniques are often combined with computational methods to present the abstract and processed data in an explicit way to help the domain expert understand the data and then extract useful data driven insights e g patterns causal inferences and anomaly detection after the initial visual analysis the domain expert i e as the user of the visual computing application can validate these insights using existing domain knowledge and principles which often lead to a theory guided interpretation for a better understanding of the insights as the next step the user can either use the derived insights to 1 enrich the existing body of knowledge 2 tune the parameters of the computation and visualization methods for a better output or 3 generate hypotheses to guide future research efforts using simulation models and experimental methods fox and hendler 2011 as the last step in the loop the simulation models and experimental methods can generate more new data and simulation outputs these outputs can be reintroduced into the feedback loop to start another iteration to further refine the data driven analysis 2 2 2 design techniques and strategy a feedback loop typically consists of two major components 1 computational methods and 2 objective driven visual computing methods for achieving a specific data analysis goal or exploring certain facets of the data these components are normally formulated based on one or multiple visual computing design techniques computational methods are introduced into the loop to facilitate the data representations and transformations these methods are primarily applied to transform and simplify complex environmental datasets into abstract forms to highlight important features and patterns the visual computing methods are created to facilitate the visual information seeking process shneiderman 1994 and they often employ one or many visual computing design techniques among these techniques are analytical reasoning visual representations and interaction data representations and transformations and presentation and dissemination of results thomas and cook 2006 ribarsky et al 2009 overall combining these techniques into a visual interface can enable users to explore and understand different facets of a complex dataset and connect information and patterns identified at different data facets into a logical data story that complies with the existing domain knowledge and enables users to derive new insights for knowledge generation a common design strategy for creating visual interfaces follows the visual information seeking mantra shneiderman 2003 the mantra defines seven common types of data 1d 2d 3d temporal multidimensional tree and network data and seven visual analytical tasks zoom filter details on demand relate history and extract these visual analytical tasks are often implemented in a visual interface as user interaction techniques to optimize the visual information seeking process during a visual analysis the mantra specifies a sequence of visual analytical tasks overview first then zoom and filter and then details on demand shneiderman 2003 based on this mantra the designer should first identify the data type and data facets that must be analyzed to meet the objective of the visual analysis then the designer should select a suite of visual representations e g maps graphs charts visual encoding that can effectively visualize the identified data facets each of these visual representations is tasked with visualizing specific data facets e g temporal spatial multivariate multiscale after the selection of graphs and charts the designer must associate individual visual analytical tasks with each chart or graph as an example a map is designed to provide an overview of the spatial facets of a dataset therefore it is associated with the overview task afterward multiple charts and graphs should be linked to create coordinated views based on the task sequence specified by the mantra different tasks associated with graphs and charts are then translated into different user interaction techniques the user can directly interact with the data in a chart facet e g zoom and filter through different keyboard and mouse events e g mouse click and hover and observe the variation and patterns in other data facets through the automatically updated coordinated views because the coordinated views can visually connect variations and patterns across different data facets the user can use these views to observe interconnections and correlations between multiple variables ensembles and spatial and temporal scales the process should eventually help the user derive new qualitative insights e g empirical relationships in addition computational methods e g statistical and ml models are connected to the visual computing techniques and they can be used to conceptualize and quantify the derived qualitative insights using mathematical representations and statistical metrics 2 3 applications in water resources management here we discuss application areas in the research sector which is driven by scientific investigation and exploratory analysis of hydrologic data as well as the water resources management sector which is focused on water resources planning management practices and decision optimization during the discussion of each sector we summarize areas that can benefit from visualization and visual analytics based on the review of successful applications 2 3 1 research sector for supporting research activities in water resources management visual computing techniques can support data driven studies to facilitate the analysis and human understanding of massive dynamic ambiguous multifaceted and conflicting data the human computer feedback loop can bring unique capabilities to the data analytics and environmental modeling efforts by allowing the modeler to interact with hydrologic environmental simulations and data models and their outputs through visual interfaces and automated pipelines based on our literature review we summarized a list of benefits enabled by visual computing techniques improved discovery management and quality control of massive water related data fuhrmann 2000 ames et al 2012 leonard et al 2017 horsburgh and reeder 2014 jadidoleslam et al 2020 improved interpretation and optimization of simulation models kratzert et al 2019 tian et al 2016 su et al 2016 zhang et al 2017 deval et al 2022 and enhanced qualitative analysis and exploration e g extraction of patterns and empirical relationships of complex hydrologic and environmental data mazher 2020 xu et al 2019 walker et al 2020 accorsi et al 2014 marbouti et al 2018 smith et al 2016 sanyal et al 2017 clark 2022 visual computing techniques can be applied to a number of water related research areas to facilitate big data driven studies these areas include but are not limited to hydrologic response water quality soil water interaction water hazard mitigation and the water food energy nexus a detailed discussion and use case analysis of how visualization and visual analytics can benefit these research areas are presented in section 3 2 3 2 planning and management sector unlike the research sectors water resources planning and management applications often focus on complex decision support processes with an emphasis on the social dimension of water resources one of the critical needs is to bring the public sector into water resources planning and management processes paniconi et al 1999 through effective communication because many watershed management activities require the understanding consent and support from local communities e g water managers landowners residents other local stakeholders examples of these activities include the installation or retrofitting of hydraulic structure and urban water infrastructure e g weir sensors retention ponds groundwater wells the modification of land use and land cover e g the conservation reserve program for increasing a communities resilience to water related hazards and the relocation of structures and infrastructure for reducing potential flood damage carson et al 2018 to this end public engagement and participation are essential for enabling a holistic and integrated water resource management approach that addresses the needs of various social groups and communities in a watershed to support this social dimension of the water resources management many studies integrate visual computing techniques into the emerging web based technologies to provide easy to understand visual representations these practices serve as effective means for conveying and disseminating research output visions and complex concepts of environmental and watershed processes to the general public in the spirit of the expression a picture is worth a thousand words many of these visual techniques are friendly explicit and intuitive for nontechnical participants e g stakeholders policy makers students involved in water resources management these visual techniques are then integrated into web applications that can be accessed through the internet using various devices thereby providing efficient and low cost agents to promote water science education to nontechnical audiences with the goal of raising public awareness of many water resource related issues gober et al 2003 more recent studies have integrated visual computing techniques into serious games which are games developed for serious applications rather than entertainment to encourage public participation and engagement in water management some of these techniques entail visually appealing representations and intriguing user interaction workflows this practice can bring a fun factor to users during a water resources planning and education task as a result visual computing techniques when devised properly can be applied to lower the technical barrier of water management they can effectively incentivize the public sector to participate and engage in the collaborative planning and decision making processes in addition visual analytics techniques are frequently used as effective tools for optimizing multiobjective and multicriteria decisions to support the management of water resources in both rural and urban areas matrosov et al 2015 reed and kollat 2013 these application areas include the following promoting water education and raising public awareness of various water related issues demir et al 2018 haynes et al 2018 sermet and demir 2020 facilitating collaborative water management and public engagement xu et al 2020 sermet et al 2020 sermet and demir 2022 and optimizing multiobjective and multicriteria decision problems for water management aydin et al 2015 matrosov et al 2015 reed and kollat 2013 3 visualization for data driven research this section begins with the review of data visualizations to introduce popular graphs charts and visual encoding and representations that are often used for analyzing hydrologic and environmental data the remainder of this section then reviews the application of visualization and visual analytics in various application areas as summarized in section 2 3 1 that benefit data driven research for water resources management 3 1 visualization of hydrologic data historically visual analyses of hydrologic data were superseded by computational methods during the time period when most research was led by physical conceptual and statistical models ladsonet al 2018 many visualizations were integrated into domain based methodologies and played critical roles in supporting hydrologic analyses examples of these visualizations include thiessen polygons unit hydrographs and graphical routing methods adamala et al 2019 ladsonet al 2018 the situation began to change when more data driven analyses were introduced into water resources management water related data are complex and entail multiple data dimensions and facets many hydrologic modeling efforts require mapping and displaying spatial data e g topography and hydrologic units with the recent evolution in information and sensor technologies that enable better data acquisition access and organization maidment 2008a more effort has been expended on the visualization of hydrologic and environmental data to support more advanced data management and analytics tasks for example many hydroinformatics systems use visualization to facilitate data discovery and quality control many recent research applications often share the spirit of bringing water observational data together through big data cyberinfrastructure and hydroinformatics systems maidment 2008a 2008b josset et al 2019 examples of these applications include cuahsi s hydrologic information system his usgs s national water information system and the national climatic data center s climate data online 3 1 1 simple charts graphs and maps previous hydrologic visualization research mainly focused on the effective visual presentation of different types of hydrologic and environmental observations of multidimensional data e g spatial temporal multivariate and ensemble tarboton et al 2008 similar to traffic flow data connected to road networks water related observation data are closely associated with individual hydrologic units e g stream river corridor catchment that topologically connect through a hierarchical network structure in a watershed system in this regard many hydrologic observations also have a topological dimension to visualize a single dimension of hydrologic data e g the temporal or spatial dimension basic charts graphs and visual representations are adequate ladson et al ladsonet al 2018 summarized a list of basic visual representations that are frequently employed to visualize time series hydrologic data that present stage discharge relationship flood frequency and duration curves and unit hydrographs these representations consist of different variations of the line graph bar chart heatmap and circular plot and can be used to present changes in a single variable or to compare multiple time series data 3 1 2 advanced visual encoding and representation visualizing multiple facets of the hydrologic data at the same time is a more challenging task that often requires more advanced visual encoding and representation many studies link multiple charts into coordinated views each of which focuses on a single component or scale of the data united states geological survey united states geological survey 2020a encoded bar charts for visualizing time series data that reflect the number of water gauges in each us state into a matrix that presents state locations topologically in 2d space fig 2 a the link graphs and charts can be used to view the temporal and spatial variability of the complex data to display the overall trends and can also depict detailed variations and patterns within a specific dimension linked visualizations often require well defined user interaction techniques to synchronize the display of different charts and graphs based on different user actions e g selection of a subset of data or filter data based on specific attributes or regions burch and weiskopf 2011 devised an innovative timeedgetrees representation to visualize time varying water levels in multiple german rivers the representation visually encodes individual time series data into color gradient lines and rearranges them into a hierarchical structure that reflects river connectivity upstream downstream and confluences in a watershed the representation uses a hierarchical node link diagram as its basic layout to present the connectivity between individual streams each stream and its measuring site are denoted as a node and any time varying variables associated with the river can be visually encoded into that node fig 2b users can interact with the visual representation by filtering and zooming to a specific node or branch of the node link diagram the timeedgetrees can efficiently represent the temporal variation and topology of the water level data such that users can observe the dynamics of the time varying data in the context of flow continuity for example the visual representation can provide insights on how water level or temperature changes could affect the same variable in neighboring rivers its node link diagram can also be applied to visualize variables that reflect the wave propagation from upstream to downstream in a watershed united states geological survey united states geological survey 2020b adopted a stream graph representation to visually compare the flood duration measured at 65 stream flow sites over the past 20 years fig 2c the main goal of this visualization was to highlight a single stream gauge on the james river near stratford sd which was flooding continuously for 534 days while also comparing the flood duration at that site with that of other similar sites the efficient stacking of area plots allows a single graph to cover multiple dimensions simultaneously and avoid visual clutter caused by the intersection and overlying of multiple points and line features with more variety of hydrologic data available in better spatial and temporal resolutions the visualization of hydrologic data evolved from the utilization of simple and single graphs into the development of more advanced visual representations that can cover multiple facets of the water data these visual computing techniques have played important roles in supporting various hydrologic analyses and modeling efforts despite the usefulness of encoding more aspects of data visually into a single chart these visual representations are sophisticated and challenging for nondomain experts to interpret and understand compared with simple graphs and charts in many more advanced visual computing applications in which visual analytics become critical components to lead data driven research advanced data transformation and visual analytical reasoning techniques are required to supplement the visual encoding and representations we detail this aspect in section 3 2 with an emphasis on the design of a visual analytics workflow 3 2 data discovery management and quality control at the beginning of the 21st century fuhrmann 2000 pioneered the design and application of visual computing techniques for discovering and managing hydrologic data through the development of a low cost multimedia hydrologic visualization system hydrovis this system enables the visualization of digital hydrologic data and the documentation of hydrologic models for the weser river catchment hydrovis s visualization components consist of electronic maps temporal and nontemporal cartographic animations the display of geologic profiles interactive diagrams and hypertext e g photographs and tables many of these components such as electronic maps and cartographic animations could be considered prototypes of later web mapping and cyber geographic information system gis technologies that arrived in the web 2 0 age hydrovis was developed before the open data initiative luna reyes and najafabadi 2019 and served as a pilot study for exploring new media to promote visualizations of hydrologic data fuhrmann 2000 highlighted the future market and research needs for visualizing hydrologic data as well as the challenges posed by data sharing restrictions at the government level the advent of the open data initiative and web based technology brought the visualization of hydrologic data into the age of cyberinfrastructure during this period ames et al 2012 developed a web services based and open source software tool called hydrodesktop this revolutionary software tool allows users to search across and access hydrologic data services published through cuahsi his fig 3 a users can discover download manage and visualize hydrologic data retrieved from the cuahsi his data services using the hydrodesktop interface the novelty of hydrodesktop includes its data search and discovery ability through web services and its software extensibility by which it can incorporate custom data analysis and visualization plug ins the hydrodesktop visualization features are designed to support the discovery of hydrologic time series data these features include map based geovisualizations of monitoring locations and other spatial data and a visual interface with different plots to support the downloading organization visualization editing and maintenance of hydrologic time series data building on top of the hydrodesktop software system horsburgh and reeder 2014 addressed the interoperability aspect of the visualization and analysis of hydrologic data using web based hydroinformatics applications by developing a software plug in named hydror to link the cuahsi his with the r statistical computing environment fig 3b this link enables a straightforward hydrologic data management and analysis pipeline that allows hydrologists to discover and access a wide variety of hydrologic data provided from web based systems and repositories through the plug in users can directly import these data into widely used native hydrologic visualization and analysis environments demir et al 2018 further expanded the cyberinfrastructure approach for promoting the discovery and sharing of real time hydrologic data by developing an end to end web based platform called the iowa flood information system ifis the platform can effectively address multiple aspects of the decision making process for flood risk management and mitigation for the state of iowa fig 3c the platform was initially developed to enable centralized data access to and visualization of real time and historical water data e g water levels gauge heights hourly and seasonal flood forecasts rainfall conditions collected from a wide range of sources including next generation radar nexrad stations iowa flood center stream sensors and usgs and national weather service stream gauges for over 1 000 communities in iowa demir and krajewski 2013 developed based on integrated modular and adaptive system design ifis later evolved into a generalized flood cyberinfrastructure able to incorporate a variety of flood related data cloud based computing resources data analytics tools and advanced hydrologic models for supporting flood risk management and disaster preparedness and response efforts in iowa demir et al 2014 2018 from a visualization perspective the platform employed a number of advanced web based mapping and visual computing technologies to enable interactive visualization interfaces that allow users to explore and discover large volumes of diverse data retrieved from nexrad radars and over 500 sensors that describe real time stream conditions soil conditions and precipitation 50 gb of data every day the ifis visual interface employs a variety of charts and plots to enable the platform users to visually inspect and verify the availability of different hydrologic time series data and compare measurements between multiple sensors in a watershed these data visualizations 1 play an important role by allowing users to explore filter and discover flood related datasets collected from distributed sources and 2 provide a centralized interface to support data query and downloads the geovisualization capability of ifis allows the platform to display various gis layers and flood maps for selected communities in iowa these flood maps cover over 4 500 scenarios the ifis platform also provides evolutionary scientific visualizations and communication tools for promoting the social water dimension of flood management which will be detailed in section 4 demir et al 2018 developed the idea of an adaptive and modular web framework using superior software engineering and data structure design they built a generic and flexible pipeline for integrating a wide variety of hydrologic data models and data analytics with an html based gui and interactive web based visualization libraries the data visualizations provided by ifis are aimed at helping both technical users e g watershed managers researchers and nontechnical users e g stakeholders students as the platform becomes a more comprehensive decision support system for flood mitigation and watershed management more advanced user interaction designs are adopted to arrange coordinate and reuse various visualization interfaces embedded in ifis to ensure effective user interactions and clear design of userflows for various data discovery and decision support tasks rink et al 2012 presented an integrated approach for visual data management for the analysis and simulation of hydrologic processes through a real world use case their approach combines visual data management and numerical simulation to enable the discovery and selection of large datasets based on keywords and regions defined by users fig 3d the framework is built on a visual data management framework called the opengeosys data explorer which can import data from standardized file formats and databases and allow users to explore geoscientific data in a 3d space by displaying data related attributes on a digital terrain model the framework can serve as an easy to use tool for many data management purposes including surveying the availability of data modeling results in a specific region enabling integrated access to heterogeneous data collected from various sources searching for a defined subset using keywords and validating data through the detection of inaccuracies within a single dataset or inconsistencies across multiple datasets the data validation process is supported by the integration of different data structures and data viewers which allow the visualization of 2d data such as time series from dataloggers or stratigraphic profiles of boreholes rink et al 2012 also shared a vision to integrate tools for automatic parameter estimation into the framework to allow visual comparisons of measured data and simulated results in the future along with visual computing applications for data discovery and management advanced visual analytics workflows are developed to improve the quality control of large hydrologic and environmental datasets large scale hydrography datasets such as the national hydrographic dataset nhd often present limitations in stream and watershed connectivity such as disconnected and intermittent streams and subbasins buttenfield et al 2011 manually validating and correcting the connectivity and flow direction issues in millions of streams in the nhd is a time consuming and labor intensive effort that presents a big challenge to hydrologic modelers to address this challenge leonard et al 2017 presented the development and application of a visual analytics approach for the data cleaning and integration of the continental united states conus heterogeneous national hydrography data products using multiscale graph models the effort aims to support nation scale hydrologic modeling at the coarsest scale the approach first constructs a smaller graph using level 12 hydrologic unit code huc 12 watersheds as nodes to automatically validate the huc 12 watershed connectivity the concept of huc is explained in water resources of the united states seaber et al 1987 this automation can significantly reduce the data cleaning efforts that do not necessarily require human judgment when data issues require an expert judgement or high resolution datasets the graph model highlights these data issues and constructs a graph at a finer scale to assist human experts with reasoning and justification in the finer graph streams within a huc 12 node are represented as edges this setting allows expert users to inspect and correct data issues related to edge directions at a finer scale a visual interface is then created to allow expert users to analyze and interface with the graph model in summary leonard et al 2017 applied a visual computing approach to automate the analysis and cleaning of a conus hydrography dataset which consisted of about 851 million edges and 683 million nodes the effort also successfully demonstrated the effectiveness of its visual analytics workflow s capability of combining the computational power with human reasoning to resolve large scale data quality issues 3 3 interpretation and optimization of model data visualization also plays an important role in supporting hydrologic and environmental modeling efforts visual techniques have been widely applied to improve the presentation of hydrologic simulation output for the dissemination of model driven insights to researchers and decision makers jones et al 2014 koutsoyiannis et al 2003 visualization and visual analytics foster a better understanding of complex and partially unknown environmental processes tian et al 2016 namwamba 1998 and improve the evaluation and optimization of hydrologic models jadidoleslam et al 2020 rajib et al 2016 in past decades many applications were developed to visualize hydrologic modeling results using a variety of time series plots and geovisualizations powered by gis and web based mapping technologies sections 3 3 1 and 3 3 2 selectively review sophisticated visual analysis applications that utilize simulation data and ml to present unique visual analytics workflows that help the audience explore new insights in the simulation outputs these efforts are designed to help audience develop an in depth understanding of the modeling process both physical and data driven for better optimization strategies 3 3 1 simulation model data a few studies have focused on developing visualization frameworks to examine and explore complex environmental and hydrologic processes that are simulated using domain models for new insights and hypotheses these studies provide practical examples to demonstrate how visual computing techniques can be applied to support and improve modeling efforts in water and environmental research zhang et al 2017 focused on the development and design of computer based flow visualizations to help researchers explore and elucidate the dynamic flow process and the fluid movement laws the overall objective of these flow visualizations is to foster a better understanding of the complicated hydrologic cycle thereby improving watershed modeling and water resources management at the regional level zhang et al 2017 also evaluated various flow visualization methods e g scalar field visualization vector field visualization and visual water effects through a virtual watershed platform the platform can generate flow data using spatially distributed hydrodynamic models and visualize these data in a virtual 3d environment the platform allows end users to explore various hydrodynamic attributes of the flow and their interactions with other attributes such as terrain landforms and inhabitants case studies were conducted to demonstrate the platform s ability to visualize hydrodynamic features in river flows and ocean currents tian et al 2016 combined 3d exploratory visualizations with environmental modeling pipelines to facilitate the interpretation and validation of simulation output from physically based fully integrated surface water groundwater sw gw models their visualization tool was devised and implemented to incorporate sw gw modeling results promote data and model sharing among the water resources research communities and provide a virtual globe based 3d environment for visually exploring and validating modeling results su et al 2016 introduced a data oriented multidimensional and dynamic visualization software to explore massive marine hydrologic and environmental datasets and modeling results the software tool can visualize marine water environmental factors in a 3d interaction and volume rendering environment examples of these factors include an oceanographic planar graph contour line rendering isosurface rendering factor field volume rendering and dynamic simulation of the current field the visualization system was developed using the cuda sanders and kandrot 2010 parallel computing library to parallelize and increase the speed of volume rendering for marine water environmental data in a netcdf network common data form format the tool s high performance enables users to generate interactive visualizations based on different user defined scene and simulation properties the combined efforts of visualization and simulation models can help domain scientists and nontechnical water management communities to interpret simulation results from hydrodynamic models with an overall objective of improving the understanding of the complex hydrologic cycle these efforts also increase the practicability of hydrologic models for supporting decisions in real world water resources management operations 3 3 2 machine learning ml model data as more traditional ml and deep learning models are increasingly used to model hydrologic processes and predict environmental variables it is critical for both data scientists and hydrologists to understand the data models implicit and hidden training processes to validate and optimize model configurations one remarkable example is the application of long short term memory lstm networks for rainfall runoff forecasting lstms are particularly well suited for modeling the rainfall runoff process because their memory cells can represent dynamic reservoirs and storage thus this ml technique plays an important role in the state space modeling approach for analyzing the hydrologic system kratzert et al 2019 inspired by the visualization tool strobelt et al 2017 developed for recurrent neural networks with a focus on understanding changes in hidden state representations over time kratzert et al 2019 demonstrate a visual analysis tool that can help domain experts interpret and analyze trained lstm models for predicting discharge in two different catchments one with snow influence and one without they conducted a qualitative analysis of the correspondence between the hydrologic system and the learned behavior of the lstm in the first step of the analysis multiple line charts were employed to visualize the time steps of snow influence on the network output over the day of year doy unit and compare the discharge output with other variables such as the median precipitation discharge and minimum temperature the visual comparison revealed that the time steps of influence pattern matched the hydrologic understanding of the yearly pattern in the second step the study employed a scatter plot to show the average correlations between memory cells and hydrologic states for a basin without effective visual analysis tools deep learning networks such as lstms are difficult to interpret and understand which limits their potential for environmental research this is because many domain scientists value the physical representation of environmental processes and are not apt to trust deep learning models that involve black box representations strobelt et al 2017 in this regard effective visual analytics methods allow a deeper understanding and validation of these learning models and can serve as a bridge to connect the ml approach with traditional environmental modeling approaches these visual computing methods could bring judgment and intervention from domain experts into deep learning models to validate and optimize the construction of their networks for more reliable and explainable predictions of hydrologic variables the combined approach of visual analytics and deep learning could expand the vision of the theory guided data science approach that aims to fully leverage the power of ml and data driven methods in water science disciplines by deeply coupling them with domain models based on scientific processes and theories karpatne et al 2017 3 4 exploratory visual analytics many recent studies employ visualizations and visual analytics techniques as an independent investigative approach to conduct exploratory analysis of complex environmental datasets for data driven insights apart from traditional environmental modeling approaches these analyses can generate new data driven insights that reveal spatiotemporal patterns of a single hydrologic variable as well as empirical relations and causal inferences between multiple environmental and hydrologic variables these efforts often lead to knowledge discovery hypothesis formation and improved understanding of the environmental phenomenon that entails partially unknown and interlinked physical processes which are challenging to solve using existing environmental models 3 4 1 visual analytical reasoning this subsection introduces the basic visual analytical reasoning components and methods for conducting exploratory visual analysis the nature of exploratory visual analytics is to combine automated data analysis techniques with interactive visualizations for effective understanding reasoning and information seeking on the basis of very large and complex datasets keim et al 2008 therefore the two major techniques involved in the design of exploratory visual interfaces are 1 data representation and transformation and 2 visual representation and user interaction many visual analytics applications focus on the use of advanced data representation and transformation techniques powered by statistical and ml models to reduce dimensions of complex datasets and remove noise in the data they allow the visual analytics interface to highlight summarize and abstract key patterns and relationships in the raw dataset in a form that can be logically perceived by target audiences after a heavy lift in data processing analytical reasoning plays an important role in the design of a visual interface and its user interactions there are many well defined techniques for designing a visual interface for user interaction e g selection of plots chats visual representation coordination between different views these techniques were developed based on the visual analytical reasoning principles ribarsky et al 2009 to ensure a visual analytics application can achieve its objective functions e g easy to use efficient data analysis logical user workflows this subsection presents some example techniques to provide more context for visual analytical reasoning methods one of the most commonly used methods is the level of detail technique heok and daman 2004 which is a computer graphics technique for reducing visualization complexity based on the rendering object s importance viewpoint relative speed or position heok and daman 2004 the technique is often applied in visual analytics to highlight important patterns based on 1 a user s interaction and selection of data facets and scale and 2 the importance of specific features in a massive dataset uchida and itoh 2009 the method can significantly improve the efficiency of a visualization by reducing potential visual clutter and noise caused by rendering unnecessary data other methods that can increase the effectiveness and evaluate the usability of a visual analytics technique include heuristic evaluation cognitive walkthrough and the human cognitive model nielsen w nielsen and mack 1994 ribarsky et al 2009 ribarsky et al 2009 provided a detailed summary and explanation of the analytical reasoning theory and its related techniques 3 4 2 data transformation and representation many studies focus on exploratory data analysis in a specific water research domain such as water quality surface runoff erosion and sediment transport and the energy water nexus ewn many of these studies incorporated more sophisticated data transformation and abstraction techniques to support visual representation and user interaction techniques for pattern extraction from complex data and simulation results common data transformation and representation techniques include statistical and mathematical models metrics and data mining techniques powered by ml models e g classification and clustering methods accorsi et al 2014 developed hydroqual to facilitate visual analysis of river water quality affected by intertwined natural processes and human activities this tool was developed to address the limitation faced by gis and statistical methods that fail to produce reliable results owing to data scarcity in some regions hydroqual combines spatiotemporal data mining and visualization techniques to help domain experts analyze and evaluate water quality data and their relationships with other environmental and urban factors during the visual interface design process accorsi et al 2014 proposed a novel metric to assess sequential dissimilarity in data through clustering and an optimized algorithm to extract temporal patterns in addition to the novel data transformation techniques a new algorithm for visualizing clusters and their associated optimization processes was devised and integrated into the visual interface in a case study hydroqual was applied to successfully highlight the relationship between values of a biological index and physicochemical parameters describing river water quality mazher 2020 presented a visual analytics workflow for analyzing high dimensional spatiotemporal hydrologic gridded datasets using ml models created based on dimensionality reduction techniques drts the study first evaluated the performance of various ml based drts in terms of their accuracy in data transformation dimensional reduction and visual presentation of transformed data these drts include principal component analysis generative topographic mapping t distributed stochastic neighbor embedding and uniform manifold approximation and projection the accuracy of these techniques was evaluated using a co ranking framework as a quality metric afterward mazher 2020 selected the best performing drt and implemented it into a generic analytical workflow the framework can project high dimensional spatiotemporal data on a 2d plane using a drt and then represent the 2d projection spatially using a 2d perceptually uniform background color map this workflow was applied to analyze the output of an australian water resource assessment model for tasmania australia the integration between ml powered data transformation analysis techniques and the 2d visual representation of processed data could significantly improve the human reasoning and perception of complex patterns in high dimensional multivariate environmental datasets xu et al 2019 devised a web based visual analytics workflow that can integrate various ml based data transformation techniques with a variety of spatial and multivariate visualizations to explore the complex environmental processes related to soil erosion and sediment transport near culverts the workflow offers systematic procedures to 1 classify the culvert sedimentation degree using a time series of aerial images 2 identify key process drivers from a variety of environmental and culvert structural characteristics through ml powered feature selection algorithms and interactive visual interfaces 3 support human interactions to perceive empirical relationships between drivers and the culvert sedimentation degree through multiple multivariate visualization techniques and a self organizing map som and 4 forecast culvert sedimentation potential across iowa using tree based ml algorithms through a case study xu et al 2019 applied the visual analytics workflow to analyze a large integrated environmental dataset that entails culvert operation conditions from the iowa department of transportation s structure inventory and inspection management system watershed characteristics from the epa s stream catchment dataset and stream corridor characterization using iowa s land use and land cover dataset and the nhd plus the analysis generated new insights that revealed a strong correlation and quantitative relationships between the degree of sediment deposition at culverts in iowa and the state s geological landform regions this insight was converted to a hypothesis and used to guide further investigations using the physically based water erosion prediction project model s simulation outputs xu 2019 clark 2022 developed a visual analytics aided deep learning approach to improve the understanding of the sustainability of current groundwater extractions in the namoi region of australia the approach combined unsupervised som with supervised long short term memory lstm models to effectively abstract patterns from a diverse set of groundwater monitoring time series to facilitate the exploratory analysis of complex hydrogeological dynamics in the namoi region the combined models enabled the predictions of water levels based on climate and anthropogenic conditions at the same time the som can also visualize the shared pattern information from across the namoi system to reduce the complexity of analyzing multiple time series the resulting visual analysis shares information between sparse time series that could not be modeled with the lstm individually sanyal et al 2017 started with a broad strategy of investigating the complex dynamics of the ewn and its interactions with climate variability from a more holistic perspective the strategy takes a variety of socioeconomic and environmental factors such as energy production and urban climate into consideration during the management of urban water resources along with this vision a web based geospatial visualization platform was developed to integrate various data analysis toolboxes with advanced data fusion and data visualization capabilities to create a knowledge discovery framework to analyze the ewn the unique contribution of the study includes the creation of an adaptive modular and flexible architecture to generate dynamic visual analytics workflows through the integration of different software modules berres et al 2018 these modules include data analysis and transformation packages for statistical visual analysis clustering principal component analysis dynamic time warping and various geovisualization and uncertainty visualization libraries 3 4 3 user interaction walker et al 2020 focused on integrating advanced user interaction techniques into interactive visualizations by presenting a web based data visualization framework the framework debuted as the interactive catchment explorer ice and was developed to help natural resource managers and researchers 1 visually explore complex and multivariate environmental datasets and modeling results 2 identify spatial patterns related to ecological conditions and 3 prioritize locations for restoration or further investigation the framework employs a client side architecture and is deployed as an integral part of the spatial hydro ecological decision system a geovisual interface was created within the ice to display catchments across the northeast region of the united states catchment characteristics can also be visualized through color coded symbology displayed on a web map embedded within the visual interface through a series of user interaction techniques users can select and examine the statistical summary of multiple catchment characteristics represented as hydrography hydrologic ecological and environmental variables through an array of interactive histograms placed alongside each other the map of color coded catchments is displayed simultaneously this stereo arrangement of the plots and web map can help users observe correlations between different catchment characteristics by providing a coordinated view with various user interaction options this arrangement also allows users to filter and focus on subsets of data by defining thresholds through the interactive histograms at the same time the color coded display of catchment characteristics is updated based on the user s interaction to present patterns and variability for a selected environmental variable similarly marbouti et al 2018 presented watervis a geovisual analytics application designed to support the monitoring and management of hydrologic and environmental resources the tool was designed to identify environmental factors that contribute to changes in river water levels as well as enable the predictive analysis of the river stage similar to ice the design and development efforts of watervis also focused on advanced user interaction techniques in this regard both tools can serve as effective and generalized visual analytical frameworks that allow domain experts to explore potential correlations between different environmental variables which can help identify contributing factors associated with a specific environmental process 4 visualization for communication and decision support hydroinformatics and water resources management applications normally entail three major dimensions the natural dimension the social dimension and the business dimension chen and han 2016 among these dimensions the social dimension is defined as the interaction between the water environment and humans society chen and han 2016 abbott 1996 it promotes the engagement and participation of the general public in various water management and planning processes to address social concerns and needs related to water management ethics and culture this dimension also considers challenges associated with transboundary water issues and conflicting water management goals from different water management authorities priscoli 2004 recent approaches for integrated water management often entail practices designed to address the social dimension of the water resources these practices promote water education to raise public awareness of water management issues facilitate collaborative planning and public engagement in water management and encourage voluntary social sensing of water related data floress et al 2015 seelen et al 2019 reges et al 2016 they often rely on community driven efforts that involve the participation of multiple water management related participants e g watershed managers stakeholders decision makers and policy makers to solve various water related problems related to the security supply conservation and sanitation of water resources in both agricultural watersheds and urban areas vojinovic and abbott 2017 moglia and sharma 2009 among these practices the communication between multiple water resources management sectors and participants is of great importance to facilitate effective communication visual computing techniques combined with the recent web based technologies can produce effective media to bring various participants into a collaborative problem solving environment to support the planning and decision making processes koontz and newig 2014 palmer et al 2013 visual computing techniques bring unique advantages to promote the social dimension of integrated water management many visualizations are intuitive and easy to understand which allows nontechnical water management participants e g stakeholders to understand complex scientific concepts furthermore visual analytics applications can also provide solutions to optimize complex decision problems in integrated water resources management applications while bringing human input e g experiences of watershed managers into the process biswas et al 2012 prato and herath 2007 lai et al 2008 4 1 water education for public awareness visual computing applications especially scientific visualizations and visual storytelling workflows can provide practical tools to support water education and training through intuitive and user friendly visual communications visual computing techniques can help students and local water management communities develop in depth understandings of complex interlinked and multiscale environmental processes to support their development of essential knowledge skills and strategies for solving water management problems meanwhile visual computing techniques are easy to understand and can be readily disseminated and shared through web applications and smartphone apps which are an effective means to raise public awareness of contemporary water problems and survey the needs concerns and voluntary water resources data provided by the public demir et al 2018 and xu et al 2020 integrated a watershed search engine and catchment characterization tool in publicly accessible online watershed information systems to educate nontechnical users e g urban residents stakeholders on the basic concepts of watershed systems such as the hydrologic cycle and stream connectivity these concepts could help many landowners understand where the water on their properties comes from and how different land management practices could affect the quantity and quality of water flows in downstream areas demir et al 2018 also employed a series of advanced scientific visualizations as cyberlearning tools to enable the decision support and education to raise the public awareness for disaster preparedness and response these tools include web based interactive visualizations for displaying streamflow direction fig 4 b a rainfall runoff simulator fig 4c and a flood map flyover simulator fig 4d demir 2014 embedded a hydrologic simulation system within a web based 3d interactive visualization environment that demonstrates different hydrologic processes and concepts for teaching purposes the simulation system was developed using advanced web technologies and a graphics processing unit to render physical behaviors of water flow and object collisions on realistic terrains it allows students to create or load predefined scenarios control environmental parameters and evaluate environmental mitigation alternatives using realistic terrain information and water simulation both sermet and demir 2020 and haynes et al 2018 developed virtual and augmented reality applications that allow users to visualize 3d flood inundation scenes using holographic lenses fig 4e and smartphones fig 4f rydvanskiy and hedley 2020 explored how 3d geovisualization and emerging 3d mixed reality interfaces could be used for understanding and managing flood risk the study reviewed the existing cartographic tools and platforms developed in the risk management sector and discussed their potential for improving the quality of representation and analysis and reducing the knowledge barriers that impede the understanding of flood risk for nontechnical audiences furthermore the study discussed the emerging mixed reality interfaces and their advantages over traditional desktop interfaces for user interaction with 3d content the recent advent of different web graphics libraries webgls 3d web tiling services and online game engines have significantly lowered the barrier to building immersive environments to promote water urban and forestry management section 5 presents a detailed summary and discussion of web technologies for creating online 3d immersive environments many of these visual computing applications could be designed to match the background and understanding of users that are in different age groups and have different educational backgrounds thus supporting public education and college level teaching and training tasks 4 2 collaborative water planning collaborative holistic and proactive water resources management practices are effective for solving transboundary and interjurisdictional challenges carson et al 2018 cardwell et al 2008 these practices have been favored by many watershed and nature resources management communities in recent decades galvez and rojas 2019 sajjadi et al 2020 to address the technical challenges related to the communication and public engagement aspects of collaborative water management and planning tasks savic et al 2016 proposed a serious gaming approach and presented a survey of published work on gaming applications with particular interest in water systems planning and management many of the previous serious gaming applications were implemented using board game and desktop applications zagal et al 2006 to further improve the game s ability to foster collaboration and communication between different participants in water management many recent studies have integrated interactive appealing and realistic visualizations of watershed systems into web based game engines to deliver online serious games these games can provide engaging and accessible environments to facilitate public engagement in collaborative water planning processes carson et al 2018 along with the advancement in web technologies many aspects of modern serious games such as realism performance progress monitoring accessibility and portability have been significantly improved at the same time serious games are able to bring the fun factor to the problem solving process of complex and technical water management problems this practice creates an intriguing and intuitive means to attract public participation and promote water education in the following we review a few serious gaming applications that apply intuitive visual interfaces to emphasize the aspects of collaboration and public engagement in various water management operations fig 5 xu et al 2020 developed a web based serious game to support multijurisdictional collaborative planning and decision making for mitigation of multiple water hazards i e floods soil erosion water quality deterioration the serious game is available to the local watershed management communities as the iowa watershed decision support system known as iowadss which provides an interactive multiuser geovisual interface that can engage different water management participants as players and allow them to select different adaptation options i e management practices the adaptation options are devised to reduce undesirable impacts of multiple water hazards in the cedar basin watershed examples of these adaptation options include relocation of structures changing the land cover and land use and installing additional hydraulic structures the goal of the game is to find the best performing combination of adaptation options to this end the application integrates multidomain environment models using a graph model to evaluate the adaptation options selected by different users the gaming application produces scores for each individual player to evaluate their performance in the game the player that receives the highest score becomes the winner the web application employs various charts and geovisualizations to visualize the player s options selections different gaming scenario constraints and game processes a game referee interface is developed to allow players and judges e g selected technical watershed management experts to compare the performance and scores of different sessions sermet et al 2020 expanded the competitive gamification concept for water management into a generalized web based framework the framework can use public datasets to populate serious games and decision support applications for mitigating various hydrologic hazards the study focused on software design approaches and system architecture for building a modular secure and salable web based geospatial application as a web based decision support tool for water hazards mitigation the application aims to provide intuitive user interfaces and visualization for real time and collaborative data analysis and damage assessment from multiple aspects e g social environmental ecological to further improve the realism and immersion of the collaborative serious gaming approach sermet and demir 2022 created an open source collaborative virtual reality framework introduced as geospatial vr which can render 3d real world environments to host serious gaming applications intended to mitigate multiple natural hazards including flooding and wildfire the framework can automatically render realistic 3d simulation scenes of user defined spatial extents within each simulated scene users can view the digital terrain elevation model infrastructure dynamic visualizations of hazards e g flood inundation fire spread and different layers that characterize disaster damage and extent sensor readings occupancy traffic and weather the framework also incorporates multiuser support for remote virtual collaboration it enables immersive geospatial capabilities in information and decision support systems that are implemented using various open source web technologies such as the unity game engine and the node js environment 4 3 decision support and optimization visual analytics enable decision makers to visually compare multidimensional vectors that represent conflicting criteria in complex problems miettinen 2014 trindade et al 2019 these techniques often employ intuitive visual representations that can be readily understood and interpreted by nontechnical decision makers these representations highlight similarities and differences between management alternatives that emphasize different needs this subsection reviews applications that use visual analytics to enable interactive processes for decision making miettinen 2014 miettinen et al 2008 aydin et al 2015 proposed a decision support system to assess the technical sustainability of water distribution systems wds used to improve the effectiveness of the decision making process the method combines multiple maps with a modified network representation that consists of aggregated edges circle views and a grid layout to visualize the technical sustainability assessment results for various new pump and reclaimed water scenarios within a water distribution network at different time steps the technical sustainability assessment evaluates the reliability durability flexibility and adaptability of a wds through coordinated views and visual abstractions the visualization approach allows decision makers to visually compare multiple facets e g technical sustainability assessment hydraulic efficiency water quality of different pump alternatives in the context of a water distribution network thus the effort can assist decision makers in improving raw data visibility and comparing multiple decision alternatives matrosov et al 2015 integrated a water system simulator with multiobjective search to generate a diverse set of pareto optimal water supply portfolios afterward the study assessed the set by developing a state of the art visual analytics approach the approach integrates a variety of interactive plots to help planners identify more adequate water supply system designs to better understand their inherent trade offs between the best scheme portfolios the effort can help water resources managers better understand projected water demands to improve planning in a real world water resource system 5 advancements in visualization technologies the technical capabilities of visual techniques have been further improved through next generation web based technologies such as the emerging 5g network web graphics libraries accelerated by general purpose graphics processing units gpgpus adaptive client side web frameworks and a number of online data analysis and visualization platforms from a technical standpoint these hardware and software improvements have significantly enhanced the following abilities for building powerful visual computing applications internet bandwidth to transfer massive amounts of data in a timely fashion client side computational power to render large amounts of data on computers or mobile devices and organization and coordination of individual plots and charts to construct a visual analytics workflow with sophisticated user interactions powered by these capabilities online data analysis and visualization platforms such as tableau powerbi grafana and kibana are gaining popularity in business analytics and academia combined with geospatial server applications such as geoserver and cartodb these platforms are increasingly introduced in college courses and scientific research sectors the major advantage of these platforms is that they can integrate a suite of visualization techniques user interface design and data analysis tools into a generic web environment using modular and adaptive design through the web environment nontechnical users without computer science or web development backgrounds could build data queries and visual dashboards without the need to write a substantial amount of code these platforms bring big changes in software development in the hydroinformatics community where web developers were previously required to write code from scratch using heterogeneous programming languages and software stacks these online visualization platforms are becoming popular in visual computing because they can lower the technical barriers for non computer science students and domain experts for building advanced visual interfaces and dashboards they also enable domain scientists to be directly involved in developing visual interfaces and dashboards thereby promoting visual computing techniques as an integral part of the scientific process many of these platforms are also freely available and created under open source licenses which makes them accessible to scientific research communities 5 1 graphics in web based visualization most graphics in web based visual interfaces and dashboards are rendered on the client side in a user s browser as html document object model dom elements popular web visualization libraries and frameworks rely on two major types of dom elements to construct plots charts and visual representations 1 scalable vector graphics svg and 2 html5 canvas each type uses distinct graphics rendering mechanisms svg uses vector shapes to generate geometries whereas the canvas display geometries use a raster of pixels reddy et al 2021 depending on the type of dom element some visualization libraries are more suitable for fulfilling specific visualization and visual analytics needs e g displaying big data enabling advanced user interaction scaling plots and graphics to different scales and screen resolutions than other libraries plots charts and geovisualizations e g markers symbols glyphs rendered through svg based libraries use vector graphics to represent different geometries e g lines boxes dots circles and visualization components e g plot axes ticks map labels these vectors are defined as xml format objects in an svg viewer defined as svg which can be embedded in the html page that then renders the client side views any components that a user can visually see of a web application in this setting vector graphics rendered in a chart or web map are scalable which allows them to change size to fit any user defined resolution or scale without losing quality because these vectors are defined as client side objects their styles and shapes can be modified dynamically through client side javascript and cascading style sheets this allows svg based visualizations to be very responsive to user interactions e g filtering data changing line color stroke width dragging a point marker across a chart or map users can click or hover on a graph which can be applied to represent the stream network in a catchment and highlight edges that represent a specific stream to access its geometric information and other properties in another example multiple svg based plots can be readily connected through the common dom manipulation techniques because their graphics objects can be connected through the dom element s id this setting allows the visual interface to highlight corresponding graphics in other charts or maps when the user hovers over or clicks on a specific element in a chart or on a web map this feature allows developers to create coordinated views using multiple maps and charts to help users explore multiple facets of complex data simultaneously in general svg based libraries are suitable for developing visualizations and visual analytics interfaces that emphasize user interaction and view coordination a major limitation of svg based visualizations is that they are unable to efficiently render large amounts of data e g millions of points in contrast html canvas based libraries represent geometries as pixels in an html canvas element defined as canvas which is raster based and rendered in a way that resembles images such as jpeg and png compared with the svg based visualizations static canvas based visualizations cannot be readily scaled to any resolution without reconstructing the raster because individual geometries e g lines circles are defined as image pixels in a canvas element their styles cannot be dynamically modified and their attributes cannot be accessed the same way a user can interact with a vector object changing the color shape or position of a geometry in a canvas based chart would normally require the client side javascript to reconstruct the entire raster image in its canvas element however canvas based visualization libraries have better performance when they are used to render a large number of graphics such as drawing thousands of lines and circles in a chart or on a map in which graphics are represented as pixels not objects therefore handling these graphics does not require significant memory on the client side in recent years much effort has been dedicated to integrating the webgl into regular canvas elements the webgl is a javascript api that enables the gpu accelerated usage of physics and image processing and effects on the client side webgl based libraries can render interactive 3d graphics or visualize a tremendous amount of data in a web environment e g eighty trillion point locations on an interactive web map without noticeable delay or lag in visualization performance sumbera 2019 many popular 3d web applications such as the unity real time development platform buyuksalih et al 2017 and cesium 3d geospatial platform tsai et al 2016 employ webgl to create interactive 3d environments in web browsers kr ä mer and gutbell 2015 and can be used to develop web based geospatial applications to benefit research in water resources management and other urban science sectors e g digital twin cities sermet and demir 2020 kr ä mer and gutbell 2015 laksono and aditya 2019 5 2 visualization libraries and tools in this section we review several popular web based visualization libraries and frameworks and share our early experience of developing visualization oriented applications and tools that can benefit the water science community s research efforts and management operations because many visualization driven studies reviewed and discussed in previous sections are implemented using these libraries and frameworks we would like to discuss their advantages and applicability to provide insights and share our experiences regarding selecting the most appropriate web visualization technologies for a task table 1 summarizes popular web based visualization libraries and their capabilities for developing visual computing applications for research purposes through a few qualitative metrics we use github stars as an evaluator of each library s popularity which indicates the number of times the library gets endorsed by the web development community selecting a popular and trending visualization library for hydroinformatics and water management applications is important because plots and charts developed using popular libraries typically exhibit more consistent and frequent maintenance and versioning the underlying technologies of these libraries are continuously supported and improved by the open source software development community we also list the number of prebuilt chart types in each library that can be readily used and integrated into a web application as an api with minimal coding efforts most of these libraries provide a number of standard charts such as line bar area and pie some libraries offer more sophisticated chart types such as graphs parallel coordinate plots edge bundles and radar plots many webgl based libraries do not provide prebuilt charts but can create 2d and 3d environments for visualizing terrain and buildings cesium 2015 mamoowala 2020 3d objects and point clouds from lidar measurements cesium 2021 the geovisualization ability indicates if the library could be used to visualize gis data some libraries can be used to design and develop innovative visual representations of complex spatial data and choropleth maps to produce interactive web maps they can export dom elements to be readily integrated into popular web map engines such as leaflet openlayers mapbox and google maps 6 conclusion and vision here we summarize our review of visual computing applications developed for water resources management section 6 1 and we present our vision section 6 2 for integrating the emerging state of art visual computing technologies and paradigms into next generation hydroinformatics applications in pursuit of the smart water city approach 6 1 summary of past applications recent improvements in environmental monitoring technologies have enabled efficient and economic acquisitions of tremendous amounts of water related data which has led to the emergence of innovative big data applications that can address past challenges and generate useful insights in water science disciplines among these applications visual computing techniques empower the synergy of computational techniques e g ml and statistical models and human reasoning capabilities through visual interfaces to improve the understanding and solution of complex decision problems in many scientific domains we reviewed past studies that employ various visual computing techniques as their core component to benefit research efforts in the water resources management sector we also discussed visual computing methodologies in these studies from the perspectives of visual analytical reasoning visual representation and user interaction and data representation and transformation many past studies integrated visual computing techniques into gis cyberinfrastructure and domain models to benefit the big data analysis aspect of water resources management these aspects broadly include 1 improvement of discovery management and quality control of large scale hydrologic and environmental data and 2 interpretation and optimization of simulation and data models more recent studies have adopted visualization and visual analytics as independent research investigation efforts to enable qualitative analysis and exploration e g patterns dependencies interrelationships with the recent increase in volume variety and quality of environmental and hydrologic data we envision a future trend of leveraging visual computing techniques as a more significant scientific and investigative tool for solving complex research problems which are defined by big data and are challenging to solve through traditional domain specific approaches e g statistical models physical models from a social technical viewpoint visual computing techniques could be applied to various watershed and urban water management efforts to promote 1 water education and public awareness of various water related issues 2 collaborative management planning and public engagement and 3 optimization of complex multiobjective and multicriteria decision problems with the advent of web based visualization and immersive reality visual computing applications in water resource management are becoming more accessible and intuitive and serving as an effective medium to connect different participants e g hydrologists decision makers watershed managers stakeholders in a more collaborative and integrated water management approach in the near future we expect visual computing techniques to become the foundation for disseminating water education raising public awareness of various water problems and increasing public engagement we also discussed recent advancements in visualization technologies their mechanisms for rendering graphics in web applications and the advantages of different technologies for building visualization and visual analytics applications with different focuses we summarized a list of popular web visualization libraries for developing charts plots web maps and 3d geospatial environments many recent online platforms for data analysis and visualization are combined with geospatial server applications to integrate a stack of visualization gui design and data analysis tools into a generic web environment using a modular and adaptive design these online platforms enable nontechnical users without a computer science or web development background to build data queries and visual dashboards through guis without writing a substantial amount of code additionally many modern web visualization libraries provide intuitive and well defined apis that can lower the technical barriers for non computer science students and domain scientists to build advanced web apps and dashboards with web mapping data visualization and visual analytics capability 6 2 vision in recent decades many emerging visual computing technologies and paradigms have garnered attention in the scientific software community bernholdt et al 2021 we summarize several visions for emerging visualization and visual analytics approaches which are proposed through the advanced scientific computing research ascr workshop on visualization for scientific discovery decision making and communication u s department of energy 2022 and propose our vision for using these technologies to benefit next generation hydroinformatics applications for water resources management at the technological level several white papers from the workshop discussed the potential application and opportunities of the recently emerging extended reality xr technology for environmental science and earth science disciplines u s department of energy 2022 based on our review of existing virtual reality luo et al 2011 and augmented reality carmigniani et al 2011 applications in the water resources sector we believe the xr technology and its related metaverse concept could be integrated with hydroinformatics and smart city applications the integration can further overcome sociotechnical challenges and improve public education engagement voluntary data collection and collaborative planning of water resources through immersive and realistic visualizations as the metaverse concept captures the tech industry s imagination and investments it has potential as a major contributor to the next generation internet through which future xr based applications for water education and voluntary data collection could be seamlessly incorporated into our daily lives meanwhile several ascr white papers discussed a vision of developing intelligent visual analytics nazemi 2018 a concept that further leverages the capability of ai to improve visualization algorithms and visual analytics design these improvements include 1 increasing the computational capacity e g volume rendering particle tracing for visualizing big data and 2 enhancing human perception and cognition abilities during complex and analytical tasks through ai driven annotations and storytelling workflows nazemi 2018 we believe intelligent visual analytics techniques can be integrated into future hydroinformatics applications to reduce human perception efforts in exploratory visual analysis thereby making charts graphs and visual analytical workflows more intelligent and easier to understand many physical phenomena in environmental systems e g hysteresis in river flow can be captured by special graphical characteristics e g a certain shape in the line charts through the visualization of sensor observations a computer vision application powered by deep learning models can automatically detect these characteristics and then guide the expert users to the subset of big environmental observation data that discloses the graphical characteristics through annotations and automated visual storytelling workflows at the paradigm level many of the next generation internet technologies e g internet of things 5g networks are employed by a broad environmental and urban science community to develop smart city platforms and digital twin cities in this ongoing trend visual computing techniques serve as a bridge to connect smart city applications with the existing hydroinformatics applications and water management platforms this connection aims to shed light on a more integrated smart water city approach that incorporates water resources management with the planning and optimization of other urban subsystems e g building energy transportation urban microclimate we believe next generation water resources management applications will be able to address a broad scope of social demands and socioeconomic factors and have more opportunities to solve complex problems that combine urban dynamics with environmental processes examples of these applications include 1 incorporating the urban green water infrastructure design into the transportation system planning to lower the risk of roadway inundation and culvert overtopping during flood events and 2 considering the risks of water related hazards e g flood excessive soil erosion water induced landslides during urban planning to protect critical energy infrastructure e g electrical grid gas credit authorship contribution statement haowen xu review writing and original draft preparation andy berres data curation writing and revision yan liu revision and administration melissa r allen dumas data curation writing and revision jibonananda sanyal revision and administration disclaimer oak ridge national laboratory is managed by ut battelle llc for the us department of energy under contract de ac05 00or22725 this manuscript has been authored by ut battelle llc under contract numberde ac05 00or22725 with the us department of energy doe the us government retains and the publisher by accepting the article for publication acknowledges that the us government retains a nonexclusive paid up irrevocable worldwide license to publish or reproduce the published form of this manuscript or allow others to do so for us government purposes doe will provide public access to these results of federally sponsored research in accordance with the doe public access plan http energy gov downloads doe public access plan declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25581,recent advances in information communication and environmental monitoring technologies have increased the availability spatiotemporal resolution and quality of water related data thereby leading to the emergence of many innovative big data applications among these applications visualization and visual analytics also known as the visual computing techniques empower the synergy of computational methods e g machine learning and statistical models with human reasoning to improve the understanding and solution toward complex science and engineering problems these approaches are frequently integrated with geographic information systems and cyberinfrastructure to provide new opportunities and methods for enhancing water resources management in this paper we present a comprehensive review of recent hydroinformatics applications that employ visual computing techniques to 1 support complex data driven research problems and 2 support the communication and decision makings in the water resources management sector then we conduct a technical review of the state of the art web based visualization technologies and libraries to share our experiences on developing shareable adaptive and interactive visualizations and visual interfaces for water resources management applications we close with a vision that applies the emerging visual computing technologies and paradigms to develop the next generation of hydroinformatics applications keywords big data hydroinformatics visual analytics visualization human computer interaction 1 introduction to date the water sciences discipline like many other scientific domains has been driven into the big data era with the advancement of next generation information and communication technologies researchers are confronted with rapidly growing amounts and variety of water related data which arise in many areas of water resources research and management and challenge the capabilities of current data analytics guo et al 2015 adamala 2017 despite many computational methods e g statistics numerical simulation machine learning ml are developed to address the avalanche of big data through intelligent and automated data analytics their implicit nature honegger 2018 has limited their ability to conduct exploratory analyses for information and pattern extraction or to support complex decision making for which human intelligence collaboration and justification are indispensable for decades the visual computing discipline has played an important role in exploring analyzing and presenting scientific data kehrer 2011 earnshaw et al 2019 it enables direct human interactions with computational methods to provide an effective integration of human reasoning into computational intelligence within the visualization community the research is separated into information visualization scientific visualization and visual analytics andrienko et al 2011 information visualization presents abstract data in visual formats e g charts graphs lists maps to facilitate human cognition for insight and pattern extractions burley and ashburn 2010 scientific visualization on the other hand focuses on rendering raw scientific data as often 3d graphics to enable a better depiction and interpretation of real world scientific phenomena and processes visual analytics emerges as an applied research discipline from computer graphics design and cognitive science to enable more advanced analytical reasoning capability on large information workloads by combining the strength of computational resources and human intelligence through sophisticated visual interfaces and dashboards thomas and cook 2006 these visual interfaces and dashboards often have more sophisticated analytical workflows that involve advanced user interaction techniques data transformation and coordinated views to enable users to explore different facets and perspectives of complex data simultaneously and logically 1 1 visual computing for scientific research in recent decades visual computing techniques have been applied in many disciplines few and edge 2007 koylu 2019 including social sciences wu et al 2016 climate science nocke et al 2015 wong et al 2014 urban science zheng et al 2016 transportation planning and mobility management andrienko et al 2017 berres et al 2021 and biomedical informatics wu et al 2019 to improve the knowledge building hypothesis generation and decision support of complex problems kohlhammer et al 2011 andrienko et al 2007 visual computing techniques bring unique value to big data analysis in which information overload and data complexity hinder effective dissemination communication and perception of data and research output as a particular example the us department of homeland security dhs has established the national visualization and analytics center to promote the development and application of advanced visual analytics technologies to provide a strategic advantage in emergency response and counter terrorism operations thomas and cook 2006 councilet al 2003 wong 2007 as a joint research effort of the national science foundation and dhs the foundations on data analysis and visual analytics fodava initiative was created to cultivate next generation visual computing techniques for scientific research dill et al 2012 kielman et al 2009 compared with other scientific disciplines visual computing applications are relatively limited in the water science sector we compared the research trends of visualization and visual analytics in different domains using search results from scopus https www scopus com we only identified 127 water resources management related documents from scopus when searching article titles keywords and abstracts for information visualization scientific visualization visual analytics visual analysis visual computing or visualization our search was conducted on 02 27 2022 for the time being we discovered that visual computing applications in the water resources management sector are not as well developed as they are for other science domains e g social science climate science transportation planning for which 1 000 4 000 visual computing related research documents can be discovered using the same search terms review and vision articles in other science disciplines often systematically incorporate visualization and visual analytics techniques into their domain specific approaches to create a well defined interdisciplinary research area whereas such articles do not exist for water resources management applications we also conducted an exhaustive search for hydrologic and water resources research applications defined as subject areas through the search terms published in the top tier visualization venues e g ieee vis and ieee transactions on visualization and computer graphics using scopus and could not identify any articles related to water resources management as many recent articles have presented fragmented visions to describe how certain types of data visualization and visual analytics techniques could practically benefit specific water related research and management applications tague and frew 2021 grainger et al 2016 we believe that more advanced and system based visual computing techniques can be applied to improve the water resources management repertoire from many different perspectives as the water science discipline enters the big data age more attention is given to the emerging computation techniques that enable ai through deep learning and hybrid models allen dumas et al 2021 adamala 2017 mar ç ais and de dreuzy 2017 lange and sippel 2020 past reviews that focus on the visualization of environmental data were limited to particular research applications as an example grainger et al 2016 provided a detailed review of environmental data visualization for non scientific contexts nevertheless the value of visual computing techniques as a critical investigative approach to support broad water resources research and management applications is often overlooked and rarely discussed in the literature review articles that focus on visualization and visual analytics applications in the water resources management sector are rare this situation limits the public awareness of the visual computing approaches and their potential for playing more important roles in water resources research and management applications to fill this gap we conduct a comprehensive review of recent visual computing applications in the water resource management domain first we focus on the methodological aspects of the visual computing techniques by reviewing a selection of successful research applications during the review we discuss the benefits and potential opportunities related to different visualization and visual analytics techniques for enhancing both the data driven research and the communication and decision making processes in various water resources management applications second we discuss the contemporary visualization technologies used for implementing advanced visual computing techniques we describe a strategy that integrates the emerging visual computing techniques into water resource management applications for amore holistic approach to smart city management of water resources we aim to share our experience and provide advice to lower the technical burden of development and allow non computer science domain experts researchers to develop useful visualization and visual analytics dashboards within shareable and accessible web applications 1 2 paper structure and organization our review is structured in the following way section 2 describes the motivation of this work section 3 focuses on the visual computing applications that support data driven research in water resources management section 4 dives into the communication and decision support aspects of visual computing applications for supporting collaborative and integrated water resources management with an emphasis on the social dimension of water resources both sections are outlined based on detailed research and application areas summarized in sections 2 3 1 and 2 3 2 section 5 describes the technical advancement in web based visualization technologies and their potential for benefiting hydroinformatics applications before going into detail on the visualization technologies some basic notations for computer graphics rendering in a web environment are clarified the remainder of the section summarizes popular web visualization libraries for creating charts plots web maps and 3d geospatial environments many libraries provide intuitive and well defined application programming interfaces apis we believe using these technologies can remarkably lower the technical burden of web development and allow both professional software developers and non computer science domain experts to develop useful visualization and visual analytics dash boards to support their research and water resources management applications finally section 6 presents our vision to integrate the emerging visual computing technologies and paradigms to create next generation hydroinformatics applications to support water resources management 2 motivation in this section we first review the current state of visual computing applications in the water resources management sector then we discuss the unique strengths and benefits of visual computing for supporting research and decision support applications through a dynamic human computer feedback loop finally we briefly discuss some application areas of visual computing techniques in the water resources research and management sectors these areas are summarized through the review of selected studies 2 1 current state over a long period of time data visualization tools have been developed for specific water management or hydroinformatics applications as marginal and supplementary components to support the production presentation and dissemination of analytical results from simulations and statistical models a similar bottleneck also exists in many other science domains for which visualization tools are considered the end product or side product of scientific research they are not deemed a pivotal research tool or major approach that can be adaptively and systematically applied to lead the scientific investigations themselves fox and hendler 2011 developed in the early 1990s the original concept of hydroinformatics stemmed from computational hydraulics abbott et al 1991 waldrop 1979 in which research efforts are primarily driven by the numerical simulation of water flows and related processes abbott and vojinovic 2013 during that time period data modeling and visualization techniques were complementary to the mainstream hydrologic and environmental modeling approaches in the past two decades however the emergence of data intensive science and increasing awareness of the social dimension of water management have expanded the scope of hydroinformatics and generated numerous opportunities for data driven and collaborative water research applications vojinovic 2012 adamala 2017 abbott 1996 subsequently these opportunities have triggered demands for effective analytical reasoning capabilities that require the involvement of multiple sectors e g research institutes management authorities policy makers including the public carson et al 2018 to this end these opportunities require a new hydroinformatics paradigm that can support the quantitative and qualitative analysis of big environmental data and address social needs and related concerns for water management manyika et al 2011 vojinovic and abbott 2017 the new paradigm could also benefit many emerging research efforts such as social hydrology which focuses on the exploration of the dynamic interactions and feedback between hydrologic and human processes sivapalan 2015 brelsford et al 2020 these efforts often require public participation and the use of complex multidomain urban hydro datasets with the emergence of the open government initiative ginsberg 2011 and open watre data initiative blodgett et al 2016 and the formation of collaborative hydrologic research communities such as the consortium of universities for the advancement of hydrologic science inc cuahsi and the national water center a tremendous amount of hydrologic data and data driven tools have become freely available and can be accessed through a variety of web platforms examples of these platforms include the usgs s national water information system and cuahsi s hydroshare tarboton et al 2014 maidment 2016 the new hydroinformatics paradigm has generated demands and opportunities for researchers to integrate more visual computing techniques into the water management sector for now most studies in the water science sector only employ basic forms of visualization e g graphs charts maps data viewers in their water management and hydroinformatics applications they primarily use visualizations to facilitate the presentation and dissemination of hydrologic data simulation results and research output advanced visual computing and human computer interaction techniques are often missing from these applications these techniques include 1 visual analytical reasoning 2 visual representations and interaction and 3 data representation and transformation thomas and cook 2006 given the current state of the water science sector we believe there are many opportunities to use visual computing techniques in a more systematic way and combine them with traditional investigative methods such as environmental modeling and experimental methods in section 2 2 we detail a systematic use of visual computing techniques by developing a dynamic human computer feedback loop endert et al 2014 2 2 benefits of visual computing techniques we believe the major benefit and strength of visualization and visual analytics in big data analytics is their capability to create cycles of feedback between humans and computers we refer to these cycles as the feedback loops which are important parts of a visual analytical pipeline fig 1 these loops have a significant advantage in facilitating human perception and reasoning during the analysis of massive and complex environmental datasets 2 2 1 feedback between humans and computers within the feedback loop visual computing techniques can address challenges that are difficult to solve using computational methods these challenges are often related to the complexity of water related data which are becoming increasingly multifaceted i e multivariate spatiotemporal multirun multivalued ensemble kehrer 2011 furthermore many environmental and hydrologic variables often exhibit a high degree of spatial and temporal variability asce task committee on application 2000 and their underlying environmental processes often interconnect with other riverine processes e g ecological biological stream morphological at a conceptual level the feedback loop is designed to place domain experts into the analytical pipeline to supervise the data analysis by applying human experiences justification and domain knowledge keim et al 2008 within the first iteration of the loop visual computing techniques are often combined with computational methods to present the abstract and processed data in an explicit way to help the domain expert understand the data and then extract useful data driven insights e g patterns causal inferences and anomaly detection after the initial visual analysis the domain expert i e as the user of the visual computing application can validate these insights using existing domain knowledge and principles which often lead to a theory guided interpretation for a better understanding of the insights as the next step the user can either use the derived insights to 1 enrich the existing body of knowledge 2 tune the parameters of the computation and visualization methods for a better output or 3 generate hypotheses to guide future research efforts using simulation models and experimental methods fox and hendler 2011 as the last step in the loop the simulation models and experimental methods can generate more new data and simulation outputs these outputs can be reintroduced into the feedback loop to start another iteration to further refine the data driven analysis 2 2 2 design techniques and strategy a feedback loop typically consists of two major components 1 computational methods and 2 objective driven visual computing methods for achieving a specific data analysis goal or exploring certain facets of the data these components are normally formulated based on one or multiple visual computing design techniques computational methods are introduced into the loop to facilitate the data representations and transformations these methods are primarily applied to transform and simplify complex environmental datasets into abstract forms to highlight important features and patterns the visual computing methods are created to facilitate the visual information seeking process shneiderman 1994 and they often employ one or many visual computing design techniques among these techniques are analytical reasoning visual representations and interaction data representations and transformations and presentation and dissemination of results thomas and cook 2006 ribarsky et al 2009 overall combining these techniques into a visual interface can enable users to explore and understand different facets of a complex dataset and connect information and patterns identified at different data facets into a logical data story that complies with the existing domain knowledge and enables users to derive new insights for knowledge generation a common design strategy for creating visual interfaces follows the visual information seeking mantra shneiderman 2003 the mantra defines seven common types of data 1d 2d 3d temporal multidimensional tree and network data and seven visual analytical tasks zoom filter details on demand relate history and extract these visual analytical tasks are often implemented in a visual interface as user interaction techniques to optimize the visual information seeking process during a visual analysis the mantra specifies a sequence of visual analytical tasks overview first then zoom and filter and then details on demand shneiderman 2003 based on this mantra the designer should first identify the data type and data facets that must be analyzed to meet the objective of the visual analysis then the designer should select a suite of visual representations e g maps graphs charts visual encoding that can effectively visualize the identified data facets each of these visual representations is tasked with visualizing specific data facets e g temporal spatial multivariate multiscale after the selection of graphs and charts the designer must associate individual visual analytical tasks with each chart or graph as an example a map is designed to provide an overview of the spatial facets of a dataset therefore it is associated with the overview task afterward multiple charts and graphs should be linked to create coordinated views based on the task sequence specified by the mantra different tasks associated with graphs and charts are then translated into different user interaction techniques the user can directly interact with the data in a chart facet e g zoom and filter through different keyboard and mouse events e g mouse click and hover and observe the variation and patterns in other data facets through the automatically updated coordinated views because the coordinated views can visually connect variations and patterns across different data facets the user can use these views to observe interconnections and correlations between multiple variables ensembles and spatial and temporal scales the process should eventually help the user derive new qualitative insights e g empirical relationships in addition computational methods e g statistical and ml models are connected to the visual computing techniques and they can be used to conceptualize and quantify the derived qualitative insights using mathematical representations and statistical metrics 2 3 applications in water resources management here we discuss application areas in the research sector which is driven by scientific investigation and exploratory analysis of hydrologic data as well as the water resources management sector which is focused on water resources planning management practices and decision optimization during the discussion of each sector we summarize areas that can benefit from visualization and visual analytics based on the review of successful applications 2 3 1 research sector for supporting research activities in water resources management visual computing techniques can support data driven studies to facilitate the analysis and human understanding of massive dynamic ambiguous multifaceted and conflicting data the human computer feedback loop can bring unique capabilities to the data analytics and environmental modeling efforts by allowing the modeler to interact with hydrologic environmental simulations and data models and their outputs through visual interfaces and automated pipelines based on our literature review we summarized a list of benefits enabled by visual computing techniques improved discovery management and quality control of massive water related data fuhrmann 2000 ames et al 2012 leonard et al 2017 horsburgh and reeder 2014 jadidoleslam et al 2020 improved interpretation and optimization of simulation models kratzert et al 2019 tian et al 2016 su et al 2016 zhang et al 2017 deval et al 2022 and enhanced qualitative analysis and exploration e g extraction of patterns and empirical relationships of complex hydrologic and environmental data mazher 2020 xu et al 2019 walker et al 2020 accorsi et al 2014 marbouti et al 2018 smith et al 2016 sanyal et al 2017 clark 2022 visual computing techniques can be applied to a number of water related research areas to facilitate big data driven studies these areas include but are not limited to hydrologic response water quality soil water interaction water hazard mitigation and the water food energy nexus a detailed discussion and use case analysis of how visualization and visual analytics can benefit these research areas are presented in section 3 2 3 2 planning and management sector unlike the research sectors water resources planning and management applications often focus on complex decision support processes with an emphasis on the social dimension of water resources one of the critical needs is to bring the public sector into water resources planning and management processes paniconi et al 1999 through effective communication because many watershed management activities require the understanding consent and support from local communities e g water managers landowners residents other local stakeholders examples of these activities include the installation or retrofitting of hydraulic structure and urban water infrastructure e g weir sensors retention ponds groundwater wells the modification of land use and land cover e g the conservation reserve program for increasing a communities resilience to water related hazards and the relocation of structures and infrastructure for reducing potential flood damage carson et al 2018 to this end public engagement and participation are essential for enabling a holistic and integrated water resource management approach that addresses the needs of various social groups and communities in a watershed to support this social dimension of the water resources management many studies integrate visual computing techniques into the emerging web based technologies to provide easy to understand visual representations these practices serve as effective means for conveying and disseminating research output visions and complex concepts of environmental and watershed processes to the general public in the spirit of the expression a picture is worth a thousand words many of these visual techniques are friendly explicit and intuitive for nontechnical participants e g stakeholders policy makers students involved in water resources management these visual techniques are then integrated into web applications that can be accessed through the internet using various devices thereby providing efficient and low cost agents to promote water science education to nontechnical audiences with the goal of raising public awareness of many water resource related issues gober et al 2003 more recent studies have integrated visual computing techniques into serious games which are games developed for serious applications rather than entertainment to encourage public participation and engagement in water management some of these techniques entail visually appealing representations and intriguing user interaction workflows this practice can bring a fun factor to users during a water resources planning and education task as a result visual computing techniques when devised properly can be applied to lower the technical barrier of water management they can effectively incentivize the public sector to participate and engage in the collaborative planning and decision making processes in addition visual analytics techniques are frequently used as effective tools for optimizing multiobjective and multicriteria decisions to support the management of water resources in both rural and urban areas matrosov et al 2015 reed and kollat 2013 these application areas include the following promoting water education and raising public awareness of various water related issues demir et al 2018 haynes et al 2018 sermet and demir 2020 facilitating collaborative water management and public engagement xu et al 2020 sermet et al 2020 sermet and demir 2022 and optimizing multiobjective and multicriteria decision problems for water management aydin et al 2015 matrosov et al 2015 reed and kollat 2013 3 visualization for data driven research this section begins with the review of data visualizations to introduce popular graphs charts and visual encoding and representations that are often used for analyzing hydrologic and environmental data the remainder of this section then reviews the application of visualization and visual analytics in various application areas as summarized in section 2 3 1 that benefit data driven research for water resources management 3 1 visualization of hydrologic data historically visual analyses of hydrologic data were superseded by computational methods during the time period when most research was led by physical conceptual and statistical models ladsonet al 2018 many visualizations were integrated into domain based methodologies and played critical roles in supporting hydrologic analyses examples of these visualizations include thiessen polygons unit hydrographs and graphical routing methods adamala et al 2019 ladsonet al 2018 the situation began to change when more data driven analyses were introduced into water resources management water related data are complex and entail multiple data dimensions and facets many hydrologic modeling efforts require mapping and displaying spatial data e g topography and hydrologic units with the recent evolution in information and sensor technologies that enable better data acquisition access and organization maidment 2008a more effort has been expended on the visualization of hydrologic and environmental data to support more advanced data management and analytics tasks for example many hydroinformatics systems use visualization to facilitate data discovery and quality control many recent research applications often share the spirit of bringing water observational data together through big data cyberinfrastructure and hydroinformatics systems maidment 2008a 2008b josset et al 2019 examples of these applications include cuahsi s hydrologic information system his usgs s national water information system and the national climatic data center s climate data online 3 1 1 simple charts graphs and maps previous hydrologic visualization research mainly focused on the effective visual presentation of different types of hydrologic and environmental observations of multidimensional data e g spatial temporal multivariate and ensemble tarboton et al 2008 similar to traffic flow data connected to road networks water related observation data are closely associated with individual hydrologic units e g stream river corridor catchment that topologically connect through a hierarchical network structure in a watershed system in this regard many hydrologic observations also have a topological dimension to visualize a single dimension of hydrologic data e g the temporal or spatial dimension basic charts graphs and visual representations are adequate ladson et al ladsonet al 2018 summarized a list of basic visual representations that are frequently employed to visualize time series hydrologic data that present stage discharge relationship flood frequency and duration curves and unit hydrographs these representations consist of different variations of the line graph bar chart heatmap and circular plot and can be used to present changes in a single variable or to compare multiple time series data 3 1 2 advanced visual encoding and representation visualizing multiple facets of the hydrologic data at the same time is a more challenging task that often requires more advanced visual encoding and representation many studies link multiple charts into coordinated views each of which focuses on a single component or scale of the data united states geological survey united states geological survey 2020a encoded bar charts for visualizing time series data that reflect the number of water gauges in each us state into a matrix that presents state locations topologically in 2d space fig 2 a the link graphs and charts can be used to view the temporal and spatial variability of the complex data to display the overall trends and can also depict detailed variations and patterns within a specific dimension linked visualizations often require well defined user interaction techniques to synchronize the display of different charts and graphs based on different user actions e g selection of a subset of data or filter data based on specific attributes or regions burch and weiskopf 2011 devised an innovative timeedgetrees representation to visualize time varying water levels in multiple german rivers the representation visually encodes individual time series data into color gradient lines and rearranges them into a hierarchical structure that reflects river connectivity upstream downstream and confluences in a watershed the representation uses a hierarchical node link diagram as its basic layout to present the connectivity between individual streams each stream and its measuring site are denoted as a node and any time varying variables associated with the river can be visually encoded into that node fig 2b users can interact with the visual representation by filtering and zooming to a specific node or branch of the node link diagram the timeedgetrees can efficiently represent the temporal variation and topology of the water level data such that users can observe the dynamics of the time varying data in the context of flow continuity for example the visual representation can provide insights on how water level or temperature changes could affect the same variable in neighboring rivers its node link diagram can also be applied to visualize variables that reflect the wave propagation from upstream to downstream in a watershed united states geological survey united states geological survey 2020b adopted a stream graph representation to visually compare the flood duration measured at 65 stream flow sites over the past 20 years fig 2c the main goal of this visualization was to highlight a single stream gauge on the james river near stratford sd which was flooding continuously for 534 days while also comparing the flood duration at that site with that of other similar sites the efficient stacking of area plots allows a single graph to cover multiple dimensions simultaneously and avoid visual clutter caused by the intersection and overlying of multiple points and line features with more variety of hydrologic data available in better spatial and temporal resolutions the visualization of hydrologic data evolved from the utilization of simple and single graphs into the development of more advanced visual representations that can cover multiple facets of the water data these visual computing techniques have played important roles in supporting various hydrologic analyses and modeling efforts despite the usefulness of encoding more aspects of data visually into a single chart these visual representations are sophisticated and challenging for nondomain experts to interpret and understand compared with simple graphs and charts in many more advanced visual computing applications in which visual analytics become critical components to lead data driven research advanced data transformation and visual analytical reasoning techniques are required to supplement the visual encoding and representations we detail this aspect in section 3 2 with an emphasis on the design of a visual analytics workflow 3 2 data discovery management and quality control at the beginning of the 21st century fuhrmann 2000 pioneered the design and application of visual computing techniques for discovering and managing hydrologic data through the development of a low cost multimedia hydrologic visualization system hydrovis this system enables the visualization of digital hydrologic data and the documentation of hydrologic models for the weser river catchment hydrovis s visualization components consist of electronic maps temporal and nontemporal cartographic animations the display of geologic profiles interactive diagrams and hypertext e g photographs and tables many of these components such as electronic maps and cartographic animations could be considered prototypes of later web mapping and cyber geographic information system gis technologies that arrived in the web 2 0 age hydrovis was developed before the open data initiative luna reyes and najafabadi 2019 and served as a pilot study for exploring new media to promote visualizations of hydrologic data fuhrmann 2000 highlighted the future market and research needs for visualizing hydrologic data as well as the challenges posed by data sharing restrictions at the government level the advent of the open data initiative and web based technology brought the visualization of hydrologic data into the age of cyberinfrastructure during this period ames et al 2012 developed a web services based and open source software tool called hydrodesktop this revolutionary software tool allows users to search across and access hydrologic data services published through cuahsi his fig 3 a users can discover download manage and visualize hydrologic data retrieved from the cuahsi his data services using the hydrodesktop interface the novelty of hydrodesktop includes its data search and discovery ability through web services and its software extensibility by which it can incorporate custom data analysis and visualization plug ins the hydrodesktop visualization features are designed to support the discovery of hydrologic time series data these features include map based geovisualizations of monitoring locations and other spatial data and a visual interface with different plots to support the downloading organization visualization editing and maintenance of hydrologic time series data building on top of the hydrodesktop software system horsburgh and reeder 2014 addressed the interoperability aspect of the visualization and analysis of hydrologic data using web based hydroinformatics applications by developing a software plug in named hydror to link the cuahsi his with the r statistical computing environment fig 3b this link enables a straightforward hydrologic data management and analysis pipeline that allows hydrologists to discover and access a wide variety of hydrologic data provided from web based systems and repositories through the plug in users can directly import these data into widely used native hydrologic visualization and analysis environments demir et al 2018 further expanded the cyberinfrastructure approach for promoting the discovery and sharing of real time hydrologic data by developing an end to end web based platform called the iowa flood information system ifis the platform can effectively address multiple aspects of the decision making process for flood risk management and mitigation for the state of iowa fig 3c the platform was initially developed to enable centralized data access to and visualization of real time and historical water data e g water levels gauge heights hourly and seasonal flood forecasts rainfall conditions collected from a wide range of sources including next generation radar nexrad stations iowa flood center stream sensors and usgs and national weather service stream gauges for over 1 000 communities in iowa demir and krajewski 2013 developed based on integrated modular and adaptive system design ifis later evolved into a generalized flood cyberinfrastructure able to incorporate a variety of flood related data cloud based computing resources data analytics tools and advanced hydrologic models for supporting flood risk management and disaster preparedness and response efforts in iowa demir et al 2014 2018 from a visualization perspective the platform employed a number of advanced web based mapping and visual computing technologies to enable interactive visualization interfaces that allow users to explore and discover large volumes of diverse data retrieved from nexrad radars and over 500 sensors that describe real time stream conditions soil conditions and precipitation 50 gb of data every day the ifis visual interface employs a variety of charts and plots to enable the platform users to visually inspect and verify the availability of different hydrologic time series data and compare measurements between multiple sensors in a watershed these data visualizations 1 play an important role by allowing users to explore filter and discover flood related datasets collected from distributed sources and 2 provide a centralized interface to support data query and downloads the geovisualization capability of ifis allows the platform to display various gis layers and flood maps for selected communities in iowa these flood maps cover over 4 500 scenarios the ifis platform also provides evolutionary scientific visualizations and communication tools for promoting the social water dimension of flood management which will be detailed in section 4 demir et al 2018 developed the idea of an adaptive and modular web framework using superior software engineering and data structure design they built a generic and flexible pipeline for integrating a wide variety of hydrologic data models and data analytics with an html based gui and interactive web based visualization libraries the data visualizations provided by ifis are aimed at helping both technical users e g watershed managers researchers and nontechnical users e g stakeholders students as the platform becomes a more comprehensive decision support system for flood mitigation and watershed management more advanced user interaction designs are adopted to arrange coordinate and reuse various visualization interfaces embedded in ifis to ensure effective user interactions and clear design of userflows for various data discovery and decision support tasks rink et al 2012 presented an integrated approach for visual data management for the analysis and simulation of hydrologic processes through a real world use case their approach combines visual data management and numerical simulation to enable the discovery and selection of large datasets based on keywords and regions defined by users fig 3d the framework is built on a visual data management framework called the opengeosys data explorer which can import data from standardized file formats and databases and allow users to explore geoscientific data in a 3d space by displaying data related attributes on a digital terrain model the framework can serve as an easy to use tool for many data management purposes including surveying the availability of data modeling results in a specific region enabling integrated access to heterogeneous data collected from various sources searching for a defined subset using keywords and validating data through the detection of inaccuracies within a single dataset or inconsistencies across multiple datasets the data validation process is supported by the integration of different data structures and data viewers which allow the visualization of 2d data such as time series from dataloggers or stratigraphic profiles of boreholes rink et al 2012 also shared a vision to integrate tools for automatic parameter estimation into the framework to allow visual comparisons of measured data and simulated results in the future along with visual computing applications for data discovery and management advanced visual analytics workflows are developed to improve the quality control of large hydrologic and environmental datasets large scale hydrography datasets such as the national hydrographic dataset nhd often present limitations in stream and watershed connectivity such as disconnected and intermittent streams and subbasins buttenfield et al 2011 manually validating and correcting the connectivity and flow direction issues in millions of streams in the nhd is a time consuming and labor intensive effort that presents a big challenge to hydrologic modelers to address this challenge leonard et al 2017 presented the development and application of a visual analytics approach for the data cleaning and integration of the continental united states conus heterogeneous national hydrography data products using multiscale graph models the effort aims to support nation scale hydrologic modeling at the coarsest scale the approach first constructs a smaller graph using level 12 hydrologic unit code huc 12 watersheds as nodes to automatically validate the huc 12 watershed connectivity the concept of huc is explained in water resources of the united states seaber et al 1987 this automation can significantly reduce the data cleaning efforts that do not necessarily require human judgment when data issues require an expert judgement or high resolution datasets the graph model highlights these data issues and constructs a graph at a finer scale to assist human experts with reasoning and justification in the finer graph streams within a huc 12 node are represented as edges this setting allows expert users to inspect and correct data issues related to edge directions at a finer scale a visual interface is then created to allow expert users to analyze and interface with the graph model in summary leonard et al 2017 applied a visual computing approach to automate the analysis and cleaning of a conus hydrography dataset which consisted of about 851 million edges and 683 million nodes the effort also successfully demonstrated the effectiveness of its visual analytics workflow s capability of combining the computational power with human reasoning to resolve large scale data quality issues 3 3 interpretation and optimization of model data visualization also plays an important role in supporting hydrologic and environmental modeling efforts visual techniques have been widely applied to improve the presentation of hydrologic simulation output for the dissemination of model driven insights to researchers and decision makers jones et al 2014 koutsoyiannis et al 2003 visualization and visual analytics foster a better understanding of complex and partially unknown environmental processes tian et al 2016 namwamba 1998 and improve the evaluation and optimization of hydrologic models jadidoleslam et al 2020 rajib et al 2016 in past decades many applications were developed to visualize hydrologic modeling results using a variety of time series plots and geovisualizations powered by gis and web based mapping technologies sections 3 3 1 and 3 3 2 selectively review sophisticated visual analysis applications that utilize simulation data and ml to present unique visual analytics workflows that help the audience explore new insights in the simulation outputs these efforts are designed to help audience develop an in depth understanding of the modeling process both physical and data driven for better optimization strategies 3 3 1 simulation model data a few studies have focused on developing visualization frameworks to examine and explore complex environmental and hydrologic processes that are simulated using domain models for new insights and hypotheses these studies provide practical examples to demonstrate how visual computing techniques can be applied to support and improve modeling efforts in water and environmental research zhang et al 2017 focused on the development and design of computer based flow visualizations to help researchers explore and elucidate the dynamic flow process and the fluid movement laws the overall objective of these flow visualizations is to foster a better understanding of the complicated hydrologic cycle thereby improving watershed modeling and water resources management at the regional level zhang et al 2017 also evaluated various flow visualization methods e g scalar field visualization vector field visualization and visual water effects through a virtual watershed platform the platform can generate flow data using spatially distributed hydrodynamic models and visualize these data in a virtual 3d environment the platform allows end users to explore various hydrodynamic attributes of the flow and their interactions with other attributes such as terrain landforms and inhabitants case studies were conducted to demonstrate the platform s ability to visualize hydrodynamic features in river flows and ocean currents tian et al 2016 combined 3d exploratory visualizations with environmental modeling pipelines to facilitate the interpretation and validation of simulation output from physically based fully integrated surface water groundwater sw gw models their visualization tool was devised and implemented to incorporate sw gw modeling results promote data and model sharing among the water resources research communities and provide a virtual globe based 3d environment for visually exploring and validating modeling results su et al 2016 introduced a data oriented multidimensional and dynamic visualization software to explore massive marine hydrologic and environmental datasets and modeling results the software tool can visualize marine water environmental factors in a 3d interaction and volume rendering environment examples of these factors include an oceanographic planar graph contour line rendering isosurface rendering factor field volume rendering and dynamic simulation of the current field the visualization system was developed using the cuda sanders and kandrot 2010 parallel computing library to parallelize and increase the speed of volume rendering for marine water environmental data in a netcdf network common data form format the tool s high performance enables users to generate interactive visualizations based on different user defined scene and simulation properties the combined efforts of visualization and simulation models can help domain scientists and nontechnical water management communities to interpret simulation results from hydrodynamic models with an overall objective of improving the understanding of the complex hydrologic cycle these efforts also increase the practicability of hydrologic models for supporting decisions in real world water resources management operations 3 3 2 machine learning ml model data as more traditional ml and deep learning models are increasingly used to model hydrologic processes and predict environmental variables it is critical for both data scientists and hydrologists to understand the data models implicit and hidden training processes to validate and optimize model configurations one remarkable example is the application of long short term memory lstm networks for rainfall runoff forecasting lstms are particularly well suited for modeling the rainfall runoff process because their memory cells can represent dynamic reservoirs and storage thus this ml technique plays an important role in the state space modeling approach for analyzing the hydrologic system kratzert et al 2019 inspired by the visualization tool strobelt et al 2017 developed for recurrent neural networks with a focus on understanding changes in hidden state representations over time kratzert et al 2019 demonstrate a visual analysis tool that can help domain experts interpret and analyze trained lstm models for predicting discharge in two different catchments one with snow influence and one without they conducted a qualitative analysis of the correspondence between the hydrologic system and the learned behavior of the lstm in the first step of the analysis multiple line charts were employed to visualize the time steps of snow influence on the network output over the day of year doy unit and compare the discharge output with other variables such as the median precipitation discharge and minimum temperature the visual comparison revealed that the time steps of influence pattern matched the hydrologic understanding of the yearly pattern in the second step the study employed a scatter plot to show the average correlations between memory cells and hydrologic states for a basin without effective visual analysis tools deep learning networks such as lstms are difficult to interpret and understand which limits their potential for environmental research this is because many domain scientists value the physical representation of environmental processes and are not apt to trust deep learning models that involve black box representations strobelt et al 2017 in this regard effective visual analytics methods allow a deeper understanding and validation of these learning models and can serve as a bridge to connect the ml approach with traditional environmental modeling approaches these visual computing methods could bring judgment and intervention from domain experts into deep learning models to validate and optimize the construction of their networks for more reliable and explainable predictions of hydrologic variables the combined approach of visual analytics and deep learning could expand the vision of the theory guided data science approach that aims to fully leverage the power of ml and data driven methods in water science disciplines by deeply coupling them with domain models based on scientific processes and theories karpatne et al 2017 3 4 exploratory visual analytics many recent studies employ visualizations and visual analytics techniques as an independent investigative approach to conduct exploratory analysis of complex environmental datasets for data driven insights apart from traditional environmental modeling approaches these analyses can generate new data driven insights that reveal spatiotemporal patterns of a single hydrologic variable as well as empirical relations and causal inferences between multiple environmental and hydrologic variables these efforts often lead to knowledge discovery hypothesis formation and improved understanding of the environmental phenomenon that entails partially unknown and interlinked physical processes which are challenging to solve using existing environmental models 3 4 1 visual analytical reasoning this subsection introduces the basic visual analytical reasoning components and methods for conducting exploratory visual analysis the nature of exploratory visual analytics is to combine automated data analysis techniques with interactive visualizations for effective understanding reasoning and information seeking on the basis of very large and complex datasets keim et al 2008 therefore the two major techniques involved in the design of exploratory visual interfaces are 1 data representation and transformation and 2 visual representation and user interaction many visual analytics applications focus on the use of advanced data representation and transformation techniques powered by statistical and ml models to reduce dimensions of complex datasets and remove noise in the data they allow the visual analytics interface to highlight summarize and abstract key patterns and relationships in the raw dataset in a form that can be logically perceived by target audiences after a heavy lift in data processing analytical reasoning plays an important role in the design of a visual interface and its user interactions there are many well defined techniques for designing a visual interface for user interaction e g selection of plots chats visual representation coordination between different views these techniques were developed based on the visual analytical reasoning principles ribarsky et al 2009 to ensure a visual analytics application can achieve its objective functions e g easy to use efficient data analysis logical user workflows this subsection presents some example techniques to provide more context for visual analytical reasoning methods one of the most commonly used methods is the level of detail technique heok and daman 2004 which is a computer graphics technique for reducing visualization complexity based on the rendering object s importance viewpoint relative speed or position heok and daman 2004 the technique is often applied in visual analytics to highlight important patterns based on 1 a user s interaction and selection of data facets and scale and 2 the importance of specific features in a massive dataset uchida and itoh 2009 the method can significantly improve the efficiency of a visualization by reducing potential visual clutter and noise caused by rendering unnecessary data other methods that can increase the effectiveness and evaluate the usability of a visual analytics technique include heuristic evaluation cognitive walkthrough and the human cognitive model nielsen w nielsen and mack 1994 ribarsky et al 2009 ribarsky et al 2009 provided a detailed summary and explanation of the analytical reasoning theory and its related techniques 3 4 2 data transformation and representation many studies focus on exploratory data analysis in a specific water research domain such as water quality surface runoff erosion and sediment transport and the energy water nexus ewn many of these studies incorporated more sophisticated data transformation and abstraction techniques to support visual representation and user interaction techniques for pattern extraction from complex data and simulation results common data transformation and representation techniques include statistical and mathematical models metrics and data mining techniques powered by ml models e g classification and clustering methods accorsi et al 2014 developed hydroqual to facilitate visual analysis of river water quality affected by intertwined natural processes and human activities this tool was developed to address the limitation faced by gis and statistical methods that fail to produce reliable results owing to data scarcity in some regions hydroqual combines spatiotemporal data mining and visualization techniques to help domain experts analyze and evaluate water quality data and their relationships with other environmental and urban factors during the visual interface design process accorsi et al 2014 proposed a novel metric to assess sequential dissimilarity in data through clustering and an optimized algorithm to extract temporal patterns in addition to the novel data transformation techniques a new algorithm for visualizing clusters and their associated optimization processes was devised and integrated into the visual interface in a case study hydroqual was applied to successfully highlight the relationship between values of a biological index and physicochemical parameters describing river water quality mazher 2020 presented a visual analytics workflow for analyzing high dimensional spatiotemporal hydrologic gridded datasets using ml models created based on dimensionality reduction techniques drts the study first evaluated the performance of various ml based drts in terms of their accuracy in data transformation dimensional reduction and visual presentation of transformed data these drts include principal component analysis generative topographic mapping t distributed stochastic neighbor embedding and uniform manifold approximation and projection the accuracy of these techniques was evaluated using a co ranking framework as a quality metric afterward mazher 2020 selected the best performing drt and implemented it into a generic analytical workflow the framework can project high dimensional spatiotemporal data on a 2d plane using a drt and then represent the 2d projection spatially using a 2d perceptually uniform background color map this workflow was applied to analyze the output of an australian water resource assessment model for tasmania australia the integration between ml powered data transformation analysis techniques and the 2d visual representation of processed data could significantly improve the human reasoning and perception of complex patterns in high dimensional multivariate environmental datasets xu et al 2019 devised a web based visual analytics workflow that can integrate various ml based data transformation techniques with a variety of spatial and multivariate visualizations to explore the complex environmental processes related to soil erosion and sediment transport near culverts the workflow offers systematic procedures to 1 classify the culvert sedimentation degree using a time series of aerial images 2 identify key process drivers from a variety of environmental and culvert structural characteristics through ml powered feature selection algorithms and interactive visual interfaces 3 support human interactions to perceive empirical relationships between drivers and the culvert sedimentation degree through multiple multivariate visualization techniques and a self organizing map som and 4 forecast culvert sedimentation potential across iowa using tree based ml algorithms through a case study xu et al 2019 applied the visual analytics workflow to analyze a large integrated environmental dataset that entails culvert operation conditions from the iowa department of transportation s structure inventory and inspection management system watershed characteristics from the epa s stream catchment dataset and stream corridor characterization using iowa s land use and land cover dataset and the nhd plus the analysis generated new insights that revealed a strong correlation and quantitative relationships between the degree of sediment deposition at culverts in iowa and the state s geological landform regions this insight was converted to a hypothesis and used to guide further investigations using the physically based water erosion prediction project model s simulation outputs xu 2019 clark 2022 developed a visual analytics aided deep learning approach to improve the understanding of the sustainability of current groundwater extractions in the namoi region of australia the approach combined unsupervised som with supervised long short term memory lstm models to effectively abstract patterns from a diverse set of groundwater monitoring time series to facilitate the exploratory analysis of complex hydrogeological dynamics in the namoi region the combined models enabled the predictions of water levels based on climate and anthropogenic conditions at the same time the som can also visualize the shared pattern information from across the namoi system to reduce the complexity of analyzing multiple time series the resulting visual analysis shares information between sparse time series that could not be modeled with the lstm individually sanyal et al 2017 started with a broad strategy of investigating the complex dynamics of the ewn and its interactions with climate variability from a more holistic perspective the strategy takes a variety of socioeconomic and environmental factors such as energy production and urban climate into consideration during the management of urban water resources along with this vision a web based geospatial visualization platform was developed to integrate various data analysis toolboxes with advanced data fusion and data visualization capabilities to create a knowledge discovery framework to analyze the ewn the unique contribution of the study includes the creation of an adaptive modular and flexible architecture to generate dynamic visual analytics workflows through the integration of different software modules berres et al 2018 these modules include data analysis and transformation packages for statistical visual analysis clustering principal component analysis dynamic time warping and various geovisualization and uncertainty visualization libraries 3 4 3 user interaction walker et al 2020 focused on integrating advanced user interaction techniques into interactive visualizations by presenting a web based data visualization framework the framework debuted as the interactive catchment explorer ice and was developed to help natural resource managers and researchers 1 visually explore complex and multivariate environmental datasets and modeling results 2 identify spatial patterns related to ecological conditions and 3 prioritize locations for restoration or further investigation the framework employs a client side architecture and is deployed as an integral part of the spatial hydro ecological decision system a geovisual interface was created within the ice to display catchments across the northeast region of the united states catchment characteristics can also be visualized through color coded symbology displayed on a web map embedded within the visual interface through a series of user interaction techniques users can select and examine the statistical summary of multiple catchment characteristics represented as hydrography hydrologic ecological and environmental variables through an array of interactive histograms placed alongside each other the map of color coded catchments is displayed simultaneously this stereo arrangement of the plots and web map can help users observe correlations between different catchment characteristics by providing a coordinated view with various user interaction options this arrangement also allows users to filter and focus on subsets of data by defining thresholds through the interactive histograms at the same time the color coded display of catchment characteristics is updated based on the user s interaction to present patterns and variability for a selected environmental variable similarly marbouti et al 2018 presented watervis a geovisual analytics application designed to support the monitoring and management of hydrologic and environmental resources the tool was designed to identify environmental factors that contribute to changes in river water levels as well as enable the predictive analysis of the river stage similar to ice the design and development efforts of watervis also focused on advanced user interaction techniques in this regard both tools can serve as effective and generalized visual analytical frameworks that allow domain experts to explore potential correlations between different environmental variables which can help identify contributing factors associated with a specific environmental process 4 visualization for communication and decision support hydroinformatics and water resources management applications normally entail three major dimensions the natural dimension the social dimension and the business dimension chen and han 2016 among these dimensions the social dimension is defined as the interaction between the water environment and humans society chen and han 2016 abbott 1996 it promotes the engagement and participation of the general public in various water management and planning processes to address social concerns and needs related to water management ethics and culture this dimension also considers challenges associated with transboundary water issues and conflicting water management goals from different water management authorities priscoli 2004 recent approaches for integrated water management often entail practices designed to address the social dimension of the water resources these practices promote water education to raise public awareness of water management issues facilitate collaborative planning and public engagement in water management and encourage voluntary social sensing of water related data floress et al 2015 seelen et al 2019 reges et al 2016 they often rely on community driven efforts that involve the participation of multiple water management related participants e g watershed managers stakeholders decision makers and policy makers to solve various water related problems related to the security supply conservation and sanitation of water resources in both agricultural watersheds and urban areas vojinovic and abbott 2017 moglia and sharma 2009 among these practices the communication between multiple water resources management sectors and participants is of great importance to facilitate effective communication visual computing techniques combined with the recent web based technologies can produce effective media to bring various participants into a collaborative problem solving environment to support the planning and decision making processes koontz and newig 2014 palmer et al 2013 visual computing techniques bring unique advantages to promote the social dimension of integrated water management many visualizations are intuitive and easy to understand which allows nontechnical water management participants e g stakeholders to understand complex scientific concepts furthermore visual analytics applications can also provide solutions to optimize complex decision problems in integrated water resources management applications while bringing human input e g experiences of watershed managers into the process biswas et al 2012 prato and herath 2007 lai et al 2008 4 1 water education for public awareness visual computing applications especially scientific visualizations and visual storytelling workflows can provide practical tools to support water education and training through intuitive and user friendly visual communications visual computing techniques can help students and local water management communities develop in depth understandings of complex interlinked and multiscale environmental processes to support their development of essential knowledge skills and strategies for solving water management problems meanwhile visual computing techniques are easy to understand and can be readily disseminated and shared through web applications and smartphone apps which are an effective means to raise public awareness of contemporary water problems and survey the needs concerns and voluntary water resources data provided by the public demir et al 2018 and xu et al 2020 integrated a watershed search engine and catchment characterization tool in publicly accessible online watershed information systems to educate nontechnical users e g urban residents stakeholders on the basic concepts of watershed systems such as the hydrologic cycle and stream connectivity these concepts could help many landowners understand where the water on their properties comes from and how different land management practices could affect the quantity and quality of water flows in downstream areas demir et al 2018 also employed a series of advanced scientific visualizations as cyberlearning tools to enable the decision support and education to raise the public awareness for disaster preparedness and response these tools include web based interactive visualizations for displaying streamflow direction fig 4 b a rainfall runoff simulator fig 4c and a flood map flyover simulator fig 4d demir 2014 embedded a hydrologic simulation system within a web based 3d interactive visualization environment that demonstrates different hydrologic processes and concepts for teaching purposes the simulation system was developed using advanced web technologies and a graphics processing unit to render physical behaviors of water flow and object collisions on realistic terrains it allows students to create or load predefined scenarios control environmental parameters and evaluate environmental mitigation alternatives using realistic terrain information and water simulation both sermet and demir 2020 and haynes et al 2018 developed virtual and augmented reality applications that allow users to visualize 3d flood inundation scenes using holographic lenses fig 4e and smartphones fig 4f rydvanskiy and hedley 2020 explored how 3d geovisualization and emerging 3d mixed reality interfaces could be used for understanding and managing flood risk the study reviewed the existing cartographic tools and platforms developed in the risk management sector and discussed their potential for improving the quality of representation and analysis and reducing the knowledge barriers that impede the understanding of flood risk for nontechnical audiences furthermore the study discussed the emerging mixed reality interfaces and their advantages over traditional desktop interfaces for user interaction with 3d content the recent advent of different web graphics libraries webgls 3d web tiling services and online game engines have significantly lowered the barrier to building immersive environments to promote water urban and forestry management section 5 presents a detailed summary and discussion of web technologies for creating online 3d immersive environments many of these visual computing applications could be designed to match the background and understanding of users that are in different age groups and have different educational backgrounds thus supporting public education and college level teaching and training tasks 4 2 collaborative water planning collaborative holistic and proactive water resources management practices are effective for solving transboundary and interjurisdictional challenges carson et al 2018 cardwell et al 2008 these practices have been favored by many watershed and nature resources management communities in recent decades galvez and rojas 2019 sajjadi et al 2020 to address the technical challenges related to the communication and public engagement aspects of collaborative water management and planning tasks savic et al 2016 proposed a serious gaming approach and presented a survey of published work on gaming applications with particular interest in water systems planning and management many of the previous serious gaming applications were implemented using board game and desktop applications zagal et al 2006 to further improve the game s ability to foster collaboration and communication between different participants in water management many recent studies have integrated interactive appealing and realistic visualizations of watershed systems into web based game engines to deliver online serious games these games can provide engaging and accessible environments to facilitate public engagement in collaborative water planning processes carson et al 2018 along with the advancement in web technologies many aspects of modern serious games such as realism performance progress monitoring accessibility and portability have been significantly improved at the same time serious games are able to bring the fun factor to the problem solving process of complex and technical water management problems this practice creates an intriguing and intuitive means to attract public participation and promote water education in the following we review a few serious gaming applications that apply intuitive visual interfaces to emphasize the aspects of collaboration and public engagement in various water management operations fig 5 xu et al 2020 developed a web based serious game to support multijurisdictional collaborative planning and decision making for mitigation of multiple water hazards i e floods soil erosion water quality deterioration the serious game is available to the local watershed management communities as the iowa watershed decision support system known as iowadss which provides an interactive multiuser geovisual interface that can engage different water management participants as players and allow them to select different adaptation options i e management practices the adaptation options are devised to reduce undesirable impacts of multiple water hazards in the cedar basin watershed examples of these adaptation options include relocation of structures changing the land cover and land use and installing additional hydraulic structures the goal of the game is to find the best performing combination of adaptation options to this end the application integrates multidomain environment models using a graph model to evaluate the adaptation options selected by different users the gaming application produces scores for each individual player to evaluate their performance in the game the player that receives the highest score becomes the winner the web application employs various charts and geovisualizations to visualize the player s options selections different gaming scenario constraints and game processes a game referee interface is developed to allow players and judges e g selected technical watershed management experts to compare the performance and scores of different sessions sermet et al 2020 expanded the competitive gamification concept for water management into a generalized web based framework the framework can use public datasets to populate serious games and decision support applications for mitigating various hydrologic hazards the study focused on software design approaches and system architecture for building a modular secure and salable web based geospatial application as a web based decision support tool for water hazards mitigation the application aims to provide intuitive user interfaces and visualization for real time and collaborative data analysis and damage assessment from multiple aspects e g social environmental ecological to further improve the realism and immersion of the collaborative serious gaming approach sermet and demir 2022 created an open source collaborative virtual reality framework introduced as geospatial vr which can render 3d real world environments to host serious gaming applications intended to mitigate multiple natural hazards including flooding and wildfire the framework can automatically render realistic 3d simulation scenes of user defined spatial extents within each simulated scene users can view the digital terrain elevation model infrastructure dynamic visualizations of hazards e g flood inundation fire spread and different layers that characterize disaster damage and extent sensor readings occupancy traffic and weather the framework also incorporates multiuser support for remote virtual collaboration it enables immersive geospatial capabilities in information and decision support systems that are implemented using various open source web technologies such as the unity game engine and the node js environment 4 3 decision support and optimization visual analytics enable decision makers to visually compare multidimensional vectors that represent conflicting criteria in complex problems miettinen 2014 trindade et al 2019 these techniques often employ intuitive visual representations that can be readily understood and interpreted by nontechnical decision makers these representations highlight similarities and differences between management alternatives that emphasize different needs this subsection reviews applications that use visual analytics to enable interactive processes for decision making miettinen 2014 miettinen et al 2008 aydin et al 2015 proposed a decision support system to assess the technical sustainability of water distribution systems wds used to improve the effectiveness of the decision making process the method combines multiple maps with a modified network representation that consists of aggregated edges circle views and a grid layout to visualize the technical sustainability assessment results for various new pump and reclaimed water scenarios within a water distribution network at different time steps the technical sustainability assessment evaluates the reliability durability flexibility and adaptability of a wds through coordinated views and visual abstractions the visualization approach allows decision makers to visually compare multiple facets e g technical sustainability assessment hydraulic efficiency water quality of different pump alternatives in the context of a water distribution network thus the effort can assist decision makers in improving raw data visibility and comparing multiple decision alternatives matrosov et al 2015 integrated a water system simulator with multiobjective search to generate a diverse set of pareto optimal water supply portfolios afterward the study assessed the set by developing a state of the art visual analytics approach the approach integrates a variety of interactive plots to help planners identify more adequate water supply system designs to better understand their inherent trade offs between the best scheme portfolios the effort can help water resources managers better understand projected water demands to improve planning in a real world water resource system 5 advancements in visualization technologies the technical capabilities of visual techniques have been further improved through next generation web based technologies such as the emerging 5g network web graphics libraries accelerated by general purpose graphics processing units gpgpus adaptive client side web frameworks and a number of online data analysis and visualization platforms from a technical standpoint these hardware and software improvements have significantly enhanced the following abilities for building powerful visual computing applications internet bandwidth to transfer massive amounts of data in a timely fashion client side computational power to render large amounts of data on computers or mobile devices and organization and coordination of individual plots and charts to construct a visual analytics workflow with sophisticated user interactions powered by these capabilities online data analysis and visualization platforms such as tableau powerbi grafana and kibana are gaining popularity in business analytics and academia combined with geospatial server applications such as geoserver and cartodb these platforms are increasingly introduced in college courses and scientific research sectors the major advantage of these platforms is that they can integrate a suite of visualization techniques user interface design and data analysis tools into a generic web environment using modular and adaptive design through the web environment nontechnical users without computer science or web development backgrounds could build data queries and visual dashboards without the need to write a substantial amount of code these platforms bring big changes in software development in the hydroinformatics community where web developers were previously required to write code from scratch using heterogeneous programming languages and software stacks these online visualization platforms are becoming popular in visual computing because they can lower the technical barriers for non computer science students and domain experts for building advanced visual interfaces and dashboards they also enable domain scientists to be directly involved in developing visual interfaces and dashboards thereby promoting visual computing techniques as an integral part of the scientific process many of these platforms are also freely available and created under open source licenses which makes them accessible to scientific research communities 5 1 graphics in web based visualization most graphics in web based visual interfaces and dashboards are rendered on the client side in a user s browser as html document object model dom elements popular web visualization libraries and frameworks rely on two major types of dom elements to construct plots charts and visual representations 1 scalable vector graphics svg and 2 html5 canvas each type uses distinct graphics rendering mechanisms svg uses vector shapes to generate geometries whereas the canvas display geometries use a raster of pixels reddy et al 2021 depending on the type of dom element some visualization libraries are more suitable for fulfilling specific visualization and visual analytics needs e g displaying big data enabling advanced user interaction scaling plots and graphics to different scales and screen resolutions than other libraries plots charts and geovisualizations e g markers symbols glyphs rendered through svg based libraries use vector graphics to represent different geometries e g lines boxes dots circles and visualization components e g plot axes ticks map labels these vectors are defined as xml format objects in an svg viewer defined as svg which can be embedded in the html page that then renders the client side views any components that a user can visually see of a web application in this setting vector graphics rendered in a chart or web map are scalable which allows them to change size to fit any user defined resolution or scale without losing quality because these vectors are defined as client side objects their styles and shapes can be modified dynamically through client side javascript and cascading style sheets this allows svg based visualizations to be very responsive to user interactions e g filtering data changing line color stroke width dragging a point marker across a chart or map users can click or hover on a graph which can be applied to represent the stream network in a catchment and highlight edges that represent a specific stream to access its geometric information and other properties in another example multiple svg based plots can be readily connected through the common dom manipulation techniques because their graphics objects can be connected through the dom element s id this setting allows the visual interface to highlight corresponding graphics in other charts or maps when the user hovers over or clicks on a specific element in a chart or on a web map this feature allows developers to create coordinated views using multiple maps and charts to help users explore multiple facets of complex data simultaneously in general svg based libraries are suitable for developing visualizations and visual analytics interfaces that emphasize user interaction and view coordination a major limitation of svg based visualizations is that they are unable to efficiently render large amounts of data e g millions of points in contrast html canvas based libraries represent geometries as pixels in an html canvas element defined as canvas which is raster based and rendered in a way that resembles images such as jpeg and png compared with the svg based visualizations static canvas based visualizations cannot be readily scaled to any resolution without reconstructing the raster because individual geometries e g lines circles are defined as image pixels in a canvas element their styles cannot be dynamically modified and their attributes cannot be accessed the same way a user can interact with a vector object changing the color shape or position of a geometry in a canvas based chart would normally require the client side javascript to reconstruct the entire raster image in its canvas element however canvas based visualization libraries have better performance when they are used to render a large number of graphics such as drawing thousands of lines and circles in a chart or on a map in which graphics are represented as pixels not objects therefore handling these graphics does not require significant memory on the client side in recent years much effort has been dedicated to integrating the webgl into regular canvas elements the webgl is a javascript api that enables the gpu accelerated usage of physics and image processing and effects on the client side webgl based libraries can render interactive 3d graphics or visualize a tremendous amount of data in a web environment e g eighty trillion point locations on an interactive web map without noticeable delay or lag in visualization performance sumbera 2019 many popular 3d web applications such as the unity real time development platform buyuksalih et al 2017 and cesium 3d geospatial platform tsai et al 2016 employ webgl to create interactive 3d environments in web browsers kr ä mer and gutbell 2015 and can be used to develop web based geospatial applications to benefit research in water resources management and other urban science sectors e g digital twin cities sermet and demir 2020 kr ä mer and gutbell 2015 laksono and aditya 2019 5 2 visualization libraries and tools in this section we review several popular web based visualization libraries and frameworks and share our early experience of developing visualization oriented applications and tools that can benefit the water science community s research efforts and management operations because many visualization driven studies reviewed and discussed in previous sections are implemented using these libraries and frameworks we would like to discuss their advantages and applicability to provide insights and share our experiences regarding selecting the most appropriate web visualization technologies for a task table 1 summarizes popular web based visualization libraries and their capabilities for developing visual computing applications for research purposes through a few qualitative metrics we use github stars as an evaluator of each library s popularity which indicates the number of times the library gets endorsed by the web development community selecting a popular and trending visualization library for hydroinformatics and water management applications is important because plots and charts developed using popular libraries typically exhibit more consistent and frequent maintenance and versioning the underlying technologies of these libraries are continuously supported and improved by the open source software development community we also list the number of prebuilt chart types in each library that can be readily used and integrated into a web application as an api with minimal coding efforts most of these libraries provide a number of standard charts such as line bar area and pie some libraries offer more sophisticated chart types such as graphs parallel coordinate plots edge bundles and radar plots many webgl based libraries do not provide prebuilt charts but can create 2d and 3d environments for visualizing terrain and buildings cesium 2015 mamoowala 2020 3d objects and point clouds from lidar measurements cesium 2021 the geovisualization ability indicates if the library could be used to visualize gis data some libraries can be used to design and develop innovative visual representations of complex spatial data and choropleth maps to produce interactive web maps they can export dom elements to be readily integrated into popular web map engines such as leaflet openlayers mapbox and google maps 6 conclusion and vision here we summarize our review of visual computing applications developed for water resources management section 6 1 and we present our vision section 6 2 for integrating the emerging state of art visual computing technologies and paradigms into next generation hydroinformatics applications in pursuit of the smart water city approach 6 1 summary of past applications recent improvements in environmental monitoring technologies have enabled efficient and economic acquisitions of tremendous amounts of water related data which has led to the emergence of innovative big data applications that can address past challenges and generate useful insights in water science disciplines among these applications visual computing techniques empower the synergy of computational techniques e g ml and statistical models and human reasoning capabilities through visual interfaces to improve the understanding and solution of complex decision problems in many scientific domains we reviewed past studies that employ various visual computing techniques as their core component to benefit research efforts in the water resources management sector we also discussed visual computing methodologies in these studies from the perspectives of visual analytical reasoning visual representation and user interaction and data representation and transformation many past studies integrated visual computing techniques into gis cyberinfrastructure and domain models to benefit the big data analysis aspect of water resources management these aspects broadly include 1 improvement of discovery management and quality control of large scale hydrologic and environmental data and 2 interpretation and optimization of simulation and data models more recent studies have adopted visualization and visual analytics as independent research investigation efforts to enable qualitative analysis and exploration e g patterns dependencies interrelationships with the recent increase in volume variety and quality of environmental and hydrologic data we envision a future trend of leveraging visual computing techniques as a more significant scientific and investigative tool for solving complex research problems which are defined by big data and are challenging to solve through traditional domain specific approaches e g statistical models physical models from a social technical viewpoint visual computing techniques could be applied to various watershed and urban water management efforts to promote 1 water education and public awareness of various water related issues 2 collaborative management planning and public engagement and 3 optimization of complex multiobjective and multicriteria decision problems with the advent of web based visualization and immersive reality visual computing applications in water resource management are becoming more accessible and intuitive and serving as an effective medium to connect different participants e g hydrologists decision makers watershed managers stakeholders in a more collaborative and integrated water management approach in the near future we expect visual computing techniques to become the foundation for disseminating water education raising public awareness of various water problems and increasing public engagement we also discussed recent advancements in visualization technologies their mechanisms for rendering graphics in web applications and the advantages of different technologies for building visualization and visual analytics applications with different focuses we summarized a list of popular web visualization libraries for developing charts plots web maps and 3d geospatial environments many recent online platforms for data analysis and visualization are combined with geospatial server applications to integrate a stack of visualization gui design and data analysis tools into a generic web environment using a modular and adaptive design these online platforms enable nontechnical users without a computer science or web development background to build data queries and visual dashboards through guis without writing a substantial amount of code additionally many modern web visualization libraries provide intuitive and well defined apis that can lower the technical barriers for non computer science students and domain scientists to build advanced web apps and dashboards with web mapping data visualization and visual analytics capability 6 2 vision in recent decades many emerging visual computing technologies and paradigms have garnered attention in the scientific software community bernholdt et al 2021 we summarize several visions for emerging visualization and visual analytics approaches which are proposed through the advanced scientific computing research ascr workshop on visualization for scientific discovery decision making and communication u s department of energy 2022 and propose our vision for using these technologies to benefit next generation hydroinformatics applications for water resources management at the technological level several white papers from the workshop discussed the potential application and opportunities of the recently emerging extended reality xr technology for environmental science and earth science disciplines u s department of energy 2022 based on our review of existing virtual reality luo et al 2011 and augmented reality carmigniani et al 2011 applications in the water resources sector we believe the xr technology and its related metaverse concept could be integrated with hydroinformatics and smart city applications the integration can further overcome sociotechnical challenges and improve public education engagement voluntary data collection and collaborative planning of water resources through immersive and realistic visualizations as the metaverse concept captures the tech industry s imagination and investments it has potential as a major contributor to the next generation internet through which future xr based applications for water education and voluntary data collection could be seamlessly incorporated into our daily lives meanwhile several ascr white papers discussed a vision of developing intelligent visual analytics nazemi 2018 a concept that further leverages the capability of ai to improve visualization algorithms and visual analytics design these improvements include 1 increasing the computational capacity e g volume rendering particle tracing for visualizing big data and 2 enhancing human perception and cognition abilities during complex and analytical tasks through ai driven annotations and storytelling workflows nazemi 2018 we believe intelligent visual analytics techniques can be integrated into future hydroinformatics applications to reduce human perception efforts in exploratory visual analysis thereby making charts graphs and visual analytical workflows more intelligent and easier to understand many physical phenomena in environmental systems e g hysteresis in river flow can be captured by special graphical characteristics e g a certain shape in the line charts through the visualization of sensor observations a computer vision application powered by deep learning models can automatically detect these characteristics and then guide the expert users to the subset of big environmental observation data that discloses the graphical characteristics through annotations and automated visual storytelling workflows at the paradigm level many of the next generation internet technologies e g internet of things 5g networks are employed by a broad environmental and urban science community to develop smart city platforms and digital twin cities in this ongoing trend visual computing techniques serve as a bridge to connect smart city applications with the existing hydroinformatics applications and water management platforms this connection aims to shed light on a more integrated smart water city approach that incorporates water resources management with the planning and optimization of other urban subsystems e g building energy transportation urban microclimate we believe next generation water resources management applications will be able to address a broad scope of social demands and socioeconomic factors and have more opportunities to solve complex problems that combine urban dynamics with environmental processes examples of these applications include 1 incorporating the urban green water infrastructure design into the transportation system planning to lower the risk of roadway inundation and culvert overtopping during flood events and 2 considering the risks of water related hazards e g flood excessive soil erosion water induced landslides during urban planning to protect critical energy infrastructure e g electrical grid gas credit authorship contribution statement haowen xu review writing and original draft preparation andy berres data curation writing and revision yan liu revision and administration melissa r allen dumas data curation writing and revision jibonananda sanyal revision and administration disclaimer oak ridge national laboratory is managed by ut battelle llc for the us department of energy under contract de ac05 00or22725 this manuscript has been authored by ut battelle llc under contract numberde ac05 00or22725 with the us department of energy doe the us government retains and the publisher by accepting the article for publication acknowledges that the us government retains a nonexclusive paid up irrevocable worldwide license to publish or reproduce the published form of this manuscript or allow others to do so for us government purposes doe will provide public access to these results of federally sponsored research in accordance with the doe public access plan http energy gov downloads doe public access plan declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25582,climate change could alter species composition with feedback on fire disturbances by modifying fuel types and loads however the existing fire predictions were mainly based on climate fire linkages that might overestimate the probability and size of fire disturbances due to simplifying or omitting vegetation feedback we applied a model coupling framework that combines forest succession climate fire linkages and vegetation feedback to predict burned area aboveground biomass and species composition of boreal forests in northeast china under climate change conditions results showed that climate change and fire would favor the recruitment of deciduous species but these species need a long time to replace the existing coniferous species burned area would increase with climate change climate change historical and future fire disturbances affect aboveground biomass by altering tree mortality and regeneration further studies should address strategies for altering species composition through forest management practices to adaptation climate change and reduce carbon losses from fire graphical abstract image 1 keywords climate change vegetation feedback forest landscape model model coupling wildfire boreal forests 1 introduction climate change directly affects forest ecosystems through physiological and demographic processes such as photosynthesis respiration growth mortality and species competition which catalyze the dynamics of forest succession anderson teixeira et al 2013 boulanger et al 2017 rüger et al 2020 climate change also indirectly affects forest ecosystems by altering the frequency and intensity of fire disturbances mcdowell et al 2020 seidl et al 2017 previous studies showed that climate change has already increased burned area in many regions of the world in recent decades westerling et al 2006 abatzoglou et al 2019 increases in frequency and intensity of fire would alter the species composition of boreal forests by initiating cycles of secondary succession and generating opportunities for deciduous species johnstone et al 2010 hart et al 2019 thereby affecting the aboveground biomass of forests vanderwel et al 2013 in turn changes in species composition and aboveground biomass feedback to fire and climate change by modifying fuel properties and loads surface albedo carbon and water fluxes of forest ecosystems rogers et al 2015 terrier et al 2013 thus predicting the responses of boreal forests to climate fire vegetation interactions has important implications for developing adaptive forest management strategies to cope with climate change and fire disturbance the existing fire prediction studies were mainly based on climate fire linkages and establishing statistical relationships among fire such as historical fire records or tree ring reconstruction of fire history climate vegetation topography and human activities data these relationships have previously been used to predict fire regimes under future climate conditions fonseca et al 2019 young et al 2017 forecasts based on climate fire linkages have suggested that burned areas would increase significantly with climate change particularly in boreal forests flannigan et al 2009 liu et al 2012 these predictions assume that vegetation would remain relatively static since they mainly accounted for climate indicators such as temperature precipitation fuel moisture and fire weather hessl 2011 however recent studies have reported that climate induced changes in species composition and stand age would reduce burned area of boreal forests by modifying fuel properties and loads boulanger et al 2017 girardin et al 2013 fig 1 without accounting for vegetation feedback these studies based on climate fire linkages may overestimate the frequency and size of future fire disturbances dynamic global vegetation models dgvms integrate the interactions of vegetation dynamics between the processes of fire occurrences spread and effects to predict fire regimes under climate change conditions bachelet et al 2015 rogers et al 2011 the predictions from dgvms suggested that the existing coniferous species would gradually be replaced by deciduous species between 2050 and 2100 which would significantly reduce burned area of boreal forests holsinger et al 2019 wu et al 2015 however the interactions between fire and vegetation dynamics in dgvms are highly simplified due to the coarse spatial resolutions 50 100 km required to simulate at regional to global scales bradstock 2010 in most dgvms fire occurrence is determined by fuel moisture and loads fire effects are simulated as interactions between fire intensity and fire tolerance of each plant functional type sato et al 2007 thonicke et al 2001 plant functional types are sets of species showing similar responses to the environment and similar effects on ecosystem functions wullschleger et al 2014 the effects of fire on aboveground biomass are usually simulated as reducing part of the biomass of each plant functional type lenihan et al 2003 the appearance and extinction of plant functional types pfts are mainly determined by prevailing environmental conditions and resource competition and individual species responses to climate change and disturbances are not considered in the dgvms hantson et al 2016 abundant studies have revealed differences in mortality rate and recruitment between individual tree species even within the same pft allen et al 2010 hanbury brown et al 2022 mcdowell et al 2011 fire could enhance the expansion of fire tolerant species such as water oak and longleaf pine due to these species have a higher survival rate and ability of recruitment hanberry et al 2020 thus lumping the responses of individual species to climate change and fire may lead to high uncertainty in predicting fire disturbances under future climate conditions hessl 2011 héon et al 2014 many ecological process models i e empirical models theoretical community models and patch scale vegetation models can well simulate the effects of climate change on fire and the response of forests to fire however these ecological process models have inherent limitations that may reduce their utility for exploring climate fire vegetation interactions keane et al 2004 for instance empirical and theoretical community models have assumed that vegetation would quickly response to changing climate cary et al 2006 bradstock 2010 in contrast to dgvms and ecological process models forest landscape models are designed to simulate species level forest dynamics in combination with natural and anthropogenic disturbances such as fire scheller et al 2011 he et al 2017 these models can simulate fire occurrence spread and effects at a much finer spatial scale 10 1000 m spatial resolution fire occurrence is determined by fuel availability and climate conditions schumacher et al 2006 the direction and speed of fire spread mainly depend on fuel moisture and loads wind direction and topography of neighboring pixels sturtevant et al 2009 yang et al 2004 fire effects tree mortality and biomass reduction are simulated as the interactions among fire intensity age cohorts and fire tolerance of each species keane et al 2004 fires often lead to a high mortality rate for young age cohorts and low fire tolerance species ehle and baker 2003 therefore forest landscape models can represent the effects of fire on forests more realistically however forest landscape models simulate burned area using historical fire data or predictions from climate fire linkages models without including vegetation feedback keane et al 2015 this is because forest landscape models need to balance ecological complexity and the current computational capabilities to simulate fine scale spatial processes at large spatial and long temporal scales keane and finney 2003 species composition is expected to change significantly under future climate conditions which would feedback to fire regimes by altering fuel types and distribution higuera et al 2009 this may lead to simulated results from forest landscape models that cannot reflect the novel fire regimes under climate change conditions more than 80 of china boreal forests are distributed in the great xing an mountains of northeast china since the 1980s 30 of china s forest fires occurred in this region chang et al 2013 previous studies showed that china boreal forests are vulnerable and sensitive to climate change and fire wan et al 2018 zhang and liang 2014 climate change and fire would accelerate the northward migration of deciduous species and thus alter fire regimes of boreal forests in northeast china peng et al 2009 palaeoecological studies also found that climate induced changes in forest composition significantly altered fire regimes of boreal forests girardin et al 2013 terrier et al 2013 in this study we investigate the response of boreal forests to climate fire vegetation interactions in northeast china to do this we applied a model coupling framework to integrate the dynamics of forest succession climate fire linkages and vegetation feedback for predicting burned area aboveground biomass and species composition under climate change and corresponding fire disturbance scenarios we hypothesized that 1 climate change and fire would favor the recruitment of deciduous species and thereby lead to the replacement of coniferous species by deciduous species at the end of 21st century 2 changes in species composition would markedly reduce burned area of boreal forests in 2000 2100 and 3 the decline in burned area would promote the accumulation of aboveground biomass of boreal forests 2 methods 2 1 study area the study area comprises 8 37 106 ha of forest over northeast china fig 2 this area spans a substantial elevation gradient ranging from 406 to 1515 m the mean daily temperatures range from 37 to 17 1 c and the average annual temperature is 4 31 c annual precipitation is 503 1 mm most of the precipitation is concentrated in the summer seasonally frozen soil is widely distributed in the study area and permafrost is mainly distributed in the marshes the vegetation regionalization of this region belongs to siberian taiga forest larix gmelinii and betula platyphylla are the widest distribution species which cover more than 80 of the forest pinus sylvestris picea koriensis and pinus pumila account for less than 15 of the forest populus davidiana populus suaveolens and chosenia arbutifolia are primarily occurred in the south slope and river valleys occupying approximately 5 of the forest the major disturbances in this region are fire and timber harvesting zhang and liang 2014 over 40 of forest in the area was harvested between 1965 and 2007 although timber harvesting was banned fire suppression policies and timber harvesting have altered fire regimes of boreal forests chang et al 2008 compared to historical fire regimes the current fire regimes in this region are described as having less frequent surface fires but more high severity crown fires fang et al 2015 long term fire and timber harvesting result in many larix gmelinii forests gradually degenerating into secondary betula platyphylla and populus davidiana forests chen et al 2015 the mean stand age of boreal forests in our study area is 40 60 years li et al 2013 2 2 model coupling framework in this study the forest ecosystem model linkages 3 0 dijak et al 2017 the spatial point pattern analysis model spp liu et al 2012 and the forest landscape model landis pro wang et al 2014 were integrated into a model coupling framework for predicting the response of boreal forests to climate fire vegetation interactions huang et al 2021 the effects of climate change on resource carrying capacity maximum growing space mgso and species potential colonization probability species establishment probability sep were simulated by linkages model we used the spp model to predict fire occurrence density under climate change scenarios the mgso sep and fire occurrence density were then entered into landis pro to simulate the effects of climate change fire and their interactions on tree growth seed dispersal mortality and biomass accumulation appendix s1 to distinguish from the current model coupling framework simulated species composition from landis pro was entered into spp model as a vegetation feedback parameter to predict fire occurrence density for the next time step fig 3 in landis pro model simulated species composition was used to calculate fuel loads at each pixel the effects of climate change and vegetation feedback on fire occurrence spread and cumulative burned area were simulated in landis pro through updated seps species composition fire occurrence probability fire return interval and the mean fire size 2 3 model parameterization linkages model and parameterization linkages 3 0 is a semi empirical model designed to simulate stand dynamics evapotranspiration soil carbon and hydrological cycles dijak et al 2017 linkages model calculates growing season degree days soil moisture actual and potential evapotranspiration based on daily precipitation temperature wind speed solar radiation soil field capacity and wilting point these factors constrain tree reproduction growth and biomass accumulation pastor and post 1986 changes in temperature and precipitation cause a prolonged water deficit due to evapotranspiration and respiration thereby leading to tree mortality in this study we applied linkages model to simulate the response of species potential colonization probability sep and resource carrying capacity mgso to climate change the daily climate data from a meteorological observation dataset and a climate change dataset was used to parameterize spp and linkages model climate change dataset was derived from the projections of six general circulation models gcms of ipcc cmip5 cnrm cm5 ipsl cm5a lr fgoals g2 ccsm4 hadgem2 ao and bnu esm under three greenhouse gas emission scenarios lower rcp2 6 medium rcp4 5 and higher rcp8 5 flato et al 2013 vuuren et al 2011 the performances of gcms used in this study were tested by meteorological observed data predictions from six gcms showed that temperature and precipitation would increase in our study area over the 21st century fig 4 and fig s1 compared to the current climate the annual mean temperature and precipitation from six gcms increased by 0 9 5 5 c and 32 3 76 1 over the 21st century table 1 the meteorological observation dataset was provided by china national meteorological information center 1965 2014 http www cma gov cn and climate change data were downloaded from the earth system grid federation 2006 2100 https esgf node llnl gov we used the machine learning ensemble thin plate spline interpolation model machisplin to downscale climate data to 3 km spatial resolution in the machisplin model elevation aspect and slope were used to interpolate climate data through a machine learning ensemble that included boosted regression trees brt neural networks nn generalized additive model gam multivariate adaptive regression splines mars support vector machines svm and random forests rf algorithms xue et al 2021 the thickness of soil layers texture soil carbon and nitrogen content were provided by china national soil information service platform http www soilinfo cn soil layer field water holding capacity and wilting point were calculated based on the percentages of clay sand and rock the parameters of individual tree species were obtained from previous studies in this area huang et al 2018 table s1 stand parameters diameter at breast height number of trees slope and aspect were obtained from china national forest inventory data spp model and parameterization the spp model is a dataset x x 1 x n containing n fire occurrence data observed at a specific period which can generate new dataset x through the poisson point process ppp function liu et al 2012 the ppp function fits fire occurrence density and spatial variables based on a log linear regression model as follows f i r e o c c u r r a n c e d e n s i t y f u t u r e e x p θ 1 θ 2 c lim a t e θ n h u m a n where fire occurrence density future represents future fire occurrence density under climate change conditions parameter vector θ 1 θ 2 θ n was estimated using the ppm function in the spatstat package of r software baddeley and turner 2005 spatial variables in table 2 were used to fit the ppm function we collected 182 fire occurrence records ranging from 1965 to 2014 in the china national science data infrastructure of forestry http www lknet ac cn the fire occurrence record included the geographic coordinates burned area the cause of each fire and dates of occurrence and extinction a total of 182 fires burned 57 041ha of forest in our study area fig s2 in this study the spp model was conducted based on 182 fire occurrence records the 30 m digital elevation model dem data were derived from the international scientific data service platform of computer network information center chinese academy of sciences http datamirror csdb cn slope and aspect were generated from 30 m dem data to represent the effects of topography on fire occurrence and spread our study area was divided into bottomland flat steep slope and ridge top the land use map road and population density were provided by the resource and environmental science data center of chinese academy of sciences https www resdc cn we calculated the euclidean distance to the nearest settlement or road for each pixel table 2 the initial vegetation types were obtained from a forest type map in the study area fig 2 vegetation types were grouped into coniferous forest 65 2 deciduous forest 21 7 mixed forest 7 5 shrub and wetland 5 6 at each time step we used the simulated species composition from landis pro as new vegetation types to predict fire occurrence density for the next time step in the spp model fire weather index fwi was used to simulate the effects of temperature precipitation relative humidity and wind speed on fire occurrence density fine fuel moisture code ffmc and duff moisture code dmc were used to reflect the moisture content of litter moderate duff layers and medium size woody material ffmc and dmc were determined by the daily temperature precipitation relative humidity and wind speed in this study ffmc and dmc were estimated from the current climate and climate change data using the r statistical package fwi fbp wang et al 2013 the 90th percentile of daily ffmc and dmc at each pixel during the fire season 5th april to 20th october were used to calculate fire occurrence density landis pro model and parameterization in landis pro fire simulations involve the processes of fire occurrence fire spread and interaction of fire with tree species appendix s2 and fig s3 at each time step the poisson distribution is used to generate the number of ignitions for a given ecoregion or land type following either a historic fire ignition distribution or a prediction of future fire ignition distribution yang et al 2004 whether a fire ignition can result in fire initiation depends on a stochastic function based on fuel loads and fuel moisture of ignition pixels fuel loads were estimated based on species age and tree species leaf type e g conifer vs deciduous fire spread mainly depends on fuel configuration topography and prevailing wind yang et al 2008 a fire will spread out from the ignited pixel along eight directions to the neighboring pixels the probability of spreading direction at each pixel is determined by topography fuel type and loads wind direction and speed in landis pro fuel types from different species have different flammability due to differences in physical and chemical attributes which are reflected in the fuel quality coefficient the interactions of climate change and fire with tree species are simulated across the whole landscape including tree growth establishment and mortality we divided the study area into four ecoregions according to land use topography and vegetation type each ecoregion had a homogenous resource carrying capacity and species potential colonization probability tables s2 and s3 the life history attributes for each tree species were obtained from previous studies conducted in this region huang et al 2018 table s4 the initial forest composition derived from a forest type map and china national forest inventory data at each time step species composition simulated by landis pro was used to update the forest composition map for the next time step we estimated the initial fire parameters from the historical fire occurrence records the fire regime map was derived from the ecoregion map reflecting the geographic differences in fire regimes 30 m dem data were used to simulate the impacts of terrain on the spread of fire ignition points at each time step fire parameters were estimated by the outputs of the spp model fire occurrence density and landis pro model burned area under climate change conditions appendix s3 and fig s4 2 4 experimental design and data analysis to investigate the response of northeast china boreal forests to climate fire vegetation interactions we designed a factorial experiment with two levels of fire disturbances with vegetation feedback vs without vegetation feedback and ten climate scenarios current climate vs nine climate change scenarios to assess the sensitivity of our model coupling framework to climate change we selected nine climate change scenarios from six cmip5 global climate models gcms to represent the lowest to highest temperature and precipitation changes in 2000 2100 temperature and precipitation increased by 0 5 5 c and 0 76 in our study area at the end of 21st century respectively the current climate without vegetation feedback scenario was treated as the reference to distinguish the effects of climate change and vegetation feedback in the without vegetation feedback scenarios vegetation was assumed to be relatively static for the vegetation feedback scenario fire was simulated with climate change vegetation feedback and their interactions vegetation was dynamic with climate change and fire throughout the simulation period aboveground biomass and burned area were simulated from 2000 to 2100 using 5 year time steps at 150m spatial resolution five replications started with the same input parameters but used different random number seeds to account for the effects of stochasticity in fire occurrence and spread seed dispersal and seedling establishment sturtevant et al 2009 scheller et al 2011 the simulated results were divided into two groups without vegetation feedback vs with vegetation feedback to quantify the effects of climate change fire vegetation feedback and their interactions on burned area and aboveground biomass to assess the temporal variation in burned area and aboveground biomass our simulation results were analyzed separately for the short term 0 30 years medium term 40 60 years and long term 80 100 years we used tukey s honestly significant difference hsd to test the differences in burned area and aboveground biomass between rcp2 6 rcp4 5 and rcp8 5 scenarios at three time periods p 0 05 we calculated the changes in spatial distribution of tree species between the current climate and nine climate change scenarios the changes in spatial distribution of tree species between the end of 21st century and initial species distribution were categorized as colonization unchanged and extinction in our study area data analyses were done using r statistical software v4 0 2 r core team 2020 2 5 model validation in 2000 and 2010 471 and 539 forest inventory plots were used to validate landis pro respectively fig s5 observed aboveground biomass was estimated based on the stand volume at each forest inventory plot we then directly compared observed and simulated aboveground biomass to evaluate the performance of landis pro we used the average of burned area from historical fire occurrence data to validate the simulated burned area from landis pro the model validation results showed that the simulated aboveground biomass and burned area were close to observed values appendix s4 figs s6 and s7 3 results 3 1 changes in burned area of boreal forests in the 21st century regardless of whether vegetation feedback was considered climate change would significantly increase burned area of boreal forests in northeast china over the 21st century fig 5 a and fig s8 burned area was expected to increase by 34 336 3508 34 668 ha under the without vegetation feedback scenarios and by 23 239 2479 25 756 ha under the vegetation feedback scenarios in 2080 2100 burned area under the vegetation feedback scenarios was 14 12 lower than that in the without vegetation feedback scenarios the variation in burned area of boreal forests is affected by climate change under the without and with vegetation feedback scenarios there were significant differences in burned area among rcp2 6 rcp4 5 and rcp8 5 scenarios at three time periods p 0 05 fig 5b burned area under the rcp2 6 scenarios with a relatively small degree of climate change was significantly lower than that in the rcp4 5 and rcp8 5 scenarios with significant climate change under the without and with vegetation feedback scenarios the difference in burned area among three rcp scenarios increased with simulation time 3 2 changes in aboveground biomass of boreal forests in the 21st century aboveground biomass increased considerably in the 21st century at the landscape scale recovering from historical timber harvesting and fire disturbances fig 6 a and fig s9 although climate change and fire significantly increased tree mortality rate of boreal forests fig s10 aboveground biomass increased by 143 51 t ha in the 21st century aboveground biomass under the vegetation feedback scenarios was 0 4 14 1 higher than that in the scenarios without vegetation feedback the differences in aboveground biomass between without vegetation feedback and with vegetation feedback scenarios increase with simulation time the differences in aboveground biomass between these two scenarios have increased by 351 147 at the end of 21st century the differences in aboveground biomass among rcp2 6 rcp4 5 and rcp8 5 scenarios were varied at the three time periods fig 6b in the short term the difference in aboveground biomass difference between the three rcp scenarios was not significant p 0 05 whereas there was a significant difference in the biomass among the three rcp scenarios in the long term p 0 05 in the medium term the aboveground biomass variation among three rcp scenarios is slight when vegetation feedback is considered but there was a significant difference in aboveground biomass between three rcp scenarios without vegetation feedback 3 3 shifts in the spatial distribution of species composition over the 21st century there was a divergent response of tree species to climate fire vegetation interactions fig 7 and fig 8 populus davidiana benefited substantially from climate change and fire disturbances in the 21st century compared to the initial distribution the proportions of populus davidiana would increase by 832 and 1157 under the without and with vegetation feedback scenarios in 2100 populus davidiana would colonize in the northeastern of the study area climate change and fire would alter the spatial distribution of betula platyphylla from 2000 to 2100 the proportion of betula platyphylla declined by 74 91 in 2080 2100 fig 7 betula platyphylla would become extinct in most of the study area over the 21st century and only colonize the northeast and west of the study area fig 8 although climate change and fire would reduce the proportion of larix gmelinii it was still the dominant species in this region at the end of 21st century the distribution of larix gmelinii remained unchanged in most of the study area fig 8 climate change and fire are beneficial to expansion of pinus sylvestris the proportions of pinus sylvestris would increase by 16 271 during the 21st century and it would predominantly colonize the northeastern of the study area 4 discussions this study applied a new model coupling framework that combines forest succession climate fire linkages and vegetation feedback to simulate the responses of boreal forests to climate fire vegetation interactions in northeast china our results suggested that climate change and fire would favor the recruitment of deciduous species but these species would take a long time to replace the existing coniferous species changes in species composition would partly offset the effects of climate change on burned area over the 21st century the effects of vegetation feedback on burned areas mainly depend on the velocity of coniferous species be replaced by deciduous species climate change historical and future fire disturbances could affect aboveground biomass by altering the mortality and regeneration of trees this study provides new insight into the role of climate fire vegetation interactions in regulating future forest dynamics and fire disturbances climate change and fire can strongly modify environmental conditions and the recruitment of tree seedlings thereby altering species composition and successional trajectories of boreal forests this study suggests that climate change and increases in burned area would favor deciduous species at the expense of coniferous species this is because deciduous species i e populus davidiana can better adapt to climate change and fire through asexual sprouting from roots or stumps and long distance seed dispersal rehfeldt et al 2009 landhäusser et al 2019 in our model simulation the populus davidiana seed dispersal distance was parameterized at 2400 m huang et al 2018 climate change and fire kill the existing species larix gmelinii and betula platyphylla and new coniferous species seedlings have difficulties reestablishing under warmer and drier conditions this creates opportunities for populus davidiana to move north and occupy the newly released growing space however larix gmelinii would still be the dominant species in our study area over the 21st century these findings are not entirely consistent with the first hypothesis and findings of previous studies which suggested that the rate of vegetation change could increase with higher frequency and intensity of fire girardin and terrier 2015 stralberg et al 2018 as a tree species with a small distribution under the current climate conditions even though populus davidiana can better adapt to climate warming and fire it still takes a long time to occupy the growth space of existing coniferous species moreover larix gmelinii may be more resilient to climate change and fire because it has more broad scale regeneration prospects and is long lived with a relatively higher tolerance for environmental conditions bertrand et al 2011 halofsky et al 2018 therefore the inertia of forest ecosystem may cause little change in species composition of boreal forests in northeast china over the 21st century this study hypothesized that vegetation changes would limit the increases in burned area caused by climate change however our simulation results suggested that climate change would significantly increase the burned area of boreal forests over the 21st century despite the changes in forest composition can partially offset the effects of climate change on burned area from the beginning to middle of 21st century temperature in the study area increased rapidly and the changes in precipitation were relatively small leading to a rapid increase in the burned area during this period after the 2050s temperature fluctuation and increases in precipitation leading to a smaller increase in burned area at the end of 21st century this implies that climate change has a stronger influence than vegetation feedback on the burned area of boreal forests in the 21st century our results are consistent with those reported in previous studies based on climate fire linkages models flannigan et al 2005 liu et al 2012 but inconsistent with fire predictions from dgvms knorr et al 2016 scholze et al 2006 and our second hypothesis the discrepancy in burned area between this study and some dgvms was likely due to the transition rate of species composition of boreal forests in most dgvms vegetation changes mainly depend on bioclimatic limits and resource competition with each pft and do not consider demographic processes and the response of individual species to climate change and fire snell 2013 compared to dgvms forest landscape models include species level demographic processes i e seed dispersal species establishment growth mortality and resprouting they keep track of tree age and size when simulating the dynamics of forest succession liang et al 2017 therefore forest landscape models can capture the fact that adult trees can tolerate warmer climates forests have inertia that causes them to change gradually over time under all but extreme disturbances the forest landscape model landis ii integrates vegetation feedback into fire predictions liang et al 2017 scheller et al 2019 the findings from landis ii and this study suggested that future studies should incorporate vegetation feedback and vegetation responses to climate change into fire predictions for realistically assessing the effects of climate change and fire on forests given the prediction that climate change and increasing fires significantly affect tree mortality and regeneration we hypothesized that the decrease in burned area would lead to higher aboveground biomass of boreal forests our results demonstrated that the long term fire disturbances and intense timber harvesting caused a legacy effect and that tree growth would continue for a century or longer this may reduce the effects of climate change and fire on aboveground biomass of boreal forests our results are not entirely consistent with the third hypothesis this is because the stand age of boreal forests in northeast china is affected primarily by historical fire and harvest the initial stand age in our study area is 40 60 years li et al 2013 extensive tree growth and forest recovery could continue to promote the accumulation of aboveground biomass in boreal forests of northeast china aboveground biomass increased considerably in the 21st century suggesting that the historic fire and timber harvesting may have a greater effect on aboveground biomass than the effects of climate change rhemtulla et al 2009 loudermilk et al 2013 besides the growth rate of deciduous species is faster than coniferous species and thus have potential to accumulate more aboveground biomass moreover climate change and fire not only cause carbon losses from fire emissions and tree mortality kurz et al 2008 but also alter vegetation recovery after fire due to seed dispersal limitations and low water availability johnstone et al 2011 whitman et al 2019 therefore this study highlights climate change forest succession and past and future disturbances have combined effects on the carbon sequestration of boreal forests we included estimates of dead and live fuel which reflected the effects of fire suppression in this study fires simulated in our model coupling framework involved many high severity crown fires and reflected the reports from previous studies chang et al 2008 fang et al 2015 although fire suppression policies can increase aboveground biomass by altering stand density and reducing the frequency of fire disturbances long term fire suppression might result in a build up of fuel loads which would increase the probability of catastrophic fires chang et al 2007 deciduous species are less flammable than coniferous species and thus have the potential to reduce fire occurrence density and burned area of boreal forests lynch et al 2004 terrier et al 2013 our results showed that vegetation feedback is expected to offset partial effects of climate change on the burned area of boreal forests the effects of vegetation feedback on burned areas mainly depend on replacing coniferous species with deciduous species hence planting appropriately deciduous species may be an option for reducing burned area and promoting boreal forests to adapt to climate change our simulated results are limited by three factors 1 in our model coupling framework changes in forest composition were only represented by the presence and absence of eight existing tree species the invasive species and understory vegetation were excluded in this study previous studies showed that climate change favors temperate species and alters understory plant communities of boreal forests bellard et al 2013 hedwall et al 2019 this may accelerate the velocity of vegetation change and thus amplify the effects of vegetation feedback on fire regimes by altering fuel characteristics and loads 2 fire is strongly associated with human activities such as population distance to settlements and roads land use and cover change guo et al 2014 previous studies revealed that climate warming would increase human activities in the boreal forests of northeast china which alter fire regimes of boreal forests by modifying fire ignition patterns and occurrence probabilities liu et al 2015 in contrast some studies projected that population density would decline in this region due to environmental protection policies hu and zhou 2014 thus we assumed that human activities would remain constant in the 21st century which may lead to high uncertainties in our simulated results 3 this study did not consider the effects of climate change and fire on permafrost degradation prior studies reported that climate change and increased fire disturbances would accelerate permafrost degradation in this region jin et al 2007 thereby affecting the spatial distribution of tree species and fire regimes tchebakova et al 2009 future studies should consider these factors to accurately predict the response of boreal forests to climate change fire and their interactions 5 conclusions vegetation lags behind climate change which leads to little change in species composition of boreal forests in northeast china over the 21st century burned area would significantly increase with climate change in this period climate change past and future fire disturbances have multifaceted consequences on the aboveground biomass of boreal forests our results highlight the importance of accounting for vegetation feedback in fire prediction and suggest that fire disturbance will catalyze the responses of boreal forests to climate change our results also showed that vegetation change is expected to offset partial effects of climate change on burned area of boreal forests vegetation feedback would significantly reduce burned area of boreal forests when the changes in species composition significantly modifies landscape flammability therefore it is necessary to implement forest management strategies such as planting appropriate deciduous species to reduce the burned area and carbon losses from catastrophic fires further studies should address how to alter species composition through forest management practices to adapt to climate change and reduce the frequency and size of fire disturbances software availability name of software spatstat developer prof adrian baddeley adrian baddeley curtin edu au program language r download http spatstat org download html name of software linkages 3 0 developer dr william d dijak wdijak fs fed us download https drive google com file d 1zt 6tw0fizcdjn4nbvfplv6v2k lrfgy view usp sharing program language fortran and c name of software landis pro developer prof hong s he heh missouri edu program language c and c download https github com landispro landis pro 7 1 credit authorship contribution statement chao huang conceptualization methodology software validation data curation formal analysis writing review editing jiayuan feng conceptualization data curation formal analysis writing review editing fangran tang conceptualization data curation formal analysis writing review editing hong s he conceptualization methodology software validation writing review editing yu liang conceptualization methodology software validation writing review editing mia m wu conceptualization software validation wenru xu conceptualization software validation bo liu data curation formal analysis writing review editing fuxi shi data curation formal analysis fusheng chen conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by the national natural science foundation of china 31800408 31961133027 31971486 and 42067049 the national key r d program of china 2018yfe0207800 and 2017yfa0604403 and the double thousand plan of jiangxi province jxsq2020101080 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105410 
25582,climate change could alter species composition with feedback on fire disturbances by modifying fuel types and loads however the existing fire predictions were mainly based on climate fire linkages that might overestimate the probability and size of fire disturbances due to simplifying or omitting vegetation feedback we applied a model coupling framework that combines forest succession climate fire linkages and vegetation feedback to predict burned area aboveground biomass and species composition of boreal forests in northeast china under climate change conditions results showed that climate change and fire would favor the recruitment of deciduous species but these species need a long time to replace the existing coniferous species burned area would increase with climate change climate change historical and future fire disturbances affect aboveground biomass by altering tree mortality and regeneration further studies should address strategies for altering species composition through forest management practices to adaptation climate change and reduce carbon losses from fire graphical abstract image 1 keywords climate change vegetation feedback forest landscape model model coupling wildfire boreal forests 1 introduction climate change directly affects forest ecosystems through physiological and demographic processes such as photosynthesis respiration growth mortality and species competition which catalyze the dynamics of forest succession anderson teixeira et al 2013 boulanger et al 2017 rüger et al 2020 climate change also indirectly affects forest ecosystems by altering the frequency and intensity of fire disturbances mcdowell et al 2020 seidl et al 2017 previous studies showed that climate change has already increased burned area in many regions of the world in recent decades westerling et al 2006 abatzoglou et al 2019 increases in frequency and intensity of fire would alter the species composition of boreal forests by initiating cycles of secondary succession and generating opportunities for deciduous species johnstone et al 2010 hart et al 2019 thereby affecting the aboveground biomass of forests vanderwel et al 2013 in turn changes in species composition and aboveground biomass feedback to fire and climate change by modifying fuel properties and loads surface albedo carbon and water fluxes of forest ecosystems rogers et al 2015 terrier et al 2013 thus predicting the responses of boreal forests to climate fire vegetation interactions has important implications for developing adaptive forest management strategies to cope with climate change and fire disturbance the existing fire prediction studies were mainly based on climate fire linkages and establishing statistical relationships among fire such as historical fire records or tree ring reconstruction of fire history climate vegetation topography and human activities data these relationships have previously been used to predict fire regimes under future climate conditions fonseca et al 2019 young et al 2017 forecasts based on climate fire linkages have suggested that burned areas would increase significantly with climate change particularly in boreal forests flannigan et al 2009 liu et al 2012 these predictions assume that vegetation would remain relatively static since they mainly accounted for climate indicators such as temperature precipitation fuel moisture and fire weather hessl 2011 however recent studies have reported that climate induced changes in species composition and stand age would reduce burned area of boreal forests by modifying fuel properties and loads boulanger et al 2017 girardin et al 2013 fig 1 without accounting for vegetation feedback these studies based on climate fire linkages may overestimate the frequency and size of future fire disturbances dynamic global vegetation models dgvms integrate the interactions of vegetation dynamics between the processes of fire occurrences spread and effects to predict fire regimes under climate change conditions bachelet et al 2015 rogers et al 2011 the predictions from dgvms suggested that the existing coniferous species would gradually be replaced by deciduous species between 2050 and 2100 which would significantly reduce burned area of boreal forests holsinger et al 2019 wu et al 2015 however the interactions between fire and vegetation dynamics in dgvms are highly simplified due to the coarse spatial resolutions 50 100 km required to simulate at regional to global scales bradstock 2010 in most dgvms fire occurrence is determined by fuel moisture and loads fire effects are simulated as interactions between fire intensity and fire tolerance of each plant functional type sato et al 2007 thonicke et al 2001 plant functional types are sets of species showing similar responses to the environment and similar effects on ecosystem functions wullschleger et al 2014 the effects of fire on aboveground biomass are usually simulated as reducing part of the biomass of each plant functional type lenihan et al 2003 the appearance and extinction of plant functional types pfts are mainly determined by prevailing environmental conditions and resource competition and individual species responses to climate change and disturbances are not considered in the dgvms hantson et al 2016 abundant studies have revealed differences in mortality rate and recruitment between individual tree species even within the same pft allen et al 2010 hanbury brown et al 2022 mcdowell et al 2011 fire could enhance the expansion of fire tolerant species such as water oak and longleaf pine due to these species have a higher survival rate and ability of recruitment hanberry et al 2020 thus lumping the responses of individual species to climate change and fire may lead to high uncertainty in predicting fire disturbances under future climate conditions hessl 2011 héon et al 2014 many ecological process models i e empirical models theoretical community models and patch scale vegetation models can well simulate the effects of climate change on fire and the response of forests to fire however these ecological process models have inherent limitations that may reduce their utility for exploring climate fire vegetation interactions keane et al 2004 for instance empirical and theoretical community models have assumed that vegetation would quickly response to changing climate cary et al 2006 bradstock 2010 in contrast to dgvms and ecological process models forest landscape models are designed to simulate species level forest dynamics in combination with natural and anthropogenic disturbances such as fire scheller et al 2011 he et al 2017 these models can simulate fire occurrence spread and effects at a much finer spatial scale 10 1000 m spatial resolution fire occurrence is determined by fuel availability and climate conditions schumacher et al 2006 the direction and speed of fire spread mainly depend on fuel moisture and loads wind direction and topography of neighboring pixels sturtevant et al 2009 yang et al 2004 fire effects tree mortality and biomass reduction are simulated as the interactions among fire intensity age cohorts and fire tolerance of each species keane et al 2004 fires often lead to a high mortality rate for young age cohorts and low fire tolerance species ehle and baker 2003 therefore forest landscape models can represent the effects of fire on forests more realistically however forest landscape models simulate burned area using historical fire data or predictions from climate fire linkages models without including vegetation feedback keane et al 2015 this is because forest landscape models need to balance ecological complexity and the current computational capabilities to simulate fine scale spatial processes at large spatial and long temporal scales keane and finney 2003 species composition is expected to change significantly under future climate conditions which would feedback to fire regimes by altering fuel types and distribution higuera et al 2009 this may lead to simulated results from forest landscape models that cannot reflect the novel fire regimes under climate change conditions more than 80 of china boreal forests are distributed in the great xing an mountains of northeast china since the 1980s 30 of china s forest fires occurred in this region chang et al 2013 previous studies showed that china boreal forests are vulnerable and sensitive to climate change and fire wan et al 2018 zhang and liang 2014 climate change and fire would accelerate the northward migration of deciduous species and thus alter fire regimes of boreal forests in northeast china peng et al 2009 palaeoecological studies also found that climate induced changes in forest composition significantly altered fire regimes of boreal forests girardin et al 2013 terrier et al 2013 in this study we investigate the response of boreal forests to climate fire vegetation interactions in northeast china to do this we applied a model coupling framework to integrate the dynamics of forest succession climate fire linkages and vegetation feedback for predicting burned area aboveground biomass and species composition under climate change and corresponding fire disturbance scenarios we hypothesized that 1 climate change and fire would favor the recruitment of deciduous species and thereby lead to the replacement of coniferous species by deciduous species at the end of 21st century 2 changes in species composition would markedly reduce burned area of boreal forests in 2000 2100 and 3 the decline in burned area would promote the accumulation of aboveground biomass of boreal forests 2 methods 2 1 study area the study area comprises 8 37 106 ha of forest over northeast china fig 2 this area spans a substantial elevation gradient ranging from 406 to 1515 m the mean daily temperatures range from 37 to 17 1 c and the average annual temperature is 4 31 c annual precipitation is 503 1 mm most of the precipitation is concentrated in the summer seasonally frozen soil is widely distributed in the study area and permafrost is mainly distributed in the marshes the vegetation regionalization of this region belongs to siberian taiga forest larix gmelinii and betula platyphylla are the widest distribution species which cover more than 80 of the forest pinus sylvestris picea koriensis and pinus pumila account for less than 15 of the forest populus davidiana populus suaveolens and chosenia arbutifolia are primarily occurred in the south slope and river valleys occupying approximately 5 of the forest the major disturbances in this region are fire and timber harvesting zhang and liang 2014 over 40 of forest in the area was harvested between 1965 and 2007 although timber harvesting was banned fire suppression policies and timber harvesting have altered fire regimes of boreal forests chang et al 2008 compared to historical fire regimes the current fire regimes in this region are described as having less frequent surface fires but more high severity crown fires fang et al 2015 long term fire and timber harvesting result in many larix gmelinii forests gradually degenerating into secondary betula platyphylla and populus davidiana forests chen et al 2015 the mean stand age of boreal forests in our study area is 40 60 years li et al 2013 2 2 model coupling framework in this study the forest ecosystem model linkages 3 0 dijak et al 2017 the spatial point pattern analysis model spp liu et al 2012 and the forest landscape model landis pro wang et al 2014 were integrated into a model coupling framework for predicting the response of boreal forests to climate fire vegetation interactions huang et al 2021 the effects of climate change on resource carrying capacity maximum growing space mgso and species potential colonization probability species establishment probability sep were simulated by linkages model we used the spp model to predict fire occurrence density under climate change scenarios the mgso sep and fire occurrence density were then entered into landis pro to simulate the effects of climate change fire and their interactions on tree growth seed dispersal mortality and biomass accumulation appendix s1 to distinguish from the current model coupling framework simulated species composition from landis pro was entered into spp model as a vegetation feedback parameter to predict fire occurrence density for the next time step fig 3 in landis pro model simulated species composition was used to calculate fuel loads at each pixel the effects of climate change and vegetation feedback on fire occurrence spread and cumulative burned area were simulated in landis pro through updated seps species composition fire occurrence probability fire return interval and the mean fire size 2 3 model parameterization linkages model and parameterization linkages 3 0 is a semi empirical model designed to simulate stand dynamics evapotranspiration soil carbon and hydrological cycles dijak et al 2017 linkages model calculates growing season degree days soil moisture actual and potential evapotranspiration based on daily precipitation temperature wind speed solar radiation soil field capacity and wilting point these factors constrain tree reproduction growth and biomass accumulation pastor and post 1986 changes in temperature and precipitation cause a prolonged water deficit due to evapotranspiration and respiration thereby leading to tree mortality in this study we applied linkages model to simulate the response of species potential colonization probability sep and resource carrying capacity mgso to climate change the daily climate data from a meteorological observation dataset and a climate change dataset was used to parameterize spp and linkages model climate change dataset was derived from the projections of six general circulation models gcms of ipcc cmip5 cnrm cm5 ipsl cm5a lr fgoals g2 ccsm4 hadgem2 ao and bnu esm under three greenhouse gas emission scenarios lower rcp2 6 medium rcp4 5 and higher rcp8 5 flato et al 2013 vuuren et al 2011 the performances of gcms used in this study were tested by meteorological observed data predictions from six gcms showed that temperature and precipitation would increase in our study area over the 21st century fig 4 and fig s1 compared to the current climate the annual mean temperature and precipitation from six gcms increased by 0 9 5 5 c and 32 3 76 1 over the 21st century table 1 the meteorological observation dataset was provided by china national meteorological information center 1965 2014 http www cma gov cn and climate change data were downloaded from the earth system grid federation 2006 2100 https esgf node llnl gov we used the machine learning ensemble thin plate spline interpolation model machisplin to downscale climate data to 3 km spatial resolution in the machisplin model elevation aspect and slope were used to interpolate climate data through a machine learning ensemble that included boosted regression trees brt neural networks nn generalized additive model gam multivariate adaptive regression splines mars support vector machines svm and random forests rf algorithms xue et al 2021 the thickness of soil layers texture soil carbon and nitrogen content were provided by china national soil information service platform http www soilinfo cn soil layer field water holding capacity and wilting point were calculated based on the percentages of clay sand and rock the parameters of individual tree species were obtained from previous studies in this area huang et al 2018 table s1 stand parameters diameter at breast height number of trees slope and aspect were obtained from china national forest inventory data spp model and parameterization the spp model is a dataset x x 1 x n containing n fire occurrence data observed at a specific period which can generate new dataset x through the poisson point process ppp function liu et al 2012 the ppp function fits fire occurrence density and spatial variables based on a log linear regression model as follows f i r e o c c u r r a n c e d e n s i t y f u t u r e e x p θ 1 θ 2 c lim a t e θ n h u m a n where fire occurrence density future represents future fire occurrence density under climate change conditions parameter vector θ 1 θ 2 θ n was estimated using the ppm function in the spatstat package of r software baddeley and turner 2005 spatial variables in table 2 were used to fit the ppm function we collected 182 fire occurrence records ranging from 1965 to 2014 in the china national science data infrastructure of forestry http www lknet ac cn the fire occurrence record included the geographic coordinates burned area the cause of each fire and dates of occurrence and extinction a total of 182 fires burned 57 041ha of forest in our study area fig s2 in this study the spp model was conducted based on 182 fire occurrence records the 30 m digital elevation model dem data were derived from the international scientific data service platform of computer network information center chinese academy of sciences http datamirror csdb cn slope and aspect were generated from 30 m dem data to represent the effects of topography on fire occurrence and spread our study area was divided into bottomland flat steep slope and ridge top the land use map road and population density were provided by the resource and environmental science data center of chinese academy of sciences https www resdc cn we calculated the euclidean distance to the nearest settlement or road for each pixel table 2 the initial vegetation types were obtained from a forest type map in the study area fig 2 vegetation types were grouped into coniferous forest 65 2 deciduous forest 21 7 mixed forest 7 5 shrub and wetland 5 6 at each time step we used the simulated species composition from landis pro as new vegetation types to predict fire occurrence density for the next time step in the spp model fire weather index fwi was used to simulate the effects of temperature precipitation relative humidity and wind speed on fire occurrence density fine fuel moisture code ffmc and duff moisture code dmc were used to reflect the moisture content of litter moderate duff layers and medium size woody material ffmc and dmc were determined by the daily temperature precipitation relative humidity and wind speed in this study ffmc and dmc were estimated from the current climate and climate change data using the r statistical package fwi fbp wang et al 2013 the 90th percentile of daily ffmc and dmc at each pixel during the fire season 5th april to 20th october were used to calculate fire occurrence density landis pro model and parameterization in landis pro fire simulations involve the processes of fire occurrence fire spread and interaction of fire with tree species appendix s2 and fig s3 at each time step the poisson distribution is used to generate the number of ignitions for a given ecoregion or land type following either a historic fire ignition distribution or a prediction of future fire ignition distribution yang et al 2004 whether a fire ignition can result in fire initiation depends on a stochastic function based on fuel loads and fuel moisture of ignition pixels fuel loads were estimated based on species age and tree species leaf type e g conifer vs deciduous fire spread mainly depends on fuel configuration topography and prevailing wind yang et al 2008 a fire will spread out from the ignited pixel along eight directions to the neighboring pixels the probability of spreading direction at each pixel is determined by topography fuel type and loads wind direction and speed in landis pro fuel types from different species have different flammability due to differences in physical and chemical attributes which are reflected in the fuel quality coefficient the interactions of climate change and fire with tree species are simulated across the whole landscape including tree growth establishment and mortality we divided the study area into four ecoregions according to land use topography and vegetation type each ecoregion had a homogenous resource carrying capacity and species potential colonization probability tables s2 and s3 the life history attributes for each tree species were obtained from previous studies conducted in this region huang et al 2018 table s4 the initial forest composition derived from a forest type map and china national forest inventory data at each time step species composition simulated by landis pro was used to update the forest composition map for the next time step we estimated the initial fire parameters from the historical fire occurrence records the fire regime map was derived from the ecoregion map reflecting the geographic differences in fire regimes 30 m dem data were used to simulate the impacts of terrain on the spread of fire ignition points at each time step fire parameters were estimated by the outputs of the spp model fire occurrence density and landis pro model burned area under climate change conditions appendix s3 and fig s4 2 4 experimental design and data analysis to investigate the response of northeast china boreal forests to climate fire vegetation interactions we designed a factorial experiment with two levels of fire disturbances with vegetation feedback vs without vegetation feedback and ten climate scenarios current climate vs nine climate change scenarios to assess the sensitivity of our model coupling framework to climate change we selected nine climate change scenarios from six cmip5 global climate models gcms to represent the lowest to highest temperature and precipitation changes in 2000 2100 temperature and precipitation increased by 0 5 5 c and 0 76 in our study area at the end of 21st century respectively the current climate without vegetation feedback scenario was treated as the reference to distinguish the effects of climate change and vegetation feedback in the without vegetation feedback scenarios vegetation was assumed to be relatively static for the vegetation feedback scenario fire was simulated with climate change vegetation feedback and their interactions vegetation was dynamic with climate change and fire throughout the simulation period aboveground biomass and burned area were simulated from 2000 to 2100 using 5 year time steps at 150m spatial resolution five replications started with the same input parameters but used different random number seeds to account for the effects of stochasticity in fire occurrence and spread seed dispersal and seedling establishment sturtevant et al 2009 scheller et al 2011 the simulated results were divided into two groups without vegetation feedback vs with vegetation feedback to quantify the effects of climate change fire vegetation feedback and their interactions on burned area and aboveground biomass to assess the temporal variation in burned area and aboveground biomass our simulation results were analyzed separately for the short term 0 30 years medium term 40 60 years and long term 80 100 years we used tukey s honestly significant difference hsd to test the differences in burned area and aboveground biomass between rcp2 6 rcp4 5 and rcp8 5 scenarios at three time periods p 0 05 we calculated the changes in spatial distribution of tree species between the current climate and nine climate change scenarios the changes in spatial distribution of tree species between the end of 21st century and initial species distribution were categorized as colonization unchanged and extinction in our study area data analyses were done using r statistical software v4 0 2 r core team 2020 2 5 model validation in 2000 and 2010 471 and 539 forest inventory plots were used to validate landis pro respectively fig s5 observed aboveground biomass was estimated based on the stand volume at each forest inventory plot we then directly compared observed and simulated aboveground biomass to evaluate the performance of landis pro we used the average of burned area from historical fire occurrence data to validate the simulated burned area from landis pro the model validation results showed that the simulated aboveground biomass and burned area were close to observed values appendix s4 figs s6 and s7 3 results 3 1 changes in burned area of boreal forests in the 21st century regardless of whether vegetation feedback was considered climate change would significantly increase burned area of boreal forests in northeast china over the 21st century fig 5 a and fig s8 burned area was expected to increase by 34 336 3508 34 668 ha under the without vegetation feedback scenarios and by 23 239 2479 25 756 ha under the vegetation feedback scenarios in 2080 2100 burned area under the vegetation feedback scenarios was 14 12 lower than that in the without vegetation feedback scenarios the variation in burned area of boreal forests is affected by climate change under the without and with vegetation feedback scenarios there were significant differences in burned area among rcp2 6 rcp4 5 and rcp8 5 scenarios at three time periods p 0 05 fig 5b burned area under the rcp2 6 scenarios with a relatively small degree of climate change was significantly lower than that in the rcp4 5 and rcp8 5 scenarios with significant climate change under the without and with vegetation feedback scenarios the difference in burned area among three rcp scenarios increased with simulation time 3 2 changes in aboveground biomass of boreal forests in the 21st century aboveground biomass increased considerably in the 21st century at the landscape scale recovering from historical timber harvesting and fire disturbances fig 6 a and fig s9 although climate change and fire significantly increased tree mortality rate of boreal forests fig s10 aboveground biomass increased by 143 51 t ha in the 21st century aboveground biomass under the vegetation feedback scenarios was 0 4 14 1 higher than that in the scenarios without vegetation feedback the differences in aboveground biomass between without vegetation feedback and with vegetation feedback scenarios increase with simulation time the differences in aboveground biomass between these two scenarios have increased by 351 147 at the end of 21st century the differences in aboveground biomass among rcp2 6 rcp4 5 and rcp8 5 scenarios were varied at the three time periods fig 6b in the short term the difference in aboveground biomass difference between the three rcp scenarios was not significant p 0 05 whereas there was a significant difference in the biomass among the three rcp scenarios in the long term p 0 05 in the medium term the aboveground biomass variation among three rcp scenarios is slight when vegetation feedback is considered but there was a significant difference in aboveground biomass between three rcp scenarios without vegetation feedback 3 3 shifts in the spatial distribution of species composition over the 21st century there was a divergent response of tree species to climate fire vegetation interactions fig 7 and fig 8 populus davidiana benefited substantially from climate change and fire disturbances in the 21st century compared to the initial distribution the proportions of populus davidiana would increase by 832 and 1157 under the without and with vegetation feedback scenarios in 2100 populus davidiana would colonize in the northeastern of the study area climate change and fire would alter the spatial distribution of betula platyphylla from 2000 to 2100 the proportion of betula platyphylla declined by 74 91 in 2080 2100 fig 7 betula platyphylla would become extinct in most of the study area over the 21st century and only colonize the northeast and west of the study area fig 8 although climate change and fire would reduce the proportion of larix gmelinii it was still the dominant species in this region at the end of 21st century the distribution of larix gmelinii remained unchanged in most of the study area fig 8 climate change and fire are beneficial to expansion of pinus sylvestris the proportions of pinus sylvestris would increase by 16 271 during the 21st century and it would predominantly colonize the northeastern of the study area 4 discussions this study applied a new model coupling framework that combines forest succession climate fire linkages and vegetation feedback to simulate the responses of boreal forests to climate fire vegetation interactions in northeast china our results suggested that climate change and fire would favor the recruitment of deciduous species but these species would take a long time to replace the existing coniferous species changes in species composition would partly offset the effects of climate change on burned area over the 21st century the effects of vegetation feedback on burned areas mainly depend on the velocity of coniferous species be replaced by deciduous species climate change historical and future fire disturbances could affect aboveground biomass by altering the mortality and regeneration of trees this study provides new insight into the role of climate fire vegetation interactions in regulating future forest dynamics and fire disturbances climate change and fire can strongly modify environmental conditions and the recruitment of tree seedlings thereby altering species composition and successional trajectories of boreal forests this study suggests that climate change and increases in burned area would favor deciduous species at the expense of coniferous species this is because deciduous species i e populus davidiana can better adapt to climate change and fire through asexual sprouting from roots or stumps and long distance seed dispersal rehfeldt et al 2009 landhäusser et al 2019 in our model simulation the populus davidiana seed dispersal distance was parameterized at 2400 m huang et al 2018 climate change and fire kill the existing species larix gmelinii and betula platyphylla and new coniferous species seedlings have difficulties reestablishing under warmer and drier conditions this creates opportunities for populus davidiana to move north and occupy the newly released growing space however larix gmelinii would still be the dominant species in our study area over the 21st century these findings are not entirely consistent with the first hypothesis and findings of previous studies which suggested that the rate of vegetation change could increase with higher frequency and intensity of fire girardin and terrier 2015 stralberg et al 2018 as a tree species with a small distribution under the current climate conditions even though populus davidiana can better adapt to climate warming and fire it still takes a long time to occupy the growth space of existing coniferous species moreover larix gmelinii may be more resilient to climate change and fire because it has more broad scale regeneration prospects and is long lived with a relatively higher tolerance for environmental conditions bertrand et al 2011 halofsky et al 2018 therefore the inertia of forest ecosystem may cause little change in species composition of boreal forests in northeast china over the 21st century this study hypothesized that vegetation changes would limit the increases in burned area caused by climate change however our simulation results suggested that climate change would significantly increase the burned area of boreal forests over the 21st century despite the changes in forest composition can partially offset the effects of climate change on burned area from the beginning to middle of 21st century temperature in the study area increased rapidly and the changes in precipitation were relatively small leading to a rapid increase in the burned area during this period after the 2050s temperature fluctuation and increases in precipitation leading to a smaller increase in burned area at the end of 21st century this implies that climate change has a stronger influence than vegetation feedback on the burned area of boreal forests in the 21st century our results are consistent with those reported in previous studies based on climate fire linkages models flannigan et al 2005 liu et al 2012 but inconsistent with fire predictions from dgvms knorr et al 2016 scholze et al 2006 and our second hypothesis the discrepancy in burned area between this study and some dgvms was likely due to the transition rate of species composition of boreal forests in most dgvms vegetation changes mainly depend on bioclimatic limits and resource competition with each pft and do not consider demographic processes and the response of individual species to climate change and fire snell 2013 compared to dgvms forest landscape models include species level demographic processes i e seed dispersal species establishment growth mortality and resprouting they keep track of tree age and size when simulating the dynamics of forest succession liang et al 2017 therefore forest landscape models can capture the fact that adult trees can tolerate warmer climates forests have inertia that causes them to change gradually over time under all but extreme disturbances the forest landscape model landis ii integrates vegetation feedback into fire predictions liang et al 2017 scheller et al 2019 the findings from landis ii and this study suggested that future studies should incorporate vegetation feedback and vegetation responses to climate change into fire predictions for realistically assessing the effects of climate change and fire on forests given the prediction that climate change and increasing fires significantly affect tree mortality and regeneration we hypothesized that the decrease in burned area would lead to higher aboveground biomass of boreal forests our results demonstrated that the long term fire disturbances and intense timber harvesting caused a legacy effect and that tree growth would continue for a century or longer this may reduce the effects of climate change and fire on aboveground biomass of boreal forests our results are not entirely consistent with the third hypothesis this is because the stand age of boreal forests in northeast china is affected primarily by historical fire and harvest the initial stand age in our study area is 40 60 years li et al 2013 extensive tree growth and forest recovery could continue to promote the accumulation of aboveground biomass in boreal forests of northeast china aboveground biomass increased considerably in the 21st century suggesting that the historic fire and timber harvesting may have a greater effect on aboveground biomass than the effects of climate change rhemtulla et al 2009 loudermilk et al 2013 besides the growth rate of deciduous species is faster than coniferous species and thus have potential to accumulate more aboveground biomass moreover climate change and fire not only cause carbon losses from fire emissions and tree mortality kurz et al 2008 but also alter vegetation recovery after fire due to seed dispersal limitations and low water availability johnstone et al 2011 whitman et al 2019 therefore this study highlights climate change forest succession and past and future disturbances have combined effects on the carbon sequestration of boreal forests we included estimates of dead and live fuel which reflected the effects of fire suppression in this study fires simulated in our model coupling framework involved many high severity crown fires and reflected the reports from previous studies chang et al 2008 fang et al 2015 although fire suppression policies can increase aboveground biomass by altering stand density and reducing the frequency of fire disturbances long term fire suppression might result in a build up of fuel loads which would increase the probability of catastrophic fires chang et al 2007 deciduous species are less flammable than coniferous species and thus have the potential to reduce fire occurrence density and burned area of boreal forests lynch et al 2004 terrier et al 2013 our results showed that vegetation feedback is expected to offset partial effects of climate change on the burned area of boreal forests the effects of vegetation feedback on burned areas mainly depend on replacing coniferous species with deciduous species hence planting appropriately deciduous species may be an option for reducing burned area and promoting boreal forests to adapt to climate change our simulated results are limited by three factors 1 in our model coupling framework changes in forest composition were only represented by the presence and absence of eight existing tree species the invasive species and understory vegetation were excluded in this study previous studies showed that climate change favors temperate species and alters understory plant communities of boreal forests bellard et al 2013 hedwall et al 2019 this may accelerate the velocity of vegetation change and thus amplify the effects of vegetation feedback on fire regimes by altering fuel characteristics and loads 2 fire is strongly associated with human activities such as population distance to settlements and roads land use and cover change guo et al 2014 previous studies revealed that climate warming would increase human activities in the boreal forests of northeast china which alter fire regimes of boreal forests by modifying fire ignition patterns and occurrence probabilities liu et al 2015 in contrast some studies projected that population density would decline in this region due to environmental protection policies hu and zhou 2014 thus we assumed that human activities would remain constant in the 21st century which may lead to high uncertainties in our simulated results 3 this study did not consider the effects of climate change and fire on permafrost degradation prior studies reported that climate change and increased fire disturbances would accelerate permafrost degradation in this region jin et al 2007 thereby affecting the spatial distribution of tree species and fire regimes tchebakova et al 2009 future studies should consider these factors to accurately predict the response of boreal forests to climate change fire and their interactions 5 conclusions vegetation lags behind climate change which leads to little change in species composition of boreal forests in northeast china over the 21st century burned area would significantly increase with climate change in this period climate change past and future fire disturbances have multifaceted consequences on the aboveground biomass of boreal forests our results highlight the importance of accounting for vegetation feedback in fire prediction and suggest that fire disturbance will catalyze the responses of boreal forests to climate change our results also showed that vegetation change is expected to offset partial effects of climate change on burned area of boreal forests vegetation feedback would significantly reduce burned area of boreal forests when the changes in species composition significantly modifies landscape flammability therefore it is necessary to implement forest management strategies such as planting appropriate deciduous species to reduce the burned area and carbon losses from catastrophic fires further studies should address how to alter species composition through forest management practices to adapt to climate change and reduce the frequency and size of fire disturbances software availability name of software spatstat developer prof adrian baddeley adrian baddeley curtin edu au program language r download http spatstat org download html name of software linkages 3 0 developer dr william d dijak wdijak fs fed us download https drive google com file d 1zt 6tw0fizcdjn4nbvfplv6v2k lrfgy view usp sharing program language fortran and c name of software landis pro developer prof hong s he heh missouri edu program language c and c download https github com landispro landis pro 7 1 credit authorship contribution statement chao huang conceptualization methodology software validation data curation formal analysis writing review editing jiayuan feng conceptualization data curation formal analysis writing review editing fangran tang conceptualization data curation formal analysis writing review editing hong s he conceptualization methodology software validation writing review editing yu liang conceptualization methodology software validation writing review editing mia m wu conceptualization software validation wenru xu conceptualization software validation bo liu data curation formal analysis writing review editing fuxi shi data curation formal analysis fusheng chen conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by the national natural science foundation of china 31800408 31961133027 31971486 and 42067049 the national key r d program of china 2018yfe0207800 and 2017yfa0604403 and the double thousand plan of jiangxi province jxsq2020101080 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105410 
25583,flow like landslides are a common type of natural hazards that may impose a great risk to people and their properties different models have been reported for simulating flow like landslides all of which possess limitations due to the underlying assumptions and simplifications harnessing the advantages of two types of prevailing modelling approaches a new coupled model is developed which adopts a discrete element method dem model to simulate the complex collapsing process in the source area and a depth averaged model dam to predict the predominantly convective movement in the runout and deposition zones the coupled model is finally implemented on the nvidia cuda programming platform to achieve gpu high performance computing two laboratory tests are considered to validate the model and a field scale landslide event is simulated to verify its applicability in real world conditions satisfactory results confirm that the coupled model is able to reproduce the dynamic process of real world flow like landslides keywords flow like landslide granular flow discrete element method depth averaged model coupled model gpu 1 introduction natural hazards such as flow like landslides may cause substantial damage to properties and even threaten human lives in many areas across the world hürlimann et al 2006 shan and zhao 2014 teufelsbauer et al 2011 ye et al 2011 for example on june 24 2017 a large landslide suddenly occurred and struck the xinmo village in sichuan province china creating a large amount of rapidly moving landslide material that destroyed 103 houses and caused 10 deaths 3 injuries and 73 people missing yan et al 2020 to mitigate the impact of these hazardous flow like landslides it is necessary to develop and apply robust numerical modelling tools to support the development of effective risk management schemes the area impacted by a landslide may be divided into a source zone runout path and deposition zone wang et al 2021 based on the principles of solid or fluid mechanics numerous efforts have been devoted to the development of numerical methods to simulate the complex landslide dynamics in these three impact zones continuum approaches such as finite element method fem have been developed to analyse landslide initiation by solving the governing equations derived from mass and momentum conservation griffiths and lane 1999 fem provides an effective approach to predict the incipient slope failure in the source area including the location of sliding surface initiation time and velocity cuomo et al 2021 gian et al 2016 liu et al 2018 fem models commonly adopt computational meshes that are conformed to the sliding material such computational meshes may become severely distorted due to large deformations leading to inaccurate or even unconverged numerical solutions bui et al 2008 conte et al 2019 zhang et al 2015 furthermore a fem model cannot provide microcosmic description of the granular behaviour of geomaterial which is usually discontinuous and involves element separation and rearrangement which is often important for analysing the initiation and evolution of landslides different from a continuum method the discrete element method dem treats the geomaterial as a set of particles that move and interact with each other according to the newton s laws of motion providing an alternative approach to simulate the landslide dynamics in the source area li et al 2012 staron 2008 dem models can simulate the micromechanical behaviour between particles and provide a grain level description of the geomaterial by directly considering the microstructural response of the material without introducing sophisticated constitutive models due to their flexibility in capturing large deformation dem models can effectively avoid the geometric issues related to solid fluid transition in granular flow modelling zhang et al 2015 and have been applied to simulate the whole process dynamics of a granular avalanche mead and cleary 2015 recently attempts have been made to accelerate dem models through implementation on graphic processing units gpus to achieve high performance computing making these computationally expensive models more suitable for large scale simulations involving a large number of particles xu et al 2019 zhou et al 2021 when modelling landslide dynamics in the runout path and deposition zone both lagrangian based methods and grid based depth averaged models have been widely used typical lagrangian methods include smooth particle hydrodynamics sph gingold and monaghan 1977 rickenmann 1999 material point method mpm sulsky et al 1994 and particle finite element method pfem onate et al 2004 these lagrangian computational techniques represent the physical behaviour of a geophysical granular flow using a collection of particles that move according to the forcing system of each particles and its neighbours cremonesi et al 2020 and are capable of directly tracking free surface evolution and handling large deformation research effort has been reported to improve the performance of these computationally expensive lagrangian based models by taking advantages of central processing unit cpu and gpu based high performance computing technologies e g sph peng et al 2019 yang et al 2021 mpm dong et al 2015 dong and grabe 2018 feng and xu 2021 and pfem zhang et al 2021 making it possible for these particle based methods to simulate large scale events involving millions to tens of millions of particles zhu et al 2015 whilst lagrangian models have been widely reported to simulate geophysical granular flows andersen and andersen 2010 cremonesi et al 2017 pinyol et al 2018 haddad et al 2010 mcdougall and hungr 2004 zhang et al 2015 they are still restricted by certain inherent numerical issues for example sph models may suffer from the inherent numerical instability associated with point wise integration bonet and kulasegaram 2000 inconsistencies potentially caused by insufficient neighbouring particles and complex boundary treatment soga et al 2018 mpm may produce numerical solutions with spurious noises when the material elements move through computational cell boundaries xu et al 2019 pfem s general applicability is also restricted by numerical issues including the so called volumetric locking due to the use of low order elements and numerical errors created by frequent remeshing yuan et al 2019 landslides often display liquid and solid lubricant behaviour in the runout area where the sliding movement is commonly predominated by convective flow dynamics with negligible change of velocity along the flow depth the governing equations may be then integrated vertically to derive the depth averaged mathematical model in which the mechanical behaviour between the landslide material and the slip surface can be packed into a relatively simple friction law mangeney et al 2000 leading to a much simplified formulation the resulting depth averaged models dams are computationally much more efficient than the full three dimensional models one of the earliest dams was reported by savage and hutter 1989 incorporated with the mohr coulomb internal rheology law and constant coulomb bed friction since then dams have been further improved and widely applied to simulate granular flows and real world landslides cannon 1993 pudasaini and hutter 2003 vagnon et al 2019 xia and liang 2018 however dams cannot provide reliable prediction of the landslide dynamics in the source area zhan et al 2019 where the dynamic behaviour of geomaterial is highly complex and the vertical momentum transfer may not be negligible domnik et al 2013 hutter et al 1995 pudasaini and hutter 2003 as a summary different modelling approaches all have their pros and cons and it is desirable to exploit the advantages of different modelling approaches to develop a robust model for more reliable simulation of the whole process landslide dynamics across the source area runout path and deposition zone this work therefore aims to develop a new landslide modelling approach by coupling a three dimensional dem model with a computationally more efficient two dimensional dam in this new landslide modelling framework the computationally demanding dem model is only used to simulate the granular flow dynamics to provide grain level description of geomaterial in the landslide source area whilst the computationally more efficient dam is adopted to predict the predominant convective movements in the runout and deposit zones additionally high performance gpu computing is explored to further accelerate the coupled model for large scale field applications it should be noted that this work is focused on simulation of the flow dynamics of a landslide and the initiation mechanism is not considered in the proposed coupled model which will be considered in future research 2 the new gpu accelerated coupled dem dam model in this work a longitudinal coupling strategy is implemented to transfer the values of flow variables from the dem model to the dam to develop a coupled model for efficient landslide simulations schematically represented in fig 1 the longitudinal coupling approach has been widely adopted for modelling river lake and river estuary systems chen et al 2012 in which each of systems subdomains is distinctively simulated by models of different dimensionality and the numerical solutions are connected and exchanged at the joint subdomain boundaries mintgen and manhart 2018 2 1 discrete element method dem model dem was originally developed by cundall and strack 1979 and has been successfully applied to simulate a range of granular flow problems calvetti et al 2017 liu et al 2020 owen et al 2009 thakur et al 2014 zhou et al 2019 in a dem model the interaction between two particles is realised through a contact model that can be further divided into a normal contact model tangential contact model and rolling contact model as illustrated in fig 2 dem models are generally implemented through an explicit numerical scheme that requires a small time step the time step is typically less than a critical value expressed as a fraction of the natural frequency of an equivalent mass spring system malone and xu 2008 estimated using the following formula tsuji et al 1993 1 δ t c 2 π m k n where k n is normal stiffness and m is the mass of the particle under consideration a particle may be subject to forces and torques and subsequently undergo translational and rotational movements for an arbitrary particle i the governing equations for a translational and rotational particle movement are derived from the newton s second law and given respectively as follows thakur et al 2014 2 m i x f r f l d 3 i i θ m r m l d where x is the translational acceleration f r is the resultant force i e the combined forces acting on particle i f l d is the local damping force i i 0 4 m i r i 2 is the moment of inertia with r being the particle radius θ is the angular acceleration m r is the resultant moment m l d is the local damping moment in this work local damping cundall 1987 is introduced to efficiently obtain a particle system with a static equilibrium coetzee 2016 the expressions of local damping force f l d and local damping moment m l d are given as follows 4 f l d α f r s i g n x 5 m l d α m r s i g n θ where α is the local damping ratio f r and m r represent the magnitude of f r and m r s i g n x and s i g n θ define the directions of the translational velocity x and angular velocity θ respectively the resultant force f r and moment m r are given by 6 f r m i g j 1 k i f c i j f d i j 7 m r j 1 k i t i j m r i j where g is the gravitational acceleration f c i j and f d i j are the contact force and damping force between particles i and j with j being one of the k i in contact neighbouring particles t i j is the torque generated by the inter particle forces at the contact point of particles i and j causing particle i to rotate and m r i j is the inter particle rolling resistance torque t i j is calculated by 8 t i j r i f c t i j f d t i j in which r i is a distance vector from the mass centre of particle i to the contact point the inter particle forces f c i j and f d i j in eq 6 can be decomposed into the normal and tangential components i e f c n i j and f d n i j and f c t i j and f d t i j these normal and tangential force components are calculated using a linear contact force model that is widely used for modelling the contact between elastic particles the linear relationship between the normal contact force f c n i j and the normal displacement δ n is given by 9 f c n i j k n δ n where k n is the normal stiffness calculated by 10 k n 4 e c r 2 in which e c is the contact stiffness modulus which is a scaling constant correlated with the young s modulus of equivalent continuum material e and is strongly dependent on the severity of the contact connections between particles r r i r j 2 is the arithmetic mean radius of the two contacting particles i and j there are commonly two approaches to determine the tangential shear force f c t i j a history dependent models which require details about the previous contacts and b history independent models which only involve information of the current kinematic state govender et al 2014 a history dependent model records the contact history during a collision and is more difficult to implement for gpu computing without severe performance penalties due to the need of sorting substantial data on the gpu govender et al 2014 2015 a history independent model ignores the shear displacement throughout the lifetime of a contact and may slow but not stop or reverse the movement in the tangent direction a history independent model may be insufficient for applications that require truly static friction such as heap formation angles of repose and the quasi static stages of avalanches bell et al 2005 but it is considered to be sufficient for the simulation of the granular flow induced by a flow like landslide and therefore adopted in this work as it is computationally much more efficient and can be easily implemented for gpu computing bell et al 2005 longmore et al 2013 for implementation the formulation is simplified as tordesillas and walsh 2002 11 f c t i j k t v t δ t where k t is the tangential stiffness which is assumed to be the same as the normal stiffness k n v t is the relative tangential velocity between particles i and j δ t is the time step which should be smaller than the critical time step δ t c calculated in eq 1 the tangential force f c t i j is constrained by the coulomb friction as follows 12 f c t i j μ f c n i j f d n i j where μ is the sliding friction coefficient that may be further split into a particle particle friction coefficient μ p and a particle wall friction coefficient μ w for a real world granular flow the flow energy may be dissipated through inelastic collisions and converted into heat or sound waves such a dynamic system will eventually become stationary without external disturbing energy or driving force in the adopted dem model a contact damping force is included to account for the dissipation of system energy in eqs 6 8 malone and xu 2008 which may be calculated using a linear viscous damping model as follows 13 f d n i j c n ν n 14 f d t i j c t ν t where ν n and ν t are the relative normal and tangential velocities c n and c t are the corresponding normal and tangential damping coefficients it is a common practice to estimate the value of c n based on a coefficient of restitution e defined as the ratio of the relative velocities at the contact point before and after a collision wang and mason 1992 which may be calculated by the following formula ting et al 1989 15 c n 2 l n e m i k n l n e 2 π 2 the energy dissipation induced by a collision increases as e decreases with e 1 indicating zero energy dissipation and e 0 representing a critically damped system with no rebound it is normal to assume the tangential damping coefficient c t equal to c n the rolling resistance torque m r i j in eq 7 consists of two components i e a mechanical spring torque m r i j k and a viscous damping torque m r i j d ai et al 2011 16 m r i j m r i j k m r i j d the spring torque m r i j k can be numerically approximated through the following scheme 17 m r i j k k r δ θ r δ t where δ θ r is the relative angular velocity between two particles and k r k t r r 2 is the rolling stiffness with r r r i r j r i r j m r i j k is limited by 18 m r i j k μ r r r f c n i j f d n i j where μ r is the rolling friction coefficient the viscous damping torque m r i j d in eq 16 is related to a damping constant c r and the relative rolling angular velocity δ θ r between the two in contact particles i e 19 m r i j d c r δ θ r if m r i j k μ r r r f c n i j f d n i j 0 if m r i j k μ r r r f c n i j f d n i j in which c r is calculated using 20 c r η r c r c r i t where η r is the rolling viscous damping ratio and c r c r i t is the critical rolling viscous damping coefficient given by 21 c r c r i t 2 i r k r in which i r is the equivalent moment of inertia for the relative rotational vibration mode against the contact point 22 i r 1 1 i i m i r i 2 1 i j m j r j 2 where i i and i j are the moment of inertia of particles i and j with respect to their centroids 2 2 depth averaged model dam the depth averaged model dam presented by xia and liang 2018 is adopted in this work for modelling the landslide run out process the model is based on the following depth averaged equations written in a matrix form as 23 q t f q x g q y s b s f where x y defines the two dimensional cartesian system q is the vector containing the flow variables f and g are the vectors of numerical fluxes in the x and y directions respectively and s b and s f contain respectively the source terms accounting for the slope gravity and friction effects the vector terms are given by 24 q h u h v h f q u h u 2 h 1 φ 2 1 2 g h 2 u v h g q v h u v h v 2 h 1 φ 2 1 2 g h 2 h 25 s b 0 a h b x 1 2 g h 2 1 φ 2 x a h b y 1 2 g h 2 1 φ 2 y s f 0 μ w a h u φ u 2 v 2 u b x v b y 2 μ w a h v φ u 2 v 2 u b x v b y 2 26 with a g φ 2 and φ b x 2 b y 2 1 1 2 where h is the depth of the landslide material b is the bed elevation u and v are the depth averaged velocity components in the x and y directions respectively μ w is the friction coefficient between the geomaterial and the slip surface 1 φ 2 accounts for the effects of complex topography when a cartesian coordinate system is used xia and liang 2018 the adopted dam solves the above depth averaged governing equations using an explicit first order godunov type finite volume scheme and the details of the numerical methods can be found in xia and liang 2018 2 3 model coupling strategy a one way longitudinal coupling strategy is implemented to develop the coupled dem dam model as illustrated in fig 3 the model coupling scheme involves an overlapping area termed as interface area herein where the transfer of flow information from the dem model to dam occurs the width of the interface area is equal to a cell length of the dam computational grid which is normally set as at least two times of the particle diameter to ensure sufficient number of particles in the interface area the interface area literally occupies the first column of the uniform dam computational grid after particles move out of the interface area they are kept in dem solution process until moving beyond two more grid cells downstream after that they are marked as invalid particles and no longer involved in the dem calculation in implementation a particle is considered to move out of the interface area cell when its centre crosses the grid line the values of the depth averaged flow variables i e depth h and unit width discharges q x uh and q y vh are needed in the interface area to support the following dam computation which are calculated as follows 27 h t d a m h t d e m q x t d a m u x t d e m h t d e m q y t d a m u y t d e m h t d e m where h t d a m is the flow depth and q x t d a m and q y t d a m are unit width discharge components of the dam at time t these flow variables are estimated from the dem modelling outputs in the interface area 28 h t d e m h t δ t d e m δ m ρ d a m δ x δ y u x t d e m u t d e m cos θ u y t d e m u t d e m sin θ where ρ d a m ρ d e m 1 n p is material density used in the dam with ρ d e m being the density of particle material and n p being the porosity ratio of material adopted in the dam δ x and δ y are the lengths of a dam cell in the x and y direction respectively δ m m t m t δ t is the increment of mass in the interface cell during time step δt θ tan 1 u j y u j x is the direction of the overall horizontal velocity with u j x 1 n j 1 n u j x and u j y 1 n j 1 n u j y being the average velocities in the x and y directions u t d e m 1 n j 1 n u j x 2 u j y 2 is the average horizontal velocity of all dem particles in the interface cell under consideration with n being the number of particles and u j x and u j y being the velocities of particle j at x and y directions respectively the proposed coupling scheme effectively ensures strict mass conservation and also reinforces momentum conservation by deriving the depth averaged velocities for the dam by averaging the velocities of all of the dem particles inside the interface cell herein since the boundary flow variables h t d a m q x t d a m and q y t d a m are derived by taking into account the relevant quantities of all of the particles in an interface cell the influence of particle size on the deduced flow depth and velocities is lumped into the calculations and may be linked to the number of particles the mass of a single particle and the velocities of individual particles which may need to be analysed case by case 2 4 gpu implementation all computational components of the coupled dem dam modelling framework are implemented on gpus to achieve high performance computing 2 4 1 contact detection in the dem model detecting the neighbouring particles in contact with the targeted particle is the most time demanding procedure of a dem model and extensive studies have been reported to optimize the neighbour searching process for more efficient dem simulations he et al 2018 mio et al 2007 shire et al 2020 a uniform grid searching approach as illustrated in fig 4 a is adopted in this work which is further implemented on gpu for much improved computational efficiency each of the particles and grid cells is provided with an index and the index of the cell in which the particle is located is identified according to the particle s position and stored in an array hash as shown in fig 4 b the particle index array is sorted according to the hash array using the fast radix sorting algorithm described in satish et al 2009 and an example is shown in fig 5 after this the first and last particles in each of the grid cells can be determined through a simple algorithm by comparing the hash values of any two contiguous particles if the two particles have the same hash value they belong to the same grid cell otherwise they are in different cells for example if particle a has a hash value n but particle a 1 has a hash value n 1 the two particles are located in two different cells i e particle a in cell n and particle a 1 in cell n 1 since all of the particles have already been sorted in a sequential manner according to hash values particle a is the last particle of cell n whilst particle a 1 is the first particle of cell n 1 xia and liang 2016 after the first and last particles of each grid cell are identified it is efficient to sweep all of the particles in each cell the uniform grid searching algorithm is implemented on a virtual search grid with cubic cells occupying the whole computational domain as illustrated in fig 6 for a targeted particle the neighbouring particles located in the current and its 26 neighbouring cells will be searched to identify all of the in contact particles two particles are defined as in contact when the distance between their centres is equal to or smaller than the sum of their radii 2 4 2 implementation of the coupled model the architecture of nvidia gpu as utilised in this work consists of streaming multiprocessors sms and each sm contains a number of streaming processors sps and a single instruction unit remacle et al 2012 enabling parallel computing the gpu implementation of the current coupled model is achieved through the platform of compute unified device architecture cuda c which is a cpu gpu hybrid programming framework proposed by nvidia in a cuda based heterogeneous parallel model the cpu serves as the host and mainly executes the logical process programs serial computing and data transaction whilst the gpu is the device executing all of the parallel processing tasks fig 7 illustrates the algorithm of the dem dam coupled model implemented on a gpu the model code is designed with a host programme and kernel functions the host programme runs on the cpu to launch the kernel functions written in cuda to run on the gpu device the cpu and gpu communicate with each other through the peripheral component interconnect pci express the whole computational programme of the coupled model may be divided into two parts i e dem and dam when a simulation task is launched the pre defined geomaterial properties and parameters are first read into the host memory through the host terminal programme and then the data are copied from the host cpu to the device gpu once the initialization is completed the dem and dam calculations are started and performed in parallel in each time step the dem calculation is carried out following the order of contact detection contact force calculation and particle motion update since the dem model typically requires much smaller time steps the dem calculation will iterate multiple times until reaching the dam time step for synchronization at the moment of synchronization the depth averaged flow depth and discharges will be estimated from the dem predictions at the interface cells to drive the dam calculation in the downstream runout and deposition zones these calculations will repeat until the entire simulation is complete it should be noted that the bandwidth between cpu and gpu determines the efficiency of memory transfer 3 results and discussion since the adopted dam has been intensively validated in xia and liang 2018 the focus of this section is to validate the newly developed dem modelling component and the coupled model against two experimental cases and one real world landslide event all of the simulations are run on an nvidia tesla p100 gpu 3 1 granular slumping over a horizontal surface in a rectangular channel the experimental investigation of granular slumping reported by lajeunesse et al 2005 is first considered to demonstrate the advantages of the coupled model and confirm its capability in simulating granular flows as shown in fig 8 the experiment was carried out in a 45 mm wide rectangular channel with two vertical glass walls the upstream part of the channel was fitted with a vertical gate to form a reservoir of granular mass the initial l i h i w heap of granular materials constrained in the reservoir was suddenly released to downstream by opening the vertical gate spreading in the horizontal channel until coming to the rest a number of previous studies cleary and frank 2006 girolami et al 2012 lacaze et al 2008 lube et al 2005 staron and hinch 2005 zenit 2005 used dem models to simulate unidirectional or symmetrical granular column spreading processes and lube et al 2005 commented that these granular flow processes are dynamically similar table 1 lists the values of the model parameters used in these studies the values of the parameters involved in the current simulations are specified according to the previous studies and listed in tables 1 and 2 to compare the results and demonstrate the performance of different modelling approaches the test case is simulated using the dem dam and coupled models the interface area of the coupled model is marked by the pink lines in fig 9 the normalised surface profiles of the granular flow predicted by the dam dem and coupled models are presented in fig 9 in comparison with the experimental measurements herein the travel distance and flow depth are non dimensionalised through x l i and h l i with x and h representing the instantaneous height and runout distance of granular flow the characteristic time is defined as τ c h i g from the experimental observations the flow dynamics may be characterised into two stages in the initial collapsing stage of the granular column the vertical movement of the granular materials in the source area is significant leading to the formation of a granular pile lasting for about τc the granular pile continues to spread until it comes to the rest at the second stage the flow is predominated by the localized dynamics in a layer below the free surface with its shape varying in time lajeunesse et al 2005 these observations highlight that the dam is not suitable for modelling the initial collapsing process of a granular column in the source area which is characterised with the non negligible vertical movements this explains the unsatisfactory results produced by the dam as shown in fig 9 in which a much faster material collapsing process in the source area is predicted subsequently leading to more rapid runout and extended deposit area in the downstream on the other hand both of the dem and coupled model results are consistent and compare reasonably well with the measurements fig 10 demonstrates the internal flow structures measured from the experiment and reproduced by the dem model both the experimental and predicted velocity fields define a well developed interface below which the grains remain static above this interface predominant vertical velocities are observed indicating the granular column falls in the vertical direction due to gravity this again confirms the non negligible vertical movement of the granular material in the source area and demonstrates that the dem model is able to accurately reproduce this complex flow dynamics moving further downstream the grain velocity is directed toward the horizontal direction and the granular flow becomes predominantly convective with negligible variation in the vertical direction this justifies the validity of the proposed coupled modelling strategy i e using a dem model to simulate the granular collapsing dynamics with significant vertical momentum transfer in the source area and adopting a dam to simulate the predominantly convective runout and depositing processes 3 2 granular flow over an irregular terrain through a narrow gate to demonstrate the computational capacity and efficiency of the coupled model for simulating granular flows over more realistic topographies the flume experiment reported by iverson et al 2004 is considered the experiment is performed in a 0 2m wide and 1m long flume as shown in fig 11 in the flume the sloping surface after the gate is made from formica which is also connected to a planar horizontal runout surface at the end a custom formed urethane insert is fitted on the steep slope to create an irregular terrain surface to generate complex granular flow dynamics the material properties and parameters for model set up are summarized in table 3 taking the recommended values from the experiment the interface area of the coupled model is marked as red lines in fig 12 fig 12 presents the simulation results produced by different models comparing with the experimental measurements from the measurements it can be seen that the granular material rapidly spreads out after passing the gate leading to lateral momentum exchange after moving down from the inclined and irregular terrain surface the sliding material starts to deposit on the horizontal surface from the numerical results presented in fig 12 the three models are shown to capture the flow dynamics at different accuracy the flow patterns reproduced by the dem model better match the experimental measurements at t 0 27s 0 48s and 1 11s comparing with the dam predictions this indicates that the dem model better capture the flow dynamics in the early stage however when the flow evolves into the deposition dominated stage after t 1 11s the dem model predicts a more spread out deposition area and longer runout distance furthermore the dem model predicts much smoothened and thinner piles of sands stranded behind the gate compared with the experimental observations and the dam predictions the inconsistent dem predictions may be caused by the adoption of a history independent model to quantify the tangential force between particles which can only slow down but not stop the movement in the tangential direction subsequently weakening the pile formation that requires truly static friction another reason may be due to the use of the perfectly spherical particles in the dem model which are subject to less resistance comparing with the real sand particles used in the experiment leading to smaller energy dissipation and longer travel distance to more quantitatively evaluate the performance of the three numerical models the absolute differences between the predicted flow depths and experimental measurements in the runout and deposition areas are presented in fig 13 also shown in the figure are root mean square errors rmses calculated against the experimental measurements at different output times out of the three models the coupled model predicts the flow depth travel distance and final deposition pattern that are closer to the experimental observations the better simulation accuracy of the coupled model is further confirmed by the slightly but consistently smaller values of rmse as indicated by the velocity field shown in fig 14 the superior simulation accuracy of the coupled model is gained by using the dem model to more realistically represent the granular collapsing dynamics in the initiation zone predominated by vertical momentum exchange and the dam that better simulates the downstream runout and deposition processes in terms of computational efficiency it takes the coupled model 19 85h to complete the simulation of this 8s experimental process but costs the dem model 48 82h therefore the coupled model is about 2 5 times more efficient than the dem model 3 3 real world case study the shuicheng landslide in guizhou china the shuicheng landslide is adopted herein to confirm the current coupled model s reliability in the simulation of real world landslides the catastrophic event occurred at the night of july 23 2019 at jichang town guizhou province china which was initiated at a high elevation and evolved into a rapid and long runout flow like landslide based on a comparative analysis of the pre landslide google satellite map and the post landslide unmanned aerial vehicle uav image as shown in fig 15 about 70 104 m3 of the sliding body became unstable at the high elevation resulting in an overall downward dislocation of 40 60 m gao et al 2020 the downstream village impacted by the landslide accommodated 77 registered residents from 22 households and another 8 migrant workers visiting relatives and friends when the event which happened among them 23 people were safe 11 were rescued and sent to hospitals for treatment of injuries 42 were found dead and 9 are still missing ma et al 2020 zhao et al 2020 the landslide area presents a u shape in the plane view and the landslide body is located on a large slope surface with an average angle of about 28 according to the local topographic conditions and the landslide deposit marks the landslide area could be divided into source area runout and deposit zones ma et al 2020 zhao et al 2021 as indicated in fig 15 from the main and lateral scarps of the source area the quaternary regolith mingled with the strong weathered basalt fragments is the main source material which is extremely loose and of low strength ma et al 2020 the runout zone was located in the middle part of the landslide impact area with a width of about 150 320 m and average slope of 25 the final deposition area was about 760 m long and 90 360 m wide located at about 1350 to 1230 m in elevation and had a 12 average slope angle ma et al 2020 the detailed digital elevation data sliding surface and sliding body as required to set up the coupled model to simulate the landslide event were introduced by zhao et al 2021 the resolution of the digital elevation data is 4 m and 1 017 896 particles are created to represent the landslide material in the source zone the model parameters are determined through trial and error and summarized in table 4 the event lasted for approximately 60 s as concluded from the seismic signal analysis performed by zhang et al 2020 fig 16 and fig 17 present the simulation results in terms of moving material depth and velocity maps to reveal the landslide dynamics the displaced sliding material has an overall trend of moving downwards with the middle and rear parts of the slide body pushing the front edge forwards to enter an acceleration stage whilst the flow velocity of the leading edge significantly increases with time the velocity of the trailing edge reduces at around t 20 s the sliding material hits the basaltic ridge and is divided into two branches to enter the two gullies at either side of the ridge at this moment the maximum velocity of 40 8 m s is predicted near to the entrance of both gullies the sliding mass in the right gully moves faster and reaches the deposition area earlier than that from the left at t 40 s the moving mass from the two gullies meets again and gradually deposits at the toe of the mountain after t 50 s the shape and thickness of the landslide deposition remain largely unchanged and only a small amount of sliding material continues to move along the gullies indicating that the overall movement of the landslide has already settled to quantitively assess the simulation results the statistical matrices including probability of detection pod and false alarm ratio far ming et al 2020 saleh et al 2017 schubert and sanders 2012 are calculated pod represents the ratio between the correctly predicted landslide impact cells hit cells and all observed impact cells in the deposition area the value of pod ranges from 0 to 1 with pod 1 representing a perfect match between the prediction and observation far is defined as the ratio between the cells that are not observed to be affected in reality but predicted to be impacted by the model false alarm cells and total predicted impact cells with the perfect score being 0 the pod and far scores are presented in table 5 in which pod returns a relatively high score while far is relatively low indicating that the impact area of the landslide predicted by the coupled model is generally consistent with the post event investigation this is further confirmed by the visual comparison between the predicted and observed distributions of geomaterial in the deposition area as shown in fig 18 most of the landslide material settles down and deposits at the main depression area at the bottom of the slope which is correctly reproduced by the model for a real world simulation like this there may not be sufficient high quality field data to inform the choices of all model parameters the trial and error approach is commonly used and it is necessary to perform parameter sensitivity analysis to confirm the reliability of the simulation results herein parameter sensitivity analysis tests are carried out for the key model parameters including contact stiffness modulus e c coefficient of restitution e rolling friction coefficient μ r interparticle friction coefficient μ p and basal friction coefficients μ w and μ in which the parameters are kept the same as in table 4 while a single parameter changes contact stiffness modulus e c fig 19 shows the effect of varying e c on the final deposition of the landslide in general the final deposition morphology predicted with different values of e c is consistent showing that e c has little impact on the overall landslide dynamics this was also concluded by kadau et al 2006 and girolami et al 2012 restitution coefficient e the coefficient of restitution e is the ratio of the final and initial relative speeds between two particles after they collide reflecting the recovery capability of the particles after collision and potentially affecting the energy dissipation during a granular collapse fig 20 compares the simulation results produced with different values of e indicating that it only has insignificant influence on the final landslide deposition morphology the reason may be because for a highly dynamic flow like landslide like this the relative velocities between particles are negligible when comparing with the global velocities of the sliding flow rolling friction coefficient μ r rolling friction resists the motion when an object rolls on a surface which is function of the radius of the rolling object the depth that the object sinks into the surface and the toughness of the surface fig 21 shows the final deposition morphology predicted with four different values of μ r from the results the final stacking forms are almost identical implying that the influence of μ r on the simulation results is insignificant this suggests that energy dissipation induced by the particle rolling friction is negligible when simulating a highly dynamic flow like landslide particle particle friction coefficient μ p particle particle friction also termed internal friction resists the movement between particles simulations with four different values of μ p i e 0 15 0 25 0 35 and 0 45 are run and the predicted final landslide deposition patterns are shown in fig 22 from the results it is apparent that the impact of μ p on the final deposit morphology is limited which again indicates the negligible influence of interparticle friction on the overall flow dynamics basal friction coefficients μ w and μ the basal friction is created by the interaction between the landslide material and slip surface and is considered as an important factor affecting the propagation and final runout distance of a flow like landslide lucas et al 2014 wang et al 2018 μ w and μ are respectively the basal friction coefficient in the dem and dam modelling components fig 23 and fig 24 compare the final deposition patterns predicted by the coupled model with different basal friction coefficients when the basal friction coefficient is small e g μ w 0 13 or μ 0 13 the landslide material is easier to be accelerated and moves faster to the downstream travelling for a longer distance due to the reduced energy dissipation as the basal friction coefficient increases e g μ w 0 43 or μ 0 43 the energy loss through friction effect is increased leading to a slower sliding speed and a shorter runout distance overall the basal friction coefficients seem to have a more visible influence on the simulation results and should be carefully calibrated to ensure reliable predictions 4 conclusions this work proposes a new coupled dem dam model for simulating the dynamic process of granular flows from collapsing to runout and deposition in which a dem model is utilised to provide the grain level prediction of the complex collapsing process in the source area and a dam is adopted to simulate the predominantly convective flow dynamics in the runout and deposition zones a longitudinal coupling strategy is implemented such that the flow depths and discharges extracted from the dem model predictions are used in the interface cells to drive the dam simulation in the downstream a dam reduces the spatial complexity of landslide simulation and thus the coupled modelling strategy may significantly increase computational efficiency to further improve its performance the coupled modelling framework is implemented on gpu using the nvidia cuda programming platform to achieve high performance computing the gpu accelerated coupled model is validated against two experimental granular flow tests and its performance in real world application is demonstrated by reproducing a field scale landslide event the first test case of granular slumping over a horizontal surface reveals the predominant vertical movement of the sliding material at the beginning of granular collapse in the source area which requires the use of a three dimensional dem model to provide accurate prediction after the initial granular collapsing stage the sliding material moves out of the source area to form a predominantly advective flow that can be reliably simulated using a depth average model this effectively justifies the necessity of developing a coupled model for more accurate and also more efficient simulations the coupled model is found to outperforms the dam and dem model in reproducing the experimental test case of granular flow over irregular topography this may be a direct result of using the dem model to more reliably capture the complex collapsing process in the source area which is beyond the capability of a dam derived based on the depth average assumption on the other hand adopting a dam to simulate the predominantly advective flow dynamics in the runout and deposition zones effectively avoids the numerical issues of the dem model in over estimating the overall flow dynamics and final deposition area induced by using perfectly spherical particles and a history independent tangential force model the coupled model is about 2 5 times computationally more efficient than the dem model for this test case finally the coupled model is applied to simulate the dynamic process of a real world flow like landslide happened in guizhou china i e the shuicheng landslide the simulation results in terms of impact area runout distance and final deposition morphology compare reasonably well with the post event survey demonstrating the predictive capacity of the coupled model and its applicability in real world conditions parameter sensitivity analysis has also been carried out for this real world test the contact stiffness modulus e c coefficient of restitution e rolling friction coefficient μ r and interparticle friction coefficient μ p are found to have limited influence on the simulation results provided their values are selected in a reasonable range as suggested in the existing literature however the basal friction coefficients μ w and μ may have non negligible effect on the landslide dynamics and should be carefully calibrated for reliable predictions whilst the proposed coupled model provides an accurate and efficient tool for simulation of flow like landslide dynamics including real world cases it still has two major limitations for wider applications that may need further development in the future firstly due to the adoption of the dam modelling component the coupled model can only be applied to reliably simulate the dynamic process of flow like granular flows but not falling sliding and topple type of mass movement another limitation is that the current coupled model is not able to simulate the initiation mechanism of slope instability declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was partly supported by the weact project ne s005919 1 funded by the uk natural environment research council nerc through the shear programme the authors are deeply grateful to richard m iverson at usgs for providing the experimental data for the test case considered in section 3 2 many thanks also go to associate professor weihua zhao from chengdu university of technology for the data support of the shuicheng landslide simulation in section 3 3 
25583,flow like landslides are a common type of natural hazards that may impose a great risk to people and their properties different models have been reported for simulating flow like landslides all of which possess limitations due to the underlying assumptions and simplifications harnessing the advantages of two types of prevailing modelling approaches a new coupled model is developed which adopts a discrete element method dem model to simulate the complex collapsing process in the source area and a depth averaged model dam to predict the predominantly convective movement in the runout and deposition zones the coupled model is finally implemented on the nvidia cuda programming platform to achieve gpu high performance computing two laboratory tests are considered to validate the model and a field scale landslide event is simulated to verify its applicability in real world conditions satisfactory results confirm that the coupled model is able to reproduce the dynamic process of real world flow like landslides keywords flow like landslide granular flow discrete element method depth averaged model coupled model gpu 1 introduction natural hazards such as flow like landslides may cause substantial damage to properties and even threaten human lives in many areas across the world hürlimann et al 2006 shan and zhao 2014 teufelsbauer et al 2011 ye et al 2011 for example on june 24 2017 a large landslide suddenly occurred and struck the xinmo village in sichuan province china creating a large amount of rapidly moving landslide material that destroyed 103 houses and caused 10 deaths 3 injuries and 73 people missing yan et al 2020 to mitigate the impact of these hazardous flow like landslides it is necessary to develop and apply robust numerical modelling tools to support the development of effective risk management schemes the area impacted by a landslide may be divided into a source zone runout path and deposition zone wang et al 2021 based on the principles of solid or fluid mechanics numerous efforts have been devoted to the development of numerical methods to simulate the complex landslide dynamics in these three impact zones continuum approaches such as finite element method fem have been developed to analyse landslide initiation by solving the governing equations derived from mass and momentum conservation griffiths and lane 1999 fem provides an effective approach to predict the incipient slope failure in the source area including the location of sliding surface initiation time and velocity cuomo et al 2021 gian et al 2016 liu et al 2018 fem models commonly adopt computational meshes that are conformed to the sliding material such computational meshes may become severely distorted due to large deformations leading to inaccurate or even unconverged numerical solutions bui et al 2008 conte et al 2019 zhang et al 2015 furthermore a fem model cannot provide microcosmic description of the granular behaviour of geomaterial which is usually discontinuous and involves element separation and rearrangement which is often important for analysing the initiation and evolution of landslides different from a continuum method the discrete element method dem treats the geomaterial as a set of particles that move and interact with each other according to the newton s laws of motion providing an alternative approach to simulate the landslide dynamics in the source area li et al 2012 staron 2008 dem models can simulate the micromechanical behaviour between particles and provide a grain level description of the geomaterial by directly considering the microstructural response of the material without introducing sophisticated constitutive models due to their flexibility in capturing large deformation dem models can effectively avoid the geometric issues related to solid fluid transition in granular flow modelling zhang et al 2015 and have been applied to simulate the whole process dynamics of a granular avalanche mead and cleary 2015 recently attempts have been made to accelerate dem models through implementation on graphic processing units gpus to achieve high performance computing making these computationally expensive models more suitable for large scale simulations involving a large number of particles xu et al 2019 zhou et al 2021 when modelling landslide dynamics in the runout path and deposition zone both lagrangian based methods and grid based depth averaged models have been widely used typical lagrangian methods include smooth particle hydrodynamics sph gingold and monaghan 1977 rickenmann 1999 material point method mpm sulsky et al 1994 and particle finite element method pfem onate et al 2004 these lagrangian computational techniques represent the physical behaviour of a geophysical granular flow using a collection of particles that move according to the forcing system of each particles and its neighbours cremonesi et al 2020 and are capable of directly tracking free surface evolution and handling large deformation research effort has been reported to improve the performance of these computationally expensive lagrangian based models by taking advantages of central processing unit cpu and gpu based high performance computing technologies e g sph peng et al 2019 yang et al 2021 mpm dong et al 2015 dong and grabe 2018 feng and xu 2021 and pfem zhang et al 2021 making it possible for these particle based methods to simulate large scale events involving millions to tens of millions of particles zhu et al 2015 whilst lagrangian models have been widely reported to simulate geophysical granular flows andersen and andersen 2010 cremonesi et al 2017 pinyol et al 2018 haddad et al 2010 mcdougall and hungr 2004 zhang et al 2015 they are still restricted by certain inherent numerical issues for example sph models may suffer from the inherent numerical instability associated with point wise integration bonet and kulasegaram 2000 inconsistencies potentially caused by insufficient neighbouring particles and complex boundary treatment soga et al 2018 mpm may produce numerical solutions with spurious noises when the material elements move through computational cell boundaries xu et al 2019 pfem s general applicability is also restricted by numerical issues including the so called volumetric locking due to the use of low order elements and numerical errors created by frequent remeshing yuan et al 2019 landslides often display liquid and solid lubricant behaviour in the runout area where the sliding movement is commonly predominated by convective flow dynamics with negligible change of velocity along the flow depth the governing equations may be then integrated vertically to derive the depth averaged mathematical model in which the mechanical behaviour between the landslide material and the slip surface can be packed into a relatively simple friction law mangeney et al 2000 leading to a much simplified formulation the resulting depth averaged models dams are computationally much more efficient than the full three dimensional models one of the earliest dams was reported by savage and hutter 1989 incorporated with the mohr coulomb internal rheology law and constant coulomb bed friction since then dams have been further improved and widely applied to simulate granular flows and real world landslides cannon 1993 pudasaini and hutter 2003 vagnon et al 2019 xia and liang 2018 however dams cannot provide reliable prediction of the landslide dynamics in the source area zhan et al 2019 where the dynamic behaviour of geomaterial is highly complex and the vertical momentum transfer may not be negligible domnik et al 2013 hutter et al 1995 pudasaini and hutter 2003 as a summary different modelling approaches all have their pros and cons and it is desirable to exploit the advantages of different modelling approaches to develop a robust model for more reliable simulation of the whole process landslide dynamics across the source area runout path and deposition zone this work therefore aims to develop a new landslide modelling approach by coupling a three dimensional dem model with a computationally more efficient two dimensional dam in this new landslide modelling framework the computationally demanding dem model is only used to simulate the granular flow dynamics to provide grain level description of geomaterial in the landslide source area whilst the computationally more efficient dam is adopted to predict the predominant convective movements in the runout and deposit zones additionally high performance gpu computing is explored to further accelerate the coupled model for large scale field applications it should be noted that this work is focused on simulation of the flow dynamics of a landslide and the initiation mechanism is not considered in the proposed coupled model which will be considered in future research 2 the new gpu accelerated coupled dem dam model in this work a longitudinal coupling strategy is implemented to transfer the values of flow variables from the dem model to the dam to develop a coupled model for efficient landslide simulations schematically represented in fig 1 the longitudinal coupling approach has been widely adopted for modelling river lake and river estuary systems chen et al 2012 in which each of systems subdomains is distinctively simulated by models of different dimensionality and the numerical solutions are connected and exchanged at the joint subdomain boundaries mintgen and manhart 2018 2 1 discrete element method dem model dem was originally developed by cundall and strack 1979 and has been successfully applied to simulate a range of granular flow problems calvetti et al 2017 liu et al 2020 owen et al 2009 thakur et al 2014 zhou et al 2019 in a dem model the interaction between two particles is realised through a contact model that can be further divided into a normal contact model tangential contact model and rolling contact model as illustrated in fig 2 dem models are generally implemented through an explicit numerical scheme that requires a small time step the time step is typically less than a critical value expressed as a fraction of the natural frequency of an equivalent mass spring system malone and xu 2008 estimated using the following formula tsuji et al 1993 1 δ t c 2 π m k n where k n is normal stiffness and m is the mass of the particle under consideration a particle may be subject to forces and torques and subsequently undergo translational and rotational movements for an arbitrary particle i the governing equations for a translational and rotational particle movement are derived from the newton s second law and given respectively as follows thakur et al 2014 2 m i x f r f l d 3 i i θ m r m l d where x is the translational acceleration f r is the resultant force i e the combined forces acting on particle i f l d is the local damping force i i 0 4 m i r i 2 is the moment of inertia with r being the particle radius θ is the angular acceleration m r is the resultant moment m l d is the local damping moment in this work local damping cundall 1987 is introduced to efficiently obtain a particle system with a static equilibrium coetzee 2016 the expressions of local damping force f l d and local damping moment m l d are given as follows 4 f l d α f r s i g n x 5 m l d α m r s i g n θ where α is the local damping ratio f r and m r represent the magnitude of f r and m r s i g n x and s i g n θ define the directions of the translational velocity x and angular velocity θ respectively the resultant force f r and moment m r are given by 6 f r m i g j 1 k i f c i j f d i j 7 m r j 1 k i t i j m r i j where g is the gravitational acceleration f c i j and f d i j are the contact force and damping force between particles i and j with j being one of the k i in contact neighbouring particles t i j is the torque generated by the inter particle forces at the contact point of particles i and j causing particle i to rotate and m r i j is the inter particle rolling resistance torque t i j is calculated by 8 t i j r i f c t i j f d t i j in which r i is a distance vector from the mass centre of particle i to the contact point the inter particle forces f c i j and f d i j in eq 6 can be decomposed into the normal and tangential components i e f c n i j and f d n i j and f c t i j and f d t i j these normal and tangential force components are calculated using a linear contact force model that is widely used for modelling the contact between elastic particles the linear relationship between the normal contact force f c n i j and the normal displacement δ n is given by 9 f c n i j k n δ n where k n is the normal stiffness calculated by 10 k n 4 e c r 2 in which e c is the contact stiffness modulus which is a scaling constant correlated with the young s modulus of equivalent continuum material e and is strongly dependent on the severity of the contact connections between particles r r i r j 2 is the arithmetic mean radius of the two contacting particles i and j there are commonly two approaches to determine the tangential shear force f c t i j a history dependent models which require details about the previous contacts and b history independent models which only involve information of the current kinematic state govender et al 2014 a history dependent model records the contact history during a collision and is more difficult to implement for gpu computing without severe performance penalties due to the need of sorting substantial data on the gpu govender et al 2014 2015 a history independent model ignores the shear displacement throughout the lifetime of a contact and may slow but not stop or reverse the movement in the tangent direction a history independent model may be insufficient for applications that require truly static friction such as heap formation angles of repose and the quasi static stages of avalanches bell et al 2005 but it is considered to be sufficient for the simulation of the granular flow induced by a flow like landslide and therefore adopted in this work as it is computationally much more efficient and can be easily implemented for gpu computing bell et al 2005 longmore et al 2013 for implementation the formulation is simplified as tordesillas and walsh 2002 11 f c t i j k t v t δ t where k t is the tangential stiffness which is assumed to be the same as the normal stiffness k n v t is the relative tangential velocity between particles i and j δ t is the time step which should be smaller than the critical time step δ t c calculated in eq 1 the tangential force f c t i j is constrained by the coulomb friction as follows 12 f c t i j μ f c n i j f d n i j where μ is the sliding friction coefficient that may be further split into a particle particle friction coefficient μ p and a particle wall friction coefficient μ w for a real world granular flow the flow energy may be dissipated through inelastic collisions and converted into heat or sound waves such a dynamic system will eventually become stationary without external disturbing energy or driving force in the adopted dem model a contact damping force is included to account for the dissipation of system energy in eqs 6 8 malone and xu 2008 which may be calculated using a linear viscous damping model as follows 13 f d n i j c n ν n 14 f d t i j c t ν t where ν n and ν t are the relative normal and tangential velocities c n and c t are the corresponding normal and tangential damping coefficients it is a common practice to estimate the value of c n based on a coefficient of restitution e defined as the ratio of the relative velocities at the contact point before and after a collision wang and mason 1992 which may be calculated by the following formula ting et al 1989 15 c n 2 l n e m i k n l n e 2 π 2 the energy dissipation induced by a collision increases as e decreases with e 1 indicating zero energy dissipation and e 0 representing a critically damped system with no rebound it is normal to assume the tangential damping coefficient c t equal to c n the rolling resistance torque m r i j in eq 7 consists of two components i e a mechanical spring torque m r i j k and a viscous damping torque m r i j d ai et al 2011 16 m r i j m r i j k m r i j d the spring torque m r i j k can be numerically approximated through the following scheme 17 m r i j k k r δ θ r δ t where δ θ r is the relative angular velocity between two particles and k r k t r r 2 is the rolling stiffness with r r r i r j r i r j m r i j k is limited by 18 m r i j k μ r r r f c n i j f d n i j where μ r is the rolling friction coefficient the viscous damping torque m r i j d in eq 16 is related to a damping constant c r and the relative rolling angular velocity δ θ r between the two in contact particles i e 19 m r i j d c r δ θ r if m r i j k μ r r r f c n i j f d n i j 0 if m r i j k μ r r r f c n i j f d n i j in which c r is calculated using 20 c r η r c r c r i t where η r is the rolling viscous damping ratio and c r c r i t is the critical rolling viscous damping coefficient given by 21 c r c r i t 2 i r k r in which i r is the equivalent moment of inertia for the relative rotational vibration mode against the contact point 22 i r 1 1 i i m i r i 2 1 i j m j r j 2 where i i and i j are the moment of inertia of particles i and j with respect to their centroids 2 2 depth averaged model dam the depth averaged model dam presented by xia and liang 2018 is adopted in this work for modelling the landslide run out process the model is based on the following depth averaged equations written in a matrix form as 23 q t f q x g q y s b s f where x y defines the two dimensional cartesian system q is the vector containing the flow variables f and g are the vectors of numerical fluxes in the x and y directions respectively and s b and s f contain respectively the source terms accounting for the slope gravity and friction effects the vector terms are given by 24 q h u h v h f q u h u 2 h 1 φ 2 1 2 g h 2 u v h g q v h u v h v 2 h 1 φ 2 1 2 g h 2 h 25 s b 0 a h b x 1 2 g h 2 1 φ 2 x a h b y 1 2 g h 2 1 φ 2 y s f 0 μ w a h u φ u 2 v 2 u b x v b y 2 μ w a h v φ u 2 v 2 u b x v b y 2 26 with a g φ 2 and φ b x 2 b y 2 1 1 2 where h is the depth of the landslide material b is the bed elevation u and v are the depth averaged velocity components in the x and y directions respectively μ w is the friction coefficient between the geomaterial and the slip surface 1 φ 2 accounts for the effects of complex topography when a cartesian coordinate system is used xia and liang 2018 the adopted dam solves the above depth averaged governing equations using an explicit first order godunov type finite volume scheme and the details of the numerical methods can be found in xia and liang 2018 2 3 model coupling strategy a one way longitudinal coupling strategy is implemented to develop the coupled dem dam model as illustrated in fig 3 the model coupling scheme involves an overlapping area termed as interface area herein where the transfer of flow information from the dem model to dam occurs the width of the interface area is equal to a cell length of the dam computational grid which is normally set as at least two times of the particle diameter to ensure sufficient number of particles in the interface area the interface area literally occupies the first column of the uniform dam computational grid after particles move out of the interface area they are kept in dem solution process until moving beyond two more grid cells downstream after that they are marked as invalid particles and no longer involved in the dem calculation in implementation a particle is considered to move out of the interface area cell when its centre crosses the grid line the values of the depth averaged flow variables i e depth h and unit width discharges q x uh and q y vh are needed in the interface area to support the following dam computation which are calculated as follows 27 h t d a m h t d e m q x t d a m u x t d e m h t d e m q y t d a m u y t d e m h t d e m where h t d a m is the flow depth and q x t d a m and q y t d a m are unit width discharge components of the dam at time t these flow variables are estimated from the dem modelling outputs in the interface area 28 h t d e m h t δ t d e m δ m ρ d a m δ x δ y u x t d e m u t d e m cos θ u y t d e m u t d e m sin θ where ρ d a m ρ d e m 1 n p is material density used in the dam with ρ d e m being the density of particle material and n p being the porosity ratio of material adopted in the dam δ x and δ y are the lengths of a dam cell in the x and y direction respectively δ m m t m t δ t is the increment of mass in the interface cell during time step δt θ tan 1 u j y u j x is the direction of the overall horizontal velocity with u j x 1 n j 1 n u j x and u j y 1 n j 1 n u j y being the average velocities in the x and y directions u t d e m 1 n j 1 n u j x 2 u j y 2 is the average horizontal velocity of all dem particles in the interface cell under consideration with n being the number of particles and u j x and u j y being the velocities of particle j at x and y directions respectively the proposed coupling scheme effectively ensures strict mass conservation and also reinforces momentum conservation by deriving the depth averaged velocities for the dam by averaging the velocities of all of the dem particles inside the interface cell herein since the boundary flow variables h t d a m q x t d a m and q y t d a m are derived by taking into account the relevant quantities of all of the particles in an interface cell the influence of particle size on the deduced flow depth and velocities is lumped into the calculations and may be linked to the number of particles the mass of a single particle and the velocities of individual particles which may need to be analysed case by case 2 4 gpu implementation all computational components of the coupled dem dam modelling framework are implemented on gpus to achieve high performance computing 2 4 1 contact detection in the dem model detecting the neighbouring particles in contact with the targeted particle is the most time demanding procedure of a dem model and extensive studies have been reported to optimize the neighbour searching process for more efficient dem simulations he et al 2018 mio et al 2007 shire et al 2020 a uniform grid searching approach as illustrated in fig 4 a is adopted in this work which is further implemented on gpu for much improved computational efficiency each of the particles and grid cells is provided with an index and the index of the cell in which the particle is located is identified according to the particle s position and stored in an array hash as shown in fig 4 b the particle index array is sorted according to the hash array using the fast radix sorting algorithm described in satish et al 2009 and an example is shown in fig 5 after this the first and last particles in each of the grid cells can be determined through a simple algorithm by comparing the hash values of any two contiguous particles if the two particles have the same hash value they belong to the same grid cell otherwise they are in different cells for example if particle a has a hash value n but particle a 1 has a hash value n 1 the two particles are located in two different cells i e particle a in cell n and particle a 1 in cell n 1 since all of the particles have already been sorted in a sequential manner according to hash values particle a is the last particle of cell n whilst particle a 1 is the first particle of cell n 1 xia and liang 2016 after the first and last particles of each grid cell are identified it is efficient to sweep all of the particles in each cell the uniform grid searching algorithm is implemented on a virtual search grid with cubic cells occupying the whole computational domain as illustrated in fig 6 for a targeted particle the neighbouring particles located in the current and its 26 neighbouring cells will be searched to identify all of the in contact particles two particles are defined as in contact when the distance between their centres is equal to or smaller than the sum of their radii 2 4 2 implementation of the coupled model the architecture of nvidia gpu as utilised in this work consists of streaming multiprocessors sms and each sm contains a number of streaming processors sps and a single instruction unit remacle et al 2012 enabling parallel computing the gpu implementation of the current coupled model is achieved through the platform of compute unified device architecture cuda c which is a cpu gpu hybrid programming framework proposed by nvidia in a cuda based heterogeneous parallel model the cpu serves as the host and mainly executes the logical process programs serial computing and data transaction whilst the gpu is the device executing all of the parallel processing tasks fig 7 illustrates the algorithm of the dem dam coupled model implemented on a gpu the model code is designed with a host programme and kernel functions the host programme runs on the cpu to launch the kernel functions written in cuda to run on the gpu device the cpu and gpu communicate with each other through the peripheral component interconnect pci express the whole computational programme of the coupled model may be divided into two parts i e dem and dam when a simulation task is launched the pre defined geomaterial properties and parameters are first read into the host memory through the host terminal programme and then the data are copied from the host cpu to the device gpu once the initialization is completed the dem and dam calculations are started and performed in parallel in each time step the dem calculation is carried out following the order of contact detection contact force calculation and particle motion update since the dem model typically requires much smaller time steps the dem calculation will iterate multiple times until reaching the dam time step for synchronization at the moment of synchronization the depth averaged flow depth and discharges will be estimated from the dem predictions at the interface cells to drive the dam calculation in the downstream runout and deposition zones these calculations will repeat until the entire simulation is complete it should be noted that the bandwidth between cpu and gpu determines the efficiency of memory transfer 3 results and discussion since the adopted dam has been intensively validated in xia and liang 2018 the focus of this section is to validate the newly developed dem modelling component and the coupled model against two experimental cases and one real world landslide event all of the simulations are run on an nvidia tesla p100 gpu 3 1 granular slumping over a horizontal surface in a rectangular channel the experimental investigation of granular slumping reported by lajeunesse et al 2005 is first considered to demonstrate the advantages of the coupled model and confirm its capability in simulating granular flows as shown in fig 8 the experiment was carried out in a 45 mm wide rectangular channel with two vertical glass walls the upstream part of the channel was fitted with a vertical gate to form a reservoir of granular mass the initial l i h i w heap of granular materials constrained in the reservoir was suddenly released to downstream by opening the vertical gate spreading in the horizontal channel until coming to the rest a number of previous studies cleary and frank 2006 girolami et al 2012 lacaze et al 2008 lube et al 2005 staron and hinch 2005 zenit 2005 used dem models to simulate unidirectional or symmetrical granular column spreading processes and lube et al 2005 commented that these granular flow processes are dynamically similar table 1 lists the values of the model parameters used in these studies the values of the parameters involved in the current simulations are specified according to the previous studies and listed in tables 1 and 2 to compare the results and demonstrate the performance of different modelling approaches the test case is simulated using the dem dam and coupled models the interface area of the coupled model is marked by the pink lines in fig 9 the normalised surface profiles of the granular flow predicted by the dam dem and coupled models are presented in fig 9 in comparison with the experimental measurements herein the travel distance and flow depth are non dimensionalised through x l i and h l i with x and h representing the instantaneous height and runout distance of granular flow the characteristic time is defined as τ c h i g from the experimental observations the flow dynamics may be characterised into two stages in the initial collapsing stage of the granular column the vertical movement of the granular materials in the source area is significant leading to the formation of a granular pile lasting for about τc the granular pile continues to spread until it comes to the rest at the second stage the flow is predominated by the localized dynamics in a layer below the free surface with its shape varying in time lajeunesse et al 2005 these observations highlight that the dam is not suitable for modelling the initial collapsing process of a granular column in the source area which is characterised with the non negligible vertical movements this explains the unsatisfactory results produced by the dam as shown in fig 9 in which a much faster material collapsing process in the source area is predicted subsequently leading to more rapid runout and extended deposit area in the downstream on the other hand both of the dem and coupled model results are consistent and compare reasonably well with the measurements fig 10 demonstrates the internal flow structures measured from the experiment and reproduced by the dem model both the experimental and predicted velocity fields define a well developed interface below which the grains remain static above this interface predominant vertical velocities are observed indicating the granular column falls in the vertical direction due to gravity this again confirms the non negligible vertical movement of the granular material in the source area and demonstrates that the dem model is able to accurately reproduce this complex flow dynamics moving further downstream the grain velocity is directed toward the horizontal direction and the granular flow becomes predominantly convective with negligible variation in the vertical direction this justifies the validity of the proposed coupled modelling strategy i e using a dem model to simulate the granular collapsing dynamics with significant vertical momentum transfer in the source area and adopting a dam to simulate the predominantly convective runout and depositing processes 3 2 granular flow over an irregular terrain through a narrow gate to demonstrate the computational capacity and efficiency of the coupled model for simulating granular flows over more realistic topographies the flume experiment reported by iverson et al 2004 is considered the experiment is performed in a 0 2m wide and 1m long flume as shown in fig 11 in the flume the sloping surface after the gate is made from formica which is also connected to a planar horizontal runout surface at the end a custom formed urethane insert is fitted on the steep slope to create an irregular terrain surface to generate complex granular flow dynamics the material properties and parameters for model set up are summarized in table 3 taking the recommended values from the experiment the interface area of the coupled model is marked as red lines in fig 12 fig 12 presents the simulation results produced by different models comparing with the experimental measurements from the measurements it can be seen that the granular material rapidly spreads out after passing the gate leading to lateral momentum exchange after moving down from the inclined and irregular terrain surface the sliding material starts to deposit on the horizontal surface from the numerical results presented in fig 12 the three models are shown to capture the flow dynamics at different accuracy the flow patterns reproduced by the dem model better match the experimental measurements at t 0 27s 0 48s and 1 11s comparing with the dam predictions this indicates that the dem model better capture the flow dynamics in the early stage however when the flow evolves into the deposition dominated stage after t 1 11s the dem model predicts a more spread out deposition area and longer runout distance furthermore the dem model predicts much smoothened and thinner piles of sands stranded behind the gate compared with the experimental observations and the dam predictions the inconsistent dem predictions may be caused by the adoption of a history independent model to quantify the tangential force between particles which can only slow down but not stop the movement in the tangential direction subsequently weakening the pile formation that requires truly static friction another reason may be due to the use of the perfectly spherical particles in the dem model which are subject to less resistance comparing with the real sand particles used in the experiment leading to smaller energy dissipation and longer travel distance to more quantitatively evaluate the performance of the three numerical models the absolute differences between the predicted flow depths and experimental measurements in the runout and deposition areas are presented in fig 13 also shown in the figure are root mean square errors rmses calculated against the experimental measurements at different output times out of the three models the coupled model predicts the flow depth travel distance and final deposition pattern that are closer to the experimental observations the better simulation accuracy of the coupled model is further confirmed by the slightly but consistently smaller values of rmse as indicated by the velocity field shown in fig 14 the superior simulation accuracy of the coupled model is gained by using the dem model to more realistically represent the granular collapsing dynamics in the initiation zone predominated by vertical momentum exchange and the dam that better simulates the downstream runout and deposition processes in terms of computational efficiency it takes the coupled model 19 85h to complete the simulation of this 8s experimental process but costs the dem model 48 82h therefore the coupled model is about 2 5 times more efficient than the dem model 3 3 real world case study the shuicheng landslide in guizhou china the shuicheng landslide is adopted herein to confirm the current coupled model s reliability in the simulation of real world landslides the catastrophic event occurred at the night of july 23 2019 at jichang town guizhou province china which was initiated at a high elevation and evolved into a rapid and long runout flow like landslide based on a comparative analysis of the pre landslide google satellite map and the post landslide unmanned aerial vehicle uav image as shown in fig 15 about 70 104 m3 of the sliding body became unstable at the high elevation resulting in an overall downward dislocation of 40 60 m gao et al 2020 the downstream village impacted by the landslide accommodated 77 registered residents from 22 households and another 8 migrant workers visiting relatives and friends when the event which happened among them 23 people were safe 11 were rescued and sent to hospitals for treatment of injuries 42 were found dead and 9 are still missing ma et al 2020 zhao et al 2020 the landslide area presents a u shape in the plane view and the landslide body is located on a large slope surface with an average angle of about 28 according to the local topographic conditions and the landslide deposit marks the landslide area could be divided into source area runout and deposit zones ma et al 2020 zhao et al 2021 as indicated in fig 15 from the main and lateral scarps of the source area the quaternary regolith mingled with the strong weathered basalt fragments is the main source material which is extremely loose and of low strength ma et al 2020 the runout zone was located in the middle part of the landslide impact area with a width of about 150 320 m and average slope of 25 the final deposition area was about 760 m long and 90 360 m wide located at about 1350 to 1230 m in elevation and had a 12 average slope angle ma et al 2020 the detailed digital elevation data sliding surface and sliding body as required to set up the coupled model to simulate the landslide event were introduced by zhao et al 2021 the resolution of the digital elevation data is 4 m and 1 017 896 particles are created to represent the landslide material in the source zone the model parameters are determined through trial and error and summarized in table 4 the event lasted for approximately 60 s as concluded from the seismic signal analysis performed by zhang et al 2020 fig 16 and fig 17 present the simulation results in terms of moving material depth and velocity maps to reveal the landslide dynamics the displaced sliding material has an overall trend of moving downwards with the middle and rear parts of the slide body pushing the front edge forwards to enter an acceleration stage whilst the flow velocity of the leading edge significantly increases with time the velocity of the trailing edge reduces at around t 20 s the sliding material hits the basaltic ridge and is divided into two branches to enter the two gullies at either side of the ridge at this moment the maximum velocity of 40 8 m s is predicted near to the entrance of both gullies the sliding mass in the right gully moves faster and reaches the deposition area earlier than that from the left at t 40 s the moving mass from the two gullies meets again and gradually deposits at the toe of the mountain after t 50 s the shape and thickness of the landslide deposition remain largely unchanged and only a small amount of sliding material continues to move along the gullies indicating that the overall movement of the landslide has already settled to quantitively assess the simulation results the statistical matrices including probability of detection pod and false alarm ratio far ming et al 2020 saleh et al 2017 schubert and sanders 2012 are calculated pod represents the ratio between the correctly predicted landslide impact cells hit cells and all observed impact cells in the deposition area the value of pod ranges from 0 to 1 with pod 1 representing a perfect match between the prediction and observation far is defined as the ratio between the cells that are not observed to be affected in reality but predicted to be impacted by the model false alarm cells and total predicted impact cells with the perfect score being 0 the pod and far scores are presented in table 5 in which pod returns a relatively high score while far is relatively low indicating that the impact area of the landslide predicted by the coupled model is generally consistent with the post event investigation this is further confirmed by the visual comparison between the predicted and observed distributions of geomaterial in the deposition area as shown in fig 18 most of the landslide material settles down and deposits at the main depression area at the bottom of the slope which is correctly reproduced by the model for a real world simulation like this there may not be sufficient high quality field data to inform the choices of all model parameters the trial and error approach is commonly used and it is necessary to perform parameter sensitivity analysis to confirm the reliability of the simulation results herein parameter sensitivity analysis tests are carried out for the key model parameters including contact stiffness modulus e c coefficient of restitution e rolling friction coefficient μ r interparticle friction coefficient μ p and basal friction coefficients μ w and μ in which the parameters are kept the same as in table 4 while a single parameter changes contact stiffness modulus e c fig 19 shows the effect of varying e c on the final deposition of the landslide in general the final deposition morphology predicted with different values of e c is consistent showing that e c has little impact on the overall landslide dynamics this was also concluded by kadau et al 2006 and girolami et al 2012 restitution coefficient e the coefficient of restitution e is the ratio of the final and initial relative speeds between two particles after they collide reflecting the recovery capability of the particles after collision and potentially affecting the energy dissipation during a granular collapse fig 20 compares the simulation results produced with different values of e indicating that it only has insignificant influence on the final landslide deposition morphology the reason may be because for a highly dynamic flow like landslide like this the relative velocities between particles are negligible when comparing with the global velocities of the sliding flow rolling friction coefficient μ r rolling friction resists the motion when an object rolls on a surface which is function of the radius of the rolling object the depth that the object sinks into the surface and the toughness of the surface fig 21 shows the final deposition morphology predicted with four different values of μ r from the results the final stacking forms are almost identical implying that the influence of μ r on the simulation results is insignificant this suggests that energy dissipation induced by the particle rolling friction is negligible when simulating a highly dynamic flow like landslide particle particle friction coefficient μ p particle particle friction also termed internal friction resists the movement between particles simulations with four different values of μ p i e 0 15 0 25 0 35 and 0 45 are run and the predicted final landslide deposition patterns are shown in fig 22 from the results it is apparent that the impact of μ p on the final deposit morphology is limited which again indicates the negligible influence of interparticle friction on the overall flow dynamics basal friction coefficients μ w and μ the basal friction is created by the interaction between the landslide material and slip surface and is considered as an important factor affecting the propagation and final runout distance of a flow like landslide lucas et al 2014 wang et al 2018 μ w and μ are respectively the basal friction coefficient in the dem and dam modelling components fig 23 and fig 24 compare the final deposition patterns predicted by the coupled model with different basal friction coefficients when the basal friction coefficient is small e g μ w 0 13 or μ 0 13 the landslide material is easier to be accelerated and moves faster to the downstream travelling for a longer distance due to the reduced energy dissipation as the basal friction coefficient increases e g μ w 0 43 or μ 0 43 the energy loss through friction effect is increased leading to a slower sliding speed and a shorter runout distance overall the basal friction coefficients seem to have a more visible influence on the simulation results and should be carefully calibrated to ensure reliable predictions 4 conclusions this work proposes a new coupled dem dam model for simulating the dynamic process of granular flows from collapsing to runout and deposition in which a dem model is utilised to provide the grain level prediction of the complex collapsing process in the source area and a dam is adopted to simulate the predominantly convective flow dynamics in the runout and deposition zones a longitudinal coupling strategy is implemented such that the flow depths and discharges extracted from the dem model predictions are used in the interface cells to drive the dam simulation in the downstream a dam reduces the spatial complexity of landslide simulation and thus the coupled modelling strategy may significantly increase computational efficiency to further improve its performance the coupled modelling framework is implemented on gpu using the nvidia cuda programming platform to achieve high performance computing the gpu accelerated coupled model is validated against two experimental granular flow tests and its performance in real world application is demonstrated by reproducing a field scale landslide event the first test case of granular slumping over a horizontal surface reveals the predominant vertical movement of the sliding material at the beginning of granular collapse in the source area which requires the use of a three dimensional dem model to provide accurate prediction after the initial granular collapsing stage the sliding material moves out of the source area to form a predominantly advective flow that can be reliably simulated using a depth average model this effectively justifies the necessity of developing a coupled model for more accurate and also more efficient simulations the coupled model is found to outperforms the dam and dem model in reproducing the experimental test case of granular flow over irregular topography this may be a direct result of using the dem model to more reliably capture the complex collapsing process in the source area which is beyond the capability of a dam derived based on the depth average assumption on the other hand adopting a dam to simulate the predominantly advective flow dynamics in the runout and deposition zones effectively avoids the numerical issues of the dem model in over estimating the overall flow dynamics and final deposition area induced by using perfectly spherical particles and a history independent tangential force model the coupled model is about 2 5 times computationally more efficient than the dem model for this test case finally the coupled model is applied to simulate the dynamic process of a real world flow like landslide happened in guizhou china i e the shuicheng landslide the simulation results in terms of impact area runout distance and final deposition morphology compare reasonably well with the post event survey demonstrating the predictive capacity of the coupled model and its applicability in real world conditions parameter sensitivity analysis has also been carried out for this real world test the contact stiffness modulus e c coefficient of restitution e rolling friction coefficient μ r and interparticle friction coefficient μ p are found to have limited influence on the simulation results provided their values are selected in a reasonable range as suggested in the existing literature however the basal friction coefficients μ w and μ may have non negligible effect on the landslide dynamics and should be carefully calibrated for reliable predictions whilst the proposed coupled model provides an accurate and efficient tool for simulation of flow like landslide dynamics including real world cases it still has two major limitations for wider applications that may need further development in the future firstly due to the adoption of the dam modelling component the coupled model can only be applied to reliably simulate the dynamic process of flow like granular flows but not falling sliding and topple type of mass movement another limitation is that the current coupled model is not able to simulate the initiation mechanism of slope instability declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was partly supported by the weact project ne s005919 1 funded by the uk natural environment research council nerc through the shear programme the authors are deeply grateful to richard m iverson at usgs for providing the experimental data for the test case considered in section 3 2 many thanks also go to associate professor weihua zhao from chengdu university of technology for the data support of the shuicheng landslide simulation in section 3 3 
25584,while modelling includes many detailed processes the model setup gets costly delineating distributed parameters requires advanced gis processing techniques and programming expertise limiting models usage to researchers and practitioners with sufficient resources although high resolution input data get increasingly available only a few preprocessing algorithms of integrated hydrological models can handle these in a reasonable time and for both subcatchment and raster model architectures here the collaborative open source python 3 6 topographic analysis tool tatoo library is presented integrating different models preprocessing into one processing environment and combining not model specific topographic preprocessing functions with model specific parameter calculation functions utilising high resolution dems and flow network shapefiles tatoo offers algorithms to delineate 1 raster or subcatchment based model networks 2 runoff generation concentration and routing parameters and 3 channel and foreland cross section geometries including bankfull water levels tatoo s capabilities and time requirements are demonstrated for the large area runoff simulation model s preprocessing keywords hydrology modelling preprocessing python cross section larsim ihm abbreviations larsim large area runoff simulation model ihm integrated hydrological model 1 introduction integrated hydrological models ihms are used worldwide to address water related research and engineering design questions such as surface and sub surface processes forecasting protection measures and resources management ihms require preprocessing of input data being time consuming and costly for large ihms with many different model elements i e discretised spatial units of the catchment therefore the widespread application and acceptance of complex and spatially distributed ihms in science and especially engineering design largely depend on the easy and cheap setup of the model e g fatichi et al 2016 consequently many tools have been recently developed to semi automatically preprocess spatial data for single few or seldomly even some hydrological and hydrodynamic models table 1 by way of contrast there is no preprocessing module for the ihm larsim large area runoff simulation model see ludwig and bremicker 2006 or www larsim de published yet although it is used widely as an official operational forecast model in several german austrian french and swiss states and cantons for more than 20 years scientists or public authorities which develop and advance many ihms have limited resources for a model or even more preprocessing tool development additionally such preprocessors have to keep up with the model development and hardware e g new reproduced processes or higher computational power and to consider progress in programming languages e g the recent upgrade of python from version 2 to 3 as well as potential connected software e g esri arcmap 10 and arcgis pro finally they shall include newly available datasets e g high resolution lidar elevation models to gain future acceptance overall the preprocessing of ihms is very arduous and time consuming gardner et al 2018 and such tasks can take a significant portion of the hydrological modeller s time and effort gichamo et al 2020 berry et al 2014 gichamo et al 2020 and viviroli et al 2007 showed that preprocessing tools reduce the time for model setup and execution considerably while krysanova et al 1998 highlight the improved transferability however with limited resources available models and tools are prone to be fastly outdated or slow and inefficient for new model applications chen et al 2020 there are many general similarities between ihms but the details of the specific ihm requirements inhibit the direct application of foreign tools as the value calculation is usually model independent but each ihm has particular conventions for the parameter for example the ihm larsim assumes that runoff generated within a model element enters the respective channel section of a traversed element at half its length while channel inflows from upstream model elements and runoff from headwater elements sum up at the beginning of each traversed element s channel section other models like mike she butts and graham 2005 or shetran ewen et al 2000 need flow networks located on the edges of cells sometimes there is even a multi functional use of parameters e g flow length in larsim represents the physical channel length serves as an identification value for model element connections and can suppress the channel routing using a key value leg 2021a such contradictions obstruct the development of a unique model independent preprocessing algorithm for the entire process and hamper the development of one which is applicable for at least some ihms nevertheless instead of creating and maintaining the whole workflow for every single model separately it would be much more efficient to have essential functions which apply for all or at least many models using similar spatial data e g based on leonard and duffy 2013 and delineate specific model parameters from their results different groups see chen et al 2020 and sources therein are working on open web distributed platforms sharing data e g geoss and fluidearth and gis tools or model resources e g cybergis opengms ewater integrate models e g esmf and csdms or to develop new web apps e g tethys in swain et al 2016 with summa clark et al 2015a 2015b 2015c its integration with hydroshare cuahsi jupyterhub cybergis jupyter and pysumma see choi et al 2021 and references therein as well as hydrods gichamo et al 2020 and the esmvaltool righi et al 2020 open web based frameworks are evolving for physically based models nevertheless to the author s knowledge a preprocessing framework is still missing for conceptual ihms this paper proposes tatoo the topographic analysis tool library it is a collaborative preprocessing toolbox built on the idea of an open web based depository containing 1 not model specific open source topographic preprocessing functions 2 model specific parameter calculation functions utilising outputs of topographic functions and 3 model specific workflows combining 1 and 2 for model application it offers the integration of different models preprocessing into a single processing environment and therefore aims to make this laborious task more efficient and transparent and face the reproducibility challenge e g hutton et al 2016 stagge et al 2019 tatoo contributes to tackling some methodological gaps in recently available environmental software first the packages transfer well known algorithms to an up to date programming language and software python 3 6 with arcgis pro 2 5 including functions to delineate semi distributed irregular or grid shaped model elements and networks their runoff generation concentration and routing parameters as well as channel and foreland cross section geometries second tatoo can deal with recent high resolution raster datasets such as digital elevation models dems with few metres resolutions e g 1 m and even shapefiles representing complex flow networks third tatoo provides structured and well explained functions for different ihms comparable to the design of volk and turner 2019 while proposing additional workflows to preprocess data and input files specifically for the ihm larsim finally compared to the tools in table 1 tatoo offers the following significant new techniques optimisation of subcatchments sizes during delineation respecting user settings integration of polyline flow networks into dem based flow length and slope calculations for overland and channel flow modules in both raster and subcatchment model architectures delineation of cross sections including automatic detection of the bankfull channel water level and solution of frequent topographical conflicts this article gives an overview of the tatoo library s technical attributes requirements and essential methods in section 2 whereby sections 2 3 to 2 5 focus on the new techniques examples and quantitative analysis of the resulting parameters the calculation times needed manual efforts and implications for the broader modelling community are in section 3 section 4 concludes and discusses the progress made with tatoo and outlines potential future works finally supplementary material is available e g an user manual and a test dataset 2 methods 2 1 design goals infrastructure and environment the tatoo library s design rests upon a few fundamental goals which are 1 little time is needed for model setup and therefore fast processing speed 2 applicability by as many users as possible 3 high flexibility to use functions independent of but also specific enough for the chosen ihm 4 support of fast and straightforward changes in the light of fast evolving programming language and software development model and gis and 5 algorithms are automatically applicable with little user interaction but still many operator interventions to control and construct the model for individual purposes based on beven 2012 i designed tatoo for ihms with a semi distributed model structure and parameters to define runoff generation using hydrological response units hru and runoff routing i e runoff concentration and channel routing semi distributed includes irregularly shaped i e vector and grid based i e raster architectures which are treated separately due to their differing technical fundamentals in geo information systems gis for simplicity in the following sections i refer to these as subcatchment and raster models following goodchild 1992 and sui and maggio 1999 there are different integration strategies for gis frameworks and models that range from loosely coupled exchange of files to fully integrated systems one software the design of tatoo connects open source python 3 functions and the closed source software arcgis pro of esri loosely to fulfil the described needs python offers various tools and packages oliphant 2007 and is an easy starting point for non experienced programmers due to its explicit language perkel 2015 the procedures use numpy walt et al 2011 pandas mckinney 2013 and other prevalent open source python packages and the closed source arcpy environment of esri arcgis pro version 2 5 admittedly this combination is somehow counterintuitive free and open source software for geospatial applications foss4g development has improved rapidly during the last decades akbari and rajabi 2013 brovelli et al 2017 steiniger and bocher 2009 while closed source software shows limitations especially concerning cloud and parallel computing reproducibility and adaptability muenchow et al 2019 sui 2014 tang and matyas 2018 however using arcpy is advantageous in accelerating the development especially during the early stages compared to often selective open source alternatives it covers nearly all areas of gis applications has well maintained documentation and the sophisticated gui arcgis pro which interacts with the package s functions and helps to display the results quickly e g gardner et al 2018 therefore the first version of tatoo utilises arcpy acknowledging the potential of replacing it with foss4g such as taudem geopandas saga gdal pyshp or ogr in future versions comparable to e g gardner et al 2018 and crystal ng et al 2018 modellers need some python programming skills to apply or extend tatoo functionalities they can run the tatoo functions using any familiar python environment such as spyder or jupyter i recommend using anaconda to manage the python packages interactions e g arcpy with numpy tatoo offers different output types to support the connectivity most major functions result in pandas dataframes which allow the user to process the data further within the chosen python environment additionally there are functions to export the results in geo information files for arcgis e g feature classes raster files and tables or even other gis software e g shapefiles or geotiffs finally it is possible to export the parameters to the required spatial model input files as shown for the model larsim 2 2 structure of the tatoo library three different packages form the tatoo library the first tatoo raster py contains all functions explicitly designed for raster model preprocessing and the second tatoo subcatch py provides functions for subcatchment model preprocessing functions from the third tatoo common py are general functions which raster or subcatchment packages call either as sub or as stand alone functions all together they are part of two scripts which outline exemplary workflows for raster and subcatchment model creation fig 1 shows the interdependencies of all packages and workflows although raster and subcatchment architectures of ihms exhibit fundamental differences in their parameter delineation methodology the following structure of four major sections can satisfy both 1 delineate the model domain and network 2 calculate the runoff concentration parameters 3 derive the cross section information representing channels and floodplains 4 calculate the parameters of runoff generation chapters 2 3 until 2 6 explain specifically the methods in depth while sections 3 1 until 3 4 contain appertaining examples and results fig 2 outlines workflows for both structures and holds an overview of existing functionalities and possible user interventions overall the raster package consists of 24 the subcatchment package 23 and the common package 24 sub functions documented in detail within the online depository see supplementary material section 2 3 model domain and network the first part of tatoo deals with the detailed reproduction of the actual flow network resulting in the calculation structure of the model elements this structure is usually the backbone of a model referenced by many other model files and the input for calculating the model network a digital polyline river network file describes the actual flow network referred to as flow network or fnw tatoo differentiates three types of model elements whose definitions the following sections refer to first there are headwater elements which do not have any inflow second there are so called traversed elements with one or more contributing headwater or traversed elements some ihms can programmatically sum up maximal two contributing elements at once at a confluence point so the model structure requires additional artificial connectors called dummy elements which are a technical trick without affecting the model outputs fig 3 may illustrate the concept for raster models the availability of high resolution airborne dem rasters z h allows automatic delineation procedures for the model s watershed area and flow structure of raster models these often rest upon the neighbour steepest gradient unidirectional d8 flow direction while there would be single stochastic e g ρ8 of fairfield and leymarie 1991 and multiple flow alternatives e g quinn et al 1991 costa cabral and burges 1994 tarboton 1997 seibert and mcglynn 2007 crystal ng et al 2018 discuss a variety of different d8 implementations while rieger 1998 erskine et al 2006 and wilson et al 2007 rated the multiple flow direction methods as superior however many ihms do not support multiple direction flow and arcgis pro does not support the stochastic single direction method precluding any d8 alternative in tatoo dependent on the grid resolution automated flow direction delineation remains prone to errors due to e g uncorrected measurement errors not resolved features and missing underground hydraulic connections e g lidberg et al 2017 the model catchment and network delineation is based on the final resolution of the ihm meaning that the used dem resolution is often far lower than the original data therefore and because of specific topographic and geological structures unsupervised extracted catchment areas and model networks are very uncertain condon and maxwell 2015 erdbrügger et al 2021 gardner et al 2018 hammond and han 2006 hinton et al 1993 woodrow et al 2016 especially artificial close by parallel branches built for e g drainage hydropower or mills are poorly separatable using the model resolution dem z l e g tarboton et al 1991 hammond and han 2006 lindsay 2016b and stream burning and depression filling and thus depression breaching leads to a significant increase in the alignment between model structure and flow features lidberg et al 2017 therefore the presented procedure follows a semi automated approach giving the modeller the possibility to engage in the delineation process of the model domain and network four functions describe this process in tatoo aggregation and correction of z h with preprocess dem delineation of the model domain usually a surface watershed using create pourpoint and calc watershed and setup of the model s network with calc model network at first preprocess dem aggregates z h to z l fitting the desired model resolution and burning streams by a user defined value subsequently the user may create pour point features at subcatchments outlets p out using create pourpoint to include subcatchments in the model domain or clip them using p out and z l the function calc watershed removes pits delineates the first draft of the model domain watershed based on d8 and creates a point feature class to manipulate it users may check the displayed catchment borders compare them to other sources like the catchment delineated with z h and correct encountered mismatches a rerun of the function calc watershed will automatically integrate the changes in the flow direction raster resulting in a corrected catchment boundary afterwards calc model network establishes the relations of the model flow structure consisting of element centre points connecting polylines and polygon features using create element polyg finally users can adapt the model network manually to reproduce diverting and even crossing structures using the same procedure as the watershed delineation the procedures for subcatchment models follow those or raster models create pourpoint except for using z h instead of z l lidberg et al 2017 by way of contrast the subcatchment delineation differs fundamentally from the raster package as the subcatchment structure is similar to the surface watershed borders beyond the functionalities of the tools in table 1 tatoo offers an optimisation function to achieve similar sizes of subcatchments the function optimize subc identifies the most suitable pour points for subcatchment optimisation based on the desired subcatchment size thereby there are two principles first the algorithm identifies pour points of major tributaries upstream to the confluence points using the flow accumulation differences resulting in similar points as the pfafstetter scheme see verdin and verdin 1999 second it decides the necessity of dissecting subcatchments into equal parts by adding pour points along the fnw in general the optimiser allows subcatchments with 50 150 of the desired subcatchment size but to prevent problems during the modelling e g for minimum channel segment length the user can define a minimum flow length threshold l min sustained during the optimisation users may move identified delete superfluous or create missing pour points in arcgis pro before further processing dummy elements are implemented only in cases where the subcatchment optimiser respects l min the subcatchments inlying centroids represent their coordinates 2 4 flow lengths elevations and slopes the second section of tatoo focuses on delineating spatially distributed parameters necessary for runoff routing usually table 1 the calculations rest upon grid based flow length and elevation values resulting in longitudinal gradients and referring to the energy transition from potential to kinetic while water flows downwards depending on the applied ihm spatial runoff concentration and channel routing are treated separately in different modules although both need flow length and gradient values the tatoo tools process these together and eventually split them into runoff and routing shares to ensure that both parts correspond a crucial part of determining parameters is determining the appropriate flow length using z l the resulting low resolution flow length raster l l straightens especially on meandering river courses it underestimates the actual flow length value significantly for many catchments see fig 4 wu et al 2008 who analysed dems with 10 m do not support these findings in a first view but studies from paz et al 2008 dehvari and heck 2013 rinderer et al 2014 woodrow et al 2016 and erdbrügger et al 2021 suggest that dems with 6 m resolution already smooth out the microtopography that strongly affects contributing areas stream lengths and the extraction of streams furthermore chang and tsai 1991 deng et al 2007 and wu et al 2008 showed that also the slope means standard deviations and accuracy decreased with lower dem resolution especially for steep areas tatoo functions shall implement detailed topographic information such as exact flow length into ihms therefore it utilises the high resolution rasters to determine flow length and slopes and allows the opportunity to integrate the fnw directly into the raster calculation for raster models prepr routing rasters depicts a high resolution flow length raster l h for all model elements containing a segment of the fnw to consider small scale flow path variations e g meanders automatically and it uses l l for all model elements without a piece while calculating and merging l h and l l conflicts may arise first the definition of flow length is crucial during the calculation of l l routines in arcgis define flow length as the length between raster neighbours centre to centre but ihms usually interpret flow length as the flow path within a model element that also means that f l from gis ignores parts of the flow length in headwater elements and at the outflow if the raster shape is equivalent to the model domain second the geometrical construction of a raster with straight and diagonal connections results in flow lengths between two cells of either d r or 2 d r with d r referring to the raster resolution therefore deviations r remain at confluences between contributing elements which increase with increasing d r consequently it is necessary to redistribute l l third a deficient reproduction of the fnw with raster elements during the calculation of l h results in significant allocation errors due to cut off line segments outside the flow accumulation based river course finally there are deviations where model elements with l h and l l adjoin each other therefore flow length is formalised as the following for the runoff concentration lengths l ro in traversed elements l ro t l r o t d r 1 2 4 holds throughout the catchment domain furthermore l ro of headwater elements l ro h and channel lengths delineated from l l l ch ras are l r o h c h r a s d r 2 d r r where r depends on the determination method of the downstream l ch while l ch ras have distinct values the channel lengths delineated from l h incorporating the fnw l ch fnw yield a smooth distribution example in fig 5 finally l l m i n l m i n prepr routing rasters contains the respective algorithms they estimate the missing share of l l in headwater elements redistribute l l compensate differences at model elements where l h and l l deviate and ensure the incorporation of all polyline segments in the l h calculation besides the user can assign l h or l l to single model elements manually using create fl ind point the subsequent function summar gisdata for roandrout merges l h and l l respecting users choice elevation differences or slopes are the second longitudinal information for runoff routing wherefore tatoo extracts the maximum z max and minimum z min elevation values for each model element in calc roandrout params from z h including monotonically decreasing streams similar to the flow length processing a redistribution of elevation residuals to the upstream raster elements solves conflicts at confluence points the user can define a minimum slope of the channel routing s min users also define the lowest runoff concentration elevation as z rc min z ch min z ch max with z ch min z ch max being the element s minimum maximum channel elevation default average as well as the highest runoff concentration elevation as z rc max z max z min with z min z max being the elements minimum maximum default elevation although the variations within a model element might be minor all factors together can significantly influence the runoff reaction time compared to the raster models the determination of runoff concentration and channel routing parameters for subcatchments is more intuitive wherefore all subfunctions are part of calc params the basis are the high resolution elevation raster z h and the consequential upstream flow length raster l h now imagine a traversed subcatchment with two upstream tributaries see fig 6 for the channel routing the channel flow length l ch is the average length of all flow paths from the inlets to the outlet also defining the channel elevation difference δ z c h keep in mind that the inlets might not be at the natural confluence point due to the definition of l min during subcatchment optimisation depending on the number and the distance between the inlets residual flow length values and elevation differences remain these are balanced upstream with the entering subcatchments attributes retaining the catchment wide flow length and elevation distribution for headwater elements the values remain empty the runoff concentration flow length for traversed elements l rc t is the distance between the subcatchment s maximum of l h and a user defined point along its channel flow path between the inlets confluence point and the outlet the maximum and minimum elevation z max and z min are the respective values of z h the ignored flow length and elevation residuals from the downstream subcatchment s channel routing calculation are beeing compensated with the upstream tributaries as for raster models l l m i n l m i n and s s m i n s m i n apply please refer to the documentation for further details 2 5 cross section geometries the last missing geometrical information is cross section data tatoo first contains methods to obtain cross sections using regression equations estimating downstream hydraulic geometry dhg e g gleason 2015 as most others in table 1 second it also can delineate cross sections directly from z h compare choi and mantilla 2015 while the first is the same for both model types the latter differs significantly for raster and subcatchment models dependent on the methodology the output tables contain either geometry attributes of a threefold trapezoidal profile ttp or all necessary variables for use in the well known gaukler manning strickler gms formula using the dhg method tatoo calculates a ttp see fig 7 within calc roandrout params estimating channel and floodplain parameters based on the dhg formula of allen et al 1994 or krauter 2005 there are others such as leopold and maddock 1953 ames et al 2009 and bieger et al 2016 from which many see gleason 2015 for a review rely solely on the channel forming discharge q ch which may be the 1 or 2 year return period flood values from a nearby gauge station allen et al 1994 the function extrapolates q ch linearly based on the catchment s flow accumulation i e the subcatchment area the user may set all other ttp geometry parameters for the foreland and valley see fig 7 as constants particular dhg formulas might not apply to catchments or will not result in realistic geometries as they rely on empirical data sets reflecting multiple variables such as climate land use slope soil type and geology they are therefore either a global average of the dataset or reflect very local conditions limiting their spatial transferability ames et al 2009 furthermore most channels in densely settled regions have undergone an extensive overprint through human activities e g constructions or agriculture making inadequate equations for unregulated and undiverted streams if the model application requires a realistic representation of the cross section geometries there is a need for fastly applicable delineation algorithms which can handle precise dem data and finally yet importantly allow extensive possibilities of user intervention the additional functionalities provided within tatoo include cross section delineation and channel fitting algorithms and they are applicable for any model requiring cross section data for raster models the delineation process consists of four steps 1 creation and manipulation of cross section lines along with the river network 2 handling of cross section conflicts 3 fitting of the bankfull channel parameters and 4 calculation of cross section parameter functions create csl creates planar lines perpendicular to the fnw applying a user defined horizontal spacing δl ch cs and a minimum inflow catchment area these lines determine the position of the cross sections assuming that the water flux is perpendicular at all points of the lines the valley s expected maximum water level heights should predefine the cross section length l cs each cross section centre point c cs is one of the potentially multiple intersection points with the fnw i fnw the fnw might meander in the valley or be interrupted by e g lakes dams culverts bridges and buildings the automatic placement of the cross section will consequently not be hydraulically suitable in every case and might intersect at confluences therefore the user can manually move turn create and delete cross sections in arcgis pro before parameter calculation instead of deleting them automatically e g choi and mantilla 2015 the c cs define the allocated model elements one per element and the cross section applies to any downstream model element until another cross section is defined that limits the number of profiles needed depending on the topography and the desired resolution as soon as the user is satisfied with the cross section locations and orientation the function df profdat from cs extracts the corresponding elevation data from z h while the methodology is very similar to choi and mantilla 2015 or wang and trauth 2020 until here tatoo includes three major corrections tackling challenges of mesoscale catchments fig 8 first if there are multiple i fnw the function excludes the cross section part beyond the watershed line between c cs and the next i fnw preventing double hydraulic usage second the algorithm deletes cross sections which monotonically decrease from both sides maximum elevations z cs max outwards if c cs is within a monotonically decreasing section the function adds an artificial channel with a user defined width and depth the last correction unifies z cs max of all profiles it clips parts exceeding the user defined vertical distance to z c cs called δz max and adds a vertical wall if z c c s δ z m a x z c s m a x holds routing modules of ihms may distinguish between the channel and the foreland to reproduce the different surface roughnesses and flow regimes during floods many models and their pre processors e g the hec ras mapper in hec 2020 still require their users to digitalise the river overbanks manually e g pramanik et al 2010 gichamo et al 2012 while tatoo tries to find them automatically it can be estimated from the cross section profiles if the accuracy of the used dem is high enough e g schumann et al 2008 and errors such as water surface reflections are corrected e g domeneghetti 2016 bures et al 2019 to reproduce the channel adequately overbanks expressed through the bankfull channel depth h bf ch can be identified by a sharp change in elevation choi and mantilla 2015 or the cross section gradient as the channel banks are steep compared to the relatively flat forelands tarboton and ames 2001 a histogram of elevation values can express the cross section gradient and the first histogram peak above the channel s lowest point may then determine w bf ch fig 9 if the algorithm cannot determine h bf ch this way it instead uses the selected dhg formula aside from user defined constant strickler roughnesses k st for channel and foreland the gms needs the width of water surface level w the traversed area a and the wetted perimeter u as functions of the water level h in the cross section the user can define the vertical evaluation heights with their maximum h max and the vertical spacing δh w h a h and u h are determined separately for the left and right cross section parts depression shares of a h belong to the water level of the high point between the depression and the channel i e they fill up when water overflows the dam in between by way of contrast the determination of cross section geometries for subcatchment models differs significantly from the raster package assuming that subcatchments are larger than elements of raster models and therefore represent a longer channel stretch it seems unreliable to describe the channel section with a single cross section consequently tatoo uses the average of equidistant cross sections within a subcatchment instead identical to the raster version the user may define the δl ch cs and l cs then the algorithm creates cross sections along the river course similar to pilotti 2016 and calculates their averaged geometry the raster correction methods apply in the next step except for the intersection point handling the resulting averaged and corrected cross section is then used in a three step optimisation approach to obtain ttp parameters 1 select h bf ch the same way as in the raster version 2 fit the channel trapezoid 3 optimize the foreland trapezoids individually for both sides of the channel all parameters are made available as pandas dataframe and arcgis pro polygon feature classes including joinable parameter tables 2 6 parameters for runoff generation there is still a considerable variability of methods to reproduce runoff generation e g single or multiple linear storages richard s equation green and ampt approach scs cn method see beven 2012 for more while each of them needs different parameter sets therefore data for vertical water movement processes is usually particular for every hydrological model consequently tatoo offers user defined complexity of the soil routine it is possible to work with the empirical linear storage approach of zhao 1977 a simplified green and ampt 1911 infiltration routine based on steinbrich et al 2016 capillary rise and impervious share the function calc hrus intersects the prepared model element structure land use data impervious percentage and soil polygons performing control mechanisms to prevent inconsistencies between them finally it can subsume hrus to grouped response units kouwen et al 1993 of so called distribution function models such as e g the slurp model kite 1995 or the dhms model vinogradov et al 2011 by way of contrast averaging would affect the simulation of the soil moisture kuo et al 1999 2 7 testing environment i tested tatoo by applying it to the large area runoff simulation model larsim which is an ihm of bremicker 1998 based on the rainfall runoff model fgmod ludwig 1982 recently german austrian swiss and french authorities and scientists are using the model for operational flood forecasts as well as for questions of flood protection bremicker et al 2011 haag et al 2005a water management gathenya 1999 haag et al 2006 and even river temperature modelling haag et al 2005b haag and luce 2008 a summary of applications is available in bremicker et al 2013 a strength of larsim is its flexibility modellers may run the model in a design oriented rainfall runoff approach with meteorological scenario creation or a comprehensive water balance scheme including a dynamic phenological model chmielewski et al 2008 meanwhile it is possible to combine nearly 100 physical and conceptual methods to reproduce hydrological processes a comprehensive summary of all functionalities of the model is available in ludwig and bremicker 2006 the technical documentation is published in leg 2021b and leg 2021a generally the model element architecture is of the following structure the smallest spatial entities of the model are hrus containing land use and soil information for vertical water flux calculations of four runoff components separated fast and slow direct runoff interflow and baseflow the hrus are non located within either irregular polygon or cell model elements the model calculates the runoff concentration time of all runoff components separately within each subcatchment using a calibratable approach based on kirpich 1940 consequently the runoff components form the sub catchment outflow contributing to a one dimensional channel section scheme tatoo includes all functions required to calculate the spatial parameters for raster and catchment based models which leg 2021b recommend every distributed ihm needs plenty of spatial data to reproduce a catchment correctly for the tatoo application with larsim i used five different data sets of bavarian or german public authorities table 2 from the 1 m dem from lidar i digitised the fnw utilising existing approximate and even deficient river network polylines fgn25 for orientation the tatoo library was initially developed based on three catchments in the southern german state bavaria simbach am inn 33 km2 340 570 m schöllkrippen 64 km2 200 530 m and stöckach 77 km2 330 530 m for these catchments i created different raster and subcatchment model resolutions ranging from 0 01 to 5 0 km2 using the two proposed workflows tatoo raster example py and tatoo subcatch xample py afterwards i set up raster models with a model element size of 0 01 km2 and subcatchment based models with a target element size of 1 0 km2 for 37 additional catchments to ensure tatoo s applicability and bug free functionality as well as to assess the performance of the tools regarding the remaining manual working time the catchments cover an ample variety of catchment attributes compare fig 10 and their size ranges from 1 2 to 160 km2 comparable to the usgs huc level 12 scale 3 results and discussion the following section shows the software results qualitatively with selected cases and quantitatively by analysing the results of all 40 catchments for subcatchment and raster architectures finally tatoo demonstrates its performance by applying timing analysis to all setups and a perspective for implementation in other existing environments is given 3 1 model domain and network for raster models i show the domain and flow structure calculation in the following at the example of groβschwindau a 21 km2 large catchment in upper bavaria using the aggregated 1 m dem z l and a single pour point at the catchment outlet the first calculation of the watershed exhibits significant deviations of the watershed boundary compared to the original 1 m dem z h with 72 correction points the overestimation of the catchment reduces from 2 0 to 0 47 fig 11 the range is within the same magnitude as the median of all catchments 2 7 to 0 9 but significantly lower than the mean 7 2 to 1 4 which points to seven predominantly smaller catchments with a deviation of more than 10 see fig 12 while it is aside from grid overlapping theoretically possible to achieve total congruency this might be undesirable due to cogent hydrological reasons like sub surface karstic pits schulla 2019 or culverts diverting significant catchment areas non identified within z h such explain the remaining discrepancies 1 three cases in the corrected models coming back to the example many parts of the initially calculated model network are already satisfactory due to the automatic consideration of the fnw there are still allocation problems especially at adjacent flow paths below the chosen resolution of 100 m and steep valleys where the grid centres are not near their depression line we can quickly appr 20 min solve these conflicts by creating 101 additional correction points that improve the model network significantly see example in fig 13 for subcatchment architecture the confluence points concentrate along the fnw for the example catchment obermühlhausen see fig 14 with a catchment area of 34 km2 the optimisation results in 49 well shaped subcatchments mean 0 69 km2 median 0 70 km2 std 0 34 km2 of which six subcatchments are larger and 43 are smaller than the chosen target size of 1 0 km2 confluence points constrain 12 subcatchments of the latter subcatchments created applying the pfafstetter method are smaller mean 0 69 km2 median 0 62 km2 and less homogeneous std 0 45 km2 as pour points can only be confluences overall the mean of all 3418 subcatchments covering together an area of 2551 km2 is 0 75 km2 with a standard deviation of 0 37 km2 see fig 15 the remarkable bias of 25 from the initially set value reduces to 15 excluding the 475 constrained subcatchments 14 the subcatchment optimisation procedure entirely relies on the available dem data quality issues e g left barriers in z h may severely hamper the subcatchment delineation from my own experiences such corrections are very costly in terms of labour so it is essential to provide an appropriate fnw as input enabling the algorithm to ignore non corrected culverts bridges and other barriers in the flow path additionally the subcatchment delineation also relies on well separatable landscape elements which is not the case if the subcatchment elements are small compared to the dem resolution with decreasing area long parallel and straight hillslope topographies splinter in segments due to over the edge connections of d8 for a dem resolution of 1 m the area threshold is about 0 01 km2 see example in fig 16 depending on the hillslope length and shape additionally authors report limited applicability of the d8 method in flat areas rahman et al 2010 areas where the local slope gradient differs from the primary slope gradient ridges and the banks of incised streams erdbrügger et al 2021 3 2 flow lengths elevations and slopes flow length elevation and slope parameters for runoff concentration and channel routing are available as pandas dataframe and arcgis pro polygon feature classes including joinable parameter tables comparing the resulting flow lengths based on pure raster calculations as all tools in table 1 use and with consideration of a fnw for 10 480 100 m raster model elements in eleven randomly chosen test catchments exhibits an elongation of flow lengths with a maximum of 13 mean 4 4 std 2 82 and rare shortenings up to 6 remarkably the elongation propagates stepwise with stream distance from the outlet especially where the water bodies meander neighbouring sub catchments can exhibit very different behaviour fig 17 fig 18 and fig 19 summarise the final flow length and slope values exemplarily concerning their spatial distribution and quantitatively with histograms summarising all 40 catchments for raster models the definitions dominate the flow length distribution for the different model element types and cause multiple distinct peaks while the association of model element types to topographic elements is dominant for the slope parameters the medians categorised for model element types s ro h 0 096 s ro t 0 143 s ch 0 073 reflect that headwater elements represent ridges and hilltops traversed elements ditches and small creeks in upper i e steeper valleys and channels lower i e flatter valley areas the minimum thresholds l 0 05 km and s 10 4 applied if users include the fnw for raster models parameter calculation users in the average have to decide manually for 0 37 of the model elements standard deviation 0 25 where l h or l l shall be assigned this number depends on the desired model resolution for subcatchment models fig 19 the medians of l ro h 2 17 km l ro t 1 41 km and l ch 0 89 km differ significantly while the standard deviations are in the same range l ro h 0 58 km l ro t 0 64 km l ch 0 54 km in comparison to raster models all flow length parameters have smooth distributions l ch is comparable for subcatchment and raster models considering their divergent element sizes 1 0 and 0 01 km2 respectively while l ro h and l ro t are approximately half for raster models the order of subcatchment models slope medians is s ch 0 009 s ro h 0 039 s ro t 0 047 the distributions show similar characteristics to those of raster models but their medians are generally smaller especially for s ch with almost one order of magnitude reflecting averaging due to larger model element sizes as a side note the comparison of the discrepancies between flow length and slope parameter distributions of different model types show impressively the discrepancies emerging from choosing different model types and resolutions 3 3 cross section geometries the proposed simple histogram based channel identification method reliably determines w ch bf in many cases as the following test illustrates from 505 cross sections in the example catchment ansbach size 130 km2 h bf ch was measured manually from z h for 101 randomly selected ones within arcgis using experts knowledge and compared to the algorithm s optimisation results the algorithm has underestimated 24 10 overestimated and 67 well defined 0 05 m exemplarily compared to the impressive hit rate of about 98 in choi and mantilla 2015 this seems very weak but the cited authors defined a horizontal deviation of 20 m as a hit which is not comparable to 0 05 m in height here the coefficient of determination proves an overall good fit to the manually determined values r2 0 81 the under and overestimated values nevertheless show that the channel fitting algorithm is heavily dependent on elevation histograms with a well defined histogram peak otherwise resulting in two significant issues on the one hand side there is a tendency towards underestimation of h bf ch if at least one floodplain is significantly lower than the river bank e g drained formerly swampy floodplains the algorithm assumes that the channel is the lowest point in the cross section profile to determine the first peak in the elevation histogram resulting in an underestimation of h bf ch see fig 20 left panel on the other hand the algorithm overestimates the channel depth if both floodplains are nearly as steep as the channel bank e g alpine creeks or if the banks slopes are gradually decreasing towards the floodplains because the algorithm will struggle to find any well defined peak in the elevation histogram see fig 20 right panel the gradient usually decreases with increasing height resulting in overestimated h bf ch and w ch values for completeness the algorithm will fail of course if the cross section does not comprise any channel single cross sections apply for raster model elements wherefore the quality of cross sections is of central importance for good quality simulation results during the testing phase it has turned out that δl ch cs 2d r is expedient to cover the fnw and at the same time leave a margin to be flexible during manual adjustment of cross sections positions therefore for low model resolutions δl ch cs is large compared to hydraulic 1d modelling samuels 1990 castellarin et al 2009 additionally it is practical to choose l cs and δz max large enough as the correction algorithms crop the original cross section see example scene in fig 21 pilotti et al 2011 propose l cs as several hundreds of metres orthogonal to the watercourse in complex bathymetry of mountain valleys indicating that it should be even more significant for flat regions the resulting gms parameters are satisfactory in most cases still there are some limitations fig 22 δh is at or even beyond the measurement precision of z h within channels and agriculture uses the analysed area intensively tending to either enlarge erosion protection or bury drainage such small creeks therefore the cluster of h bf ch close to δh seems unrealistic furthermore outliers of w bf ch 30 m indicate some poor channel delineation as the analysed densely settled catchments are maximum 160 km2 in size and w bf ch of the significant rivers is less than 30 m at the catchments outlets nevertheless h bf ch and w bf ch are generally more realistic than the results obtained from dhg which are about one decimal power too small for subcatchment models averaged multiple cross sections determine the required ttp parameters an example shows fig 23 while fig 24 summarises the parameter ranges the parameter distributions fit well to the expected ranges of small to medium sized catchments within a hilly landscape the definition of the ttp has two significant restrictions first the floodplains have to be horizontal s fp 0 this assumption remains preferably valid at streams with large catchments the test catchments are small in these terms wherefore w fp l and w fp r are often set close to the minimum 0 01 m compensating for this with flat but not horizontal forelands e g left floodplain in fig 23 only a few cross sections show significant horizontal floodplains within the analysed catchments the second restriction is that negative slope values within the ttp are not allowed therefore one has to mention that besides the uncertainties through discretisation and averaging this method cannot reflect linear structures or flow barriers within the cross section finally the parameter distributions emphasise restrictions of the tested dhg formula as these significantly underestimate channel widths and depths and the width of flood plains and forelands that leads to the conclusion that using these tested dhg formulas for simulation in bavarian upstream catchments will probably lead to underestimating channels flow capacity and velocity and overestimating flow time 3 4 parameters for runoff generation tatoo functions of runoff generation focus on the intersection of the readily prepared input parameter files of land use impervious share and soil with the model elements and the subsequent grouping process of hrus to grus the grouping reduces the number of features by about one order of magnitude fig 25 shortening the simulation time significantly 3 5 computational performance and remaining manual working time with tatoo users can implement very detailed spatial information in mesoscale ihms quickly generally the algorithms calculation times strongly depend on the created model the catchment size the resolution of the input data e g z h the computational environment and the user s knowledge concerning the model and pre processor as well as the remaining effort of the user s manual corrections a calculation example imagine a larsim model grid of 100 m for a 100 km2 catchment using a dem with 1 m resolution resulting in 10 000 model elements with six physical cores 3 6 ghz and 32 gb ram and without user intervention it takes about 30 min computational time to complete all necessary algorithms for the raster example including cross sections assuming a perimeter of 60 km a fnw length of 150 km and 300 cross sections the user might need an additional 130 min to complete the corrections see fig 26 thus the overall time for the described raster setup is about 2 3 h using tatoo while the manual efforts dominate the raster model setup this relation is reversed for subcatchment models as their preprocessing only needs two manual steps with a few minutes of manual working time the overall needed time for the mentioned model setup example with desired subcatchments of 1 0 km2 is approximately 30 min using arcpy from arcgis pro version 2 5 the most costly step in calculation time is the calculation of l h as it is not parallelised yet the functions prepr routing rasters for raster models and calc params for subcatchment setups need the arcpy flow length algorithm as esri showed significant engagement in recent releases to parallelise more and more tools the calculation time of tatoo might decrease even further in future the transformation to foss software could speed up the calculations as well for example by replacing the arcpy flowlength function with grass or saga tools 3 6 relevance for various model types subjects and scales there are several possibilities to apply the tatoo library beyond its target group of particular interest for integration in ongoing works are initiatives to calculate store and share standardized geospatial catchment or river reach information and therefore save computational expenses for every single modeller such databases are available for australia geofabric au bom 2015 and stein et al 2014 the united states of america nhdplus moore and dewald 2016 and moore et al 2019 streamcat hill et al 2016 the european union ecrins eea 2012 and jager and vogt 2010 eu hydro gallaun et al 2019 and even near global hydrosheds lehner et al 2008 and lehner and grill 2013 hydroatlas linke et al 2019 domisch et al 2015 the latter is particularly promising as they provide a clear perspective toward an open and integrated standard for topographical parameters meanwhile the most sophisticated initiatives geophabric streamcat eu hydro and hydroatlas provide hundreds of different parameters for millions of subcatchments a further increase of globally available homogeneous dem resolution from usually used few arc seconds towards few meters is foreseeable it makes an application of some tatoo functions on a continental or even global scale imaginable e g to provide pre calculated channel and foreland geometries for each river segment especially the integration with hydroatlas seems promising as its highest level of detail in the average of 130 6 km2 catchment area and 4 2 km river segment length fits the scale tatoo can easily handle with a 1 m dem to improve the fnw quality see concerns in linke et al 2019 with little manual work as input for tatoo recently developed deep learning techniques might worthful mao et al 2021 generally water related fields relying on a high level of topographic details stemming from a large amount of dem data often through a combination of high resolution and large area from catchment to continental scales may also benefit from tatoo here are some examples certainly studies performing hydrological and one dimensional hydrodynamic modelling such as flood risk and climate change adaptation and resilience studies e g springer et al 2020 or hattermann et al 2018 are promising candidates furthermore other water related scientific fields such as sediment e g vigiak et al 2017 habitat e g domisch et al 2015 and ecosystem service studies e g review for the danube river basin in perosa et al 2021 could benefit as well finally besides modelling deep learning and artificial intelligence algorithms can be applied to many detailed parameters tatoo can produce 4 conclusions tatoo is a python 3 6 library loosely coupled with arcgis pro 2 5 that contains functions to set up integrated hydrological models ihms the functionalities cover the whole spatially related setup process elaborated and documented using detailed exemplary workflows for the larsim the new functionalities focus on using recent high resolution dem data supported by fnw features precisely on the one hand users can delineate raster and subcatchment model structures and files automatically and efficiently within a short time while still considering specific needs as e g model resolution or subcatchment sizes on the other tatoo includes new methods to consider high resolution dem data in integrated hydrological models highlighted by the efficient incorporation of cross section information in both model structures i showed that the python 3 6 functions interacting with arcgis pro 2 5 produce reliable parameter distributions for raster and subcatchment model architectures and are very efficient in manual and computational working time when applying them to 40 german catchments concerning the model assumptions e g static model network scale limitations and empiric formula i chose the methodology and it architecture to my best conscience nonetheless many recent implementable developments would complement the work done so far such as hybrid flow enforcement algorithm lindsay 2016a and the topologicalbreachburn method lindsay 2016b pem4pit a physically based method for removing pits in dems grimaldi et al 2007 distance transform optimisation to correct for the orthogonal and diagonal flow length steps butt and maragos 1998 or smith 2004 2d dimensional flow schemes in integrated hydrological models e g schulla 2019 non planar or dog legged cross sections petikas et al 2020 and automatic strickler value determination along cross sections choi and mantilla 2015 furthermore someone could integrate recently developed object based hydrological model engines such as echse kneis 2015 online repositories e g hydroshare other processing environments e g cuahsi jupyter hub and cybergis jupyter and model apis as pysumma e g leonard and duffy 2013 vice versa tatoo could be integrated into an available web based gis environment chen et al 2020 or global hydro database linke et al 2019 tatoo also covers only some available methods in larsim so one could further extend the range of functions and of course build model setup routines for other models on top of the presented packages finally replacing the closed source and commercial arcpy with foss4g alternatives would make tatoo applicable to a broader community overall using tatoo modellers can accelerate the setup process of several detailed ihms significantly while the additionally proposed workflows are especially useful for the larsim community their application will enable profound well documented and enhanced analysis requiring many different catchments models or setups as model comparison or scale studies regionalisation of model parameters and extreme value analysis supplementary files the documentation of the described functionalities is three fold to fulfil the needs of reproducibility 1 self explaining documentation within the code with an overview in each function header and in line line by line documentation of the code 2 explanations for application of tatoo within the exemplary workflow scripts 3 a reproducible showcase based on downloadable data the showcase can serve as a demonstrator for both the raster and subcatchment functionalities of tatoo with a real case eight km2 tributary of lower bavaria in southern germany including a 1 m dem that enables users to try and review the workflows under controlled conditions code examples and documentation are available online at the tatoo project in the open science framework https doi org 10 17605 osf io gahju program and computing requirements arcgis pro version 2 5 or newer https pro arcgis com en pro app latest arcpy get started what is arcpy htm mandatory will include python 3 along with the arcpy package for application of existing workflows larsim version 1040 or newer https www larsim info en the model software availability the first open source tatoo release is available from 2021 on the platform open science framework https doi org 10 17605 osf io gahju including an integrated github versioning in zenodo https zenodo org record 5229292 available downloads include the libraries 1 mb english example workflows 3 mb and a test dataset 0 4 gb the python 3 6 library requires the arcpy library of esri arcgis pro version 2 5 and standard open source packages e g numpy there are no specific requirements for the hardware declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements research funded by the bavarian state ministry of the environment and consumer protection the bavarian environmental agency bayerisches landesamt für umwelt lfu and the bavarian agency for digitisation high speed internet and surveying landesamt für digitalisierung breitband und vermessung lfdbv kindly provide the support and test case data i would like to thank prof dr ing markus disse with the technical university of munich and prof dr ralf ludwig with the ludwig maximilians universität munich for their support and guidance during the development and two anonymous reviewers for their timely and insightful colleague reviews all data used in the analysis and supporting the conclusions in this manuscript can be obtained from the technical university of munich e mail johannes mitterer tum de any trade firm or product name is for descriptive purposes only and does not imply endorsement by the bavarian government appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105406 
25584,while modelling includes many detailed processes the model setup gets costly delineating distributed parameters requires advanced gis processing techniques and programming expertise limiting models usage to researchers and practitioners with sufficient resources although high resolution input data get increasingly available only a few preprocessing algorithms of integrated hydrological models can handle these in a reasonable time and for both subcatchment and raster model architectures here the collaborative open source python 3 6 topographic analysis tool tatoo library is presented integrating different models preprocessing into one processing environment and combining not model specific topographic preprocessing functions with model specific parameter calculation functions utilising high resolution dems and flow network shapefiles tatoo offers algorithms to delineate 1 raster or subcatchment based model networks 2 runoff generation concentration and routing parameters and 3 channel and foreland cross section geometries including bankfull water levels tatoo s capabilities and time requirements are demonstrated for the large area runoff simulation model s preprocessing keywords hydrology modelling preprocessing python cross section larsim ihm abbreviations larsim large area runoff simulation model ihm integrated hydrological model 1 introduction integrated hydrological models ihms are used worldwide to address water related research and engineering design questions such as surface and sub surface processes forecasting protection measures and resources management ihms require preprocessing of input data being time consuming and costly for large ihms with many different model elements i e discretised spatial units of the catchment therefore the widespread application and acceptance of complex and spatially distributed ihms in science and especially engineering design largely depend on the easy and cheap setup of the model e g fatichi et al 2016 consequently many tools have been recently developed to semi automatically preprocess spatial data for single few or seldomly even some hydrological and hydrodynamic models table 1 by way of contrast there is no preprocessing module for the ihm larsim large area runoff simulation model see ludwig and bremicker 2006 or www larsim de published yet although it is used widely as an official operational forecast model in several german austrian french and swiss states and cantons for more than 20 years scientists or public authorities which develop and advance many ihms have limited resources for a model or even more preprocessing tool development additionally such preprocessors have to keep up with the model development and hardware e g new reproduced processes or higher computational power and to consider progress in programming languages e g the recent upgrade of python from version 2 to 3 as well as potential connected software e g esri arcmap 10 and arcgis pro finally they shall include newly available datasets e g high resolution lidar elevation models to gain future acceptance overall the preprocessing of ihms is very arduous and time consuming gardner et al 2018 and such tasks can take a significant portion of the hydrological modeller s time and effort gichamo et al 2020 berry et al 2014 gichamo et al 2020 and viviroli et al 2007 showed that preprocessing tools reduce the time for model setup and execution considerably while krysanova et al 1998 highlight the improved transferability however with limited resources available models and tools are prone to be fastly outdated or slow and inefficient for new model applications chen et al 2020 there are many general similarities between ihms but the details of the specific ihm requirements inhibit the direct application of foreign tools as the value calculation is usually model independent but each ihm has particular conventions for the parameter for example the ihm larsim assumes that runoff generated within a model element enters the respective channel section of a traversed element at half its length while channel inflows from upstream model elements and runoff from headwater elements sum up at the beginning of each traversed element s channel section other models like mike she butts and graham 2005 or shetran ewen et al 2000 need flow networks located on the edges of cells sometimes there is even a multi functional use of parameters e g flow length in larsim represents the physical channel length serves as an identification value for model element connections and can suppress the channel routing using a key value leg 2021a such contradictions obstruct the development of a unique model independent preprocessing algorithm for the entire process and hamper the development of one which is applicable for at least some ihms nevertheless instead of creating and maintaining the whole workflow for every single model separately it would be much more efficient to have essential functions which apply for all or at least many models using similar spatial data e g based on leonard and duffy 2013 and delineate specific model parameters from their results different groups see chen et al 2020 and sources therein are working on open web distributed platforms sharing data e g geoss and fluidearth and gis tools or model resources e g cybergis opengms ewater integrate models e g esmf and csdms or to develop new web apps e g tethys in swain et al 2016 with summa clark et al 2015a 2015b 2015c its integration with hydroshare cuahsi jupyterhub cybergis jupyter and pysumma see choi et al 2021 and references therein as well as hydrods gichamo et al 2020 and the esmvaltool righi et al 2020 open web based frameworks are evolving for physically based models nevertheless to the author s knowledge a preprocessing framework is still missing for conceptual ihms this paper proposes tatoo the topographic analysis tool library it is a collaborative preprocessing toolbox built on the idea of an open web based depository containing 1 not model specific open source topographic preprocessing functions 2 model specific parameter calculation functions utilising outputs of topographic functions and 3 model specific workflows combining 1 and 2 for model application it offers the integration of different models preprocessing into a single processing environment and therefore aims to make this laborious task more efficient and transparent and face the reproducibility challenge e g hutton et al 2016 stagge et al 2019 tatoo contributes to tackling some methodological gaps in recently available environmental software first the packages transfer well known algorithms to an up to date programming language and software python 3 6 with arcgis pro 2 5 including functions to delineate semi distributed irregular or grid shaped model elements and networks their runoff generation concentration and routing parameters as well as channel and foreland cross section geometries second tatoo can deal with recent high resolution raster datasets such as digital elevation models dems with few metres resolutions e g 1 m and even shapefiles representing complex flow networks third tatoo provides structured and well explained functions for different ihms comparable to the design of volk and turner 2019 while proposing additional workflows to preprocess data and input files specifically for the ihm larsim finally compared to the tools in table 1 tatoo offers the following significant new techniques optimisation of subcatchments sizes during delineation respecting user settings integration of polyline flow networks into dem based flow length and slope calculations for overland and channel flow modules in both raster and subcatchment model architectures delineation of cross sections including automatic detection of the bankfull channel water level and solution of frequent topographical conflicts this article gives an overview of the tatoo library s technical attributes requirements and essential methods in section 2 whereby sections 2 3 to 2 5 focus on the new techniques examples and quantitative analysis of the resulting parameters the calculation times needed manual efforts and implications for the broader modelling community are in section 3 section 4 concludes and discusses the progress made with tatoo and outlines potential future works finally supplementary material is available e g an user manual and a test dataset 2 methods 2 1 design goals infrastructure and environment the tatoo library s design rests upon a few fundamental goals which are 1 little time is needed for model setup and therefore fast processing speed 2 applicability by as many users as possible 3 high flexibility to use functions independent of but also specific enough for the chosen ihm 4 support of fast and straightforward changes in the light of fast evolving programming language and software development model and gis and 5 algorithms are automatically applicable with little user interaction but still many operator interventions to control and construct the model for individual purposes based on beven 2012 i designed tatoo for ihms with a semi distributed model structure and parameters to define runoff generation using hydrological response units hru and runoff routing i e runoff concentration and channel routing semi distributed includes irregularly shaped i e vector and grid based i e raster architectures which are treated separately due to their differing technical fundamentals in geo information systems gis for simplicity in the following sections i refer to these as subcatchment and raster models following goodchild 1992 and sui and maggio 1999 there are different integration strategies for gis frameworks and models that range from loosely coupled exchange of files to fully integrated systems one software the design of tatoo connects open source python 3 functions and the closed source software arcgis pro of esri loosely to fulfil the described needs python offers various tools and packages oliphant 2007 and is an easy starting point for non experienced programmers due to its explicit language perkel 2015 the procedures use numpy walt et al 2011 pandas mckinney 2013 and other prevalent open source python packages and the closed source arcpy environment of esri arcgis pro version 2 5 admittedly this combination is somehow counterintuitive free and open source software for geospatial applications foss4g development has improved rapidly during the last decades akbari and rajabi 2013 brovelli et al 2017 steiniger and bocher 2009 while closed source software shows limitations especially concerning cloud and parallel computing reproducibility and adaptability muenchow et al 2019 sui 2014 tang and matyas 2018 however using arcpy is advantageous in accelerating the development especially during the early stages compared to often selective open source alternatives it covers nearly all areas of gis applications has well maintained documentation and the sophisticated gui arcgis pro which interacts with the package s functions and helps to display the results quickly e g gardner et al 2018 therefore the first version of tatoo utilises arcpy acknowledging the potential of replacing it with foss4g such as taudem geopandas saga gdal pyshp or ogr in future versions comparable to e g gardner et al 2018 and crystal ng et al 2018 modellers need some python programming skills to apply or extend tatoo functionalities they can run the tatoo functions using any familiar python environment such as spyder or jupyter i recommend using anaconda to manage the python packages interactions e g arcpy with numpy tatoo offers different output types to support the connectivity most major functions result in pandas dataframes which allow the user to process the data further within the chosen python environment additionally there are functions to export the results in geo information files for arcgis e g feature classes raster files and tables or even other gis software e g shapefiles or geotiffs finally it is possible to export the parameters to the required spatial model input files as shown for the model larsim 2 2 structure of the tatoo library three different packages form the tatoo library the first tatoo raster py contains all functions explicitly designed for raster model preprocessing and the second tatoo subcatch py provides functions for subcatchment model preprocessing functions from the third tatoo common py are general functions which raster or subcatchment packages call either as sub or as stand alone functions all together they are part of two scripts which outline exemplary workflows for raster and subcatchment model creation fig 1 shows the interdependencies of all packages and workflows although raster and subcatchment architectures of ihms exhibit fundamental differences in their parameter delineation methodology the following structure of four major sections can satisfy both 1 delineate the model domain and network 2 calculate the runoff concentration parameters 3 derive the cross section information representing channels and floodplains 4 calculate the parameters of runoff generation chapters 2 3 until 2 6 explain specifically the methods in depth while sections 3 1 until 3 4 contain appertaining examples and results fig 2 outlines workflows for both structures and holds an overview of existing functionalities and possible user interventions overall the raster package consists of 24 the subcatchment package 23 and the common package 24 sub functions documented in detail within the online depository see supplementary material section 2 3 model domain and network the first part of tatoo deals with the detailed reproduction of the actual flow network resulting in the calculation structure of the model elements this structure is usually the backbone of a model referenced by many other model files and the input for calculating the model network a digital polyline river network file describes the actual flow network referred to as flow network or fnw tatoo differentiates three types of model elements whose definitions the following sections refer to first there are headwater elements which do not have any inflow second there are so called traversed elements with one or more contributing headwater or traversed elements some ihms can programmatically sum up maximal two contributing elements at once at a confluence point so the model structure requires additional artificial connectors called dummy elements which are a technical trick without affecting the model outputs fig 3 may illustrate the concept for raster models the availability of high resolution airborne dem rasters z h allows automatic delineation procedures for the model s watershed area and flow structure of raster models these often rest upon the neighbour steepest gradient unidirectional d8 flow direction while there would be single stochastic e g ρ8 of fairfield and leymarie 1991 and multiple flow alternatives e g quinn et al 1991 costa cabral and burges 1994 tarboton 1997 seibert and mcglynn 2007 crystal ng et al 2018 discuss a variety of different d8 implementations while rieger 1998 erskine et al 2006 and wilson et al 2007 rated the multiple flow direction methods as superior however many ihms do not support multiple direction flow and arcgis pro does not support the stochastic single direction method precluding any d8 alternative in tatoo dependent on the grid resolution automated flow direction delineation remains prone to errors due to e g uncorrected measurement errors not resolved features and missing underground hydraulic connections e g lidberg et al 2017 the model catchment and network delineation is based on the final resolution of the ihm meaning that the used dem resolution is often far lower than the original data therefore and because of specific topographic and geological structures unsupervised extracted catchment areas and model networks are very uncertain condon and maxwell 2015 erdbrügger et al 2021 gardner et al 2018 hammond and han 2006 hinton et al 1993 woodrow et al 2016 especially artificial close by parallel branches built for e g drainage hydropower or mills are poorly separatable using the model resolution dem z l e g tarboton et al 1991 hammond and han 2006 lindsay 2016b and stream burning and depression filling and thus depression breaching leads to a significant increase in the alignment between model structure and flow features lidberg et al 2017 therefore the presented procedure follows a semi automated approach giving the modeller the possibility to engage in the delineation process of the model domain and network four functions describe this process in tatoo aggregation and correction of z h with preprocess dem delineation of the model domain usually a surface watershed using create pourpoint and calc watershed and setup of the model s network with calc model network at first preprocess dem aggregates z h to z l fitting the desired model resolution and burning streams by a user defined value subsequently the user may create pour point features at subcatchments outlets p out using create pourpoint to include subcatchments in the model domain or clip them using p out and z l the function calc watershed removes pits delineates the first draft of the model domain watershed based on d8 and creates a point feature class to manipulate it users may check the displayed catchment borders compare them to other sources like the catchment delineated with z h and correct encountered mismatches a rerun of the function calc watershed will automatically integrate the changes in the flow direction raster resulting in a corrected catchment boundary afterwards calc model network establishes the relations of the model flow structure consisting of element centre points connecting polylines and polygon features using create element polyg finally users can adapt the model network manually to reproduce diverting and even crossing structures using the same procedure as the watershed delineation the procedures for subcatchment models follow those or raster models create pourpoint except for using z h instead of z l lidberg et al 2017 by way of contrast the subcatchment delineation differs fundamentally from the raster package as the subcatchment structure is similar to the surface watershed borders beyond the functionalities of the tools in table 1 tatoo offers an optimisation function to achieve similar sizes of subcatchments the function optimize subc identifies the most suitable pour points for subcatchment optimisation based on the desired subcatchment size thereby there are two principles first the algorithm identifies pour points of major tributaries upstream to the confluence points using the flow accumulation differences resulting in similar points as the pfafstetter scheme see verdin and verdin 1999 second it decides the necessity of dissecting subcatchments into equal parts by adding pour points along the fnw in general the optimiser allows subcatchments with 50 150 of the desired subcatchment size but to prevent problems during the modelling e g for minimum channel segment length the user can define a minimum flow length threshold l min sustained during the optimisation users may move identified delete superfluous or create missing pour points in arcgis pro before further processing dummy elements are implemented only in cases where the subcatchment optimiser respects l min the subcatchments inlying centroids represent their coordinates 2 4 flow lengths elevations and slopes the second section of tatoo focuses on delineating spatially distributed parameters necessary for runoff routing usually table 1 the calculations rest upon grid based flow length and elevation values resulting in longitudinal gradients and referring to the energy transition from potential to kinetic while water flows downwards depending on the applied ihm spatial runoff concentration and channel routing are treated separately in different modules although both need flow length and gradient values the tatoo tools process these together and eventually split them into runoff and routing shares to ensure that both parts correspond a crucial part of determining parameters is determining the appropriate flow length using z l the resulting low resolution flow length raster l l straightens especially on meandering river courses it underestimates the actual flow length value significantly for many catchments see fig 4 wu et al 2008 who analysed dems with 10 m do not support these findings in a first view but studies from paz et al 2008 dehvari and heck 2013 rinderer et al 2014 woodrow et al 2016 and erdbrügger et al 2021 suggest that dems with 6 m resolution already smooth out the microtopography that strongly affects contributing areas stream lengths and the extraction of streams furthermore chang and tsai 1991 deng et al 2007 and wu et al 2008 showed that also the slope means standard deviations and accuracy decreased with lower dem resolution especially for steep areas tatoo functions shall implement detailed topographic information such as exact flow length into ihms therefore it utilises the high resolution rasters to determine flow length and slopes and allows the opportunity to integrate the fnw directly into the raster calculation for raster models prepr routing rasters depicts a high resolution flow length raster l h for all model elements containing a segment of the fnw to consider small scale flow path variations e g meanders automatically and it uses l l for all model elements without a piece while calculating and merging l h and l l conflicts may arise first the definition of flow length is crucial during the calculation of l l routines in arcgis define flow length as the length between raster neighbours centre to centre but ihms usually interpret flow length as the flow path within a model element that also means that f l from gis ignores parts of the flow length in headwater elements and at the outflow if the raster shape is equivalent to the model domain second the geometrical construction of a raster with straight and diagonal connections results in flow lengths between two cells of either d r or 2 d r with d r referring to the raster resolution therefore deviations r remain at confluences between contributing elements which increase with increasing d r consequently it is necessary to redistribute l l third a deficient reproduction of the fnw with raster elements during the calculation of l h results in significant allocation errors due to cut off line segments outside the flow accumulation based river course finally there are deviations where model elements with l h and l l adjoin each other therefore flow length is formalised as the following for the runoff concentration lengths l ro in traversed elements l ro t l r o t d r 1 2 4 holds throughout the catchment domain furthermore l ro of headwater elements l ro h and channel lengths delineated from l l l ch ras are l r o h c h r a s d r 2 d r r where r depends on the determination method of the downstream l ch while l ch ras have distinct values the channel lengths delineated from l h incorporating the fnw l ch fnw yield a smooth distribution example in fig 5 finally l l m i n l m i n prepr routing rasters contains the respective algorithms they estimate the missing share of l l in headwater elements redistribute l l compensate differences at model elements where l h and l l deviate and ensure the incorporation of all polyline segments in the l h calculation besides the user can assign l h or l l to single model elements manually using create fl ind point the subsequent function summar gisdata for roandrout merges l h and l l respecting users choice elevation differences or slopes are the second longitudinal information for runoff routing wherefore tatoo extracts the maximum z max and minimum z min elevation values for each model element in calc roandrout params from z h including monotonically decreasing streams similar to the flow length processing a redistribution of elevation residuals to the upstream raster elements solves conflicts at confluence points the user can define a minimum slope of the channel routing s min users also define the lowest runoff concentration elevation as z rc min z ch min z ch max with z ch min z ch max being the element s minimum maximum channel elevation default average as well as the highest runoff concentration elevation as z rc max z max z min with z min z max being the elements minimum maximum default elevation although the variations within a model element might be minor all factors together can significantly influence the runoff reaction time compared to the raster models the determination of runoff concentration and channel routing parameters for subcatchments is more intuitive wherefore all subfunctions are part of calc params the basis are the high resolution elevation raster z h and the consequential upstream flow length raster l h now imagine a traversed subcatchment with two upstream tributaries see fig 6 for the channel routing the channel flow length l ch is the average length of all flow paths from the inlets to the outlet also defining the channel elevation difference δ z c h keep in mind that the inlets might not be at the natural confluence point due to the definition of l min during subcatchment optimisation depending on the number and the distance between the inlets residual flow length values and elevation differences remain these are balanced upstream with the entering subcatchments attributes retaining the catchment wide flow length and elevation distribution for headwater elements the values remain empty the runoff concentration flow length for traversed elements l rc t is the distance between the subcatchment s maximum of l h and a user defined point along its channel flow path between the inlets confluence point and the outlet the maximum and minimum elevation z max and z min are the respective values of z h the ignored flow length and elevation residuals from the downstream subcatchment s channel routing calculation are beeing compensated with the upstream tributaries as for raster models l l m i n l m i n and s s m i n s m i n apply please refer to the documentation for further details 2 5 cross section geometries the last missing geometrical information is cross section data tatoo first contains methods to obtain cross sections using regression equations estimating downstream hydraulic geometry dhg e g gleason 2015 as most others in table 1 second it also can delineate cross sections directly from z h compare choi and mantilla 2015 while the first is the same for both model types the latter differs significantly for raster and subcatchment models dependent on the methodology the output tables contain either geometry attributes of a threefold trapezoidal profile ttp or all necessary variables for use in the well known gaukler manning strickler gms formula using the dhg method tatoo calculates a ttp see fig 7 within calc roandrout params estimating channel and floodplain parameters based on the dhg formula of allen et al 1994 or krauter 2005 there are others such as leopold and maddock 1953 ames et al 2009 and bieger et al 2016 from which many see gleason 2015 for a review rely solely on the channel forming discharge q ch which may be the 1 or 2 year return period flood values from a nearby gauge station allen et al 1994 the function extrapolates q ch linearly based on the catchment s flow accumulation i e the subcatchment area the user may set all other ttp geometry parameters for the foreland and valley see fig 7 as constants particular dhg formulas might not apply to catchments or will not result in realistic geometries as they rely on empirical data sets reflecting multiple variables such as climate land use slope soil type and geology they are therefore either a global average of the dataset or reflect very local conditions limiting their spatial transferability ames et al 2009 furthermore most channels in densely settled regions have undergone an extensive overprint through human activities e g constructions or agriculture making inadequate equations for unregulated and undiverted streams if the model application requires a realistic representation of the cross section geometries there is a need for fastly applicable delineation algorithms which can handle precise dem data and finally yet importantly allow extensive possibilities of user intervention the additional functionalities provided within tatoo include cross section delineation and channel fitting algorithms and they are applicable for any model requiring cross section data for raster models the delineation process consists of four steps 1 creation and manipulation of cross section lines along with the river network 2 handling of cross section conflicts 3 fitting of the bankfull channel parameters and 4 calculation of cross section parameter functions create csl creates planar lines perpendicular to the fnw applying a user defined horizontal spacing δl ch cs and a minimum inflow catchment area these lines determine the position of the cross sections assuming that the water flux is perpendicular at all points of the lines the valley s expected maximum water level heights should predefine the cross section length l cs each cross section centre point c cs is one of the potentially multiple intersection points with the fnw i fnw the fnw might meander in the valley or be interrupted by e g lakes dams culverts bridges and buildings the automatic placement of the cross section will consequently not be hydraulically suitable in every case and might intersect at confluences therefore the user can manually move turn create and delete cross sections in arcgis pro before parameter calculation instead of deleting them automatically e g choi and mantilla 2015 the c cs define the allocated model elements one per element and the cross section applies to any downstream model element until another cross section is defined that limits the number of profiles needed depending on the topography and the desired resolution as soon as the user is satisfied with the cross section locations and orientation the function df profdat from cs extracts the corresponding elevation data from z h while the methodology is very similar to choi and mantilla 2015 or wang and trauth 2020 until here tatoo includes three major corrections tackling challenges of mesoscale catchments fig 8 first if there are multiple i fnw the function excludes the cross section part beyond the watershed line between c cs and the next i fnw preventing double hydraulic usage second the algorithm deletes cross sections which monotonically decrease from both sides maximum elevations z cs max outwards if c cs is within a monotonically decreasing section the function adds an artificial channel with a user defined width and depth the last correction unifies z cs max of all profiles it clips parts exceeding the user defined vertical distance to z c cs called δz max and adds a vertical wall if z c c s δ z m a x z c s m a x holds routing modules of ihms may distinguish between the channel and the foreland to reproduce the different surface roughnesses and flow regimes during floods many models and their pre processors e g the hec ras mapper in hec 2020 still require their users to digitalise the river overbanks manually e g pramanik et al 2010 gichamo et al 2012 while tatoo tries to find them automatically it can be estimated from the cross section profiles if the accuracy of the used dem is high enough e g schumann et al 2008 and errors such as water surface reflections are corrected e g domeneghetti 2016 bures et al 2019 to reproduce the channel adequately overbanks expressed through the bankfull channel depth h bf ch can be identified by a sharp change in elevation choi and mantilla 2015 or the cross section gradient as the channel banks are steep compared to the relatively flat forelands tarboton and ames 2001 a histogram of elevation values can express the cross section gradient and the first histogram peak above the channel s lowest point may then determine w bf ch fig 9 if the algorithm cannot determine h bf ch this way it instead uses the selected dhg formula aside from user defined constant strickler roughnesses k st for channel and foreland the gms needs the width of water surface level w the traversed area a and the wetted perimeter u as functions of the water level h in the cross section the user can define the vertical evaluation heights with their maximum h max and the vertical spacing δh w h a h and u h are determined separately for the left and right cross section parts depression shares of a h belong to the water level of the high point between the depression and the channel i e they fill up when water overflows the dam in between by way of contrast the determination of cross section geometries for subcatchment models differs significantly from the raster package assuming that subcatchments are larger than elements of raster models and therefore represent a longer channel stretch it seems unreliable to describe the channel section with a single cross section consequently tatoo uses the average of equidistant cross sections within a subcatchment instead identical to the raster version the user may define the δl ch cs and l cs then the algorithm creates cross sections along the river course similar to pilotti 2016 and calculates their averaged geometry the raster correction methods apply in the next step except for the intersection point handling the resulting averaged and corrected cross section is then used in a three step optimisation approach to obtain ttp parameters 1 select h bf ch the same way as in the raster version 2 fit the channel trapezoid 3 optimize the foreland trapezoids individually for both sides of the channel all parameters are made available as pandas dataframe and arcgis pro polygon feature classes including joinable parameter tables 2 6 parameters for runoff generation there is still a considerable variability of methods to reproduce runoff generation e g single or multiple linear storages richard s equation green and ampt approach scs cn method see beven 2012 for more while each of them needs different parameter sets therefore data for vertical water movement processes is usually particular for every hydrological model consequently tatoo offers user defined complexity of the soil routine it is possible to work with the empirical linear storage approach of zhao 1977 a simplified green and ampt 1911 infiltration routine based on steinbrich et al 2016 capillary rise and impervious share the function calc hrus intersects the prepared model element structure land use data impervious percentage and soil polygons performing control mechanisms to prevent inconsistencies between them finally it can subsume hrus to grouped response units kouwen et al 1993 of so called distribution function models such as e g the slurp model kite 1995 or the dhms model vinogradov et al 2011 by way of contrast averaging would affect the simulation of the soil moisture kuo et al 1999 2 7 testing environment i tested tatoo by applying it to the large area runoff simulation model larsim which is an ihm of bremicker 1998 based on the rainfall runoff model fgmod ludwig 1982 recently german austrian swiss and french authorities and scientists are using the model for operational flood forecasts as well as for questions of flood protection bremicker et al 2011 haag et al 2005a water management gathenya 1999 haag et al 2006 and even river temperature modelling haag et al 2005b haag and luce 2008 a summary of applications is available in bremicker et al 2013 a strength of larsim is its flexibility modellers may run the model in a design oriented rainfall runoff approach with meteorological scenario creation or a comprehensive water balance scheme including a dynamic phenological model chmielewski et al 2008 meanwhile it is possible to combine nearly 100 physical and conceptual methods to reproduce hydrological processes a comprehensive summary of all functionalities of the model is available in ludwig and bremicker 2006 the technical documentation is published in leg 2021b and leg 2021a generally the model element architecture is of the following structure the smallest spatial entities of the model are hrus containing land use and soil information for vertical water flux calculations of four runoff components separated fast and slow direct runoff interflow and baseflow the hrus are non located within either irregular polygon or cell model elements the model calculates the runoff concentration time of all runoff components separately within each subcatchment using a calibratable approach based on kirpich 1940 consequently the runoff components form the sub catchment outflow contributing to a one dimensional channel section scheme tatoo includes all functions required to calculate the spatial parameters for raster and catchment based models which leg 2021b recommend every distributed ihm needs plenty of spatial data to reproduce a catchment correctly for the tatoo application with larsim i used five different data sets of bavarian or german public authorities table 2 from the 1 m dem from lidar i digitised the fnw utilising existing approximate and even deficient river network polylines fgn25 for orientation the tatoo library was initially developed based on three catchments in the southern german state bavaria simbach am inn 33 km2 340 570 m schöllkrippen 64 km2 200 530 m and stöckach 77 km2 330 530 m for these catchments i created different raster and subcatchment model resolutions ranging from 0 01 to 5 0 km2 using the two proposed workflows tatoo raster example py and tatoo subcatch xample py afterwards i set up raster models with a model element size of 0 01 km2 and subcatchment based models with a target element size of 1 0 km2 for 37 additional catchments to ensure tatoo s applicability and bug free functionality as well as to assess the performance of the tools regarding the remaining manual working time the catchments cover an ample variety of catchment attributes compare fig 10 and their size ranges from 1 2 to 160 km2 comparable to the usgs huc level 12 scale 3 results and discussion the following section shows the software results qualitatively with selected cases and quantitatively by analysing the results of all 40 catchments for subcatchment and raster architectures finally tatoo demonstrates its performance by applying timing analysis to all setups and a perspective for implementation in other existing environments is given 3 1 model domain and network for raster models i show the domain and flow structure calculation in the following at the example of groβschwindau a 21 km2 large catchment in upper bavaria using the aggregated 1 m dem z l and a single pour point at the catchment outlet the first calculation of the watershed exhibits significant deviations of the watershed boundary compared to the original 1 m dem z h with 72 correction points the overestimation of the catchment reduces from 2 0 to 0 47 fig 11 the range is within the same magnitude as the median of all catchments 2 7 to 0 9 but significantly lower than the mean 7 2 to 1 4 which points to seven predominantly smaller catchments with a deviation of more than 10 see fig 12 while it is aside from grid overlapping theoretically possible to achieve total congruency this might be undesirable due to cogent hydrological reasons like sub surface karstic pits schulla 2019 or culverts diverting significant catchment areas non identified within z h such explain the remaining discrepancies 1 three cases in the corrected models coming back to the example many parts of the initially calculated model network are already satisfactory due to the automatic consideration of the fnw there are still allocation problems especially at adjacent flow paths below the chosen resolution of 100 m and steep valleys where the grid centres are not near their depression line we can quickly appr 20 min solve these conflicts by creating 101 additional correction points that improve the model network significantly see example in fig 13 for subcatchment architecture the confluence points concentrate along the fnw for the example catchment obermühlhausen see fig 14 with a catchment area of 34 km2 the optimisation results in 49 well shaped subcatchments mean 0 69 km2 median 0 70 km2 std 0 34 km2 of which six subcatchments are larger and 43 are smaller than the chosen target size of 1 0 km2 confluence points constrain 12 subcatchments of the latter subcatchments created applying the pfafstetter method are smaller mean 0 69 km2 median 0 62 km2 and less homogeneous std 0 45 km2 as pour points can only be confluences overall the mean of all 3418 subcatchments covering together an area of 2551 km2 is 0 75 km2 with a standard deviation of 0 37 km2 see fig 15 the remarkable bias of 25 from the initially set value reduces to 15 excluding the 475 constrained subcatchments 14 the subcatchment optimisation procedure entirely relies on the available dem data quality issues e g left barriers in z h may severely hamper the subcatchment delineation from my own experiences such corrections are very costly in terms of labour so it is essential to provide an appropriate fnw as input enabling the algorithm to ignore non corrected culverts bridges and other barriers in the flow path additionally the subcatchment delineation also relies on well separatable landscape elements which is not the case if the subcatchment elements are small compared to the dem resolution with decreasing area long parallel and straight hillslope topographies splinter in segments due to over the edge connections of d8 for a dem resolution of 1 m the area threshold is about 0 01 km2 see example in fig 16 depending on the hillslope length and shape additionally authors report limited applicability of the d8 method in flat areas rahman et al 2010 areas where the local slope gradient differs from the primary slope gradient ridges and the banks of incised streams erdbrügger et al 2021 3 2 flow lengths elevations and slopes flow length elevation and slope parameters for runoff concentration and channel routing are available as pandas dataframe and arcgis pro polygon feature classes including joinable parameter tables comparing the resulting flow lengths based on pure raster calculations as all tools in table 1 use and with consideration of a fnw for 10 480 100 m raster model elements in eleven randomly chosen test catchments exhibits an elongation of flow lengths with a maximum of 13 mean 4 4 std 2 82 and rare shortenings up to 6 remarkably the elongation propagates stepwise with stream distance from the outlet especially where the water bodies meander neighbouring sub catchments can exhibit very different behaviour fig 17 fig 18 and fig 19 summarise the final flow length and slope values exemplarily concerning their spatial distribution and quantitatively with histograms summarising all 40 catchments for raster models the definitions dominate the flow length distribution for the different model element types and cause multiple distinct peaks while the association of model element types to topographic elements is dominant for the slope parameters the medians categorised for model element types s ro h 0 096 s ro t 0 143 s ch 0 073 reflect that headwater elements represent ridges and hilltops traversed elements ditches and small creeks in upper i e steeper valleys and channels lower i e flatter valley areas the minimum thresholds l 0 05 km and s 10 4 applied if users include the fnw for raster models parameter calculation users in the average have to decide manually for 0 37 of the model elements standard deviation 0 25 where l h or l l shall be assigned this number depends on the desired model resolution for subcatchment models fig 19 the medians of l ro h 2 17 km l ro t 1 41 km and l ch 0 89 km differ significantly while the standard deviations are in the same range l ro h 0 58 km l ro t 0 64 km l ch 0 54 km in comparison to raster models all flow length parameters have smooth distributions l ch is comparable for subcatchment and raster models considering their divergent element sizes 1 0 and 0 01 km2 respectively while l ro h and l ro t are approximately half for raster models the order of subcatchment models slope medians is s ch 0 009 s ro h 0 039 s ro t 0 047 the distributions show similar characteristics to those of raster models but their medians are generally smaller especially for s ch with almost one order of magnitude reflecting averaging due to larger model element sizes as a side note the comparison of the discrepancies between flow length and slope parameter distributions of different model types show impressively the discrepancies emerging from choosing different model types and resolutions 3 3 cross section geometries the proposed simple histogram based channel identification method reliably determines w ch bf in many cases as the following test illustrates from 505 cross sections in the example catchment ansbach size 130 km2 h bf ch was measured manually from z h for 101 randomly selected ones within arcgis using experts knowledge and compared to the algorithm s optimisation results the algorithm has underestimated 24 10 overestimated and 67 well defined 0 05 m exemplarily compared to the impressive hit rate of about 98 in choi and mantilla 2015 this seems very weak but the cited authors defined a horizontal deviation of 20 m as a hit which is not comparable to 0 05 m in height here the coefficient of determination proves an overall good fit to the manually determined values r2 0 81 the under and overestimated values nevertheless show that the channel fitting algorithm is heavily dependent on elevation histograms with a well defined histogram peak otherwise resulting in two significant issues on the one hand side there is a tendency towards underestimation of h bf ch if at least one floodplain is significantly lower than the river bank e g drained formerly swampy floodplains the algorithm assumes that the channel is the lowest point in the cross section profile to determine the first peak in the elevation histogram resulting in an underestimation of h bf ch see fig 20 left panel on the other hand the algorithm overestimates the channel depth if both floodplains are nearly as steep as the channel bank e g alpine creeks or if the banks slopes are gradually decreasing towards the floodplains because the algorithm will struggle to find any well defined peak in the elevation histogram see fig 20 right panel the gradient usually decreases with increasing height resulting in overestimated h bf ch and w ch values for completeness the algorithm will fail of course if the cross section does not comprise any channel single cross sections apply for raster model elements wherefore the quality of cross sections is of central importance for good quality simulation results during the testing phase it has turned out that δl ch cs 2d r is expedient to cover the fnw and at the same time leave a margin to be flexible during manual adjustment of cross sections positions therefore for low model resolutions δl ch cs is large compared to hydraulic 1d modelling samuels 1990 castellarin et al 2009 additionally it is practical to choose l cs and δz max large enough as the correction algorithms crop the original cross section see example scene in fig 21 pilotti et al 2011 propose l cs as several hundreds of metres orthogonal to the watercourse in complex bathymetry of mountain valleys indicating that it should be even more significant for flat regions the resulting gms parameters are satisfactory in most cases still there are some limitations fig 22 δh is at or even beyond the measurement precision of z h within channels and agriculture uses the analysed area intensively tending to either enlarge erosion protection or bury drainage such small creeks therefore the cluster of h bf ch close to δh seems unrealistic furthermore outliers of w bf ch 30 m indicate some poor channel delineation as the analysed densely settled catchments are maximum 160 km2 in size and w bf ch of the significant rivers is less than 30 m at the catchments outlets nevertheless h bf ch and w bf ch are generally more realistic than the results obtained from dhg which are about one decimal power too small for subcatchment models averaged multiple cross sections determine the required ttp parameters an example shows fig 23 while fig 24 summarises the parameter ranges the parameter distributions fit well to the expected ranges of small to medium sized catchments within a hilly landscape the definition of the ttp has two significant restrictions first the floodplains have to be horizontal s fp 0 this assumption remains preferably valid at streams with large catchments the test catchments are small in these terms wherefore w fp l and w fp r are often set close to the minimum 0 01 m compensating for this with flat but not horizontal forelands e g left floodplain in fig 23 only a few cross sections show significant horizontal floodplains within the analysed catchments the second restriction is that negative slope values within the ttp are not allowed therefore one has to mention that besides the uncertainties through discretisation and averaging this method cannot reflect linear structures or flow barriers within the cross section finally the parameter distributions emphasise restrictions of the tested dhg formula as these significantly underestimate channel widths and depths and the width of flood plains and forelands that leads to the conclusion that using these tested dhg formulas for simulation in bavarian upstream catchments will probably lead to underestimating channels flow capacity and velocity and overestimating flow time 3 4 parameters for runoff generation tatoo functions of runoff generation focus on the intersection of the readily prepared input parameter files of land use impervious share and soil with the model elements and the subsequent grouping process of hrus to grus the grouping reduces the number of features by about one order of magnitude fig 25 shortening the simulation time significantly 3 5 computational performance and remaining manual working time with tatoo users can implement very detailed spatial information in mesoscale ihms quickly generally the algorithms calculation times strongly depend on the created model the catchment size the resolution of the input data e g z h the computational environment and the user s knowledge concerning the model and pre processor as well as the remaining effort of the user s manual corrections a calculation example imagine a larsim model grid of 100 m for a 100 km2 catchment using a dem with 1 m resolution resulting in 10 000 model elements with six physical cores 3 6 ghz and 32 gb ram and without user intervention it takes about 30 min computational time to complete all necessary algorithms for the raster example including cross sections assuming a perimeter of 60 km a fnw length of 150 km and 300 cross sections the user might need an additional 130 min to complete the corrections see fig 26 thus the overall time for the described raster setup is about 2 3 h using tatoo while the manual efforts dominate the raster model setup this relation is reversed for subcatchment models as their preprocessing only needs two manual steps with a few minutes of manual working time the overall needed time for the mentioned model setup example with desired subcatchments of 1 0 km2 is approximately 30 min using arcpy from arcgis pro version 2 5 the most costly step in calculation time is the calculation of l h as it is not parallelised yet the functions prepr routing rasters for raster models and calc params for subcatchment setups need the arcpy flow length algorithm as esri showed significant engagement in recent releases to parallelise more and more tools the calculation time of tatoo might decrease even further in future the transformation to foss software could speed up the calculations as well for example by replacing the arcpy flowlength function with grass or saga tools 3 6 relevance for various model types subjects and scales there are several possibilities to apply the tatoo library beyond its target group of particular interest for integration in ongoing works are initiatives to calculate store and share standardized geospatial catchment or river reach information and therefore save computational expenses for every single modeller such databases are available for australia geofabric au bom 2015 and stein et al 2014 the united states of america nhdplus moore and dewald 2016 and moore et al 2019 streamcat hill et al 2016 the european union ecrins eea 2012 and jager and vogt 2010 eu hydro gallaun et al 2019 and even near global hydrosheds lehner et al 2008 and lehner and grill 2013 hydroatlas linke et al 2019 domisch et al 2015 the latter is particularly promising as they provide a clear perspective toward an open and integrated standard for topographical parameters meanwhile the most sophisticated initiatives geophabric streamcat eu hydro and hydroatlas provide hundreds of different parameters for millions of subcatchments a further increase of globally available homogeneous dem resolution from usually used few arc seconds towards few meters is foreseeable it makes an application of some tatoo functions on a continental or even global scale imaginable e g to provide pre calculated channel and foreland geometries for each river segment especially the integration with hydroatlas seems promising as its highest level of detail in the average of 130 6 km2 catchment area and 4 2 km river segment length fits the scale tatoo can easily handle with a 1 m dem to improve the fnw quality see concerns in linke et al 2019 with little manual work as input for tatoo recently developed deep learning techniques might worthful mao et al 2021 generally water related fields relying on a high level of topographic details stemming from a large amount of dem data often through a combination of high resolution and large area from catchment to continental scales may also benefit from tatoo here are some examples certainly studies performing hydrological and one dimensional hydrodynamic modelling such as flood risk and climate change adaptation and resilience studies e g springer et al 2020 or hattermann et al 2018 are promising candidates furthermore other water related scientific fields such as sediment e g vigiak et al 2017 habitat e g domisch et al 2015 and ecosystem service studies e g review for the danube river basin in perosa et al 2021 could benefit as well finally besides modelling deep learning and artificial intelligence algorithms can be applied to many detailed parameters tatoo can produce 4 conclusions tatoo is a python 3 6 library loosely coupled with arcgis pro 2 5 that contains functions to set up integrated hydrological models ihms the functionalities cover the whole spatially related setup process elaborated and documented using detailed exemplary workflows for the larsim the new functionalities focus on using recent high resolution dem data supported by fnw features precisely on the one hand users can delineate raster and subcatchment model structures and files automatically and efficiently within a short time while still considering specific needs as e g model resolution or subcatchment sizes on the other tatoo includes new methods to consider high resolution dem data in integrated hydrological models highlighted by the efficient incorporation of cross section information in both model structures i showed that the python 3 6 functions interacting with arcgis pro 2 5 produce reliable parameter distributions for raster and subcatchment model architectures and are very efficient in manual and computational working time when applying them to 40 german catchments concerning the model assumptions e g static model network scale limitations and empiric formula i chose the methodology and it architecture to my best conscience nonetheless many recent implementable developments would complement the work done so far such as hybrid flow enforcement algorithm lindsay 2016a and the topologicalbreachburn method lindsay 2016b pem4pit a physically based method for removing pits in dems grimaldi et al 2007 distance transform optimisation to correct for the orthogonal and diagonal flow length steps butt and maragos 1998 or smith 2004 2d dimensional flow schemes in integrated hydrological models e g schulla 2019 non planar or dog legged cross sections petikas et al 2020 and automatic strickler value determination along cross sections choi and mantilla 2015 furthermore someone could integrate recently developed object based hydrological model engines such as echse kneis 2015 online repositories e g hydroshare other processing environments e g cuahsi jupyter hub and cybergis jupyter and model apis as pysumma e g leonard and duffy 2013 vice versa tatoo could be integrated into an available web based gis environment chen et al 2020 or global hydro database linke et al 2019 tatoo also covers only some available methods in larsim so one could further extend the range of functions and of course build model setup routines for other models on top of the presented packages finally replacing the closed source and commercial arcpy with foss4g alternatives would make tatoo applicable to a broader community overall using tatoo modellers can accelerate the setup process of several detailed ihms significantly while the additionally proposed workflows are especially useful for the larsim community their application will enable profound well documented and enhanced analysis requiring many different catchments models or setups as model comparison or scale studies regionalisation of model parameters and extreme value analysis supplementary files the documentation of the described functionalities is three fold to fulfil the needs of reproducibility 1 self explaining documentation within the code with an overview in each function header and in line line by line documentation of the code 2 explanations for application of tatoo within the exemplary workflow scripts 3 a reproducible showcase based on downloadable data the showcase can serve as a demonstrator for both the raster and subcatchment functionalities of tatoo with a real case eight km2 tributary of lower bavaria in southern germany including a 1 m dem that enables users to try and review the workflows under controlled conditions code examples and documentation are available online at the tatoo project in the open science framework https doi org 10 17605 osf io gahju program and computing requirements arcgis pro version 2 5 or newer https pro arcgis com en pro app latest arcpy get started what is arcpy htm mandatory will include python 3 along with the arcpy package for application of existing workflows larsim version 1040 or newer https www larsim info en the model software availability the first open source tatoo release is available from 2021 on the platform open science framework https doi org 10 17605 osf io gahju including an integrated github versioning in zenodo https zenodo org record 5229292 available downloads include the libraries 1 mb english example workflows 3 mb and a test dataset 0 4 gb the python 3 6 library requires the arcpy library of esri arcgis pro version 2 5 and standard open source packages e g numpy there are no specific requirements for the hardware declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements research funded by the bavarian state ministry of the environment and consumer protection the bavarian environmental agency bayerisches landesamt für umwelt lfu and the bavarian agency for digitisation high speed internet and surveying landesamt für digitalisierung breitband und vermessung lfdbv kindly provide the support and test case data i would like to thank prof dr ing markus disse with the technical university of munich and prof dr ralf ludwig with the ludwig maximilians universität munich for their support and guidance during the development and two anonymous reviewers for their timely and insightful colleague reviews all data used in the analysis and supporting the conclusions in this manuscript can be obtained from the technical university of munich e mail johannes mitterer tum de any trade firm or product name is for descriptive purposes only and does not imply endorsement by the bavarian government appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105406 
