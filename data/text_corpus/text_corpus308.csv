index,text
1540,mesh grid based methods such as the finite element method fem and finite difference method fdm are extensively used for simulation of contaminant species transport in groundwater however these methods in their standard form are susceptible to instabilities such as oscillations and numerical dispersion in the solution further due to the use of mesh grid these methods are also computationally expensive in this study a meshfree method named radial point collocation method rpcm is demonstrated for simulating reactive transport involving linked first order reactions in a coupled flow environment multiquadrics radial basis functions mq rbf are used for approximation of the state variables the model uses local support domains which produce sparse matrix systems that efficiently deal with the ill conditioning problem which generally occurs while using global support domains the model developed is verified against the semi analytical solutions and its performance is compared with fem for case studies it is observed that the model provides accurate solutions for the problems considered and also handles advective flow conditions better than fem the proposed model successfully simulates the fate of contaminants in linked chain reactions graphical abstract unlabelled image keywords contamination meshfree modelling point collocation method linked first order multispecies reaction radial basis function 1 introduction simple or complex first order reaction networks consisting of parent daughter species system are frequently observed in the sub surface environment in the course of the reaction pathway the parent species degrade and daughter species are produced in succession decay chains are examples of simple networks radionuclide species chlorinated solvents nitrogenous species etc undergo such type of reaction quezada et al 2004 on the other hand in a complex connected pathway daughter species may have several parents and vice versa in both cases the rate of production of a species depends on the rate of degradation of its parent species some well known sources of contamination include insecticides pesticides from agriculture storage facilities in industries and nuclear power plants organic waste from septic tanks and landfills etc through which the contaminants enter the groundwater aquifer batu 2005 further these are transported through a spatially variable flow field through advection and dispersion processes modelling the fate of the contaminants is crucial as the contaminants have several adverse effects on the environment moreover the models can also be used to take precautionary steps design the release from sources and remediation of a contaminated aquifer the flow and transport process in groundwater are represented mathematically using partial differential equations pdes bear and cheng 2010 a number of analytical and semi analytical models have been developed to solve the transport of connected first order decay reactions quezada et al 2004 suk 2016 sun et al 1999 wang and neville 2019 however these solutions assume the flow fields to be unidirectional in field conditions the flow field is affected by heterogeneity and anisotropy of the aquifer medium apart from that presence of sources sinks such as injection pumping well recharge ponds and drains as well as boundary conditions alter the flow direction in an aquifer development of numerical models has enabled to handle such nonuniformity and complex reactions fdm and fem are most popular numerical techniques used to solve groundwater related problems rastogi 2007 bear and cheng 2010 seyedpour et al 2019b these methods discretize the problem domain using grid mesh consisting of interconnected nodes some disadvantages due to the use of mesh include the requirement of high computational effort the need for re meshing etc liu and gu 2005 additionally these methods are susceptible to instabilities such as numerical dispersion and artificial oscillation while solving the transport problems hirsch 2007 patankar 1980 operator splitting is a technique which is often used to handle such an issue besides it is also used for handling reactions in the mesh grid based models clement et al 1998 due to the above reasons meshfree methods are being developed in order to eliminate the mesh and mesh related issues some examples of application of these methods to contaminant transport problems are smooth particle hydrodynamics sph herrera et al 2009 meshless petrov galerkin mlpg boddula and eldho 2017 random walk particle tracking majumder and eldho 2017 2019 radial point interpolation method rpim praveen kumar and dodagoudar 2008 radial point collocation method rpcm anshuman et al 2019 meenal and eldho 2012 singh et al 2016 dehghan and abbaszadeh 2018d used a combined moving kriging interpolation and element free galerkin method for groundwater and other water science related problems ilati and dehghan 2016 applied four local weak form based meshless models for groundwater aquifer remediation problem however the solute type in most of these studies is conservative and some studies involve reactive type solute involving single species rpcm is a strong form meshfree method which uses local support domain around each node for the approximation of the state variable head or concentration using rbfs liu and gu 2005 multiquadrics rbf mq rbf is used in this study owing to its high convergence and successful application in numerous groundwater studies hardy 1971 developed mq rbfs for the approximation of irregular surfaces later kansa developed a method to solve pdes using mq rbfs and global support domain kansa 1990a 1990b however using global support domain renders ill conditioned global matrices which are not desirable liu and gu 2005 to overcome the issue local support domains are used which produce sparse global matrices coupled flow and transport problem was solved by rectangular meenal and eldho 2012 and circular shaped support domains singh et al 2016 dehghan and abbaszadeh 2018b introduced a space splitting based local rbf collocation method for solving equations involving mass conservation laws dehghan and abbaszadeh 2017 used proper orthogonal decomposition to rbf finite difference for shallow water models further a proper orthogonal decomposition discrete empirical interpolation method along with local rbf differential quadrature approach for prevention of groundwater contamination which reduces the computational time dehghan and abbaszadeh 2018a seyedpour et al 2019a developed an mq rbf based model for contaminant remediation problem and validated the model with experimental results using a physical sandbox model anshuman et al 2019 developed a reactive transport model for simulating first order decay and linear adsorption reaction in porous media as mentioned above the rpcm meshfree method has many advantages however the application of rpcm model is tested for first order decay and linear adsorption reaction involving single species the current study aims to develop and apply the rpcm model for linked first order reactions involving multiple species in a coupled flow environment the 1d model developed is compared with semi analytical solutions for different seepage velocities and dispersion coefficients in the case studies 1d and 2d models are compared with fem model simulations for homogenous and heterogeneous aquifers the simulation patterns obtained from rpcm and fem model are observed to be in good agreement with each other 2 methodology 2 1 governing equations and boundary conditions the governing equation for flow at steady state in a 2d heterogeneous and anisotropic confined aquifer is given by eq 1 bear and cheng 2010 1 x t x h x y t y h y q w δ x x i y y i 0 x y ω where t x and t y are transmissivities in x and y directions ω is the problem domain q w represents the sources sinks and δ is the kronecker delta function the distribution of the head in the aquifer can be estimated by solving eq 1 along with boundary conditions the dirichlet and neumann boundary conditions applied at the specified head boundary and specified flux boundary are given by eqs 2 and 3 respectively 2 h x y t h 0 x y ω 1 3 t h n q 0 x y ω 2 here h 0 and q 0 are known head and flux values along the boundaries ω1 and ω2 respectively the term n is the direction normal to the plane of the boundary the magnitude and direction of the velocity field are computed from the head distribution using darcy s law as follows bear and cheng 2010 4 v x k x n e h x v y k y n e h y where k x and k y are coefficients of permeability in x and y directions and n e is the porosity of the medium the transport of contaminant species c in a porous medium due to advection dispersion and the reaction in the problem domain ω is governed by eq 5 the current study assumes that the groundwater temperature is constant throughout the aquifer and therefore the effect of temperature on contaminant transport is neglected the reaction considered here includes linear adsorption and first order degradation 5 r c c t x d xx c x y d yy c y v x c x v y c y r c λc n e qc n e δ x x i y y i x y ω where d xx and d yy are dispersion coefficients are estimated from velocity field see eq 4 and dispersivities α l and α t as shown in eq 6 rastogi 2007 the term v refers to the magnitude of resultant seepage velocity 6 d xx α l v x 2 α t v y 2 v d yy α l v y 2 α t v x 2 v the term r c is known as the retardation factor which represents the linear adsorption process and given as rastogi 2007 7 r c 1 ρ b k d n e where ρ b n e and k d denote the bulk density of soil porosity of the medium and distribution coefficient respectively the degradation of the contaminant is represented by a first order reaction rate λ the term q and c represent solute injection rate and concentration of injected solute respectively in this study the transport process of a linked first order reaction is studied in this type of reaction a particular species in the sequence may have multiple parents and multiple daughters the contribution of each parent to its daughter species acts as a source term for the latter considering this phenomenon the eq 5 can be modified for the transport of species c in a sequence as shown in eq 8 bauer et al 2001 8 r c c t x d xx c x y d yy c y v x c x v y c y rλc n e qc n e δ x x i y y i j 1 p b j λ j c j n e the terms with subscript j represent the contribution from p number of parent species in the case of multiple daughters the fraction of contribution from the parent species is denoted by branching coefficient b along with the governing equations the following initial and boundary conditions are also applied at suitable boundaries 9 c x y t 0 0 x y ω initial condition 10 c x y t c 0 x y ω 1 dirichlet b c 11 d xx c x n x d yy c y n y f x y ω 2 neumann b c where c 0 concentration along the specified concentration boundary f flux along the specified flux boundary n x n y components of the outward normal unit vector 2 2 radial point collocation method in rpcm the state variable u x can be approximated at point of interest x as follows dehghan et al 2016 dehghan and haghjoo saniji 2017 liu and gu 2005 12 u x i 1 n r i x a i j 1 m p j x b j r t a p t b here r is the radial basis function rbf p is the polynomial basis function pbf a and b are unknown coefficients the term n and m refers to the number of rbfs and pbfs respectively the unknown coefficients a and b are determined using a local support domain around each node each local support domain contains n nodes by enforcing eq 12 at these n nodes a system of n linear equations is formed these equations in matrix form are presented as follows 13 u r a p b the matrix r is represented as follows 14 r r r 11 r r 1 n r r n 1 r r nn here r r ij are radial basis terms and r ij is the radial distance from point of interest i to node j in this study mq rbf has been used due to their high accuracy and successful applications to groundwater problems meenal and eldho 2012 singh et al 2016 anshuman et al 2019 it is given by eq 14 15 r r ij r ij 2 c s 2 q the terms c s and q are the mq rbf shape parameters further the following constraint conditions can be used in order to obtain a set of m equations liu and gu 2005 16 i 1 n p j x a p t a j 1 2 m the eqs 13 and 16 can be combined in the following form 17 û u 0 r p p t 0 a b g a b the unknown coefficients a and b are estimated as follows 18 a b g 1 û these coefficients are substituted in eq 12 to obtain the following 19 u x r t p t g 1 û ϕ û here ϕ values are known as shape function values in this study only mq rbfs are used to estimate the shape function values hence the polynomial terms p in eq 12 17 and 19 are not used the directional derivatives of ϕ i e ϕ x ϕ y 2 ϕ x 2 and 2 ϕ y 2 can be estimated in a similar way by replacing the corresponding derivatives of mq rbf r in eq 19 however the matrix g is unaltered in coupled flow and transport problem the state variables are head and concentrations of the species for example the head values h and concentration values c for node k can be represented using the shape function values ϕ 20 h k i 1 n ϕ i h i 21 c k i 1 n ϕ i c i after approximation of shape functions and directional derivatives these values are stored in n n matrix form where n is the total number of nodes in the problem domain the k1 k2 k3 k4 and k5 matrices are formed for ϕ ϕ x ϕ y 2 ϕ x 2 and 2 ϕ y 2 terms respectively the matrices obtained are sparse in nature owing to the use of local support domains the governing equations and boundary conditions discussed in section 2 1 are discretized using point collocation technique for node i the governing eq 1 and boundary conditions 2 and 3 are discretized as follows 22 a t x i k 3 i t y i k 4 i h i q i 22 b k 1 i h i h 0 22 c t x i n x i k 2 i t y i n y i k 3 i h i q 0 where n x and n y are direction component here i represents the row of corresponding vectors and matrices the concentration term c in the governing eqs 5 and 8 for contaminant transport is discretized using a semi implicit scheme as shown in eq 23 rastogi 2007 23 c θ c t δ t 1 θ c t here c t is the concentration of species at time instant t and δt is the time step used in the rpcm model for this study the value of θ is fixed as 1 2 substituting eq 23 in eq 5 governing equation for i th node is expressed as eq 24 24 r c c i t δ t θδt d x x i 2 c i t δ t x 2 d y y i 2 c i t δ t y 2 v x i c i t δ t x v y i c i t δ t i y λc i t δ t r c c i t 1 θ δ t d x x i 2 c i t x 2 d y y i 2 c i t y 2 v x i c i t x v y i c i t y λ c i t q w c i θδ t in linked first order reactions the contribution from parent p can be implemented as follows 25 r c c i t δ t θδt d x x i 2 c i t δ t x 2 d y y i 2 c i t δ t y 2 v x i c i t δ t x v y i c i t δ t i y λc i t δ t r c c i t 1 θ δ t d x x i 2 c i t x 2 d y y i 2 c i t y 2 v x i c i t x v y i c i t y λ c i t q w c i θδ t λ p c p i δt here c p t is the concentration of parent p at time t whereas λ p is the corresponding decay rate using the values of shape function and its derivatives the eq 25 is discretized as 26 r c k 1 i θδt d x x i k 4 i d y y i k 5 i v x i k 2 i v y i k 3 i λ c k 1 i c i t δ t r c k 1 i 1 θ δt d x x i k 4 i d y y i k 5 i v x i k 2 i v y i k 3 i λ c k 1 i c i t θ δ t q w c i λ p δt p j t similarly the applicable boundary conditions see eqs 10 and 11 can be implemented at boundary nodes by eq 27 27a k 1 i c i c 0 27b d xx i n x i k 2 i d yy i n y i k 3 i c i f note that the computation of matrices containing the values of shape function and its derivatives is done only in the beginning the same matrices are used for solving the system of equations for head and concentrations of different species 3 model verification and numerical analysis 3 1 verification with semi analytical solution in this problem the rpcm model is compared to a semi analytical solution named decay wang and neville 2019 a 1d domain of 2000 m is considered fig 1 a with an initial condition of zero concentration the continuous contamination source for species 1 is located at the left boundary the reaction pathway for the problem has 4 levels see fig 1 b level 1 2 and 4 consist of species 1 2 and 5 respectively level 3 consists of species 3 and 4 which have common parent 2 and common daughter 5 the concentration of species 1 is maintained as c0 100 ppm at the source location the concentrations of other species at this location are set to zero these chemical species exhibit linear adsorption and first order decay reactions the characteristics of the species are listed in table 1 the initial condition is given as 28 for i t h species at t 0 c i 0 x y 0 x y ω the rpcm transport model is developed by using 201 nodes with nodal distance dc of 10 m the simulation period is 3000 days with a time step of 10 days the mq rbf shape parameters are q 0 98 and c s 5 dc the radius of the local support domain is 5 dc the simulation times for the models are approximately 11 s using a pc specification of core i7 6770 3 40 ghz cpu and 16 gb ram the model is verified against the semi analytical code decay wang and neville 2019 for different values of seepage velocity and dispersion coefficient see fig 2 the result obtained by the model is observed to agree well with the semi analytical solutions for different flow and transport conditions it is observed that the concentration profile is the steepest for species 1 i e the concentration front is sharper than other species in the network a part of the parent species converts into the daughter species and the contribution added as a source term hence the sources for the species which are created later in the reaction network are dispersed compared to the point source in case of species 1 due to this reason the concentration profile tends to be flatter for a species which is created later in a network the following error indicators are used for quantifying the model accuracy with varying flow and transport parameters 29 mean absolute error mae i 1 n c i exact c i num n 30 root mean square error rmse i 1 n c i exact c i num 2 n 31 maximum point error mpe max c i exact c i num here the superscript exact and num refer to the simulated concentrations obtained by semi analytical method decay and proposed rpcm model respectively the peclet number pe which is used as a measure of advection is given by 32 pe v x d here δx is the nodal distance dc used in the model the errors for different cases are presented in table 2 as observed in table 2 the peclet number pe is increased gradually by increasing the velocity v for first 3 cases and similarly it is increased from case 4 6 by decreasing the dispersion coefficient d it is observed that errors obtained for species 1 are the highest for every case except case 4 and the corresponding magnitudes decrease with increase in level in the reaction pathway the errors are observed to increase more rapidly when velocity is increased for case 1 3 compared to case 4 6 where dispersion coefficient is decreased gradually the maximum values of errors are observed for case 3 for species 1 therefore the velocity has more impact on model performance compared to dispersion coefficient nevertheless the maximum values of mae mpe and rmse are 0 145 3 836 and 0 578 which indicates the model performance can be considered to be accurate 3 2 numerical analyses as observed in eq 15 the mq rbf has two shape parameters namely c s and q the choice of mq rbf shape parameters q and c s are crucial as the accuracy of the simulations depends on their values liu and gu 2005 suggested the values of q be fixed as 0 98 or 1 03 for fluid flow and solid problems the parameter c s is a free parameter and generally represented as multiples of nodal distance dc the sensitivity of the parameter c s is analyzed extensively in the literature anshuman et al 2019 singh et al 2016 in the present study the parameter c s is fixed as 5 dc as satisfactory results are reported for 1d and 2d groundwater problems here stability and convergence of the time discretisation are analyzed furthermore the effect of size of local support domain on model simulation is studied 3 2 1 stability of time discretisation the proposed rpcm model uses a semi implicit formulation which depends on the temporal weighting parameter θ as shown in eq 24 and 25 when θ 1 the method is known as implicit method for fdm the simulation becomes unconditionally stable when θ 1 2 similarly for implicit method is found to be unconditionally stable for element free galerkin method dehghan and abbaszadeh 2018c rpcm based contaminant transport model with θ 1 2 becomes unstable in case of high pe problems anshuman et al 2019 singh et al 2016 here the earlier problem discussed in section 3 1 is considered for assessment for model performance for different θ values i e θ 1 2 2 3 and 1 the seepage velocity is fixed as 1 5 m d the dispersion coefficient is taken as 1 5 m2 d and 0 1 m2 d for case a and case b which correspond to pe 10 and pe 150 respectively the results obtained are plotted in fig 3 it is observed that the model simulation is stable for θ 1 2 2 3 and 1 for case a it matches closely with the semi analytical solution when θ 1 2 however for case a while numerical dispersion is observed when θ is increased the model simulation for species 1 is unstable near the concentration front for high advection case b when θ 1 2 nevertheless the concentration profiles for the remaining species are stable on the other hand numerical dispersion is significant for θ 2 3 and 1 although stable simulations are observed the error indicators are presented for case a and b in tables 3 and 4 respectively it is observed that the error in model simulations are least when θ 1 2 for most of the species it is important to note that the stability of the model for high advection problems can be improved by employing upwinding techniques liu and gu 2005 3 2 2 convergence of time discretisation here the proposed model is tested for different time steps in order to analyze the convergence of the time discretisation the problem from section 3 1 is considered with velocity 1 5 m d and dispersion coefficient 1 5m2 d respectively the model is run for time step size δt 30 d 15d 10d 7 5d 2d and 1d the rest of the model parameters are kept same as problem discussed in section 3 1 the mae values are computed against semi analytical solution as shown in fig 4 it is observed that the errors in simulation decreases and becomes constant as the time step δt is refined this also indicates that the time discretisation used in the proposed model eqs 24 and 25 is convergent the variation of cpu time with respect to δt is presented in table 5 it is observed that the relative cpu time decreases almost linearly with respect to increase in time step δt 3 2 3 model stability with respect to local support domain the local support domain plays an important role in the model simulation by enhancing the size of support domain the model simulation stabilizes in case of high advective flows singh et al 2016 further model simulations involving high reaction rates can also be stabilized by increasing the support domain size anshuman et al 2019 here the effect of support domain on stability of the simulation of different species in a linked first order reaction is studied the problem from section 3 1 is considered with velocity 1 5 m d and dispersion coefficient 0 25 m2 d the model is tested for support domain radii 2 d c and 5 d c the remaining parameters are considered to be same as in section 3 1 due to low value of dispersion coefficient d the problem is advection dominant with pe 60 the model simulation with support domain size 2 d c shows oscillations near the concentration front for species 1 fig 5 however the oscillations are stabilized to a great extent when the support domain size is increased to 5 d c on the other hand the simulations of daughter species 2 5 are observed to be stable for both support domain sizes as they are created from corresponding parent species which are already dispersed in the domain the mae values computed against semi analytical solution is presented in table 6 it is observed that mae value is higher for species 1 when support domain size is 2 d c nevertheless for remaining species mae values are almost identical for both support domain sizes moreover there is little impact on cpu time due to increasing support domain size however this impact can be higher when dimensionality of the problem increases due to significant increase in number of nodes for computation of shape function and derivatives for groundwater contaminant transport problems satisfactory results are obtained when support domain size is varied between 3 d c to 5 d c anshuman et al 2019 singh et al 2016 4 model applications 4 1 case study 1 in this section the rpcm model performance is compared with that of fem the problem discussed in section 3 1 is considered two cases are considered with velocities 1 m d and 2 m d respectively the dispersion coefficient is 1 m2 d for the first case pe is 10 and for the higher advective case pe is 20 the fem model developed in comsol consists of 201 nodes and 200 elements both models are simulated for 3000 days with a time step of 3 days the remaining problem variables and rpcm model parameters are the same as given in section 3 1 the results obtained are plotted in fig 6 the error indicators computed against the semi analytical code decay wang and neville 2019 are higher for fem compared to that of rpcm see tables 7 and 8 it is observed that both models produce similar concentration profiles for the first case see fig 6 a for more advective case i e pe 20 high oscillations are observed near the concentration front obtained by fem for species 1 and 2 it is observed that in higher advective case fem model shows oscillations for species 1 and 2 the decrease in oscillations is attributed to the flatter concentration profiles of subsequent species on the other hand the rpcm model simulations are free from oscillations for all species the cpu time for the rpcm model is 11 25 s it is important to note that comsol software implements re meshing in order to produce stable simulation by refining the mesh at each time step due to this reason the cpu time for fem model is 60 s hence it can be stated that the proposed model handles the problem in a better way compared to fem model 4 2 case study 2 in this section the coupled rpcm 2d model is applied to a hypothetical confined aquifer as shown in fig 7 the aquifer dimensions are 300 m 100 m the north boundary is considered to be impervious the head along the west boundary south boundary and east boundary vary linearly from 21 m to 20 m 20 m to 19 m and 19 m to 18 m respectively the thickness of the aquifer is 10 m the flow in the aquifer is assumed to be in steady state the contaminant source for chemical species 1 is assumed to be located along the west boundary between 0 m 60 m and 0 100 m see fig 7a the reaction pathway followed by species 1 is presented in fig 7b the characteristics of the contaminant species are presented in table 9 the aquifer material is assumed to be homogenous and isotropic the hydraulic conductivity and porosity of the aquifer are 2 5 m d and 0 3 respectively the longitudinal and lateral dispersivities α l and α t are fixed as 0 5 m the coupled rpcm model is developed using 1281 nodes with nodal distance dc of 5 m respectively the radius of the local support domain is 3 dc the mq rbf shape parameters are q 0 98 and cs 5 dc the fem model having very fine mesh is developed in comsol and used to estimate the model performance the fem model consists of 23 829 interconnected nodes forming triangular elements based on the boundary conditions for the flow component of the model specified head or dirichlet boundary condition is applied at the west south and east boundary whereas neumann condition with zero flux is applicable to the north boundary the result obtained from the flow simulation is presented in fig 8 it is observed that the head contours obtained by rpcm model match well with that of fem for the transport models the west boundary is considered to be dirichlet boundary and in the remaining boundaries neumann boundary condition is applied the initial condition is given by for 1st species at t 0 33 a c 10 x y 250 ppm 50 m x 75 m 50 m y 75 m 0 ppm otherwise for 3rd species at t 0 33 b c 30 x y 100 ppm 120 m x 140 m 40 m y 60 m 0 ppm otherwise 33 c for remaining species at t 0 c i 0 x y 0 x y ω the simulation period of the models is 365 days with a time step of 5 days the spread of contaminants in the aquifer after 1 year as simulated by the models are presented in fig 9 the patterns of spreading of the contaminants match for both fem and rpcm however the slight difference in magnitude of concentration is noticeable the cpu times used by rpcm and fem models are 310 s and 213 s respectively in order to inspect the variation of concentration with respect to time the breakthrough curves are plotted for observation wells ob1 and ob2 located at 200 m 40 m and 220 m 60 m respectively from fig 10 it is observed that the concentration profiles obtained by both models are comparable due to the presence of spatially variable initial conditions the concentration profile for species 3 rises and falls with respect to time the error indicators mae and rmse are computed for rpcm against fem at ob1 and ob2 see table 10 the error values are high for species 1 and 3 at ob1 and ob2 it is due to the fact that the concentration profiles of the species are steep and the concentrations are of high magnitude however for species 2 4 and 5 the error values are lesser as the concentration profiles are relatively flatter compared to other species 4 3 case study 3 here a heterogeneous field aquifer of area 4 5 km2 is considered for the study the aquifer data used for is the study is adapted from singh et al 2016 the west to the north west boundary of the aquifer is encircled by a lake the remaining boundary is treated as a flux boundary the transmissivity of the aquifer is spatially varying and represented with 11 zones minimum zonal transmissivity is 30 m2 d while the maximum value approaches 170 m2 d there is an influx of water into the aquifer through the recharge zone as shown in fig 11 a these data are used to develop the flow models in rpcm and fem further in order to assess the performance of the reactive transport model a hypothetical scenario is assumed in which contaminant species 1 is injected in the aquifer through a source see fig 11 a the species 1 undergoes a decay chain reaction as shown in fig 11 b the characteristics of the contaminants are presented in table 11 the dispersivities α l and α t are assumed suitably to be 10 m the initial condition is given by for 1st species at t 0 34 a c 10 x y 1000 ppm 1240 m x 1339 2 m 813 2 m y 1027 2 m 0 ppm otherwise for 2nd species at t 0 34 b c 20 x y 100 ppm 1240 m x 1339 2 m 813 2 m y 1027 2 m 0 ppm otherwise 34 c for 3 rd species at t 0 c 30 x y 0 x y ω two rpcm based models are developed with uniform and non uniform rpcm nu nodal distributions respectively see fig 12 in uniform nodes based model the aquifer is represented using 1005 nodes with a nodal difference of δx 49 6 m and δy 42 8 m the same number of nodes is used in the non uniform node based rpcm model rpcm nu the mq rbf shape parameters q and c s are set as 0 98 and 5 dc respectively the size of the local support domain for rpcm model having uniform nodal distribution is fixed as 3 dc in the rpcm nu model local support domain size is computed using estimated area of the support domain and estimated number of nodes in local support domain liu and gu 2005 the fem model is developed using comsol with 5858 nodes with triangular elements dirichlet boundary condition is applied in the flow model for the nodes located at the north and west boundary see fig 11 a which is adjacent to the lake the remaining boundary is treated as a flux boundary the outward flux from this boundary is calibrated to be 6 1 10 5 m2 d using the observed head values singh et al 2016 the head distributions obtained from the fem and rpcm models are shown in fig 13 it is observed that the rpcm models produce similar head values in comparison to fem for both nodal distributions the simulated head values at randomly selected locations are presented in table 12 the absolute percentage difference is computed with respect to fem solutions at these locations it is observed that percentage difference obtained is lesser than 0 29 for rpcm models with different nodal configuration at the source location shown in fig 11 the contaminant species 1 is injected at 10 ppm day in the rpcm and fem transport models concentrations at the boundary are set to zero assuming no contaminant reaches the boundary during the simulation period of 3 years the time step used in both models is 5 days the results obtained at the end of the simulation period are plotted in fig 14 it is observed that the migration patterns of the contaminants are similar for rpcm and fem the concentration of the contaminant species at the end of the simulation period are presented in table 13 for randomly selected locations around the source it is observed that the simulations obtained by rpcm models are slightly higher than that of fem the rpcm model results for different nodal arrangements are also observed to be very close to each other the relative difference computed against fem simulation has the highest value of 0 44 for selected locations moreover the difference is lowest for species 1 and gradually increases at all locations the cpu time for both rpcm based models is approximately 71 s whereas for fem model in comsol it is 16 s 5 discussion in this study a new meshfree rpcm model is developed for simulating the fate of contaminants in linked first order reactions under coupled flow conditions the state variables for the problems are approximated using mq rbfs following which the governing equations and boundary conditions are solved the model uses local support domains for the approximation of shape functions and its derivatives hence the globally assembled matrix consisting of governing equations and boundary conditions are also sparse in nature this technique removes the ill conditionality which is often encountered in global support domains liu and gu 2005 the model developed is verified with a semi analytical solution decay wang and neville 2019 for a 5 species linked reaction with varying seepage velocities and dispersion coefficients furthermore the stability of the time discretisation is tested with respect to time weighting parameter θ it is observed that in the proposed method θ 0 5 gives oscillatory solution for first species near the concentration front when pe is increased to 150 on the other hand simulations are stabilized when the value of θ is increased to 2 3 and 1 however large amount of numerical dispersion is observed due to which errors obtained for these values are higher compared to that of proposed method θ 0 5 the time discretisation is also observed to be convergent when time step is gradually decreased from δt 30d to δt 1d the effect of support domain size is also studied for high advective case it is observed that the model simulations are stabilized when radius of support domain is enhanced the model performance is also compared with that of the fem model for the case studies in the 1d case the rpcm transport model performance is comparable to that of fem when pe 10 for more advective case pe 20 the fem model shows a high value of oscillations in the vicinity of concentration front for species 1 and 2 nevertheless concentration profiles gradually stabilize for remaining species due to the contribution from dispersed parent species in contrast the rpcm model yields oscillation free solutions for both cases and handles the steeper concentration front better than fem it should be noted that the comsol software implements re meshing in order to stabilize the concentration profiles comsol 2007 the rpcm 2d model performance is compared with fem for a homogenous and isotropic aquifer in coupled flow condition in case study 2 there is an excellent match between head distribution obtained by both models a spatially varying initial condition is used for species 1 and 3 although some differences are observed in concentration profiles at two observation wells ob1 and ob2 the mae and rmse values computed against fem are lesser than 5 66 and 6 812 respectively for species 1 this difference can be attributed to the structural differences between the two models in case study 3 transport of a 3 species decay chain in a heterogeneous field aquifer is simulated two rpcm models with different nodal arrangements are developed the head contours obtained by the fem and rpcm models are mostly similar a small difference in the magnitude of concentration obtained by fem and rpcm models is observed at the observation points around the source it is due to the fact that both models handle heterogeneity differently the fem comsol model relies on nodal connectivity and refines the mesh at zonal boundaries on the other hand in the rpcm models transmissivity values are assigned directly to the nodes however the rpcm models give close values for both types of nodal arrangements used due to the absence of mesh grid the rpcm model is more computationally efficient compared to fem it reduces the number of steps in the algorithm and eliminates the issue of re meshing apart from that the mesh refinement is also necessary in case of fem near the source sinks located inside the problem domain pepper and stephenson 1995 on the other hand the proposed rpcm model uses mq rbfs for the approximation of state variables which handles the presence of concentration gradients efficiently additionally the proposed model does not necessitate operator splitting which is commonly implemented in grid based methods for handling advection dispersion reaction and source sinks zheng and wang 1999 zienkiewicz et al 2005 the model handles advection and reaction terms by collecting the upstream information by using local support domain liu and gu 2005 by increasing the radius of local support domain the high advection and reaction rates can be handled anshuman et al 2019 singh et al 2016 nevertheless unlike rpcm this technique is not implemented easily in the grid based methods liu and gu 2005 from the comparison of cpu times it is observed that the time required for the proposed model is higher compared to that of fem or 2d models the reason for this is that the proposed model is developed in python using numpy package oliphant 2006 while the fem model developed in comsol which uses java programming language the computation in java is faster compared to python as it is a compiled language however python language is used in this study for faster development of code for the proposed problem the computation time can be improved using low level languages such as fortran although hypothetical chemical species are assumed as contaminants in this study the proposed model can easily accommodate contaminants which are frequently encountered in the field the characteristics of the contaminants e g dispersivities decay rates retardation factors etc can be provided for individual species in the reaction network 6 conclusions in this paper a new meshfree rpcm model is proposed for the transport of complex first order reaction networks branched series or complex connected networks can be easily handled by adding the contribution from parent species as a source term in the governing equation of daughter species the model uses mq rbf for the approximation of state variables and derivatives the governing equations and boundary conditions are solved using point collocation method the proposed model does not require operator splitting for handling reactions which are common in conventionally used grid mesh based methods moreover the use of local support domain helps to handle advection efficiently and eliminates the ill conditioning problem observed in the global support domains the effectiveness of the model in handling heterogeneity is also demonstrated in the study the aquifer parameters are directly assigned to the nodes unlike the grid mesh based methods which require refinement of grid meshes at the zone boundaries as the model is fully meshfree it eliminates the need for meshing and re meshing for transient problems due to its simplicity and accuracy rpcm based coupled flow and transport model can be effectively used for transport of complex first order reaction networks declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the board of research in nuclear sciences brns for providing support through the project modelling of reactive transport in groundwater using meshfree based numerical methods project no 16brns002 the authors also thank dr laishram guneshwor singh health physics division bhabha atomic research centre for providing the necessary data for the study the authors are thankful to the reviewers for their valuable comments which helped to improve the manuscript appendix a supplementary data model development steps image 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jconhyd 2019 103582 
1540,mesh grid based methods such as the finite element method fem and finite difference method fdm are extensively used for simulation of contaminant species transport in groundwater however these methods in their standard form are susceptible to instabilities such as oscillations and numerical dispersion in the solution further due to the use of mesh grid these methods are also computationally expensive in this study a meshfree method named radial point collocation method rpcm is demonstrated for simulating reactive transport involving linked first order reactions in a coupled flow environment multiquadrics radial basis functions mq rbf are used for approximation of the state variables the model uses local support domains which produce sparse matrix systems that efficiently deal with the ill conditioning problem which generally occurs while using global support domains the model developed is verified against the semi analytical solutions and its performance is compared with fem for case studies it is observed that the model provides accurate solutions for the problems considered and also handles advective flow conditions better than fem the proposed model successfully simulates the fate of contaminants in linked chain reactions graphical abstract unlabelled image keywords contamination meshfree modelling point collocation method linked first order multispecies reaction radial basis function 1 introduction simple or complex first order reaction networks consisting of parent daughter species system are frequently observed in the sub surface environment in the course of the reaction pathway the parent species degrade and daughter species are produced in succession decay chains are examples of simple networks radionuclide species chlorinated solvents nitrogenous species etc undergo such type of reaction quezada et al 2004 on the other hand in a complex connected pathway daughter species may have several parents and vice versa in both cases the rate of production of a species depends on the rate of degradation of its parent species some well known sources of contamination include insecticides pesticides from agriculture storage facilities in industries and nuclear power plants organic waste from septic tanks and landfills etc through which the contaminants enter the groundwater aquifer batu 2005 further these are transported through a spatially variable flow field through advection and dispersion processes modelling the fate of the contaminants is crucial as the contaminants have several adverse effects on the environment moreover the models can also be used to take precautionary steps design the release from sources and remediation of a contaminated aquifer the flow and transport process in groundwater are represented mathematically using partial differential equations pdes bear and cheng 2010 a number of analytical and semi analytical models have been developed to solve the transport of connected first order decay reactions quezada et al 2004 suk 2016 sun et al 1999 wang and neville 2019 however these solutions assume the flow fields to be unidirectional in field conditions the flow field is affected by heterogeneity and anisotropy of the aquifer medium apart from that presence of sources sinks such as injection pumping well recharge ponds and drains as well as boundary conditions alter the flow direction in an aquifer development of numerical models has enabled to handle such nonuniformity and complex reactions fdm and fem are most popular numerical techniques used to solve groundwater related problems rastogi 2007 bear and cheng 2010 seyedpour et al 2019b these methods discretize the problem domain using grid mesh consisting of interconnected nodes some disadvantages due to the use of mesh include the requirement of high computational effort the need for re meshing etc liu and gu 2005 additionally these methods are susceptible to instabilities such as numerical dispersion and artificial oscillation while solving the transport problems hirsch 2007 patankar 1980 operator splitting is a technique which is often used to handle such an issue besides it is also used for handling reactions in the mesh grid based models clement et al 1998 due to the above reasons meshfree methods are being developed in order to eliminate the mesh and mesh related issues some examples of application of these methods to contaminant transport problems are smooth particle hydrodynamics sph herrera et al 2009 meshless petrov galerkin mlpg boddula and eldho 2017 random walk particle tracking majumder and eldho 2017 2019 radial point interpolation method rpim praveen kumar and dodagoudar 2008 radial point collocation method rpcm anshuman et al 2019 meenal and eldho 2012 singh et al 2016 dehghan and abbaszadeh 2018d used a combined moving kriging interpolation and element free galerkin method for groundwater and other water science related problems ilati and dehghan 2016 applied four local weak form based meshless models for groundwater aquifer remediation problem however the solute type in most of these studies is conservative and some studies involve reactive type solute involving single species rpcm is a strong form meshfree method which uses local support domain around each node for the approximation of the state variable head or concentration using rbfs liu and gu 2005 multiquadrics rbf mq rbf is used in this study owing to its high convergence and successful application in numerous groundwater studies hardy 1971 developed mq rbfs for the approximation of irregular surfaces later kansa developed a method to solve pdes using mq rbfs and global support domain kansa 1990a 1990b however using global support domain renders ill conditioned global matrices which are not desirable liu and gu 2005 to overcome the issue local support domains are used which produce sparse global matrices coupled flow and transport problem was solved by rectangular meenal and eldho 2012 and circular shaped support domains singh et al 2016 dehghan and abbaszadeh 2018b introduced a space splitting based local rbf collocation method for solving equations involving mass conservation laws dehghan and abbaszadeh 2017 used proper orthogonal decomposition to rbf finite difference for shallow water models further a proper orthogonal decomposition discrete empirical interpolation method along with local rbf differential quadrature approach for prevention of groundwater contamination which reduces the computational time dehghan and abbaszadeh 2018a seyedpour et al 2019a developed an mq rbf based model for contaminant remediation problem and validated the model with experimental results using a physical sandbox model anshuman et al 2019 developed a reactive transport model for simulating first order decay and linear adsorption reaction in porous media as mentioned above the rpcm meshfree method has many advantages however the application of rpcm model is tested for first order decay and linear adsorption reaction involving single species the current study aims to develop and apply the rpcm model for linked first order reactions involving multiple species in a coupled flow environment the 1d model developed is compared with semi analytical solutions for different seepage velocities and dispersion coefficients in the case studies 1d and 2d models are compared with fem model simulations for homogenous and heterogeneous aquifers the simulation patterns obtained from rpcm and fem model are observed to be in good agreement with each other 2 methodology 2 1 governing equations and boundary conditions the governing equation for flow at steady state in a 2d heterogeneous and anisotropic confined aquifer is given by eq 1 bear and cheng 2010 1 x t x h x y t y h y q w δ x x i y y i 0 x y ω where t x and t y are transmissivities in x and y directions ω is the problem domain q w represents the sources sinks and δ is the kronecker delta function the distribution of the head in the aquifer can be estimated by solving eq 1 along with boundary conditions the dirichlet and neumann boundary conditions applied at the specified head boundary and specified flux boundary are given by eqs 2 and 3 respectively 2 h x y t h 0 x y ω 1 3 t h n q 0 x y ω 2 here h 0 and q 0 are known head and flux values along the boundaries ω1 and ω2 respectively the term n is the direction normal to the plane of the boundary the magnitude and direction of the velocity field are computed from the head distribution using darcy s law as follows bear and cheng 2010 4 v x k x n e h x v y k y n e h y where k x and k y are coefficients of permeability in x and y directions and n e is the porosity of the medium the transport of contaminant species c in a porous medium due to advection dispersion and the reaction in the problem domain ω is governed by eq 5 the current study assumes that the groundwater temperature is constant throughout the aquifer and therefore the effect of temperature on contaminant transport is neglected the reaction considered here includes linear adsorption and first order degradation 5 r c c t x d xx c x y d yy c y v x c x v y c y r c λc n e qc n e δ x x i y y i x y ω where d xx and d yy are dispersion coefficients are estimated from velocity field see eq 4 and dispersivities α l and α t as shown in eq 6 rastogi 2007 the term v refers to the magnitude of resultant seepage velocity 6 d xx α l v x 2 α t v y 2 v d yy α l v y 2 α t v x 2 v the term r c is known as the retardation factor which represents the linear adsorption process and given as rastogi 2007 7 r c 1 ρ b k d n e where ρ b n e and k d denote the bulk density of soil porosity of the medium and distribution coefficient respectively the degradation of the contaminant is represented by a first order reaction rate λ the term q and c represent solute injection rate and concentration of injected solute respectively in this study the transport process of a linked first order reaction is studied in this type of reaction a particular species in the sequence may have multiple parents and multiple daughters the contribution of each parent to its daughter species acts as a source term for the latter considering this phenomenon the eq 5 can be modified for the transport of species c in a sequence as shown in eq 8 bauer et al 2001 8 r c c t x d xx c x y d yy c y v x c x v y c y rλc n e qc n e δ x x i y y i j 1 p b j λ j c j n e the terms with subscript j represent the contribution from p number of parent species in the case of multiple daughters the fraction of contribution from the parent species is denoted by branching coefficient b along with the governing equations the following initial and boundary conditions are also applied at suitable boundaries 9 c x y t 0 0 x y ω initial condition 10 c x y t c 0 x y ω 1 dirichlet b c 11 d xx c x n x d yy c y n y f x y ω 2 neumann b c where c 0 concentration along the specified concentration boundary f flux along the specified flux boundary n x n y components of the outward normal unit vector 2 2 radial point collocation method in rpcm the state variable u x can be approximated at point of interest x as follows dehghan et al 2016 dehghan and haghjoo saniji 2017 liu and gu 2005 12 u x i 1 n r i x a i j 1 m p j x b j r t a p t b here r is the radial basis function rbf p is the polynomial basis function pbf a and b are unknown coefficients the term n and m refers to the number of rbfs and pbfs respectively the unknown coefficients a and b are determined using a local support domain around each node each local support domain contains n nodes by enforcing eq 12 at these n nodes a system of n linear equations is formed these equations in matrix form are presented as follows 13 u r a p b the matrix r is represented as follows 14 r r r 11 r r 1 n r r n 1 r r nn here r r ij are radial basis terms and r ij is the radial distance from point of interest i to node j in this study mq rbf has been used due to their high accuracy and successful applications to groundwater problems meenal and eldho 2012 singh et al 2016 anshuman et al 2019 it is given by eq 14 15 r r ij r ij 2 c s 2 q the terms c s and q are the mq rbf shape parameters further the following constraint conditions can be used in order to obtain a set of m equations liu and gu 2005 16 i 1 n p j x a p t a j 1 2 m the eqs 13 and 16 can be combined in the following form 17 û u 0 r p p t 0 a b g a b the unknown coefficients a and b are estimated as follows 18 a b g 1 û these coefficients are substituted in eq 12 to obtain the following 19 u x r t p t g 1 û ϕ û here ϕ values are known as shape function values in this study only mq rbfs are used to estimate the shape function values hence the polynomial terms p in eq 12 17 and 19 are not used the directional derivatives of ϕ i e ϕ x ϕ y 2 ϕ x 2 and 2 ϕ y 2 can be estimated in a similar way by replacing the corresponding derivatives of mq rbf r in eq 19 however the matrix g is unaltered in coupled flow and transport problem the state variables are head and concentrations of the species for example the head values h and concentration values c for node k can be represented using the shape function values ϕ 20 h k i 1 n ϕ i h i 21 c k i 1 n ϕ i c i after approximation of shape functions and directional derivatives these values are stored in n n matrix form where n is the total number of nodes in the problem domain the k1 k2 k3 k4 and k5 matrices are formed for ϕ ϕ x ϕ y 2 ϕ x 2 and 2 ϕ y 2 terms respectively the matrices obtained are sparse in nature owing to the use of local support domains the governing equations and boundary conditions discussed in section 2 1 are discretized using point collocation technique for node i the governing eq 1 and boundary conditions 2 and 3 are discretized as follows 22 a t x i k 3 i t y i k 4 i h i q i 22 b k 1 i h i h 0 22 c t x i n x i k 2 i t y i n y i k 3 i h i q 0 where n x and n y are direction component here i represents the row of corresponding vectors and matrices the concentration term c in the governing eqs 5 and 8 for contaminant transport is discretized using a semi implicit scheme as shown in eq 23 rastogi 2007 23 c θ c t δ t 1 θ c t here c t is the concentration of species at time instant t and δt is the time step used in the rpcm model for this study the value of θ is fixed as 1 2 substituting eq 23 in eq 5 governing equation for i th node is expressed as eq 24 24 r c c i t δ t θδt d x x i 2 c i t δ t x 2 d y y i 2 c i t δ t y 2 v x i c i t δ t x v y i c i t δ t i y λc i t δ t r c c i t 1 θ δ t d x x i 2 c i t x 2 d y y i 2 c i t y 2 v x i c i t x v y i c i t y λ c i t q w c i θδ t in linked first order reactions the contribution from parent p can be implemented as follows 25 r c c i t δ t θδt d x x i 2 c i t δ t x 2 d y y i 2 c i t δ t y 2 v x i c i t δ t x v y i c i t δ t i y λc i t δ t r c c i t 1 θ δ t d x x i 2 c i t x 2 d y y i 2 c i t y 2 v x i c i t x v y i c i t y λ c i t q w c i θδ t λ p c p i δt here c p t is the concentration of parent p at time t whereas λ p is the corresponding decay rate using the values of shape function and its derivatives the eq 25 is discretized as 26 r c k 1 i θδt d x x i k 4 i d y y i k 5 i v x i k 2 i v y i k 3 i λ c k 1 i c i t δ t r c k 1 i 1 θ δt d x x i k 4 i d y y i k 5 i v x i k 2 i v y i k 3 i λ c k 1 i c i t θ δ t q w c i λ p δt p j t similarly the applicable boundary conditions see eqs 10 and 11 can be implemented at boundary nodes by eq 27 27a k 1 i c i c 0 27b d xx i n x i k 2 i d yy i n y i k 3 i c i f note that the computation of matrices containing the values of shape function and its derivatives is done only in the beginning the same matrices are used for solving the system of equations for head and concentrations of different species 3 model verification and numerical analysis 3 1 verification with semi analytical solution in this problem the rpcm model is compared to a semi analytical solution named decay wang and neville 2019 a 1d domain of 2000 m is considered fig 1 a with an initial condition of zero concentration the continuous contamination source for species 1 is located at the left boundary the reaction pathway for the problem has 4 levels see fig 1 b level 1 2 and 4 consist of species 1 2 and 5 respectively level 3 consists of species 3 and 4 which have common parent 2 and common daughter 5 the concentration of species 1 is maintained as c0 100 ppm at the source location the concentrations of other species at this location are set to zero these chemical species exhibit linear adsorption and first order decay reactions the characteristics of the species are listed in table 1 the initial condition is given as 28 for i t h species at t 0 c i 0 x y 0 x y ω the rpcm transport model is developed by using 201 nodes with nodal distance dc of 10 m the simulation period is 3000 days with a time step of 10 days the mq rbf shape parameters are q 0 98 and c s 5 dc the radius of the local support domain is 5 dc the simulation times for the models are approximately 11 s using a pc specification of core i7 6770 3 40 ghz cpu and 16 gb ram the model is verified against the semi analytical code decay wang and neville 2019 for different values of seepage velocity and dispersion coefficient see fig 2 the result obtained by the model is observed to agree well with the semi analytical solutions for different flow and transport conditions it is observed that the concentration profile is the steepest for species 1 i e the concentration front is sharper than other species in the network a part of the parent species converts into the daughter species and the contribution added as a source term hence the sources for the species which are created later in the reaction network are dispersed compared to the point source in case of species 1 due to this reason the concentration profile tends to be flatter for a species which is created later in a network the following error indicators are used for quantifying the model accuracy with varying flow and transport parameters 29 mean absolute error mae i 1 n c i exact c i num n 30 root mean square error rmse i 1 n c i exact c i num 2 n 31 maximum point error mpe max c i exact c i num here the superscript exact and num refer to the simulated concentrations obtained by semi analytical method decay and proposed rpcm model respectively the peclet number pe which is used as a measure of advection is given by 32 pe v x d here δx is the nodal distance dc used in the model the errors for different cases are presented in table 2 as observed in table 2 the peclet number pe is increased gradually by increasing the velocity v for first 3 cases and similarly it is increased from case 4 6 by decreasing the dispersion coefficient d it is observed that errors obtained for species 1 are the highest for every case except case 4 and the corresponding magnitudes decrease with increase in level in the reaction pathway the errors are observed to increase more rapidly when velocity is increased for case 1 3 compared to case 4 6 where dispersion coefficient is decreased gradually the maximum values of errors are observed for case 3 for species 1 therefore the velocity has more impact on model performance compared to dispersion coefficient nevertheless the maximum values of mae mpe and rmse are 0 145 3 836 and 0 578 which indicates the model performance can be considered to be accurate 3 2 numerical analyses as observed in eq 15 the mq rbf has two shape parameters namely c s and q the choice of mq rbf shape parameters q and c s are crucial as the accuracy of the simulations depends on their values liu and gu 2005 suggested the values of q be fixed as 0 98 or 1 03 for fluid flow and solid problems the parameter c s is a free parameter and generally represented as multiples of nodal distance dc the sensitivity of the parameter c s is analyzed extensively in the literature anshuman et al 2019 singh et al 2016 in the present study the parameter c s is fixed as 5 dc as satisfactory results are reported for 1d and 2d groundwater problems here stability and convergence of the time discretisation are analyzed furthermore the effect of size of local support domain on model simulation is studied 3 2 1 stability of time discretisation the proposed rpcm model uses a semi implicit formulation which depends on the temporal weighting parameter θ as shown in eq 24 and 25 when θ 1 the method is known as implicit method for fdm the simulation becomes unconditionally stable when θ 1 2 similarly for implicit method is found to be unconditionally stable for element free galerkin method dehghan and abbaszadeh 2018c rpcm based contaminant transport model with θ 1 2 becomes unstable in case of high pe problems anshuman et al 2019 singh et al 2016 here the earlier problem discussed in section 3 1 is considered for assessment for model performance for different θ values i e θ 1 2 2 3 and 1 the seepage velocity is fixed as 1 5 m d the dispersion coefficient is taken as 1 5 m2 d and 0 1 m2 d for case a and case b which correspond to pe 10 and pe 150 respectively the results obtained are plotted in fig 3 it is observed that the model simulation is stable for θ 1 2 2 3 and 1 for case a it matches closely with the semi analytical solution when θ 1 2 however for case a while numerical dispersion is observed when θ is increased the model simulation for species 1 is unstable near the concentration front for high advection case b when θ 1 2 nevertheless the concentration profiles for the remaining species are stable on the other hand numerical dispersion is significant for θ 2 3 and 1 although stable simulations are observed the error indicators are presented for case a and b in tables 3 and 4 respectively it is observed that the error in model simulations are least when θ 1 2 for most of the species it is important to note that the stability of the model for high advection problems can be improved by employing upwinding techniques liu and gu 2005 3 2 2 convergence of time discretisation here the proposed model is tested for different time steps in order to analyze the convergence of the time discretisation the problem from section 3 1 is considered with velocity 1 5 m d and dispersion coefficient 1 5m2 d respectively the model is run for time step size δt 30 d 15d 10d 7 5d 2d and 1d the rest of the model parameters are kept same as problem discussed in section 3 1 the mae values are computed against semi analytical solution as shown in fig 4 it is observed that the errors in simulation decreases and becomes constant as the time step δt is refined this also indicates that the time discretisation used in the proposed model eqs 24 and 25 is convergent the variation of cpu time with respect to δt is presented in table 5 it is observed that the relative cpu time decreases almost linearly with respect to increase in time step δt 3 2 3 model stability with respect to local support domain the local support domain plays an important role in the model simulation by enhancing the size of support domain the model simulation stabilizes in case of high advective flows singh et al 2016 further model simulations involving high reaction rates can also be stabilized by increasing the support domain size anshuman et al 2019 here the effect of support domain on stability of the simulation of different species in a linked first order reaction is studied the problem from section 3 1 is considered with velocity 1 5 m d and dispersion coefficient 0 25 m2 d the model is tested for support domain radii 2 d c and 5 d c the remaining parameters are considered to be same as in section 3 1 due to low value of dispersion coefficient d the problem is advection dominant with pe 60 the model simulation with support domain size 2 d c shows oscillations near the concentration front for species 1 fig 5 however the oscillations are stabilized to a great extent when the support domain size is increased to 5 d c on the other hand the simulations of daughter species 2 5 are observed to be stable for both support domain sizes as they are created from corresponding parent species which are already dispersed in the domain the mae values computed against semi analytical solution is presented in table 6 it is observed that mae value is higher for species 1 when support domain size is 2 d c nevertheless for remaining species mae values are almost identical for both support domain sizes moreover there is little impact on cpu time due to increasing support domain size however this impact can be higher when dimensionality of the problem increases due to significant increase in number of nodes for computation of shape function and derivatives for groundwater contaminant transport problems satisfactory results are obtained when support domain size is varied between 3 d c to 5 d c anshuman et al 2019 singh et al 2016 4 model applications 4 1 case study 1 in this section the rpcm model performance is compared with that of fem the problem discussed in section 3 1 is considered two cases are considered with velocities 1 m d and 2 m d respectively the dispersion coefficient is 1 m2 d for the first case pe is 10 and for the higher advective case pe is 20 the fem model developed in comsol consists of 201 nodes and 200 elements both models are simulated for 3000 days with a time step of 3 days the remaining problem variables and rpcm model parameters are the same as given in section 3 1 the results obtained are plotted in fig 6 the error indicators computed against the semi analytical code decay wang and neville 2019 are higher for fem compared to that of rpcm see tables 7 and 8 it is observed that both models produce similar concentration profiles for the first case see fig 6 a for more advective case i e pe 20 high oscillations are observed near the concentration front obtained by fem for species 1 and 2 it is observed that in higher advective case fem model shows oscillations for species 1 and 2 the decrease in oscillations is attributed to the flatter concentration profiles of subsequent species on the other hand the rpcm model simulations are free from oscillations for all species the cpu time for the rpcm model is 11 25 s it is important to note that comsol software implements re meshing in order to produce stable simulation by refining the mesh at each time step due to this reason the cpu time for fem model is 60 s hence it can be stated that the proposed model handles the problem in a better way compared to fem model 4 2 case study 2 in this section the coupled rpcm 2d model is applied to a hypothetical confined aquifer as shown in fig 7 the aquifer dimensions are 300 m 100 m the north boundary is considered to be impervious the head along the west boundary south boundary and east boundary vary linearly from 21 m to 20 m 20 m to 19 m and 19 m to 18 m respectively the thickness of the aquifer is 10 m the flow in the aquifer is assumed to be in steady state the contaminant source for chemical species 1 is assumed to be located along the west boundary between 0 m 60 m and 0 100 m see fig 7a the reaction pathway followed by species 1 is presented in fig 7b the characteristics of the contaminant species are presented in table 9 the aquifer material is assumed to be homogenous and isotropic the hydraulic conductivity and porosity of the aquifer are 2 5 m d and 0 3 respectively the longitudinal and lateral dispersivities α l and α t are fixed as 0 5 m the coupled rpcm model is developed using 1281 nodes with nodal distance dc of 5 m respectively the radius of the local support domain is 3 dc the mq rbf shape parameters are q 0 98 and cs 5 dc the fem model having very fine mesh is developed in comsol and used to estimate the model performance the fem model consists of 23 829 interconnected nodes forming triangular elements based on the boundary conditions for the flow component of the model specified head or dirichlet boundary condition is applied at the west south and east boundary whereas neumann condition with zero flux is applicable to the north boundary the result obtained from the flow simulation is presented in fig 8 it is observed that the head contours obtained by rpcm model match well with that of fem for the transport models the west boundary is considered to be dirichlet boundary and in the remaining boundaries neumann boundary condition is applied the initial condition is given by for 1st species at t 0 33 a c 10 x y 250 ppm 50 m x 75 m 50 m y 75 m 0 ppm otherwise for 3rd species at t 0 33 b c 30 x y 100 ppm 120 m x 140 m 40 m y 60 m 0 ppm otherwise 33 c for remaining species at t 0 c i 0 x y 0 x y ω the simulation period of the models is 365 days with a time step of 5 days the spread of contaminants in the aquifer after 1 year as simulated by the models are presented in fig 9 the patterns of spreading of the contaminants match for both fem and rpcm however the slight difference in magnitude of concentration is noticeable the cpu times used by rpcm and fem models are 310 s and 213 s respectively in order to inspect the variation of concentration with respect to time the breakthrough curves are plotted for observation wells ob1 and ob2 located at 200 m 40 m and 220 m 60 m respectively from fig 10 it is observed that the concentration profiles obtained by both models are comparable due to the presence of spatially variable initial conditions the concentration profile for species 3 rises and falls with respect to time the error indicators mae and rmse are computed for rpcm against fem at ob1 and ob2 see table 10 the error values are high for species 1 and 3 at ob1 and ob2 it is due to the fact that the concentration profiles of the species are steep and the concentrations are of high magnitude however for species 2 4 and 5 the error values are lesser as the concentration profiles are relatively flatter compared to other species 4 3 case study 3 here a heterogeneous field aquifer of area 4 5 km2 is considered for the study the aquifer data used for is the study is adapted from singh et al 2016 the west to the north west boundary of the aquifer is encircled by a lake the remaining boundary is treated as a flux boundary the transmissivity of the aquifer is spatially varying and represented with 11 zones minimum zonal transmissivity is 30 m2 d while the maximum value approaches 170 m2 d there is an influx of water into the aquifer through the recharge zone as shown in fig 11 a these data are used to develop the flow models in rpcm and fem further in order to assess the performance of the reactive transport model a hypothetical scenario is assumed in which contaminant species 1 is injected in the aquifer through a source see fig 11 a the species 1 undergoes a decay chain reaction as shown in fig 11 b the characteristics of the contaminants are presented in table 11 the dispersivities α l and α t are assumed suitably to be 10 m the initial condition is given by for 1st species at t 0 34 a c 10 x y 1000 ppm 1240 m x 1339 2 m 813 2 m y 1027 2 m 0 ppm otherwise for 2nd species at t 0 34 b c 20 x y 100 ppm 1240 m x 1339 2 m 813 2 m y 1027 2 m 0 ppm otherwise 34 c for 3 rd species at t 0 c 30 x y 0 x y ω two rpcm based models are developed with uniform and non uniform rpcm nu nodal distributions respectively see fig 12 in uniform nodes based model the aquifer is represented using 1005 nodes with a nodal difference of δx 49 6 m and δy 42 8 m the same number of nodes is used in the non uniform node based rpcm model rpcm nu the mq rbf shape parameters q and c s are set as 0 98 and 5 dc respectively the size of the local support domain for rpcm model having uniform nodal distribution is fixed as 3 dc in the rpcm nu model local support domain size is computed using estimated area of the support domain and estimated number of nodes in local support domain liu and gu 2005 the fem model is developed using comsol with 5858 nodes with triangular elements dirichlet boundary condition is applied in the flow model for the nodes located at the north and west boundary see fig 11 a which is adjacent to the lake the remaining boundary is treated as a flux boundary the outward flux from this boundary is calibrated to be 6 1 10 5 m2 d using the observed head values singh et al 2016 the head distributions obtained from the fem and rpcm models are shown in fig 13 it is observed that the rpcm models produce similar head values in comparison to fem for both nodal distributions the simulated head values at randomly selected locations are presented in table 12 the absolute percentage difference is computed with respect to fem solutions at these locations it is observed that percentage difference obtained is lesser than 0 29 for rpcm models with different nodal configuration at the source location shown in fig 11 the contaminant species 1 is injected at 10 ppm day in the rpcm and fem transport models concentrations at the boundary are set to zero assuming no contaminant reaches the boundary during the simulation period of 3 years the time step used in both models is 5 days the results obtained at the end of the simulation period are plotted in fig 14 it is observed that the migration patterns of the contaminants are similar for rpcm and fem the concentration of the contaminant species at the end of the simulation period are presented in table 13 for randomly selected locations around the source it is observed that the simulations obtained by rpcm models are slightly higher than that of fem the rpcm model results for different nodal arrangements are also observed to be very close to each other the relative difference computed against fem simulation has the highest value of 0 44 for selected locations moreover the difference is lowest for species 1 and gradually increases at all locations the cpu time for both rpcm based models is approximately 71 s whereas for fem model in comsol it is 16 s 5 discussion in this study a new meshfree rpcm model is developed for simulating the fate of contaminants in linked first order reactions under coupled flow conditions the state variables for the problems are approximated using mq rbfs following which the governing equations and boundary conditions are solved the model uses local support domains for the approximation of shape functions and its derivatives hence the globally assembled matrix consisting of governing equations and boundary conditions are also sparse in nature this technique removes the ill conditionality which is often encountered in global support domains liu and gu 2005 the model developed is verified with a semi analytical solution decay wang and neville 2019 for a 5 species linked reaction with varying seepage velocities and dispersion coefficients furthermore the stability of the time discretisation is tested with respect to time weighting parameter θ it is observed that in the proposed method θ 0 5 gives oscillatory solution for first species near the concentration front when pe is increased to 150 on the other hand simulations are stabilized when the value of θ is increased to 2 3 and 1 however large amount of numerical dispersion is observed due to which errors obtained for these values are higher compared to that of proposed method θ 0 5 the time discretisation is also observed to be convergent when time step is gradually decreased from δt 30d to δt 1d the effect of support domain size is also studied for high advective case it is observed that the model simulations are stabilized when radius of support domain is enhanced the model performance is also compared with that of the fem model for the case studies in the 1d case the rpcm transport model performance is comparable to that of fem when pe 10 for more advective case pe 20 the fem model shows a high value of oscillations in the vicinity of concentration front for species 1 and 2 nevertheless concentration profiles gradually stabilize for remaining species due to the contribution from dispersed parent species in contrast the rpcm model yields oscillation free solutions for both cases and handles the steeper concentration front better than fem it should be noted that the comsol software implements re meshing in order to stabilize the concentration profiles comsol 2007 the rpcm 2d model performance is compared with fem for a homogenous and isotropic aquifer in coupled flow condition in case study 2 there is an excellent match between head distribution obtained by both models a spatially varying initial condition is used for species 1 and 3 although some differences are observed in concentration profiles at two observation wells ob1 and ob2 the mae and rmse values computed against fem are lesser than 5 66 and 6 812 respectively for species 1 this difference can be attributed to the structural differences between the two models in case study 3 transport of a 3 species decay chain in a heterogeneous field aquifer is simulated two rpcm models with different nodal arrangements are developed the head contours obtained by the fem and rpcm models are mostly similar a small difference in the magnitude of concentration obtained by fem and rpcm models is observed at the observation points around the source it is due to the fact that both models handle heterogeneity differently the fem comsol model relies on nodal connectivity and refines the mesh at zonal boundaries on the other hand in the rpcm models transmissivity values are assigned directly to the nodes however the rpcm models give close values for both types of nodal arrangements used due to the absence of mesh grid the rpcm model is more computationally efficient compared to fem it reduces the number of steps in the algorithm and eliminates the issue of re meshing apart from that the mesh refinement is also necessary in case of fem near the source sinks located inside the problem domain pepper and stephenson 1995 on the other hand the proposed rpcm model uses mq rbfs for the approximation of state variables which handles the presence of concentration gradients efficiently additionally the proposed model does not necessitate operator splitting which is commonly implemented in grid based methods for handling advection dispersion reaction and source sinks zheng and wang 1999 zienkiewicz et al 2005 the model handles advection and reaction terms by collecting the upstream information by using local support domain liu and gu 2005 by increasing the radius of local support domain the high advection and reaction rates can be handled anshuman et al 2019 singh et al 2016 nevertheless unlike rpcm this technique is not implemented easily in the grid based methods liu and gu 2005 from the comparison of cpu times it is observed that the time required for the proposed model is higher compared to that of fem or 2d models the reason for this is that the proposed model is developed in python using numpy package oliphant 2006 while the fem model developed in comsol which uses java programming language the computation in java is faster compared to python as it is a compiled language however python language is used in this study for faster development of code for the proposed problem the computation time can be improved using low level languages such as fortran although hypothetical chemical species are assumed as contaminants in this study the proposed model can easily accommodate contaminants which are frequently encountered in the field the characteristics of the contaminants e g dispersivities decay rates retardation factors etc can be provided for individual species in the reaction network 6 conclusions in this paper a new meshfree rpcm model is proposed for the transport of complex first order reaction networks branched series or complex connected networks can be easily handled by adding the contribution from parent species as a source term in the governing equation of daughter species the model uses mq rbf for the approximation of state variables and derivatives the governing equations and boundary conditions are solved using point collocation method the proposed model does not require operator splitting for handling reactions which are common in conventionally used grid mesh based methods moreover the use of local support domain helps to handle advection efficiently and eliminates the ill conditioning problem observed in the global support domains the effectiveness of the model in handling heterogeneity is also demonstrated in the study the aquifer parameters are directly assigned to the nodes unlike the grid mesh based methods which require refinement of grid meshes at the zone boundaries as the model is fully meshfree it eliminates the need for meshing and re meshing for transient problems due to its simplicity and accuracy rpcm based coupled flow and transport model can be effectively used for transport of complex first order reaction networks declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the board of research in nuclear sciences brns for providing support through the project modelling of reactive transport in groundwater using meshfree based numerical methods project no 16brns002 the authors also thank dr laishram guneshwor singh health physics division bhabha atomic research centre for providing the necessary data for the study the authors are thankful to the reviewers for their valuable comments which helped to improve the manuscript appendix a supplementary data model development steps image 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jconhyd 2019 103582 
1541,column experiments were performed to assess the effectiveness of zeolite and compost zeolite mixture in removing dissolved lead pb2 from acidic water of ph 2 4 the acid neutralizing ability and hydraulic performance of the materials were also studied fitting the advection dispersion equation ade and mathematical models i e the dose response adams bohart and yoon nelson models to the pb2 experimental breakthrough curves btcs was also performed the compost zeolite mixture proved to be better than zeolite alone both in removing pb2 and in buffering the acidic ph the maximum adsorption capacity qo obtained for zeolite was 0 097 mg g and 0 151 mg g for the compost zeolite mixture respectively lead removal was attributed to ion exchange and adsorption observed pb2 btcs demonstrated sorption related nonequilibrium effects in the columns the hydraulic conductivity of zeolite decreased by 2 and by 28 8 in the case of compost zeolite mixture at the end of the experiment the entire experimental btc of pb2 was well described by the dose response model while the adams bohart model was better in describing only the initial part of the lead btcs keywords permeable reactive barriers zeolite compost lead modelling acidic groundwater 1 introduction acidic groundwater can be defined as groundwater with low buffering capacity as a result of a drop in alkalinity and an increase in acidity and other chemical modifications de caritat 1995 it is mostly found in terrains where the aquifer is porous shallow highly leached and where there is absence of carbonates giving rise to poorly buffered groundwater hansen and postma 1995 takem et al 2015 acidification of groundwater can be instigated by natural as well as anthropogenic phenomena such as dissociation of humic acids oxidation of sulphur and nitrogen compounds acid precipitation landfilling and mineral mining acid mine drainage knutsson 1994 wingenfelder et al 2005 natural acidification of groundwater can also be caused by deposition of sea salt loaded precipitation which can result in cation exchange of marine na with soil bound h and or a13 de caritat 1995 in most cases these natural and anthropogenic processes act in concert to exert their effect on the groundwater groundwater acidification used to be a major environmental problem in north america and europe knutsson 1994 appleyard et al 2004 in recent years however it has become an issue of global concern due to accelerating demographic growth and industrialization appleyard et al 2004 reported of widespread acidification of groundwater in perth western australia due to oxidation of sulfide minerals in an alluvial aeolian plain largely formed from quaternary sand and sand limestone dunes groundwater ph as low as 1 9 was measured in some shallow monitoring wells and boreholes in the area takem et al 2015 also reported of decreases in ph of shallow groundwater from a range of 3 94 7 70 to a range of 3 8 6 8 over a period of 15 years in an unconfined aquifer in the coastal urban town of douala cameroon in the western part of africa the acidification of the groundwater was attributed to acid atmospheric deposition industrial effluent discharges and acid spill chemical weathering and coastal atmospheric deposition cation exchange acidic groundwater can be detrimental to both aquatic and terrestrial organisms it may trigger the mobilization of heavy metals such as zinc cadmium lead copper and nickel kjoller et al 2004 these metals have the potential of causing both acute and chronic haematological as well as neurological problems when taken up by humans jaishankar et al 2014 knutsson 1994 also reported that surface waters interacting with groundwater of ph lower than 5 could support few or no fish species and very few species of invertebrates in many regions of finland norway and sweden additionally depending on the geology and the predominant cause s of acidification the groundwater may be characterized by moderate to high levels of sulphate iron manganese which can make it harmful for human use doye and duchesne 2003 wingenfelder et al 2005 permeable reactive barriers prbs have been widely acknowledged as cost effective and sustainable alternative to other established treatment methods such as the conventional pump and treat p t systems for remediating shallow groundwater initially the prb was installed to remediate groundwater impacted by chlorinated solvents such as perchlorethylene pce and trichloroethylene tce henderson and demond 2007 obiri nyarko et al 2014 later due to the successful removal of the contaminants prbs were applied to remove other contaminants such as nutrients e g no3 so4 2 heavy metals e g pb cu cd zn as and petroleum hydrocarbons e g benzene toluene ethylbenzene xylene henderson and demond 2007 obiri nyarko et al 2014 prbs have also been used for other purposes such as amelioration of acidity or alkalinity of groundwater waybrant et al 2002 gibert et al 2011 in general remediation of groundwater by prbs is accomplished by the emplacement of a carefully selected reactive medium across the flow trajectory of the contaminant plume which removes the contaminants or ameliorates its conditions passively via processes such as precipitation adsorption ion exchange and biodegradation henderson and demond 2007 obiri nyarko et al 2014 two main factors are considered when assessing the performance of prbs these are the high reactivity and good long term hydraulic performance of the materials therefore materials that meet these criteria and are of low cost are the most preferred natural zeolites are one of the low cost materials frequently evaluated as prb materials for the removal of contaminants from groundwater jun et al 2009 huang et al 2015 obiri nyarko et al 2015a they have received tremendous attention due to their porous nature moreover they are also effective in removing a variety of heavy metals which is often accompanied by the release of non toxic exchangeable cations k na ca2 and mg2 to the environment they are also able to buffer acidic or alkaline water perić et al 2004 wingenfelder et al 2005 medvidović et al 2006 under extremely acidic conditions however there can be deterioration of their effectiveness due to disintegration of their structure or rejection of heavy metals due to the preponderance of h both phenomena can lead to early contaminant breakthrough wingenfelder et al 2005 cozmuta et al 2012 obiri nyarko et al 2015b this is undesirable especially when used for the removal of heavy metals under acidic conditions compost is a low cost material that can be derived from agricultural by products or industrial waste materials it has also received wide acclaim for groundwater remediation in recent times compost contains functional groups such as carboxylic acid and phenolic hydroxyl which make it possible for both ph buffering and removal of heavy metals mikkelsen 2005 in batch tests compost was shown to increase ph from 3 2 to 7 1 obiri nyarko et al 2015a and reduce dissolved pb concentrations by over 91 seelsaen et al 2007 obiri nyarko et al 2015a the downside of compost when used alone however is that its organic component can decompose resulting in an increase of the prb permeability this can affect the residence time as well as the long term reactivity of the compost to overcome such problems chemical treatment or its combination with other materials has been used as a technique for improving physical chemical properties as well as performance of compost mondal 2009 the addition of compost to zeolite could therefore offset the weaknesses of these individual reactive materials however such a combination has so far not been investigated neither under dynamic conditions nor for the removal of heavy metals from acidic groundwater accordingly column experiments were carried out to compare the effectiveness of zeolite and compost zeolite mixture 1 3 5 by weight which was found optimal in the previous batch study obiri nyarko et al 2015a as prb materials in concomitantly neutralizing acidic groundwater and removing pb2 lead one of the toxic metals listed among the priority pollutants by us epa nakada et al 1979 bellinger and bellinger 2006 was used as a representative contaminant because of its widespread presence in the environment and toxicity to human health through accumulation in living tissues and the food chain fan et al 2014 hydraulic conductivity tests were also performed to assess the hydraulic performance of the materials this is particularly important as decreases in hydraulic conductivity causing prb failures have frequently been reported in the literature henderson and demond 2007 moraci et al 2016 the advection dispersion equation ade van genuchten 1981 the adams bohart model bohart and adams 1920 the dose response model yan et al 2001 and the yoon nelson model yoon 1984 were also applied to the pb2 experimental data to allow further interpretation of the results 2 materials and methods 2 1 reactive materials and test solution natural zeolite and compost a by product derived from food and plant waste were obtained in poland and used in this study impurities in the compost were removed by handpicking while the zeolite was washed with deionized water both materials were air dried before used detailed description of the materials as well as experiments to determine their environmental compatibility have been reported in obiri nyarko et al 2015a 2015b briefly the zeolite used was chemically composed of sio2 69 9 al2o3 12 5 fe2o3 1 6 mgo 0 9 cao 2 4 mno 1 1 h2o 8 0 na2o 0 3 k2o 3 1 and tio 0 3 mineralogical characterization by xrd philips apd pw 3020 x pert fitted with goniometer cu lamp and a graphite monochromator also showed that it was dominated by clinoptilolite 75 other physical and chemical properties including the ph bulk density ρb cation exchange capacity cec and moisture content mc of the zeolite and compost are presented in table 1 stock solution of 1000 mg pb2 dm3 was prepared by spiking deionized water with analytical grade of pb fluka and thereafter stirred for 10 min with a magnetic stirrer from the stock pb2 solution of concentration 1 76 mg pb2 dm3 and ph 2 4 was prepared and used for the experiments the ph of the solution was adjusted with 0 1 m naoh and hno3 to the desired value to support the modelling with the ade a conservative tracer solution using sodium chloride nacl was prepared one 1 g of nacl salt was dissolved in 1 dm3 of deionized water and later diluted for the experiments all the chemicals used in study were of analytical grade 2 2 column experiments the column experiments were carried out in stainless steel cylinders of length 30 cm inner diameter of 5 35 cm and ca 675 cm3 internal volume fig 1 the columns had two inlets at the base one for feeding the column with the influent solution and the other for influent sample collection and two similar outlets at the top for discharge of the effluent solution and collection of effluent samples for analysis each column was divided into three sections the top and bottom sections were packed with 170 g of glass beads grain size 2 3 mm and the middle portion was filled with the reactive material all the columns were packed manually the amount of material total pore volume pv bulk density and total porosity n of the packed columns are summarized in table 2 the total pv was estimated from the saturated and dry weights of the packed columns and the total porosity was determined gravimetrically by dividing the total pv by the total volume of the columns determination of the bulk density was accomplished by dividing the weight of the packed column by its total volume before permeating the columns with the test solution deionized water was flushed through them to equilibrate the system subsequently a peristaltic pump was used to introduce the solutions into the columns in an upward flow direction at a flow rate of 1 67 cm3 min which is equivalent to an average darcy flux of ca 107 cm day the imposed flow rate was to expedite the exhaustion of the reactive media effluent samples were taken at predetermined time intervals using disposable glass syringe part of the taken samples were analyzed immediately for pb2 using adsorption atomic spectrophotometry aas 3 corp zeiss detection limit of 0 001 mg dm3 and exchangeable cations ca2 mg2 na and k using ion chromatography chloride was determined titrimetrically using agno3 as the standard and k2cro4 as the indicator korkmaz 2001 unanalyzed pb2 samples were preserved by acidification with concentrated hno3 and stored in the refrigerator part of the unfiltered effluent samples were analyzed immediately for ph using a multifunctional computer meter elmetron cx 742 in all cases the ph meter was calibrated with standard solutions of 4 7 and 10 ph units before use 2 3 analysis of breakthrough curves btcs analysis of the effectiveness of the reactive materials in attenuating pb2 in the columns was based on breakthrough curves btcs which were obtained by plotting the relative concentrations of pb2 i e effluent concentration c influent concentration c o against the effluent volume a c c o 0 05 i e the point on the btc where the effluent solute concentration is 5 of its influent value was considered as the breakthrough point while c c o 0 95 i e the point on the btc where the effluent concentration is 95 of its influent value was considered as point of column exhaustion medvidović et al 2006 the total amount of the pb2 injected into the columns mtotal mg was determined using eq 1 1 m total c o q t total 1000 where ttotal represents the total experimental time min q is the flow rate cm3 min the total mass of pb2 removed qtotal mg in the column was determined using eq 2 2 q total q 1000 0 t total c rem dt where crem c o ct is the reduction of the pb2 concentration in the effluent from the column due to sorption mg dm3 the rate of pb2 removal r and the total removal capacity of the material qe mg g were determined using eqs 3 and 4 respectively 3 r q total m total x 100 4 q e q total m where m is the mass of the adsorbent g 2 4 modelling the pb2 breakthrough curves btcs the btcs of pb2 were modelled using the advection dispersion equation ade dose response adams bohart and yoon nelson models 2 4 1 the advection dispersion equation ade the ade has been used extensively to describe solute transport in porous media van genuchten 1981 ogata and banks 1961 it can be fitted to experimental data from column studies and used to predict future treatment performance eq 5 can be used as the analytical solution to the ade for a one dimensional case ogata and banks 1961 5 c c o 1 2 erfc rz v p t 2 d l tr 1 2 1 2 exp v p x d l erfc rz v p t 2 d l tr 1 2 where vp cm min is the average pore water velocity z cm is length of the column r is the retardation factor dl cm2 min is the hydrodynamic dispersion coefficient c and c o are the effluent and input concentrations of pb2 mg dm3 erfc is the complementary error function and t is the time min dl is the sum of the effective diffusion coefficient df and mechanical dispersion coefficient dm i e dl df dm the dm is a function of the pore water velocity and the dispersivity of the porous material dm αvp where α is the longitudinal dispersivity cm min as vp 0 dm 0 and diffusion becomes the dominant transport mechanism i e dl df also when diffusion is negligible mechanical dispersion becomes the dominant transport mechanism and dl αvp eq 5 was first fitted to the chloride experimental data to determine the hydrodynamic properties including the vp and dl chloride was assumed to behave as a conservative element i e it is not subject to any sorption ion exchange or anion exclusion processes and so the retardation factor r was set to 1 while the vp and dl were regressed until the simulated btc was similar to the experimental cl btc the péclet number p e describing the relative importance of molecular diffusion and mechanical dispersion in the transport of solute was calculated from the vp and dl using eq 6 6 p e v p z d l thereafter eq 5 was fitted to the btcs of pb2 for both materials using the vp and dl estimated from the chloride curve fitting to determine the retardation of pb2 all the transport processes evaluated in this study with the ade were performed using the following initial and boundary conditions ogata and banks 1961 c x 0 0 c t 0 c 0 t c o i e the initial condition is c 0 for the entire sample and the boundary conditions are c 0 at an infinite distance from the inlet and c c o at the inlet 2 4 2 the dose response model the dose response model was proposed by yan et al 2001 and was initially developed for pharmacological studies it has recently been used to describe metal adsorption kinetics in continuous columns senthilkumar et al 2006 araneda et al 2011 and is also known to reduce the errors of conventional mathematical models such as the adams bohart model yan et al 2001 it can be represented by eq 7 7 c c o 1 1 1 c o v q o m k where c o is the initial concentration and c is the concentration mg dm3 k represents the kinetic constant of the dose response model v is the effluent volume dm3 qo represents the maximum concentration of the solute in the solid phase mg g and m is the mass of the adsorbent g 2 4 3 the adams bohart model adams and bohart model assumes that the equilibrium is not instantaneous and that the sorption rate is proportional to the residual capacity of the solid and the concentration of the sorbed substance bohart and adams 1920 it is generally used to describe the initial portion c c o 0 15 of the breakthrough curve homem et al 2018 the model can be expressed as eq 8 8 c c o exp k ab c o t k ab n o z v p where c o and c are the input and effluent metal ions concentration in mg dm3 kab is the kinetic constant in dm3 mg min no is the maximum volumetric sorption capacity in mg dm3 z is the length of the column in cm and vp is the pore water velocity in cm min 2 4 4 the yoon nelson model the yoon nelson model is based on the assumption that the rate of decrease in the probability of adsorption for each sorbate molecule is proportional to the probability of adsorbate adsorption and the probability of adsorbate breakthrough on the adsorbent this model has been widely used especially in single adsorbate systems yoon 1984 due to the simplicity of its expression moreover it requires no detailed data concerning the characteristics of the adsorbate the type of adsorbent and the physical properties of the adsorbent ayoob and gupta 2007 the eq 9 is given as 9 c c o 1 1 e k yn τ t where τ is the time required for 50 adsorbate breakthrough min and kyn is the rate constant dm3 min and t is the breakthrough sampling time min 2 4 5 error analysis the accuracy of fitting the models to the experimental data was evaluated based on the coefficient of determination r2 and root mean square error rmse eq 10 the higher the r2 and smaller closer to 0 the rmse the better is the model prediction low r2 and large rmse indicate large overestimation or underestimation of the experimental data by the model 10 rmse j 1 n c c o cal c c o exp 2 n where c c o cal and c c o exp respectively are the predicted and measured relative concentration at time t n is the number of observations 2 5 determination of hydraulic conductivity to study the hydraulic performance of the reactive materials hydraulic conductivity k of the materials was determined before and after the experiments using the constant head method head and keeton 2008 the k was calculated using eq 11 11 k vz hat where k is the hydraulic conductivity cm s a is the cross sectional area of the column cm2 h is the head difference cm z is the length of the column cm t is time s and v is effluent volume cm3 3 results and discussion 3 1 lead breakthrough curves btcs and effects of reactive materials on ph breakthrough curves btcs showing pb2 removal from the acidic water by zeolite and compost zeolite as well as the ability of the materials to neutralize acidic ph are shown in fig 2a and b in table 3 the results of the quantitative analyses of the btcs are presented pb2 breakthrough occurred in zeolite at pv 30 whereas it was delayed to pv 40 in the compost zeolite as shown in table 3 both the rate of pb2 removal and the adsorption capacity determined by integration of the btcs were also higher for the mixture than zeolite this is likely due to a synergistic effect produced by the addition of compost to the zeolite in both columns however c co 0 95 was not reached signifying that the capacities of the materials were not exhausted at the time the experiments were stopped solution ph is one of the important operational parameters that affect the adsorption of metals onto adsorbents the uptake capacity of metal ions the adsorption mechanism the degree of ionization the surface charge of the adsorbent and the speciation of the adsorbate are all largely affected by the ph of the solution heidari et al 2013 as shown in fig 2a and b both materials raised the ph from 2 4 to above 7 initially but in the case of zeolite the ph dropped rapidly thereafter while the decline was gradual in the case of the compost zeolite mixture though both materials were able to keep the effluent ph above the influent ph of 2 4 the results clearly show that the compost zeolite mixture has a higher capacity to buffer acidic ph than zeolite this may be attributed to the differences in their cecs table 1 as well as the inherent ph of the compost 8 05 table 1 it can also be seen from fig 2a and b that the shapes of the ph profiles were the opposite of the btcs indicating that by observing the ph profiles the behaviour of lead in the materials can also be determined a number of ph buffering mechanisms can be suggested for the studied materials these include i the exchange of h with exchangeable cations e g na and k in both zeolite and compost rivera et al 2000 medvidović et al 2006 filippidis and kantiranis 2007 latifah et al 2018 ii protonation of functional groups e g phenolic and carboxyls in the case of compost latifah et al 2018 and iii binding of h to the lewis basic sites linked to the framework oxygen atoms of the zeolite filippidis and kantiranis 2007 3 2 pb2 removal mechanisms the immobilization of heavy metals by the studied materials is a complex process that may comprise one or more of the following ion exchange adsorption and precipitation of metal ion hydroxide complexes on active sites of the particle surface trgo and perić 2003 latifah et al 2018 the process may be ion exchange if there is stoichiometric replacement of an ion in the solid phase by an equivalent of another ion in the liquid phase i e the amount of cations displaced into solution is equal to the amount of metals taken up onto the solid phase ion exchange reactions are also referred as outer sphere complexation and do not involve formation of bonds between metal ions and sorbent surface doula and ioannou 2003 if the metal ion is removed from solution into the solid phase without displacement of any cations into solution or removal of equal amount of cations the process is adsorption also referred to as chemisorption or inner sphere complexation bolt et al 1978 precipitation of the metals as sparingly soluble salts or hydroxides on the other hand is accompanied by the simultaneous removal of some anions from solution without displacing any sorbed cations ponizovsky and tsadilas 2003 minceva et al 2008 noted that solution ph affects the mechanism of metal ions binding by changing it from ion exchange and or adsorption at acidic region to adsorption and or complexation and possible precipitation at the basic region lead removal from solution by the studied materials was possibly via ion exchange and adsorption removal via precipitation is considered marginal in this study regarding the measured ph values during the removal of lead by the materials ca2 k na and mg2 were released into solution fig 3a and b suggesting the occurrence of ion exchange in the columns perić et al 2004 wingenfelder et al 2005 obiri nyarko et al 2015b though separate experiments were not performed to confirm this it is probable that the ca2 k na and mg2 were released not only in exchange for pb2 but also for h taking into consideration the high concentration of the latter solution and the ph profiles in fig 2a and b adsorption of lead as pboh is also suggested considering the effluent ph values measured in this study which ranged from 3 32 to 8 02 geochemical simulations using minteq showed that the dominant lead species at effluent ph of 8 02 were pb2 28 84 pb3 oh 4 2 0 05 pboh 68 59 and pb oh 2 aq 2 51 and at effluent ph of 3 32 the solution was saturated with pb2 99 99 the high concentration of pboh in solution could result in lead removal as pboh via adsorption onto the inner surface of the zeolite perić et al 2004 minceva et al 2008 3 3 modelling breakthrough curves btcs of pb2 3 3 1 the advection dispersion equation ade the experimental and simulated btcs of lead and chloride for the studied materials are shown in fig 4a and b while the estimated parameters are presented in table 4 the chloride experiments were performed to evaluate the flow characteristics of the columns more than 99 of the injected chloride was recovered in fig 4a and b it can be seen that the experimental btcs of the chloride did not exhibit any significant tailing that would suggest the presence of physical nonequilibrium processes in the columns i e non uniform flow as a result of mobile immobile regions chloride experimental btcs were well described by the ade r2 98 rmse 0 06 the dispersion coefficients were of 0 735 cm2 min for zeolite and 0 593 cm2 min for the compost zeolite and the respective dispersivities calculated from dl αvp were of 3 5 cm and 3 12 cm the p e estimated was 8 57 for zeolite and 9 61 for compost zeolite signifying that solute transport was predominantly controlled by mechanical dispersion in both columns according to fetter 2001 p e 0 4 indicates that solute transport is controlled mainly by molecular diffusion while p e between 0 4 and 6 suggests that transport of solute results from the combined effects of molecular diffusion and mechanical dispersion higher p e 6 indicates the dominance of mechanical dispersion over molecular diffusion following the good agreement between the chloride experimental data and the ade simulated btcs the vp and dl obtained from the chloride curve fitting were fixed in eq 5 for the determination of r in the case of lead it can be seen from fig 4a and b that lead was strongly retarded by the column materials vis à vis the chloride which travelled at the same velocity as that of water r 1 between the two materials fitted pb retardation factors indicate relatively high retardation of lead by the compost zeolite r 60 in comparison to the zeolite r 41 it is conspicuous however that the ade could not fit the lead experimental data well as it did the chloride data especially for zeolite the ade predicted an early breakthrough time and underestimated the the mass of lead adsorbed in the columns at the end of the experiment especially in the column with zeolite several studies have shown that the ade is unable to accurately predict solute behaviour in systems where physical and chemical nonequilibrium processes are present van genuchten and wierenga 1976 the ade suffers this drawback because it was developed on the assumption of uniform flow and transport i e the porous medium is considered as an interconnected continuum while sorption is represented as an equilibrium process van genuchten and wierenga 1976 since physical nonequilibrium was shown to be marginal in the columns the lack of agreement between the experimental and predicted pb btcs is attributed to chemical nonequilibrium processes in the columns chemical nonequilibrium results when the rate of sorption of solute is slower than the rate at which it moves with the bulk liquid toride et al 1995 and has been shown to be influenced by the pore water velocity darland and inskeep 1997 high pore water velocity results in a shorter residence time causing transport to be more anomalous or non fickian cortis et al 2004 these observations have important ramifications for the design of a full scale prb under equilibrium transport conditions i e when the behaviour of the contaminant obeys the fickian theory it is assumed that the entire adsorption capacity of the material becomes exhausted at the time of breakthrough consequently the thickness of the prb can be determined from the breakthrough point however for nonequilibrium conditions such as those observed in this study where breakthrough can occur before the adsorption capacity of the material is exhausted the thickness of the prb cannot be determined by the breakthrough time rather the residence time which captures the kinetic processes must be used as an example obiri nyarko et al 2014 provided eq 12 for determining the residence time tres of a first order reaction 12 t res ln c t c o k where ct is the target concentration down gradient of the prb mg dm3 c o is the concentration of the contaminant entering the prb mg l and k is the rate of reaction 1 min the prb thickness b for the first order reaction can then be calculated using eq 13 13 b v p x t res x sf where vp is the pore water velocity cm min tres is the residence time min and sf is a safety factor considered for all uncertainties in reaction kinetics and groundwater flow the effect of chemical nonequilibrium may be expected to reduce for field conditions where groundwater movement is slower than the velocity used in this study 3 3 2 dose response adams bohart and yoon nelson models the results of fitting the dose response yoon nelson and adams bohart models to the pb2 experimental data are shown in fig 5 for zeolite and fig 6 for compost zeolite while the estimated adsorption and kinetic parameters as well as the correlation coefficients and root mean square errors are presented in table 5 the dose response model showed good agreement with the experimental data for both column materials r2 0 95 rmse 0 091 sorption capacities qo determined from this model were also similar to the sorption capacities qe calculated by integrating the total area above the btcs prediction of pb2 btcs by the yoon nelson model was also in good agreement with the experimental data moreover the values of τ were similar to those obtained experimentally compared to the dose response model however relatively low r2 and high rmse were obtained for the yoon nelson model the adams bohart model was applied to describe the initial part of the btcs c c o 0 0 15 high r2 0 99 and low rmse 0 06 were obtained for both materials when it was fitted to the initial part of the btcs beyond this range large discrepancies were found between the experimental data and the predicted curves resulting in low r2 and high rmse this confirms that the adams bohart model is appropriate for analyzing the initial part of btcs homem et al 2018 as per the r2 and rmse listed in table 5 it can be concluded that both the dose response and yoon nelson models can be applied to describe the entire sorption process in both columns but the dose response model gives better fits the adams bohart model is only suitable for describing the initial part of the btcs table 6 gives the literature values of qo obtained from the sorption of pb2 onto a range of adsorbents as well as the respective experimental conditions under which they were obtained as can be seen the qo obtained for the materials in this study were only comparable to that of the sugarcane bagasse whereas it was lower than all the other listed materials this may be attributed to either the relatively low initial pb2 concentration high flow rate and or the low solution ph used in this study though the effects of these parameters were not investigated individually in this study they have been shown to influence the adsorption process in many other researches lim et al 2008 noted that pb2 adsorption by sawdust decreased from 2 307 to 1 636 mg g when the initial solution ph was decreased from 4 5 to 3 similar observation was reported by bektaş and kara 2004 and berber mendoza et al 2006 who studied pb2 removal from aqueous solution by natural clinoptilolite it was explained that at low solution ph ionic groups on the surface of the adsorbent become protonated resulting in repulsion of metal ions from the adsorption sites zhang et al 2010 berber mendoza et al 2006 also noted that low solution ph results in competition between h and metal ions for the same binding sites on the adsorbent due to the relatively large number of hydrogen ions in very acidic conditions ph 3 the competitive exchange of h with the exchangeable cations present in the zeolite framework was found to be the main reason for lower retention of zn2 cd2 and pb2 on zeolite minceva et al 2008 high initial sorbate concentration has also been shown to increase the amount of sorbate sorbed lim et al 2008 günay et al 2007 observed that the adsorption capacity of raw clinoptilolite for pb2 increased from 19 321 to 80 933 mg g when the initial pb2 concentration was increased from 50 to 400 mg dm3 as the initial concentration increases the amount and rate at which the adsorbate molecules pass from the bulk solution to the particle surface also increase medvidović et al 2006 however observed that both the breakthrough time and saturation time decrease as initial solute concentration increases in general column adsorption capacity and breakthrough time decrease as flow rate increases high flow rate minimizes the contact time between the adsorbate and the adsorbent and causes slow or no diffusion of contaminants into the particles after apparent fixed bed saturation has been reached weber and wang 1987 medvidović et al 2006 vijayaraghavan and prabu 2006 zeolite capacities and particle diffusion coefficients in columns were found to vary with the flow rate lehmann et al 2001 inglezakis and grigoropoulou 2003 a similar observation was made when vijayaraghavan and prabu 2006 studied cu adsorption by sargassum wightii the adsorption capacity of sargassum wightii decreased from 52 6 to 48 9 mg g when the flow rate was increased from 5 to 20 ml min a corresponding decrease in breakthrough time from 12 4 to 3 1 h was observed 3 3 3 hydraulic conductivity the initial and final hydraulic conductivities k of the column materials are presented in table 7 zeolite had an initial k of 2 14 10 3 cm s which is almost twice that of the compost zeolite k 1 20 10 3 cm s the difference could be due to differences in the grain size of the materials table 1 the final k measured for both materials were lower than the initial values for zeolite the k reduced slightly to 2 10 10 3 cm s representing about 2 reduction whereas it reduced to 8 54 10 4 cm s in the case of compost zeolite mixture representing 28 8 reduction these reductions could be attributed to hydration of zeolite clogging of existing flow paths due to dust migration in the columns park et al 2002 or particle attrition altare et al 2007 as indicated above both reactivity and hydraulic performance of the materials are important factors that must be considered when selecting reactive materials and designing prbs for in situ remediation of groundwater the initial k of the prb must be greater or equal to the k of the surrounding aquifer it is also important to note that during the prb operation several physical biological and chemical processes can occur that may lead to changes increase or decrease in the k of the prb excessive increase may lead to insufficient contact between the contaminant and the reactive material while flow of the contaminated groundwater in the barrier may be impeded causing preferential flow if there is excessive decrease henderson and demond 2007 consequently maintaining a constant k throughout the remediation period is imperative though the compost zeolite mixture has a relatively high reactivity the results show that significant decrease of k can occur when applied in a prb the k of zeolite on the other hand was almost maintained though it had relatively low reactivity and buffering capacity since both reactivity and k can be influenced by the mixing ratios of the mixtures obiri nyarko et al 2014 and the grain size further studies exploring these for the compost zeolite may be needed as it has been shown to be effective both in pb2 removal and ph buffering 4 conclusion the effectiveness of zeolite and the compost zeolite mixture as prb materials for removing pb2 from low ph groundwater was investigated the ability of the materials to buffer ph and their hydraulic performance were also studied the compost zeolite mixture was more effective than zeolite in the simultaneous removal of pb2 and neutralization of acidity the maximum adsorption capacity qo was of 0 151 mg g for the mixture and of 0 097 mg g for zeolite retardation factors determined by fitting of the ade to the lead btcs were r 41 for zeolite and r 60 for the compost zeolite mixture lead was removed via ion exchange and adsorption the occurrence of these mechanisms was supported by the presence of pboh in solution and the release of ca2 k na and mg2 during the uptake of pb2 the dose response model described the entire process of pb2 sorption onto the studied materials better than the yoon nelson model while the initial part of the adsorption process was well described by the adams bohart model hydraulic conductivity decreased by 28 8 of the initial value in the column with compost zeolite mixture and only about 2 for zeolite such decreases can affect the long term performance of the prb comparing the two materials zeolite alone may be used as filler in prbs under conditions similar to those investigated in this study while compost zeolite mixture may be used in some other applications further investigations may however be carried out to study the effects of different mixing ratios and grain size of the compost zeolite as these properties have been shown to affect both reactivity and hydraulic performance of reactive materials declaration of competing interest obiri nyarko franklin kwiatkowska malina jolanta malina grzegorz and wołowiec krzysztof the authors of the manuscript assessment of zeolite and compost zeolite mixture as permeable reactive materials for the removal of lead from a model acidic groundwater do hereby to declare that there is no conflict of interest in relation to this work acknowledgement the research leading to these results has received funding from the european community s seventh framework programme fp7 2007 2013 under grant agreement no 265063 
1541,column experiments were performed to assess the effectiveness of zeolite and compost zeolite mixture in removing dissolved lead pb2 from acidic water of ph 2 4 the acid neutralizing ability and hydraulic performance of the materials were also studied fitting the advection dispersion equation ade and mathematical models i e the dose response adams bohart and yoon nelson models to the pb2 experimental breakthrough curves btcs was also performed the compost zeolite mixture proved to be better than zeolite alone both in removing pb2 and in buffering the acidic ph the maximum adsorption capacity qo obtained for zeolite was 0 097 mg g and 0 151 mg g for the compost zeolite mixture respectively lead removal was attributed to ion exchange and adsorption observed pb2 btcs demonstrated sorption related nonequilibrium effects in the columns the hydraulic conductivity of zeolite decreased by 2 and by 28 8 in the case of compost zeolite mixture at the end of the experiment the entire experimental btc of pb2 was well described by the dose response model while the adams bohart model was better in describing only the initial part of the lead btcs keywords permeable reactive barriers zeolite compost lead modelling acidic groundwater 1 introduction acidic groundwater can be defined as groundwater with low buffering capacity as a result of a drop in alkalinity and an increase in acidity and other chemical modifications de caritat 1995 it is mostly found in terrains where the aquifer is porous shallow highly leached and where there is absence of carbonates giving rise to poorly buffered groundwater hansen and postma 1995 takem et al 2015 acidification of groundwater can be instigated by natural as well as anthropogenic phenomena such as dissociation of humic acids oxidation of sulphur and nitrogen compounds acid precipitation landfilling and mineral mining acid mine drainage knutsson 1994 wingenfelder et al 2005 natural acidification of groundwater can also be caused by deposition of sea salt loaded precipitation which can result in cation exchange of marine na with soil bound h and or a13 de caritat 1995 in most cases these natural and anthropogenic processes act in concert to exert their effect on the groundwater groundwater acidification used to be a major environmental problem in north america and europe knutsson 1994 appleyard et al 2004 in recent years however it has become an issue of global concern due to accelerating demographic growth and industrialization appleyard et al 2004 reported of widespread acidification of groundwater in perth western australia due to oxidation of sulfide minerals in an alluvial aeolian plain largely formed from quaternary sand and sand limestone dunes groundwater ph as low as 1 9 was measured in some shallow monitoring wells and boreholes in the area takem et al 2015 also reported of decreases in ph of shallow groundwater from a range of 3 94 7 70 to a range of 3 8 6 8 over a period of 15 years in an unconfined aquifer in the coastal urban town of douala cameroon in the western part of africa the acidification of the groundwater was attributed to acid atmospheric deposition industrial effluent discharges and acid spill chemical weathering and coastal atmospheric deposition cation exchange acidic groundwater can be detrimental to both aquatic and terrestrial organisms it may trigger the mobilization of heavy metals such as zinc cadmium lead copper and nickel kjoller et al 2004 these metals have the potential of causing both acute and chronic haematological as well as neurological problems when taken up by humans jaishankar et al 2014 knutsson 1994 also reported that surface waters interacting with groundwater of ph lower than 5 could support few or no fish species and very few species of invertebrates in many regions of finland norway and sweden additionally depending on the geology and the predominant cause s of acidification the groundwater may be characterized by moderate to high levels of sulphate iron manganese which can make it harmful for human use doye and duchesne 2003 wingenfelder et al 2005 permeable reactive barriers prbs have been widely acknowledged as cost effective and sustainable alternative to other established treatment methods such as the conventional pump and treat p t systems for remediating shallow groundwater initially the prb was installed to remediate groundwater impacted by chlorinated solvents such as perchlorethylene pce and trichloroethylene tce henderson and demond 2007 obiri nyarko et al 2014 later due to the successful removal of the contaminants prbs were applied to remove other contaminants such as nutrients e g no3 so4 2 heavy metals e g pb cu cd zn as and petroleum hydrocarbons e g benzene toluene ethylbenzene xylene henderson and demond 2007 obiri nyarko et al 2014 prbs have also been used for other purposes such as amelioration of acidity or alkalinity of groundwater waybrant et al 2002 gibert et al 2011 in general remediation of groundwater by prbs is accomplished by the emplacement of a carefully selected reactive medium across the flow trajectory of the contaminant plume which removes the contaminants or ameliorates its conditions passively via processes such as precipitation adsorption ion exchange and biodegradation henderson and demond 2007 obiri nyarko et al 2014 two main factors are considered when assessing the performance of prbs these are the high reactivity and good long term hydraulic performance of the materials therefore materials that meet these criteria and are of low cost are the most preferred natural zeolites are one of the low cost materials frequently evaluated as prb materials for the removal of contaminants from groundwater jun et al 2009 huang et al 2015 obiri nyarko et al 2015a they have received tremendous attention due to their porous nature moreover they are also effective in removing a variety of heavy metals which is often accompanied by the release of non toxic exchangeable cations k na ca2 and mg2 to the environment they are also able to buffer acidic or alkaline water perić et al 2004 wingenfelder et al 2005 medvidović et al 2006 under extremely acidic conditions however there can be deterioration of their effectiveness due to disintegration of their structure or rejection of heavy metals due to the preponderance of h both phenomena can lead to early contaminant breakthrough wingenfelder et al 2005 cozmuta et al 2012 obiri nyarko et al 2015b this is undesirable especially when used for the removal of heavy metals under acidic conditions compost is a low cost material that can be derived from agricultural by products or industrial waste materials it has also received wide acclaim for groundwater remediation in recent times compost contains functional groups such as carboxylic acid and phenolic hydroxyl which make it possible for both ph buffering and removal of heavy metals mikkelsen 2005 in batch tests compost was shown to increase ph from 3 2 to 7 1 obiri nyarko et al 2015a and reduce dissolved pb concentrations by over 91 seelsaen et al 2007 obiri nyarko et al 2015a the downside of compost when used alone however is that its organic component can decompose resulting in an increase of the prb permeability this can affect the residence time as well as the long term reactivity of the compost to overcome such problems chemical treatment or its combination with other materials has been used as a technique for improving physical chemical properties as well as performance of compost mondal 2009 the addition of compost to zeolite could therefore offset the weaknesses of these individual reactive materials however such a combination has so far not been investigated neither under dynamic conditions nor for the removal of heavy metals from acidic groundwater accordingly column experiments were carried out to compare the effectiveness of zeolite and compost zeolite mixture 1 3 5 by weight which was found optimal in the previous batch study obiri nyarko et al 2015a as prb materials in concomitantly neutralizing acidic groundwater and removing pb2 lead one of the toxic metals listed among the priority pollutants by us epa nakada et al 1979 bellinger and bellinger 2006 was used as a representative contaminant because of its widespread presence in the environment and toxicity to human health through accumulation in living tissues and the food chain fan et al 2014 hydraulic conductivity tests were also performed to assess the hydraulic performance of the materials this is particularly important as decreases in hydraulic conductivity causing prb failures have frequently been reported in the literature henderson and demond 2007 moraci et al 2016 the advection dispersion equation ade van genuchten 1981 the adams bohart model bohart and adams 1920 the dose response model yan et al 2001 and the yoon nelson model yoon 1984 were also applied to the pb2 experimental data to allow further interpretation of the results 2 materials and methods 2 1 reactive materials and test solution natural zeolite and compost a by product derived from food and plant waste were obtained in poland and used in this study impurities in the compost were removed by handpicking while the zeolite was washed with deionized water both materials were air dried before used detailed description of the materials as well as experiments to determine their environmental compatibility have been reported in obiri nyarko et al 2015a 2015b briefly the zeolite used was chemically composed of sio2 69 9 al2o3 12 5 fe2o3 1 6 mgo 0 9 cao 2 4 mno 1 1 h2o 8 0 na2o 0 3 k2o 3 1 and tio 0 3 mineralogical characterization by xrd philips apd pw 3020 x pert fitted with goniometer cu lamp and a graphite monochromator also showed that it was dominated by clinoptilolite 75 other physical and chemical properties including the ph bulk density ρb cation exchange capacity cec and moisture content mc of the zeolite and compost are presented in table 1 stock solution of 1000 mg pb2 dm3 was prepared by spiking deionized water with analytical grade of pb fluka and thereafter stirred for 10 min with a magnetic stirrer from the stock pb2 solution of concentration 1 76 mg pb2 dm3 and ph 2 4 was prepared and used for the experiments the ph of the solution was adjusted with 0 1 m naoh and hno3 to the desired value to support the modelling with the ade a conservative tracer solution using sodium chloride nacl was prepared one 1 g of nacl salt was dissolved in 1 dm3 of deionized water and later diluted for the experiments all the chemicals used in study were of analytical grade 2 2 column experiments the column experiments were carried out in stainless steel cylinders of length 30 cm inner diameter of 5 35 cm and ca 675 cm3 internal volume fig 1 the columns had two inlets at the base one for feeding the column with the influent solution and the other for influent sample collection and two similar outlets at the top for discharge of the effluent solution and collection of effluent samples for analysis each column was divided into three sections the top and bottom sections were packed with 170 g of glass beads grain size 2 3 mm and the middle portion was filled with the reactive material all the columns were packed manually the amount of material total pore volume pv bulk density and total porosity n of the packed columns are summarized in table 2 the total pv was estimated from the saturated and dry weights of the packed columns and the total porosity was determined gravimetrically by dividing the total pv by the total volume of the columns determination of the bulk density was accomplished by dividing the weight of the packed column by its total volume before permeating the columns with the test solution deionized water was flushed through them to equilibrate the system subsequently a peristaltic pump was used to introduce the solutions into the columns in an upward flow direction at a flow rate of 1 67 cm3 min which is equivalent to an average darcy flux of ca 107 cm day the imposed flow rate was to expedite the exhaustion of the reactive media effluent samples were taken at predetermined time intervals using disposable glass syringe part of the taken samples were analyzed immediately for pb2 using adsorption atomic spectrophotometry aas 3 corp zeiss detection limit of 0 001 mg dm3 and exchangeable cations ca2 mg2 na and k using ion chromatography chloride was determined titrimetrically using agno3 as the standard and k2cro4 as the indicator korkmaz 2001 unanalyzed pb2 samples were preserved by acidification with concentrated hno3 and stored in the refrigerator part of the unfiltered effluent samples were analyzed immediately for ph using a multifunctional computer meter elmetron cx 742 in all cases the ph meter was calibrated with standard solutions of 4 7 and 10 ph units before use 2 3 analysis of breakthrough curves btcs analysis of the effectiveness of the reactive materials in attenuating pb2 in the columns was based on breakthrough curves btcs which were obtained by plotting the relative concentrations of pb2 i e effluent concentration c influent concentration c o against the effluent volume a c c o 0 05 i e the point on the btc where the effluent solute concentration is 5 of its influent value was considered as the breakthrough point while c c o 0 95 i e the point on the btc where the effluent concentration is 95 of its influent value was considered as point of column exhaustion medvidović et al 2006 the total amount of the pb2 injected into the columns mtotal mg was determined using eq 1 1 m total c o q t total 1000 where ttotal represents the total experimental time min q is the flow rate cm3 min the total mass of pb2 removed qtotal mg in the column was determined using eq 2 2 q total q 1000 0 t total c rem dt where crem c o ct is the reduction of the pb2 concentration in the effluent from the column due to sorption mg dm3 the rate of pb2 removal r and the total removal capacity of the material qe mg g were determined using eqs 3 and 4 respectively 3 r q total m total x 100 4 q e q total m where m is the mass of the adsorbent g 2 4 modelling the pb2 breakthrough curves btcs the btcs of pb2 were modelled using the advection dispersion equation ade dose response adams bohart and yoon nelson models 2 4 1 the advection dispersion equation ade the ade has been used extensively to describe solute transport in porous media van genuchten 1981 ogata and banks 1961 it can be fitted to experimental data from column studies and used to predict future treatment performance eq 5 can be used as the analytical solution to the ade for a one dimensional case ogata and banks 1961 5 c c o 1 2 erfc rz v p t 2 d l tr 1 2 1 2 exp v p x d l erfc rz v p t 2 d l tr 1 2 where vp cm min is the average pore water velocity z cm is length of the column r is the retardation factor dl cm2 min is the hydrodynamic dispersion coefficient c and c o are the effluent and input concentrations of pb2 mg dm3 erfc is the complementary error function and t is the time min dl is the sum of the effective diffusion coefficient df and mechanical dispersion coefficient dm i e dl df dm the dm is a function of the pore water velocity and the dispersivity of the porous material dm αvp where α is the longitudinal dispersivity cm min as vp 0 dm 0 and diffusion becomes the dominant transport mechanism i e dl df also when diffusion is negligible mechanical dispersion becomes the dominant transport mechanism and dl αvp eq 5 was first fitted to the chloride experimental data to determine the hydrodynamic properties including the vp and dl chloride was assumed to behave as a conservative element i e it is not subject to any sorption ion exchange or anion exclusion processes and so the retardation factor r was set to 1 while the vp and dl were regressed until the simulated btc was similar to the experimental cl btc the péclet number p e describing the relative importance of molecular diffusion and mechanical dispersion in the transport of solute was calculated from the vp and dl using eq 6 6 p e v p z d l thereafter eq 5 was fitted to the btcs of pb2 for both materials using the vp and dl estimated from the chloride curve fitting to determine the retardation of pb2 all the transport processes evaluated in this study with the ade were performed using the following initial and boundary conditions ogata and banks 1961 c x 0 0 c t 0 c 0 t c o i e the initial condition is c 0 for the entire sample and the boundary conditions are c 0 at an infinite distance from the inlet and c c o at the inlet 2 4 2 the dose response model the dose response model was proposed by yan et al 2001 and was initially developed for pharmacological studies it has recently been used to describe metal adsorption kinetics in continuous columns senthilkumar et al 2006 araneda et al 2011 and is also known to reduce the errors of conventional mathematical models such as the adams bohart model yan et al 2001 it can be represented by eq 7 7 c c o 1 1 1 c o v q o m k where c o is the initial concentration and c is the concentration mg dm3 k represents the kinetic constant of the dose response model v is the effluent volume dm3 qo represents the maximum concentration of the solute in the solid phase mg g and m is the mass of the adsorbent g 2 4 3 the adams bohart model adams and bohart model assumes that the equilibrium is not instantaneous and that the sorption rate is proportional to the residual capacity of the solid and the concentration of the sorbed substance bohart and adams 1920 it is generally used to describe the initial portion c c o 0 15 of the breakthrough curve homem et al 2018 the model can be expressed as eq 8 8 c c o exp k ab c o t k ab n o z v p where c o and c are the input and effluent metal ions concentration in mg dm3 kab is the kinetic constant in dm3 mg min no is the maximum volumetric sorption capacity in mg dm3 z is the length of the column in cm and vp is the pore water velocity in cm min 2 4 4 the yoon nelson model the yoon nelson model is based on the assumption that the rate of decrease in the probability of adsorption for each sorbate molecule is proportional to the probability of adsorbate adsorption and the probability of adsorbate breakthrough on the adsorbent this model has been widely used especially in single adsorbate systems yoon 1984 due to the simplicity of its expression moreover it requires no detailed data concerning the characteristics of the adsorbate the type of adsorbent and the physical properties of the adsorbent ayoob and gupta 2007 the eq 9 is given as 9 c c o 1 1 e k yn τ t where τ is the time required for 50 adsorbate breakthrough min and kyn is the rate constant dm3 min and t is the breakthrough sampling time min 2 4 5 error analysis the accuracy of fitting the models to the experimental data was evaluated based on the coefficient of determination r2 and root mean square error rmse eq 10 the higher the r2 and smaller closer to 0 the rmse the better is the model prediction low r2 and large rmse indicate large overestimation or underestimation of the experimental data by the model 10 rmse j 1 n c c o cal c c o exp 2 n where c c o cal and c c o exp respectively are the predicted and measured relative concentration at time t n is the number of observations 2 5 determination of hydraulic conductivity to study the hydraulic performance of the reactive materials hydraulic conductivity k of the materials was determined before and after the experiments using the constant head method head and keeton 2008 the k was calculated using eq 11 11 k vz hat where k is the hydraulic conductivity cm s a is the cross sectional area of the column cm2 h is the head difference cm z is the length of the column cm t is time s and v is effluent volume cm3 3 results and discussion 3 1 lead breakthrough curves btcs and effects of reactive materials on ph breakthrough curves btcs showing pb2 removal from the acidic water by zeolite and compost zeolite as well as the ability of the materials to neutralize acidic ph are shown in fig 2a and b in table 3 the results of the quantitative analyses of the btcs are presented pb2 breakthrough occurred in zeolite at pv 30 whereas it was delayed to pv 40 in the compost zeolite as shown in table 3 both the rate of pb2 removal and the adsorption capacity determined by integration of the btcs were also higher for the mixture than zeolite this is likely due to a synergistic effect produced by the addition of compost to the zeolite in both columns however c co 0 95 was not reached signifying that the capacities of the materials were not exhausted at the time the experiments were stopped solution ph is one of the important operational parameters that affect the adsorption of metals onto adsorbents the uptake capacity of metal ions the adsorption mechanism the degree of ionization the surface charge of the adsorbent and the speciation of the adsorbate are all largely affected by the ph of the solution heidari et al 2013 as shown in fig 2a and b both materials raised the ph from 2 4 to above 7 initially but in the case of zeolite the ph dropped rapidly thereafter while the decline was gradual in the case of the compost zeolite mixture though both materials were able to keep the effluent ph above the influent ph of 2 4 the results clearly show that the compost zeolite mixture has a higher capacity to buffer acidic ph than zeolite this may be attributed to the differences in their cecs table 1 as well as the inherent ph of the compost 8 05 table 1 it can also be seen from fig 2a and b that the shapes of the ph profiles were the opposite of the btcs indicating that by observing the ph profiles the behaviour of lead in the materials can also be determined a number of ph buffering mechanisms can be suggested for the studied materials these include i the exchange of h with exchangeable cations e g na and k in both zeolite and compost rivera et al 2000 medvidović et al 2006 filippidis and kantiranis 2007 latifah et al 2018 ii protonation of functional groups e g phenolic and carboxyls in the case of compost latifah et al 2018 and iii binding of h to the lewis basic sites linked to the framework oxygen atoms of the zeolite filippidis and kantiranis 2007 3 2 pb2 removal mechanisms the immobilization of heavy metals by the studied materials is a complex process that may comprise one or more of the following ion exchange adsorption and precipitation of metal ion hydroxide complexes on active sites of the particle surface trgo and perić 2003 latifah et al 2018 the process may be ion exchange if there is stoichiometric replacement of an ion in the solid phase by an equivalent of another ion in the liquid phase i e the amount of cations displaced into solution is equal to the amount of metals taken up onto the solid phase ion exchange reactions are also referred as outer sphere complexation and do not involve formation of bonds between metal ions and sorbent surface doula and ioannou 2003 if the metal ion is removed from solution into the solid phase without displacement of any cations into solution or removal of equal amount of cations the process is adsorption also referred to as chemisorption or inner sphere complexation bolt et al 1978 precipitation of the metals as sparingly soluble salts or hydroxides on the other hand is accompanied by the simultaneous removal of some anions from solution without displacing any sorbed cations ponizovsky and tsadilas 2003 minceva et al 2008 noted that solution ph affects the mechanism of metal ions binding by changing it from ion exchange and or adsorption at acidic region to adsorption and or complexation and possible precipitation at the basic region lead removal from solution by the studied materials was possibly via ion exchange and adsorption removal via precipitation is considered marginal in this study regarding the measured ph values during the removal of lead by the materials ca2 k na and mg2 were released into solution fig 3a and b suggesting the occurrence of ion exchange in the columns perić et al 2004 wingenfelder et al 2005 obiri nyarko et al 2015b though separate experiments were not performed to confirm this it is probable that the ca2 k na and mg2 were released not only in exchange for pb2 but also for h taking into consideration the high concentration of the latter solution and the ph profiles in fig 2a and b adsorption of lead as pboh is also suggested considering the effluent ph values measured in this study which ranged from 3 32 to 8 02 geochemical simulations using minteq showed that the dominant lead species at effluent ph of 8 02 were pb2 28 84 pb3 oh 4 2 0 05 pboh 68 59 and pb oh 2 aq 2 51 and at effluent ph of 3 32 the solution was saturated with pb2 99 99 the high concentration of pboh in solution could result in lead removal as pboh via adsorption onto the inner surface of the zeolite perić et al 2004 minceva et al 2008 3 3 modelling breakthrough curves btcs of pb2 3 3 1 the advection dispersion equation ade the experimental and simulated btcs of lead and chloride for the studied materials are shown in fig 4a and b while the estimated parameters are presented in table 4 the chloride experiments were performed to evaluate the flow characteristics of the columns more than 99 of the injected chloride was recovered in fig 4a and b it can be seen that the experimental btcs of the chloride did not exhibit any significant tailing that would suggest the presence of physical nonequilibrium processes in the columns i e non uniform flow as a result of mobile immobile regions chloride experimental btcs were well described by the ade r2 98 rmse 0 06 the dispersion coefficients were of 0 735 cm2 min for zeolite and 0 593 cm2 min for the compost zeolite and the respective dispersivities calculated from dl αvp were of 3 5 cm and 3 12 cm the p e estimated was 8 57 for zeolite and 9 61 for compost zeolite signifying that solute transport was predominantly controlled by mechanical dispersion in both columns according to fetter 2001 p e 0 4 indicates that solute transport is controlled mainly by molecular diffusion while p e between 0 4 and 6 suggests that transport of solute results from the combined effects of molecular diffusion and mechanical dispersion higher p e 6 indicates the dominance of mechanical dispersion over molecular diffusion following the good agreement between the chloride experimental data and the ade simulated btcs the vp and dl obtained from the chloride curve fitting were fixed in eq 5 for the determination of r in the case of lead it can be seen from fig 4a and b that lead was strongly retarded by the column materials vis à vis the chloride which travelled at the same velocity as that of water r 1 between the two materials fitted pb retardation factors indicate relatively high retardation of lead by the compost zeolite r 60 in comparison to the zeolite r 41 it is conspicuous however that the ade could not fit the lead experimental data well as it did the chloride data especially for zeolite the ade predicted an early breakthrough time and underestimated the the mass of lead adsorbed in the columns at the end of the experiment especially in the column with zeolite several studies have shown that the ade is unable to accurately predict solute behaviour in systems where physical and chemical nonequilibrium processes are present van genuchten and wierenga 1976 the ade suffers this drawback because it was developed on the assumption of uniform flow and transport i e the porous medium is considered as an interconnected continuum while sorption is represented as an equilibrium process van genuchten and wierenga 1976 since physical nonequilibrium was shown to be marginal in the columns the lack of agreement between the experimental and predicted pb btcs is attributed to chemical nonequilibrium processes in the columns chemical nonequilibrium results when the rate of sorption of solute is slower than the rate at which it moves with the bulk liquid toride et al 1995 and has been shown to be influenced by the pore water velocity darland and inskeep 1997 high pore water velocity results in a shorter residence time causing transport to be more anomalous or non fickian cortis et al 2004 these observations have important ramifications for the design of a full scale prb under equilibrium transport conditions i e when the behaviour of the contaminant obeys the fickian theory it is assumed that the entire adsorption capacity of the material becomes exhausted at the time of breakthrough consequently the thickness of the prb can be determined from the breakthrough point however for nonequilibrium conditions such as those observed in this study where breakthrough can occur before the adsorption capacity of the material is exhausted the thickness of the prb cannot be determined by the breakthrough time rather the residence time which captures the kinetic processes must be used as an example obiri nyarko et al 2014 provided eq 12 for determining the residence time tres of a first order reaction 12 t res ln c t c o k where ct is the target concentration down gradient of the prb mg dm3 c o is the concentration of the contaminant entering the prb mg l and k is the rate of reaction 1 min the prb thickness b for the first order reaction can then be calculated using eq 13 13 b v p x t res x sf where vp is the pore water velocity cm min tres is the residence time min and sf is a safety factor considered for all uncertainties in reaction kinetics and groundwater flow the effect of chemical nonequilibrium may be expected to reduce for field conditions where groundwater movement is slower than the velocity used in this study 3 3 2 dose response adams bohart and yoon nelson models the results of fitting the dose response yoon nelson and adams bohart models to the pb2 experimental data are shown in fig 5 for zeolite and fig 6 for compost zeolite while the estimated adsorption and kinetic parameters as well as the correlation coefficients and root mean square errors are presented in table 5 the dose response model showed good agreement with the experimental data for both column materials r2 0 95 rmse 0 091 sorption capacities qo determined from this model were also similar to the sorption capacities qe calculated by integrating the total area above the btcs prediction of pb2 btcs by the yoon nelson model was also in good agreement with the experimental data moreover the values of τ were similar to those obtained experimentally compared to the dose response model however relatively low r2 and high rmse were obtained for the yoon nelson model the adams bohart model was applied to describe the initial part of the btcs c c o 0 0 15 high r2 0 99 and low rmse 0 06 were obtained for both materials when it was fitted to the initial part of the btcs beyond this range large discrepancies were found between the experimental data and the predicted curves resulting in low r2 and high rmse this confirms that the adams bohart model is appropriate for analyzing the initial part of btcs homem et al 2018 as per the r2 and rmse listed in table 5 it can be concluded that both the dose response and yoon nelson models can be applied to describe the entire sorption process in both columns but the dose response model gives better fits the adams bohart model is only suitable for describing the initial part of the btcs table 6 gives the literature values of qo obtained from the sorption of pb2 onto a range of adsorbents as well as the respective experimental conditions under which they were obtained as can be seen the qo obtained for the materials in this study were only comparable to that of the sugarcane bagasse whereas it was lower than all the other listed materials this may be attributed to either the relatively low initial pb2 concentration high flow rate and or the low solution ph used in this study though the effects of these parameters were not investigated individually in this study they have been shown to influence the adsorption process in many other researches lim et al 2008 noted that pb2 adsorption by sawdust decreased from 2 307 to 1 636 mg g when the initial solution ph was decreased from 4 5 to 3 similar observation was reported by bektaş and kara 2004 and berber mendoza et al 2006 who studied pb2 removal from aqueous solution by natural clinoptilolite it was explained that at low solution ph ionic groups on the surface of the adsorbent become protonated resulting in repulsion of metal ions from the adsorption sites zhang et al 2010 berber mendoza et al 2006 also noted that low solution ph results in competition between h and metal ions for the same binding sites on the adsorbent due to the relatively large number of hydrogen ions in very acidic conditions ph 3 the competitive exchange of h with the exchangeable cations present in the zeolite framework was found to be the main reason for lower retention of zn2 cd2 and pb2 on zeolite minceva et al 2008 high initial sorbate concentration has also been shown to increase the amount of sorbate sorbed lim et al 2008 günay et al 2007 observed that the adsorption capacity of raw clinoptilolite for pb2 increased from 19 321 to 80 933 mg g when the initial pb2 concentration was increased from 50 to 400 mg dm3 as the initial concentration increases the amount and rate at which the adsorbate molecules pass from the bulk solution to the particle surface also increase medvidović et al 2006 however observed that both the breakthrough time and saturation time decrease as initial solute concentration increases in general column adsorption capacity and breakthrough time decrease as flow rate increases high flow rate minimizes the contact time between the adsorbate and the adsorbent and causes slow or no diffusion of contaminants into the particles after apparent fixed bed saturation has been reached weber and wang 1987 medvidović et al 2006 vijayaraghavan and prabu 2006 zeolite capacities and particle diffusion coefficients in columns were found to vary with the flow rate lehmann et al 2001 inglezakis and grigoropoulou 2003 a similar observation was made when vijayaraghavan and prabu 2006 studied cu adsorption by sargassum wightii the adsorption capacity of sargassum wightii decreased from 52 6 to 48 9 mg g when the flow rate was increased from 5 to 20 ml min a corresponding decrease in breakthrough time from 12 4 to 3 1 h was observed 3 3 3 hydraulic conductivity the initial and final hydraulic conductivities k of the column materials are presented in table 7 zeolite had an initial k of 2 14 10 3 cm s which is almost twice that of the compost zeolite k 1 20 10 3 cm s the difference could be due to differences in the grain size of the materials table 1 the final k measured for both materials were lower than the initial values for zeolite the k reduced slightly to 2 10 10 3 cm s representing about 2 reduction whereas it reduced to 8 54 10 4 cm s in the case of compost zeolite mixture representing 28 8 reduction these reductions could be attributed to hydration of zeolite clogging of existing flow paths due to dust migration in the columns park et al 2002 or particle attrition altare et al 2007 as indicated above both reactivity and hydraulic performance of the materials are important factors that must be considered when selecting reactive materials and designing prbs for in situ remediation of groundwater the initial k of the prb must be greater or equal to the k of the surrounding aquifer it is also important to note that during the prb operation several physical biological and chemical processes can occur that may lead to changes increase or decrease in the k of the prb excessive increase may lead to insufficient contact between the contaminant and the reactive material while flow of the contaminated groundwater in the barrier may be impeded causing preferential flow if there is excessive decrease henderson and demond 2007 consequently maintaining a constant k throughout the remediation period is imperative though the compost zeolite mixture has a relatively high reactivity the results show that significant decrease of k can occur when applied in a prb the k of zeolite on the other hand was almost maintained though it had relatively low reactivity and buffering capacity since both reactivity and k can be influenced by the mixing ratios of the mixtures obiri nyarko et al 2014 and the grain size further studies exploring these for the compost zeolite may be needed as it has been shown to be effective both in pb2 removal and ph buffering 4 conclusion the effectiveness of zeolite and the compost zeolite mixture as prb materials for removing pb2 from low ph groundwater was investigated the ability of the materials to buffer ph and their hydraulic performance were also studied the compost zeolite mixture was more effective than zeolite in the simultaneous removal of pb2 and neutralization of acidity the maximum adsorption capacity qo was of 0 151 mg g for the mixture and of 0 097 mg g for zeolite retardation factors determined by fitting of the ade to the lead btcs were r 41 for zeolite and r 60 for the compost zeolite mixture lead was removed via ion exchange and adsorption the occurrence of these mechanisms was supported by the presence of pboh in solution and the release of ca2 k na and mg2 during the uptake of pb2 the dose response model described the entire process of pb2 sorption onto the studied materials better than the yoon nelson model while the initial part of the adsorption process was well described by the adams bohart model hydraulic conductivity decreased by 28 8 of the initial value in the column with compost zeolite mixture and only about 2 for zeolite such decreases can affect the long term performance of the prb comparing the two materials zeolite alone may be used as filler in prbs under conditions similar to those investigated in this study while compost zeolite mixture may be used in some other applications further investigations may however be carried out to study the effects of different mixing ratios and grain size of the compost zeolite as these properties have been shown to affect both reactivity and hydraulic performance of reactive materials declaration of competing interest obiri nyarko franklin kwiatkowska malina jolanta malina grzegorz and wołowiec krzysztof the authors of the manuscript assessment of zeolite and compost zeolite mixture as permeable reactive materials for the removal of lead from a model acidic groundwater do hereby to declare that there is no conflict of interest in relation to this work acknowledgement the research leading to these results has received funding from the european community s seventh framework programme fp7 2007 2013 under grant agreement no 265063 
1542,a contaminant source localisation strategy was developed considering unknown heterogeneous hydraulic conductivity field unknown dispersivity and unknown location of a continuous contaminant source the gauss levenberg marquardt algorithm is combined with a data worth analysis to estimate the unknown parameters and identify the best locations of additional measurements the data collection strategy is iterative based on the ability of the additional dataset to decrease the uncertainties on the contaminant source location two 2d synthetic models are considered the method is first illustrated with a simple model and a more complex model is then considered to evaluate the ability of the approach to locate the contaminant source from hydraulic heads and concentration data this approach is parsimonious in terms of model runs and applicable to real cases the results give a good estimate of the source location and the dispersivity with acceptable nrmse for each case new observations introduced at each iteration decrease the standard deviation of the source location and improve the nrmse the estimated hydraulic conductivity field presents the same features as the original field keywords contaminant source localisation iterative strategy glma data worth heterogeneous synthetic cases k field estimation abbreviations glma gauss levenberg marquardt algorithm dw data worth svd singular value decomposition rmse root mean square error n rmse normalized root mean square error 1 introduction the identification of contaminant source location is a challenge for the management of numerous contaminated sites a good knowledge of the source location allows a better strategy for the site remediation and the reduction of treatment costs migration plume processes are linked to the porous medium properties which are highly heterogeneous causing concentrated mass fluxes in a small zone studies showed that 70 80 of the plume mass discharge occurs in 10 20 of the contaminated area guilbeault et al 2005 this 10 is the true source zone which may often be quite small but has to be localised during the past 30 years groundwater flow and pollutant transport models coupled with different inversion methods have been developed for source identification a number of methods are available in the literature to estimate source localisation in synthetic cases from observations mostly concentration data these methods can be classified as follows nonlinear optimisation approach geostatistical approach or backward simulation approach bagtzoglou and atmadja 2005 optimisation methods are the most used approaches and allow source localisation from the comparison between observed and simulated data after a forward simulation gorelick et al 1983 were the first to use an optimisation method for source localisation the test was carried out on a 2d homogeneous synthetic case in steady and transient states all parameters of the geological medium were known hydrodynamics and transport observations were represented by concentration history of the tracer moreover errors on observations were considered the method presented in their paper is a restrictive method and is not suitable for real cases due to the requirement of known parameters such as wagner 1992 who used a nonlinear optimisation method and worked on a synthetic 2d case in steady state he developed an approach to simultaneously respond to parameter estimation and source characterization with nonlinear maximum likelihood estimation the source was considered as continuous initial parameters are unknown field of hydraulic conductivity k dispersivity α l porosity w and boundary conditions since the k field is parametrized with only two zones of piecewise constancy this facilitates the source localisation mahar and datta 1997 used a nonlinear optimisation method combining source localisation and the identification of the best location for additional measurement points measurement of source fluxes they considered a synthetic 2d homogeneous case in steady state with known hydrogeological and transport parameters the same authors worked with a homogeneous 2d case mahar and datta 2000 to identify the location of a transient source with several observations concentrations datta et al 2009 used the same synthetic case to estimate simultaneously parameters k field α l and w and release history of several potential sources with a nonlinear program estimated parameters were close to the actual value and proved the robustness of the method in a homogeneous case sun et al 2006 also worked on several 2d homogeneous cases in transient state with constrained robust least squares estimator combined with an optimization in order to reduce significantly the computing time aral et al 2001 used a genetic algorithm allowing a nonlinear optimisation and provides a fair results improvment the latter approach is based on a 2d heterogeneous model in steady state k field and α l are known with a transient source other optimisation methods stochastic or ensemble optimisation for instance have also been developed by singh et al 2004 yeh et al 2007 yeh et al 2014 ayvaz 2016 xu and gómez hernández 2016 2018 and applied to this domain unlike previous papers that carried out their analysis on synthetic cases bashi azghadi et al 2016 worked on a real case with a nonlinear optimisation method which minimises the number of probing wells and average regret in estimating polluted area the site is a highly polluted oil refinery due to leakage from several tanks and the contaminant release is known to minimise the number of probing wells the authors used a monte carlo analysis to assess uncertainties with a large number of randomly generated scenarios considering several variables such as the oil tank position at the origin of the contamination the method permits the location of the source with a limited number of observations during the last 20 years geostatistical approaches have been used for source identification snodgrass and kitanidis 1997 used a geostatistical method combined with bayesian theory tarantola 1987 to localise a source between two potential zones in a 1d homogeneous synthetic case with a concentration release they considered known hydraulic conductivity fields k fields and dispersivities α michalak and kitanidis 2004a used geostatistical inverse modelling for contaminant source identification in a real site with observed field data with known hydraulic and transport parameters this study showed that the history of contamination can be estimated with a good precision gzyl et al 2014 worked also in a real site with several sources using a multi step approach to identify the contaminant release history with a geostatistical method butera et al 2013 developed an analytical method for source localisation based on the geostatistical approach used by snodgrass and kitanidis 1997 other methods using backward simulation coupled or not to geostatistics were developed these methods consider known homogeneous or heterogeneous k field and known α l bagtzoglou et al 1992 were among the first to use the inversion of transport equation to localise a source in their work transport equation was modelled with an inverse time and an unchanged dispersivity neupauer and wilson 1999 used the adjoint method in a synthetic case with only one observation the approach was also tested with several observations to localise sources in a real site in a 1d case neupauer and wilson 2005 michalak and kitanidis 2004b coupled the adjoint method for backward simulation with a geostatistical approach to identify the historical distribution of contaminant cupola et al 2015 compared the adjoint method with the approach developed by butera et al 2013 for a source localisation in a sand tank authors established the reliability of both methods and showed that the adjoint method is able to detect only one source compared to cupola et al 2015 approach recently xu and gomez hernandez 2018 presented a method to simultaneously identify a source and estimate a k field with a kalman filter like approach the identification was proven with this method but uncertainty about k field generated was significant also the dispersivity was considered as known this study is original in that the k field is also estimated together with the source location which makes the case closer to real world problem table 1 summarises the characteristics of the existing approaches and shows that few studies can be applied to real case indeed the challenge for real world cases is to deal with unknown heterogeneous field of hydraulic properties and unknown transport parameters dispersivities in such contexts the source identification may become challenging numerous studies consider known or homogeneous parameter fields yet estimated location may be largely uncertain when inferred with biased parameters the implementation of source identification methods that require a large number of model runs is often limited by the computational burden associated with advective dispersive transport models considering these constraints this paper proposes an optimisation approach using the glma to identify jointly the source hydraulic and transport properties in order to provide an approach applicable to realistic case studies with unknown parameters we consider here that hydraulic conductivity dispersivity and source location are unknown and the contaminant release is constant to our knowledge the glma has not been used before for contaminant source localisation as the problem includes a lot of uncertainty and generally very few measurement points the second objective is to analyse the collection of complementary field data to better constrain the uncertainty of the unknown parameters more precisely the objective is to add new measurement points to decrease uncertainties about source location to place these additional observations a data worth analysis can be used with available tools as predunc moore et al 2010 or pyemu a python script developed by white et al 2016 due to the cost of a drilling only a limited number of data can be added and dw analysis leads to optimize observation strategies with limited costs data worth analysis dw was studied by several authors in hydrogeology to optimize the data collection while increasing value of information and therefore shrinking more the uncertainty this analysis is performed with nonlinear optimisation methods such as the ones developed in freeze et al 1992 james and freeze 1993 james and gorelick 1994 fu and gómez hernández 2009 from the 70 s to the 2000 s several studies conducted dw analysis in the context of hydrogeological problems i e gates and kisiel 1974 maddock 1973 dausman et al 2010 hill et al 2013 other authors used dw analysis for hydrogeological and remediation problems based on finding the best location for pump treat tucciarelli and pinder 1991 freeze et al 1992 james and gorelick 1994 wallis et al 2014 used the dw for transport problem with an evaluation of the introduction of multiple observations in a tracer test experiment wöhling et al 2016 extended the multiple observations approach with two types of data hydraulic conductivity k and heads data h to decrease the predictive uncertainty of the hyporheic fluxes travel time they used a genetic algorithm to find an optimal combination of predefined number of measurement location vilhelmsen and ferré 2017 worked only with a single type of data hydraulic conductivity they extend the dw analysis to select multiple observations to reduce one or multiple forecast wöhling et al 2016 tested the multiple observations with a genetic algorithm 2500 potential new measurement location is included and 1 million combinations of a maximum of 4 measurements are considered to find the best location of new data which is not easy to implement for a practical case glma combined with a data worth analysis are used in this manuscript to develop an innovative practical methodology for real world case studies this is a new contribution to the domain according to the authors knowledge more precisely an iterative method is described for source identification based on glma coupled with a linear dw analysis to identify the best location of new measurement the method is then applied to two synthetic cases with heterogeneous hydraulic conductivity field this manuscript is organized as follows the first section material and methods details the glma method and the iterative approach to add new measurements with the dw analysis description the second and third sections present the construction of the considered 2d heterogeneous synthetic cases together with the results on the source localisation the presented approach is eventually summarized and discussed 2 material and methods 2 1 strategy the global strategy is based on an iterative approach to minimise uncertainties at each phase of the source localisation the strategy can be applied in real situations as it requires only a small number of wells in the plume and one or two additional sampling campaigns fig 1 shows a schematic representation of the strategy one cycle corresponds to one run of the source localisation algorithm glma using pest parameter estimation code and addition of new observations to provide new hydraulic head and concentration data respectively h and c for each cycle the method provides estimated parameters hydraulic conductivity k field dispersivity α and the source position including uncertainties on these parameters for the source we will use the term ys which is the position of the source along the y axis see fig 3 uncertainties linked to ys are analysed through a dw analysis to detect the best zones to drill new wells and then obtain new observation which will increase the accuracy on the source localisation the parameter xs will not be considered in order to focus the analysis on the variation of ys on a fixed xs value along x axis which corresponds to the perpendicular transect to the plume direction 2 2 source search with glma 2 2 1 glma approach the gauss levenberg marquardt algorithm is a non linear optimisation method pest code to calibrate a model with observed data through the adjustment of parameters the glma aims at minimizing the gap between observed and simulated data expressed with an objective function φ eq 1 1 φ i 1 m w i d i d i 2 where i is the iteration number d i is the observed data d i the simulated data w i the weight imposed for each data chosen to ensure a good representation of each members in the overall function the glma method will look for the best parameters set to find the minimal phi by changing iteratively the parameters values in our study the adjustable parameters are the field of k parameterized with pilot points the position of the source y s and the dispersivity α at each iteration the nonlinear problem is simplified by using a linear approximation 2 d x p ε where p is the parameters vector d the data vector x is the linearized model jacobian matrix and ε is the total errors in the measurement and the model at each optimisation stage and iteration x is updated to use the modified parameters and aim to give the best optimisation due to the unknown characteristics of the contaminated site hydraulic and transport parameters the model has to take into account a number of parameters higher than the number of observations the system is under determined to obtain a non uniqueness solution several approaches carrera and neuman 1986 have been investigated to increase the stability of inverse problems regularisation improves the condition problem namely tikhonov regularisation entails the addition of a term into the objective function to give preference to a particular solution tonkin and doherty 2005 and will be used in our case the general approach is presented in fig 2 the initial k field is obtained by kriging from the k values at the pilot points details of interpolation are defined in part 3 1 1 the global approach fig 2 is divided in two steps i step 0 first optimisation to estimate the pilot points parameters for the k field by simulating only the hydraulic heads data h ii step 1 second optimisation to estimate all the parameters by simulating h and concentration data c in this step initial values of pilot points correspond to the parameters estimated in step 0 2 2 2 initial parameters to help the resolution of the problem it is possible to set initially a lower and upper limit for each parameter for the pilot points representing the k field the interval taken for each parameter corresponds to an a priori knowledge of the geologic characteristics for ys the interval corresponds to a potential distance between two points where the source can be located dispersivity is more complex to estimate the chosen limits correspond to the estimate of the dispersivity linked to the size of the plume and the heterogeneity of the sediment gelhar 1992 in addition the parameters were separated in three groups one for k one for ys and one for α l thus allowing assigning different weight in the regularisation equations higher for ys and α l it is also possible to transform the value of the parameters in order to stabilize the variation between parameters a log10 transformation is used for k and α l 2 2 3 reference observation dataset data was simulated with modflow harbaugh et al 2000 and mt3dms zheng and wang 1999 observations data used for the analysis come from simulated data of a synthetic case where noise have been added on each observation for performance evaluation mahar and datta 2001 in eq 3 singh et al 2004 3 d obs d sim φ d sim e where d obs is the observation data used for the analysis d sim the simulated data φ is a random fraction a value of 0 1 is used corresponding to a moderate noise level e is a standard normal deviates generated with the random number generation of the excel analysis toolpack mean 0 and standard deviation 1 observation data are separated in two different groups to separate the hydraulic head h data and concentration c data observations are square root transformed see eq 1 used to make observation with a low concentration values more visible in the global objective function 2 3 data worth analysis the data worth analysis allows the effect of new observations on the variance of a prediction of interest in our case if we consider that the position of the source is our prediction of interest the analysis will help us to locate future drilling to limit uncertainties on ys 2 3 1 theory let the vector p designate model parameters and d the measurements of hydraulic heads and concentrations considering bayes theorem the posterior probability distribution of model parameters p is defined by p p d with 4 p p d p p p d p p d where p d p is the likelihood function and p p the prior probability distribution of parameters that encapsulated expert knowledge by direct measurement at one or several discrete location considering the eq 1 the eq 4 and a gaussian distribution of p and ε with the schur s complement the posteriori covariance matrix of parameters c p d is defined by 5 c p d c p c p x t xc p x t c d 1 xc p where c p is the covariance matrix associated with the prior parameters c d is the covariance matrix associated with the prior observations then considering s the vector of the forecast 6 s y t p where y is the sensitivity of the prediction of interest depending on each parameter assuming a linear model and considering eqs 5 and 6 it is possible to calculate the predictive uncertainty variance of a given forecast s dausman et al 2010 with 7 σ s 2 y t c p y y t c p x t xc p x t c d 1 x c p y in the eq 7 the term y t c p y represents uncertainties associated to the prediction before the calibration the other term on the right represents the decrease of uncertainty obtained with the calibration eq 7 is linear but transport equations assume a nonlinear problem which elements of x are dependent on parameters values p in order to respond to this nonlinearity x can be represented by the jacobian matrix the sensitivity matrix between parameters and observation obtained with the optimisation vilhelmsen and ferré 2017 thus it is not directly the values of observations and parameters that are used but rather the covariances and the jacobian to take account of new data in the jacobian vilhelmsen and ferré 2017 defined the complete jacobian matrix x all according to a prediction of interest y 8 x all y t x base x nd where x all is the total jacobian containing the prediction of interest y t x base the basic jacobian containing the initially existing data used for calibration and x nd the jacobian containing the new observations at each line of the matrix then the authors defined the dw as follows 9 dw σ dec 2 σ base 2 where σ dec 2 the variance value of the prediction of interest after adding data and σ base 2 defines the variance value of the prediction of interest on the existing data at the beginning of the analysis dw ranges between 0 and 100 for a fictitious new data added if the dw value is close to 100 no decrease was noted and the added observation or an area of added observations will not reduce the uncertainty on the prediction of interest if dw is close to 0 the added observation will markedly decrease the prediction uncertainty for a better understanding we will base our study on the value 1 dw which means that when the value is closer to 100 the observations decrease the prediction uncertainty 2 3 2 applications of the data worth adding a number of fictitious observations in the jacobian matrix complete jacobian the value of the variance of the prediction of interest here the source location ys on each of the new observations is calculated the number of fictitious observations depends on the studied domain corresponding to on observation per cell of the domain it is therefore possible to build a map of variances related to a prediction of interest and to have a value of 1 dw over an entire domain zones with higher value of 1 dw represent where new observations are needed to reduce uncertainty of ys assessment of adding new observations with the data worth analysis is realised with pyemu tool white et al 2016 which calculate the variance of the prediction 2 4 iterative choice of the best points for operational reasons it is not reasonable to conduct a single campaign for one drilling thus the number of observation to be added after each phase has been set to three the first point chosen is the zone where 1 dw is the highest the problem is to target the 2nd and 3rd point vilhelmsen and ferré 2017 used a method to have multiple combinations of new observations with a random search procedure in a data worth analysis 2500 potential new measurement and 1 million combinations in our work about real site applicability saving time we want to target observations without a random procedure so when the point p 1 is chosen the goal is to select the p 2 in a region where the concentrations measured at p 1 have no influence for this we used a geostatistical approach considering that concentrations values as correlated with each other directional variograms are calculated based on the concentration field with the simulated plume with glma then we define an ellipse p xp yp rx ry having p 1 as center that defines the limits away from which there is no correlation with measurements at p 1 the dimensions rx and ry of the ellipse correspond to 2 3 of the corresponding range of the two directional variograms doherty et al 2010 the zone selected for p 2 corresponds to the zone outside this first ellipse where 1 dw is the highest then p 3 is selected outside the two previous ellipse having p 1 and p 2 as center this approach will however be limited to the situation where geostatistical analysis of the tracer plume seems to be valid although there is no formal way to determine which geological medium can be approached with classical geostatistics the presented approach might be valid for porous medium as geostatistics are now commonly used but more questionable in fractured medium or with the occurrence of structural discontinuities in the geological medium e g faults 3 source localisation in case a 3 1 synthetic cases construction dimensions of the case a domain are 200 50 m with a mesh size of 1 m in y axis and 5 m for the x axis 3 1 1 hydrodynamic parameters the boundary conditions were placed upstream and downstream with an imposed hydraulic head of 10 50 m and 10 00 m respectively gradient of 0 0025 the generation of the k field was carried out from 52 pilots points homogeneously distributed with a 15 m spacing k values on each point were randomly generated to have a range of 3 to 300 m day 1 corresponding to a distribution type that can be found on a real site fig 3 the heterogeneous reference k field is obtained by kriging with a 25 m range spherical variogram 3 1 2 transport and source parameters the source was placed as shown in the fig 3 with a value of 10 mg l the longitudinal dispersivity α l is equal to 3 m and the transvers to 0 3 m the coordinate of the center of the source are located at x a 14 m and y a 29 m center of the source the source has a width of 2 m according to the y axis ys is used as the parameter of the source corresponding to center of the source it is allowed to vary between 10 and 40 m see table 2 the simulation is steady state with a continuous source 3 1 3 data used for the optimisation for the case a ten observations were added from p1 to p10 fig 3 their location was chosen in order to have a non ideally location with respect to the plume p1 p2 p3 p4 and p10 the goal is to have a case close to the reality knowing that at the beginning of the study of a contaminated site the existing wells are in most cases very poorly located errors were also added see part 2 2 3 and these disturbed data are considered as observed data 3 2 glma implementation 3 2 1 initial parameters initial parameters are presented in table 2 in the step 0 described in the fig 3 the first calibration is realised only with h to have the best estimation of the pilot points represented the k field before a second optimisation represented by the step 1 the parameters characteristics transformation increment are identical for the two steps once hydraulic head observations are calibrated in the step 0 the second optimisation in step 1 is realised using i hydraulic head and concentration observations in two different groups ii and k field represented by pilot points α l and ys parameters in three groups the pilot points values estimated in step 0 are used for the step 1 as initial parameters this approach has been used elsewhere it has the advantage to allow a rapid estimation of the k field with flow only simulations which shall be a good start for the more costly runs including flow and transport 3 2 2 regularisation to help the parameters estimation regularisations methods are used in our calibration i tikhonov regularisation and ii singular value decomposition svd a priori information is added in the tikhonov regularisation with a higher weight value for ys and α l in the global objective function this point is important in order to promote ys and α l in the global objective function in the first stages of the optimization in addition a svd is used with a truncation of 5 10 7 3 3 case a results to evaluate the calibration of the models and the robustness of the source location root mean square error rmse criterion and normalized root mean square error nrmse are used the nrmse considered in this study is the normalisation representing by the range of the observed data maximum value minus minimum value and expressed as a percentage as long as the nrmse for h is 5 and the nrmse for c is 15 we consider that the calibration is acceptable for us 3 3 1 phase 1 optimisation in the phase 1 gave ys equal to 30 84 5 32 m reference 29 m and α l equal to 2 65 1 15 m reference 3 m rmse between simulated and observed data for h and c is respectively equal to 0 001 m and 0 0007 mg l 1 the nrmse for h and c are respectively 5 and 15 3 3 2 dw analysis and choice of new points once calibration is done the goal is to calculate the worth of data linked to ys data worth is calculated with the parameter estimated in the step 1 of phase 1 for each new point located in the mesh grid of the domain 2000 points the 1 dw map is used to find the first point to add to decrease the variance linked to ys for this case we considered that the new points must be located at an x coordinate higher than 25 m fig 4 in order to constraint the analysis enough so the first point is located at a coordinate 25 30 p11 in the fig 4 the concentration simulated in the phase 1 were used to calculate the directional variogram along the x and y axes which allow to draw the ellipse p a xp yp rx ry where xp and yp are the coordinate of the ellipse center corresponding to the first point located and rx 14 m ry 5 m corresponding to the 2 3 of the directional variogram range the second point p12 is located outside the first ellipse at a coordinate 25 36 5 where 1 dw is higher then the third point is located outside the second ellipse at a coordinate 38 32 5 see fig 4 points p11 p12 and p13 are used for the phase 2 it can be seen that the variance decreases rapidly downgradient the source and is small around the existing points with measured information 3 3 3 phase 2 like phase 1 the step 0 was done with 13 hydraulic head values in order to have the initial pilot point parameters for the second calibration the initial parameters ys and α l correspond to the parameters estimated in the phase 1 optimisation in the phase 2 gave ys equal to 30 7 2 29 m 29 m and a longitudinal dispersivity equal to 2 95 1 09 m 3 m rmse between simulated and observed data for h and c is respectively equal to 0 0015 m and 0 002 mg l 1 nrmse h 5 and nrmse c 15 3 4 comparison between phase 1 and phase 2 the fig 4 shows the 1 dw maps before and after the addition of new observation adding new points allow the decrease of the variance linked to y s and decrease the standard deviation for ys fig 5 4 source localisation in case b 4 1 synthetic case construction dimensions of the case b domain are 400 100 m with a mesh size of 1 m for y and 5 m for x 4 1 1 hydrodynamic parameters for the case b the boundary condition was placed upstream on the left with an imposed hydraulic head of 14 m the generation of the k field was carried out from 24 pilots points randomly distributed in a subdomain of 400 100 meters fig 6 then an interpolation using thiessen polygon yang et al 2004 was used to generate the k field around the pilot points with a range of 3 300 m day 1 4 1 2 transport and source parameters in the case b the source carried a constant concentration of 10 mg l 1 the longitudinal dispersivity was set to 1 80 m and the transvers to 0 18 m the coordinates of the source center are located at x b 101 m and y b 61 m fig 6 the source has a width of 2 m according to the y axis this case is more complex due to the thiessen polygon with a highly heterogeneous k field 4 1 3 data used for the optimisation for the case b ten observations were added from p1 to p10 fig 6 errors were added like the case a as used to have observed data for the optimisation 4 2 glma implementation the same method is used see glma implementation for the case a the parameters are presented in the table 2 where the potential range of y s 20 70 m is also shown 4 3 case b results 4 3 1 phase 1 optimisation in the phase 1 step 1 gave ys equal to 56 76 1 90 m ref 61 m and a longitudinal dispersivity equal to 0 50 1 38 m ref 1 8 rmse for h and c is respectively equal to 0 01 m and 0 33 mg l 1 this calibration gives a nrmse h 1 36 and a nrmse c 10 given a low correlation compared to the case a but acceptable according to the astm standard 4 3 2 first dw analysis and choice of new points data worth is calculated with the parameter estimated in the step 1 of phase 1 for each new point located in the mesh grid of the subdomain of the zone studied corresponding to 3000 points in the case b the new observations must be located at an x coordinate higher than 125 m fig 7 to constrain the analysis the first point is located at 125 55 p11 in the fig 7 the concentration simulated in the phase 1 allowed us to draw the ellipse p b xp yp rx ry where xp and yp are the coordinate of the ellipse center corresponding to the first point located and rx 33 m ry 11 m the point p12 is located at a coordinate 160 55 and the third point is located at a coordinate 190 5 50 5 see fig 7 observations p11 p12 and p13 are used for the phase 2 4 3 3 phase 2 optimisation in the phase 2 gave ys equal to 61 89 1 67 m ref 61 m and a longitudinal dispersivity equal to 0 49 1 38 m ref 1 8 m rmse between simulated and observed data for head observation and concentration is respectively equal to 0 07 m and 0 33 mg l 1 nrmse for h and c are acceptable 3 39 for h and 9 6 for c furthermore 1 dw map in the phase 2 see fig 7 still has zones with high value that is why another addition of new points is proposed 4 3 4 second dw analysis and choice of new points due to the uncertainties still visible in the phase 2 dw map another dw analysis is calculated with the parameter estimated in the phase 2 the first observation is located at a coordinate 125 5 66 5 p14 in the fig 7 the ellipse p a xp yp rx ry has the same dimension rx 33 m ry 11 m the second point p15 is located at a coordinate 159 5 68 5 and the third point is located outside the second ellipse at a coordinate 192 5 65 1 observations p14 p15 and p16 are used for the phase 3 4 3 5 phase 3 the final optimisation gave ys equal to 64 51 0 37 m ref 61 m and a α l equal to 1 47 1 04 m ref 1 8 rmse for h and c are respectively equal to 0 09 and 0 38 given respectively a nrmse equal to 4 15 and 7 86 4 4 4comparison between phase 1 phase 2 and phase 3 the three data worth maps are presented in fig 7 and after the addition of new observation adding new points allow the decrease of the variance linked to ys in three phases to have a better estimation of ys and α l with a lower standard deviation fig 8 5 general results 5 1 results for the source localisation the table 3 summaries results from optimisation used for cases a and case b table 4 shows computing time for each phases the source localisation in the synthetic case a gave the best estimation with a high correlation between observed and simulated data fig 9 the final value for ys is 30 7 29 is the reference value indeed pilot points interpolation method used during the modelling phases of the case a is identical to the method used for the construction case same pilot points number same type of kriging the case a mainly allowed establishing the methodology on an easily achievable case giving low nrmse and a good parameters estimation for the case b the construction method is different to the one used for the modelling phases which adds more errors in the calibration of the observations and the localisation of the source nrmse for h and c of case b fig 9 are higher than case a but are acceptable according to our criteria the final value for ys is 64 m the reference value is 61 m with a low standard deviation errors can due to the plume coming from ys 61 m and turns before the area fixed for the new observation adding indeed the information received by the optimisation is in some ways wrong and cannot simulate a turn of the plume before the authorized sampling zone 5 2 k field comparison to go further in the analysis figs 10 and 11 show a comparison between the reference k field and the estimated k field for each case a third k field was estimated by considering the source and the dispersivity as known only pilot points were estimated this comparison helped us to know the optimum k field estimated by the glma thus k field associated with the location of the source are almost identical to the calibrated k field considering known parameters proving i the results robustness and ii that the source has not stagnated in a local minimum during the optimisation phase if we compare the estimated k field with the reference k field absolute values are not exactly the same as the modelling was carried out in steady state the absolute value of k cannot be estimated nevertheless it is possible to note a same order of magnitude with the high and low zones of hydraulic conductivity similar areas are surrounded in dotted lines in figs 10 and 11 this analysis confirms the results obtained showing the robustness of the method 6 discussion and conclusion this study introduced the development and implementation of a source localisation strategy on two synthetic cases the method has been developed to be applicable to a real problem with i a limited number of new observations to reduce uncertainties about the source location ii spatial constraints for the source position similar to what happens on a real site ii consideration of a steady state source stabilized plume without historical knowledge of contaminant and iv unknown transport ys and α l and hydraulic k field parameters the bibliography study showed that works on source localisation are generally effective when the evolution of a plume is taken into account history of pollutants on one or more points a stabilized plume is more complex to analyse due to the constant release also these cases are the most common in reality having not been used to our knowledge the choice of the method was thus focused on a nonlinear optimization using the glma from the pest application combined with a dw analysis to minimise uncertainties on the source localisation results show that it is possible to estimate ys α l and k field with low standard deviation for each synthetic case the dw analysis allowed the decrease of y s standard deviation from 5 3 m to 2 3 m in case a and from 1 9 to 0 4 in case b however maps showed a visual small effect of adding observations the interest of adding observations rather appears by analysing the jacobian matrix calculated in the last optimisation of each phase sensitivity values of the jacobian are presented in table 5 more precisely the table presents a part of the 10 most sensitive values in green and the least sensitive ones in red for each observation among all the associated parameters only ys sensitivities are presented it appears that in case a the new observations are sensitive to the source p11 p12 and p13 for case b the situation is more complex it is interesting to note that p3 p7 and p8 remain sensitive throughout the study because they are located on the north part of the plume on the other hand in phase 2 the added points are not sensitive to the source which is not visible to the dw map calculated this could result from the fact that the dw assumes a linear model in the domain which is not the case when the k field is heterogeneous during the transition from phase 2 to phase 3 the added points become sensitive observation added in phase 2 clearly defined the flow close to the source the model becomes closer to the reference conditions necessary for the correct application of the dw approach this outlines the fact that the larger the exclusion zone the highest the error on the source position although this seems evident the presented study cases show that the error on the source position is much smaller than the size of the exclusion as the method is intended to be applied to real field sites it must be robust and it could be interesting to know its true uncertainty indeed the glma method is quite efficient but i it cannot assert that the obtained results are the global minimum and ii the obtained uncertainty is the one of the linearized model in order to assess the robustness of the method several tests have been carried out in order to calibrate the c and h by considering different fixed y s and leaving the pilot points of the k field and the dispersivity vary for cases a and b an optimisation was carried out on each of the 13 imposed positions of y s varying every two meters from 11 to 39 m for case a and from 25 to 69 for case b all phases have been tested the results are presented in the two first lines of the fig 12 on the first phase before adding observations through dw the optimisation allows obtaining a minimal rmse for a wide range of fixed y s case a rmse c 0 05 mg l 1 and rmse h 0 01 m case b rmse c 0 3 mg l 1 and rmse h 0 3 m for case a fig 12 a and c on phase 1 sources y s giving good results vary between 17 and 37 m for c and h adding observations in phase 2 13 observations reduced this range from 27 to 35 m reference y s 29 m for case b fig 12 b and d in phase 1 sources y s giving good nrmse are included on a large range from 35 to 67 m with 10 observations in phase 3 the interval is much smaller ranging from 59 to 67 m reference y s 61 m the overall results are summarized in the fig 13 in addition these different tests have allowed evaluating k fields estimated for each fixed y s fig 12 e and f shows the standard deviation of pilot points values k field estimated as a function of imposed y s during the last phase one can note that the minimum value of σ k lies within the interval of the low values of hnrmse and cnrmse moreover as indicated by the closeness of the final solution and the minimum of σ k the value found by the glma algorithm seem to correspond to the σ k minimum in case a the minimum standard deviation value of the pilot points is associated with a y s 31 m which correspond to the estimated value of 30 7 m during the strategy application for case b the minimum value of the standard deviation in phase 3 is assigned to a y s 65 m close to the value estimated in the strategy this point raises the fact that if the heterogeneity of the k field is increased it is possible to reproduce almost any observed value therefore the estimated position of the source corresponds to the model that satisfies the observed values and has the minimum heterogeneity it can be further observed that the uncertainty in ys around the final point given in fig 12 is much higher than the one provided by the glma method indeed as already stated above the glma uncertainty is based on the linearized model but also the obtained uncertainty on ys considers k and α fixed thus the initial methodology is interesting but it must be accompanied by a more precise study taking into account two new criterions with i a glma analysis of the y s range corresponding to the lowest rmse and ii an analysis of the smallest heterogeneity of k field estimated in the last phase the method shall further be validated for a number of different cases and levels of heterogeneity in order to confirm its effectiveness and applicability some important points have not been tested in this study and could be used for improvements or perspectives on the future with i the use of a smaller number of observations at the beginning ii the localisation of two or more sources iii the simultaneous localisation of ys and xs iv the implementation of transient phenomena recharge or punctual pumping and v the localisation of a source in reactive transport problem acknowledgments this work was developed during elyess essouayed phd and supported by innovasol bordeaux inp ensegid and ea 4592 georessources et environnement 
1542,a contaminant source localisation strategy was developed considering unknown heterogeneous hydraulic conductivity field unknown dispersivity and unknown location of a continuous contaminant source the gauss levenberg marquardt algorithm is combined with a data worth analysis to estimate the unknown parameters and identify the best locations of additional measurements the data collection strategy is iterative based on the ability of the additional dataset to decrease the uncertainties on the contaminant source location two 2d synthetic models are considered the method is first illustrated with a simple model and a more complex model is then considered to evaluate the ability of the approach to locate the contaminant source from hydraulic heads and concentration data this approach is parsimonious in terms of model runs and applicable to real cases the results give a good estimate of the source location and the dispersivity with acceptable nrmse for each case new observations introduced at each iteration decrease the standard deviation of the source location and improve the nrmse the estimated hydraulic conductivity field presents the same features as the original field keywords contaminant source localisation iterative strategy glma data worth heterogeneous synthetic cases k field estimation abbreviations glma gauss levenberg marquardt algorithm dw data worth svd singular value decomposition rmse root mean square error n rmse normalized root mean square error 1 introduction the identification of contaminant source location is a challenge for the management of numerous contaminated sites a good knowledge of the source location allows a better strategy for the site remediation and the reduction of treatment costs migration plume processes are linked to the porous medium properties which are highly heterogeneous causing concentrated mass fluxes in a small zone studies showed that 70 80 of the plume mass discharge occurs in 10 20 of the contaminated area guilbeault et al 2005 this 10 is the true source zone which may often be quite small but has to be localised during the past 30 years groundwater flow and pollutant transport models coupled with different inversion methods have been developed for source identification a number of methods are available in the literature to estimate source localisation in synthetic cases from observations mostly concentration data these methods can be classified as follows nonlinear optimisation approach geostatistical approach or backward simulation approach bagtzoglou and atmadja 2005 optimisation methods are the most used approaches and allow source localisation from the comparison between observed and simulated data after a forward simulation gorelick et al 1983 were the first to use an optimisation method for source localisation the test was carried out on a 2d homogeneous synthetic case in steady and transient states all parameters of the geological medium were known hydrodynamics and transport observations were represented by concentration history of the tracer moreover errors on observations were considered the method presented in their paper is a restrictive method and is not suitable for real cases due to the requirement of known parameters such as wagner 1992 who used a nonlinear optimisation method and worked on a synthetic 2d case in steady state he developed an approach to simultaneously respond to parameter estimation and source characterization with nonlinear maximum likelihood estimation the source was considered as continuous initial parameters are unknown field of hydraulic conductivity k dispersivity α l porosity w and boundary conditions since the k field is parametrized with only two zones of piecewise constancy this facilitates the source localisation mahar and datta 1997 used a nonlinear optimisation method combining source localisation and the identification of the best location for additional measurement points measurement of source fluxes they considered a synthetic 2d homogeneous case in steady state with known hydrogeological and transport parameters the same authors worked with a homogeneous 2d case mahar and datta 2000 to identify the location of a transient source with several observations concentrations datta et al 2009 used the same synthetic case to estimate simultaneously parameters k field α l and w and release history of several potential sources with a nonlinear program estimated parameters were close to the actual value and proved the robustness of the method in a homogeneous case sun et al 2006 also worked on several 2d homogeneous cases in transient state with constrained robust least squares estimator combined with an optimization in order to reduce significantly the computing time aral et al 2001 used a genetic algorithm allowing a nonlinear optimisation and provides a fair results improvment the latter approach is based on a 2d heterogeneous model in steady state k field and α l are known with a transient source other optimisation methods stochastic or ensemble optimisation for instance have also been developed by singh et al 2004 yeh et al 2007 yeh et al 2014 ayvaz 2016 xu and gómez hernández 2016 2018 and applied to this domain unlike previous papers that carried out their analysis on synthetic cases bashi azghadi et al 2016 worked on a real case with a nonlinear optimisation method which minimises the number of probing wells and average regret in estimating polluted area the site is a highly polluted oil refinery due to leakage from several tanks and the contaminant release is known to minimise the number of probing wells the authors used a monte carlo analysis to assess uncertainties with a large number of randomly generated scenarios considering several variables such as the oil tank position at the origin of the contamination the method permits the location of the source with a limited number of observations during the last 20 years geostatistical approaches have been used for source identification snodgrass and kitanidis 1997 used a geostatistical method combined with bayesian theory tarantola 1987 to localise a source between two potential zones in a 1d homogeneous synthetic case with a concentration release they considered known hydraulic conductivity fields k fields and dispersivities α michalak and kitanidis 2004a used geostatistical inverse modelling for contaminant source identification in a real site with observed field data with known hydraulic and transport parameters this study showed that the history of contamination can be estimated with a good precision gzyl et al 2014 worked also in a real site with several sources using a multi step approach to identify the contaminant release history with a geostatistical method butera et al 2013 developed an analytical method for source localisation based on the geostatistical approach used by snodgrass and kitanidis 1997 other methods using backward simulation coupled or not to geostatistics were developed these methods consider known homogeneous or heterogeneous k field and known α l bagtzoglou et al 1992 were among the first to use the inversion of transport equation to localise a source in their work transport equation was modelled with an inverse time and an unchanged dispersivity neupauer and wilson 1999 used the adjoint method in a synthetic case with only one observation the approach was also tested with several observations to localise sources in a real site in a 1d case neupauer and wilson 2005 michalak and kitanidis 2004b coupled the adjoint method for backward simulation with a geostatistical approach to identify the historical distribution of contaminant cupola et al 2015 compared the adjoint method with the approach developed by butera et al 2013 for a source localisation in a sand tank authors established the reliability of both methods and showed that the adjoint method is able to detect only one source compared to cupola et al 2015 approach recently xu and gomez hernandez 2018 presented a method to simultaneously identify a source and estimate a k field with a kalman filter like approach the identification was proven with this method but uncertainty about k field generated was significant also the dispersivity was considered as known this study is original in that the k field is also estimated together with the source location which makes the case closer to real world problem table 1 summarises the characteristics of the existing approaches and shows that few studies can be applied to real case indeed the challenge for real world cases is to deal with unknown heterogeneous field of hydraulic properties and unknown transport parameters dispersivities in such contexts the source identification may become challenging numerous studies consider known or homogeneous parameter fields yet estimated location may be largely uncertain when inferred with biased parameters the implementation of source identification methods that require a large number of model runs is often limited by the computational burden associated with advective dispersive transport models considering these constraints this paper proposes an optimisation approach using the glma to identify jointly the source hydraulic and transport properties in order to provide an approach applicable to realistic case studies with unknown parameters we consider here that hydraulic conductivity dispersivity and source location are unknown and the contaminant release is constant to our knowledge the glma has not been used before for contaminant source localisation as the problem includes a lot of uncertainty and generally very few measurement points the second objective is to analyse the collection of complementary field data to better constrain the uncertainty of the unknown parameters more precisely the objective is to add new measurement points to decrease uncertainties about source location to place these additional observations a data worth analysis can be used with available tools as predunc moore et al 2010 or pyemu a python script developed by white et al 2016 due to the cost of a drilling only a limited number of data can be added and dw analysis leads to optimize observation strategies with limited costs data worth analysis dw was studied by several authors in hydrogeology to optimize the data collection while increasing value of information and therefore shrinking more the uncertainty this analysis is performed with nonlinear optimisation methods such as the ones developed in freeze et al 1992 james and freeze 1993 james and gorelick 1994 fu and gómez hernández 2009 from the 70 s to the 2000 s several studies conducted dw analysis in the context of hydrogeological problems i e gates and kisiel 1974 maddock 1973 dausman et al 2010 hill et al 2013 other authors used dw analysis for hydrogeological and remediation problems based on finding the best location for pump treat tucciarelli and pinder 1991 freeze et al 1992 james and gorelick 1994 wallis et al 2014 used the dw for transport problem with an evaluation of the introduction of multiple observations in a tracer test experiment wöhling et al 2016 extended the multiple observations approach with two types of data hydraulic conductivity k and heads data h to decrease the predictive uncertainty of the hyporheic fluxes travel time they used a genetic algorithm to find an optimal combination of predefined number of measurement location vilhelmsen and ferré 2017 worked only with a single type of data hydraulic conductivity they extend the dw analysis to select multiple observations to reduce one or multiple forecast wöhling et al 2016 tested the multiple observations with a genetic algorithm 2500 potential new measurement location is included and 1 million combinations of a maximum of 4 measurements are considered to find the best location of new data which is not easy to implement for a practical case glma combined with a data worth analysis are used in this manuscript to develop an innovative practical methodology for real world case studies this is a new contribution to the domain according to the authors knowledge more precisely an iterative method is described for source identification based on glma coupled with a linear dw analysis to identify the best location of new measurement the method is then applied to two synthetic cases with heterogeneous hydraulic conductivity field this manuscript is organized as follows the first section material and methods details the glma method and the iterative approach to add new measurements with the dw analysis description the second and third sections present the construction of the considered 2d heterogeneous synthetic cases together with the results on the source localisation the presented approach is eventually summarized and discussed 2 material and methods 2 1 strategy the global strategy is based on an iterative approach to minimise uncertainties at each phase of the source localisation the strategy can be applied in real situations as it requires only a small number of wells in the plume and one or two additional sampling campaigns fig 1 shows a schematic representation of the strategy one cycle corresponds to one run of the source localisation algorithm glma using pest parameter estimation code and addition of new observations to provide new hydraulic head and concentration data respectively h and c for each cycle the method provides estimated parameters hydraulic conductivity k field dispersivity α and the source position including uncertainties on these parameters for the source we will use the term ys which is the position of the source along the y axis see fig 3 uncertainties linked to ys are analysed through a dw analysis to detect the best zones to drill new wells and then obtain new observation which will increase the accuracy on the source localisation the parameter xs will not be considered in order to focus the analysis on the variation of ys on a fixed xs value along x axis which corresponds to the perpendicular transect to the plume direction 2 2 source search with glma 2 2 1 glma approach the gauss levenberg marquardt algorithm is a non linear optimisation method pest code to calibrate a model with observed data through the adjustment of parameters the glma aims at minimizing the gap between observed and simulated data expressed with an objective function φ eq 1 1 φ i 1 m w i d i d i 2 where i is the iteration number d i is the observed data d i the simulated data w i the weight imposed for each data chosen to ensure a good representation of each members in the overall function the glma method will look for the best parameters set to find the minimal phi by changing iteratively the parameters values in our study the adjustable parameters are the field of k parameterized with pilot points the position of the source y s and the dispersivity α at each iteration the nonlinear problem is simplified by using a linear approximation 2 d x p ε where p is the parameters vector d the data vector x is the linearized model jacobian matrix and ε is the total errors in the measurement and the model at each optimisation stage and iteration x is updated to use the modified parameters and aim to give the best optimisation due to the unknown characteristics of the contaminated site hydraulic and transport parameters the model has to take into account a number of parameters higher than the number of observations the system is under determined to obtain a non uniqueness solution several approaches carrera and neuman 1986 have been investigated to increase the stability of inverse problems regularisation improves the condition problem namely tikhonov regularisation entails the addition of a term into the objective function to give preference to a particular solution tonkin and doherty 2005 and will be used in our case the general approach is presented in fig 2 the initial k field is obtained by kriging from the k values at the pilot points details of interpolation are defined in part 3 1 1 the global approach fig 2 is divided in two steps i step 0 first optimisation to estimate the pilot points parameters for the k field by simulating only the hydraulic heads data h ii step 1 second optimisation to estimate all the parameters by simulating h and concentration data c in this step initial values of pilot points correspond to the parameters estimated in step 0 2 2 2 initial parameters to help the resolution of the problem it is possible to set initially a lower and upper limit for each parameter for the pilot points representing the k field the interval taken for each parameter corresponds to an a priori knowledge of the geologic characteristics for ys the interval corresponds to a potential distance between two points where the source can be located dispersivity is more complex to estimate the chosen limits correspond to the estimate of the dispersivity linked to the size of the plume and the heterogeneity of the sediment gelhar 1992 in addition the parameters were separated in three groups one for k one for ys and one for α l thus allowing assigning different weight in the regularisation equations higher for ys and α l it is also possible to transform the value of the parameters in order to stabilize the variation between parameters a log10 transformation is used for k and α l 2 2 3 reference observation dataset data was simulated with modflow harbaugh et al 2000 and mt3dms zheng and wang 1999 observations data used for the analysis come from simulated data of a synthetic case where noise have been added on each observation for performance evaluation mahar and datta 2001 in eq 3 singh et al 2004 3 d obs d sim φ d sim e where d obs is the observation data used for the analysis d sim the simulated data φ is a random fraction a value of 0 1 is used corresponding to a moderate noise level e is a standard normal deviates generated with the random number generation of the excel analysis toolpack mean 0 and standard deviation 1 observation data are separated in two different groups to separate the hydraulic head h data and concentration c data observations are square root transformed see eq 1 used to make observation with a low concentration values more visible in the global objective function 2 3 data worth analysis the data worth analysis allows the effect of new observations on the variance of a prediction of interest in our case if we consider that the position of the source is our prediction of interest the analysis will help us to locate future drilling to limit uncertainties on ys 2 3 1 theory let the vector p designate model parameters and d the measurements of hydraulic heads and concentrations considering bayes theorem the posterior probability distribution of model parameters p is defined by p p d with 4 p p d p p p d p p d where p d p is the likelihood function and p p the prior probability distribution of parameters that encapsulated expert knowledge by direct measurement at one or several discrete location considering the eq 1 the eq 4 and a gaussian distribution of p and ε with the schur s complement the posteriori covariance matrix of parameters c p d is defined by 5 c p d c p c p x t xc p x t c d 1 xc p where c p is the covariance matrix associated with the prior parameters c d is the covariance matrix associated with the prior observations then considering s the vector of the forecast 6 s y t p where y is the sensitivity of the prediction of interest depending on each parameter assuming a linear model and considering eqs 5 and 6 it is possible to calculate the predictive uncertainty variance of a given forecast s dausman et al 2010 with 7 σ s 2 y t c p y y t c p x t xc p x t c d 1 x c p y in the eq 7 the term y t c p y represents uncertainties associated to the prediction before the calibration the other term on the right represents the decrease of uncertainty obtained with the calibration eq 7 is linear but transport equations assume a nonlinear problem which elements of x are dependent on parameters values p in order to respond to this nonlinearity x can be represented by the jacobian matrix the sensitivity matrix between parameters and observation obtained with the optimisation vilhelmsen and ferré 2017 thus it is not directly the values of observations and parameters that are used but rather the covariances and the jacobian to take account of new data in the jacobian vilhelmsen and ferré 2017 defined the complete jacobian matrix x all according to a prediction of interest y 8 x all y t x base x nd where x all is the total jacobian containing the prediction of interest y t x base the basic jacobian containing the initially existing data used for calibration and x nd the jacobian containing the new observations at each line of the matrix then the authors defined the dw as follows 9 dw σ dec 2 σ base 2 where σ dec 2 the variance value of the prediction of interest after adding data and σ base 2 defines the variance value of the prediction of interest on the existing data at the beginning of the analysis dw ranges between 0 and 100 for a fictitious new data added if the dw value is close to 100 no decrease was noted and the added observation or an area of added observations will not reduce the uncertainty on the prediction of interest if dw is close to 0 the added observation will markedly decrease the prediction uncertainty for a better understanding we will base our study on the value 1 dw which means that when the value is closer to 100 the observations decrease the prediction uncertainty 2 3 2 applications of the data worth adding a number of fictitious observations in the jacobian matrix complete jacobian the value of the variance of the prediction of interest here the source location ys on each of the new observations is calculated the number of fictitious observations depends on the studied domain corresponding to on observation per cell of the domain it is therefore possible to build a map of variances related to a prediction of interest and to have a value of 1 dw over an entire domain zones with higher value of 1 dw represent where new observations are needed to reduce uncertainty of ys assessment of adding new observations with the data worth analysis is realised with pyemu tool white et al 2016 which calculate the variance of the prediction 2 4 iterative choice of the best points for operational reasons it is not reasonable to conduct a single campaign for one drilling thus the number of observation to be added after each phase has been set to three the first point chosen is the zone where 1 dw is the highest the problem is to target the 2nd and 3rd point vilhelmsen and ferré 2017 used a method to have multiple combinations of new observations with a random search procedure in a data worth analysis 2500 potential new measurement and 1 million combinations in our work about real site applicability saving time we want to target observations without a random procedure so when the point p 1 is chosen the goal is to select the p 2 in a region where the concentrations measured at p 1 have no influence for this we used a geostatistical approach considering that concentrations values as correlated with each other directional variograms are calculated based on the concentration field with the simulated plume with glma then we define an ellipse p xp yp rx ry having p 1 as center that defines the limits away from which there is no correlation with measurements at p 1 the dimensions rx and ry of the ellipse correspond to 2 3 of the corresponding range of the two directional variograms doherty et al 2010 the zone selected for p 2 corresponds to the zone outside this first ellipse where 1 dw is the highest then p 3 is selected outside the two previous ellipse having p 1 and p 2 as center this approach will however be limited to the situation where geostatistical analysis of the tracer plume seems to be valid although there is no formal way to determine which geological medium can be approached with classical geostatistics the presented approach might be valid for porous medium as geostatistics are now commonly used but more questionable in fractured medium or with the occurrence of structural discontinuities in the geological medium e g faults 3 source localisation in case a 3 1 synthetic cases construction dimensions of the case a domain are 200 50 m with a mesh size of 1 m in y axis and 5 m for the x axis 3 1 1 hydrodynamic parameters the boundary conditions were placed upstream and downstream with an imposed hydraulic head of 10 50 m and 10 00 m respectively gradient of 0 0025 the generation of the k field was carried out from 52 pilots points homogeneously distributed with a 15 m spacing k values on each point were randomly generated to have a range of 3 to 300 m day 1 corresponding to a distribution type that can be found on a real site fig 3 the heterogeneous reference k field is obtained by kriging with a 25 m range spherical variogram 3 1 2 transport and source parameters the source was placed as shown in the fig 3 with a value of 10 mg l the longitudinal dispersivity α l is equal to 3 m and the transvers to 0 3 m the coordinate of the center of the source are located at x a 14 m and y a 29 m center of the source the source has a width of 2 m according to the y axis ys is used as the parameter of the source corresponding to center of the source it is allowed to vary between 10 and 40 m see table 2 the simulation is steady state with a continuous source 3 1 3 data used for the optimisation for the case a ten observations were added from p1 to p10 fig 3 their location was chosen in order to have a non ideally location with respect to the plume p1 p2 p3 p4 and p10 the goal is to have a case close to the reality knowing that at the beginning of the study of a contaminated site the existing wells are in most cases very poorly located errors were also added see part 2 2 3 and these disturbed data are considered as observed data 3 2 glma implementation 3 2 1 initial parameters initial parameters are presented in table 2 in the step 0 described in the fig 3 the first calibration is realised only with h to have the best estimation of the pilot points represented the k field before a second optimisation represented by the step 1 the parameters characteristics transformation increment are identical for the two steps once hydraulic head observations are calibrated in the step 0 the second optimisation in step 1 is realised using i hydraulic head and concentration observations in two different groups ii and k field represented by pilot points α l and ys parameters in three groups the pilot points values estimated in step 0 are used for the step 1 as initial parameters this approach has been used elsewhere it has the advantage to allow a rapid estimation of the k field with flow only simulations which shall be a good start for the more costly runs including flow and transport 3 2 2 regularisation to help the parameters estimation regularisations methods are used in our calibration i tikhonov regularisation and ii singular value decomposition svd a priori information is added in the tikhonov regularisation with a higher weight value for ys and α l in the global objective function this point is important in order to promote ys and α l in the global objective function in the first stages of the optimization in addition a svd is used with a truncation of 5 10 7 3 3 case a results to evaluate the calibration of the models and the robustness of the source location root mean square error rmse criterion and normalized root mean square error nrmse are used the nrmse considered in this study is the normalisation representing by the range of the observed data maximum value minus minimum value and expressed as a percentage as long as the nrmse for h is 5 and the nrmse for c is 15 we consider that the calibration is acceptable for us 3 3 1 phase 1 optimisation in the phase 1 gave ys equal to 30 84 5 32 m reference 29 m and α l equal to 2 65 1 15 m reference 3 m rmse between simulated and observed data for h and c is respectively equal to 0 001 m and 0 0007 mg l 1 the nrmse for h and c are respectively 5 and 15 3 3 2 dw analysis and choice of new points once calibration is done the goal is to calculate the worth of data linked to ys data worth is calculated with the parameter estimated in the step 1 of phase 1 for each new point located in the mesh grid of the domain 2000 points the 1 dw map is used to find the first point to add to decrease the variance linked to ys for this case we considered that the new points must be located at an x coordinate higher than 25 m fig 4 in order to constraint the analysis enough so the first point is located at a coordinate 25 30 p11 in the fig 4 the concentration simulated in the phase 1 were used to calculate the directional variogram along the x and y axes which allow to draw the ellipse p a xp yp rx ry where xp and yp are the coordinate of the ellipse center corresponding to the first point located and rx 14 m ry 5 m corresponding to the 2 3 of the directional variogram range the second point p12 is located outside the first ellipse at a coordinate 25 36 5 where 1 dw is higher then the third point is located outside the second ellipse at a coordinate 38 32 5 see fig 4 points p11 p12 and p13 are used for the phase 2 it can be seen that the variance decreases rapidly downgradient the source and is small around the existing points with measured information 3 3 3 phase 2 like phase 1 the step 0 was done with 13 hydraulic head values in order to have the initial pilot point parameters for the second calibration the initial parameters ys and α l correspond to the parameters estimated in the phase 1 optimisation in the phase 2 gave ys equal to 30 7 2 29 m 29 m and a longitudinal dispersivity equal to 2 95 1 09 m 3 m rmse between simulated and observed data for h and c is respectively equal to 0 0015 m and 0 002 mg l 1 nrmse h 5 and nrmse c 15 3 4 comparison between phase 1 and phase 2 the fig 4 shows the 1 dw maps before and after the addition of new observation adding new points allow the decrease of the variance linked to y s and decrease the standard deviation for ys fig 5 4 source localisation in case b 4 1 synthetic case construction dimensions of the case b domain are 400 100 m with a mesh size of 1 m for y and 5 m for x 4 1 1 hydrodynamic parameters for the case b the boundary condition was placed upstream on the left with an imposed hydraulic head of 14 m the generation of the k field was carried out from 24 pilots points randomly distributed in a subdomain of 400 100 meters fig 6 then an interpolation using thiessen polygon yang et al 2004 was used to generate the k field around the pilot points with a range of 3 300 m day 1 4 1 2 transport and source parameters in the case b the source carried a constant concentration of 10 mg l 1 the longitudinal dispersivity was set to 1 80 m and the transvers to 0 18 m the coordinates of the source center are located at x b 101 m and y b 61 m fig 6 the source has a width of 2 m according to the y axis this case is more complex due to the thiessen polygon with a highly heterogeneous k field 4 1 3 data used for the optimisation for the case b ten observations were added from p1 to p10 fig 6 errors were added like the case a as used to have observed data for the optimisation 4 2 glma implementation the same method is used see glma implementation for the case a the parameters are presented in the table 2 where the potential range of y s 20 70 m is also shown 4 3 case b results 4 3 1 phase 1 optimisation in the phase 1 step 1 gave ys equal to 56 76 1 90 m ref 61 m and a longitudinal dispersivity equal to 0 50 1 38 m ref 1 8 rmse for h and c is respectively equal to 0 01 m and 0 33 mg l 1 this calibration gives a nrmse h 1 36 and a nrmse c 10 given a low correlation compared to the case a but acceptable according to the astm standard 4 3 2 first dw analysis and choice of new points data worth is calculated with the parameter estimated in the step 1 of phase 1 for each new point located in the mesh grid of the subdomain of the zone studied corresponding to 3000 points in the case b the new observations must be located at an x coordinate higher than 125 m fig 7 to constrain the analysis the first point is located at 125 55 p11 in the fig 7 the concentration simulated in the phase 1 allowed us to draw the ellipse p b xp yp rx ry where xp and yp are the coordinate of the ellipse center corresponding to the first point located and rx 33 m ry 11 m the point p12 is located at a coordinate 160 55 and the third point is located at a coordinate 190 5 50 5 see fig 7 observations p11 p12 and p13 are used for the phase 2 4 3 3 phase 2 optimisation in the phase 2 gave ys equal to 61 89 1 67 m ref 61 m and a longitudinal dispersivity equal to 0 49 1 38 m ref 1 8 m rmse between simulated and observed data for head observation and concentration is respectively equal to 0 07 m and 0 33 mg l 1 nrmse for h and c are acceptable 3 39 for h and 9 6 for c furthermore 1 dw map in the phase 2 see fig 7 still has zones with high value that is why another addition of new points is proposed 4 3 4 second dw analysis and choice of new points due to the uncertainties still visible in the phase 2 dw map another dw analysis is calculated with the parameter estimated in the phase 2 the first observation is located at a coordinate 125 5 66 5 p14 in the fig 7 the ellipse p a xp yp rx ry has the same dimension rx 33 m ry 11 m the second point p15 is located at a coordinate 159 5 68 5 and the third point is located outside the second ellipse at a coordinate 192 5 65 1 observations p14 p15 and p16 are used for the phase 3 4 3 5 phase 3 the final optimisation gave ys equal to 64 51 0 37 m ref 61 m and a α l equal to 1 47 1 04 m ref 1 8 rmse for h and c are respectively equal to 0 09 and 0 38 given respectively a nrmse equal to 4 15 and 7 86 4 4 4comparison between phase 1 phase 2 and phase 3 the three data worth maps are presented in fig 7 and after the addition of new observation adding new points allow the decrease of the variance linked to ys in three phases to have a better estimation of ys and α l with a lower standard deviation fig 8 5 general results 5 1 results for the source localisation the table 3 summaries results from optimisation used for cases a and case b table 4 shows computing time for each phases the source localisation in the synthetic case a gave the best estimation with a high correlation between observed and simulated data fig 9 the final value for ys is 30 7 29 is the reference value indeed pilot points interpolation method used during the modelling phases of the case a is identical to the method used for the construction case same pilot points number same type of kriging the case a mainly allowed establishing the methodology on an easily achievable case giving low nrmse and a good parameters estimation for the case b the construction method is different to the one used for the modelling phases which adds more errors in the calibration of the observations and the localisation of the source nrmse for h and c of case b fig 9 are higher than case a but are acceptable according to our criteria the final value for ys is 64 m the reference value is 61 m with a low standard deviation errors can due to the plume coming from ys 61 m and turns before the area fixed for the new observation adding indeed the information received by the optimisation is in some ways wrong and cannot simulate a turn of the plume before the authorized sampling zone 5 2 k field comparison to go further in the analysis figs 10 and 11 show a comparison between the reference k field and the estimated k field for each case a third k field was estimated by considering the source and the dispersivity as known only pilot points were estimated this comparison helped us to know the optimum k field estimated by the glma thus k field associated with the location of the source are almost identical to the calibrated k field considering known parameters proving i the results robustness and ii that the source has not stagnated in a local minimum during the optimisation phase if we compare the estimated k field with the reference k field absolute values are not exactly the same as the modelling was carried out in steady state the absolute value of k cannot be estimated nevertheless it is possible to note a same order of magnitude with the high and low zones of hydraulic conductivity similar areas are surrounded in dotted lines in figs 10 and 11 this analysis confirms the results obtained showing the robustness of the method 6 discussion and conclusion this study introduced the development and implementation of a source localisation strategy on two synthetic cases the method has been developed to be applicable to a real problem with i a limited number of new observations to reduce uncertainties about the source location ii spatial constraints for the source position similar to what happens on a real site ii consideration of a steady state source stabilized plume without historical knowledge of contaminant and iv unknown transport ys and α l and hydraulic k field parameters the bibliography study showed that works on source localisation are generally effective when the evolution of a plume is taken into account history of pollutants on one or more points a stabilized plume is more complex to analyse due to the constant release also these cases are the most common in reality having not been used to our knowledge the choice of the method was thus focused on a nonlinear optimization using the glma from the pest application combined with a dw analysis to minimise uncertainties on the source localisation results show that it is possible to estimate ys α l and k field with low standard deviation for each synthetic case the dw analysis allowed the decrease of y s standard deviation from 5 3 m to 2 3 m in case a and from 1 9 to 0 4 in case b however maps showed a visual small effect of adding observations the interest of adding observations rather appears by analysing the jacobian matrix calculated in the last optimisation of each phase sensitivity values of the jacobian are presented in table 5 more precisely the table presents a part of the 10 most sensitive values in green and the least sensitive ones in red for each observation among all the associated parameters only ys sensitivities are presented it appears that in case a the new observations are sensitive to the source p11 p12 and p13 for case b the situation is more complex it is interesting to note that p3 p7 and p8 remain sensitive throughout the study because they are located on the north part of the plume on the other hand in phase 2 the added points are not sensitive to the source which is not visible to the dw map calculated this could result from the fact that the dw assumes a linear model in the domain which is not the case when the k field is heterogeneous during the transition from phase 2 to phase 3 the added points become sensitive observation added in phase 2 clearly defined the flow close to the source the model becomes closer to the reference conditions necessary for the correct application of the dw approach this outlines the fact that the larger the exclusion zone the highest the error on the source position although this seems evident the presented study cases show that the error on the source position is much smaller than the size of the exclusion as the method is intended to be applied to real field sites it must be robust and it could be interesting to know its true uncertainty indeed the glma method is quite efficient but i it cannot assert that the obtained results are the global minimum and ii the obtained uncertainty is the one of the linearized model in order to assess the robustness of the method several tests have been carried out in order to calibrate the c and h by considering different fixed y s and leaving the pilot points of the k field and the dispersivity vary for cases a and b an optimisation was carried out on each of the 13 imposed positions of y s varying every two meters from 11 to 39 m for case a and from 25 to 69 for case b all phases have been tested the results are presented in the two first lines of the fig 12 on the first phase before adding observations through dw the optimisation allows obtaining a minimal rmse for a wide range of fixed y s case a rmse c 0 05 mg l 1 and rmse h 0 01 m case b rmse c 0 3 mg l 1 and rmse h 0 3 m for case a fig 12 a and c on phase 1 sources y s giving good results vary between 17 and 37 m for c and h adding observations in phase 2 13 observations reduced this range from 27 to 35 m reference y s 29 m for case b fig 12 b and d in phase 1 sources y s giving good nrmse are included on a large range from 35 to 67 m with 10 observations in phase 3 the interval is much smaller ranging from 59 to 67 m reference y s 61 m the overall results are summarized in the fig 13 in addition these different tests have allowed evaluating k fields estimated for each fixed y s fig 12 e and f shows the standard deviation of pilot points values k field estimated as a function of imposed y s during the last phase one can note that the minimum value of σ k lies within the interval of the low values of hnrmse and cnrmse moreover as indicated by the closeness of the final solution and the minimum of σ k the value found by the glma algorithm seem to correspond to the σ k minimum in case a the minimum standard deviation value of the pilot points is associated with a y s 31 m which correspond to the estimated value of 30 7 m during the strategy application for case b the minimum value of the standard deviation in phase 3 is assigned to a y s 65 m close to the value estimated in the strategy this point raises the fact that if the heterogeneity of the k field is increased it is possible to reproduce almost any observed value therefore the estimated position of the source corresponds to the model that satisfies the observed values and has the minimum heterogeneity it can be further observed that the uncertainty in ys around the final point given in fig 12 is much higher than the one provided by the glma method indeed as already stated above the glma uncertainty is based on the linearized model but also the obtained uncertainty on ys considers k and α fixed thus the initial methodology is interesting but it must be accompanied by a more precise study taking into account two new criterions with i a glma analysis of the y s range corresponding to the lowest rmse and ii an analysis of the smallest heterogeneity of k field estimated in the last phase the method shall further be validated for a number of different cases and levels of heterogeneity in order to confirm its effectiveness and applicability some important points have not been tested in this study and could be used for improvements or perspectives on the future with i the use of a smaller number of observations at the beginning ii the localisation of two or more sources iii the simultaneous localisation of ys and xs iv the implementation of transient phenomena recharge or punctual pumping and v the localisation of a source in reactive transport problem acknowledgments this work was developed during elyess essouayed phd and supported by innovasol bordeaux inp ensegid and ea 4592 georessources et environnement 
1543,vulnerability maps were generated for altınova region within the antalya travertine plateau based on drastic sintacs epik cop and pi methods majority of the study area is covered by productive karstic aquifer which is composed of travertine travertine includes typical karstic features such as dolines springs and caves where groundwater of travertine aquifer is the sole source for irrigation areal extends of low medium high and very high vulnerability classes and their areal extends were determined for all methods and compared with each other high and very high vulnerable areas covered 74 of the study area as investigated by all methods except pi although pi is a specific method for karstic aquifers this method could not generate a reasonable vulnerability map based on the assigned parameter definitions and scores only areal extents were not sufficient to decide about the proper vulnerability method for the study area therefore no3 concentration based validation method was performed for all generated vulnerability maps consequently the areas which had no3 concentrations higher than 30 mg l were matched with high very high vulnerable areas according to this validation method application of sintacs with karstic aquifer weights could validate 95 of the area with no3 concentrations higher than the selected threshold level of 30 mg l for altınova region this study showed that simulation performance of vulnerability methods was highly related to the defined parameter definitions score ranges and weights of each method similar parameters with variable score ranges could create considerably distinct vulnerability maps validation is the essential interpretation step for taking decision on the proper vulnerability method additionally site specific contaminant observations are critical for validation of vulnerability maps validated vulnerability maps could be used as a valuable water resources management tool graphical abstract unlabelled image keywords antalya travertine plateau vulnerability mapping validation karst aquifer 1 introduction freshwater resources are crucial for human life irrigation and industrial use climate change excess withdrawal and contamination are common threats to freshwater resources adverse impacts of excess withdrawal and contamination can be suppressed by preventive management strategies detailed characterization of freshwater resources is essential to propose and accomplish site specific management strategies based on the results of a detailed characterization study protection areas and vulnerability risk maps can easily be adopted for freshwater resources lakes streams groundwater or wetlands characterization of groundwater resources is much more complex than surface water resources because of unpredictable geological setup and storage flow conditions of the aquifer environment because of this complexity intrinsic vulnerability assessment is a good option to prescribe probable areas for groundwater contamination intrinsic vulnerability is the first step on the way to risk assessment for groundwater resources various vulnerability assessment methods have been widely used for groundwater management applications since late 1960s margat 1968 since then vulnerability applications were widely applied all around the world for different hydrogeologic conditions some of the vulnerability applications were conducted by babiker et al 2005 goldscheider 2005 varol and davraz 2010 güler et al 2013 alaya et al 2013 masoompour samakosh et al 2013 yin et al 2013 muhammad et al 2015 chandoul et al 2015 shekhawat and chundawat 2015 busico et al 2017 çil 2017 elçi 2017 guettaia et al 2017 kazakis et al 2018 increasing accessibility to digital mapping technologies favored vulnerability applications machiwal et al 2018a some of the well known qualitative index based vulnerability methods machiwal et al 2018b are drastic aller et al 1987 god foster 1987 and gla hölting et al 1995 drastic is one of the pioneering vulnerability methods which was presented at 1987 aller et al 1987 drastic involves almost all possible characteristics of generally granular aquifer systems depth to water net recharge etc which may stimulate contamination or even pollution risk of groundwater many methods were developed by modification of pioneering methods such as sintacs civita and maio 2004 civita 2010 which was modified from drastic vulnerability methods specially developed for karstic aquifer environments are established as a sub group of methods under qualitative index based vulnerability methods diversity ray and o dell 1993 gla epik doerfliger et al 1999 pi goldscheider et al 2000 cop vías et al 2006 and core pavlis and cummins 2014 are some of the vulnerability methods that were developed to simulate vulnerability to groundwater contamination based on karst specific aquifer characteristics karst aquifers have unusual flow and storage condition in comparison to granular aquifers bakalowicz 2005 basic karstic aquifer characteristics which may stimulate and spread contamination are point wise recharge via dolines dissolution conduit of caves and groundwater fast flow and transport of contaminants through those conduits those characteristics increase the transport rate of contaminant within the aquifer without having the retardation advantages of soil cover and low permeable geologic units major complexity for aquifer vulnerability applications is the difficulty in characterization of karstic features and their areal extents common cause of uncertainty in vulnerability assessment applications is lack of information on assessment method parameters selection of proper assessment method discussion on proposed modified methods and validation approaches are the key points for the success of applied assessment method those uncertainties along with the current future research trends were recently discussed at review papers on vulnerability methodology gogu and dassargues 2000 machiwal et al 2018b in this study drastic sintacs cop epik and pi vulnerability methods were applied to altınova region within the antalya travertine plateau atp prevalent aquifer of the study area is the travertine which is a precipitation product of karstic springs and karstification is still effective over the travertine aquifer groundwater of travertine aquifer is the major source for irrigation and used as potable water for antalya city dense urbanization and agricultural production are the common sources of groundwater contamination the generated vulnerability maps based on different vulnerability methods were compared with each other and the observed no3 nitrate concentrations for validation the results of this study clearly showed that validation is a crucial step of vulnerability assessment especially for karst aquifers 2 study area study area is located within the antalya travertine plateau atp at the mediterranean coast of turkey fig 1 atp is the world s largest freshwater travertine deposition which extends 650 km2 atp laterally contacts with mesozoic limestones at the west and north borders along this lithologic contact karst springs discharge groundwater of mesozoic limestones travertine deposition originates as a result of secondary deposition of caco3 saturated groundwater discharges koşun et al 2019 travertine was developed in three stages during the quaternary where the thickness of the travertine is over 280 m at the northern boundary of the atp today lower stage of travertine is underwater whereas upper and middle stages are exposed atp hosts typical karst features such as springs caves dolines and solution channels some of major karst features are shown in fig 1 mediterranean climate with typically hot and dry summers and mild and wet winters prevails in the study area long term average air temperature and precipitation observations are 18 5 c and 1106 mm respectively actual evaporation is 771 mm based on turc equation turc 1954 the vulnerability assessment study was conducted for altınova region which is located at the eastern part of middle plateau and covers an area of 72 8 km2 fig 1 northern boundary of the study area is the upper and middle plateau contact western boundary is the düden spring and river eastern boundary is the aksu stream valley and the southern boundary is the airport zone which decided based on change in land use selected study area is the only region where groundwater abstracted for irrigation supply from travertine aquifer travertine belkıs conglomerate and kurşunlu formation are exposed geologic units over the study area fig 2 belkıs conglomerate and travertine are quaternary aged and overlay kurşunlu formation with discordant belkıs conglomerate is not classified as a separate geologic unit for some of the further interpretations because of its small exposure area and similar hydrogeological properties with kurşunlu formation mta 1997 travertine covers 85 of the study area and thickness of travertine in the study area varies from 50 m to 170 m kurşunlu formation is a fluvial geologic unit composed of sandstone and conglomerate which is aged to upper pliocene maximum thickness of kurşunlu formation is 150 m mta 1997 all of those units were classified as aquifers with variable porosity and permeability characteristics hydraulic conductivity constants and effective porosity of kurşunlu formation are 86 4 mm day and 20 respectively hydraulic characteristics of travertine aquifer exhibit high spatial variations due to irregular deposition conditions and ongoing dissolution karstification within the aquifer porosity of the travertine changes from 2 to 22 based on the experimental results akçal 2011 average hydraulic conductivity of travertine was reported as 864 mm day and this average value was used for vulnerability assessment groundwater head distribution was obtained based on the water table elevation measurements at november 2015 fig 3 water table elevations of the study area varied from 16 m to 75 m groundwater flow direction was from ne to sw at the eastern part and from n to s at the western part of the study area depth to groundwater is one of the essential parameters of the vulnerability assessment and it was generated from groundwater level measurements at november 2015 according to those hydraulic properties actual flow velocity of travertine and kurşunlu formations were 19 6 m day 216 m day and 3 m day respectively amil 2018 the study area is generally flat with slope values 2 but the slope increases up to 10 at a small area close to the eastern boundary lower topographic slope and highly permeable travertine favor infiltration instead of surface runoff widespread and dense infiltration encourages groundwater recharge and faster contaminant transport to the water table greenhouses cover 23 17 4 km2 of the study area and vegetables tomatoes pepper and cut flowers are the major agricultural products fig 4 the areas covered by greenhouses were classified from google earth images greenhouse planting is a year round agricultural practice at the study area groundwater of the travertine aquifer is the sole source of irrigation because of extensive and perennial planting fertilizers and pesticides are the potential sources of groundwater contamination extensive greenhouses reduce areal natural infiltration because of covered infrastructures infiltration from greenhouse areas is limited to the irrigation water excess which is important for the transport of probable contaminant s transport to the groundwater 3 materials and methods well known and widely used drastic sintacs cop epik and pi intrinsic vulnerability assessment methods were applied to the study area depth to groundwater net recharge effective infiltration aquifer media lithology soil type land use slope vadose zone protective cover hydraulic conductivity constant precipitation karst development layer index height and fracture density were parameters of the applied vulnerability methods method parameters were generated by literature survey and site observations the details of the parameter estimations and method specific ratings are presented elsewhere amil 2018 amil et al 2019 areal distribution of all the parameters and vulnerability maps were generated by arcgis software with 50 m 50 m resolution topo to raster interpolation routine was used for areal interpolation of pointwise data and measurements raster calculator tool of arcgis program was used for calculations from parameter maps to vulnerability maps a total 25 observation points 23 wells and 2 springs were selected for characterization of the study area for vulnerability assessment and validation as shown in fig 5 no3 is a widespread contaminant for the study area because of applied fertilizers therefore no3 concentrations of 16 17 may 2016 samples were used for validation of the generated vulnerability maps no3 concentrations were used for validation of the generated vulnerability maps no3 concentrations were analyzed by ion chromatography at water chemistry laboratory of hacettepe university with a total detection limit of 0 1 mg l the measured no3 concentrations varied between 0 1 and 108 2 mg l for the study area where the highest no3 concentrations were around the observation points of a1 a10 a16 a17 and a20 fig 5 a the performance of applied areal distribution approach tested based on root mean square error rms between observed and distributed values the rms error calculated as 0 05 which is an acceptable difference for this distribution since groundwater is primarily used for irrigation pollution limit was selected as higher than 30 mg l which was suggested as a limit concentration for irrigation water by fao fao 1985 moreover areal distribution of no3 concentrations was reclassified to show areal extend of no3 concentrations with values higher than 30 mg l fig 5 b reclassified no3 map generated in order to simplify and ease comparison with the vulnerability maps accordingly in 75 55 km2 of the study area groundwater no3 concentrations were higher than 30 mg l reclassified map of no3 concentrations with no3 concentration higher than 30 mg l was used as a validation map for vulnerability assessment validation maps generated by the selection of matching areas of very high high vulnerability index and no3 concentrations higher than 30 mg l as an example for drastic method validated vulnerable area drastic index 158 and no3 30 were compared by arcgis 4 results and discussion 4 1 results of vulnerability assessment results of all applied intrinsic vulnerability assessment methods drastic sintacs cop epik and pi are presented below with brief description of the methods reclassified map of no3 concentrations is presented together with vulnerability maps for comparison and validation 4 1 1 drastic drastic is the most popular vulnerability assessment method developed by aller et al 1987 this method was developed for various aquifer environment types such as granular karstic and fractured aquifers depth to water d net recharge r aquifer media a soil media s topography t impact of vadose zone i and hydraulic conductivity of the aquifer media c are the parameters of the method the details about the classes and weights of each parameter is presented elsewhere aller et al 1987 the parameter classes weights and the assigned scores for the study are presented in table 1 hydraulic conductivities of conglomerate aquifer and travertine aquifer are 86 4 mm day and 864 mm day respectively since all hydraulic conductivities are higher than drastic method description 81 5 mm day aquifer media c parameter was applied as greater than 81 5 mm day for all the study area net recharge and soil media parameters were assigned variable scores for greenhouse covered area and rest of the study area the scores of aquifer media and impact of vadose zone parameters were assigned different scores for the travertine and conglomerate aquifers depth to water parameter map was generated from point wise observations topography map was constituted by the slope tool of gis program based on the digital elevation model of the study area areal drastic index di values were calculated by eq 1 1 di d r d w r r r w a r a w s r s w t r t w i r i w c r c w drastic index based vulnerability map of the study area and no3 concentration based validation map are presented in fig 6 drastic index values were classified for low di 125 136 9 medium di 137 157 9 high 158 173 9 and very high 174 199 vulnerability zones areal extends of low medium high and very high zones were 2 8 km2 15 9 km2 34 km2 and 19 6 km2 respectively fig 6 a variable aquifer types greenhouse covered areas and depth to groundwater were the distinctive parameters for drastic method application the study area with the geological formation of travertine was classified as highly vulnerable in addition shallow groundwater depth zone as depth to groundwater values are lower at northern part of the study area within the travertine aquifer was classified as very high vulnerable the total areal extend of high and very high vulnerable zones was 53 6 km2 37 2 km2 of this high very high vulnerable zone validated by no3 concentrations fig 6 b within the shallow groundwater depth zone of the travertine aquifer such as well numbers a5 a6 a7 no3 concentrations were lower than the selected threshold concentration of 30 mg l therefore vulnerability classification for this area was over estimated in regard to no3 concentrations contrarily vulnerability classification missed out some wells a16 and a17 with high no3 concentrations within the conglomerate aquifer 4 1 2 sintacs sintacs method was revised from drastic for representation of variable aquifer environments in italy civita and maio 2004 civita 2010 this method has seven parameters being similar to drastic but weights parameter classes and scores are different from drastic depth to groundwater s effective infiltration action i unsaturated zone attenuation capacity n soil overburden attenuation capacity t hydrogeologic characteristics of the aquifer a hydraulic conductivity range of the aquifer c and hydrologic role of the topographic slope s are the parameters of sintacs method the details about the classes and weights of each parameter is presented elsewhere civita and maio 2004 civita 2010 sintacs weights are variable for different aquifer types and contaminants e g leaky aquifer karstic aquifer and nitrate in this application karstic aquifer weights were selected the parameter classes weights and the assigned scores for the study are presented in table 2 slope map was constituted by the slope tool of gis program based on the digital elevation model of the study area the scores of hydraulic conductivity range of the aquifer environment c and unsaturated zone attenuation capacity n parameters were different for the travertine and conglomerate aquifers parameter scores for aquifer environment and soil were classified according to different lithological descriptions hydrogeologic characteristics of the aquifer environment a and unsaturated zone attenuation capacity n scores of travertine aquifer were assigned as 10 based on karstic limestone lithology description of the method similarly aquifer environment a and unsaturated zone attenuation capacity n scores of conglomerate aquifer were assigned as 9 and 8 respectively based on sandstone conglomerate lithology description of the sintacs method hydraulic conductivity values were estimated as 10 5 m s 864 mm day and 10 6 m s 86 4 mm day for travertine and conglomerate aquifers respectively consequently corresponding scores of hydraulic conductivity ranges c were assigned as 4 and 3 for travertine and conglomerate aquifers respectively effective infiltration action and soil overburden attenuation capacity parameters had variable scores for greenhouses and rest of the study area depth to groundwater parameter map was generated from point wise observations of november 2015 areal sintacs index si values were calculated by eq 2 increasing sintacs index si values correspond to increasing aquifer vulnerability 2 si s r s w i r i w n r n w t r t w a r a w c r c w s r s w sintacs index based vulnerability map of the study area and no3 concentration based validation map are presented in fig 7 sintacs index values were classified for medium si 120 150 9 high 151 172 9 and very high 173 199 vulnerability zones low vulnerability zone was not classified by sintacs methods areal extends of medium high and very high zones were 2 9 km2 16 km2 and 53 5 km2 respectively fig 7 a variable aquifer types and greenhouse covered areas were the distinctive parameters for sintacs method application the study area with the geological formation of travertine was classified as high and very high vulnerable the area of conglomerate aquifer was classified to have all medium high and very high vulnerability zones the total areal extend of high and very high vulnerable zone was 69 5 km2 and 52 km2 of this zone was validated by no3 concentrations fig 7 b no3 concentrations at the northern part of the travertine aquifer were lower than the selected threshold concentration 30 mg l for the validation therefore vulnerability classification for this area was over estimated in regard to no3 concentrations in contrary to drastic method sintacs method could validate the high no3 concentrations at wells a16 and a17 within the conglomerate aquifer 4 1 3 cop cop vulnerability method was specifically developed for karstic aquifers including effects of channel flow and climate on vulnerability vías et al 2006 this method has three main parameters concentration of flow c overlaying layers o and precipitation p cop index cop i values were calculated by eq 3 all descriptions and attributed scores are presented in table 3 contrary to all other common vulnerability methods decreasing cop index cop i values correspond to increasing aquifer vulnerability 3 cop index cscore oscore pscore overlaying layers o score value is obtained by summing subfactors of soil os and lithology ol eq 4 4 oscore os ol os subfactor of soil combines soil texture e g clayey silty and thickness soil was defined as loam and the overall thickness of soil cover was assigned as 0 5 for the study area ol lithology description covers lithology and fracture development ly thickness of layer m and confining conditions cn information lithology and fracture development ly was assigned as 1 for travertine and 40 for conglomerate aquifers the thickness of travertine aquifer was derived from the well log data available at the literature as presented in fig 1 conglomerate aquifer was classified as qb and plk and their thickness values were assigned as 20 m and 150 m respectively layer index is calculated by multiplying lithology ly and layer thickness values eq 5 5 layer index ly m confining conditions cn are classified as unconfined semi confined and confined aquifers being critical for the recharge of the aquifers this parameter was defined as 1 for unconfined aquifers since all the aquifers of the study area are unconfined as a result lithology ol was calculated by multiplying values of layer index and confining conditions eq 6 6 ol layer index cn overlaying layers o score value was calculated by eq 4 and overlaying layer factor map was generated concentration of flow c score values were embedded into the vulnerability method to simulate the effects of point wise or areal recharge conditions daly et al 2002 since travertine aquifer recharge was mostly areal point wise recharge conditions were not considered in the vulnerability mapping taking this condition into consideration concentration of flow c was calculated by eq 7 and overlaying layer factor map was generated 7 c sf sv in eq 7 sf describes surface features whereas sv defines slope and vegetation sf value was assigned as 0 5 for travertine aquifer to define developed permeable karts environment and 1 for conglomerate aquifer group units qb and plk to define non karstified permeable unit overall slope values over the study area were lower than 9 and natural vegetation was negligible concentrations of flow c score values were calculated with eq 7 and overlaying layer factor map generated precipitation p score values depend on precipitation temporal distribution which is the ratio of annual total precipitation to number of rainy days eq 8 increase in precipitation intensity increases the vulnerability of the aquifer precipitation p scores were calculated by eq 9 8 precipitation temporal distribution pi annual precipitation mm number of rainy days 9 p pq pi where pq precipitation quantity mm year pi precipitation temporal distribution the annual precipitation quantity of the study area was 1106 1 mm year according to records of 1970 2015 observation period greenhouse covered areas were assumed not to receive annual precipitation because of covered infrastructure the infiltration from greenhouses was limited to the irrigation water excess accordingly pq values were assigned as 400 mm for greenhouse covered areas and 1106 1 mm for rest of the study area average number of rainy days was calculated as 75 1 days for the observational period from 1929 to 2016 using the data sets from turkish state meteorological services tsms 2019 cop based vulnerability map of the study area and no3 concentration based validation maps are presented in fig 8 cop index values were classified for low 2 4 medium 1 2 high 0 5 1 and very high 0 0 5 vulnerability zones areal extends of low medium high and very high zones were 10 71 km2 0 25 km2 13 4 km2 and 48 1 km2 respectively fig 8 a different aquifer types and greenhouse covered areas were the distinctive parameters for cop method application the study area with the geological formation of travertine was classified as very high vulnerable whereas medium and low vulnerability zones were classified for conglomerate aquifers qb and plk greenhouses within the conglomerated aquifer were not classified with different vulnerability classes the total areal extend of high and very high vulnerable zones was 61 5 km2 and 47 1 km2 of this zone was validated by no3 concentrations fig 8 b no3 concentrations at the northern part of the travertine aquifer were lower than the selected threshold concentration 30 mg l for the validation therefore vulnerability classification for this area was again over estimated in regard to no3 concentrations being similar to results of drastic method cop method could not validate the high no3 concentrations at wells a16 and a17 within the conglomerate aquifer 4 1 4 epik epik vulnerability method was developed for interpretation of vulnerability of karst aquifers such as cop method doerfliger et al 1999 epikarst e protective cover p infiltration conditions i and karst network development k are the parameters of the method each parameter has specific scores and weighting constants the sum of multiplied scores and weighting constants gives the epik vulnerability index value eq 10 10 fp α e β p γ i δ k where fp is the epik vulnerability index e p i and k are the scores of parameters and α β γ and δ are the weighting constants of each parameter weighting constants for α β γ and δ were defined as 3 1 3 and 2 respectively all descriptions and attributed scores for the study area are presented in table 4 epikarst e parameter is classified according to karstic morphologic features e1 class with score of 1 is described as highly developed based on available karst features such as caves dolines karrens etc whereas e3 class with the score of 4 is defined as limited or not available karst features regarding the study area travertine aquifer was defined as e1 class and conglomerate group aquifers were classified as e3 class protective cover p parameter was defined according to the covering geologic material over the karst or lower conductivity aquifers those geologic materials are soil or high conductivity unconsolidated deposits e g morren alluvium thickness of defined protective cover was used to assign scores of protective cover because of thin soil cover all over the study area protective cover score was assigned as 1 infiltration conditions i parameter depends on characterization of point dolines losing streams or artificial drainage areas and diffuse infiltration zones besides those karstic descriptions vegetation and slope were also embedded in the classifications different infiltration condition classifications were made for greenhouse covered areas and the rest of the study area since infiltration through the greenhouse covered areas was limited to the irrigation water excess i parameter was assigned as i4 class with a parameter score of 4 i3 class was assigned to the rest of the study area because of slope values lower than 9 the last parameter of epik method is the karst network development k k1 parameter that represents well developed karst network was assigned to travertine aquifer whereas k3 parameter was selected for non karstic conglomerate group aquifer units the scores for the k1 and k3 parameters are 1 and 3 respectively epik based vulnerability map of the study area and no3 concentration based validation maps are presented in fig 9 epik vulnerability index was classified for medium 25 and very high 19 vulnerability zones areal extends of medium and very high zones were 11 km2 and 61 5 km2 respectively fig 9 a variability of aquifer type was the only distinctive parameter for epik method application the study area with the geological formation of travertine was classified as very high vulnerable whereas medium vulnerability zone was classified for conglomerate group aquifers qb and plk although the total areal extend of very high vulnerable zone was 61 5 km2 only 47 1 km2 of this zone was validated by no3 concentrations fig 9 b no3 concentrations at the northern part of the travertine aquifer were lower than the selected threshold concentration 30 mg l for the validation therefore vulnerability classification for this area was again over estimated in regard to no3 concentrations being similar to results of drastic and cop methods epik method could not validate the high no3 concentrations at wells a16 and a17 within the conglomerate aquifer 4 1 5 pi although pi vulnerability method was developed as a vulnerability mapping method that could be applied for all aquifer types this method contains special parameters for karst aquifers goldscheider et al 2000 the details of pi method are available at european cost action 620 report zwahlen 2004 this method has two parameters namely protective cover p and infiltration conditions i where pi vulnerability index π is calculated by multiplying values of these two parameters all descriptions and attributed scores for the study area are presented in table 5 protective cover p parameter contains all layers soil layers non karstic rocks and karstic vadose zone above the water table p parameter scores were calculated by eq 11 this equation is modified from gla method hölting et al 1995 where the components of this equation are effective field capacity efc of soil type of lower soil and grain size distribution net recharge lithology and fracture density of rocks zwahlen 2004 11 pts t i̇ 1 m si mi j 1 n bj mj r a where pts total score of protective cover t topsoil s subsoil m thickness of each stratum m b bedrock r recharge mm year a artesian pressure bedrock b score was characterized by multiplying lithology l and fracturing f topsoil parameter depends on efc which is the water content of soil available for plants since in situ efc experiment results were not available for the study area efc was estimated for greenhouse covered area and rest of the study area using the existing information water content of soil of atp was determined as 10 for dry season by başal 1999 and the overall soil thickness for the study area was observed as 50 cm considering these characteristics efc was calculated as 50 mm and the corresponding t parameter score was assigned as 10 for the study area for greenhouse covered areas saturation of soils was much higher than this value due to yearlong irrigation and efc score was assigned as 50 lower soil was not considered for the calculations because of its absence over the study area recharge r parameter was assigned different scores for greenhouse covered areas 1 75 score for 50 mm recharge and the rest of the study area 1 score for 334 9 mm recharge lithology l parameter was classified according to the geologic units of the study area for fracture density f sub parameter densely fractured and karstified score was assigned to travertine aquifer whereas conglomerate group aquifers were characterized with very few fractured score lithology l score was 5 for all geologic units of the study area layer thickness values were obtained from the literature see fig 1 l and f score maps were multiplied by raster calculator module of arcgis software and the bedrock b map was generated for generation of m map thickness of each stratum in m atp travertine qa thickness map see fig 1 and average thickness values for conglomerate units 20 m for qb and 150 m for plk as presented in mta 1997 were used as no subsoil s definition was made for the study area it was not included in the calculations artesian a conditions were not considered since all aquifers of the study area are unconfined infiltration condition i parameter was also classified for the geologic units of the study area by considering soil type slope and plant cover pi based vulnerability map of the study area and no3 concentration based validation maps are presented in fig 10 pi vulnerability index was classified for low 3 4 medium 2 3 and high 2 vulnerability zones based on the assigned parameter scores very high vulnerability class was not defined areal extends of low medium and high vulnerable zones were 10 6 km2 58 8 km2 and 3 3 km2 respectively fig 10 a geological difference of the aquifers was the distinctive parameter for pi application thin travertine regions were classified as high vulnerable where the rest of the travertine aquifer area was classified as medium vulnerable conglomerate aquifer qb and plk areas were classified as medium and low vulnerability zones although the total areal extend of high vulnerable zone was 3 3 km2 only 1 1 km2 of this zone was validated by no3 concentrations fig 10 b as a result the generated vulnerability map of the study area by pi method was not validated in regard to high no3 concentrations pi method underestimated the vulnerability of almost all the regions except a small portion at the southern boundary of the study area 4 2 comparison of vulnerability assessment validation results for selection of appropriate vulnerability assessment method for the study area all generated vulnerability maps and validation results in regard to no3 concentrations were compared with each other as presented in table 6 although medium vulnerability zones were classified by all methods low high and very high vulnerability classes were not generated by some of the applied methods areas with low vulnerability were classified by drastic cop and pi methods and the areal extends of low vulnerable zones were 2 8 km2 10 7 km2 and 10 6 km2 respectively based on the highest percentage values approximately 15 of the study area was classified as low vulnerable to contamination and low vulnerable areas were all within the conglomerate aquifer units this classification was accepted as reasonable because of lower permeability of conglomerate aquifer units the areal extends of medium vulnerable zones were classified as 22 4 0 4 15 and 81 for drastic sintacs cop epik and pi methods respectively the lowest medium vulnerable zone 0 4 was generated by cop method for qb geological unit moreover the highest areal extent 81 of medium vulnerability class was obtained by pi method for almost all travertine exposure the areal extend of high and very high vulnerable areas was obtained to be higher than 74 of the study area by all the applied methods except pi method according to pi method the total area classified as high and very high vulnerable was only 3 3 km2 which covered 5 of the study area although pi is specific method developed for karstic aquifers this method could not generate a reasonable vulnerability map based on the assigned parameter definitions and scores according to results of sintacs method 22 and 73 of the study area were classified as high and very high vulnerable according to these results travertine and conglomerate group aquifers excluding the greenhouse covered areas were classified as high very high vulnerable only areal extents were not sufficient to decide about the proper vulnerability method for the study area therefore no3 concentration based validation method was performed for all the generated vulnerability maps for the validation process the areas with no3 concentrations of higher than 30 mg l were matched with high very high vulnerable areas outputs of the validation study showed that application of sintacs method with karstic aquifer weights could simulate 95 of the validation area as high and very high vulnerable where no3 concentrations were higher than the selected threshold level the validation performance of the karst specific methods cop and epik was 86 whereas pi method could validate only 2 of the area with no3 concentrations higher than 30 mg l the pioneering vulnerability method of drastic which does not contain any specific description for karst environment could validate 68 of the validation area in regard to no3 concentrations the simulation success of sintacs epik and cop methods depends on the more detailed score range descriptions for net recharge effective infiltration parameters compared to drastic method although vulnerability was primarily classified according to the thickness of aquifer by pi method this method was not successful to classify areas with high no3 concentrations as high vulnerable as a result sintacs method could be regarded as the most appropriate method for vulnerability assessment based on the applied validation approach this does not mean that sintacs method has special advantages against the other applied vulnerability methods but parameter definitions score ranges and weights of sintacs method were the most appropriate for altınova region modification of vulnerability method parameters and weights could be applied to increase the success of simulations hydraulic conductivity is the only parameter which is not defined by in situ measurements for study area at the same time hydraulic conductivity values may easily change in couple order of magnitude aerially in karst environments so in order to test the uncertainty of sintacs method hydraulic conductivity value has been increased one order of magnitude from 864 mm day to 8640 mm day and sintacs index values recalculated as a result maximum sintacs index value for the study area has been changed from 199 to 209 the change in hydraulic conductivity slightly increase 5 vulnerability index values and the areal extends of vulnerability classes 5 conclusions vulnerability assessment was conducted for altnova region within the atp via drastic sintacs epik cop and pi methods majority of the study area was covered by productive karstic aquifer which was composed of travertine and includes typical karstic features such as dolines springs and caves all the parameter maps and vulnerability index maps were generated by arcgis software in addition to areal extends of low medium high and very high vulnerability classes by application of both general and karst specific aquifer vulnerability methods to the study area we had the chance to compare the results of different methods high and very high vulnerable areas covered 74 of the study area according to all vulnerability methods except pi method total areal extend of high and very high vulnerable areas was obtained as 3 3 km2 by pi method which covered only 5 of the study area although pi method is a specific method for karstic aquifers this method could not generate a reasonable vulnerability map based on the assigned parameter definitions and scores the areal extends of high and very high vulnerable zones were classified as 22 and 73 of the study area by sintacs method according to these results travertine and conglomerate group aquifers excluding greenhouse covered areas were classified as high and very high vulnerable no3 concentration based validation method was performed to compare results of different vulnerability methods and the generated maps for the validation process the areas with no3 concentrations of higher than 30 mg l were matched with high very high vulnerable areas application of sintacs method with karstic aquifer weights could validate 95 of the area with no3 concentrations higher than the selected threshold level as a result sintacs method was accepted as the most appropriate method for vulnerability assessment in the study area outputs of this study showed that simulation performance of vulnerability methods was highly related to the defined parameter definitions score ranges and weights of each method similar parameters with different score ranges may create considerably different vulnerability maps as it happened for drastic and sintacs methods in altınova region therefore vulnerability mapping should be conducted in three stages for representative outputs i generate vulnerability maps based on different methods ii carry out site observations for at least one of the probable contaminants iii validate each vulnerability map by comparing with observed contaminant concentrations at the end of this process the best representative vulnerability method and validated scores of all parameters could be defined for the investigated study area afterwards the results of the best representative vulnerability method could be used as a valuable water resources management tool travertine aquifer of the study area is highly vulnerable to contamination and groundwater is already contaminated according to no3 concentrations for irrigation water quality growing agriculture may increase the concentrations of the agriculture based contaminants such as heavy metals and phosphate po4 3 near future since groundwater is the sole source of irrigation water so it is critical to keep water quality adequate for irrigation beyond the study area same travertine aquifer is also water resource for drinking water of antalya city as a result of the complex hydrogeologic setup of karstic aquifers contaminants may quickly transported long distances within the aquifer where groundwater is used as drinking water continuous groundwater quality observations are crucial for protection of water resources against contamination acknowledgement financial support was provided for this study by the scientific and technological research council of turkey tubitak project no 114y696 hacettepe university fhd 2015 8936 and fyl 2018 17095 grants 
1543,vulnerability maps were generated for altınova region within the antalya travertine plateau based on drastic sintacs epik cop and pi methods majority of the study area is covered by productive karstic aquifer which is composed of travertine travertine includes typical karstic features such as dolines springs and caves where groundwater of travertine aquifer is the sole source for irrigation areal extends of low medium high and very high vulnerability classes and their areal extends were determined for all methods and compared with each other high and very high vulnerable areas covered 74 of the study area as investigated by all methods except pi although pi is a specific method for karstic aquifers this method could not generate a reasonable vulnerability map based on the assigned parameter definitions and scores only areal extents were not sufficient to decide about the proper vulnerability method for the study area therefore no3 concentration based validation method was performed for all generated vulnerability maps consequently the areas which had no3 concentrations higher than 30 mg l were matched with high very high vulnerable areas according to this validation method application of sintacs with karstic aquifer weights could validate 95 of the area with no3 concentrations higher than the selected threshold level of 30 mg l for altınova region this study showed that simulation performance of vulnerability methods was highly related to the defined parameter definitions score ranges and weights of each method similar parameters with variable score ranges could create considerably distinct vulnerability maps validation is the essential interpretation step for taking decision on the proper vulnerability method additionally site specific contaminant observations are critical for validation of vulnerability maps validated vulnerability maps could be used as a valuable water resources management tool graphical abstract unlabelled image keywords antalya travertine plateau vulnerability mapping validation karst aquifer 1 introduction freshwater resources are crucial for human life irrigation and industrial use climate change excess withdrawal and contamination are common threats to freshwater resources adverse impacts of excess withdrawal and contamination can be suppressed by preventive management strategies detailed characterization of freshwater resources is essential to propose and accomplish site specific management strategies based on the results of a detailed characterization study protection areas and vulnerability risk maps can easily be adopted for freshwater resources lakes streams groundwater or wetlands characterization of groundwater resources is much more complex than surface water resources because of unpredictable geological setup and storage flow conditions of the aquifer environment because of this complexity intrinsic vulnerability assessment is a good option to prescribe probable areas for groundwater contamination intrinsic vulnerability is the first step on the way to risk assessment for groundwater resources various vulnerability assessment methods have been widely used for groundwater management applications since late 1960s margat 1968 since then vulnerability applications were widely applied all around the world for different hydrogeologic conditions some of the vulnerability applications were conducted by babiker et al 2005 goldscheider 2005 varol and davraz 2010 güler et al 2013 alaya et al 2013 masoompour samakosh et al 2013 yin et al 2013 muhammad et al 2015 chandoul et al 2015 shekhawat and chundawat 2015 busico et al 2017 çil 2017 elçi 2017 guettaia et al 2017 kazakis et al 2018 increasing accessibility to digital mapping technologies favored vulnerability applications machiwal et al 2018a some of the well known qualitative index based vulnerability methods machiwal et al 2018b are drastic aller et al 1987 god foster 1987 and gla hölting et al 1995 drastic is one of the pioneering vulnerability methods which was presented at 1987 aller et al 1987 drastic involves almost all possible characteristics of generally granular aquifer systems depth to water net recharge etc which may stimulate contamination or even pollution risk of groundwater many methods were developed by modification of pioneering methods such as sintacs civita and maio 2004 civita 2010 which was modified from drastic vulnerability methods specially developed for karstic aquifer environments are established as a sub group of methods under qualitative index based vulnerability methods diversity ray and o dell 1993 gla epik doerfliger et al 1999 pi goldscheider et al 2000 cop vías et al 2006 and core pavlis and cummins 2014 are some of the vulnerability methods that were developed to simulate vulnerability to groundwater contamination based on karst specific aquifer characteristics karst aquifers have unusual flow and storage condition in comparison to granular aquifers bakalowicz 2005 basic karstic aquifer characteristics which may stimulate and spread contamination are point wise recharge via dolines dissolution conduit of caves and groundwater fast flow and transport of contaminants through those conduits those characteristics increase the transport rate of contaminant within the aquifer without having the retardation advantages of soil cover and low permeable geologic units major complexity for aquifer vulnerability applications is the difficulty in characterization of karstic features and their areal extents common cause of uncertainty in vulnerability assessment applications is lack of information on assessment method parameters selection of proper assessment method discussion on proposed modified methods and validation approaches are the key points for the success of applied assessment method those uncertainties along with the current future research trends were recently discussed at review papers on vulnerability methodology gogu and dassargues 2000 machiwal et al 2018b in this study drastic sintacs cop epik and pi vulnerability methods were applied to altınova region within the antalya travertine plateau atp prevalent aquifer of the study area is the travertine which is a precipitation product of karstic springs and karstification is still effective over the travertine aquifer groundwater of travertine aquifer is the major source for irrigation and used as potable water for antalya city dense urbanization and agricultural production are the common sources of groundwater contamination the generated vulnerability maps based on different vulnerability methods were compared with each other and the observed no3 nitrate concentrations for validation the results of this study clearly showed that validation is a crucial step of vulnerability assessment especially for karst aquifers 2 study area study area is located within the antalya travertine plateau atp at the mediterranean coast of turkey fig 1 atp is the world s largest freshwater travertine deposition which extends 650 km2 atp laterally contacts with mesozoic limestones at the west and north borders along this lithologic contact karst springs discharge groundwater of mesozoic limestones travertine deposition originates as a result of secondary deposition of caco3 saturated groundwater discharges koşun et al 2019 travertine was developed in three stages during the quaternary where the thickness of the travertine is over 280 m at the northern boundary of the atp today lower stage of travertine is underwater whereas upper and middle stages are exposed atp hosts typical karst features such as springs caves dolines and solution channels some of major karst features are shown in fig 1 mediterranean climate with typically hot and dry summers and mild and wet winters prevails in the study area long term average air temperature and precipitation observations are 18 5 c and 1106 mm respectively actual evaporation is 771 mm based on turc equation turc 1954 the vulnerability assessment study was conducted for altınova region which is located at the eastern part of middle plateau and covers an area of 72 8 km2 fig 1 northern boundary of the study area is the upper and middle plateau contact western boundary is the düden spring and river eastern boundary is the aksu stream valley and the southern boundary is the airport zone which decided based on change in land use selected study area is the only region where groundwater abstracted for irrigation supply from travertine aquifer travertine belkıs conglomerate and kurşunlu formation are exposed geologic units over the study area fig 2 belkıs conglomerate and travertine are quaternary aged and overlay kurşunlu formation with discordant belkıs conglomerate is not classified as a separate geologic unit for some of the further interpretations because of its small exposure area and similar hydrogeological properties with kurşunlu formation mta 1997 travertine covers 85 of the study area and thickness of travertine in the study area varies from 50 m to 170 m kurşunlu formation is a fluvial geologic unit composed of sandstone and conglomerate which is aged to upper pliocene maximum thickness of kurşunlu formation is 150 m mta 1997 all of those units were classified as aquifers with variable porosity and permeability characteristics hydraulic conductivity constants and effective porosity of kurşunlu formation are 86 4 mm day and 20 respectively hydraulic characteristics of travertine aquifer exhibit high spatial variations due to irregular deposition conditions and ongoing dissolution karstification within the aquifer porosity of the travertine changes from 2 to 22 based on the experimental results akçal 2011 average hydraulic conductivity of travertine was reported as 864 mm day and this average value was used for vulnerability assessment groundwater head distribution was obtained based on the water table elevation measurements at november 2015 fig 3 water table elevations of the study area varied from 16 m to 75 m groundwater flow direction was from ne to sw at the eastern part and from n to s at the western part of the study area depth to groundwater is one of the essential parameters of the vulnerability assessment and it was generated from groundwater level measurements at november 2015 according to those hydraulic properties actual flow velocity of travertine and kurşunlu formations were 19 6 m day 216 m day and 3 m day respectively amil 2018 the study area is generally flat with slope values 2 but the slope increases up to 10 at a small area close to the eastern boundary lower topographic slope and highly permeable travertine favor infiltration instead of surface runoff widespread and dense infiltration encourages groundwater recharge and faster contaminant transport to the water table greenhouses cover 23 17 4 km2 of the study area and vegetables tomatoes pepper and cut flowers are the major agricultural products fig 4 the areas covered by greenhouses were classified from google earth images greenhouse planting is a year round agricultural practice at the study area groundwater of the travertine aquifer is the sole source of irrigation because of extensive and perennial planting fertilizers and pesticides are the potential sources of groundwater contamination extensive greenhouses reduce areal natural infiltration because of covered infrastructures infiltration from greenhouse areas is limited to the irrigation water excess which is important for the transport of probable contaminant s transport to the groundwater 3 materials and methods well known and widely used drastic sintacs cop epik and pi intrinsic vulnerability assessment methods were applied to the study area depth to groundwater net recharge effective infiltration aquifer media lithology soil type land use slope vadose zone protective cover hydraulic conductivity constant precipitation karst development layer index height and fracture density were parameters of the applied vulnerability methods method parameters were generated by literature survey and site observations the details of the parameter estimations and method specific ratings are presented elsewhere amil 2018 amil et al 2019 areal distribution of all the parameters and vulnerability maps were generated by arcgis software with 50 m 50 m resolution topo to raster interpolation routine was used for areal interpolation of pointwise data and measurements raster calculator tool of arcgis program was used for calculations from parameter maps to vulnerability maps a total 25 observation points 23 wells and 2 springs were selected for characterization of the study area for vulnerability assessment and validation as shown in fig 5 no3 is a widespread contaminant for the study area because of applied fertilizers therefore no3 concentrations of 16 17 may 2016 samples were used for validation of the generated vulnerability maps no3 concentrations were used for validation of the generated vulnerability maps no3 concentrations were analyzed by ion chromatography at water chemistry laboratory of hacettepe university with a total detection limit of 0 1 mg l the measured no3 concentrations varied between 0 1 and 108 2 mg l for the study area where the highest no3 concentrations were around the observation points of a1 a10 a16 a17 and a20 fig 5 a the performance of applied areal distribution approach tested based on root mean square error rms between observed and distributed values the rms error calculated as 0 05 which is an acceptable difference for this distribution since groundwater is primarily used for irrigation pollution limit was selected as higher than 30 mg l which was suggested as a limit concentration for irrigation water by fao fao 1985 moreover areal distribution of no3 concentrations was reclassified to show areal extend of no3 concentrations with values higher than 30 mg l fig 5 b reclassified no3 map generated in order to simplify and ease comparison with the vulnerability maps accordingly in 75 55 km2 of the study area groundwater no3 concentrations were higher than 30 mg l reclassified map of no3 concentrations with no3 concentration higher than 30 mg l was used as a validation map for vulnerability assessment validation maps generated by the selection of matching areas of very high high vulnerability index and no3 concentrations higher than 30 mg l as an example for drastic method validated vulnerable area drastic index 158 and no3 30 were compared by arcgis 4 results and discussion 4 1 results of vulnerability assessment results of all applied intrinsic vulnerability assessment methods drastic sintacs cop epik and pi are presented below with brief description of the methods reclassified map of no3 concentrations is presented together with vulnerability maps for comparison and validation 4 1 1 drastic drastic is the most popular vulnerability assessment method developed by aller et al 1987 this method was developed for various aquifer environment types such as granular karstic and fractured aquifers depth to water d net recharge r aquifer media a soil media s topography t impact of vadose zone i and hydraulic conductivity of the aquifer media c are the parameters of the method the details about the classes and weights of each parameter is presented elsewhere aller et al 1987 the parameter classes weights and the assigned scores for the study are presented in table 1 hydraulic conductivities of conglomerate aquifer and travertine aquifer are 86 4 mm day and 864 mm day respectively since all hydraulic conductivities are higher than drastic method description 81 5 mm day aquifer media c parameter was applied as greater than 81 5 mm day for all the study area net recharge and soil media parameters were assigned variable scores for greenhouse covered area and rest of the study area the scores of aquifer media and impact of vadose zone parameters were assigned different scores for the travertine and conglomerate aquifers depth to water parameter map was generated from point wise observations topography map was constituted by the slope tool of gis program based on the digital elevation model of the study area areal drastic index di values were calculated by eq 1 1 di d r d w r r r w a r a w s r s w t r t w i r i w c r c w drastic index based vulnerability map of the study area and no3 concentration based validation map are presented in fig 6 drastic index values were classified for low di 125 136 9 medium di 137 157 9 high 158 173 9 and very high 174 199 vulnerability zones areal extends of low medium high and very high zones were 2 8 km2 15 9 km2 34 km2 and 19 6 km2 respectively fig 6 a variable aquifer types greenhouse covered areas and depth to groundwater were the distinctive parameters for drastic method application the study area with the geological formation of travertine was classified as highly vulnerable in addition shallow groundwater depth zone as depth to groundwater values are lower at northern part of the study area within the travertine aquifer was classified as very high vulnerable the total areal extend of high and very high vulnerable zones was 53 6 km2 37 2 km2 of this high very high vulnerable zone validated by no3 concentrations fig 6 b within the shallow groundwater depth zone of the travertine aquifer such as well numbers a5 a6 a7 no3 concentrations were lower than the selected threshold concentration of 30 mg l therefore vulnerability classification for this area was over estimated in regard to no3 concentrations contrarily vulnerability classification missed out some wells a16 and a17 with high no3 concentrations within the conglomerate aquifer 4 1 2 sintacs sintacs method was revised from drastic for representation of variable aquifer environments in italy civita and maio 2004 civita 2010 this method has seven parameters being similar to drastic but weights parameter classes and scores are different from drastic depth to groundwater s effective infiltration action i unsaturated zone attenuation capacity n soil overburden attenuation capacity t hydrogeologic characteristics of the aquifer a hydraulic conductivity range of the aquifer c and hydrologic role of the topographic slope s are the parameters of sintacs method the details about the classes and weights of each parameter is presented elsewhere civita and maio 2004 civita 2010 sintacs weights are variable for different aquifer types and contaminants e g leaky aquifer karstic aquifer and nitrate in this application karstic aquifer weights were selected the parameter classes weights and the assigned scores for the study are presented in table 2 slope map was constituted by the slope tool of gis program based on the digital elevation model of the study area the scores of hydraulic conductivity range of the aquifer environment c and unsaturated zone attenuation capacity n parameters were different for the travertine and conglomerate aquifers parameter scores for aquifer environment and soil were classified according to different lithological descriptions hydrogeologic characteristics of the aquifer environment a and unsaturated zone attenuation capacity n scores of travertine aquifer were assigned as 10 based on karstic limestone lithology description of the method similarly aquifer environment a and unsaturated zone attenuation capacity n scores of conglomerate aquifer were assigned as 9 and 8 respectively based on sandstone conglomerate lithology description of the sintacs method hydraulic conductivity values were estimated as 10 5 m s 864 mm day and 10 6 m s 86 4 mm day for travertine and conglomerate aquifers respectively consequently corresponding scores of hydraulic conductivity ranges c were assigned as 4 and 3 for travertine and conglomerate aquifers respectively effective infiltration action and soil overburden attenuation capacity parameters had variable scores for greenhouses and rest of the study area depth to groundwater parameter map was generated from point wise observations of november 2015 areal sintacs index si values were calculated by eq 2 increasing sintacs index si values correspond to increasing aquifer vulnerability 2 si s r s w i r i w n r n w t r t w a r a w c r c w s r s w sintacs index based vulnerability map of the study area and no3 concentration based validation map are presented in fig 7 sintacs index values were classified for medium si 120 150 9 high 151 172 9 and very high 173 199 vulnerability zones low vulnerability zone was not classified by sintacs methods areal extends of medium high and very high zones were 2 9 km2 16 km2 and 53 5 km2 respectively fig 7 a variable aquifer types and greenhouse covered areas were the distinctive parameters for sintacs method application the study area with the geological formation of travertine was classified as high and very high vulnerable the area of conglomerate aquifer was classified to have all medium high and very high vulnerability zones the total areal extend of high and very high vulnerable zone was 69 5 km2 and 52 km2 of this zone was validated by no3 concentrations fig 7 b no3 concentrations at the northern part of the travertine aquifer were lower than the selected threshold concentration 30 mg l for the validation therefore vulnerability classification for this area was over estimated in regard to no3 concentrations in contrary to drastic method sintacs method could validate the high no3 concentrations at wells a16 and a17 within the conglomerate aquifer 4 1 3 cop cop vulnerability method was specifically developed for karstic aquifers including effects of channel flow and climate on vulnerability vías et al 2006 this method has three main parameters concentration of flow c overlaying layers o and precipitation p cop index cop i values were calculated by eq 3 all descriptions and attributed scores are presented in table 3 contrary to all other common vulnerability methods decreasing cop index cop i values correspond to increasing aquifer vulnerability 3 cop index cscore oscore pscore overlaying layers o score value is obtained by summing subfactors of soil os and lithology ol eq 4 4 oscore os ol os subfactor of soil combines soil texture e g clayey silty and thickness soil was defined as loam and the overall thickness of soil cover was assigned as 0 5 for the study area ol lithology description covers lithology and fracture development ly thickness of layer m and confining conditions cn information lithology and fracture development ly was assigned as 1 for travertine and 40 for conglomerate aquifers the thickness of travertine aquifer was derived from the well log data available at the literature as presented in fig 1 conglomerate aquifer was classified as qb and plk and their thickness values were assigned as 20 m and 150 m respectively layer index is calculated by multiplying lithology ly and layer thickness values eq 5 5 layer index ly m confining conditions cn are classified as unconfined semi confined and confined aquifers being critical for the recharge of the aquifers this parameter was defined as 1 for unconfined aquifers since all the aquifers of the study area are unconfined as a result lithology ol was calculated by multiplying values of layer index and confining conditions eq 6 6 ol layer index cn overlaying layers o score value was calculated by eq 4 and overlaying layer factor map was generated concentration of flow c score values were embedded into the vulnerability method to simulate the effects of point wise or areal recharge conditions daly et al 2002 since travertine aquifer recharge was mostly areal point wise recharge conditions were not considered in the vulnerability mapping taking this condition into consideration concentration of flow c was calculated by eq 7 and overlaying layer factor map was generated 7 c sf sv in eq 7 sf describes surface features whereas sv defines slope and vegetation sf value was assigned as 0 5 for travertine aquifer to define developed permeable karts environment and 1 for conglomerate aquifer group units qb and plk to define non karstified permeable unit overall slope values over the study area were lower than 9 and natural vegetation was negligible concentrations of flow c score values were calculated with eq 7 and overlaying layer factor map generated precipitation p score values depend on precipitation temporal distribution which is the ratio of annual total precipitation to number of rainy days eq 8 increase in precipitation intensity increases the vulnerability of the aquifer precipitation p scores were calculated by eq 9 8 precipitation temporal distribution pi annual precipitation mm number of rainy days 9 p pq pi where pq precipitation quantity mm year pi precipitation temporal distribution the annual precipitation quantity of the study area was 1106 1 mm year according to records of 1970 2015 observation period greenhouse covered areas were assumed not to receive annual precipitation because of covered infrastructure the infiltration from greenhouses was limited to the irrigation water excess accordingly pq values were assigned as 400 mm for greenhouse covered areas and 1106 1 mm for rest of the study area average number of rainy days was calculated as 75 1 days for the observational period from 1929 to 2016 using the data sets from turkish state meteorological services tsms 2019 cop based vulnerability map of the study area and no3 concentration based validation maps are presented in fig 8 cop index values were classified for low 2 4 medium 1 2 high 0 5 1 and very high 0 0 5 vulnerability zones areal extends of low medium high and very high zones were 10 71 km2 0 25 km2 13 4 km2 and 48 1 km2 respectively fig 8 a different aquifer types and greenhouse covered areas were the distinctive parameters for cop method application the study area with the geological formation of travertine was classified as very high vulnerable whereas medium and low vulnerability zones were classified for conglomerate aquifers qb and plk greenhouses within the conglomerated aquifer were not classified with different vulnerability classes the total areal extend of high and very high vulnerable zones was 61 5 km2 and 47 1 km2 of this zone was validated by no3 concentrations fig 8 b no3 concentrations at the northern part of the travertine aquifer were lower than the selected threshold concentration 30 mg l for the validation therefore vulnerability classification for this area was again over estimated in regard to no3 concentrations being similar to results of drastic method cop method could not validate the high no3 concentrations at wells a16 and a17 within the conglomerate aquifer 4 1 4 epik epik vulnerability method was developed for interpretation of vulnerability of karst aquifers such as cop method doerfliger et al 1999 epikarst e protective cover p infiltration conditions i and karst network development k are the parameters of the method each parameter has specific scores and weighting constants the sum of multiplied scores and weighting constants gives the epik vulnerability index value eq 10 10 fp α e β p γ i δ k where fp is the epik vulnerability index e p i and k are the scores of parameters and α β γ and δ are the weighting constants of each parameter weighting constants for α β γ and δ were defined as 3 1 3 and 2 respectively all descriptions and attributed scores for the study area are presented in table 4 epikarst e parameter is classified according to karstic morphologic features e1 class with score of 1 is described as highly developed based on available karst features such as caves dolines karrens etc whereas e3 class with the score of 4 is defined as limited or not available karst features regarding the study area travertine aquifer was defined as e1 class and conglomerate group aquifers were classified as e3 class protective cover p parameter was defined according to the covering geologic material over the karst or lower conductivity aquifers those geologic materials are soil or high conductivity unconsolidated deposits e g morren alluvium thickness of defined protective cover was used to assign scores of protective cover because of thin soil cover all over the study area protective cover score was assigned as 1 infiltration conditions i parameter depends on characterization of point dolines losing streams or artificial drainage areas and diffuse infiltration zones besides those karstic descriptions vegetation and slope were also embedded in the classifications different infiltration condition classifications were made for greenhouse covered areas and the rest of the study area since infiltration through the greenhouse covered areas was limited to the irrigation water excess i parameter was assigned as i4 class with a parameter score of 4 i3 class was assigned to the rest of the study area because of slope values lower than 9 the last parameter of epik method is the karst network development k k1 parameter that represents well developed karst network was assigned to travertine aquifer whereas k3 parameter was selected for non karstic conglomerate group aquifer units the scores for the k1 and k3 parameters are 1 and 3 respectively epik based vulnerability map of the study area and no3 concentration based validation maps are presented in fig 9 epik vulnerability index was classified for medium 25 and very high 19 vulnerability zones areal extends of medium and very high zones were 11 km2 and 61 5 km2 respectively fig 9 a variability of aquifer type was the only distinctive parameter for epik method application the study area with the geological formation of travertine was classified as very high vulnerable whereas medium vulnerability zone was classified for conglomerate group aquifers qb and plk although the total areal extend of very high vulnerable zone was 61 5 km2 only 47 1 km2 of this zone was validated by no3 concentrations fig 9 b no3 concentrations at the northern part of the travertine aquifer were lower than the selected threshold concentration 30 mg l for the validation therefore vulnerability classification for this area was again over estimated in regard to no3 concentrations being similar to results of drastic and cop methods epik method could not validate the high no3 concentrations at wells a16 and a17 within the conglomerate aquifer 4 1 5 pi although pi vulnerability method was developed as a vulnerability mapping method that could be applied for all aquifer types this method contains special parameters for karst aquifers goldscheider et al 2000 the details of pi method are available at european cost action 620 report zwahlen 2004 this method has two parameters namely protective cover p and infiltration conditions i where pi vulnerability index π is calculated by multiplying values of these two parameters all descriptions and attributed scores for the study area are presented in table 5 protective cover p parameter contains all layers soil layers non karstic rocks and karstic vadose zone above the water table p parameter scores were calculated by eq 11 this equation is modified from gla method hölting et al 1995 where the components of this equation are effective field capacity efc of soil type of lower soil and grain size distribution net recharge lithology and fracture density of rocks zwahlen 2004 11 pts t i̇ 1 m si mi j 1 n bj mj r a where pts total score of protective cover t topsoil s subsoil m thickness of each stratum m b bedrock r recharge mm year a artesian pressure bedrock b score was characterized by multiplying lithology l and fracturing f topsoil parameter depends on efc which is the water content of soil available for plants since in situ efc experiment results were not available for the study area efc was estimated for greenhouse covered area and rest of the study area using the existing information water content of soil of atp was determined as 10 for dry season by başal 1999 and the overall soil thickness for the study area was observed as 50 cm considering these characteristics efc was calculated as 50 mm and the corresponding t parameter score was assigned as 10 for the study area for greenhouse covered areas saturation of soils was much higher than this value due to yearlong irrigation and efc score was assigned as 50 lower soil was not considered for the calculations because of its absence over the study area recharge r parameter was assigned different scores for greenhouse covered areas 1 75 score for 50 mm recharge and the rest of the study area 1 score for 334 9 mm recharge lithology l parameter was classified according to the geologic units of the study area for fracture density f sub parameter densely fractured and karstified score was assigned to travertine aquifer whereas conglomerate group aquifers were characterized with very few fractured score lithology l score was 5 for all geologic units of the study area layer thickness values were obtained from the literature see fig 1 l and f score maps were multiplied by raster calculator module of arcgis software and the bedrock b map was generated for generation of m map thickness of each stratum in m atp travertine qa thickness map see fig 1 and average thickness values for conglomerate units 20 m for qb and 150 m for plk as presented in mta 1997 were used as no subsoil s definition was made for the study area it was not included in the calculations artesian a conditions were not considered since all aquifers of the study area are unconfined infiltration condition i parameter was also classified for the geologic units of the study area by considering soil type slope and plant cover pi based vulnerability map of the study area and no3 concentration based validation maps are presented in fig 10 pi vulnerability index was classified for low 3 4 medium 2 3 and high 2 vulnerability zones based on the assigned parameter scores very high vulnerability class was not defined areal extends of low medium and high vulnerable zones were 10 6 km2 58 8 km2 and 3 3 km2 respectively fig 10 a geological difference of the aquifers was the distinctive parameter for pi application thin travertine regions were classified as high vulnerable where the rest of the travertine aquifer area was classified as medium vulnerable conglomerate aquifer qb and plk areas were classified as medium and low vulnerability zones although the total areal extend of high vulnerable zone was 3 3 km2 only 1 1 km2 of this zone was validated by no3 concentrations fig 10 b as a result the generated vulnerability map of the study area by pi method was not validated in regard to high no3 concentrations pi method underestimated the vulnerability of almost all the regions except a small portion at the southern boundary of the study area 4 2 comparison of vulnerability assessment validation results for selection of appropriate vulnerability assessment method for the study area all generated vulnerability maps and validation results in regard to no3 concentrations were compared with each other as presented in table 6 although medium vulnerability zones were classified by all methods low high and very high vulnerability classes were not generated by some of the applied methods areas with low vulnerability were classified by drastic cop and pi methods and the areal extends of low vulnerable zones were 2 8 km2 10 7 km2 and 10 6 km2 respectively based on the highest percentage values approximately 15 of the study area was classified as low vulnerable to contamination and low vulnerable areas were all within the conglomerate aquifer units this classification was accepted as reasonable because of lower permeability of conglomerate aquifer units the areal extends of medium vulnerable zones were classified as 22 4 0 4 15 and 81 for drastic sintacs cop epik and pi methods respectively the lowest medium vulnerable zone 0 4 was generated by cop method for qb geological unit moreover the highest areal extent 81 of medium vulnerability class was obtained by pi method for almost all travertine exposure the areal extend of high and very high vulnerable areas was obtained to be higher than 74 of the study area by all the applied methods except pi method according to pi method the total area classified as high and very high vulnerable was only 3 3 km2 which covered 5 of the study area although pi is specific method developed for karstic aquifers this method could not generate a reasonable vulnerability map based on the assigned parameter definitions and scores according to results of sintacs method 22 and 73 of the study area were classified as high and very high vulnerable according to these results travertine and conglomerate group aquifers excluding the greenhouse covered areas were classified as high very high vulnerable only areal extents were not sufficient to decide about the proper vulnerability method for the study area therefore no3 concentration based validation method was performed for all the generated vulnerability maps for the validation process the areas with no3 concentrations of higher than 30 mg l were matched with high very high vulnerable areas outputs of the validation study showed that application of sintacs method with karstic aquifer weights could simulate 95 of the validation area as high and very high vulnerable where no3 concentrations were higher than the selected threshold level the validation performance of the karst specific methods cop and epik was 86 whereas pi method could validate only 2 of the area with no3 concentrations higher than 30 mg l the pioneering vulnerability method of drastic which does not contain any specific description for karst environment could validate 68 of the validation area in regard to no3 concentrations the simulation success of sintacs epik and cop methods depends on the more detailed score range descriptions for net recharge effective infiltration parameters compared to drastic method although vulnerability was primarily classified according to the thickness of aquifer by pi method this method was not successful to classify areas with high no3 concentrations as high vulnerable as a result sintacs method could be regarded as the most appropriate method for vulnerability assessment based on the applied validation approach this does not mean that sintacs method has special advantages against the other applied vulnerability methods but parameter definitions score ranges and weights of sintacs method were the most appropriate for altınova region modification of vulnerability method parameters and weights could be applied to increase the success of simulations hydraulic conductivity is the only parameter which is not defined by in situ measurements for study area at the same time hydraulic conductivity values may easily change in couple order of magnitude aerially in karst environments so in order to test the uncertainty of sintacs method hydraulic conductivity value has been increased one order of magnitude from 864 mm day to 8640 mm day and sintacs index values recalculated as a result maximum sintacs index value for the study area has been changed from 199 to 209 the change in hydraulic conductivity slightly increase 5 vulnerability index values and the areal extends of vulnerability classes 5 conclusions vulnerability assessment was conducted for altnova region within the atp via drastic sintacs epik cop and pi methods majority of the study area was covered by productive karstic aquifer which was composed of travertine and includes typical karstic features such as dolines springs and caves all the parameter maps and vulnerability index maps were generated by arcgis software in addition to areal extends of low medium high and very high vulnerability classes by application of both general and karst specific aquifer vulnerability methods to the study area we had the chance to compare the results of different methods high and very high vulnerable areas covered 74 of the study area according to all vulnerability methods except pi method total areal extend of high and very high vulnerable areas was obtained as 3 3 km2 by pi method which covered only 5 of the study area although pi method is a specific method for karstic aquifers this method could not generate a reasonable vulnerability map based on the assigned parameter definitions and scores the areal extends of high and very high vulnerable zones were classified as 22 and 73 of the study area by sintacs method according to these results travertine and conglomerate group aquifers excluding greenhouse covered areas were classified as high and very high vulnerable no3 concentration based validation method was performed to compare results of different vulnerability methods and the generated maps for the validation process the areas with no3 concentrations of higher than 30 mg l were matched with high very high vulnerable areas application of sintacs method with karstic aquifer weights could validate 95 of the area with no3 concentrations higher than the selected threshold level as a result sintacs method was accepted as the most appropriate method for vulnerability assessment in the study area outputs of this study showed that simulation performance of vulnerability methods was highly related to the defined parameter definitions score ranges and weights of each method similar parameters with different score ranges may create considerably different vulnerability maps as it happened for drastic and sintacs methods in altınova region therefore vulnerability mapping should be conducted in three stages for representative outputs i generate vulnerability maps based on different methods ii carry out site observations for at least one of the probable contaminants iii validate each vulnerability map by comparing with observed contaminant concentrations at the end of this process the best representative vulnerability method and validated scores of all parameters could be defined for the investigated study area afterwards the results of the best representative vulnerability method could be used as a valuable water resources management tool travertine aquifer of the study area is highly vulnerable to contamination and groundwater is already contaminated according to no3 concentrations for irrigation water quality growing agriculture may increase the concentrations of the agriculture based contaminants such as heavy metals and phosphate po4 3 near future since groundwater is the sole source of irrigation water so it is critical to keep water quality adequate for irrigation beyond the study area same travertine aquifer is also water resource for drinking water of antalya city as a result of the complex hydrogeologic setup of karstic aquifers contaminants may quickly transported long distances within the aquifer where groundwater is used as drinking water continuous groundwater quality observations are crucial for protection of water resources against contamination acknowledgement financial support was provided for this study by the scientific and technological research council of turkey tubitak project no 114y696 hacettepe university fhd 2015 8936 and fyl 2018 17095 grants 
1544,phosphate modified ordered mesoporous carbon momc np has been synthesized and proven to be an effective adsorbent for pb ii removal from aqueous solutions however the key application components of the mass transfer operations and diffusion coefficient have not been determined in this study a modified finite bath diffusion control model was mathematically developed containing a constant related to the radius of the adsorbent particle and the fractional attainment of adsorption the adsorption experiments were conducted under various initial pb ii concentrations ranging from 60 mg l 1 to 100 mg l 1 the results suggested that the modified finite bath diffusion control model was more applicable to the experimental data than the original finite bath diffusion control model the average value of the diffusion coefficient λ d obtained from the modified finite bath diffusion control model was 1 63 10 2 cm2 s 1 indicating the effective diffusivity in the adsorption of pb ii on momc np overall the modified finite bath diffusion control model exhibited the precise description and simulation of the mass transfer kinetics for pb ii adsorption onto momc np therefore the modified finite bath diffusion control model could be effectively used to investigate the mass transfer kinetics of the adsorption process graphical abstract unlabelled image keywords omc phosphate modification lead ii adsorption finite bath diffusion control model mass transfer modeling 1 introduction pb ii contamination attributable to the drinking water is creating considerable concern owing to the non biodegradable nature of pb ii accumulation of this metal in living organisms can cause detrimental effects to health bai et al 2018 bhat et al 2015 sun et al 2018 long term exposure to pb ii beyond the acceptable limits has been identified to cause health problems such as abortion stillbirths sterility mental disturbance and liver and kidney damage chen et al 2019 goel et al 2005 kadirvelu and namasivayam 2010 several available techniques extensively used for the treatment of pb ii from water are chemical precipitation ion exchange membrane separation reverse osmosis and adsorption among these technologies the adsorption technique has gained a lot of attention due to its effective pb ii ion removal less cost and simple operations ilia et al 2017 mittal et al 2006 zhou et al 2019 currently various adsorbents have been reported for pb ii ions removal from aqueous solution such as chitosan tripolyphosphate ngah and fatinathan 2010 modified lignin demirbas 2004 phosphorylated bacterial cellulose oshima et al 2008 shang et al 2019 carbon aerogel kumar et al 2005 carbon nanotubes li et al 2002 and chitosan ng et al 2003 in this study a phosphate modified omc momc np was synthesized for pb ii removal from the aqueous solution because the phosphate groups and hydroxyl groups have shown excellent chelating properties with pb ii illy et al 2015 lian et al 2019 the momc np achieved higher pb ii removal efficiency because of the presence of these functional groups onto the surface of omc the adsorption kinetics and isotherms for pb ii adsorption onto momc np has been investigated by the previous study lian et al 2018 which suggested that the adsorption of pb ii onto momc np was monolayer chemisorption however to the best of our knowledge very limited number of studies were conducted on the mass transfer kinetics of pb ii removal onto surface functionalized omc which needs more exploration to have better insights into the adsorption mechanism the mass transfer of pb ii onto momc np was investigated in order to understand the adsorption mechanism in this study for the first time the understanding of the mass transfer kinetics in pb ii adsorption process is of key importance to evaluate and predict the adsorption performance of momc np guo and wang 2019 theoretically the mass transfer kinetics involves three stages 1 external diffusion through which the adsorbate diffuses from the external liquid phase to the surface around the adsorbent 2 the internal diffusion through which the adsorbate diffuses inside the adsorbent 3 the sorption equilibrium through which the adsorbate was adsorbed by the active sites on the adsorbent bouabidi et al 2018 generally the external diffusion of pb ii species was the controlling step due to the relatively faster adsorption onto active sites during pb ii adsorption process currently the pseudo first order wu et al 2019 the pseudo second order yu et al 2019 and intra particle diffusion models xiong et al 2019 are widely applied to describe the adsorption kinetics however the scopes of the pseudo first order and pseudo second order models only focus on the step of pb ii adsorption onto the active sites meanwhile the scope of intra particle diffusion model only covers the internal diffusion additionally there are very limited number of studies investigating the external diffusion step for pb ii adsorption which is a necessary step regarding the entire mass transfer process therefore the development and validation of a new model which can entirely describe the mass transfer process is of paramount importance several models have been reported regarding the evaluation of the internal and external diffusion rate of the mass transfer process in the previous works which were pore volume diffusion model ocampo perez et al 2010 the pore volume and surface diffusion model souza et al 2017 and a new film pore mass transfer model guo and wang 2019 however all these models exhibited the common potential issues which were only the parts of the whole mass transfer process were determined and the methods were of great complication and high restriction thus the authors were urged to develop a new highly efficient mass transfer kinetics model the modified finite bath diffusion control model to explore the mechanism of mass transfer kinetics of pb ii adsorption onto momc np the modified finite bath diffusion control model can precisely describe the mass transfer kinetics including external diffusion internal diffusion and sorption equilibrium and the key application component of the mass transfer operations and diffusion coefficient which are very important and necessary to understand and predict the rates of mass transfer can be determined the objective of this study is to confirm the applicability of the modified finite bath diffusion control model which can be used to describe the adsorption kinetics of pb ii onto momc np and then to determine the key components of the mass transfer operation and diffusion coefficient 2 experimental procedures 2 1 materials all pb ii solutions prepared in this study used deionized water obtained from brs dual deionization canisters filters the triblock copolymer surfactant pluronic p123 was purchased from sigma aldrich tetraethyl orthosilicate teos 98 hydrochloric acid hcl 37 and hydrofluoric acid hf 48 were purchased from acros organics phosphoric acid h3po4 85 nitric acid 69 71 and pb ii nitrate 99 99 were purchased from fisher scientific a pb ii stock solution with a concentration of 1000 mg l 1 was prepared by dissolving 0 32 g pb no3 2 into 200 ml of di water various standard solutions were prepared by transferring the different amount of stock solutions into 100 ml volumetric flasks the three initial concentrations of 60 mg l 1 80 mg l 1 and 100 mg l 1 pb ii solution were used in this study 2 2 synthesis of adsorbent the omc was prepared via a hard template method using sba 15 silica template the synthesis procedures have been reported by the previous study and other papers ahmad et al 2018a c 2019a b 2019b chao et al 2016 2017 goscianska et al 2014 guo et al 2013 konggidinata et al 2017 shou et al 2016 zhu et al 2006 the momc np was prepared by the following procedures first 2 0 g of omc was added to 1 m nitric acid with continuous stirring at room temperature for 2 h the reflux condenser was applied to contain the mixture at 140 c for 4 h then the mixture was washed with di water and placed in the oven at 80 c for overnight next 65 ml of 85 phosphoric acid was added and the mixture was stirred at room temperature for 2 h the reflux condenser was also used to keep the mixture at 140 c for 8 h the obtained product was washed with 2 l of di water and dried at 80 c for overnight in the oven the overview preparation of momc np is shown in fig 1 2 3 adsorption experiments this study investigated the effects of ph on pb ii adsorption performance which indicated the optimal ph at 5 for pb ii adsorption onto phosphate modified omc therefore all the batch adsorption experiments were conducted under the controlled ph at 5 the procedures in details are as follows 0 04 g momc np was weighed and then put into a 43 ml glass vial glass beads were added and 40 ml standard solution was transferred into the vial the glass vials were capped and sealed with laboratory parafilm the glass vials were placed in an e24 incubator shaker the glass vials containing solution and momc np were agitated at a speed of 275 rpm for 3 h then 10 ml of the solution was filtered and transferred from the vial to a new vial using a syringe filter with a pore size of 0 45 μm finally the pb ii concentration of the blank solution and the filtration solutions were measured by atomic absorption spectrometer perkin elmer pinaacle 900 t tran et al 2018 2 4 development of finite bath diffusion model molecular diffusion controls the rate of most mass transfer operations in micro and nonporous media determination of the diffusion coefficient for a targeted component is very important for predicting rates of mass transfer and many other correlations to find the diffusion constant a modified finite bath diffusion control model gang et al 2007 was derived following the approach of adams et al 1969 assuming a linear change of concentration of adsorbate species across the layer from a value c on the surface of the adsorbent particle to zero at the surface of the inner core of the unconverted form of the functional groups covering layer fick s first law can be written as follows 1 j d c r r i where j flux per unit area in the covering layer r i radius of the inner core comprising the unconverted functional groups covering layer on omc r initial radius of the adsorbent particle and d diffusion coefficient of the adsorbate species within the converted form of the functional groups covering layer the adsorbate concentration at the surface of the functional groups covering layer c can be related to the external concentration c by the following expression yan et al 2011 2 c k c 2 z where k and z are characteristic constants substituting eq 2 into eq 1 and expressing j in moles per unit area of functional groups covering layer within the volume v of the adsorbent particles in terms of the change in concentration of volume v of external solution according to gang and coworkers gang et al 2001 the following is obtained 3 d cv dt 3 v d k c 2 z r r r i the fractional conversion of the functional groups covering layer x can be represented by 4 x 1 r i 3 r s 3 r 3 r s 3 from eq 4 the following equation is obtained 5 r i r 1 x x r s r 3 1 3 where r s radius of the solid core of the adsorbent particle and the adsorbate concentration c is given by 6 c c 0 1 ω x where c 0 initial adsorbate concentration in solution and ω equivalent ratio defined as the ratio of the total adsorption capacity of the adsorbent to the total adsorbate content of the external solution substituting eq 6 into eq 3 yields 7 c 0 vd 1 ω x dt 3 v d k c 0 1 z 1 ω x 2 z r r r i by substituting eq 5 into eq 7 eq 8 is obtained 8 d 1 ω x dt 3 v d k c 0 1 z 1 ω x 2 z v r 2 1 1 x x r s r 3 1 3 to simplify the equation chanda and rempel chanda and rempel 1993 ignored the term of r s r 3 in the above eq 8 and take ω 1 for the special case when r s r 1 and for small values of x thus chanda and rempel s approximation was only applicable for low values of x however x can be as high as 0 8 0 9 in practice so the x r s r 3 term should not be neglected in our study a constant x 0 was introduced into the equation to consider this effect x 0 is a constant related to r s and the fractional attainment of equilibrium adsorption x which is defined as x 0 x r s r 3 on the basis of the definition of ω and high values of x conditions ω can be approximately expressed as r 3 r s 3 r 3 that is ω 1 r s r 3 thus eq 8 becomes 9 d 1 ω x dt 3 v d k c 0 1 z 1 ω x 2 z v r 2 1 1 ω x 1 3 according to the same simplification procedures as used by chanda and rempel chanda and rempel 1993 eq 9 can be rewritten with u 1 ω x λ k c 0 1 z as 10 du dt 3 v d λ u 2 z v r 2 1 u 1 3 11 1 u 1 3 u 2 z du 3 v d λ v r 2 dt const 12 u z 1 1 z 3 u z 2 3 2 3 z 3 v d λ v r 2 t const when t 0 and u 1 13 const 1 z 1 3 2 3 z 1 14 1 ω x z 1 1 z 3 1 ω x z 2 3 2 3 z 3 v d λ v r 2 t 1 1 z 3 2 3 z expanding via a taylor series as the following and ignoring terms that are higher than quadratic in x eq 15 below is derived 15 1 ω x z 1 1 z 1 z 1 ω x z 1 z 2 2 ω x 2 1 z 16 3 1 ω x z 2 3 2 3 z 3 2 3 z 1 z 2 3 ω x z 2 3 z 5 3 2 ω x 2 thus the following approximations are presented 17 1 6 ω x 2 3 v d λ v r 2 t since ω 1 r s r 3 according to chanda and rempel s theory the r s r 3 term can be ignored and the original equation is obtained 18 x 18 v d λ v r 2 1 2 t 1 2 in this study r s r 3 cannot be ignored since x 0 x r s r 3 ω 1 r s r 3 1 x 0 x so eq 18 becomes 19 x 18 v d λ v r 2 1 2 t 1 2 x 0 therefore the plot of x verses t1 2 should be linear with constant x 0 able to be determined from the intercept of the straight line λ d the product of the distribution coefficient and the effective diffusivity can be determined from the slope of the straight line according to chanda and rempel s simplification for z 1 integration of eq 10 becomes 20 1 u 1 u 2 3 du 3 v d λ v r 2 t const 21 ln u 3 u 1 3 3 v d λ v r 2 t const when t 0 and u 1 constant 3 after u is substituted by 1 ω x and ω is replaced by 1 r s r 3 1 x 0 x where r s r 3 can be neglected then eq 21 becomes 22 ln 1 1 x 3 1 1 x 1 3 3 v d λ v r 2 t in our study r s r 3 cannot be ignored and ω 1 r s r 3 1 x 0 x the modified equation is given as 23 ln 1 1 x x 0 3 1 1 x x 0 1 3 3 v d λ v r 2 t therefore the plot of ln 1 1 x x 0 3 1 1 x x 0 1 3 versus t should be linear with constant λ d being determined from the slope of the straight line comparing with the original equations eqs 18 and 22 in chanda and rempel s chanda and rempel 1993 study a constant x 0 was introduced into the modified model in eqs 19 and 23 x 0 is related to the radius of the absorbent particle and the fractional attainment of adsorption the illustration of the modified finite bath diffusion model for pb ii adsorption onto momc np is shown in fig 2 3 results and discussion 3 1 ph effects the experiments of pb ii adsorption onto momc np was conducted at various ph conditions as shown in fig 3 the highest equilibrium adsorption capacity of pb ii was 50 mg g 1 under the initial concentration of pb ii of 50 mg l 1 however the precipitation was observed in the pb ii solution when the ph of the solution reached 5 5 suggesting that the optimum ph was around 5 the formation of insoluble species of pb oh 2 occurred at the ph value of 6 which was reported in the previous study farooghi et al 2018 at ph 5 the adsorption capacity increased with the increase of the ph value therefore the optimal ph value of the solution for the adsorption experiments was around 5 the possible reason is that the ph value of the solution can affect the adsorption capacity by influencing the surface charge of the adsorbents resulting in the dissociation of the functional groups on the surface of momc np namasivayam and kadirvelu 1997 3 2 particle size distribution as shown in fig 2 the particle of momc np was proposed to be spherical in shape the measured size value of an irregularly shaped particle depends on the orientation of the particle relative to the projection surface winger et al 2019 the particle size distribution of the momc np was measured and analyzed as shown in fig 4 from the results the particle size was mainly distributed in the range from 200 to 600 μm however a peak can be observed in the curve which indicates the majority of the particles of momc np in a certain range therefore the average diameter of the particle of momc np applied in the modified finite bath diffusion control model was calculated to be 375 0 μm 3 3 kinetics study the previous study lian et al 2018 has reported that the initial pb ii concentration has a strong effect on the adsorption capacity of the absorbent the adsorption capacity of momc np for pb ii removal exhibited significant improvement of 39 by increasing the initial concentration from 60 mg l 1 to 100 mg l 1 the reason is probably attributed to the higher concentration of pb ii solution which exhibits the stronger driving force for pb ii to reach the active sites present on the surface of momc np similar observations were reported where the increment of adsorption capacity was due to the stronger concentration gradient by the adsorbates shi et al 2018 tan et al 2012 zhang et al 2013 in order to detect the controlling steps affecting the adsorption kinetics the weber morris intra particle diffusion model was used the straight lines at three initial concentrations were plotted by qt vs t1 2 fig 5 if the plot of the model is linear and goes through the origin then the adsorption of pb ii onto the momc np would be controlled by intra particle diffusion however as shown in fig 5 a none of the three lines pass through the origin indicating that the adsorption process is not controlled by intra particle diffusion as shown in fig 5 b a similar trend was observed where the adsorption capacity gradually increases and then flattens as the process reached equilibrium for three initial concentrations this indicates that the faster mass transfer through the boundary layer on the surface of momc np occurred at the beginning and then the adsorption was controlled by slower diffusion of adsorbate into momc np particles singh et al 2012 solsvik and jakobsen 2012 the deviation from the origin may be due to the difference in the rate of diffusion in the initial and final stages of adsorption processes as previously discussed by qiu and coworkers qiu et al 2009 the analysis of the weber morris intra particle diffusion model suggests that the adsorption process is not only controlled by intra particle diffusion the results showed limited information obtained from the weber morris intra particle diffusion model regarding the mass transfer process therefore in order to better understand the adsorption kinetics modified finite bath diffusion model was developed and employed 3 4 finite bath diffusion model analysis the original eq 18 and modified eq 19 finite bath diffusion models were plotted as shown in figs 6 and 7 based on the adsorption experimental data at different initial pb ii concentrations the results show that the experimental results do not fit well with the eq 18 finite bath diffusion models fig 6 based on the low r2 of 0 06 0 14 and 0 11 for the initial concentration of 60 80 100 mg l 1 respectively from fig 6 the results exhibit the trend that the fractional conversion of functional groups covering the layer increase faster at the beginning than that at the end of the adsorption process this phenomenon is probably due to the turning of the external diffusion process to the time controlled process with the increase of the reaction time the more pb ii species are adsorbed by momc np the diffusion rate from the liquid phase to the surface phase of momc np is lowered due to the less concentration of pb ii in the solution similar results were reported by qiu and coworkers qiu et al 2009 on the other hand the modified finite bath diffusion model eq 19 fit well to the three different concentrations 60 mg l 1 80 mg l 1 and 100 mg l 1 with r2 of 0 85 0 88 and 0 84 respectively fig 7 in addition the data in table 1 show that the modified model exhibits a better fit to the results of the initial concentration of 80 mg l 1 with the r2 of 0 88 on the other hand the values of λ d calculated via the slopes of the modified model decrease with the increase of the initial concentration of pb ii indicating that the higher initial concentration of pb ii shows the positive effects on the faster pb ii adsorption process these results were consistent with the results of the initial concentration effects reported in the literature yousefzadeh et al 2018 yu et al 2019 in which the higher initial concentration of pb ii resulted in the faster adsorption kinetics the results of fig 7 show that the x 0 values the intercepts of the modified model lines depicted in fig 7 increased as the initial concentration decreased from 100 mg l 1 to 60 mg l 1 these results could be directly attributed to the less number of active sites adsorbing pb ii species on the adsorbents the lower initial concentration of pb ii resulted in the lower diffusion driving force which helped to diffuse pb ii species inside the particle similar observations were reported in the literature shi et al 2018 tan et al 2012 the x 0 is the adsorption rate at the beginning of the adsorption process which is calculated by the following equation 24 x 0 c c 0 where c is the amount of pb ii adsorbed on the adsorbent at the beginning of the adsorption process c0 is the initial concentration the amount of the adsorbents in the adsorption experiments of three different initial concentrations are the same which indicates that the amount of activated sites for pb ii adsorption are the same therefore the c in three different initial concentrations are similar however the pb ii concentration of the solution is higher enough than the amount of the activated sites even the concentration of 60 mg l 1 therefore higher initial concentration has a lower adsorption rate at the beginning of the adsorption process based on the eq 24 correspondingly the λ d values for eq 19 in table 1 also show the same trend in that as the initial pb ii concentration increases the λ d value decreases from 1 47 10 2 cm2 s 1 to 1 02 10 2 cm2 s 1 which is also consistent with the above discussion the average radius of the modified ordered mesoporous carbon 375 μm as showed in fig 4 was used for calculation of λ d according to the original and modified finite bath diffusion models plots of ln 1 1 x 3 1 1 x 1 3 and ln 1 1 x x 0 3 1 1 x x 0 1 3 verses t should be linear the eqs 22 and 23 were plotted as shown in figs 8 and 9 respectively the x 0 obtained from eq 19 was used in eq 23 based on figs 8 and 9 it can be found that the original model eq 22 and modified model eq 23 fitted well to the experimental data with the average r2 of 0 84 and 0 89 respectively comparing the results of experimental data fitted to the original model eq 18 the model eq 22 exhibited the better fitting indicating that the model eq 22 was more reasonable to describe the adsorption process than eq 18 similarly the modified model eq 23 was better than model eqs 19 and 22 the modified model eq 23 showed the r2 of 0 88 0 92 and 0 88 at the initial concentration of 60 80 100 mg l 1 respectively suggesting the best fitting to the adsorption experiments data the λ d values were also calculated from the slopes of the lines in fig 9 and recorded in table 1 the λ d values decreased from 2 42 10 2 cm2 s 1 to 1 53 10 2 cm2 s 1 with the increase of the initial concentration from 60 mg l 1 to 100 mg l 1 the average of the λ d values for the momc np adsorbent is 1 63 10 2 cm2 s 1 chanda and rempel chanda and rempel 1993 found that the sorption of uranyl sulfate on pvp coated silica gel correlated well with the original model exhibiting a λ d value of 5 4 10 6 cm2 s 1 some studies has already reported a λ d value of 4 1 10 6 cm2 s 1 for quaternized poly 4 vinylpyridine coated activated carbon and a λ d value of 2 9 10 4 cm2 s 1 for the iron oxide coated gac gang et al 2007 yan et al 2011 it can be found that λ d value in this study is higher than what they found the one possible reason is that momc np has bigger pore size compared with the other reports overall the modified finite bath diffusion model fitted well to the experiments with a diffusion coefficient λ d of 1 63 10 2 cm2 s 1 overall all these results suggested that the modified finite bath diffusion model can describe the entire mass transfer kinetics reasonably and precisely than weber morris intra particle diffusion model during pb ii adsorption process the value of λ d is regarded as a necessary and useful parameter expressing the rate of mass transfer process during the adsorption process yan et al 2011 therefore the modified finite bath diffusion model could be a new method in the applications of describing the mass transfer process during other adsorption processes 4 conclusions the omc was successfully synthesized via hard template method and phosphate functional groups modified omc was also prepared using phosphate acid the effects of the ph were investigated and the results showed that the optimal ph value for pb ii adsorption onto momc np was around 5 the weber morris intra particle diffusion model was applied to investigate the mass transfer process and indicated that the adsorption process was not only controlled by intra particle diffusion additionally the finite bath diffusion model and the modified finite bath diffusion model were successfully developed and described the entire mass transfer process during the pb ii adsorption precisely in this work the modified finite bath diffusion model showed better description regarding the entire mass transfer process during the adsorption of pb ii onto momc np and the overall diffusion coefficient λ d was found to be 1 63 10 2 cm2 s 1 which is much higher than those reported in other studies therefore the modified finite bath diffusion model could become a potentially precise and highly efficient model to describe the mass transfer process during other adsorption process in the future acknowledgments this work was supported by louisiana board of regents leqsf 2015 16 enh tr 32 and leqsf 2016 17 rd c 15 and the university of louisiana at lafayette appreciation to the staffs and assistance provided from the department of civil engineering department of chemical engineering department of chemistry and department of biology at the university of louisiana at lafayette is also acknowledged in this study 
1544,phosphate modified ordered mesoporous carbon momc np has been synthesized and proven to be an effective adsorbent for pb ii removal from aqueous solutions however the key application components of the mass transfer operations and diffusion coefficient have not been determined in this study a modified finite bath diffusion control model was mathematically developed containing a constant related to the radius of the adsorbent particle and the fractional attainment of adsorption the adsorption experiments were conducted under various initial pb ii concentrations ranging from 60 mg l 1 to 100 mg l 1 the results suggested that the modified finite bath diffusion control model was more applicable to the experimental data than the original finite bath diffusion control model the average value of the diffusion coefficient λ d obtained from the modified finite bath diffusion control model was 1 63 10 2 cm2 s 1 indicating the effective diffusivity in the adsorption of pb ii on momc np overall the modified finite bath diffusion control model exhibited the precise description and simulation of the mass transfer kinetics for pb ii adsorption onto momc np therefore the modified finite bath diffusion control model could be effectively used to investigate the mass transfer kinetics of the adsorption process graphical abstract unlabelled image keywords omc phosphate modification lead ii adsorption finite bath diffusion control model mass transfer modeling 1 introduction pb ii contamination attributable to the drinking water is creating considerable concern owing to the non biodegradable nature of pb ii accumulation of this metal in living organisms can cause detrimental effects to health bai et al 2018 bhat et al 2015 sun et al 2018 long term exposure to pb ii beyond the acceptable limits has been identified to cause health problems such as abortion stillbirths sterility mental disturbance and liver and kidney damage chen et al 2019 goel et al 2005 kadirvelu and namasivayam 2010 several available techniques extensively used for the treatment of pb ii from water are chemical precipitation ion exchange membrane separation reverse osmosis and adsorption among these technologies the adsorption technique has gained a lot of attention due to its effective pb ii ion removal less cost and simple operations ilia et al 2017 mittal et al 2006 zhou et al 2019 currently various adsorbents have been reported for pb ii ions removal from aqueous solution such as chitosan tripolyphosphate ngah and fatinathan 2010 modified lignin demirbas 2004 phosphorylated bacterial cellulose oshima et al 2008 shang et al 2019 carbon aerogel kumar et al 2005 carbon nanotubes li et al 2002 and chitosan ng et al 2003 in this study a phosphate modified omc momc np was synthesized for pb ii removal from the aqueous solution because the phosphate groups and hydroxyl groups have shown excellent chelating properties with pb ii illy et al 2015 lian et al 2019 the momc np achieved higher pb ii removal efficiency because of the presence of these functional groups onto the surface of omc the adsorption kinetics and isotherms for pb ii adsorption onto momc np has been investigated by the previous study lian et al 2018 which suggested that the adsorption of pb ii onto momc np was monolayer chemisorption however to the best of our knowledge very limited number of studies were conducted on the mass transfer kinetics of pb ii removal onto surface functionalized omc which needs more exploration to have better insights into the adsorption mechanism the mass transfer of pb ii onto momc np was investigated in order to understand the adsorption mechanism in this study for the first time the understanding of the mass transfer kinetics in pb ii adsorption process is of key importance to evaluate and predict the adsorption performance of momc np guo and wang 2019 theoretically the mass transfer kinetics involves three stages 1 external diffusion through which the adsorbate diffuses from the external liquid phase to the surface around the adsorbent 2 the internal diffusion through which the adsorbate diffuses inside the adsorbent 3 the sorption equilibrium through which the adsorbate was adsorbed by the active sites on the adsorbent bouabidi et al 2018 generally the external diffusion of pb ii species was the controlling step due to the relatively faster adsorption onto active sites during pb ii adsorption process currently the pseudo first order wu et al 2019 the pseudo second order yu et al 2019 and intra particle diffusion models xiong et al 2019 are widely applied to describe the adsorption kinetics however the scopes of the pseudo first order and pseudo second order models only focus on the step of pb ii adsorption onto the active sites meanwhile the scope of intra particle diffusion model only covers the internal diffusion additionally there are very limited number of studies investigating the external diffusion step for pb ii adsorption which is a necessary step regarding the entire mass transfer process therefore the development and validation of a new model which can entirely describe the mass transfer process is of paramount importance several models have been reported regarding the evaluation of the internal and external diffusion rate of the mass transfer process in the previous works which were pore volume diffusion model ocampo perez et al 2010 the pore volume and surface diffusion model souza et al 2017 and a new film pore mass transfer model guo and wang 2019 however all these models exhibited the common potential issues which were only the parts of the whole mass transfer process were determined and the methods were of great complication and high restriction thus the authors were urged to develop a new highly efficient mass transfer kinetics model the modified finite bath diffusion control model to explore the mechanism of mass transfer kinetics of pb ii adsorption onto momc np the modified finite bath diffusion control model can precisely describe the mass transfer kinetics including external diffusion internal diffusion and sorption equilibrium and the key application component of the mass transfer operations and diffusion coefficient which are very important and necessary to understand and predict the rates of mass transfer can be determined the objective of this study is to confirm the applicability of the modified finite bath diffusion control model which can be used to describe the adsorption kinetics of pb ii onto momc np and then to determine the key components of the mass transfer operation and diffusion coefficient 2 experimental procedures 2 1 materials all pb ii solutions prepared in this study used deionized water obtained from brs dual deionization canisters filters the triblock copolymer surfactant pluronic p123 was purchased from sigma aldrich tetraethyl orthosilicate teos 98 hydrochloric acid hcl 37 and hydrofluoric acid hf 48 were purchased from acros organics phosphoric acid h3po4 85 nitric acid 69 71 and pb ii nitrate 99 99 were purchased from fisher scientific a pb ii stock solution with a concentration of 1000 mg l 1 was prepared by dissolving 0 32 g pb no3 2 into 200 ml of di water various standard solutions were prepared by transferring the different amount of stock solutions into 100 ml volumetric flasks the three initial concentrations of 60 mg l 1 80 mg l 1 and 100 mg l 1 pb ii solution were used in this study 2 2 synthesis of adsorbent the omc was prepared via a hard template method using sba 15 silica template the synthesis procedures have been reported by the previous study and other papers ahmad et al 2018a c 2019a b 2019b chao et al 2016 2017 goscianska et al 2014 guo et al 2013 konggidinata et al 2017 shou et al 2016 zhu et al 2006 the momc np was prepared by the following procedures first 2 0 g of omc was added to 1 m nitric acid with continuous stirring at room temperature for 2 h the reflux condenser was applied to contain the mixture at 140 c for 4 h then the mixture was washed with di water and placed in the oven at 80 c for overnight next 65 ml of 85 phosphoric acid was added and the mixture was stirred at room temperature for 2 h the reflux condenser was also used to keep the mixture at 140 c for 8 h the obtained product was washed with 2 l of di water and dried at 80 c for overnight in the oven the overview preparation of momc np is shown in fig 1 2 3 adsorption experiments this study investigated the effects of ph on pb ii adsorption performance which indicated the optimal ph at 5 for pb ii adsorption onto phosphate modified omc therefore all the batch adsorption experiments were conducted under the controlled ph at 5 the procedures in details are as follows 0 04 g momc np was weighed and then put into a 43 ml glass vial glass beads were added and 40 ml standard solution was transferred into the vial the glass vials were capped and sealed with laboratory parafilm the glass vials were placed in an e24 incubator shaker the glass vials containing solution and momc np were agitated at a speed of 275 rpm for 3 h then 10 ml of the solution was filtered and transferred from the vial to a new vial using a syringe filter with a pore size of 0 45 μm finally the pb ii concentration of the blank solution and the filtration solutions were measured by atomic absorption spectrometer perkin elmer pinaacle 900 t tran et al 2018 2 4 development of finite bath diffusion model molecular diffusion controls the rate of most mass transfer operations in micro and nonporous media determination of the diffusion coefficient for a targeted component is very important for predicting rates of mass transfer and many other correlations to find the diffusion constant a modified finite bath diffusion control model gang et al 2007 was derived following the approach of adams et al 1969 assuming a linear change of concentration of adsorbate species across the layer from a value c on the surface of the adsorbent particle to zero at the surface of the inner core of the unconverted form of the functional groups covering layer fick s first law can be written as follows 1 j d c r r i where j flux per unit area in the covering layer r i radius of the inner core comprising the unconverted functional groups covering layer on omc r initial radius of the adsorbent particle and d diffusion coefficient of the adsorbate species within the converted form of the functional groups covering layer the adsorbate concentration at the surface of the functional groups covering layer c can be related to the external concentration c by the following expression yan et al 2011 2 c k c 2 z where k and z are characteristic constants substituting eq 2 into eq 1 and expressing j in moles per unit area of functional groups covering layer within the volume v of the adsorbent particles in terms of the change in concentration of volume v of external solution according to gang and coworkers gang et al 2001 the following is obtained 3 d cv dt 3 v d k c 2 z r r r i the fractional conversion of the functional groups covering layer x can be represented by 4 x 1 r i 3 r s 3 r 3 r s 3 from eq 4 the following equation is obtained 5 r i r 1 x x r s r 3 1 3 where r s radius of the solid core of the adsorbent particle and the adsorbate concentration c is given by 6 c c 0 1 ω x where c 0 initial adsorbate concentration in solution and ω equivalent ratio defined as the ratio of the total adsorption capacity of the adsorbent to the total adsorbate content of the external solution substituting eq 6 into eq 3 yields 7 c 0 vd 1 ω x dt 3 v d k c 0 1 z 1 ω x 2 z r r r i by substituting eq 5 into eq 7 eq 8 is obtained 8 d 1 ω x dt 3 v d k c 0 1 z 1 ω x 2 z v r 2 1 1 x x r s r 3 1 3 to simplify the equation chanda and rempel chanda and rempel 1993 ignored the term of r s r 3 in the above eq 8 and take ω 1 for the special case when r s r 1 and for small values of x thus chanda and rempel s approximation was only applicable for low values of x however x can be as high as 0 8 0 9 in practice so the x r s r 3 term should not be neglected in our study a constant x 0 was introduced into the equation to consider this effect x 0 is a constant related to r s and the fractional attainment of equilibrium adsorption x which is defined as x 0 x r s r 3 on the basis of the definition of ω and high values of x conditions ω can be approximately expressed as r 3 r s 3 r 3 that is ω 1 r s r 3 thus eq 8 becomes 9 d 1 ω x dt 3 v d k c 0 1 z 1 ω x 2 z v r 2 1 1 ω x 1 3 according to the same simplification procedures as used by chanda and rempel chanda and rempel 1993 eq 9 can be rewritten with u 1 ω x λ k c 0 1 z as 10 du dt 3 v d λ u 2 z v r 2 1 u 1 3 11 1 u 1 3 u 2 z du 3 v d λ v r 2 dt const 12 u z 1 1 z 3 u z 2 3 2 3 z 3 v d λ v r 2 t const when t 0 and u 1 13 const 1 z 1 3 2 3 z 1 14 1 ω x z 1 1 z 3 1 ω x z 2 3 2 3 z 3 v d λ v r 2 t 1 1 z 3 2 3 z expanding via a taylor series as the following and ignoring terms that are higher than quadratic in x eq 15 below is derived 15 1 ω x z 1 1 z 1 z 1 ω x z 1 z 2 2 ω x 2 1 z 16 3 1 ω x z 2 3 2 3 z 3 2 3 z 1 z 2 3 ω x z 2 3 z 5 3 2 ω x 2 thus the following approximations are presented 17 1 6 ω x 2 3 v d λ v r 2 t since ω 1 r s r 3 according to chanda and rempel s theory the r s r 3 term can be ignored and the original equation is obtained 18 x 18 v d λ v r 2 1 2 t 1 2 in this study r s r 3 cannot be ignored since x 0 x r s r 3 ω 1 r s r 3 1 x 0 x so eq 18 becomes 19 x 18 v d λ v r 2 1 2 t 1 2 x 0 therefore the plot of x verses t1 2 should be linear with constant x 0 able to be determined from the intercept of the straight line λ d the product of the distribution coefficient and the effective diffusivity can be determined from the slope of the straight line according to chanda and rempel s simplification for z 1 integration of eq 10 becomes 20 1 u 1 u 2 3 du 3 v d λ v r 2 t const 21 ln u 3 u 1 3 3 v d λ v r 2 t const when t 0 and u 1 constant 3 after u is substituted by 1 ω x and ω is replaced by 1 r s r 3 1 x 0 x where r s r 3 can be neglected then eq 21 becomes 22 ln 1 1 x 3 1 1 x 1 3 3 v d λ v r 2 t in our study r s r 3 cannot be ignored and ω 1 r s r 3 1 x 0 x the modified equation is given as 23 ln 1 1 x x 0 3 1 1 x x 0 1 3 3 v d λ v r 2 t therefore the plot of ln 1 1 x x 0 3 1 1 x x 0 1 3 versus t should be linear with constant λ d being determined from the slope of the straight line comparing with the original equations eqs 18 and 22 in chanda and rempel s chanda and rempel 1993 study a constant x 0 was introduced into the modified model in eqs 19 and 23 x 0 is related to the radius of the absorbent particle and the fractional attainment of adsorption the illustration of the modified finite bath diffusion model for pb ii adsorption onto momc np is shown in fig 2 3 results and discussion 3 1 ph effects the experiments of pb ii adsorption onto momc np was conducted at various ph conditions as shown in fig 3 the highest equilibrium adsorption capacity of pb ii was 50 mg g 1 under the initial concentration of pb ii of 50 mg l 1 however the precipitation was observed in the pb ii solution when the ph of the solution reached 5 5 suggesting that the optimum ph was around 5 the formation of insoluble species of pb oh 2 occurred at the ph value of 6 which was reported in the previous study farooghi et al 2018 at ph 5 the adsorption capacity increased with the increase of the ph value therefore the optimal ph value of the solution for the adsorption experiments was around 5 the possible reason is that the ph value of the solution can affect the adsorption capacity by influencing the surface charge of the adsorbents resulting in the dissociation of the functional groups on the surface of momc np namasivayam and kadirvelu 1997 3 2 particle size distribution as shown in fig 2 the particle of momc np was proposed to be spherical in shape the measured size value of an irregularly shaped particle depends on the orientation of the particle relative to the projection surface winger et al 2019 the particle size distribution of the momc np was measured and analyzed as shown in fig 4 from the results the particle size was mainly distributed in the range from 200 to 600 μm however a peak can be observed in the curve which indicates the majority of the particles of momc np in a certain range therefore the average diameter of the particle of momc np applied in the modified finite bath diffusion control model was calculated to be 375 0 μm 3 3 kinetics study the previous study lian et al 2018 has reported that the initial pb ii concentration has a strong effect on the adsorption capacity of the absorbent the adsorption capacity of momc np for pb ii removal exhibited significant improvement of 39 by increasing the initial concentration from 60 mg l 1 to 100 mg l 1 the reason is probably attributed to the higher concentration of pb ii solution which exhibits the stronger driving force for pb ii to reach the active sites present on the surface of momc np similar observations were reported where the increment of adsorption capacity was due to the stronger concentration gradient by the adsorbates shi et al 2018 tan et al 2012 zhang et al 2013 in order to detect the controlling steps affecting the adsorption kinetics the weber morris intra particle diffusion model was used the straight lines at three initial concentrations were plotted by qt vs t1 2 fig 5 if the plot of the model is linear and goes through the origin then the adsorption of pb ii onto the momc np would be controlled by intra particle diffusion however as shown in fig 5 a none of the three lines pass through the origin indicating that the adsorption process is not controlled by intra particle diffusion as shown in fig 5 b a similar trend was observed where the adsorption capacity gradually increases and then flattens as the process reached equilibrium for three initial concentrations this indicates that the faster mass transfer through the boundary layer on the surface of momc np occurred at the beginning and then the adsorption was controlled by slower diffusion of adsorbate into momc np particles singh et al 2012 solsvik and jakobsen 2012 the deviation from the origin may be due to the difference in the rate of diffusion in the initial and final stages of adsorption processes as previously discussed by qiu and coworkers qiu et al 2009 the analysis of the weber morris intra particle diffusion model suggests that the adsorption process is not only controlled by intra particle diffusion the results showed limited information obtained from the weber morris intra particle diffusion model regarding the mass transfer process therefore in order to better understand the adsorption kinetics modified finite bath diffusion model was developed and employed 3 4 finite bath diffusion model analysis the original eq 18 and modified eq 19 finite bath diffusion models were plotted as shown in figs 6 and 7 based on the adsorption experimental data at different initial pb ii concentrations the results show that the experimental results do not fit well with the eq 18 finite bath diffusion models fig 6 based on the low r2 of 0 06 0 14 and 0 11 for the initial concentration of 60 80 100 mg l 1 respectively from fig 6 the results exhibit the trend that the fractional conversion of functional groups covering the layer increase faster at the beginning than that at the end of the adsorption process this phenomenon is probably due to the turning of the external diffusion process to the time controlled process with the increase of the reaction time the more pb ii species are adsorbed by momc np the diffusion rate from the liquid phase to the surface phase of momc np is lowered due to the less concentration of pb ii in the solution similar results were reported by qiu and coworkers qiu et al 2009 on the other hand the modified finite bath diffusion model eq 19 fit well to the three different concentrations 60 mg l 1 80 mg l 1 and 100 mg l 1 with r2 of 0 85 0 88 and 0 84 respectively fig 7 in addition the data in table 1 show that the modified model exhibits a better fit to the results of the initial concentration of 80 mg l 1 with the r2 of 0 88 on the other hand the values of λ d calculated via the slopes of the modified model decrease with the increase of the initial concentration of pb ii indicating that the higher initial concentration of pb ii shows the positive effects on the faster pb ii adsorption process these results were consistent with the results of the initial concentration effects reported in the literature yousefzadeh et al 2018 yu et al 2019 in which the higher initial concentration of pb ii resulted in the faster adsorption kinetics the results of fig 7 show that the x 0 values the intercepts of the modified model lines depicted in fig 7 increased as the initial concentration decreased from 100 mg l 1 to 60 mg l 1 these results could be directly attributed to the less number of active sites adsorbing pb ii species on the adsorbents the lower initial concentration of pb ii resulted in the lower diffusion driving force which helped to diffuse pb ii species inside the particle similar observations were reported in the literature shi et al 2018 tan et al 2012 the x 0 is the adsorption rate at the beginning of the adsorption process which is calculated by the following equation 24 x 0 c c 0 where c is the amount of pb ii adsorbed on the adsorbent at the beginning of the adsorption process c0 is the initial concentration the amount of the adsorbents in the adsorption experiments of three different initial concentrations are the same which indicates that the amount of activated sites for pb ii adsorption are the same therefore the c in three different initial concentrations are similar however the pb ii concentration of the solution is higher enough than the amount of the activated sites even the concentration of 60 mg l 1 therefore higher initial concentration has a lower adsorption rate at the beginning of the adsorption process based on the eq 24 correspondingly the λ d values for eq 19 in table 1 also show the same trend in that as the initial pb ii concentration increases the λ d value decreases from 1 47 10 2 cm2 s 1 to 1 02 10 2 cm2 s 1 which is also consistent with the above discussion the average radius of the modified ordered mesoporous carbon 375 μm as showed in fig 4 was used for calculation of λ d according to the original and modified finite bath diffusion models plots of ln 1 1 x 3 1 1 x 1 3 and ln 1 1 x x 0 3 1 1 x x 0 1 3 verses t should be linear the eqs 22 and 23 were plotted as shown in figs 8 and 9 respectively the x 0 obtained from eq 19 was used in eq 23 based on figs 8 and 9 it can be found that the original model eq 22 and modified model eq 23 fitted well to the experimental data with the average r2 of 0 84 and 0 89 respectively comparing the results of experimental data fitted to the original model eq 18 the model eq 22 exhibited the better fitting indicating that the model eq 22 was more reasonable to describe the adsorption process than eq 18 similarly the modified model eq 23 was better than model eqs 19 and 22 the modified model eq 23 showed the r2 of 0 88 0 92 and 0 88 at the initial concentration of 60 80 100 mg l 1 respectively suggesting the best fitting to the adsorption experiments data the λ d values were also calculated from the slopes of the lines in fig 9 and recorded in table 1 the λ d values decreased from 2 42 10 2 cm2 s 1 to 1 53 10 2 cm2 s 1 with the increase of the initial concentration from 60 mg l 1 to 100 mg l 1 the average of the λ d values for the momc np adsorbent is 1 63 10 2 cm2 s 1 chanda and rempel chanda and rempel 1993 found that the sorption of uranyl sulfate on pvp coated silica gel correlated well with the original model exhibiting a λ d value of 5 4 10 6 cm2 s 1 some studies has already reported a λ d value of 4 1 10 6 cm2 s 1 for quaternized poly 4 vinylpyridine coated activated carbon and a λ d value of 2 9 10 4 cm2 s 1 for the iron oxide coated gac gang et al 2007 yan et al 2011 it can be found that λ d value in this study is higher than what they found the one possible reason is that momc np has bigger pore size compared with the other reports overall the modified finite bath diffusion model fitted well to the experiments with a diffusion coefficient λ d of 1 63 10 2 cm2 s 1 overall all these results suggested that the modified finite bath diffusion model can describe the entire mass transfer kinetics reasonably and precisely than weber morris intra particle diffusion model during pb ii adsorption process the value of λ d is regarded as a necessary and useful parameter expressing the rate of mass transfer process during the adsorption process yan et al 2011 therefore the modified finite bath diffusion model could be a new method in the applications of describing the mass transfer process during other adsorption processes 4 conclusions the omc was successfully synthesized via hard template method and phosphate functional groups modified omc was also prepared using phosphate acid the effects of the ph were investigated and the results showed that the optimal ph value for pb ii adsorption onto momc np was around 5 the weber morris intra particle diffusion model was applied to investigate the mass transfer process and indicated that the adsorption process was not only controlled by intra particle diffusion additionally the finite bath diffusion model and the modified finite bath diffusion model were successfully developed and described the entire mass transfer process during the pb ii adsorption precisely in this work the modified finite bath diffusion model showed better description regarding the entire mass transfer process during the adsorption of pb ii onto momc np and the overall diffusion coefficient λ d was found to be 1 63 10 2 cm2 s 1 which is much higher than those reported in other studies therefore the modified finite bath diffusion model could become a potentially precise and highly efficient model to describe the mass transfer process during other adsorption process in the future acknowledgments this work was supported by louisiana board of regents leqsf 2015 16 enh tr 32 and leqsf 2016 17 rd c 15 and the university of louisiana at lafayette appreciation to the staffs and assistance provided from the department of civil engineering department of chemical engineering department of chemistry and department of biology at the university of louisiana at lafayette is also acknowledged in this study 
